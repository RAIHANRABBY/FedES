{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["VNy6-RxAKjH8"],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Mbfw8uvdftFM","executionInfo":{"status":"ok","timestamp":1717432373692,"user_tz":-360,"elapsed":1998,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sb"]},{"cell_type":"code","source":["\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"INiFJfLjgOkx","executionInfo":{"status":"ok","timestamp":1717432373693,"user_tz":-360,"elapsed":10,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import ExtraTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score, cross_val_predict"],"metadata":{"id":"lYo2Uq77gQSH","executionInfo":{"status":"ok","timestamp":1717432377343,"user_tz":-360,"elapsed":3659,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPool1D, Flatten, Dropout,LSTM"],"metadata":{"id":"g66575_xgVzz","executionInfo":{"status":"ok","timestamp":1717432379662,"user_tz":-360,"elapsed":2327,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MOCNWlamfr3v","executionInfo":{"status":"ok","timestamp":1717432404545,"user_tz":-360,"elapsed":24891,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"e3d341a2-3e08-4ed4-af31-185217a7d611"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Raw_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/only data/raw_data.npz'\n","\n","Theta_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/feature domain/Alpha_frequency.npz'\n","\n","\n","\n","# RAW = np.load(Raw_data, allow_pickle=True)  # Allow loading pickled object arrays\n","# X = RAW['X'].astype('float64')\n","# Y = RAW['Y'].astype('float64')\n","# group = RAW['Group'].astype('float64')"],"metadata":{"id":"iNy9eOGMf2qO","executionInfo":{"status":"ok","timestamp":1717432404546,"user_tz":-360,"elapsed":9,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["This is a good performing model"],"metadata":{"id":"PzeABzSyHgKg"}},{"cell_type":"code","source":["# %%capture\n","# !pip install wandb"],"metadata":{"id":"bSIlXc4sZuAW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import wandb\n","# !wandb login"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vBQBhtSpZvDI","executionInfo":{"status":"ok","timestamp":1716584494629,"user_tz":-360,"elapsed":99086,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}},"outputId":"2e039ac0-fa75-4289-a177-772fe10591a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}]},{"cell_type":"markdown","source":["# CNN-LSTM"],"metadata":{"id":"6DhAYwXUSE9z"}},{"cell_type":"code","source":["%%capture\n","!pip install tensorflow_addons"],"metadata":{"id":"0kg8-Rai9ecZ","executionInfo":{"status":"ok","timestamp":1717432620055,"user_tz":-360,"elapsed":8866,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(LSTM(256, return_sequences=True))\n","    model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dense(32, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_callback = ModelCheckpoint(\n","                f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Alpha/CNN_LSTM/best_model_{run_name}.h5',\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Alpha/CNN_LSTM/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Evaluate client model\n","            y_pred = (client_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"VvjC2xCQNHLP","executionInfo":{"status":"ok","timestamp":1717432653485,"user_tz":-360,"elapsed":618,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4ba388a5-0d60-4a57-a3a4-000e55eca076"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["global_model, metrics_df = federated_learning(Theta_data)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVURUnmYNNNg","outputId":"7949a6b4-7703-4b6f-899f-3e961a7b4ade","executionInfo":{"status":"ok","timestamp":1717433899010,"user_tz":-360,"elapsed":1240743,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"collapsed":true},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.6932 - accuracy: 0.4930"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 19s 59ms/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6931 - val_accuracy: 0.5172\n","Epoch 2/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5124 - val_loss: 0.6931 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.4995 - val_loss: 0.6932 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5075 - val_loss: 0.6932 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5070 - val_loss: 0.6932 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5084 - val_loss: 0.6932 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5078 - val_loss: 0.6932 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5062 - val_loss: 0.6932 - val_accuracy: 0.4849\n","Epoch 9/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6930 - accuracy: 0.5065 - val_loss: 0.6932 - val_accuracy: 0.4849\n","Epoch 10/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6930 - accuracy: 0.5065 - val_loss: 0.6932 - val_accuracy: 0.4849\n","Epoch 11/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6930 - accuracy: 0.5081 - val_loss: 0.6932 - val_accuracy: 0.4849\n","Epoch 12/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6930 - accuracy: 0.5081 - val_loss: 0.6932 - val_accuracy: 0.4849\n","Epoch 13/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6930 - accuracy: 0.5075 - val_loss: 0.6932 - val_accuracy: 0.4849\n","Epoch 14/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6929 - accuracy: 0.5110 - val_loss: 0.6932 - val_accuracy: 0.4860\n","Epoch 15/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6928 - accuracy: 0.5167 - val_loss: 0.6932 - val_accuracy: 0.4838\n","Epoch 16/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6928 - accuracy: 0.5189 - val_loss: 0.6931 - val_accuracy: 0.4849\n","Epoch 17/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6927 - accuracy: 0.5218 - val_loss: 0.6931 - val_accuracy: 0.4828\n","Epoch 18/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6927 - accuracy: 0.5124 - val_loss: 0.6931 - val_accuracy: 0.4849\n","Epoch 19/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6924 - accuracy: 0.5423 - val_loss: 0.6930 - val_accuracy: 0.5280\n","Epoch 20/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6922 - accuracy: 0.5647 - val_loss: 0.6929 - val_accuracy: 0.5162\n","Epoch 21/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6920 - accuracy: 0.5504 - val_loss: 0.6928 - val_accuracy: 0.5528\n","Epoch 22/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6917 - accuracy: 0.5649 - val_loss: 0.6928 - val_accuracy: 0.5065\n","Epoch 23/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6910 - accuracy: 0.5577 - val_loss: 0.6923 - val_accuracy: 0.5560\n","Epoch 24/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6905 - accuracy: 0.5800 - val_loss: 0.6920 - val_accuracy: 0.5496\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6898 - accuracy: 0.5665 - val_loss: 0.6916 - val_accuracy: 0.5550\n","Epoch 26/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6889 - accuracy: 0.5663 - val_loss: 0.6909 - val_accuracy: 0.5539\n","Epoch 27/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6875 - accuracy: 0.5717 - val_loss: 0.6905 - val_accuracy: 0.5582\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6864 - accuracy: 0.5811 - val_loss: 0.6915 - val_accuracy: 0.5194\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6841 - accuracy: 0.5735 - val_loss: 0.6903 - val_accuracy: 0.5420\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6823 - accuracy: 0.5789 - val_loss: 0.6877 - val_accuracy: 0.5582\n","Epoch 31/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6788 - accuracy: 0.5932 - val_loss: 0.6876 - val_accuracy: 0.5614\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6758 - accuracy: 0.5889 - val_loss: 0.6868 - val_accuracy: 0.5614\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6710 - accuracy: 0.5994 - val_loss: 0.6881 - val_accuracy: 0.5539\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6679 - accuracy: 0.6008 - val_loss: 0.6872 - val_accuracy: 0.5539\n","Epoch 35/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6653 - accuracy: 0.5967 - val_loss: 0.6856 - val_accuracy: 0.5636\n","Epoch 36/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6606 - accuracy: 0.6096 - val_loss: 0.6864 - val_accuracy: 0.5647\n","Epoch 37/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.6617 - accuracy: 0.6013 - val_loss: 0.6856 - val_accuracy: 0.5722\n","Epoch 38/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6564 - accuracy: 0.5956 - val_loss: 0.6860 - val_accuracy: 0.5722\n","Epoch 39/100\n","29/29 [==============================] - 1s 40ms/step - loss: 0.6515 - accuracy: 0.6091 - val_loss: 0.6878 - val_accuracy: 0.5733\n","Epoch 40/100\n","29/29 [==============================] - 1s 47ms/step - loss: 0.6446 - accuracy: 0.6272 - val_loss: 0.6863 - val_accuracy: 0.5776\n","Epoch 41/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6421 - accuracy: 0.6228 - val_loss: 0.6873 - val_accuracy: 0.5754\n","Epoch 42/100\n","29/29 [==============================] - 1s 41ms/step - loss: 0.6398 - accuracy: 0.6188 - val_loss: 0.6900 - val_accuracy: 0.5819\n","Epoch 43/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.6350 - accuracy: 0.6325 - val_loss: 0.6908 - val_accuracy: 0.5733\n","Epoch 44/100\n","29/29 [==============================] - 1s 36ms/step - loss: 0.6343 - accuracy: 0.6298 - val_loss: 0.6902 - val_accuracy: 0.5873\n","Epoch 45/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6303 - accuracy: 0.6261 - val_loss: 0.6978 - val_accuracy: 0.5625\n","Epoch 46/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6275 - accuracy: 0.6414 - val_loss: 0.6890 - val_accuracy: 0.5981\n","Epoch 47/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6192 - accuracy: 0.6430 - val_loss: 0.6918 - val_accuracy: 0.5894\n","Epoch 48/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6199 - accuracy: 0.6495 - val_loss: 0.6900 - val_accuracy: 0.6013\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6142 - accuracy: 0.6552 - val_loss: 0.6937 - val_accuracy: 0.5905\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6101 - accuracy: 0.6549 - val_loss: 0.7054 - val_accuracy: 0.5657\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6059 - accuracy: 0.6565 - val_loss: 0.6990 - val_accuracy: 0.5884\n","Epoch 52/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6060 - accuracy: 0.6579 - val_loss: 0.6933 - val_accuracy: 0.6024\n","Epoch 53/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6038 - accuracy: 0.6633 - val_loss: 0.6936 - val_accuracy: 0.6099\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5976 - accuracy: 0.6668 - val_loss: 0.6953 - val_accuracy: 0.6067\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5899 - accuracy: 0.6756 - val_loss: 0.6962 - val_accuracy: 0.6099\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5896 - accuracy: 0.6743 - val_loss: 0.6983 - val_accuracy: 0.6013\n","Epoch 57/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5850 - accuracy: 0.6773 - val_loss: 0.6990 - val_accuracy: 0.6088\n","Epoch 58/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5795 - accuracy: 0.6843 - val_loss: 0.7004 - val_accuracy: 0.6131\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5788 - accuracy: 0.6856 - val_loss: 0.7052 - val_accuracy: 0.6131\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5783 - accuracy: 0.6778 - val_loss: 0.7050 - val_accuracy: 0.6056\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5715 - accuracy: 0.6956 - val_loss: 0.7118 - val_accuracy: 0.5797\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5652 - accuracy: 0.6980 - val_loss: 0.7151 - val_accuracy: 0.5797\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5637 - accuracy: 0.7023 - val_loss: 0.7090 - val_accuracy: 0.6131\n","Epoch 64/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5622 - accuracy: 0.7004 - val_loss: 0.7324 - val_accuracy: 0.5582\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5606 - accuracy: 0.6942 - val_loss: 0.7123 - val_accuracy: 0.6078\n","Epoch 66/100\n","29/29 [==============================] - 1s 38ms/step - loss: 0.5564 - accuracy: 0.7107 - val_loss: 0.7142 - val_accuracy: 0.6153\n","Epoch 67/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.5512 - accuracy: 0.7080 - val_loss: 0.7427 - val_accuracy: 0.5625\n","Epoch 68/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5451 - accuracy: 0.7085 - val_loss: 0.7197 - val_accuracy: 0.6078\n","Epoch 69/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5444 - accuracy: 0.7096 - val_loss: 0.7234 - val_accuracy: 0.6121\n","Epoch 70/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5426 - accuracy: 0.7150 - val_loss: 0.7215 - val_accuracy: 0.6067\n","Epoch 71/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5350 - accuracy: 0.7223 - val_loss: 0.7323 - val_accuracy: 0.5841\n","Epoch 72/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5290 - accuracy: 0.7247 - val_loss: 0.7281 - val_accuracy: 0.6024\n","Epoch 73/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5237 - accuracy: 0.7344 - val_loss: 0.7375 - val_accuracy: 0.5916\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5226 - accuracy: 0.7311 - val_loss: 0.7387 - val_accuracy: 0.5916\n","Epoch 75/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5171 - accuracy: 0.7381 - val_loss: 0.7409 - val_accuracy: 0.5981\n","Epoch 76/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5204 - accuracy: 0.7387 - val_loss: 0.7521 - val_accuracy: 0.5873\n","Epoch 77/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5096 - accuracy: 0.7379 - val_loss: 0.7415 - val_accuracy: 0.5970\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5056 - accuracy: 0.7443 - val_loss: 0.7554 - val_accuracy: 0.5905\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5031 - accuracy: 0.7470 - val_loss: 0.7751 - val_accuracy: 0.5744\n","Epoch 80/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5001 - accuracy: 0.7446 - val_loss: 0.7549 - val_accuracy: 0.6121\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4947 - accuracy: 0.7487 - val_loss: 0.7689 - val_accuracy: 0.5938\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4861 - accuracy: 0.7643 - val_loss: 0.7696 - val_accuracy: 0.5884\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4857 - accuracy: 0.7562 - val_loss: 0.7723 - val_accuracy: 0.5927\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4834 - accuracy: 0.7492 - val_loss: 0.7870 - val_accuracy: 0.5884\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4838 - accuracy: 0.7584 - val_loss: 0.8155 - val_accuracy: 0.5625\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4868 - accuracy: 0.7570 - val_loss: 0.7777 - val_accuracy: 0.6099\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4802 - accuracy: 0.7629 - val_loss: 0.7843 - val_accuracy: 0.5905\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4663 - accuracy: 0.7716 - val_loss: 0.7933 - val_accuracy: 0.5884\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4621 - accuracy: 0.7683 - val_loss: 0.7937 - val_accuracy: 0.5970\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4604 - accuracy: 0.7740 - val_loss: 0.8189 - val_accuracy: 0.5808\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4581 - accuracy: 0.7724 - val_loss: 0.8194 - val_accuracy: 0.5862\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4553 - accuracy: 0.7812 - val_loss: 0.8316 - val_accuracy: 0.5830\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4438 - accuracy: 0.7899 - val_loss: 0.8422 - val_accuracy: 0.5722\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4419 - accuracy: 0.7926 - val_loss: 0.8407 - val_accuracy: 0.5808\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4496 - accuracy: 0.7842 - val_loss: 0.8296 - val_accuracy: 0.5938\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4392 - accuracy: 0.7942 - val_loss: 0.8401 - val_accuracy: 0.5905\n","Epoch 97/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4298 - accuracy: 0.7990 - val_loss: 0.8515 - val_accuracy: 0.5787\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4232 - accuracy: 0.7966 - val_loss: 0.8452 - val_accuracy: 0.5927\n","Epoch 99/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4211 - accuracy: 0.7990 - val_loss: 0.8664 - val_accuracy: 0.5797\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4149 - accuracy: 0.8128 - val_loss: 0.8801 - val_accuracy: 0.5776\n","{'loss': [0.6931589245796204, 0.693133533000946, 0.6931303143501282, 0.6931248903274536, 0.6931145191192627, 0.6930974721908569, 0.6931041479110718, 0.693090558052063, 0.6930396556854248, 0.6930442452430725, 0.6930214166641235, 0.6929863095283508, 0.6929513216018677, 0.6929262280464172, 0.6928207874298096, 0.6927891373634338, 0.692733108997345, 0.6926568150520325, 0.6924420595169067, 0.6922219395637512, 0.6920038461685181, 0.6916703581809998, 0.6910440921783447, 0.6904537081718445, 0.6898098587989807, 0.6888963580131531, 0.6875488758087158, 0.6863532066345215, 0.6840934753417969, 0.6822647452354431, 0.6788232922554016, 0.6757772564888, 0.6709981560707092, 0.6679432392120361, 0.6653331518173218, 0.6606264710426331, 0.6617280840873718, 0.6563847661018372, 0.6515218615531921, 0.64457106590271, 0.6420800685882568, 0.6398347020149231, 0.6349653601646423, 0.6343338489532471, 0.6303353309631348, 0.6275058388710022, 0.6191686391830444, 0.6199280023574829, 0.6142157912254333, 0.6100773811340332, 0.605925440788269, 0.6060123443603516, 0.6037506461143494, 0.5976098775863647, 0.5899023413658142, 0.5895602703094482, 0.5850002765655518, 0.5794867873191833, 0.578774094581604, 0.5782794952392578, 0.5714676380157471, 0.5651757717132568, 0.5637381076812744, 0.5621801018714905, 0.5606229901313782, 0.5563925504684448, 0.5512303709983826, 0.5451078414916992, 0.5443770885467529, 0.5425707101821899, 0.535034716129303, 0.5289852023124695, 0.5237254500389099, 0.5226174592971802, 0.5170685052871704, 0.5204228758811951, 0.5095930099487305, 0.5055935382843018, 0.5031428933143616, 0.5000907778739929, 0.49469029903411865, 0.486067533493042, 0.48573970794677734, 0.4834120273590088, 0.48379313945770264, 0.4867702126502991, 0.48017317056655884, 0.4662826657295227, 0.4621233344078064, 0.46038004755973816, 0.45808759331703186, 0.4553220272064209, 0.44377490878105164, 0.44185757637023926, 0.4496443569660187, 0.43915534019470215, 0.4298374652862549, 0.4231913685798645, 0.4210977256298065, 0.414936900138855], 'accuracy': [0.49380388855934143, 0.5123922228813171, 0.49946120381355286, 0.5075430870056152, 0.5070043206214905, 0.5083512663841248, 0.5078125, 0.506196141242981, 0.506465494632721, 0.506465494632721, 0.5080819129943848, 0.5080819129943848, 0.5075430870056152, 0.5110452771186829, 0.5167025923728943, 0.5188577771186829, 0.521821141242981, 0.5123922228813171, 0.5422952771186829, 0.5646551847457886, 0.5503771305084229, 0.5649245977401733, 0.5576508641242981, 0.5800107717514038, 0.5665409564971924, 0.5662715435028076, 0.571659505367279, 0.5810883641242981, 0.5735452771186829, 0.5789331793785095, 0.5932112336158752, 0.5889008641242981, 0.5994073152542114, 0.6007543206214905, 0.5967133641242981, 0.6096444129943848, 0.6012930870056152, 0.5956357717514038, 0.6091055870056152, 0.6271551847457886, 0.6228448152542114, 0.618803858757019, 0.6325430870056152, 0.6298491358757019, 0.6260775923728943, 0.6414331793785095, 0.6430495977401733, 0.6495150923728943, 0.6551724076271057, 0.654902994632721, 0.6565194129943848, 0.657866358757019, 0.6632543206214905, 0.6667564511299133, 0.6756465435028076, 0.6742995977401733, 0.6772629022598267, 0.6842672228813171, 0.6856142282485962, 0.6778017282485962, 0.6955819129943848, 0.6980064511299133, 0.7023168206214905, 0.7004310488700867, 0.6942349076271057, 0.7106680870056152, 0.7079741358757019, 0.7085129022598267, 0.709590494632721, 0.7149784564971924, 0.7222521305084229, 0.7246767282485962, 0.734375, 0.7311422228813171, 0.7381465435028076, 0.7386853694915771, 0.7378771305084229, 0.7443426847457886, 0.7470366358757019, 0.7446120977401733, 0.748652994632721, 0.764277994632721, 0.756196141242981, 0.7491918206214905, 0.7583512663841248, 0.7570043206214905, 0.7629310488700867, 0.7715517282485962, 0.7683189511299133, 0.7739762663841248, 0.7723599076271057, 0.78125, 0.7898706793785095, 0.7925646305084229, 0.7842133641242981, 0.7941810488700867, 0.7990301847457886, 0.7966055870056152, 0.7990301847457886, 0.8127694129943848], 'val_loss': [0.693146288394928, 0.6931499242782593, 0.6931586265563965, 0.6931568384170532, 0.6931590437889099, 0.6931681632995605, 0.6931725144386292, 0.6931779384613037, 0.6931850910186768, 0.6931852102279663, 0.693179190158844, 0.6931827664375305, 0.6931787133216858, 0.6931794285774231, 0.6931517124176025, 0.6931406855583191, 0.6931103467941284, 0.6931283473968506, 0.6929930448532104, 0.6929376721382141, 0.6927832961082458, 0.6927707195281982, 0.6923159956932068, 0.6920269131660461, 0.6915555000305176, 0.6908800005912781, 0.6904686689376831, 0.6914780139923096, 0.690313994884491, 0.6876608729362488, 0.6876268982887268, 0.686834990978241, 0.688066303730011, 0.6872410774230957, 0.6855592131614685, 0.686400294303894, 0.6856132745742798, 0.6859891414642334, 0.687760591506958, 0.6863099932670593, 0.6873302459716797, 0.6899598836898804, 0.6907579302787781, 0.6902355551719666, 0.6978344917297363, 0.6890192627906799, 0.6918167471885681, 0.6899682879447937, 0.6937136650085449, 0.7054088115692139, 0.6990267634391785, 0.6933008432388306, 0.6935803890228271, 0.69529128074646, 0.6961661577224731, 0.6982836127281189, 0.6990184187889099, 0.7003970742225647, 0.70521080493927, 0.7050219774246216, 0.7117903232574463, 0.7151347994804382, 0.7090098261833191, 0.7324173450469971, 0.712270975112915, 0.7142126560211182, 0.7426653504371643, 0.7196707129478455, 0.7233790755271912, 0.7214510440826416, 0.7322661280632019, 0.7281256318092346, 0.7374515533447266, 0.7386544346809387, 0.7409158945083618, 0.7521482706069946, 0.7414632439613342, 0.7553579211235046, 0.7751267552375793, 0.7549082636833191, 0.7689014077186584, 0.7696101069450378, 0.7723149061203003, 0.7869760394096375, 0.8155156970024109, 0.7776941657066345, 0.7842761278152466, 0.793271541595459, 0.7936872243881226, 0.8189406991004944, 0.8193953037261963, 0.8316107988357544, 0.8421654105186462, 0.8406762480735779, 0.8295754790306091, 0.8400987982749939, 0.8515137434005737, 0.845246434211731, 0.866439700126648, 0.8801482915878296], 'val_accuracy': [0.517241358757019, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.48383620381355286, 0.48491379618644714, 0.48275861144065857, 0.48491379618644714, 0.5280172228813171, 0.5161637663841248, 0.5528017282485962, 0.506465494632721, 0.556034505367279, 0.5495689511299133, 0.5549569129943848, 0.5538793206214905, 0.5581896305084229, 0.5193965435028076, 0.5420258641242981, 0.5581896305084229, 0.5614224076271057, 0.5614224076271057, 0.5538793206214905, 0.5538793206214905, 0.5635775923728943, 0.5646551847457886, 0.5721982717514038, 0.5721982717514038, 0.5732758641242981, 0.5775862336158752, 0.5754310488700867, 0.5818965435028076, 0.5732758641242981, 0.587284505367279, 0.5625, 0.5980603694915771, 0.5894396305084229, 0.6012930870056152, 0.5905172228813171, 0.5657327771186829, 0.5883620977401733, 0.6023706793785095, 0.6099137663841248, 0.6066810488700867, 0.6099137663841248, 0.6012930870056152, 0.6088362336158752, 0.6131465435028076, 0.6131465435028076, 0.6056034564971924, 0.579741358757019, 0.579741358757019, 0.6131465435028076, 0.5581896305084229, 0.607758641242981, 0.6153017282485962, 0.5625, 0.607758641242981, 0.6120689511299133, 0.6066810488700867, 0.5840517282485962, 0.6023706793785095, 0.5915948152542114, 0.5915948152542114, 0.5980603694915771, 0.587284505367279, 0.5969827771186829, 0.5905172228813171, 0.5743534564971924, 0.6120689511299133, 0.59375, 0.5883620977401733, 0.5926724076271057, 0.5883620977401733, 0.5625, 0.6099137663841248, 0.5905172228813171, 0.5883620977401733, 0.5969827771186829, 0.5808189511299133, 0.5862069129943848, 0.5829741358757019, 0.5721982717514038, 0.5808189511299133, 0.59375, 0.5905172228813171, 0.5786637663841248, 0.5926724076271057, 0.579741358757019, 0.5775862336158752]}\n","38/38 [==============================] - 1s 10ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4935"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 100ms/step - loss: 0.6931 - accuracy: 0.4935 - val_loss: 0.6931 - val_accuracy: 0.5045\n","Epoch 2/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.4912 - val_loss: 0.6931 - val_accuracy: 0.4977\n","Epoch 3/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.4873 - val_loss: 0.6931 - val_accuracy: 0.5045\n","Epoch 4/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.4943 - val_loss: 0.6931 - val_accuracy: 0.4943\n","Epoch 5/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6931 - accuracy: 0.5023 - val_loss: 0.6931 - val_accuracy: 0.5000\n","Epoch 6/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.5150 - val_loss: 0.6931 - val_accuracy: 0.5011\n","Epoch 7/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6931 - accuracy: 0.5263 - val_loss: 0.6931 - val_accuracy: 0.5011\n","Epoch 8/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.6931 - accuracy: 0.5207 - val_loss: 0.6931 - val_accuracy: 0.5000\n","Epoch 9/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6931 - accuracy: 0.5272 - val_loss: 0.6931 - val_accuracy: 0.5000\n","Epoch 10/100\n","28/28 [==============================] - 1s 40ms/step - loss: 0.6931 - accuracy: 0.5158 - val_loss: 0.6931 - val_accuracy: 0.5000\n","Epoch 11/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6930 - accuracy: 0.5221 - val_loss: 0.6931 - val_accuracy: 0.5000\n","Epoch 12/100\n","28/28 [==============================] - 1s 17ms/step - loss: 0.6930 - accuracy: 0.5238 - val_loss: 0.6931 - val_accuracy: 0.5000\n","Epoch 13/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6930 - accuracy: 0.5266 - val_loss: 0.6931 - val_accuracy: 0.5011\n","Epoch 14/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6929 - accuracy: 0.5269 - val_loss: 0.6931 - val_accuracy: 0.5000\n","Epoch 15/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6929 - accuracy: 0.5354 - val_loss: 0.6931 - val_accuracy: 0.4989\n","Epoch 16/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6929 - accuracy: 0.5243 - val_loss: 0.6931 - val_accuracy: 0.4989\n","Epoch 17/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6927 - accuracy: 0.5504 - val_loss: 0.6931 - val_accuracy: 0.4898\n","Epoch 18/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6926 - accuracy: 0.5594 - val_loss: 0.6930 - val_accuracy: 0.5000\n","Epoch 19/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6924 - accuracy: 0.5538 - val_loss: 0.6930 - val_accuracy: 0.5000\n","Epoch 20/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6922 - accuracy: 0.5535 - val_loss: 0.6929 - val_accuracy: 0.5045\n","Epoch 21/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6920 - accuracy: 0.5574 - val_loss: 0.6928 - val_accuracy: 0.5113\n","Epoch 22/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6916 - accuracy: 0.5640 - val_loss: 0.6926 - val_accuracy: 0.5328\n","Epoch 23/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6912 - accuracy: 0.5659 - val_loss: 0.6924 - val_accuracy: 0.5407\n","Epoch 24/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6906 - accuracy: 0.5608 - val_loss: 0.6921 - val_accuracy: 0.5260\n","Epoch 25/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6898 - accuracy: 0.5671 - val_loss: 0.6918 - val_accuracy: 0.5192\n","Epoch 26/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6889 - accuracy: 0.5747 - val_loss: 0.6912 - val_accuracy: 0.5419\n","Epoch 27/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6879 - accuracy: 0.5758 - val_loss: 0.6906 - val_accuracy: 0.5430\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6861 - accuracy: 0.5772 - val_loss: 0.6902 - val_accuracy: 0.5294\n","Epoch 29/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6851 - accuracy: 0.5707 - val_loss: 0.6890 - val_accuracy: 0.5441\n","Epoch 30/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6825 - accuracy: 0.5894 - val_loss: 0.6883 - val_accuracy: 0.5475\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6792 - accuracy: 0.5891 - val_loss: 0.6887 - val_accuracy: 0.5260\n","Epoch 32/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6765 - accuracy: 0.5897 - val_loss: 0.6871 - val_accuracy: 0.5577\n","Epoch 33/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6732 - accuracy: 0.5956 - val_loss: 0.6859 - val_accuracy: 0.5509\n","Epoch 34/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6693 - accuracy: 0.5988 - val_loss: 0.6874 - val_accuracy: 0.5566\n","Epoch 35/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6663 - accuracy: 0.6010 - val_loss: 0.6855 - val_accuracy: 0.5577\n","Epoch 36/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6631 - accuracy: 0.6064 - val_loss: 0.6888 - val_accuracy: 0.5577\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6582 - accuracy: 0.6061 - val_loss: 0.6891 - val_accuracy: 0.5566\n","Epoch 38/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6564 - accuracy: 0.6067 - val_loss: 0.6900 - val_accuracy: 0.5226\n","Epoch 39/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6519 - accuracy: 0.6180 - val_loss: 0.6885 - val_accuracy: 0.5464\n","Epoch 40/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.6481 - accuracy: 0.6174 - val_loss: 0.6925 - val_accuracy: 0.5588\n","Epoch 41/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6458 - accuracy: 0.6115 - val_loss: 0.6895 - val_accuracy: 0.5622\n","Epoch 42/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6403 - accuracy: 0.6279 - val_loss: 0.6877 - val_accuracy: 0.5396\n","Epoch 43/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6370 - accuracy: 0.6319 - val_loss: 0.6888 - val_accuracy: 0.5645\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6315 - accuracy: 0.6392 - val_loss: 0.6924 - val_accuracy: 0.5407\n","Epoch 45/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6309 - accuracy: 0.6302 - val_loss: 0.6927 - val_accuracy: 0.5679\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6235 - accuracy: 0.6398 - val_loss: 0.6925 - val_accuracy: 0.5441\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6223 - accuracy: 0.6460 - val_loss: 0.6956 - val_accuracy: 0.5452\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6170 - accuracy: 0.6534 - val_loss: 0.6970 - val_accuracy: 0.5509\n","Epoch 49/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6153 - accuracy: 0.6494 - val_loss: 0.6997 - val_accuracy: 0.5747\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6149 - accuracy: 0.6505 - val_loss: 0.7073 - val_accuracy: 0.5701\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6086 - accuracy: 0.6607 - val_loss: 0.6993 - val_accuracy: 0.5498\n","Epoch 52/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6039 - accuracy: 0.6658 - val_loss: 0.7031 - val_accuracy: 0.5656\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6013 - accuracy: 0.6726 - val_loss: 0.7084 - val_accuracy: 0.5656\n","Epoch 54/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5937 - accuracy: 0.6701 - val_loss: 0.7128 - val_accuracy: 0.5758\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5958 - accuracy: 0.6630 - val_loss: 0.7089 - val_accuracy: 0.5600\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5870 - accuracy: 0.6836 - val_loss: 0.7157 - val_accuracy: 0.5701\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5896 - accuracy: 0.6805 - val_loss: 0.7164 - val_accuracy: 0.5622\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5882 - accuracy: 0.6681 - val_loss: 0.7120 - val_accuracy: 0.5724\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5805 - accuracy: 0.6879 - val_loss: 0.7127 - val_accuracy: 0.5713\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5789 - accuracy: 0.6876 - val_loss: 0.7150 - val_accuracy: 0.5633\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5763 - accuracy: 0.6848 - val_loss: 0.7159 - val_accuracy: 0.5679\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5716 - accuracy: 0.6952 - val_loss: 0.7227 - val_accuracy: 0.5701\n","Epoch 63/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5669 - accuracy: 0.7032 - val_loss: 0.7210 - val_accuracy: 0.5713\n","Epoch 64/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5674 - accuracy: 0.6919 - val_loss: 0.7215 - val_accuracy: 0.5747\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5647 - accuracy: 0.6967 - val_loss: 0.7329 - val_accuracy: 0.5577\n","Epoch 66/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5605 - accuracy: 0.6978 - val_loss: 0.7240 - val_accuracy: 0.5701\n","Epoch 67/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5518 - accuracy: 0.7057 - val_loss: 0.7315 - val_accuracy: 0.5577\n","Epoch 68/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.5498 - accuracy: 0.7057 - val_loss: 0.7411 - val_accuracy: 0.5792\n","Epoch 69/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5512 - accuracy: 0.7134 - val_loss: 0.7360 - val_accuracy: 0.5735\n","Epoch 70/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5409 - accuracy: 0.7201 - val_loss: 0.7419 - val_accuracy: 0.5735\n","Epoch 71/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5435 - accuracy: 0.7128 - val_loss: 0.7403 - val_accuracy: 0.5826\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5330 - accuracy: 0.7323 - val_loss: 0.7433 - val_accuracy: 0.5713\n","Epoch 73/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5307 - accuracy: 0.7400 - val_loss: 0.7450 - val_accuracy: 0.5781\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5313 - accuracy: 0.7284 - val_loss: 0.7597 - val_accuracy: 0.5611\n","Epoch 75/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5257 - accuracy: 0.7298 - val_loss: 0.7505 - val_accuracy: 0.5792\n","Epoch 76/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5246 - accuracy: 0.7315 - val_loss: 0.7559 - val_accuracy: 0.5928\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5203 - accuracy: 0.7334 - val_loss: 0.7581 - val_accuracy: 0.5713\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5097 - accuracy: 0.7397 - val_loss: 0.7629 - val_accuracy: 0.5803\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5138 - accuracy: 0.7388 - val_loss: 0.7742 - val_accuracy: 0.5769\n","Epoch 80/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5088 - accuracy: 0.7482 - val_loss: 0.7786 - val_accuracy: 0.5758\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5009 - accuracy: 0.7558 - val_loss: 0.7704 - val_accuracy: 0.5905\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4927 - accuracy: 0.7530 - val_loss: 0.7762 - val_accuracy: 0.5871\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4935 - accuracy: 0.7493 - val_loss: 0.7843 - val_accuracy: 0.5860\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4936 - accuracy: 0.7507 - val_loss: 0.7875 - val_accuracy: 0.5826\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4893 - accuracy: 0.7606 - val_loss: 0.7929 - val_accuracy: 0.5837\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4836 - accuracy: 0.7600 - val_loss: 0.7954 - val_accuracy: 0.5871\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4744 - accuracy: 0.7674 - val_loss: 0.8033 - val_accuracy: 0.5871\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4721 - accuracy: 0.7683 - val_loss: 0.8291 - val_accuracy: 0.5633\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4753 - accuracy: 0.7719 - val_loss: 0.8102 - val_accuracy: 0.5871\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4744 - accuracy: 0.7646 - val_loss: 0.8283 - val_accuracy: 0.5826\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4616 - accuracy: 0.7813 - val_loss: 0.8199 - val_accuracy: 0.5882\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4638 - accuracy: 0.7770 - val_loss: 0.8242 - val_accuracy: 0.5837\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4577 - accuracy: 0.7847 - val_loss: 0.8351 - val_accuracy: 0.5848\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4544 - accuracy: 0.7818 - val_loss: 0.8295 - val_accuracy: 0.5905\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4475 - accuracy: 0.7883 - val_loss: 0.8375 - val_accuracy: 0.5860\n","Epoch 96/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4391 - accuracy: 0.7892 - val_loss: 0.8502 - val_accuracy: 0.5871\n","Epoch 97/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4360 - accuracy: 0.7926 - val_loss: 0.8659 - val_accuracy: 0.5837\n","Epoch 98/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4356 - accuracy: 0.7957 - val_loss: 0.8615 - val_accuracy: 0.5803\n","Epoch 99/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4250 - accuracy: 0.7971 - val_loss: 0.8759 - val_accuracy: 0.5792\n","Epoch 100/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4251 - accuracy: 0.8002 - val_loss: 0.8927 - val_accuracy: 0.5747\n","{'loss': [0.6931430697441101, 0.6931561231613159, 0.6931517124176025, 0.6931312084197998, 0.6931251883506775, 0.693119466304779, 0.6930893063545227, 0.693096399307251, 0.6930652260780334, 0.6930764317512512, 0.6930450201034546, 0.6930295825004578, 0.6929875016212463, 0.6929307579994202, 0.6928879618644714, 0.6928659081459045, 0.6926753520965576, 0.6925806403160095, 0.6923831105232239, 0.6921808123588562, 0.6919500231742859, 0.691577136516571, 0.6911539435386658, 0.6905789971351624, 0.6898272633552551, 0.6888571977615356, 0.6878727078437805, 0.6860965490341187, 0.6850798726081848, 0.6825080513954163, 0.679233193397522, 0.676501452922821, 0.6731792092323303, 0.6693229675292969, 0.6663212776184082, 0.6631332635879517, 0.6582221984863281, 0.6563913226127625, 0.6519172191619873, 0.6481189131736755, 0.6457961797714233, 0.6403409242630005, 0.6370429992675781, 0.6314845085144043, 0.6309398412704468, 0.6235324144363403, 0.6222763061523438, 0.6170036196708679, 0.6153042316436768, 0.6149067282676697, 0.608566164970398, 0.6038702130317688, 0.6013462543487549, 0.5936547517776489, 0.5958147644996643, 0.5870048999786377, 0.589553713798523, 0.58820641040802, 0.5805436372756958, 0.5788998603820801, 0.5762577056884766, 0.5716162323951721, 0.566920816898346, 0.5673757791519165, 0.5647290349006653, 0.5605209469795227, 0.551754891872406, 0.54979008436203, 0.5512205362319946, 0.5409210324287415, 0.5435459613800049, 0.5329916477203369, 0.530694305896759, 0.5313177108764648, 0.5256628394126892, 0.5246209502220154, 0.5202873945236206, 0.5096870064735413, 0.5137609839439392, 0.508780300617218, 0.5008638501167297, 0.49271875619888306, 0.49353107810020447, 0.4936092495918274, 0.48928597569465637, 0.4836072027683258, 0.4744328558444977, 0.4720742702484131, 0.4753195643424988, 0.4743807911872864, 0.4616386592388153, 0.46378573775291443, 0.4577197730541229, 0.4543670415878296, 0.4475117027759552, 0.4391363561153412, 0.43600374460220337, 0.4356110990047455, 0.4249843955039978, 0.4251178801059723], 'accuracy': [0.4934917986392975, 0.4912280738353729, 0.48726654052734375, 0.4943406879901886, 0.5022637248039246, 0.5149971842765808, 0.5263158082962036, 0.5206564664840698, 0.5271646976470947, 0.5158460736274719, 0.5220713019371033, 0.5237690806388855, 0.5265987515449524, 0.5268816947937012, 0.5353707075119019, 0.5243350267410278, 0.5503678321838379, 0.5594227313995361, 0.5537634491920471, 0.5534804463386536, 0.5574420094490051, 0.5639501810073853, 0.565930962562561, 0.5608375668525696, 0.5670627951622009, 0.5747028589248657, 0.5758347511291504, 0.5772495865821838, 0.5707413554191589, 0.5894170999526978, 0.5891340970993042, 0.5897000432014465, 0.5956423282623291, 0.5987549424171448, 0.6010186672210693, 0.6063950061798096, 0.6061120629310608, 0.6066780090332031, 0.6179966330528259, 0.6174306869506836, 0.611488401889801, 0.6279004216194153, 0.6318619251251221, 0.6392189860343933, 0.6301641464233398, 0.6397849321365356, 0.646010160446167, 0.653367280960083, 0.6494057774543762, 0.6505376100540161, 0.660724401473999, 0.6658177971839905, 0.6726089119911194, 0.670062243938446, 0.6629881262779236, 0.6836445927619934, 0.6805319786071777, 0.668081521987915, 0.6878890991210938, 0.6876060962677002, 0.6847764849662781, 0.695246160030365, 0.7031692266464233, 0.6918506026268005, 0.6966609954833984, 0.6977928876876831, 0.7057158946990967, 0.7057158946990967, 0.7133559584617615, 0.7201471328735352, 0.7127900123596191, 0.7323146462440491, 0.7399547100067139, 0.7283531427383423, 0.7297679781913757, 0.731465756893158, 0.7334465384483337, 0.7396717667579651, 0.738822877407074, 0.748160719871521, 0.7558007836341858, 0.7529711127281189, 0.7492926120758057, 0.7507073879241943, 0.7606111764907837, 0.7600452899932861, 0.7674023509025574, 0.7682512998580933, 0.7719298005104065, 0.7645727396011353, 0.7812677025794983, 0.777023196220398, 0.7846632599830627, 0.7818335890769958, 0.7883418202400208, 0.7891907095909119, 0.7925863265991211, 0.7956989407539368, 0.7971137762069702, 0.8002263903617859], 'val_loss': [0.6931456327438354, 0.6931475400924683, 0.6931464672088623, 0.6931470036506653, 0.693147599697113, 0.6931473612785339, 0.6931472420692444, 0.6931458115577698, 0.6931467056274414, 0.6931462287902832, 0.6931479573249817, 0.693140983581543, 0.6931393146514893, 0.6931337118148804, 0.6931197047233582, 0.6931079030036926, 0.6930769085884094, 0.6930429935455322, 0.6930065155029297, 0.6929190754890442, 0.6928064823150635, 0.6926155686378479, 0.6923848986625671, 0.6921321749687195, 0.6917989253997803, 0.6912397146224976, 0.6905681490898132, 0.6901757717132568, 0.6889858245849609, 0.6883194446563721, 0.6886619329452515, 0.6871296167373657, 0.6859421730041504, 0.6874249577522278, 0.6855073571205139, 0.6888049840927124, 0.6891130208969116, 0.6899756789207458, 0.6884710192680359, 0.6925005316734314, 0.6895248889923096, 0.6876787543296814, 0.6888352632522583, 0.6923613548278809, 0.6926776170730591, 0.6924779415130615, 0.6955508589744568, 0.696951687335968, 0.6996644735336304, 0.7073496580123901, 0.699334442615509, 0.7031475901603699, 0.7084303498268127, 0.7127559185028076, 0.7088737487792969, 0.7157081365585327, 0.7164129614830017, 0.7119616866111755, 0.71270751953125, 0.7149847149848938, 0.7158717513084412, 0.7226929068565369, 0.7210301756858826, 0.7215336561203003, 0.7329317927360535, 0.7240404486656189, 0.7314761877059937, 0.7410849332809448, 0.7359868884086609, 0.7418842315673828, 0.7403363585472107, 0.7433085441589355, 0.7449854016304016, 0.7596843838691711, 0.750453531742096, 0.7559250593185425, 0.7580748796463013, 0.7628757953643799, 0.774222731590271, 0.7785966396331787, 0.7704188227653503, 0.776171863079071, 0.7843239307403564, 0.787526547908783, 0.7929407358169556, 0.7953919768333435, 0.8033064007759094, 0.8290787935256958, 0.8102495074272156, 0.8282837271690369, 0.8198747634887695, 0.8241716623306274, 0.8350676894187927, 0.8294551372528076, 0.8375353217124939, 0.8501557111740112, 0.8658806085586548, 0.8614774942398071, 0.8759382367134094, 0.8926531672477722], 'val_accuracy': [0.5045248866081238, 0.4977375566959381, 0.5045248866081238, 0.4943438768386841, 0.5, 0.5011312365531921, 0.5011312365531921, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5011312365531921, 0.5, 0.49886876344680786, 0.49886876344680786, 0.4898189902305603, 0.5, 0.5, 0.5045248866081238, 0.5113122463226318, 0.5328054428100586, 0.540723979473114, 0.5260180830955505, 0.5192307829856873, 0.5418552160263062, 0.5429864525794983, 0.529411792755127, 0.5441176295280457, 0.5475113391876221, 0.5260180830955505, 0.557692289352417, 0.5509049892425537, 0.5565611124038696, 0.557692289352417, 0.557692289352417, 0.5565611124038696, 0.5226244330406189, 0.5463801026344299, 0.5588235259056091, 0.5622171759605408, 0.5395927429199219, 0.564479649066925, 0.540723979473114, 0.5678732991218567, 0.5441176295280457, 0.5452488660812378, 0.5509049892425537, 0.5746606588363647, 0.570135772228241, 0.5497737526893616, 0.5656108856201172, 0.5656108856201172, 0.5757918357849121, 0.5599547624588013, 0.570135772228241, 0.5622171759605408, 0.5723981857299805, 0.5712669491767883, 0.5633484125137329, 0.5678732991218567, 0.570135772228241, 0.5712669491767883, 0.5746606588363647, 0.557692289352417, 0.570135772228241, 0.557692289352417, 0.5791855454444885, 0.5735294222831726, 0.5735294222831726, 0.5825791954994202, 0.5712669491767883, 0.5780543088912964, 0.5610859990119934, 0.5791855454444885, 0.5927602052688599, 0.5712669491767883, 0.5803167223930359, 0.5769230723381042, 0.5757918357849121, 0.5904977321624756, 0.587104082107544, 0.5859728455543518, 0.5825791954994202, 0.5837104320526123, 0.587104082107544, 0.587104082107544, 0.5633484125137329, 0.587104082107544, 0.5825791954994202, 0.5882353186607361, 0.5837104320526123, 0.5848416090011597, 0.5904977321624756, 0.5859728455543518, 0.587104082107544, 0.5837104320526123, 0.5803167223930359, 0.5791855454444885, 0.5746606588363647]}\n","45/45 [==============================] - 2s 10ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5090"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 63ms/step - loss: 0.6931 - accuracy: 0.5090 - val_loss: 0.6932 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5233 - val_loss: 0.6932 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6931 - accuracy: 0.5010 - val_loss: 0.6932 - val_accuracy: 0.4876\n","Epoch 4/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6930 - accuracy: 0.5253 - val_loss: 0.6932 - val_accuracy: 0.4876\n","Epoch 5/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6929 - accuracy: 0.5307 - val_loss: 0.6932 - val_accuracy: 0.4886\n","Epoch 6/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6929 - accuracy: 0.5310 - val_loss: 0.6932 - val_accuracy: 0.4876\n","Epoch 7/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6927 - accuracy: 0.5279 - val_loss: 0.6932 - val_accuracy: 0.4948\n","Epoch 8/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6926 - accuracy: 0.5276 - val_loss: 0.6932 - val_accuracy: 0.4959\n","Epoch 9/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5287 - val_loss: 0.6932 - val_accuracy: 0.4948\n","Epoch 10/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6920 - accuracy: 0.5426 - val_loss: 0.6931 - val_accuracy: 0.4938\n","Epoch 11/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6917 - accuracy: 0.5318 - val_loss: 0.6931 - val_accuracy: 0.4948\n","Epoch 12/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6912 - accuracy: 0.5264 - val_loss: 0.6930 - val_accuracy: 0.5000\n","Epoch 13/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6906 - accuracy: 0.5341 - val_loss: 0.6929 - val_accuracy: 0.5021\n","Epoch 14/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6899 - accuracy: 0.5328 - val_loss: 0.6928 - val_accuracy: 0.5041\n","Epoch 15/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6892 - accuracy: 0.5326 - val_loss: 0.6926 - val_accuracy: 0.5031\n","Epoch 16/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6885 - accuracy: 0.5401 - val_loss: 0.6924 - val_accuracy: 0.5062\n","Epoch 17/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6877 - accuracy: 0.5468 - val_loss: 0.6923 - val_accuracy: 0.5114\n","Epoch 18/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6873 - accuracy: 0.5398 - val_loss: 0.6922 - val_accuracy: 0.5145\n","Epoch 19/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6866 - accuracy: 0.5455 - val_loss: 0.6921 - val_accuracy: 0.5176\n","Epoch 20/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6854 - accuracy: 0.5556 - val_loss: 0.6920 - val_accuracy: 0.5196\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6845 - accuracy: 0.5592 - val_loss: 0.6919 - val_accuracy: 0.5186\n","Epoch 22/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6835 - accuracy: 0.5599 - val_loss: 0.6920 - val_accuracy: 0.5176\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6817 - accuracy: 0.5690 - val_loss: 0.6918 - val_accuracy: 0.5176\n","Epoch 24/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6804 - accuracy: 0.5711 - val_loss: 0.6919 - val_accuracy: 0.5134\n","Epoch 25/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6782 - accuracy: 0.5742 - val_loss: 0.6923 - val_accuracy: 0.5186\n","Epoch 26/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6768 - accuracy: 0.5804 - val_loss: 0.6926 - val_accuracy: 0.5258\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6752 - accuracy: 0.5739 - val_loss: 0.6934 - val_accuracy: 0.5238\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6722 - accuracy: 0.5801 - val_loss: 0.6956 - val_accuracy: 0.5062\n","Epoch 29/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6717 - accuracy: 0.5814 - val_loss: 0.6965 - val_accuracy: 0.5269\n","Epoch 30/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6691 - accuracy: 0.5910 - val_loss: 0.6978 - val_accuracy: 0.5072\n","Epoch 31/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6678 - accuracy: 0.5917 - val_loss: 0.7000 - val_accuracy: 0.5103\n","Epoch 32/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6659 - accuracy: 0.5915 - val_loss: 0.7006 - val_accuracy: 0.5331\n","Epoch 33/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6637 - accuracy: 0.5959 - val_loss: 0.7041 - val_accuracy: 0.5093\n","Epoch 34/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6616 - accuracy: 0.6000 - val_loss: 0.7034 - val_accuracy: 0.5227\n","Epoch 35/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6588 - accuracy: 0.5977 - val_loss: 0.7054 - val_accuracy: 0.5248\n","Epoch 36/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6562 - accuracy: 0.6065 - val_loss: 0.7092 - val_accuracy: 0.5155\n","Epoch 37/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6538 - accuracy: 0.6085 - val_loss: 0.7102 - val_accuracy: 0.5382\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6530 - accuracy: 0.6109 - val_loss: 0.7119 - val_accuracy: 0.5124\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6525 - accuracy: 0.6093 - val_loss: 0.7120 - val_accuracy: 0.5227\n","Epoch 40/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6490 - accuracy: 0.6103 - val_loss: 0.7155 - val_accuracy: 0.5186\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6479 - accuracy: 0.6119 - val_loss: 0.7148 - val_accuracy: 0.5320\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6441 - accuracy: 0.6256 - val_loss: 0.7184 - val_accuracy: 0.5207\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6436 - accuracy: 0.6264 - val_loss: 0.7187 - val_accuracy: 0.5300\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6375 - accuracy: 0.6279 - val_loss: 0.7197 - val_accuracy: 0.5279\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6373 - accuracy: 0.6258 - val_loss: 0.7210 - val_accuracy: 0.5331\n","Epoch 46/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6373 - accuracy: 0.6297 - val_loss: 0.7231 - val_accuracy: 0.5434\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6348 - accuracy: 0.6266 - val_loss: 0.7249 - val_accuracy: 0.5320\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6317 - accuracy: 0.6289 - val_loss: 0.7297 - val_accuracy: 0.5269\n","Epoch 49/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6280 - accuracy: 0.6444 - val_loss: 0.7299 - val_accuracy: 0.5486\n","Epoch 50/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6245 - accuracy: 0.6463 - val_loss: 0.7313 - val_accuracy: 0.5413\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6234 - accuracy: 0.6447 - val_loss: 0.7331 - val_accuracy: 0.5331\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6227 - accuracy: 0.6496 - val_loss: 0.7318 - val_accuracy: 0.5424\n","Epoch 53/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6167 - accuracy: 0.6568 - val_loss: 0.7369 - val_accuracy: 0.5455\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6179 - accuracy: 0.6501 - val_loss: 0.7361 - val_accuracy: 0.5424\n","Epoch 55/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6120 - accuracy: 0.6530 - val_loss: 0.7380 - val_accuracy: 0.5455\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6161 - accuracy: 0.6504 - val_loss: 0.7404 - val_accuracy: 0.5455\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6075 - accuracy: 0.6643 - val_loss: 0.7426 - val_accuracy: 0.5444\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6066 - accuracy: 0.6682 - val_loss: 0.7442 - val_accuracy: 0.5403\n","Epoch 59/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6037 - accuracy: 0.6672 - val_loss: 0.7437 - val_accuracy: 0.5568\n","Epoch 60/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6041 - accuracy: 0.6708 - val_loss: 0.7448 - val_accuracy: 0.5486\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5980 - accuracy: 0.6693 - val_loss: 0.7506 - val_accuracy: 0.5527\n","Epoch 62/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5933 - accuracy: 0.6760 - val_loss: 0.7568 - val_accuracy: 0.5393\n","Epoch 63/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5934 - accuracy: 0.6757 - val_loss: 0.7553 - val_accuracy: 0.5517\n","Epoch 64/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5902 - accuracy: 0.6824 - val_loss: 0.7582 - val_accuracy: 0.5496\n","Epoch 65/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5897 - accuracy: 0.6806 - val_loss: 0.7614 - val_accuracy: 0.5486\n","Epoch 66/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5865 - accuracy: 0.6899 - val_loss: 0.7643 - val_accuracy: 0.5434\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5825 - accuracy: 0.6842 - val_loss: 0.7697 - val_accuracy: 0.5465\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5797 - accuracy: 0.6860 - val_loss: 0.7787 - val_accuracy: 0.5393\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5821 - accuracy: 0.6866 - val_loss: 0.7682 - val_accuracy: 0.5517\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5770 - accuracy: 0.6866 - val_loss: 0.7701 - val_accuracy: 0.5413\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5725 - accuracy: 0.6964 - val_loss: 0.7736 - val_accuracy: 0.5506\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5683 - accuracy: 0.6972 - val_loss: 0.7785 - val_accuracy: 0.5496\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5639 - accuracy: 0.7023 - val_loss: 0.7786 - val_accuracy: 0.5465\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5653 - accuracy: 0.7049 - val_loss: 0.7861 - val_accuracy: 0.5444\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5629 - accuracy: 0.7047 - val_loss: 0.7983 - val_accuracy: 0.5413\n","Epoch 76/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5658 - accuracy: 0.6943 - val_loss: 0.7874 - val_accuracy: 0.5465\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5525 - accuracy: 0.7054 - val_loss: 0.7906 - val_accuracy: 0.5475\n","Epoch 78/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5528 - accuracy: 0.7150 - val_loss: 0.7954 - val_accuracy: 0.5413\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5445 - accuracy: 0.7274 - val_loss: 0.7993 - val_accuracy: 0.5506\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5463 - accuracy: 0.7165 - val_loss: 0.8022 - val_accuracy: 0.5486\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5377 - accuracy: 0.7297 - val_loss: 0.8086 - val_accuracy: 0.5393\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5398 - accuracy: 0.7243 - val_loss: 0.8138 - val_accuracy: 0.5362\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5375 - accuracy: 0.7256 - val_loss: 0.8146 - val_accuracy: 0.5382\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5384 - accuracy: 0.7225 - val_loss: 0.8179 - val_accuracy: 0.5393\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5349 - accuracy: 0.7225 - val_loss: 0.8201 - val_accuracy: 0.5413\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5268 - accuracy: 0.7227 - val_loss: 0.8199 - val_accuracy: 0.5475\n","Epoch 87/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5217 - accuracy: 0.7375 - val_loss: 0.8252 - val_accuracy: 0.5403\n","Epoch 88/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5210 - accuracy: 0.7388 - val_loss: 0.8329 - val_accuracy: 0.5444\n","Epoch 89/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5146 - accuracy: 0.7473 - val_loss: 0.8370 - val_accuracy: 0.5403\n","Epoch 90/100\n","31/31 [==============================] - 2s 52ms/step - loss: 0.5166 - accuracy: 0.7416 - val_loss: 0.8519 - val_accuracy: 0.5465\n","Epoch 91/100\n","31/31 [==============================] - 1s 41ms/step - loss: 0.5155 - accuracy: 0.7439 - val_loss: 0.8477 - val_accuracy: 0.5424\n","Epoch 92/100\n","31/31 [==============================] - 1s 44ms/step - loss: 0.5025 - accuracy: 0.7494 - val_loss: 0.8554 - val_accuracy: 0.5465\n","Epoch 93/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5056 - accuracy: 0.7413 - val_loss: 0.8640 - val_accuracy: 0.5413\n","Epoch 94/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4989 - accuracy: 0.7537 - val_loss: 0.8653 - val_accuracy: 0.5403\n","Epoch 95/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4991 - accuracy: 0.7525 - val_loss: 0.8701 - val_accuracy: 0.5475\n","Epoch 96/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4921 - accuracy: 0.7620 - val_loss: 0.8800 - val_accuracy: 0.5455\n","Epoch 97/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4986 - accuracy: 0.7460 - val_loss: 0.8827 - val_accuracy: 0.5465\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4844 - accuracy: 0.7602 - val_loss: 0.8913 - val_accuracy: 0.5403\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4807 - accuracy: 0.7664 - val_loss: 0.8892 - val_accuracy: 0.5434\n","Epoch 100/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4792 - accuracy: 0.7685 - val_loss: 0.8928 - val_accuracy: 0.5413\n","{'loss': [0.6931358575820923, 0.6930880546569824, 0.6930899620056152, 0.6930415034294128, 0.6929478645324707, 0.6928655505180359, 0.6927313804626465, 0.6925580501556396, 0.6923362016677856, 0.6919947266578674, 0.6916791796684265, 0.6912243366241455, 0.690572202205658, 0.6899157166481018, 0.6891757845878601, 0.6885452270507812, 0.6876616477966309, 0.6872881650924683, 0.6865976452827454, 0.6854363083839417, 0.6844549775123596, 0.6835298538208008, 0.6816664338111877, 0.6803761124610901, 0.6781656742095947, 0.6768107414245605, 0.675194263458252, 0.6722338199615479, 0.6717309355735779, 0.6691404581069946, 0.6678321957588196, 0.6659488677978516, 0.6637382507324219, 0.6616230010986328, 0.6587930917739868, 0.656205415725708, 0.6537678837776184, 0.6529894471168518, 0.6524627804756165, 0.6490442752838135, 0.6478970646858215, 0.6441477537155151, 0.643552303314209, 0.6375482678413391, 0.6373053789138794, 0.6373223066329956, 0.6347531676292419, 0.631689190864563, 0.6279749870300293, 0.6245418190956116, 0.6233991384506226, 0.6227352619171143, 0.6166563630104065, 0.6178633570671082, 0.6119880676269531, 0.6161496043205261, 0.6075412034988403, 0.6066070795059204, 0.6037324070930481, 0.604142963886261, 0.5979945659637451, 0.5932970643043518, 0.5933539271354675, 0.5902335047721863, 0.5897194147109985, 0.586451530456543, 0.5825399160385132, 0.5796862840652466, 0.5821315050125122, 0.5770198106765747, 0.5724570155143738, 0.5683334469795227, 0.5638571381568909, 0.5652615427970886, 0.5628532767295837, 0.5657731294631958, 0.5525027513504028, 0.5528032779693604, 0.5445220470428467, 0.5463463664054871, 0.5376754403114319, 0.5398125052452087, 0.5375232696533203, 0.5384320616722107, 0.5349315404891968, 0.526791512966156, 0.5217375755310059, 0.521048903465271, 0.5146401524543762, 0.5166379809379578, 0.5154617428779602, 0.5024913549423218, 0.5055764317512512, 0.4989132285118103, 0.499093621969223, 0.4920940101146698, 0.49859967827796936, 0.4844340682029724, 0.48072460293769836, 0.4791843295097351], 'accuracy': [0.5090439319610596, 0.5232558250427246, 0.50103360414505, 0.5253229737281799, 0.5307493805885315, 0.5310077667236328, 0.5279069542884827, 0.5276485681533813, 0.5286821722984314, 0.5426356792449951, 0.5317829251289368, 0.52635657787323, 0.5341085195541382, 0.5328165292739868, 0.5325581431388855, 0.5400516986846924, 0.5467700362205505, 0.5397932529449463, 0.5454780459403992, 0.5555555820465088, 0.5591731071472168, 0.5599483251571655, 0.5689922571182251, 0.5710594058036804, 0.5741602182388306, 0.5803617835044861, 0.5739018321037292, 0.58010333776474, 0.5813953280448914, 0.5909560918807983, 0.5917312502861023, 0.591472864151001, 0.5958656072616577, 0.6000000238418579, 0.5976744294166565, 0.6064599752426147, 0.6085271239280701, 0.6108527183532715, 0.6093023419380188, 0.6103359460830688, 0.6118863224983215, 0.6255813837051392, 0.6263566017150879, 0.6279069781303406, 0.6258397698402405, 0.6297157406806946, 0.6266149878501892, 0.6289405822753906, 0.644444465637207, 0.646253228187561, 0.6447028517723083, 0.6496124267578125, 0.6568475365638733, 0.6501291990280151, 0.6529715657234192, 0.6503875851631165, 0.6643410921096802, 0.6682170629501343, 0.6671834588050842, 0.670801043510437, 0.6692506670951843, 0.6759690046310425, 0.6757106184959412, 0.6824289560317993, 0.6806201338768005, 0.6899224519729614, 0.6842377185821533, 0.6860465407371521, 0.6865633130073547, 0.6865633130073547, 0.6963824033737183, 0.697157621383667, 0.7023255825042725, 0.7049095630645752, 0.7046511769294739, 0.6943152546882629, 0.7054263353347778, 0.7149870991706848, 0.7273901700973511, 0.7165374755859375, 0.7297157645225525, 0.7242894172668457, 0.7255814075469971, 0.7224805951118469, 0.7224805951118469, 0.722739040851593, 0.7374677062034607, 0.7387596964836121, 0.7472867965698242, 0.7416020631790161, 0.7439276576042175, 0.7493540048599243, 0.7413436770439148, 0.753746747970581, 0.7524547576904297, 0.7620155215263367, 0.7459948062896729, 0.7602066993713379, 0.7664082646369934, 0.7684754729270935], 'val_loss': [0.6931605339050293, 0.6931625604629517, 0.6931580901145935, 0.693178117275238, 0.6931853890419006, 0.6931973099708557, 0.6931874752044678, 0.6931959986686707, 0.6931756138801575, 0.6931464076042175, 0.693093478679657, 0.6930103302001953, 0.6929289102554321, 0.6927624940872192, 0.6925649642944336, 0.692427933216095, 0.6922529935836792, 0.6922106742858887, 0.692082405090332, 0.6920169591903687, 0.6919465661048889, 0.6920451521873474, 0.6918200850486755, 0.6918588280677795, 0.6923046112060547, 0.6925624012947083, 0.6934006810188293, 0.6956114768981934, 0.696453869342804, 0.6978468298912048, 0.699995219707489, 0.7006162405014038, 0.7040964961051941, 0.7033922672271729, 0.7054271697998047, 0.7091765403747559, 0.7102410793304443, 0.7118855714797974, 0.7119582891464233, 0.7154551148414612, 0.7147662043571472, 0.7183623313903809, 0.718687117099762, 0.7196547389030457, 0.7210320830345154, 0.7230761051177979, 0.724919319152832, 0.7297030091285706, 0.729882001876831, 0.7313237190246582, 0.7330517768859863, 0.7317967414855957, 0.7369493246078491, 0.7360547184944153, 0.7379761338233948, 0.7403867244720459, 0.7425984740257263, 0.7442275285720825, 0.743662416934967, 0.7448069453239441, 0.7506367564201355, 0.7568036913871765, 0.7552846670150757, 0.7581709027290344, 0.7613580226898193, 0.7643277645111084, 0.7696791887283325, 0.7787490487098694, 0.7681739330291748, 0.7701259851455688, 0.7736136317253113, 0.7784883975982666, 0.7786033749580383, 0.7860797047615051, 0.7983052134513855, 0.7874295115470886, 0.790561318397522, 0.7954230308532715, 0.7992988228797913, 0.8021977543830872, 0.8086429834365845, 0.8138240575790405, 0.8145954012870789, 0.8178548216819763, 0.8200845718383789, 0.8199133276939392, 0.8252126574516296, 0.8328936696052551, 0.8369525074958801, 0.8518708944320679, 0.8476511836051941, 0.8554379343986511, 0.8639927506446838, 0.8653212785720825, 0.8701112270355225, 0.8800051212310791, 0.882680356502533, 0.8912961483001709, 0.8891936540603638, 0.892799437046051], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.4876033067703247, 0.4876033067703247, 0.4886363744735718, 0.4876033067703247, 0.4948347210884094, 0.4958677589893341, 0.4948347210884094, 0.49380165338516235, 0.4948347210884094, 0.5, 0.5020661354064941, 0.5041322112083435, 0.5030992031097412, 0.5061983466148376, 0.5113636255264282, 0.5144628286361694, 0.5175619721412659, 0.51962810754776, 0.5185950398445129, 0.5175619721412659, 0.5175619721412659, 0.5134297609329224, 0.5185950398445129, 0.5258264541625977, 0.5237603187561035, 0.5061983466148376, 0.5268595218658447, 0.5072314143180847, 0.5103305578231812, 0.5330578684806824, 0.5092975497245789, 0.5227272510528564, 0.5247933864593506, 0.5154958963394165, 0.538223147392273, 0.5123966932296753, 0.5227272510528564, 0.5185950398445129, 0.5320248007774353, 0.5206611752510071, 0.5299586653709412, 0.5278925895690918, 0.5330578684806824, 0.5433884263038635, 0.5320248007774353, 0.5268595218658447, 0.5485537052154541, 0.5413222908973694, 0.5330578684806824, 0.5423553586006165, 0.5454545617103577, 0.5423553586006165, 0.5454545617103577, 0.5454545617103577, 0.5444214940071106, 0.5402892827987671, 0.5568181872367859, 0.5485537052154541, 0.5526859760284424, 0.53925621509552, 0.5516529083251953, 0.5495867729187012, 0.5485537052154541, 0.5433884263038635, 0.5464876294136047, 0.53925621509552, 0.5516529083251953, 0.5413222908973694, 0.5506198406219482, 0.5495867729187012, 0.5464876294136047, 0.5444214940071106, 0.5413222908973694, 0.5464876294136047, 0.547520637512207, 0.5413222908973694, 0.5506198406219482, 0.5485537052154541, 0.53925621509552, 0.5361570119857788, 0.538223147392273, 0.53925621509552, 0.5413222908973694, 0.547520637512207, 0.5402892827987671, 0.5444214940071106, 0.5402892827987671, 0.5464876294136047, 0.5423553586006165, 0.5464876294136047, 0.5413222908973694, 0.5402892827987671, 0.547520637512207, 0.5454545617103577, 0.5464876294136047, 0.5402892827987671, 0.5433884263038635, 0.5413222908973694]}\n","32/32 [==============================] - 1s 9ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/29 [========================>.....] - ETA: 0s - loss: 0.6156 - accuracy: 0.6619"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 62ms/step - loss: 0.6128 - accuracy: 0.6619 - val_loss: 0.6941 - val_accuracy: 0.4860\n","Epoch 2/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.5800 - accuracy: 0.6932 - val_loss: 0.6933 - val_accuracy: 0.4871\n","Epoch 3/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5701 - accuracy: 0.7039 - val_loss: 0.6930 - val_accuracy: 0.4871\n","Epoch 4/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5681 - accuracy: 0.7037 - val_loss: 0.6917 - val_accuracy: 0.4871\n","Epoch 5/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5647 - accuracy: 0.7082 - val_loss: 0.6917 - val_accuracy: 0.4871\n","Epoch 6/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5553 - accuracy: 0.7223 - val_loss: 0.6900 - val_accuracy: 0.4871\n","Epoch 7/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5521 - accuracy: 0.7228 - val_loss: 0.6883 - val_accuracy: 0.4881\n","Epoch 8/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5509 - accuracy: 0.7117 - val_loss: 0.6865 - val_accuracy: 0.4968\n","Epoch 9/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5513 - accuracy: 0.7085 - val_loss: 0.6845 - val_accuracy: 0.5022\n","Epoch 10/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5409 - accuracy: 0.7231 - val_loss: 0.6847 - val_accuracy: 0.4978\n","Epoch 11/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5345 - accuracy: 0.7260 - val_loss: 0.6810 - val_accuracy: 0.5183\n","Epoch 12/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5365 - accuracy: 0.7255 - val_loss: 0.6780 - val_accuracy: 0.5377\n","Epoch 13/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5298 - accuracy: 0.7341 - val_loss: 0.6730 - val_accuracy: 0.5679\n","Epoch 14/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5258 - accuracy: 0.7295 - val_loss: 0.6724 - val_accuracy: 0.5453\n","Epoch 15/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5147 - accuracy: 0.7446 - val_loss: 0.6657 - val_accuracy: 0.5700\n","Epoch 16/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5224 - accuracy: 0.7395 - val_loss: 0.6653 - val_accuracy: 0.5636\n","Epoch 17/100\n","29/29 [==============================] - 2s 69ms/step - loss: 0.5137 - accuracy: 0.7306 - val_loss: 0.6571 - val_accuracy: 0.5884\n","Epoch 18/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5088 - accuracy: 0.7406 - val_loss: 0.6512 - val_accuracy: 0.6067\n","Epoch 19/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5072 - accuracy: 0.7503 - val_loss: 0.6438 - val_accuracy: 0.6293\n","Epoch 20/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4995 - accuracy: 0.7584 - val_loss: 0.6415 - val_accuracy: 0.6218\n","Epoch 21/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4935 - accuracy: 0.7567 - val_loss: 0.6388 - val_accuracy: 0.6304\n","Epoch 22/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4932 - accuracy: 0.7548 - val_loss: 0.6307 - val_accuracy: 0.6584\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4831 - accuracy: 0.7689 - val_loss: 0.6378 - val_accuracy: 0.6369\n","Epoch 24/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4862 - accuracy: 0.7602 - val_loss: 0.6308 - val_accuracy: 0.6627\n","Epoch 25/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4805 - accuracy: 0.7629 - val_loss: 0.6335 - val_accuracy: 0.6573\n","Epoch 26/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4830 - accuracy: 0.7578 - val_loss: 0.6345 - val_accuracy: 0.6735\n","Epoch 27/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4756 - accuracy: 0.7592 - val_loss: 0.6325 - val_accuracy: 0.6692\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4685 - accuracy: 0.7788 - val_loss: 0.6397 - val_accuracy: 0.6606\n","Epoch 29/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4657 - accuracy: 0.7732 - val_loss: 0.6491 - val_accuracy: 0.6573\n","Epoch 30/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4639 - accuracy: 0.7810 - val_loss: 0.6507 - val_accuracy: 0.6573\n","Epoch 31/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4637 - accuracy: 0.7748 - val_loss: 0.6504 - val_accuracy: 0.6703\n","Epoch 32/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4667 - accuracy: 0.7705 - val_loss: 0.6630 - val_accuracy: 0.6552\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4520 - accuracy: 0.7826 - val_loss: 0.6639 - val_accuracy: 0.6638\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4449 - accuracy: 0.7812 - val_loss: 0.7001 - val_accuracy: 0.6121\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4399 - accuracy: 0.7936 - val_loss: 0.6812 - val_accuracy: 0.6498\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4365 - accuracy: 0.7990 - val_loss: 0.6764 - val_accuracy: 0.6519\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4263 - accuracy: 0.8052 - val_loss: 0.7051 - val_accuracy: 0.6250\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4432 - accuracy: 0.7893 - val_loss: 0.6836 - val_accuracy: 0.6509\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4268 - accuracy: 0.7934 - val_loss: 0.6750 - val_accuracy: 0.6562\n","Epoch 40/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4262 - accuracy: 0.8017 - val_loss: 0.6803 - val_accuracy: 0.6670\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4157 - accuracy: 0.8058 - val_loss: 0.6852 - val_accuracy: 0.6552\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4131 - accuracy: 0.8090 - val_loss: 0.6933 - val_accuracy: 0.6584\n","Epoch 43/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4234 - accuracy: 0.8039 - val_loss: 0.6935 - val_accuracy: 0.6584\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4062 - accuracy: 0.8117 - val_loss: 0.7086 - val_accuracy: 0.6325\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4055 - accuracy: 0.8155 - val_loss: 0.7001 - val_accuracy: 0.6649\n","Epoch 46/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4030 - accuracy: 0.8120 - val_loss: 0.7058 - val_accuracy: 0.6562\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3955 - accuracy: 0.8217 - val_loss: 0.7055 - val_accuracy: 0.6562\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3955 - accuracy: 0.8133 - val_loss: 0.7126 - val_accuracy: 0.6573\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3868 - accuracy: 0.8249 - val_loss: 0.7094 - val_accuracy: 0.6606\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3857 - accuracy: 0.8289 - val_loss: 0.7436 - val_accuracy: 0.6315\n","Epoch 51/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3873 - accuracy: 0.8235 - val_loss: 0.7597 - val_accuracy: 0.6239\n","Epoch 52/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3877 - accuracy: 0.8187 - val_loss: 0.7209 - val_accuracy: 0.6573\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3766 - accuracy: 0.8270 - val_loss: 0.7207 - val_accuracy: 0.6552\n","Epoch 54/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3712 - accuracy: 0.8335 - val_loss: 0.7309 - val_accuracy: 0.6606\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3661 - accuracy: 0.8402 - val_loss: 0.7354 - val_accuracy: 0.6476\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3683 - accuracy: 0.8241 - val_loss: 0.7640 - val_accuracy: 0.6401\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3591 - accuracy: 0.8416 - val_loss: 0.7415 - val_accuracy: 0.6595\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3606 - accuracy: 0.8297 - val_loss: 0.7467 - val_accuracy: 0.6487\n","Epoch 59/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3568 - accuracy: 0.8351 - val_loss: 0.7679 - val_accuracy: 0.6466\n","Epoch 60/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3434 - accuracy: 0.8494 - val_loss: 0.7486 - val_accuracy: 0.6498\n","Epoch 61/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3574 - accuracy: 0.8421 - val_loss: 0.7760 - val_accuracy: 0.6422\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3334 - accuracy: 0.8497 - val_loss: 0.7655 - val_accuracy: 0.6498\n","Epoch 63/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3337 - accuracy: 0.8551 - val_loss: 0.7676 - val_accuracy: 0.6541\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3424 - accuracy: 0.8475 - val_loss: 0.7981 - val_accuracy: 0.6412\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3290 - accuracy: 0.8561 - val_loss: 0.7765 - val_accuracy: 0.6498\n","Epoch 66/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3191 - accuracy: 0.8575 - val_loss: 0.7885 - val_accuracy: 0.6444\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3281 - accuracy: 0.8540 - val_loss: 0.8049 - val_accuracy: 0.6390\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3152 - accuracy: 0.8631 - val_loss: 0.8241 - val_accuracy: 0.6466\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3045 - accuracy: 0.8672 - val_loss: 0.8269 - val_accuracy: 0.6401\n","Epoch 70/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3122 - accuracy: 0.8723 - val_loss: 0.8208 - val_accuracy: 0.6476\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3106 - accuracy: 0.8588 - val_loss: 0.8176 - val_accuracy: 0.6433\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3041 - accuracy: 0.8699 - val_loss: 0.8234 - val_accuracy: 0.6433\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2931 - accuracy: 0.8782 - val_loss: 0.8360 - val_accuracy: 0.6369\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2895 - accuracy: 0.8774 - val_loss: 0.8435 - val_accuracy: 0.6369\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3000 - accuracy: 0.8615 - val_loss: 0.8463 - val_accuracy: 0.6401\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2938 - accuracy: 0.8723 - val_loss: 0.8537 - val_accuracy: 0.6444\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2860 - accuracy: 0.8745 - val_loss: 0.8623 - val_accuracy: 0.6433\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2772 - accuracy: 0.8831 - val_loss: 0.8573 - val_accuracy: 0.6358\n","Epoch 79/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2793 - accuracy: 0.8836 - val_loss: 0.8611 - val_accuracy: 0.6433\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2701 - accuracy: 0.8863 - val_loss: 0.8707 - val_accuracy: 0.6433\n","Epoch 81/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2604 - accuracy: 0.8909 - val_loss: 0.8859 - val_accuracy: 0.6487\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2676 - accuracy: 0.8898 - val_loss: 0.8899 - val_accuracy: 0.6315\n","Epoch 83/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2617 - accuracy: 0.8839 - val_loss: 0.9306 - val_accuracy: 0.6325\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2623 - accuracy: 0.8834 - val_loss: 0.9080 - val_accuracy: 0.6304\n","Epoch 85/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2527 - accuracy: 0.8906 - val_loss: 0.9049 - val_accuracy: 0.6315\n","Epoch 86/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2486 - accuracy: 0.8930 - val_loss: 0.9275 - val_accuracy: 0.6455\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2488 - accuracy: 0.8960 - val_loss: 0.9460 - val_accuracy: 0.6455\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2533 - accuracy: 0.8930 - val_loss: 0.9332 - val_accuracy: 0.6401\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2623 - accuracy: 0.8887 - val_loss: 0.9262 - val_accuracy: 0.6315\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2418 - accuracy: 0.8992 - val_loss: 0.9725 - val_accuracy: 0.6412\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2378 - accuracy: 0.9095 - val_loss: 0.9472 - val_accuracy: 0.6390\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2241 - accuracy: 0.9124 - val_loss: 0.9628 - val_accuracy: 0.6228\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2325 - accuracy: 0.9009 - val_loss: 0.9669 - val_accuracy: 0.6433\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2200 - accuracy: 0.9049 - val_loss: 0.9705 - val_accuracy: 0.6239\n","Epoch 95/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2281 - accuracy: 0.9060 - val_loss: 0.9696 - val_accuracy: 0.6422\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2240 - accuracy: 0.9038 - val_loss: 0.9822 - val_accuracy: 0.6390\n","Epoch 97/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2261 - accuracy: 0.9073 - val_loss: 0.9786 - val_accuracy: 0.6250\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2141 - accuracy: 0.9143 - val_loss: 0.9918 - val_accuracy: 0.6336\n","Epoch 99/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2113 - accuracy: 0.9138 - val_loss: 0.9971 - val_accuracy: 0.6304\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2098 - accuracy: 0.9127 - val_loss: 1.0225 - val_accuracy: 0.6261\n","{'loss': [0.6127585172653198, 0.5799666047096252, 0.5700899958610535, 0.5680893659591675, 0.5646783709526062, 0.5553338527679443, 0.5521367788314819, 0.5508736371994019, 0.5513390302658081, 0.5409269332885742, 0.5344541072845459, 0.5365009307861328, 0.5297773480415344, 0.5258239507675171, 0.5147013664245605, 0.5223567485809326, 0.5136664509773254, 0.5087748169898987, 0.5071691870689392, 0.4995289444923401, 0.4934592843055725, 0.4931517541408539, 0.4831131100654602, 0.48624032735824585, 0.4804530441761017, 0.4829727113246918, 0.47556209564208984, 0.4685356020927429, 0.46574029326438904, 0.4638664126396179, 0.463652104139328, 0.46673065423965454, 0.45197367668151855, 0.4449479579925537, 0.4399021863937378, 0.4364842474460602, 0.42631444334983826, 0.44320231676101685, 0.4267803132534027, 0.4261983335018158, 0.4157480299472809, 0.4131374657154083, 0.42343080043792725, 0.4061870574951172, 0.40554341673851013, 0.4030161201953888, 0.3955160081386566, 0.3954782783985138, 0.38681986927986145, 0.3856540322303772, 0.38734620809555054, 0.38770514726638794, 0.3765600025653839, 0.37121880054473877, 0.3661353886127472, 0.36826270818710327, 0.35914328694343567, 0.3605579435825348, 0.35684627294540405, 0.3434312641620636, 0.3573836088180542, 0.3333908021450043, 0.3337138295173645, 0.3423953354358673, 0.32895180583000183, 0.3191400170326233, 0.32814252376556396, 0.31524550914764404, 0.3045082986354828, 0.3121746778488159, 0.3106444478034973, 0.30414459109306335, 0.2931469678878784, 0.2894582152366638, 0.29999852180480957, 0.293753981590271, 0.28603923320770264, 0.2772422730922699, 0.2792738080024719, 0.27008381485939026, 0.2603941261768341, 0.26764702796936035, 0.261740505695343, 0.26225554943084717, 0.25271153450012207, 0.2485838085412979, 0.24881699681282043, 0.2532571852207184, 0.26228272914886475, 0.2418234944343567, 0.23781432211399078, 0.22413799166679382, 0.23251202702522278, 0.21997520327568054, 0.22813382744789124, 0.2240021824836731, 0.2260894775390625, 0.21414507925510406, 0.21128292381763458, 0.20980121195316315], 'accuracy': [0.6619073152542114, 0.6931573152542114, 0.7039331793785095, 0.7036637663841248, 0.7082435488700867, 0.7222521305084229, 0.7227909564971924, 0.7117456793785095, 0.7085129022598267, 0.7230603694915771, 0.7260237336158752, 0.7254849076271057, 0.7341055870056152, 0.7295258641242981, 0.7446120977401733, 0.7394935488700867, 0.7306034564971924, 0.740571141242981, 0.7502694129943848, 0.7583512663841248, 0.7567349076271057, 0.7548491358757019, 0.7688577771186829, 0.7602370977401733, 0.7629310488700867, 0.7578125, 0.759159505367279, 0.7788254022598267, 0.7731680870056152, 0.7809805870056152, 0.774784505367279, 0.7704741358757019, 0.782597005367279, 0.78125, 0.7936422228813171, 0.7990301847457886, 0.8052262663841248, 0.7893319129943848, 0.7933728694915771, 0.8017241358757019, 0.8057650923728943, 0.8089978694915771, 0.8038793206214905, 0.8116918206214905, 0.8154633641242981, 0.8119612336158752, 0.821659505367279, 0.8133081793785095, 0.8248922228813171, 0.8289331793785095, 0.8235452771186829, 0.818696141242981, 0.8270474076271057, 0.8335129022598267, 0.8402478694915771, 0.8240840435028076, 0.8415948152542114, 0.829741358757019, 0.8351293206214905, 0.8494073152542114, 0.842133641242981, 0.8496767282485962, 0.8550646305084229, 0.8475215435028076, 0.8561422228813171, 0.8574892282485962, 0.8539870977401733, 0.8631465435028076, 0.8671875, 0.8723060488700867, 0.8588362336158752, 0.8698814511299133, 0.8782327771186829, 0.8774245977401733, 0.8615301847457886, 0.8723060488700867, 0.8744612336158752, 0.8830819129943848, 0.8836206793785095, 0.8863146305084229, 0.8908944129943848, 0.8898168206214905, 0.8838900923728943, 0.8833512663841248, 0.890625, 0.8930495977401733, 0.8960129022598267, 0.8930495977401733, 0.8887392282485962, 0.8992456793785095, 0.9094827771186829, 0.912446141242981, 0.9008620977401733, 0.904902994632721, 0.9059805870056152, 0.9038254022598267, 0.9073275923728943, 0.9143319129943848, 0.9137930870056152, 0.912715494632721], 'val_loss': [0.6940591931343079, 0.693297803401947, 0.6930360198020935, 0.6916869878768921, 0.691684901714325, 0.689988911151886, 0.6882538795471191, 0.6864648461341858, 0.6844597458839417, 0.6846722364425659, 0.6809626817703247, 0.6780312657356262, 0.672956109046936, 0.6724165678024292, 0.6656522154808044, 0.6653180718421936, 0.6571207642555237, 0.6512196063995361, 0.6438460350036621, 0.6415444016456604, 0.6387637853622437, 0.6306722164154053, 0.6377812623977661, 0.6307523250579834, 0.633490800857544, 0.6344834566116333, 0.6324735879898071, 0.6397250890731812, 0.6490757465362549, 0.6506869196891785, 0.6504314541816711, 0.6630429029464722, 0.6639440655708313, 0.7001276612281799, 0.6811533570289612, 0.6764095425605774, 0.7051478028297424, 0.6835694313049316, 0.6750380992889404, 0.6803148984909058, 0.685151219367981, 0.6932877898216248, 0.6935138702392578, 0.708578884601593, 0.7001449465751648, 0.705828070640564, 0.7054966688156128, 0.7126244902610779, 0.7093657851219177, 0.743563175201416, 0.7596846222877502, 0.7208617925643921, 0.7206695079803467, 0.7308640480041504, 0.7354406714439392, 0.7640462517738342, 0.7414869070053101, 0.7466930747032166, 0.767940878868103, 0.7485590577125549, 0.775966227054596, 0.7655481696128845, 0.7675826549530029, 0.7980854511260986, 0.7765204906463623, 0.7884658575057983, 0.8049163222312927, 0.8241381049156189, 0.8268914818763733, 0.820822536945343, 0.8176459670066833, 0.8234272599220276, 0.8359866142272949, 0.8434650897979736, 0.8463362455368042, 0.8536778092384338, 0.8623396158218384, 0.857323408126831, 0.8610596656799316, 0.8707075715065002, 0.8858805894851685, 0.8899203538894653, 0.9306472539901733, 0.9079768657684326, 0.9049394726753235, 0.9274901747703552, 0.9459806680679321, 0.9332111477851868, 0.9261860251426697, 0.9725335240364075, 0.9472265839576721, 0.9628173112869263, 0.9668794274330139, 0.9704716801643372, 0.9695758819580078, 0.9822098016738892, 0.9785997867584229, 0.9917750358581543, 0.9971269369125366, 1.0224803686141968], 'val_accuracy': [0.48599138855934143, 0.48706895112991333, 0.48706895112991333, 0.48706895112991333, 0.48706895112991333, 0.48706895112991333, 0.4881465435028076, 0.4967672526836395, 0.5021551847457886, 0.4978448152542114, 0.5183189511299133, 0.537715494632721, 0.5678879022598267, 0.545258641242981, 0.5700430870056152, 0.5635775923728943, 0.5883620977401733, 0.6066810488700867, 0.6293103694915771, 0.6217672228813171, 0.6303879022598267, 0.6584051847457886, 0.6368534564971924, 0.662715494632721, 0.6573275923728943, 0.673491358757019, 0.6691810488700867, 0.6605603694915771, 0.6573275923728943, 0.6573275923728943, 0.670258641242981, 0.6551724076271057, 0.6637930870056152, 0.6120689511299133, 0.649784505367279, 0.6519396305084229, 0.625, 0.6508620977401733, 0.65625, 0.6670258641242981, 0.6551724076271057, 0.6584051847457886, 0.6584051847457886, 0.6325430870056152, 0.6648706793785095, 0.65625, 0.65625, 0.6573275923728943, 0.6605603694915771, 0.631465494632721, 0.6239224076271057, 0.6573275923728943, 0.6551724076271057, 0.6605603694915771, 0.6476293206214905, 0.6400862336158752, 0.6594827771186829, 0.6487069129943848, 0.6465517282485962, 0.649784505367279, 0.642241358757019, 0.649784505367279, 0.6540948152542114, 0.6411637663841248, 0.649784505367279, 0.6443965435028076, 0.639008641242981, 0.6465517282485962, 0.6400862336158752, 0.6476293206214905, 0.6433189511299133, 0.6433189511299133, 0.6368534564971924, 0.6368534564971924, 0.6400862336158752, 0.6443965435028076, 0.6433189511299133, 0.6357758641242981, 0.6433189511299133, 0.6433189511299133, 0.6487069129943848, 0.631465494632721, 0.6325430870056152, 0.6303879022598267, 0.631465494632721, 0.6454741358757019, 0.6454741358757019, 0.6400862336158752, 0.631465494632721, 0.6411637663841248, 0.639008641242981, 0.6228448152542114, 0.6433189511299133, 0.6239224076271057, 0.642241358757019, 0.639008641242981, 0.625, 0.6336206793785095, 0.6303879022598267, 0.6260775923728943]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.6015 - accuracy: 0.6715"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 54ms/step - loss: 0.6015 - accuracy: 0.6715 - val_loss: 0.6922 - val_accuracy: 0.4977\n","Epoch 2/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5753 - accuracy: 0.6944 - val_loss: 0.6920 - val_accuracy: 0.5000\n","Epoch 3/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5708 - accuracy: 0.6969 - val_loss: 0.6905 - val_accuracy: 0.5023\n","Epoch 4/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5651 - accuracy: 0.7015 - val_loss: 0.6906 - val_accuracy: 0.5023\n","Epoch 5/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5552 - accuracy: 0.7122 - val_loss: 0.6894 - val_accuracy: 0.5045\n","Epoch 6/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5542 - accuracy: 0.7187 - val_loss: 0.6880 - val_accuracy: 0.5057\n","Epoch 7/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5469 - accuracy: 0.7201 - val_loss: 0.6868 - val_accuracy: 0.5068\n","Epoch 8/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5436 - accuracy: 0.7247 - val_loss: 0.6844 - val_accuracy: 0.5136\n","Epoch 9/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5423 - accuracy: 0.7281 - val_loss: 0.6825 - val_accuracy: 0.5204\n","Epoch 10/100\n","28/28 [==============================] - 1s 43ms/step - loss: 0.5349 - accuracy: 0.7334 - val_loss: 0.6790 - val_accuracy: 0.5339\n","Epoch 11/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5314 - accuracy: 0.7357 - val_loss: 0.6779 - val_accuracy: 0.5283\n","Epoch 12/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5324 - accuracy: 0.7306 - val_loss: 0.6751 - val_accuracy: 0.5430\n","Epoch 13/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.5225 - accuracy: 0.7349 - val_loss: 0.6695 - val_accuracy: 0.5690\n","Epoch 14/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5202 - accuracy: 0.7368 - val_loss: 0.6680 - val_accuracy: 0.5588\n","Epoch 15/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5206 - accuracy: 0.7360 - val_loss: 0.6635 - val_accuracy: 0.5667\n","Epoch 16/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.5104 - accuracy: 0.7487 - val_loss: 0.6593 - val_accuracy: 0.5848\n","Epoch 17/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5095 - accuracy: 0.7465 - val_loss: 0.6645 - val_accuracy: 0.5600\n","Epoch 18/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.5056 - accuracy: 0.7513 - val_loss: 0.6441 - val_accuracy: 0.6459\n","Epoch 19/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4972 - accuracy: 0.7507 - val_loss: 0.6466 - val_accuracy: 0.6131\n","Epoch 20/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4967 - accuracy: 0.7583 - val_loss: 0.6445 - val_accuracy: 0.6075\n","Epoch 21/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4937 - accuracy: 0.7626 - val_loss: 0.6337 - val_accuracy: 0.6290\n","Epoch 22/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4878 - accuracy: 0.7606 - val_loss: 0.6329 - val_accuracy: 0.6222\n","Epoch 23/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4877 - accuracy: 0.7609 - val_loss: 0.6285 - val_accuracy: 0.6493\n","Epoch 24/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4805 - accuracy: 0.7654 - val_loss: 0.6307 - val_accuracy: 0.6516\n","Epoch 25/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4722 - accuracy: 0.7694 - val_loss: 0.6386 - val_accuracy: 0.6471\n","Epoch 26/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4813 - accuracy: 0.7632 - val_loss: 0.6364 - val_accuracy: 0.6505\n","Epoch 27/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4694 - accuracy: 0.7728 - val_loss: 0.6398 - val_accuracy: 0.6538\n","Epoch 28/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4636 - accuracy: 0.7739 - val_loss: 0.6467 - val_accuracy: 0.6606\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4584 - accuracy: 0.7895 - val_loss: 0.6583 - val_accuracy: 0.6505\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4589 - accuracy: 0.7835 - val_loss: 0.6615 - val_accuracy: 0.6505\n","Epoch 31/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4511 - accuracy: 0.7849 - val_loss: 0.6638 - val_accuracy: 0.6618\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4557 - accuracy: 0.7847 - val_loss: 0.6713 - val_accuracy: 0.6584\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4521 - accuracy: 0.7869 - val_loss: 0.6762 - val_accuracy: 0.6584\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4392 - accuracy: 0.8022 - val_loss: 0.6888 - val_accuracy: 0.6561\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4384 - accuracy: 0.7963 - val_loss: 0.6826 - val_accuracy: 0.6606\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4389 - accuracy: 0.7906 - val_loss: 0.7005 - val_accuracy: 0.6572\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4324 - accuracy: 0.7929 - val_loss: 0.6974 - val_accuracy: 0.6572\n","Epoch 38/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4211 - accuracy: 0.8104 - val_loss: 0.7183 - val_accuracy: 0.6425\n","Epoch 39/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4272 - accuracy: 0.8014 - val_loss: 0.7036 - val_accuracy: 0.6629\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4196 - accuracy: 0.8048 - val_loss: 0.7118 - val_accuracy: 0.6471\n","Epoch 41/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4157 - accuracy: 0.8101 - val_loss: 0.7140 - val_accuracy: 0.6550\n","Epoch 42/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4086 - accuracy: 0.8172 - val_loss: 0.7256 - val_accuracy: 0.6357\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4123 - accuracy: 0.8161 - val_loss: 0.7227 - val_accuracy: 0.6572\n","Epoch 44/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4140 - accuracy: 0.8130 - val_loss: 0.7358 - val_accuracy: 0.6403\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3942 - accuracy: 0.8220 - val_loss: 0.7264 - val_accuracy: 0.6584\n","Epoch 46/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3971 - accuracy: 0.8223 - val_loss: 0.7432 - val_accuracy: 0.6561\n","Epoch 47/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.4039 - accuracy: 0.8209 - val_loss: 0.7424 - val_accuracy: 0.6640\n","Epoch 48/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3940 - accuracy: 0.8152 - val_loss: 0.7463 - val_accuracy: 0.6572\n","Epoch 49/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3854 - accuracy: 0.8271 - val_loss: 0.7918 - val_accuracy: 0.6222\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3828 - accuracy: 0.8291 - val_loss: 0.7526 - val_accuracy: 0.6618\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3718 - accuracy: 0.8418 - val_loss: 0.7619 - val_accuracy: 0.6516\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3797 - accuracy: 0.8297 - val_loss: 0.7791 - val_accuracy: 0.6301\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3830 - accuracy: 0.8231 - val_loss: 0.7803 - val_accuracy: 0.6516\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3681 - accuracy: 0.8364 - val_loss: 0.8044 - val_accuracy: 0.6290\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3688 - accuracy: 0.8353 - val_loss: 0.7783 - val_accuracy: 0.6550\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3643 - accuracy: 0.8410 - val_loss: 0.7732 - val_accuracy: 0.6482\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3568 - accuracy: 0.8430 - val_loss: 0.7925 - val_accuracy: 0.6380\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3466 - accuracy: 0.8540 - val_loss: 0.7870 - val_accuracy: 0.6629\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3399 - accuracy: 0.8517 - val_loss: 0.8102 - val_accuracy: 0.6380\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3447 - accuracy: 0.8534 - val_loss: 0.8070 - val_accuracy: 0.6516\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3418 - accuracy: 0.8463 - val_loss: 0.8061 - val_accuracy: 0.6550\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3339 - accuracy: 0.8563 - val_loss: 0.8109 - val_accuracy: 0.6640\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3263 - accuracy: 0.8625 - val_loss: 0.8223 - val_accuracy: 0.6572\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3295 - accuracy: 0.8582 - val_loss: 0.8350 - val_accuracy: 0.6561\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3390 - accuracy: 0.8469 - val_loss: 0.8509 - val_accuracy: 0.6505\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3209 - accuracy: 0.8667 - val_loss: 0.8333 - val_accuracy: 0.6527\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3249 - accuracy: 0.8531 - val_loss: 0.8408 - val_accuracy: 0.6369\n","Epoch 68/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3187 - accuracy: 0.8727 - val_loss: 0.8558 - val_accuracy: 0.6357\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3065 - accuracy: 0.8676 - val_loss: 0.8638 - val_accuracy: 0.6493\n","Epoch 70/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3143 - accuracy: 0.8664 - val_loss: 0.8715 - val_accuracy: 0.6516\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3064 - accuracy: 0.8690 - val_loss: 0.8615 - val_accuracy: 0.6493\n","Epoch 72/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2985 - accuracy: 0.8707 - val_loss: 0.8931 - val_accuracy: 0.6369\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3015 - accuracy: 0.8769 - val_loss: 0.8832 - val_accuracy: 0.6572\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2904 - accuracy: 0.8786 - val_loss: 0.8976 - val_accuracy: 0.6391\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3020 - accuracy: 0.8645 - val_loss: 0.9057 - val_accuracy: 0.6538\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2860 - accuracy: 0.8846 - val_loss: 0.9140 - val_accuracy: 0.6324\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2846 - accuracy: 0.8851 - val_loss: 0.9088 - val_accuracy: 0.6505\n","Epoch 78/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2878 - accuracy: 0.8786 - val_loss: 0.9364 - val_accuracy: 0.6210\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2804 - accuracy: 0.8857 - val_loss: 0.9479 - val_accuracy: 0.6357\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2706 - accuracy: 0.8854 - val_loss: 0.9286 - val_accuracy: 0.6493\n","Epoch 81/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2705 - accuracy: 0.8874 - val_loss: 0.9303 - val_accuracy: 0.6516\n","Epoch 82/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2703 - accuracy: 0.8846 - val_loss: 0.9351 - val_accuracy: 0.6516\n","Epoch 83/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2661 - accuracy: 0.8888 - val_loss: 0.9516 - val_accuracy: 0.6561\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2514 - accuracy: 0.9007 - val_loss: 0.9487 - val_accuracy: 0.6538\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2586 - accuracy: 0.8930 - val_loss: 0.9749 - val_accuracy: 0.6516\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2557 - accuracy: 0.8922 - val_loss: 0.9583 - val_accuracy: 0.6459\n","Epoch 87/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2520 - accuracy: 0.9001 - val_loss: 0.9722 - val_accuracy: 0.6493\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2499 - accuracy: 0.8945 - val_loss: 0.9797 - val_accuracy: 0.6527\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2459 - accuracy: 0.8981 - val_loss: 0.9708 - val_accuracy: 0.6584\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2382 - accuracy: 0.9061 - val_loss: 0.9888 - val_accuracy: 0.6471\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2385 - accuracy: 0.9021 - val_loss: 1.0546 - val_accuracy: 0.6357\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2362 - accuracy: 0.9080 - val_loss: 1.0126 - val_accuracy: 0.6516\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2317 - accuracy: 0.8990 - val_loss: 1.0795 - val_accuracy: 0.6199\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2320 - accuracy: 0.9035 - val_loss: 1.0239 - val_accuracy: 0.6538\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2289 - accuracy: 0.9109 - val_loss: 1.0536 - val_accuracy: 0.6437\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2253 - accuracy: 0.9117 - val_loss: 1.0234 - val_accuracy: 0.6425\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2237 - accuracy: 0.9123 - val_loss: 1.0623 - val_accuracy: 0.6369\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2264 - accuracy: 0.9066 - val_loss: 1.0425 - val_accuracy: 0.6437\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2098 - accuracy: 0.9188 - val_loss: 1.0694 - val_accuracy: 0.6425\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2102 - accuracy: 0.9160 - val_loss: 1.0504 - val_accuracy: 0.6471\n","{'loss': [0.6015039682388306, 0.575330913066864, 0.5708194971084595, 0.5650554895401001, 0.5552387833595276, 0.5542171597480774, 0.5468835234642029, 0.543624997138977, 0.5423406362533569, 0.5349346399307251, 0.5313854813575745, 0.5324147343635559, 0.5224536657333374, 0.5201854705810547, 0.520585834980011, 0.5104079246520996, 0.5095404386520386, 0.5056171417236328, 0.4972054660320282, 0.49665147066116333, 0.49366867542266846, 0.4878358244895935, 0.4877455532550812, 0.48054587841033936, 0.47215473651885986, 0.4813082218170166, 0.46936166286468506, 0.46356290578842163, 0.4583641588687897, 0.45890703797340393, 0.4510622024536133, 0.45570772886276245, 0.45210954546928406, 0.43921959400177, 0.4383673071861267, 0.438921183347702, 0.4324127733707428, 0.4210634231567383, 0.4271892309188843, 0.41961944103240967, 0.415678471326828, 0.40864163637161255, 0.4123254418373108, 0.4140148460865021, 0.39415329694747925, 0.3971060812473297, 0.40385156869888306, 0.3939693868160248, 0.3853894770145416, 0.3827507197856903, 0.37181898951530457, 0.3797008693218231, 0.38304537534713745, 0.3680593967437744, 0.36880216002464294, 0.3643302023410797, 0.3568441569805145, 0.34659454226493835, 0.339877188205719, 0.34473368525505066, 0.34175893664360046, 0.3338901698589325, 0.3263370096683502, 0.32954517006874084, 0.33900728821754456, 0.32089611887931824, 0.3249366879463196, 0.3186674416065216, 0.30653274059295654, 0.31427979469299316, 0.306425005197525, 0.29854637384414673, 0.30149590969085693, 0.2903997600078583, 0.3019847273826599, 0.2860204577445984, 0.2845938801765442, 0.2878369987010956, 0.2803555428981781, 0.2706315815448761, 0.27054306864738464, 0.27029839158058167, 0.2660706043243408, 0.25144124031066895, 0.2586144804954529, 0.25567787885665894, 0.25201472640037537, 0.24987240135669708, 0.2459317445755005, 0.23823226988315582, 0.23850730061531067, 0.23620115220546722, 0.23166336119174957, 0.23196087777614594, 0.22889591753482819, 0.22529935836791992, 0.22370927035808563, 0.22638380527496338, 0.2097700983285904, 0.21022255718708038], 'accuracy': [0.6714770793914795, 0.6943972706794739, 0.696943998336792, 0.7014714479446411, 0.7122241258621216, 0.7187322974205017, 0.7201471328735352, 0.7246745824813843, 0.7280701994895935, 0.7334465384483337, 0.7357102632522583, 0.7306168675422668, 0.7348613739013672, 0.7368420958518982, 0.7359932065010071, 0.7487266659736633, 0.7464629411697388, 0.7512733340263367, 0.7507073879241943, 0.7583475112915039, 0.7625919580459595, 0.7606111764907837, 0.7608941793441772, 0.7654216289520264, 0.7693831324577332, 0.7631579041481018, 0.7727787494659424, 0.7739105820655823, 0.7894737124443054, 0.7835314273834229, 0.7849462628364563, 0.7846632599830627, 0.7869269847869873, 0.8022071123123169, 0.7962648272514343, 0.7906055450439453, 0.7928692698478699, 0.810413122177124, 0.8013582229614258, 0.804753839969635, 0.8101301789283752, 0.8172042965888977, 0.8160724639892578, 0.8129597902297974, 0.8220146894454956, 0.8222976922988892, 0.8208828568458557, 0.8152235150337219, 0.8271080851554871, 0.8290888667106628, 0.8418223261833191, 0.8296547532081604, 0.8231465816497803, 0.8364459276199341, 0.8353140950202942, 0.8409733772277832, 0.842954158782959, 0.853989839553833, 0.8517261147499084, 0.8534238934516907, 0.8463497161865234, 0.8562535643577576, 0.8624787926673889, 0.8582342863082886, 0.8469156622886658, 0.8667232394218445, 0.8531408905982971, 0.872665524482727, 0.8675721287727356, 0.8664402961730957, 0.868986964225769, 0.870684802532196, 0.8769100308418274, 0.8786078095436096, 0.8644595146179199, 0.8845500946044922, 0.8851160407066345, 0.8786078095436096, 0.8856819272041321, 0.8853989839553833, 0.8873797655105591, 0.8845500946044922, 0.8887945413589478, 0.9006791114807129, 0.8930390477180481, 0.892190158367157, 0.9001131653785706, 0.8944538831710815, 0.8981324434280396, 0.9060554504394531, 0.9020939469337463, 0.9080362319946289, 0.8989813327789307, 0.9035087823867798, 0.9108659029006958, 0.9117147922515869, 0.9122806787490845, 0.9066213965415955, 0.9187889099121094, 0.9159592390060425], 'val_loss': [0.6922441720962524, 0.6920022368431091, 0.6904716491699219, 0.6905557513237, 0.6893947720527649, 0.6879922747612, 0.6867767572402954, 0.6843520402908325, 0.6824713945388794, 0.6789635419845581, 0.6778773665428162, 0.6750801205635071, 0.6695325970649719, 0.6679922342300415, 0.6635280251502991, 0.6593077778816223, 0.6645042896270752, 0.6441442370414734, 0.6465672254562378, 0.6445099711418152, 0.6337229013442993, 0.6329174637794495, 0.6285462975502014, 0.6306752562522888, 0.6386216282844543, 0.6363713145256042, 0.6398492455482483, 0.6467002034187317, 0.6582977175712585, 0.6615487337112427, 0.663784384727478, 0.671274721622467, 0.676180899143219, 0.6888411641120911, 0.6826441287994385, 0.7005279660224915, 0.697350025177002, 0.7182578444480896, 0.7036207318305969, 0.7117676734924316, 0.7139971256256104, 0.7255908846855164, 0.7227171063423157, 0.735751748085022, 0.7264493107795715, 0.7431787848472595, 0.7423630952835083, 0.7462651133537292, 0.7917503714561462, 0.7526425719261169, 0.761885404586792, 0.7790623307228088, 0.7802547216415405, 0.8043884038925171, 0.7782534956932068, 0.7731910347938538, 0.792465090751648, 0.7869616150856018, 0.8101628422737122, 0.8069558143615723, 0.8061364889144897, 0.8108943700790405, 0.8223457336425781, 0.8349797129631042, 0.8509238958358765, 0.833331286907196, 0.840781033039093, 0.8558348417282104, 0.8638052940368652, 0.8714598417282104, 0.8614559769630432, 0.8931471705436707, 0.8832202553749084, 0.8976187705993652, 0.9056844711303711, 0.9139513969421387, 0.9087535738945007, 0.9363563656806946, 0.9478877186775208, 0.928580105304718, 0.9303272366523743, 0.9351494312286377, 0.951572597026825, 0.948728621006012, 0.9748827219009399, 0.9583407640457153, 0.9722076654434204, 0.9797348380088806, 0.9707952737808228, 0.9888066649436951, 1.0545666217803955, 1.0125548839569092, 1.079457402229309, 1.023903489112854, 1.0535587072372437, 1.0234407186508179, 1.0622878074645996, 1.04245924949646, 1.0693786144256592, 1.0504086017608643], 'val_accuracy': [0.4977375566959381, 0.5, 0.5022624731063843, 0.5022624731063843, 0.5045248866081238, 0.5056561231613159, 0.5067873597145081, 0.5135746598243713, 0.5203620195388794, 0.5339366793632507, 0.5282805562019348, 0.5429864525794983, 0.5690045356750488, 0.5588235259056091, 0.5667420625686646, 0.5848416090011597, 0.5599547624588013, 0.6459276080131531, 0.6131221652030945, 0.6074660420417786, 0.6289592981338501, 0.622171938419342, 0.6493212580680847, 0.651583731174469, 0.6470588445663452, 0.6504524946212769, 0.6538461446762085, 0.6606335043907166, 0.6504524946212769, 0.6504524946212769, 0.6617646813392639, 0.6583710312843323, 0.6583710312843323, 0.6561086177825928, 0.6606335043907166, 0.6572397947311401, 0.6572397947311401, 0.6425339579582214, 0.662895917892456, 0.6470588445663452, 0.6549773812294006, 0.6357465982437134, 0.6572397947311401, 0.6402714848518372, 0.6583710312843323, 0.6561086177825928, 0.6640271544456482, 0.6572397947311401, 0.622171938419342, 0.6617646813392639, 0.651583731174469, 0.6300904750823975, 0.651583731174469, 0.6289592981338501, 0.6549773812294006, 0.6481900215148926, 0.6380090713500977, 0.662895917892456, 0.6380090713500977, 0.651583731174469, 0.6549773812294006, 0.6640271544456482, 0.6572397947311401, 0.6561086177825928, 0.6504524946212769, 0.6527149081230164, 0.6368778347969055, 0.6357465982437134, 0.6493212580680847, 0.651583731174469, 0.6493212580680847, 0.6368778347969055, 0.6572397947311401, 0.639140248298645, 0.6538461446762085, 0.6323529481887817, 0.6504524946212769, 0.6210407018661499, 0.6357465982437134, 0.6493212580680847, 0.651583731174469, 0.651583731174469, 0.6561086177825928, 0.6538461446762085, 0.651583731174469, 0.6459276080131531, 0.6493212580680847, 0.6527149081230164, 0.6583710312843323, 0.6470588445663452, 0.6357465982437134, 0.651583731174469, 0.6199095249176025, 0.6538461446762085, 0.6436651349067688, 0.6425339579582214, 0.6368778347969055, 0.6436651349067688, 0.6425339579582214, 0.6470588445663452]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.5985 - accuracy: 0.6684"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 55ms/step - loss: 0.6001 - accuracy: 0.6656 - val_loss: 0.6954 - val_accuracy: 0.4876\n","Epoch 2/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5799 - accuracy: 0.6925 - val_loss: 0.6945 - val_accuracy: 0.4897\n","Epoch 3/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5743 - accuracy: 0.6953 - val_loss: 0.6941 - val_accuracy: 0.4907\n","Epoch 4/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5688 - accuracy: 0.7044 - val_loss: 0.6936 - val_accuracy: 0.4886\n","Epoch 5/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5631 - accuracy: 0.7085 - val_loss: 0.6929 - val_accuracy: 0.4897\n","Epoch 6/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5588 - accuracy: 0.7093 - val_loss: 0.6923 - val_accuracy: 0.4938\n","Epoch 7/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5565 - accuracy: 0.7127 - val_loss: 0.6918 - val_accuracy: 0.4938\n","Epoch 8/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5530 - accuracy: 0.7132 - val_loss: 0.6895 - val_accuracy: 0.5021\n","Epoch 9/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5484 - accuracy: 0.7233 - val_loss: 0.6876 - val_accuracy: 0.5031\n","Epoch 10/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5442 - accuracy: 0.7217 - val_loss: 0.6878 - val_accuracy: 0.5031\n","Epoch 11/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5377 - accuracy: 0.7240 - val_loss: 0.6859 - val_accuracy: 0.5093\n","Epoch 12/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5366 - accuracy: 0.7279 - val_loss: 0.6869 - val_accuracy: 0.5124\n","Epoch 13/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5353 - accuracy: 0.7230 - val_loss: 0.6839 - val_accuracy: 0.5207\n","Epoch 14/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5167 - accuracy: 0.7509 - val_loss: 0.6780 - val_accuracy: 0.5558\n","Epoch 15/100\n","31/31 [==============================] - 2s 50ms/step - loss: 0.5229 - accuracy: 0.7344 - val_loss: 0.6784 - val_accuracy: 0.5599\n","Epoch 16/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5185 - accuracy: 0.7403 - val_loss: 0.6751 - val_accuracy: 0.5785\n","Epoch 17/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5195 - accuracy: 0.7328 - val_loss: 0.6721 - val_accuracy: 0.5981\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.6791 - val_accuracy: 0.5795\n","Epoch 19/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5113 - accuracy: 0.7385 - val_loss: 0.6810 - val_accuracy: 0.5868\n","Epoch 20/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5026 - accuracy: 0.7501 - val_loss: 0.6766 - val_accuracy: 0.6043\n","Epoch 21/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5065 - accuracy: 0.7465 - val_loss: 0.6805 - val_accuracy: 0.6116\n","Epoch 22/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5008 - accuracy: 0.7514 - val_loss: 0.6935 - val_accuracy: 0.5971\n","Epoch 23/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4931 - accuracy: 0.7615 - val_loss: 0.7034 - val_accuracy: 0.5971\n","Epoch 24/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4891 - accuracy: 0.7566 - val_loss: 0.7029 - val_accuracy: 0.6105\n","Epoch 25/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4858 - accuracy: 0.7612 - val_loss: 0.7168 - val_accuracy: 0.6033\n","Epoch 26/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4879 - accuracy: 0.7623 - val_loss: 0.7244 - val_accuracy: 0.6064\n","Epoch 27/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4797 - accuracy: 0.7667 - val_loss: 0.7362 - val_accuracy: 0.6002\n","Epoch 28/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4707 - accuracy: 0.7783 - val_loss: 0.7425 - val_accuracy: 0.6043\n","Epoch 29/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4704 - accuracy: 0.7646 - val_loss: 0.7546 - val_accuracy: 0.5971\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4634 - accuracy: 0.7817 - val_loss: 0.7579 - val_accuracy: 0.6012\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4639 - accuracy: 0.7705 - val_loss: 0.7638 - val_accuracy: 0.6095\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4628 - accuracy: 0.7778 - val_loss: 0.7763 - val_accuracy: 0.5961\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4628 - accuracy: 0.7770 - val_loss: 0.7781 - val_accuracy: 0.6054\n","Epoch 34/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4540 - accuracy: 0.7801 - val_loss: 0.7827 - val_accuracy: 0.5961\n","Epoch 35/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4468 - accuracy: 0.7879 - val_loss: 0.7936 - val_accuracy: 0.5909\n","Epoch 36/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4455 - accuracy: 0.7943 - val_loss: 0.8026 - val_accuracy: 0.5950\n","Epoch 37/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4399 - accuracy: 0.7910 - val_loss: 0.8112 - val_accuracy: 0.6023\n","Epoch 38/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4398 - accuracy: 0.7928 - val_loss: 0.8043 - val_accuracy: 0.6126\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4335 - accuracy: 0.8018 - val_loss: 0.8208 - val_accuracy: 0.5868\n","Epoch 40/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4277 - accuracy: 0.7987 - val_loss: 0.8117 - val_accuracy: 0.6105\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4371 - accuracy: 0.7935 - val_loss: 0.8118 - val_accuracy: 0.6085\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4177 - accuracy: 0.8065 - val_loss: 0.8264 - val_accuracy: 0.5940\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4195 - accuracy: 0.8010 - val_loss: 0.8198 - val_accuracy: 0.6105\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4151 - accuracy: 0.8047 - val_loss: 0.8297 - val_accuracy: 0.6064\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4191 - accuracy: 0.8052 - val_loss: 0.8890 - val_accuracy: 0.5888\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4055 - accuracy: 0.8176 - val_loss: 0.8526 - val_accuracy: 0.5961\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4121 - accuracy: 0.8103 - val_loss: 0.8485 - val_accuracy: 0.6012\n","Epoch 48/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3990 - accuracy: 0.8168 - val_loss: 0.8495 - val_accuracy: 0.6105\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3984 - accuracy: 0.8155 - val_loss: 0.8644 - val_accuracy: 0.6002\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3987 - accuracy: 0.8134 - val_loss: 0.8633 - val_accuracy: 0.6043\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4012 - accuracy: 0.8132 - val_loss: 0.8560 - val_accuracy: 0.6064\n","Epoch 52/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3896 - accuracy: 0.8235 - val_loss: 0.8826 - val_accuracy: 0.6012\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3905 - accuracy: 0.8186 - val_loss: 0.8769 - val_accuracy: 0.6064\n","Epoch 54/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3863 - accuracy: 0.8225 - val_loss: 0.8756 - val_accuracy: 0.6126\n","Epoch 55/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3754 - accuracy: 0.8302 - val_loss: 0.8782 - val_accuracy: 0.6064\n","Epoch 56/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3740 - accuracy: 0.8295 - val_loss: 0.9074 - val_accuracy: 0.5940\n","Epoch 57/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3760 - accuracy: 0.8287 - val_loss: 0.9579 - val_accuracy: 0.5868\n","Epoch 58/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3797 - accuracy: 0.8279 - val_loss: 0.9137 - val_accuracy: 0.5981\n","Epoch 59/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3608 - accuracy: 0.8375 - val_loss: 0.9142 - val_accuracy: 0.6054\n","Epoch 60/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3572 - accuracy: 0.8426 - val_loss: 0.9205 - val_accuracy: 0.6054\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3540 - accuracy: 0.8457 - val_loss: 0.9273 - val_accuracy: 0.6085\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3569 - accuracy: 0.8380 - val_loss: 0.9260 - val_accuracy: 0.6054\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3461 - accuracy: 0.8452 - val_loss: 0.9524 - val_accuracy: 0.6002\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3600 - accuracy: 0.8359 - val_loss: 0.9443 - val_accuracy: 0.6023\n","Epoch 65/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3461 - accuracy: 0.8460 - val_loss: 0.9554 - val_accuracy: 0.6043\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3315 - accuracy: 0.8517 - val_loss: 0.9647 - val_accuracy: 0.6012\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3372 - accuracy: 0.8522 - val_loss: 0.9683 - val_accuracy: 0.6002\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3336 - accuracy: 0.8535 - val_loss: 0.9653 - val_accuracy: 0.6054\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3291 - accuracy: 0.8556 - val_loss: 0.9782 - val_accuracy: 0.6095\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3227 - accuracy: 0.8630 - val_loss: 0.9877 - val_accuracy: 0.6023\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3133 - accuracy: 0.8672 - val_loss: 1.0294 - val_accuracy: 0.5847\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3193 - accuracy: 0.8599 - val_loss: 1.0147 - val_accuracy: 0.6012\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3134 - accuracy: 0.8618 - val_loss: 1.0207 - val_accuracy: 0.6002\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3213 - accuracy: 0.8623 - val_loss: 1.0387 - val_accuracy: 0.5899\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3121 - accuracy: 0.8584 - val_loss: 1.0341 - val_accuracy: 0.5940\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3175 - accuracy: 0.8589 - val_loss: 1.0231 - val_accuracy: 0.6012\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2987 - accuracy: 0.8682 - val_loss: 1.0359 - val_accuracy: 0.6033\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2918 - accuracy: 0.8747 - val_loss: 1.0382 - val_accuracy: 0.6064\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2950 - accuracy: 0.8747 - val_loss: 1.0474 - val_accuracy: 0.6023\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2923 - accuracy: 0.8760 - val_loss: 1.0719 - val_accuracy: 0.6002\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2899 - accuracy: 0.8747 - val_loss: 1.0717 - val_accuracy: 0.6033\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2916 - accuracy: 0.8729 - val_loss: 1.0764 - val_accuracy: 0.5981\n","Epoch 83/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2784 - accuracy: 0.8850 - val_loss: 1.0746 - val_accuracy: 0.6064\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2802 - accuracy: 0.8757 - val_loss: 1.0797 - val_accuracy: 0.6043\n","Epoch 85/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2899 - accuracy: 0.8716 - val_loss: 1.0823 - val_accuracy: 0.5971\n","Epoch 86/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2756 - accuracy: 0.8806 - val_loss: 1.1484 - val_accuracy: 0.5919\n","Epoch 87/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2766 - accuracy: 0.8884 - val_loss: 1.1096 - val_accuracy: 0.5992\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2667 - accuracy: 0.8915 - val_loss: 1.1169 - val_accuracy: 0.6033\n","Epoch 89/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2619 - accuracy: 0.8876 - val_loss: 1.1340 - val_accuracy: 0.6043\n","Epoch 90/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2587 - accuracy: 0.8915 - val_loss: 1.1306 - val_accuracy: 0.6064\n","Epoch 91/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2475 - accuracy: 0.9003 - val_loss: 1.1556 - val_accuracy: 0.6023\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2456 - accuracy: 0.8964 - val_loss: 1.1643 - val_accuracy: 0.6064\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2599 - accuracy: 0.8879 - val_loss: 1.1765 - val_accuracy: 0.5940\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2490 - accuracy: 0.8938 - val_loss: 1.2028 - val_accuracy: 0.5971\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2558 - accuracy: 0.8920 - val_loss: 1.2385 - val_accuracy: 0.5878\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2658 - accuracy: 0.8819 - val_loss: 1.1703 - val_accuracy: 0.6033\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2435 - accuracy: 0.9000 - val_loss: 1.1785 - val_accuracy: 0.6054\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2357 - accuracy: 0.8987 - val_loss: 1.2137 - val_accuracy: 0.5961\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2323 - accuracy: 0.9070 - val_loss: 1.1991 - val_accuracy: 0.5940\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2269 - accuracy: 0.9057 - val_loss: 1.2064 - val_accuracy: 0.5992\n","{'loss': [0.6001375913619995, 0.579943835735321, 0.5743481516838074, 0.5688251256942749, 0.563132643699646, 0.5588414072990417, 0.5564683675765991, 0.5530149936676025, 0.5483903884887695, 0.5442497730255127, 0.5377242565155029, 0.536616325378418, 0.535267174243927, 0.5167278051376343, 0.5229089260101318, 0.5184930562973022, 0.5194939374923706, 0.5049077868461609, 0.5112882256507874, 0.502568781375885, 0.5065315961837769, 0.5008001923561096, 0.493137925863266, 0.4890528917312622, 0.485757440328598, 0.48787781596183777, 0.4797395169734955, 0.4707307517528534, 0.4704109728336334, 0.4634205996990204, 0.4639038145542145, 0.4627547264099121, 0.4627702534198761, 0.4540483057498932, 0.446844220161438, 0.44550254940986633, 0.4399486184120178, 0.4398495554924011, 0.43353161215782166, 0.42766839265823364, 0.43711867928504944, 0.41770315170288086, 0.41949525475502014, 0.41514360904693604, 0.41906964778900146, 0.40548622608184814, 0.4120565354824066, 0.3990213871002197, 0.39837560057640076, 0.3986709415912628, 0.4012278914451599, 0.3895758390426636, 0.3905215859413147, 0.3862987756729126, 0.3754465579986572, 0.37398555874824524, 0.3759678900241852, 0.37966233491897583, 0.36077743768692017, 0.35723286867141724, 0.35402965545654297, 0.35691991448402405, 0.34606775641441345, 0.36003437638282776, 0.34606730937957764, 0.33147484064102173, 0.3371739089488983, 0.33358946442604065, 0.32914426922798157, 0.32267481088638306, 0.3133189082145691, 0.3193063735961914, 0.3134191632270813, 0.32126864790916443, 0.31209123134613037, 0.31750601530075073, 0.29874974489212036, 0.29176706075668335, 0.29499176144599915, 0.2922762930393219, 0.2898904085159302, 0.2916383147239685, 0.2784193754196167, 0.2802206575870514, 0.2898738384246826, 0.27562034130096436, 0.2766260504722595, 0.2666657269001007, 0.261917382478714, 0.2587258815765381, 0.2475288063287735, 0.2455538958311081, 0.2599259912967682, 0.24903498589992523, 0.2558329403400421, 0.26576778292655945, 0.24354158341884613, 0.23573751747608185, 0.2323291301727295, 0.22689324617385864], 'accuracy': [0.6656330823898315, 0.6925064325332642, 0.695348858833313, 0.7043927907943726, 0.708527147769928, 0.7093023061752319, 0.7126615047454834, 0.713178277015686, 0.7232558131217957, 0.721705436706543, 0.7240310311317444, 0.7279070019721985, 0.7229974269866943, 0.750904381275177, 0.7343669533729553, 0.7403100728988647, 0.7328165173530579, 0.750904381275177, 0.7385013103485107, 0.750129222869873, 0.7465116381645203, 0.7514212131500244, 0.7614986896514893, 0.7565891742706299, 0.7612403035163879, 0.762273907661438, 0.7666666507720947, 0.778294563293457, 0.7645995020866394, 0.7816537618637085, 0.7705426216125488, 0.7777777910232544, 0.7770025730133057, 0.7801033854484558, 0.7878552675247192, 0.7943152189254761, 0.7909560799598694, 0.7927648425102234, 0.801808774471283, 0.7987080216407776, 0.7935400605201721, 0.8064599633216858, 0.801033616065979, 0.804651141166687, 0.8051679730415344, 0.8175710439682007, 0.8103359341621399, 0.8167958855628967, 0.8155038952827454, 0.8134366869926453, 0.813178300857544, 0.8235142230987549, 0.8186046481132507, 0.8224806189537048, 0.830232560634613, 0.8294573426246643, 0.8286821842193604, 0.8279069662094116, 0.8374677300453186, 0.8426356315612793, 0.8457364439964294, 0.8379845023155212, 0.845219612121582, 0.8359172940254211, 0.8459948301315308, 0.8516795635223389, 0.8521963953971863, 0.8534883856773376, 0.855555534362793, 0.8630490899085999, 0.8671834468841553, 0.8599483370780945, 0.8617570996284485, 0.8622739315032959, 0.8583979606628418, 0.8589147329330444, 0.8682170510292053, 0.8746770024299622, 0.8746770024299622, 0.8759689927101135, 0.8746770024299622, 0.8728682398796082, 0.8850129246711731, 0.8757106065750122, 0.8715762495994568, 0.8806201815605164, 0.8883720636367798, 0.8914728760719299, 0.8875969052314758, 0.8914728760719299, 0.9002584218978882, 0.8963824510574341, 0.8878552913665771, 0.8937984704971313, 0.8919896483421326, 0.8819121718406677, 0.8999999761581421, 0.8987079858779907, 0.9069767594337463, 0.905684769153595], 'val_loss': [0.6953738927841187, 0.6944819092750549, 0.6940759420394897, 0.693584680557251, 0.6928786635398865, 0.6922694444656372, 0.6917791962623596, 0.6894550323486328, 0.6875810027122498, 0.6878433227539062, 0.6858940720558167, 0.6869279146194458, 0.683915913105011, 0.6779574751853943, 0.6783831119537354, 0.6750967502593994, 0.6721107363700867, 0.6790944933891296, 0.680988073348999, 0.676569938659668, 0.6804654002189636, 0.6934702396392822, 0.7034385204315186, 0.7028553485870361, 0.7167937159538269, 0.7244160175323486, 0.73624187707901, 0.7425284385681152, 0.7545803189277649, 0.7579034566879272, 0.7637728452682495, 0.7763233184814453, 0.7780612707138062, 0.782741904258728, 0.7936075925827026, 0.8025854825973511, 0.8111603260040283, 0.8042841553688049, 0.8208020925521851, 0.8117126226425171, 0.811846911907196, 0.8263660669326782, 0.8197861909866333, 0.8296681046485901, 0.889021635055542, 0.8525947332382202, 0.8484942317008972, 0.8495198488235474, 0.8643944263458252, 0.8633126616477966, 0.8559668660163879, 0.8826069831848145, 0.8769479393959045, 0.8755627870559692, 0.8781817555427551, 0.9074240922927856, 0.9579144716262817, 0.913729727268219, 0.9142349362373352, 0.920451283454895, 0.927311897277832, 0.9259753227233887, 0.9523676037788391, 0.9443289637565613, 0.955426037311554, 0.9647419452667236, 0.9683079123497009, 0.9652527570724487, 0.9782252311706543, 0.987724781036377, 1.0293668508529663, 1.0147336721420288, 1.0206727981567383, 1.0386829376220703, 1.0341216325759888, 1.023087501525879, 1.035902976989746, 1.0381532907485962, 1.0473600625991821, 1.071909785270691, 1.0716969966888428, 1.0763678550720215, 1.074622631072998, 1.0797244310379028, 1.0822534561157227, 1.1484442949295044, 1.1095749139785767, 1.1169123649597168, 1.134006381034851, 1.1306151151657104, 1.1555864810943604, 1.1642531156539917, 1.1765105724334717, 1.2027744054794312, 1.2385426759719849, 1.1703423261642456, 1.1785224676132202, 1.2136956453323364, 1.1991137266159058, 1.2064166069030762], 'val_accuracy': [0.4876033067703247, 0.48966941237449646, 0.49070248007774353, 0.4886363744735718, 0.48966941237449646, 0.49380165338516235, 0.49380165338516235, 0.5020661354064941, 0.5030992031097412, 0.5030992031097412, 0.5092975497245789, 0.5123966932296753, 0.5206611752510071, 0.5557851195335388, 0.5599173307418823, 0.5785123705863953, 0.5981404781341553, 0.5795454382896423, 0.586776852607727, 0.6043388247489929, 0.6115702390670776, 0.5971074104309082, 0.5971074104309082, 0.6105371713638306, 0.6033057570457458, 0.6064049601554871, 0.6002066135406494, 0.6043388247489929, 0.5971074104309082, 0.6012396812438965, 0.6095041036605835, 0.5960744023323059, 0.60537189245224, 0.5960744023323059, 0.5909090638160706, 0.5950413346290588, 0.6022727489471436, 0.6126033067703247, 0.586776852607727, 0.6105371713638306, 0.6084710955619812, 0.5940082669258118, 0.6105371713638306, 0.6064049601554871, 0.5888429880142212, 0.5960744023323059, 0.6012396812438965, 0.6105371713638306, 0.6002066135406494, 0.6043388247489929, 0.6064049601554871, 0.6012396812438965, 0.6064049601554871, 0.6126033067703247, 0.6064049601554871, 0.5940082669258118, 0.586776852607727, 0.5981404781341553, 0.60537189245224, 0.60537189245224, 0.6084710955619812, 0.60537189245224, 0.6002066135406494, 0.6022727489471436, 0.6043388247489929, 0.6012396812438965, 0.6002066135406494, 0.60537189245224, 0.6095041036605835, 0.6022727489471436, 0.5847107172012329, 0.6012396812438965, 0.6002066135406494, 0.5898760557174683, 0.5940082669258118, 0.6012396812438965, 0.6033057570457458, 0.6064049601554871, 0.6022727489471436, 0.6002066135406494, 0.6033057570457458, 0.5981404781341553, 0.6064049601554871, 0.6043388247489929, 0.5971074104309082, 0.5919421315193176, 0.5991735458374023, 0.6033057570457458, 0.6043388247489929, 0.6064049601554871, 0.6022727489471436, 0.6064049601554871, 0.5940082669258118, 0.5971074104309082, 0.5878099203109741, 0.6033057570457458, 0.60537189245224, 0.5960744023323059, 0.5940082669258118, 0.5991735458374023]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.3626 - accuracy: 0.8464"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 52ms/step - loss: 0.3626 - accuracy: 0.8464 - val_loss: 0.7091 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3496 - accuracy: 0.8438 - val_loss: 0.7087 - val_accuracy: 0.4860\n","Epoch 3/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3373 - accuracy: 0.8438 - val_loss: 0.7051 - val_accuracy: 0.4860\n","Epoch 4/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3170 - accuracy: 0.8548 - val_loss: 0.6986 - val_accuracy: 0.4860\n","Epoch 5/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3161 - accuracy: 0.8656 - val_loss: 0.6992 - val_accuracy: 0.4860\n","Epoch 6/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3057 - accuracy: 0.8688 - val_loss: 0.6919 - val_accuracy: 0.4860\n","Epoch 7/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3039 - accuracy: 0.8664 - val_loss: 0.6852 - val_accuracy: 0.4946\n","Epoch 8/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2904 - accuracy: 0.8683 - val_loss: 0.6855 - val_accuracy: 0.4957\n","Epoch 9/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2903 - accuracy: 0.8710 - val_loss: 0.6784 - val_accuracy: 0.5022\n","Epoch 10/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.2855 - accuracy: 0.8755 - val_loss: 0.6683 - val_accuracy: 0.5194\n","Epoch 11/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2800 - accuracy: 0.8769 - val_loss: 0.6650 - val_accuracy: 0.5226\n","Epoch 12/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2851 - accuracy: 0.8758 - val_loss: 0.6535 - val_accuracy: 0.5517\n","Epoch 13/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2761 - accuracy: 0.8807 - val_loss: 0.6423 - val_accuracy: 0.5733\n","Epoch 14/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2690 - accuracy: 0.8839 - val_loss: 0.6419 - val_accuracy: 0.5657\n","Epoch 15/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2680 - accuracy: 0.8912 - val_loss: 0.6231 - val_accuracy: 0.6078\n","Epoch 16/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2724 - accuracy: 0.8825 - val_loss: 0.6322 - val_accuracy: 0.5938\n","Epoch 17/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2631 - accuracy: 0.8842 - val_loss: 0.6104 - val_accuracy: 0.6282\n","Epoch 18/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.2611 - accuracy: 0.8855 - val_loss: 0.5969 - val_accuracy: 0.6509\n","Epoch 19/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.2581 - accuracy: 0.8912 - val_loss: 0.5783 - val_accuracy: 0.6832\n","Epoch 20/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2511 - accuracy: 0.8914 - val_loss: 0.5942 - val_accuracy: 0.6746\n","Epoch 21/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.2449 - accuracy: 0.9003 - val_loss: 0.5703 - val_accuracy: 0.7069\n","Epoch 22/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.2484 - accuracy: 0.8998 - val_loss: 0.5615 - val_accuracy: 0.7241\n","Epoch 23/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2358 - accuracy: 0.9038 - val_loss: 0.6457 - val_accuracy: 0.6703\n","Epoch 24/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2539 - accuracy: 0.8879 - val_loss: 0.6427 - val_accuracy: 0.6875\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2360 - accuracy: 0.9057 - val_loss: 0.6102 - val_accuracy: 0.7101\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2328 - accuracy: 0.9027 - val_loss: 0.6317 - val_accuracy: 0.7188\n","Epoch 27/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2276 - accuracy: 0.9108 - val_loss: 0.6239 - val_accuracy: 0.7252\n","Epoch 28/100\n","29/29 [==============================] - 1s 40ms/step - loss: 0.2174 - accuracy: 0.9084 - val_loss: 0.6390 - val_accuracy: 0.7306\n","Epoch 29/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2312 - accuracy: 0.9060 - val_loss: 0.6564 - val_accuracy: 0.7274\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2171 - accuracy: 0.9133 - val_loss: 0.6897 - val_accuracy: 0.7144\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2130 - accuracy: 0.9154 - val_loss: 0.7026 - val_accuracy: 0.7069\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2044 - accuracy: 0.9173 - val_loss: 0.7100 - val_accuracy: 0.7295\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2145 - accuracy: 0.9100 - val_loss: 0.6972 - val_accuracy: 0.7220\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2069 - accuracy: 0.9149 - val_loss: 0.7149 - val_accuracy: 0.7284\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2147 - accuracy: 0.9138 - val_loss: 0.7175 - val_accuracy: 0.7284\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2106 - accuracy: 0.9100 - val_loss: 0.7197 - val_accuracy: 0.7220\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2043 - accuracy: 0.9154 - val_loss: 0.7460 - val_accuracy: 0.7177\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1996 - accuracy: 0.9146 - val_loss: 0.7651 - val_accuracy: 0.7166\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2024 - accuracy: 0.9170 - val_loss: 0.8107 - val_accuracy: 0.7026\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2109 - accuracy: 0.9127 - val_loss: 0.7587 - val_accuracy: 0.7209\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1886 - accuracy: 0.9251 - val_loss: 0.7464 - val_accuracy: 0.7284\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1779 - accuracy: 0.9302 - val_loss: 0.7762 - val_accuracy: 0.7198\n","Epoch 43/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1857 - accuracy: 0.9224 - val_loss: 0.7706 - val_accuracy: 0.7231\n","Epoch 44/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1743 - accuracy: 0.9310 - val_loss: 0.8008 - val_accuracy: 0.7091\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1778 - accuracy: 0.9273 - val_loss: 0.8183 - val_accuracy: 0.7091\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1789 - accuracy: 0.9278 - val_loss: 0.7913 - val_accuracy: 0.7134\n","Epoch 47/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1961 - accuracy: 0.9143 - val_loss: 0.8008 - val_accuracy: 0.7188\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1722 - accuracy: 0.9348 - val_loss: 0.8681 - val_accuracy: 0.7134\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1740 - accuracy: 0.9291 - val_loss: 0.7969 - val_accuracy: 0.7166\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1691 - accuracy: 0.9313 - val_loss: 0.8076 - val_accuracy: 0.7231\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1630 - accuracy: 0.9329 - val_loss: 0.8161 - val_accuracy: 0.7123\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1610 - accuracy: 0.9370 - val_loss: 0.8087 - val_accuracy: 0.7080\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1611 - accuracy: 0.9362 - val_loss: 0.8447 - val_accuracy: 0.7112\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1588 - accuracy: 0.9362 - val_loss: 0.8540 - val_accuracy: 0.7123\n","Epoch 55/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1567 - accuracy: 0.9372 - val_loss: 0.8370 - val_accuracy: 0.7144\n","Epoch 56/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1602 - accuracy: 0.9383 - val_loss: 0.8870 - val_accuracy: 0.7123\n","Epoch 57/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1437 - accuracy: 0.9459 - val_loss: 0.8476 - val_accuracy: 0.7134\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1404 - accuracy: 0.9445 - val_loss: 0.8627 - val_accuracy: 0.7155\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1425 - accuracy: 0.9475 - val_loss: 0.8661 - val_accuracy: 0.7177\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1450 - accuracy: 0.9450 - val_loss: 0.8803 - val_accuracy: 0.7080\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1403 - accuracy: 0.9450 - val_loss: 0.8748 - val_accuracy: 0.7198\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1401 - accuracy: 0.9459 - val_loss: 0.8822 - val_accuracy: 0.7058\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1377 - accuracy: 0.9469 - val_loss: 0.9057 - val_accuracy: 0.7015\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1417 - accuracy: 0.9480 - val_loss: 0.9031 - val_accuracy: 0.7123\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1388 - accuracy: 0.9456 - val_loss: 0.8867 - val_accuracy: 0.7144\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1290 - accuracy: 0.9488 - val_loss: 0.9338 - val_accuracy: 0.7101\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1368 - accuracy: 0.9485 - val_loss: 0.9023 - val_accuracy: 0.7091\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1254 - accuracy: 0.9531 - val_loss: 0.9069 - val_accuracy: 0.7080\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1212 - accuracy: 0.9564 - val_loss: 0.9181 - val_accuracy: 0.7091\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1259 - accuracy: 0.9523 - val_loss: 1.0692 - val_accuracy: 0.6907\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1321 - accuracy: 0.9485 - val_loss: 0.9137 - val_accuracy: 0.7144\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1233 - accuracy: 0.9561 - val_loss: 0.9370 - val_accuracy: 0.7198\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1097 - accuracy: 0.9623 - val_loss: 0.9530 - val_accuracy: 0.7069\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1164 - accuracy: 0.9542 - val_loss: 0.9912 - val_accuracy: 0.6972\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1332 - accuracy: 0.9477 - val_loss: 0.9517 - val_accuracy: 0.7069\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1138 - accuracy: 0.9569 - val_loss: 0.9411 - val_accuracy: 0.7101\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1131 - accuracy: 0.9580 - val_loss: 0.9517 - val_accuracy: 0.7134\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1025 - accuracy: 0.9663 - val_loss: 0.9513 - val_accuracy: 0.7177\n","Epoch 79/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1123 - accuracy: 0.9588 - val_loss: 0.9702 - val_accuracy: 0.7123\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1066 - accuracy: 0.9615 - val_loss: 0.9799 - val_accuracy: 0.7112\n","Epoch 81/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1037 - accuracy: 0.9647 - val_loss: 1.0050 - val_accuracy: 0.7047\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1162 - accuracy: 0.9537 - val_loss: 1.0020 - val_accuracy: 0.7091\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1093 - accuracy: 0.9588 - val_loss: 0.9960 - val_accuracy: 0.7069\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1173 - accuracy: 0.9547 - val_loss: 1.0462 - val_accuracy: 0.7069\n","Epoch 85/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1078 - accuracy: 0.9636 - val_loss: 0.9994 - val_accuracy: 0.7112\n","Epoch 86/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0954 - accuracy: 0.9677 - val_loss: 1.0327 - val_accuracy: 0.7080\n","Epoch 87/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1121 - accuracy: 0.9607 - val_loss: 1.0156 - val_accuracy: 0.7047\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1056 - accuracy: 0.9593 - val_loss: 1.0109 - val_accuracy: 0.7080\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0956 - accuracy: 0.9669 - val_loss: 1.0647 - val_accuracy: 0.7058\n","Epoch 90/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0953 - accuracy: 0.9679 - val_loss: 1.0203 - val_accuracy: 0.7058\n","Epoch 91/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0904 - accuracy: 0.9679 - val_loss: 1.0423 - val_accuracy: 0.7080\n","Epoch 92/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0859 - accuracy: 0.9723 - val_loss: 1.0484 - val_accuracy: 0.7004\n","Epoch 93/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0897 - accuracy: 0.9679 - val_loss: 1.0456 - val_accuracy: 0.7091\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0785 - accuracy: 0.9744 - val_loss: 1.0462 - val_accuracy: 0.7134\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0896 - accuracy: 0.9658 - val_loss: 1.0575 - val_accuracy: 0.7112\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1100 - accuracy: 0.9558 - val_loss: 1.0903 - val_accuracy: 0.7177\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0851 - accuracy: 0.9706 - val_loss: 1.1072 - val_accuracy: 0.7091\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0825 - accuracy: 0.9714 - val_loss: 1.0711 - val_accuracy: 0.7091\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0830 - accuracy: 0.9690 - val_loss: 1.0862 - val_accuracy: 0.7101\n","Epoch 100/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0817 - accuracy: 0.9701 - val_loss: 1.0880 - val_accuracy: 0.7112\n","{'loss': [0.3626093566417694, 0.3496387302875519, 0.3372668921947479, 0.3170401155948639, 0.31608861684799194, 0.3057490587234497, 0.3039362132549286, 0.2903786599636078, 0.29025083780288696, 0.28548577427864075, 0.28004762530326843, 0.285141259431839, 0.27614519000053406, 0.26896676421165466, 0.26796454191207886, 0.2724030613899231, 0.263092577457428, 0.26114726066589355, 0.2581438720226288, 0.2510750889778137, 0.24485932290554047, 0.2484274059534073, 0.23577894270420074, 0.25394612550735474, 0.23604978621006012, 0.23283052444458008, 0.22755764424800873, 0.21743136644363403, 0.23115132749080658, 0.21708902716636658, 0.21302881836891174, 0.20444999635219574, 0.21446937322616577, 0.20693974196910858, 0.21467003226280212, 0.21058453619480133, 0.20428818464279175, 0.19959433376789093, 0.2023686021566391, 0.21091511845588684, 0.18859481811523438, 0.17792819440364838, 0.18569137156009674, 0.1743423044681549, 0.17780497670173645, 0.17885929346084595, 0.19610358774662018, 0.17223519086837769, 0.17402739822864532, 0.16909994184970856, 0.16297201812267303, 0.16096985340118408, 0.16113820672035217, 0.15881529450416565, 0.15672732889652252, 0.16017892956733704, 0.14372606575489044, 0.14039503037929535, 0.14249923825263977, 0.14497245848178864, 0.14029736816883087, 0.14011718332767487, 0.1377488672733307, 0.14165925979614258, 0.13884231448173523, 0.12895594537258148, 0.1368429958820343, 0.1253952533006668, 0.12122108787298203, 0.12592092156410217, 0.1321406364440918, 0.12327592074871063, 0.10970368981361389, 0.11640907824039459, 0.1331806182861328, 0.1137646809220314, 0.11314604431390762, 0.10253114253282547, 0.11226363480091095, 0.10662326961755753, 0.10370434820652008, 0.11624479293823242, 0.10929602384567261, 0.1173122376203537, 0.10778053849935532, 0.0954432561993599, 0.11213761568069458, 0.1056361123919487, 0.09557858109474182, 0.09533762186765671, 0.09040983766317368, 0.08585841953754425, 0.08974352478981018, 0.07849516719579697, 0.08959095180034637, 0.11000185459852219, 0.08510611206293106, 0.08251131325960159, 0.08304283767938614, 0.0817030742764473], 'accuracy': [0.8464439511299133, 0.84375, 0.84375, 0.8547952771186829, 0.865571141242981, 0.868803858757019, 0.8663793206214905, 0.8682650923728943, 0.8709590435028076, 0.8755387663841248, 0.8768857717514038, 0.8758081793785095, 0.8806573152542114, 0.8838900923728943, 0.8911637663841248, 0.8825430870056152, 0.884159505367279, 0.8855064511299133, 0.8911637663841248, 0.8914331793785095, 0.9003232717514038, 0.899784505367279, 0.9038254022598267, 0.8879310488700867, 0.9057112336158752, 0.9027478694915771, 0.9108297228813171, 0.9084051847457886, 0.9059805870056152, 0.9132543206214905, 0.915409505367279, 0.9172952771186829, 0.9100215435028076, 0.9148706793785095, 0.9137930870056152, 0.9100215435028076, 0.915409505367279, 0.9146012663841248, 0.9170258641242981, 0.912715494632721, 0.9251077771186829, 0.9302262663841248, 0.9224137663841248, 0.931034505367279, 0.9272629022598267, 0.9278017282485962, 0.9143319129943848, 0.9348060488700867, 0.9291487336158752, 0.931303858757019, 0.9329202771186829, 0.9369612336158752, 0.936152994632721, 0.936152994632721, 0.9372305870056152, 0.9383081793785095, 0.9458512663841248, 0.9445043206214905, 0.9474676847457886, 0.9450430870056152, 0.9450430870056152, 0.9458512663841248, 0.946928858757019, 0.9480064511299133, 0.9455819129943848, 0.9488146305084229, 0.9485452771186829, 0.953125, 0.9563577771186829, 0.9523168206214905, 0.9485452771186829, 0.9560883641242981, 0.962284505367279, 0.9542025923728943, 0.9477370977401733, 0.9568965435028076, 0.9579741358757019, 0.9663254022598267, 0.9587823152542114, 0.9614762663841248, 0.9647090435028076, 0.9536637663841248, 0.9587823152542114, 0.954741358757019, 0.9636314511299133, 0.9676724076271057, 0.9606680870056152, 0.959321141242981, 0.9668642282485962, 0.9679418206214905, 0.9679418206214905, 0.9722521305084229, 0.9679418206214905, 0.9744073152542114, 0.9657866358757019, 0.9558189511299133, 0.9706357717514038, 0.9714439511299133, 0.9690194129943848, 0.970097005367279], 'val_loss': [0.7090849876403809, 0.7087070941925049, 0.7050559520721436, 0.6985670924186707, 0.6991695761680603, 0.6919274926185608, 0.6851757168769836, 0.6855124831199646, 0.6783801913261414, 0.6683313846588135, 0.6649544835090637, 0.653473973274231, 0.6423029899597168, 0.6418769955635071, 0.6230879426002502, 0.6321513652801514, 0.6103870868682861, 0.5969005227088928, 0.5783097743988037, 0.5941709280014038, 0.5703270435333252, 0.5614822506904602, 0.6457340121269226, 0.6427369713783264, 0.6102360486984253, 0.6317018866539001, 0.6239129304885864, 0.6389644145965576, 0.6563876867294312, 0.689727246761322, 0.702638566493988, 0.7099716067314148, 0.6971539258956909, 0.7149173021316528, 0.7175053358078003, 0.7196556329727173, 0.7460184693336487, 0.7650856375694275, 0.8107118010520935, 0.7586565613746643, 0.7464121580123901, 0.7761657238006592, 0.7706340551376343, 0.8007935881614685, 0.8182584643363953, 0.7913134098052979, 0.8008319139480591, 0.8681431412696838, 0.79688960313797, 0.8076246976852417, 0.8160873055458069, 0.8086848855018616, 0.8446601629257202, 0.8539856672286987, 0.8370401263237, 0.8870132565498352, 0.8476253151893616, 0.8626576066017151, 0.8661156892776489, 0.8802803754806519, 0.874770998954773, 0.8822363615036011, 0.9057287573814392, 0.903099000453949, 0.8867170214653015, 0.9337983727455139, 0.9023396968841553, 0.9069133996963501, 0.918134331703186, 1.0691630840301514, 0.9137097001075745, 0.936954915523529, 0.9529628753662109, 0.9912307858467102, 0.9517356753349304, 0.9410995841026306, 0.9517320394515991, 0.9512984156608582, 0.9702404141426086, 0.9798598289489746, 1.0050060749053955, 1.0019595623016357, 0.9960066676139832, 1.0462279319763184, 0.99936842918396, 1.0326664447784424, 1.0155714750289917, 1.0109156370162964, 1.0647320747375488, 1.0202586650848389, 1.0422512292861938, 1.048412561416626, 1.0455821752548218, 1.0461758375167847, 1.0574861764907837, 1.0903444290161133, 1.1072344779968262, 1.0710721015930176, 1.0861809253692627, 1.0880415439605713], 'val_accuracy': [0.48491379618644714, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.49461206793785095, 0.49568966031074524, 0.5021551847457886, 0.5193965435028076, 0.5226293206214905, 0.5517241358757019, 0.5732758641242981, 0.5657327771186829, 0.607758641242981, 0.59375, 0.6282327771186829, 0.6508620977401733, 0.6831896305084229, 0.6745689511299133, 0.7068965435028076, 0.7241379022598267, 0.670258641242981, 0.6875, 0.7101293206214905, 0.71875, 0.725215494632721, 0.7306034564971924, 0.7273706793785095, 0.7144396305084229, 0.7068965435028076, 0.7295258641242981, 0.7219827771186829, 0.7284482717514038, 0.7284482717514038, 0.7219827771186829, 0.7176724076271057, 0.7165948152542114, 0.7025862336158752, 0.7209051847457886, 0.7284482717514038, 0.7198275923728943, 0.7230603694915771, 0.7090517282485962, 0.7090517282485962, 0.7133620977401733, 0.71875, 0.7133620977401733, 0.7165948152542114, 0.7230603694915771, 0.712284505367279, 0.7079741358757019, 0.7112069129943848, 0.712284505367279, 0.7144396305084229, 0.712284505367279, 0.7133620977401733, 0.7155172228813171, 0.7176724076271057, 0.7079741358757019, 0.7198275923728943, 0.7058189511299133, 0.701508641242981, 0.712284505367279, 0.7144396305084229, 0.7101293206214905, 0.7090517282485962, 0.7079741358757019, 0.7090517282485962, 0.6907327771186829, 0.7144396305084229, 0.7198275923728943, 0.7068965435028076, 0.6971982717514038, 0.7068965435028076, 0.7101293206214905, 0.7133620977401733, 0.7176724076271057, 0.712284505367279, 0.7112069129943848, 0.704741358757019, 0.7090517282485962, 0.7068965435028076, 0.7068965435028076, 0.7112069129943848, 0.7079741358757019, 0.704741358757019, 0.7079741358757019, 0.7058189511299133, 0.7058189511299133, 0.7079741358757019, 0.7004310488700867, 0.7090517282485962, 0.7133620977401733, 0.7112069129943848, 0.7176724076271057, 0.7090517282485962, 0.7090517282485962, 0.7101293206214905, 0.7112069129943848]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 7s 56ms/step - loss: 0.3573 - accuracy: 0.8413 - val_loss: 0.7039 - val_accuracy: 0.4977\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3392 - accuracy: 0.8424 - val_loss: 0.7015 - val_accuracy: 0.4989\n","Epoch 3/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3134 - accuracy: 0.8681 - val_loss: 0.6982 - val_accuracy: 0.5000\n","Epoch 4/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3124 - accuracy: 0.8670 - val_loss: 0.6973 - val_accuracy: 0.5011\n","Epoch 5/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3081 - accuracy: 0.8650 - val_loss: 0.6890 - val_accuracy: 0.5045\n","Epoch 6/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.3035 - accuracy: 0.8639 - val_loss: 0.6855 - val_accuracy: 0.5079\n","Epoch 7/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.3021 - accuracy: 0.8645 - val_loss: 0.6794 - val_accuracy: 0.5147\n","Epoch 8/100\n","28/28 [==============================] - 1s 41ms/step - loss: 0.2926 - accuracy: 0.8744 - val_loss: 0.6679 - val_accuracy: 0.5294\n","Epoch 9/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2965 - accuracy: 0.8724 - val_loss: 0.6760 - val_accuracy: 0.5158\n","Epoch 10/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2905 - accuracy: 0.8690 - val_loss: 0.6590 - val_accuracy: 0.5385\n","Epoch 11/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2884 - accuracy: 0.8766 - val_loss: 0.6637 - val_accuracy: 0.5339\n","Epoch 12/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2827 - accuracy: 0.8789 - val_loss: 0.6495 - val_accuracy: 0.5554\n","Epoch 13/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.2847 - accuracy: 0.8772 - val_loss: 0.6489 - val_accuracy: 0.5577\n","Epoch 14/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2716 - accuracy: 0.8843 - val_loss: 0.6245 - val_accuracy: 0.5984\n","Epoch 15/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2636 - accuracy: 0.8905 - val_loss: 0.6190 - val_accuracy: 0.6063\n","Epoch 16/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2624 - accuracy: 0.8933 - val_loss: 0.6017 - val_accuracy: 0.6357\n","Epoch 17/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2672 - accuracy: 0.8854 - val_loss: 0.5869 - val_accuracy: 0.6629\n","Epoch 18/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2540 - accuracy: 0.8947 - val_loss: 0.5798 - val_accuracy: 0.6606\n","Epoch 19/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2541 - accuracy: 0.8947 - val_loss: 0.5950 - val_accuracy: 0.6516\n","Epoch 20/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2463 - accuracy: 0.8970 - val_loss: 0.5584 - val_accuracy: 0.6934\n","Epoch 21/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2472 - accuracy: 0.8933 - val_loss: 0.5657 - val_accuracy: 0.6923\n","Epoch 22/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2491 - accuracy: 0.8967 - val_loss: 0.5512 - val_accuracy: 0.7070\n","Epoch 23/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2383 - accuracy: 0.9049 - val_loss: 0.5725 - val_accuracy: 0.7002\n","Epoch 24/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2420 - accuracy: 0.9035 - val_loss: 0.5859 - val_accuracy: 0.7093\n","Epoch 25/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2359 - accuracy: 0.9072 - val_loss: 0.5787 - val_accuracy: 0.7262\n","Epoch 26/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2355 - accuracy: 0.9021 - val_loss: 0.6042 - val_accuracy: 0.7104\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2267 - accuracy: 0.9097 - val_loss: 0.6043 - val_accuracy: 0.7251\n","Epoch 28/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.2244 - accuracy: 0.9106 - val_loss: 0.6199 - val_accuracy: 0.7387\n","Epoch 29/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2155 - accuracy: 0.9179 - val_loss: 0.6414 - val_accuracy: 0.7342\n","Epoch 30/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.2210 - accuracy: 0.9095 - val_loss: 0.6643 - val_accuracy: 0.7455\n","Epoch 31/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2181 - accuracy: 0.9086 - val_loss: 0.6762 - val_accuracy: 0.7330\n","Epoch 32/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2221 - accuracy: 0.9038 - val_loss: 0.6809 - val_accuracy: 0.7217\n","Epoch 33/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2242 - accuracy: 0.9061 - val_loss: 0.7093 - val_accuracy: 0.7410\n","Epoch 34/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2112 - accuracy: 0.9213 - val_loss: 0.6942 - val_accuracy: 0.7251\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2076 - accuracy: 0.9188 - val_loss: 0.7270 - val_accuracy: 0.7364\n","Epoch 36/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2044 - accuracy: 0.9191 - val_loss: 0.7123 - val_accuracy: 0.7319\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2035 - accuracy: 0.9165 - val_loss: 0.7349 - val_accuracy: 0.7115\n","Epoch 38/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1984 - accuracy: 0.9261 - val_loss: 0.7544 - val_accuracy: 0.7432\n","Epoch 39/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1989 - accuracy: 0.9244 - val_loss: 0.7908 - val_accuracy: 0.7240\n","Epoch 40/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2111 - accuracy: 0.9160 - val_loss: 0.7467 - val_accuracy: 0.7330\n","Epoch 41/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1962 - accuracy: 0.9233 - val_loss: 0.7379 - val_accuracy: 0.7342\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1881 - accuracy: 0.9264 - val_loss: 0.7563 - val_accuracy: 0.7421\n","Epoch 43/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1802 - accuracy: 0.9290 - val_loss: 0.7750 - val_accuracy: 0.7330\n","Epoch 44/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1823 - accuracy: 0.9290 - val_loss: 0.7891 - val_accuracy: 0.7195\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1858 - accuracy: 0.9247 - val_loss: 0.7617 - val_accuracy: 0.7251\n","Epoch 46/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1761 - accuracy: 0.9324 - val_loss: 0.7873 - val_accuracy: 0.7161\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1773 - accuracy: 0.9307 - val_loss: 0.8070 - val_accuracy: 0.7342\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1667 - accuracy: 0.9400 - val_loss: 0.7893 - val_accuracy: 0.7240\n","Epoch 49/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1679 - accuracy: 0.9358 - val_loss: 0.8174 - val_accuracy: 0.7149\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1712 - accuracy: 0.9324 - val_loss: 0.8433 - val_accuracy: 0.7364\n","Epoch 51/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1591 - accuracy: 0.9392 - val_loss: 0.8330 - val_accuracy: 0.7410\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1521 - accuracy: 0.9414 - val_loss: 0.8331 - val_accuracy: 0.7296\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1580 - accuracy: 0.9375 - val_loss: 0.8331 - val_accuracy: 0.7217\n","Epoch 54/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1572 - accuracy: 0.9423 - val_loss: 0.8530 - val_accuracy: 0.7387\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1601 - accuracy: 0.9409 - val_loss: 0.8411 - val_accuracy: 0.7262\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1530 - accuracy: 0.9397 - val_loss: 0.8591 - val_accuracy: 0.7376\n","Epoch 57/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1510 - accuracy: 0.9383 - val_loss: 0.8710 - val_accuracy: 0.7014\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1523 - accuracy: 0.9454 - val_loss: 0.8609 - val_accuracy: 0.7285\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1521 - accuracy: 0.9414 - val_loss: 0.8611 - val_accuracy: 0.7240\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1388 - accuracy: 0.9485 - val_loss: 0.8673 - val_accuracy: 0.7353\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1577 - accuracy: 0.9380 - val_loss: 0.9029 - val_accuracy: 0.6946\n","Epoch 62/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.1632 - accuracy: 0.9369 - val_loss: 0.8757 - val_accuracy: 0.7183\n","Epoch 63/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1268 - accuracy: 0.9542 - val_loss: 0.8974 - val_accuracy: 0.7149\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1380 - accuracy: 0.9502 - val_loss: 0.8978 - val_accuracy: 0.7262\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1362 - accuracy: 0.9474 - val_loss: 0.9049 - val_accuracy: 0.7308\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1353 - accuracy: 0.9485 - val_loss: 0.9251 - val_accuracy: 0.7274\n","Epoch 67/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1281 - accuracy: 0.9542 - val_loss: 0.9549 - val_accuracy: 0.7330\n","Epoch 68/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1309 - accuracy: 0.9519 - val_loss: 0.9608 - val_accuracy: 0.7319\n","Epoch 69/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.1289 - accuracy: 0.9485 - val_loss: 0.9314 - val_accuracy: 0.7330\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1317 - accuracy: 0.9491 - val_loss: 0.9424 - val_accuracy: 0.7229\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1187 - accuracy: 0.9559 - val_loss: 0.9518 - val_accuracy: 0.7127\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1122 - accuracy: 0.9601 - val_loss: 0.9591 - val_accuracy: 0.7262\n","Epoch 73/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1276 - accuracy: 0.9471 - val_loss: 0.9648 - val_accuracy: 0.7308\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1222 - accuracy: 0.9522 - val_loss: 0.9480 - val_accuracy: 0.7229\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1124 - accuracy: 0.9601 - val_loss: 0.9893 - val_accuracy: 0.7251\n","Epoch 76/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1207 - accuracy: 0.9542 - val_loss: 0.9785 - val_accuracy: 0.7296\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1181 - accuracy: 0.9573 - val_loss: 1.0016 - val_accuracy: 0.7353\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1043 - accuracy: 0.9629 - val_loss: 1.0007 - val_accuracy: 0.7353\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1040 - accuracy: 0.9635 - val_loss: 1.0616 - val_accuracy: 0.6912\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1235 - accuracy: 0.9516 - val_loss: 1.0283 - val_accuracy: 0.7251\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1044 - accuracy: 0.9632 - val_loss: 1.0308 - val_accuracy: 0.7308\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1020 - accuracy: 0.9658 - val_loss: 1.0148 - val_accuracy: 0.7274\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0917 - accuracy: 0.9683 - val_loss: 1.0465 - val_accuracy: 0.7251\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0920 - accuracy: 0.9711 - val_loss: 1.0559 - val_accuracy: 0.7206\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1010 - accuracy: 0.9626 - val_loss: 1.0565 - val_accuracy: 0.7183\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0875 - accuracy: 0.9689 - val_loss: 1.1132 - val_accuracy: 0.7206\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1011 - accuracy: 0.9635 - val_loss: 1.1025 - val_accuracy: 0.7172\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0920 - accuracy: 0.9677 - val_loss: 1.0949 - val_accuracy: 0.7183\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0966 - accuracy: 0.9638 - val_loss: 1.0927 - val_accuracy: 0.7285\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0886 - accuracy: 0.9706 - val_loss: 1.0777 - val_accuracy: 0.7285\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0835 - accuracy: 0.9709 - val_loss: 1.0915 - val_accuracy: 0.7240\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0980 - accuracy: 0.9626 - val_loss: 1.1401 - val_accuracy: 0.7036\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0879 - accuracy: 0.9731 - val_loss: 1.1091 - val_accuracy: 0.7115\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0931 - accuracy: 0.9643 - val_loss: 1.1246 - val_accuracy: 0.7183\n","Epoch 95/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0876 - accuracy: 0.9689 - val_loss: 1.0848 - val_accuracy: 0.7353\n","Epoch 96/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0856 - accuracy: 0.9686 - val_loss: 1.1233 - val_accuracy: 0.7104\n","Epoch 97/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0935 - accuracy: 0.9677 - val_loss: 1.1187 - val_accuracy: 0.7296\n","Epoch 98/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0896 - accuracy: 0.9677 - val_loss: 1.1259 - val_accuracy: 0.7183\n","Epoch 99/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0898 - accuracy: 0.9643 - val_loss: 1.1496 - val_accuracy: 0.7183\n","Epoch 100/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0724 - accuracy: 0.9788 - val_loss: 1.1281 - val_accuracy: 0.7240\n","{'loss': [0.35730981826782227, 0.33918002247810364, 0.3133801221847534, 0.3124353289604187, 0.3080500066280365, 0.30351465940475464, 0.30205169320106506, 0.292601078748703, 0.29652655124664307, 0.2905355989933014, 0.2884230613708496, 0.2827214300632477, 0.28468185663223267, 0.2715955078601837, 0.2635880708694458, 0.26237794756889343, 0.2671898305416107, 0.25404807925224304, 0.254141628742218, 0.24634818732738495, 0.24722133576869965, 0.24913637340068817, 0.23834101855754852, 0.24201546609401703, 0.23587697744369507, 0.23547179996967316, 0.2267305850982666, 0.22437770664691925, 0.2155321091413498, 0.2210361808538437, 0.21813614666461945, 0.22211192548274994, 0.22421744465827942, 0.2112474888563156, 0.20761887729167938, 0.20435978472232819, 0.20345571637153625, 0.19836871325969696, 0.1988731473684311, 0.2111114114522934, 0.19618776440620422, 0.18812501430511475, 0.1802053302526474, 0.1822914481163025, 0.18576911091804504, 0.17614704370498657, 0.17733627557754517, 0.16668818891048431, 0.16785462200641632, 0.1712033748626709, 0.1590883433818817, 0.15210644900798798, 0.157985657453537, 0.15719851851463318, 0.1601087898015976, 0.15302947163581848, 0.15097633004188538, 0.1523360311985016, 0.15205490589141846, 0.13876530528068542, 0.15773113071918488, 0.16324570775032043, 0.12678232789039612, 0.13797585666179657, 0.1361626833677292, 0.13530747592449188, 0.12805019319057465, 0.13094918429851532, 0.12894608080387115, 0.13168081641197205, 0.11865466833114624, 0.1121557205915451, 0.12759920954704285, 0.12221167236566544, 0.11235303431749344, 0.12069206684827805, 0.11812661588191986, 0.1042962297797203, 0.10404161363840103, 0.12349499017000198, 0.10439828783273697, 0.10201043635606766, 0.09168059378862381, 0.09195785969495773, 0.1010226160287857, 0.08747068792581558, 0.10105351358652115, 0.09198492765426636, 0.09663466364145279, 0.08856269717216492, 0.08345415443181992, 0.09799851477146149, 0.08794532716274261, 0.09306775778532028, 0.08761108666658401, 0.08564890921115875, 0.09347038716077805, 0.08964692801237106, 0.08975589275360107, 0.07237043976783752], 'accuracy': [0.8412563800811768, 0.8423882126808167, 0.8681380748748779, 0.867006242275238, 0.8650254607200623, 0.8638936281204224, 0.8644595146179199, 0.8743633031845093, 0.8723825812339783, 0.868986964225769, 0.8766270279884338, 0.8788907527923584, 0.8771929740905762, 0.8842670917510986, 0.8904923796653748, 0.8933219909667969, 0.8853989839553833, 0.8947368264198303, 0.8947368264198303, 0.8970005512237549, 0.8933219909667969, 0.8967176079750061, 0.9049236178398132, 0.9035087823867798, 0.9071873426437378, 0.9020939469337463, 0.9097340106964111, 0.9105829000473022, 0.9179400205612183, 0.9094510674476624, 0.9086021780967712, 0.9037917256355286, 0.9060554504394531, 0.9213355779647827, 0.9187889099121094, 0.9190718531608582, 0.9165251851081848, 0.9261460304260254, 0.9244481921195984, 0.9159592390060425, 0.9233163595199585, 0.9264289736747742, 0.9289756417274475, 0.9289756417274475, 0.9247311949729919, 0.9323712587356567, 0.9306734800338745, 0.9400113224983215, 0.9357668161392212, 0.9323712587356567, 0.9391624331474304, 0.941426157951355, 0.9374646544456482, 0.9422750473022461, 0.9408602118492126, 0.9397283792495728, 0.9383135437965393, 0.9453876614570618, 0.941426157951355, 0.9485002756118774, 0.9380305409431458, 0.9368987083435059, 0.9541596174240112, 0.9501980543136597, 0.9473684430122375, 0.9485002756118774, 0.9541596174240112, 0.9518958926200867, 0.9485002756118774, 0.9490662217140198, 0.9558573961257935, 0.960101842880249, 0.947085440158844, 0.9521788358688354, 0.960101842880249, 0.9541596174240112, 0.9572722315788269, 0.9629315137863159, 0.9634974598884583, 0.9516128897666931, 0.9632145166397095, 0.9657611846923828, 0.9683078527450562, 0.971137523651123, 0.9626485705375671, 0.9688737988471985, 0.9634974598884583, 0.9677419066429138, 0.963780403137207, 0.9705715775489807, 0.9708545804023743, 0.9626485705375671, 0.9731183052062988, 0.9643463492393494, 0.9688737988471985, 0.9685908555984497, 0.9677419066429138, 0.9677419066429138, 0.9643463492393494, 0.9787775874137878], 'val_loss': [0.7038582563400269, 0.7015022039413452, 0.6982457041740417, 0.697299599647522, 0.6889965534210205, 0.6854619383811951, 0.6793710589408875, 0.667922854423523, 0.6760015487670898, 0.6590217351913452, 0.6637251973152161, 0.6494617462158203, 0.648902416229248, 0.6244662404060364, 0.6189548373222351, 0.6017130017280579, 0.5868716835975647, 0.5798478722572327, 0.5950055122375488, 0.5584373474121094, 0.5657459497451782, 0.551209032535553, 0.5725395083427429, 0.5859332084655762, 0.5787093043327332, 0.6042078733444214, 0.6042943596839905, 0.6199389100074768, 0.6413891315460205, 0.6643090844154358, 0.6761769652366638, 0.6809284090995789, 0.70926833152771, 0.6942216157913208, 0.727003812789917, 0.7122795581817627, 0.7349161505699158, 0.7544127702713013, 0.7908433079719543, 0.7466645836830139, 0.7378990054130554, 0.7563215494155884, 0.774963915348053, 0.7890945076942444, 0.7616795897483826, 0.7872658967971802, 0.807003378868103, 0.7892879247665405, 0.8174077868461609, 0.8433418869972229, 0.8329786062240601, 0.8331092596054077, 0.8331210017204285, 0.8530429601669312, 0.8410645127296448, 0.8591418862342834, 0.8710158467292786, 0.8609194755554199, 0.8610977530479431, 0.8672874569892883, 0.9029251933097839, 0.8756995797157288, 0.8974063396453857, 0.8978198766708374, 0.9048880338668823, 0.9251492023468018, 0.9549049735069275, 0.9608216881752014, 0.9313737750053406, 0.9424276947975159, 0.9517569541931152, 0.9590981006622314, 0.964799165725708, 0.9480275511741638, 0.9893194437026978, 0.978483259677887, 1.0015590190887451, 1.00065279006958, 1.0616401433944702, 1.0283383131027222, 1.0307718515396118, 1.0148122310638428, 1.0464528799057007, 1.0558600425720215, 1.0565071105957031, 1.1132376194000244, 1.1024696826934814, 1.0948673486709595, 1.0927077531814575, 1.077663540840149, 1.0914807319641113, 1.1400794982910156, 1.1091376543045044, 1.124597430229187, 1.0847845077514648, 1.1233106851577759, 1.118660569190979, 1.125942587852478, 1.1496477127075195, 1.1281120777130127], 'val_accuracy': [0.4977375566959381, 0.49886876344680786, 0.5, 0.5011312365531921, 0.5045248866081238, 0.5079185366630554, 0.5147058963775635, 0.529411792755127, 0.5158371329307556, 0.5384615659713745, 0.5339366793632507, 0.5554298758506775, 0.557692289352417, 0.598416268825531, 0.6063348650932312, 0.6357465982437134, 0.662895917892456, 0.6606335043907166, 0.651583731174469, 0.6934388875961304, 0.692307710647583, 0.7070135474205017, 0.7002262473106384, 0.709276020526886, 0.726244330406189, 0.7104072570800781, 0.7251130938529968, 0.7386877536773682, 0.7341628670692444, 0.7454751133918762, 0.733031690120697, 0.7217194437980652, 0.7409502267837524, 0.7251130938529968, 0.7364253401756287, 0.7319004535675049, 0.7115384340286255, 0.7432126402854919, 0.7239819169044495, 0.733031690120697, 0.7341628670692444, 0.7420814633369446, 0.733031690120697, 0.7194570302963257, 0.7251130938529968, 0.7160633206367493, 0.7341628670692444, 0.7239819169044495, 0.7149321436882019, 0.7364253401756287, 0.7409502267837524, 0.7296379804611206, 0.7217194437980652, 0.7386877536773682, 0.726244330406189, 0.7375565767288208, 0.7013574838638306, 0.7285068035125732, 0.7239819169044495, 0.7352941036224365, 0.6945701241493225, 0.7183257937431335, 0.7149321436882019, 0.726244330406189, 0.7307692170143127, 0.7273755669593811, 0.733031690120697, 0.7319004535675049, 0.733031690120697, 0.7228506803512573, 0.7126696705818176, 0.726244330406189, 0.7307692170143127, 0.7228506803512573, 0.7251130938529968, 0.7296379804611206, 0.7352941036224365, 0.7352941036224365, 0.6911764740943909, 0.7251130938529968, 0.7307692170143127, 0.7273755669593811, 0.7251130938529968, 0.720588207244873, 0.7183257937431335, 0.720588207244873, 0.7171945571899414, 0.7183257937431335, 0.7285068035125732, 0.7285068035125732, 0.7239819169044495, 0.7036198973655701, 0.7115384340286255, 0.7183257937431335, 0.7352941036224365, 0.7104072570800781, 0.7296379804611206, 0.7183257937431335, 0.7183257937431335, 0.7239819169044495]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.3646 - accuracy: 0.8411"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 54ms/step - loss: 0.3638 - accuracy: 0.8411 - val_loss: 0.7113 - val_accuracy: 0.4886\n","Epoch 2/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3683 - accuracy: 0.8357 - val_loss: 0.7051 - val_accuracy: 0.4897\n","Epoch 3/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3552 - accuracy: 0.8333 - val_loss: 0.7041 - val_accuracy: 0.4897\n","Epoch 4/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3346 - accuracy: 0.8499 - val_loss: 0.7057 - val_accuracy: 0.4897\n","Epoch 5/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3271 - accuracy: 0.8543 - val_loss: 0.7034 - val_accuracy: 0.4928\n","Epoch 6/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3265 - accuracy: 0.8545 - val_loss: 0.6956 - val_accuracy: 0.4938\n","Epoch 7/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3198 - accuracy: 0.8599 - val_loss: 0.6959 - val_accuracy: 0.4969\n","Epoch 8/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3168 - accuracy: 0.8685 - val_loss: 0.6958 - val_accuracy: 0.4969\n","Epoch 9/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3050 - accuracy: 0.8669 - val_loss: 0.6857 - val_accuracy: 0.5145\n","Epoch 10/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2999 - accuracy: 0.8729 - val_loss: 0.6850 - val_accuracy: 0.5217\n","Epoch 11/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3070 - accuracy: 0.8643 - val_loss: 0.6919 - val_accuracy: 0.5196\n","Epoch 12/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3005 - accuracy: 0.8661 - val_loss: 0.6836 - val_accuracy: 0.5289\n","Epoch 13/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2923 - accuracy: 0.8721 - val_loss: 0.6738 - val_accuracy: 0.5486\n","Epoch 14/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2921 - accuracy: 0.8693 - val_loss: 0.6520 - val_accuracy: 0.6054\n","Epoch 15/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2809 - accuracy: 0.8798 - val_loss: 0.6529 - val_accuracy: 0.5992\n","Epoch 16/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2768 - accuracy: 0.8840 - val_loss: 0.6373 - val_accuracy: 0.6467\n","Epoch 17/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2850 - accuracy: 0.8718 - val_loss: 0.6810 - val_accuracy: 0.5981\n","Epoch 18/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2692 - accuracy: 0.8840 - val_loss: 0.6821 - val_accuracy: 0.6085\n","Epoch 19/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.2686 - accuracy: 0.8863 - val_loss: 0.6659 - val_accuracy: 0.6477\n","Epoch 20/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2685 - accuracy: 0.8855 - val_loss: 0.7074 - val_accuracy: 0.6302\n","Epoch 21/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.2690 - accuracy: 0.8835 - val_loss: 0.7079 - val_accuracy: 0.6539\n","Epoch 22/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.2587 - accuracy: 0.8879 - val_loss: 0.7238 - val_accuracy: 0.6643\n","Epoch 23/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2505 - accuracy: 0.8930 - val_loss: 0.7399 - val_accuracy: 0.6767\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2528 - accuracy: 0.8920 - val_loss: 0.7852 - val_accuracy: 0.6725\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2531 - accuracy: 0.8946 - val_loss: 0.7882 - val_accuracy: 0.6746\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2549 - accuracy: 0.8899 - val_loss: 0.8311 - val_accuracy: 0.6694\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2527 - accuracy: 0.8863 - val_loss: 0.8568 - val_accuracy: 0.6725\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2472 - accuracy: 0.8941 - val_loss: 0.8700 - val_accuracy: 0.6767\n","Epoch 29/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2490 - accuracy: 0.8879 - val_loss: 0.8762 - val_accuracy: 0.6901\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2377 - accuracy: 0.9000 - val_loss: 0.8987 - val_accuracy: 0.6818\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2401 - accuracy: 0.8979 - val_loss: 0.9485 - val_accuracy: 0.6591\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2217 - accuracy: 0.9132 - val_loss: 0.9288 - val_accuracy: 0.6663\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2431 - accuracy: 0.8904 - val_loss: 0.9258 - val_accuracy: 0.6653\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2292 - accuracy: 0.9016 - val_loss: 0.9266 - val_accuracy: 0.6808\n","Epoch 35/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2266 - accuracy: 0.9062 - val_loss: 0.9591 - val_accuracy: 0.6756\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2219 - accuracy: 0.9052 - val_loss: 0.9824 - val_accuracy: 0.6674\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2203 - accuracy: 0.9041 - val_loss: 0.9553 - val_accuracy: 0.6798\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2189 - accuracy: 0.9070 - val_loss: 0.9936 - val_accuracy: 0.6663\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2284 - accuracy: 0.9036 - val_loss: 0.9797 - val_accuracy: 0.6705\n","Epoch 40/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2028 - accuracy: 0.9207 - val_loss: 0.9754 - val_accuracy: 0.6715\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1993 - accuracy: 0.9194 - val_loss: 0.9961 - val_accuracy: 0.6705\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2016 - accuracy: 0.9209 - val_loss: 1.0305 - val_accuracy: 0.6591\n","Epoch 43/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2119 - accuracy: 0.9119 - val_loss: 1.0133 - val_accuracy: 0.6674\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1972 - accuracy: 0.9163 - val_loss: 1.0440 - val_accuracy: 0.6653\n","Epoch 45/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2098 - accuracy: 0.9106 - val_loss: 1.0070 - val_accuracy: 0.6777\n","Epoch 46/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1976 - accuracy: 0.9189 - val_loss: 1.0103 - val_accuracy: 0.6715\n","Epoch 47/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1894 - accuracy: 0.9292 - val_loss: 1.0584 - val_accuracy: 0.6591\n","Epoch 48/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1922 - accuracy: 0.9284 - val_loss: 1.0539 - val_accuracy: 0.6736\n","Epoch 49/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1832 - accuracy: 0.9248 - val_loss: 1.0437 - val_accuracy: 0.6725\n","Epoch 50/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1922 - accuracy: 0.9202 - val_loss: 1.0670 - val_accuracy: 0.6694\n","Epoch 51/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1822 - accuracy: 0.9264 - val_loss: 1.0975 - val_accuracy: 0.6663\n","Epoch 52/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1858 - accuracy: 0.9233 - val_loss: 1.0827 - val_accuracy: 0.6622\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1795 - accuracy: 0.9297 - val_loss: 1.1343 - val_accuracy: 0.6612\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1783 - accuracy: 0.9282 - val_loss: 1.1173 - val_accuracy: 0.6570\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1795 - accuracy: 0.9276 - val_loss: 1.1077 - val_accuracy: 0.6643\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1720 - accuracy: 0.9261 - val_loss: 1.1241 - val_accuracy: 0.6643\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1731 - accuracy: 0.9279 - val_loss: 1.1060 - val_accuracy: 0.6684\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1716 - accuracy: 0.9305 - val_loss: 1.1300 - val_accuracy: 0.6643\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1704 - accuracy: 0.9305 - val_loss: 1.1403 - val_accuracy: 0.6632\n","Epoch 60/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1660 - accuracy: 0.9331 - val_loss: 1.1295 - val_accuracy: 0.6643\n","Epoch 61/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1557 - accuracy: 0.9408 - val_loss: 1.1783 - val_accuracy: 0.6601\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1655 - accuracy: 0.9364 - val_loss: 1.1696 - val_accuracy: 0.6715\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1577 - accuracy: 0.9372 - val_loss: 1.1931 - val_accuracy: 0.6694\n","Epoch 64/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1524 - accuracy: 0.9411 - val_loss: 1.1896 - val_accuracy: 0.6653\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1617 - accuracy: 0.9357 - val_loss: 1.2626 - val_accuracy: 0.6467\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1657 - accuracy: 0.9339 - val_loss: 1.1851 - val_accuracy: 0.6581\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1516 - accuracy: 0.9419 - val_loss: 1.2068 - val_accuracy: 0.6663\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1617 - accuracy: 0.9380 - val_loss: 1.2452 - val_accuracy: 0.6694\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1557 - accuracy: 0.9326 - val_loss: 1.2145 - val_accuracy: 0.6787\n","Epoch 70/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1414 - accuracy: 0.9499 - val_loss: 1.2047 - val_accuracy: 0.6756\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1471 - accuracy: 0.9429 - val_loss: 1.2393 - val_accuracy: 0.6653\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1700 - accuracy: 0.9266 - val_loss: 1.2325 - val_accuracy: 0.6674\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1535 - accuracy: 0.9372 - val_loss: 1.2519 - val_accuracy: 0.6560\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1475 - accuracy: 0.9426 - val_loss: 1.2486 - val_accuracy: 0.6612\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1377 - accuracy: 0.9463 - val_loss: 1.2626 - val_accuracy: 0.6643\n","Epoch 76/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1425 - accuracy: 0.9455 - val_loss: 1.2893 - val_accuracy: 0.6570\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1324 - accuracy: 0.9496 - val_loss: 1.3124 - val_accuracy: 0.6519\n","Epoch 78/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1331 - accuracy: 0.9512 - val_loss: 1.2784 - val_accuracy: 0.6632\n","Epoch 79/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1455 - accuracy: 0.9455 - val_loss: 1.2749 - val_accuracy: 0.6643\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1392 - accuracy: 0.9426 - val_loss: 1.2634 - val_accuracy: 0.6622\n","Epoch 81/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1242 - accuracy: 0.9504 - val_loss: 1.2866 - val_accuracy: 0.6643\n","Epoch 82/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1224 - accuracy: 0.9550 - val_loss: 1.3438 - val_accuracy: 0.6560\n","Epoch 83/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1370 - accuracy: 0.9460 - val_loss: 1.3488 - val_accuracy: 0.6643\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1246 - accuracy: 0.9519 - val_loss: 1.4022 - val_accuracy: 0.6612\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1226 - accuracy: 0.9527 - val_loss: 1.4020 - val_accuracy: 0.6570\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1324 - accuracy: 0.9478 - val_loss: 1.3541 - val_accuracy: 0.6550\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1126 - accuracy: 0.9628 - val_loss: 1.3718 - val_accuracy: 0.6601\n","Epoch 88/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1097 - accuracy: 0.9597 - val_loss: 1.3439 - val_accuracy: 0.6508\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1127 - accuracy: 0.9581 - val_loss: 1.4133 - val_accuracy: 0.6488\n","Epoch 90/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1098 - accuracy: 0.9587 - val_loss: 1.3538 - val_accuracy: 0.6622\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1109 - accuracy: 0.9571 - val_loss: 1.3676 - val_accuracy: 0.6539\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1091 - accuracy: 0.9612 - val_loss: 1.4329 - val_accuracy: 0.6550\n","Epoch 93/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1123 - accuracy: 0.9571 - val_loss: 1.4009 - val_accuracy: 0.6632\n","Epoch 94/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1210 - accuracy: 0.9504 - val_loss: 1.4298 - val_accuracy: 0.6643\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1163 - accuracy: 0.9522 - val_loss: 1.3838 - val_accuracy: 0.6622\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1083 - accuracy: 0.9571 - val_loss: 1.4248 - val_accuracy: 0.6632\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0992 - accuracy: 0.9661 - val_loss: 1.4357 - val_accuracy: 0.6508\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0989 - accuracy: 0.9638 - val_loss: 1.4900 - val_accuracy: 0.6508\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1014 - accuracy: 0.9597 - val_loss: 1.4803 - val_accuracy: 0.6663\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1336 - accuracy: 0.9460 - val_loss: 1.4432 - val_accuracy: 0.6550\n","{'loss': [0.36375558376312256, 0.3682951033115387, 0.35516995191574097, 0.33461156487464905, 0.32709357142448425, 0.32651829719543457, 0.3198418915271759, 0.3167720437049866, 0.30501776933670044, 0.29992687702178955, 0.30698662996292114, 0.30052173137664795, 0.2922505736351013, 0.29205191135406494, 0.28087231516838074, 0.2768218517303467, 0.28499165177345276, 0.26919007301330566, 0.2686060965061188, 0.2684933543205261, 0.2689763605594635, 0.2587215006351471, 0.2504834532737732, 0.25283870100975037, 0.2530646324157715, 0.2548951804637909, 0.25268200039863586, 0.24716976284980774, 0.24896526336669922, 0.23772285878658295, 0.24013280868530273, 0.22171248495578766, 0.243095263838768, 0.22916069626808167, 0.22655875980854034, 0.22190123796463013, 0.2202911227941513, 0.21890506148338318, 0.22840814292430878, 0.20284627377986908, 0.1993039846420288, 0.20160003006458282, 0.21185773611068726, 0.19723711907863617, 0.20978856086730957, 0.19760683178901672, 0.18941491842269897, 0.19216205179691315, 0.18324704468250275, 0.19220975041389465, 0.18222326040267944, 0.18583987653255463, 0.17948020994663239, 0.17825432121753693, 0.17947955429553986, 0.1719910055398941, 0.17308631539344788, 0.17157092690467834, 0.17037075757980347, 0.1660349816083908, 0.15570850670337677, 0.16547594964504242, 0.15770401060581207, 0.1523999571800232, 0.16169579327106476, 0.16568219661712646, 0.1516008973121643, 0.1616823375225067, 0.15568707883358002, 0.14144624769687653, 0.14710529148578644, 0.17000311613082886, 0.15350666642189026, 0.14747804403305054, 0.1377231776714325, 0.14247117936611176, 0.1323874145746231, 0.1331152319908142, 0.145452082157135, 0.1392115354537964, 0.12420186400413513, 0.1224193200469017, 0.13703487813472748, 0.12457811832427979, 0.12255685031414032, 0.13237231969833374, 0.1126154437661171, 0.10968854278326035, 0.11272085458040237, 0.10976614058017731, 0.11094477027654648, 0.10910911858081818, 0.11228927224874496, 0.12099672108888626, 0.11630254983901978, 0.10826671868562698, 0.09919784963130951, 0.09891721606254578, 0.10137077420949936, 0.13362962007522583], 'accuracy': [0.8410852551460266, 0.8356589078903198, 0.8333333134651184, 0.8498708009719849, 0.8542635440826416, 0.8545219898223877, 0.8599483370780945, 0.8684754371643066, 0.866925060749054, 0.8728682398796082, 0.8643410801887512, 0.8661498427391052, 0.8720930218696594, 0.8692506551742554, 0.8798449635505676, 0.883979320526123, 0.8718346357345581, 0.883979320526123, 0.8863049149513245, 0.8855296969413757, 0.8834625482559204, 0.8878552913665771, 0.8930232524871826, 0.8919896483421326, 0.8945736289024353, 0.8899224996566772, 0.8863049149513245, 0.8940568566322327, 0.8878552913665771, 0.8999999761581421, 0.8979328274726868, 0.9131782650947571, 0.8904392719268799, 0.9015504121780396, 0.9062015414237976, 0.9051679372787476, 0.9041343927383423, 0.9069767594337463, 0.9036175608634949, 0.920671820640564, 0.9193798303604126, 0.9209302067756653, 0.9118863344192505, 0.9162790775299072, 0.9105943441390991, 0.91886305809021, 0.9291989803314209, 0.9284237623214722, 0.9248061776161194, 0.9201550483703613, 0.9263566136360168, 0.9232558012008667, 0.9297157526016235, 0.9281653761863708, 0.9276486039161682, 0.9260981678962708, 0.9279069900512695, 0.9304909706115723, 0.9304909706115723, 0.933074951171875, 0.9408268928527832, 0.9364340901374817, 0.9372093081474304, 0.9410852789878845, 0.9356589317321777, 0.933850109577179, 0.9418604373931885, 0.9379844665527344, 0.9325581192970276, 0.9498708248138428, 0.9428940415382385, 0.9266149997711182, 0.9372093081474304, 0.9426356554031372, 0.94625324010849, 0.9454780220985413, 0.9496123790740967, 0.9511628150939941, 0.9454780220985413, 0.9426356554031372, 0.9503875970840454, 0.9550387859344482, 0.9459948539733887, 0.9519379734992981, 0.9527131915092468, 0.9478036165237427, 0.9627906680107117, 0.9596899151802063, 0.9581395387649536, 0.9586563110351562, 0.9571059346199036, 0.961240291595459, 0.9571059346199036, 0.9503875970840454, 0.9521963596343994, 0.9571059346199036, 0.9661498665809631, 0.9638242721557617, 0.9596899151802063, 0.9459948539733887], 'val_loss': [0.7113379836082458, 0.7051356434822083, 0.7041369080543518, 0.7057117819786072, 0.7034490704536438, 0.6955866813659668, 0.6959376931190491, 0.6957981586456299, 0.6857297420501709, 0.6850292086601257, 0.6919039487838745, 0.6836457848548889, 0.6737707853317261, 0.6520305275917053, 0.6528797745704651, 0.637342095375061, 0.6810448169708252, 0.6820504665374756, 0.6659441590309143, 0.707365870475769, 0.7079206705093384, 0.7238463163375854, 0.7398694157600403, 0.7852138876914978, 0.7881996631622314, 0.8311281800270081, 0.8567794561386108, 0.8700208067893982, 0.8762447834014893, 0.8986692428588867, 0.9485148191452026, 0.9288455843925476, 0.925788938999176, 0.9266170263290405, 0.9591043591499329, 0.9824032187461853, 0.9553122520446777, 0.9935757517814636, 0.9796650409698486, 0.9754233360290527, 0.9961256980895996, 1.0304596424102783, 1.0133150815963745, 1.043953537940979, 1.0069878101348877, 1.0103007555007935, 1.0584309101104736, 1.053870439529419, 1.043742060661316, 1.0670018196105957, 1.097481608390808, 1.082718849182129, 1.1342729330062866, 1.1173207759857178, 1.1077078580856323, 1.1241048574447632, 1.1060460805892944, 1.1300253868103027, 1.1403478384017944, 1.1294713020324707, 1.1782540082931519, 1.1695759296417236, 1.1930599212646484, 1.1896439790725708, 1.2626062631607056, 1.1851125955581665, 1.2067546844482422, 1.245223879814148, 1.2145220041275024, 1.204684853553772, 1.2393136024475098, 1.2325109243392944, 1.25188148021698, 1.2485731840133667, 1.2626163959503174, 1.2893260717391968, 1.3123927116394043, 1.2783643007278442, 1.2748570442199707, 1.2633947134017944, 1.2866050004959106, 1.3438212871551514, 1.348755121231079, 1.4021743535995483, 1.402005910873413, 1.35411536693573, 1.3717666864395142, 1.3438633680343628, 1.4133344888687134, 1.3537771701812744, 1.3675776720046997, 1.432897686958313, 1.400853157043457, 1.429793357849121, 1.3838191032409668, 1.4248226881027222, 1.4356993436813354, 1.4900120496749878, 1.4803446531295776, 1.4432063102722168], 'val_accuracy': [0.4886363744735718, 0.48966941237449646, 0.48966941237449646, 0.48966941237449646, 0.4927685856819153, 0.49380165338516235, 0.4969008266925812, 0.4969008266925812, 0.5144628286361694, 0.5216942429542542, 0.51962810754776, 0.5289255976676941, 0.5485537052154541, 0.60537189245224, 0.5991735458374023, 0.6466942429542542, 0.5981404781341553, 0.6084710955619812, 0.6477272510528564, 0.6301652789115906, 0.6539255976676941, 0.66425621509552, 0.6766529083251953, 0.672520637512207, 0.6745867729187012, 0.6694214940071106, 0.672520637512207, 0.6766529083251953, 0.6900826692581177, 0.6818181872367859, 0.6590909361839294, 0.6663222908973694, 0.6652892827987671, 0.6807851195335388, 0.6756198406219482, 0.6673553586006165, 0.6797520518302917, 0.6663222908973694, 0.6704545617103577, 0.6714876294136047, 0.6704545617103577, 0.6590909361839294, 0.6673553586006165, 0.6652892827987671, 0.6776859760284424, 0.6714876294136047, 0.6590909361839294, 0.6735537052154541, 0.672520637512207, 0.6694214940071106, 0.6663222908973694, 0.6621900796890259, 0.6611570119857788, 0.6570248007774353, 0.66425621509552, 0.66425621509552, 0.6683884263038635, 0.66425621509552, 0.663223147392273, 0.66425621509552, 0.6601239442825317, 0.6714876294136047, 0.6694214940071106, 0.6652892827987671, 0.6466942429542542, 0.6580578684806824, 0.6663222908973694, 0.6694214940071106, 0.6787189841270447, 0.6756198406219482, 0.6652892827987671, 0.6673553586006165, 0.6559917330741882, 0.6611570119857788, 0.66425621509552, 0.6570248007774353, 0.6518595218658447, 0.663223147392273, 0.66425621509552, 0.6621900796890259, 0.66425621509552, 0.6559917330741882, 0.66425621509552, 0.6611570119857788, 0.6570248007774353, 0.6549586653709412, 0.6601239442825317, 0.6508264541625977, 0.6487603187561035, 0.6621900796890259, 0.6539255976676941, 0.6549586653709412, 0.663223147392273, 0.66425621509552, 0.6621900796890259, 0.663223147392273, 0.6508264541625977, 0.6508264541625977, 0.6663222908973694, 0.6549586653709412]}\n","32/32 [==============================] - 2s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 6s 54ms/step - loss: 0.2051 - accuracy: 0.9246 - val_loss: 0.7180 - val_accuracy: 0.4871\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 13ms/step - loss: 0.1743 - accuracy: 0.9310 - val_loss: 0.7119 - val_accuracy: 0.4871\n","Epoch 3/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1631 - accuracy: 0.9359 - val_loss: 0.7048 - val_accuracy: 0.4871\n","Epoch 4/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1588 - accuracy: 0.9413 - val_loss: 0.7021 - val_accuracy: 0.4881\n","Epoch 5/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1480 - accuracy: 0.9402 - val_loss: 0.6955 - val_accuracy: 0.4935\n","Epoch 6/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1507 - accuracy: 0.9362 - val_loss: 0.6875 - val_accuracy: 0.4989\n","Epoch 7/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.1448 - accuracy: 0.9391 - val_loss: 0.6786 - val_accuracy: 0.5086\n","Epoch 8/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.1472 - accuracy: 0.9399 - val_loss: 0.6691 - val_accuracy: 0.5194\n","Epoch 9/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.1446 - accuracy: 0.9394 - val_loss: 0.6602 - val_accuracy: 0.5248\n","Epoch 10/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.1346 - accuracy: 0.9453 - val_loss: 0.6565 - val_accuracy: 0.5334\n","Epoch 11/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.1751 - accuracy: 0.9267 - val_loss: 0.6352 - val_accuracy: 0.5657\n","Epoch 12/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1271 - accuracy: 0.9504 - val_loss: 0.6099 - val_accuracy: 0.6131\n","Epoch 13/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1233 - accuracy: 0.9529 - val_loss: 0.6038 - val_accuracy: 0.6153\n","Epoch 14/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1214 - accuracy: 0.9542 - val_loss: 0.5882 - val_accuracy: 0.6433\n","Epoch 15/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1322 - accuracy: 0.9485 - val_loss: 0.5995 - val_accuracy: 0.6272\n","Epoch 16/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1274 - accuracy: 0.9520 - val_loss: 0.5675 - val_accuracy: 0.6767\n","Epoch 17/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1262 - accuracy: 0.9502 - val_loss: 0.5492 - val_accuracy: 0.6994\n","Epoch 18/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1207 - accuracy: 0.9512 - val_loss: 0.5729 - val_accuracy: 0.6821\n","Epoch 19/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1093 - accuracy: 0.9564 - val_loss: 0.5115 - val_accuracy: 0.7651\n","Epoch 20/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1205 - accuracy: 0.9569 - val_loss: 0.5029 - val_accuracy: 0.7759\n","Epoch 21/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1075 - accuracy: 0.9607 - val_loss: 0.5283 - val_accuracy: 0.7672\n","Epoch 22/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1195 - accuracy: 0.9520 - val_loss: 0.5422 - val_accuracy: 0.7705\n","Epoch 23/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1237 - accuracy: 0.9483 - val_loss: 0.6078 - val_accuracy: 0.7511\n","Epoch 24/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.1069 - accuracy: 0.9609 - val_loss: 0.5712 - val_accuracy: 0.7802\n","Epoch 25/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1080 - accuracy: 0.9617 - val_loss: 0.6047 - val_accuracy: 0.7866\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0963 - accuracy: 0.9663 - val_loss: 0.6722 - val_accuracy: 0.7705\n","Epoch 27/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1036 - accuracy: 0.9647 - val_loss: 0.6659 - val_accuracy: 0.7759\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0930 - accuracy: 0.9671 - val_loss: 0.6870 - val_accuracy: 0.7759\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1039 - accuracy: 0.9574 - val_loss: 0.7392 - val_accuracy: 0.7748\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0907 - accuracy: 0.9685 - val_loss: 0.7197 - val_accuracy: 0.7812\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0918 - accuracy: 0.9666 - val_loss: 0.7368 - val_accuracy: 0.7845\n","Epoch 32/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0887 - accuracy: 0.9709 - val_loss: 0.7836 - val_accuracy: 0.7759\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0841 - accuracy: 0.9698 - val_loss: 0.7824 - val_accuracy: 0.7780\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0795 - accuracy: 0.9709 - val_loss: 0.8073 - val_accuracy: 0.7737\n","Epoch 35/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1006 - accuracy: 0.9607 - val_loss: 0.8189 - val_accuracy: 0.7780\n","Epoch 36/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0784 - accuracy: 0.9714 - val_loss: 0.8288 - val_accuracy: 0.7662\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0765 - accuracy: 0.9741 - val_loss: 0.8003 - val_accuracy: 0.7769\n","Epoch 38/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0724 - accuracy: 0.9763 - val_loss: 0.8101 - val_accuracy: 0.7780\n","Epoch 39/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0820 - accuracy: 0.9688 - val_loss: 0.8074 - val_accuracy: 0.7748\n","Epoch 40/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0769 - accuracy: 0.9728 - val_loss: 0.8365 - val_accuracy: 0.7672\n","Epoch 41/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0743 - accuracy: 0.9725 - val_loss: 0.8376 - val_accuracy: 0.7705\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0822 - accuracy: 0.9714 - val_loss: 0.8676 - val_accuracy: 0.7672\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0906 - accuracy: 0.9647 - val_loss: 0.8328 - val_accuracy: 0.7737\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0861 - accuracy: 0.9682 - val_loss: 0.8586 - val_accuracy: 0.7640\n","Epoch 45/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0931 - accuracy: 0.9634 - val_loss: 0.8476 - val_accuracy: 0.7662\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0922 - accuracy: 0.9655 - val_loss: 0.8964 - val_accuracy: 0.7608\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0910 - accuracy: 0.9652 - val_loss: 0.8449 - val_accuracy: 0.7726\n","Epoch 48/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0741 - accuracy: 0.9717 - val_loss: 0.8646 - val_accuracy: 0.7683\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0635 - accuracy: 0.9820 - val_loss: 0.8830 - val_accuracy: 0.7651\n","Epoch 50/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0735 - accuracy: 0.9731 - val_loss: 0.9391 - val_accuracy: 0.7619\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0751 - accuracy: 0.9717 - val_loss: 0.9108 - val_accuracy: 0.7586\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0625 - accuracy: 0.9803 - val_loss: 0.8997 - val_accuracy: 0.7683\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0803 - accuracy: 0.9698 - val_loss: 0.8977 - val_accuracy: 0.7726\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0945 - accuracy: 0.9666 - val_loss: 0.9084 - val_accuracy: 0.7629\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0613 - accuracy: 0.9784 - val_loss: 0.8805 - val_accuracy: 0.7705\n","Epoch 56/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0611 - accuracy: 0.9811 - val_loss: 0.8926 - val_accuracy: 0.7629\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0564 - accuracy: 0.9833 - val_loss: 0.9359 - val_accuracy: 0.7694\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0690 - accuracy: 0.9760 - val_loss: 0.9330 - val_accuracy: 0.7629\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0575 - accuracy: 0.9825 - val_loss: 0.9324 - val_accuracy: 0.7608\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0696 - accuracy: 0.9776 - val_loss: 0.9352 - val_accuracy: 0.7662\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0691 - accuracy: 0.9749 - val_loss: 0.9254 - val_accuracy: 0.7575\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0984 - accuracy: 0.9604 - val_loss: 0.9787 - val_accuracy: 0.7640\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0737 - accuracy: 0.9720 - val_loss: 0.9139 - val_accuracy: 0.7586\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0591 - accuracy: 0.9801 - val_loss: 0.9467 - val_accuracy: 0.7640\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0698 - accuracy: 0.9774 - val_loss: 0.9433 - val_accuracy: 0.7554\n","Epoch 66/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0808 - accuracy: 0.9682 - val_loss: 0.9746 - val_accuracy: 0.7640\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0537 - accuracy: 0.9833 - val_loss: 0.9281 - val_accuracy: 0.7629\n","Epoch 68/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0610 - accuracy: 0.9809 - val_loss: 0.9290 - val_accuracy: 0.7672\n","Epoch 69/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0580 - accuracy: 0.9798 - val_loss: 0.9458 - val_accuracy: 0.7640\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0518 - accuracy: 0.9830 - val_loss: 0.9374 - val_accuracy: 0.7619\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0540 - accuracy: 0.9814 - val_loss: 0.9958 - val_accuracy: 0.7619\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0502 - accuracy: 0.9860 - val_loss: 0.9536 - val_accuracy: 0.7662\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0509 - accuracy: 0.9822 - val_loss: 1.0277 - val_accuracy: 0.7597\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0442 - accuracy: 0.9871 - val_loss: 0.9751 - val_accuracy: 0.7640\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0476 - accuracy: 0.9868 - val_loss: 0.9852 - val_accuracy: 0.7672\n","Epoch 76/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0528 - accuracy: 0.9833 - val_loss: 0.9973 - val_accuracy: 0.7586\n","Epoch 77/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0507 - accuracy: 0.9852 - val_loss: 0.9856 - val_accuracy: 0.7651\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0633 - accuracy: 0.9749 - val_loss: 1.0077 - val_accuracy: 0.7629\n","Epoch 79/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0458 - accuracy: 0.9868 - val_loss: 1.0174 - val_accuracy: 0.7565\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0471 - accuracy: 0.9865 - val_loss: 1.0123 - val_accuracy: 0.7565\n","Epoch 81/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0534 - accuracy: 0.9833 - val_loss: 1.0256 - val_accuracy: 0.7586\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0449 - accuracy: 0.9849 - val_loss: 1.0037 - val_accuracy: 0.7575\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0413 - accuracy: 0.9895 - val_loss: 1.0109 - val_accuracy: 0.7575\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0444 - accuracy: 0.9849 - val_loss: 1.0668 - val_accuracy: 0.7608\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0374 - accuracy: 0.9911 - val_loss: 1.0942 - val_accuracy: 0.7532\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0522 - accuracy: 0.9809 - val_loss: 1.0297 - val_accuracy: 0.7575\n","Epoch 87/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0348 - accuracy: 0.9892 - val_loss: 1.0476 - val_accuracy: 0.7554\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0430 - accuracy: 0.9863 - val_loss: 1.0593 - val_accuracy: 0.7629\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0359 - accuracy: 0.9898 - val_loss: 1.0562 - val_accuracy: 0.7640\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0527 - accuracy: 0.9865 - val_loss: 1.1117 - val_accuracy: 0.7489\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0498 - accuracy: 0.9833 - val_loss: 1.0415 - val_accuracy: 0.7522\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0415 - accuracy: 0.9890 - val_loss: 1.0586 - val_accuracy: 0.7554\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0449 - accuracy: 0.9849 - val_loss: 1.0555 - val_accuracy: 0.7532\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0378 - accuracy: 0.9860 - val_loss: 1.0535 - val_accuracy: 0.7575\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0378 - accuracy: 0.9876 - val_loss: 1.0728 - val_accuracy: 0.7608\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0361 - accuracy: 0.9892 - val_loss: 1.0703 - val_accuracy: 0.7586\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0385 - accuracy: 0.9871 - val_loss: 1.0768 - val_accuracy: 0.7586\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0376 - accuracy: 0.9895 - val_loss: 1.0783 - val_accuracy: 0.7554\n","Epoch 99/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0380 - accuracy: 0.9884 - val_loss: 1.1064 - val_accuracy: 0.7565\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0385 - accuracy: 0.9884 - val_loss: 1.0938 - val_accuracy: 0.7511\n","{'loss': [0.20509469509124756, 0.17425695061683655, 0.16306769847869873, 0.1587616503238678, 0.14804024994373322, 0.15068534016609192, 0.1448165774345398, 0.14716698229312897, 0.1445959508419037, 0.13462243974208832, 0.1751098334789276, 0.12706029415130615, 0.12333962321281433, 0.12141630053520203, 0.13221856951713562, 0.12743328511714935, 0.12616212666034698, 0.12068885564804077, 0.10925929248332977, 0.12045891582965851, 0.10753121227025986, 0.11945832520723343, 0.1237335130572319, 0.10689491778612137, 0.10795529186725616, 0.09631631523370743, 0.10355623811483383, 0.09298951923847198, 0.10390464216470718, 0.09069928526878357, 0.0918281078338623, 0.0886877179145813, 0.08410782366991043, 0.07953529804944992, 0.10062971711158752, 0.07836432754993439, 0.07646525651216507, 0.07239501178264618, 0.08200134336948395, 0.07691600173711777, 0.07429838180541992, 0.08221859484910965, 0.09063079208135605, 0.08612164855003357, 0.09314778447151184, 0.09222826361656189, 0.0909884124994278, 0.07414894551038742, 0.0635087639093399, 0.07349216192960739, 0.07506035268306732, 0.06254075467586517, 0.08032098412513733, 0.09447377175092697, 0.061259675770998, 0.061063606292009354, 0.0564347542822361, 0.0690106600522995, 0.05748239904642105, 0.0696215108036995, 0.06905663758516312, 0.09838803857564926, 0.07365857809782028, 0.05905378609895706, 0.06981472671031952, 0.08077512681484222, 0.05374625325202942, 0.061008110642433167, 0.058009710162878036, 0.05176914110779762, 0.05397789552807808, 0.05020535737276077, 0.050946686416864395, 0.04423721134662628, 0.04764237999916077, 0.052848316729068756, 0.050655514001846313, 0.06334532052278519, 0.04579544812440872, 0.04706833139061928, 0.05335163697600365, 0.04493365436792374, 0.041287925094366074, 0.04444704204797745, 0.03741561248898506, 0.052190717309713364, 0.034802164882421494, 0.042985256761312485, 0.0359339639544487, 0.052675556391477585, 0.04981263726949692, 0.041457559913396835, 0.04491790384054184, 0.03780069947242737, 0.037832897156476974, 0.03608367219567299, 0.038490455597639084, 0.03760631009936333, 0.037951741367578506, 0.03854891657829285], 'accuracy': [0.9245689511299133, 0.931034505367279, 0.935883641242981, 0.9412715435028076, 0.9401939511299133, 0.936152994632721, 0.939116358757019, 0.9399245977401733, 0.9393857717514038, 0.9453125, 0.9267241358757019, 0.9504310488700867, 0.9528555870056152, 0.9542025923728943, 0.9485452771186829, 0.9520474076271057, 0.9501616358757019, 0.9512392282485962, 0.9563577771186829, 0.9568965435028076, 0.9606680870056152, 0.9520474076271057, 0.9482758641242981, 0.9609375, 0.9617456793785095, 0.9663254022598267, 0.9647090435028076, 0.967133641242981, 0.9574353694915771, 0.9684805870056152, 0.9665948152542114, 0.9709051847457886, 0.9698275923728943, 0.9709051847457886, 0.9606680870056152, 0.9714439511299133, 0.9741379022598267, 0.9762930870056152, 0.96875, 0.9727909564971924, 0.9725215435028076, 0.9714439511299133, 0.9647090435028076, 0.9682112336158752, 0.9633620977401733, 0.9655172228813171, 0.9652478694915771, 0.9717133641242981, 0.9819504022598267, 0.9730603694915771, 0.9717133641242981, 0.9803340435028076, 0.9698275923728943, 0.9665948152542114, 0.9784482717514038, 0.9811422228813171, 0.9832974076271057, 0.9760237336158752, 0.9824892282485962, 0.9776400923728943, 0.974946141242981, 0.9603987336158752, 0.9719827771186829, 0.9800646305084229, 0.9773706793785095, 0.9682112336158752, 0.9832974076271057, 0.9808728694915771, 0.9797952771186829, 0.983027994632721, 0.9814116358757019, 0.985991358757019, 0.9822198152542114, 0.9870689511299133, 0.9867995977401733, 0.9832974076271057, 0.9851831793785095, 0.974946141242981, 0.9867995977401733, 0.9865301847457886, 0.9832974076271057, 0.9849137663841248, 0.9894935488700867, 0.9849137663841248, 0.9911099076271057, 0.9808728694915771, 0.9892241358757019, 0.9862607717514038, 0.9897629022598267, 0.9865301847457886, 0.9832974076271057, 0.9889547228813171, 0.9849137663841248, 0.985991358757019, 0.9876077771186829, 0.9892241358757019, 0.9870689511299133, 0.9894935488700867, 0.9884159564971924, 0.9884159564971924], 'val_loss': [0.7180138230323792, 0.7119230031967163, 0.7048138976097107, 0.7020964622497559, 0.6955063343048096, 0.6874601244926453, 0.6786045432090759, 0.6691383123397827, 0.6601590514183044, 0.6564632654190063, 0.6352181434631348, 0.609859824180603, 0.6038461923599243, 0.5882401466369629, 0.5995346307754517, 0.5675321221351624, 0.5492070913314819, 0.5729158520698547, 0.5114647746086121, 0.5029104948043823, 0.5283278822898865, 0.5422032475471497, 0.6078203320503235, 0.5711726546287537, 0.6046640872955322, 0.6722277402877808, 0.6659216284751892, 0.687029242515564, 0.7392474412918091, 0.7197284698486328, 0.736752986907959, 0.783611536026001, 0.7824001908302307, 0.8073480725288391, 0.8189018368721008, 0.8287622332572937, 0.8003251552581787, 0.8101063370704651, 0.807426929473877, 0.8365381956100464, 0.8375796675682068, 0.8675588965415955, 0.832816481590271, 0.8585861921310425, 0.8475827574729919, 0.896353542804718, 0.8449046015739441, 0.8645826578140259, 0.8829672336578369, 0.9391140937805176, 0.9107946753501892, 0.899732232093811, 0.8976863622665405, 0.9083945155143738, 0.8805475831031799, 0.8926154375076294, 0.9359195828437805, 0.9330013990402222, 0.932428777217865, 0.9352148175239563, 0.9253517389297485, 0.9787304997444153, 0.91392982006073, 0.9467133283615112, 0.9432958364486694, 0.9746356010437012, 0.9280957579612732, 0.9289863109588623, 0.9457509517669678, 0.9374161958694458, 0.9958236813545227, 0.9535506963729858, 1.0276967287063599, 0.9751185774803162, 0.985160231590271, 0.9972742795944214, 0.9856011867523193, 1.0076725482940674, 1.017431616783142, 1.012320637702942, 1.0255558490753174, 1.0036911964416504, 1.0108795166015625, 1.0668057203292847, 1.0941824913024902, 1.0296753644943237, 1.0475786924362183, 1.0593341588974, 1.0561970472335815, 1.11174476146698, 1.0415297746658325, 1.058617353439331, 1.0554873943328857, 1.0534809827804565, 1.072798490524292, 1.0702649354934692, 1.076798677444458, 1.0782917737960815, 1.106373906135559, 1.0937621593475342], 'val_accuracy': [0.48706895112991333, 0.48706895112991333, 0.48706895112991333, 0.4881465435028076, 0.49353447556495667, 0.4989224076271057, 0.5086206793785095, 0.5193965435028076, 0.524784505367279, 0.5334051847457886, 0.5657327771186829, 0.6131465435028076, 0.6153017282485962, 0.6433189511299133, 0.6271551847457886, 0.6767241358757019, 0.6993534564971924, 0.6821120977401733, 0.7650862336158752, 0.7758620977401733, 0.767241358757019, 0.7704741358757019, 0.7510775923728943, 0.7801724076271057, 0.7866379022598267, 0.7704741358757019, 0.7758620977401733, 0.7758620977401733, 0.774784505367279, 0.78125, 0.7844827771186829, 0.7758620977401733, 0.7780172228813171, 0.7737069129943848, 0.7780172228813171, 0.7661637663841248, 0.7769396305084229, 0.7780172228813171, 0.774784505367279, 0.767241358757019, 0.7704741358757019, 0.767241358757019, 0.7737069129943848, 0.764008641242981, 0.7661637663841248, 0.7607758641242981, 0.7726293206214905, 0.7683189511299133, 0.7650862336158752, 0.7618534564971924, 0.7586206793785095, 0.7683189511299133, 0.7726293206214905, 0.7629310488700867, 0.7704741358757019, 0.7629310488700867, 0.7693965435028076, 0.7629310488700867, 0.7607758641242981, 0.7661637663841248, 0.7575430870056152, 0.764008641242981, 0.7586206793785095, 0.764008641242981, 0.7553879022598267, 0.764008641242981, 0.7629310488700867, 0.767241358757019, 0.764008641242981, 0.7618534564971924, 0.7618534564971924, 0.7661637663841248, 0.7596982717514038, 0.764008641242981, 0.767241358757019, 0.7586206793785095, 0.7650862336158752, 0.7629310488700867, 0.756465494632721, 0.756465494632721, 0.7586206793785095, 0.7575430870056152, 0.7575430870056152, 0.7607758641242981, 0.7532327771186829, 0.7575430870056152, 0.7553879022598267, 0.7629310488700867, 0.764008641242981, 0.7489224076271057, 0.7521551847457886, 0.7553879022598267, 0.7532327771186829, 0.7575430870056152, 0.7607758641242981, 0.7586206793785095, 0.7586206793785095, 0.7553879022598267, 0.756465494632721, 0.7510775923728943]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.2441 - accuracy: 0.9031"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 59ms/step - loss: 0.2441 - accuracy: 0.9024 - val_loss: 0.7052 - val_accuracy: 0.4989\n","Epoch 2/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1684 - accuracy: 0.9312 - val_loss: 0.7053 - val_accuracy: 0.4989\n","Epoch 3/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1620 - accuracy: 0.9329 - val_loss: 0.6971 - val_accuracy: 0.5045\n","Epoch 4/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.1607 - accuracy: 0.9358 - val_loss: 0.6958 - val_accuracy: 0.5057\n","Epoch 5/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1547 - accuracy: 0.9383 - val_loss: 0.6899 - val_accuracy: 0.5090\n","Epoch 6/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1554 - accuracy: 0.9355 - val_loss: 0.6854 - val_accuracy: 0.5113\n","Epoch 7/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1468 - accuracy: 0.9403 - val_loss: 0.6683 - val_accuracy: 0.5294\n","Epoch 8/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1416 - accuracy: 0.9479 - val_loss: 0.6754 - val_accuracy: 0.5215\n","Epoch 9/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.1369 - accuracy: 0.9454 - val_loss: 0.6557 - val_accuracy: 0.5396\n","Epoch 10/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1375 - accuracy: 0.9465 - val_loss: 0.6515 - val_accuracy: 0.5441\n","Epoch 11/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.1413 - accuracy: 0.9420 - val_loss: 0.6229 - val_accuracy: 0.5848\n","Epoch 12/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1485 - accuracy: 0.9394 - val_loss: 0.6000 - val_accuracy: 0.6437\n","Epoch 13/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1391 - accuracy: 0.9437 - val_loss: 0.5973 - val_accuracy: 0.6256\n","Epoch 14/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1257 - accuracy: 0.9530 - val_loss: 0.6005 - val_accuracy: 0.6120\n","Epoch 15/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1335 - accuracy: 0.9479 - val_loss: 0.5588 - val_accuracy: 0.6742\n","Epoch 16/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1196 - accuracy: 0.9564 - val_loss: 0.5588 - val_accuracy: 0.6742\n","Epoch 17/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.1102 - accuracy: 0.9624 - val_loss: 0.5174 - val_accuracy: 0.7296\n","Epoch 18/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.1253 - accuracy: 0.9547 - val_loss: 0.5029 - val_accuracy: 0.7658\n","Epoch 19/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1285 - accuracy: 0.9522 - val_loss: 0.5031 - val_accuracy: 0.7613\n","Epoch 20/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1039 - accuracy: 0.9663 - val_loss: 0.5036 - val_accuracy: 0.7410\n","Epoch 21/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.1054 - accuracy: 0.9632 - val_loss: 0.4837 - val_accuracy: 0.7817\n","Epoch 22/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1018 - accuracy: 0.9626 - val_loss: 0.5013 - val_accuracy: 0.7692\n","Epoch 23/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1082 - accuracy: 0.9590 - val_loss: 0.5387 - val_accuracy: 0.7681\n","Epoch 24/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.1020 - accuracy: 0.9598 - val_loss: 0.5387 - val_accuracy: 0.7885\n","Epoch 25/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0978 - accuracy: 0.9649 - val_loss: 0.5381 - val_accuracy: 0.7952\n","Epoch 26/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0968 - accuracy: 0.9638 - val_loss: 0.5517 - val_accuracy: 0.7986\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1032 - accuracy: 0.9663 - val_loss: 0.5969 - val_accuracy: 0.7851\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0960 - accuracy: 0.9632 - val_loss: 0.6295 - val_accuracy: 0.7952\n","Epoch 29/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1095 - accuracy: 0.9641 - val_loss: 0.6629 - val_accuracy: 0.7862\n","Epoch 30/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0917 - accuracy: 0.9694 - val_loss: 0.7278 - val_accuracy: 0.7738\n","Epoch 31/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0920 - accuracy: 0.9677 - val_loss: 0.6939 - val_accuracy: 0.7930\n","Epoch 32/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0898 - accuracy: 0.9692 - val_loss: 0.7145 - val_accuracy: 0.8009\n","Epoch 33/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0910 - accuracy: 0.9680 - val_loss: 0.7622 - val_accuracy: 0.7862\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0853 - accuracy: 0.9734 - val_loss: 0.7509 - val_accuracy: 0.7783\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1034 - accuracy: 0.9576 - val_loss: 0.7216 - val_accuracy: 0.7952\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1018 - accuracy: 0.9615 - val_loss: 0.7444 - val_accuracy: 0.7851\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0988 - accuracy: 0.9666 - val_loss: 0.7906 - val_accuracy: 0.7873\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0954 - accuracy: 0.9595 - val_loss: 0.7879 - val_accuracy: 0.7919\n","Epoch 39/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0807 - accuracy: 0.9717 - val_loss: 0.7910 - val_accuracy: 0.7794\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0913 - accuracy: 0.9680 - val_loss: 0.7775 - val_accuracy: 0.7873\n","Epoch 41/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0853 - accuracy: 0.9697 - val_loss: 0.7737 - val_accuracy: 0.7907\n","Epoch 42/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0819 - accuracy: 0.9714 - val_loss: 0.9218 - val_accuracy: 0.7590\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0905 - accuracy: 0.9694 - val_loss: 0.8896 - val_accuracy: 0.7738\n","Epoch 44/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0860 - accuracy: 0.9689 - val_loss: 0.8159 - val_accuracy: 0.7839\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0676 - accuracy: 0.9771 - val_loss: 0.8164 - val_accuracy: 0.7783\n","Epoch 46/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0737 - accuracy: 0.9771 - val_loss: 0.8037 - val_accuracy: 0.7851\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0826 - accuracy: 0.9711 - val_loss: 0.8510 - val_accuracy: 0.7873\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0656 - accuracy: 0.9808 - val_loss: 0.8583 - val_accuracy: 0.7794\n","Epoch 49/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0676 - accuracy: 0.9774 - val_loss: 0.8226 - val_accuracy: 0.7805\n","Epoch 50/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0703 - accuracy: 0.9745 - val_loss: 0.9018 - val_accuracy: 0.7794\n","Epoch 51/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0971 - accuracy: 0.9615 - val_loss: 0.8120 - val_accuracy: 0.7907\n","Epoch 52/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1107 - accuracy: 0.9542 - val_loss: 0.8541 - val_accuracy: 0.7873\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0842 - accuracy: 0.9669 - val_loss: 0.8286 - val_accuracy: 0.7873\n","Epoch 54/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0661 - accuracy: 0.9796 - val_loss: 0.8512 - val_accuracy: 0.7726\n","Epoch 55/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0740 - accuracy: 0.9743 - val_loss: 0.8268 - val_accuracy: 0.7862\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0675 - accuracy: 0.9757 - val_loss: 0.9258 - val_accuracy: 0.7613\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0689 - accuracy: 0.9785 - val_loss: 0.8434 - val_accuracy: 0.7862\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0567 - accuracy: 0.9808 - val_loss: 0.8555 - val_accuracy: 0.7896\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0604 - accuracy: 0.9805 - val_loss: 0.8670 - val_accuracy: 0.7828\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0568 - accuracy: 0.9847 - val_loss: 0.8627 - val_accuracy: 0.7794\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0629 - accuracy: 0.9782 - val_loss: 0.9418 - val_accuracy: 0.7602\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0582 - accuracy: 0.9808 - val_loss: 0.9058 - val_accuracy: 0.7613\n","Epoch 63/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0572 - accuracy: 0.9825 - val_loss: 0.8921 - val_accuracy: 0.7817\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0712 - accuracy: 0.9697 - val_loss: 0.9266 - val_accuracy: 0.7749\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0620 - accuracy: 0.9782 - val_loss: 0.9284 - val_accuracy: 0.7771\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0544 - accuracy: 0.9836 - val_loss: 0.9812 - val_accuracy: 0.7613\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0614 - accuracy: 0.9791 - val_loss: 0.9252 - val_accuracy: 0.7794\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0497 - accuracy: 0.9842 - val_loss: 0.9263 - val_accuracy: 0.7726\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0550 - accuracy: 0.9844 - val_loss: 0.9748 - val_accuracy: 0.7704\n","Epoch 70/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0631 - accuracy: 0.9791 - val_loss: 0.9414 - val_accuracy: 0.7658\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0690 - accuracy: 0.9728 - val_loss: 0.9286 - val_accuracy: 0.7738\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0485 - accuracy: 0.9847 - val_loss: 0.9495 - val_accuracy: 0.7760\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0466 - accuracy: 0.9864 - val_loss: 0.9367 - val_accuracy: 0.7783\n","Epoch 74/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0464 - accuracy: 0.9867 - val_loss: 0.9359 - val_accuracy: 0.7715\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0437 - accuracy: 0.9870 - val_loss: 0.9336 - val_accuracy: 0.7749\n","Epoch 76/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0475 - accuracy: 0.9867 - val_loss: 0.9469 - val_accuracy: 0.7738\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0468 - accuracy: 0.9850 - val_loss: 0.9893 - val_accuracy: 0.7715\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0480 - accuracy: 0.9847 - val_loss: 0.9692 - val_accuracy: 0.7862\n","Epoch 79/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0501 - accuracy: 0.9844 - val_loss: 1.0624 - val_accuracy: 0.7602\n","Epoch 80/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0533 - accuracy: 0.9819 - val_loss: 0.9715 - val_accuracy: 0.7760\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0541 - accuracy: 0.9825 - val_loss: 1.0271 - val_accuracy: 0.7624\n","Epoch 82/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0418 - accuracy: 0.9870 - val_loss: 1.0323 - val_accuracy: 0.7613\n","Epoch 83/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0388 - accuracy: 0.9884 - val_loss: 0.9992 - val_accuracy: 0.7794\n","Epoch 84/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0374 - accuracy: 0.9890 - val_loss: 1.0157 - val_accuracy: 0.7681\n","Epoch 85/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0396 - accuracy: 0.9881 - val_loss: 0.9997 - val_accuracy: 0.7681\n","Epoch 86/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0506 - accuracy: 0.9833 - val_loss: 1.0525 - val_accuracy: 0.7783\n","Epoch 87/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0489 - accuracy: 0.9819 - val_loss: 0.9859 - val_accuracy: 0.7771\n","Epoch 88/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0424 - accuracy: 0.9867 - val_loss: 1.0080 - val_accuracy: 0.7760\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0455 - accuracy: 0.9830 - val_loss: 1.0048 - val_accuracy: 0.7749\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0358 - accuracy: 0.9884 - val_loss: 1.0357 - val_accuracy: 0.7760\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0440 - accuracy: 0.9859 - val_loss: 1.0404 - val_accuracy: 0.7738\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0360 - accuracy: 0.9892 - val_loss: 1.1058 - val_accuracy: 0.7590\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0424 - accuracy: 0.9873 - val_loss: 1.0620 - val_accuracy: 0.7670\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0361 - accuracy: 0.9890 - val_loss: 1.0465 - val_accuracy: 0.7704\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0337 - accuracy: 0.9904 - val_loss: 1.0229 - val_accuracy: 0.7817\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0412 - accuracy: 0.9859 - val_loss: 1.0424 - val_accuracy: 0.7749\n","Epoch 97/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0397 - accuracy: 0.9881 - val_loss: 1.2207 - val_accuracy: 0.7545\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0415 - accuracy: 0.9861 - val_loss: 1.0660 - val_accuracy: 0.7670\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0271 - accuracy: 0.9935 - val_loss: 1.0662 - val_accuracy: 0.7692\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0334 - accuracy: 0.9892 - val_loss: 1.0838 - val_accuracy: 0.7681\n","{'loss': [0.24406929314136505, 0.1683802753686905, 0.16198968887329102, 0.16065548360347748, 0.15473665297031403, 0.155374675989151, 0.14683929085731506, 0.14163687825202942, 0.13686755299568176, 0.13746657967567444, 0.14132443070411682, 0.14847467839717865, 0.13906382024288177, 0.12569695711135864, 0.13351759314537048, 0.11961289495229721, 0.1101900041103363, 0.1253063976764679, 0.12854765355587006, 0.10392317175865173, 0.10535260289907455, 0.10177914798259735, 0.108162060379982, 0.10203344374895096, 0.09777745604515076, 0.0968455970287323, 0.10317769646644592, 0.09604626893997192, 0.10954567044973373, 0.09173933416604996, 0.0919906347990036, 0.08976021409034729, 0.09103134274482727, 0.08525704592466354, 0.10340793430805206, 0.10178347676992416, 0.09876503795385361, 0.09536394476890564, 0.08068852871656418, 0.0912787988781929, 0.08529270440340042, 0.08194083720445633, 0.09047843515872955, 0.08597918599843979, 0.06761825829744339, 0.07374649494886398, 0.0825890451669693, 0.06563695520162582, 0.06755088269710541, 0.07032254338264465, 0.09705498814582825, 0.11072977632284164, 0.08419483155012131, 0.06607288122177124, 0.07403566688299179, 0.0675043836236, 0.06885217130184174, 0.05670398846268654, 0.06039787456393242, 0.056792281568050385, 0.0629022940993309, 0.058217473328113556, 0.05724141001701355, 0.07116014510393143, 0.061977650970220566, 0.05439446121454239, 0.061429742723703384, 0.049664001911878586, 0.05496508255600929, 0.06308551132678986, 0.06899711489677429, 0.048487745225429535, 0.046621374785900116, 0.04635206609964371, 0.04366174340248108, 0.047534115612506866, 0.04679369926452637, 0.048021480441093445, 0.05005233734846115, 0.05328432470560074, 0.05405101925134659, 0.04184900224208832, 0.03881961479783058, 0.03736643120646477, 0.03964546322822571, 0.05063105374574661, 0.04888908192515373, 0.042403679341077805, 0.045510467141866684, 0.03577834740281105, 0.0440225824713707, 0.03604794666171074, 0.04238040745258331, 0.0361250638961792, 0.033707983791828156, 0.04118555411696434, 0.039730481803417206, 0.041490573436021805, 0.027063976973295212, 0.03341630846261978], 'accuracy': [0.9023768901824951, 0.9312393665313721, 0.9329372048377991, 0.9357668161392212, 0.9383135437965393, 0.9354838728904724, 0.9402942657470703, 0.9479343295097351, 0.9453876614570618, 0.9465195536613464, 0.9419921040534973, 0.9394453763961792, 0.9436898827552795, 0.9530277252197266, 0.9479343295097351, 0.9564233422279358, 0.9623655676841736, 0.9547255039215088, 0.9521788358688354, 0.9663271307945251, 0.9632145166397095, 0.9626485705375671, 0.9589700102806091, 0.9598188996315002, 0.9649122953414917, 0.963780403137207, 0.9663271307945251, 0.9632145166397095, 0.9640634059906006, 0.9694397449493408, 0.9677419066429138, 0.9691567420959473, 0.9680249094963074, 0.9734012484550476, 0.9575551748275757, 0.9615166783332825, 0.9666100740432739, 0.9595359563827515, 0.9717034697532654, 0.9680249094963074, 0.9697226881980896, 0.9714204668998718, 0.9694397449493408, 0.9688737988471985, 0.9770798087120056, 0.9770798087120056, 0.971137523651123, 0.9807583689689636, 0.9773627519607544, 0.9745330810546875, 0.9615166783332825, 0.9541596174240112, 0.9668930172920227, 0.979626476764679, 0.9742501378059387, 0.9756649732589722, 0.9784946441650391, 0.9807583689689636, 0.9804753661155701, 0.9847198724746704, 0.9782116413116455, 0.9807583689689636, 0.9824561476707458, 0.9697226881980896, 0.9782116413116455, 0.9835879802703857, 0.9790605306625366, 0.9841539263725281, 0.9844368696212769, 0.9790605306625366, 0.9728353023529053, 0.9847198724746704, 0.9864176511764526, 0.9867005944252014, 0.986983597278595, 0.9867005944252014, 0.9850028157234192, 0.9847198724746704, 0.9844368696212769, 0.9818902015686035, 0.9824561476707458, 0.986983597278595, 0.9883984327316284, 0.988964319229126, 0.9881154298782349, 0.983305037021637, 0.9818902015686035, 0.9867005944252014, 0.9830220937728882, 0.9883984327316284, 0.9858517050743103, 0.9892473220825195, 0.9872665405273438, 0.988964319229126, 0.9903791546821594, 0.9858517050743103, 0.9881154298782349, 0.9861347079277039, 0.9934917688369751, 0.9892473220825195], 'val_loss': [0.7051801085472107, 0.7052776217460632, 0.6971152424812317, 0.6958447098731995, 0.6898759007453918, 0.6853905320167542, 0.6682549118995667, 0.6753827929496765, 0.6556783318519592, 0.6514736413955688, 0.6229403614997864, 0.5999624729156494, 0.5972839593887329, 0.600476861000061, 0.5587723851203918, 0.5588039755821228, 0.5174188613891602, 0.5029247403144836, 0.5030874013900757, 0.5035555362701416, 0.4837190806865692, 0.5013487935066223, 0.5387216210365295, 0.5387410521507263, 0.5380872488021851, 0.5516647696495056, 0.5969173312187195, 0.6294560432434082, 0.6629242300987244, 0.7277782559394836, 0.6938738226890564, 0.7145184278488159, 0.7622336149215698, 0.7508803009986877, 0.7216347455978394, 0.7444292306900024, 0.7906115651130676, 0.787937581539154, 0.7910054326057434, 0.7774845361709595, 0.7736796140670776, 0.92180335521698, 0.8896310925483704, 0.8158852458000183, 0.8164263367652893, 0.803703248500824, 0.8509535789489746, 0.8583085536956787, 0.8225626349449158, 0.9017864465713501, 0.8120169043540955, 0.8540971279144287, 0.8286014795303345, 0.8512173891067505, 0.8267830610275269, 0.9257699251174927, 0.8434258103370667, 0.8555318713188171, 0.8669911623001099, 0.8627244234085083, 0.9417699575424194, 0.9057713150978088, 0.8921094536781311, 0.9266404509544373, 0.928386926651001, 0.9811684489250183, 0.9251648187637329, 0.9262956380844116, 0.9748303890228271, 0.9414140582084656, 0.928636372089386, 0.9494806528091431, 0.9366630911827087, 0.9359331130981445, 0.933621346950531, 0.9469414353370667, 0.9892758131027222, 0.9692195057868958, 1.062410593032837, 0.9715433120727539, 1.0271186828613281, 1.0322809219360352, 0.9991757273674011, 1.015737771987915, 0.9996799230575562, 1.0525407791137695, 0.9859335422515869, 1.0080333948135376, 1.0048298835754395, 1.035723328590393, 1.040444254875183, 1.1058412790298462, 1.0619949102401733, 1.0465104579925537, 1.0229105949401855, 1.042391300201416, 1.220732569694519, 1.0659544467926025, 1.066246747970581, 1.0837763547897339], 'val_accuracy': [0.49886876344680786, 0.49886876344680786, 0.5045248866081238, 0.5056561231613159, 0.5090497732162476, 0.5113122463226318, 0.529411792755127, 0.5214931964874268, 0.5395927429199219, 0.5441176295280457, 0.5848416090011597, 0.6436651349067688, 0.6255655884742737, 0.6119909286499023, 0.6742081642150879, 0.6742081642150879, 0.7296379804611206, 0.7658371329307556, 0.7613122463226318, 0.7409502267837524, 0.7816742062568665, 0.7692307829856873, 0.7680995464324951, 0.7884615659713745, 0.7952488660812378, 0.7986425161361694, 0.7850678563117981, 0.7952488660812378, 0.7861990928649902, 0.773755669593811, 0.7929864525794983, 0.8009049892425537, 0.7861990928649902, 0.7782805562019348, 0.7952488660812378, 0.7850678563117981, 0.7873303294181824, 0.7918552160263062, 0.779411792755127, 0.7873303294181824, 0.790723979473114, 0.7590497732162476, 0.773755669593811, 0.7839366793632507, 0.7782805562019348, 0.7850678563117981, 0.7873303294181824, 0.779411792755127, 0.7805429697036743, 0.779411792755127, 0.790723979473114, 0.7873303294181824, 0.7873303294181824, 0.7726244330406189, 0.7861990928649902, 0.7613122463226318, 0.7861990928649902, 0.7895927429199219, 0.7828054428100586, 0.779411792755127, 0.7601810097694397, 0.7613122463226318, 0.7816742062568665, 0.7748869061470032, 0.7771493196487427, 0.7613122463226318, 0.779411792755127, 0.7726244330406189, 0.7703620195388794, 0.7658371329307556, 0.773755669593811, 0.7760180830955505, 0.7782805562019348, 0.7714931964874268, 0.7748869061470032, 0.773755669593811, 0.7714931964874268, 0.7861990928649902, 0.7601810097694397, 0.7760180830955505, 0.7624434232711792, 0.7613122463226318, 0.779411792755127, 0.7680995464324951, 0.7680995464324951, 0.7782805562019348, 0.7771493196487427, 0.7760180830955505, 0.7748869061470032, 0.7760180830955505, 0.773755669593811, 0.7590497732162476, 0.766968309879303, 0.7703620195388794, 0.7816742062568665, 0.7748869061470032, 0.7545248866081238, 0.766968309879303, 0.7692307829856873, 0.7680995464324951]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.2703 - accuracy: 0.8982"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 53ms/step - loss: 0.2653 - accuracy: 0.9000 - val_loss: 0.7224 - val_accuracy: 0.4876\n","Epoch 2/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2070 - accuracy: 0.9181 - val_loss: 0.7203 - val_accuracy: 0.4886\n","Epoch 3/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1951 - accuracy: 0.9212 - val_loss: 0.7177 - val_accuracy: 0.4886\n","Epoch 4/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2004 - accuracy: 0.9212 - val_loss: 0.7121 - val_accuracy: 0.4928\n","Epoch 5/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.1819 - accuracy: 0.9292 - val_loss: 0.7048 - val_accuracy: 0.4948\n","Epoch 6/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1791 - accuracy: 0.9276 - val_loss: 0.7043 - val_accuracy: 0.4959\n","Epoch 7/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1902 - accuracy: 0.9194 - val_loss: 0.6951 - val_accuracy: 0.5031\n","Epoch 8/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1671 - accuracy: 0.9346 - val_loss: 0.6797 - val_accuracy: 0.5269\n","Epoch 9/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.1566 - accuracy: 0.9359 - val_loss: 0.6728 - val_accuracy: 0.5362\n","Epoch 10/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.1810 - accuracy: 0.9230 - val_loss: 0.6581 - val_accuracy: 0.5579\n","Epoch 11/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1779 - accuracy: 0.9287 - val_loss: 0.6683 - val_accuracy: 0.5527\n","Epoch 12/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.1567 - accuracy: 0.9393 - val_loss: 0.6519 - val_accuracy: 0.5888\n","Epoch 13/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.1457 - accuracy: 0.9447 - val_loss: 0.6494 - val_accuracy: 0.6002\n","Epoch 14/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1467 - accuracy: 0.9447 - val_loss: 0.6688 - val_accuracy: 0.5971\n","Epoch 15/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.1486 - accuracy: 0.9401 - val_loss: 0.6287 - val_accuracy: 0.6508\n","Epoch 16/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1381 - accuracy: 0.9450 - val_loss: 0.6382 - val_accuracy: 0.6550\n","Epoch 17/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1413 - accuracy: 0.9439 - val_loss: 0.6398 - val_accuracy: 0.6818\n","Epoch 18/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.1348 - accuracy: 0.9478 - val_loss: 0.6373 - val_accuracy: 0.6973\n","Epoch 19/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1297 - accuracy: 0.9530 - val_loss: 0.6778 - val_accuracy: 0.6942\n","Epoch 20/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1279 - accuracy: 0.9483 - val_loss: 0.6936 - val_accuracy: 0.7107\n","Epoch 21/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1428 - accuracy: 0.9393 - val_loss: 0.6937 - val_accuracy: 0.7221\n","Epoch 22/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1291 - accuracy: 0.9488 - val_loss: 0.7365 - val_accuracy: 0.7386\n","Epoch 23/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1212 - accuracy: 0.9527 - val_loss: 0.7717 - val_accuracy: 0.7417\n","Epoch 24/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1285 - accuracy: 0.9506 - val_loss: 0.8274 - val_accuracy: 0.7304\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1117 - accuracy: 0.9607 - val_loss: 0.9174 - val_accuracy: 0.7221\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1213 - accuracy: 0.9568 - val_loss: 0.8948 - val_accuracy: 0.7324\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1220 - accuracy: 0.9576 - val_loss: 0.9840 - val_accuracy: 0.7076\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1199 - accuracy: 0.9532 - val_loss: 0.9379 - val_accuracy: 0.7283\n","Epoch 29/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1174 - accuracy: 0.9556 - val_loss: 0.9940 - val_accuracy: 0.7304\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1233 - accuracy: 0.9527 - val_loss: 1.0180 - val_accuracy: 0.7293\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1145 - accuracy: 0.9545 - val_loss: 1.0216 - val_accuracy: 0.7314\n","Epoch 32/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1140 - accuracy: 0.9566 - val_loss: 0.9973 - val_accuracy: 0.7324\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1105 - accuracy: 0.9605 - val_loss: 1.0825 - val_accuracy: 0.7386\n","Epoch 34/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1250 - accuracy: 0.9501 - val_loss: 1.0666 - val_accuracy: 0.7242\n","Epoch 35/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1077 - accuracy: 0.9592 - val_loss: 1.0651 - val_accuracy: 0.7335\n","Epoch 36/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1169 - accuracy: 0.9550 - val_loss: 1.0551 - val_accuracy: 0.7180\n","Epoch 37/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0977 - accuracy: 0.9641 - val_loss: 1.1159 - val_accuracy: 0.7066\n","Epoch 38/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0992 - accuracy: 0.9623 - val_loss: 1.1094 - val_accuracy: 0.7169\n","Epoch 39/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0985 - accuracy: 0.9628 - val_loss: 1.0814 - val_accuracy: 0.7335\n","Epoch 40/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0931 - accuracy: 0.9656 - val_loss: 1.0913 - val_accuracy: 0.7335\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1056 - accuracy: 0.9625 - val_loss: 1.1158 - val_accuracy: 0.7242\n","Epoch 42/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0971 - accuracy: 0.9643 - val_loss: 1.1324 - val_accuracy: 0.7076\n","Epoch 43/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0882 - accuracy: 0.9682 - val_loss: 1.1251 - val_accuracy: 0.7221\n","Epoch 44/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0910 - accuracy: 0.9680 - val_loss: 1.1026 - val_accuracy: 0.7376\n","Epoch 45/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.1054 - accuracy: 0.9620 - val_loss: 1.1181 - val_accuracy: 0.7273\n","Epoch 46/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0932 - accuracy: 0.9672 - val_loss: 1.1267 - val_accuracy: 0.7252\n","Epoch 47/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.1009 - accuracy: 0.9607 - val_loss: 1.1416 - val_accuracy: 0.7324\n","Epoch 48/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0974 - accuracy: 0.9651 - val_loss: 1.1410 - val_accuracy: 0.7293\n","Epoch 49/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0893 - accuracy: 0.9667 - val_loss: 1.1556 - val_accuracy: 0.7231\n","Epoch 50/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.1015 - accuracy: 0.9618 - val_loss: 1.1686 - val_accuracy: 0.7304\n","Epoch 51/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0875 - accuracy: 0.9685 - val_loss: 1.2027 - val_accuracy: 0.7159\n","Epoch 52/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0939 - accuracy: 0.9638 - val_loss: 1.1805 - val_accuracy: 0.7283\n","Epoch 53/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.0904 - accuracy: 0.9620 - val_loss: 1.2365 - val_accuracy: 0.7273\n","Epoch 54/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.1016 - accuracy: 0.9615 - val_loss: 1.2499 - val_accuracy: 0.7087\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0868 - accuracy: 0.9677 - val_loss: 1.2394 - val_accuracy: 0.7221\n","Epoch 56/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0780 - accuracy: 0.9739 - val_loss: 1.2228 - val_accuracy: 0.7180\n","Epoch 57/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0750 - accuracy: 0.9716 - val_loss: 1.2391 - val_accuracy: 0.7252\n","Epoch 58/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0763 - accuracy: 0.9731 - val_loss: 1.2570 - val_accuracy: 0.7242\n","Epoch 59/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0910 - accuracy: 0.9687 - val_loss: 1.3604 - val_accuracy: 0.7045\n","Epoch 60/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1083 - accuracy: 0.9540 - val_loss: 1.2122 - val_accuracy: 0.7180\n","Epoch 61/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0831 - accuracy: 0.9711 - val_loss: 1.1836 - val_accuracy: 0.7190\n","Epoch 62/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0734 - accuracy: 0.9747 - val_loss: 1.2152 - val_accuracy: 0.7180\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0653 - accuracy: 0.9788 - val_loss: 1.2416 - val_accuracy: 0.7293\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0679 - accuracy: 0.9742 - val_loss: 1.2699 - val_accuracy: 0.7169\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0700 - accuracy: 0.9770 - val_loss: 1.2984 - val_accuracy: 0.7138\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0754 - accuracy: 0.9713 - val_loss: 1.3370 - val_accuracy: 0.7138\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0716 - accuracy: 0.9752 - val_loss: 1.3594 - val_accuracy: 0.6952\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0741 - accuracy: 0.9726 - val_loss: 1.2985 - val_accuracy: 0.7200\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0624 - accuracy: 0.9786 - val_loss: 1.3008 - val_accuracy: 0.7149\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0678 - accuracy: 0.9780 - val_loss: 1.2813 - val_accuracy: 0.7180\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0700 - accuracy: 0.9729 - val_loss: 1.3911 - val_accuracy: 0.6983\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0937 - accuracy: 0.9677 - val_loss: 1.3087 - val_accuracy: 0.7159\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0664 - accuracy: 0.9757 - val_loss: 1.3030 - val_accuracy: 0.7231\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0585 - accuracy: 0.9811 - val_loss: 1.3089 - val_accuracy: 0.7242\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0583 - accuracy: 0.9817 - val_loss: 1.3502 - val_accuracy: 0.7190\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0595 - accuracy: 0.9793 - val_loss: 1.3206 - val_accuracy: 0.7097\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0654 - accuracy: 0.9775 - val_loss: 1.3454 - val_accuracy: 0.7211\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0602 - accuracy: 0.9798 - val_loss: 1.3836 - val_accuracy: 0.7107\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0653 - accuracy: 0.9762 - val_loss: 1.4246 - val_accuracy: 0.7159\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1240 - accuracy: 0.9486 - val_loss: 1.4146 - val_accuracy: 0.6870\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0771 - accuracy: 0.9698 - val_loss: 1.3817 - val_accuracy: 0.7014\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0579 - accuracy: 0.9801 - val_loss: 1.3590 - val_accuracy: 0.7087\n","Epoch 83/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0535 - accuracy: 0.9819 - val_loss: 1.4110 - val_accuracy: 0.7159\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0577 - accuracy: 0.9806 - val_loss: 1.3832 - val_accuracy: 0.7159\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0566 - accuracy: 0.9804 - val_loss: 1.3670 - val_accuracy: 0.7190\n","Epoch 86/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0582 - accuracy: 0.9778 - val_loss: 1.4108 - val_accuracy: 0.7045\n","Epoch 87/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0587 - accuracy: 0.9801 - val_loss: 1.3863 - val_accuracy: 0.7056\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0534 - accuracy: 0.9832 - val_loss: 1.3953 - val_accuracy: 0.7097\n","Epoch 89/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0572 - accuracy: 0.9798 - val_loss: 1.4289 - val_accuracy: 0.7128\n","Epoch 90/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0628 - accuracy: 0.9791 - val_loss: 1.5201 - val_accuracy: 0.6921\n","Epoch 91/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0506 - accuracy: 0.9829 - val_loss: 1.4651 - val_accuracy: 0.7138\n","Epoch 92/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0564 - accuracy: 0.9793 - val_loss: 1.5565 - val_accuracy: 0.7004\n","Epoch 93/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0738 - accuracy: 0.9749 - val_loss: 1.4445 - val_accuracy: 0.7035\n","Epoch 94/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0604 - accuracy: 0.9801 - val_loss: 1.4270 - val_accuracy: 0.7169\n","Epoch 95/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0480 - accuracy: 0.9840 - val_loss: 1.4630 - val_accuracy: 0.7025\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0435 - accuracy: 0.9881 - val_loss: 1.4657 - val_accuracy: 0.7056\n","Epoch 97/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0484 - accuracy: 0.9842 - val_loss: 1.5007 - val_accuracy: 0.7107\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0468 - accuracy: 0.9850 - val_loss: 1.4643 - val_accuracy: 0.7128\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0482 - accuracy: 0.9845 - val_loss: 1.6014 - val_accuracy: 0.6942\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0462 - accuracy: 0.9840 - val_loss: 1.4908 - val_accuracy: 0.7107\n","{'loss': [0.265270859003067, 0.2069903016090393, 0.19511547684669495, 0.2004294991493225, 0.18192772567272186, 0.17906761169433594, 0.19023261964321136, 0.16710269451141357, 0.15655671060085297, 0.18104548752307892, 0.1779198795557022, 0.15669465065002441, 0.14572063088417053, 0.14665469527244568, 0.14857232570648193, 0.13810600340366364, 0.14127252995967865, 0.1347949057817459, 0.12968996167182922, 0.12787047028541565, 0.14283031225204468, 0.12906432151794434, 0.12124190479516983, 0.12845610082149506, 0.11169068515300751, 0.12129349261522293, 0.12204515933990479, 0.11985420435667038, 0.11738040298223495, 0.12330905348062515, 0.11450348794460297, 0.11401093006134033, 0.11050941795110703, 0.12498940527439117, 0.10768582671880722, 0.11690393835306168, 0.09770845621824265, 0.09920734167098999, 0.09848615527153015, 0.09307100623846054, 0.1055789440870285, 0.09708736836910248, 0.08823858946561813, 0.09095928072929382, 0.10544481128454208, 0.0931728258728981, 0.10092484205961227, 0.09740431606769562, 0.08932990580797195, 0.10145298391580582, 0.08749213814735413, 0.09390237927436829, 0.09042637050151825, 0.10158178210258484, 0.08678025752305984, 0.07804977893829346, 0.07498808950185776, 0.07631193846464157, 0.09103533625602722, 0.10831669718027115, 0.08314875513315201, 0.07340911775827408, 0.06530062109231949, 0.0679420679807663, 0.07004406303167343, 0.07540339231491089, 0.07156528532505035, 0.0741494745016098, 0.06244286149740219, 0.06781303137540817, 0.06998363882303238, 0.09365914762020111, 0.06637663394212723, 0.05850750952959061, 0.05827996879816055, 0.059507254511117935, 0.06536994874477386, 0.06023351848125458, 0.06531026214361191, 0.1239977702498436, 0.07710378617048264, 0.05790436640381813, 0.053536687046289444, 0.05767948552966118, 0.0565517321228981, 0.058207739144563675, 0.05873560160398483, 0.05337667465209961, 0.05723753198981285, 0.06280449777841568, 0.05061262100934982, 0.05638204887509346, 0.07375172525644302, 0.060384877026081085, 0.04801753908395767, 0.04347081109881401, 0.0484444722533226, 0.046846602112054825, 0.04824502766132355, 0.04624542221426964], 'accuracy': [0.8999999761581421, 0.9180878400802612, 0.9211886525154114, 0.9211886525154114, 0.9291989803314209, 0.9276486039161682, 0.9193798303604126, 0.9346253275871277, 0.935917317867279, 0.9229974150657654, 0.9286821484565735, 0.9392764568328857, 0.9447028636932373, 0.9447028636932373, 0.9400516748428345, 0.9449612498283386, 0.9439276456832886, 0.9478036165237427, 0.9529715776443481, 0.9483203887939453, 0.9392764568328857, 0.9488372206687927, 0.9527131915092468, 0.9506459832191467, 0.9607235193252563, 0.9568475484848022, 0.957622766494751, 0.9532299637794495, 0.9555555582046509, 0.9527131915092468, 0.9545219540596008, 0.9565891623497009, 0.960465133190155, 0.9501292109489441, 0.9591731429100037, 0.9550387859344482, 0.964082658290863, 0.962273895740509, 0.9627906680107117, 0.9656330943107605, 0.9625322818756104, 0.9643411040306091, 0.9682170748710632, 0.9679586291313171, 0.9620155096054077, 0.9671834707260132, 0.9607235193252563, 0.9651162624359131, 0.9666666388511658, 0.9617571234703064, 0.9684754610061646, 0.9638242721557617, 0.9620155096054077, 0.9614987373352051, 0.9677002429962158, 0.9739018082618713, 0.9715762138366699, 0.9731265902519226, 0.9687338471412659, 0.9540051817893982, 0.9710594415664673, 0.9746770262718201, 0.9788113832473755, 0.9741601943969727, 0.9770025610923767, 0.9713178277015686, 0.9751937985420227, 0.97260981798172, 0.9785529971122742, 0.9780361652374268, 0.9728682041168213, 0.9677002429962158, 0.9757105708122253, 0.9811369776725769, 0.9816537499427795, 0.9793281555175781, 0.9775193929672241, 0.9798449873924255, 0.9762274026870728, 0.9485788345336914, 0.9697674512863159, 0.9801033735275269, 0.9819121360778809, 0.9806201457977295, 0.9803617596626282, 0.9777777791023254, 0.9801033735275269, 0.9832041263580322, 0.9798449873924255, 0.9790697693824768, 0.9829457402229309, 0.9793281555175781, 0.9749354124069214, 0.9801033735275269, 0.983979344367981, 0.9881137013435364, 0.9842377305030823, 0.985012948513031, 0.9844961166381836, 0.983979344367981], 'val_loss': [0.7224319577217102, 0.7202685475349426, 0.7177340984344482, 0.7120752930641174, 0.7048344612121582, 0.7043166756629944, 0.6951133012771606, 0.6797386407852173, 0.6728345155715942, 0.658143937587738, 0.6683400273323059, 0.6519076824188232, 0.6493813991546631, 0.6688224673271179, 0.6287006139755249, 0.6381692886352539, 0.6397707462310791, 0.6373433470726013, 0.6778233051300049, 0.6936397552490234, 0.6937082409858704, 0.7365459203720093, 0.7717337012290955, 0.8274368047714233, 0.9174020886421204, 0.8948113322257996, 0.9840444326400757, 0.93793785572052, 0.9940451979637146, 1.0179873704910278, 1.0215792655944824, 0.9973493218421936, 1.0824576616287231, 1.0666273832321167, 1.065104365348816, 1.055090069770813, 1.1158934831619263, 1.1093637943267822, 1.0813666582107544, 1.0913112163543701, 1.1158227920532227, 1.132354736328125, 1.1250884532928467, 1.102635383605957, 1.1180599927902222, 1.1266883611679077, 1.1416144371032715, 1.1409833431243896, 1.1556090116500854, 1.168619155883789, 1.2027323246002197, 1.180462121963501, 1.2364869117736816, 1.2498929500579834, 1.2394424676895142, 1.222800374031067, 1.2391031980514526, 1.2570422887802124, 1.3604297637939453, 1.2122336626052856, 1.1835647821426392, 1.2152483463287354, 1.2415516376495361, 1.2699484825134277, 1.2983524799346924, 1.337014079093933, 1.3594274520874023, 1.2985304594039917, 1.300769567489624, 1.281347632408142, 1.3910759687423706, 1.3086854219436646, 1.3029638528823853, 1.3089076280593872, 1.3502289056777954, 1.3205639123916626, 1.3453737497329712, 1.3836275339126587, 1.4245935678482056, 1.4146091938018799, 1.3817428350448608, 1.3590407371520996, 1.4109911918640137, 1.3832143545150757, 1.3670001029968262, 1.410774827003479, 1.3863048553466797, 1.395288109779358, 1.4289051294326782, 1.5201389789581299, 1.4651497602462769, 1.5565013885498047, 1.444490671157837, 1.4270405769348145, 1.4630448818206787, 1.4657222032546997, 1.5007470846176147, 1.4642682075500488, 1.6013622283935547, 1.4907816648483276], 'val_accuracy': [0.4876033067703247, 0.4886363744735718, 0.4886363744735718, 0.4927685856819153, 0.4948347210884094, 0.4958677589893341, 0.5030992031097412, 0.5268595218658447, 0.5361570119857788, 0.557851254940033, 0.5526859760284424, 0.5888429880142212, 0.6002066135406494, 0.5971074104309082, 0.6508264541625977, 0.6549586653709412, 0.6818181872367859, 0.6973140239715576, 0.6942148804664612, 0.71074378490448, 0.7221074104309082, 0.7386363744735718, 0.7417355179786682, 0.73037189245224, 0.7221074104309082, 0.7324380278587341, 0.7076446413993835, 0.7283057570457458, 0.73037189245224, 0.7293388247489929, 0.7314049601554871, 0.7324380278587341, 0.7386363744735718, 0.7241735458374023, 0.7334710955619812, 0.7179751992225647, 0.7066115736961365, 0.7169421315193176, 0.7334710955619812, 0.7334710955619812, 0.7241735458374023, 0.7076446413993835, 0.7221074104309082, 0.7376033067703247, 0.7272727489471436, 0.7252066135406494, 0.7324380278587341, 0.7293388247489929, 0.7231404781341553, 0.73037189245224, 0.7159090638160706, 0.7283057570457458, 0.7272727489471436, 0.7086777091026306, 0.7221074104309082, 0.7179751992225647, 0.7252066135406494, 0.7241735458374023, 0.7045454382896423, 0.7179751992225647, 0.7190082669258118, 0.7179751992225647, 0.7293388247489929, 0.7169421315193176, 0.7138429880142212, 0.7138429880142212, 0.6952479481697083, 0.7200413346290588, 0.7148760557174683, 0.7179751992225647, 0.6983470916748047, 0.7159090638160706, 0.7231404781341553, 0.7241735458374023, 0.7190082669258118, 0.7097107172012329, 0.7210744023323059, 0.71074378490448, 0.7159090638160706, 0.6869834661483765, 0.7014462947845459, 0.7086777091026306, 0.7159090638160706, 0.7159090638160706, 0.7190082669258118, 0.7045454382896423, 0.7055785059928894, 0.7097107172012329, 0.7128099203109741, 0.692148745059967, 0.7138429880142212, 0.7004132270812988, 0.7035123705863953, 0.7169421315193176, 0.702479362487793, 0.7055785059928894, 0.71074378490448, 0.7128099203109741, 0.6942148804664612, 0.71074378490448]}\n","32/32 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/29 [========================>.....] - ETA: 0s - loss: 0.1694 - accuracy: 0.9378"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 9s 56ms/step - loss: 0.1570 - accuracy: 0.9434 - val_loss: 0.7246 - val_accuracy: 0.4871\n","Epoch 2/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1053 - accuracy: 0.9599 - val_loss: 0.7132 - val_accuracy: 0.4871\n","Epoch 3/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0973 - accuracy: 0.9631 - val_loss: 0.7060 - val_accuracy: 0.4892\n","Epoch 4/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0986 - accuracy: 0.9626 - val_loss: 0.6998 - val_accuracy: 0.4946\n","Epoch 5/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0815 - accuracy: 0.9696 - val_loss: 0.6916 - val_accuracy: 0.4989\n","Epoch 6/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0790 - accuracy: 0.9690 - val_loss: 0.6851 - val_accuracy: 0.5097\n","Epoch 7/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.0753 - accuracy: 0.9714 - val_loss: 0.6652 - val_accuracy: 0.5216\n","Epoch 8/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0695 - accuracy: 0.9749 - val_loss: 0.6557 - val_accuracy: 0.5291\n","Epoch 9/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0721 - accuracy: 0.9744 - val_loss: 0.6333 - val_accuracy: 0.5733\n","Epoch 10/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.0726 - accuracy: 0.9720 - val_loss: 0.6184 - val_accuracy: 0.5894\n","Epoch 11/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.0752 - accuracy: 0.9714 - val_loss: 0.6146 - val_accuracy: 0.6121\n","Epoch 12/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0647 - accuracy: 0.9787 - val_loss: 0.5798 - val_accuracy: 0.6552\n","Epoch 13/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0616 - accuracy: 0.9784 - val_loss: 0.5662 - val_accuracy: 0.6703\n","Epoch 14/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0653 - accuracy: 0.9766 - val_loss: 0.5283 - val_accuracy: 0.7446\n","Epoch 15/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0719 - accuracy: 0.9712 - val_loss: 0.5217 - val_accuracy: 0.7403\n","Epoch 16/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0675 - accuracy: 0.9744 - val_loss: 0.5022 - val_accuracy: 0.7629\n","Epoch 17/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0599 - accuracy: 0.9779 - val_loss: 0.4908 - val_accuracy: 0.7608\n","Epoch 18/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0566 - accuracy: 0.9811 - val_loss: 0.4723 - val_accuracy: 0.7974\n","Epoch 19/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0545 - accuracy: 0.9822 - val_loss: 0.5262 - val_accuracy: 0.7532\n","Epoch 20/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0530 - accuracy: 0.9830 - val_loss: 0.4731 - val_accuracy: 0.8060\n","Epoch 21/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0489 - accuracy: 0.9849 - val_loss: 0.5040 - val_accuracy: 0.8060\n","Epoch 22/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0564 - accuracy: 0.9795 - val_loss: 0.5013 - val_accuracy: 0.8200\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0519 - accuracy: 0.9833 - val_loss: 0.5702 - val_accuracy: 0.8006\n","Epoch 24/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0526 - accuracy: 0.9822 - val_loss: 0.5728 - val_accuracy: 0.8265\n","Epoch 25/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0450 - accuracy: 0.9844 - val_loss: 0.5786 - val_accuracy: 0.8276\n","Epoch 26/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0470 - accuracy: 0.9852 - val_loss: 0.6240 - val_accuracy: 0.8254\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0508 - accuracy: 0.9828 - val_loss: 0.6520 - val_accuracy: 0.8114\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0457 - accuracy: 0.9836 - val_loss: 0.7227 - val_accuracy: 0.8093\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0490 - accuracy: 0.9830 - val_loss: 0.7150 - val_accuracy: 0.8233\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0491 - accuracy: 0.9833 - val_loss: 0.7202 - val_accuracy: 0.8222\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0479 - accuracy: 0.9871 - val_loss: 0.7285 - val_accuracy: 0.8168\n","Epoch 32/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0473 - accuracy: 0.9838 - val_loss: 0.7619 - val_accuracy: 0.8190\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0663 - accuracy: 0.9774 - val_loss: 0.7900 - val_accuracy: 0.8114\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0463 - accuracy: 0.9838 - val_loss: 0.7637 - val_accuracy: 0.8222\n","Epoch 35/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0431 - accuracy: 0.9857 - val_loss: 0.8050 - val_accuracy: 0.8190\n","Epoch 36/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0400 - accuracy: 0.9884 - val_loss: 0.8048 - val_accuracy: 0.8179\n","Epoch 37/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0366 - accuracy: 0.9895 - val_loss: 0.8244 - val_accuracy: 0.8103\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0495 - accuracy: 0.9822 - val_loss: 0.8592 - val_accuracy: 0.8028\n","Epoch 39/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0389 - accuracy: 0.9871 - val_loss: 0.8228 - val_accuracy: 0.8147\n","Epoch 40/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0421 - accuracy: 0.9844 - val_loss: 0.8236 - val_accuracy: 0.8233\n","Epoch 41/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0441 - accuracy: 0.9830 - val_loss: 0.8919 - val_accuracy: 0.7953\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0519 - accuracy: 0.9822 - val_loss: 0.8384 - val_accuracy: 0.8136\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0513 - accuracy: 0.9833 - val_loss: 0.9673 - val_accuracy: 0.7845\n","Epoch 44/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0496 - accuracy: 0.9841 - val_loss: 0.9027 - val_accuracy: 0.7953\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0450 - accuracy: 0.9863 - val_loss: 0.8451 - val_accuracy: 0.8028\n","Epoch 46/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0377 - accuracy: 0.9884 - val_loss: 0.8622 - val_accuracy: 0.8093\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0355 - accuracy: 0.9881 - val_loss: 0.9863 - val_accuracy: 0.7823\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0326 - accuracy: 0.9914 - val_loss: 0.8866 - val_accuracy: 0.7985\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0299 - accuracy: 0.9925 - val_loss: 0.8847 - val_accuracy: 0.8071\n","Epoch 50/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0376 - accuracy: 0.9876 - val_loss: 0.8914 - val_accuracy: 0.8017\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0442 - accuracy: 0.9838 - val_loss: 0.9011 - val_accuracy: 0.8017\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0401 - accuracy: 0.9890 - val_loss: 0.8828 - val_accuracy: 0.8103\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0346 - accuracy: 0.9916 - val_loss: 0.8893 - val_accuracy: 0.8071\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0381 - accuracy: 0.9873 - val_loss: 0.9033 - val_accuracy: 0.8060\n","Epoch 55/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0383 - accuracy: 0.9860 - val_loss: 0.8981 - val_accuracy: 0.8071\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0312 - accuracy: 0.9895 - val_loss: 0.9056 - val_accuracy: 0.8050\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0428 - accuracy: 0.9846 - val_loss: 1.0114 - val_accuracy: 0.7802\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0693 - accuracy: 0.9766 - val_loss: 0.9383 - val_accuracy: 0.8039\n","Epoch 59/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0463 - accuracy: 0.9855 - val_loss: 0.9270 - val_accuracy: 0.8125\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0370 - accuracy: 0.9895 - val_loss: 0.9361 - val_accuracy: 0.8039\n","Epoch 61/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0318 - accuracy: 0.9903 - val_loss: 0.9073 - val_accuracy: 0.8093\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0298 - accuracy: 0.9895 - val_loss: 0.9207 - val_accuracy: 0.8071\n","Epoch 63/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0254 - accuracy: 0.9927 - val_loss: 0.9318 - val_accuracy: 0.8093\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0284 - accuracy: 0.9916 - val_loss: 0.9488 - val_accuracy: 0.8114\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0317 - accuracy: 0.9916 - val_loss: 0.9666 - val_accuracy: 0.7899\n","Epoch 66/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0356 - accuracy: 0.9879 - val_loss: 0.9549 - val_accuracy: 0.8050\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0294 - accuracy: 0.9922 - val_loss: 0.9888 - val_accuracy: 0.7963\n","Epoch 68/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0278 - accuracy: 0.9925 - val_loss: 0.9557 - val_accuracy: 0.7974\n","Epoch 69/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0256 - accuracy: 0.9922 - val_loss: 0.9534 - val_accuracy: 0.8093\n","Epoch 70/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0228 - accuracy: 0.9946 - val_loss: 0.9506 - val_accuracy: 0.8114\n","Epoch 71/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0286 - accuracy: 0.9903 - val_loss: 0.9324 - val_accuracy: 0.8050\n","Epoch 72/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0245 - accuracy: 0.9922 - val_loss: 0.9519 - val_accuracy: 0.7996\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0229 - accuracy: 0.9946 - val_loss: 0.9406 - val_accuracy: 0.8093\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0208 - accuracy: 0.9952 - val_loss: 0.9544 - val_accuracy: 0.7931\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 0.9536 - val_accuracy: 0.8179\n","Epoch 76/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0304 - accuracy: 0.9898 - val_loss: 0.9997 - val_accuracy: 0.7996\n","Epoch 77/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0247 - accuracy: 0.9927 - val_loss: 0.9779 - val_accuracy: 0.7996\n","Epoch 78/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0273 - accuracy: 0.9914 - val_loss: 0.9656 - val_accuracy: 0.8071\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0228 - accuracy: 0.9943 - val_loss: 1.0629 - val_accuracy: 0.7909\n","Epoch 80/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0339 - accuracy: 0.9884 - val_loss: 1.0670 - val_accuracy: 0.7888\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 0.9724 - val_accuracy: 0.8071\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.9870 - val_accuracy: 0.8006\n","Epoch 83/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0198 - accuracy: 0.9943 - val_loss: 0.9869 - val_accuracy: 0.8039\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0212 - accuracy: 0.9930 - val_loss: 1.0016 - val_accuracy: 0.8060\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0166 - accuracy: 0.9954 - val_loss: 0.9867 - val_accuracy: 0.8006\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0335 - accuracy: 0.9906 - val_loss: 1.0345 - val_accuracy: 0.7985\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0340 - accuracy: 0.9911 - val_loss: 1.0044 - val_accuracy: 0.7985\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0269 - accuracy: 0.9908 - val_loss: 0.9937 - val_accuracy: 0.8017\n","Epoch 89/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0236 - accuracy: 0.9922 - val_loss: 1.0084 - val_accuracy: 0.7985\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0322 - accuracy: 0.9860 - val_loss: 1.0288 - val_accuracy: 0.7942\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 1.0386 - val_accuracy: 0.7845\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0317 - accuracy: 0.9900 - val_loss: 1.0539 - val_accuracy: 0.7931\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0324 - accuracy: 0.9873 - val_loss: 1.0775 - val_accuracy: 0.7856\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0293 - accuracy: 0.9914 - val_loss: 1.0211 - val_accuracy: 0.8071\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0316 - accuracy: 0.9876 - val_loss: 1.0818 - val_accuracy: 0.7920\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 1.0408 - val_accuracy: 0.7920\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0194 - accuracy: 0.9957 - val_loss: 1.0650 - val_accuracy: 0.8006\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0177 - accuracy: 0.9954 - val_loss: 1.0640 - val_accuracy: 0.8017\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0181 - accuracy: 0.9938 - val_loss: 1.0175 - val_accuracy: 0.7963\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0163 - accuracy: 0.9938 - val_loss: 1.0453 - val_accuracy: 0.7974\n","{'loss': [0.15702328085899353, 0.10528597980737686, 0.09726251661777496, 0.0985817164182663, 0.08145087212324142, 0.07904532551765442, 0.07527710497379303, 0.06947747617959976, 0.07208982855081558, 0.07260467112064362, 0.07522426545619965, 0.06470205634832382, 0.061589837074279785, 0.06532144546508789, 0.07194405794143677, 0.06753236800432205, 0.05989895015954971, 0.05664929002523422, 0.05450670048594475, 0.0529940240085125, 0.04888736084103584, 0.05642805993556976, 0.0519229993224144, 0.052565716207027435, 0.04503581300377846, 0.04703299701213837, 0.050775423645973206, 0.04572233557701111, 0.04901396110653877, 0.04910733923316002, 0.04792735353112221, 0.04725019633769989, 0.06632205843925476, 0.04626878350973129, 0.04307311400771141, 0.03998183831572533, 0.03659990057349205, 0.04952632263302803, 0.03891129046678543, 0.04205106198787689, 0.04406701400876045, 0.051879674196243286, 0.0513065941631794, 0.04956453666090965, 0.045037027448415756, 0.03772297501564026, 0.03545503690838814, 0.0326177142560482, 0.0299230869859457, 0.03759722784161568, 0.04423389583826065, 0.04013267531991005, 0.03455158695578575, 0.03810209408402443, 0.038330722600221634, 0.031184177845716476, 0.04279882460832596, 0.06927698105573654, 0.04625409096479416, 0.03696532920002937, 0.03182131052017212, 0.029801471158862114, 0.025391530245542526, 0.028393054381012917, 0.031697746366262436, 0.03560655564069748, 0.02943696267902851, 0.02776215597987175, 0.025579432025551796, 0.022828493267297745, 0.028638748452067375, 0.024466725066304207, 0.0228811576962471, 0.020804353058338165, 0.022930987179279327, 0.03037874400615692, 0.024684669449925423, 0.027299337089061737, 0.02282726764678955, 0.033944401890039444, 0.023120684549212456, 0.02323557808995247, 0.019790472462773323, 0.021194320172071457, 0.016560262069106102, 0.033475250005722046, 0.03399460390210152, 0.0268727894872427, 0.02358279377222061, 0.03221311792731285, 0.019705966114997864, 0.03167986124753952, 0.032405756413936615, 0.029329147189855576, 0.03159995377063751, 0.020145101472735405, 0.01936250738799572, 0.017682233825325966, 0.018093446269631386, 0.016309943050146103], 'accuracy': [0.9434267282485962, 0.9598599076271057, 0.9630926847457886, 0.962553858757019, 0.9695581793785095, 0.9690194129943848, 0.9714439511299133, 0.974946141242981, 0.9744073152542114, 0.9719827771186829, 0.9714439511299133, 0.9787176847457886, 0.9784482717514038, 0.9765625, 0.9711745977401733, 0.9744073152542114, 0.977909505367279, 0.9811422228813171, 0.9822198152542114, 0.983027994632721, 0.9849137663841248, 0.9795258641242981, 0.9832974076271057, 0.9822198152542114, 0.984375, 0.9851831793785095, 0.982758641242981, 0.9835668206214905, 0.983027994632721, 0.9832974076271057, 0.9870689511299133, 0.9838362336158752, 0.9773706793785095, 0.9838362336158752, 0.985722005367279, 0.9884159564971924, 0.9894935488700867, 0.9822198152542114, 0.9870689511299133, 0.984375, 0.983027994632721, 0.9822198152542114, 0.9832974076271057, 0.9841055870056152, 0.9862607717514038, 0.9884159564971924, 0.9881465435028076, 0.9913793206214905, 0.9924569129943848, 0.9876077771186829, 0.9838362336158752, 0.9889547228813171, 0.9916487336158752, 0.9873383641242981, 0.985991358757019, 0.9894935488700867, 0.9846444129943848, 0.9765625, 0.9854525923728943, 0.9894935488700867, 0.9903017282485962, 0.9894935488700867, 0.9927262663841248, 0.9916487336158752, 0.9916487336158752, 0.9878771305084229, 0.9921875, 0.9924569129943848, 0.9921875, 0.9946120977401733, 0.9903017282485962, 0.9921875, 0.9946120977401733, 0.9951508641242981, 0.9932650923728943, 0.9897629022598267, 0.9927262663841248, 0.9913793206214905, 0.9943426847457886, 0.9884159564971924, 0.9932650923728943, 0.9927262663841248, 0.9943426847457886, 0.9929956793785095, 0.9954202771186829, 0.990571141242981, 0.9911099076271057, 0.990840494632721, 0.9921875, 0.985991358757019, 0.993803858757019, 0.9900323152542114, 0.9873383641242981, 0.9913793206214905, 0.9876077771186829, 0.9932650923728943, 0.9956896305084229, 0.9954202771186829, 0.993803858757019, 0.993803858757019], 'val_loss': [0.7245903015136719, 0.713209331035614, 0.7059663534164429, 0.6997509002685547, 0.6915944218635559, 0.6851106286048889, 0.6651667356491089, 0.6556560397148132, 0.633328378200531, 0.6184268593788147, 0.6146462559700012, 0.5798195600509644, 0.5662289261817932, 0.5283017158508301, 0.5217498540878296, 0.5021698474884033, 0.49079033732414246, 0.4722646176815033, 0.5262232422828674, 0.47313401103019714, 0.5040087699890137, 0.5012969970703125, 0.5702419877052307, 0.5728273987770081, 0.5785778164863586, 0.6239997744560242, 0.6519697904586792, 0.7226642370223999, 0.714966356754303, 0.720220685005188, 0.7284539341926575, 0.7619478702545166, 0.7900245189666748, 0.7637382745742798, 0.8049746751785278, 0.8048076033592224, 0.8243514895439148, 0.8591868877410889, 0.8227548003196716, 0.8235870003700256, 0.8918585777282715, 0.8384254574775696, 0.9672905206680298, 0.9027363061904907, 0.8451160788536072, 0.8621945977210999, 0.9862927794456482, 0.886604368686676, 0.8847469091415405, 0.8914362788200378, 0.9010675549507141, 0.8828103542327881, 0.8893476128578186, 0.9032783508300781, 0.8981187343597412, 0.905612051486969, 1.0114173889160156, 0.9383093118667603, 0.9269903898239136, 0.9361280202865601, 0.9073185324668884, 0.9207056760787964, 0.9317500591278076, 0.9487952589988708, 0.966640830039978, 0.9549394249916077, 0.9887810945510864, 0.9556549787521362, 0.9534189105033875, 0.9506125450134277, 0.9323827624320984, 0.9518775343894958, 0.9406077861785889, 0.9543765783309937, 0.9536349773406982, 0.9997014403343201, 0.9778819680213928, 0.9656280875205994, 1.0629276037216187, 1.0670121908187866, 0.9724457859992981, 0.986954391002655, 0.9869270324707031, 1.0015608072280884, 0.9866504073143005, 1.0345406532287598, 1.00444495677948, 0.9937286972999573, 1.0084190368652344, 1.028766393661499, 1.0386021137237549, 1.0538651943206787, 1.0774638652801514, 1.0210788249969482, 1.0817787647247314, 1.0407955646514893, 1.0649640560150146, 1.0640462636947632, 1.0175058841705322, 1.0453473329544067], 'val_accuracy': [0.48706895112991333, 0.48706895112991333, 0.4892241358757019, 0.49461206793785095, 0.4989224076271057, 0.5096982717514038, 0.5215517282485962, 0.5290948152542114, 0.5732758641242981, 0.5894396305084229, 0.6120689511299133, 0.6551724076271057, 0.670258641242981, 0.7446120977401733, 0.7403017282485962, 0.7629310488700867, 0.7607758641242981, 0.7974137663841248, 0.7532327771186829, 0.806034505367279, 0.806034505367279, 0.8200430870056152, 0.8006465435028076, 0.826508641242981, 0.8275862336158752, 0.8254310488700867, 0.8114224076271057, 0.8092672228813171, 0.8232758641242981, 0.8221982717514038, 0.8168103694915771, 0.818965494632721, 0.8114224076271057, 0.8221982717514038, 0.818965494632721, 0.8178879022598267, 0.8103448152542114, 0.8028017282485962, 0.8146551847457886, 0.8232758641242981, 0.795258641242981, 0.8135775923728943, 0.7844827771186829, 0.795258641242981, 0.8028017282485962, 0.8092672228813171, 0.7823275923728943, 0.798491358757019, 0.8071120977401733, 0.8017241358757019, 0.8017241358757019, 0.8103448152542114, 0.8071120977401733, 0.806034505367279, 0.8071120977401733, 0.8049569129943848, 0.7801724076271057, 0.8038793206214905, 0.8125, 0.8038793206214905, 0.8092672228813171, 0.8071120977401733, 0.8092672228813171, 0.8114224076271057, 0.7898706793785095, 0.8049569129943848, 0.7963362336158752, 0.7974137663841248, 0.8092672228813171, 0.8114224076271057, 0.8049569129943848, 0.7995689511299133, 0.8092672228813171, 0.7931034564971924, 0.8178879022598267, 0.7995689511299133, 0.7995689511299133, 0.8071120977401733, 0.7909482717514038, 0.7887930870056152, 0.8071120977401733, 0.8006465435028076, 0.8038793206214905, 0.806034505367279, 0.8006465435028076, 0.798491358757019, 0.798491358757019, 0.8017241358757019, 0.798491358757019, 0.7941810488700867, 0.7844827771186829, 0.7931034564971924, 0.7855603694915771, 0.8071120977401733, 0.7920258641242981, 0.7920258641242981, 0.8006465435028076, 0.8017241358757019, 0.7963362336158752, 0.7974137663841248]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.1800 - accuracy: 0.9350"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 10s 60ms/step - loss: 0.1771 - accuracy: 0.9360 - val_loss: 0.7113 - val_accuracy: 0.5000\n","Epoch 2/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0919 - accuracy: 0.9700 - val_loss: 0.7046 - val_accuracy: 0.5045\n","Epoch 3/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0910 - accuracy: 0.9658 - val_loss: 0.7070 - val_accuracy: 0.5045\n","Epoch 4/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0983 - accuracy: 0.9641 - val_loss: 0.6927 - val_accuracy: 0.5113\n","Epoch 5/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0819 - accuracy: 0.9703 - val_loss: 0.6979 - val_accuracy: 0.5113\n","Epoch 6/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0983 - accuracy: 0.9629 - val_loss: 0.6688 - val_accuracy: 0.5283\n","Epoch 7/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0839 - accuracy: 0.9711 - val_loss: 0.6555 - val_accuracy: 0.5407\n","Epoch 8/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0806 - accuracy: 0.9692 - val_loss: 0.6659 - val_accuracy: 0.5339\n","Epoch 9/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0787 - accuracy: 0.9706 - val_loss: 0.6378 - val_accuracy: 0.5566\n","Epoch 10/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0673 - accuracy: 0.9785 - val_loss: 0.6163 - val_accuracy: 0.5837\n","Epoch 11/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0629 - accuracy: 0.9782 - val_loss: 0.6088 - val_accuracy: 0.6007\n","Epoch 12/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0707 - accuracy: 0.9751 - val_loss: 0.5702 - val_accuracy: 0.6719\n","Epoch 13/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0649 - accuracy: 0.9774 - val_loss: 0.5579 - val_accuracy: 0.6708\n","Epoch 14/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0579 - accuracy: 0.9816 - val_loss: 0.5764 - val_accuracy: 0.6425\n","Epoch 15/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0662 - accuracy: 0.9762 - val_loss: 0.5550 - val_accuracy: 0.6742\n","Epoch 16/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0639 - accuracy: 0.9776 - val_loss: 0.4823 - val_accuracy: 0.7545\n","Epoch 17/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0539 - accuracy: 0.9810 - val_loss: 0.5086 - val_accuracy: 0.7206\n","Epoch 18/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0568 - accuracy: 0.9805 - val_loss: 0.4586 - val_accuracy: 0.7805\n","Epoch 19/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0483 - accuracy: 0.9836 - val_loss: 0.4346 - val_accuracy: 0.8009\n","Epoch 20/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0522 - accuracy: 0.9791 - val_loss: 0.4280 - val_accuracy: 0.8032\n","Epoch 21/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0586 - accuracy: 0.9822 - val_loss: 0.4100 - val_accuracy: 0.8348\n","Epoch 22/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0524 - accuracy: 0.9813 - val_loss: 0.4552 - val_accuracy: 0.8269\n","Epoch 23/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0573 - accuracy: 0.9791 - val_loss: 0.4748 - val_accuracy: 0.8258\n","Epoch 24/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0499 - accuracy: 0.9850 - val_loss: 0.4914 - val_accuracy: 0.8133\n","Epoch 25/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0445 - accuracy: 0.9856 - val_loss: 0.4951 - val_accuracy: 0.8348\n","Epoch 26/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0473 - accuracy: 0.9833 - val_loss: 0.5483 - val_accuracy: 0.8179\n","Epoch 27/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0535 - accuracy: 0.9799 - val_loss: 0.5706 - val_accuracy: 0.8281\n","Epoch 28/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0450 - accuracy: 0.9816 - val_loss: 0.6281 - val_accuracy: 0.8156\n","Epoch 29/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0478 - accuracy: 0.9833 - val_loss: 0.5970 - val_accuracy: 0.8337\n","Epoch 30/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0504 - accuracy: 0.9822 - val_loss: 0.6158 - val_accuracy: 0.8416\n","Epoch 31/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0431 - accuracy: 0.9861 - val_loss: 0.6456 - val_accuracy: 0.8371\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0497 - accuracy: 0.9822 - val_loss: 0.6825 - val_accuracy: 0.8201\n","Epoch 33/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0570 - accuracy: 0.9802 - val_loss: 0.6616 - val_accuracy: 0.8258\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0425 - accuracy: 0.9898 - val_loss: 0.6930 - val_accuracy: 0.8348\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0436 - accuracy: 0.9842 - val_loss: 0.7080 - val_accuracy: 0.8281\n","Epoch 36/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0554 - accuracy: 0.9782 - val_loss: 0.7406 - val_accuracy: 0.8167\n","Epoch 37/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0402 - accuracy: 0.9881 - val_loss: 0.6993 - val_accuracy: 0.8337\n","Epoch 38/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0424 - accuracy: 0.9867 - val_loss: 0.7451 - val_accuracy: 0.8292\n","Epoch 39/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0465 - accuracy: 0.9833 - val_loss: 0.7378 - val_accuracy: 0.8258\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0545 - accuracy: 0.9805 - val_loss: 0.7142 - val_accuracy: 0.8337\n","Epoch 41/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0410 - accuracy: 0.9875 - val_loss: 0.7485 - val_accuracy: 0.8258\n","Epoch 42/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0330 - accuracy: 0.9898 - val_loss: 0.7422 - val_accuracy: 0.8314\n","Epoch 43/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0292 - accuracy: 0.9929 - val_loss: 0.7368 - val_accuracy: 0.8314\n","Epoch 44/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0307 - accuracy: 0.9909 - val_loss: 0.7824 - val_accuracy: 0.8201\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0359 - accuracy: 0.9887 - val_loss: 0.7523 - val_accuracy: 0.8235\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0364 - accuracy: 0.9878 - val_loss: 0.9260 - val_accuracy: 0.7986\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0506 - accuracy: 0.9793 - val_loss: 0.7700 - val_accuracy: 0.8247\n","Epoch 48/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0303 - accuracy: 0.9907 - val_loss: 0.7782 - val_accuracy: 0.8269\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0265 - accuracy: 0.9949 - val_loss: 0.7772 - val_accuracy: 0.8303\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0464 - accuracy: 0.9819 - val_loss: 0.7620 - val_accuracy: 0.8235\n","Epoch 51/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0279 - accuracy: 0.9946 - val_loss: 0.7762 - val_accuracy: 0.8235\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9915 - val_loss: 0.8069 - val_accuracy: 0.8167\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0291 - accuracy: 0.9895 - val_loss: 0.7931 - val_accuracy: 0.8201\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0346 - accuracy: 0.9884 - val_loss: 0.7843 - val_accuracy: 0.8269\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0289 - accuracy: 0.9907 - val_loss: 0.8015 - val_accuracy: 0.8213\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0297 - accuracy: 0.9912 - val_loss: 0.7795 - val_accuracy: 0.8269\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0340 - accuracy: 0.9904 - val_loss: 0.8181 - val_accuracy: 0.8247\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0288 - accuracy: 0.9915 - val_loss: 0.8226 - val_accuracy: 0.8224\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0264 - accuracy: 0.9924 - val_loss: 0.8219 - val_accuracy: 0.8235\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 0.8211 - val_accuracy: 0.8201\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0312 - accuracy: 0.9921 - val_loss: 0.8358 - val_accuracy: 0.8247\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0367 - accuracy: 0.9875 - val_loss: 0.8212 - val_accuracy: 0.8201\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0289 - accuracy: 0.9898 - val_loss: 0.8479 - val_accuracy: 0.8235\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0355 - accuracy: 0.9890 - val_loss: 0.8475 - val_accuracy: 0.8054\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0314 - accuracy: 0.9915 - val_loss: 1.0111 - val_accuracy: 0.7907\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0364 - accuracy: 0.9850 - val_loss: 0.8976 - val_accuracy: 0.8167\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0239 - accuracy: 0.9932 - val_loss: 0.9051 - val_accuracy: 0.8043\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0293 - accuracy: 0.9907 - val_loss: 0.8760 - val_accuracy: 0.8224\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0327 - accuracy: 0.9884 - val_loss: 0.8974 - val_accuracy: 0.8111\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0261 - accuracy: 0.9921 - val_loss: 0.8670 - val_accuracy: 0.8145\n","Epoch 71/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 1.0066 - val_accuracy: 0.7941\n","Epoch 72/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0301 - accuracy: 0.9892 - val_loss: 0.9623 - val_accuracy: 0.8066\n","Epoch 73/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0414 - accuracy: 0.9847 - val_loss: 0.9844 - val_accuracy: 0.7964\n","Epoch 74/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0449 - accuracy: 0.9853 - val_loss: 0.8599 - val_accuracy: 0.8179\n","Epoch 75/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0295 - accuracy: 0.9904 - val_loss: 0.8328 - val_accuracy: 0.8179\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0253 - accuracy: 0.9909 - val_loss: 0.8798 - val_accuracy: 0.8122\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0228 - accuracy: 0.9935 - val_loss: 0.9091 - val_accuracy: 0.8100\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0184 - accuracy: 0.9958 - val_loss: 0.9027 - val_accuracy: 0.8122\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0224 - accuracy: 0.9952 - val_loss: 0.9898 - val_accuracy: 0.8020\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0321 - accuracy: 0.9895 - val_loss: 0.9058 - val_accuracy: 0.8100\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0327 - accuracy: 0.9915 - val_loss: 0.9873 - val_accuracy: 0.8088\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0507 - accuracy: 0.9844 - val_loss: 0.9996 - val_accuracy: 0.8009\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0566 - accuracy: 0.9774 - val_loss: 0.9234 - val_accuracy: 0.8066\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0367 - accuracy: 0.9898 - val_loss: 0.8837 - val_accuracy: 0.8145\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0391 - accuracy: 0.9856 - val_loss: 0.8692 - val_accuracy: 0.8190\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0222 - accuracy: 0.9932 - val_loss: 0.9109 - val_accuracy: 0.8156\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0201 - accuracy: 0.9949 - val_loss: 0.8851 - val_accuracy: 0.8179\n","Epoch 88/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0166 - accuracy: 0.9960 - val_loss: 0.8981 - val_accuracy: 0.8201\n","Epoch 89/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0160 - accuracy: 0.9975 - val_loss: 0.8836 - val_accuracy: 0.8179\n","Epoch 90/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0204 - accuracy: 0.9935 - val_loss: 1.0194 - val_accuracy: 0.8088\n","Epoch 91/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0292 - accuracy: 0.9929 - val_loss: 0.9161 - val_accuracy: 0.8066\n","Epoch 92/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0257 - accuracy: 0.9912 - val_loss: 0.8983 - val_accuracy: 0.8111\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0154 - accuracy: 0.9960 - val_loss: 0.9199 - val_accuracy: 0.8133\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0139 - accuracy: 0.9972 - val_loss: 0.8953 - val_accuracy: 0.8213\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0194 - accuracy: 0.9958 - val_loss: 0.9782 - val_accuracy: 0.7941\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0188 - accuracy: 0.9949 - val_loss: 0.9812 - val_accuracy: 0.8122\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0202 - accuracy: 0.9946 - val_loss: 1.0166 - val_accuracy: 0.8032\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0226 - accuracy: 0.9941 - val_loss: 0.9818 - val_accuracy: 0.8043\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0186 - accuracy: 0.9952 - val_loss: 0.9547 - val_accuracy: 0.8054\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0495 - accuracy: 0.9813 - val_loss: 0.9610 - val_accuracy: 0.8167\n","{'loss': [0.1770881563425064, 0.09188541024923325, 0.09096656739711761, 0.09832806140184402, 0.08191198855638504, 0.09828972816467285, 0.08393920212984085, 0.0805906429886818, 0.07868718355894089, 0.06727331876754761, 0.06287487596273422, 0.07074560225009918, 0.06492210924625397, 0.05788809433579445, 0.0662217065691948, 0.0639418438076973, 0.05386276915669441, 0.05678354203701019, 0.04825448617339134, 0.05224093049764633, 0.0585768036544323, 0.05242004990577698, 0.05725571885704994, 0.04991195723414421, 0.04452820494771004, 0.047291576862335205, 0.0534820631146431, 0.044980488717556, 0.047846682369709015, 0.050435710698366165, 0.04310917481780052, 0.04967602714896202, 0.05704460293054581, 0.04250017926096916, 0.043610889464616776, 0.05541722849011421, 0.040220070630311966, 0.0424325093626976, 0.04654940217733383, 0.05453032627701759, 0.04102000594139099, 0.03299703821539879, 0.029172927141189575, 0.030677732080221176, 0.03591694310307503, 0.03643103688955307, 0.05063073709607124, 0.030281826853752136, 0.026549216359853745, 0.04640664905309677, 0.027865316718816757, 0.03018691949546337, 0.029073528945446014, 0.034630779176950455, 0.028948785737156868, 0.029655758291482925, 0.03401551768183708, 0.02884615771472454, 0.02639101631939411, 0.02391960844397545, 0.031204670667648315, 0.0367380790412426, 0.028923211619257927, 0.035520557314157486, 0.03142279386520386, 0.0364404022693634, 0.023884743452072144, 0.02931724116206169, 0.03267485648393631, 0.026069097220897675, 0.028654523193836212, 0.03010416217148304, 0.04141268506646156, 0.044930215924978256, 0.029511628672480583, 0.025288647040724754, 0.022776110097765923, 0.01839682087302208, 0.022401055321097374, 0.03207159414887428, 0.03267170861363411, 0.05065101385116577, 0.05659973993897438, 0.03670986741781235, 0.039094261825084686, 0.022155141457915306, 0.020130684599280357, 0.016583861783146858, 0.016040831804275513, 0.020420905202627182, 0.029239635914564133, 0.02572007104754448, 0.015423495322465897, 0.013854509219527245, 0.019387535750865936, 0.018764382228255272, 0.02019559033215046, 0.022561533376574516, 0.018572168424725533, 0.04953878000378609], 'accuracy': [0.9360498189926147, 0.9700056314468384, 0.9657611846923828, 0.9640634059906006, 0.9702886343002319, 0.9629315137863159, 0.971137523651123, 0.9691567420959473, 0.9705715775489807, 0.9784946441650391, 0.9782116413116455, 0.9750990271568298, 0.9773627519607544, 0.9816072583198547, 0.9762309193611145, 0.977645754814148, 0.9810413122177124, 0.9804753661155701, 0.9835879802703857, 0.9790605306625366, 0.9821732044219971, 0.9813242554664612, 0.9790605306625366, 0.9850028157234192, 0.9855687618255615, 0.983305037021637, 0.9799094796180725, 0.9816072583198547, 0.983305037021637, 0.9821732044219971, 0.9861347079277039, 0.9821732044219971, 0.9801924228668213, 0.9898132681846619, 0.9841539263725281, 0.9782116413116455, 0.9881154298782349, 0.9867005944252014, 0.983305037021637, 0.9804753661155701, 0.9875495433807373, 0.9898132681846619, 0.9929258823394775, 0.9909451007843018, 0.9886813759803772, 0.9878324866294861, 0.9793435335159302, 0.990662157535553, 0.9949066042900085, 0.9818902015686035, 0.9946236610412598, 0.9915110468864441, 0.9895302653312683, 0.9883984327316284, 0.990662157535553, 0.9912280440330505, 0.9903791546821594, 0.9915110468864441, 0.9923599362373352, 0.9923599362373352, 0.9920769929885864, 0.9875495433807373, 0.9898132681846619, 0.988964319229126, 0.9915110468864441, 0.9850028157234192, 0.9932088255882263, 0.990662157535553, 0.9883984327316284, 0.9920769929885864, 0.9912280440330505, 0.9892473220825195, 0.9847198724746704, 0.9852858185768127, 0.9903791546821594, 0.9909451007843018, 0.9934917688369751, 0.9957554936408997, 0.9951896071434021, 0.9895302653312683, 0.9915110468864441, 0.9844368696212769, 0.9773627519607544, 0.9898132681846619, 0.9855687618255615, 0.9932088255882263, 0.9949066042900085, 0.9960384964942932, 0.9974533319473267, 0.9934917688369751, 0.9929258823394775, 0.9912280440330505, 0.9960384964942932, 0.9971703290939331, 0.9957554936408997, 0.9949066042900085, 0.9946236610412598, 0.9940577149391174, 0.9951896071434021, 0.9813242554664612], 'val_loss': [0.7113229036331177, 0.704635739326477, 0.7070121765136719, 0.6927127838134766, 0.6978925466537476, 0.6687985062599182, 0.6554662585258484, 0.6658705472946167, 0.6378058791160583, 0.6163259744644165, 0.6088191270828247, 0.5701970458030701, 0.5579013228416443, 0.5764290690422058, 0.5549919605255127, 0.4823471009731293, 0.5086163282394409, 0.4585789740085602, 0.4345853626728058, 0.4279540181159973, 0.4100174307823181, 0.4552231729030609, 0.4747999608516693, 0.4913654625415802, 0.4951494038105011, 0.5482932925224304, 0.570577085018158, 0.6280810236930847, 0.5969679951667786, 0.6158011555671692, 0.645599901676178, 0.6824635863304138, 0.6615697741508484, 0.6929908394813538, 0.7079740762710571, 0.7405896782875061, 0.6993358731269836, 0.7451277375221252, 0.7378214597702026, 0.7141728401184082, 0.7484941482543945, 0.7422436475753784, 0.7367894649505615, 0.7824451327323914, 0.752343475818634, 0.9259945750236511, 0.7700054049491882, 0.7782024145126343, 0.7772006392478943, 0.762015700340271, 0.7762488722801208, 0.8068734407424927, 0.7930933833122253, 0.7842900156974792, 0.8015005588531494, 0.779495358467102, 0.8180912137031555, 0.8226022720336914, 0.8219383358955383, 0.8210715651512146, 0.8358454704284668, 0.8211752772331238, 0.8479436039924622, 0.8475233316421509, 1.0111130475997925, 0.8975504040718079, 0.9051065444946289, 0.876039445400238, 0.8974214196205139, 0.8670156598091125, 1.0066193342208862, 0.9623334407806396, 0.9844348430633545, 0.8599447011947632, 0.8327599167823792, 0.8798322081565857, 0.9091154932975769, 0.9027109146118164, 0.9898393750190735, 0.9058278203010559, 0.9872655272483826, 0.9996243715286255, 0.9233911037445068, 0.8836530447006226, 0.8691902160644531, 0.9109190702438354, 0.8850832581520081, 0.8980882167816162, 0.8836212158203125, 1.019357681274414, 0.9160780906677246, 0.8983033299446106, 0.9198952913284302, 0.8953312039375305, 0.9781748056411743, 0.9811968803405762, 1.0166103839874268, 0.9818478226661682, 0.9546908736228943, 0.9610333442687988], 'val_accuracy': [0.5, 0.5045248866081238, 0.5045248866081238, 0.5113122463226318, 0.5113122463226318, 0.5282805562019348, 0.540723979473114, 0.5339366793632507, 0.5565611124038696, 0.5837104320526123, 0.6006787419319153, 0.6719456911087036, 0.6708144545555115, 0.6425339579582214, 0.6742081642150879, 0.7545248866081238, 0.720588207244873, 0.7805429697036743, 0.8009049892425537, 0.8031674027442932, 0.8348416090011597, 0.8269230723381042, 0.8257918357849121, 0.8133484125137329, 0.8348416090011597, 0.8178732991218567, 0.8280543088912964, 0.8156108856201172, 0.8337104320526123, 0.8416289687156677, 0.837104082107544, 0.820135772228241, 0.8257918357849121, 0.8348416090011597, 0.8280543088912964, 0.8167420625686646, 0.8337104320526123, 0.8291855454444885, 0.8257918357849121, 0.8337104320526123, 0.8257918357849121, 0.831447958946228, 0.831447958946228, 0.820135772228241, 0.8235294222831726, 0.7986425161361694, 0.8246606588363647, 0.8269230723381042, 0.8303167223930359, 0.8235294222831726, 0.8235294222831726, 0.8167420625686646, 0.820135772228241, 0.8269230723381042, 0.8212669491767883, 0.8269230723381042, 0.8246606588363647, 0.8223981857299805, 0.8235294222831726, 0.820135772228241, 0.8246606588363647, 0.820135772228241, 0.8235294222831726, 0.8054298758506775, 0.790723979473114, 0.8167420625686646, 0.8042986392974854, 0.8223981857299805, 0.8110859990119934, 0.814479649066925, 0.7941176295280457, 0.8065611124038696, 0.7963801026344299, 0.8178732991218567, 0.8178732991218567, 0.8122171759605408, 0.8099547624588013, 0.8122171759605408, 0.8020362257957458, 0.8099547624588013, 0.8088235259056091, 0.8009049892425537, 0.8065611124038696, 0.814479649066925, 0.8190045356750488, 0.8156108856201172, 0.8178732991218567, 0.820135772228241, 0.8178732991218567, 0.8088235259056091, 0.8065611124038696, 0.8110859990119934, 0.8133484125137329, 0.8212669491767883, 0.7941176295280457, 0.8122171759605408, 0.8031674027442932, 0.8042986392974854, 0.8054298758506775, 0.8167420625686646]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.2567 - accuracy: 0.9163"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 70ms/step - loss: 0.2489 - accuracy: 0.9186 - val_loss: 0.7283 - val_accuracy: 0.4897\n","Epoch 2/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.1429 - accuracy: 0.9527 - val_loss: 0.7197 - val_accuracy: 0.4917\n","Epoch 3/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1229 - accuracy: 0.9509 - val_loss: 0.7175 - val_accuracy: 0.4907\n","Epoch 4/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.1165 - accuracy: 0.9568 - val_loss: 0.7103 - val_accuracy: 0.4959\n","Epoch 5/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.1117 - accuracy: 0.9584 - val_loss: 0.6990 - val_accuracy: 0.5052\n","Epoch 6/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.1116 - accuracy: 0.9643 - val_loss: 0.6966 - val_accuracy: 0.5114\n","Epoch 7/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1049 - accuracy: 0.9615 - val_loss: 0.6810 - val_accuracy: 0.5258\n","Epoch 8/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.0988 - accuracy: 0.9607 - val_loss: 0.6745 - val_accuracy: 0.5320\n","Epoch 9/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0986 - accuracy: 0.9636 - val_loss: 0.6459 - val_accuracy: 0.5764\n","Epoch 10/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0809 - accuracy: 0.9711 - val_loss: 0.6675 - val_accuracy: 0.5517\n","Epoch 11/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0878 - accuracy: 0.9711 - val_loss: 0.6199 - val_accuracy: 0.6333\n","Epoch 12/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0814 - accuracy: 0.9677 - val_loss: 0.6338 - val_accuracy: 0.6136\n","Epoch 13/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0792 - accuracy: 0.9731 - val_loss: 0.6269 - val_accuracy: 0.6405\n","Epoch 14/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1003 - accuracy: 0.9592 - val_loss: 0.6112 - val_accuracy: 0.6725\n","Epoch 15/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0810 - accuracy: 0.9726 - val_loss: 0.6042 - val_accuracy: 0.6818\n","Epoch 16/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0735 - accuracy: 0.9731 - val_loss: 0.5847 - val_accuracy: 0.7169\n","Epoch 17/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0844 - accuracy: 0.9682 - val_loss: 0.5847 - val_accuracy: 0.7552\n","Epoch 18/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0957 - accuracy: 0.9610 - val_loss: 0.5751 - val_accuracy: 0.7789\n","Epoch 19/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0818 - accuracy: 0.9708 - val_loss: 0.5922 - val_accuracy: 0.7862\n","Epoch 20/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0814 - accuracy: 0.9672 - val_loss: 0.6673 - val_accuracy: 0.7686\n","Epoch 21/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0719 - accuracy: 0.9716 - val_loss: 0.6862 - val_accuracy: 0.7779\n","Epoch 22/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0634 - accuracy: 0.9773 - val_loss: 0.7278 - val_accuracy: 0.7903\n","Epoch 23/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0744 - accuracy: 0.9744 - val_loss: 0.7760 - val_accuracy: 0.7831\n","Epoch 24/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0599 - accuracy: 0.9773 - val_loss: 0.8261 - val_accuracy: 0.7810\n","Epoch 25/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0669 - accuracy: 0.9783 - val_loss: 0.9312 - val_accuracy: 0.7696\n","Epoch 26/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0708 - accuracy: 0.9755 - val_loss: 0.9441 - val_accuracy: 0.7758\n","Epoch 27/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0596 - accuracy: 0.9801 - val_loss: 0.9648 - val_accuracy: 0.7831\n","Epoch 28/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0563 - accuracy: 0.9804 - val_loss: 1.0626 - val_accuracy: 0.7707\n","Epoch 29/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0680 - accuracy: 0.9739 - val_loss: 1.0023 - val_accuracy: 0.7800\n","Epoch 30/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0628 - accuracy: 0.9783 - val_loss: 1.0881 - val_accuracy: 0.7707\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0618 - accuracy: 0.9798 - val_loss: 1.0313 - val_accuracy: 0.7789\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0585 - accuracy: 0.9793 - val_loss: 1.0764 - val_accuracy: 0.7686\n","Epoch 33/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0537 - accuracy: 0.9819 - val_loss: 1.0713 - val_accuracy: 0.7727\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0746 - accuracy: 0.9698 - val_loss: 1.0965 - val_accuracy: 0.7696\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0655 - accuracy: 0.9773 - val_loss: 1.1059 - val_accuracy: 0.7717\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0835 - accuracy: 0.9654 - val_loss: 1.1014 - val_accuracy: 0.7738\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0601 - accuracy: 0.9796 - val_loss: 1.0663 - val_accuracy: 0.7779\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0508 - accuracy: 0.9835 - val_loss: 1.0958 - val_accuracy: 0.7696\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0534 - accuracy: 0.9819 - val_loss: 1.0869 - val_accuracy: 0.7831\n","Epoch 40/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0488 - accuracy: 0.9871 - val_loss: 1.0979 - val_accuracy: 0.7686\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0542 - accuracy: 0.9809 - val_loss: 1.0973 - val_accuracy: 0.7800\n","Epoch 42/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0449 - accuracy: 0.9853 - val_loss: 1.1388 - val_accuracy: 0.7707\n","Epoch 43/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0573 - accuracy: 0.9801 - val_loss: 1.1217 - val_accuracy: 0.7831\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0535 - accuracy: 0.9817 - val_loss: 1.1674 - val_accuracy: 0.7686\n","Epoch 45/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0505 - accuracy: 0.9822 - val_loss: 1.1501 - val_accuracy: 0.7758\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0468 - accuracy: 0.9845 - val_loss: 1.1346 - val_accuracy: 0.7758\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0476 - accuracy: 0.9860 - val_loss: 1.1496 - val_accuracy: 0.7789\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0548 - accuracy: 0.9786 - val_loss: 1.4083 - val_accuracy: 0.7314\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0754 - accuracy: 0.9703 - val_loss: 1.1771 - val_accuracy: 0.7727\n","Epoch 50/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0447 - accuracy: 0.9835 - val_loss: 1.1709 - val_accuracy: 0.7789\n","Epoch 51/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0394 - accuracy: 0.9879 - val_loss: 1.1695 - val_accuracy: 0.7717\n","Epoch 52/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0544 - accuracy: 0.9835 - val_loss: 1.3319 - val_accuracy: 0.7345\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0454 - accuracy: 0.9853 - val_loss: 1.1803 - val_accuracy: 0.7624\n","Epoch 54/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0403 - accuracy: 0.9863 - val_loss: 1.2065 - val_accuracy: 0.7686\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0544 - accuracy: 0.9791 - val_loss: 1.1853 - val_accuracy: 0.7769\n","Epoch 56/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0469 - accuracy: 0.9835 - val_loss: 1.2768 - val_accuracy: 0.7665\n","Epoch 57/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0472 - accuracy: 0.9858 - val_loss: 1.2048 - val_accuracy: 0.7686\n","Epoch 58/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0453 - accuracy: 0.9850 - val_loss: 1.2346 - val_accuracy: 0.7593\n","Epoch 59/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0356 - accuracy: 0.9881 - val_loss: 1.2795 - val_accuracy: 0.7510\n","Epoch 60/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0531 - accuracy: 0.9806 - val_loss: 1.2538 - val_accuracy: 0.7448\n","Epoch 61/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0475 - accuracy: 0.9827 - val_loss: 1.2849 - val_accuracy: 0.7531\n","Epoch 62/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0449 - accuracy: 0.9868 - val_loss: 1.2197 - val_accuracy: 0.7758\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0417 - accuracy: 0.9891 - val_loss: 1.2658 - val_accuracy: 0.7769\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0371 - accuracy: 0.9889 - val_loss: 1.3966 - val_accuracy: 0.7562\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0456 - accuracy: 0.9837 - val_loss: 1.3428 - val_accuracy: 0.7500\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0430 - accuracy: 0.9855 - val_loss: 1.2882 - val_accuracy: 0.7665\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0467 - accuracy: 0.9837 - val_loss: 1.3138 - val_accuracy: 0.7645\n","Epoch 68/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0374 - accuracy: 0.9881 - val_loss: 1.3850 - val_accuracy: 0.7583\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0742 - accuracy: 0.9729 - val_loss: 1.4038 - val_accuracy: 0.7490\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0390 - accuracy: 0.9894 - val_loss: 1.2876 - val_accuracy: 0.7531\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0350 - accuracy: 0.9897 - val_loss: 1.2735 - val_accuracy: 0.7727\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0343 - accuracy: 0.9886 - val_loss: 1.2967 - val_accuracy: 0.7645\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0367 - accuracy: 0.9873 - val_loss: 1.3021 - val_accuracy: 0.7645\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0464 - accuracy: 0.9809 - val_loss: 1.3269 - val_accuracy: 0.7634\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0472 - accuracy: 0.9827 - val_loss: 1.4522 - val_accuracy: 0.7614\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0498 - accuracy: 0.9835 - val_loss: 1.3301 - val_accuracy: 0.7438\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0348 - accuracy: 0.9881 - val_loss: 1.2449 - val_accuracy: 0.7645\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0346 - accuracy: 0.9884 - val_loss: 1.2431 - val_accuracy: 0.7655\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0299 - accuracy: 0.9920 - val_loss: 1.2929 - val_accuracy: 0.7562\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0271 - accuracy: 0.9935 - val_loss: 1.2707 - val_accuracy: 0.7665\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0266 - accuracy: 0.9920 - val_loss: 1.3160 - val_accuracy: 0.7727\n","Epoch 82/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0254 - accuracy: 0.9928 - val_loss: 1.3183 - val_accuracy: 0.7552\n","Epoch 83/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0352 - accuracy: 0.9886 - val_loss: 1.3928 - val_accuracy: 0.7521\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0470 - accuracy: 0.9829 - val_loss: 1.4949 - val_accuracy: 0.7366\n","Epoch 85/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0578 - accuracy: 0.9752 - val_loss: 1.3133 - val_accuracy: 0.7603\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0336 - accuracy: 0.9899 - val_loss: 1.3185 - val_accuracy: 0.7572\n","Epoch 87/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0326 - accuracy: 0.9897 - val_loss: 1.3182 - val_accuracy: 0.7624\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0336 - accuracy: 0.9873 - val_loss: 1.4337 - val_accuracy: 0.7448\n","Epoch 89/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0296 - accuracy: 0.9912 - val_loss: 1.3741 - val_accuracy: 0.7521\n","Epoch 90/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 1.3726 - val_accuracy: 0.7624\n","Epoch 91/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0329 - accuracy: 0.9894 - val_loss: 1.4683 - val_accuracy: 0.7490\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0305 - accuracy: 0.9897 - val_loss: 1.3690 - val_accuracy: 0.7583\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0323 - accuracy: 0.9902 - val_loss: 1.4286 - val_accuracy: 0.7603\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0363 - accuracy: 0.9871 - val_loss: 1.3596 - val_accuracy: 0.7614\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0247 - accuracy: 0.9917 - val_loss: 1.4161 - val_accuracy: 0.7521\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0196 - accuracy: 0.9959 - val_loss: 1.3915 - val_accuracy: 0.7655\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0274 - accuracy: 0.9922 - val_loss: 1.4374 - val_accuracy: 0.7583\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0309 - accuracy: 0.9907 - val_loss: 1.3964 - val_accuracy: 0.7624\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 1.5725 - val_accuracy: 0.7448\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0627 - accuracy: 0.9749 - val_loss: 1.4641 - val_accuracy: 0.7521\n","{'loss': [0.24889926612377167, 0.142935112118721, 0.12285646051168442, 0.11652851849794388, 0.11167248338460922, 0.11156398802995682, 0.10486403852701187, 0.09883889555931091, 0.0985635295510292, 0.08090808987617493, 0.08782900869846344, 0.08139122277498245, 0.07922382652759552, 0.10026418417692184, 0.0809568464756012, 0.07346136122941971, 0.08438434451818466, 0.09566080570220947, 0.08180085569620132, 0.08138790726661682, 0.0718865618109703, 0.06338930130004883, 0.07438260316848755, 0.059930164366960526, 0.06689829379320145, 0.07077611982822418, 0.05955023318529129, 0.05626698583364487, 0.06796788424253464, 0.06277893483638763, 0.06177116930484772, 0.05846787616610527, 0.0537310354411602, 0.07464777678251266, 0.06548384577035904, 0.08348805457353592, 0.060110464692115784, 0.05077901482582092, 0.053372953087091446, 0.048802122473716736, 0.05420544371008873, 0.044918473809957504, 0.05732329934835434, 0.053483493626117706, 0.05047280713915825, 0.046828463673591614, 0.047574952244758606, 0.05479161813855171, 0.07538124918937683, 0.04471477493643761, 0.03943943977355957, 0.05438420921564102, 0.045445989817380905, 0.04029053822159767, 0.05443151667714119, 0.046864017844200134, 0.04717640578746796, 0.04525824636220932, 0.035641491413116455, 0.0530557855963707, 0.04748820140957832, 0.04489215090870857, 0.041659072041511536, 0.03708592429757118, 0.04560157656669617, 0.042977962642908096, 0.046730391681194305, 0.03740396350622177, 0.07419147342443466, 0.03899345546960831, 0.035044167190790176, 0.03428080305457115, 0.03670449182391167, 0.046395543962717056, 0.04719872400164604, 0.04977485537528992, 0.03478112816810608, 0.03458073362708092, 0.02989456057548523, 0.027073871344327927, 0.026598289608955383, 0.025429124012589455, 0.035230740904808044, 0.047001782804727554, 0.05779600143432617, 0.03363814577460289, 0.03263307735323906, 0.0336473248898983, 0.02964738756418228, 0.024538688361644745, 0.03290676325559616, 0.030503779649734497, 0.03230830654501915, 0.0363445021212101, 0.02473212033510208, 0.019644971936941147, 0.027374926954507828, 0.030883150175213814, 0.0244605615735054, 0.0627257227897644], 'accuracy': [0.9186046719551086, 0.9527131915092468, 0.950904369354248, 0.9568475484848022, 0.9583979249000549, 0.9643411040306091, 0.9614987373352051, 0.9607235193252563, 0.9635658860206604, 0.9710594415664673, 0.9710594415664673, 0.9677002429962158, 0.9731265902519226, 0.9591731429100037, 0.97260981798172, 0.9731265902519226, 0.9682170748710632, 0.9609819054603577, 0.970801055431366, 0.9671834707260132, 0.9715762138366699, 0.9772610068321228, 0.974418580532074, 0.9772610068321228, 0.9782945513725281, 0.975452184677124, 0.9801033735275269, 0.9803617596626282, 0.9739018082618713, 0.9782945513725281, 0.9798449873924255, 0.9793281555175781, 0.9819121360778809, 0.9697674512863159, 0.9772610068321228, 0.9653746485710144, 0.9795865416526794, 0.9834625124931335, 0.9819121360778809, 0.9870800971984863, 0.9808785319328308, 0.9852713346481323, 0.9801033735275269, 0.9816537499427795, 0.9821705222129822, 0.9844961166381836, 0.9860464930534363, 0.9785529971122742, 0.9702842235565186, 0.9834625124931335, 0.9878553152084351, 0.9834625124931335, 0.9852713346481323, 0.9863049387931824, 0.9790697693824768, 0.9834625124931335, 0.985788106918335, 0.985012948513031, 0.9881137013435364, 0.9806201457977295, 0.9826873540878296, 0.986821711063385, 0.9891473054885864, 0.9888888597488403, 0.9837209582328796, 0.9855297207832336, 0.9837209582328796, 0.9881137013435364, 0.9728682041168213, 0.9894056916236877, 0.9896640777587891, 0.988630473613739, 0.9873384833335876, 0.9808785319328308, 0.9826873540878296, 0.9834625124931335, 0.9881137013435364, 0.9883720874786377, 0.9919896721839905, 0.9935400485992432, 0.9919896721839905, 0.9927648305892944, 0.988630473613739, 0.9829457402229309, 0.9751937985420227, 0.9899224638938904, 0.9896640777587891, 0.9873384833335876, 0.9912144541740417, 0.9932816624641418, 0.9894056916236877, 0.9896640777587891, 0.9901808500289917, 0.9870800971984863, 0.9917312860488892, 0.9958656430244446, 0.9922480583190918, 0.9906976819038391, 0.9932816624641418, 0.9749354124069214], 'val_loss': [0.7283080816268921, 0.719680905342102, 0.7175422310829163, 0.7103034257888794, 0.6989556550979614, 0.6966091394424438, 0.6809947490692139, 0.6744653582572937, 0.6458701491355896, 0.6674955487251282, 0.6199382543563843, 0.6338401436805725, 0.6269261837005615, 0.6111983060836792, 0.6041864156723022, 0.5846866965293884, 0.5846635103225708, 0.575076162815094, 0.592195987701416, 0.667280912399292, 0.6861753463745117, 0.727769136428833, 0.7759952545166016, 0.8261221051216125, 0.9312066435813904, 0.9440550804138184, 0.9648467302322388, 1.0625640153884888, 1.0023434162139893, 1.0881341695785522, 1.0312660932540894, 1.0764305591583252, 1.0712943077087402, 1.096501350402832, 1.105916142463684, 1.1014139652252197, 1.0662561655044556, 1.0958232879638672, 1.0868760347366333, 1.0978714227676392, 1.0973066091537476, 1.138783574104309, 1.1216933727264404, 1.1674158573150635, 1.150067687034607, 1.1345620155334473, 1.1495927572250366, 1.408292293548584, 1.17706298828125, 1.1709017753601074, 1.1695096492767334, 1.3319318294525146, 1.1802877187728882, 1.2064783573150635, 1.185347318649292, 1.2767839431762695, 1.204758882522583, 1.2345796823501587, 1.279531478881836, 1.2538388967514038, 1.2848905324935913, 1.2196917533874512, 1.265771508216858, 1.3966233730316162, 1.3428285121917725, 1.2882418632507324, 1.3138179779052734, 1.3849618434906006, 1.4037877321243286, 1.2876254320144653, 1.2734748125076294, 1.2966938018798828, 1.3021377325057983, 1.3269002437591553, 1.4521725177764893, 1.3301403522491455, 1.2448514699935913, 1.243054747581482, 1.2929400205612183, 1.2707408666610718, 1.3159949779510498, 1.3183326721191406, 1.3927702903747559, 1.4949110746383667, 1.3133469820022583, 1.318473219871521, 1.3182260990142822, 1.4337271451950073, 1.374084711074829, 1.3726215362548828, 1.4682847261428833, 1.3689745664596558, 1.4286181926727295, 1.3595725297927856, 1.4160913228988647, 1.3914698362350464, 1.4373589754104614, 1.3963714838027954, 1.5724937915802002, 1.4640789031982422], 'val_accuracy': [0.48966941237449646, 0.4917355477809906, 0.49070248007774353, 0.4958677589893341, 0.5051652789115906, 0.5113636255264282, 0.5258264541625977, 0.5320248007774353, 0.5764462947845459, 0.5516529083251953, 0.6332644820213318, 0.6136363744735718, 0.6404958963394165, 0.672520637512207, 0.6818181872367859, 0.7169421315193176, 0.7551652789115906, 0.7789255976676941, 0.7861570119857788, 0.7685950398445129, 0.7778925895690918, 0.7902892827987671, 0.7830578684806824, 0.7809917330741882, 0.76962810754776, 0.7758264541625977, 0.7830578684806824, 0.7706611752510071, 0.7799586653709412, 0.7706611752510071, 0.7789255976676941, 0.7685950398445129, 0.7727272510528564, 0.76962810754776, 0.7716942429542542, 0.7737603187561035, 0.7778925895690918, 0.76962810754776, 0.7830578684806824, 0.7685950398445129, 0.7799586653709412, 0.7706611752510071, 0.7830578684806824, 0.7685950398445129, 0.7758264541625977, 0.7758264541625977, 0.7789255976676941, 0.7314049601554871, 0.7727272510528564, 0.7789255976676941, 0.7716942429542542, 0.7345041036605835, 0.7623966932296753, 0.7685950398445129, 0.7768595218658447, 0.7665289044380188, 0.7685950398445129, 0.7592975497245789, 0.7510330677032471, 0.7448347210884094, 0.7530992031097412, 0.7758264541625977, 0.7768595218658447, 0.7561983466148376, 0.75, 0.7665289044380188, 0.7644628286361694, 0.7582644820213318, 0.7489669322967529, 0.7530992031097412, 0.7727272510528564, 0.7644628286361694, 0.7644628286361694, 0.7634297609329224, 0.7613636255264282, 0.7438016533851624, 0.7644628286361694, 0.7654958963394165, 0.7561983466148376, 0.7665289044380188, 0.7727272510528564, 0.7551652789115906, 0.7520661354064941, 0.7365702390670776, 0.7603305578231812, 0.7572314143180847, 0.7623966932296753, 0.7448347210884094, 0.7520661354064941, 0.7623966932296753, 0.7489669322967529, 0.7582644820213318, 0.7603305578231812, 0.7613636255264282, 0.7520661354064941, 0.7654958963394165, 0.7582644820213318, 0.7623966932296753, 0.7448347210884094, 0.7520661354064941]}\n","32/32 [==============================] - 1s 4ms/step\n"]}]},{"cell_type":"code","source":["\n","metrics_df.round(3)"],"metadata":{"id":"Ik5JoVP2NPvY","colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"status":"ok","timestamp":1717433899012,"user_tz":-360,"elapsed":11,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"b67a7b69-6fad-4204-c10b-d9949ac357d4"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.559      0.547   0.687  0.609        0.687        0.432   \n","1        1     0.567      0.578   0.496  0.534        0.496        0.638   \n","2        2     0.578      0.584   0.544  0.563        0.544        0.612   \n","3        0     0.632      0.617   0.700  0.656        0.700        0.564   \n","4        1     0.609      0.610   0.606  0.608        0.606        0.613   \n","5        2     0.644      0.647   0.631  0.639        0.631        0.657   \n","6        0     0.688      0.688   0.687  0.687        0.687        0.688   \n","7        1     0.673      0.671   0.678  0.675        0.678        0.668   \n","8        2     0.730      0.721   0.751  0.735        0.751        0.709   \n","9        0     0.745      0.735   0.765  0.750        0.765        0.724   \n","10       1     0.738      0.740   0.734  0.737        0.734        0.742   \n","11       2     0.761      0.732   0.823  0.775        0.823        0.699   \n","12       0     0.776      0.763   0.799  0.781        0.799        0.752   \n","13       1     0.768      0.801   0.715  0.755        0.715        0.822   \n","14       2     0.795      0.775   0.831  0.802        0.831        0.759   \n","\n","    Kappa  \n","0   0.119  \n","1   0.134  \n","2   0.157  \n","3   0.265  \n","4   0.219  \n","5   0.287  \n","6   0.375  \n","7   0.346  \n","8   0.460  \n","9   0.489  \n","10  0.476  \n","11  0.522  \n","12  0.551  \n","13  0.537  \n","14  0.590  "],"text/html":["\n","  <div id=\"df-53bde3bc-deef-408a-b51c-3f0c37724f26\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.559</td>\n","      <td>0.547</td>\n","      <td>0.687</td>\n","      <td>0.609</td>\n","      <td>0.687</td>\n","      <td>0.432</td>\n","      <td>0.119</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.567</td>\n","      <td>0.578</td>\n","      <td>0.496</td>\n","      <td>0.534</td>\n","      <td>0.496</td>\n","      <td>0.638</td>\n","      <td>0.134</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.578</td>\n","      <td>0.584</td>\n","      <td>0.544</td>\n","      <td>0.563</td>\n","      <td>0.544</td>\n","      <td>0.612</td>\n","      <td>0.157</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.632</td>\n","      <td>0.617</td>\n","      <td>0.700</td>\n","      <td>0.656</td>\n","      <td>0.700</td>\n","      <td>0.564</td>\n","      <td>0.265</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.609</td>\n","      <td>0.610</td>\n","      <td>0.606</td>\n","      <td>0.608</td>\n","      <td>0.606</td>\n","      <td>0.613</td>\n","      <td>0.219</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.644</td>\n","      <td>0.647</td>\n","      <td>0.631</td>\n","      <td>0.639</td>\n","      <td>0.631</td>\n","      <td>0.657</td>\n","      <td>0.287</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.688</td>\n","      <td>0.688</td>\n","      <td>0.687</td>\n","      <td>0.687</td>\n","      <td>0.687</td>\n","      <td>0.688</td>\n","      <td>0.375</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.673</td>\n","      <td>0.671</td>\n","      <td>0.678</td>\n","      <td>0.675</td>\n","      <td>0.678</td>\n","      <td>0.668</td>\n","      <td>0.346</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.730</td>\n","      <td>0.721</td>\n","      <td>0.751</td>\n","      <td>0.735</td>\n","      <td>0.751</td>\n","      <td>0.709</td>\n","      <td>0.460</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.745</td>\n","      <td>0.735</td>\n","      <td>0.765</td>\n","      <td>0.750</td>\n","      <td>0.765</td>\n","      <td>0.724</td>\n","      <td>0.489</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.738</td>\n","      <td>0.740</td>\n","      <td>0.734</td>\n","      <td>0.737</td>\n","      <td>0.734</td>\n","      <td>0.742</td>\n","      <td>0.476</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.761</td>\n","      <td>0.732</td>\n","      <td>0.823</td>\n","      <td>0.775</td>\n","      <td>0.823</td>\n","      <td>0.699</td>\n","      <td>0.522</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.776</td>\n","      <td>0.763</td>\n","      <td>0.799</td>\n","      <td>0.781</td>\n","      <td>0.799</td>\n","      <td>0.752</td>\n","      <td>0.551</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.768</td>\n","      <td>0.801</td>\n","      <td>0.715</td>\n","      <td>0.755</td>\n","      <td>0.715</td>\n","      <td>0.822</td>\n","      <td>0.537</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.795</td>\n","      <td>0.775</td>\n","      <td>0.831</td>\n","      <td>0.802</td>\n","      <td>0.831</td>\n","      <td>0.759</td>\n","      <td>0.590</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53bde3bc-deef-408a-b51c-3f0c37724f26')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-53bde3bc-deef-408a-b51c-3f0c37724f26 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-53bde3bc-deef-408a-b51c-3f0c37724f26');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-73de19a7-9c6d-452a-bf9b-10faf2a013f0\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-73de19a7-9c6d-452a-bf9b-10faf2a013f0')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-73de19a7-9c6d-452a-bf9b-10faf2a013f0 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08156434795388766,\n        \"min\": 0.559,\n        \"max\": 0.795,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.745,\n          0.761,\n          0.559\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07971897067646,\n        \"min\": 0.547,\n        \"max\": 0.801,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.735,\n          0.732,\n          0.547\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09654078832039754,\n        \"min\": 0.496,\n        \"max\": 0.831,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.734,\n          0.799,\n          0.687\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08354679327578449,\n        \"min\": 0.534,\n        \"max\": 0.802,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.75,\n          0.775,\n          0.609\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09654078832039754,\n        \"min\": 0.496,\n        \"max\": 0.831,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.734,\n          0.799,\n          0.687\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09417648073595405,\n        \"min\": 0.432,\n        \"max\": 0.822,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.724,\n          0.699,\n          0.432\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16278770867371437,\n        \"min\": 0.119,\n        \"max\": 0.59,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.489,\n          0.522,\n          0.119\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["metrics_df.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Frequency Domain/Alpha_CNN_LSTM.csv', index = False)"],"metadata":{"id":"Ncf_cMAQF6g4","executionInfo":{"status":"ok","timestamp":1717433900010,"user_tz":-360,"elapsed":39,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["#Draw CNN_LSTM"],"metadata":{"id":"VNy6-RxAKjH8"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import re\n","import os\n","\n","# Function to read CSV logs and extract accuracy and validation accuracy\n","def read_logs(log_dir, num_clients, local_epochs):\n","    dataframes = []\n","    for epoch in range(local_epochs):\n","        for client in range(num_clients):\n","            log_file = os.path.join(log_dir, f'training_log_epoch_{epoch}_client_{client}.csv')\n","            if os.path.exists(log_file):\n","                df = pd.read_csv(log_file, sep=';')\n","                df['epoch_number'] = epoch\n","                df['client_number'] = client\n","                dataframes.append(df)\n","            else:\n","                print(f\"Log file not found: {log_file}\")\n","\n","    return pd.concat(dataframes) if dataframes else pd.DataFrame()\n","\n","# Function to plot the training and validation accuracy\n","def plot_accuracy(all_metrics_df, unique_epochs, output_dir):\n","    # Set the Seaborn style\n","    sns.set(style=\"whitegrid\")\n","\n","    # Create subplots for each epoch\n","    fig, axes = plt.subplots(2, len(unique_epochs), figsize=(len(unique_epochs) * 3, 4.5), sharex=True)\n","\n","    # Set the color palette\n","    palette = sns.color_palette(\"Set1\", n_colors=all_metrics_df['client_number'].nunique())\n","\n","    # Store the lines and labels for the legend\n","    lines = []\n","    labels = []\n","\n","    # Iterate through each epoch and plot the training and validation accuracy\n","    for i, epoch in enumerate(unique_epochs):\n","        epoch_df = all_metrics_df[all_metrics_df['epoch_number'] == epoch]\n","        for j, client in enumerate(epoch_df['client_number'].unique()):\n","            client_df = epoch_df[epoch_df['client_number'] == client].dropna(subset=['accuracy', 'val_accuracy'])\n","            if not client_df.empty:\n","                line, = axes[0, i].plot(client_df.index, client_df['accuracy'], label=f'Client {client}', alpha=0.6, color=palette[j], linewidth=2.0)\n","                axes[1, i].plot(client_df.index, client_df['val_accuracy'], label=f'Client {client}', alpha=0.6, color=palette[j], linewidth=2.0)\n","\n","                if i == 0:\n","                    lines.append(line)\n","                    labels.append(f'Client {client}')\n","\n","        axes[0, i].set_title(f'Epoch {epoch}', fontsize=12, fontweight='bold')\n","        axes[0, i].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","        axes[1, i].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","        axes[1, i].set_xlabel('Steps', fontsize=10, fontweight='bold')\n","        axes[0, i].grid(True)\n","        axes[1, i].grid(True)\n","        axes[0, i].tick_params(axis='both', which='major', labelsize=10)\n","        axes[1, i].tick_params(axis='both', which='major', labelsize=10)\n","\n","    # Add a single legend for the entire figure\n","    fig.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, 1.0), ncol=len(labels), fontsize=10, frameon=True)\n","\n","    # Add row labels\n","    fig.text(0.04, 0.75, 'Training Accuracy', ha='center', va='center', rotation='vertical', fontsize=12, fontweight='bold')\n","    fig.text(0.04, 0.25, 'Validation Accuracy', ha='center', va='center', rotation='vertical', fontsize=12, fontweight='bold')\n","\n","    plt.tight_layout(rect=[0.05, 0, 1, 0.95])\n","    plt.subplots_adjust(hspace=0.2, top=0.88)  # Add some space between the rows and reduce space between the legend and plot\n","\n","    # Save the figure in high DPI PNG and PDF\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    fig.savefig(os.path.join(output_dir, 'accuracy_plot.png'), dpi=300, format='png')\n","    fig.savefig(os.path.join(output_dir, 'accuracy_plot.pdf'), dpi=300, format='pdf')\n","\n","    plt.show()\n","\n","# Directory where CSV logs are saved\n","log_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Alpha'\n","\n","# Output directory for saving plots\n","output_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Alpha/plots'\n","\n","# Number of clients and local epochs\n","num_clients = 3\n","local_epochs = 5\n","\n","# Read logs and generate the dataframe\n","all_metrics_df = read_logs(log_dir, num_clients, local_epochs)\n","\n","# Get unique epochs from the dataframe\n","unique_epochs = sorted(all_metrics_df['epoch_number'].unique())\n","\n","# Plot the accuracy\n","plot_accuracy(all_metrics_df, unique_epochs, output_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":462},"id":"e-S2thS6KnXT","executionInfo":{"status":"ok","timestamp":1716749578328,"user_tz":-360,"elapsed":16018,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}},"outputId":"bbc1cf86-e06d-40bb-e411-1c989efbd1fd"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x450 with 10 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import re\n","import os\n","\n","# Function to read CSV logs and extract accuracy and validation accuracy\n","def read_logs(log_dir, num_clients, local_epochs):\n","    dataframes = []\n","    for epoch in range(local_epochs):\n","        for client in range(num_clients):\n","            log_file = os.path.join(log_dir, f'training_log_epoch_{epoch}_client_{client}.csv')\n","            if os.path.exists(log_file):\n","                df = pd.read_csv(log_file, sep=';')\n","                df['epoch_number'] = epoch\n","                df['client_number'] = client\n","                dataframes.append(df)\n","            else:\n","                print(f\"Log file not found: {log_file}\")\n","\n","    return pd.concat(dataframes) if dataframes else pd.DataFrame()\n","\n","# Function to plot the training and validation accuracy for the final epoch\n","def plot_final_epoch_accuracy(all_metrics_df, output_dir):\n","    # Set the Seaborn style\n","    sns.set(style=\"whitegrid\")\n","\n","    # Get the final epoch number\n","    final_epoch = all_metrics_df['epoch_number'].max()\n","\n","    # Filter the data for the final epoch\n","    final_epoch_df = all_metrics_df[all_metrics_df['epoch_number'] == final_epoch]\n","\n","    # Calculate the average training and validation accuracy for the final epoch\n","    avg_train_accuracy = final_epoch_df['accuracy'].mean()\n","    avg_val_accuracy = final_epoch_df['val_accuracy'].mean()\n","\n","    print(f\"Final Epoch: {final_epoch}\")\n","    print(f\"Average Training Accuracy: {avg_train_accuracy:.4f}\")\n","    print(f\"Average Validation Accuracy: {avg_val_accuracy:.4f}\")\n","\n","    # Create a single plot for the final epoch\n","    fig, ax = plt.subplots(figsize=(12, 6))\n","\n","    # Set the color palette\n","    palette = sns.color_palette(\"Set1\", n_colors=final_epoch_df['client_number'].nunique())\n","\n","    # Store the lines and labels for the legend\n","    lines = []\n","    labels = []\n","\n","    # Plot the training and validation accuracy for the final epoch\n","    for client in final_epoch_df['client_number'].unique():\n","        client_df = final_epoch_df[final_epoch_df['client_number'] == client].dropna(subset=['accuracy', 'val_accuracy'])\n","        if not client_df.empty:\n","            line, = ax.plot(client_df.index, client_df['accuracy'], label=f'Training Client {client}', alpha=0.6, color=palette[client], linewidth=2.0)\n","            ax.plot(client_df.index, client_df['val_accuracy'], '--', label=f'Validation Client {client}', alpha=0.6, color=palette[client], linewidth=2.0)\n","\n","            if len(lines) < final_epoch_df['client_number'].nunique():\n","                lines.append(line)\n","                labels.append(f'Client {client}')\n","\n","    ax.set_title(f'Accuracy (Epoch {final_epoch})', fontsize=12, fontweight='bold')\n","    ax.set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","    ax.set_ylim(0.5, 1.0)  # Ensure y-axis covers full range of accuracy\n","    ax.set_xlabel('Steps', fontsize=10, fontweight='bold')\n","    ax.set_ylabel('Accuracy', fontsize=10, fontweight='bold')\n","    ax.grid(True)\n","    ax.tick_params(axis='both', which='major', labelsize=10)\n","\n","    # Add a single legend for the entire figure\n","    fig.legend(loc='lower right', bbox_to_anchor=(0.95, 0.05), fontsize=10, frameon=True)\n","\n","    # Add text for the final epoch average accuracy\n","    fig.text(0.5, 0.01, f'Final Epoch Average Training Accuracy: {avg_train_accuracy:.4f}', ha='center', fontsize=12, fontweight='bold')\n","    fig.text(0.5, -0.03, f'Final Epoch Average Validation Accuracy: {avg_val_accuracy:.4f}', ha='center', fontsize=12, fontweight='bold')\n","\n","    plt.tight_layout(rect=[0.05, 0.05, 1, 0.95])\n","\n","    # Save the figure in high DPI PNG and PDF\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    fig.savefig(os.path.join(output_dir, 'final_epoch_accuracy_plot.png'), dpi=300, format='png')\n","    fig.savefig(os.path.join(output_dir, 'final_epoch_accuracy_plot.pdf'), dpi=300, format='pdf')\n","\n","    plt.show()\n","\n","# Directory where CSV logs are saved\n","log_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Alpha'\n","\n","# Output directory for saving plots\n","output_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Alpha/plots'\n","\n","# Number of clients and local epochs\n","num_clients = 3\n","local_epochs = 5\n","\n","# Read logs and generate the dataframe\n","all_metrics_df = read_logs(log_dir, num_clients, local_epochs)\n","\n","# Plot the accuracy for the final epoch\n","plot_final_epoch_accuracy(all_metrics_df, output_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":663},"id":"NlC1cJDfRFjG","executionInfo":{"status":"ok","timestamp":1716752488442,"user_tz":-360,"elapsed":5393,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}},"outputId":"bb84b1be-3582-4a45-dd5f-3fe763e66fa6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Final Epoch: 4\n","Average Training Accuracy: 0.9812\n","Average Validation Accuracy: 0.7619\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["# CNN"],"metadata":{"id":"QUuWzfMHSNmi"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    # model.add(Dropout(0.5))\n","    # model.add(LSTM(256, return_sequences=True))\n","    # model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Alpha/CNN/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Alpha/CNN/training_log_{run_name}.csv', append=True, separator=';')\n","\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"8xrx_fxBSWGd","executionInfo":{"status":"ok","timestamp":1717434123887,"user_tz":-360,"elapsed":689,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["global_model_CNN, metrics_df_CNN = federated_learning(Theta_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H1TaNdIbSfkq","outputId":"aab60c2b-8878-4001-f5d5-2f484d1121fc","executionInfo":{"status":"ok","timestamp":1717434991047,"user_tz":-360,"elapsed":170060,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":16,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 5s 27ms/step - loss: 1.7713 - accuracy: 0.5100 - val_loss: 1.7659 - val_accuracy: 0.4978\n","Epoch 2/100\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 0s 10ms/step - loss: 1.7601 - accuracy: 0.5447 - val_loss: 1.7557 - val_accuracy: 0.4838\n","Epoch 3/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.7495 - accuracy: 0.5189 - val_loss: 1.7457 - val_accuracy: 0.4860\n","Epoch 4/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.7387 - accuracy: 0.5552 - val_loss: 1.7357 - val_accuracy: 0.4881\n","Epoch 5/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.7281 - accuracy: 0.5649 - val_loss: 1.7259 - val_accuracy: 0.4892\n","Epoch 6/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.7177 - accuracy: 0.5660 - val_loss: 1.7161 - val_accuracy: 0.5226\n","Epoch 7/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.7075 - accuracy: 0.5617 - val_loss: 1.7065 - val_accuracy: 0.4903\n","Epoch 8/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.6972 - accuracy: 0.5768 - val_loss: 1.6970 - val_accuracy: 0.5194\n","Epoch 9/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.6870 - accuracy: 0.5738 - val_loss: 1.6875 - val_accuracy: 0.5345\n","Epoch 10/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.6769 - accuracy: 0.5870 - val_loss: 1.6782 - val_accuracy: 0.5216\n","Epoch 11/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.6673 - accuracy: 0.5768 - val_loss: 1.6691 - val_accuracy: 0.4828\n","Epoch 12/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.6575 - accuracy: 0.5692 - val_loss: 1.6598 - val_accuracy: 0.5280\n","Epoch 13/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.6476 - accuracy: 0.5633 - val_loss: 1.6506 - val_accuracy: 0.5366\n","Epoch 14/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.6375 - accuracy: 0.5846 - val_loss: 1.6418 - val_accuracy: 0.5388\n","Epoch 15/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.6278 - accuracy: 0.5900 - val_loss: 1.6329 - val_accuracy: 0.5388\n","Epoch 16/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.6179 - accuracy: 0.5964 - val_loss: 1.6243 - val_accuracy: 0.5280\n","Epoch 17/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.6082 - accuracy: 0.5970 - val_loss: 1.6156 - val_accuracy: 0.5280\n","Epoch 18/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.5985 - accuracy: 0.5999 - val_loss: 1.6064 - val_accuracy: 0.5399\n","Epoch 19/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.5895 - accuracy: 0.5911 - val_loss: 1.5974 - val_accuracy: 0.5485\n","Epoch 20/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.5802 - accuracy: 0.5905 - val_loss: 1.5889 - val_accuracy: 0.5506\n","Epoch 21/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.5704 - accuracy: 0.6018 - val_loss: 1.5806 - val_accuracy: 0.5560\n","Epoch 22/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.5606 - accuracy: 0.6078 - val_loss: 1.5736 - val_accuracy: 0.5323\n","Epoch 23/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.5512 - accuracy: 0.6029 - val_loss: 1.5646 - val_accuracy: 0.5506\n","Epoch 24/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.5412 - accuracy: 0.6123 - val_loss: 1.5558 - val_accuracy: 0.5399\n","Epoch 25/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.5327 - accuracy: 0.5911 - val_loss: 1.5477 - val_accuracy: 0.5442\n","Epoch 26/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.5237 - accuracy: 0.6131 - val_loss: 1.5400 - val_accuracy: 0.5625\n","Epoch 27/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.5133 - accuracy: 0.6115 - val_loss: 1.5325 - val_accuracy: 0.5625\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.5027 - accuracy: 0.6210 - val_loss: 1.5244 - val_accuracy: 0.5593\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.4931 - accuracy: 0.6296 - val_loss: 1.5169 - val_accuracy: 0.5625\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.4836 - accuracy: 0.6320 - val_loss: 1.5104 - val_accuracy: 0.5550\n","Epoch 31/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.4735 - accuracy: 0.6304 - val_loss: 1.5026 - val_accuracy: 0.5657\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.4640 - accuracy: 0.6390 - val_loss: 1.4956 - val_accuracy: 0.5593\n","Epoch 33/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4546 - accuracy: 0.6371 - val_loss: 1.4933 - val_accuracy: 0.5496\n","Epoch 34/100\n","29/29 [==============================] - 1s 35ms/step - loss: 1.4441 - accuracy: 0.6382 - val_loss: 1.4815 - val_accuracy: 0.5754\n","Epoch 35/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.4368 - accuracy: 0.6379 - val_loss: 1.4778 - val_accuracy: 0.5625\n","Epoch 36/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.4274 - accuracy: 0.6401 - val_loss: 1.4688 - val_accuracy: 0.5744\n","Epoch 37/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.4163 - accuracy: 0.6503 - val_loss: 1.4651 - val_accuracy: 0.5765\n","Epoch 38/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.4102 - accuracy: 0.6436 - val_loss: 1.4604 - val_accuracy: 0.5560\n","Epoch 39/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3986 - accuracy: 0.6571 - val_loss: 1.4506 - val_accuracy: 0.5776\n","Epoch 40/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.3879 - accuracy: 0.6703 - val_loss: 1.4450 - val_accuracy: 0.5830\n","Epoch 41/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3781 - accuracy: 0.6689 - val_loss: 1.4382 - val_accuracy: 0.5797\n","Epoch 42/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3692 - accuracy: 0.6659 - val_loss: 1.4344 - val_accuracy: 0.5754\n","Epoch 43/100\n","29/29 [==============================] - 1s 30ms/step - loss: 1.3586 - accuracy: 0.6719 - val_loss: 1.4266 - val_accuracy: 0.5894\n","Epoch 44/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.3484 - accuracy: 0.6808 - val_loss: 1.4219 - val_accuracy: 0.5948\n","Epoch 45/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.3387 - accuracy: 0.6824 - val_loss: 1.4178 - val_accuracy: 0.5830\n","Epoch 46/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.3308 - accuracy: 0.6835 - val_loss: 1.4137 - val_accuracy: 0.5776\n","Epoch 47/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.3207 - accuracy: 0.6902 - val_loss: 1.4066 - val_accuracy: 0.5970\n","Epoch 48/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.3146 - accuracy: 0.6786 - val_loss: 1.4028 - val_accuracy: 0.5873\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3016 - accuracy: 0.6934 - val_loss: 1.3970 - val_accuracy: 0.6034\n","Epoch 50/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2980 - accuracy: 0.6886 - val_loss: 1.3935 - val_accuracy: 0.5851\n","Epoch 51/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.2836 - accuracy: 0.6985 - val_loss: 1.3946 - val_accuracy: 0.5647\n","Epoch 52/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2744 - accuracy: 0.7020 - val_loss: 1.3845 - val_accuracy: 0.5938\n","Epoch 53/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.2640 - accuracy: 0.7088 - val_loss: 1.3839 - val_accuracy: 0.5808\n","Epoch 54/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.2556 - accuracy: 0.7101 - val_loss: 1.3773 - val_accuracy: 0.5948\n","Epoch 55/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.2457 - accuracy: 0.7174 - val_loss: 1.3803 - val_accuracy: 0.5851\n","Epoch 56/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.2362 - accuracy: 0.7152 - val_loss: 1.3735 - val_accuracy: 0.5884\n","Epoch 57/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.2278 - accuracy: 0.7171 - val_loss: 1.3679 - val_accuracy: 0.6013\n","Epoch 58/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.2197 - accuracy: 0.7214 - val_loss: 1.3745 - val_accuracy: 0.5862\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2124 - accuracy: 0.7274 - val_loss: 1.3616 - val_accuracy: 0.5862\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1969 - accuracy: 0.7363 - val_loss: 1.3647 - val_accuracy: 0.5873\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1895 - accuracy: 0.7365 - val_loss: 1.3615 - val_accuracy: 0.5916\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1816 - accuracy: 0.7430 - val_loss: 1.3629 - val_accuracy: 0.5754\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1734 - accuracy: 0.7373 - val_loss: 1.3655 - val_accuracy: 0.5733\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1646 - accuracy: 0.7438 - val_loss: 1.3550 - val_accuracy: 0.6013\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1527 - accuracy: 0.7508 - val_loss: 1.3518 - val_accuracy: 0.6002\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1462 - accuracy: 0.7605 - val_loss: 1.3482 - val_accuracy: 0.5819\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1384 - accuracy: 0.7613 - val_loss: 1.3659 - val_accuracy: 0.5657\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1305 - accuracy: 0.7597 - val_loss: 1.3460 - val_accuracy: 0.5862\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1166 - accuracy: 0.7584 - val_loss: 1.3446 - val_accuracy: 0.5873\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1092 - accuracy: 0.7732 - val_loss: 1.3449 - val_accuracy: 0.5830\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1039 - accuracy: 0.7675 - val_loss: 1.3411 - val_accuracy: 0.5894\n","Epoch 72/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0899 - accuracy: 0.7818 - val_loss: 1.3460 - val_accuracy: 0.5851\n","Epoch 73/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0852 - accuracy: 0.7796 - val_loss: 1.3458 - val_accuracy: 0.5862\n","Epoch 74/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0747 - accuracy: 0.7899 - val_loss: 1.3395 - val_accuracy: 0.5970\n","Epoch 75/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0638 - accuracy: 0.7891 - val_loss: 1.3404 - val_accuracy: 0.5851\n","Epoch 76/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0550 - accuracy: 0.7845 - val_loss: 1.3421 - val_accuracy: 0.5970\n","Epoch 77/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0498 - accuracy: 0.7939 - val_loss: 1.3475 - val_accuracy: 0.5905\n","Epoch 78/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0378 - accuracy: 0.8055 - val_loss: 1.3413 - val_accuracy: 0.5916\n","Epoch 79/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0291 - accuracy: 0.8028 - val_loss: 1.3430 - val_accuracy: 0.5851\n","Epoch 80/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0216 - accuracy: 0.8033 - val_loss: 1.3468 - val_accuracy: 0.5873\n","Epoch 81/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0159 - accuracy: 0.8052 - val_loss: 1.3446 - val_accuracy: 0.5862\n","Epoch 82/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0044 - accuracy: 0.8147 - val_loss: 1.3524 - val_accuracy: 0.5927\n","Epoch 83/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0081 - accuracy: 0.8079 - val_loss: 1.3727 - val_accuracy: 0.5862\n","Epoch 84/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9948 - accuracy: 0.8106 - val_loss: 1.3753 - val_accuracy: 0.5517\n","Epoch 85/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9811 - accuracy: 0.8225 - val_loss: 1.3484 - val_accuracy: 0.5916\n","Epoch 86/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9687 - accuracy: 0.8287 - val_loss: 1.3548 - val_accuracy: 0.5776\n","Epoch 87/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9719 - accuracy: 0.8252 - val_loss: 1.3886 - val_accuracy: 0.5431\n","Epoch 88/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9589 - accuracy: 0.8273 - val_loss: 1.3538 - val_accuracy: 0.5862\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9518 - accuracy: 0.8284 - val_loss: 1.3536 - val_accuracy: 0.5948\n","Epoch 90/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9416 - accuracy: 0.8394 - val_loss: 1.3575 - val_accuracy: 0.5830\n","Epoch 91/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9319 - accuracy: 0.8402 - val_loss: 1.3575 - val_accuracy: 0.5916\n","Epoch 92/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9251 - accuracy: 0.8454 - val_loss: 1.3667 - val_accuracy: 0.5690\n","Epoch 93/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9163 - accuracy: 0.8459 - val_loss: 1.3632 - val_accuracy: 0.5819\n","Epoch 94/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9093 - accuracy: 0.8505 - val_loss: 1.3663 - val_accuracy: 0.5884\n","Epoch 95/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9118 - accuracy: 0.8419 - val_loss: 1.3695 - val_accuracy: 0.5862\n","Epoch 96/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8937 - accuracy: 0.8534 - val_loss: 1.3918 - val_accuracy: 0.5582\n","Epoch 97/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8895 - accuracy: 0.8567 - val_loss: 1.3840 - val_accuracy: 0.5636\n","Epoch 98/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8773 - accuracy: 0.8596 - val_loss: 1.3787 - val_accuracy: 0.5722\n","Epoch 99/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8791 - accuracy: 0.8532 - val_loss: 1.3761 - val_accuracy: 0.5905\n","Epoch 100/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8665 - accuracy: 0.8631 - val_loss: 1.3778 - val_accuracy: 0.5841\n","{'loss': [1.771269679069519, 1.7600582838058472, 1.7494903802871704, 1.7387028932571411, 1.7280791997909546, 1.7176941633224487, 1.7075116634368896, 1.6972254514694214, 1.686965823173523, 1.676920771598816, 1.6672935485839844, 1.6575368642807007, 1.6475944519042969, 1.637481451034546, 1.6278153657913208, 1.6179192066192627, 1.6082383394241333, 1.5985217094421387, 1.5894676446914673, 1.5801897048950195, 1.5704482793807983, 1.5606329441070557, 1.5512313842773438, 1.541152000427246, 1.5326812267303467, 1.5236992835998535, 1.513317346572876, 1.5027439594268799, 1.4931397438049316, 1.483595371246338, 1.4735053777694702, 1.463962197303772, 1.4546167850494385, 1.444109320640564, 1.4367742538452148, 1.4274163246154785, 1.416344165802002, 1.4102489948272705, 1.3986341953277588, 1.3878589868545532, 1.3780912160873413, 1.3692173957824707, 1.358599305152893, 1.3484148979187012, 1.3386763334274292, 1.3307745456695557, 1.3206980228424072, 1.3146240711212158, 1.301551103591919, 1.2979912757873535, 1.2836023569107056, 1.2743914127349854, 1.263980746269226, 1.2555994987487793, 1.245700478553772, 1.236228108406067, 1.2277586460113525, 1.219739556312561, 1.212364673614502, 1.1969109773635864, 1.1894845962524414, 1.181581735610962, 1.1734029054641724, 1.164628505706787, 1.1526598930358887, 1.1461858749389648, 1.138422966003418, 1.130548357963562, 1.1166329383850098, 1.1091721057891846, 1.1039260625839233, 1.089880347251892, 1.0852305889129639, 1.0746753215789795, 1.0638034343719482, 1.0549546480178833, 1.049771785736084, 1.0378214120864868, 1.0291433334350586, 1.0215643644332886, 1.0158923864364624, 1.0044052600860596, 1.0080994367599487, 0.9948148131370544, 0.9811102747917175, 0.9687265753746033, 0.9718844294548035, 0.95893394947052, 0.9518492221832275, 0.9415969252586365, 0.9318634271621704, 0.9250857830047607, 0.9162552356719971, 0.9093275666236877, 0.9117999076843262, 0.893740177154541, 0.8894966244697571, 0.8772971034049988, 0.879132091999054, 0.8665451407432556], 'accuracy': [0.5099676847457886, 0.5447198152542114, 0.5188577771186829, 0.5552262663841248, 0.5649245977401733, 0.5660021305084229, 0.5616918206214905, 0.576777994632721, 0.5738146305084229, 0.5870150923728943, 0.576777994632721, 0.5692349076271057, 0.5633081793785095, 0.584590494632721, 0.5899784564971924, 0.5964439511299133, 0.5969827771186829, 0.599946141242981, 0.5910560488700867, 0.5905172228813171, 0.6018319129943848, 0.607758641242981, 0.602909505367279, 0.6123383641242981, 0.5910560488700867, 0.6131465435028076, 0.6115301847457886, 0.6209590435028076, 0.6295797228813171, 0.6320043206214905, 0.6303879022598267, 0.639008641242981, 0.6371228694915771, 0.6382004022598267, 0.6379310488700867, 0.6400862336158752, 0.6503232717514038, 0.6435883641242981, 0.6570581793785095, 0.670258641242981, 0.6689116358757019, 0.6659482717514038, 0.671875, 0.6807650923728943, 0.6823814511299133, 0.6834590435028076, 0.6901939511299133, 0.6786099076271057, 0.6934267282485962, 0.6885775923728943, 0.6985452771186829, 0.7020474076271057, 0.7087823152542114, 0.7101293206214905, 0.717402994632721, 0.7152478694915771, 0.717133641242981, 0.7214439511299133, 0.7273706793785095, 0.7362607717514038, 0.7365301847457886, 0.7429956793785095, 0.7373383641242981, 0.743803858757019, 0.7508081793785095, 0.7605064511299133, 0.7613146305084229, 0.7596982717514038, 0.7583512663841248, 0.7731680870056152, 0.7675107717514038, 0.7817887663841248, 0.779633641242981, 0.7898706793785095, 0.7890625, 0.7844827771186829, 0.7939116358757019, 0.8054956793785095, 0.8028017282485962, 0.803340494632721, 0.8052262663841248, 0.8146551847457886, 0.8079202771186829, 0.8106142282485962, 0.8224676847457886, 0.8286637663841248, 0.8251616358757019, 0.8273168206214905, 0.8283944129943848, 0.8394396305084229, 0.8402478694915771, 0.845366358757019, 0.8459051847457886, 0.8504849076271057, 0.8418642282485962, 0.8534482717514038, 0.8566810488700867, 0.8596444129943848, 0.853178858757019, 0.8631465435028076], 'val_loss': [1.7658668756484985, 1.7557092905044556, 1.745674967765808, 1.735718011856079, 1.7258812189102173, 1.716117024421692, 1.706520915031433, 1.696958303451538, 1.6874524354934692, 1.6781866550445557, 1.6690895557403564, 1.6598254442214966, 1.6505824327468872, 1.6418288946151733, 1.632921814918518, 1.6243113279342651, 1.6155587434768677, 1.6063573360443115, 1.5974313020706177, 1.5888841152191162, 1.5806303024291992, 1.573636770248413, 1.5646332502365112, 1.5558217763900757, 1.5476785898208618, 1.5399515628814697, 1.5324647426605225, 1.5244064331054688, 1.5168788433074951, 1.5104069709777832, 1.5025925636291504, 1.4955613613128662, 1.4933239221572876, 1.4815186262130737, 1.4777805805206299, 1.468785285949707, 1.465094804763794, 1.4604456424713135, 1.4506137371063232, 1.4449622631072998, 1.4382480382919312, 1.4343570470809937, 1.4265944957733154, 1.4218789339065552, 1.4177672863006592, 1.4136642217636108, 1.4065923690795898, 1.402761697769165, 1.3969721794128418, 1.3935253620147705, 1.3946422338485718, 1.3844962120056152, 1.383924961090088, 1.3772770166397095, 1.380272388458252, 1.3734604120254517, 1.3678736686706543, 1.3744611740112305, 1.3615968227386475, 1.3647328615188599, 1.3614647388458252, 1.3628613948822021, 1.3655232191085815, 1.3550429344177246, 1.3518176078796387, 1.348173975944519, 1.3659104108810425, 1.3460427522659302, 1.3446162939071655, 1.3448933362960815, 1.341139554977417, 1.3460214138031006, 1.3457655906677246, 1.3395363092422485, 1.3403524160385132, 1.342057228088379, 1.347456693649292, 1.341261386871338, 1.342950463294983, 1.3468360900878906, 1.3446030616760254, 1.3523714542388916, 1.3726627826690674, 1.3752787113189697, 1.3483762741088867, 1.3547812700271606, 1.3885877132415771, 1.353844404220581, 1.3535834550857544, 1.357494592666626, 1.3575422763824463, 1.3666636943817139, 1.3632004261016846, 1.3662807941436768, 1.3695162534713745, 1.3918421268463135, 1.384040355682373, 1.378686547279358, 1.3761388063430786, 1.3777958154678345], 'val_accuracy': [0.4978448152542114, 0.48383620381355286, 0.48599138855934143, 0.4881465435028076, 0.4892241358757019, 0.5226293206214905, 0.4903017282485962, 0.5193965435028076, 0.5344827771186829, 0.5215517282485962, 0.48275861144065857, 0.5280172228813171, 0.5366379022598267, 0.5387930870056152, 0.5387930870056152, 0.5280172228813171, 0.5280172228813171, 0.5398706793785095, 0.548491358757019, 0.5506465435028076, 0.556034505367279, 0.5323275923728943, 0.5506465435028076, 0.5398706793785095, 0.5441810488700867, 0.5625, 0.5625, 0.5592672228813171, 0.5625, 0.5549569129943848, 0.5657327771186829, 0.5592672228813171, 0.5495689511299133, 0.5754310488700867, 0.5625, 0.5743534564971924, 0.576508641242981, 0.556034505367279, 0.5775862336158752, 0.5829741358757019, 0.579741358757019, 0.5754310488700867, 0.5894396305084229, 0.5948275923728943, 0.5829741358757019, 0.5775862336158752, 0.5969827771186829, 0.587284505367279, 0.6034482717514038, 0.5851293206214905, 0.5646551847457886, 0.59375, 0.5808189511299133, 0.5948275923728943, 0.5851293206214905, 0.5883620977401733, 0.6012930870056152, 0.5862069129943848, 0.5862069129943848, 0.587284505367279, 0.5915948152542114, 0.5754310488700867, 0.5732758641242981, 0.6012930870056152, 0.600215494632721, 0.5818965435028076, 0.5657327771186829, 0.5862069129943848, 0.587284505367279, 0.5829741358757019, 0.5894396305084229, 0.5851293206214905, 0.5862069129943848, 0.5969827771186829, 0.5851293206214905, 0.5969827771186829, 0.5905172228813171, 0.5915948152542114, 0.5851293206214905, 0.587284505367279, 0.5862069129943848, 0.5926724076271057, 0.5862069129943848, 0.5517241358757019, 0.5915948152542114, 0.5775862336158752, 0.5431034564971924, 0.5862069129943848, 0.5948275923728943, 0.5829741358757019, 0.5915948152542114, 0.568965494632721, 0.5818965435028076, 0.5883620977401733, 0.5862069129943848, 0.5581896305084229, 0.5635775923728943, 0.5721982717514038, 0.5905172228813171, 0.5840517282485962]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 1.7719 - accuracy: 0.4931"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 4s 68ms/step - loss: 1.7718 - accuracy: 0.4943 - val_loss: 1.7662 - val_accuracy: 0.5034\n","Epoch 2/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.7607 - accuracy: 0.5173 - val_loss: 1.7562 - val_accuracy: 0.5068\n","Epoch 3/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.7502 - accuracy: 0.5532 - val_loss: 1.7464 - val_accuracy: 0.4887\n","Epoch 4/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.7398 - accuracy: 0.5453 - val_loss: 1.7366 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.7296 - accuracy: 0.5470 - val_loss: 1.7270 - val_accuracy: 0.4977\n","Epoch 6/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.7195 - accuracy: 0.5577 - val_loss: 1.7175 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.7095 - accuracy: 0.5504 - val_loss: 1.7081 - val_accuracy: 0.4943\n","Epoch 8/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6993 - accuracy: 0.5665 - val_loss: 1.6989 - val_accuracy: 0.4966\n","Epoch 9/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6896 - accuracy: 0.5804 - val_loss: 1.6898 - val_accuracy: 0.4932\n","Epoch 10/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.6794 - accuracy: 0.5812 - val_loss: 1.6806 - val_accuracy: 0.5181\n","Epoch 11/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.6700 - accuracy: 0.5560 - val_loss: 1.6718 - val_accuracy: 0.5034\n","Epoch 12/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.6602 - accuracy: 0.5753 - val_loss: 1.6629 - val_accuracy: 0.5215\n","Epoch 13/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6501 - accuracy: 0.6061 - val_loss: 1.6542 - val_accuracy: 0.5090\n","Epoch 14/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.6406 - accuracy: 0.5971 - val_loss: 1.6455 - val_accuracy: 0.5238\n","Epoch 15/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.6313 - accuracy: 0.5962 - val_loss: 1.6369 - val_accuracy: 0.5249\n","Epoch 16/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6226 - accuracy: 0.5806 - val_loss: 1.6284 - val_accuracy: 0.5249\n","Epoch 17/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6120 - accuracy: 0.6067 - val_loss: 1.6201 - val_accuracy: 0.5158\n","Epoch 18/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.6026 - accuracy: 0.5996 - val_loss: 1.6119 - val_accuracy: 0.5090\n","Epoch 19/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.5931 - accuracy: 0.6067 - val_loss: 1.6034 - val_accuracy: 0.5249\n","Epoch 20/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.5834 - accuracy: 0.6058 - val_loss: 1.5951 - val_accuracy: 0.5385\n","Epoch 21/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.5750 - accuracy: 0.5965 - val_loss: 1.5872 - val_accuracy: 0.5260\n","Epoch 22/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.5643 - accuracy: 0.6098 - val_loss: 1.5789 - val_accuracy: 0.5339\n","Epoch 23/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.5548 - accuracy: 0.6143 - val_loss: 1.5713 - val_accuracy: 0.5396\n","Epoch 24/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5460 - accuracy: 0.6152 - val_loss: 1.5636 - val_accuracy: 0.5339\n","Epoch 25/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5366 - accuracy: 0.6135 - val_loss: 1.5568 - val_accuracy: 0.5385\n","Epoch 26/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5283 - accuracy: 0.6070 - val_loss: 1.5484 - val_accuracy: 0.5339\n","Epoch 27/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5174 - accuracy: 0.6200 - val_loss: 1.5405 - val_accuracy: 0.5419\n","Epoch 28/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.5081 - accuracy: 0.6239 - val_loss: 1.5343 - val_accuracy: 0.5305\n","Epoch 29/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4985 - accuracy: 0.6262 - val_loss: 1.5264 - val_accuracy: 0.5498\n","Epoch 30/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.4894 - accuracy: 0.6302 - val_loss: 1.5215 - val_accuracy: 0.5362\n","Epoch 31/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4805 - accuracy: 0.6234 - val_loss: 1.5117 - val_accuracy: 0.5520\n","Epoch 32/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4696 - accuracy: 0.6282 - val_loss: 1.5067 - val_accuracy: 0.5509\n","Epoch 33/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4607 - accuracy: 0.6327 - val_loss: 1.4998 - val_accuracy: 0.5407\n","Epoch 34/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4504 - accuracy: 0.6446 - val_loss: 1.4932 - val_accuracy: 0.5509\n","Epoch 35/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4411 - accuracy: 0.6406 - val_loss: 1.4876 - val_accuracy: 0.5464\n","Epoch 36/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4315 - accuracy: 0.6463 - val_loss: 1.4819 - val_accuracy: 0.5441\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4227 - accuracy: 0.6491 - val_loss: 1.4757 - val_accuracy: 0.5543\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4133 - accuracy: 0.6573 - val_loss: 1.4691 - val_accuracy: 0.5554\n","Epoch 39/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.4042 - accuracy: 0.6545 - val_loss: 1.4638 - val_accuracy: 0.5554\n","Epoch 40/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3943 - accuracy: 0.6630 - val_loss: 1.4569 - val_accuracy: 0.5577\n","Epoch 41/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3855 - accuracy: 0.6585 - val_loss: 1.4525 - val_accuracy: 0.5611\n","Epoch 42/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.3780 - accuracy: 0.6619 - val_loss: 1.4562 - val_accuracy: 0.5532\n","Epoch 43/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.3667 - accuracy: 0.6701 - val_loss: 1.4417 - val_accuracy: 0.5588\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3572 - accuracy: 0.6706 - val_loss: 1.4365 - val_accuracy: 0.5656\n","Epoch 45/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.3474 - accuracy: 0.6797 - val_loss: 1.4314 - val_accuracy: 0.5566\n","Epoch 46/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.3391 - accuracy: 0.6853 - val_loss: 1.4254 - val_accuracy: 0.5633\n","Epoch 47/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3323 - accuracy: 0.6735 - val_loss: 1.4335 - val_accuracy: 0.5747\n","Epoch 48/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3225 - accuracy: 0.6802 - val_loss: 1.4186 - val_accuracy: 0.5611\n","Epoch 49/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3122 - accuracy: 0.6907 - val_loss: 1.4135 - val_accuracy: 0.5690\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3035 - accuracy: 0.6950 - val_loss: 1.4087 - val_accuracy: 0.5656\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2930 - accuracy: 0.7046 - val_loss: 1.4041 - val_accuracy: 0.5633\n","Epoch 52/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2847 - accuracy: 0.6958 - val_loss: 1.4033 - val_accuracy: 0.5656\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2755 - accuracy: 0.7125 - val_loss: 1.3997 - val_accuracy: 0.5679\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2661 - accuracy: 0.7156 - val_loss: 1.3938 - val_accuracy: 0.5667\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2578 - accuracy: 0.7145 - val_loss: 1.3894 - val_accuracy: 0.5622\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2555 - accuracy: 0.7145 - val_loss: 1.3848 - val_accuracy: 0.5656\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2392 - accuracy: 0.7235 - val_loss: 1.3816 - val_accuracy: 0.5679\n","Epoch 58/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2303 - accuracy: 0.7230 - val_loss: 1.3853 - val_accuracy: 0.5554\n","Epoch 59/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.2247 - accuracy: 0.7295 - val_loss: 1.3796 - val_accuracy: 0.5611\n","Epoch 60/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2171 - accuracy: 0.7196 - val_loss: 1.3846 - val_accuracy: 0.5543\n","Epoch 61/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2069 - accuracy: 0.7284 - val_loss: 1.3771 - val_accuracy: 0.5633\n","Epoch 62/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1977 - accuracy: 0.7391 - val_loss: 1.3694 - val_accuracy: 0.5758\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1877 - accuracy: 0.7425 - val_loss: 1.3679 - val_accuracy: 0.5792\n","Epoch 64/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1814 - accuracy: 0.7450 - val_loss: 1.3767 - val_accuracy: 0.5735\n","Epoch 65/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1708 - accuracy: 0.7490 - val_loss: 1.3584 - val_accuracy: 0.5882\n","Epoch 66/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1636 - accuracy: 0.7445 - val_loss: 1.3648 - val_accuracy: 0.5724\n","Epoch 67/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1551 - accuracy: 0.7484 - val_loss: 1.3592 - val_accuracy: 0.5724\n","Epoch 68/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1451 - accuracy: 0.7634 - val_loss: 1.3498 - val_accuracy: 0.5826\n","Epoch 69/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1352 - accuracy: 0.7640 - val_loss: 1.3530 - val_accuracy: 0.5724\n","Epoch 70/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1294 - accuracy: 0.7620 - val_loss: 1.3543 - val_accuracy: 0.5814\n","Epoch 71/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1192 - accuracy: 0.7666 - val_loss: 1.3640 - val_accuracy: 0.5837\n","Epoch 72/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1255 - accuracy: 0.7482 - val_loss: 1.3415 - val_accuracy: 0.5747\n","Epoch 73/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1036 - accuracy: 0.7767 - val_loss: 1.3535 - val_accuracy: 0.5814\n","Epoch 74/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0937 - accuracy: 0.7728 - val_loss: 1.3413 - val_accuracy: 0.5690\n","Epoch 75/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0862 - accuracy: 0.7852 - val_loss: 1.3522 - val_accuracy: 0.5826\n","Epoch 76/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0794 - accuracy: 0.7847 - val_loss: 1.3394 - val_accuracy: 0.5837\n","Epoch 77/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0704 - accuracy: 0.7895 - val_loss: 1.3427 - val_accuracy: 0.5781\n","Epoch 78/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0647 - accuracy: 0.7855 - val_loss: 1.3409 - val_accuracy: 0.5860\n","Epoch 79/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0516 - accuracy: 0.7960 - val_loss: 1.3403 - val_accuracy: 0.5679\n","Epoch 80/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0454 - accuracy: 0.7988 - val_loss: 1.3462 - val_accuracy: 0.5781\n","Epoch 81/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0361 - accuracy: 0.7994 - val_loss: 1.3434 - val_accuracy: 0.5826\n","Epoch 82/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0281 - accuracy: 0.8076 - val_loss: 1.3473 - val_accuracy: 0.5690\n","Epoch 83/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0298 - accuracy: 0.7943 - val_loss: 1.3471 - val_accuracy: 0.5905\n","Epoch 84/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0121 - accuracy: 0.8127 - val_loss: 1.3405 - val_accuracy: 0.5769\n","Epoch 85/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0151 - accuracy: 0.7982 - val_loss: 1.3433 - val_accuracy: 0.5758\n","Epoch 86/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9987 - accuracy: 0.8161 - val_loss: 1.3476 - val_accuracy: 0.5656\n","Epoch 87/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9894 - accuracy: 0.8217 - val_loss: 1.3620 - val_accuracy: 0.5882\n","Epoch 88/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9823 - accuracy: 0.8217 - val_loss: 1.3412 - val_accuracy: 0.5735\n","Epoch 89/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9729 - accuracy: 0.8285 - val_loss: 1.3482 - val_accuracy: 0.5679\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9658 - accuracy: 0.8282 - val_loss: 1.3434 - val_accuracy: 0.5814\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9575 - accuracy: 0.8339 - val_loss: 1.3542 - val_accuracy: 0.5645\n","Epoch 92/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9481 - accuracy: 0.8345 - val_loss: 1.3475 - val_accuracy: 0.5916\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9438 - accuracy: 0.8311 - val_loss: 1.3565 - val_accuracy: 0.5633\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9352 - accuracy: 0.8387 - val_loss: 1.3554 - val_accuracy: 0.5916\n","Epoch 95/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9377 - accuracy: 0.8314 - val_loss: 1.3578 - val_accuracy: 0.5611\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9293 - accuracy: 0.8353 - val_loss: 1.3557 - val_accuracy: 0.5588\n","Epoch 97/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9141 - accuracy: 0.8418 - val_loss: 1.3742 - val_accuracy: 0.5611\n","Epoch 98/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9071 - accuracy: 0.8489 - val_loss: 1.4044 - val_accuracy: 0.5950\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9335 - accuracy: 0.8124 - val_loss: 1.3875 - val_accuracy: 0.5532\n","Epoch 100/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8940 - accuracy: 0.8500 - val_loss: 1.3561 - val_accuracy: 0.5758\n","{'loss': [1.7717604637145996, 1.760710597038269, 1.7502244710922241, 1.7397853136062622, 1.7295643091201782, 1.719465732574463, 1.709486722946167, 1.6993162631988525, 1.6895911693572998, 1.679360270500183, 1.6699645519256592, 1.6602237224578857, 1.650124430656433, 1.640550136566162, 1.631301760673523, 1.622562050819397, 1.6119552850723267, 1.6026097536087036, 1.5931302309036255, 1.583364725112915, 1.5750154256820679, 1.5642786026000977, 1.5548170804977417, 1.545965552330017, 1.5365930795669556, 1.5282933712005615, 1.5174120664596558, 1.5080538988113403, 1.4984654188156128, 1.4893543720245361, 1.4805338382720947, 1.4695936441421509, 1.4606980085372925, 1.4504443407058716, 1.4410662651062012, 1.4315426349639893, 1.4227374792099, 1.4132533073425293, 1.404152512550354, 1.3942911624908447, 1.3855104446411133, 1.378008246421814, 1.366726040840149, 1.357161045074463, 1.347448468208313, 1.3391468524932861, 1.332345962524414, 1.3225352764129639, 1.3121938705444336, 1.3035061359405518, 1.2929590940475464, 1.2846558094024658, 1.2754592895507812, 1.266134262084961, 1.2577753067016602, 1.2555160522460938, 1.239200472831726, 1.2302792072296143, 1.2247214317321777, 1.2170711755752563, 1.2069123983383179, 1.1977050304412842, 1.1876957416534424, 1.1813546419143677, 1.1707531213760376, 1.1636202335357666, 1.1550724506378174, 1.1451225280761719, 1.135219693183899, 1.129441738128662, 1.1192139387130737, 1.1254563331604004, 1.103615164756775, 1.0937490463256836, 1.0862067937850952, 1.079372763633728, 1.0704375505447388, 1.06468665599823, 1.0515867471694946, 1.045407772064209, 1.036129117012024, 1.0280636548995972, 1.0297596454620361, 1.0120927095413208, 1.0150761604309082, 0.9987315535545349, 0.9894008636474609, 0.9823203086853027, 0.9729467034339905, 0.965828537940979, 0.9574783444404602, 0.9481366276741028, 0.9437756538391113, 0.9351668357849121, 0.9376599192619324, 0.929345428943634, 0.9141367077827454, 0.9070609211921692, 0.9334996342658997, 0.8939729928970337], 'accuracy': [0.4943406879901886, 0.5172609090805054, 0.5531975030899048, 0.5452744960784912, 0.5469722747802734, 0.5577249526977539, 0.5503678321838379, 0.5664969086647034, 0.5803622007369995, 0.5812110900878906, 0.5560271739959717, 0.5752688050270081, 0.6061120629310608, 0.5970571637153625, 0.5962082743644714, 0.5806451439857483, 0.6066780090332031, 0.5996038317680359, 0.6066780090332031, 0.6058290600776672, 0.5964912176132202, 0.6097906231880188, 0.6143180727958679, 0.615166962146759, 0.6134691834449768, 0.6069609522819519, 0.6199773550033569, 0.6239388585090637, 0.6262025833129883, 0.6301641464233398, 0.6233729720115662, 0.6281833648681641, 0.6327108144760132, 0.6445953845977783, 0.6406338214874268, 0.6462931632995605, 0.6491228342056274, 0.6573287844657898, 0.6544991731643677, 0.6629881262779236, 0.6584606766700745, 0.6618562340736389, 0.670062243938446, 0.6706281900405884, 0.6796830892562866, 0.6853423714637756, 0.6734578609466553, 0.680249035358429, 0.6907187104225159, 0.6949632167816162, 0.7045840620994568, 0.6958121061325073, 0.7125070691108704, 0.715619683265686, 0.7144878506660461, 0.7144878506660461, 0.7235427498817444, 0.722976803779602, 0.7294849753379822, 0.7195811867713928, 0.7283531427383423, 0.7391058206558228, 0.742501437664032, 0.7450481057167053, 0.7490096092224121, 0.744482159614563, 0.7484436631202698, 0.7634408473968506, 0.7640067934989929, 0.7620260119438171, 0.7665534615516663, 0.748160719871521, 0.7767402529716492, 0.7727787494659424, 0.7852292060852051, 0.7846632599830627, 0.7894737124443054, 0.7855121493339539, 0.7959818840026855, 0.7988115549087524, 0.7993775010108948, 0.8075834512710571, 0.7942841053009033, 0.8126768469810486, 0.7982456088066101, 0.8160724639892578, 0.8217317461967468, 0.8217317461967468, 0.8285229206085205, 0.8282399773597717, 0.8338992595672607, 0.8344652056694031, 0.8310695886611938, 0.8387096524238586, 0.8313525915145874, 0.8353140950202942, 0.8418223261833191, 0.8488964438438416, 0.8123939037322998, 0.8500282764434814], 'val_loss': [1.7662007808685303, 1.7562259435653687, 1.7463762760162354, 1.736632227897644, 1.7270251512527466, 1.7175185680389404, 1.7081292867660522, 1.6988862752914429, 1.6897526979446411, 1.6806451082229614, 1.6717737913131714, 1.6628923416137695, 1.654160976409912, 1.6454782485961914, 1.6369240283966064, 1.6284022331237793, 1.6200824975967407, 1.6119109392166138, 1.6034318208694458, 1.5950928926467896, 1.587188482284546, 1.5788533687591553, 1.5713108777999878, 1.563639760017395, 1.5567641258239746, 1.5483555793762207, 1.5404729843139648, 1.534287452697754, 1.5263540744781494, 1.5215340852737427, 1.5117472410202026, 1.5066558122634888, 1.4997756481170654, 1.4932196140289307, 1.4875587224960327, 1.4818891286849976, 1.4756520986557007, 1.4690779447555542, 1.4637782573699951, 1.4569228887557983, 1.452542781829834, 1.4561843872070312, 1.4416722059249878, 1.4365234375, 1.4314484596252441, 1.425385594367981, 1.4335466623306274, 1.4185680150985718, 1.413466453552246, 1.408665418624878, 1.4041261672973633, 1.403330683708191, 1.3997352123260498, 1.393836259841919, 1.3893591165542603, 1.3847609758377075, 1.381608247756958, 1.385254144668579, 1.3795619010925293, 1.3846211433410645, 1.3770785331726074, 1.369398832321167, 1.3679296970367432, 1.3767240047454834, 1.3583682775497437, 1.3647775650024414, 1.3591639995574951, 1.3498250246047974, 1.3529821634292603, 1.3542839288711548, 1.3639837503433228, 1.341505765914917, 1.3534753322601318, 1.341259479522705, 1.3522452116012573, 1.3394269943237305, 1.3427393436431885, 1.3408558368682861, 1.3402878046035767, 1.3461962938308716, 1.3433504104614258, 1.347290277481079, 1.3470748662948608, 1.3405165672302246, 1.3433095216751099, 1.3476297855377197, 1.3620043992996216, 1.3411650657653809, 1.348235011100769, 1.3434165716171265, 1.3542357683181763, 1.3474808931350708, 1.3565469980239868, 1.35540771484375, 1.3577982187271118, 1.3556795120239258, 1.3741838932037354, 1.4044015407562256, 1.3875120878219604, 1.3561302423477173], 'val_accuracy': [0.5033936500549316, 0.5067873597145081, 0.48868778347969055, 0.4954751133918762, 0.4977375566959381, 0.4954751133918762, 0.4943438768386841, 0.49660632014274597, 0.49321267008781433, 0.5180995464324951, 0.5033936500549316, 0.5214931964874268, 0.5090497732162476, 0.523755669593811, 0.5248869061470032, 0.5248869061470032, 0.5158371329307556, 0.5090497732162476, 0.5248869061470032, 0.5384615659713745, 0.5260180830955505, 0.5339366793632507, 0.5395927429199219, 0.5339366793632507, 0.5384615659713745, 0.5339366793632507, 0.5418552160263062, 0.5305429697036743, 0.5497737526893616, 0.5361990928649902, 0.5520362257957458, 0.5509049892425537, 0.540723979473114, 0.5509049892425537, 0.5463801026344299, 0.5441176295280457, 0.5542986392974854, 0.5554298758506775, 0.5554298758506775, 0.557692289352417, 0.5610859990119934, 0.5531674027442932, 0.5588235259056091, 0.5656108856201172, 0.5565611124038696, 0.5633484125137329, 0.5746606588363647, 0.5610859990119934, 0.5690045356750488, 0.5656108856201172, 0.5633484125137329, 0.5656108856201172, 0.5678732991218567, 0.5667420625686646, 0.5622171759605408, 0.5656108856201172, 0.5678732991218567, 0.5554298758506775, 0.5610859990119934, 0.5542986392974854, 0.5633484125137329, 0.5757918357849121, 0.5791855454444885, 0.5735294222831726, 0.5882353186607361, 0.5723981857299805, 0.5723981857299805, 0.5825791954994202, 0.5723981857299805, 0.581447958946228, 0.5837104320526123, 0.5746606588363647, 0.581447958946228, 0.5690045356750488, 0.5825791954994202, 0.5837104320526123, 0.5780543088912964, 0.5859728455543518, 0.5678732991218567, 0.5780543088912964, 0.5825791954994202, 0.5690045356750488, 0.5904977321624756, 0.5769230723381042, 0.5757918357849121, 0.5656108856201172, 0.5882353186607361, 0.5735294222831726, 0.5678732991218567, 0.581447958946228, 0.564479649066925, 0.5916289687156677, 0.5633484125137329, 0.5916289687156677, 0.5610859990119934, 0.5588235259056091, 0.5610859990119934, 0.5950226187705994, 0.5531674027442932, 0.5757918357849121]}\n","45/45 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 3s 28ms/step - loss: 1.7707 - accuracy: 0.4982 - val_loss: 1.7652 - val_accuracy: 0.4897\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 1.7626 - accuracy: 0.5859"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 0s 15ms/step - loss: 1.7583 - accuracy: 0.5165 - val_loss: 1.7543 - val_accuracy: 0.5072\n","Epoch 3/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.7463 - accuracy: 0.5362 - val_loss: 1.7435 - val_accuracy: 0.4969\n","Epoch 4/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.7349 - accuracy: 0.5320 - val_loss: 1.7329 - val_accuracy: 0.4948\n","Epoch 5/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.7236 - accuracy: 0.5362 - val_loss: 1.7224 - val_accuracy: 0.4979\n","Epoch 6/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.7124 - accuracy: 0.5398 - val_loss: 1.7120 - val_accuracy: 0.4990\n","Epoch 7/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.7010 - accuracy: 0.5411 - val_loss: 1.7017 - val_accuracy: 0.5010\n","Epoch 8/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.6899 - accuracy: 0.5509 - val_loss: 1.6917 - val_accuracy: 0.5000\n","Epoch 9/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.6792 - accuracy: 0.5576 - val_loss: 1.6817 - val_accuracy: 0.5021\n","Epoch 10/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.6678 - accuracy: 0.5628 - val_loss: 1.6718 - val_accuracy: 0.5186\n","Epoch 11/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.6571 - accuracy: 0.5724 - val_loss: 1.6622 - val_accuracy: 0.5145\n","Epoch 12/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.6464 - accuracy: 0.5698 - val_loss: 1.6529 - val_accuracy: 0.5031\n","Epoch 13/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.6358 - accuracy: 0.5690 - val_loss: 1.6436 - val_accuracy: 0.5021\n","Epoch 14/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.6254 - accuracy: 0.5811 - val_loss: 1.6339 - val_accuracy: 0.4979\n","Epoch 15/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.6151 - accuracy: 0.5863 - val_loss: 1.6248 - val_accuracy: 0.4959\n","Epoch 16/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.6044 - accuracy: 0.5796 - val_loss: 1.6160 - val_accuracy: 0.5062\n","Epoch 17/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.5942 - accuracy: 0.5889 - val_loss: 1.6072 - val_accuracy: 0.4969\n","Epoch 18/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5837 - accuracy: 0.5935 - val_loss: 1.5984 - val_accuracy: 0.5021\n","Epoch 19/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.5734 - accuracy: 0.5873 - val_loss: 1.5907 - val_accuracy: 0.5145\n","Epoch 20/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.5632 - accuracy: 0.6041 - val_loss: 1.5823 - val_accuracy: 0.4979\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.5533 - accuracy: 0.5951 - val_loss: 1.5741 - val_accuracy: 0.5083\n","Epoch 22/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5440 - accuracy: 0.5930 - val_loss: 1.5670 - val_accuracy: 0.5103\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.5337 - accuracy: 0.6093 - val_loss: 1.5599 - val_accuracy: 0.5083\n","Epoch 24/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5243 - accuracy: 0.6018 - val_loss: 1.5528 - val_accuracy: 0.5145\n","Epoch 25/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.5133 - accuracy: 0.6096 - val_loss: 1.5461 - val_accuracy: 0.5124\n","Epoch 26/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.5034 - accuracy: 0.6183 - val_loss: 1.5396 - val_accuracy: 0.5124\n","Epoch 27/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.4939 - accuracy: 0.6178 - val_loss: 1.5327 - val_accuracy: 0.5217\n","Epoch 28/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.4843 - accuracy: 0.6245 - val_loss: 1.5269 - val_accuracy: 0.5217\n","Epoch 29/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.4741 - accuracy: 0.6245 - val_loss: 1.5209 - val_accuracy: 0.5258\n","Epoch 30/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.4634 - accuracy: 0.6297 - val_loss: 1.5234 - val_accuracy: 0.5041\n","Epoch 31/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4565 - accuracy: 0.6253 - val_loss: 1.5092 - val_accuracy: 0.5289\n","Epoch 32/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.4469 - accuracy: 0.6261 - val_loss: 1.5061 - val_accuracy: 0.5207\n","Epoch 33/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4363 - accuracy: 0.6390 - val_loss: 1.4976 - val_accuracy: 0.5310\n","Epoch 34/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.4274 - accuracy: 0.6463 - val_loss: 1.4948 - val_accuracy: 0.5300\n","Epoch 35/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.4185 - accuracy: 0.6351 - val_loss: 1.4879 - val_accuracy: 0.5382\n","Epoch 36/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.4067 - accuracy: 0.6514 - val_loss: 1.4833 - val_accuracy: 0.5248\n","Epoch 37/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.3965 - accuracy: 0.6566 - val_loss: 1.4794 - val_accuracy: 0.5310\n","Epoch 38/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3883 - accuracy: 0.6537 - val_loss: 1.4760 - val_accuracy: 0.5403\n","Epoch 39/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3775 - accuracy: 0.6636 - val_loss: 1.4705 - val_accuracy: 0.5341\n","Epoch 40/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.3682 - accuracy: 0.6661 - val_loss: 1.4650 - val_accuracy: 0.5351\n","Epoch 41/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3587 - accuracy: 0.6708 - val_loss: 1.4606 - val_accuracy: 0.5341\n","Epoch 42/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.3491 - accuracy: 0.6788 - val_loss: 1.4576 - val_accuracy: 0.5362\n","Epoch 43/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3403 - accuracy: 0.6770 - val_loss: 1.4539 - val_accuracy: 0.5413\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3313 - accuracy: 0.6731 - val_loss: 1.4519 - val_accuracy: 0.5444\n","Epoch 45/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.3264 - accuracy: 0.6641 - val_loss: 1.4430 - val_accuracy: 0.5362\n","Epoch 46/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3154 - accuracy: 0.6840 - val_loss: 1.4404 - val_accuracy: 0.5424\n","Epoch 47/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.3036 - accuracy: 0.6946 - val_loss: 1.4360 - val_accuracy: 0.5372\n","Epoch 48/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2950 - accuracy: 0.6966 - val_loss: 1.4393 - val_accuracy: 0.5527\n","Epoch 49/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2873 - accuracy: 0.6972 - val_loss: 1.4358 - val_accuracy: 0.5548\n","Epoch 50/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2770 - accuracy: 0.7016 - val_loss: 1.4280 - val_accuracy: 0.5413\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2674 - accuracy: 0.7070 - val_loss: 1.4253 - val_accuracy: 0.5486\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2587 - accuracy: 0.6972 - val_loss: 1.4259 - val_accuracy: 0.5527\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2508 - accuracy: 0.7109 - val_loss: 1.4245 - val_accuracy: 0.5537\n","Epoch 54/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2451 - accuracy: 0.7016 - val_loss: 1.4366 - val_accuracy: 0.5496\n","Epoch 55/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2358 - accuracy: 0.7072 - val_loss: 1.4144 - val_accuracy: 0.5517\n","Epoch 56/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2239 - accuracy: 0.7178 - val_loss: 1.4153 - val_accuracy: 0.5537\n","Epoch 57/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2161 - accuracy: 0.7212 - val_loss: 1.4182 - val_accuracy: 0.5455\n","Epoch 58/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2071 - accuracy: 0.7315 - val_loss: 1.4116 - val_accuracy: 0.5548\n","Epoch 59/100\n","31/31 [==============================] - 1s 28ms/step - loss: 1.1969 - accuracy: 0.7307 - val_loss: 1.4191 - val_accuracy: 0.5610\n","Epoch 60/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.1903 - accuracy: 0.7289 - val_loss: 1.4066 - val_accuracy: 0.5506\n","Epoch 61/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1808 - accuracy: 0.7372 - val_loss: 1.4072 - val_accuracy: 0.5465\n","Epoch 62/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.1741 - accuracy: 0.7328 - val_loss: 1.4124 - val_accuracy: 0.5661\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1648 - accuracy: 0.7289 - val_loss: 1.4114 - val_accuracy: 0.5465\n","Epoch 64/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1543 - accuracy: 0.7496 - val_loss: 1.4049 - val_accuracy: 0.5475\n","Epoch 65/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1449 - accuracy: 0.7535 - val_loss: 1.4006 - val_accuracy: 0.5475\n","Epoch 66/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1385 - accuracy: 0.7519 - val_loss: 1.4045 - val_accuracy: 0.5465\n","Epoch 67/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1283 - accuracy: 0.7530 - val_loss: 1.4039 - val_accuracy: 0.5289\n","Epoch 68/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1204 - accuracy: 0.7568 - val_loss: 1.4015 - val_accuracy: 0.5424\n","Epoch 69/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1136 - accuracy: 0.7550 - val_loss: 1.4075 - val_accuracy: 0.5238\n","Epoch 70/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1068 - accuracy: 0.7597 - val_loss: 1.4028 - val_accuracy: 0.5548\n","Epoch 71/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0934 - accuracy: 0.7664 - val_loss: 1.4044 - val_accuracy: 0.5496\n","Epoch 72/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0914 - accuracy: 0.7592 - val_loss: 1.4038 - val_accuracy: 0.5475\n","Epoch 73/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0807 - accuracy: 0.7703 - val_loss: 1.3974 - val_accuracy: 0.5434\n","Epoch 74/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0721 - accuracy: 0.7791 - val_loss: 1.4009 - val_accuracy: 0.5372\n","Epoch 75/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0658 - accuracy: 0.7693 - val_loss: 1.4007 - val_accuracy: 0.5362\n","Epoch 76/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0585 - accuracy: 0.7747 - val_loss: 1.4061 - val_accuracy: 0.5258\n","Epoch 77/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0455 - accuracy: 0.7891 - val_loss: 1.3993 - val_accuracy: 0.5393\n","Epoch 78/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0374 - accuracy: 0.7866 - val_loss: 1.4003 - val_accuracy: 0.5444\n","Epoch 79/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0279 - accuracy: 0.7922 - val_loss: 1.4116 - val_accuracy: 0.5300\n","Epoch 80/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0239 - accuracy: 0.7925 - val_loss: 1.4205 - val_accuracy: 0.5620\n","Epoch 81/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0261 - accuracy: 0.7736 - val_loss: 1.4124 - val_accuracy: 0.5444\n","Epoch 82/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0074 - accuracy: 0.7948 - val_loss: 1.4010 - val_accuracy: 0.5372\n","Epoch 83/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9984 - accuracy: 0.8067 - val_loss: 1.4040 - val_accuracy: 0.5351\n","Epoch 84/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9921 - accuracy: 0.8065 - val_loss: 1.4111 - val_accuracy: 0.5548\n","Epoch 85/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9846 - accuracy: 0.8057 - val_loss: 1.4076 - val_accuracy: 0.5393\n","Epoch 86/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9846 - accuracy: 0.7990 - val_loss: 1.4275 - val_accuracy: 0.5568\n","Epoch 87/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9767 - accuracy: 0.7997 - val_loss: 1.4113 - val_accuracy: 0.5362\n","Epoch 88/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9598 - accuracy: 0.8163 - val_loss: 1.4172 - val_accuracy: 0.5537\n","Epoch 89/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9554 - accuracy: 0.8189 - val_loss: 1.4207 - val_accuracy: 0.5300\n","Epoch 90/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9448 - accuracy: 0.8194 - val_loss: 1.4266 - val_accuracy: 0.5372\n","Epoch 91/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9387 - accuracy: 0.8276 - val_loss: 1.4257 - val_accuracy: 0.5465\n","Epoch 92/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9319 - accuracy: 0.8264 - val_loss: 1.4315 - val_accuracy: 0.5527\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9274 - accuracy: 0.8209 - val_loss: 1.4238 - val_accuracy: 0.5320\n","Epoch 94/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9194 - accuracy: 0.8261 - val_loss: 1.4371 - val_accuracy: 0.5537\n","Epoch 95/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.9144 - accuracy: 0.8302 - val_loss: 1.4350 - val_accuracy: 0.5269\n","Epoch 96/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9060 - accuracy: 0.8302 - val_loss: 1.4339 - val_accuracy: 0.5300\n","Epoch 97/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.8987 - accuracy: 0.8346 - val_loss: 1.4319 - val_accuracy: 0.5475\n","Epoch 98/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8875 - accuracy: 0.8444 - val_loss: 1.4403 - val_accuracy: 0.5331\n","Epoch 99/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8774 - accuracy: 0.8525 - val_loss: 1.4548 - val_accuracy: 0.5434\n","Epoch 100/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8778 - accuracy: 0.8429 - val_loss: 1.4461 - val_accuracy: 0.5351\n","{'loss': [1.770713210105896, 1.7582699060440063, 1.7463430166244507, 1.7348688840866089, 1.7236242294311523, 1.7123712301254272, 1.7009855508804321, 1.6898958683013916, 1.679194688796997, 1.6677533388137817, 1.657122254371643, 1.6464356184005737, 1.6358363628387451, 1.625378966331482, 1.6150718927383423, 1.6044191122055054, 1.5941780805587769, 1.583666205406189, 1.573412299156189, 1.5631529092788696, 1.5533154010772705, 1.5439975261688232, 1.5336915254592896, 1.5242999792099, 1.5133084058761597, 1.5033727884292603, 1.4938966035842896, 1.4842597246170044, 1.4741296768188477, 1.463366150856018, 1.4565386772155762, 1.4469358921051025, 1.4362534284591675, 1.4274187088012695, 1.4185104370117188, 1.4067442417144775, 1.3964910507202148, 1.38828444480896, 1.3775023221969604, 1.3681564331054688, 1.3587273359298706, 1.3491315841674805, 1.3403265476226807, 1.331254243850708, 1.3264480829238892, 1.3153523206710815, 1.3035539388656616, 1.294969081878662, 1.2873475551605225, 1.2770214080810547, 1.267376184463501, 1.2587497234344482, 1.2507790327072144, 1.2451248168945312, 1.235750436782837, 1.2238600254058838, 1.2161093950271606, 1.2071096897125244, 1.19691002368927, 1.190264344215393, 1.1807581186294556, 1.1741437911987305, 1.1648117303848267, 1.1542645692825317, 1.1448630094528198, 1.1385409832000732, 1.1283187866210938, 1.1204051971435547, 1.1135547161102295, 1.1067943572998047, 1.0933688879013062, 1.0913876295089722, 1.0807151794433594, 1.0720617771148682, 1.0657787322998047, 1.0584521293640137, 1.0454851388931274, 1.0374422073364258, 1.027924656867981, 1.0239441394805908, 1.0260796546936035, 1.0073689222335815, 0.9983630180358887, 0.9920977354049683, 0.9846299290657043, 0.9846122860908508, 0.976690411567688, 0.959777295589447, 0.9554066061973572, 0.9448124170303345, 0.9387120604515076, 0.9318892955780029, 0.9274390339851379, 0.9193788170814514, 0.914423942565918, 0.905977725982666, 0.8986942768096924, 0.887486457824707, 0.8773612380027771, 0.8778022527694702], 'accuracy': [0.4981912076473236, 0.5165374875068665, 0.5361757278442383, 0.5320413708686829, 0.5361757278442383, 0.5397932529449463, 0.5410852432250977, 0.550904393196106, 0.5576227307319641, 0.5627906918525696, 0.5723513960838318, 0.569767415523529, 0.5689922571182251, 0.58113694190979, 0.5863049030303955, 0.5795865654945374, 0.5888888835906982, 0.5935400724411011, 0.5873385071754456, 0.6041343808174133, 0.5950904488563538, 0.5930232405662537, 0.6093023419380188, 0.6018087863922119, 0.6095607280731201, 0.6183462738990784, 0.617829442024231, 0.6245477795600891, 0.6245477795600891, 0.6297157406806946, 0.6253229975700378, 0.6260982155799866, 0.6390180587768555, 0.646253228187561, 0.6351421475410461, 0.6514211893081665, 0.656589150428772, 0.6537467837333679, 0.6635658740997314, 0.6661498546600342, 0.670801043510437, 0.6788113713264465, 0.6770026087760925, 0.6731266379356384, 0.6640827059745789, 0.683979332447052, 0.6945736408233643, 0.6966408491134644, 0.697157621383667, 0.7015503644943237, 0.7069767713546753, 0.697157621383667, 0.7108527421951294, 0.7015503644943237, 0.7072351574897766, 0.7178294658660889, 0.7211886048316956, 0.7315245270729065, 0.7307493686676025, 0.7289405465126038, 0.7372093200683594, 0.7328165173530579, 0.7289405465126038, 0.7496123909950256, 0.7534883618354797, 0.751937985420227, 0.7529715895652771, 0.7568475604057312, 0.7550387382507324, 0.7596899271011353, 0.7664082646369934, 0.7591731548309326, 0.7702842354774475, 0.7790697813034058, 0.7692506313323975, 0.7746769785881042, 0.7891472578048706, 0.7865633368492126, 0.7922480702400208, 0.7925064563751221, 0.773643434047699, 0.7948320508003235, 0.8067183494567871, 0.8064599633216858, 0.8056847453117371, 0.7989664077758789, 0.7997416257858276, 0.8162790536880493, 0.818863034248352, 0.8193798661231995, 0.8276485800743103, 0.8263565897941589, 0.8209302425384521, 0.8260982036590576, 0.830232560634613, 0.830232560634613, 0.8346253037452698, 0.8444444537162781, 0.8524547815322876, 0.8428940773010254], 'val_loss': [1.7651787996292114, 1.7543144226074219, 1.7435331344604492, 1.7328827381134033, 1.7223628759384155, 1.7119991779327393, 1.7017204761505127, 1.6916718482971191, 1.6816879510879517, 1.671830177307129, 1.6622374057769775, 1.6528874635696411, 1.6436268091201782, 1.6338907480239868, 1.6247864961624146, 1.6159664392471313, 1.6072150468826294, 1.5984069108963013, 1.5907440185546875, 1.5823228359222412, 1.5740729570388794, 1.5669760704040527, 1.5599170923233032, 1.5527580976486206, 1.5461173057556152, 1.5396233797073364, 1.5326896905899048, 1.5269427299499512, 1.5209214687347412, 1.5233542919158936, 1.5092161893844604, 1.5060641765594482, 1.4976264238357544, 1.4947750568389893, 1.4878730773925781, 1.4832885265350342, 1.4794468879699707, 1.4759529829025269, 1.470505952835083, 1.4649684429168701, 1.4605762958526611, 1.4575917720794678, 1.4539018869400024, 1.451852560043335, 1.4429984092712402, 1.4404265880584717, 1.4359560012817383, 1.439322829246521, 1.4358493089675903, 1.4279816150665283, 1.4253389835357666, 1.4258562326431274, 1.4245214462280273, 1.4366315603256226, 1.4144015312194824, 1.4152836799621582, 1.4182043075561523, 1.4115508794784546, 1.419134497642517, 1.4066110849380493, 1.407156229019165, 1.412449598312378, 1.4114011526107788, 1.4049060344696045, 1.400577187538147, 1.404490351676941, 1.4038715362548828, 1.4015214443206787, 1.4075300693511963, 1.4027823209762573, 1.4044305086135864, 1.4037895202636719, 1.397435188293457, 1.4009032249450684, 1.400679111480713, 1.4060925245285034, 1.399288296699524, 1.4003223180770874, 1.4115971326828003, 1.4205244779586792, 1.4123574495315552, 1.400972604751587, 1.4039661884307861, 1.4110733270645142, 1.4076247215270996, 1.4274773597717285, 1.411329746246338, 1.4172478914260864, 1.4206527471542358, 1.426574945449829, 1.4256925582885742, 1.4315241575241089, 1.423845648765564, 1.4370758533477783, 1.4349734783172607, 1.4339011907577515, 1.4318575859069824, 1.4403406381607056, 1.4547815322875977, 1.4460883140563965], 'val_accuracy': [0.48966941237449646, 0.5072314143180847, 0.4969008266925812, 0.4948347210884094, 0.49793389439582825, 0.49896693229675293, 0.5010330677032471, 0.5, 0.5020661354064941, 0.5185950398445129, 0.5144628286361694, 0.5030992031097412, 0.5020661354064941, 0.49793389439582825, 0.4958677589893341, 0.5061983466148376, 0.4969008266925812, 0.5020661354064941, 0.5144628286361694, 0.49793389439582825, 0.5082644820213318, 0.5103305578231812, 0.5082644820213318, 0.5144628286361694, 0.5123966932296753, 0.5123966932296753, 0.5216942429542542, 0.5216942429542542, 0.5258264541625977, 0.5041322112083435, 0.5289255976676941, 0.5206611752510071, 0.5309917330741882, 0.5299586653709412, 0.538223147392273, 0.5247933864593506, 0.5309917330741882, 0.5402892827987671, 0.5340909361839294, 0.5351239442825317, 0.5340909361839294, 0.5361570119857788, 0.5413222908973694, 0.5444214940071106, 0.5361570119857788, 0.5423553586006165, 0.5371900796890259, 0.5526859760284424, 0.5547520518302917, 0.5413222908973694, 0.5485537052154541, 0.5526859760284424, 0.5537189841270447, 0.5495867729187012, 0.5516529083251953, 0.5537189841270447, 0.5454545617103577, 0.5547520518302917, 0.5609503984451294, 0.5506198406219482, 0.5464876294136047, 0.56611567735672, 0.5464876294136047, 0.547520637512207, 0.547520637512207, 0.5464876294136047, 0.5289255976676941, 0.5423553586006165, 0.5237603187561035, 0.5547520518302917, 0.5495867729187012, 0.547520637512207, 0.5433884263038635, 0.5371900796890259, 0.5361570119857788, 0.5258264541625977, 0.53925621509552, 0.5444214940071106, 0.5299586653709412, 0.5619834661483765, 0.5444214940071106, 0.5371900796890259, 0.5351239442825317, 0.5547520518302917, 0.53925621509552, 0.5568181872367859, 0.5361570119857788, 0.5537189841270447, 0.5299586653709412, 0.5371900796890259, 0.5464876294136047, 0.5526859760284424, 0.5320248007774353, 0.5537189841270447, 0.5268595218658447, 0.5299586653709412, 0.547520637512207, 0.5330578684806824, 0.5433884263038635, 0.5351239442825317]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 1.0270 - accuracy: 0.7462"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 4s 63ms/step - loss: 1.0270 - accuracy: 0.7462 - val_loss: 1.2055 - val_accuracy: 0.4881\n","Epoch 2/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0090 - accuracy: 0.7718 - val_loss: 1.2003 - val_accuracy: 0.4881\n","Epoch 3/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9980 - accuracy: 0.7726 - val_loss: 1.1985 - val_accuracy: 0.4881\n","Epoch 4/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9887 - accuracy: 0.7772 - val_loss: 1.1955 - val_accuracy: 0.4881\n","Epoch 5/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9776 - accuracy: 0.7804 - val_loss: 1.1929 - val_accuracy: 0.4892\n","Epoch 6/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.9723 - accuracy: 0.7869 - val_loss: 1.1816 - val_accuracy: 0.5000\n","Epoch 7/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9647 - accuracy: 0.7899 - val_loss: 1.1722 - val_accuracy: 0.5226\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9684 - accuracy: 0.7761 - val_loss: 1.1686 - val_accuracy: 0.5237\n","Epoch 9/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9514 - accuracy: 0.7928 - val_loss: 1.1639 - val_accuracy: 0.5302\n","Epoch 10/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9416 - accuracy: 0.8025 - val_loss: 1.1566 - val_accuracy: 0.5453\n","Epoch 11/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9317 - accuracy: 0.8117 - val_loss: 1.1518 - val_accuracy: 0.5506\n","Epoch 12/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9255 - accuracy: 0.8114 - val_loss: 1.1485 - val_accuracy: 0.5453\n","Epoch 13/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9174 - accuracy: 0.8155 - val_loss: 1.1328 - val_accuracy: 0.6207\n","Epoch 14/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9123 - accuracy: 0.8200 - val_loss: 1.1352 - val_accuracy: 0.5711\n","Epoch 15/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9022 - accuracy: 0.8268 - val_loss: 1.1197 - val_accuracy: 0.6218\n","Epoch 16/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8977 - accuracy: 0.8244 - val_loss: 1.1174 - val_accuracy: 0.6121\n","Epoch 17/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8922 - accuracy: 0.8230 - val_loss: 1.1018 - val_accuracy: 0.6562\n","Epoch 18/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8842 - accuracy: 0.8279 - val_loss: 1.1010 - val_accuracy: 0.6358\n","Epoch 19/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8813 - accuracy: 0.8230 - val_loss: 1.0968 - val_accuracy: 0.6444\n","Epoch 20/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8692 - accuracy: 0.8349 - val_loss: 1.0883 - val_accuracy: 0.6519\n","Epoch 21/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8618 - accuracy: 0.8384 - val_loss: 1.0917 - val_accuracy: 0.6401\n","Epoch 22/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8557 - accuracy: 0.8440 - val_loss: 1.0800 - val_accuracy: 0.6519\n","Epoch 23/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8508 - accuracy: 0.8419 - val_loss: 1.0816 - val_accuracy: 0.6530\n","Epoch 24/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8482 - accuracy: 0.8400 - val_loss: 1.0749 - val_accuracy: 0.6595\n","Epoch 25/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8375 - accuracy: 0.8451 - val_loss: 1.0758 - val_accuracy: 0.6519\n","Epoch 26/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8330 - accuracy: 0.8464 - val_loss: 1.0746 - val_accuracy: 0.6616\n","Epoch 27/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8247 - accuracy: 0.8548 - val_loss: 1.0778 - val_accuracy: 0.6595\n","Epoch 28/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8208 - accuracy: 0.8586 - val_loss: 1.0795 - val_accuracy: 0.6638\n","Epoch 29/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8129 - accuracy: 0.8605 - val_loss: 1.0814 - val_accuracy: 0.6616\n","Epoch 30/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8035 - accuracy: 0.8685 - val_loss: 1.0829 - val_accuracy: 0.6595\n","Epoch 31/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7970 - accuracy: 0.8650 - val_loss: 1.0853 - val_accuracy: 0.6466\n","Epoch 32/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7974 - accuracy: 0.8591 - val_loss: 1.1130 - val_accuracy: 0.6487\n","Epoch 33/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7866 - accuracy: 0.8677 - val_loss: 1.0885 - val_accuracy: 0.6455\n","Epoch 34/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7776 - accuracy: 0.8753 - val_loss: 1.0920 - val_accuracy: 0.6509\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7786 - accuracy: 0.8707 - val_loss: 1.1000 - val_accuracy: 0.6552\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7754 - accuracy: 0.8672 - val_loss: 1.1120 - val_accuracy: 0.6552\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7631 - accuracy: 0.8726 - val_loss: 1.1089 - val_accuracy: 0.6487\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7598 - accuracy: 0.8710 - val_loss: 1.0992 - val_accuracy: 0.6455\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7531 - accuracy: 0.8825 - val_loss: 1.1136 - val_accuracy: 0.6584\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7533 - accuracy: 0.8699 - val_loss: 1.1073 - val_accuracy: 0.6509\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7397 - accuracy: 0.8882 - val_loss: 1.1064 - val_accuracy: 0.6530\n","Epoch 42/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7351 - accuracy: 0.8890 - val_loss: 1.1065 - val_accuracy: 0.6455\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7293 - accuracy: 0.8901 - val_loss: 1.1071 - val_accuracy: 0.6509\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7185 - accuracy: 0.9001 - val_loss: 1.1083 - val_accuracy: 0.6455\n","Epoch 45/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7131 - accuracy: 0.9033 - val_loss: 1.1042 - val_accuracy: 0.6541\n","Epoch 46/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7080 - accuracy: 0.9022 - val_loss: 1.1234 - val_accuracy: 0.6498\n","Epoch 47/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7028 - accuracy: 0.9036 - val_loss: 1.1122 - val_accuracy: 0.6552\n","Epoch 48/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7001 - accuracy: 0.9014 - val_loss: 1.1165 - val_accuracy: 0.6487\n","Epoch 49/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6915 - accuracy: 0.9071 - val_loss: 1.1136 - val_accuracy: 0.6509\n","Epoch 50/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6949 - accuracy: 0.8976 - val_loss: 1.1361 - val_accuracy: 0.6444\n","Epoch 51/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6904 - accuracy: 0.9014 - val_loss: 1.1170 - val_accuracy: 0.6573\n","Epoch 52/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6769 - accuracy: 0.9141 - val_loss: 1.1199 - val_accuracy: 0.6487\n","Epoch 53/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6747 - accuracy: 0.9162 - val_loss: 1.1248 - val_accuracy: 0.6519\n","Epoch 54/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6662 - accuracy: 0.9176 - val_loss: 1.1288 - val_accuracy: 0.6487\n","Epoch 55/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6604 - accuracy: 0.9213 - val_loss: 1.1269 - val_accuracy: 0.6433\n","Epoch 56/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6545 - accuracy: 0.9227 - val_loss: 1.1309 - val_accuracy: 0.6562\n","Epoch 57/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6516 - accuracy: 0.9219 - val_loss: 1.1321 - val_accuracy: 0.6487\n","Epoch 58/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6545 - accuracy: 0.9159 - val_loss: 1.1384 - val_accuracy: 0.6476\n","Epoch 59/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6451 - accuracy: 0.9184 - val_loss: 1.1425 - val_accuracy: 0.6530\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6344 - accuracy: 0.9283 - val_loss: 1.1359 - val_accuracy: 0.6422\n","Epoch 61/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6340 - accuracy: 0.9227 - val_loss: 1.1395 - val_accuracy: 0.6476\n","Epoch 62/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6261 - accuracy: 0.9308 - val_loss: 1.1436 - val_accuracy: 0.6530\n","Epoch 63/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6208 - accuracy: 0.9340 - val_loss: 1.1482 - val_accuracy: 0.6530\n","Epoch 64/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6140 - accuracy: 0.9308 - val_loss: 1.1573 - val_accuracy: 0.6498\n","Epoch 65/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6119 - accuracy: 0.9367 - val_loss: 1.1571 - val_accuracy: 0.6466\n","Epoch 66/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6063 - accuracy: 0.9362 - val_loss: 1.1689 - val_accuracy: 0.6476\n","Epoch 67/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6026 - accuracy: 0.9391 - val_loss: 1.1670 - val_accuracy: 0.6509\n","Epoch 68/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6009 - accuracy: 0.9335 - val_loss: 1.1721 - val_accuracy: 0.6541\n","Epoch 69/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6030 - accuracy: 0.9316 - val_loss: 1.1718 - val_accuracy: 0.6476\n","Epoch 70/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6010 - accuracy: 0.9300 - val_loss: 1.1752 - val_accuracy: 0.6530\n","Epoch 71/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5860 - accuracy: 0.9405 - val_loss: 1.2039 - val_accuracy: 0.6325\n","Epoch 72/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5846 - accuracy: 0.9421 - val_loss: 1.1823 - val_accuracy: 0.6455\n","Epoch 73/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5793 - accuracy: 0.9445 - val_loss: 1.1758 - val_accuracy: 0.6455\n","Epoch 74/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5715 - accuracy: 0.9477 - val_loss: 1.1777 - val_accuracy: 0.6519\n","Epoch 75/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5675 - accuracy: 0.9472 - val_loss: 1.1837 - val_accuracy: 0.6476\n","Epoch 76/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5614 - accuracy: 0.9507 - val_loss: 1.2007 - val_accuracy: 0.6498\n","Epoch 77/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5628 - accuracy: 0.9512 - val_loss: 1.2105 - val_accuracy: 0.6379\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5614 - accuracy: 0.9440 - val_loss: 1.2100 - val_accuracy: 0.6444\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5588 - accuracy: 0.9485 - val_loss: 1.1971 - val_accuracy: 0.6509\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5450 - accuracy: 0.9564 - val_loss: 1.2036 - val_accuracy: 0.6476\n","Epoch 81/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5425 - accuracy: 0.9582 - val_loss: 1.2042 - val_accuracy: 0.6487\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5431 - accuracy: 0.9539 - val_loss: 1.2125 - val_accuracy: 0.6401\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5397 - accuracy: 0.9545 - val_loss: 1.2218 - val_accuracy: 0.6519\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5325 - accuracy: 0.9574 - val_loss: 1.2101 - val_accuracy: 0.6422\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5318 - accuracy: 0.9574 - val_loss: 1.2170 - val_accuracy: 0.6466\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5270 - accuracy: 0.9596 - val_loss: 1.2302 - val_accuracy: 0.6487\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5244 - accuracy: 0.9599 - val_loss: 1.2297 - val_accuracy: 0.6444\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5237 - accuracy: 0.9588 - val_loss: 1.2411 - val_accuracy: 0.6412\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5155 - accuracy: 0.9652 - val_loss: 1.2452 - val_accuracy: 0.6369\n","Epoch 90/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5104 - accuracy: 0.9647 - val_loss: 1.2384 - val_accuracy: 0.6444\n","Epoch 91/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5064 - accuracy: 0.9655 - val_loss: 1.2469 - val_accuracy: 0.6433\n","Epoch 92/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5072 - accuracy: 0.9679 - val_loss: 1.2427 - val_accuracy: 0.6444\n","Epoch 93/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5053 - accuracy: 0.9650 - val_loss: 1.2480 - val_accuracy: 0.6487\n","Epoch 94/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4990 - accuracy: 0.9671 - val_loss: 1.2544 - val_accuracy: 0.6433\n","Epoch 95/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4933 - accuracy: 0.9720 - val_loss: 1.2653 - val_accuracy: 0.6401\n","Epoch 96/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4910 - accuracy: 0.9739 - val_loss: 1.2673 - val_accuracy: 0.6487\n","Epoch 97/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4896 - accuracy: 0.9725 - val_loss: 1.2712 - val_accuracy: 0.6498\n","Epoch 98/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4840 - accuracy: 0.9749 - val_loss: 1.2842 - val_accuracy: 0.6390\n","Epoch 99/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4818 - accuracy: 0.9760 - val_loss: 1.2987 - val_accuracy: 0.6466\n","Epoch 100/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4828 - accuracy: 0.9725 - val_loss: 1.2796 - val_accuracy: 0.6412\n","{'loss': [1.0270298719406128, 1.008975863456726, 0.9980394840240479, 0.9887039661407471, 0.9775877594947815, 0.9722961187362671, 0.9646954536437988, 0.9684168696403503, 0.9514086246490479, 0.9416230320930481, 0.9316545724868774, 0.9255331158638, 0.9174017906188965, 0.9122556447982788, 0.9021798968315125, 0.8976632952690125, 0.8921888470649719, 0.8841661810874939, 0.8812946677207947, 0.8692254424095154, 0.8617832660675049, 0.8557420969009399, 0.8507801294326782, 0.8481996655464172, 0.8375408053398132, 0.8330309391021729, 0.8246833682060242, 0.8208009004592896, 0.8129439949989319, 0.8034595251083374, 0.7969680428504944, 0.7974148988723755, 0.7865937352180481, 0.7776075005531311, 0.7786150574684143, 0.7753620147705078, 0.7631074786186218, 0.759832501411438, 0.7530930638313293, 0.753337025642395, 0.7397420406341553, 0.7350873351097107, 0.729317843914032, 0.7185244560241699, 0.7130545377731323, 0.7080345749855042, 0.7028133869171143, 0.700148344039917, 0.6914804577827454, 0.6949150562286377, 0.6903876066207886, 0.6768887639045715, 0.6747230887413025, 0.6661843061447144, 0.6604499816894531, 0.6545076966285706, 0.6516360640525818, 0.6545305848121643, 0.6451463103294373, 0.6344148516654968, 0.6339964270591736, 0.6261435151100159, 0.6208431124687195, 0.613999605178833, 0.611944854259491, 0.6063305139541626, 0.6025863885879517, 0.6009217500686646, 0.602963924407959, 0.6010094285011292, 0.5860356092453003, 0.5845866203308105, 0.5792752504348755, 0.5715420842170715, 0.5675243735313416, 0.5614490509033203, 0.5627890825271606, 0.561375081539154, 0.5587754845619202, 0.5450170636177063, 0.5424712896347046, 0.5430911779403687, 0.539657711982727, 0.5325093865394592, 0.531757116317749, 0.5269938707351685, 0.5243549942970276, 0.5237381458282471, 0.5154500603675842, 0.5104094743728638, 0.506424069404602, 0.5071929693222046, 0.5053132772445679, 0.4989880621433258, 0.4932953119277954, 0.4910305142402649, 0.489620566368103, 0.483987420797348, 0.4817611873149872, 0.48282772302627563], 'accuracy': [0.7462284564971924, 0.771821141242981, 0.7726293206214905, 0.7772090435028076, 0.7804418206214905, 0.7869073152542114, 0.7898706793785095, 0.7761314511299133, 0.7928340435028076, 0.8025323152542114, 0.8116918206214905, 0.8114224076271057, 0.8154633641242981, 0.8200430870056152, 0.826777994632721, 0.8243534564971924, 0.8230064511299133, 0.8278555870056152, 0.8230064511299133, 0.8348599076271057, 0.8383620977401733, 0.8440194129943848, 0.8418642282485962, 0.8399784564971924, 0.845097005367279, 0.8464439511299133, 0.8547952771186829, 0.8585668206214905, 0.8604525923728943, 0.868534505367279, 0.8650323152542114, 0.8591055870056152, 0.8677262663841248, 0.8752694129943848, 0.8706896305084229, 0.8671875, 0.8725754022598267, 0.8709590435028076, 0.8825430870056152, 0.8698814511299133, 0.8882004022598267, 0.889008641242981, 0.8900862336158752, 0.900053858757019, 0.9032866358757019, 0.9022090435028076, 0.9035560488700867, 0.9014008641242981, 0.9070581793785095, 0.8976293206214905, 0.9014008641242981, 0.9140625, 0.9162176847457886, 0.9175646305084229, 0.9213362336158752, 0.9226831793785095, 0.921875, 0.9159482717514038, 0.9183728694915771, 0.928340494632721, 0.9226831793785095, 0.9307650923728943, 0.9339978694915771, 0.9307650923728943, 0.9366918206214905, 0.936152994632721, 0.939116358757019, 0.9334590435028076, 0.9315732717514038, 0.9299569129943848, 0.9404633641242981, 0.9420797228813171, 0.9445043206214905, 0.9477370977401733, 0.9471982717514038, 0.9507004022598267, 0.9512392282485962, 0.943965494632721, 0.9485452771186829, 0.9563577771186829, 0.9582435488700867, 0.9539331793785095, 0.954472005367279, 0.9574353694915771, 0.9574353694915771, 0.959590494632721, 0.9598599076271057, 0.9587823152542114, 0.9652478694915771, 0.9647090435028076, 0.9655172228813171, 0.9679418206214905, 0.9649784564971924, 0.967133641242981, 0.9719827771186829, 0.9738685488700867, 0.9725215435028076, 0.974946141242981, 0.9760237336158752, 0.9725215435028076], 'val_loss': [1.2055046558380127, 1.2002965211868286, 1.1985300779342651, 1.1954582929611206, 1.1928789615631104, 1.1815640926361084, 1.172243356704712, 1.1685575246810913, 1.163887858390808, 1.1565918922424316, 1.1518185138702393, 1.1485166549682617, 1.1327502727508545, 1.1352486610412598, 1.119722843170166, 1.117445707321167, 1.1017991304397583, 1.1010336875915527, 1.0967994928359985, 1.0882922410964966, 1.091681718826294, 1.0799877643585205, 1.0816190242767334, 1.0748764276504517, 1.075760006904602, 1.0746315717697144, 1.0777627229690552, 1.0794649124145508, 1.081356406211853, 1.0829370021820068, 1.0853300094604492, 1.1129717826843262, 1.0885368585586548, 1.0920188426971436, 1.1000392436981201, 1.1119786500930786, 1.1089366674423218, 1.099192500114441, 1.1136143207550049, 1.107334852218628, 1.106364130973816, 1.1065304279327393, 1.1070680618286133, 1.1082968711853027, 1.1041815280914307, 1.123389720916748, 1.11222243309021, 1.116465449333191, 1.113585352897644, 1.1360642910003662, 1.116956114768982, 1.119919776916504, 1.1248207092285156, 1.1287842988967896, 1.1268858909606934, 1.1309176683425903, 1.1321375370025635, 1.1383761167526245, 1.1425052881240845, 1.1359460353851318, 1.1395494937896729, 1.143648386001587, 1.1481951475143433, 1.1573017835617065, 1.15709388256073, 1.168900489807129, 1.1669944524765015, 1.172123908996582, 1.1718080043792725, 1.1752023696899414, 1.203904151916504, 1.1823347806930542, 1.1758078336715698, 1.1777068376541138, 1.1837401390075684, 1.200717568397522, 1.2104889154434204, 1.2100064754486084, 1.197087049484253, 1.2035657167434692, 1.2041608095169067, 1.2124629020690918, 1.2218111753463745, 1.2101104259490967, 1.217002511024475, 1.2302051782608032, 1.2297124862670898, 1.2411280870437622, 1.2452127933502197, 1.238410234451294, 1.2469029426574707, 1.2427356243133545, 1.24797785282135, 1.2543599605560303, 1.2653213739395142, 1.267269492149353, 1.2712236642837524, 1.2842168807983398, 1.298734188079834, 1.2795588970184326], 'val_accuracy': [0.4881465435028076, 0.4881465435028076, 0.4881465435028076, 0.4881465435028076, 0.4892241358757019, 0.5, 0.5226293206214905, 0.5237069129943848, 0.5301724076271057, 0.545258641242981, 0.5506465435028076, 0.545258641242981, 0.6206896305084229, 0.5711206793785095, 0.6217672228813171, 0.6120689511299133, 0.65625, 0.6357758641242981, 0.6443965435028076, 0.6519396305084229, 0.6400862336158752, 0.6519396305084229, 0.6530172228813171, 0.6594827771186829, 0.6519396305084229, 0.6616379022598267, 0.6594827771186829, 0.6637930870056152, 0.6616379022598267, 0.6594827771186829, 0.6465517282485962, 0.6487069129943848, 0.6454741358757019, 0.6508620977401733, 0.6551724076271057, 0.6551724076271057, 0.6487069129943848, 0.6454741358757019, 0.6584051847457886, 0.6508620977401733, 0.6530172228813171, 0.6454741358757019, 0.6508620977401733, 0.6454741358757019, 0.6540948152542114, 0.649784505367279, 0.6551724076271057, 0.6487069129943848, 0.6508620977401733, 0.6443965435028076, 0.6573275923728943, 0.6487069129943848, 0.6519396305084229, 0.6487069129943848, 0.6433189511299133, 0.65625, 0.6487069129943848, 0.6476293206214905, 0.6530172228813171, 0.642241358757019, 0.6476293206214905, 0.6530172228813171, 0.6530172228813171, 0.649784505367279, 0.6465517282485962, 0.6476293206214905, 0.6508620977401733, 0.6540948152542114, 0.6476293206214905, 0.6530172228813171, 0.6325430870056152, 0.6454741358757019, 0.6454741358757019, 0.6519396305084229, 0.6476293206214905, 0.649784505367279, 0.6379310488700867, 0.6443965435028076, 0.6508620977401733, 0.6476293206214905, 0.6487069129943848, 0.6400862336158752, 0.6519396305084229, 0.642241358757019, 0.6465517282485962, 0.6487069129943848, 0.6443965435028076, 0.6411637663841248, 0.6368534564971924, 0.6443965435028076, 0.6433189511299133, 0.6443965435028076, 0.6487069129943848, 0.6433189511299133, 0.6400862336158752, 0.6487069129943848, 0.649784505367279, 0.639008641242981, 0.6465517282485962, 0.6411637663841248]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 29ms/step - loss: 1.0280 - accuracy: 0.7482 - val_loss: 1.2025 - val_accuracy: 0.5023\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.9894 - accuracy: 0.8047"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 0s 17ms/step - loss: 1.0096 - accuracy: 0.7640 - val_loss: 1.1968 - val_accuracy: 0.5068\n","Epoch 3/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0010 - accuracy: 0.7666 - val_loss: 1.1934 - val_accuracy: 0.5057\n","Epoch 4/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9907 - accuracy: 0.7745 - val_loss: 1.1884 - val_accuracy: 0.5068\n","Epoch 5/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9820 - accuracy: 0.7810 - val_loss: 1.1857 - val_accuracy: 0.5079\n","Epoch 6/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9743 - accuracy: 0.7849 - val_loss: 1.1807 - val_accuracy: 0.5113\n","Epoch 7/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9642 - accuracy: 0.7937 - val_loss: 1.1758 - val_accuracy: 0.5136\n","Epoch 8/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9586 - accuracy: 0.7926 - val_loss: 1.1731 - val_accuracy: 0.5124\n","Epoch 9/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9520 - accuracy: 0.7937 - val_loss: 1.1654 - val_accuracy: 0.5170\n","Epoch 10/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9479 - accuracy: 0.7869 - val_loss: 1.1573 - val_accuracy: 0.5385\n","Epoch 11/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9398 - accuracy: 0.7977 - val_loss: 1.1491 - val_accuracy: 0.5509\n","Epoch 12/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9321 - accuracy: 0.7951 - val_loss: 1.1463 - val_accuracy: 0.5486\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9280 - accuracy: 0.8011 - val_loss: 1.1322 - val_accuracy: 0.6018\n","Epoch 14/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9124 - accuracy: 0.8172 - val_loss: 1.1277 - val_accuracy: 0.5984\n","Epoch 15/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9065 - accuracy: 0.8183 - val_loss: 1.1229 - val_accuracy: 0.5939\n","Epoch 16/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9013 - accuracy: 0.8200 - val_loss: 1.1084 - val_accuracy: 0.6335\n","Epoch 17/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8928 - accuracy: 0.8268 - val_loss: 1.1006 - val_accuracy: 0.6425\n","Epoch 18/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8860 - accuracy: 0.8297 - val_loss: 1.0968 - val_accuracy: 0.6244\n","Epoch 19/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8792 - accuracy: 0.8325 - val_loss: 1.0849 - val_accuracy: 0.6561\n","Epoch 20/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8778 - accuracy: 0.8223 - val_loss: 1.0923 - val_accuracy: 0.6233\n","Epoch 21/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8697 - accuracy: 0.8308 - val_loss: 1.0752 - val_accuracy: 0.6516\n","Epoch 22/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8632 - accuracy: 0.8331 - val_loss: 1.0662 - val_accuracy: 0.6652\n","Epoch 23/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8626 - accuracy: 0.8299 - val_loss: 1.0759 - val_accuracy: 0.6425\n","Epoch 24/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8507 - accuracy: 0.8370 - val_loss: 1.0808 - val_accuracy: 0.6380\n","Epoch 25/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8440 - accuracy: 0.8449 - val_loss: 1.0687 - val_accuracy: 0.6527\n","Epoch 26/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8368 - accuracy: 0.8472 - val_loss: 1.0836 - val_accuracy: 0.6380\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8323 - accuracy: 0.8427 - val_loss: 1.0656 - val_accuracy: 0.6629\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8258 - accuracy: 0.8495 - val_loss: 1.0642 - val_accuracy: 0.6652\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8235 - accuracy: 0.8480 - val_loss: 1.1024 - val_accuracy: 0.6312\n","Epoch 30/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8208 - accuracy: 0.8449 - val_loss: 1.0746 - val_accuracy: 0.6697\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8051 - accuracy: 0.8611 - val_loss: 1.0741 - val_accuracy: 0.6595\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7994 - accuracy: 0.8596 - val_loss: 1.0844 - val_accuracy: 0.6437\n","Epoch 33/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8029 - accuracy: 0.8548 - val_loss: 1.0831 - val_accuracy: 0.6516\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7981 - accuracy: 0.8585 - val_loss: 1.0766 - val_accuracy: 0.6708\n","Epoch 35/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7896 - accuracy: 0.8602 - val_loss: 1.1178 - val_accuracy: 0.6267\n","Epoch 36/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7842 - accuracy: 0.8636 - val_loss: 1.1147 - val_accuracy: 0.6652\n","Epoch 37/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7907 - accuracy: 0.8523 - val_loss: 1.1401 - val_accuracy: 0.6165\n","Epoch 38/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.7727 - accuracy: 0.8645 - val_loss: 1.0891 - val_accuracy: 0.6731\n","Epoch 39/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7605 - accuracy: 0.8763 - val_loss: 1.0807 - val_accuracy: 0.6584\n","Epoch 40/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7542 - accuracy: 0.8803 - val_loss: 1.0855 - val_accuracy: 0.6731\n","Epoch 41/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7483 - accuracy: 0.8834 - val_loss: 1.0961 - val_accuracy: 0.6369\n","Epoch 42/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7472 - accuracy: 0.8789 - val_loss: 1.0823 - val_accuracy: 0.6652\n","Epoch 43/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7506 - accuracy: 0.8704 - val_loss: 1.0895 - val_accuracy: 0.6697\n","Epoch 44/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7442 - accuracy: 0.8812 - val_loss: 1.0900 - val_accuracy: 0.6663\n","Epoch 45/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7293 - accuracy: 0.8908 - val_loss: 1.0865 - val_accuracy: 0.6538\n","Epoch 46/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7238 - accuracy: 0.8894 - val_loss: 1.0861 - val_accuracy: 0.6595\n","Epoch 47/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7220 - accuracy: 0.8939 - val_loss: 1.1045 - val_accuracy: 0.6505\n","Epoch 48/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7168 - accuracy: 0.8905 - val_loss: 1.0887 - val_accuracy: 0.6584\n","Epoch 49/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7076 - accuracy: 0.8973 - val_loss: 1.1000 - val_accuracy: 0.6437\n","Epoch 50/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6998 - accuracy: 0.9049 - val_loss: 1.1067 - val_accuracy: 0.6471\n","Epoch 51/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6975 - accuracy: 0.9007 - val_loss: 1.0969 - val_accuracy: 0.6572\n","Epoch 52/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6935 - accuracy: 0.9027 - val_loss: 1.0957 - val_accuracy: 0.6618\n","Epoch 53/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6916 - accuracy: 0.9052 - val_loss: 1.1146 - val_accuracy: 0.6459\n","Epoch 54/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6862 - accuracy: 0.9052 - val_loss: 1.0996 - val_accuracy: 0.6618\n","Epoch 55/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6790 - accuracy: 0.9083 - val_loss: 1.1092 - val_accuracy: 0.6493\n","Epoch 56/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6744 - accuracy: 0.9061 - val_loss: 1.1265 - val_accuracy: 0.6674\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6706 - accuracy: 0.9089 - val_loss: 1.1056 - val_accuracy: 0.6595\n","Epoch 58/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6678 - accuracy: 0.9095 - val_loss: 1.1083 - val_accuracy: 0.6482\n","Epoch 59/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6552 - accuracy: 0.9162 - val_loss: 1.1150 - val_accuracy: 0.6674\n","Epoch 60/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6514 - accuracy: 0.9196 - val_loss: 1.1234 - val_accuracy: 0.6505\n","Epoch 61/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6468 - accuracy: 0.9194 - val_loss: 1.1228 - val_accuracy: 0.6708\n","Epoch 62/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6438 - accuracy: 0.9213 - val_loss: 1.1167 - val_accuracy: 0.6674\n","Epoch 63/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6357 - accuracy: 0.9202 - val_loss: 1.1363 - val_accuracy: 0.6437\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6335 - accuracy: 0.9247 - val_loss: 1.1204 - val_accuracy: 0.6505\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6301 - accuracy: 0.9253 - val_loss: 1.1489 - val_accuracy: 0.6357\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6243 - accuracy: 0.9267 - val_loss: 1.1324 - val_accuracy: 0.6471\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6198 - accuracy: 0.9267 - val_loss: 1.1482 - val_accuracy: 0.6459\n","Epoch 68/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6148 - accuracy: 0.9295 - val_loss: 1.1415 - val_accuracy: 0.6550\n","Epoch 69/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6212 - accuracy: 0.9216 - val_loss: 1.1674 - val_accuracy: 0.6357\n","Epoch 70/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6118 - accuracy: 0.9261 - val_loss: 1.1415 - val_accuracy: 0.6425\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6069 - accuracy: 0.9318 - val_loss: 1.1780 - val_accuracy: 0.6301\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5974 - accuracy: 0.9366 - val_loss: 1.1450 - val_accuracy: 0.6538\n","Epoch 73/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5881 - accuracy: 0.9423 - val_loss: 1.1533 - val_accuracy: 0.6414\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5850 - accuracy: 0.9454 - val_loss: 1.1534 - val_accuracy: 0.6425\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5796 - accuracy: 0.9454 - val_loss: 1.1498 - val_accuracy: 0.6606\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5776 - accuracy: 0.9451 - val_loss: 1.1557 - val_accuracy: 0.6516\n","Epoch 77/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5732 - accuracy: 0.9457 - val_loss: 1.1619 - val_accuracy: 0.6527\n","Epoch 78/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5711 - accuracy: 0.9465 - val_loss: 1.1616 - val_accuracy: 0.6629\n","Epoch 79/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5712 - accuracy: 0.9448 - val_loss: 1.1734 - val_accuracy: 0.6516\n","Epoch 80/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5606 - accuracy: 0.9516 - val_loss: 1.1786 - val_accuracy: 0.6471\n","Epoch 81/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5565 - accuracy: 0.9533 - val_loss: 1.1692 - val_accuracy: 0.6550\n","Epoch 82/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5543 - accuracy: 0.9508 - val_loss: 1.1749 - val_accuracy: 0.6527\n","Epoch 83/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5589 - accuracy: 0.9468 - val_loss: 1.1839 - val_accuracy: 0.6595\n","Epoch 84/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5475 - accuracy: 0.9491 - val_loss: 1.1851 - val_accuracy: 0.6640\n","Epoch 85/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5397 - accuracy: 0.9559 - val_loss: 1.1878 - val_accuracy: 0.6584\n","Epoch 86/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5393 - accuracy: 0.9578 - val_loss: 1.2290 - val_accuracy: 0.6606\n","Epoch 87/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5404 - accuracy: 0.9564 - val_loss: 1.2021 - val_accuracy: 0.6448\n","Epoch 88/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5287 - accuracy: 0.9604 - val_loss: 1.1987 - val_accuracy: 0.6674\n","Epoch 89/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5226 - accuracy: 0.9677 - val_loss: 1.2002 - val_accuracy: 0.6584\n","Epoch 90/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5224 - accuracy: 0.9618 - val_loss: 1.2221 - val_accuracy: 0.6708\n","Epoch 91/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5200 - accuracy: 0.9629 - val_loss: 1.2326 - val_accuracy: 0.6380\n","Epoch 92/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5178 - accuracy: 0.9635 - val_loss: 1.2146 - val_accuracy: 0.6640\n","Epoch 93/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5135 - accuracy: 0.9666 - val_loss: 1.2174 - val_accuracy: 0.6606\n","Epoch 94/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5074 - accuracy: 0.9683 - val_loss: 1.2316 - val_accuracy: 0.6618\n","Epoch 95/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5072 - accuracy: 0.9666 - val_loss: 1.2441 - val_accuracy: 0.6403\n","Epoch 96/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5020 - accuracy: 0.9697 - val_loss: 1.2269 - val_accuracy: 0.6640\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4984 - accuracy: 0.9700 - val_loss: 1.2361 - val_accuracy: 0.6584\n","Epoch 98/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4998 - accuracy: 0.9697 - val_loss: 1.2393 - val_accuracy: 0.6640\n","Epoch 99/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4901 - accuracy: 0.9754 - val_loss: 1.2548 - val_accuracy: 0.6493\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4873 - accuracy: 0.9740 - val_loss: 1.2446 - val_accuracy: 0.6595\n","{'loss': [1.0280011892318726, 1.009626030921936, 1.0010359287261963, 0.9906795024871826, 0.9820036292076111, 0.9743461608886719, 0.9642367959022522, 0.9585974216461182, 0.9520001411437988, 0.9478843212127686, 0.939755380153656, 0.9320505857467651, 0.9280444383621216, 0.9123544096946716, 0.9064686894416809, 0.9013323783874512, 0.8928468823432922, 0.8859853148460388, 0.8791550993919373, 0.8778454661369324, 0.869701087474823, 0.8631691932678223, 0.8626367449760437, 0.85065096616745, 0.8440290093421936, 0.8367851376533508, 0.8323268294334412, 0.8257789015769958, 0.8234612941741943, 0.8208341598510742, 0.8051064610481262, 0.7993707656860352, 0.8029403686523438, 0.7980981469154358, 0.7895790338516235, 0.7841712832450867, 0.7906630039215088, 0.7726855874061584, 0.7605084776878357, 0.7541898488998413, 0.7483408451080322, 0.7471843957901001, 0.7506077289581299, 0.7441830635070801, 0.7293384075164795, 0.7238326668739319, 0.7219650745391846, 0.7167696356773376, 0.7075778245925903, 0.6997718811035156, 0.697546660900116, 0.6934884786605835, 0.6916460394859314, 0.6862364411354065, 0.6789818406105042, 0.674368143081665, 0.6706254482269287, 0.6677855253219604, 0.6552032232284546, 0.6513744592666626, 0.6467584371566772, 0.6438261270523071, 0.6357159614562988, 0.6335013508796692, 0.630118191242218, 0.6242613196372986, 0.6198109984397888, 0.6147789359092712, 0.6212352514266968, 0.6117741465568542, 0.6069309711456299, 0.5973808169364929, 0.5881007313728333, 0.5849961042404175, 0.5795751810073853, 0.5776459574699402, 0.5731940865516663, 0.571079671382904, 0.5711789727210999, 0.5606116652488708, 0.5565097332000732, 0.5542635321617126, 0.5588932037353516, 0.547450602054596, 0.5397181510925293, 0.5392722487449646, 0.540422260761261, 0.5287333130836487, 0.5226495265960693, 0.5223729014396667, 0.5199552774429321, 0.517824649810791, 0.5135006904602051, 0.5074387788772583, 0.5071845054626465, 0.5020015835762024, 0.4983881115913391, 0.49984225630760193, 0.49006253480911255, 0.48734891414642334], 'accuracy': [0.748160719871521, 0.7640067934989929, 0.7665534615516663, 0.7744765281677246, 0.7809846997261047, 0.7849462628364563, 0.793718159198761, 0.7925863265991211, 0.793718159198761, 0.7869269847869873, 0.7976796627044678, 0.7951329946517944, 0.801075279712677, 0.8172042965888977, 0.8183361887931824, 0.8200339674949646, 0.8268251419067383, 0.8296547532081604, 0.8324844241142273, 0.8222976922988892, 0.8307866454124451, 0.8330503702163696, 0.829937756061554, 0.8370118737220764, 0.8449349403381348, 0.8471986651420593, 0.8426712155342102, 0.8494623899459839, 0.8480475544929504, 0.8449349403381348, 0.8610639572143555, 0.859649121761322, 0.8548387289047241, 0.8585172891616821, 0.8602150678634644, 0.8636106252670288, 0.852292001247406, 0.8644595146179199, 0.8763440847396851, 0.8803055882453918, 0.8834182024002075, 0.8788907527923584, 0.8704017996788025, 0.881154477596283, 0.8907753229141235, 0.8893604874610901, 0.8938879370689392, 0.8904923796653748, 0.8972835540771484, 0.9049236178398132, 0.9006791114807129, 0.9026598930358887, 0.905206561088562, 0.905206561088562, 0.9083191752433777, 0.9060554504394531, 0.90888512134552, 0.9094510674476624, 0.916242241859436, 0.9196377992630005, 0.9193548560142517, 0.9213355779647827, 0.9202037453651428, 0.9247311949729919, 0.9252971410751343, 0.926711916923523, 0.926711916923523, 0.9295415878295898, 0.9216185808181763, 0.9261460304260254, 0.9318053126335144, 0.9366157054901123, 0.9422750473022461, 0.9453876614570618, 0.9453876614570618, 0.945104718208313, 0.9456706047058105, 0.9465195536613464, 0.9448217153549194, 0.9516128897666931, 0.9533106684684753, 0.950764000415802, 0.9468024969100952, 0.9490662217140198, 0.9558573961257935, 0.9578381180763245, 0.9564233422279358, 0.9603848457336426, 0.9677419066429138, 0.961799681186676, 0.9629315137863159, 0.9634974598884583, 0.9666100740432739, 0.9683078527450562, 0.9666100740432739, 0.9697226881980896, 0.9700056314468384, 0.9697226881980896, 0.9753820300102234, 0.9739671945571899], 'val_loss': [1.2024914026260376, 1.1968368291854858, 1.1934056282043457, 1.1884398460388184, 1.1857236623764038, 1.1806879043579102, 1.1758240461349487, 1.1730724573135376, 1.165395975112915, 1.157317876815796, 1.1491038799285889, 1.146283507347107, 1.1322497129440308, 1.1276795864105225, 1.1228687763214111, 1.1084147691726685, 1.1005909442901611, 1.096828818321228, 1.0849393606185913, 1.0922967195510864, 1.075171709060669, 1.066230297088623, 1.0758826732635498, 1.0807992219924927, 1.0686556100845337, 1.083644986152649, 1.0655561685562134, 1.0642385482788086, 1.102410078048706, 1.074558138847351, 1.0740673542022705, 1.0844130516052246, 1.083115577697754, 1.0765886306762695, 1.1178319454193115, 1.1146948337554932, 1.140122413635254, 1.0891022682189941, 1.0807243585586548, 1.0854755640029907, 1.0960887670516968, 1.0822982788085938, 1.0895345211029053, 1.0900459289550781, 1.0865085124969482, 1.0860613584518433, 1.1044566631317139, 1.088696002960205, 1.0999704599380493, 1.1067479848861694, 1.0969009399414062, 1.095681071281433, 1.1145503520965576, 1.0995968580245972, 1.1092253923416138, 1.1265392303466797, 1.1055936813354492, 1.1082839965820312, 1.1149815320968628, 1.1234126091003418, 1.1228396892547607, 1.1167246103286743, 1.1363015174865723, 1.1204267740249634, 1.1489477157592773, 1.132379174232483, 1.1482242345809937, 1.1415437459945679, 1.1674219369888306, 1.141526699066162, 1.177950382232666, 1.1449896097183228, 1.1533327102661133, 1.1533552408218384, 1.1497617959976196, 1.1557419300079346, 1.1619385480880737, 1.161573052406311, 1.173351526260376, 1.1785856485366821, 1.1692489385604858, 1.1749238967895508, 1.1838703155517578, 1.1850684881210327, 1.1877696514129639, 1.2290260791778564, 1.202101469039917, 1.1986732482910156, 1.2002304792404175, 1.2221165895462036, 1.2326170206069946, 1.2146073579788208, 1.2173755168914795, 1.2315871715545654, 1.2440898418426514, 1.2269471883773804, 1.2361146211624146, 1.2392594814300537, 1.2548364400863647, 1.244584083557129], 'val_accuracy': [0.5022624731063843, 0.5067873597145081, 0.5056561231613159, 0.5067873597145081, 0.5079185366630554, 0.5113122463226318, 0.5135746598243713, 0.5124434232711792, 0.516968309879303, 0.5384615659713745, 0.5509049892425537, 0.5486425161361694, 0.6018099784851074, 0.598416268825531, 0.5938913822174072, 0.6334841847419739, 0.6425339579582214, 0.6244344115257263, 0.6561086177825928, 0.6233031749725342, 0.651583731174469, 0.6651583909988403, 0.6425339579582214, 0.6380090713500977, 0.6527149081230164, 0.6380090713500977, 0.662895917892456, 0.6651583909988403, 0.6312217116355896, 0.6696832776069641, 0.6595022678375244, 0.6436651349067688, 0.651583731174469, 0.6708144545555115, 0.6266968250274658, 0.6651583909988403, 0.6165158152580261, 0.6730769276618958, 0.6583710312843323, 0.6730769276618958, 0.6368778347969055, 0.6651583909988403, 0.6696832776069641, 0.6662895679473877, 0.6538461446762085, 0.6595022678375244, 0.6504524946212769, 0.6583710312843323, 0.6436651349067688, 0.6470588445663452, 0.6572397947311401, 0.6617646813392639, 0.6459276080131531, 0.6617646813392639, 0.6493212580680847, 0.6674208045005798, 0.6595022678375244, 0.6481900215148926, 0.6674208045005798, 0.6504524946212769, 0.6708144545555115, 0.6674208045005798, 0.6436651349067688, 0.6504524946212769, 0.6357465982437134, 0.6470588445663452, 0.6459276080131531, 0.6549773812294006, 0.6357465982437134, 0.6425339579582214, 0.6300904750823975, 0.6538461446762085, 0.6414027214050293, 0.6425339579582214, 0.6606335043907166, 0.651583731174469, 0.6527149081230164, 0.662895917892456, 0.651583731174469, 0.6470588445663452, 0.6549773812294006, 0.6527149081230164, 0.6595022678375244, 0.6640271544456482, 0.6583710312843323, 0.6606335043907166, 0.6447963714599609, 0.6674208045005798, 0.6583710312843323, 0.6708144545555115, 0.6380090713500977, 0.6640271544456482, 0.6606335043907166, 0.6617646813392639, 0.6402714848518372, 0.6640271544456482, 0.6583710312843323, 0.6640271544456482, 0.6493212580680847, 0.6595022678375244]}\n","45/45 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 4s 29ms/step - loss: 1.0340 - accuracy: 0.7460 - val_loss: 1.2058 - val_accuracy: 0.4917\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 1.0202 - accuracy: 0.7734"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 0s 13ms/step - loss: 1.0187 - accuracy: 0.7540 - val_loss: 1.2028 - val_accuracy: 0.4907\n","Epoch 3/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0048 - accuracy: 0.7607 - val_loss: 1.2000 - val_accuracy: 0.4897\n","Epoch 4/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0015 - accuracy: 0.7654 - val_loss: 1.1955 - val_accuracy: 0.4938\n","Epoch 5/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9898 - accuracy: 0.7698 - val_loss: 1.1894 - val_accuracy: 0.4990\n","Epoch 6/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9828 - accuracy: 0.7749 - val_loss: 1.1879 - val_accuracy: 0.4979\n","Epoch 7/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9715 - accuracy: 0.7817 - val_loss: 1.1838 - val_accuracy: 0.5052\n","Epoch 8/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9644 - accuracy: 0.7853 - val_loss: 1.1780 - val_accuracy: 0.5155\n","Epoch 9/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9596 - accuracy: 0.7904 - val_loss: 1.1724 - val_accuracy: 0.5124\n","Epoch 10/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9520 - accuracy: 0.7930 - val_loss: 1.1612 - val_accuracy: 0.5289\n","Epoch 11/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9490 - accuracy: 0.7933 - val_loss: 1.1594 - val_accuracy: 0.5279\n","Epoch 12/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9423 - accuracy: 0.7886 - val_loss: 1.1613 - val_accuracy: 0.5227\n","Epoch 13/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9292 - accuracy: 0.8083 - val_loss: 1.1413 - val_accuracy: 0.5692\n","Epoch 14/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9193 - accuracy: 0.8158 - val_loss: 1.1436 - val_accuracy: 0.5486\n","Epoch 15/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9157 - accuracy: 0.8137 - val_loss: 1.1385 - val_accuracy: 0.5640\n","Epoch 16/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9094 - accuracy: 0.8098 - val_loss: 1.1279 - val_accuracy: 0.5868\n","Epoch 17/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9039 - accuracy: 0.8163 - val_loss: 1.1294 - val_accuracy: 0.5806\n","Epoch 18/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8938 - accuracy: 0.8199 - val_loss: 1.1203 - val_accuracy: 0.6074\n","Epoch 19/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8894 - accuracy: 0.8189 - val_loss: 1.1281 - val_accuracy: 0.5857\n","Epoch 20/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8813 - accuracy: 0.8266 - val_loss: 1.1235 - val_accuracy: 0.5981\n","Epoch 21/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8841 - accuracy: 0.8132 - val_loss: 1.1198 - val_accuracy: 0.6167\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8731 - accuracy: 0.8261 - val_loss: 1.1285 - val_accuracy: 0.6043\n","Epoch 23/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8669 - accuracy: 0.8222 - val_loss: 1.1320 - val_accuracy: 0.6188\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8569 - accuracy: 0.8362 - val_loss: 1.1339 - val_accuracy: 0.6167\n","Epoch 25/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8503 - accuracy: 0.8354 - val_loss: 1.1390 - val_accuracy: 0.6260\n","Epoch 26/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8445 - accuracy: 0.8375 - val_loss: 1.1691 - val_accuracy: 0.5826\n","Epoch 27/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8429 - accuracy: 0.8344 - val_loss: 1.1484 - val_accuracy: 0.6209\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8306 - accuracy: 0.8442 - val_loss: 1.1513 - val_accuracy: 0.6240\n","Epoch 29/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8264 - accuracy: 0.8439 - val_loss: 1.1584 - val_accuracy: 0.6209\n","Epoch 30/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8217 - accuracy: 0.8501 - val_loss: 1.1593 - val_accuracy: 0.6074\n","Epoch 31/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8132 - accuracy: 0.8530 - val_loss: 1.1646 - val_accuracy: 0.6074\n","Epoch 32/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8088 - accuracy: 0.8522 - val_loss: 1.1966 - val_accuracy: 0.5847\n","Epoch 33/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8060 - accuracy: 0.8468 - val_loss: 1.1698 - val_accuracy: 0.6064\n","Epoch 34/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7948 - accuracy: 0.8612 - val_loss: 1.1670 - val_accuracy: 0.6136\n","Epoch 35/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7943 - accuracy: 0.8501 - val_loss: 1.1986 - val_accuracy: 0.5909\n","Epoch 36/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7927 - accuracy: 0.8537 - val_loss: 1.1907 - val_accuracy: 0.5940\n","Epoch 37/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7781 - accuracy: 0.8646 - val_loss: 1.1835 - val_accuracy: 0.6012\n","Epoch 38/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7723 - accuracy: 0.8672 - val_loss: 1.1748 - val_accuracy: 0.6291\n","Epoch 39/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7673 - accuracy: 0.8703 - val_loss: 1.1783 - val_accuracy: 0.6198\n","Epoch 40/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7598 - accuracy: 0.8744 - val_loss: 1.1817 - val_accuracy: 0.6043\n","Epoch 41/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7594 - accuracy: 0.8718 - val_loss: 1.1833 - val_accuracy: 0.6240\n","Epoch 42/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7566 - accuracy: 0.8711 - val_loss: 1.1811 - val_accuracy: 0.6157\n","Epoch 43/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7504 - accuracy: 0.8747 - val_loss: 1.2031 - val_accuracy: 0.5868\n","Epoch 44/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7411 - accuracy: 0.8791 - val_loss: 1.1879 - val_accuracy: 0.6157\n","Epoch 45/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7313 - accuracy: 0.8897 - val_loss: 1.1948 - val_accuracy: 0.6012\n","Epoch 46/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7324 - accuracy: 0.8778 - val_loss: 1.1973 - val_accuracy: 0.5981\n","Epoch 47/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7191 - accuracy: 0.8894 - val_loss: 1.1964 - val_accuracy: 0.6271\n","Epoch 48/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7147 - accuracy: 0.8933 - val_loss: 1.1986 - val_accuracy: 0.6105\n","Epoch 49/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7132 - accuracy: 0.8933 - val_loss: 1.1960 - val_accuracy: 0.6157\n","Epoch 50/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7046 - accuracy: 0.8941 - val_loss: 1.2008 - val_accuracy: 0.6074\n","Epoch 51/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7028 - accuracy: 0.8891 - val_loss: 1.2734 - val_accuracy: 0.5816\n","Epoch 52/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6981 - accuracy: 0.8948 - val_loss: 1.2072 - val_accuracy: 0.6178\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6883 - accuracy: 0.9023 - val_loss: 1.2126 - val_accuracy: 0.6085\n","Epoch 54/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6820 - accuracy: 0.9049 - val_loss: 1.2293 - val_accuracy: 0.6229\n","Epoch 55/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6856 - accuracy: 0.8995 - val_loss: 1.2238 - val_accuracy: 0.5992\n","Epoch 56/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6812 - accuracy: 0.8948 - val_loss: 1.2253 - val_accuracy: 0.6033\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6696 - accuracy: 0.9028 - val_loss: 1.2352 - val_accuracy: 0.6147\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6638 - accuracy: 0.9044 - val_loss: 1.2251 - val_accuracy: 0.6136\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6650 - accuracy: 0.9036 - val_loss: 1.2370 - val_accuracy: 0.5981\n","Epoch 60/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6517 - accuracy: 0.9152 - val_loss: 1.2442 - val_accuracy: 0.6002\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6479 - accuracy: 0.9173 - val_loss: 1.2332 - val_accuracy: 0.6147\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6431 - accuracy: 0.9163 - val_loss: 1.2598 - val_accuracy: 0.5878\n","Epoch 63/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6512 - accuracy: 0.9083 - val_loss: 1.2512 - val_accuracy: 0.6023\n","Epoch 64/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6358 - accuracy: 0.9173 - val_loss: 1.2405 - val_accuracy: 0.6105\n","Epoch 65/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6272 - accuracy: 0.9222 - val_loss: 1.2538 - val_accuracy: 0.6002\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6226 - accuracy: 0.9212 - val_loss: 1.2644 - val_accuracy: 0.5992\n","Epoch 67/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6186 - accuracy: 0.9248 - val_loss: 1.2551 - val_accuracy: 0.6147\n","Epoch 68/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6135 - accuracy: 0.9261 - val_loss: 1.2603 - val_accuracy: 0.6219\n","Epoch 69/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6108 - accuracy: 0.9261 - val_loss: 1.2626 - val_accuracy: 0.6074\n","Epoch 70/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6072 - accuracy: 0.9264 - val_loss: 1.2703 - val_accuracy: 0.6250\n","Epoch 71/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6120 - accuracy: 0.9207 - val_loss: 1.3323 - val_accuracy: 0.5857\n","Epoch 72/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6029 - accuracy: 0.9240 - val_loss: 1.2793 - val_accuracy: 0.6064\n","Epoch 73/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5961 - accuracy: 0.9323 - val_loss: 1.3137 - val_accuracy: 0.5888\n","Epoch 74/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5978 - accuracy: 0.9264 - val_loss: 1.2812 - val_accuracy: 0.6209\n","Epoch 75/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5868 - accuracy: 0.9367 - val_loss: 1.2963 - val_accuracy: 0.6229\n","Epoch 76/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5812 - accuracy: 0.9380 - val_loss: 1.2832 - val_accuracy: 0.6095\n","Epoch 77/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5745 - accuracy: 0.9424 - val_loss: 1.2891 - val_accuracy: 0.6167\n","Epoch 78/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5713 - accuracy: 0.9375 - val_loss: 1.3290 - val_accuracy: 0.5930\n","Epoch 79/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5704 - accuracy: 0.9401 - val_loss: 1.2994 - val_accuracy: 0.6167\n","Epoch 80/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5656 - accuracy: 0.9421 - val_loss: 1.3042 - val_accuracy: 0.6095\n","Epoch 81/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5596 - accuracy: 0.9408 - val_loss: 1.3166 - val_accuracy: 0.6043\n","Epoch 82/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5529 - accuracy: 0.9488 - val_loss: 1.3271 - val_accuracy: 0.6240\n","Epoch 83/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5609 - accuracy: 0.9398 - val_loss: 1.3927 - val_accuracy: 0.5868\n","Epoch 84/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5528 - accuracy: 0.9408 - val_loss: 1.3181 - val_accuracy: 0.6136\n","Epoch 85/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5443 - accuracy: 0.9494 - val_loss: 1.3475 - val_accuracy: 0.6260\n","Epoch 86/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5396 - accuracy: 0.9530 - val_loss: 1.3451 - val_accuracy: 0.6002\n","Epoch 87/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5335 - accuracy: 0.9563 - val_loss: 1.3426 - val_accuracy: 0.6188\n","Epoch 88/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5320 - accuracy: 0.9540 - val_loss: 1.3374 - val_accuracy: 0.6105\n","Epoch 89/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5316 - accuracy: 0.9540 - val_loss: 1.3461 - val_accuracy: 0.6147\n","Epoch 90/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5243 - accuracy: 0.9576 - val_loss: 1.3723 - val_accuracy: 0.6012\n","Epoch 91/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5209 - accuracy: 0.9576 - val_loss: 1.3507 - val_accuracy: 0.6188\n","Epoch 92/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5216 - accuracy: 0.9563 - val_loss: 1.3684 - val_accuracy: 0.6281\n","Epoch 93/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5128 - accuracy: 0.9605 - val_loss: 1.3574 - val_accuracy: 0.6229\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5101 - accuracy: 0.9651 - val_loss: 1.3714 - val_accuracy: 0.6198\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5090 - accuracy: 0.9638 - val_loss: 1.3740 - val_accuracy: 0.6147\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5032 - accuracy: 0.9630 - val_loss: 1.3926 - val_accuracy: 0.6012\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5043 - accuracy: 0.9618 - val_loss: 1.3841 - val_accuracy: 0.6260\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4982 - accuracy: 0.9656 - val_loss: 1.3856 - val_accuracy: 0.6229\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4939 - accuracy: 0.9680 - val_loss: 1.3942 - val_accuracy: 0.6240\n","Epoch 100/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4952 - accuracy: 0.9651 - val_loss: 1.4033 - val_accuracy: 0.6229\n","{'loss': [1.0340369939804077, 1.0187140703201294, 1.0047507286071777, 1.0014560222625732, 0.9897934198379517, 0.9827569127082825, 0.9715168476104736, 0.9644346833229065, 0.959588348865509, 0.9519616365432739, 0.9489830732345581, 0.9423003196716309, 0.9292465448379517, 0.9192542433738708, 0.9157317280769348, 0.9094322919845581, 0.9038933515548706, 0.893807590007782, 0.8894214034080505, 0.8813292384147644, 0.8840723633766174, 0.8731294274330139, 0.8669480085372925, 0.8568518757820129, 0.8503016233444214, 0.8444533348083496, 0.8429110646247864, 0.8305864334106445, 0.8263980746269226, 0.8217048645019531, 0.8132064938545227, 0.8087815046310425, 0.8059833645820618, 0.794795036315918, 0.7943114638328552, 0.7926844358444214, 0.778065025806427, 0.7722537517547607, 0.7672899961471558, 0.7597817778587341, 0.759415864944458, 0.7565778493881226, 0.7504141926765442, 0.7411414980888367, 0.7312718033790588, 0.7323593497276306, 0.719118058681488, 0.7146846055984497, 0.7131816744804382, 0.704560399055481, 0.7028307914733887, 0.6980708837509155, 0.6883499622344971, 0.6819700598716736, 0.6855764389038086, 0.6811578869819641, 0.6695843935012817, 0.6638252139091492, 0.6649931073188782, 0.6516661047935486, 0.6479418277740479, 0.6431338787078857, 0.6512083411216736, 0.6358048319816589, 0.6271503567695618, 0.6225964426994324, 0.6185654997825623, 0.6134741306304932, 0.6107791066169739, 0.6072458028793335, 0.6119611859321594, 0.6028772592544556, 0.5960873961448669, 0.5977993011474609, 0.5867546200752258, 0.5812442302703857, 0.5745002031326294, 0.5713269710540771, 0.5703831315040588, 0.5655844211578369, 0.559643030166626, 0.5529190301895142, 0.5609058737754822, 0.5527740120887756, 0.5442618727684021, 0.5395582914352417, 0.5334563255310059, 0.5320037007331848, 0.5316339135169983, 0.5242839455604553, 0.5209195017814636, 0.5215650200843811, 0.5128037333488464, 0.5100830793380737, 0.508994460105896, 0.5031542181968689, 0.5042603015899658, 0.4982152283191681, 0.49389171600341797, 0.49517133831977844], 'accuracy': [0.7459948062896729, 0.7540051937103271, 0.7607235312461853, 0.7653746604919434, 0.7697674632072449, 0.7749354243278503, 0.7816537618637085, 0.7852713465690613, 0.790439248085022, 0.7930232286453247, 0.7932816743850708, 0.788630485534668, 0.8082687258720398, 0.8157622814178467, 0.8136950731277466, 0.8098191022872925, 0.8162790536880493, 0.8198966383934021, 0.818863034248352, 0.8266149759292603, 0.813178300857544, 0.8260982036590576, 0.8222222328186035, 0.8361757397651672, 0.8354005217552185, 0.8374677300453186, 0.8343669176101685, 0.8441860675811768, 0.8439276218414307, 0.8501291871070862, 0.8529715538024902, 0.8521963953971863, 0.8467700481414795, 0.8612403273582458, 0.8501291871070862, 0.853746771812439, 0.8645994663238525, 0.8671834468841553, 0.8702842593193054, 0.8744186162948608, 0.8718346357345581, 0.8710594177246094, 0.8746770024299622, 0.8790697455406189, 0.8896640539169312, 0.8777777552604675, 0.8894056677818298, 0.8932816386222839, 0.8932816386222839, 0.8940568566322327, 0.8891472816467285, 0.8948320150375366, 0.9023255705833435, 0.9049095511436462, 0.8994832038879395, 0.8948320150375366, 0.9028424024581909, 0.9043927788734436, 0.9036175608634949, 0.9152454733848572, 0.9173126816749573, 0.9162790775299072, 0.9082687497138977, 0.9173126816749573, 0.9222221970558167, 0.9211886525154114, 0.9248061776161194, 0.9260981678962708, 0.9260981678962708, 0.9263566136360168, 0.920671820640564, 0.9240310192108154, 0.9322997331619263, 0.9263566136360168, 0.9366925358772278, 0.9379844665527344, 0.9423772692680359, 0.9374676942825317, 0.9400516748428345, 0.9421188831329346, 0.9408268928527832, 0.9488372206687927, 0.9397932887077332, 0.9408268928527832, 0.9493539929389954, 0.9529715776443481, 0.9563307762145996, 0.9540051817893982, 0.9540051817893982, 0.957622766494751, 0.957622766494751, 0.9563307762145996, 0.960465133190155, 0.9651162624359131, 0.9638242721557617, 0.9630491137504578, 0.9617571234703064, 0.9656330943107605, 0.9679586291313171, 0.9651162624359131], 'val_loss': [1.205816388130188, 1.2028114795684814, 1.1999973058700562, 1.1955472230911255, 1.18939208984375, 1.1879106760025024, 1.1837834119796753, 1.1779847145080566, 1.1724168062210083, 1.161159873008728, 1.1594040393829346, 1.1613028049468994, 1.1412806510925293, 1.1436042785644531, 1.1385433673858643, 1.1279211044311523, 1.129350185394287, 1.1202551126480103, 1.1280609369277954, 1.1235201358795166, 1.1197731494903564, 1.1285046339035034, 1.1320104598999023, 1.1339263916015625, 1.1390300989151, 1.1690682172775269, 1.148403286933899, 1.1512994766235352, 1.158443808555603, 1.159250020980835, 1.1645896434783936, 1.1965500116348267, 1.1697841882705688, 1.1669944524765015, 1.198581576347351, 1.1906691789627075, 1.1835087537765503, 1.1748145818710327, 1.178337574005127, 1.1816627979278564, 1.1833479404449463, 1.1811487674713135, 1.2030967473983765, 1.1878634691238403, 1.1948281526565552, 1.197271466255188, 1.1964459419250488, 1.1986371278762817, 1.1960127353668213, 1.2007821798324585, 1.2734229564666748, 1.207208514213562, 1.2126144170761108, 1.2292907238006592, 1.2237534523010254, 1.2253038883209229, 1.2351914644241333, 1.2250888347625732, 1.2369977235794067, 1.244208812713623, 1.233249306678772, 1.2597945928573608, 1.2511800527572632, 1.240529179573059, 1.253788948059082, 1.2643622159957886, 1.255117416381836, 1.260256052017212, 1.262644648551941, 1.2703102827072144, 1.3322855234146118, 1.279260516166687, 1.3136560916900635, 1.2812020778656006, 1.2962778806686401, 1.2832015752792358, 1.2890926599502563, 1.3290379047393799, 1.2994261980056763, 1.3041737079620361, 1.3165645599365234, 1.327109932899475, 1.392737865447998, 1.3180718421936035, 1.3475159406661987, 1.345090389251709, 1.3426109552383423, 1.3373594284057617, 1.3461157083511353, 1.3723418712615967, 1.350698471069336, 1.3684405088424683, 1.3574036359786987, 1.3713717460632324, 1.373965859413147, 1.3926146030426025, 1.3840652704238892, 1.3856383562088013, 1.3941537141799927, 1.403324842453003], 'val_accuracy': [0.4917355477809906, 0.49070248007774353, 0.48966941237449646, 0.49380165338516235, 0.49896693229675293, 0.49793389439582825, 0.5051652789115906, 0.5154958963394165, 0.5123966932296753, 0.5289255976676941, 0.5278925895690918, 0.5227272510528564, 0.5692148804664612, 0.5485537052154541, 0.5640496015548706, 0.586776852607727, 0.5805785059928894, 0.6074380278587341, 0.58574378490448, 0.5981404781341553, 0.6167355179786682, 0.6043388247489929, 0.6188016533851624, 0.6167355179786682, 0.6260330677032471, 0.5826446413993835, 0.6208677887916565, 0.6239669322967529, 0.6208677887916565, 0.6074380278587341, 0.6074380278587341, 0.5847107172012329, 0.6064049601554871, 0.6136363744735718, 0.5909090638160706, 0.5940082669258118, 0.6012396812438965, 0.6291322112083435, 0.6198347210884094, 0.6043388247489929, 0.6239669322967529, 0.6157024502754211, 0.586776852607727, 0.6157024502754211, 0.6012396812438965, 0.5981404781341553, 0.6270661354064941, 0.6105371713638306, 0.6157024502754211, 0.6074380278587341, 0.5816115736961365, 0.6177685856819153, 0.6084710955619812, 0.6229338645935059, 0.5991735458374023, 0.6033057570457458, 0.6146694421768188, 0.6136363744735718, 0.5981404781341553, 0.6002066135406494, 0.6146694421768188, 0.5878099203109741, 0.6022727489471436, 0.6105371713638306, 0.6002066135406494, 0.5991735458374023, 0.6146694421768188, 0.6219007968902588, 0.6074380278587341, 0.625, 0.58574378490448, 0.6064049601554871, 0.5888429880142212, 0.6208677887916565, 0.6229338645935059, 0.6095041036605835, 0.6167355179786682, 0.5929751992225647, 0.6167355179786682, 0.6095041036605835, 0.6043388247489929, 0.6239669322967529, 0.586776852607727, 0.6136363744735718, 0.6260330677032471, 0.6002066135406494, 0.6188016533851624, 0.6105371713638306, 0.6146694421768188, 0.6012396812438965, 0.6188016533851624, 0.6280992031097412, 0.6229338645935059, 0.6198347210884094, 0.6146694421768188, 0.6012396812438965, 0.6260330677032471, 0.6229338645935059, 0.6239669322967529, 0.6229338645935059]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 4s 37ms/step - loss: 0.6160 - accuracy: 0.8928 - val_loss: 1.0789 - val_accuracy: 0.4881\n","Epoch 2/100\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 0s 13ms/step - loss: 0.5838 - accuracy: 0.9197 - val_loss: 1.0789 - val_accuracy: 0.4881\n","Epoch 3/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5737 - accuracy: 0.9221 - val_loss: 1.0781 - val_accuracy: 0.4892\n","Epoch 4/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5623 - accuracy: 0.9281 - val_loss: 1.0813 - val_accuracy: 0.4892\n","Epoch 5/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5593 - accuracy: 0.9294 - val_loss: 1.0799 - val_accuracy: 0.4903\n","Epoch 6/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5470 - accuracy: 0.9370 - val_loss: 1.0706 - val_accuracy: 0.4978\n","Epoch 7/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5453 - accuracy: 0.9356 - val_loss: 1.0685 - val_accuracy: 0.5043\n","Epoch 8/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5441 - accuracy: 0.9399 - val_loss: 1.0697 - val_accuracy: 0.5032\n","Epoch 9/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5324 - accuracy: 0.9445 - val_loss: 1.0632 - val_accuracy: 0.5097\n","Epoch 10/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5267 - accuracy: 0.9448 - val_loss: 1.0443 - val_accuracy: 0.5291\n","Epoch 11/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5278 - accuracy: 0.9499 - val_loss: 1.0111 - val_accuracy: 0.5539\n","Epoch 12/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5190 - accuracy: 0.9507 - val_loss: 1.0169 - val_accuracy: 0.5517\n","Epoch 13/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5120 - accuracy: 0.9555 - val_loss: 1.0084 - val_accuracy: 0.5636\n","Epoch 14/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5115 - accuracy: 0.9564 - val_loss: 0.9694 - val_accuracy: 0.6110\n","Epoch 15/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5091 - accuracy: 0.9542 - val_loss: 0.9281 - val_accuracy: 0.6821\n","Epoch 16/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5037 - accuracy: 0.9572 - val_loss: 0.9383 - val_accuracy: 0.6573\n","Epoch 17/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4995 - accuracy: 0.9615 - val_loss: 0.9051 - val_accuracy: 0.7134\n","Epoch 18/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5002 - accuracy: 0.9569 - val_loss: 0.9086 - val_accuracy: 0.7080\n","Epoch 19/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4916 - accuracy: 0.9617 - val_loss: 0.8847 - val_accuracy: 0.7317\n","Epoch 20/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4874 - accuracy: 0.9677 - val_loss: 0.9212 - val_accuracy: 0.7026\n","Epoch 21/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4910 - accuracy: 0.9601 - val_loss: 0.8704 - val_accuracy: 0.7446\n","Epoch 22/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4805 - accuracy: 0.9682 - val_loss: 0.8918 - val_accuracy: 0.7392\n","Epoch 23/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.4834 - accuracy: 0.9636 - val_loss: 0.8869 - val_accuracy: 0.7468\n","Epoch 24/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4768 - accuracy: 0.9688 - val_loss: 0.9114 - val_accuracy: 0.7468\n","Epoch 25/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4725 - accuracy: 0.9701 - val_loss: 0.9026 - val_accuracy: 0.7435\n","Epoch 26/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4707 - accuracy: 0.9685 - val_loss: 0.9157 - val_accuracy: 0.7435\n","Epoch 27/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4685 - accuracy: 0.9731 - val_loss: 0.9299 - val_accuracy: 0.7392\n","Epoch 28/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4600 - accuracy: 0.9758 - val_loss: 0.9484 - val_accuracy: 0.7522\n","Epoch 29/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4578 - accuracy: 0.9782 - val_loss: 0.9511 - val_accuracy: 0.7371\n","Epoch 30/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4549 - accuracy: 0.9779 - val_loss: 0.9564 - val_accuracy: 0.7457\n","Epoch 31/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4521 - accuracy: 0.9790 - val_loss: 0.9672 - val_accuracy: 0.7381\n","Epoch 32/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4498 - accuracy: 0.9814 - val_loss: 0.9689 - val_accuracy: 0.7435\n","Epoch 33/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4534 - accuracy: 0.9736 - val_loss: 1.0010 - val_accuracy: 0.7392\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4472 - accuracy: 0.9801 - val_loss: 0.9864 - val_accuracy: 0.7446\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4417 - accuracy: 0.9817 - val_loss: 0.9920 - val_accuracy: 0.7306\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4414 - accuracy: 0.9809 - val_loss: 0.9957 - val_accuracy: 0.7414\n","Epoch 37/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4356 - accuracy: 0.9844 - val_loss: 1.0044 - val_accuracy: 0.7263\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4397 - accuracy: 0.9798 - val_loss: 0.9989 - val_accuracy: 0.7338\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4318 - accuracy: 0.9852 - val_loss: 1.0046 - val_accuracy: 0.7317\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4312 - accuracy: 0.9844 - val_loss: 1.0112 - val_accuracy: 0.7317\n","Epoch 41/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4282 - accuracy: 0.9846 - val_loss: 1.0818 - val_accuracy: 0.7166\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4267 - accuracy: 0.9852 - val_loss: 1.0088 - val_accuracy: 0.7381\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4347 - accuracy: 0.9784 - val_loss: 1.0164 - val_accuracy: 0.7414\n","Epoch 44/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4234 - accuracy: 0.9860 - val_loss: 1.0147 - val_accuracy: 0.7381\n","Epoch 45/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4176 - accuracy: 0.9879 - val_loss: 1.0204 - val_accuracy: 0.7403\n","Epoch 46/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4176 - accuracy: 0.9876 - val_loss: 1.0271 - val_accuracy: 0.7371\n","Epoch 47/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4222 - accuracy: 0.9820 - val_loss: 1.0375 - val_accuracy: 0.7284\n","Epoch 48/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4141 - accuracy: 0.9865 - val_loss: 1.0327 - val_accuracy: 0.7338\n","Epoch 49/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4081 - accuracy: 0.9900 - val_loss: 1.0412 - val_accuracy: 0.7306\n","Epoch 50/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4075 - accuracy: 0.9895 - val_loss: 1.0363 - val_accuracy: 0.7306\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4041 - accuracy: 0.9908 - val_loss: 1.0449 - val_accuracy: 0.7274\n","Epoch 52/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4059 - accuracy: 0.9895 - val_loss: 1.0692 - val_accuracy: 0.7403\n","Epoch 53/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4066 - accuracy: 0.9898 - val_loss: 1.0504 - val_accuracy: 0.7349\n","Epoch 54/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4000 - accuracy: 0.9933 - val_loss: 1.0533 - val_accuracy: 0.7284\n","Epoch 55/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3995 - accuracy: 0.9895 - val_loss: 1.0612 - val_accuracy: 0.7231\n","Epoch 56/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3964 - accuracy: 0.9930 - val_loss: 1.1077 - val_accuracy: 0.7338\n","Epoch 57/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3972 - accuracy: 0.9908 - val_loss: 1.0649 - val_accuracy: 0.7328\n","Epoch 58/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3932 - accuracy: 0.9933 - val_loss: 1.1182 - val_accuracy: 0.7209\n","Epoch 59/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3952 - accuracy: 0.9906 - val_loss: 1.0825 - val_accuracy: 0.7274\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3958 - accuracy: 0.9906 - val_loss: 1.0798 - val_accuracy: 0.7360\n","Epoch 61/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3882 - accuracy: 0.9935 - val_loss: 1.0926 - val_accuracy: 0.7220\n","Epoch 62/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3855 - accuracy: 0.9946 - val_loss: 1.0842 - val_accuracy: 0.7328\n","Epoch 63/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3865 - accuracy: 0.9938 - val_loss: 1.1043 - val_accuracy: 0.7371\n","Epoch 64/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3929 - accuracy: 0.9895 - val_loss: 1.1035 - val_accuracy: 0.7188\n","Epoch 65/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3881 - accuracy: 0.9914 - val_loss: 1.1163 - val_accuracy: 0.7371\n","Epoch 66/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3810 - accuracy: 0.9943 - val_loss: 1.1039 - val_accuracy: 0.7252\n","Epoch 67/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3819 - accuracy: 0.9949 - val_loss: 1.1166 - val_accuracy: 0.7188\n","Epoch 68/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3796 - accuracy: 0.9949 - val_loss: 1.1107 - val_accuracy: 0.7220\n","Epoch 69/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3766 - accuracy: 0.9952 - val_loss: 1.1072 - val_accuracy: 0.7338\n","Epoch 70/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3733 - accuracy: 0.9960 - val_loss: 1.1090 - val_accuracy: 0.7252\n","Epoch 71/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3744 - accuracy: 0.9946 - val_loss: 1.1269 - val_accuracy: 0.7166\n","Epoch 72/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3697 - accuracy: 0.9965 - val_loss: 1.1215 - val_accuracy: 0.7360\n","Epoch 73/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3718 - accuracy: 0.9946 - val_loss: 1.1240 - val_accuracy: 0.7274\n","Epoch 74/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3686 - accuracy: 0.9965 - val_loss: 1.1270 - val_accuracy: 0.7392\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3731 - accuracy: 0.9943 - val_loss: 1.1354 - val_accuracy: 0.7328\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3683 - accuracy: 0.9949 - val_loss: 1.1416 - val_accuracy: 0.7209\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3683 - accuracy: 0.9954 - val_loss: 1.1407 - val_accuracy: 0.7295\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3637 - accuracy: 0.9970 - val_loss: 1.1380 - val_accuracy: 0.7338\n","Epoch 79/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3662 - accuracy: 0.9962 - val_loss: 1.1675 - val_accuracy: 0.7101\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3604 - accuracy: 0.9976 - val_loss: 1.1605 - val_accuracy: 0.7177\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3581 - accuracy: 0.9976 - val_loss: 1.1581 - val_accuracy: 0.7166\n","Epoch 82/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3612 - accuracy: 0.9965 - val_loss: 1.1621 - val_accuracy: 0.7241\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3598 - accuracy: 0.9965 - val_loss: 1.2009 - val_accuracy: 0.7058\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3557 - accuracy: 0.9970 - val_loss: 1.1579 - val_accuracy: 0.7338\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3553 - accuracy: 0.9978 - val_loss: 1.1684 - val_accuracy: 0.7328\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3549 - accuracy: 0.9978 - val_loss: 1.1713 - val_accuracy: 0.7295\n","Epoch 87/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3526 - accuracy: 0.9978 - val_loss: 1.1766 - val_accuracy: 0.7177\n","Epoch 88/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3533 - accuracy: 0.9973 - val_loss: 1.1737 - val_accuracy: 0.7295\n","Epoch 89/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3512 - accuracy: 0.9970 - val_loss: 1.1799 - val_accuracy: 0.7188\n","Epoch 90/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3484 - accuracy: 0.9981 - val_loss: 1.1823 - val_accuracy: 0.7349\n","Epoch 91/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3491 - accuracy: 0.9984 - val_loss: 1.1931 - val_accuracy: 0.7134\n","Epoch 92/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3490 - accuracy: 0.9981 - val_loss: 1.2248 - val_accuracy: 0.7317\n","Epoch 93/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3515 - accuracy: 0.9973 - val_loss: 1.1879 - val_accuracy: 0.7220\n","Epoch 94/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3490 - accuracy: 0.9987 - val_loss: 1.1876 - val_accuracy: 0.7306\n","Epoch 95/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3439 - accuracy: 0.9981 - val_loss: 1.2145 - val_accuracy: 0.7209\n","Epoch 96/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3453 - accuracy: 0.9981 - val_loss: 1.2148 - val_accuracy: 0.7295\n","Epoch 97/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3432 - accuracy: 0.9989 - val_loss: 1.2044 - val_accuracy: 0.7317\n","Epoch 98/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3457 - accuracy: 0.9978 - val_loss: 1.2135 - val_accuracy: 0.7274\n","Epoch 99/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3420 - accuracy: 0.9984 - val_loss: 1.2312 - val_accuracy: 0.7144\n","Epoch 100/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3385 - accuracy: 0.9989 - val_loss: 1.2158 - val_accuracy: 0.7198\n","{'loss': [0.6160318851470947, 0.5837506055831909, 0.5736843347549438, 0.5623279213905334, 0.5593037605285645, 0.5469929575920105, 0.5453305840492249, 0.544050395488739, 0.5324257612228394, 0.526711642742157, 0.5277753472328186, 0.5189840197563171, 0.5119738578796387, 0.5115176439285278, 0.5090967416763306, 0.50370192527771, 0.4994693398475647, 0.5002139806747437, 0.49159878492355347, 0.4873647093772888, 0.491049200296402, 0.48053792119026184, 0.4833885729312897, 0.4767860174179077, 0.47249022126197815, 0.4706830680370331, 0.468534916639328, 0.4599995017051697, 0.4577615559101105, 0.45492658019065857, 0.45212867856025696, 0.44980373978614807, 0.45338761806488037, 0.4472270607948303, 0.44173943996429443, 0.4414224624633789, 0.43563517928123474, 0.43972665071487427, 0.431767076253891, 0.4311906695365906, 0.4282399117946625, 0.4267151653766632, 0.43465811014175415, 0.4234171211719513, 0.4176143705844879, 0.41756394505500793, 0.42215994000434875, 0.4141395688056946, 0.4081140160560608, 0.407510370016098, 0.40410172939300537, 0.4058748483657837, 0.40662503242492676, 0.4000292122364044, 0.3995477855205536, 0.39644336700439453, 0.3971586227416992, 0.39321988821029663, 0.39524373412132263, 0.39576277136802673, 0.38824841380119324, 0.3854643404483795, 0.38650327920913696, 0.3928941488265991, 0.38812255859375, 0.38095322251319885, 0.38194775581359863, 0.3795592784881592, 0.3765580356121063, 0.37328073382377625, 0.37437546253204346, 0.36969873309135437, 0.3717651069164276, 0.3686215877532959, 0.373109370470047, 0.36832931637763977, 0.3683381676673889, 0.36372464895248413, 0.36622029542922974, 0.3604426681995392, 0.3581004738807678, 0.36118197441101074, 0.3598172962665558, 0.35570117831230164, 0.35526347160339355, 0.3549047112464905, 0.35260993242263794, 0.35327011346817017, 0.35119083523750305, 0.3484235405921936, 0.349127858877182, 0.3489854037761688, 0.3515207767486572, 0.3489721417427063, 0.3438868224620819, 0.3452911972999573, 0.34322589635849, 0.3456938564777374, 0.3419785797595978, 0.33848708868026733], 'accuracy': [0.8927801847457886, 0.9197198152542114, 0.9221444129943848, 0.928071141242981, 0.9294180870056152, 0.9369612336158752, 0.9356142282485962, 0.9399245977401733, 0.9445043206214905, 0.9447737336158752, 0.9498922228813171, 0.9507004022598267, 0.9555495977401733, 0.9563577771186829, 0.9542025923728943, 0.9571659564971924, 0.9614762663841248, 0.9568965435028076, 0.9617456793785095, 0.9676724076271057, 0.9601293206214905, 0.9682112336158752, 0.9636314511299133, 0.96875, 0.970097005367279, 0.9684805870056152, 0.9730603694915771, 0.9757543206214905, 0.978178858757019, 0.977909505367279, 0.9789870977401733, 0.9814116358757019, 0.9735991358757019, 0.9800646305084229, 0.9816810488700867, 0.9808728694915771, 0.984375, 0.9797952771186829, 0.9851831793785095, 0.984375, 0.9846444129943848, 0.9851831793785095, 0.9784482717514038, 0.985991358757019, 0.9878771305084229, 0.9876077771186829, 0.9819504022598267, 0.9865301847457886, 0.9900323152542114, 0.9894935488700867, 0.990840494632721, 0.9894935488700867, 0.9897629022598267, 0.9932650923728943, 0.9894935488700867, 0.9929956793785095, 0.990840494632721, 0.9932650923728943, 0.990571141242981, 0.990571141242981, 0.993534505367279, 0.9946120977401733, 0.993803858757019, 0.9894935488700867, 0.9913793206214905, 0.9943426847457886, 0.9948814511299133, 0.9948814511299133, 0.9951508641242981, 0.9959590435028076, 0.9946120977401733, 0.9964978694915771, 0.9946120977401733, 0.9964978694915771, 0.9943426847457886, 0.9948814511299133, 0.9954202771186829, 0.9970366358757019, 0.9962284564971924, 0.9975754022598267, 0.9975754022598267, 0.9964978694915771, 0.9964978694915771, 0.9970366358757019, 0.9978448152542114, 0.9978448152542114, 0.9978448152542114, 0.9973060488700867, 0.9970366358757019, 0.9981142282485962, 0.998383641242981, 0.9981142282485962, 0.9973060488700867, 0.998652994632721, 0.9981142282485962, 0.9981142282485962, 0.9989224076271057, 0.9978448152542114, 0.998383641242981, 0.9989224076271057], 'val_loss': [1.0788719654083252, 1.078891634941101, 1.078126072883606, 1.0812748670578003, 1.079864740371704, 1.070615530014038, 1.0684744119644165, 1.0696725845336914, 1.063186526298523, 1.0442684888839722, 1.0110905170440674, 1.016926884651184, 1.0084340572357178, 0.9694379568099976, 0.92806077003479, 0.9382697939872742, 0.9051043391227722, 0.9085687398910522, 0.8847315311431885, 0.921170711517334, 0.8704428672790527, 0.8917507529258728, 0.88685142993927, 0.9113642573356628, 0.9026133418083191, 0.9156892895698547, 0.9299043416976929, 0.9483898282051086, 0.9511034488677979, 0.956422746181488, 0.9672061204910278, 0.968868613243103, 1.000962734222412, 0.98639315366745, 0.9920153617858887, 0.9956508278846741, 1.0043951272964478, 0.9989123344421387, 1.0046435594558716, 1.0111703872680664, 1.0818146467208862, 1.0088392496109009, 1.0163668394088745, 1.0146502256393433, 1.0204002857208252, 1.027069091796875, 1.037474513053894, 1.0326775312423706, 1.0411696434020996, 1.0362941026687622, 1.044853925704956, 1.06919264793396, 1.0503898859024048, 1.0532892942428589, 1.0612424612045288, 1.10774564743042, 1.0649091005325317, 1.1181877851486206, 1.0825185775756836, 1.0798115730285645, 1.0926039218902588, 1.0841572284698486, 1.1043386459350586, 1.1035425662994385, 1.1163394451141357, 1.1038789749145508, 1.1166378259658813, 1.1107313632965088, 1.1071702241897583, 1.1089613437652588, 1.126867413520813, 1.121474027633667, 1.1240366697311401, 1.1269557476043701, 1.1354361772537231, 1.1415777206420898, 1.1407259702682495, 1.1380436420440674, 1.1675349473953247, 1.1604855060577393, 1.158127784729004, 1.1620844602584839, 1.2009121179580688, 1.1579313278198242, 1.1684479713439941, 1.1713463068008423, 1.1766339540481567, 1.1737475395202637, 1.1799226999282837, 1.182347297668457, 1.1931169033050537, 1.2248433828353882, 1.187922716140747, 1.1875890493392944, 1.2145447731018066, 1.21480131149292, 1.204370141029358, 1.2134627103805542, 1.2311863899230957, 1.2158465385437012], 'val_accuracy': [0.4881465435028076, 0.4881465435028076, 0.4892241358757019, 0.4892241358757019, 0.4903017282485962, 0.4978448152542114, 0.5043103694915771, 0.5032327771186829, 0.5096982717514038, 0.5290948152542114, 0.5538793206214905, 0.5517241358757019, 0.5635775923728943, 0.610991358757019, 0.6821120977401733, 0.6573275923728943, 0.7133620977401733, 0.7079741358757019, 0.7316810488700867, 0.7025862336158752, 0.7446120977401733, 0.7392241358757019, 0.7467672228813171, 0.7467672228813171, 0.743534505367279, 0.743534505367279, 0.7392241358757019, 0.7521551847457886, 0.7370689511299133, 0.7456896305084229, 0.7381465435028076, 0.743534505367279, 0.7392241358757019, 0.7446120977401733, 0.7306034564971924, 0.7413793206214905, 0.7262930870056152, 0.7338362336158752, 0.7316810488700867, 0.7316810488700867, 0.7165948152542114, 0.7381465435028076, 0.7413793206214905, 0.7381465435028076, 0.7403017282485962, 0.7370689511299133, 0.7284482717514038, 0.7338362336158752, 0.7306034564971924, 0.7306034564971924, 0.7273706793785095, 0.7403017282485962, 0.7349137663841248, 0.7284482717514038, 0.7230603694915771, 0.7338362336158752, 0.732758641242981, 0.7209051847457886, 0.7273706793785095, 0.735991358757019, 0.7219827771186829, 0.732758641242981, 0.7370689511299133, 0.71875, 0.7370689511299133, 0.725215494632721, 0.71875, 0.7219827771186829, 0.7338362336158752, 0.725215494632721, 0.7165948152542114, 0.735991358757019, 0.7273706793785095, 0.7392241358757019, 0.732758641242981, 0.7209051847457886, 0.7295258641242981, 0.7338362336158752, 0.7101293206214905, 0.7176724076271057, 0.7165948152542114, 0.7241379022598267, 0.7058189511299133, 0.7338362336158752, 0.732758641242981, 0.7295258641242981, 0.7176724076271057, 0.7295258641242981, 0.71875, 0.7349137663841248, 0.7133620977401733, 0.7316810488700867, 0.7219827771186829, 0.7306034564971924, 0.7209051847457886, 0.7295258641242981, 0.7316810488700867, 0.7273706793785095, 0.7144396305084229, 0.7198275923728943]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 37ms/step - loss: 0.6141 - accuracy: 0.8978 - val_loss: 1.0735 - val_accuracy: 0.5000\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.5500 - accuracy: 0.9375"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 1s 23ms/step - loss: 0.5865 - accuracy: 0.9126 - val_loss: 1.0691 - val_accuracy: 0.5034\n","Epoch 3/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5836 - accuracy: 0.9131 - val_loss: 1.0737 - val_accuracy: 0.5023\n","Epoch 4/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5676 - accuracy: 0.9242 - val_loss: 1.0696 - val_accuracy: 0.5045\n","Epoch 5/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5616 - accuracy: 0.9244 - val_loss: 1.0754 - val_accuracy: 0.5045\n","Epoch 6/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5625 - accuracy: 0.9256 - val_loss: 1.0693 - val_accuracy: 0.5057\n","Epoch 7/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5506 - accuracy: 0.9324 - val_loss: 1.0659 - val_accuracy: 0.5057\n","Epoch 8/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5427 - accuracy: 0.9352 - val_loss: 1.0589 - val_accuracy: 0.5113\n","Epoch 9/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5366 - accuracy: 0.9423 - val_loss: 1.0541 - val_accuracy: 0.5147\n","Epoch 10/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5328 - accuracy: 0.9474 - val_loss: 1.0517 - val_accuracy: 0.5238\n","Epoch 11/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5321 - accuracy: 0.9434 - val_loss: 1.0304 - val_accuracy: 0.5373\n","Epoch 12/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5236 - accuracy: 0.9516 - val_loss: 1.0323 - val_accuracy: 0.5441\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5208 - accuracy: 0.9460 - val_loss: 1.0190 - val_accuracy: 0.5520\n","Epoch 14/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5179 - accuracy: 0.9502 - val_loss: 0.9481 - val_accuracy: 0.6437\n","Epoch 15/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5160 - accuracy: 0.9513 - val_loss: 0.9843 - val_accuracy: 0.6029\n","Epoch 16/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5097 - accuracy: 0.9544 - val_loss: 0.9652 - val_accuracy: 0.6222\n","Epoch 17/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5015 - accuracy: 0.9578 - val_loss: 0.9108 - val_accuracy: 0.6900\n","Epoch 18/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4982 - accuracy: 0.9598 - val_loss: 0.9473 - val_accuracy: 0.6550\n","Epoch 19/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4959 - accuracy: 0.9615 - val_loss: 0.8948 - val_accuracy: 0.7104\n","Epoch 20/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4953 - accuracy: 0.9595 - val_loss: 0.9519 - val_accuracy: 0.6674\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4900 - accuracy: 0.9638 - val_loss: 0.8744 - val_accuracy: 0.7285\n","Epoch 22/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4895 - accuracy: 0.9604 - val_loss: 0.9133 - val_accuracy: 0.7014\n","Epoch 23/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4883 - accuracy: 0.9632 - val_loss: 0.8716 - val_accuracy: 0.7330\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4783 - accuracy: 0.9692 - val_loss: 0.8723 - val_accuracy: 0.7421\n","Epoch 25/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4784 - accuracy: 0.9666 - val_loss: 0.9331 - val_accuracy: 0.7093\n","Epoch 26/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4743 - accuracy: 0.9700 - val_loss: 0.8900 - val_accuracy: 0.7500\n","Epoch 27/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4708 - accuracy: 0.9703 - val_loss: 0.8965 - val_accuracy: 0.7421\n","Epoch 28/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4656 - accuracy: 0.9726 - val_loss: 0.9068 - val_accuracy: 0.7545\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4635 - accuracy: 0.9745 - val_loss: 0.9178 - val_accuracy: 0.7511\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4615 - accuracy: 0.9737 - val_loss: 0.9265 - val_accuracy: 0.7466\n","Epoch 31/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4597 - accuracy: 0.9723 - val_loss: 0.9984 - val_accuracy: 0.7206\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4571 - accuracy: 0.9731 - val_loss: 0.9417 - val_accuracy: 0.7466\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4540 - accuracy: 0.9765 - val_loss: 0.9525 - val_accuracy: 0.7477\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4504 - accuracy: 0.9802 - val_loss: 0.9553 - val_accuracy: 0.7443\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4477 - accuracy: 0.9785 - val_loss: 0.9582 - val_accuracy: 0.7398\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4466 - accuracy: 0.9791 - val_loss: 1.0024 - val_accuracy: 0.7251\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4412 - accuracy: 0.9799 - val_loss: 0.9697 - val_accuracy: 0.7500\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4381 - accuracy: 0.9825 - val_loss: 0.9982 - val_accuracy: 0.7296\n","Epoch 39/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4490 - accuracy: 0.9754 - val_loss: 1.0203 - val_accuracy: 0.7353\n","Epoch 40/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4339 - accuracy: 0.9822 - val_loss: 0.9884 - val_accuracy: 0.7319\n","Epoch 41/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4318 - accuracy: 0.9833 - val_loss: 0.9914 - val_accuracy: 0.7443\n","Epoch 42/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4263 - accuracy: 0.9842 - val_loss: 1.0037 - val_accuracy: 0.7217\n","Epoch 43/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4300 - accuracy: 0.9842 - val_loss: 0.9969 - val_accuracy: 0.7353\n","Epoch 44/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4272 - accuracy: 0.9808 - val_loss: 0.9998 - val_accuracy: 0.7398\n","Epoch 45/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4248 - accuracy: 0.9853 - val_loss: 1.0031 - val_accuracy: 0.7296\n","Epoch 46/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4174 - accuracy: 0.9887 - val_loss: 1.0158 - val_accuracy: 0.7330\n","Epoch 47/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4144 - accuracy: 0.9887 - val_loss: 1.0104 - val_accuracy: 0.7353\n","Epoch 48/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4127 - accuracy: 0.9895 - val_loss: 1.0169 - val_accuracy: 0.7421\n","Epoch 49/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4129 - accuracy: 0.9895 - val_loss: 1.0161 - val_accuracy: 0.7376\n","Epoch 50/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4088 - accuracy: 0.9921 - val_loss: 1.0227 - val_accuracy: 0.7421\n","Epoch 51/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4170 - accuracy: 0.9825 - val_loss: 1.1176 - val_accuracy: 0.7048\n","Epoch 52/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4193 - accuracy: 0.9799 - val_loss: 1.0335 - val_accuracy: 0.7285\n","Epoch 53/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4027 - accuracy: 0.9907 - val_loss: 1.0479 - val_accuracy: 0.7296\n","Epoch 54/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4036 - accuracy: 0.9904 - val_loss: 1.0329 - val_accuracy: 0.7353\n","Epoch 55/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4019 - accuracy: 0.9898 - val_loss: 1.0438 - val_accuracy: 0.7376\n","Epoch 56/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3970 - accuracy: 0.9921 - val_loss: 1.0485 - val_accuracy: 0.7421\n","Epoch 57/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3995 - accuracy: 0.9907 - val_loss: 1.0445 - val_accuracy: 0.7353\n","Epoch 58/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3933 - accuracy: 0.9926 - val_loss: 1.0531 - val_accuracy: 0.7319\n","Epoch 59/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3915 - accuracy: 0.9946 - val_loss: 1.0505 - val_accuracy: 0.7342\n","Epoch 60/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3910 - accuracy: 0.9938 - val_loss: 1.0528 - val_accuracy: 0.7353\n","Epoch 61/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3897 - accuracy: 0.9909 - val_loss: 1.0775 - val_accuracy: 0.7330\n","Epoch 62/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3942 - accuracy: 0.9901 - val_loss: 1.0695 - val_accuracy: 0.7285\n","Epoch 63/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3872 - accuracy: 0.9935 - val_loss: 1.0666 - val_accuracy: 0.7330\n","Epoch 64/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3853 - accuracy: 0.9932 - val_loss: 1.0808 - val_accuracy: 0.7308\n","Epoch 65/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3913 - accuracy: 0.9904 - val_loss: 1.1013 - val_accuracy: 0.7206\n","Epoch 66/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3849 - accuracy: 0.9926 - val_loss: 1.0839 - val_accuracy: 0.7342\n","Epoch 67/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3830 - accuracy: 0.9943 - val_loss: 1.0942 - val_accuracy: 0.7274\n","Epoch 68/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3823 - accuracy: 0.9938 - val_loss: 1.0822 - val_accuracy: 0.7285\n","Epoch 69/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3815 - accuracy: 0.9918 - val_loss: 1.0937 - val_accuracy: 0.7330\n","Epoch 70/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3810 - accuracy: 0.9935 - val_loss: 1.0998 - val_accuracy: 0.7217\n","Epoch 71/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3797 - accuracy: 0.9941 - val_loss: 1.1185 - val_accuracy: 0.7285\n","Epoch 72/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3742 - accuracy: 0.9949 - val_loss: 1.1011 - val_accuracy: 0.7296\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3717 - accuracy: 0.9952 - val_loss: 1.1141 - val_accuracy: 0.7206\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3698 - accuracy: 0.9966 - val_loss: 1.1045 - val_accuracy: 0.7274\n","Epoch 75/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3669 - accuracy: 0.9969 - val_loss: 1.1074 - val_accuracy: 0.7319\n","Epoch 76/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3662 - accuracy: 0.9966 - val_loss: 1.1079 - val_accuracy: 0.7308\n","Epoch 77/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3657 - accuracy: 0.9966 - val_loss: 1.1128 - val_accuracy: 0.7376\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3652 - accuracy: 0.9975 - val_loss: 1.1206 - val_accuracy: 0.7229\n","Epoch 79/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3640 - accuracy: 0.9969 - val_loss: 1.1247 - val_accuracy: 0.7274\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3643 - accuracy: 0.9966 - val_loss: 1.1348 - val_accuracy: 0.7240\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3627 - accuracy: 0.9975 - val_loss: 1.1263 - val_accuracy: 0.7251\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3616 - accuracy: 0.9958 - val_loss: 1.1259 - val_accuracy: 0.7308\n","Epoch 83/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3632 - accuracy: 0.9966 - val_loss: 1.1266 - val_accuracy: 0.7262\n","Epoch 84/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3571 - accuracy: 0.9975 - val_loss: 1.1390 - val_accuracy: 0.7274\n","Epoch 85/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3554 - accuracy: 0.9983 - val_loss: 1.1400 - val_accuracy: 0.7319\n","Epoch 86/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3586 - accuracy: 0.9958 - val_loss: 1.2454 - val_accuracy: 0.7048\n","Epoch 87/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3649 - accuracy: 0.9932 - val_loss: 1.1604 - val_accuracy: 0.7285\n","Epoch 88/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3572 - accuracy: 0.9958 - val_loss: 1.1885 - val_accuracy: 0.7172\n","Epoch 89/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3565 - accuracy: 0.9969 - val_loss: 1.1531 - val_accuracy: 0.7240\n","Epoch 90/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3495 - accuracy: 0.9992 - val_loss: 1.1602 - val_accuracy: 0.7217\n","Epoch 91/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3510 - accuracy: 0.9977 - val_loss: 1.1656 - val_accuracy: 0.7240\n","Epoch 92/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3511 - accuracy: 0.9963 - val_loss: 1.1886 - val_accuracy: 0.7172\n","Epoch 93/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3495 - accuracy: 0.9989 - val_loss: 1.1767 - val_accuracy: 0.7274\n","Epoch 94/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3459 - accuracy: 0.9992 - val_loss: 1.1791 - val_accuracy: 0.7262\n","Epoch 95/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3451 - accuracy: 0.9992 - val_loss: 1.1686 - val_accuracy: 0.7251\n","Epoch 96/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3435 - accuracy: 0.9986 - val_loss: 1.1744 - val_accuracy: 0.7274\n","Epoch 97/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3432 - accuracy: 0.9992 - val_loss: 1.1778 - val_accuracy: 0.7285\n","Epoch 98/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3426 - accuracy: 0.9997 - val_loss: 1.1796 - val_accuracy: 0.7240\n","Epoch 99/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3425 - accuracy: 0.9986 - val_loss: 1.1990 - val_accuracy: 0.7217\n","Epoch 100/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3406 - accuracy: 0.9989 - val_loss: 1.1962 - val_accuracy: 0.7217\n","{'loss': [0.6141259074211121, 0.5865402817726135, 0.5835935473442078, 0.5675532817840576, 0.5616400241851807, 0.5624881982803345, 0.550645112991333, 0.5427457094192505, 0.5365670323371887, 0.5328094959259033, 0.5321369171142578, 0.5236220955848694, 0.5208438634872437, 0.517882764339447, 0.5159511566162109, 0.5097008347511292, 0.5014908909797668, 0.4982127845287323, 0.49588915705680847, 0.4953426718711853, 0.4899784326553345, 0.48946961760520935, 0.48830822110176086, 0.47826001048088074, 0.4783572554588318, 0.47429922223091125, 0.4707520306110382, 0.46559378504753113, 0.46354788541793823, 0.46149253845214844, 0.45965641736984253, 0.4571191966533661, 0.4540237784385681, 0.45042866468429565, 0.4476798176765442, 0.44656941294670105, 0.44121357798576355, 0.4381209909915924, 0.4490315914154053, 0.4339368939399719, 0.4318006932735443, 0.42630133032798767, 0.4299990236759186, 0.427168607711792, 0.4247679114341736, 0.4173787236213684, 0.41443222761154175, 0.4127452075481415, 0.4129275679588318, 0.4088055193424225, 0.4170312285423279, 0.4193093776702881, 0.4027062654495239, 0.4035623371601105, 0.4019433557987213, 0.3970368802547455, 0.3994829058647156, 0.39331620931625366, 0.39153939485549927, 0.39096471667289734, 0.3897131681442261, 0.39420589804649353, 0.3872009813785553, 0.38534584641456604, 0.3912852704524994, 0.3849405348300934, 0.3830399215221405, 0.38232195377349854, 0.3815377652645111, 0.38100898265838623, 0.37969455122947693, 0.3742265999317169, 0.37165236473083496, 0.36981257796287537, 0.3668980896472931, 0.3662402927875519, 0.36571457982063293, 0.36518052220344543, 0.3640138506889343, 0.3642570972442627, 0.36267900466918945, 0.36162057518959045, 0.36321279406547546, 0.3570646345615387, 0.3554157018661499, 0.35864827036857605, 0.36492958664894104, 0.35721227526664734, 0.3564949035644531, 0.34947070479393005, 0.35104385018348694, 0.3511180877685547, 0.3494824469089508, 0.345866858959198, 0.34506237506866455, 0.34349170327186584, 0.34317827224731445, 0.34263166785240173, 0.3424701392650604, 0.3405615985393524], 'accuracy': [0.897849440574646, 0.912563681602478, 0.9131296277046204, 0.9241652488708496, 0.9244481921195984, 0.9255800843238831, 0.9323712587356567, 0.9352009296417236, 0.9422750473022461, 0.9473684430122375, 0.943406879901886, 0.9516128897666931, 0.9459536075592041, 0.9501980543136597, 0.9513299465179443, 0.95444256067276, 0.9578381180763245, 0.9598188996315002, 0.9615166783332825, 0.9595359563827515, 0.963780403137207, 0.9603848457336426, 0.9632145166397095, 0.9691567420959473, 0.9666100740432739, 0.9700056314468384, 0.9702886343002319, 0.9725523591041565, 0.9745330810546875, 0.9736841917037964, 0.9722693562507629, 0.9731183052062988, 0.9765138626098633, 0.9801924228668213, 0.9784946441650391, 0.9790605306625366, 0.9799094796180725, 0.9824561476707458, 0.9753820300102234, 0.9821732044219971, 0.983305037021637, 0.9841539263725281, 0.9841539263725281, 0.9807583689689636, 0.9852858185768127, 0.9886813759803772, 0.9886813759803772, 0.9895302653312683, 0.9895302653312683, 0.9920769929885864, 0.9824561476707458, 0.9799094796180725, 0.990662157535553, 0.9903791546821594, 0.9898132681846619, 0.9920769929885864, 0.990662157535553, 0.992642879486084, 0.9946236610412598, 0.9937747716903687, 0.9909451007843018, 0.9900962114334106, 0.9934917688369751, 0.9932088255882263, 0.9903791546821594, 0.992642879486084, 0.994340717792511, 0.9937747716903687, 0.9917939901351929, 0.9934917688369751, 0.9940577149391174, 0.9949066042900085, 0.9951896071434021, 0.9966044425964355, 0.9968873858451843, 0.9966044425964355, 0.9966044425964355, 0.9974533319473267, 0.9968873858451843, 0.9966044425964355, 0.9974533319473267, 0.9957554936408997, 0.9966044425964355, 0.9974533319473267, 0.9983022212982178, 0.9957554936408997, 0.9932088255882263, 0.9957554936408997, 0.9968873858451843, 0.9991511106491089, 0.9977362751960754, 0.996321439743042, 0.9988681674003601, 0.9991511106491089, 0.9991511106491089, 0.9985851645469666, 0.9991511106491089, 0.9997170567512512, 0.9985851645469666, 0.9988681674003601], 'val_loss': [1.073531985282898, 1.0690659284591675, 1.0736805200576782, 1.0696275234222412, 1.0754011869430542, 1.0692628622055054, 1.0659369230270386, 1.058850884437561, 1.0540730953216553, 1.051660418510437, 1.03042733669281, 1.0322747230529785, 1.0189892053604126, 0.9480826258659363, 0.9842918515205383, 0.9652220606803894, 0.9108070731163025, 0.9472559690475464, 0.8948190212249756, 0.9518632888793945, 0.874418318271637, 0.9133056402206421, 0.8715590238571167, 0.8723232746124268, 0.9331405162811279, 0.890045702457428, 0.8965194225311279, 0.9068121314048767, 0.9177674055099487, 0.9265367388725281, 0.9984073042869568, 0.9417259097099304, 0.9525489211082458, 0.955295205116272, 0.9581939578056335, 1.0023926496505737, 0.9696648120880127, 0.9982473850250244, 1.0203114748001099, 0.9883649349212646, 0.9913850426673889, 1.0036767721176147, 0.9969250559806824, 0.9998395442962646, 1.0031403303146362, 1.0157957077026367, 1.0104200839996338, 1.016913652420044, 1.0161058902740479, 1.022663950920105, 1.1175709962844849, 1.0334609746932983, 1.0478520393371582, 1.0328770875930786, 1.0437967777252197, 1.04851233959198, 1.0445078611373901, 1.0530500411987305, 1.050486445426941, 1.0527889728546143, 1.0775349140167236, 1.0695302486419678, 1.0665968656539917, 1.0807994604110718, 1.1013072729110718, 1.083923578262329, 1.0942293405532837, 1.0821722745895386, 1.0936812162399292, 1.0997596979141235, 1.1185237169265747, 1.101096272468567, 1.114113211631775, 1.1045080423355103, 1.10741126537323, 1.1079378128051758, 1.1128089427947998, 1.1206077337265015, 1.1246954202651978, 1.1347942352294922, 1.1262953281402588, 1.125941514968872, 1.126631259918213, 1.1389892101287842, 1.140015959739685, 1.2453843355178833, 1.160396933555603, 1.188480019569397, 1.153051495552063, 1.1601612567901611, 1.1656098365783691, 1.1885559558868408, 1.1767266988754272, 1.179050326347351, 1.1686259508132935, 1.1744201183319092, 1.177797794342041, 1.1796306371688843, 1.1989935636520386, 1.1962270736694336], 'val_accuracy': [0.5, 0.5033936500549316, 0.5022624731063843, 0.5045248866081238, 0.5045248866081238, 0.5056561231613159, 0.5056561231613159, 0.5113122463226318, 0.5147058963775635, 0.523755669593811, 0.5373303294181824, 0.5441176295280457, 0.5520362257957458, 0.6436651349067688, 0.6029411554336548, 0.622171938419342, 0.6900452375411987, 0.6549773812294006, 0.7104072570800781, 0.6674208045005798, 0.7285068035125732, 0.7013574838638306, 0.733031690120697, 0.7420814633369446, 0.709276020526886, 0.75, 0.7420814633369446, 0.7545248866081238, 0.7511312365531921, 0.7466063499450684, 0.720588207244873, 0.7466063499450684, 0.7477375268936157, 0.7443438768386841, 0.7398189902305603, 0.7251130938529968, 0.75, 0.7296379804611206, 0.7352941036224365, 0.7319004535675049, 0.7443438768386841, 0.7217194437980652, 0.7352941036224365, 0.7398189902305603, 0.7296379804611206, 0.733031690120697, 0.7352941036224365, 0.7420814633369446, 0.7375565767288208, 0.7420814633369446, 0.7047511339187622, 0.7285068035125732, 0.7296379804611206, 0.7352941036224365, 0.7375565767288208, 0.7420814633369446, 0.7352941036224365, 0.7319004535675049, 0.7341628670692444, 0.7352941036224365, 0.733031690120697, 0.7285068035125732, 0.733031690120697, 0.7307692170143127, 0.720588207244873, 0.7341628670692444, 0.7273755669593811, 0.7285068035125732, 0.733031690120697, 0.7217194437980652, 0.7285068035125732, 0.7296379804611206, 0.720588207244873, 0.7273755669593811, 0.7319004535675049, 0.7307692170143127, 0.7375565767288208, 0.7228506803512573, 0.7273755669593811, 0.7239819169044495, 0.7251130938529968, 0.7307692170143127, 0.726244330406189, 0.7273755669593811, 0.7319004535675049, 0.7047511339187622, 0.7285068035125732, 0.7171945571899414, 0.7239819169044495, 0.7217194437980652, 0.7239819169044495, 0.7171945571899414, 0.7273755669593811, 0.726244330406189, 0.7251130938529968, 0.7273755669593811, 0.7285068035125732, 0.7239819169044495, 0.7217194437980652, 0.7217194437980652]}\n","45/45 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 5s 29ms/step - loss: 0.6363 - accuracy: 0.8871 - val_loss: 1.0797 - val_accuracy: 0.4938\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.6029 - accuracy: 0.9062"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 1s 18ms/step - loss: 0.6118 - accuracy: 0.8997 - val_loss: 1.0763 - val_accuracy: 0.4959\n","Epoch 3/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6203 - accuracy: 0.8871 - val_loss: 1.0773 - val_accuracy: 0.4969\n","Epoch 4/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6050 - accuracy: 0.8961 - val_loss: 1.0817 - val_accuracy: 0.4959\n","Epoch 5/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5801 - accuracy: 0.9160 - val_loss: 1.0774 - val_accuracy: 0.4990\n","Epoch 6/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5732 - accuracy: 0.9214 - val_loss: 1.0731 - val_accuracy: 0.5031\n","Epoch 7/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5659 - accuracy: 0.9243 - val_loss: 1.0776 - val_accuracy: 0.5031\n","Epoch 8/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5619 - accuracy: 0.9264 - val_loss: 1.0582 - val_accuracy: 0.5176\n","Epoch 9/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5787 - accuracy: 0.9140 - val_loss: 1.0534 - val_accuracy: 0.5217\n","Epoch 10/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5503 - accuracy: 0.9357 - val_loss: 1.0453 - val_accuracy: 0.5269\n","Epoch 11/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5455 - accuracy: 0.9385 - val_loss: 1.0209 - val_accuracy: 0.5579\n","Epoch 12/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5500 - accuracy: 0.9305 - val_loss: 1.0069 - val_accuracy: 0.5816\n","Epoch 13/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5454 - accuracy: 0.9339 - val_loss: 1.0282 - val_accuracy: 0.5661\n","Epoch 14/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5325 - accuracy: 0.9447 - val_loss: 0.9750 - val_accuracy: 0.6343\n","Epoch 15/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5361 - accuracy: 0.9395 - val_loss: 0.9946 - val_accuracy: 0.6147\n","Epoch 16/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5259 - accuracy: 0.9450 - val_loss: 0.9863 - val_accuracy: 0.6343\n","Epoch 17/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5185 - accuracy: 0.9543 - val_loss: 0.9541 - val_accuracy: 0.6890\n","Epoch 18/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5210 - accuracy: 0.9442 - val_loss: 0.9892 - val_accuracy: 0.6612\n","Epoch 19/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5255 - accuracy: 0.9424 - val_loss: 1.0093 - val_accuracy: 0.6643\n","Epoch 20/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5143 - accuracy: 0.9532 - val_loss: 0.9856 - val_accuracy: 0.6880\n","Epoch 21/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5081 - accuracy: 0.9517 - val_loss: 0.9734 - val_accuracy: 0.7066\n","Epoch 22/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5008 - accuracy: 0.9561 - val_loss: 1.0050 - val_accuracy: 0.6983\n","Epoch 23/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4988 - accuracy: 0.9605 - val_loss: 1.0227 - val_accuracy: 0.7004\n","Epoch 24/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5000 - accuracy: 0.9556 - val_loss: 1.0870 - val_accuracy: 0.6746\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5145 - accuracy: 0.9388 - val_loss: 1.0731 - val_accuracy: 0.7045\n","Epoch 26/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5056 - accuracy: 0.9496 - val_loss: 1.0671 - val_accuracy: 0.6952\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4946 - accuracy: 0.9579 - val_loss: 1.0909 - val_accuracy: 0.6952\n","Epoch 28/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4842 - accuracy: 0.9612 - val_loss: 1.1245 - val_accuracy: 0.6870\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4817 - accuracy: 0.9646 - val_loss: 1.0910 - val_accuracy: 0.7045\n","Epoch 30/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4827 - accuracy: 0.9618 - val_loss: 1.0939 - val_accuracy: 0.7149\n","Epoch 31/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4885 - accuracy: 0.9550 - val_loss: 1.1596 - val_accuracy: 0.6860\n","Epoch 32/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4797 - accuracy: 0.9623 - val_loss: 1.1005 - val_accuracy: 0.7066\n","Epoch 33/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4713 - accuracy: 0.9677 - val_loss: 1.1241 - val_accuracy: 0.7025\n","Epoch 34/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4719 - accuracy: 0.9649 - val_loss: 1.1396 - val_accuracy: 0.6963\n","Epoch 35/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4683 - accuracy: 0.9726 - val_loss: 1.1309 - val_accuracy: 0.7004\n","Epoch 36/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4645 - accuracy: 0.9687 - val_loss: 1.1235 - val_accuracy: 0.7118\n","Epoch 37/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4600 - accuracy: 0.9736 - val_loss: 1.1324 - val_accuracy: 0.7097\n","Epoch 38/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4547 - accuracy: 0.9747 - val_loss: 1.1372 - val_accuracy: 0.7107\n","Epoch 39/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4537 - accuracy: 0.9739 - val_loss: 1.1396 - val_accuracy: 0.7014\n","Epoch 40/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4529 - accuracy: 0.9757 - val_loss: 1.1975 - val_accuracy: 0.6818\n","Epoch 41/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4497 - accuracy: 0.9793 - val_loss: 1.1454 - val_accuracy: 0.7107\n","Epoch 42/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4513 - accuracy: 0.9708 - val_loss: 1.1733 - val_accuracy: 0.6973\n","Epoch 43/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4494 - accuracy: 0.9739 - val_loss: 1.1617 - val_accuracy: 0.7087\n","Epoch 44/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4400 - accuracy: 0.9804 - val_loss: 1.1727 - val_accuracy: 0.6994\n","Epoch 45/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4528 - accuracy: 0.9687 - val_loss: 1.1688 - val_accuracy: 0.7066\n","Epoch 46/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4447 - accuracy: 0.9749 - val_loss: 1.1919 - val_accuracy: 0.6942\n","Epoch 47/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4377 - accuracy: 0.9796 - val_loss: 1.1801 - val_accuracy: 0.7076\n","Epoch 48/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4452 - accuracy: 0.9726 - val_loss: 1.2876 - val_accuracy: 0.6890\n","Epoch 49/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4551 - accuracy: 0.9656 - val_loss: 1.2637 - val_accuracy: 0.6674\n","Epoch 50/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4361 - accuracy: 0.9767 - val_loss: 1.2041 - val_accuracy: 0.6829\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4259 - accuracy: 0.9827 - val_loss: 1.1804 - val_accuracy: 0.7087\n","Epoch 52/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4235 - accuracy: 0.9855 - val_loss: 1.1839 - val_accuracy: 0.7107\n","Epoch 53/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4246 - accuracy: 0.9832 - val_loss: 1.2272 - val_accuracy: 0.6890\n","Epoch 54/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4220 - accuracy: 0.9837 - val_loss: 1.2263 - val_accuracy: 0.7025\n","Epoch 55/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4223 - accuracy: 0.9824 - val_loss: 1.2134 - val_accuracy: 0.6983\n","Epoch 56/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4197 - accuracy: 0.9858 - val_loss: 1.2059 - val_accuracy: 0.7066\n","Epoch 57/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4119 - accuracy: 0.9881 - val_loss: 1.2384 - val_accuracy: 0.6829\n","Epoch 58/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4140 - accuracy: 0.9860 - val_loss: 1.2110 - val_accuracy: 0.7056\n","Epoch 59/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4131 - accuracy: 0.9850 - val_loss: 1.2422 - val_accuracy: 0.6890\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4109 - accuracy: 0.9860 - val_loss: 1.2588 - val_accuracy: 0.6818\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4080 - accuracy: 0.9889 - val_loss: 1.2276 - val_accuracy: 0.7045\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4067 - accuracy: 0.9873 - val_loss: 1.2929 - val_accuracy: 0.6746\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4052 - accuracy: 0.9886 - val_loss: 1.2381 - val_accuracy: 0.7035\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4079 - accuracy: 0.9863 - val_loss: 1.2388 - val_accuracy: 0.7035\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4128 - accuracy: 0.9827 - val_loss: 1.2397 - val_accuracy: 0.7056\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4010 - accuracy: 0.9897 - val_loss: 1.2463 - val_accuracy: 0.7107\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3970 - accuracy: 0.9917 - val_loss: 1.2454 - val_accuracy: 0.7118\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3954 - accuracy: 0.9920 - val_loss: 1.2569 - val_accuracy: 0.6983\n","Epoch 69/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3930 - accuracy: 0.9904 - val_loss: 1.2631 - val_accuracy: 0.6983\n","Epoch 70/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3908 - accuracy: 0.9928 - val_loss: 1.2597 - val_accuracy: 0.7045\n","Epoch 71/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3912 - accuracy: 0.9904 - val_loss: 1.2716 - val_accuracy: 0.7045\n","Epoch 72/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3914 - accuracy: 0.9902 - val_loss: 1.2974 - val_accuracy: 0.6921\n","Epoch 73/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3945 - accuracy: 0.9876 - val_loss: 1.2690 - val_accuracy: 0.7066\n","Epoch 74/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3866 - accuracy: 0.9907 - val_loss: 1.2735 - val_accuracy: 0.7025\n","Epoch 75/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3839 - accuracy: 0.9917 - val_loss: 1.2948 - val_accuracy: 0.6880\n","Epoch 76/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3851 - accuracy: 0.9917 - val_loss: 1.2823 - val_accuracy: 0.7014\n","Epoch 77/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3788 - accuracy: 0.9943 - val_loss: 1.2869 - val_accuracy: 0.7066\n","Epoch 78/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3783 - accuracy: 0.9943 - val_loss: 1.2906 - val_accuracy: 0.7087\n","Epoch 79/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3767 - accuracy: 0.9946 - val_loss: 1.3460 - val_accuracy: 0.6767\n","Epoch 80/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3808 - accuracy: 0.9915 - val_loss: 1.3260 - val_accuracy: 0.7004\n","Epoch 81/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3762 - accuracy: 0.9928 - val_loss: 1.3876 - val_accuracy: 0.6901\n","Epoch 82/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3884 - accuracy: 0.9860 - val_loss: 1.3086 - val_accuracy: 0.7076\n","Epoch 83/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3741 - accuracy: 0.9938 - val_loss: 1.3608 - val_accuracy: 0.6715\n","Epoch 84/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3748 - accuracy: 0.9935 - val_loss: 1.3232 - val_accuracy: 0.7035\n","Epoch 85/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3701 - accuracy: 0.9946 - val_loss: 1.3764 - val_accuracy: 0.6746\n","Epoch 86/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3724 - accuracy: 0.9941 - val_loss: 1.3306 - val_accuracy: 0.7066\n","Epoch 87/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3750 - accuracy: 0.9920 - val_loss: 1.3444 - val_accuracy: 0.6963\n","Epoch 88/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3744 - accuracy: 0.9897 - val_loss: 1.3528 - val_accuracy: 0.6901\n","Epoch 89/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3766 - accuracy: 0.9889 - val_loss: 1.3414 - val_accuracy: 0.7035\n","Epoch 90/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3647 - accuracy: 0.9953 - val_loss: 1.3557 - val_accuracy: 0.6932\n","Epoch 91/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3641 - accuracy: 0.9951 - val_loss: 1.3453 - val_accuracy: 0.6994\n","Epoch 92/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3632 - accuracy: 0.9959 - val_loss: 1.3589 - val_accuracy: 0.6973\n","Epoch 93/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3729 - accuracy: 0.9912 - val_loss: 1.4030 - val_accuracy: 0.6736\n","Epoch 94/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3610 - accuracy: 0.9959 - val_loss: 1.3750 - val_accuracy: 0.6911\n","Epoch 95/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3596 - accuracy: 0.9966 - val_loss: 1.3694 - val_accuracy: 0.7025\n","Epoch 96/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3601 - accuracy: 0.9966 - val_loss: 1.3646 - val_accuracy: 0.7056\n","Epoch 97/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3588 - accuracy: 0.9953 - val_loss: 1.3908 - val_accuracy: 0.6911\n","Epoch 98/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3578 - accuracy: 0.9964 - val_loss: 1.3714 - val_accuracy: 0.7004\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3539 - accuracy: 0.9984 - val_loss: 1.3996 - val_accuracy: 0.6911\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3561 - accuracy: 0.9966 - val_loss: 1.4068 - val_accuracy: 0.6932\n","{'loss': [0.6362559795379639, 0.6118308901786804, 0.6203129887580872, 0.6049634218215942, 0.5801270008087158, 0.5731939673423767, 0.5659166574478149, 0.5619308352470398, 0.5786933302879333, 0.5503304600715637, 0.5454661846160889, 0.5499728322029114, 0.5453805923461914, 0.5324880480766296, 0.5360575914382935, 0.5259186625480652, 0.5184615850448608, 0.5210378766059875, 0.525505542755127, 0.5142852067947388, 0.5080810785293579, 0.500781774520874, 0.49877509474754333, 0.5000130534172058, 0.514494776725769, 0.505606472492218, 0.4945925176143646, 0.48415982723236084, 0.48172691464424133, 0.48273345828056335, 0.4884538948535919, 0.4796622097492218, 0.47133055329322815, 0.4719051122665405, 0.4683043360710144, 0.46451759338378906, 0.4600302577018738, 0.45473045110702515, 0.45368674397468567, 0.4529157876968384, 0.44973185658454895, 0.45131170749664307, 0.44937703013420105, 0.439981609582901, 0.45277777314186096, 0.4447113871574402, 0.4376579523086548, 0.44524356722831726, 0.4550517201423645, 0.43606215715408325, 0.4259399175643921, 0.42349857091903687, 0.4246447682380676, 0.42203468084335327, 0.4223353862762451, 0.41970524191856384, 0.41193780303001404, 0.4140177071094513, 0.41306835412979126, 0.41093477606773376, 0.4079637825489044, 0.4067299962043762, 0.4051927328109741, 0.40790849924087524, 0.412802517414093, 0.40095338225364685, 0.3969651162624359, 0.3953859806060791, 0.3929792642593384, 0.3907683193683624, 0.39118492603302, 0.39135977625846863, 0.39449241757392883, 0.3866271674633026, 0.3838666081428528, 0.3851076364517212, 0.3787821829319, 0.37834763526916504, 0.37668025493621826, 0.38079705834388733, 0.37624526023864746, 0.3884311616420746, 0.37405577301979065, 0.3748326003551483, 0.370145708322525, 0.3724157512187958, 0.37504926323890686, 0.3743719458580017, 0.3766205906867981, 0.36465078592300415, 0.36412546038627625, 0.36321207880973816, 0.37287360429763794, 0.36098068952560425, 0.3595988154411316, 0.3601401448249817, 0.35884588956832886, 0.3578154742717743, 0.35389047861099243, 0.3561176359653473], 'accuracy': [0.8870801329612732, 0.8997415900230408, 0.8870801329612732, 0.896124005317688, 0.9160206913948059, 0.9214470386505127, 0.9242894053459167, 0.9263566136360168, 0.9139534831047058, 0.9356589317321777, 0.9385012984275818, 0.9304909706115723, 0.933850109577179, 0.9447028636932373, 0.9395349025726318, 0.9449612498283386, 0.9542635679244995, 0.9441860318183899, 0.9423772692680359, 0.9532299637794495, 0.9516795873641968, 0.9560723304748535, 0.960465133190155, 0.9555555582046509, 0.9387596845626831, 0.9496123790740967, 0.9578811526298523, 0.961240291595459, 0.9645994901657104, 0.9617571234703064, 0.9550387859344482, 0.962273895740509, 0.9677002429962158, 0.9648578763008118, 0.97260981798172, 0.9687338471412659, 0.97364342212677, 0.9746770262718201, 0.9739018082618713, 0.9757105708122253, 0.9793281555175781, 0.970801055431366, 0.9739018082618713, 0.9803617596626282, 0.9687338471412659, 0.9749354124069214, 0.9795865416526794, 0.97260981798172, 0.9656330943107605, 0.9767441749572754, 0.9826873540878296, 0.9855297207832336, 0.9832041263580322, 0.9837209582328796, 0.9824289679527283, 0.985788106918335, 0.9881137013435364, 0.9860464930534363, 0.985012948513031, 0.9860464930534363, 0.9888888597488403, 0.9873384833335876, 0.988630473613739, 0.9863049387931824, 0.9826873540878296, 0.9896640777587891, 0.9917312860488892, 0.9919896721839905, 0.9904392957687378, 0.9927648305892944, 0.9904392957687378, 0.9901808500289917, 0.987596869468689, 0.9906976819038391, 0.9917312860488892, 0.9917312860488892, 0.9943152666091919, 0.9943152666091919, 0.9945736527442932, 0.9914728403091431, 0.9927648305892944, 0.9860464930534363, 0.9937984347343445, 0.9935400485992432, 0.9945736527442932, 0.9940568208694458, 0.9919896721839905, 0.9896640777587891, 0.9888888597488403, 0.9953488111495972, 0.9950904250144958, 0.9958656430244446, 0.9912144541740417, 0.9958656430244446, 0.9966408014297485, 0.9966408014297485, 0.9953488111495972, 0.9963824152946472, 0.9984496235847473, 0.9966408014297485], 'val_loss': [1.0796908140182495, 1.0763282775878906, 1.0773156881332397, 1.0817166566848755, 1.0774314403533936, 1.0730880498886108, 1.0775763988494873, 1.0581512451171875, 1.053415060043335, 1.0453039407730103, 1.0209015607833862, 1.006888747215271, 1.028185248374939, 0.9750136733055115, 0.9946417808532715, 0.9863443970680237, 0.9540533423423767, 0.9892352223396301, 1.0092825889587402, 0.9856112003326416, 0.9733855724334717, 1.0050171613693237, 1.0226573944091797, 1.087020754814148, 1.0731315612792969, 1.0671448707580566, 1.090903878211975, 1.1245313882827759, 1.0910305976867676, 1.0939488410949707, 1.1595685482025146, 1.100494384765625, 1.1241259574890137, 1.1395530700683594, 1.1309176683425903, 1.1235318183898926, 1.13242506980896, 1.1371756792068481, 1.1395946741104126, 1.1974668502807617, 1.1453726291656494, 1.173272967338562, 1.1616718769073486, 1.1727015972137451, 1.1688048839569092, 1.1919001340866089, 1.180124282836914, 1.28755521774292, 1.2636747360229492, 1.2040807008743286, 1.1803898811340332, 1.1838799715042114, 1.2271815538406372, 1.226284146308899, 1.2133558988571167, 1.205906629562378, 1.2383787631988525, 1.2109849452972412, 1.2422354221343994, 1.2588143348693848, 1.227647304534912, 1.2928731441497803, 1.2380530834197998, 1.238757610321045, 1.239723801612854, 1.2463096380233765, 1.2454200983047485, 1.25689697265625, 1.2631174325942993, 1.2597391605377197, 1.2715880870819092, 1.2973647117614746, 1.2689722776412964, 1.2734795808792114, 1.2948113679885864, 1.282331943511963, 1.286937952041626, 1.290623664855957, 1.345990538597107, 1.326019525527954, 1.3876402378082275, 1.308626413345337, 1.360770344734192, 1.3232223987579346, 1.3763679265975952, 1.330613613128662, 1.3443572521209717, 1.3528203964233398, 1.341414451599121, 1.3556641340255737, 1.3453361988067627, 1.358880639076233, 1.4030330181121826, 1.3749545812606812, 1.3694310188293457, 1.3646215200424194, 1.3907954692840576, 1.3713971376419067, 1.3996412754058838, 1.4067802429199219], 'val_accuracy': [0.49380165338516235, 0.4958677589893341, 0.4969008266925812, 0.4958677589893341, 0.49896693229675293, 0.5030992031097412, 0.5030992031097412, 0.5175619721412659, 0.5216942429542542, 0.5268595218658447, 0.557851254940033, 0.5816115736961365, 0.56611567735672, 0.6342975497245789, 0.6146694421768188, 0.6342975497245789, 0.6890496015548706, 0.6611570119857788, 0.66425621509552, 0.6880165338516235, 0.7066115736961365, 0.6983470916748047, 0.7004132270812988, 0.6745867729187012, 0.7045454382896423, 0.6952479481697083, 0.6952479481697083, 0.6869834661483765, 0.7045454382896423, 0.7148760557174683, 0.6859503984451294, 0.7066115736961365, 0.702479362487793, 0.6962810158729553, 0.7004132270812988, 0.711776852607727, 0.7097107172012329, 0.71074378490448, 0.7014462947845459, 0.6818181872367859, 0.71074378490448, 0.6973140239715576, 0.7086777091026306, 0.6993801593780518, 0.7066115736961365, 0.6942148804664612, 0.7076446413993835, 0.6890496015548706, 0.6673553586006165, 0.682851254940033, 0.7086777091026306, 0.71074378490448, 0.6890496015548706, 0.702479362487793, 0.6983470916748047, 0.7066115736961365, 0.682851254940033, 0.7055785059928894, 0.6890496015548706, 0.6818181872367859, 0.7045454382896423, 0.6745867729187012, 0.7035123705863953, 0.7035123705863953, 0.7055785059928894, 0.71074378490448, 0.711776852607727, 0.6983470916748047, 0.6983470916748047, 0.7045454382896423, 0.7045454382896423, 0.692148745059967, 0.7066115736961365, 0.702479362487793, 0.6880165338516235, 0.7014462947845459, 0.7066115736961365, 0.7086777091026306, 0.6766529083251953, 0.7004132270812988, 0.6900826692581177, 0.7076446413993835, 0.6714876294136047, 0.7035123705863953, 0.6745867729187012, 0.7066115736961365, 0.6962810158729553, 0.6900826692581177, 0.7035123705863953, 0.6931818127632141, 0.6993801593780518, 0.6973140239715576, 0.6735537052154541, 0.69111567735672, 0.702479362487793, 0.7055785059928894, 0.69111567735672, 0.7004132270812988, 0.69111567735672, 0.6931818127632141]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 27ms/step - loss: 0.4360 - accuracy: 0.9596 - val_loss: 1.0867 - val_accuracy: 0.4860\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.4310 - accuracy: 0.9688"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 1s 20ms/step - loss: 0.4081 - accuracy: 0.9723 - val_loss: 1.0841 - val_accuracy: 0.4881\n","Epoch 3/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4046 - accuracy: 0.9717 - val_loss: 1.0880 - val_accuracy: 0.4881\n","Epoch 4/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3978 - accuracy: 0.9755 - val_loss: 1.0937 - val_accuracy: 0.4892\n","Epoch 5/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3853 - accuracy: 0.9833 - val_loss: 1.0880 - val_accuracy: 0.4914\n","Epoch 6/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3810 - accuracy: 0.9846 - val_loss: 1.0858 - val_accuracy: 0.4957\n","Epoch 7/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3746 - accuracy: 0.9895 - val_loss: 1.0782 - val_accuracy: 0.5022\n","Epoch 8/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3752 - accuracy: 0.9876 - val_loss: 1.0777 - val_accuracy: 0.5054\n","Epoch 9/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3714 - accuracy: 0.9900 - val_loss: 1.0789 - val_accuracy: 0.5108\n","Epoch 10/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3774 - accuracy: 0.9873 - val_loss: 1.0375 - val_accuracy: 0.5334\n","Epoch 11/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3698 - accuracy: 0.9881 - val_loss: 1.0466 - val_accuracy: 0.5388\n","Epoch 12/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3633 - accuracy: 0.9919 - val_loss: 1.0411 - val_accuracy: 0.5463\n","Epoch 13/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3633 - accuracy: 0.9949 - val_loss: 1.0350 - val_accuracy: 0.5625\n","Epoch 14/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3640 - accuracy: 0.9922 - val_loss: 0.9380 - val_accuracy: 0.6272\n","Epoch 15/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3585 - accuracy: 0.9941 - val_loss: 0.9546 - val_accuracy: 0.6261\n","Epoch 16/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3587 - accuracy: 0.9954 - val_loss: 0.8602 - val_accuracy: 0.7037\n","Epoch 17/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3559 - accuracy: 0.9957 - val_loss: 0.8488 - val_accuracy: 0.7177\n","Epoch 18/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3581 - accuracy: 0.9933 - val_loss: 0.7947 - val_accuracy: 0.7856\n","Epoch 19/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3544 - accuracy: 0.9938 - val_loss: 0.8351 - val_accuracy: 0.7489\n","Epoch 20/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3520 - accuracy: 0.9954 - val_loss: 0.8247 - val_accuracy: 0.7759\n","Epoch 21/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3537 - accuracy: 0.9954 - val_loss: 0.7912 - val_accuracy: 0.7942\n","Epoch 22/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3523 - accuracy: 0.9938 - val_loss: 0.8529 - val_accuracy: 0.7748\n","Epoch 23/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3544 - accuracy: 0.9946 - val_loss: 0.8156 - val_accuracy: 0.8071\n","Epoch 24/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3470 - accuracy: 0.9957 - val_loss: 0.8855 - val_accuracy: 0.7802\n","Epoch 25/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3443 - accuracy: 0.9970 - val_loss: 0.8642 - val_accuracy: 0.7953\n","Epoch 26/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3427 - accuracy: 0.9970 - val_loss: 0.8644 - val_accuracy: 0.8006\n","Epoch 27/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3424 - accuracy: 0.9968 - val_loss: 0.8876 - val_accuracy: 0.8006\n","Epoch 28/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3399 - accuracy: 0.9978 - val_loss: 0.8897 - val_accuracy: 0.8028\n","Epoch 29/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3401 - accuracy: 0.9978 - val_loss: 0.8928 - val_accuracy: 0.8060\n","Epoch 30/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3400 - accuracy: 0.9978 - val_loss: 0.9100 - val_accuracy: 0.7963\n","Epoch 31/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3379 - accuracy: 0.9978 - val_loss: 0.9197 - val_accuracy: 0.8028\n","Epoch 32/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3496 - accuracy: 0.9916 - val_loss: 0.9319 - val_accuracy: 0.8006\n","Epoch 33/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3441 - accuracy: 0.9962 - val_loss: 0.9576 - val_accuracy: 0.7888\n","Epoch 34/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3349 - accuracy: 0.9989 - val_loss: 0.9650 - val_accuracy: 0.7888\n","Epoch 35/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3360 - accuracy: 0.9978 - val_loss: 0.9510 - val_accuracy: 0.7931\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3345 - accuracy: 0.9970 - val_loss: 0.9523 - val_accuracy: 0.7996\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3311 - accuracy: 0.9987 - val_loss: 0.9568 - val_accuracy: 0.7996\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3322 - accuracy: 0.9981 - val_loss: 0.9595 - val_accuracy: 0.7953\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3328 - accuracy: 0.9981 - val_loss: 0.9702 - val_accuracy: 0.7942\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3305 - accuracy: 0.9984 - val_loss: 0.9859 - val_accuracy: 0.7899\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3286 - accuracy: 0.9987 - val_loss: 0.9697 - val_accuracy: 0.7985\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3264 - accuracy: 0.9992 - val_loss: 0.9886 - val_accuracy: 0.7877\n","Epoch 43/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3264 - accuracy: 0.9984 - val_loss: 0.9685 - val_accuracy: 0.7942\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3258 - accuracy: 0.9987 - val_loss: 0.9915 - val_accuracy: 0.7877\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3254 - accuracy: 0.9995 - val_loss: 0.9941 - val_accuracy: 0.7888\n","Epoch 46/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3246 - accuracy: 0.9987 - val_loss: 1.0000 - val_accuracy: 0.7931\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3268 - accuracy: 0.9984 - val_loss: 0.9960 - val_accuracy: 0.7877\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3221 - accuracy: 0.9987 - val_loss: 0.9985 - val_accuracy: 0.7866\n","Epoch 49/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3230 - accuracy: 0.9995 - val_loss: 0.9998 - val_accuracy: 0.7856\n","Epoch 50/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3216 - accuracy: 0.9995 - val_loss: 0.9867 - val_accuracy: 0.7974\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3199 - accuracy: 0.9989 - val_loss: 0.9929 - val_accuracy: 0.7953\n","Epoch 52/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3182 - accuracy: 0.9995 - val_loss: 0.9916 - val_accuracy: 0.7942\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3176 - accuracy: 0.9995 - val_loss: 0.9928 - val_accuracy: 0.7909\n","Epoch 54/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3207 - accuracy: 0.9984 - val_loss: 0.9975 - val_accuracy: 0.7866\n","Epoch 55/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3203 - accuracy: 0.9989 - val_loss: 1.0070 - val_accuracy: 0.7866\n","Epoch 56/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3180 - accuracy: 0.9987 - val_loss: 1.0032 - val_accuracy: 0.7888\n","Epoch 57/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3171 - accuracy: 0.9995 - val_loss: 1.0274 - val_accuracy: 0.7845\n","Epoch 58/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3163 - accuracy: 0.9981 - val_loss: 1.0078 - val_accuracy: 0.7877\n","Epoch 59/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3145 - accuracy: 1.0000 - val_loss: 1.0393 - val_accuracy: 0.7780\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3153 - accuracy: 0.9987 - val_loss: 1.0133 - val_accuracy: 0.7909\n","Epoch 61/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3120 - accuracy: 0.9992 - val_loss: 1.0186 - val_accuracy: 0.7845\n","Epoch 62/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3123 - accuracy: 0.9995 - val_loss: 1.0265 - val_accuracy: 0.7866\n","Epoch 63/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3127 - accuracy: 0.9997 - val_loss: 1.0185 - val_accuracy: 0.7877\n","Epoch 64/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3139 - accuracy: 0.9992 - val_loss: 1.0395 - val_accuracy: 0.7802\n","Epoch 65/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3115 - accuracy: 1.0000 - val_loss: 1.0471 - val_accuracy: 0.7834\n","Epoch 66/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3087 - accuracy: 0.9997 - val_loss: 1.0275 - val_accuracy: 0.7909\n","Epoch 67/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3093 - accuracy: 0.9995 - val_loss: 1.0266 - val_accuracy: 0.7888\n","Epoch 68/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3078 - accuracy: 0.9997 - val_loss: 1.0399 - val_accuracy: 0.7834\n","Epoch 69/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3112 - accuracy: 0.9997 - val_loss: 1.0536 - val_accuracy: 0.7802\n","Epoch 70/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3072 - accuracy: 0.9995 - val_loss: 1.0357 - val_accuracy: 0.7812\n","Epoch 71/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3058 - accuracy: 0.9997 - val_loss: 1.0630 - val_accuracy: 0.7802\n","Epoch 72/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3036 - accuracy: 1.0000 - val_loss: 1.0371 - val_accuracy: 0.7899\n","Epoch 73/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3051 - accuracy: 0.9995 - val_loss: 1.0417 - val_accuracy: 0.7866\n","Epoch 74/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3073 - accuracy: 0.9987 - val_loss: 1.0648 - val_accuracy: 0.7769\n","Epoch 75/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3081 - accuracy: 0.9992 - val_loss: 1.0512 - val_accuracy: 0.7845\n","Epoch 76/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3041 - accuracy: 0.9995 - val_loss: 1.0860 - val_accuracy: 0.7812\n","Epoch 77/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3030 - accuracy: 0.9997 - val_loss: 1.0851 - val_accuracy: 0.7780\n","Epoch 78/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3086 - accuracy: 0.9981 - val_loss: 1.0865 - val_accuracy: 0.7802\n","Epoch 79/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3010 - accuracy: 0.9997 - val_loss: 1.0538 - val_accuracy: 0.7802\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3002 - accuracy: 0.9995 - val_loss: 1.0572 - val_accuracy: 0.7866\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2989 - accuracy: 0.9997 - val_loss: 1.0705 - val_accuracy: 0.7769\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2994 - accuracy: 0.9995 - val_loss: 1.0759 - val_accuracy: 0.7845\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2987 - accuracy: 1.0000 - val_loss: 1.0552 - val_accuracy: 0.7856\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2971 - accuracy: 0.9997 - val_loss: 1.0658 - val_accuracy: 0.7845\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2960 - accuracy: 1.0000 - val_loss: 1.0814 - val_accuracy: 0.7769\n","Epoch 86/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2960 - accuracy: 0.9997 - val_loss: 1.0677 - val_accuracy: 0.7823\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2947 - accuracy: 1.0000 - val_loss: 1.0678 - val_accuracy: 0.7823\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2942 - accuracy: 1.0000 - val_loss: 1.0703 - val_accuracy: 0.7834\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2934 - accuracy: 1.0000 - val_loss: 1.0675 - val_accuracy: 0.7759\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2926 - accuracy: 1.0000 - val_loss: 1.0701 - val_accuracy: 0.7780\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2937 - accuracy: 0.9997 - val_loss: 1.0852 - val_accuracy: 0.7791\n","Epoch 92/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2942 - accuracy: 1.0000 - val_loss: 1.0903 - val_accuracy: 0.7759\n","Epoch 93/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2942 - accuracy: 1.0000 - val_loss: 1.1319 - val_accuracy: 0.7694\n","Epoch 94/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2933 - accuracy: 1.0000 - val_loss: 1.1300 - val_accuracy: 0.7662\n","Epoch 95/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2918 - accuracy: 1.0000 - val_loss: 1.0791 - val_accuracy: 0.7780\n","Epoch 96/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2891 - accuracy: 1.0000 - val_loss: 1.0964 - val_accuracy: 0.7812\n","Epoch 97/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2887 - accuracy: 1.0000 - val_loss: 1.0840 - val_accuracy: 0.7823\n","Epoch 98/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2886 - accuracy: 0.9997 - val_loss: 1.0993 - val_accuracy: 0.7759\n","Epoch 99/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2880 - accuracy: 1.0000 - val_loss: 1.0832 - val_accuracy: 0.7802\n","Epoch 100/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2890 - accuracy: 1.0000 - val_loss: 1.0918 - val_accuracy: 0.7759\n","{'loss': [0.43602412939071655, 0.40809324383735657, 0.4045729339122772, 0.39784371852874756, 0.3852910101413727, 0.38102057576179504, 0.3746320903301239, 0.3752458691596985, 0.37144991755485535, 0.37741819024086, 0.3698427975177765, 0.3633281886577606, 0.3633028566837311, 0.364005982875824, 0.3585450053215027, 0.3586747646331787, 0.355861634016037, 0.35808542370796204, 0.3543962836265564, 0.35201767086982727, 0.3536820113658905, 0.35229799151420593, 0.35441234707832336, 0.3469898998737335, 0.34428977966308594, 0.3426683247089386, 0.3424301743507385, 0.3399117588996887, 0.340081125497818, 0.33997589349746704, 0.3378605544567108, 0.3495906591415405, 0.34412628412246704, 0.3348850607872009, 0.3360421359539032, 0.33449262380599976, 0.3310914635658264, 0.3321836292743683, 0.33279672265052795, 0.3305431306362152, 0.32856133580207825, 0.3264159560203552, 0.32636260986328125, 0.32582515478134155, 0.3253501355648041, 0.32462018728256226, 0.3267807066440582, 0.32209745049476624, 0.32302358746528625, 0.32164910435676575, 0.3199075162410736, 0.31817951798439026, 0.31760919094085693, 0.3207031488418579, 0.3203297555446625, 0.3180249333381653, 0.3171224296092987, 0.3163435161113739, 0.3145236670970917, 0.3153132200241089, 0.31203633546829224, 0.3123285472393036, 0.3127295970916748, 0.3138611316680908, 0.3115266263484955, 0.30872562527656555, 0.30933552980422974, 0.3078012764453888, 0.3111662268638611, 0.3071770966053009, 0.30578187108039856, 0.30361437797546387, 0.30511802434921265, 0.30734750628471375, 0.3080505430698395, 0.3041391670703888, 0.30295461416244507, 0.30857113003730774, 0.3010256886482239, 0.3002457320690155, 0.2988678812980652, 0.29941391944885254, 0.2987048327922821, 0.2971026301383972, 0.29600560665130615, 0.2959960997104645, 0.2947363555431366, 0.29416221380233765, 0.2933724522590637, 0.2925865650177002, 0.29374733567237854, 0.2942271828651428, 0.29423192143440247, 0.2933460474014282, 0.29183459281921387, 0.28910791873931885, 0.2887283265590668, 0.2886369228363037, 0.2879968285560608, 0.2890223562717438], 'accuracy': [0.959590494632721, 0.9722521305084229, 0.9717133641242981, 0.9754849076271057, 0.9832974076271057, 0.9846444129943848, 0.9894935488700867, 0.9876077771186829, 0.9900323152542114, 0.9873383641242981, 0.9881465435028076, 0.9919180870056152, 0.9948814511299133, 0.9921875, 0.9940732717514038, 0.9954202771186829, 0.9956896305084229, 0.9932650923728943, 0.993803858757019, 0.9954202771186829, 0.9954202771186829, 0.993803858757019, 0.9946120977401733, 0.9956896305084229, 0.9970366358757019, 0.9970366358757019, 0.9967672228813171, 0.9978448152542114, 0.9978448152542114, 0.9978448152542114, 0.9978448152542114, 0.9916487336158752, 0.9962284564971924, 0.9989224076271057, 0.9978448152542114, 0.9970366358757019, 0.998652994632721, 0.9981142282485962, 0.9981142282485962, 0.998383641242981, 0.998652994632721, 0.9991918206214905, 0.998383641242981, 0.998652994632721, 0.9994612336158752, 0.998652994632721, 0.998383641242981, 0.998652994632721, 0.9994612336158752, 0.9994612336158752, 0.9989224076271057, 0.9994612336158752, 0.9994612336158752, 0.998383641242981, 0.9989224076271057, 0.998652994632721, 0.9994612336158752, 0.9981142282485962, 1.0, 0.998652994632721, 0.9991918206214905, 0.9994612336158752, 0.9997305870056152, 0.9991918206214905, 1.0, 0.9997305870056152, 0.9994612336158752, 0.9997305870056152, 0.9997305870056152, 0.9994612336158752, 0.9997305870056152, 1.0, 0.9994612336158752, 0.998652994632721, 0.9991918206214905, 0.9994612336158752, 0.9997305870056152, 0.9981142282485962, 0.9997305870056152, 0.9994612336158752, 0.9997305870056152, 0.9994612336158752, 1.0, 0.9997305870056152, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0], 'val_loss': [1.086653709411621, 1.0841126441955566, 1.0880064964294434, 1.093709111213684, 1.0879905223846436, 1.0857969522476196, 1.078230381011963, 1.0777204036712646, 1.078936219215393, 1.0375301837921143, 1.0465502738952637, 1.041121482849121, 1.0349891185760498, 0.9379709362983704, 0.9546290636062622, 0.8602194786071777, 0.848816454410553, 0.7946712374687195, 0.8351450562477112, 0.8247472047805786, 0.7911981344223022, 0.8528901934623718, 0.8156250715255737, 0.8854970335960388, 0.8642089366912842, 0.8644269704818726, 0.8875826597213745, 0.8897355794906616, 0.8927675485610962, 0.9099937081336975, 0.9197150468826294, 0.9318556785583496, 0.9575554132461548, 0.9649827480316162, 0.9509969353675842, 0.9523100852966309, 0.9568124413490295, 0.9595087766647339, 0.9702112078666687, 0.9858675599098206, 0.9696506857872009, 0.9886252880096436, 0.9684935212135315, 0.9915429949760437, 0.9940672516822815, 1.0000170469284058, 0.9959842562675476, 0.9985479116439819, 0.9998431205749512, 0.9866651296615601, 0.9928587675094604, 0.9916362166404724, 0.9927887320518494, 0.9975332617759705, 1.0069711208343506, 1.0031824111938477, 1.0274076461791992, 1.0078067779541016, 1.0393131971359253, 1.0133106708526611, 1.0185920000076294, 1.0265392065048218, 1.0185142755508423, 1.0394835472106934, 1.0471457242965698, 1.0274649858474731, 1.0265611410140991, 1.0398859977722168, 1.0536420345306396, 1.0357311964035034, 1.063035249710083, 1.0371021032333374, 1.041666030883789, 1.0647757053375244, 1.0512202978134155, 1.085984706878662, 1.085119605064392, 1.0864977836608887, 1.0537614822387695, 1.0572055578231812, 1.0705033540725708, 1.0758966207504272, 1.0551899671554565, 1.0657647848129272, 1.0814168453216553, 1.067712664604187, 1.0677688121795654, 1.0702952146530151, 1.0675395727157593, 1.070101022720337, 1.0852404832839966, 1.090271234512329, 1.1318681240081787, 1.129973292350769, 1.079115867614746, 1.0964229106903076, 1.0839611291885376, 1.099343180656433, 1.083235263824463, 1.0918340682983398], 'val_accuracy': [0.48599138855934143, 0.4881465435028076, 0.4881465435028076, 0.4892241358757019, 0.4913793206214905, 0.49568966031074524, 0.5021551847457886, 0.5053879022598267, 0.5107758641242981, 0.5334051847457886, 0.5387930870056152, 0.5463362336158752, 0.5625, 0.6271551847457886, 0.6260775923728943, 0.7036637663841248, 0.7176724076271057, 0.7855603694915771, 0.7489224076271057, 0.7758620977401733, 0.7941810488700867, 0.774784505367279, 0.8071120977401733, 0.7801724076271057, 0.795258641242981, 0.8006465435028076, 0.8006465435028076, 0.8028017282485962, 0.806034505367279, 0.7963362336158752, 0.8028017282485962, 0.8006465435028076, 0.7887930870056152, 0.7887930870056152, 0.7931034564971924, 0.7995689511299133, 0.7995689511299133, 0.795258641242981, 0.7941810488700867, 0.7898706793785095, 0.798491358757019, 0.787715494632721, 0.7941810488700867, 0.787715494632721, 0.7887930870056152, 0.7931034564971924, 0.787715494632721, 0.7866379022598267, 0.7855603694915771, 0.7974137663841248, 0.795258641242981, 0.7941810488700867, 0.7909482717514038, 0.7866379022598267, 0.7866379022598267, 0.7887930870056152, 0.7844827771186829, 0.787715494632721, 0.7780172228813171, 0.7909482717514038, 0.7844827771186829, 0.7866379022598267, 0.787715494632721, 0.7801724076271057, 0.7834051847457886, 0.7909482717514038, 0.7887930870056152, 0.7834051847457886, 0.7801724076271057, 0.78125, 0.7801724076271057, 0.7898706793785095, 0.7866379022598267, 0.7769396305084229, 0.7844827771186829, 0.78125, 0.7780172228813171, 0.7801724076271057, 0.7801724076271057, 0.7866379022598267, 0.7769396305084229, 0.7844827771186829, 0.7855603694915771, 0.7844827771186829, 0.7769396305084229, 0.7823275923728943, 0.7823275923728943, 0.7834051847457886, 0.7758620977401733, 0.7780172228813171, 0.7790948152542114, 0.7758620977401733, 0.7693965435028076, 0.7661637663841248, 0.7780172228813171, 0.78125, 0.7823275923728943, 0.7758620977401733, 0.7801724076271057, 0.7758620977401733]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 38ms/step - loss: 0.4470 - accuracy: 0.9491 - val_loss: 1.0691 - val_accuracy: 0.5000\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.4082 - accuracy: 0.9766"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 0s 15ms/step - loss: 0.4051 - accuracy: 0.9743 - val_loss: 1.0713 - val_accuracy: 0.5000\n","Epoch 3/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3987 - accuracy: 0.9765 - val_loss: 1.0696 - val_accuracy: 0.5034\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3985 - accuracy: 0.9762 - val_loss: 1.0755 - val_accuracy: 0.5057\n","Epoch 5/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3870 - accuracy: 0.9816 - val_loss: 1.0763 - val_accuracy: 0.5057\n","Epoch 6/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3821 - accuracy: 0.9844 - val_loss: 1.0763 - val_accuracy: 0.5079\n","Epoch 7/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3809 - accuracy: 0.9856 - val_loss: 1.0765 - val_accuracy: 0.5090\n","Epoch 8/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3767 - accuracy: 0.9881 - val_loss: 1.0689 - val_accuracy: 0.5147\n","Epoch 9/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3734 - accuracy: 0.9890 - val_loss: 1.0385 - val_accuracy: 0.5294\n","Epoch 10/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3743 - accuracy: 0.9875 - val_loss: 1.0408 - val_accuracy: 0.5328\n","Epoch 11/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3706 - accuracy: 0.9909 - val_loss: 1.0509 - val_accuracy: 0.5373\n","Epoch 12/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3685 - accuracy: 0.9887 - val_loss: 1.0238 - val_accuracy: 0.5532\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3624 - accuracy: 0.9929 - val_loss: 0.9830 - val_accuracy: 0.5837\n","Epoch 14/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3628 - accuracy: 0.9935 - val_loss: 1.0154 - val_accuracy: 0.5781\n","Epoch 15/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3673 - accuracy: 0.9892 - val_loss: 0.9341 - val_accuracy: 0.6312\n","Epoch 16/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3600 - accuracy: 0.9946 - val_loss: 0.9172 - val_accuracy: 0.6584\n","Epoch 17/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3560 - accuracy: 0.9960 - val_loss: 0.9306 - val_accuracy: 0.6595\n","Epoch 18/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3567 - accuracy: 0.9949 - val_loss: 0.8793 - val_accuracy: 0.7048\n","Epoch 19/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3529 - accuracy: 0.9960 - val_loss: 0.8116 - val_accuracy: 0.7624\n","Epoch 20/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3521 - accuracy: 0.9960 - val_loss: 0.8045 - val_accuracy: 0.7624\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3495 - accuracy: 0.9969 - val_loss: 0.8087 - val_accuracy: 0.7715\n","Epoch 22/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3493 - accuracy: 0.9969 - val_loss: 0.7534 - val_accuracy: 0.7964\n","Epoch 23/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3676 - accuracy: 0.9861 - val_loss: 0.8822 - val_accuracy: 0.7545\n","Epoch 24/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3515 - accuracy: 0.9969 - val_loss: 0.7776 - val_accuracy: 0.7952\n","Epoch 25/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3455 - accuracy: 0.9972 - val_loss: 0.8254 - val_accuracy: 0.7805\n","Epoch 26/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3525 - accuracy: 0.9929 - val_loss: 0.8259 - val_accuracy: 0.7907\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3445 - accuracy: 0.9963 - val_loss: 0.8680 - val_accuracy: 0.7704\n","Epoch 28/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3401 - accuracy: 0.9989 - val_loss: 0.8212 - val_accuracy: 0.8111\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3388 - accuracy: 0.9986 - val_loss: 0.8287 - val_accuracy: 0.8088\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3383 - accuracy: 0.9986 - val_loss: 0.8706 - val_accuracy: 0.7919\n","Epoch 31/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3405 - accuracy: 0.9975 - val_loss: 0.8513 - val_accuracy: 0.8122\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3415 - accuracy: 0.9966 - val_loss: 0.8749 - val_accuracy: 0.7930\n","Epoch 33/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3349 - accuracy: 0.9983 - val_loss: 0.8680 - val_accuracy: 0.8032\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3371 - accuracy: 0.9986 - val_loss: 0.8704 - val_accuracy: 0.8088\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3325 - accuracy: 0.9989 - val_loss: 0.8777 - val_accuracy: 0.7964\n","Epoch 36/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3336 - accuracy: 0.9989 - val_loss: 0.8934 - val_accuracy: 0.7986\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3350 - accuracy: 0.9975 - val_loss: 0.8933 - val_accuracy: 0.7986\n","Epoch 38/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3304 - accuracy: 0.9997 - val_loss: 0.9608 - val_accuracy: 0.7760\n","Epoch 39/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3392 - accuracy: 0.9955 - val_loss: 0.8984 - val_accuracy: 0.7975\n","Epoch 40/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3353 - accuracy: 0.9986 - val_loss: 0.9258 - val_accuracy: 0.7828\n","Epoch 41/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3273 - accuracy: 0.9997 - val_loss: 0.9473 - val_accuracy: 0.7862\n","Epoch 42/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3287 - accuracy: 0.9992 - val_loss: 0.9160 - val_accuracy: 0.7941\n","Epoch 43/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3277 - accuracy: 0.9989 - val_loss: 0.9105 - val_accuracy: 0.8043\n","Epoch 44/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3262 - accuracy: 0.9992 - val_loss: 0.9198 - val_accuracy: 0.7964\n","Epoch 45/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3247 - accuracy: 0.9992 - val_loss: 0.9236 - val_accuracy: 0.7907\n","Epoch 46/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3267 - accuracy: 0.9989 - val_loss: 0.9155 - val_accuracy: 0.7930\n","Epoch 47/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3308 - accuracy: 0.9972 - val_loss: 0.9594 - val_accuracy: 0.7794\n","Epoch 48/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3252 - accuracy: 0.9994 - val_loss: 0.9312 - val_accuracy: 0.7873\n","Epoch 49/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3205 - accuracy: 1.0000 - val_loss: 0.9228 - val_accuracy: 0.7941\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3224 - accuracy: 0.9997 - val_loss: 0.9264 - val_accuracy: 0.7930\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3208 - accuracy: 0.9997 - val_loss: 0.9508 - val_accuracy: 0.7839\n","Epoch 52/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3219 - accuracy: 0.9992 - val_loss: 0.9409 - val_accuracy: 0.7907\n","Epoch 53/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3184 - accuracy: 1.0000 - val_loss: 0.9622 - val_accuracy: 0.7851\n","Epoch 54/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3181 - accuracy: 1.0000 - val_loss: 0.9576 - val_accuracy: 0.7828\n","Epoch 55/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3176 - accuracy: 0.9997 - val_loss: 0.9397 - val_accuracy: 0.7896\n","Epoch 56/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3156 - accuracy: 0.9994 - val_loss: 0.9479 - val_accuracy: 0.7851\n","Epoch 57/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3146 - accuracy: 1.0000 - val_loss: 0.9388 - val_accuracy: 0.7919\n","Epoch 58/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3146 - accuracy: 0.9994 - val_loss: 0.9454 - val_accuracy: 0.7885\n","Epoch 59/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3142 - accuracy: 1.0000 - val_loss: 0.9455 - val_accuracy: 0.7862\n","Epoch 60/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3131 - accuracy: 1.0000 - val_loss: 0.9495 - val_accuracy: 0.7896\n","Epoch 61/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3153 - accuracy: 0.9997 - val_loss: 0.9528 - val_accuracy: 0.7862\n","Epoch 62/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3139 - accuracy: 0.9992 - val_loss: 0.9539 - val_accuracy: 0.7862\n","Epoch 63/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3118 - accuracy: 1.0000 - val_loss: 0.9569 - val_accuracy: 0.7805\n","Epoch 64/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3098 - accuracy: 1.0000 - val_loss: 0.9948 - val_accuracy: 0.7771\n","Epoch 65/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3106 - accuracy: 1.0000 - val_loss: 0.9664 - val_accuracy: 0.7907\n","Epoch 66/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3127 - accuracy: 0.9989 - val_loss: 0.9979 - val_accuracy: 0.7817\n","Epoch 67/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3232 - accuracy: 0.9972 - val_loss: 1.0389 - val_accuracy: 0.7738\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3128 - accuracy: 0.9983 - val_loss: 1.0062 - val_accuracy: 0.7805\n","Epoch 69/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3098 - accuracy: 1.0000 - val_loss: 0.9804 - val_accuracy: 0.7885\n","Epoch 70/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3080 - accuracy: 0.9994 - val_loss: 1.0179 - val_accuracy: 0.7794\n","Epoch 71/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3086 - accuracy: 0.9997 - val_loss: 0.9788 - val_accuracy: 0.7862\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3058 - accuracy: 0.9997 - val_loss: 0.9877 - val_accuracy: 0.7828\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3060 - accuracy: 0.9997 - val_loss: 1.0191 - val_accuracy: 0.7726\n","Epoch 74/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3040 - accuracy: 1.0000 - val_loss: 1.0025 - val_accuracy: 0.7805\n","Epoch 75/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3049 - accuracy: 1.0000 - val_loss: 0.9866 - val_accuracy: 0.7794\n","Epoch 76/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3021 - accuracy: 1.0000 - val_loss: 0.9892 - val_accuracy: 0.7783\n","Epoch 77/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3030 - accuracy: 0.9997 - val_loss: 1.0023 - val_accuracy: 0.7805\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3018 - accuracy: 0.9997 - val_loss: 1.0324 - val_accuracy: 0.7715\n","Epoch 79/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3015 - accuracy: 1.0000 - val_loss: 0.9971 - val_accuracy: 0.7783\n","Epoch 80/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3001 - accuracy: 1.0000 - val_loss: 0.9998 - val_accuracy: 0.7828\n","Epoch 81/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3002 - accuracy: 0.9997 - val_loss: 0.9943 - val_accuracy: 0.7851\n","Epoch 82/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2986 - accuracy: 1.0000 - val_loss: 1.0122 - val_accuracy: 0.7771\n","Epoch 83/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2978 - accuracy: 0.9997 - val_loss: 1.0213 - val_accuracy: 0.7726\n","Epoch 84/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2980 - accuracy: 1.0000 - val_loss: 1.0206 - val_accuracy: 0.7749\n","Epoch 85/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2970 - accuracy: 1.0000 - val_loss: 1.0002 - val_accuracy: 0.7851\n","Epoch 86/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2968 - accuracy: 1.0000 - val_loss: 1.0071 - val_accuracy: 0.7794\n","Epoch 87/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2973 - accuracy: 0.9997 - val_loss: 1.0058 - val_accuracy: 0.7817\n","Epoch 88/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2951 - accuracy: 1.0000 - val_loss: 1.0130 - val_accuracy: 0.7839\n","Epoch 89/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2949 - accuracy: 1.0000 - val_loss: 1.0138 - val_accuracy: 0.7817\n","Epoch 90/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2966 - accuracy: 0.9997 - val_loss: 1.0206 - val_accuracy: 0.7771\n","Epoch 91/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2940 - accuracy: 1.0000 - val_loss: 1.0227 - val_accuracy: 0.7839\n","Epoch 92/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2929 - accuracy: 1.0000 - val_loss: 1.0116 - val_accuracy: 0.7817\n","Epoch 93/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2925 - accuracy: 1.0000 - val_loss: 1.0176 - val_accuracy: 0.7805\n","Epoch 94/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2919 - accuracy: 0.9997 - val_loss: 1.0309 - val_accuracy: 0.7783\n","Epoch 95/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2908 - accuracy: 1.0000 - val_loss: 1.0184 - val_accuracy: 0.7862\n","Epoch 96/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2895 - accuracy: 1.0000 - val_loss: 1.0228 - val_accuracy: 0.7805\n","Epoch 97/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2900 - accuracy: 1.0000 - val_loss: 1.0243 - val_accuracy: 0.7862\n","Epoch 98/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2897 - accuracy: 1.0000 - val_loss: 1.0572 - val_accuracy: 0.7715\n","Epoch 99/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2901 - accuracy: 1.0000 - val_loss: 1.0223 - val_accuracy: 0.7828\n","Epoch 100/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2881 - accuracy: 1.0000 - val_loss: 1.0298 - val_accuracy: 0.7862\n","{'loss': [0.447009801864624, 0.40505293011665344, 0.3987174332141876, 0.39849719405174255, 0.38699913024902344, 0.382056325674057, 0.38088253140449524, 0.3767201900482178, 0.3734305202960968, 0.37431424856185913, 0.37064456939697266, 0.3684954345226288, 0.3624023497104645, 0.3627561330795288, 0.36731305718421936, 0.3599664270877838, 0.3559592664241791, 0.35672229528427124, 0.3529132902622223, 0.3520711064338684, 0.3494710922241211, 0.3493313789367676, 0.3676471412181854, 0.35146620869636536, 0.3454746603965759, 0.3525097370147705, 0.3444500267505646, 0.3401235044002533, 0.33883628249168396, 0.3382744789123535, 0.34049105644226074, 0.3415088653564453, 0.334890216588974, 0.33705487847328186, 0.33246350288391113, 0.3336453139781952, 0.3350283205509186, 0.33041995763778687, 0.3392485976219177, 0.3353157639503479, 0.3273211121559143, 0.3287472724914551, 0.3276841342449188, 0.32623425126075745, 0.32470637559890747, 0.32670873403549194, 0.33082646131515503, 0.3251877427101135, 0.3205187916755676, 0.3224475085735321, 0.32075631618499756, 0.32191577553749084, 0.3183816969394684, 0.31813934445381165, 0.3175683617591858, 0.3156280815601349, 0.3146038353443146, 0.31457215547561646, 0.31416407227516174, 0.31309211254119873, 0.31533539295196533, 0.3138958513736725, 0.31182557344436646, 0.3097999393939972, 0.310624897480011, 0.3127148151397705, 0.32315266132354736, 0.3127698302268982, 0.30981969833374023, 0.3080321252346039, 0.308612585067749, 0.30578622221946716, 0.3060474991798401, 0.30404549837112427, 0.30486565828323364, 0.3020545244216919, 0.30295640230178833, 0.3017899990081787, 0.30147477984428406, 0.3001164495944977, 0.30021432042121887, 0.2985702157020569, 0.2978072166442871, 0.29800981283187866, 0.29704225063323975, 0.29682573676109314, 0.297298789024353, 0.2950800061225891, 0.2948685884475708, 0.29661235213279724, 0.29403597116470337, 0.2928699254989624, 0.292466402053833, 0.291908860206604, 0.29083359241485596, 0.28951114416122437, 0.2900145351886749, 0.28969675302505493, 0.2900547385215759, 0.2880970537662506], 'accuracy': [0.9490662217140198, 0.9742501378059387, 0.9765138626098633, 0.9762309193611145, 0.9816072583198547, 0.9844368696212769, 0.9855687618255615, 0.9881154298782349, 0.988964319229126, 0.9875495433807373, 0.9909451007843018, 0.9886813759803772, 0.9929258823394775, 0.9934917688369751, 0.9892473220825195, 0.9946236610412598, 0.9960384964942932, 0.9949066042900085, 0.9960384964942932, 0.9960384964942932, 0.9968873858451843, 0.9968873858451843, 0.9861347079277039, 0.9968873858451843, 0.9971703290939331, 0.9929258823394775, 0.996321439743042, 0.9988681674003601, 0.9985851645469666, 0.9985851645469666, 0.9974533319473267, 0.9966044425964355, 0.9983022212982178, 0.9985851645469666, 0.9988681674003601, 0.9988681674003601, 0.9974533319473267, 0.9997170567512512, 0.9954725503921509, 0.9985851645469666, 0.9997170567512512, 0.9991511106491089, 0.9988681674003601, 0.9991511106491089, 0.9991511106491089, 0.9988681674003601, 0.9971703290939331, 0.9994340538978577, 1.0, 0.9997170567512512, 0.9997170567512512, 0.9991511106491089, 1.0, 1.0, 0.9997170567512512, 0.9994340538978577, 1.0, 0.9994340538978577, 1.0, 1.0, 0.9997170567512512, 0.9991511106491089, 1.0, 1.0, 1.0, 0.9988681674003601, 0.9971703290939331, 0.9983022212982178, 1.0, 0.9994340538978577, 0.9997170567512512, 0.9997170567512512, 0.9997170567512512, 1.0, 1.0, 1.0, 0.9997170567512512, 0.9997170567512512, 1.0, 1.0, 0.9997170567512512, 1.0, 0.9997170567512512, 1.0, 1.0, 1.0, 0.9997170567512512, 1.0, 1.0, 0.9997170567512512, 1.0, 1.0, 1.0, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [1.069104552268982, 1.071251392364502, 1.0696308612823486, 1.075457215309143, 1.076271891593933, 1.0763013362884521, 1.0764638185501099, 1.0688767433166504, 1.038488507270813, 1.0407893657684326, 1.0509097576141357, 1.0238064527511597, 0.982978105545044, 1.015429973602295, 0.9340690970420837, 0.9171814918518066, 0.9306163787841797, 0.8793469071388245, 0.8116351366043091, 0.804489016532898, 0.8086782097816467, 0.7534326910972595, 0.8822477459907532, 0.7776059508323669, 0.8254493474960327, 0.8258770704269409, 0.8679766654968262, 0.8211830854415894, 0.8286774754524231, 0.8705841898918152, 0.8512933254241943, 0.8748717904090881, 0.8680092096328735, 0.8703573346138, 0.8777256011962891, 0.8934333324432373, 0.8933165669441223, 0.9608295559883118, 0.8984187841415405, 0.9257687926292419, 0.9472805261611938, 0.9159854650497437, 0.910504937171936, 0.919754147529602, 0.9235666990280151, 0.9155324101448059, 0.959423303604126, 0.9312352538108826, 0.9227814078330994, 0.9264236092567444, 0.9507608413696289, 0.9408877491950989, 0.9622200131416321, 0.9575822353363037, 0.9396921992301941, 0.9479460120201111, 0.9387940168380737, 0.9453920125961304, 0.9454590082168579, 0.9494937062263489, 0.952752947807312, 0.9538595080375671, 0.9569036364555359, 0.9947580099105835, 0.9663941264152527, 0.997853696346283, 1.0388751029968262, 1.006177306175232, 0.9804115295410156, 1.0178909301757812, 0.9788230061531067, 0.9876636266708374, 1.0191125869750977, 1.0025310516357422, 0.9865807294845581, 0.9892317056655884, 1.0023168325424194, 1.0324187278747559, 0.997113823890686, 0.9998200535774231, 0.9943080544471741, 1.012204885482788, 1.0213207006454468, 1.0205827951431274, 1.0001990795135498, 1.0071256160736084, 1.0058029890060425, 1.0129953622817993, 1.013849139213562, 1.020561695098877, 1.0227065086364746, 1.0115879774093628, 1.0176401138305664, 1.0308587551116943, 1.018399715423584, 1.0227879285812378, 1.0242952108383179, 1.0572293996810913, 1.0223039388656616, 1.0297918319702148], 'val_accuracy': [0.5, 0.5, 0.5033936500549316, 0.5056561231613159, 0.5056561231613159, 0.5079185366630554, 0.5090497732162476, 0.5147058963775635, 0.529411792755127, 0.5328054428100586, 0.5373303294181824, 0.5531674027442932, 0.5837104320526123, 0.5780543088912964, 0.6312217116355896, 0.6583710312843323, 0.6595022678375244, 0.7047511339187622, 0.7624434232711792, 0.7624434232711792, 0.7714931964874268, 0.7963801026344299, 0.7545248866081238, 0.7952488660812378, 0.7805429697036743, 0.790723979473114, 0.7703620195388794, 0.8110859990119934, 0.8088235259056091, 0.7918552160263062, 0.8122171759605408, 0.7929864525794983, 0.8031674027442932, 0.8088235259056091, 0.7963801026344299, 0.7986425161361694, 0.7986425161361694, 0.7760180830955505, 0.7975113391876221, 0.7828054428100586, 0.7861990928649902, 0.7941176295280457, 0.8042986392974854, 0.7963801026344299, 0.790723979473114, 0.7929864525794983, 0.779411792755127, 0.7873303294181824, 0.7941176295280457, 0.7929864525794983, 0.7839366793632507, 0.790723979473114, 0.7850678563117981, 0.7828054428100586, 0.7895927429199219, 0.7850678563117981, 0.7918552160263062, 0.7884615659713745, 0.7861990928649902, 0.7895927429199219, 0.7861990928649902, 0.7861990928649902, 0.7805429697036743, 0.7771493196487427, 0.790723979473114, 0.7816742062568665, 0.773755669593811, 0.7805429697036743, 0.7884615659713745, 0.779411792755127, 0.7861990928649902, 0.7828054428100586, 0.7726244330406189, 0.7805429697036743, 0.779411792755127, 0.7782805562019348, 0.7805429697036743, 0.7714931964874268, 0.7782805562019348, 0.7828054428100586, 0.7850678563117981, 0.7771493196487427, 0.7726244330406189, 0.7748869061470032, 0.7850678563117981, 0.779411792755127, 0.7816742062568665, 0.7839366793632507, 0.7816742062568665, 0.7771493196487427, 0.7839366793632507, 0.7816742062568665, 0.7805429697036743, 0.7782805562019348, 0.7861990928649902, 0.7805429697036743, 0.7861990928649902, 0.7714931964874268, 0.7828054428100586, 0.7861990928649902]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 4s 27ms/step - loss: 0.4928 - accuracy: 0.9385 - val_loss: 1.0849 - val_accuracy: 0.4928\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.4796 - accuracy: 0.9375"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 1s 16ms/step - loss: 0.4422 - accuracy: 0.9584 - val_loss: 1.0871 - val_accuracy: 0.4938\n","Epoch 3/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4239 - accuracy: 0.9641 - val_loss: 1.0864 - val_accuracy: 0.4948\n","Epoch 4/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4193 - accuracy: 0.9649 - val_loss: 1.0914 - val_accuracy: 0.4969\n","Epoch 5/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4163 - accuracy: 0.9623 - val_loss: 1.0985 - val_accuracy: 0.4990\n","Epoch 6/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4055 - accuracy: 0.9726 - val_loss: 1.1006 - val_accuracy: 0.4990\n","Epoch 7/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4035 - accuracy: 0.9744 - val_loss: 1.1014 - val_accuracy: 0.5041\n","Epoch 8/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3952 - accuracy: 0.9757 - val_loss: 1.0771 - val_accuracy: 0.5176\n","Epoch 9/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3996 - accuracy: 0.9752 - val_loss: 1.0818 - val_accuracy: 0.5217\n","Epoch 10/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3873 - accuracy: 0.9822 - val_loss: 1.0612 - val_accuracy: 0.5310\n","Epoch 11/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3863 - accuracy: 0.9806 - val_loss: 1.1031 - val_accuracy: 0.5289\n","Epoch 12/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3910 - accuracy: 0.9786 - val_loss: 1.0040 - val_accuracy: 0.5795\n","Epoch 13/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3804 - accuracy: 0.9850 - val_loss: 0.9980 - val_accuracy: 0.6002\n","Epoch 14/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3820 - accuracy: 0.9827 - val_loss: 0.9849 - val_accuracy: 0.6178\n","Epoch 15/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3765 - accuracy: 0.9860 - val_loss: 0.9777 - val_accuracy: 0.6384\n","Epoch 16/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3710 - accuracy: 0.9912 - val_loss: 0.9420 - val_accuracy: 0.6694\n","Epoch 17/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3735 - accuracy: 0.9894 - val_loss: 0.9242 - val_accuracy: 0.6994\n","Epoch 18/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3733 - accuracy: 0.9881 - val_loss: 0.9134 - val_accuracy: 0.7376\n","Epoch 19/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3770 - accuracy: 0.9837 - val_loss: 0.9050 - val_accuracy: 0.7562\n","Epoch 20/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3706 - accuracy: 0.9891 - val_loss: 0.9257 - val_accuracy: 0.7562\n","Epoch 21/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3660 - accuracy: 0.9910 - val_loss: 0.9393 - val_accuracy: 0.7696\n","Epoch 22/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3632 - accuracy: 0.9935 - val_loss: 1.0148 - val_accuracy: 0.7417\n","Epoch 23/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3644 - accuracy: 0.9907 - val_loss: 0.9698 - val_accuracy: 0.7748\n","Epoch 24/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3623 - accuracy: 0.9915 - val_loss: 1.0450 - val_accuracy: 0.7521\n","Epoch 25/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3590 - accuracy: 0.9943 - val_loss: 1.0195 - val_accuracy: 0.7769\n","Epoch 26/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3565 - accuracy: 0.9951 - val_loss: 1.0299 - val_accuracy: 0.7748\n","Epoch 27/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3641 - accuracy: 0.9904 - val_loss: 1.1110 - val_accuracy: 0.7572\n","Epoch 28/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3568 - accuracy: 0.9935 - val_loss: 1.0676 - val_accuracy: 0.7800\n","Epoch 29/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3732 - accuracy: 0.9814 - val_loss: 1.0679 - val_accuracy: 0.7769\n","Epoch 30/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3577 - accuracy: 0.9922 - val_loss: 1.0964 - val_accuracy: 0.7727\n","Epoch 31/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3523 - accuracy: 0.9943 - val_loss: 1.1551 - val_accuracy: 0.7531\n","Epoch 32/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3529 - accuracy: 0.9938 - val_loss: 1.1202 - val_accuracy: 0.7810\n","Epoch 33/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3504 - accuracy: 0.9956 - val_loss: 1.1122 - val_accuracy: 0.7758\n","Epoch 34/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3475 - accuracy: 0.9964 - val_loss: 1.1168 - val_accuracy: 0.7779\n","Epoch 35/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3479 - accuracy: 0.9961 - val_loss: 1.1305 - val_accuracy: 0.7738\n","Epoch 36/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3471 - accuracy: 0.9972 - val_loss: 1.1550 - val_accuracy: 0.7614\n","Epoch 37/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3425 - accuracy: 0.9977 - val_loss: 1.1418 - val_accuracy: 0.7800\n","Epoch 38/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3413 - accuracy: 0.9972 - val_loss: 1.1364 - val_accuracy: 0.7738\n","Epoch 39/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3422 - accuracy: 0.9969 - val_loss: 1.1417 - val_accuracy: 0.7707\n","Epoch 40/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3401 - accuracy: 0.9969 - val_loss: 1.1538 - val_accuracy: 0.7614\n","Epoch 41/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3390 - accuracy: 0.9974 - val_loss: 1.1600 - val_accuracy: 0.7603\n","Epoch 42/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3388 - accuracy: 0.9987 - val_loss: 1.1531 - val_accuracy: 0.7634\n","Epoch 43/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3421 - accuracy: 0.9961 - val_loss: 1.2093 - val_accuracy: 0.7583\n","Epoch 44/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3399 - accuracy: 0.9966 - val_loss: 1.1605 - val_accuracy: 0.7748\n","Epoch 45/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3353 - accuracy: 0.9987 - val_loss: 1.1535 - val_accuracy: 0.7665\n","Epoch 46/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3341 - accuracy: 0.9977 - val_loss: 1.1638 - val_accuracy: 0.7738\n","Epoch 47/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3349 - accuracy: 0.9982 - val_loss: 1.2089 - val_accuracy: 0.7727\n","Epoch 48/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3384 - accuracy: 0.9961 - val_loss: 1.1847 - val_accuracy: 0.7696\n","Epoch 49/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3340 - accuracy: 0.9987 - val_loss: 1.1736 - val_accuracy: 0.7707\n","Epoch 50/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3329 - accuracy: 0.9982 - val_loss: 1.2193 - val_accuracy: 0.7490\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3343 - accuracy: 0.9977 - val_loss: 1.1905 - val_accuracy: 0.7707\n","Epoch 52/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3306 - accuracy: 0.9984 - val_loss: 1.1922 - val_accuracy: 0.7552\n","Epoch 53/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3298 - accuracy: 0.9982 - val_loss: 1.1992 - val_accuracy: 0.7603\n","Epoch 54/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3321 - accuracy: 0.9969 - val_loss: 1.2244 - val_accuracy: 0.7707\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3282 - accuracy: 0.9997 - val_loss: 1.1893 - val_accuracy: 0.7665\n","Epoch 56/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3269 - accuracy: 0.9992 - val_loss: 1.2014 - val_accuracy: 0.7562\n","Epoch 57/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3313 - accuracy: 0.9956 - val_loss: 1.2226 - val_accuracy: 0.7727\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3302 - accuracy: 0.9982 - val_loss: 1.2344 - val_accuracy: 0.7490\n","Epoch 59/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3272 - accuracy: 0.9982 - val_loss: 1.2255 - val_accuracy: 0.7717\n","Epoch 60/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3262 - accuracy: 0.9979 - val_loss: 1.2354 - val_accuracy: 0.7500\n","Epoch 61/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3233 - accuracy: 0.9990 - val_loss: 1.2587 - val_accuracy: 0.7583\n","Epoch 62/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3351 - accuracy: 0.9948 - val_loss: 1.2202 - val_accuracy: 0.7572\n","Epoch 63/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3202 - accuracy: 0.9997 - val_loss: 1.2200 - val_accuracy: 0.7583\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3198 - accuracy: 0.9997 - val_loss: 1.2215 - val_accuracy: 0.7541\n","Epoch 65/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3196 - accuracy: 0.9992 - val_loss: 1.2481 - val_accuracy: 0.7686\n","Epoch 66/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3220 - accuracy: 0.9979 - val_loss: 1.2356 - val_accuracy: 0.7655\n","Epoch 67/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3208 - accuracy: 0.9992 - val_loss: 1.2256 - val_accuracy: 0.7541\n","Epoch 68/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3228 - accuracy: 0.9972 - val_loss: 1.2582 - val_accuracy: 0.7479\n","Epoch 69/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3187 - accuracy: 0.9987 - val_loss: 1.2443 - val_accuracy: 0.7738\n","Epoch 70/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3192 - accuracy: 0.9982 - val_loss: 1.2981 - val_accuracy: 0.7469\n","Epoch 71/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3185 - accuracy: 0.9977 - val_loss: 1.2513 - val_accuracy: 0.7686\n","Epoch 72/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3153 - accuracy: 0.9992 - val_loss: 1.2388 - val_accuracy: 0.7521\n","Epoch 73/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3141 - accuracy: 0.9990 - val_loss: 1.2383 - val_accuracy: 0.7510\n","Epoch 74/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3150 - accuracy: 0.9990 - val_loss: 1.2622 - val_accuracy: 0.7510\n","Epoch 75/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3120 - accuracy: 1.0000 - val_loss: 1.2517 - val_accuracy: 0.7593\n","Epoch 76/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3113 - accuracy: 0.9997 - val_loss: 1.2539 - val_accuracy: 0.7521\n","Epoch 77/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3103 - accuracy: 0.9995 - val_loss: 1.2587 - val_accuracy: 0.7521\n","Epoch 78/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3139 - accuracy: 0.9990 - val_loss: 1.2568 - val_accuracy: 0.7541\n","Epoch 79/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3132 - accuracy: 0.9987 - val_loss: 1.2722 - val_accuracy: 0.7655\n","Epoch 80/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3097 - accuracy: 0.9997 - val_loss: 1.2845 - val_accuracy: 0.7531\n","Epoch 81/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3097 - accuracy: 0.9992 - val_loss: 1.2703 - val_accuracy: 0.7676\n","Epoch 82/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3102 - accuracy: 0.9992 - val_loss: 1.2649 - val_accuracy: 0.7490\n","Epoch 83/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3083 - accuracy: 0.9992 - val_loss: 1.2830 - val_accuracy: 0.7459\n","Epoch 84/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3074 - accuracy: 0.9995 - val_loss: 1.2818 - val_accuracy: 0.7428\n","Epoch 85/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3214 - accuracy: 0.9941 - val_loss: 1.3772 - val_accuracy: 0.7345\n","Epoch 86/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3112 - accuracy: 0.9977 - val_loss: 1.3064 - val_accuracy: 0.7624\n","Epoch 87/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3200 - accuracy: 0.9964 - val_loss: 1.3148 - val_accuracy: 0.7417\n","Epoch 88/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3143 - accuracy: 0.9953 - val_loss: 1.2863 - val_accuracy: 0.7562\n","Epoch 89/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3444 - accuracy: 0.9858 - val_loss: 1.2869 - val_accuracy: 0.7634\n","Epoch 90/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3367 - accuracy: 0.9910 - val_loss: 1.4244 - val_accuracy: 0.7438\n","Epoch 91/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3198 - accuracy: 0.9946 - val_loss: 1.3522 - val_accuracy: 0.7428\n","Epoch 92/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3175 - accuracy: 0.9959 - val_loss: 1.3377 - val_accuracy: 0.7490\n","Epoch 93/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3078 - accuracy: 0.9982 - val_loss: 1.3076 - val_accuracy: 0.7459\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3027 - accuracy: 1.0000 - val_loss: 1.3291 - val_accuracy: 0.7355\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3027 - accuracy: 0.9992 - val_loss: 1.2929 - val_accuracy: 0.7438\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3019 - accuracy: 0.9992 - val_loss: 1.2942 - val_accuracy: 0.7469\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3003 - accuracy: 0.9997 - val_loss: 1.3094 - val_accuracy: 0.7407\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2987 - accuracy: 1.0000 - val_loss: 1.3175 - val_accuracy: 0.7438\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2997 - accuracy: 0.9992 - val_loss: 1.3482 - val_accuracy: 0.7397\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2994 - accuracy: 0.9997 - val_loss: 1.3252 - val_accuracy: 0.7417\n","{'loss': [0.4928450882434845, 0.4421706795692444, 0.4238620400428772, 0.4192887246608734, 0.4163432717323303, 0.4054698050022125, 0.40352940559387207, 0.3951902389526367, 0.39955416321754456, 0.38726359605789185, 0.38628217577934265, 0.3910177946090698, 0.38040629029273987, 0.38202041387557983, 0.37653353810310364, 0.3709639012813568, 0.37353286147117615, 0.37326493859291077, 0.37702205777168274, 0.37058863043785095, 0.36601510643959045, 0.3631995618343353, 0.364398330450058, 0.3622676432132721, 0.35902610421180725, 0.3565070629119873, 0.3640543222427368, 0.3568355143070221, 0.3731591999530792, 0.35774099826812744, 0.3522726595401764, 0.3528687357902527, 0.35036715865135193, 0.34745949506759644, 0.34788915514945984, 0.34707871079444885, 0.34252285957336426, 0.3412977159023285, 0.3422388732433319, 0.34014731645584106, 0.33898767828941345, 0.3388160765171051, 0.3421109914779663, 0.3398524224758148, 0.33532601594924927, 0.3340896964073181, 0.3349311351776123, 0.3383645713329315, 0.3340189456939697, 0.3328656852245331, 0.33426475524902344, 0.33061859011650085, 0.3297620415687561, 0.3320600390434265, 0.3282284140586853, 0.3269401490688324, 0.3313392996788025, 0.33018818497657776, 0.3272465765476227, 0.3262028694152832, 0.3232603967189789, 0.33512362837791443, 0.3202012777328491, 0.31979382038116455, 0.31960606575012207, 0.3219950199127197, 0.32077503204345703, 0.3227989375591278, 0.3187195360660553, 0.3192029595375061, 0.3185388743877411, 0.3152707517147064, 0.3141137659549713, 0.31499728560447693, 0.3120170533657074, 0.3112756609916687, 0.310261994600296, 0.3138890266418457, 0.31316015124320984, 0.3097367286682129, 0.3096678853034973, 0.31023600697517395, 0.30827441811561584, 0.307405561208725, 0.32140475511550903, 0.3111554980278015, 0.319985032081604, 0.31429415941238403, 0.3443693220615387, 0.33670929074287415, 0.31975141167640686, 0.3174763321876526, 0.30782365798950195, 0.30266571044921875, 0.3026604950428009, 0.30187806487083435, 0.3002816140651703, 0.2987220585346222, 0.29970958828926086, 0.2993931770324707], 'accuracy': [0.9385012984275818, 0.9583979249000549, 0.964082658290863, 0.9648578763008118, 0.962273895740509, 0.97260981798172, 0.974418580532074, 0.9757105708122253, 0.9751937985420227, 0.9821705222129822, 0.9806201457977295, 0.9785529971122742, 0.985012948513031, 0.9826873540878296, 0.9860464930534363, 0.9912144541740417, 0.9894056916236877, 0.9881137013435364, 0.9837209582328796, 0.9891473054885864, 0.9909560680389404, 0.9935400485992432, 0.9906976819038391, 0.9914728403091431, 0.9943152666091919, 0.9950904250144958, 0.9904392957687378, 0.9935400485992432, 0.9813953638076782, 0.9922480583190918, 0.9943152666091919, 0.9937984347343445, 0.9956072568893433, 0.9963824152946472, 0.9961240291595459, 0.997157633304596, 0.9976744055747986, 0.997157633304596, 0.9968992471694946, 0.9968992471694946, 0.9974160194396973, 0.9987080097198486, 0.9961240291595459, 0.9966408014297485, 0.9987080097198486, 0.9976744055747986, 0.998191237449646, 0.9961240291595459, 0.9987080097198486, 0.998191237449646, 0.9976744055747986, 0.9984496235847473, 0.998191237449646, 0.9968992471694946, 0.9997416138648987, 0.9992247819900513, 0.9956072568893433, 0.998191237449646, 0.998191237449646, 0.9979327917098999, 0.99896639585495, 0.9948320388793945, 0.9997416138648987, 0.9997416138648987, 0.9992247819900513, 0.9979327917098999, 0.9992247819900513, 0.997157633304596, 0.9987080097198486, 0.998191237449646, 0.9976744055747986, 0.9992247819900513, 0.99896639585495, 0.99896639585495, 1.0, 0.9997416138648987, 0.9994832277297974, 0.99896639585495, 0.9987080097198486, 0.9997416138648987, 0.9992247819900513, 0.9992247819900513, 0.9992247819900513, 0.9994832277297974, 0.9940568208694458, 0.9976744055747986, 0.9963824152946472, 0.9953488111495972, 0.985788106918335, 0.9909560680389404, 0.9945736527442932, 0.9958656430244446, 0.998191237449646, 1.0, 0.9992247819900513, 0.9992247819900513, 0.9997416138648987, 1.0, 0.9992247819900513, 0.9997416138648987], 'val_loss': [1.084884762763977, 1.087122917175293, 1.0864406824111938, 1.0913736820220947, 1.0984854698181152, 1.1006299257278442, 1.1013612747192383, 1.077144742012024, 1.0817759037017822, 1.0611521005630493, 1.103112816810608, 1.0039604902267456, 0.997987687587738, 0.9849032759666443, 0.9777396321296692, 0.9420080780982971, 0.9241902828216553, 0.9134018421173096, 0.9049577116966248, 0.9257041811943054, 0.9392759203910828, 1.0148016214370728, 0.9697628021240234, 1.0449694395065308, 1.0195481777191162, 1.029945731163025, 1.1109551191329956, 1.067632794380188, 1.0678566694259644, 1.0964289903640747, 1.1550955772399902, 1.1202057600021362, 1.1121762990951538, 1.1168193817138672, 1.1304755210876465, 1.1549524068832397, 1.1417560577392578, 1.1363836526870728, 1.1416757106781006, 1.1538347005844116, 1.1599775552749634, 1.1531240940093994, 1.2093274593353271, 1.160538911819458, 1.1534597873687744, 1.1637921333312988, 1.2089298963546753, 1.1847366094589233, 1.1736379861831665, 1.219271183013916, 1.1905403137207031, 1.192187786102295, 1.1991633176803589, 1.2244168519973755, 1.189318060874939, 1.2013863325119019, 1.2226313352584839, 1.2344108819961548, 1.225508451461792, 1.235386610031128, 1.258728265762329, 1.220220923423767, 1.2200074195861816, 1.2214633226394653, 1.24814772605896, 1.2355893850326538, 1.2256160974502563, 1.2582036256790161, 1.2443277835845947, 1.2980806827545166, 1.251261830329895, 1.2387861013412476, 1.2383112907409668, 1.2621551752090454, 1.2517153024673462, 1.2538578510284424, 1.25873601436615, 1.256820797920227, 1.2721902132034302, 1.2845176458358765, 1.2703474760055542, 1.2648812532424927, 1.2829852104187012, 1.2817937135696411, 1.3772380352020264, 1.3063993453979492, 1.3148341178894043, 1.2863023281097412, 1.2869473695755005, 1.424381136894226, 1.352152943611145, 1.337688684463501, 1.3075577020645142, 1.329097032546997, 1.2929291725158691, 1.2942487001419067, 1.3094205856323242, 1.3174824714660645, 1.348156213760376, 1.3251862525939941], 'val_accuracy': [0.4927685856819153, 0.49380165338516235, 0.4948347210884094, 0.4969008266925812, 0.49896693229675293, 0.49896693229675293, 0.5041322112083435, 0.5175619721412659, 0.5216942429542542, 0.5309917330741882, 0.5289255976676941, 0.5795454382896423, 0.6002066135406494, 0.6177685856819153, 0.6384297609329224, 0.6694214940071106, 0.6993801593780518, 0.7376033067703247, 0.7561983466148376, 0.7561983466148376, 0.76962810754776, 0.7417355179786682, 0.7747933864593506, 0.7520661354064941, 0.7768595218658447, 0.7747933864593506, 0.7572314143180847, 0.7799586653709412, 0.7768595218658447, 0.7727272510528564, 0.7530992031097412, 0.7809917330741882, 0.7758264541625977, 0.7778925895690918, 0.7737603187561035, 0.7613636255264282, 0.7799586653709412, 0.7737603187561035, 0.7706611752510071, 0.7613636255264282, 0.7603305578231812, 0.7634297609329224, 0.7582644820213318, 0.7747933864593506, 0.7665289044380188, 0.7737603187561035, 0.7727272510528564, 0.76962810754776, 0.7706611752510071, 0.7489669322967529, 0.7706611752510071, 0.7551652789115906, 0.7603305578231812, 0.7706611752510071, 0.7665289044380188, 0.7561983466148376, 0.7727272510528564, 0.7489669322967529, 0.7716942429542542, 0.75, 0.7582644820213318, 0.7572314143180847, 0.7582644820213318, 0.7541322112083435, 0.7685950398445129, 0.7654958963394165, 0.7541322112083435, 0.7479338645935059, 0.7737603187561035, 0.7469007968902588, 0.7685950398445129, 0.7520661354064941, 0.7510330677032471, 0.7510330677032471, 0.7592975497245789, 0.7520661354064941, 0.7520661354064941, 0.7541322112083435, 0.7654958963394165, 0.7530992031097412, 0.7675619721412659, 0.7489669322967529, 0.7458677887916565, 0.7427685856819153, 0.7345041036605835, 0.7623966932296753, 0.7417355179786682, 0.7561983466148376, 0.7634297609329224, 0.7438016533851624, 0.7427685856819153, 0.7489669322967529, 0.7458677887916565, 0.7355371713638306, 0.7438016533851624, 0.7469007968902588, 0.7407024502754211, 0.7438016533851624, 0.7396694421768188, 0.7417355179786682]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 28ms/step - loss: 0.4086 - accuracy: 0.9564 - val_loss: 1.0954 - val_accuracy: 0.4881\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.3540 - accuracy: 0.9688"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 12ms/step - loss: 0.3495 - accuracy: 0.9779 - val_loss: 1.0901 - val_accuracy: 0.4881\n","Epoch 3/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3260 - accuracy: 0.9898 - val_loss: 1.1035 - val_accuracy: 0.4881\n","Epoch 4/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3128 - accuracy: 0.9933 - val_loss: 1.1077 - val_accuracy: 0.4903\n","Epoch 5/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3093 - accuracy: 0.9960 - val_loss: 1.1135 - val_accuracy: 0.4903\n","Epoch 6/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3088 - accuracy: 0.9965 - val_loss: 1.1100 - val_accuracy: 0.4946\n","Epoch 7/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3072 - accuracy: 0.9970 - val_loss: 1.1078 - val_accuracy: 0.4989\n","Epoch 8/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3047 - accuracy: 0.9987 - val_loss: 1.1019 - val_accuracy: 0.5022\n","Epoch 9/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3069 - accuracy: 0.9973 - val_loss: 1.0845 - val_accuracy: 0.5140\n","Epoch 10/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3056 - accuracy: 0.9981 - val_loss: 1.0767 - val_accuracy: 0.5216\n","Epoch 11/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3024 - accuracy: 0.9984 - val_loss: 1.0582 - val_accuracy: 0.5388\n","Epoch 12/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3001 - accuracy: 0.9987 - val_loss: 1.0121 - val_accuracy: 0.5657\n","Epoch 13/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2996 - accuracy: 0.9989 - val_loss: 1.0297 - val_accuracy: 0.5722\n","Epoch 14/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3004 - accuracy: 0.9989 - val_loss: 0.9649 - val_accuracy: 0.6110\n","Epoch 15/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2984 - accuracy: 0.9992 - val_loss: 0.8851 - val_accuracy: 0.6519\n","Epoch 16/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2970 - accuracy: 0.9997 - val_loss: 0.8213 - val_accuracy: 0.7155\n","Epoch 17/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2972 - accuracy: 0.9992 - val_loss: 0.7931 - val_accuracy: 0.7435\n","Epoch 18/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2977 - accuracy: 0.9995 - val_loss: 0.8161 - val_accuracy: 0.7381\n","Epoch 19/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2947 - accuracy: 0.9997 - val_loss: 0.7321 - val_accuracy: 0.8103\n","Epoch 20/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2941 - accuracy: 1.0000 - val_loss: 0.7628 - val_accuracy: 0.8006\n","Epoch 21/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2947 - accuracy: 1.0000 - val_loss: 0.7695 - val_accuracy: 0.8060\n","Epoch 22/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2961 - accuracy: 0.9995 - val_loss: 0.7399 - val_accuracy: 0.8287\n","Epoch 23/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2929 - accuracy: 1.0000 - val_loss: 0.7536 - val_accuracy: 0.8308\n","Epoch 24/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2917 - accuracy: 0.9997 - val_loss: 0.8039 - val_accuracy: 0.8179\n","Epoch 25/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2961 - accuracy: 0.9984 - val_loss: 0.8312 - val_accuracy: 0.8222\n","Epoch 26/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2934 - accuracy: 0.9995 - val_loss: 0.7901 - val_accuracy: 0.8351\n","Epoch 27/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2900 - accuracy: 1.0000 - val_loss: 0.8150 - val_accuracy: 0.8308\n","Epoch 28/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2901 - accuracy: 0.9997 - val_loss: 0.7994 - val_accuracy: 0.8405\n","Epoch 29/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2899 - accuracy: 1.0000 - val_loss: 0.8143 - val_accuracy: 0.8341\n","Epoch 30/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2880 - accuracy: 0.9997 - val_loss: 0.8224 - val_accuracy: 0.8394\n","Epoch 31/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2879 - accuracy: 0.9997 - val_loss: 0.8507 - val_accuracy: 0.8276\n","Epoch 32/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2913 - accuracy: 0.9987 - val_loss: 0.8499 - val_accuracy: 0.8287\n","Epoch 33/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2886 - accuracy: 0.9997 - val_loss: 0.8461 - val_accuracy: 0.8373\n","Epoch 34/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2866 - accuracy: 1.0000 - val_loss: 0.8513 - val_accuracy: 0.8351\n","Epoch 35/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2859 - accuracy: 1.0000 - val_loss: 0.8594 - val_accuracy: 0.8308\n","Epoch 36/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2846 - accuracy: 1.0000 - val_loss: 0.8561 - val_accuracy: 0.8394\n","Epoch 37/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2851 - accuracy: 1.0000 - val_loss: 0.8670 - val_accuracy: 0.8351\n","Epoch 38/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2850 - accuracy: 1.0000 - val_loss: 0.8893 - val_accuracy: 0.8287\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2854 - accuracy: 1.0000 - val_loss: 0.8713 - val_accuracy: 0.8308\n","Epoch 40/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2840 - accuracy: 0.9995 - val_loss: 0.8716 - val_accuracy: 0.8362\n","Epoch 41/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2824 - accuracy: 1.0000 - val_loss: 0.9059 - val_accuracy: 0.8233\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2820 - accuracy: 1.0000 - val_loss: 0.8721 - val_accuracy: 0.8351\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2808 - accuracy: 1.0000 - val_loss: 0.8919 - val_accuracy: 0.8276\n","Epoch 44/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2817 - accuracy: 1.0000 - val_loss: 0.8746 - val_accuracy: 0.8297\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2804 - accuracy: 1.0000 - val_loss: 0.9033 - val_accuracy: 0.8287\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2796 - accuracy: 1.0000 - val_loss: 0.8956 - val_accuracy: 0.8276\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2806 - accuracy: 0.9995 - val_loss: 0.8907 - val_accuracy: 0.8276\n","Epoch 48/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2786 - accuracy: 1.0000 - val_loss: 0.8839 - val_accuracy: 0.8254\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2772 - accuracy: 1.0000 - val_loss: 0.8838 - val_accuracy: 0.8265\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2780 - accuracy: 1.0000 - val_loss: 0.8830 - val_accuracy: 0.8297\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2779 - accuracy: 0.9997 - val_loss: 0.8872 - val_accuracy: 0.8265\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2765 - accuracy: 1.0000 - val_loss: 0.8996 - val_accuracy: 0.8244\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2756 - accuracy: 1.0000 - val_loss: 0.8851 - val_accuracy: 0.8287\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2755 - accuracy: 1.0000 - val_loss: 0.8884 - val_accuracy: 0.8297\n","Epoch 55/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2751 - accuracy: 1.0000 - val_loss: 0.8944 - val_accuracy: 0.8287\n","Epoch 56/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2759 - accuracy: 0.9997 - val_loss: 0.9001 - val_accuracy: 0.8308\n","Epoch 57/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2741 - accuracy: 1.0000 - val_loss: 0.9145 - val_accuracy: 0.8254\n","Epoch 58/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2730 - accuracy: 1.0000 - val_loss: 0.9096 - val_accuracy: 0.8254\n","Epoch 59/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2722 - accuracy: 1.0000 - val_loss: 0.9010 - val_accuracy: 0.8254\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2746 - accuracy: 1.0000 - val_loss: 0.9119 - val_accuracy: 0.8222\n","Epoch 61/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2722 - accuracy: 1.0000 - val_loss: 0.9030 - val_accuracy: 0.8265\n","Epoch 62/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2711 - accuracy: 1.0000 - val_loss: 0.9024 - val_accuracy: 0.8254\n","Epoch 63/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2708 - accuracy: 1.0000 - val_loss: 0.9076 - val_accuracy: 0.8244\n","Epoch 64/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2706 - accuracy: 1.0000 - val_loss: 0.9277 - val_accuracy: 0.8136\n","Epoch 65/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2697 - accuracy: 0.9997 - val_loss: 0.9106 - val_accuracy: 0.8265\n","Epoch 66/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2685 - accuracy: 1.0000 - val_loss: 0.9207 - val_accuracy: 0.8222\n","Epoch 67/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2681 - accuracy: 1.0000 - val_loss: 0.9100 - val_accuracy: 0.8222\n","Epoch 68/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2673 - accuracy: 1.0000 - val_loss: 0.9075 - val_accuracy: 0.8179\n","Epoch 69/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2665 - accuracy: 1.0000 - val_loss: 0.9389 - val_accuracy: 0.8190\n","Epoch 70/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2713 - accuracy: 1.0000 - val_loss: 0.9569 - val_accuracy: 0.8179\n","Epoch 71/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2703 - accuracy: 0.9989 - val_loss: 0.9317 - val_accuracy: 0.8168\n","Epoch 72/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2664 - accuracy: 1.0000 - val_loss: 0.9207 - val_accuracy: 0.8222\n","Epoch 73/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2647 - accuracy: 0.9997 - val_loss: 0.9275 - val_accuracy: 0.8190\n","Epoch 74/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2640 - accuracy: 1.0000 - val_loss: 0.9284 - val_accuracy: 0.8222\n","Epoch 75/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2641 - accuracy: 0.9997 - val_loss: 0.9233 - val_accuracy: 0.8168\n","Epoch 76/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2627 - accuracy: 1.0000 - val_loss: 0.9219 - val_accuracy: 0.8222\n","Epoch 77/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2630 - accuracy: 1.0000 - val_loss: 0.9186 - val_accuracy: 0.8147\n","Epoch 78/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2637 - accuracy: 0.9997 - val_loss: 0.9643 - val_accuracy: 0.8103\n","Epoch 79/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2684 - accuracy: 0.9984 - val_loss: 0.9364 - val_accuracy: 0.8211\n","Epoch 80/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2616 - accuracy: 1.0000 - val_loss: 0.9411 - val_accuracy: 0.8190\n","Epoch 81/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2617 - accuracy: 0.9997 - val_loss: 0.9628 - val_accuracy: 0.8039\n","Epoch 82/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2632 - accuracy: 0.9997 - val_loss: 0.9310 - val_accuracy: 0.8190\n","Epoch 83/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2610 - accuracy: 0.9997 - val_loss: 0.9274 - val_accuracy: 0.8179\n","Epoch 84/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2585 - accuracy: 1.0000 - val_loss: 0.9570 - val_accuracy: 0.8200\n","Epoch 85/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2586 - accuracy: 1.0000 - val_loss: 0.9364 - val_accuracy: 0.8190\n","Epoch 86/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2574 - accuracy: 1.0000 - val_loss: 0.9374 - val_accuracy: 0.8179\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2567 - accuracy: 1.0000 - val_loss: 0.9294 - val_accuracy: 0.8136\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2563 - accuracy: 1.0000 - val_loss: 0.9335 - val_accuracy: 0.8190\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2551 - accuracy: 1.0000 - val_loss: 0.9379 - val_accuracy: 0.8179\n","Epoch 90/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2570 - accuracy: 0.9997 - val_loss: 1.0029 - val_accuracy: 0.8006\n","Epoch 91/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2562 - accuracy: 1.0000 - val_loss: 0.9519 - val_accuracy: 0.8147\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2537 - accuracy: 1.0000 - val_loss: 0.9428 - val_accuracy: 0.8136\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2537 - accuracy: 1.0000 - val_loss: 0.9375 - val_accuracy: 0.8147\n","Epoch 94/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2532 - accuracy: 1.0000 - val_loss: 0.9387 - val_accuracy: 0.8200\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2517 - accuracy: 1.0000 - val_loss: 0.9389 - val_accuracy: 0.8125\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2532 - accuracy: 1.0000 - val_loss: 0.9768 - val_accuracy: 0.8060\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2536 - accuracy: 1.0000 - val_loss: 0.9634 - val_accuracy: 0.8147\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2538 - accuracy: 1.0000 - val_loss: 0.9519 - val_accuracy: 0.8200\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2714 - accuracy: 0.9935 - val_loss: 1.1789 - val_accuracy: 0.7737\n","Epoch 100/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2975 - accuracy: 0.9906 - val_loss: 1.1023 - val_accuracy: 0.7888\n","{'loss': [0.40860307216644287, 0.34946054220199585, 0.32598283886909485, 0.31276506185531616, 0.3092905282974243, 0.3088012635707855, 0.30718734860420227, 0.3047482669353485, 0.3069438338279724, 0.3056364953517914, 0.30236348509788513, 0.30014273524284363, 0.29957494139671326, 0.3004121482372284, 0.2983643710613251, 0.2969672977924347, 0.2972261309623718, 0.2976953983306885, 0.2947295308113098, 0.29406648874282837, 0.29474034905433655, 0.29611074924468994, 0.29288843274116516, 0.2917015850543976, 0.29607224464416504, 0.2934189438819885, 0.28997644782066345, 0.2900746464729309, 0.28987082839012146, 0.2879842519760132, 0.28792479634284973, 0.291276752948761, 0.28860265016555786, 0.2866406738758087, 0.285876989364624, 0.28455308079719543, 0.2851089835166931, 0.28497642278671265, 0.2854002118110657, 0.28402888774871826, 0.282360315322876, 0.2820003628730774, 0.2808094024658203, 0.2817348539829254, 0.28035491704940796, 0.27955353260040283, 0.2806335687637329, 0.2786146104335785, 0.2772204577922821, 0.27803513407707214, 0.27794215083122253, 0.2764747738838196, 0.2755820155143738, 0.27548685669898987, 0.27510643005371094, 0.2759140133857727, 0.2740836441516876, 0.2729712426662445, 0.2722328007221222, 0.2746429443359375, 0.27223822474479675, 0.27110719680786133, 0.27082324028015137, 0.270562082529068, 0.26973792910575867, 0.26854798197746277, 0.26805633306503296, 0.26729506254196167, 0.26653942465782166, 0.2712755799293518, 0.27026131749153137, 0.2664261758327484, 0.2647205591201782, 0.2639879584312439, 0.26411163806915283, 0.26271215081214905, 0.26298245787620544, 0.26371195912361145, 0.26844266057014465, 0.2616075873374939, 0.26171875, 0.26322677731513977, 0.2610272467136383, 0.2584631145000458, 0.25864604115486145, 0.25744158029556274, 0.256702184677124, 0.2562706172466278, 0.25512203574180603, 0.2569776475429535, 0.2561783790588379, 0.25369974970817566, 0.2537339925765991, 0.253239244222641, 0.25174641609191895, 0.25320330262184143, 0.25357842445373535, 0.25376594066619873, 0.27138203382492065, 0.29747462272644043], 'accuracy': [0.9563577771186829, 0.977909505367279, 0.9897629022598267, 0.9932650923728943, 0.9959590435028076, 0.9964978694915771, 0.9970366358757019, 0.998652994632721, 0.9973060488700867, 0.9981142282485962, 0.998383641242981, 0.998652994632721, 0.9989224076271057, 0.9989224076271057, 0.9991918206214905, 0.9997305870056152, 0.9991918206214905, 0.9994612336158752, 0.9997305870056152, 1.0, 1.0, 0.9994612336158752, 1.0, 0.9997305870056152, 0.998383641242981, 0.9994612336158752, 1.0, 0.9997305870056152, 1.0, 0.9997305870056152, 0.9997305870056152, 0.998652994632721, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9994612336158752, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9994612336158752, 1.0, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9989224076271057, 1.0, 0.9997305870056152, 1.0, 0.9997305870056152, 1.0, 1.0, 0.9997305870056152, 0.998383641242981, 1.0, 0.9997305870056152, 0.9997305870056152, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.993534505367279, 0.990571141242981], 'val_loss': [1.0953588485717773, 1.090075135231018, 1.1034505367279053, 1.1077473163604736, 1.1135480403900146, 1.1100143194198608, 1.1078391075134277, 1.1019235849380493, 1.0844589471817017, 1.0766587257385254, 1.0581672191619873, 1.0120809078216553, 1.0297001600265503, 0.9649109840393066, 0.8851017951965332, 0.8212704658508301, 0.7930812239646912, 0.8161298036575317, 0.7320983409881592, 0.7628026604652405, 0.7695106863975525, 0.739874005317688, 0.7536148428916931, 0.8038515448570251, 0.8312377333641052, 0.7900573015213013, 0.8150206804275513, 0.7993865013122559, 0.8143393993377686, 0.8224117755889893, 0.850708544254303, 0.84993976354599, 0.8461241722106934, 0.8513076901435852, 0.859408438205719, 0.8560778498649597, 0.8670462369918823, 0.8893101215362549, 0.8712753653526306, 0.8715952038764954, 0.9058956503868103, 0.8721007704734802, 0.8918913006782532, 0.8745623826980591, 0.903329074382782, 0.8955632448196411, 0.8906887173652649, 0.8839430809020996, 0.8837578892707825, 0.8830204010009766, 0.8871551156044006, 0.8995651602745056, 0.8851287961006165, 0.8883545994758606, 0.8944224119186401, 0.9000699520111084, 0.9145145416259766, 0.9095557928085327, 0.9009893536567688, 0.9119182825088501, 0.902956485748291, 0.9023543000221252, 0.9076446890830994, 0.927709698677063, 0.9106330871582031, 0.920718789100647, 0.9100324511528015, 0.907473623752594, 0.9389339089393616, 0.9568711519241333, 0.931650698184967, 0.9206920862197876, 0.9274753928184509, 0.9284109473228455, 0.9232605695724487, 0.9219102263450623, 0.9186416864395142, 0.9643131494522095, 0.9364338517189026, 0.9410912990570068, 0.9627977609634399, 0.9309631586074829, 0.927388608455658, 0.9569820761680603, 0.9364460110664368, 0.9374377727508545, 0.9293898940086365, 0.9334945678710938, 0.9378637671470642, 1.0029228925704956, 0.9519413113594055, 0.9428362250328064, 0.9375042915344238, 0.9387414455413818, 0.9389084577560425, 0.976753294467926, 0.9633693695068359, 0.9518794417381287, 1.178928256034851, 1.102349877357483], 'val_accuracy': [0.4881465435028076, 0.4881465435028076, 0.4881465435028076, 0.4903017282485962, 0.4903017282485962, 0.49461206793785095, 0.4989224076271057, 0.5021551847457886, 0.514008641242981, 0.5215517282485962, 0.5387930870056152, 0.5657327771186829, 0.5721982717514038, 0.610991358757019, 0.6519396305084229, 0.7155172228813171, 0.743534505367279, 0.7381465435028076, 0.8103448152542114, 0.8006465435028076, 0.806034505367279, 0.8286637663841248, 0.8308189511299133, 0.8178879022598267, 0.8221982717514038, 0.8351293206214905, 0.8308189511299133, 0.8405172228813171, 0.8340517282485962, 0.8394396305084229, 0.8275862336158752, 0.8286637663841248, 0.837284505367279, 0.8351293206214905, 0.8308189511299133, 0.8394396305084229, 0.8351293206214905, 0.8286637663841248, 0.8308189511299133, 0.8362069129943848, 0.8232758641242981, 0.8351293206214905, 0.8275862336158752, 0.829741358757019, 0.8286637663841248, 0.8275862336158752, 0.8275862336158752, 0.8254310488700867, 0.826508641242981, 0.829741358757019, 0.826508641242981, 0.8243534564971924, 0.8286637663841248, 0.829741358757019, 0.8286637663841248, 0.8308189511299133, 0.8254310488700867, 0.8254310488700867, 0.8254310488700867, 0.8221982717514038, 0.826508641242981, 0.8254310488700867, 0.8243534564971924, 0.8135775923728943, 0.826508641242981, 0.8221982717514038, 0.8221982717514038, 0.8178879022598267, 0.818965494632721, 0.8178879022598267, 0.8168103694915771, 0.8221982717514038, 0.818965494632721, 0.8221982717514038, 0.8168103694915771, 0.8221982717514038, 0.8146551847457886, 0.8103448152542114, 0.8211206793785095, 0.818965494632721, 0.8038793206214905, 0.818965494632721, 0.8178879022598267, 0.8200430870056152, 0.818965494632721, 0.8178879022598267, 0.8135775923728943, 0.818965494632721, 0.8178879022598267, 0.8006465435028076, 0.8146551847457886, 0.8135775923728943, 0.8146551847457886, 0.8200430870056152, 0.8125, 0.806034505367279, 0.8146551847457886, 0.8200430870056152, 0.7737069129943848, 0.7887930870056152]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 30ms/step - loss: 0.3859 - accuracy: 0.9638 - val_loss: 1.0830 - val_accuracy: 0.5011\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.3333 - accuracy: 0.9766"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 12ms/step - loss: 0.3319 - accuracy: 0.9839 - val_loss: 1.0852 - val_accuracy: 0.5011\n","Epoch 3/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3217 - accuracy: 0.9898 - val_loss: 1.0929 - val_accuracy: 0.5011\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3216 - accuracy: 0.9892 - val_loss: 1.0890 - val_accuracy: 0.5045\n","Epoch 5/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3125 - accuracy: 0.9949 - val_loss: 1.0920 - val_accuracy: 0.5057\n","Epoch 6/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3110 - accuracy: 0.9955 - val_loss: 1.0907 - val_accuracy: 0.5079\n","Epoch 7/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3090 - accuracy: 0.9966 - val_loss: 1.0843 - val_accuracy: 0.5124\n","Epoch 8/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3058 - accuracy: 0.9972 - val_loss: 1.0817 - val_accuracy: 0.5158\n","Epoch 9/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3039 - accuracy: 0.9983 - val_loss: 1.0793 - val_accuracy: 0.5215\n","Epoch 10/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3087 - accuracy: 0.9969 - val_loss: 1.0501 - val_accuracy: 0.5328\n","Epoch 11/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3026 - accuracy: 0.9994 - val_loss: 1.0360 - val_accuracy: 0.5498\n","Epoch 12/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3016 - accuracy: 0.9983 - val_loss: 1.0346 - val_accuracy: 0.5577\n","Epoch 13/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3001 - accuracy: 0.9997 - val_loss: 0.9800 - val_accuracy: 0.5916\n","Epoch 14/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3004 - accuracy: 0.9989 - val_loss: 0.9644 - val_accuracy: 0.6075\n","Epoch 15/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2983 - accuracy: 0.9989 - val_loss: 0.9025 - val_accuracy: 0.6527\n","Epoch 16/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2974 - accuracy: 1.0000 - val_loss: 0.8517 - val_accuracy: 0.6912\n","Epoch 17/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2980 - accuracy: 0.9992 - val_loss: 0.8368 - val_accuracy: 0.7059\n","Epoch 18/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2967 - accuracy: 0.9994 - val_loss: 0.7887 - val_accuracy: 0.7421\n","Epoch 19/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2952 - accuracy: 0.9997 - val_loss: 0.7788 - val_accuracy: 0.7602\n","Epoch 20/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2950 - accuracy: 0.9997 - val_loss: 0.7883 - val_accuracy: 0.7613\n","Epoch 21/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2940 - accuracy: 0.9989 - val_loss: 0.7041 - val_accuracy: 0.8088\n","Epoch 22/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2931 - accuracy: 1.0000 - val_loss: 0.6735 - val_accuracy: 0.8371\n","Epoch 23/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2923 - accuracy: 1.0000 - val_loss: 0.6959 - val_accuracy: 0.8314\n","Epoch 24/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2914 - accuracy: 1.0000 - val_loss: 0.7223 - val_accuracy: 0.8292\n","Epoch 25/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2907 - accuracy: 0.9994 - val_loss: 0.6794 - val_accuracy: 0.8473\n","Epoch 26/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2904 - accuracy: 0.9997 - val_loss: 0.6877 - val_accuracy: 0.8507\n","Epoch 27/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2947 - accuracy: 0.9989 - val_loss: 0.7679 - val_accuracy: 0.8292\n","Epoch 28/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2907 - accuracy: 0.9997 - val_loss: 0.7773 - val_accuracy: 0.8258\n","Epoch 29/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2889 - accuracy: 1.0000 - val_loss: 0.7399 - val_accuracy: 0.8405\n","Epoch 30/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2891 - accuracy: 0.9997 - val_loss: 0.7416 - val_accuracy: 0.8462\n","Epoch 31/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2944 - accuracy: 0.9994 - val_loss: 0.7357 - val_accuracy: 0.8529\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2863 - accuracy: 1.0000 - val_loss: 0.7485 - val_accuracy: 0.8507\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2855 - accuracy: 1.0000 - val_loss: 0.7528 - val_accuracy: 0.8495\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2859 - accuracy: 1.0000 - val_loss: 0.7608 - val_accuracy: 0.8507\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2854 - accuracy: 1.0000 - val_loss: 0.7657 - val_accuracy: 0.8439\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2850 - accuracy: 1.0000 - val_loss: 0.7575 - val_accuracy: 0.8416\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2839 - accuracy: 1.0000 - val_loss: 0.7782 - val_accuracy: 0.8428\n","Epoch 38/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2850 - accuracy: 0.9994 - val_loss: 0.7689 - val_accuracy: 0.8428\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2847 - accuracy: 0.9994 - val_loss: 0.7906 - val_accuracy: 0.8337\n","Epoch 40/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2854 - accuracy: 1.0000 - val_loss: 0.7848 - val_accuracy: 0.8371\n","Epoch 41/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2823 - accuracy: 1.0000 - val_loss: 0.8015 - val_accuracy: 0.8382\n","Epoch 42/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2817 - accuracy: 1.0000 - val_loss: 0.7844 - val_accuracy: 0.8394\n","Epoch 43/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2804 - accuracy: 1.0000 - val_loss: 0.7923 - val_accuracy: 0.8337\n","Epoch 44/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2795 - accuracy: 1.0000 - val_loss: 0.7944 - val_accuracy: 0.8394\n","Epoch 45/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2800 - accuracy: 1.0000 - val_loss: 0.8194 - val_accuracy: 0.8292\n","Epoch 46/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2797 - accuracy: 1.0000 - val_loss: 0.8052 - val_accuracy: 0.8394\n","Epoch 47/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2781 - accuracy: 1.0000 - val_loss: 0.7899 - val_accuracy: 0.8314\n","Epoch 48/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2786 - accuracy: 1.0000 - val_loss: 0.7984 - val_accuracy: 0.8337\n","Epoch 49/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2776 - accuracy: 1.0000 - val_loss: 0.8186 - val_accuracy: 0.8303\n","Epoch 50/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2787 - accuracy: 0.9997 - val_loss: 0.8236 - val_accuracy: 0.8337\n","Epoch 51/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2757 - accuracy: 1.0000 - val_loss: 0.8030 - val_accuracy: 0.8337\n","Epoch 52/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2748 - accuracy: 1.0000 - val_loss: 0.8027 - val_accuracy: 0.8405\n","Epoch 53/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2744 - accuracy: 1.0000 - val_loss: 0.7997 - val_accuracy: 0.8337\n","Epoch 54/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2739 - accuracy: 1.0000 - val_loss: 0.8111 - val_accuracy: 0.8371\n","Epoch 55/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2732 - accuracy: 1.0000 - val_loss: 0.8137 - val_accuracy: 0.8337\n","Epoch 56/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2733 - accuracy: 1.0000 - val_loss: 0.8007 - val_accuracy: 0.8314\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2723 - accuracy: 1.0000 - val_loss: 0.8157 - val_accuracy: 0.8269\n","Epoch 58/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2717 - accuracy: 1.0000 - val_loss: 0.8087 - val_accuracy: 0.8382\n","Epoch 59/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2746 - accuracy: 1.0000 - val_loss: 0.8186 - val_accuracy: 0.8326\n","Epoch 60/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2710 - accuracy: 1.0000 - val_loss: 0.8230 - val_accuracy: 0.8292\n","Epoch 61/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2704 - accuracy: 1.0000 - val_loss: 0.8128 - val_accuracy: 0.8360\n","Epoch 62/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2696 - accuracy: 1.0000 - val_loss: 0.8261 - val_accuracy: 0.8224\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2691 - accuracy: 1.0000 - val_loss: 0.8279 - val_accuracy: 0.8281\n","Epoch 64/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2687 - accuracy: 1.0000 - val_loss: 0.8272 - val_accuracy: 0.8314\n","Epoch 65/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2676 - accuracy: 1.0000 - val_loss: 0.8485 - val_accuracy: 0.8258\n","Epoch 66/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2672 - accuracy: 1.0000 - val_loss: 0.8236 - val_accuracy: 0.8269\n","Epoch 67/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2683 - accuracy: 1.0000 - val_loss: 0.8519 - val_accuracy: 0.8303\n","Epoch 68/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2686 - accuracy: 1.0000 - val_loss: 0.8331 - val_accuracy: 0.8156\n","Epoch 69/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2688 - accuracy: 1.0000 - val_loss: 0.8566 - val_accuracy: 0.8201\n","Epoch 70/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2658 - accuracy: 1.0000 - val_loss: 0.8268 - val_accuracy: 0.8247\n","Epoch 71/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2643 - accuracy: 1.0000 - val_loss: 0.8292 - val_accuracy: 0.8281\n","Epoch 72/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2639 - accuracy: 1.0000 - val_loss: 0.8300 - val_accuracy: 0.8247\n","Epoch 73/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2630 - accuracy: 1.0000 - val_loss: 0.8453 - val_accuracy: 0.8213\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2624 - accuracy: 1.0000 - val_loss: 0.8315 - val_accuracy: 0.8224\n","Epoch 75/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2620 - accuracy: 1.0000 - val_loss: 0.8326 - val_accuracy: 0.8258\n","Epoch 76/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2615 - accuracy: 1.0000 - val_loss: 0.8361 - val_accuracy: 0.8224\n","Epoch 77/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2613 - accuracy: 1.0000 - val_loss: 0.8465 - val_accuracy: 0.8235\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2602 - accuracy: 1.0000 - val_loss: 0.8402 - val_accuracy: 0.8247\n","Epoch 79/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2596 - accuracy: 1.0000 - val_loss: 0.8442 - val_accuracy: 0.8258\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2600 - accuracy: 1.0000 - val_loss: 0.8724 - val_accuracy: 0.8190\n","Epoch 81/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2596 - accuracy: 1.0000 - val_loss: 0.8321 - val_accuracy: 0.8224\n","Epoch 82/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2579 - accuracy: 1.0000 - val_loss: 0.8436 - val_accuracy: 0.8258\n","Epoch 83/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2573 - accuracy: 1.0000 - val_loss: 0.8437 - val_accuracy: 0.8201\n","Epoch 84/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2567 - accuracy: 1.0000 - val_loss: 0.8520 - val_accuracy: 0.8247\n","Epoch 85/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2561 - accuracy: 1.0000 - val_loss: 0.8369 - val_accuracy: 0.8167\n","Epoch 86/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2555 - accuracy: 1.0000 - val_loss: 0.8427 - val_accuracy: 0.8145\n","Epoch 87/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2556 - accuracy: 1.0000 - val_loss: 0.8843 - val_accuracy: 0.8088\n","Epoch 88/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2560 - accuracy: 1.0000 - val_loss: 0.8461 - val_accuracy: 0.8145\n","Epoch 89/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2543 - accuracy: 1.0000 - val_loss: 0.8457 - val_accuracy: 0.8179\n","Epoch 90/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2548 - accuracy: 1.0000 - val_loss: 0.8491 - val_accuracy: 0.8224\n","Epoch 91/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2525 - accuracy: 1.0000 - val_loss: 0.8645 - val_accuracy: 0.8179\n","Epoch 92/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2521 - accuracy: 1.0000 - val_loss: 0.8485 - val_accuracy: 0.8167\n","Epoch 93/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2527 - accuracy: 1.0000 - val_loss: 0.8485 - val_accuracy: 0.8179\n","Epoch 94/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2507 - accuracy: 1.0000 - val_loss: 0.8522 - val_accuracy: 0.8111\n","Epoch 95/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2509 - accuracy: 1.0000 - val_loss: 0.8584 - val_accuracy: 0.8156\n","Epoch 96/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2493 - accuracy: 1.0000 - val_loss: 0.8536 - val_accuracy: 0.8179\n","Epoch 97/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2497 - accuracy: 1.0000 - val_loss: 0.8713 - val_accuracy: 0.8179\n","Epoch 98/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2482 - accuracy: 1.0000 - val_loss: 0.8603 - val_accuracy: 0.8133\n","Epoch 99/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2475 - accuracy: 1.0000 - val_loss: 0.9081 - val_accuracy: 0.8100\n","Epoch 100/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2472 - accuracy: 1.0000 - val_loss: 0.8552 - val_accuracy: 0.8145\n","{'loss': [0.3858564496040344, 0.3318997621536255, 0.32167065143585205, 0.32156017422676086, 0.3125308156013489, 0.31103143095970154, 0.30895140767097473, 0.30584633350372314, 0.30387043952941895, 0.308651328086853, 0.30255863070487976, 0.3016439974308014, 0.30007505416870117, 0.3004000186920166, 0.2982541024684906, 0.29744425415992737, 0.2980480492115021, 0.29666098952293396, 0.29524895548820496, 0.2950358986854553, 0.2939673066139221, 0.29311463236808777, 0.2922615110874176, 0.2913547456264496, 0.29070645570755005, 0.2903956472873688, 0.29468828439712524, 0.29069823026657104, 0.28885799646377563, 0.2890626788139343, 0.2944123148918152, 0.28626689314842224, 0.28549671173095703, 0.285887211561203, 0.2854436933994293, 0.285030335187912, 0.2839254140853882, 0.28500306606292725, 0.2846885323524475, 0.28541648387908936, 0.28233858942985535, 0.28172993659973145, 0.28035083413124084, 0.2795189917087555, 0.2799776792526245, 0.27967455983161926, 0.2781361937522888, 0.2785603702068329, 0.27759015560150146, 0.2786836326122284, 0.27571815252304077, 0.27475088834762573, 0.27436840534210205, 0.27385157346725464, 0.2732263207435608, 0.2732783555984497, 0.27225157618522644, 0.2716870903968811, 0.2745872437953949, 0.2710435092449188, 0.2703517973423004, 0.2696124315261841, 0.2691352069377899, 0.26866793632507324, 0.26756152510643005, 0.2671591639518738, 0.26834848523139954, 0.26858097314834595, 0.26875177025794983, 0.2657690644264221, 0.2643148899078369, 0.2639150619506836, 0.2630453407764435, 0.2624039649963379, 0.26198169589042664, 0.26148301362991333, 0.2613305449485779, 0.26021841168403625, 0.2595560848712921, 0.2600490152835846, 0.2596205472946167, 0.2579043209552765, 0.2573307454586029, 0.2567110061645508, 0.25608187913894653, 0.255508691072464, 0.2555515468120575, 0.2560010254383087, 0.25430721044540405, 0.25482162833213806, 0.2524767816066742, 0.25207141041755676, 0.2526697814464569, 0.2507002353668213, 0.25090083479881287, 0.24928031861782074, 0.24972888827323914, 0.24824310839176178, 0.24752315878868103, 0.24724221229553223], 'accuracy': [0.963780403137207, 0.9838709831237793, 0.9898132681846619, 0.9892473220825195, 0.9949066042900085, 0.9954725503921509, 0.9966044425964355, 0.9971703290939331, 0.9983022212982178, 0.9968873858451843, 0.9994340538978577, 0.9983022212982178, 0.9997170567512512, 0.9988681674003601, 0.9988681674003601, 1.0, 0.9991511106491089, 0.9994340538978577, 0.9997170567512512, 0.9997170567512512, 0.9988681674003601, 1.0, 1.0, 1.0, 0.9994340538978577, 0.9997170567512512, 0.9988681674003601, 0.9997170567512512, 1.0, 0.9997170567512512, 0.9994340538978577, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9994340538978577, 0.9994340538978577, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [1.0830426216125488, 1.085168719291687, 1.09291410446167, 1.0890380144119263, 1.0919917821884155, 1.0907008647918701, 1.0842692852020264, 1.081699252128601, 1.0793360471725464, 1.0501420497894287, 1.0359578132629395, 1.0346397161483765, 0.9800232648849487, 0.9644451141357422, 0.9024685025215149, 0.8516870737075806, 0.836788535118103, 0.788659393787384, 0.7788107991218567, 0.7882767915725708, 0.7041124701499939, 0.6734585762023926, 0.6959181427955627, 0.7222576141357422, 0.6793787479400635, 0.6877416372299194, 0.7679432034492493, 0.7772660851478577, 0.739912211894989, 0.7415544986724854, 0.7356697916984558, 0.7484646439552307, 0.7527570724487305, 0.7608172297477722, 0.7657411098480225, 0.7574809789657593, 0.7781532406806946, 0.7688708305358887, 0.790604829788208, 0.7847601175308228, 0.8014776706695557, 0.7844336032867432, 0.7923167943954468, 0.7944065928459167, 0.819420337677002, 0.805180549621582, 0.7898665070533752, 0.79843670129776, 0.818565845489502, 0.8235780000686646, 0.8030056357383728, 0.8027395606040955, 0.7996598482131958, 0.8111255764961243, 0.8136643171310425, 0.8007489442825317, 0.8157047629356384, 0.8087337017059326, 0.818597137928009, 0.8229770064353943, 0.8128004670143127, 0.8260582089424133, 0.8279083967208862, 0.8272470235824585, 0.8484711647033691, 0.8236178159713745, 0.8518800139427185, 0.8330823183059692, 0.8565738201141357, 0.8267713189125061, 0.8291796445846558, 0.8300227522850037, 0.8453097939491272, 0.8314762711524963, 0.8325852751731873, 0.8360809087753296, 0.8464866876602173, 0.8402194380760193, 0.8442032933235168, 0.8723741173744202, 0.832105815410614, 0.8436148166656494, 0.8436604738235474, 0.8519725799560547, 0.8368963599205017, 0.8427358865737915, 0.884265661239624, 0.8460992574691772, 0.8456761837005615, 0.84908127784729, 0.8644713163375854, 0.8484554290771484, 0.8485280871391296, 0.8522080779075623, 0.8584175109863281, 0.8535540103912354, 0.8713462948799133, 0.8603377342224121, 0.9081181883811951, 0.8552454710006714], 'val_accuracy': [0.5011312365531921, 0.5011312365531921, 0.5011312365531921, 0.5045248866081238, 0.5056561231613159, 0.5079185366630554, 0.5124434232711792, 0.5158371329307556, 0.5214931964874268, 0.5328054428100586, 0.5497737526893616, 0.557692289352417, 0.5916289687156677, 0.6074660420417786, 0.6527149081230164, 0.6911764740943909, 0.7058823704719543, 0.7420814633369446, 0.7601810097694397, 0.7613122463226318, 0.8088235259056091, 0.837104082107544, 0.831447958946228, 0.8291855454444885, 0.8472850918769836, 0.8506787419319153, 0.8291855454444885, 0.8257918357849121, 0.8404977321624756, 0.8461538553237915, 0.8529411554336548, 0.8506787419319153, 0.8495475053787231, 0.8506787419319153, 0.8438913822174072, 0.8416289687156677, 0.8427602052688599, 0.8427602052688599, 0.8337104320526123, 0.837104082107544, 0.8382353186607361, 0.8393664956092834, 0.8337104320526123, 0.8393664956092834, 0.8291855454444885, 0.8393664956092834, 0.831447958946228, 0.8337104320526123, 0.8303167223930359, 0.8337104320526123, 0.8337104320526123, 0.8404977321624756, 0.8337104320526123, 0.837104082107544, 0.8337104320526123, 0.831447958946228, 0.8269230723381042, 0.8382353186607361, 0.8325791954994202, 0.8291855454444885, 0.8359728455543518, 0.8223981857299805, 0.8280543088912964, 0.831447958946228, 0.8257918357849121, 0.8269230723381042, 0.8303167223930359, 0.8156108856201172, 0.820135772228241, 0.8246606588363647, 0.8280543088912964, 0.8246606588363647, 0.8212669491767883, 0.8223981857299805, 0.8257918357849121, 0.8223981857299805, 0.8235294222831726, 0.8246606588363647, 0.8257918357849121, 0.8190045356750488, 0.8223981857299805, 0.8257918357849121, 0.820135772228241, 0.8246606588363647, 0.8167420625686646, 0.814479649066925, 0.8088235259056091, 0.814479649066925, 0.8178732991218567, 0.8223981857299805, 0.8178732991218567, 0.8167420625686646, 0.8178732991218567, 0.8110859990119934, 0.8156108856201172, 0.8178732991218567, 0.8178732991218567, 0.8133484125137329, 0.8099547624588013, 0.814479649066925]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 5s 32ms/step - loss: 0.3905 - accuracy: 0.9636 - val_loss: 1.0934 - val_accuracy: 0.4948\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.3270 - accuracy: 0.9844"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 11ms/step - loss: 0.3459 - accuracy: 0.9778 - val_loss: 1.1111 - val_accuracy: 0.4938\n","Epoch 3/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3502 - accuracy: 0.9801 - val_loss: 1.1112 - val_accuracy: 0.4948\n","Epoch 4/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3335 - accuracy: 0.9845 - val_loss: 1.1102 - val_accuracy: 0.5000\n","Epoch 5/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3193 - accuracy: 0.9928 - val_loss: 1.1179 - val_accuracy: 0.4990\n","Epoch 6/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3245 - accuracy: 0.9876 - val_loss: 1.1167 - val_accuracy: 0.5021\n","Epoch 7/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3266 - accuracy: 0.9881 - val_loss: 1.1327 - val_accuracy: 0.5031\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3170 - accuracy: 0.9935 - val_loss: 1.1010 - val_accuracy: 0.5134\n","Epoch 9/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3220 - accuracy: 0.9891 - val_loss: 1.1284 - val_accuracy: 0.5155\n","Epoch 10/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3094 - accuracy: 0.9964 - val_loss: 1.1112 - val_accuracy: 0.5279\n","Epoch 11/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3079 - accuracy: 0.9979 - val_loss: 1.0352 - val_accuracy: 0.5568\n","Epoch 12/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3116 - accuracy: 0.9953 - val_loss: 1.0808 - val_accuracy: 0.5579\n","Epoch 13/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3066 - accuracy: 0.9979 - val_loss: 1.0292 - val_accuracy: 0.5868\n","Epoch 14/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3080 - accuracy: 0.9964 - val_loss: 0.9953 - val_accuracy: 0.6167\n","Epoch 15/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3051 - accuracy: 0.9982 - val_loss: 0.9194 - val_accuracy: 0.6849\n","Epoch 16/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3101 - accuracy: 0.9956 - val_loss: 0.9766 - val_accuracy: 0.6663\n","Epoch 17/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3027 - accuracy: 0.9982 - val_loss: 0.9049 - val_accuracy: 0.7138\n","Epoch 18/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3009 - accuracy: 0.9990 - val_loss: 0.8661 - val_accuracy: 0.7665\n","Epoch 19/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3020 - accuracy: 0.9979 - val_loss: 0.8971 - val_accuracy: 0.7603\n","Epoch 20/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2992 - accuracy: 0.9995 - val_loss: 0.8664 - val_accuracy: 0.8058\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3039 - accuracy: 0.9982 - val_loss: 0.9366 - val_accuracy: 0.7841\n","Epoch 22/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2993 - accuracy: 0.9995 - val_loss: 0.9394 - val_accuracy: 0.8048\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2985 - accuracy: 0.9990 - val_loss: 1.0151 - val_accuracy: 0.7779\n","Epoch 24/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3003 - accuracy: 0.9974 - val_loss: 0.9737 - val_accuracy: 0.8130\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2968 - accuracy: 0.9995 - val_loss: 1.0048 - val_accuracy: 0.8110\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2950 - accuracy: 0.9997 - val_loss: 1.0303 - val_accuracy: 0.8089\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2975 - accuracy: 0.9987 - val_loss: 1.0707 - val_accuracy: 0.8017\n","Epoch 28/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2940 - accuracy: 0.9997 - val_loss: 1.1082 - val_accuracy: 0.7903\n","Epoch 29/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2958 - accuracy: 0.9987 - val_loss: 1.0782 - val_accuracy: 0.8110\n","Epoch 30/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2943 - accuracy: 0.9992 - val_loss: 1.0705 - val_accuracy: 0.8161\n","Epoch 31/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2936 - accuracy: 0.9997 - val_loss: 1.0805 - val_accuracy: 0.8140\n","Epoch 32/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2916 - accuracy: 0.9992 - val_loss: 1.1046 - val_accuracy: 0.8058\n","Epoch 33/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2915 - accuracy: 0.9997 - val_loss: 1.1052 - val_accuracy: 0.8110\n","Epoch 34/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2982 - accuracy: 0.9979 - val_loss: 1.1975 - val_accuracy: 0.7758\n","Epoch 35/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2944 - accuracy: 0.9992 - val_loss: 1.1122 - val_accuracy: 0.8068\n","Epoch 36/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2905 - accuracy: 0.9992 - val_loss: 1.1138 - val_accuracy: 0.8058\n","Epoch 37/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2884 - accuracy: 1.0000 - val_loss: 1.1344 - val_accuracy: 0.8048\n","Epoch 38/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3063 - accuracy: 0.9925 - val_loss: 1.2701 - val_accuracy: 0.7831\n","Epoch 39/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3097 - accuracy: 0.9907 - val_loss: 1.1419 - val_accuracy: 0.7934\n","Epoch 40/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2940 - accuracy: 0.9990 - val_loss: 1.1217 - val_accuracy: 0.7955\n","Epoch 41/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2872 - accuracy: 1.0000 - val_loss: 1.1215 - val_accuracy: 0.8006\n","Epoch 42/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2868 - accuracy: 0.9997 - val_loss: 1.1515 - val_accuracy: 0.8058\n","Epoch 43/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2863 - accuracy: 0.9995 - val_loss: 1.1193 - val_accuracy: 0.8048\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2849 - accuracy: 1.0000 - val_loss: 1.1215 - val_accuracy: 0.8079\n","Epoch 45/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2841 - accuracy: 0.9997 - val_loss: 1.1272 - val_accuracy: 0.8027\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2843 - accuracy: 0.9997 - val_loss: 1.1276 - val_accuracy: 0.8027\n","Epoch 47/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2832 - accuracy: 1.0000 - val_loss: 1.1433 - val_accuracy: 0.8079\n","Epoch 48/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2847 - accuracy: 0.9997 - val_loss: 1.1364 - val_accuracy: 0.8058\n","Epoch 49/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2836 - accuracy: 0.9995 - val_loss: 1.1274 - val_accuracy: 0.8079\n","Epoch 50/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2874 - accuracy: 0.9995 - val_loss: 1.1359 - val_accuracy: 0.8027\n","Epoch 51/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2832 - accuracy: 0.9997 - val_loss: 1.1258 - val_accuracy: 0.8079\n","Epoch 52/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2804 - accuracy: 1.0000 - val_loss: 1.1381 - val_accuracy: 0.8006\n","Epoch 53/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2807 - accuracy: 0.9997 - val_loss: 1.1456 - val_accuracy: 0.7986\n","Epoch 54/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2797 - accuracy: 0.9997 - val_loss: 1.1413 - val_accuracy: 0.8120\n","Epoch 55/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2814 - accuracy: 0.9995 - val_loss: 1.1689 - val_accuracy: 0.8017\n","Epoch 56/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2792 - accuracy: 0.9997 - val_loss: 1.1474 - val_accuracy: 0.8027\n","Epoch 57/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2784 - accuracy: 1.0000 - val_loss: 1.1513 - val_accuracy: 0.8058\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2777 - accuracy: 1.0000 - val_loss: 1.1528 - val_accuracy: 0.7975\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2774 - accuracy: 0.9997 - val_loss: 1.1535 - val_accuracy: 0.8037\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2762 - accuracy: 1.0000 - val_loss: 1.1923 - val_accuracy: 0.7841\n","Epoch 61/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2792 - accuracy: 0.9995 - val_loss: 1.1501 - val_accuracy: 0.8058\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2769 - accuracy: 1.0000 - val_loss: 1.1833 - val_accuracy: 0.7913\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2781 - accuracy: 1.0000 - val_loss: 1.1598 - val_accuracy: 0.8037\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2809 - accuracy: 0.9984 - val_loss: 1.1554 - val_accuracy: 0.8027\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2751 - accuracy: 1.0000 - val_loss: 1.1478 - val_accuracy: 0.8027\n","Epoch 66/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2770 - accuracy: 0.9995 - val_loss: 1.1694 - val_accuracy: 0.8048\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2733 - accuracy: 1.0000 - val_loss: 1.1646 - val_accuracy: 0.7903\n","Epoch 68/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2728 - accuracy: 1.0000 - val_loss: 1.1749 - val_accuracy: 0.7996\n","Epoch 69/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2729 - accuracy: 1.0000 - val_loss: 1.1632 - val_accuracy: 0.8017\n","Epoch 70/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2748 - accuracy: 1.0000 - val_loss: 1.1752 - val_accuracy: 0.8068\n","Epoch 71/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2746 - accuracy: 0.9997 - val_loss: 1.1803 - val_accuracy: 0.7965\n","Epoch 72/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2709 - accuracy: 1.0000 - val_loss: 1.1752 - val_accuracy: 0.8027\n","Epoch 73/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2730 - accuracy: 0.9997 - val_loss: 1.1708 - val_accuracy: 0.8068\n","Epoch 74/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2707 - accuracy: 1.0000 - val_loss: 1.2004 - val_accuracy: 0.7975\n","Epoch 75/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2698 - accuracy: 1.0000 - val_loss: 1.1895 - val_accuracy: 0.7862\n","Epoch 76/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2731 - accuracy: 1.0000 - val_loss: 1.1835 - val_accuracy: 0.7975\n","Epoch 77/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2689 - accuracy: 1.0000 - val_loss: 1.1823 - val_accuracy: 0.8037\n","Epoch 78/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2689 - accuracy: 0.9997 - val_loss: 1.2020 - val_accuracy: 0.7955\n","Epoch 79/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2670 - accuracy: 1.0000 - val_loss: 1.1889 - val_accuracy: 0.8006\n","Epoch 80/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2677 - accuracy: 1.0000 - val_loss: 1.1876 - val_accuracy: 0.8017\n","Epoch 81/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2681 - accuracy: 0.9997 - val_loss: 1.2016 - val_accuracy: 0.7862\n","Epoch 82/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2661 - accuracy: 0.9997 - val_loss: 1.1882 - val_accuracy: 0.8048\n","Epoch 83/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2652 - accuracy: 1.0000 - val_loss: 1.1900 - val_accuracy: 0.8006\n","Epoch 84/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2655 - accuracy: 1.0000 - val_loss: 1.1996 - val_accuracy: 0.7975\n","Epoch 85/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2649 - accuracy: 1.0000 - val_loss: 1.2035 - val_accuracy: 0.7965\n","Epoch 86/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2656 - accuracy: 1.0000 - val_loss: 1.2125 - val_accuracy: 0.7975\n","Epoch 87/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2639 - accuracy: 1.0000 - val_loss: 1.2017 - val_accuracy: 0.7944\n","Epoch 88/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2641 - accuracy: 0.9997 - val_loss: 1.2042 - val_accuracy: 0.7862\n","Epoch 89/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2669 - accuracy: 0.9992 - val_loss: 1.2026 - val_accuracy: 0.7913\n","Epoch 90/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2622 - accuracy: 1.0000 - val_loss: 1.2042 - val_accuracy: 0.7893\n","Epoch 91/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2618 - accuracy: 1.0000 - val_loss: 1.2352 - val_accuracy: 0.7820\n","Epoch 92/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2630 - accuracy: 1.0000 - val_loss: 1.2285 - val_accuracy: 0.7944\n","Epoch 93/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2611 - accuracy: 1.0000 - val_loss: 1.2349 - val_accuracy: 0.7758\n","Epoch 94/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2614 - accuracy: 1.0000 - val_loss: 1.2081 - val_accuracy: 0.7934\n","Epoch 95/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2596 - accuracy: 1.0000 - val_loss: 1.3020 - val_accuracy: 0.7603\n","Epoch 96/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2602 - accuracy: 0.9997 - val_loss: 1.2139 - val_accuracy: 0.7955\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2578 - accuracy: 1.0000 - val_loss: 1.2167 - val_accuracy: 0.7800\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2573 - accuracy: 1.0000 - val_loss: 1.2199 - val_accuracy: 0.7944\n","Epoch 99/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2579 - accuracy: 1.0000 - val_loss: 1.2161 - val_accuracy: 0.7903\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2567 - accuracy: 1.0000 - val_loss: 1.2293 - val_accuracy: 0.7810\n","{'loss': [0.39045771956443787, 0.34591272473335266, 0.35021427273750305, 0.3335345387458801, 0.3193497359752655, 0.32453733682632446, 0.32660382986068726, 0.31700220704078674, 0.32195112109184265, 0.30942657589912415, 0.3079320192337036, 0.3116271495819092, 0.30657321214675903, 0.3080439567565918, 0.30510634183883667, 0.3100510239601135, 0.30268338322639465, 0.30093827843666077, 0.3020446300506592, 0.29916733503341675, 0.3038533329963684, 0.29932114481925964, 0.2985425293445587, 0.30025726556777954, 0.29683417081832886, 0.29504793882369995, 0.2974961996078491, 0.29404205083847046, 0.29582691192626953, 0.29428666830062866, 0.29360976815223694, 0.2916407585144043, 0.2914731502532959, 0.29819685220718384, 0.2943718433380127, 0.2905227243900299, 0.28844398260116577, 0.30625325441360474, 0.3097039759159088, 0.29399555921554565, 0.2871580123901367, 0.28676271438598633, 0.2863459289073944, 0.2848542630672455, 0.28406959772109985, 0.28431111574172974, 0.2831791937351227, 0.2846613824367523, 0.28362950682640076, 0.28737008571624756, 0.2831766605377197, 0.28044307231903076, 0.28068968653678894, 0.2797352373600006, 0.2813836634159088, 0.2792390286922455, 0.2783847153186798, 0.2776944935321808, 0.27744320034980774, 0.27624255418777466, 0.27920034527778625, 0.27686718106269836, 0.27812907099723816, 0.28092849254608154, 0.2750728726387024, 0.27699121832847595, 0.2732888460159302, 0.27283206582069397, 0.272921085357666, 0.2748136520385742, 0.2745541036128998, 0.270860880613327, 0.2729858160018921, 0.2707129418849945, 0.26975181698799133, 0.27312976121902466, 0.26891815662384033, 0.26890829205513, 0.2669936716556549, 0.26773539185523987, 0.26811182498931885, 0.2660967707633972, 0.265193909406662, 0.2655191719532013, 0.2648775577545166, 0.2655702531337738, 0.2639347016811371, 0.26407191157341003, 0.26687508821487427, 0.26223623752593994, 0.261785626411438, 0.26298999786376953, 0.2611348330974579, 0.261394739151001, 0.25955983996391296, 0.26021263003349304, 0.2577659487724304, 0.25730079412460327, 0.257856160402298, 0.25671836733818054], 'accuracy': [0.9635658860206604, 0.9777777791023254, 0.9801033735275269, 0.9844961166381836, 0.9927648305892944, 0.987596869468689, 0.9881137013435364, 0.9935400485992432, 0.9891473054885864, 0.9963824152946472, 0.9979327917098999, 0.9953488111495972, 0.9979327917098999, 0.9963824152946472, 0.998191237449646, 0.9956072568893433, 0.998191237449646, 0.99896639585495, 0.9979327917098999, 0.9994832277297974, 0.998191237449646, 0.9994832277297974, 0.99896639585495, 0.9974160194396973, 0.9994832277297974, 0.9997416138648987, 0.9987080097198486, 0.9997416138648987, 0.9987080097198486, 0.9992247819900513, 0.9997416138648987, 0.9992247819900513, 0.9997416138648987, 0.9979327917098999, 0.9992247819900513, 0.9992247819900513, 1.0, 0.9925064444541931, 0.9906976819038391, 0.99896639585495, 1.0, 0.9997416138648987, 0.9994832277297974, 1.0, 0.9997416138648987, 0.9997416138648987, 1.0, 0.9997416138648987, 0.9994832277297974, 0.9994832277297974, 0.9997416138648987, 1.0, 0.9997416138648987, 0.9997416138648987, 0.9994832277297974, 0.9997416138648987, 1.0, 1.0, 0.9997416138648987, 1.0, 0.9994832277297974, 1.0, 1.0, 0.9984496235847473, 1.0, 0.9994832277297974, 1.0, 1.0, 1.0, 1.0, 0.9997416138648987, 1.0, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 0.9997416138648987, 1.0, 1.0, 0.9997416138648987, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997416138648987, 0.9992247819900513, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0], 'val_loss': [1.093361735343933, 1.1111340522766113, 1.1112449169158936, 1.1102079153060913, 1.117902398109436, 1.1167163848876953, 1.1327300071716309, 1.100964069366455, 1.1284351348876953, 1.1112140417099, 1.0352073907852173, 1.0807502269744873, 1.0292267799377441, 0.9953154921531677, 0.9193753600120544, 0.9766321778297424, 0.9049161672592163, 0.866090714931488, 0.8971162438392639, 0.8664131760597229, 0.9366412162780762, 0.9393559098243713, 1.0150723457336426, 0.9736970067024231, 1.004762887954712, 1.0303300619125366, 1.0706851482391357, 1.1082396507263184, 1.0781886577606201, 1.0704684257507324, 1.0804741382598877, 1.104628562927246, 1.1052463054656982, 1.197493553161621, 1.112203598022461, 1.1138458251953125, 1.1343708038330078, 1.2700637578964233, 1.1419193744659424, 1.121659755706787, 1.121535062789917, 1.151489496231079, 1.1193114519119263, 1.1214635372161865, 1.1272342205047607, 1.1276458501815796, 1.1432905197143555, 1.1363747119903564, 1.1274470090866089, 1.1359472274780273, 1.1258366107940674, 1.138062834739685, 1.1456313133239746, 1.1413482427597046, 1.1688792705535889, 1.1474360227584839, 1.1512815952301025, 1.152775526046753, 1.1535264253616333, 1.1923182010650635, 1.150091290473938, 1.1832941770553589, 1.1597586870193481, 1.1554142236709595, 1.1478327512741089, 1.1693575382232666, 1.1645804643630981, 1.1748533248901367, 1.1632347106933594, 1.1752320528030396, 1.180290937423706, 1.1751879453659058, 1.1707870960235596, 1.200372576713562, 1.1895115375518799, 1.1834936141967773, 1.1822822093963623, 1.2019628286361694, 1.1888729333877563, 1.1875958442687988, 1.2015503644943237, 1.1881980895996094, 1.190002202987671, 1.1995724439620972, 1.2034512758255005, 1.2125343084335327, 1.201744794845581, 1.204240083694458, 1.2026101350784302, 1.2041577100753784, 1.2351696491241455, 1.2285466194152832, 1.2349176406860352, 1.2081342935562134, 1.3019886016845703, 1.2139486074447632, 1.2167472839355469, 1.219868540763855, 1.2161312103271484, 1.2293453216552734], 'val_accuracy': [0.4948347210884094, 0.49380165338516235, 0.4948347210884094, 0.5, 0.49896693229675293, 0.5020661354064941, 0.5030992031097412, 0.5134297609329224, 0.5154958963394165, 0.5278925895690918, 0.5568181872367859, 0.557851254940033, 0.586776852607727, 0.6167355179786682, 0.6849173307418823, 0.6663222908973694, 0.7138429880142212, 0.7665289044380188, 0.7603305578231812, 0.8057851195335388, 0.7840909361839294, 0.8047520518302917, 0.7778925895690918, 0.8130165338516235, 0.8109503984451294, 0.80888432264328, 0.8016529083251953, 0.7902892827987671, 0.8109503984451294, 0.81611567735672, 0.8140496015548706, 0.8057851195335388, 0.8109503984451294, 0.7758264541625977, 0.8068181872367859, 0.8057851195335388, 0.8047520518302917, 0.7830578684806824, 0.7933884263038635, 0.7954545617103577, 0.8006198406219482, 0.8057851195335388, 0.8047520518302917, 0.807851254940033, 0.8026859760284424, 0.8026859760284424, 0.807851254940033, 0.8057851195335388, 0.807851254940033, 0.8026859760284424, 0.807851254940033, 0.8006198406219482, 0.7985537052154541, 0.8119834661483765, 0.8016529083251953, 0.8026859760284424, 0.8057851195335388, 0.797520637512207, 0.8037189841270447, 0.7840909361839294, 0.8057851195335388, 0.7913222908973694, 0.8037189841270447, 0.8026859760284424, 0.8026859760284424, 0.8047520518302917, 0.7902892827987671, 0.7995867729187012, 0.8016529083251953, 0.8068181872367859, 0.7964876294136047, 0.8026859760284424, 0.8068181872367859, 0.797520637512207, 0.7861570119857788, 0.797520637512207, 0.8037189841270447, 0.7954545617103577, 0.8006198406219482, 0.8016529083251953, 0.7861570119857788, 0.8047520518302917, 0.8006198406219482, 0.797520637512207, 0.7964876294136047, 0.797520637512207, 0.7944214940071106, 0.7861570119857788, 0.7913222908973694, 0.78925621509552, 0.7820248007774353, 0.7944214940071106, 0.7758264541625977, 0.7933884263038635, 0.7603305578231812, 0.7954545617103577, 0.7799586653709412, 0.7944214940071106, 0.7902892827987671, 0.7809917330741882]}\n","32/32 [==============================] - 0s 3ms/step\n"]}]},{"cell_type":"code","source":["metrics_df_CNN.round(3)"],"metadata":{"id":"y3RXIk-qZ7ts","colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"status":"ok","timestamp":1717434991059,"user_tz":-360,"elapsed":15,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"c1f39309-7ee2-4aa5-e714-c9f8944c94fe"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.532      0.536   0.471  0.501        0.471        0.593   \n","1        1     0.556      0.590   0.364  0.451        0.364        0.747   \n","2        2     0.557      0.566   0.488  0.524        0.488        0.627   \n","3        0     0.600      0.607   0.564  0.585        0.564        0.635   \n","4        1     0.635      0.660   0.556  0.604        0.556        0.713   \n","5        2     0.676      0.691   0.635  0.662        0.635        0.717   \n","6        0     0.684      0.699   0.647  0.672        0.647        0.722   \n","7        1     0.717      0.715   0.722  0.718        0.722        0.712   \n","8        2     0.746      0.782   0.683  0.729        0.683        0.809   \n","9        0     0.764      0.739   0.816  0.775        0.816        0.712   \n","10       1     0.768      0.775   0.756  0.765        0.756        0.781   \n","11       2     0.799      0.840   0.739  0.786        0.739        0.859   \n","12       0     0.806      0.815   0.791  0.803        0.791        0.821   \n","13       1     0.803      0.802   0.805  0.803        0.805        0.801   \n","14       2     0.844      0.851   0.835  0.843        0.835        0.853   \n","\n","    Kappa  \n","0   0.064  \n","1   0.112  \n","2   0.114  \n","3   0.199  \n","4   0.270  \n","5   0.351  \n","6   0.369  \n","7   0.434  \n","8   0.492  \n","9   0.528  \n","10  0.537  \n","11  0.598  \n","12  0.611  \n","13  0.606  \n","14  0.689  "],"text/html":["\n","  <div id=\"df-e9ef425e-0dd6-4d79-ab3c-15a70fe5f60b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.532</td>\n","      <td>0.536</td>\n","      <td>0.471</td>\n","      <td>0.501</td>\n","      <td>0.471</td>\n","      <td>0.593</td>\n","      <td>0.064</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.556</td>\n","      <td>0.590</td>\n","      <td>0.364</td>\n","      <td>0.451</td>\n","      <td>0.364</td>\n","      <td>0.747</td>\n","      <td>0.112</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.557</td>\n","      <td>0.566</td>\n","      <td>0.488</td>\n","      <td>0.524</td>\n","      <td>0.488</td>\n","      <td>0.627</td>\n","      <td>0.114</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.600</td>\n","      <td>0.607</td>\n","      <td>0.564</td>\n","      <td>0.585</td>\n","      <td>0.564</td>\n","      <td>0.635</td>\n","      <td>0.199</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.635</td>\n","      <td>0.660</td>\n","      <td>0.556</td>\n","      <td>0.604</td>\n","      <td>0.556</td>\n","      <td>0.713</td>\n","      <td>0.270</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.676</td>\n","      <td>0.691</td>\n","      <td>0.635</td>\n","      <td>0.662</td>\n","      <td>0.635</td>\n","      <td>0.717</td>\n","      <td>0.351</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.684</td>\n","      <td>0.699</td>\n","      <td>0.647</td>\n","      <td>0.672</td>\n","      <td>0.647</td>\n","      <td>0.722</td>\n","      <td>0.369</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.717</td>\n","      <td>0.715</td>\n","      <td>0.722</td>\n","      <td>0.718</td>\n","      <td>0.722</td>\n","      <td>0.712</td>\n","      <td>0.434</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.746</td>\n","      <td>0.782</td>\n","      <td>0.683</td>\n","      <td>0.729</td>\n","      <td>0.683</td>\n","      <td>0.809</td>\n","      <td>0.492</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.764</td>\n","      <td>0.739</td>\n","      <td>0.816</td>\n","      <td>0.775</td>\n","      <td>0.816</td>\n","      <td>0.712</td>\n","      <td>0.528</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.768</td>\n","      <td>0.775</td>\n","      <td>0.756</td>\n","      <td>0.765</td>\n","      <td>0.756</td>\n","      <td>0.781</td>\n","      <td>0.537</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.799</td>\n","      <td>0.840</td>\n","      <td>0.739</td>\n","      <td>0.786</td>\n","      <td>0.739</td>\n","      <td>0.859</td>\n","      <td>0.598</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.806</td>\n","      <td>0.815</td>\n","      <td>0.791</td>\n","      <td>0.803</td>\n","      <td>0.791</td>\n","      <td>0.821</td>\n","      <td>0.611</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.803</td>\n","      <td>0.802</td>\n","      <td>0.805</td>\n","      <td>0.803</td>\n","      <td>0.805</td>\n","      <td>0.801</td>\n","      <td>0.606</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.844</td>\n","      <td>0.851</td>\n","      <td>0.835</td>\n","      <td>0.843</td>\n","      <td>0.835</td>\n","      <td>0.853</td>\n","      <td>0.689</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9ef425e-0dd6-4d79-ab3c-15a70fe5f60b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e9ef425e-0dd6-4d79-ab3c-15a70fe5f60b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e9ef425e-0dd6-4d79-ab3c-15a70fe5f60b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f9ecb461-0d9c-4548-bd97-a7f4c20a00bd\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f9ecb461-0d9c-4548-bd97-a7f4c20a00bd')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f9ecb461-0d9c-4548-bd97-a7f4c20a00bd button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df_CNN\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10280415963420565,\n        \"min\": 0.532,\n        \"max\": 0.844,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.764,\n          0.799,\n          0.532\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10195461175024334,\n        \"min\": 0.536,\n        \"max\": 0.851,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.739,\n          0.84,\n          0.536\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14309630456777137,\n        \"min\": 0.364,\n        \"max\": 0.835,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.816,\n          0.739,\n          0.471\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12309566546854059,\n        \"min\": 0.451,\n        \"max\": 0.843,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.775,\n          0.786,\n          0.501\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14309630456777137,\n        \"min\": 0.364,\n        \"max\": 0.835,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.816,\n          0.739,\n          0.471\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08117693784625803,\n        \"min\": 0.593,\n        \"max\": 0.859,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.781,\n          0.821,\n          0.593\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20575799469510872,\n        \"min\": 0.064,\n        \"max\": 0.689,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.528,\n          0.598,\n          0.064\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["metrics_df_CNN.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Frequency Domain/CNN/Alpha_frequency_CNN.csv', index = False)"],"metadata":{"id":"_iOLsKpkfzdG","executionInfo":{"status":"ok","timestamp":1717434991060,"user_tz":-360,"elapsed":14,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["# GRU"],"metadata":{"id":"8qX-s03nCx70"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout, GRU\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model_gru(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(GRU(256, return_sequences=True))\n","    model.add(GRU(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning_gru(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model_gru(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model_gru(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Alpha/CNN_GRU/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Alpha/CNN_GRU/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"ieXSN-9PI4Dx","executionInfo":{"status":"ok","timestamp":1717434991062,"user_tz":-360,"elapsed":16,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["global_model_gru, metrics_df_gru = federated_learning_gru(Theta_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MCnhrX4sC-vB","executionInfo":{"status":"ok","timestamp":1717436211524,"user_tz":-360,"elapsed":1220478,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"11898952-b7ff-4260-ac92-765e3271cfeb"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 1.4334 - accuracy: 0.5030"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 67ms/step - loss: 1.4334 - accuracy: 0.5030 - val_loss: 1.4302 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.4271 - accuracy: 0.5046 - val_loss: 1.4241 - val_accuracy: 0.5065\n","Epoch 3/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4212 - accuracy: 0.5038 - val_loss: 1.4181 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4151 - accuracy: 0.5059 - val_loss: 1.4121 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4091 - accuracy: 0.5040 - val_loss: 1.4062 - val_accuracy: 0.4806\n","Epoch 6/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.4032 - accuracy: 0.5043 - val_loss: 1.4003 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3972 - accuracy: 0.5054 - val_loss: 1.3944 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.3914 - accuracy: 0.5038 - val_loss: 1.3887 - val_accuracy: 0.4849\n","Epoch 9/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3855 - accuracy: 0.5054 - val_loss: 1.3829 - val_accuracy: 0.4849\n","Epoch 10/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3798 - accuracy: 0.5057 - val_loss: 1.3772 - val_accuracy: 0.4860\n","Epoch 11/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3740 - accuracy: 0.5097 - val_loss: 1.3715 - val_accuracy: 0.4860\n","Epoch 12/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.3682 - accuracy: 0.5086 - val_loss: 1.3659 - val_accuracy: 0.4860\n","Epoch 13/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3625 - accuracy: 0.5078 - val_loss: 1.3603 - val_accuracy: 0.4860\n","Epoch 14/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3570 - accuracy: 0.5081 - val_loss: 1.3547 - val_accuracy: 0.4849\n","Epoch 15/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3512 - accuracy: 0.5127 - val_loss: 1.3493 - val_accuracy: 0.4849\n","Epoch 16/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.3458 - accuracy: 0.5170 - val_loss: 1.3438 - val_accuracy: 0.4849\n","Epoch 17/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.3402 - accuracy: 0.5191 - val_loss: 1.3383 - val_accuracy: 0.4935\n","Epoch 18/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.3345 - accuracy: 0.5358 - val_loss: 1.3329 - val_accuracy: 0.5453\n","Epoch 19/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.3292 - accuracy: 0.5277 - val_loss: 1.3275 - val_accuracy: 0.5463\n","Epoch 20/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3235 - accuracy: 0.5358 - val_loss: 1.3222 - val_accuracy: 0.5032\n","Epoch 21/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.3180 - accuracy: 0.5442 - val_loss: 1.3169 - val_accuracy: 0.5431\n","Epoch 22/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3125 - accuracy: 0.5501 - val_loss: 1.3115 - val_accuracy: 0.5420\n","Epoch 23/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.3070 - accuracy: 0.5638 - val_loss: 1.3063 - val_accuracy: 0.5517\n","Epoch 24/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.3014 - accuracy: 0.5531 - val_loss: 1.3011 - val_accuracy: 0.5442\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2956 - accuracy: 0.5733 - val_loss: 1.2957 - val_accuracy: 0.5506\n","Epoch 26/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.2900 - accuracy: 0.5647 - val_loss: 1.2901 - val_accuracy: 0.5528\n","Epoch 27/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.2846 - accuracy: 0.5719 - val_loss: 1.2846 - val_accuracy: 0.5593\n","Epoch 28/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.2787 - accuracy: 0.5711 - val_loss: 1.2799 - val_accuracy: 0.5625\n","Epoch 29/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2726 - accuracy: 0.5773 - val_loss: 1.2745 - val_accuracy: 0.5517\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2667 - accuracy: 0.5830 - val_loss: 1.2703 - val_accuracy: 0.5431\n","Epoch 31/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.2605 - accuracy: 0.5738 - val_loss: 1.2633 - val_accuracy: 0.5647\n","Epoch 32/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.2530 - accuracy: 0.5897 - val_loss: 1.2581 - val_accuracy: 0.5668\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2477 - accuracy: 0.5878 - val_loss: 1.2529 - val_accuracy: 0.5560\n","Epoch 34/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.2409 - accuracy: 0.5935 - val_loss: 1.2476 - val_accuracy: 0.5593\n","Epoch 35/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2343 - accuracy: 0.5849 - val_loss: 1.2433 - val_accuracy: 0.5550\n","Epoch 36/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.2286 - accuracy: 0.5940 - val_loss: 1.2380 - val_accuracy: 0.5733\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2201 - accuracy: 0.6048 - val_loss: 1.2352 - val_accuracy: 0.5679\n","Epoch 38/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2138 - accuracy: 0.5959 - val_loss: 1.2299 - val_accuracy: 0.5744\n","Epoch 39/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.2087 - accuracy: 0.6010 - val_loss: 1.2249 - val_accuracy: 0.5787\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2005 - accuracy: 0.6040 - val_loss: 1.2208 - val_accuracy: 0.5722\n","Epoch 41/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1946 - accuracy: 0.6002 - val_loss: 1.2214 - val_accuracy: 0.5679\n","Epoch 42/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.1847 - accuracy: 0.6228 - val_loss: 1.2141 - val_accuracy: 0.5819\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1778 - accuracy: 0.6215 - val_loss: 1.2104 - val_accuracy: 0.5700\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1705 - accuracy: 0.6220 - val_loss: 1.2052 - val_accuracy: 0.5797\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1648 - accuracy: 0.6212 - val_loss: 1.2058 - val_accuracy: 0.5808\n","Epoch 46/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1548 - accuracy: 0.6387 - val_loss: 1.1985 - val_accuracy: 0.5873\n","Epoch 47/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1494 - accuracy: 0.6350 - val_loss: 1.1976 - val_accuracy: 0.5916\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1405 - accuracy: 0.6441 - val_loss: 1.1943 - val_accuracy: 0.5916\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1299 - accuracy: 0.6571 - val_loss: 1.1905 - val_accuracy: 0.5862\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1270 - accuracy: 0.6554 - val_loss: 1.2074 - val_accuracy: 0.5485\n","Epoch 51/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1168 - accuracy: 0.6592 - val_loss: 1.1866 - val_accuracy: 0.5959\n","Epoch 52/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1091 - accuracy: 0.6633 - val_loss: 1.1827 - val_accuracy: 0.5927\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1030 - accuracy: 0.6633 - val_loss: 1.1873 - val_accuracy: 0.5819\n","Epoch 54/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0985 - accuracy: 0.6643 - val_loss: 1.1767 - val_accuracy: 0.5894\n","Epoch 55/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0881 - accuracy: 0.6786 - val_loss: 1.1740 - val_accuracy: 0.5959\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0762 - accuracy: 0.6845 - val_loss: 1.1793 - val_accuracy: 0.5722\n","Epoch 57/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0738 - accuracy: 0.6840 - val_loss: 1.1715 - val_accuracy: 0.6013\n","Epoch 58/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0709 - accuracy: 0.6756 - val_loss: 1.1706 - val_accuracy: 0.5851\n","Epoch 59/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.0628 - accuracy: 0.6894 - val_loss: 1.1665 - val_accuracy: 0.5948\n","Epoch 60/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.0519 - accuracy: 0.6956 - val_loss: 1.1661 - val_accuracy: 0.6024\n","Epoch 61/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.0469 - accuracy: 0.6945 - val_loss: 1.1647 - val_accuracy: 0.5927\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0367 - accuracy: 0.7034 - val_loss: 1.1754 - val_accuracy: 0.5894\n","Epoch 63/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.0343 - accuracy: 0.7007 - val_loss: 1.1617 - val_accuracy: 0.6034\n","Epoch 64/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.0330 - accuracy: 0.6945 - val_loss: 1.1583 - val_accuracy: 0.5905\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0173 - accuracy: 0.7115 - val_loss: 1.1576 - val_accuracy: 0.5916\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0074 - accuracy: 0.7126 - val_loss: 1.1622 - val_accuracy: 0.5830\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0020 - accuracy: 0.7223 - val_loss: 1.1574 - val_accuracy: 0.6034\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9975 - accuracy: 0.7182 - val_loss: 1.1574 - val_accuracy: 0.5862\n","Epoch 69/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9880 - accuracy: 0.7314 - val_loss: 1.1605 - val_accuracy: 0.5830\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9813 - accuracy: 0.7287 - val_loss: 1.1587 - val_accuracy: 0.6024\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9761 - accuracy: 0.7284 - val_loss: 1.1634 - val_accuracy: 0.5841\n","Epoch 72/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9709 - accuracy: 0.7338 - val_loss: 1.1591 - val_accuracy: 0.5959\n","Epoch 73/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9587 - accuracy: 0.7425 - val_loss: 1.1605 - val_accuracy: 0.5884\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9568 - accuracy: 0.7376 - val_loss: 1.1607 - val_accuracy: 0.5841\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9475 - accuracy: 0.7422 - val_loss: 1.1620 - val_accuracy: 0.5916\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9381 - accuracy: 0.7540 - val_loss: 1.1700 - val_accuracy: 0.5959\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9334 - accuracy: 0.7460 - val_loss: 1.1656 - val_accuracy: 0.5981\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9312 - accuracy: 0.7575 - val_loss: 1.1684 - val_accuracy: 0.5938\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9217 - accuracy: 0.7543 - val_loss: 1.2064 - val_accuracy: 0.5722\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9091 - accuracy: 0.7602 - val_loss: 1.1615 - val_accuracy: 0.5916\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9025 - accuracy: 0.7721 - val_loss: 1.1693 - val_accuracy: 0.5851\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8975 - accuracy: 0.7697 - val_loss: 1.1678 - val_accuracy: 0.5851\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8937 - accuracy: 0.7624 - val_loss: 1.1703 - val_accuracy: 0.5884\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8895 - accuracy: 0.7616 - val_loss: 1.1636 - val_accuracy: 0.5916\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8865 - accuracy: 0.7707 - val_loss: 1.1642 - val_accuracy: 0.5981\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8674 - accuracy: 0.7834 - val_loss: 1.1725 - val_accuracy: 0.5927\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8605 - accuracy: 0.7869 - val_loss: 1.1679 - val_accuracy: 0.5981\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8623 - accuracy: 0.7769 - val_loss: 1.1901 - val_accuracy: 0.5873\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8534 - accuracy: 0.7815 - val_loss: 1.1725 - val_accuracy: 0.5991\n","Epoch 90/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8413 - accuracy: 0.7923 - val_loss: 1.1786 - val_accuracy: 0.5948\n","Epoch 91/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8363 - accuracy: 0.7955 - val_loss: 1.1788 - val_accuracy: 0.5959\n","Epoch 92/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8319 - accuracy: 0.7980 - val_loss: 1.1903 - val_accuracy: 0.5894\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8240 - accuracy: 0.8012 - val_loss: 1.1821 - val_accuracy: 0.5970\n","Epoch 94/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8184 - accuracy: 0.8039 - val_loss: 1.1828 - val_accuracy: 0.5948\n","Epoch 95/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8110 - accuracy: 0.8044 - val_loss: 1.1887 - val_accuracy: 0.5905\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8084 - accuracy: 0.8063 - val_loss: 1.1995 - val_accuracy: 0.5916\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8077 - accuracy: 0.8090 - val_loss: 1.2271 - val_accuracy: 0.5754\n","Epoch 98/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7893 - accuracy: 0.8165 - val_loss: 1.2053 - val_accuracy: 0.5841\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7802 - accuracy: 0.8246 - val_loss: 1.2072 - val_accuracy: 0.5851\n","Epoch 100/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7778 - accuracy: 0.8211 - val_loss: 1.1992 - val_accuracy: 0.5894\n","{'loss': [1.4333817958831787, 1.4271490573883057, 1.4211561679840088, 1.4150594472885132, 1.4090700149536133, 1.403152346611023, 1.3972450494766235, 1.3914015293121338, 1.385514497756958, 1.3797862529754639, 1.3739895820617676, 1.3681550025939941, 1.36252760887146, 1.3570058345794678, 1.3512136936187744, 1.3457742929458618, 1.3401955366134644, 1.3345441818237305, 1.3291605710983276, 1.323536992073059, 1.3180139064788818, 1.3125327825546265, 1.3069671392440796, 1.3014196157455444, 1.2955834865570068, 1.2900261878967285, 1.284557580947876, 1.2787024974822998, 1.2725943326950073, 1.2667371034622192, 1.2604916095733643, 1.2530094385147095, 1.2476779222488403, 1.2408697605133057, 1.234289288520813, 1.2285549640655518, 1.2200888395309448, 1.2137784957885742, 1.2086702585220337, 1.2004883289337158, 1.194572925567627, 1.1847431659698486, 1.177783489227295, 1.1704621315002441, 1.1648049354553223, 1.1547683477401733, 1.1494115591049194, 1.140465497970581, 1.1298531293869019, 1.1270065307617188, 1.1168338060379028, 1.1091116666793823, 1.1030244827270508, 1.0984892845153809, 1.0881435871124268, 1.0761699676513672, 1.073810338973999, 1.0708825588226318, 1.06281316280365, 1.051883578300476, 1.046873927116394, 1.0367351770401, 1.0342557430267334, 1.0330400466918945, 1.0173388719558716, 1.0074031352996826, 1.0020331144332886, 0.9974625706672668, 0.988038182258606, 0.9812741875648499, 0.9761061072349548, 0.9708510041236877, 0.9586859345436096, 0.9567644000053406, 0.9475265741348267, 0.9381285905838013, 0.9333871603012085, 0.9311875700950623, 0.9217378497123718, 0.9090690016746521, 0.9025466442108154, 0.8974528908729553, 0.8937366008758545, 0.8894652724266052, 0.8865141868591309, 0.8673517107963562, 0.8605039119720459, 0.8623301386833191, 0.8534054756164551, 0.841254711151123, 0.8362729549407959, 0.8318576216697693, 0.8239915370941162, 0.8183573484420776, 0.81099534034729, 0.8083933591842651, 0.8076863884925842, 0.7893116474151611, 0.7801799774169922, 0.7777918577194214], 'accuracy': [0.5029633641242981, 0.5045797228813171, 0.5037715435028076, 0.5059267282485962, 0.5040409564971924, 0.5043103694915771, 0.5053879022598267, 0.5037715435028076, 0.5053879022598267, 0.5056573152542114, 0.5096982717514038, 0.5086206793785095, 0.5078125, 0.5080819129943848, 0.5126616358757019, 0.516972005367279, 0.5191271305084229, 0.5358297228813171, 0.5277478694915771, 0.5358297228813171, 0.5441810488700867, 0.5501077771186829, 0.563847005367279, 0.553071141242981, 0.5732758641242981, 0.5646551847457886, 0.571928858757019, 0.5711206793785095, 0.5773168206214905, 0.5829741358757019, 0.5738146305084229, 0.5897090435028076, 0.5878232717514038, 0.5934805870056152, 0.5848599076271057, 0.5940194129943848, 0.6047952771186829, 0.5959051847457886, 0.6010237336158752, 0.6039870977401733, 0.600215494632721, 0.6228448152542114, 0.6214978694915771, 0.6220366358757019, 0.6212284564971924, 0.6387392282485962, 0.6349676847457886, 0.6441271305084229, 0.6570581793785095, 0.6554418206214905, 0.6592133641242981, 0.6632543206214905, 0.6632543206214905, 0.6643319129943848, 0.6786099076271057, 0.6845366358757019, 0.6839978694915771, 0.6756465435028076, 0.6893857717514038, 0.6955819129943848, 0.6945043206214905, 0.7033944129943848, 0.7007004022598267, 0.6945043206214905, 0.7114762663841248, 0.712553858757019, 0.7222521305084229, 0.7182112336158752, 0.7314116358757019, 0.7287176847457886, 0.7284482717514038, 0.7338362336158752, 0.7424569129943848, 0.7376077771186829, 0.7421875, 0.7540409564971924, 0.7459590435028076, 0.7575430870056152, 0.7543103694915771, 0.7602370977401733, 0.772090494632721, 0.7696659564971924, 0.7623922228813171, 0.7615840435028076, 0.7707435488700867, 0.7834051847457886, 0.7869073152542114, 0.7769396305084229, 0.7815194129943848, 0.7922952771186829, 0.795527994632721, 0.7979525923728943, 0.8011853694915771, 0.8038793206214905, 0.8044180870056152, 0.806303858757019, 0.8089978694915771, 0.8165409564971924, 0.8246228694915771, 0.8211206793785095], 'val_loss': [1.4302300214767456, 1.424136757850647, 1.4181010723114014, 1.412112832069397, 1.4061622619628906, 1.4002803564071655, 1.3944381475448608, 1.388655424118042, 1.3828938007354736, 1.3771674633026123, 1.371493935585022, 1.3658639192581177, 1.3603228330612183, 1.354737401008606, 1.3492658138275146, 1.3438361883163452, 1.3383290767669678, 1.3328853845596313, 1.3274829387664795, 1.322247862815857, 1.3168631792068481, 1.3114819526672363, 1.3062894344329834, 1.3011068105697632, 1.2957093715667725, 1.2901440858840942, 1.2846311330795288, 1.27994966506958, 1.2745190858840942, 1.2703419923782349, 1.2633475065231323, 1.258051872253418, 1.2528899908065796, 1.2475738525390625, 1.2432959079742432, 1.238007664680481, 1.2352279424667358, 1.2299206256866455, 1.2248598337173462, 1.2208136320114136, 1.221442461013794, 1.214074969291687, 1.21043860912323, 1.2051506042480469, 1.2058435678482056, 1.1985243558883667, 1.1975789070129395, 1.1942918300628662, 1.1904950141906738, 1.2074004411697388, 1.186648964881897, 1.1826647520065308, 1.1873457431793213, 1.1767154932022095, 1.1740180253982544, 1.179288387298584, 1.171505093574524, 1.1705845594406128, 1.1664903163909912, 1.1660813093185425, 1.164668083190918, 1.175363302230835, 1.1617352962493896, 1.1583164930343628, 1.1576178073883057, 1.1621638536453247, 1.1573786735534668, 1.1574186086654663, 1.1605199575424194, 1.1587374210357666, 1.1633933782577515, 1.159056305885315, 1.1605387926101685, 1.1606593132019043, 1.1620073318481445, 1.1700340509414673, 1.1655926704406738, 1.1684354543685913, 1.206418752670288, 1.1615362167358398, 1.1692999601364136, 1.167754888534546, 1.170300006866455, 1.1635924577713013, 1.1641945838928223, 1.1725425720214844, 1.1678924560546875, 1.1901079416275024, 1.1724649667739868, 1.178592324256897, 1.1787714958190918, 1.1902999877929688, 1.1821433305740356, 1.1827795505523682, 1.188714623451233, 1.199488878250122, 1.227091908454895, 1.205293893814087, 1.2071737051010132, 1.1991972923278809], 'val_accuracy': [0.48491379618644714, 0.506465494632721, 0.48491379618644714, 0.48491379618644714, 0.4806034564971924, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.49353447556495667, 0.545258641242981, 0.5463362336158752, 0.5032327771186829, 0.5431034564971924, 0.5420258641242981, 0.5517241358757019, 0.5441810488700867, 0.5506465435028076, 0.5528017282485962, 0.5592672228813171, 0.5625, 0.5517241358757019, 0.5431034564971924, 0.5646551847457886, 0.5668103694915771, 0.556034505367279, 0.5592672228813171, 0.5549569129943848, 0.5732758641242981, 0.5678879022598267, 0.5743534564971924, 0.5786637663841248, 0.5721982717514038, 0.5678879022598267, 0.5818965435028076, 0.5700430870056152, 0.579741358757019, 0.5808189511299133, 0.587284505367279, 0.5915948152542114, 0.5915948152542114, 0.5862069129943848, 0.548491358757019, 0.5959051847457886, 0.5926724076271057, 0.5818965435028076, 0.5894396305084229, 0.5959051847457886, 0.5721982717514038, 0.6012930870056152, 0.5851293206214905, 0.5948275923728943, 0.6023706793785095, 0.5926724076271057, 0.5894396305084229, 0.6034482717514038, 0.5905172228813171, 0.5915948152542114, 0.5829741358757019, 0.6034482717514038, 0.5862069129943848, 0.5829741358757019, 0.6023706793785095, 0.5840517282485962, 0.5959051847457886, 0.5883620977401733, 0.5840517282485962, 0.5915948152542114, 0.5959051847457886, 0.5980603694915771, 0.59375, 0.5721982717514038, 0.5915948152542114, 0.5851293206214905, 0.5851293206214905, 0.5883620977401733, 0.5915948152542114, 0.5980603694915771, 0.5926724076271057, 0.5980603694915771, 0.587284505367279, 0.5991379022598267, 0.5948275923728943, 0.5959051847457886, 0.5894396305084229, 0.5969827771186829, 0.5948275923728943, 0.5905172228813171, 0.5915948152542114, 0.5754310488700867, 0.5840517282485962, 0.5851293206214905, 0.5894396305084229]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 7s 51ms/step - loss: 1.4336 - accuracy: 0.5023 - val_loss: 1.4304 - val_accuracy: 0.5034\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.4277 - accuracy: 0.5008 - val_loss: 1.4246 - val_accuracy: 0.5305\n","Epoch 3/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4218 - accuracy: 0.5023 - val_loss: 1.4187 - val_accuracy: 0.4966\n","Epoch 4/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4159 - accuracy: 0.5006 - val_loss: 1.4129 - val_accuracy: 0.4977\n","Epoch 5/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4101 - accuracy: 0.5048 - val_loss: 1.4072 - val_accuracy: 0.5011\n","Epoch 6/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4043 - accuracy: 0.5113 - val_loss: 1.4015 - val_accuracy: 0.5011\n","Epoch 7/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3986 - accuracy: 0.5096 - val_loss: 1.3958 - val_accuracy: 0.5023\n","Epoch 8/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3928 - accuracy: 0.5317 - val_loss: 1.3902 - val_accuracy: 0.5260\n","Epoch 9/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3873 - accuracy: 0.5280 - val_loss: 1.3846 - val_accuracy: 0.5170\n","Epoch 10/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3816 - accuracy: 0.5498 - val_loss: 1.3791 - val_accuracy: 0.5238\n","Epoch 11/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3760 - accuracy: 0.5266 - val_loss: 1.3736 - val_accuracy: 0.5034\n","Epoch 12/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3705 - accuracy: 0.5453 - val_loss: 1.3681 - val_accuracy: 0.5124\n","Epoch 13/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3651 - accuracy: 0.5357 - val_loss: 1.3627 - val_accuracy: 0.5045\n","Epoch 14/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3595 - accuracy: 0.5436 - val_loss: 1.3573 - val_accuracy: 0.5057\n","Epoch 15/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3541 - accuracy: 0.5263 - val_loss: 1.3520 - val_accuracy: 0.4943\n","Epoch 16/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3485 - accuracy: 0.5569 - val_loss: 1.3467 - val_accuracy: 0.5034\n","Epoch 17/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3431 - accuracy: 0.5507 - val_loss: 1.3415 - val_accuracy: 0.5011\n","Epoch 18/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3377 - accuracy: 0.5540 - val_loss: 1.3362 - val_accuracy: 0.5158\n","Epoch 19/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3323 - accuracy: 0.5580 - val_loss: 1.3310 - val_accuracy: 0.5079\n","Epoch 20/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3269 - accuracy: 0.5563 - val_loss: 1.3259 - val_accuracy: 0.5147\n","Epoch 21/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3216 - accuracy: 0.5608 - val_loss: 1.3207 - val_accuracy: 0.5181\n","Epoch 22/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3161 - accuracy: 0.5540 - val_loss: 1.3157 - val_accuracy: 0.5057\n","Epoch 23/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3104 - accuracy: 0.5753 - val_loss: 1.3105 - val_accuracy: 0.5305\n","Epoch 24/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3048 - accuracy: 0.5699 - val_loss: 1.3053 - val_accuracy: 0.5249\n","Epoch 25/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2993 - accuracy: 0.5767 - val_loss: 1.3001 - val_accuracy: 0.5260\n","Epoch 26/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2936 - accuracy: 0.5688 - val_loss: 1.2951 - val_accuracy: 0.5271\n","Epoch 27/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2877 - accuracy: 0.5758 - val_loss: 1.2900 - val_accuracy: 0.5305\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2818 - accuracy: 0.5787 - val_loss: 1.2853 - val_accuracy: 0.5283\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2758 - accuracy: 0.5733 - val_loss: 1.2805 - val_accuracy: 0.5294\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2704 - accuracy: 0.5750 - val_loss: 1.2754 - val_accuracy: 0.5294\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2640 - accuracy: 0.5750 - val_loss: 1.2705 - val_accuracy: 0.5238\n","Epoch 32/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.2574 - accuracy: 0.5886 - val_loss: 1.2655 - val_accuracy: 0.5317\n","Epoch 33/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.2519 - accuracy: 0.5798 - val_loss: 1.2608 - val_accuracy: 0.5373\n","Epoch 34/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.2437 - accuracy: 0.5951 - val_loss: 1.2565 - val_accuracy: 0.5385\n","Epoch 35/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2377 - accuracy: 0.6007 - val_loss: 1.2527 - val_accuracy: 0.5339\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2296 - accuracy: 0.6070 - val_loss: 1.2489 - val_accuracy: 0.5385\n","Epoch 37/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.2247 - accuracy: 0.5990 - val_loss: 1.2445 - val_accuracy: 0.5452\n","Epoch 38/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2182 - accuracy: 0.6019 - val_loss: 1.2407 - val_accuracy: 0.5317\n","Epoch 39/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2110 - accuracy: 0.6126 - val_loss: 1.2401 - val_accuracy: 0.5373\n","Epoch 40/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.2065 - accuracy: 0.6041 - val_loss: 1.2325 - val_accuracy: 0.5419\n","Epoch 41/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.1972 - accuracy: 0.6149 - val_loss: 1.2286 - val_accuracy: 0.5475\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1906 - accuracy: 0.6231 - val_loss: 1.2296 - val_accuracy: 0.5396\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1832 - accuracy: 0.6228 - val_loss: 1.2229 - val_accuracy: 0.5464\n","Epoch 44/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1775 - accuracy: 0.6299 - val_loss: 1.2181 - val_accuracy: 0.5385\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1696 - accuracy: 0.6333 - val_loss: 1.2152 - val_accuracy: 0.5452\n","Epoch 46/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1615 - accuracy: 0.6423 - val_loss: 1.2126 - val_accuracy: 0.5419\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1551 - accuracy: 0.6381 - val_loss: 1.2097 - val_accuracy: 0.5475\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1505 - accuracy: 0.6423 - val_loss: 1.2067 - val_accuracy: 0.5452\n","Epoch 49/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1443 - accuracy: 0.6443 - val_loss: 1.2039 - val_accuracy: 0.5498\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1375 - accuracy: 0.6443 - val_loss: 1.2000 - val_accuracy: 0.5486\n","Epoch 51/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1298 - accuracy: 0.6537 - val_loss: 1.1983 - val_accuracy: 0.5464\n","Epoch 52/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.1236 - accuracy: 0.6469 - val_loss: 1.1985 - val_accuracy: 0.5554\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1204 - accuracy: 0.6525 - val_loss: 1.1944 - val_accuracy: 0.5486\n","Epoch 54/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1106 - accuracy: 0.6613 - val_loss: 1.1913 - val_accuracy: 0.5554\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1043 - accuracy: 0.6669 - val_loss: 1.1892 - val_accuracy: 0.5532\n","Epoch 56/100\n","28/28 [==============================] - 1s 31ms/step - loss: 1.1006 - accuracy: 0.6650 - val_loss: 1.1956 - val_accuracy: 0.5577\n","Epoch 57/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.0944 - accuracy: 0.6732 - val_loss: 1.1835 - val_accuracy: 0.5600\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0815 - accuracy: 0.6780 - val_loss: 1.1800 - val_accuracy: 0.5588\n","Epoch 59/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.0802 - accuracy: 0.6754 - val_loss: 1.1817 - val_accuracy: 0.5667\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0715 - accuracy: 0.6825 - val_loss: 1.1769 - val_accuracy: 0.5600\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0606 - accuracy: 0.6904 - val_loss: 1.1826 - val_accuracy: 0.5588\n","Epoch 62/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.0580 - accuracy: 0.6836 - val_loss: 1.1754 - val_accuracy: 0.5690\n","Epoch 63/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.0549 - accuracy: 0.6947 - val_loss: 1.1724 - val_accuracy: 0.5701\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0448 - accuracy: 0.6899 - val_loss: 1.1746 - val_accuracy: 0.5656\n","Epoch 65/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0376 - accuracy: 0.6899 - val_loss: 1.1708 - val_accuracy: 0.5611\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0289 - accuracy: 0.7097 - val_loss: 1.1715 - val_accuracy: 0.5701\n","Epoch 67/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.0256 - accuracy: 0.7032 - val_loss: 1.1703 - val_accuracy: 0.5724\n","Epoch 68/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0169 - accuracy: 0.7085 - val_loss: 1.1634 - val_accuracy: 0.5690\n","Epoch 69/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0109 - accuracy: 0.7085 - val_loss: 1.1676 - val_accuracy: 0.5679\n","Epoch 70/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.9980 - accuracy: 0.7309 - val_loss: 1.1772 - val_accuracy: 0.5769\n","Epoch 71/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0023 - accuracy: 0.7145 - val_loss: 1.1620 - val_accuracy: 0.5758\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9903 - accuracy: 0.7247 - val_loss: 1.1615 - val_accuracy: 0.5645\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9851 - accuracy: 0.7182 - val_loss: 1.1588 - val_accuracy: 0.5747\n","Epoch 74/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9772 - accuracy: 0.7312 - val_loss: 1.1601 - val_accuracy: 0.5792\n","Epoch 75/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.9703 - accuracy: 0.7329 - val_loss: 1.1600 - val_accuracy: 0.5803\n","Epoch 76/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9622 - accuracy: 0.7414 - val_loss: 1.1596 - val_accuracy: 0.5713\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9544 - accuracy: 0.7394 - val_loss: 1.1603 - val_accuracy: 0.5701\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9486 - accuracy: 0.7473 - val_loss: 1.1677 - val_accuracy: 0.5701\n","Epoch 79/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9516 - accuracy: 0.7306 - val_loss: 1.1594 - val_accuracy: 0.5860\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9368 - accuracy: 0.7473 - val_loss: 1.1605 - val_accuracy: 0.5713\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9304 - accuracy: 0.7499 - val_loss: 1.1590 - val_accuracy: 0.5735\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9204 - accuracy: 0.7640 - val_loss: 1.1599 - val_accuracy: 0.5826\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9158 - accuracy: 0.7575 - val_loss: 1.1675 - val_accuracy: 0.5735\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9201 - accuracy: 0.7462 - val_loss: 1.1618 - val_accuracy: 0.5792\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9003 - accuracy: 0.7716 - val_loss: 1.1595 - val_accuracy: 0.5837\n","Epoch 86/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8986 - accuracy: 0.7654 - val_loss: 1.1603 - val_accuracy: 0.5826\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8919 - accuracy: 0.7745 - val_loss: 1.1628 - val_accuracy: 0.5837\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8747 - accuracy: 0.7847 - val_loss: 1.1729 - val_accuracy: 0.5724\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8738 - accuracy: 0.7799 - val_loss: 1.1682 - val_accuracy: 0.5814\n","Epoch 90/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8637 - accuracy: 0.7849 - val_loss: 1.1786 - val_accuracy: 0.5894\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8628 - accuracy: 0.7824 - val_loss: 1.1718 - val_accuracy: 0.5814\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8540 - accuracy: 0.7912 - val_loss: 1.1806 - val_accuracy: 0.5882\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8441 - accuracy: 0.7971 - val_loss: 1.1758 - val_accuracy: 0.5860\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8354 - accuracy: 0.7968 - val_loss: 1.1781 - val_accuracy: 0.5894\n","Epoch 95/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8299 - accuracy: 0.7968 - val_loss: 1.1950 - val_accuracy: 0.5803\n","Epoch 96/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8253 - accuracy: 0.8028 - val_loss: 1.1878 - val_accuracy: 0.5860\n","Epoch 97/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.8192 - accuracy: 0.7963 - val_loss: 1.1979 - val_accuracy: 0.5928\n","Epoch 98/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8112 - accuracy: 0.8053 - val_loss: 1.1981 - val_accuracy: 0.5882\n","Epoch 99/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8008 - accuracy: 0.8104 - val_loss: 1.1918 - val_accuracy: 0.5848\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7929 - accuracy: 0.8147 - val_loss: 1.1903 - val_accuracy: 0.5871\n","{'loss': [1.433609962463379, 1.4277005195617676, 1.4217586517333984, 1.4158754348754883, 1.410098671913147, 1.4042880535125732, 1.3986328840255737, 1.392844796180725, 1.3873295783996582, 1.3816189765930176, 1.376017451286316, 1.3705058097839355, 1.3650519847869873, 1.3595340251922607, 1.3541107177734375, 1.348475694656372, 1.3431063890457153, 1.3376555442810059, 1.332291841506958, 1.3268756866455078, 1.3215534687042236, 1.316080093383789, 1.310404658317566, 1.3047736883163452, 1.2992627620697021, 1.2935668230056763, 1.2877148389816284, 1.281777024269104, 1.2758005857467651, 1.270366907119751, 1.2640308141708374, 1.2573519945144653, 1.2519123554229736, 1.2437011003494263, 1.237686038017273, 1.2295737266540527, 1.224726676940918, 1.2182356119155884, 1.2110050916671753, 1.2065054178237915, 1.1971863508224487, 1.190581202507019, 1.1832116842269897, 1.1774784326553345, 1.169568419456482, 1.1615256071090698, 1.1551358699798584, 1.1504873037338257, 1.1442813873291016, 1.1375467777252197, 1.1297577619552612, 1.1236218214035034, 1.1203532218933105, 1.1105871200561523, 1.1042808294296265, 1.1005558967590332, 1.0944492816925049, 1.0814992189407349, 1.0802382230758667, 1.0715043544769287, 1.0605567693710327, 1.0579689741134644, 1.0548980236053467, 1.044814944267273, 1.0376356840133667, 1.0288786888122559, 1.0255837440490723, 1.0169367790222168, 1.0109132528305054, 0.9980358481407166, 1.0022772550582886, 0.9903122782707214, 0.9851184487342834, 0.9772012233734131, 0.9703347086906433, 0.9621764421463013, 0.9543553590774536, 0.9485846161842346, 0.9515628814697266, 0.9367658495903015, 0.9303587675094604, 0.9204254746437073, 0.9158465266227722, 0.920097827911377, 0.9002538919448853, 0.898583710193634, 0.8919467926025391, 0.8746722936630249, 0.8737764358520508, 0.8636766076087952, 0.8628003597259521, 0.8539902567863464, 0.8440517783164978, 0.8353623151779175, 0.8299182653427124, 0.8253491520881653, 0.8192426562309265, 0.8111543655395508, 0.8007681965827942, 0.792924165725708], 'accuracy': [0.5022637248039246, 0.5008488893508911, 0.5022637248039246, 0.5005659461021423, 0.5048103928565979, 0.5113186240196228, 0.5096208453178406, 0.5316921472549438, 0.5280135869979858, 0.5498019456863403, 0.5265987515449524, 0.5452744960784912, 0.5356536507606506, 0.5435766577720642, 0.5263158082962036, 0.5568760633468628, 0.5506508350372314, 0.5540463924407959, 0.5580078959465027, 0.5563101172447205, 0.5608375668525696, 0.5540463924407959, 0.5752688050270081, 0.5698924660682678, 0.5766836404800415, 0.5687606334686279, 0.5758347511291504, 0.5786644220352173, 0.573288083076477, 0.5749858617782593, 0.5749858617782593, 0.5885682106018066, 0.5797962546348572, 0.5950763821601868, 0.6007357239723206, 0.6069609522819519, 0.5990379452705383, 0.6018675565719604, 0.6126202344894409, 0.604131281375885, 0.6148839592933655, 0.6230899691581726, 0.6228070259094238, 0.6298811435699463, 0.6332767605781555, 0.6423316597938538, 0.6380871534347534, 0.6423316597938538, 0.6443123817443848, 0.6443123817443848, 0.6536502838134766, 0.6468591094017029, 0.6525183916091919, 0.6612903475761414, 0.6669496297836304, 0.6649688482284546, 0.6731748580932617, 0.6779853105545044, 0.6754385828971863, 0.6825127601623535, 0.6904357671737671, 0.6836445927619934, 0.6946802735328674, 0.6898698210716248, 0.6898698210716248, 0.7096773982048035, 0.7031692266464233, 0.7085455656051636, 0.7085455656051636, 0.7308998107910156, 0.7144878506660461, 0.7246745824813843, 0.7181664109230042, 0.7311828136444092, 0.7328805923461914, 0.7413695454597473, 0.7393888235092163, 0.7473118305206299, 0.7306168675422668, 0.7473118305206299, 0.7498584985733032, 0.7640067934989929, 0.757498562335968, 0.7461799383163452, 0.7716468572616577, 0.7654216289520264, 0.7744765281677246, 0.7846632599830627, 0.7798528671264648, 0.7849462628364563, 0.7823995351791382, 0.7911714911460876, 0.7971137762069702, 0.7968307733535767, 0.7968307733535767, 0.8027730584144592, 0.7962648272514343, 0.8053197264671326, 0.810413122177124, 0.8146576285362244], 'val_loss': [1.4304444789886475, 1.4245660305023193, 1.4187263250350952, 1.4129273891448975, 1.4071714878082275, 1.401462435722351, 1.3957984447479248, 1.3901793956756592, 1.384600043296814, 1.3790621757507324, 1.3735747337341309, 1.368114709854126, 1.3627092838287354, 1.3573424816131592, 1.3520162105560303, 1.3467148542404175, 1.3414663076400757, 1.3362243175506592, 1.3310467004776, 1.325873613357544, 1.3207221031188965, 1.3156721591949463, 1.3104673624038696, 1.3052922487258911, 1.3000949621200562, 1.295081377029419, 1.2900134325027466, 1.2853035926818848, 1.28050696849823, 1.2754236459732056, 1.2705199718475342, 1.265531063079834, 1.2607694864273071, 1.2565075159072876, 1.2526779174804688, 1.2488970756530762, 1.2444672584533691, 1.2407026290893555, 1.2401304244995117, 1.2325329780578613, 1.2285809516906738, 1.2295700311660767, 1.222920298576355, 1.2180719375610352, 1.2151625156402588, 1.2126045227050781, 1.2097071409225464, 1.2067121267318726, 1.2039132118225098, 1.2000336647033691, 1.1982859373092651, 1.1985297203063965, 1.19444739818573, 1.1913203001022339, 1.1892030239105225, 1.1956241130828857, 1.183491826057434, 1.1800321340560913, 1.1817071437835693, 1.1769115924835205, 1.1826015710830688, 1.1753770112991333, 1.1723798513412476, 1.1746106147766113, 1.170831561088562, 1.1714993715286255, 1.170270562171936, 1.1634174585342407, 1.1676499843597412, 1.177241563796997, 1.1620041131973267, 1.1614599227905273, 1.1587553024291992, 1.1600604057312012, 1.1600258350372314, 1.1595863103866577, 1.1603225469589233, 1.1676689386367798, 1.1594101190567017, 1.1604763269424438, 1.1590406894683838, 1.1598503589630127, 1.1675368547439575, 1.1617521047592163, 1.1595284938812256, 1.1603007316589355, 1.1627777814865112, 1.1729332208633423, 1.1681643724441528, 1.1785551309585571, 1.171771764755249, 1.1805835962295532, 1.1758313179016113, 1.178119421005249, 1.194998860359192, 1.1878061294555664, 1.1978968381881714, 1.1981468200683594, 1.191799283027649, 1.1903482675552368], 'val_accuracy': [0.5033936500549316, 0.5305429697036743, 0.49660632014274597, 0.4977375566959381, 0.5011312365531921, 0.5011312365531921, 0.5022624731063843, 0.5260180830955505, 0.516968309879303, 0.523755669593811, 0.5033936500549316, 0.5124434232711792, 0.5045248866081238, 0.5056561231613159, 0.4943438768386841, 0.5033936500549316, 0.5011312365531921, 0.5158371329307556, 0.5079185366630554, 0.5147058963775635, 0.5180995464324951, 0.5056561231613159, 0.5305429697036743, 0.5248869061470032, 0.5260180830955505, 0.5271493196487427, 0.5305429697036743, 0.5282805562019348, 0.529411792755127, 0.529411792755127, 0.523755669593811, 0.5316742062568665, 0.5373303294181824, 0.5384615659713745, 0.5339366793632507, 0.5384615659713745, 0.5452488660812378, 0.5316742062568665, 0.5373303294181824, 0.5418552160263062, 0.5475113391876221, 0.5395927429199219, 0.5463801026344299, 0.5384615659713745, 0.5452488660812378, 0.5418552160263062, 0.5475113391876221, 0.5452488660812378, 0.5497737526893616, 0.5486425161361694, 0.5463801026344299, 0.5554298758506775, 0.5486425161361694, 0.5554298758506775, 0.5531674027442932, 0.557692289352417, 0.5599547624588013, 0.5588235259056091, 0.5667420625686646, 0.5599547624588013, 0.5588235259056091, 0.5690045356750488, 0.570135772228241, 0.5656108856201172, 0.5610859990119934, 0.570135772228241, 0.5723981857299805, 0.5690045356750488, 0.5678732991218567, 0.5769230723381042, 0.5757918357849121, 0.564479649066925, 0.5746606588363647, 0.5791855454444885, 0.5803167223930359, 0.5712669491767883, 0.570135772228241, 0.570135772228241, 0.5859728455543518, 0.5712669491767883, 0.5735294222831726, 0.5825791954994202, 0.5735294222831726, 0.5791855454444885, 0.5837104320526123, 0.5825791954994202, 0.5837104320526123, 0.5723981857299805, 0.581447958946228, 0.5893664956092834, 0.581447958946228, 0.5882353186607361, 0.5859728455543518, 0.5893664956092834, 0.5803167223930359, 0.5859728455543518, 0.5927602052688599, 0.5882353186607361, 0.5848416090011597, 0.587104082107544]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 1.4336 - accuracy: 0.5059"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 48ms/step - loss: 1.4335 - accuracy: 0.5047 - val_loss: 1.4298 - val_accuracy: 0.5134\n","Epoch 2/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.4268 - accuracy: 0.5052 - val_loss: 1.4233 - val_accuracy: 0.4959\n","Epoch 3/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4203 - accuracy: 0.5054 - val_loss: 1.4169 - val_accuracy: 0.4907\n","Epoch 4/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4137 - accuracy: 0.5137 - val_loss: 1.4105 - val_accuracy: 0.4959\n","Epoch 5/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4073 - accuracy: 0.5173 - val_loss: 1.4042 - val_accuracy: 0.4938\n","Epoch 6/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4009 - accuracy: 0.5256 - val_loss: 1.3979 - val_accuracy: 0.4959\n","Epoch 7/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3943 - accuracy: 0.5351 - val_loss: 1.3917 - val_accuracy: 0.4959\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3881 - accuracy: 0.5269 - val_loss: 1.3856 - val_accuracy: 0.4990\n","Epoch 9/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3816 - accuracy: 0.5297 - val_loss: 1.3795 - val_accuracy: 0.4969\n","Epoch 10/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3753 - accuracy: 0.5323 - val_loss: 1.3734 - val_accuracy: 0.5000\n","Epoch 11/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.3692 - accuracy: 0.5302 - val_loss: 1.3674 - val_accuracy: 0.5000\n","Epoch 12/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3627 - accuracy: 0.5326 - val_loss: 1.3615 - val_accuracy: 0.5000\n","Epoch 13/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3565 - accuracy: 0.5331 - val_loss: 1.3557 - val_accuracy: 0.5010\n","Epoch 14/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3503 - accuracy: 0.5375 - val_loss: 1.3498 - val_accuracy: 0.5021\n","Epoch 15/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3442 - accuracy: 0.5318 - val_loss: 1.3441 - val_accuracy: 0.5010\n","Epoch 16/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3382 - accuracy: 0.5367 - val_loss: 1.3383 - val_accuracy: 0.5083\n","Epoch 17/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3315 - accuracy: 0.5434 - val_loss: 1.3326 - val_accuracy: 0.5083\n","Epoch 18/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3256 - accuracy: 0.5460 - val_loss: 1.3269 - val_accuracy: 0.5124\n","Epoch 19/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.3192 - accuracy: 0.5504 - val_loss: 1.3214 - val_accuracy: 0.5134\n","Epoch 20/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.3127 - accuracy: 0.5491 - val_loss: 1.3159 - val_accuracy: 0.5176\n","Epoch 21/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.3068 - accuracy: 0.5563 - val_loss: 1.3105 - val_accuracy: 0.5227\n","Epoch 22/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.3009 - accuracy: 0.5618 - val_loss: 1.3051 - val_accuracy: 0.5300\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2942 - accuracy: 0.5618 - val_loss: 1.2992 - val_accuracy: 0.4979\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2878 - accuracy: 0.5656 - val_loss: 1.2940 - val_accuracy: 0.5124\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2812 - accuracy: 0.5778 - val_loss: 1.2887 - val_accuracy: 0.5062\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2750 - accuracy: 0.5747 - val_loss: 1.2836 - val_accuracy: 0.5227\n","Epoch 27/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2679 - accuracy: 0.5858 - val_loss: 1.2785 - val_accuracy: 0.5217\n","Epoch 28/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2610 - accuracy: 0.5873 - val_loss: 1.2738 - val_accuracy: 0.5300\n","Epoch 29/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.2550 - accuracy: 0.5822 - val_loss: 1.2703 - val_accuracy: 0.5145\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2493 - accuracy: 0.5840 - val_loss: 1.2654 - val_accuracy: 0.5248\n","Epoch 31/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.2431 - accuracy: 0.5912 - val_loss: 1.2632 - val_accuracy: 0.5165\n","Epoch 32/100\n","31/31 [==============================] - 1s 28ms/step - loss: 1.2362 - accuracy: 0.5961 - val_loss: 1.2577 - val_accuracy: 0.5372\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2287 - accuracy: 0.6052 - val_loss: 1.2547 - val_accuracy: 0.5300\n","Epoch 34/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2213 - accuracy: 0.6085 - val_loss: 1.2514 - val_accuracy: 0.5341\n","Epoch 35/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2157 - accuracy: 0.5995 - val_loss: 1.2486 - val_accuracy: 0.5320\n","Epoch 36/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2097 - accuracy: 0.6137 - val_loss: 1.2452 - val_accuracy: 0.5372\n","Epoch 37/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2018 - accuracy: 0.6137 - val_loss: 1.2420 - val_accuracy: 0.5351\n","Epoch 38/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.1974 - accuracy: 0.6103 - val_loss: 1.2400 - val_accuracy: 0.5341\n","Epoch 39/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.1896 - accuracy: 0.6178 - val_loss: 1.2371 - val_accuracy: 0.5362\n","Epoch 40/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.1847 - accuracy: 0.6124 - val_loss: 1.2348 - val_accuracy: 0.5444\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1763 - accuracy: 0.6181 - val_loss: 1.2318 - val_accuracy: 0.5382\n","Epoch 42/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1718 - accuracy: 0.6202 - val_loss: 1.2299 - val_accuracy: 0.5434\n","Epoch 43/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1631 - accuracy: 0.6300 - val_loss: 1.2293 - val_accuracy: 0.5382\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1545 - accuracy: 0.6398 - val_loss: 1.2287 - val_accuracy: 0.5434\n","Epoch 45/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1487 - accuracy: 0.6339 - val_loss: 1.2267 - val_accuracy: 0.5382\n","Epoch 46/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.1427 - accuracy: 0.6344 - val_loss: 1.2230 - val_accuracy: 0.5475\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1402 - accuracy: 0.6362 - val_loss: 1.2255 - val_accuracy: 0.5362\n","Epoch 48/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.1286 - accuracy: 0.6509 - val_loss: 1.2198 - val_accuracy: 0.5527\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1233 - accuracy: 0.6486 - val_loss: 1.2208 - val_accuracy: 0.5486\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1172 - accuracy: 0.6488 - val_loss: 1.2181 - val_accuracy: 0.5475\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1114 - accuracy: 0.6535 - val_loss: 1.2182 - val_accuracy: 0.5413\n","Epoch 52/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1030 - accuracy: 0.6610 - val_loss: 1.2166 - val_accuracy: 0.5506\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0986 - accuracy: 0.6667 - val_loss: 1.2154 - val_accuracy: 0.5527\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0942 - accuracy: 0.6612 - val_loss: 1.2141 - val_accuracy: 0.5444\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0863 - accuracy: 0.6695 - val_loss: 1.2141 - val_accuracy: 0.5444\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0778 - accuracy: 0.6731 - val_loss: 1.2146 - val_accuracy: 0.5372\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0736 - accuracy: 0.6770 - val_loss: 1.2186 - val_accuracy: 0.5341\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0692 - accuracy: 0.6762 - val_loss: 1.2101 - val_accuracy: 0.5506\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0588 - accuracy: 0.6835 - val_loss: 1.2109 - val_accuracy: 0.5362\n","Epoch 60/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0557 - accuracy: 0.6879 - val_loss: 1.2108 - val_accuracy: 0.5434\n","Epoch 61/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0474 - accuracy: 0.6977 - val_loss: 1.2098 - val_accuracy: 0.5475\n","Epoch 62/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0413 - accuracy: 0.6822 - val_loss: 1.2090 - val_accuracy: 0.5465\n","Epoch 63/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0357 - accuracy: 0.6953 - val_loss: 1.2047 - val_accuracy: 0.5444\n","Epoch 64/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0345 - accuracy: 0.6884 - val_loss: 1.2080 - val_accuracy: 0.5486\n","Epoch 65/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0251 - accuracy: 0.6943 - val_loss: 1.2113 - val_accuracy: 0.5475\n","Epoch 66/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.0288 - accuracy: 0.6941 - val_loss: 1.2060 - val_accuracy: 0.5537\n","Epoch 67/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0132 - accuracy: 0.7031 - val_loss: 1.2061 - val_accuracy: 0.5403\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0096 - accuracy: 0.7010 - val_loss: 1.2151 - val_accuracy: 0.5341\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9996 - accuracy: 0.7158 - val_loss: 1.2080 - val_accuracy: 0.5537\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0020 - accuracy: 0.7080 - val_loss: 1.2100 - val_accuracy: 0.5465\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9851 - accuracy: 0.7189 - val_loss: 1.2101 - val_accuracy: 0.5496\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9804 - accuracy: 0.7276 - val_loss: 1.2187 - val_accuracy: 0.5413\n","Epoch 73/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9770 - accuracy: 0.7261 - val_loss: 1.2105 - val_accuracy: 0.5382\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9696 - accuracy: 0.7222 - val_loss: 1.2113 - val_accuracy: 0.5496\n","Epoch 75/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9652 - accuracy: 0.7256 - val_loss: 1.2121 - val_accuracy: 0.5372\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9578 - accuracy: 0.7253 - val_loss: 1.2194 - val_accuracy: 0.5486\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9506 - accuracy: 0.7336 - val_loss: 1.2200 - val_accuracy: 0.5486\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9487 - accuracy: 0.7359 - val_loss: 1.2208 - val_accuracy: 0.5486\n","Epoch 79/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9366 - accuracy: 0.7437 - val_loss: 1.2275 - val_accuracy: 0.5455\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9366 - accuracy: 0.7416 - val_loss: 1.2216 - val_accuracy: 0.5475\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9276 - accuracy: 0.7468 - val_loss: 1.2248 - val_accuracy: 0.5486\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9296 - accuracy: 0.7419 - val_loss: 1.2263 - val_accuracy: 0.5403\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9208 - accuracy: 0.7411 - val_loss: 1.2221 - val_accuracy: 0.5393\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9221 - accuracy: 0.7359 - val_loss: 1.2270 - val_accuracy: 0.5465\n","Epoch 85/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9044 - accuracy: 0.7556 - val_loss: 1.2280 - val_accuracy: 0.5455\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8970 - accuracy: 0.7594 - val_loss: 1.2281 - val_accuracy: 0.5362\n","Epoch 87/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8936 - accuracy: 0.7615 - val_loss: 1.2433 - val_accuracy: 0.5403\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8857 - accuracy: 0.7659 - val_loss: 1.2371 - val_accuracy: 0.5351\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8848 - accuracy: 0.7571 - val_loss: 1.2410 - val_accuracy: 0.5424\n","Epoch 90/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8789 - accuracy: 0.7630 - val_loss: 1.2527 - val_accuracy: 0.5486\n","Epoch 91/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8754 - accuracy: 0.7643 - val_loss: 1.2473 - val_accuracy: 0.5351\n","Epoch 92/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8644 - accuracy: 0.7770 - val_loss: 1.2449 - val_accuracy: 0.5455\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8540 - accuracy: 0.7879 - val_loss: 1.2471 - val_accuracy: 0.5444\n","Epoch 94/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8484 - accuracy: 0.7873 - val_loss: 1.2472 - val_accuracy: 0.5382\n","Epoch 95/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8431 - accuracy: 0.7858 - val_loss: 1.2550 - val_accuracy: 0.5403\n","Epoch 96/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8423 - accuracy: 0.7801 - val_loss: 1.2570 - val_accuracy: 0.5465\n","Epoch 97/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8304 - accuracy: 0.7889 - val_loss: 1.2650 - val_accuracy: 0.5465\n","Epoch 98/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8372 - accuracy: 0.7755 - val_loss: 1.2872 - val_accuracy: 0.5310\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8262 - accuracy: 0.7938 - val_loss: 1.2739 - val_accuracy: 0.5434\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8118 - accuracy: 0.8018 - val_loss: 1.2745 - val_accuracy: 0.5341\n","{'loss': [1.4334580898284912, 1.4268393516540527, 1.420250654220581, 1.4137053489685059, 1.4072860479354858, 1.4008502960205078, 1.3942537307739258, 1.3880647420883179, 1.3816022872924805, 1.3752856254577637, 1.3691726922988892, 1.36272394657135, 1.3565030097961426, 1.3502742052078247, 1.3441662788391113, 1.33821439743042, 1.3314993381500244, 1.3255994319915771, 1.3192185163497925, 1.312747597694397, 1.3068079948425293, 1.300911784172058, 1.2941651344299316, 1.2878203392028809, 1.2812038660049438, 1.274985909461975, 1.2679171562194824, 1.260970950126648, 1.255011796951294, 1.2492995262145996, 1.2431309223175049, 1.2361817359924316, 1.2287013530731201, 1.2213208675384521, 1.2157105207443237, 1.2096631526947021, 1.2018483877182007, 1.197408676147461, 1.1895564794540405, 1.1846930980682373, 1.1762869358062744, 1.1717941761016846, 1.1631344556808472, 1.1544510126113892, 1.1486526727676392, 1.1427229642868042, 1.1401809453964233, 1.128631591796875, 1.1232826709747314, 1.1172049045562744, 1.1114287376403809, 1.1029939651489258, 1.0985794067382812, 1.0942158699035645, 1.0863138437271118, 1.0777748823165894, 1.0736305713653564, 1.0691934823989868, 1.0587644577026367, 1.0557464361190796, 1.0474299192428589, 1.0412518978118896, 1.0357122421264648, 1.0344945192337036, 1.025060772895813, 1.0287548303604126, 1.0132403373718262, 1.0096055269241333, 0.9996474981307983, 1.0019816160202026, 0.9850863218307495, 0.9803810715675354, 0.9770241379737854, 0.9696229100227356, 0.965199887752533, 0.9577712416648865, 0.9505895376205444, 0.9487225413322449, 0.9366408586502075, 0.9366100430488586, 0.9276213645935059, 0.9295966625213623, 0.9208159446716309, 0.9220594167709351, 0.904414176940918, 0.8969553112983704, 0.8935676217079163, 0.8857074975967407, 0.8847599625587463, 0.8789074420928955, 0.8754402995109558, 0.8643891215324402, 0.85404372215271, 0.8483713269233704, 0.8430628776550293, 0.8423008918762207, 0.8303558230400085, 0.837242603302002, 0.8262351751327515, 0.811774730682373], 'accuracy': [0.5046511888504028, 0.5051679611206055, 0.5054263472557068, 0.5136950612068176, 0.5173126459121704, 0.525581419467926, 0.5351421236991882, 0.5268734097480774, 0.5297157764434814, 0.5322997570037842, 0.5302325487136841, 0.5325581431388855, 0.5330749154090881, 0.5374677181243896, 0.5317829251289368, 0.5366925001144409, 0.5434108376502991, 0.5459948182106018, 0.5503876209259033, 0.549095630645752, 0.5563307404518127, 0.5617570877075195, 0.5617570877075195, 0.5656330585479736, 0.5777778029441833, 0.5746769905090332, 0.5857881307601929, 0.5873385071754456, 0.5821705460548401, 0.5839793086051941, 0.5912144780158997, 0.5961240530014038, 0.6051679849624634, 0.6085271239280701, 0.5994831919670105, 0.6136950850486755, 0.6136950850486755, 0.6103359460830688, 0.617829442024231, 0.6124030947685242, 0.6180878281593323, 0.6201550364494324, 0.6299741864204407, 0.6397932767868042, 0.6338501572608948, 0.6343669295310974, 0.6361756920814514, 0.6509044170379639, 0.6485788226127625, 0.6488372087478638, 0.6534883975982666, 0.6609818935394287, 0.6666666865348816, 0.6612403392791748, 0.6695090532302856, 0.6731266379356384, 0.6770026087760925, 0.6762273907661438, 0.6834625601768494, 0.6878553032875061, 0.6976743936538696, 0.682170569896698, 0.695348858833313, 0.6883720755577087, 0.6943152546882629, 0.6940568685531616, 0.7031008005142212, 0.7010335922241211, 0.7157622575759888, 0.7080103158950806, 0.7188630700111389, 0.7276485562324524, 0.7260981798171997, 0.7222222089767456, 0.7255814075469971, 0.7253230214118958, 0.7335917353630066, 0.735917329788208, 0.7436692714691162, 0.7416020631790161, 0.7467700242996216, 0.7418604493141174, 0.7410852909088135, 0.735917329788208, 0.7555555701255798, 0.7594315409660339, 0.7614986896514893, 0.7658914923667908, 0.7571059465408325, 0.7630490660667419, 0.7643410563468933, 0.7770025730133057, 0.7878552675247192, 0.7873384952545166, 0.7857881188392639, 0.7801033854484558, 0.7888888716697693, 0.775452196598053, 0.7937984466552734, 0.801808774471283], 'val_loss': [1.4298311471939087, 1.423345685005188, 1.416916847229004, 1.4105284214019775, 1.4042035341262817, 1.3979345560073853, 1.3917193412780762, 1.3855674266815186, 1.3794645071029663, 1.3734090328216553, 1.3674389123916626, 1.3614726066589355, 1.3556816577911377, 1.3498268127441406, 1.3441040515899658, 1.3383044004440308, 1.3326283693313599, 1.326938271522522, 1.3214126825332642, 1.3159044981002808, 1.310525894165039, 1.305140495300293, 1.2992366552352905, 1.2940034866333008, 1.2886658906936646, 1.283613681793213, 1.2784862518310547, 1.2738282680511475, 1.2703417539596558, 1.2653664350509644, 1.2631642818450928, 1.257705807685852, 1.254747748374939, 1.2514153718948364, 1.248576045036316, 1.2452077865600586, 1.24204421043396, 1.240027904510498, 1.237134337425232, 1.234812617301941, 1.2317509651184082, 1.2299107313156128, 1.2293258905410767, 1.2286930084228516, 1.2267268896102905, 1.2230234146118164, 1.2254600524902344, 1.2198232412338257, 1.2207822799682617, 1.218118667602539, 1.218214750289917, 1.2165851593017578, 1.215387225151062, 1.2141294479370117, 1.2141104936599731, 1.2146345376968384, 1.2186074256896973, 1.2101366519927979, 1.2108943462371826, 1.2107961177825928, 1.209765911102295, 1.2090206146240234, 1.2047053575515747, 1.208033561706543, 1.2113313674926758, 1.2059506177902222, 1.206079125404358, 1.2150535583496094, 1.2080378532409668, 1.2100471258163452, 1.2101361751556396, 1.2187458276748657, 1.210474967956543, 1.2112773656845093, 1.2120505571365356, 1.2193578481674194, 1.2200267314910889, 1.2207744121551514, 1.2274866104125977, 1.2216118574142456, 1.224812388420105, 1.2263201475143433, 1.22214937210083, 1.2270194292068481, 1.228028655052185, 1.2280759811401367, 1.2432743310928345, 1.2371224164962769, 1.24104905128479, 1.2526813745498657, 1.2472604513168335, 1.2449042797088623, 1.2471026182174683, 1.2472317218780518, 1.2549574375152588, 1.2570254802703857, 1.265023946762085, 1.2871930599212646, 1.2739068269729614, 1.2744885683059692], 'val_accuracy': [0.5134297609329224, 0.4958677589893341, 0.49070248007774353, 0.4958677589893341, 0.49380165338516235, 0.4958677589893341, 0.4958677589893341, 0.49896693229675293, 0.4969008266925812, 0.5, 0.5, 0.5, 0.5010330677032471, 0.5020661354064941, 0.5010330677032471, 0.5082644820213318, 0.5082644820213318, 0.5123966932296753, 0.5134297609329224, 0.5175619721412659, 0.5227272510528564, 0.5299586653709412, 0.49793389439582825, 0.5123966932296753, 0.5061983466148376, 0.5227272510528564, 0.5216942429542542, 0.5299586653709412, 0.5144628286361694, 0.5247933864593506, 0.5165289044380188, 0.5371900796890259, 0.5299586653709412, 0.5340909361839294, 0.5320248007774353, 0.5371900796890259, 0.5351239442825317, 0.5340909361839294, 0.5361570119857788, 0.5444214940071106, 0.538223147392273, 0.5433884263038635, 0.538223147392273, 0.5433884263038635, 0.538223147392273, 0.547520637512207, 0.5361570119857788, 0.5526859760284424, 0.5485537052154541, 0.547520637512207, 0.5413222908973694, 0.5506198406219482, 0.5526859760284424, 0.5444214940071106, 0.5444214940071106, 0.5371900796890259, 0.5340909361839294, 0.5506198406219482, 0.5361570119857788, 0.5433884263038635, 0.547520637512207, 0.5464876294136047, 0.5444214940071106, 0.5485537052154541, 0.547520637512207, 0.5537189841270447, 0.5402892827987671, 0.5340909361839294, 0.5537189841270447, 0.5464876294136047, 0.5495867729187012, 0.5413222908973694, 0.538223147392273, 0.5495867729187012, 0.5371900796890259, 0.5485537052154541, 0.5485537052154541, 0.5485537052154541, 0.5454545617103577, 0.547520637512207, 0.5485537052154541, 0.5402892827987671, 0.53925621509552, 0.5464876294136047, 0.5454545617103577, 0.5361570119857788, 0.5402892827987671, 0.5351239442825317, 0.5423553586006165, 0.5485537052154541, 0.5351239442825317, 0.5454545617103577, 0.5444214940071106, 0.538223147392273, 0.5402892827987671, 0.5464876294136047, 0.5464876294136047, 0.5309917330741882, 0.5433884263038635, 0.5340909361839294]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/29 [========================>.....] - ETA: 0s - loss: 0.9491 - accuracy: 0.7019"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 53ms/step - loss: 0.9496 - accuracy: 0.7002 - val_loss: 1.0631 - val_accuracy: 0.5571\n","Epoch 2/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9331 - accuracy: 0.7166 - val_loss: 1.0599 - val_accuracy: 0.5916\n","Epoch 3/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9257 - accuracy: 0.7209 - val_loss: 1.0565 - val_accuracy: 0.6325\n","Epoch 4/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9179 - accuracy: 0.7290 - val_loss: 1.0535 - val_accuracy: 0.5894\n","Epoch 5/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9121 - accuracy: 0.7311 - val_loss: 1.0495 - val_accuracy: 0.6175\n","Epoch 6/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8979 - accuracy: 0.7390 - val_loss: 1.0458 - val_accuracy: 0.6304\n","Epoch 7/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8942 - accuracy: 0.7416 - val_loss: 1.0421 - val_accuracy: 0.5981\n","Epoch 8/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8957 - accuracy: 0.7344 - val_loss: 1.0370 - val_accuracy: 0.6379\n","Epoch 9/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8774 - accuracy: 0.7543 - val_loss: 1.0320 - val_accuracy: 0.6444\n","Epoch 10/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.8759 - accuracy: 0.7425 - val_loss: 1.0269 - val_accuracy: 0.6498\n","Epoch 11/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.8670 - accuracy: 0.7484 - val_loss: 1.0204 - val_accuracy: 0.6767\n","Epoch 12/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8657 - accuracy: 0.7519 - val_loss: 1.0157 - val_accuracy: 0.6358\n","Epoch 13/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8621 - accuracy: 0.7457 - val_loss: 1.0085 - val_accuracy: 0.6735\n","Epoch 14/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8534 - accuracy: 0.7497 - val_loss: 1.0021 - val_accuracy: 0.6606\n","Epoch 15/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8461 - accuracy: 0.7516 - val_loss: 0.9946 - val_accuracy: 0.6703\n","Epoch 16/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8389 - accuracy: 0.7624 - val_loss: 0.9878 - val_accuracy: 0.6638\n","Epoch 17/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8301 - accuracy: 0.7664 - val_loss: 0.9819 - val_accuracy: 0.6509\n","Epoch 18/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8283 - accuracy: 0.7689 - val_loss: 0.9750 - val_accuracy: 0.6541\n","Epoch 19/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8219 - accuracy: 0.7729 - val_loss: 0.9695 - val_accuracy: 0.6466\n","Epoch 20/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8252 - accuracy: 0.7632 - val_loss: 0.9619 - val_accuracy: 0.6724\n","Epoch 21/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8076 - accuracy: 0.7764 - val_loss: 0.9591 - val_accuracy: 0.6498\n","Epoch 22/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8039 - accuracy: 0.7791 - val_loss: 0.9540 - val_accuracy: 0.6703\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7983 - accuracy: 0.7753 - val_loss: 0.9537 - val_accuracy: 0.6584\n","Epoch 24/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7904 - accuracy: 0.7864 - val_loss: 0.9683 - val_accuracy: 0.6412\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7845 - accuracy: 0.7899 - val_loss: 0.9509 - val_accuracy: 0.6746\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7757 - accuracy: 0.7912 - val_loss: 0.9725 - val_accuracy: 0.6412\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7790 - accuracy: 0.7950 - val_loss: 0.9682 - val_accuracy: 0.6487\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7728 - accuracy: 0.7988 - val_loss: 0.9572 - val_accuracy: 0.6649\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7637 - accuracy: 0.8044 - val_loss: 0.9588 - val_accuracy: 0.6746\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7589 - accuracy: 0.8015 - val_loss: 0.9604 - val_accuracy: 0.6681\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7503 - accuracy: 0.8090 - val_loss: 0.9638 - val_accuracy: 0.6616\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7485 - accuracy: 0.8028 - val_loss: 0.9702 - val_accuracy: 0.6584\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7397 - accuracy: 0.8063 - val_loss: 0.9816 - val_accuracy: 0.6498\n","Epoch 34/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7329 - accuracy: 0.8114 - val_loss: 0.9914 - val_accuracy: 0.6487\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7370 - accuracy: 0.8058 - val_loss: 0.9997 - val_accuracy: 0.6401\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7196 - accuracy: 0.8157 - val_loss: 0.9714 - val_accuracy: 0.6659\n","Epoch 37/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7237 - accuracy: 0.8176 - val_loss: 0.9878 - val_accuracy: 0.6498\n","Epoch 38/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7140 - accuracy: 0.8187 - val_loss: 0.9738 - val_accuracy: 0.6713\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7054 - accuracy: 0.8260 - val_loss: 0.9784 - val_accuracy: 0.6746\n","Epoch 40/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7126 - accuracy: 0.8133 - val_loss: 1.0018 - val_accuracy: 0.6476\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6937 - accuracy: 0.8319 - val_loss: 0.9880 - val_accuracy: 0.6627\n","Epoch 42/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6951 - accuracy: 0.8265 - val_loss: 0.9895 - val_accuracy: 0.6606\n","Epoch 43/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6865 - accuracy: 0.8370 - val_loss: 0.9918 - val_accuracy: 0.6552\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6793 - accuracy: 0.8359 - val_loss: 0.9998 - val_accuracy: 0.6638\n","Epoch 45/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6698 - accuracy: 0.8408 - val_loss: 0.9929 - val_accuracy: 0.6670\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6628 - accuracy: 0.8411 - val_loss: 1.0119 - val_accuracy: 0.6530\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6606 - accuracy: 0.8421 - val_loss: 1.0026 - val_accuracy: 0.6703\n","Epoch 48/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6563 - accuracy: 0.8456 - val_loss: 0.9994 - val_accuracy: 0.6670\n","Epoch 49/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6455 - accuracy: 0.8532 - val_loss: 1.0194 - val_accuracy: 0.6584\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6431 - accuracy: 0.8473 - val_loss: 1.0147 - val_accuracy: 0.6562\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6327 - accuracy: 0.8613 - val_loss: 1.0170 - val_accuracy: 0.6659\n","Epoch 52/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6283 - accuracy: 0.8605 - val_loss: 1.0253 - val_accuracy: 0.6584\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6234 - accuracy: 0.8650 - val_loss: 1.0419 - val_accuracy: 0.6541\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6448 - accuracy: 0.8419 - val_loss: 1.0339 - val_accuracy: 0.6649\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6197 - accuracy: 0.8583 - val_loss: 1.0280 - val_accuracy: 0.6584\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6141 - accuracy: 0.8586 - val_loss: 1.0308 - val_accuracy: 0.6573\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6103 - accuracy: 0.8637 - val_loss: 1.0269 - val_accuracy: 0.6638\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5948 - accuracy: 0.8726 - val_loss: 1.0359 - val_accuracy: 0.6552\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5936 - accuracy: 0.8677 - val_loss: 1.0281 - val_accuracy: 0.6756\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5909 - accuracy: 0.8712 - val_loss: 1.0381 - val_accuracy: 0.6573\n","Epoch 61/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5802 - accuracy: 0.8793 - val_loss: 1.1109 - val_accuracy: 0.6401\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5898 - accuracy: 0.8693 - val_loss: 1.0380 - val_accuracy: 0.6681\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5899 - accuracy: 0.8675 - val_loss: 1.0575 - val_accuracy: 0.6649\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5726 - accuracy: 0.8820 - val_loss: 1.0547 - val_accuracy: 0.6746\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5712 - accuracy: 0.8807 - val_loss: 1.0681 - val_accuracy: 0.6713\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5765 - accuracy: 0.8685 - val_loss: 1.0878 - val_accuracy: 0.6466\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5629 - accuracy: 0.8820 - val_loss: 1.0765 - val_accuracy: 0.6746\n","Epoch 68/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5640 - accuracy: 0.8828 - val_loss: 1.0657 - val_accuracy: 0.6562\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5448 - accuracy: 0.8984 - val_loss: 1.0641 - val_accuracy: 0.6649\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5471 - accuracy: 0.8885 - val_loss: 1.0712 - val_accuracy: 0.6735\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5389 - accuracy: 0.8882 - val_loss: 1.0752 - val_accuracy: 0.6606\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5380 - accuracy: 0.8917 - val_loss: 1.0920 - val_accuracy: 0.6498\n","Epoch 73/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5354 - accuracy: 0.8976 - val_loss: 1.0825 - val_accuracy: 0.6573\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5225 - accuracy: 0.8990 - val_loss: 1.0836 - val_accuracy: 0.6530\n","Epoch 75/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5260 - accuracy: 0.8952 - val_loss: 1.0887 - val_accuracy: 0.6703\n","Epoch 76/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5079 - accuracy: 0.9122 - val_loss: 1.0967 - val_accuracy: 0.6735\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5149 - accuracy: 0.8995 - val_loss: 1.1029 - val_accuracy: 0.6638\n","Epoch 78/100\n","29/29 [==============================] - 2s 54ms/step - loss: 0.5063 - accuracy: 0.9049 - val_loss: 1.1016 - val_accuracy: 0.6778\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5022 - accuracy: 0.9076 - val_loss: 1.1020 - val_accuracy: 0.6692\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5002 - accuracy: 0.9060 - val_loss: 1.1150 - val_accuracy: 0.6519\n","Epoch 81/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4887 - accuracy: 0.9184 - val_loss: 1.1215 - val_accuracy: 0.6562\n","Epoch 82/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4829 - accuracy: 0.9165 - val_loss: 1.1262 - val_accuracy: 0.6649\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4855 - accuracy: 0.9141 - val_loss: 1.1462 - val_accuracy: 0.6466\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4850 - accuracy: 0.9157 - val_loss: 1.1373 - val_accuracy: 0.6562\n","Epoch 85/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4840 - accuracy: 0.9124 - val_loss: 1.1392 - val_accuracy: 0.6713\n","Epoch 86/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4916 - accuracy: 0.9087 - val_loss: 1.1504 - val_accuracy: 0.6692\n","Epoch 87/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4620 - accuracy: 0.9294 - val_loss: 1.1560 - val_accuracy: 0.6509\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4664 - accuracy: 0.9216 - val_loss: 1.1922 - val_accuracy: 0.6498\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4612 - accuracy: 0.9232 - val_loss: 1.1803 - val_accuracy: 0.6541\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4587 - accuracy: 0.9224 - val_loss: 1.1635 - val_accuracy: 0.6606\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4494 - accuracy: 0.9275 - val_loss: 1.1816 - val_accuracy: 0.6606\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4457 - accuracy: 0.9281 - val_loss: 1.1813 - val_accuracy: 0.6649\n","Epoch 93/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4490 - accuracy: 0.9273 - val_loss: 1.1918 - val_accuracy: 0.6627\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4418 - accuracy: 0.9340 - val_loss: 1.2139 - val_accuracy: 0.6444\n","Epoch 95/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4631 - accuracy: 0.9168 - val_loss: 1.2819 - val_accuracy: 0.6444\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4429 - accuracy: 0.9256 - val_loss: 1.2439 - val_accuracy: 0.6476\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4388 - accuracy: 0.9300 - val_loss: 1.2112 - val_accuracy: 0.6659\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4374 - accuracy: 0.9321 - val_loss: 1.2452 - val_accuracy: 0.6455\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4322 - accuracy: 0.9335 - val_loss: 1.2585 - val_accuracy: 0.6552\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4414 - accuracy: 0.9259 - val_loss: 1.2345 - val_accuracy: 0.6649\n","{'loss': [0.9495784640312195, 0.9330938458442688, 0.9257424473762512, 0.9178709387779236, 0.9121463894844055, 0.8979347944259644, 0.8942061066627502, 0.895650327205658, 0.8773871064186096, 0.8758825659751892, 0.8670259714126587, 0.8657066822052002, 0.8621455430984497, 0.8533723950386047, 0.8460730314254761, 0.8389001488685608, 0.8301170468330383, 0.8283047080039978, 0.8219293355941772, 0.8251802325248718, 0.8075860738754272, 0.8038632869720459, 0.7983149290084839, 0.7903761267662048, 0.7845459580421448, 0.7757149934768677, 0.7789738774299622, 0.7728428244590759, 0.7636929154396057, 0.7588598728179932, 0.7502619028091431, 0.7484735250473022, 0.7397035360336304, 0.7328827381134033, 0.7369603514671326, 0.7196474671363831, 0.7236999869346619, 0.7139897346496582, 0.7054150700569153, 0.7125915884971619, 0.6936537623405457, 0.6950576901435852, 0.68645840883255, 0.6792903542518616, 0.6698096990585327, 0.6628417372703552, 0.6606401801109314, 0.656251072883606, 0.6455163359642029, 0.6431205868721008, 0.6326753497123718, 0.6283454895019531, 0.6234204769134521, 0.6447926163673401, 0.6196914315223694, 0.6141404509544373, 0.6102775931358337, 0.5948196649551392, 0.5935734510421753, 0.5908635854721069, 0.580177903175354, 0.5897937417030334, 0.589925229549408, 0.5726288557052612, 0.5711816549301147, 0.5765339136123657, 0.562893807888031, 0.5639946460723877, 0.544772207736969, 0.5470653176307678, 0.5389147996902466, 0.5379624366760254, 0.5354293584823608, 0.5225162506103516, 0.5260030031204224, 0.507869303226471, 0.5148656368255615, 0.5063320398330688, 0.50216144323349, 0.5002264380455017, 0.4886758029460907, 0.48285192251205444, 0.48552361130714417, 0.4849998950958252, 0.48397815227508545, 0.4916228950023651, 0.4620228707790375, 0.4663665294647217, 0.4612017571926117, 0.45871248841285706, 0.44943010807037354, 0.4457429349422455, 0.44902902841567993, 0.4417646527290344, 0.4631223976612091, 0.4429495334625244, 0.4388011395931244, 0.4373713731765747, 0.4322182536125183, 0.4413866698741913], 'accuracy': [0.7001616358757019, 0.7165948152542114, 0.7209051847457886, 0.7289870977401733, 0.7311422228813171, 0.7389547228813171, 0.7416487336158752, 0.734375, 0.7543103694915771, 0.7424569129943848, 0.748383641242981, 0.7518857717514038, 0.7456896305084229, 0.7497305870056152, 0.751616358757019, 0.7623922228813171, 0.7664331793785095, 0.7688577771186829, 0.7728987336158752, 0.7632004022598267, 0.7764008641242981, 0.7790948152542114, 0.7753232717514038, 0.7863685488700867, 0.7898706793785095, 0.7912176847457886, 0.7949892282485962, 0.7987607717514038, 0.8044180870056152, 0.8014547228813171, 0.8089978694915771, 0.8028017282485962, 0.806303858757019, 0.8114224076271057, 0.8057650923728943, 0.8157327771186829, 0.8176185488700867, 0.818696141242981, 0.8259698152542114, 0.8133081793785095, 0.8318965435028076, 0.826508641242981, 0.8370150923728943, 0.8359375, 0.8407866358757019, 0.8410560488700867, 0.842133641242981, 0.8456357717514038, 0.853178858757019, 0.8472521305084229, 0.8612607717514038, 0.8604525923728943, 0.8650323152542114, 0.8418642282485962, 0.8582974076271057, 0.8585668206214905, 0.8636853694915771, 0.8725754022598267, 0.8677262663841248, 0.8712284564971924, 0.8793103694915771, 0.8693426847457886, 0.8674569129943848, 0.8820043206214905, 0.8806573152542114, 0.868534505367279, 0.8820043206214905, 0.8828125, 0.8984375, 0.8884698152542114, 0.8882004022598267, 0.8917025923728943, 0.8976293206214905, 0.8989762663841248, 0.8952047228813171, 0.9121767282485962, 0.8995150923728943, 0.904902994632721, 0.907597005367279, 0.9059805870056152, 0.9183728694915771, 0.9164870977401733, 0.9140625, 0.915678858757019, 0.912446141242981, 0.9086745977401733, 0.9294180870056152, 0.9216055870056152, 0.923222005367279, 0.9224137663841248, 0.9275323152542114, 0.928071141242981, 0.9272629022598267, 0.9339978694915771, 0.9167564511299133, 0.9256465435028076, 0.9299569129943848, 0.9321120977401733, 0.9334590435028076, 0.9259159564971924], 'val_loss': [1.0630797147750854, 1.059929370880127, 1.0565119981765747, 1.053497552871704, 1.0495309829711914, 1.045812964439392, 1.0420550107955933, 1.0370231866836548, 1.0320303440093994, 1.0269131660461426, 1.0204112529754639, 1.0156638622283936, 1.0084903240203857, 1.0020705461502075, 0.9945982098579407, 0.987759530544281, 0.9819436073303223, 0.9749659299850464, 0.9695168733596802, 0.9618556499481201, 0.9591475129127502, 0.9539816379547119, 0.953704833984375, 0.9682973027229309, 0.9509028196334839, 0.9725098609924316, 0.9682459235191345, 0.9571659564971924, 0.958782434463501, 0.9604129791259766, 0.9637742638587952, 0.9701858758926392, 0.9816381931304932, 0.9914279580116272, 0.9997127056121826, 0.9714158177375793, 0.9877801537513733, 0.9738218784332275, 0.9784458875656128, 1.001814365386963, 0.9880359172821045, 0.9894502758979797, 0.9917995929718018, 0.9997579455375671, 0.9929195642471313, 1.0119421482086182, 1.002561092376709, 0.9994022846221924, 1.0194486379623413, 1.0147212743759155, 1.016965627670288, 1.0252865552902222, 1.0419361591339111, 1.0338568687438965, 1.027998685836792, 1.0307705402374268, 1.0269157886505127, 1.0359320640563965, 1.0281155109405518, 1.0380792617797852, 1.110858678817749, 1.038010597229004, 1.0574536323547363, 1.0546529293060303, 1.0680946111679077, 1.0877960920333862, 1.0765166282653809, 1.0657039880752563, 1.0641058683395386, 1.071221947669983, 1.075249433517456, 1.0919617414474487, 1.0825191736221313, 1.0836215019226074, 1.0886741876602173, 1.0967351198196411, 1.1028720140457153, 1.1015701293945312, 1.1020041704177856, 1.1149989366531372, 1.1214679479599, 1.1262421607971191, 1.1461788415908813, 1.1372706890106201, 1.1392138004302979, 1.1503667831420898, 1.1559669971466064, 1.1922366619110107, 1.180280089378357, 1.1634821891784668, 1.1815892457962036, 1.181339144706726, 1.1918385028839111, 1.2138755321502686, 1.2818776369094849, 1.2439377307891846, 1.21121084690094, 1.2452248334884644, 1.2585045099258423, 1.2345024347305298], 'val_accuracy': [0.5571120977401733, 0.5915948152542114, 0.6325430870056152, 0.5894396305084229, 0.6174569129943848, 0.6303879022598267, 0.5980603694915771, 0.6379310488700867, 0.6443965435028076, 0.649784505367279, 0.6767241358757019, 0.6357758641242981, 0.673491358757019, 0.6605603694915771, 0.670258641242981, 0.6637930870056152, 0.6508620977401733, 0.6540948152542114, 0.6465517282485962, 0.6724137663841248, 0.649784505367279, 0.670258641242981, 0.6584051847457886, 0.6411637663841248, 0.6745689511299133, 0.6411637663841248, 0.6487069129943848, 0.6648706793785095, 0.6745689511299133, 0.6681034564971924, 0.6616379022598267, 0.6584051847457886, 0.649784505367279, 0.6487069129943848, 0.6400862336158752, 0.6659482717514038, 0.649784505367279, 0.6713362336158752, 0.6745689511299133, 0.6476293206214905, 0.662715494632721, 0.6605603694915771, 0.6551724076271057, 0.6637930870056152, 0.6670258641242981, 0.6530172228813171, 0.670258641242981, 0.6670258641242981, 0.6584051847457886, 0.65625, 0.6659482717514038, 0.6584051847457886, 0.6540948152542114, 0.6648706793785095, 0.6584051847457886, 0.6573275923728943, 0.6637930870056152, 0.6551724076271057, 0.6756465435028076, 0.6573275923728943, 0.6400862336158752, 0.6681034564971924, 0.6648706793785095, 0.6745689511299133, 0.6713362336158752, 0.6465517282485962, 0.6745689511299133, 0.65625, 0.6648706793785095, 0.673491358757019, 0.6605603694915771, 0.649784505367279, 0.6573275923728943, 0.6530172228813171, 0.670258641242981, 0.673491358757019, 0.6637930870056152, 0.6778017282485962, 0.6691810488700867, 0.6519396305084229, 0.65625, 0.6648706793785095, 0.6465517282485962, 0.65625, 0.6713362336158752, 0.6691810488700867, 0.6508620977401733, 0.649784505367279, 0.6540948152542114, 0.6605603694915771, 0.6605603694915771, 0.6648706793785095, 0.662715494632721, 0.6443965435028076, 0.6443965435028076, 0.6476293206214905, 0.6659482717514038, 0.6454741358757019, 0.6551724076271057, 0.6648706793785095]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 7s 50ms/step - loss: 0.9551 - accuracy: 0.6822 - val_loss: 1.0624 - val_accuracy: 0.5532\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9318 - accuracy: 0.7094 - val_loss: 1.0594 - val_accuracy: 0.5600\n","Epoch 3/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9248 - accuracy: 0.7241 - val_loss: 1.0562 - val_accuracy: 0.5532\n","Epoch 4/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9208 - accuracy: 0.7187 - val_loss: 1.0526 - val_accuracy: 0.6176\n","Epoch 5/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9103 - accuracy: 0.7230 - val_loss: 1.0489 - val_accuracy: 0.5995\n","Epoch 6/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9017 - accuracy: 0.7337 - val_loss: 1.0452 - val_accuracy: 0.5905\n","Epoch 7/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8988 - accuracy: 0.7272 - val_loss: 1.0410 - val_accuracy: 0.6516\n","Epoch 8/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8917 - accuracy: 0.7332 - val_loss: 1.0361 - val_accuracy: 0.6550\n","Epoch 9/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8807 - accuracy: 0.7357 - val_loss: 1.0318 - val_accuracy: 0.6244\n","Epoch 10/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8786 - accuracy: 0.7405 - val_loss: 1.0262 - val_accuracy: 0.6505\n","Epoch 11/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.8750 - accuracy: 0.7462 - val_loss: 1.0205 - val_accuracy: 0.6572\n","Epoch 12/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8698 - accuracy: 0.7450 - val_loss: 1.0140 - val_accuracy: 0.6516\n","Epoch 13/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.8556 - accuracy: 0.7617 - val_loss: 1.0075 - val_accuracy: 0.6606\n","Epoch 14/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8489 - accuracy: 0.7660 - val_loss: 1.0009 - val_accuracy: 0.6572\n","Epoch 15/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.8455 - accuracy: 0.7541 - val_loss: 0.9929 - val_accuracy: 0.6697\n","Epoch 16/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8408 - accuracy: 0.7640 - val_loss: 0.9888 - val_accuracy: 0.6437\n","Epoch 17/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8408 - accuracy: 0.7572 - val_loss: 0.9824 - val_accuracy: 0.6538\n","Epoch 18/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8324 - accuracy: 0.7589 - val_loss: 0.9706 - val_accuracy: 0.6482\n","Epoch 19/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8116 - accuracy: 0.7807 - val_loss: 0.9653 - val_accuracy: 0.6674\n","Epoch 20/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8209 - accuracy: 0.7688 - val_loss: 0.9659 - val_accuracy: 0.6437\n","Epoch 21/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8228 - accuracy: 0.7671 - val_loss: 0.9534 - val_accuracy: 0.6572\n","Epoch 22/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8071 - accuracy: 0.7796 - val_loss: 0.9489 - val_accuracy: 0.6550\n","Epoch 23/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7978 - accuracy: 0.7801 - val_loss: 0.9443 - val_accuracy: 0.6618\n","Epoch 24/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7949 - accuracy: 0.7844 - val_loss: 0.9403 - val_accuracy: 0.6629\n","Epoch 25/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7853 - accuracy: 0.7864 - val_loss: 0.9448 - val_accuracy: 0.6595\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7770 - accuracy: 0.7898 - val_loss: 0.9537 - val_accuracy: 0.6550\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7846 - accuracy: 0.7816 - val_loss: 0.9588 - val_accuracy: 0.6550\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7707 - accuracy: 0.7912 - val_loss: 0.9601 - val_accuracy: 0.6572\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7642 - accuracy: 0.7977 - val_loss: 0.9488 - val_accuracy: 0.6640\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7616 - accuracy: 0.7934 - val_loss: 0.9560 - val_accuracy: 0.6561\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7527 - accuracy: 0.7965 - val_loss: 0.9587 - val_accuracy: 0.6550\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7494 - accuracy: 0.8070 - val_loss: 0.9573 - val_accuracy: 0.6618\n","Epoch 33/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7358 - accuracy: 0.8096 - val_loss: 0.9572 - val_accuracy: 0.6697\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7324 - accuracy: 0.8113 - val_loss: 0.9651 - val_accuracy: 0.6629\n","Epoch 35/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7261 - accuracy: 0.8178 - val_loss: 0.9822 - val_accuracy: 0.6505\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7255 - accuracy: 0.8124 - val_loss: 0.9826 - val_accuracy: 0.6505\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7174 - accuracy: 0.8186 - val_loss: 0.9650 - val_accuracy: 0.6618\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7146 - accuracy: 0.8198 - val_loss: 0.9690 - val_accuracy: 0.6686\n","Epoch 39/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7033 - accuracy: 0.8226 - val_loss: 0.9765 - val_accuracy: 0.6686\n","Epoch 40/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7030 - accuracy: 0.8212 - val_loss: 0.9835 - val_accuracy: 0.6652\n","Epoch 41/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6942 - accuracy: 0.8311 - val_loss: 0.9745 - val_accuracy: 0.6663\n","Epoch 42/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6928 - accuracy: 0.8277 - val_loss: 0.9812 - val_accuracy: 0.6674\n","Epoch 43/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6876 - accuracy: 0.8240 - val_loss: 1.0028 - val_accuracy: 0.6448\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6704 - accuracy: 0.8472 - val_loss: 0.9842 - val_accuracy: 0.6618\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6732 - accuracy: 0.8381 - val_loss: 0.9862 - val_accuracy: 0.6606\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6684 - accuracy: 0.8356 - val_loss: 0.9894 - val_accuracy: 0.6640\n","Epoch 47/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6577 - accuracy: 0.8398 - val_loss: 1.0294 - val_accuracy: 0.6448\n","Epoch 48/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6642 - accuracy: 0.8410 - val_loss: 1.0032 - val_accuracy: 0.6459\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6473 - accuracy: 0.8517 - val_loss: 1.0077 - val_accuracy: 0.6516\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6472 - accuracy: 0.8432 - val_loss: 1.0118 - val_accuracy: 0.6538\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6327 - accuracy: 0.8594 - val_loss: 1.0064 - val_accuracy: 0.6618\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6361 - accuracy: 0.8506 - val_loss: 1.0071 - val_accuracy: 0.6606\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6220 - accuracy: 0.8611 - val_loss: 1.0148 - val_accuracy: 0.6618\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6237 - accuracy: 0.8582 - val_loss: 1.0230 - val_accuracy: 0.6505\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6126 - accuracy: 0.8684 - val_loss: 1.0220 - val_accuracy: 0.6629\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6247 - accuracy: 0.8645 - val_loss: 1.0791 - val_accuracy: 0.6425\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6094 - accuracy: 0.8633 - val_loss: 1.0292 - val_accuracy: 0.6629\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5996 - accuracy: 0.8662 - val_loss: 1.0512 - val_accuracy: 0.6527\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5977 - accuracy: 0.8681 - val_loss: 1.0331 - val_accuracy: 0.6595\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6009 - accuracy: 0.8681 - val_loss: 1.0321 - val_accuracy: 0.6584\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6099 - accuracy: 0.8588 - val_loss: 1.0353 - val_accuracy: 0.6629\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5877 - accuracy: 0.8778 - val_loss: 1.0518 - val_accuracy: 0.6618\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5795 - accuracy: 0.8786 - val_loss: 1.0440 - val_accuracy: 0.6561\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5675 - accuracy: 0.8871 - val_loss: 1.0502 - val_accuracy: 0.6606\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5676 - accuracy: 0.8865 - val_loss: 1.0696 - val_accuracy: 0.6471\n","Epoch 66/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5637 - accuracy: 0.8888 - val_loss: 1.0720 - val_accuracy: 0.6505\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5729 - accuracy: 0.8758 - val_loss: 1.0652 - val_accuracy: 0.6538\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5604 - accuracy: 0.8831 - val_loss: 1.0933 - val_accuracy: 0.6459\n","Epoch 69/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5606 - accuracy: 0.8857 - val_loss: 1.0623 - val_accuracy: 0.6595\n","Epoch 70/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5529 - accuracy: 0.8848 - val_loss: 1.0677 - val_accuracy: 0.6572\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5622 - accuracy: 0.8775 - val_loss: 1.0713 - val_accuracy: 0.6538\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5434 - accuracy: 0.8930 - val_loss: 1.0888 - val_accuracy: 0.6516\n","Epoch 73/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5391 - accuracy: 0.8922 - val_loss: 1.1286 - val_accuracy: 0.6482\n","Epoch 74/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5361 - accuracy: 0.8894 - val_loss: 1.1137 - val_accuracy: 0.6550\n","Epoch 75/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5296 - accuracy: 0.8984 - val_loss: 1.0856 - val_accuracy: 0.6618\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5158 - accuracy: 0.9117 - val_loss: 1.0976 - val_accuracy: 0.6493\n","Epoch 77/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5213 - accuracy: 0.9012 - val_loss: 1.1063 - val_accuracy: 0.6550\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5223 - accuracy: 0.9004 - val_loss: 1.1242 - val_accuracy: 0.6414\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5180 - accuracy: 0.8981 - val_loss: 1.1085 - val_accuracy: 0.6550\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4996 - accuracy: 0.9114 - val_loss: 1.1273 - val_accuracy: 0.6505\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4995 - accuracy: 0.9151 - val_loss: 1.1301 - val_accuracy: 0.6516\n","Epoch 82/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4953 - accuracy: 0.9154 - val_loss: 1.1370 - val_accuracy: 0.6505\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4917 - accuracy: 0.9194 - val_loss: 1.1452 - val_accuracy: 0.6527\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4893 - accuracy: 0.9148 - val_loss: 1.1252 - val_accuracy: 0.6538\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4847 - accuracy: 0.9199 - val_loss: 1.1709 - val_accuracy: 0.6448\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4863 - accuracy: 0.9168 - val_loss: 1.1564 - val_accuracy: 0.6606\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4795 - accuracy: 0.9148 - val_loss: 1.1497 - val_accuracy: 0.6538\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4742 - accuracy: 0.9196 - val_loss: 1.1588 - val_accuracy: 0.6471\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4641 - accuracy: 0.9250 - val_loss: 1.2093 - val_accuracy: 0.6459\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4742 - accuracy: 0.9191 - val_loss: 1.1724 - val_accuracy: 0.6584\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4726 - accuracy: 0.9188 - val_loss: 1.2538 - val_accuracy: 0.6459\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4648 - accuracy: 0.9276 - val_loss: 1.1830 - val_accuracy: 0.6425\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4538 - accuracy: 0.9310 - val_loss: 1.2066 - val_accuracy: 0.6403\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4537 - accuracy: 0.9261 - val_loss: 1.2242 - val_accuracy: 0.6459\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4417 - accuracy: 0.9327 - val_loss: 1.2149 - val_accuracy: 0.6437\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4426 - accuracy: 0.9321 - val_loss: 1.1974 - val_accuracy: 0.6550\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4310 - accuracy: 0.9406 - val_loss: 1.2077 - val_accuracy: 0.6550\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4332 - accuracy: 0.9423 - val_loss: 1.2167 - val_accuracy: 0.6527\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4281 - accuracy: 0.9372 - val_loss: 1.2260 - val_accuracy: 0.6471\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4220 - accuracy: 0.9386 - val_loss: 1.2324 - val_accuracy: 0.6403\n","{'loss': [0.9551177024841309, 0.9317559003829956, 0.9248495697975159, 0.9208018779754639, 0.9103142023086548, 0.9017436504364014, 0.8987610340118408, 0.8917362689971924, 0.8806919455528259, 0.87864089012146, 0.8750020265579224, 0.8698381781578064, 0.8556075096130371, 0.8488994240760803, 0.8454773426055908, 0.840751588344574, 0.8408330082893372, 0.8323808312416077, 0.8115577101707458, 0.8208536505699158, 0.8228432536125183, 0.8071370124816895, 0.7978343367576599, 0.7948642373085022, 0.7853366732597351, 0.7769908905029297, 0.7845725417137146, 0.770746648311615, 0.7642481923103333, 0.7616069912910461, 0.7526693344116211, 0.749366044998169, 0.7358428835868835, 0.7324429750442505, 0.7260529398918152, 0.7255132794380188, 0.717361569404602, 0.714616060256958, 0.7033142447471619, 0.7029707431793213, 0.6942234635353088, 0.6927998661994934, 0.6876171827316284, 0.6703745722770691, 0.6732442378997803, 0.6683807373046875, 0.6576947569847107, 0.6642336249351501, 0.6472906470298767, 0.6472381353378296, 0.632675290107727, 0.6361302733421326, 0.6220486164093018, 0.6237387657165527, 0.6125544309616089, 0.624655544757843, 0.6093806028366089, 0.5996440052986145, 0.5977087020874023, 0.6008874773979187, 0.6099363565444946, 0.58770352602005, 0.5795259475708008, 0.5674886107444763, 0.5676468014717102, 0.5636501908302307, 0.5729143619537354, 0.5603533983230591, 0.5605965256690979, 0.5529437065124512, 0.5621764659881592, 0.5434301495552063, 0.5391125082969666, 0.5360886454582214, 0.5296304225921631, 0.5157895684242249, 0.5213462114334106, 0.5223231315612793, 0.5180216431617737, 0.4996356964111328, 0.4994696378707886, 0.49526745080947876, 0.49170589447021484, 0.4892745018005371, 0.4846992790699005, 0.4862997233867645, 0.4794718027114868, 0.47424939274787903, 0.46410995721817017, 0.47424691915512085, 0.4726486802101135, 0.46481549739837646, 0.4537997245788574, 0.45373839139938354, 0.44171494245529175, 0.44261088967323303, 0.4309538006782532, 0.4331988990306854, 0.42807066440582275, 0.42197033762931824], 'accuracy': [0.68222975730896, 0.7093944549560547, 0.7241086363792419, 0.7187322974205017, 0.722976803779602, 0.7337294816970825, 0.7272212505340576, 0.7331635355949402, 0.7357102632522583, 0.7405206561088562, 0.7461799383163452, 0.7450481057167053, 0.7617430686950684, 0.7659875750541687, 0.7541030049324036, 0.7640067934989929, 0.7572156190872192, 0.7589133977890015, 0.780701756477356, 0.7688171863555908, 0.7671194076538086, 0.7795698642730713, 0.7801358103752136, 0.784380316734314, 0.786361038684845, 0.7897566556930542, 0.7815506458282471, 0.7911714911460876, 0.7976796627044678, 0.7934352159500122, 0.7965478301048279, 0.8070175647735596, 0.8095642328262329, 0.8112620115280151, 0.81777024269104, 0.8123939037322998, 0.8186191320419312, 0.819750964641571, 0.8225806355476379, 0.8211658000946045, 0.8310695886611938, 0.8276740312576294, 0.8239954710006714, 0.8471986651420593, 0.8381437659263611, 0.835597038269043, 0.8398415446281433, 0.8409733772277832, 0.8517261147499084, 0.8432371020317078, 0.8593661785125732, 0.8505942225456238, 0.8610639572143555, 0.8582342863082886, 0.8684210777282715, 0.8644595146179199, 0.86332768201828, 0.8661573529243469, 0.8681380748748779, 0.8681380748748779, 0.8588002324104309, 0.8777589201927185, 0.8786078095436096, 0.8870967626571655, 0.8865308165550232, 0.8887945413589478, 0.8757781386375427, 0.8831352591514587, 0.8856819272041321, 0.884833037853241, 0.8774759769439697, 0.8930390477180481, 0.892190158367157, 0.8893604874610901, 0.8984153866767883, 0.9117147922515869, 0.9012450575828552, 0.9003961682319641, 0.8981324434280396, 0.9114317893981934, 0.9151103496551514, 0.9153932929039001, 0.9193548560142517, 0.9148274064064026, 0.9199207425117493, 0.9168081283569336, 0.9148274064064026, 0.9196377992630005, 0.9250141382217407, 0.9190718531608582, 0.9187889099121094, 0.9275608658790588, 0.9309564232826233, 0.9261460304260254, 0.9326542019844055, 0.9320882558822632, 0.9405772686004639, 0.9422750473022461, 0.9371816515922546, 0.9385964870452881], 'val_loss': [1.0623940229415894, 1.059436559677124, 1.0562330484390259, 1.0525785684585571, 1.0489234924316406, 1.0451953411102295, 1.0409739017486572, 1.0361039638519287, 1.031785249710083, 1.0261837244033813, 1.0204819440841675, 1.0140178203582764, 1.0075420141220093, 1.0008631944656372, 0.9929308891296387, 0.9887846112251282, 0.982444167137146, 0.9706275463104248, 0.9652820229530334, 0.9658589363098145, 0.9534395933151245, 0.9489195346832275, 0.9442543983459473, 0.9402934908866882, 0.9448368549346924, 0.9537213444709778, 0.9588382244110107, 0.9600836038589478, 0.948821485042572, 0.9560198783874512, 0.9586750268936157, 0.9572832584381104, 0.9571674466133118, 0.9651169180870056, 0.9821751117706299, 0.9825952649116516, 0.964983344078064, 0.9689949750900269, 0.9764502048492432, 0.983460009098053, 0.974500834941864, 0.9811558723449707, 1.0027971267700195, 0.9841932654380798, 0.9862449169158936, 0.989362895488739, 1.0294415950775146, 1.0032243728637695, 1.0076991319656372, 1.0117534399032593, 1.0064105987548828, 1.0070507526397705, 1.0147933959960938, 1.0230103731155396, 1.022035837173462, 1.079065203666687, 1.0291836261749268, 1.0512096881866455, 1.033105731010437, 1.0320651531219482, 1.0352777242660522, 1.051811933517456, 1.0440142154693604, 1.0502039194107056, 1.0696088075637817, 1.0719728469848633, 1.0651508569717407, 1.0933300256729126, 1.0622941255569458, 1.067739725112915, 1.0712788105010986, 1.0888057947158813, 1.1286394596099854, 1.1137338876724243, 1.0855618715286255, 1.09756600856781, 1.1062835454940796, 1.1241878271102905, 1.1085070371627808, 1.1273473501205444, 1.130072832107544, 1.136997938156128, 1.1452491283416748, 1.12519371509552, 1.1708801984786987, 1.1564029455184937, 1.149720311164856, 1.1587556600570679, 1.2093043327331543, 1.172440767288208, 1.2538303136825562, 1.18302321434021, 1.2065520286560059, 1.2242496013641357, 1.214924931526184, 1.1974276304244995, 1.2077089548110962, 1.216705322265625, 1.226032018661499, 1.232366681098938], 'val_accuracy': [0.5531674027442932, 0.5599547624588013, 0.5531674027442932, 0.6176470518112183, 0.5995475053787231, 0.5904977321624756, 0.651583731174469, 0.6549773812294006, 0.6244344115257263, 0.6504524946212769, 0.6572397947311401, 0.651583731174469, 0.6606335043907166, 0.6572397947311401, 0.6696832776069641, 0.6436651349067688, 0.6538461446762085, 0.6481900215148926, 0.6674208045005798, 0.6436651349067688, 0.6572397947311401, 0.6549773812294006, 0.6617646813392639, 0.662895917892456, 0.6595022678375244, 0.6549773812294006, 0.6549773812294006, 0.6572397947311401, 0.6640271544456482, 0.6561086177825928, 0.6549773812294006, 0.6617646813392639, 0.6696832776069641, 0.662895917892456, 0.6504524946212769, 0.6504524946212769, 0.6617646813392639, 0.668552041053772, 0.668552041053772, 0.6651583909988403, 0.6662895679473877, 0.6674208045005798, 0.6447963714599609, 0.6617646813392639, 0.6606335043907166, 0.6640271544456482, 0.6447963714599609, 0.6459276080131531, 0.651583731174469, 0.6538461446762085, 0.6617646813392639, 0.6606335043907166, 0.6617646813392639, 0.6504524946212769, 0.662895917892456, 0.6425339579582214, 0.662895917892456, 0.6527149081230164, 0.6595022678375244, 0.6583710312843323, 0.662895917892456, 0.6617646813392639, 0.6561086177825928, 0.6606335043907166, 0.6470588445663452, 0.6504524946212769, 0.6538461446762085, 0.6459276080131531, 0.6595022678375244, 0.6572397947311401, 0.6538461446762085, 0.651583731174469, 0.6481900215148926, 0.6549773812294006, 0.6617646813392639, 0.6493212580680847, 0.6549773812294006, 0.6414027214050293, 0.6549773812294006, 0.6504524946212769, 0.651583731174469, 0.6504524946212769, 0.6527149081230164, 0.6538461446762085, 0.6447963714599609, 0.6606335043907166, 0.6538461446762085, 0.6470588445663452, 0.6459276080131531, 0.6583710312843323, 0.6459276080131531, 0.6425339579582214, 0.6402714848518372, 0.6459276080131531, 0.6436651349067688, 0.6549773812294006, 0.6549773812294006, 0.6527149081230164, 0.6470588445663452, 0.6402714848518372]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/31 [=========================>....] - ETA: 0s - loss: 0.9444 - accuracy: 0.7089"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 47ms/step - loss: 0.9442 - accuracy: 0.7072 - val_loss: 1.0645 - val_accuracy: 0.5165\n","Epoch 2/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9309 - accuracy: 0.7121 - val_loss: 1.0618 - val_accuracy: 0.5165\n","Epoch 3/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9248 - accuracy: 0.7191 - val_loss: 1.0580 - val_accuracy: 0.5455\n","Epoch 4/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9153 - accuracy: 0.7220 - val_loss: 1.0552 - val_accuracy: 0.5300\n","Epoch 5/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9112 - accuracy: 0.7152 - val_loss: 1.0518 - val_accuracy: 0.5351\n","Epoch 6/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9036 - accuracy: 0.7339 - val_loss: 1.0478 - val_accuracy: 0.5816\n","Epoch 7/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8967 - accuracy: 0.7300 - val_loss: 1.0448 - val_accuracy: 0.5610\n","Epoch 8/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8910 - accuracy: 0.7276 - val_loss: 1.0401 - val_accuracy: 0.6033\n","Epoch 9/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8931 - accuracy: 0.7320 - val_loss: 1.0363 - val_accuracy: 0.5919\n","Epoch 10/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8723 - accuracy: 0.7419 - val_loss: 1.0324 - val_accuracy: 0.5961\n","Epoch 11/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8730 - accuracy: 0.7455 - val_loss: 1.0311 - val_accuracy: 0.5548\n","Epoch 12/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8747 - accuracy: 0.7313 - val_loss: 1.0260 - val_accuracy: 0.5599\n","Epoch 13/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8598 - accuracy: 0.7473 - val_loss: 1.0228 - val_accuracy: 0.5589\n","Epoch 14/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8508 - accuracy: 0.7548 - val_loss: 1.0184 - val_accuracy: 0.5878\n","Epoch 15/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8421 - accuracy: 0.7672 - val_loss: 1.0153 - val_accuracy: 0.5847\n","Epoch 16/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.8428 - accuracy: 0.7581 - val_loss: 1.0080 - val_accuracy: 0.6209\n","Epoch 17/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8341 - accuracy: 0.7654 - val_loss: 1.0036 - val_accuracy: 0.6157\n","Epoch 18/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8334 - accuracy: 0.7607 - val_loss: 1.0085 - val_accuracy: 0.6095\n","Epoch 19/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8323 - accuracy: 0.7514 - val_loss: 1.0064 - val_accuracy: 0.6178\n","Epoch 20/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8161 - accuracy: 0.7649 - val_loss: 1.0074 - val_accuracy: 0.6188\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8093 - accuracy: 0.7791 - val_loss: 1.0099 - val_accuracy: 0.6167\n","Epoch 22/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8036 - accuracy: 0.7827 - val_loss: 1.0158 - val_accuracy: 0.6136\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8004 - accuracy: 0.7778 - val_loss: 1.0260 - val_accuracy: 0.6023\n","Epoch 24/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7951 - accuracy: 0.7832 - val_loss: 1.0311 - val_accuracy: 0.6178\n","Epoch 25/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7951 - accuracy: 0.7796 - val_loss: 1.0385 - val_accuracy: 0.6250\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7834 - accuracy: 0.7891 - val_loss: 1.0429 - val_accuracy: 0.6126\n","Epoch 27/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7889 - accuracy: 0.7780 - val_loss: 1.0488 - val_accuracy: 0.6240\n","Epoch 28/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7719 - accuracy: 0.7848 - val_loss: 1.0506 - val_accuracy: 0.6260\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7730 - accuracy: 0.7922 - val_loss: 1.0566 - val_accuracy: 0.6178\n","Epoch 30/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7730 - accuracy: 0.7886 - val_loss: 1.0595 - val_accuracy: 0.6271\n","Epoch 31/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7549 - accuracy: 0.8010 - val_loss: 1.0812 - val_accuracy: 0.5971\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7558 - accuracy: 0.7876 - val_loss: 1.0704 - val_accuracy: 0.6209\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7473 - accuracy: 0.8003 - val_loss: 1.0832 - val_accuracy: 0.6064\n","Epoch 34/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7427 - accuracy: 0.8049 - val_loss: 1.0935 - val_accuracy: 0.5940\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7401 - accuracy: 0.7990 - val_loss: 1.0878 - val_accuracy: 0.6054\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7311 - accuracy: 0.8103 - val_loss: 1.0929 - val_accuracy: 0.5919\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7279 - accuracy: 0.8114 - val_loss: 1.0918 - val_accuracy: 0.6033\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7179 - accuracy: 0.8158 - val_loss: 1.0807 - val_accuracy: 0.6136\n","Epoch 39/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7184 - accuracy: 0.8155 - val_loss: 1.1237 - val_accuracy: 0.5837\n","Epoch 40/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7164 - accuracy: 0.8165 - val_loss: 1.1025 - val_accuracy: 0.6188\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7060 - accuracy: 0.8134 - val_loss: 1.0905 - val_accuracy: 0.6136\n","Epoch 42/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7095 - accuracy: 0.8163 - val_loss: 1.1035 - val_accuracy: 0.6085\n","Epoch 43/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6908 - accuracy: 0.8305 - val_loss: 1.1029 - val_accuracy: 0.6116\n","Epoch 44/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6824 - accuracy: 0.8377 - val_loss: 1.1206 - val_accuracy: 0.6043\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6852 - accuracy: 0.8222 - val_loss: 1.1536 - val_accuracy: 0.5857\n","Epoch 46/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6792 - accuracy: 0.8357 - val_loss: 1.1163 - val_accuracy: 0.6126\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6684 - accuracy: 0.8359 - val_loss: 1.1264 - val_accuracy: 0.6095\n","Epoch 48/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6659 - accuracy: 0.8398 - val_loss: 1.1245 - val_accuracy: 0.6157\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6614 - accuracy: 0.8354 - val_loss: 1.1251 - val_accuracy: 0.6178\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6540 - accuracy: 0.8390 - val_loss: 1.1388 - val_accuracy: 0.6023\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6585 - accuracy: 0.8380 - val_loss: 1.1645 - val_accuracy: 0.5878\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6485 - accuracy: 0.8434 - val_loss: 1.1479 - val_accuracy: 0.6136\n","Epoch 53/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6376 - accuracy: 0.8494 - val_loss: 1.1446 - val_accuracy: 0.6043\n","Epoch 54/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6408 - accuracy: 0.8475 - val_loss: 1.1494 - val_accuracy: 0.6136\n","Epoch 55/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6281 - accuracy: 0.8504 - val_loss: 1.1551 - val_accuracy: 0.6064\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6228 - accuracy: 0.8584 - val_loss: 1.1600 - val_accuracy: 0.6095\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6249 - accuracy: 0.8553 - val_loss: 1.1702 - val_accuracy: 0.6095\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6170 - accuracy: 0.8581 - val_loss: 1.1790 - val_accuracy: 0.6012\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6140 - accuracy: 0.8563 - val_loss: 1.1917 - val_accuracy: 0.5992\n","Epoch 60/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6078 - accuracy: 0.8628 - val_loss: 1.1844 - val_accuracy: 0.5992\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6015 - accuracy: 0.8636 - val_loss: 1.1766 - val_accuracy: 0.6064\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5933 - accuracy: 0.8700 - val_loss: 1.1831 - val_accuracy: 0.6064\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5919 - accuracy: 0.8661 - val_loss: 1.1865 - val_accuracy: 0.6126\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5886 - accuracy: 0.8687 - val_loss: 1.1912 - val_accuracy: 0.6126\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5878 - accuracy: 0.8641 - val_loss: 1.2296 - val_accuracy: 0.5961\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6002 - accuracy: 0.8556 - val_loss: 1.1976 - val_accuracy: 0.6085\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5775 - accuracy: 0.8742 - val_loss: 1.2070 - val_accuracy: 0.6147\n","Epoch 68/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5680 - accuracy: 0.8760 - val_loss: 1.2197 - val_accuracy: 0.6136\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5640 - accuracy: 0.8804 - val_loss: 1.2285 - val_accuracy: 0.6043\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5553 - accuracy: 0.8824 - val_loss: 1.2322 - val_accuracy: 0.6126\n","Epoch 71/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5549 - accuracy: 0.8829 - val_loss: 1.2405 - val_accuracy: 0.6085\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5451 - accuracy: 0.8873 - val_loss: 1.2528 - val_accuracy: 0.5930\n","Epoch 73/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5465 - accuracy: 0.8907 - val_loss: 1.2470 - val_accuracy: 0.6054\n","Epoch 74/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5392 - accuracy: 0.8894 - val_loss: 1.2885 - val_accuracy: 0.5847\n","Epoch 75/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5425 - accuracy: 0.8871 - val_loss: 1.3040 - val_accuracy: 0.5826\n","Epoch 76/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5413 - accuracy: 0.8822 - val_loss: 1.2699 - val_accuracy: 0.6033\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5287 - accuracy: 0.8938 - val_loss: 1.2660 - val_accuracy: 0.5950\n","Epoch 78/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5256 - accuracy: 0.8899 - val_loss: 1.2743 - val_accuracy: 0.6095\n","Epoch 79/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5229 - accuracy: 0.8961 - val_loss: 1.2896 - val_accuracy: 0.5961\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5192 - accuracy: 0.8943 - val_loss: 1.2975 - val_accuracy: 0.6002\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5152 - accuracy: 0.8995 - val_loss: 1.2967 - val_accuracy: 0.6033\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5054 - accuracy: 0.9016 - val_loss: 1.2969 - val_accuracy: 0.6095\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5156 - accuracy: 0.8966 - val_loss: 1.3031 - val_accuracy: 0.6043\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5128 - accuracy: 0.8984 - val_loss: 1.3014 - val_accuracy: 0.6095\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4934 - accuracy: 0.9088 - val_loss: 1.3353 - val_accuracy: 0.6023\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5043 - accuracy: 0.8948 - val_loss: 1.3996 - val_accuracy: 0.5868\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4944 - accuracy: 0.9036 - val_loss: 1.3169 - val_accuracy: 0.6085\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4811 - accuracy: 0.9124 - val_loss: 1.3457 - val_accuracy: 0.5971\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4955 - accuracy: 0.9059 - val_loss: 1.3431 - val_accuracy: 0.5950\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4868 - accuracy: 0.9088 - val_loss: 1.3884 - val_accuracy: 0.5847\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4749 - accuracy: 0.9137 - val_loss: 1.3429 - val_accuracy: 0.6033\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4669 - accuracy: 0.9171 - val_loss: 1.3555 - val_accuracy: 0.5950\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4617 - accuracy: 0.9171 - val_loss: 1.3667 - val_accuracy: 0.5909\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4697 - accuracy: 0.9163 - val_loss: 1.3536 - val_accuracy: 0.6074\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4620 - accuracy: 0.9209 - val_loss: 1.3800 - val_accuracy: 0.6043\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4567 - accuracy: 0.9212 - val_loss: 1.3866 - val_accuracy: 0.6085\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4498 - accuracy: 0.9220 - val_loss: 1.4011 - val_accuracy: 0.6023\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4440 - accuracy: 0.9287 - val_loss: 1.3968 - val_accuracy: 0.6033\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4492 - accuracy: 0.9209 - val_loss: 1.4207 - val_accuracy: 0.5971\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4499 - accuracy: 0.9222 - val_loss: 1.4342 - val_accuracy: 0.5981\n","{'loss': [0.9441724419593811, 0.9309214353561401, 0.9247972965240479, 0.9153227806091309, 0.9111512899398804, 0.9035857319831848, 0.8966974020004272, 0.8910443186759949, 0.8931265473365784, 0.8723151087760925, 0.8730008602142334, 0.8747162222862244, 0.8597757816314697, 0.8507923483848572, 0.8420671224594116, 0.8428477644920349, 0.8340556621551514, 0.8333847522735596, 0.8323161005973816, 0.8160609006881714, 0.8093122243881226, 0.8036288022994995, 0.8003962635993958, 0.7950609922409058, 0.7951101064682007, 0.7834479212760925, 0.788935661315918, 0.7719294428825378, 0.7730026245117188, 0.7729915380477905, 0.7549050450325012, 0.7557769417762756, 0.7472535967826843, 0.7426918745040894, 0.7400859594345093, 0.7310802936553955, 0.727890133857727, 0.7179274559020996, 0.7184271216392517, 0.7163901925086975, 0.7060416340827942, 0.7094600200653076, 0.6908443570137024, 0.6823670268058777, 0.6852056980133057, 0.6792049407958984, 0.6684355735778809, 0.6658668518066406, 0.6613891124725342, 0.6540420055389404, 0.6585330367088318, 0.648540735244751, 0.6376157999038696, 0.6407787203788757, 0.6281140446662903, 0.6228415966033936, 0.6249167919158936, 0.6169834733009338, 0.6140052080154419, 0.6078295111656189, 0.6015390753746033, 0.593324601650238, 0.5919311046600342, 0.5886465311050415, 0.5877941846847534, 0.6001561284065247, 0.5774627923965454, 0.5679835081100464, 0.5639795660972595, 0.5553445816040039, 0.554872989654541, 0.5451431274414062, 0.5465173721313477, 0.5391560196876526, 0.5424659848213196, 0.5412595272064209, 0.5287204384803772, 0.5255595445632935, 0.5229412317276001, 0.519160807132721, 0.515189528465271, 0.5053972005844116, 0.5156095027923584, 0.5127657651901245, 0.49339884519577026, 0.5042603015899658, 0.49438804388046265, 0.48112887144088745, 0.4955101013183594, 0.48679807782173157, 0.4748688340187073, 0.46688777208328247, 0.46171092987060547, 0.46974560618400574, 0.4620193839073181, 0.45671629905700684, 0.4498109519481659, 0.4439942538738251, 0.44917577505111694, 0.44992533326148987], 'accuracy': [0.7072351574897766, 0.7121447324752808, 0.7191214561462402, 0.7219638228416443, 0.7152454853057861, 0.7338501214981079, 0.7299741506576538, 0.7276485562324524, 0.7320413589477539, 0.7418604493141174, 0.7454780340194702, 0.7312661409378052, 0.7472867965698242, 0.7547803521156311, 0.7671834826469421, 0.7581395506858826, 0.7653746604919434, 0.7607235312461853, 0.7514212131500244, 0.7648578882217407, 0.7790697813034058, 0.7826873660087585, 0.7777777910232544, 0.7832041382789612, 0.7795865535736084, 0.7891472578048706, 0.7780361771583557, 0.7847545146942139, 0.7922480702400208, 0.788630485534668, 0.801033616065979, 0.7875968813896179, 0.8002583980560303, 0.8049095869064331, 0.7989664077758789, 0.8103359341621399, 0.8113695383071899, 0.8157622814178467, 0.8155038952827454, 0.8165374398231506, 0.8134366869926453, 0.8162790536880493, 0.8304909467697144, 0.8377261161804199, 0.8222222328186035, 0.8356589078903198, 0.8359172940254211, 0.8397932648658752, 0.8354005217552185, 0.8390181064605713, 0.8379845023155212, 0.843410849571228, 0.8493540287017822, 0.8475452065467834, 0.8503875732421875, 0.8583979606628418, 0.8552971482276917, 0.8581395149230957, 0.8563307523727417, 0.8627907037734985, 0.8635658621788025, 0.8700258135795593, 0.8661498427391052, 0.868733823299408, 0.8640826940536499, 0.855555534362793, 0.8741602301597595, 0.8759689927101135, 0.8803617358207703, 0.8824289441108704, 0.882945716381073, 0.8873385190963745, 0.8906976580619812, 0.8894056677818298, 0.8870801329612732, 0.882170557975769, 0.8937984704971313, 0.8899224996566772, 0.896124005317688, 0.894315242767334, 0.8994832038879395, 0.9015504121780396, 0.8966408371925354, 0.8984495997428894, 0.9087855219841003, 0.8948320150375366, 0.9036175608634949, 0.9124031066894531, 0.9059431552886963, 0.9087855219841003, 0.9136950969696045, 0.9170542359352112, 0.9170542359352112, 0.9162790775299072, 0.9209302067756653, 0.9211886525154114, 0.9219638109207153, 0.9286821484565735, 0.9209302067756653, 0.9222221970558167], 'val_loss': [1.0645159482955933, 1.0617765188217163, 1.057967185974121, 1.0552057027816772, 1.0517586469650269, 1.0477657318115234, 1.0448176860809326, 1.0401302576065063, 1.0363472700119019, 1.032415509223938, 1.0311065912246704, 1.025989055633545, 1.022783637046814, 1.0184321403503418, 1.0152957439422607, 1.0080022811889648, 1.0036332607269287, 1.0084724426269531, 1.0064188241958618, 1.007372498512268, 1.0099283456802368, 1.0158125162124634, 1.0259809494018555, 1.0310699939727783, 1.038533329963684, 1.0428911447525024, 1.0487685203552246, 1.0505770444869995, 1.0566022396087646, 1.059455394744873, 1.0811721086502075, 1.070438265800476, 1.083246111869812, 1.0935312509536743, 1.0877634286880493, 1.092907190322876, 1.0917569398880005, 1.0806671380996704, 1.1236860752105713, 1.1024843454360962, 1.0904735326766968, 1.1035465002059937, 1.1028774976730347, 1.1206159591674805, 1.1536012887954712, 1.1163132190704346, 1.1263667345046997, 1.1245282888412476, 1.1250931024551392, 1.1388405561447144, 1.1645110845565796, 1.1479098796844482, 1.144644856452942, 1.1493951082229614, 1.1550639867782593, 1.1600292921066284, 1.1702309846878052, 1.1790294647216797, 1.1916731595993042, 1.1843637228012085, 1.176558494567871, 1.183085560798645, 1.1864551305770874, 1.1911956071853638, 1.229602575302124, 1.1976172924041748, 1.2070225477218628, 1.2196766138076782, 1.2285237312316895, 1.2321927547454834, 1.2405070066452026, 1.252768874168396, 1.2469513416290283, 1.2884984016418457, 1.3039990663528442, 1.269884467124939, 1.2659987211227417, 1.2743041515350342, 1.2895519733428955, 1.2974978685379028, 1.296688437461853, 1.2969084978103638, 1.303086280822754, 1.3013957738876343, 1.3353252410888672, 1.399572491645813, 1.3169225454330444, 1.3456796407699585, 1.3430838584899902, 1.3884190320968628, 1.342881441116333, 1.3555234670639038, 1.3667453527450562, 1.3535661697387695, 1.3800119161605835, 1.386644721031189, 1.4010508060455322, 1.3968441486358643, 1.420707106590271, 1.4342286586761475], 'val_accuracy': [0.5165289044380188, 0.5165289044380188, 0.5454545617103577, 0.5299586653709412, 0.5351239442825317, 0.5816115736961365, 0.5609503984451294, 0.6033057570457458, 0.5919421315193176, 0.5960744023323059, 0.5547520518302917, 0.5599173307418823, 0.55888432264328, 0.5878099203109741, 0.5847107172012329, 0.6208677887916565, 0.6157024502754211, 0.6095041036605835, 0.6177685856819153, 0.6188016533851624, 0.6167355179786682, 0.6136363744735718, 0.6022727489471436, 0.6177685856819153, 0.625, 0.6126033067703247, 0.6239669322967529, 0.6260330677032471, 0.6177685856819153, 0.6270661354064941, 0.5971074104309082, 0.6208677887916565, 0.6064049601554871, 0.5940082669258118, 0.60537189245224, 0.5919421315193176, 0.6033057570457458, 0.6136363744735718, 0.5836777091026306, 0.6188016533851624, 0.6136363744735718, 0.6084710955619812, 0.6115702390670776, 0.6043388247489929, 0.58574378490448, 0.6126033067703247, 0.6095041036605835, 0.6157024502754211, 0.6177685856819153, 0.6022727489471436, 0.5878099203109741, 0.6136363744735718, 0.6043388247489929, 0.6136363744735718, 0.6064049601554871, 0.6095041036605835, 0.6095041036605835, 0.6012396812438965, 0.5991735458374023, 0.5991735458374023, 0.6064049601554871, 0.6064049601554871, 0.6126033067703247, 0.6126033067703247, 0.5960744023323059, 0.6084710955619812, 0.6146694421768188, 0.6136363744735718, 0.6043388247489929, 0.6126033067703247, 0.6084710955619812, 0.5929751992225647, 0.60537189245224, 0.5847107172012329, 0.5826446413993835, 0.6033057570457458, 0.5950413346290588, 0.6095041036605835, 0.5960744023323059, 0.6002066135406494, 0.6033057570457458, 0.6095041036605835, 0.6043388247489929, 0.6095041036605835, 0.6022727489471436, 0.586776852607727, 0.6084710955619812, 0.5971074104309082, 0.5950413346290588, 0.5847107172012329, 0.6033057570457458, 0.5950413346290588, 0.5909090638160706, 0.6074380278587341, 0.6043388247489929, 0.6084710955619812, 0.6022727489471436, 0.6033057570457458, 0.5971074104309082, 0.5981404781341553]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 0.5746 - accuracy: 0.8620"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 49ms/step - loss: 0.5751 - accuracy: 0.8615 - val_loss: 0.9455 - val_accuracy: 0.4946\n","Epoch 2/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5607 - accuracy: 0.8669 - val_loss: 0.9370 - val_accuracy: 0.5054\n","Epoch 3/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5471 - accuracy: 0.8772 - val_loss: 0.9343 - val_accuracy: 0.5086\n","Epoch 4/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5328 - accuracy: 0.8812 - val_loss: 0.9303 - val_accuracy: 0.5151\n","Epoch 5/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5135 - accuracy: 0.8909 - val_loss: 0.9261 - val_accuracy: 0.5140\n","Epoch 6/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5255 - accuracy: 0.8798 - val_loss: 0.9142 - val_accuracy: 0.5356\n","Epoch 7/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5076 - accuracy: 0.8912 - val_loss: 0.9047 - val_accuracy: 0.5593\n","Epoch 8/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5098 - accuracy: 0.8912 - val_loss: 0.8945 - val_accuracy: 0.5938\n","Epoch 9/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5064 - accuracy: 0.8982 - val_loss: 0.8907 - val_accuracy: 0.5862\n","Epoch 10/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4921 - accuracy: 0.9030 - val_loss: 0.8786 - val_accuracy: 0.6078\n","Epoch 11/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4851 - accuracy: 0.9060 - val_loss: 0.8623 - val_accuracy: 0.6498\n","Epoch 12/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4861 - accuracy: 0.9049 - val_loss: 0.8515 - val_accuracy: 0.6573\n","Epoch 13/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4856 - accuracy: 0.9030 - val_loss: 0.8461 - val_accuracy: 0.6466\n","Epoch 14/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4840 - accuracy: 0.9044 - val_loss: 0.8395 - val_accuracy: 0.6541\n","Epoch 15/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4827 - accuracy: 0.9071 - val_loss: 0.8014 - val_accuracy: 0.7349\n","Epoch 16/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4704 - accuracy: 0.9052 - val_loss: 0.8017 - val_accuracy: 0.7188\n","Epoch 17/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4604 - accuracy: 0.9154 - val_loss: 0.7949 - val_accuracy: 0.7112\n","Epoch 18/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4644 - accuracy: 0.9092 - val_loss: 0.7789 - val_accuracy: 0.7306\n","Epoch 19/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4556 - accuracy: 0.9127 - val_loss: 0.7912 - val_accuracy: 0.7177\n","Epoch 20/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4484 - accuracy: 0.9224 - val_loss: 0.7781 - val_accuracy: 0.7349\n","Epoch 21/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4393 - accuracy: 0.9267 - val_loss: 0.7660 - val_accuracy: 0.7554\n","Epoch 22/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4456 - accuracy: 0.9213 - val_loss: 0.7853 - val_accuracy: 0.7403\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4463 - accuracy: 0.9197 - val_loss: 0.8048 - val_accuracy: 0.7403\n","Epoch 24/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4312 - accuracy: 0.9259 - val_loss: 0.7976 - val_accuracy: 0.7532\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4299 - accuracy: 0.9227 - val_loss: 0.8068 - val_accuracy: 0.7435\n","Epoch 26/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4303 - accuracy: 0.9238 - val_loss: 0.8180 - val_accuracy: 0.7468\n","Epoch 27/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4213 - accuracy: 0.9324 - val_loss: 0.8447 - val_accuracy: 0.7532\n","Epoch 28/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4199 - accuracy: 0.9351 - val_loss: 0.8402 - val_accuracy: 0.7543\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4211 - accuracy: 0.9302 - val_loss: 0.8548 - val_accuracy: 0.7489\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4314 - accuracy: 0.9208 - val_loss: 0.8565 - val_accuracy: 0.7532\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4113 - accuracy: 0.9329 - val_loss: 0.8736 - val_accuracy: 0.7478\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4047 - accuracy: 0.9372 - val_loss: 0.8936 - val_accuracy: 0.7381\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3966 - accuracy: 0.9394 - val_loss: 0.8950 - val_accuracy: 0.7371\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4071 - accuracy: 0.9359 - val_loss: 0.9368 - val_accuracy: 0.7371\n","Epoch 35/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4267 - accuracy: 0.9173 - val_loss: 0.8991 - val_accuracy: 0.7349\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3955 - accuracy: 0.9397 - val_loss: 0.9133 - val_accuracy: 0.7371\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3932 - accuracy: 0.9394 - val_loss: 0.9207 - val_accuracy: 0.7392\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3860 - accuracy: 0.9440 - val_loss: 0.9097 - val_accuracy: 0.7543\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3914 - accuracy: 0.9413 - val_loss: 0.9137 - val_accuracy: 0.7392\n","Epoch 40/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3826 - accuracy: 0.9423 - val_loss: 0.9220 - val_accuracy: 0.7414\n","Epoch 41/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3763 - accuracy: 0.9512 - val_loss: 0.9211 - val_accuracy: 0.7457\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3788 - accuracy: 0.9450 - val_loss: 0.9226 - val_accuracy: 0.7381\n","Epoch 43/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3769 - accuracy: 0.9464 - val_loss: 0.9364 - val_accuracy: 0.7414\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3731 - accuracy: 0.9456 - val_loss: 1.0410 - val_accuracy: 0.7209\n","Epoch 45/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3740 - accuracy: 0.9453 - val_loss: 0.9333 - val_accuracy: 0.7414\n","Epoch 46/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3675 - accuracy: 0.9507 - val_loss: 0.9721 - val_accuracy: 0.7360\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3604 - accuracy: 0.9553 - val_loss: 0.9495 - val_accuracy: 0.7414\n","Epoch 48/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3532 - accuracy: 0.9572 - val_loss: 0.9592 - val_accuracy: 0.7425\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3613 - accuracy: 0.9504 - val_loss: 0.9917 - val_accuracy: 0.7371\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3607 - accuracy: 0.9523 - val_loss: 0.9666 - val_accuracy: 0.7414\n","Epoch 51/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3513 - accuracy: 0.9601 - val_loss: 0.9777 - val_accuracy: 0.7457\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3565 - accuracy: 0.9504 - val_loss: 0.9755 - val_accuracy: 0.7371\n","Epoch 53/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3418 - accuracy: 0.9623 - val_loss: 0.9853 - val_accuracy: 0.7328\n","Epoch 54/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3525 - accuracy: 0.9553 - val_loss: 0.9960 - val_accuracy: 0.7425\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3506 - accuracy: 0.9542 - val_loss: 1.0014 - val_accuracy: 0.7371\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3468 - accuracy: 0.9561 - val_loss: 0.9752 - val_accuracy: 0.7338\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3341 - accuracy: 0.9628 - val_loss: 1.0112 - val_accuracy: 0.7328\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3360 - accuracy: 0.9631 - val_loss: 1.0255 - val_accuracy: 0.7371\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3465 - accuracy: 0.9523 - val_loss: 1.0093 - val_accuracy: 0.7338\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3372 - accuracy: 0.9596 - val_loss: 1.0266 - val_accuracy: 0.7328\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3245 - accuracy: 0.9658 - val_loss: 1.0275 - val_accuracy: 0.7317\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3317 - accuracy: 0.9642 - val_loss: 1.0402 - val_accuracy: 0.7317\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3292 - accuracy: 0.9652 - val_loss: 1.0553 - val_accuracy: 0.7306\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3199 - accuracy: 0.9685 - val_loss: 1.0546 - val_accuracy: 0.7360\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3318 - accuracy: 0.9615 - val_loss: 1.0338 - val_accuracy: 0.7435\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3191 - accuracy: 0.9652 - val_loss: 1.0478 - val_accuracy: 0.7349\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3186 - accuracy: 0.9674 - val_loss: 1.0657 - val_accuracy: 0.7306\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3196 - accuracy: 0.9666 - val_loss: 1.0683 - val_accuracy: 0.7252\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3136 - accuracy: 0.9712 - val_loss: 1.1371 - val_accuracy: 0.7188\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3270 - accuracy: 0.9634 - val_loss: 1.1435 - val_accuracy: 0.7166\n","Epoch 71/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3169 - accuracy: 0.9674 - val_loss: 1.0753 - val_accuracy: 0.7263\n","Epoch 72/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3087 - accuracy: 0.9728 - val_loss: 1.0870 - val_accuracy: 0.7295\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3128 - accuracy: 0.9669 - val_loss: 1.1075 - val_accuracy: 0.7241\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3218 - accuracy: 0.9631 - val_loss: 1.0450 - val_accuracy: 0.7468\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3117 - accuracy: 0.9671 - val_loss: 1.0605 - val_accuracy: 0.7371\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2972 - accuracy: 0.9760 - val_loss: 1.0556 - val_accuracy: 0.7371\n","Epoch 77/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3027 - accuracy: 0.9714 - val_loss: 1.0999 - val_accuracy: 0.7381\n","Epoch 78/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3091 - accuracy: 0.9693 - val_loss: 1.1042 - val_accuracy: 0.7220\n","Epoch 79/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2984 - accuracy: 0.9749 - val_loss: 1.0872 - val_accuracy: 0.7349\n","Epoch 80/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2889 - accuracy: 0.9817 - val_loss: 1.0819 - val_accuracy: 0.7317\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2987 - accuracy: 0.9739 - val_loss: 1.1605 - val_accuracy: 0.7198\n","Epoch 82/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2901 - accuracy: 0.9784 - val_loss: 1.1146 - val_accuracy: 0.7414\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2940 - accuracy: 0.9733 - val_loss: 1.1047 - val_accuracy: 0.7425\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2857 - accuracy: 0.9784 - val_loss: 1.1554 - val_accuracy: 0.7295\n","Epoch 85/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3046 - accuracy: 0.9658 - val_loss: 1.0970 - val_accuracy: 0.7328\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3002 - accuracy: 0.9731 - val_loss: 1.1343 - val_accuracy: 0.7317\n","Epoch 87/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2983 - accuracy: 0.9677 - val_loss: 1.1260 - val_accuracy: 0.7371\n","Epoch 88/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2840 - accuracy: 0.9793 - val_loss: 1.1086 - val_accuracy: 0.7381\n","Epoch 89/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2849 - accuracy: 0.9771 - val_loss: 1.1250 - val_accuracy: 0.7209\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2861 - accuracy: 0.9758 - val_loss: 1.2245 - val_accuracy: 0.7274\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3076 - accuracy: 0.9639 - val_loss: 1.1297 - val_accuracy: 0.7371\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2870 - accuracy: 0.9728 - val_loss: 1.1334 - val_accuracy: 0.7338\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2765 - accuracy: 0.9814 - val_loss: 1.1387 - val_accuracy: 0.7274\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2762 - accuracy: 0.9811 - val_loss: 1.2200 - val_accuracy: 0.7177\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2747 - accuracy: 0.9784 - val_loss: 1.1581 - val_accuracy: 0.7263\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2772 - accuracy: 0.9795 - val_loss: 1.1456 - val_accuracy: 0.7360\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2738 - accuracy: 0.9793 - val_loss: 1.1491 - val_accuracy: 0.7328\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2699 - accuracy: 0.9828 - val_loss: 1.1825 - val_accuracy: 0.7328\n","Epoch 99/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2681 - accuracy: 0.9838 - val_loss: 1.1843 - val_accuracy: 0.7252\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2688 - accuracy: 0.9828 - val_loss: 1.1693 - val_accuracy: 0.7328\n","{'loss': [0.5750637650489807, 0.5607067346572876, 0.5471490025520325, 0.5328364968299866, 0.5134551525115967, 0.5254724621772766, 0.5076355338096619, 0.5098378658294678, 0.5064355731010437, 0.49212846159935, 0.4851367175579071, 0.4861043095588684, 0.4856155514717102, 0.48402953147888184, 0.48271942138671875, 0.47036007046699524, 0.46037647128105164, 0.46437758207321167, 0.45559096336364746, 0.4483547508716583, 0.439257949590683, 0.4455772340297699, 0.44626179337501526, 0.43122920393943787, 0.42994755506515503, 0.4303266406059265, 0.42130061984062195, 0.41989168524742126, 0.4210759401321411, 0.43141913414001465, 0.4113120138645172, 0.40474778413772583, 0.39662522077560425, 0.4071314036846161, 0.4266834557056427, 0.3955179750919342, 0.39320075511932373, 0.3860314190387726, 0.3913653492927551, 0.38260844349861145, 0.3762508034706116, 0.37883055210113525, 0.3769492208957672, 0.37308070063591003, 0.37403401732444763, 0.36750638484954834, 0.3603624701499939, 0.35320696234703064, 0.36131131649017334, 0.36068376898765564, 0.3513328433036804, 0.3565095365047455, 0.34178924560546875, 0.3525325059890747, 0.3506430685520172, 0.3468278646469116, 0.33405938744544983, 0.336003839969635, 0.34650918841362, 0.3371552526950836, 0.32452744245529175, 0.3317389190196991, 0.3291897177696228, 0.31991735100746155, 0.3318473696708679, 0.31911224126815796, 0.31855547428131104, 0.31956520676612854, 0.3135834336280823, 0.32700443267822266, 0.3168996274471283, 0.3086709678173065, 0.31283918023109436, 0.32182472944259644, 0.311747670173645, 0.29715368151664734, 0.3026579022407532, 0.3090653121471405, 0.29841142892837524, 0.2889072299003601, 0.29872778058052063, 0.29006823897361755, 0.294024795293808, 0.2857346832752228, 0.3046063780784607, 0.30017825961112976, 0.2982836365699768, 0.2839963138103485, 0.28489863872528076, 0.286137193441391, 0.3076021373271942, 0.28697529435157776, 0.2764565646648407, 0.27616360783576965, 0.27472466230392456, 0.2772011160850525, 0.2737904489040375, 0.2698513865470886, 0.2680813670158386, 0.26884862780570984], 'accuracy': [0.8615301847457886, 0.8669180870056152, 0.8771551847457886, 0.881196141242981, 0.8908944129943848, 0.8798491358757019, 0.8911637663841248, 0.8911637663841248, 0.8981680870056152, 0.9030172228813171, 0.9059805870056152, 0.904902994632721, 0.9030172228813171, 0.9043642282485962, 0.9070581793785095, 0.9051724076271057, 0.915409505367279, 0.9092133641242981, 0.912715494632721, 0.9224137663841248, 0.9267241358757019, 0.9213362336158752, 0.9197198152542114, 0.9259159564971924, 0.9226831793785095, 0.9237607717514038, 0.9323814511299133, 0.9350754022598267, 0.9302262663841248, 0.9207974076271057, 0.9329202771186829, 0.9372305870056152, 0.9393857717514038, 0.935883641242981, 0.9172952771186829, 0.9396551847457886, 0.9393857717514038, 0.943965494632721, 0.9412715435028076, 0.9423491358757019, 0.9512392282485962, 0.9450430870056152, 0.9463900923728943, 0.9455819129943848, 0.9453125, 0.9507004022598267, 0.9552801847457886, 0.9571659564971924, 0.9504310488700867, 0.9523168206214905, 0.9601293206214905, 0.9504310488700867, 0.962284505367279, 0.9552801847457886, 0.9542025923728943, 0.9560883641242981, 0.9628232717514038, 0.9630926847457886, 0.9523168206214905, 0.959590494632721, 0.9657866358757019, 0.9641702771186829, 0.9652478694915771, 0.9684805870056152, 0.9614762663841248, 0.9652478694915771, 0.967402994632721, 0.9665948152542114, 0.9711745977401733, 0.9633620977401733, 0.967402994632721, 0.9727909564971924, 0.9668642282485962, 0.9630926847457886, 0.967133641242981, 0.9760237336158752, 0.9714439511299133, 0.9692887663841248, 0.974946141242981, 0.9816810488700867, 0.9738685488700867, 0.9784482717514038, 0.9733297228813171, 0.9784482717514038, 0.9657866358757019, 0.9730603694915771, 0.9676724076271057, 0.9792564511299133, 0.9771012663841248, 0.9757543206214905, 0.9639008641242981, 0.9727909564971924, 0.9814116358757019, 0.9811422228813171, 0.9784482717514038, 0.9795258641242981, 0.9792564511299133, 0.982758641242981, 0.9838362336158752, 0.982758641242981], 'val_loss': [0.945482075214386, 0.9370492696762085, 0.934331476688385, 0.9303402900695801, 0.9260527491569519, 0.9141668081283569, 0.9046642780303955, 0.8944525718688965, 0.890737771987915, 0.8786046504974365, 0.8622559905052185, 0.8515127301216125, 0.8461005091667175, 0.8394815921783447, 0.8013553023338318, 0.801654040813446, 0.7948720455169678, 0.7789407968521118, 0.7911641597747803, 0.7780603170394897, 0.7660177946090698, 0.7853197455406189, 0.8048387765884399, 0.7976028919219971, 0.806841254234314, 0.8180280923843384, 0.8446589708328247, 0.8402091860771179, 0.8548290133476257, 0.8565126061439514, 0.8735625147819519, 0.8935752511024475, 0.8949817419052124, 0.9368265271186829, 0.8991155028343201, 0.9133487343788147, 0.9206593036651611, 0.9097272753715515, 0.9137344360351562, 0.9220266938209534, 0.9210662841796875, 0.9225690364837646, 0.936444103717804, 1.0409880876541138, 0.9332842826843262, 0.9720978736877441, 0.9495497941970825, 0.9591888189315796, 0.9917373657226562, 0.9665780663490295, 0.9777113795280457, 0.9754962921142578, 0.9853276610374451, 0.9959672689437866, 1.0014055967330933, 0.9752431511878967, 1.0111817121505737, 1.025451421737671, 1.0093261003494263, 1.0266332626342773, 1.0275423526763916, 1.0402331352233887, 1.0553330183029175, 1.0546340942382812, 1.0338032245635986, 1.0477718114852905, 1.065738558769226, 1.068278193473816, 1.1371183395385742, 1.1435482501983643, 1.0752875804901123, 1.086970567703247, 1.1075252294540405, 1.0450208187103271, 1.0604692697525024, 1.0555810928344727, 1.0998958349227905, 1.1041874885559082, 1.0872169733047485, 1.081850528717041, 1.1604750156402588, 1.1146211624145508, 1.1046770811080933, 1.1554179191589355, 1.0970040559768677, 1.1343172788619995, 1.1260074377059937, 1.1085931062698364, 1.12497079372406, 1.2245240211486816, 1.1297407150268555, 1.133404016494751, 1.138660192489624, 1.22001314163208, 1.1581065654754639, 1.1456272602081299, 1.1491118669509888, 1.1825408935546875, 1.184343934059143, 1.169299602508545], 'val_accuracy': [0.49461206793785095, 0.5053879022598267, 0.5086206793785095, 0.5150862336158752, 0.514008641242981, 0.5355603694915771, 0.5592672228813171, 0.59375, 0.5862069129943848, 0.607758641242981, 0.649784505367279, 0.6573275923728943, 0.6465517282485962, 0.6540948152542114, 0.7349137663841248, 0.71875, 0.7112069129943848, 0.7306034564971924, 0.7176724076271057, 0.7349137663841248, 0.7553879022598267, 0.7403017282485962, 0.7403017282485962, 0.7532327771186829, 0.743534505367279, 0.7467672228813171, 0.7532327771186829, 0.7543103694915771, 0.7489224076271057, 0.7532327771186829, 0.7478448152542114, 0.7381465435028076, 0.7370689511299133, 0.7370689511299133, 0.7349137663841248, 0.7370689511299133, 0.7392241358757019, 0.7543103694915771, 0.7392241358757019, 0.7413793206214905, 0.7456896305084229, 0.7381465435028076, 0.7413793206214905, 0.7209051847457886, 0.7413793206214905, 0.735991358757019, 0.7413793206214905, 0.7424569129943848, 0.7370689511299133, 0.7413793206214905, 0.7456896305084229, 0.7370689511299133, 0.732758641242981, 0.7424569129943848, 0.7370689511299133, 0.7338362336158752, 0.732758641242981, 0.7370689511299133, 0.7338362336158752, 0.732758641242981, 0.7316810488700867, 0.7316810488700867, 0.7306034564971924, 0.735991358757019, 0.743534505367279, 0.7349137663841248, 0.7306034564971924, 0.725215494632721, 0.71875, 0.7165948152542114, 0.7262930870056152, 0.7295258641242981, 0.7241379022598267, 0.7467672228813171, 0.7370689511299133, 0.7370689511299133, 0.7381465435028076, 0.7219827771186829, 0.7349137663841248, 0.7316810488700867, 0.7198275923728943, 0.7413793206214905, 0.7424569129943848, 0.7295258641242981, 0.732758641242981, 0.7316810488700867, 0.7370689511299133, 0.7381465435028076, 0.7209051847457886, 0.7273706793785095, 0.7370689511299133, 0.7338362336158752, 0.7273706793785095, 0.7176724076271057, 0.7262930870056152, 0.735991358757019, 0.732758641242981, 0.732758641242981, 0.725215494632721, 0.732758641242981]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.5745 - accuracy: 0.8571"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 53ms/step - loss: 0.5745 - accuracy: 0.8571 - val_loss: 0.9370 - val_accuracy: 0.5181\n","Epoch 2/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5478 - accuracy: 0.8746 - val_loss: 0.9310 - val_accuracy: 0.5249\n","Epoch 3/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5431 - accuracy: 0.8696 - val_loss: 0.9310 - val_accuracy: 0.5271\n","Epoch 4/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5285 - accuracy: 0.8738 - val_loss: 0.9243 - val_accuracy: 0.5271\n","Epoch 5/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5227 - accuracy: 0.8857 - val_loss: 0.9184 - val_accuracy: 0.5328\n","Epoch 6/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5207 - accuracy: 0.8888 - val_loss: 0.9067 - val_accuracy: 0.5611\n","Epoch 7/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5145 - accuracy: 0.8913 - val_loss: 0.8981 - val_accuracy: 0.5758\n","Epoch 8/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5129 - accuracy: 0.8928 - val_loss: 0.8931 - val_accuracy: 0.5769\n","Epoch 9/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4966 - accuracy: 0.8987 - val_loss: 0.8921 - val_accuracy: 0.5645\n","Epoch 10/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4964 - accuracy: 0.8981 - val_loss: 0.8700 - val_accuracy: 0.6380\n","Epoch 11/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4874 - accuracy: 0.9046 - val_loss: 0.8683 - val_accuracy: 0.6176\n","Epoch 12/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4873 - accuracy: 0.8984 - val_loss: 0.8582 - val_accuracy: 0.6290\n","Epoch 13/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4880 - accuracy: 0.8981 - val_loss: 0.8404 - val_accuracy: 0.6652\n","Epoch 14/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4828 - accuracy: 0.9083 - val_loss: 0.8219 - val_accuracy: 0.6878\n","Epoch 15/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4682 - accuracy: 0.9134 - val_loss: 0.8088 - val_accuracy: 0.7059\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4750 - accuracy: 0.9001 - val_loss: 0.8120 - val_accuracy: 0.6923\n","Epoch 17/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.4673 - accuracy: 0.9117 - val_loss: 0.7920 - val_accuracy: 0.7104\n","Epoch 18/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.4567 - accuracy: 0.9148 - val_loss: 0.7665 - val_accuracy: 0.7421\n","Epoch 19/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4590 - accuracy: 0.9120 - val_loss: 0.7825 - val_accuracy: 0.7138\n","Epoch 20/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4422 - accuracy: 0.9211 - val_loss: 0.7685 - val_accuracy: 0.7274\n","Epoch 21/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4427 - accuracy: 0.9182 - val_loss: 0.7807 - val_accuracy: 0.7183\n","Epoch 22/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.4387 - accuracy: 0.9244 - val_loss: 0.7545 - val_accuracy: 0.7432\n","Epoch 23/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4400 - accuracy: 0.9177 - val_loss: 0.8009 - val_accuracy: 0.7262\n","Epoch 24/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4453 - accuracy: 0.9185 - val_loss: 0.7987 - val_accuracy: 0.7376\n","Epoch 25/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4347 - accuracy: 0.9239 - val_loss: 0.7812 - val_accuracy: 0.7443\n","Epoch 26/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4263 - accuracy: 0.9278 - val_loss: 0.7997 - val_accuracy: 0.7376\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4267 - accuracy: 0.9270 - val_loss: 0.8139 - val_accuracy: 0.7410\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4212 - accuracy: 0.9267 - val_loss: 0.8492 - val_accuracy: 0.7296\n","Epoch 29/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4266 - accuracy: 0.9261 - val_loss: 0.8773 - val_accuracy: 0.7285\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4220 - accuracy: 0.9298 - val_loss: 0.8659 - val_accuracy: 0.7319\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4107 - accuracy: 0.9327 - val_loss: 0.8703 - val_accuracy: 0.7353\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4057 - accuracy: 0.9380 - val_loss: 0.8712 - val_accuracy: 0.7421\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3993 - accuracy: 0.9403 - val_loss: 0.8822 - val_accuracy: 0.7353\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3978 - accuracy: 0.9332 - val_loss: 0.8937 - val_accuracy: 0.7342\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3943 - accuracy: 0.9360 - val_loss: 0.9006 - val_accuracy: 0.7421\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3887 - accuracy: 0.9468 - val_loss: 0.9046 - val_accuracy: 0.7398\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3902 - accuracy: 0.9394 - val_loss: 0.9128 - val_accuracy: 0.7364\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3927 - accuracy: 0.9420 - val_loss: 0.9355 - val_accuracy: 0.7319\n","Epoch 39/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3852 - accuracy: 0.9471 - val_loss: 0.9439 - val_accuracy: 0.7319\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3788 - accuracy: 0.9499 - val_loss: 0.9511 - val_accuracy: 0.7308\n","Epoch 41/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3802 - accuracy: 0.9496 - val_loss: 0.9332 - val_accuracy: 0.7432\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3727 - accuracy: 0.9502 - val_loss: 0.9362 - val_accuracy: 0.7308\n","Epoch 43/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3958 - accuracy: 0.9327 - val_loss: 0.9471 - val_accuracy: 0.7376\n","Epoch 44/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3797 - accuracy: 0.9448 - val_loss: 0.9422 - val_accuracy: 0.7387\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3660 - accuracy: 0.9502 - val_loss: 0.9988 - val_accuracy: 0.7251\n","Epoch 46/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3630 - accuracy: 0.9510 - val_loss: 0.9677 - val_accuracy: 0.7342\n","Epoch 47/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3661 - accuracy: 0.9488 - val_loss: 0.9743 - val_accuracy: 0.7376\n","Epoch 48/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3619 - accuracy: 0.9527 - val_loss: 0.9929 - val_accuracy: 0.7308\n","Epoch 49/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3577 - accuracy: 0.9522 - val_loss: 0.9686 - val_accuracy: 0.7285\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3538 - accuracy: 0.9556 - val_loss: 0.9834 - val_accuracy: 0.7342\n","Epoch 51/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3597 - accuracy: 0.9513 - val_loss: 1.0452 - val_accuracy: 0.7183\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3583 - accuracy: 0.9477 - val_loss: 0.9856 - val_accuracy: 0.7217\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3368 - accuracy: 0.9621 - val_loss: 0.9961 - val_accuracy: 0.7274\n","Epoch 54/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3481 - accuracy: 0.9522 - val_loss: 0.9972 - val_accuracy: 0.7285\n","Epoch 55/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3429 - accuracy: 0.9581 - val_loss: 1.0381 - val_accuracy: 0.7217\n","Epoch 56/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3473 - accuracy: 0.9598 - val_loss: 1.0032 - val_accuracy: 0.7285\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3335 - accuracy: 0.9618 - val_loss: 1.0144 - val_accuracy: 0.7319\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3339 - accuracy: 0.9624 - val_loss: 1.0479 - val_accuracy: 0.7161\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3314 - accuracy: 0.9632 - val_loss: 1.0385 - val_accuracy: 0.7296\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3235 - accuracy: 0.9666 - val_loss: 1.0427 - val_accuracy: 0.7274\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3198 - accuracy: 0.9658 - val_loss: 1.0386 - val_accuracy: 0.7308\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3254 - accuracy: 0.9658 - val_loss: 1.0797 - val_accuracy: 0.7183\n","Epoch 63/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3268 - accuracy: 0.9643 - val_loss: 1.0700 - val_accuracy: 0.7308\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3192 - accuracy: 0.9666 - val_loss: 1.0795 - val_accuracy: 0.7183\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3147 - accuracy: 0.9711 - val_loss: 1.0512 - val_accuracy: 0.7240\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3106 - accuracy: 0.9743 - val_loss: 1.1068 - val_accuracy: 0.7240\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3128 - accuracy: 0.9697 - val_loss: 1.0712 - val_accuracy: 0.7240\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3265 - accuracy: 0.9587 - val_loss: 1.1616 - val_accuracy: 0.7059\n","Epoch 69/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3408 - accuracy: 0.9547 - val_loss: 1.0881 - val_accuracy: 0.7070\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3093 - accuracy: 0.9711 - val_loss: 1.0865 - val_accuracy: 0.7251\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3063 - accuracy: 0.9737 - val_loss: 1.0817 - val_accuracy: 0.7251\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3047 - accuracy: 0.9723 - val_loss: 1.0993 - val_accuracy: 0.7217\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3019 - accuracy: 0.9751 - val_loss: 1.0989 - val_accuracy: 0.7262\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3072 - accuracy: 0.9706 - val_loss: 1.1206 - val_accuracy: 0.7149\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3246 - accuracy: 0.9598 - val_loss: 1.1154 - val_accuracy: 0.7161\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3067 - accuracy: 0.9675 - val_loss: 1.1185 - val_accuracy: 0.7285\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3017 - accuracy: 0.9711 - val_loss: 1.1216 - val_accuracy: 0.7262\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2877 - accuracy: 0.9799 - val_loss: 1.1297 - val_accuracy: 0.7195\n","Epoch 79/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2922 - accuracy: 0.9771 - val_loss: 1.1323 - val_accuracy: 0.7330\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3004 - accuracy: 0.9728 - val_loss: 1.1570 - val_accuracy: 0.7138\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2910 - accuracy: 0.9774 - val_loss: 1.1356 - val_accuracy: 0.7195\n","Epoch 82/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2896 - accuracy: 0.9754 - val_loss: 1.1381 - val_accuracy: 0.7296\n","Epoch 83/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2825 - accuracy: 0.9796 - val_loss: 1.1520 - val_accuracy: 0.7217\n","Epoch 84/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2880 - accuracy: 0.9768 - val_loss: 1.2380 - val_accuracy: 0.7104\n","Epoch 85/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2883 - accuracy: 0.9774 - val_loss: 1.1695 - val_accuracy: 0.7172\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2858 - accuracy: 0.9793 - val_loss: 1.1675 - val_accuracy: 0.7206\n","Epoch 87/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2801 - accuracy: 0.9816 - val_loss: 1.1641 - val_accuracy: 0.7240\n","Epoch 88/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2850 - accuracy: 0.9751 - val_loss: 1.1771 - val_accuracy: 0.7217\n","Epoch 89/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2675 - accuracy: 0.9856 - val_loss: 1.1700 - val_accuracy: 0.7342\n","Epoch 90/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2763 - accuracy: 0.9808 - val_loss: 1.1944 - val_accuracy: 0.7206\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2729 - accuracy: 0.9825 - val_loss: 1.2053 - val_accuracy: 0.7251\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2745 - accuracy: 0.9819 - val_loss: 1.1982 - val_accuracy: 0.7240\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2745 - accuracy: 0.9819 - val_loss: 1.2130 - val_accuracy: 0.7206\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2734 - accuracy: 0.9830 - val_loss: 1.1772 - val_accuracy: 0.7138\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2706 - accuracy: 0.9813 - val_loss: 1.1957 - val_accuracy: 0.7217\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2849 - accuracy: 0.9762 - val_loss: 1.2712 - val_accuracy: 0.7127\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2709 - accuracy: 0.9796 - val_loss: 1.2497 - val_accuracy: 0.7149\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2670 - accuracy: 0.9819 - val_loss: 1.2091 - val_accuracy: 0.7195\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2713 - accuracy: 0.9796 - val_loss: 1.2253 - val_accuracy: 0.7229\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2675 - accuracy: 0.9813 - val_loss: 1.2260 - val_accuracy: 0.7172\n","{'loss': [0.5744583606719971, 0.5477564334869385, 0.5430690050125122, 0.5284713506698608, 0.5227288603782654, 0.5207204222679138, 0.5144948959350586, 0.5129347443580627, 0.4966444969177246, 0.4964430630207062, 0.4874008595943451, 0.4872622787952423, 0.48801544308662415, 0.4828360080718994, 0.4681783616542816, 0.4749705493450165, 0.4673159122467041, 0.4566827118396759, 0.459021657705307, 0.44221025705337524, 0.4427018463611603, 0.4387172758579254, 0.44002771377563477, 0.4453188478946686, 0.4346846044063568, 0.4263210892677307, 0.42667657136917114, 0.42120757699012756, 0.4265754520893097, 0.4220425486564636, 0.41074687242507935, 0.40574872493743896, 0.39934036135673523, 0.3977648913860321, 0.39433252811431885, 0.3887031674385071, 0.39017078280448914, 0.3927057683467865, 0.38515499234199524, 0.37876513600349426, 0.38015273213386536, 0.3726571500301361, 0.3958393335342407, 0.37970149517059326, 0.36596834659576416, 0.36297374963760376, 0.36607518792152405, 0.36191311478614807, 0.35774657130241394, 0.3538253903388977, 0.35972291231155396, 0.35832488536834717, 0.3368084728717804, 0.3481021523475647, 0.34292474389076233, 0.3473239839076996, 0.33351069688796997, 0.33388447761535645, 0.33143776655197144, 0.32352355122566223, 0.3198181390762329, 0.32543936371803284, 0.3268185257911682, 0.31920912861824036, 0.3147227168083191, 0.3105682134628296, 0.31284675002098083, 0.3265475630760193, 0.3407552242279053, 0.3092555105686188, 0.3062865138053894, 0.30466604232788086, 0.3018586039543152, 0.30715233087539673, 0.32460838556289673, 0.3067472279071808, 0.30169054865837097, 0.2877277433872223, 0.29222315549850464, 0.3003939390182495, 0.2909746468067169, 0.2896483838558197, 0.2824682295322418, 0.2880265712738037, 0.28825268149375916, 0.2858313024044037, 0.28006935119628906, 0.2850072681903839, 0.26748892664909363, 0.27628293633461, 0.2729172706604004, 0.27450031042099, 0.2745240330696106, 0.27338141202926636, 0.2705637514591217, 0.2848944664001465, 0.27091482281684875, 0.2670300602912903, 0.2713465690612793, 0.2674943208694458], 'accuracy': [0.8571024537086487, 0.8746463060379028, 0.8695529103279114, 0.8737974166870117, 0.8856819272041321, 0.8887945413589478, 0.8913412690162659, 0.8927561044692993, 0.8986983299255371, 0.8981324434280396, 0.9046406149864197, 0.8984153866767883, 0.8981324434280396, 0.9083191752433777, 0.9134125709533691, 0.9001131653785706, 0.9117147922515869, 0.9148274064064026, 0.9119977355003357, 0.9210526347160339, 0.918222963809967, 0.9244481921195984, 0.9176570177078247, 0.9185059666633606, 0.9238823056221008, 0.9278438091278076, 0.9269949197769165, 0.926711916923523, 0.9261460304260254, 0.9298245906829834, 0.9326542019844055, 0.9380305409431458, 0.9402942657470703, 0.9332201480865479, 0.9360498189926147, 0.9468024969100952, 0.9394453763961792, 0.9419921040534973, 0.947085440158844, 0.9499151110649109, 0.9496321678161621, 0.9501980543136597, 0.9326542019844055, 0.9448217153549194, 0.9501980543136597, 0.9510469436645508, 0.9487832188606262, 0.9527447819709778, 0.9521788358688354, 0.9555743932723999, 0.9513299465179443, 0.9476513862609863, 0.9620826244354248, 0.9521788358688354, 0.958121120929718, 0.9598188996315002, 0.961799681186676, 0.9623655676841736, 0.9632145166397095, 0.9666100740432739, 0.9657611846923828, 0.9657611846923828, 0.9643463492393494, 0.9666100740432739, 0.971137523651123, 0.9742501378059387, 0.9697226881980896, 0.9586870670318604, 0.9547255039215088, 0.971137523651123, 0.9736841917037964, 0.9722693562507629, 0.9750990271568298, 0.9705715775489807, 0.9598188996315002, 0.967458963394165, 0.971137523651123, 0.9799094796180725, 0.9770798087120056, 0.9728353023529053, 0.9773627519607544, 0.9753820300102234, 0.979626476764679, 0.9767968058586121, 0.9773627519607544, 0.9793435335159302, 0.9816072583198547, 0.9750990271568298, 0.9855687618255615, 0.9807583689689636, 0.9824561476707458, 0.9818902015686035, 0.9818902015686035, 0.9830220937728882, 0.9813242554664612, 0.9762309193611145, 0.979626476764679, 0.9818902015686035, 0.979626476764679, 0.9813242554664612], 'val_loss': [0.9370301365852356, 0.9309967160224915, 0.9309923052787781, 0.9242751598358154, 0.9184165000915527, 0.9067085981369019, 0.8980840444564819, 0.8930680751800537, 0.8921471238136292, 0.8700159788131714, 0.8683079481124878, 0.8581772446632385, 0.8404031991958618, 0.8218746781349182, 0.8087949156761169, 0.812047004699707, 0.7920210361480713, 0.7665396928787231, 0.782531201839447, 0.7684741616249084, 0.780739963054657, 0.754470705986023, 0.8008900880813599, 0.7986582517623901, 0.7812238931655884, 0.7997317314147949, 0.813925564289093, 0.8492149710655212, 0.8772608041763306, 0.8658543229103088, 0.8702727556228638, 0.871221125125885, 0.8821533918380737, 0.8936589360237122, 0.9006335139274597, 0.9046217799186707, 0.9127907156944275, 0.9355327486991882, 0.943899393081665, 0.9510855078697205, 0.9331809878349304, 0.9361913204193115, 0.9471184015274048, 0.9422069787979126, 0.998803436756134, 0.9676570296287537, 0.9742639064788818, 0.9929139614105225, 0.9685919284820557, 0.9833741784095764, 1.0451713800430298, 0.9856398105621338, 0.9960713982582092, 0.9971764087677002, 1.038120985031128, 1.0032285451889038, 1.0144404172897339, 1.0478873252868652, 1.0384975671768188, 1.0426737070083618, 1.038601040840149, 1.079702377319336, 1.0700398683547974, 1.0795108079910278, 1.0511554479599, 1.1068273782730103, 1.0711722373962402, 1.1616135835647583, 1.088078498840332, 1.0865048170089722, 1.0817450284957886, 1.0993459224700928, 1.0988919734954834, 1.1205799579620361, 1.1154413223266602, 1.1185353994369507, 1.1215837001800537, 1.1297293901443481, 1.132315993309021, 1.156952977180481, 1.1356054544448853, 1.1380795240402222, 1.1519676446914673, 1.2379717826843262, 1.1695446968078613, 1.1675381660461426, 1.1641112565994263, 1.1770778894424438, 1.1700263023376465, 1.194379210472107, 1.2052501440048218, 1.198190689086914, 1.2130162715911865, 1.1771876811981201, 1.1957188844680786, 1.2711999416351318, 1.2497159242630005, 1.209130883216858, 1.225325345993042, 1.225976824760437], 'val_accuracy': [0.5180995464324951, 0.5248869061470032, 0.5271493196487427, 0.5271493196487427, 0.5328054428100586, 0.5610859990119934, 0.5757918357849121, 0.5769230723381042, 0.564479649066925, 0.6380090713500977, 0.6176470518112183, 0.6289592981338501, 0.6651583909988403, 0.6877828240394592, 0.7058823704719543, 0.692307710647583, 0.7104072570800781, 0.7420814633369446, 0.7138009071350098, 0.7273755669593811, 0.7183257937431335, 0.7432126402854919, 0.726244330406189, 0.7375565767288208, 0.7443438768386841, 0.7375565767288208, 0.7409502267837524, 0.7296379804611206, 0.7285068035125732, 0.7319004535675049, 0.7352941036224365, 0.7420814633369446, 0.7352941036224365, 0.7341628670692444, 0.7420814633369446, 0.7398189902305603, 0.7364253401756287, 0.7319004535675049, 0.7319004535675049, 0.7307692170143127, 0.7432126402854919, 0.7307692170143127, 0.7375565767288208, 0.7386877536773682, 0.7251130938529968, 0.7341628670692444, 0.7375565767288208, 0.7307692170143127, 0.7285068035125732, 0.7341628670692444, 0.7183257937431335, 0.7217194437980652, 0.7273755669593811, 0.7285068035125732, 0.7217194437980652, 0.7285068035125732, 0.7319004535675049, 0.7160633206367493, 0.7296379804611206, 0.7273755669593811, 0.7307692170143127, 0.7183257937431335, 0.7307692170143127, 0.7183257937431335, 0.7239819169044495, 0.7239819169044495, 0.7239819169044495, 0.7058823704719543, 0.7070135474205017, 0.7251130938529968, 0.7251130938529968, 0.7217194437980652, 0.726244330406189, 0.7149321436882019, 0.7160633206367493, 0.7285068035125732, 0.726244330406189, 0.7194570302963257, 0.733031690120697, 0.7138009071350098, 0.7194570302963257, 0.7296379804611206, 0.7217194437980652, 0.7104072570800781, 0.7171945571899414, 0.720588207244873, 0.7239819169044495, 0.7217194437980652, 0.7341628670692444, 0.720588207244873, 0.7251130938529968, 0.7239819169044495, 0.720588207244873, 0.7138009071350098, 0.7217194437980652, 0.7126696705818176, 0.7149321436882019, 0.7194570302963257, 0.7228506803512573, 0.7171945571899414]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.6030 - accuracy: 0.8560"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 49ms/step - loss: 0.6052 - accuracy: 0.8527 - val_loss: 0.9508 - val_accuracy: 0.4979\n","Epoch 2/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5744 - accuracy: 0.8581 - val_loss: 0.9461 - val_accuracy: 0.5010\n","Epoch 3/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5594 - accuracy: 0.8659 - val_loss: 0.9485 - val_accuracy: 0.5052\n","Epoch 4/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5540 - accuracy: 0.8757 - val_loss: 0.9463 - val_accuracy: 0.5041\n","Epoch 5/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5475 - accuracy: 0.8755 - val_loss: 0.9267 - val_accuracy: 0.5300\n","Epoch 6/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5531 - accuracy: 0.8742 - val_loss: 0.9376 - val_accuracy: 0.5155\n","Epoch 7/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5404 - accuracy: 0.8798 - val_loss: 0.9155 - val_accuracy: 0.5506\n","Epoch 8/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5237 - accuracy: 0.8879 - val_loss: 0.9118 - val_accuracy: 0.5558\n","Epoch 9/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5218 - accuracy: 0.8868 - val_loss: 0.9122 - val_accuracy: 0.5579\n","Epoch 10/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5147 - accuracy: 0.8907 - val_loss: 0.8999 - val_accuracy: 0.5775\n","Epoch 11/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5159 - accuracy: 0.8928 - val_loss: 0.8860 - val_accuracy: 0.6074\n","Epoch 12/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5133 - accuracy: 0.8928 - val_loss: 0.8895 - val_accuracy: 0.5981\n","Epoch 13/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5075 - accuracy: 0.8922 - val_loss: 0.8700 - val_accuracy: 0.6415\n","Epoch 14/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.4986 - accuracy: 0.8984 - val_loss: 0.8570 - val_accuracy: 0.6684\n","Epoch 15/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5052 - accuracy: 0.8943 - val_loss: 0.8618 - val_accuracy: 0.6663\n","Epoch 16/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4910 - accuracy: 0.9018 - val_loss: 0.8602 - val_accuracy: 0.6715\n","Epoch 17/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4927 - accuracy: 0.8943 - val_loss: 0.8487 - val_accuracy: 0.7045\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4881 - accuracy: 0.8984 - val_loss: 0.8582 - val_accuracy: 0.7014\n","Epoch 19/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4779 - accuracy: 0.9013 - val_loss: 0.8759 - val_accuracy: 0.6880\n","Epoch 20/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4762 - accuracy: 0.9075 - val_loss: 0.8871 - val_accuracy: 0.6963\n","Epoch 21/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4677 - accuracy: 0.9090 - val_loss: 0.9087 - val_accuracy: 0.6890\n","Epoch 22/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4733 - accuracy: 0.9098 - val_loss: 0.9972 - val_accuracy: 0.6384\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4691 - accuracy: 0.9039 - val_loss: 0.9504 - val_accuracy: 0.6942\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4757 - accuracy: 0.9036 - val_loss: 1.0012 - val_accuracy: 0.6715\n","Epoch 25/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4631 - accuracy: 0.9090 - val_loss: 0.9944 - val_accuracy: 0.6829\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4517 - accuracy: 0.9168 - val_loss: 0.9997 - val_accuracy: 0.6870\n","Epoch 27/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4536 - accuracy: 0.9147 - val_loss: 1.0406 - val_accuracy: 0.6963\n","Epoch 28/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4566 - accuracy: 0.9088 - val_loss: 1.0278 - val_accuracy: 0.6952\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4487 - accuracy: 0.9096 - val_loss: 1.0711 - val_accuracy: 0.6787\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4504 - accuracy: 0.9127 - val_loss: 1.0388 - val_accuracy: 0.6932\n","Epoch 31/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4449 - accuracy: 0.9158 - val_loss: 1.0840 - val_accuracy: 0.6777\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4494 - accuracy: 0.9134 - val_loss: 1.0663 - val_accuracy: 0.6921\n","Epoch 33/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4400 - accuracy: 0.9220 - val_loss: 1.0716 - val_accuracy: 0.6901\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4550 - accuracy: 0.9127 - val_loss: 1.0830 - val_accuracy: 0.6901\n","Epoch 35/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4372 - accuracy: 0.9173 - val_loss: 1.0781 - val_accuracy: 0.7004\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4181 - accuracy: 0.9295 - val_loss: 1.1127 - val_accuracy: 0.6829\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4182 - accuracy: 0.9258 - val_loss: 1.0970 - val_accuracy: 0.6952\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4156 - accuracy: 0.9251 - val_loss: 1.1235 - val_accuracy: 0.6829\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4124 - accuracy: 0.9302 - val_loss: 1.1045 - val_accuracy: 0.6921\n","Epoch 40/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4206 - accuracy: 0.9264 - val_loss: 1.1130 - val_accuracy: 0.6911\n","Epoch 41/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4199 - accuracy: 0.9284 - val_loss: 1.1221 - val_accuracy: 0.6983\n","Epoch 42/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3988 - accuracy: 0.9393 - val_loss: 1.1173 - val_accuracy: 0.6849\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4025 - accuracy: 0.9295 - val_loss: 1.1400 - val_accuracy: 0.6890\n","Epoch 44/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4024 - accuracy: 0.9339 - val_loss: 1.2008 - val_accuracy: 0.6818\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4143 - accuracy: 0.9300 - val_loss: 1.1282 - val_accuracy: 0.6818\n","Epoch 46/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3864 - accuracy: 0.9403 - val_loss: 1.1597 - val_accuracy: 0.6777\n","Epoch 47/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3996 - accuracy: 0.9295 - val_loss: 1.1667 - val_accuracy: 0.6736\n","Epoch 48/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3854 - accuracy: 0.9432 - val_loss: 1.1814 - val_accuracy: 0.6767\n","Epoch 49/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3830 - accuracy: 0.9444 - val_loss: 1.1738 - val_accuracy: 0.6870\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3825 - accuracy: 0.9429 - val_loss: 1.1526 - val_accuracy: 0.6787\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3774 - accuracy: 0.9463 - val_loss: 1.1650 - val_accuracy: 0.6901\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3756 - accuracy: 0.9455 - val_loss: 1.2124 - val_accuracy: 0.6849\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3761 - accuracy: 0.9442 - val_loss: 1.2370 - val_accuracy: 0.6653\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3745 - accuracy: 0.9411 - val_loss: 1.2489 - val_accuracy: 0.6622\n","Epoch 55/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3738 - accuracy: 0.9437 - val_loss: 1.2423 - val_accuracy: 0.6653\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3648 - accuracy: 0.9460 - val_loss: 1.1872 - val_accuracy: 0.6777\n","Epoch 57/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3632 - accuracy: 0.9486 - val_loss: 1.2240 - val_accuracy: 0.6829\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3638 - accuracy: 0.9468 - val_loss: 1.2590 - val_accuracy: 0.6725\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3704 - accuracy: 0.9403 - val_loss: 1.2122 - val_accuracy: 0.6890\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3545 - accuracy: 0.9558 - val_loss: 1.2441 - val_accuracy: 0.6808\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3707 - accuracy: 0.9421 - val_loss: 1.2360 - val_accuracy: 0.6787\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3523 - accuracy: 0.9540 - val_loss: 1.2267 - val_accuracy: 0.6808\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3460 - accuracy: 0.9563 - val_loss: 1.2696 - val_accuracy: 0.6725\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3461 - accuracy: 0.9530 - val_loss: 1.2502 - val_accuracy: 0.6777\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3433 - accuracy: 0.9540 - val_loss: 1.2539 - val_accuracy: 0.6808\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3478 - accuracy: 0.9499 - val_loss: 1.3144 - val_accuracy: 0.6684\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3512 - accuracy: 0.9514 - val_loss: 1.2444 - val_accuracy: 0.6746\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3504 - accuracy: 0.9494 - val_loss: 1.2771 - val_accuracy: 0.6725\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3330 - accuracy: 0.9615 - val_loss: 1.2725 - val_accuracy: 0.6808\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3366 - accuracy: 0.9574 - val_loss: 1.2662 - val_accuracy: 0.6860\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3289 - accuracy: 0.9656 - val_loss: 1.2769 - val_accuracy: 0.6860\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3277 - accuracy: 0.9620 - val_loss: 1.3027 - val_accuracy: 0.6777\n","Epoch 73/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3323 - accuracy: 0.9589 - val_loss: 1.3476 - val_accuracy: 0.6736\n","Epoch 74/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3362 - accuracy: 0.9587 - val_loss: 1.2844 - val_accuracy: 0.6787\n","Epoch 75/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3518 - accuracy: 0.9483 - val_loss: 1.2925 - val_accuracy: 0.6777\n","Epoch 76/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3252 - accuracy: 0.9605 - val_loss: 1.3175 - val_accuracy: 0.6818\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3274 - accuracy: 0.9594 - val_loss: 1.4325 - val_accuracy: 0.6477\n","Epoch 78/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3205 - accuracy: 0.9638 - val_loss: 1.3342 - val_accuracy: 0.6746\n","Epoch 79/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3162 - accuracy: 0.9685 - val_loss: 1.3467 - val_accuracy: 0.6756\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3140 - accuracy: 0.9672 - val_loss: 1.3537 - val_accuracy: 0.6777\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3135 - accuracy: 0.9674 - val_loss: 1.3391 - val_accuracy: 0.6756\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3159 - accuracy: 0.9625 - val_loss: 1.3466 - val_accuracy: 0.6777\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3161 - accuracy: 0.9661 - val_loss: 1.3407 - val_accuracy: 0.6767\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3167 - accuracy: 0.9643 - val_loss: 1.3382 - val_accuracy: 0.6736\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3084 - accuracy: 0.9680 - val_loss: 1.3345 - val_accuracy: 0.6715\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3186 - accuracy: 0.9630 - val_loss: 1.3434 - val_accuracy: 0.6787\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3019 - accuracy: 0.9726 - val_loss: 1.4802 - val_accuracy: 0.6581\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3225 - accuracy: 0.9558 - val_loss: 1.3589 - val_accuracy: 0.6736\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3008 - accuracy: 0.9674 - val_loss: 1.3611 - val_accuracy: 0.6674\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3049 - accuracy: 0.9687 - val_loss: 1.3610 - val_accuracy: 0.6767\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2986 - accuracy: 0.9718 - val_loss: 1.3971 - val_accuracy: 0.6715\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3103 - accuracy: 0.9656 - val_loss: 1.3842 - val_accuracy: 0.6736\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2949 - accuracy: 0.9739 - val_loss: 1.3818 - val_accuracy: 0.6694\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2954 - accuracy: 0.9736 - val_loss: 1.3882 - val_accuracy: 0.6674\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2950 - accuracy: 0.9693 - val_loss: 1.4470 - val_accuracy: 0.6715\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2918 - accuracy: 0.9724 - val_loss: 1.4019 - val_accuracy: 0.6746\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2928 - accuracy: 0.9755 - val_loss: 1.4011 - val_accuracy: 0.6715\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2851 - accuracy: 0.9755 - val_loss: 1.4175 - val_accuracy: 0.6736\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2902 - accuracy: 0.9700 - val_loss: 1.4641 - val_accuracy: 0.6684\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2943 - accuracy: 0.9716 - val_loss: 1.4344 - val_accuracy: 0.6663\n","{'loss': [0.6051908135414124, 0.5743633508682251, 0.5593960881233215, 0.5539872646331787, 0.5475156903266907, 0.5530552268028259, 0.5403653979301453, 0.523725688457489, 0.5218232274055481, 0.5146782994270325, 0.5158988833427429, 0.5133238434791565, 0.5074822306632996, 0.49856579303741455, 0.5051657557487488, 0.49104195833206177, 0.492737352848053, 0.488115131855011, 0.477900892496109, 0.47620314359664917, 0.46769362688064575, 0.47332870960235596, 0.46913743019104004, 0.4757378101348877, 0.4631073474884033, 0.45169129967689514, 0.4536084830760956, 0.45664727687835693, 0.44869542121887207, 0.45035356283187866, 0.4449210464954376, 0.4494270086288452, 0.4399603009223938, 0.4549812376499176, 0.4372062087059021, 0.41808706521987915, 0.418172150850296, 0.41561174392700195, 0.41239070892333984, 0.42064958810806274, 0.4199177622795105, 0.3987780213356018, 0.4024772346019745, 0.40237563848495483, 0.41427579522132874, 0.3864034116268158, 0.39958927035331726, 0.38544827699661255, 0.38298413157463074, 0.3825063109397888, 0.37741610407829285, 0.3756299316883087, 0.37607359886169434, 0.37450987100601196, 0.37375760078430176, 0.364772230386734, 0.36324021220207214, 0.36381423473358154, 0.37040287256240845, 0.35447779297828674, 0.3706842362880707, 0.3522680699825287, 0.3460211157798767, 0.3461390435695648, 0.3433402180671692, 0.34775370359420776, 0.3512420058250427, 0.35040825605392456, 0.33300134539604187, 0.33660608530044556, 0.3288676142692566, 0.32769182324409485, 0.3322743773460388, 0.3362087905406952, 0.3518168032169342, 0.32516443729400635, 0.32744842767715454, 0.3205313980579376, 0.31615835428237915, 0.3139619529247284, 0.31350913643836975, 0.31593069434165955, 0.3160516321659088, 0.31674128770828247, 0.30841976404190063, 0.31861868500709534, 0.30190351605415344, 0.3224816918373108, 0.3008093535900116, 0.3049047291278839, 0.29860830307006836, 0.3103424906730652, 0.29494357109069824, 0.29538825154304504, 0.29503098130226135, 0.29181790351867676, 0.29275062680244446, 0.2851051688194275, 0.29020988941192627, 0.2942681610584259], 'accuracy': [0.8527131676673889, 0.8581395149230957, 0.8658914566040039, 0.8757106065750122, 0.8754522204399109, 0.8741602301597595, 0.8798449635505676, 0.8878552913665771, 0.8868216872215271, 0.8906976580619812, 0.8927648663520813, 0.8927648663520813, 0.8922480344772339, 0.8984495997428894, 0.894315242767334, 0.9018087983131409, 0.894315242767334, 0.8984495997428894, 0.9012919664382935, 0.907493531703949, 0.9090439081192017, 0.9098191261291504, 0.9038759469985962, 0.9036175608634949, 0.9090439081192017, 0.9167958498001099, 0.9147287011146545, 0.9087855219841003, 0.9095607399940491, 0.9126614928245544, 0.9157622456550598, 0.9134367108345032, 0.9219638109207153, 0.9126614928245544, 0.9173126816749573, 0.9294573664665222, 0.9258397817611694, 0.9250646233558655, 0.930232584476471, 0.9263566136360168, 0.9284237623214722, 0.9392764568328857, 0.9294573664665222, 0.933850109577179, 0.9299741387367249, 0.9403100609779358, 0.9294573664665222, 0.9431524276733398, 0.9444444179534912, 0.9428940415382385, 0.94625324010849, 0.9454780220985413, 0.9441860318183899, 0.9410852789878845, 0.9436692595481873, 0.9459948539733887, 0.9485788345336914, 0.9467700123786926, 0.9403100609779358, 0.9558139443397522, 0.9421188831329346, 0.9540051817893982, 0.9563307762145996, 0.9529715776443481, 0.9540051817893982, 0.9498708248138428, 0.9514212012290955, 0.9493539929389954, 0.9614987373352051, 0.9573643207550049, 0.9656330943107605, 0.9620155096054077, 0.9589147567749023, 0.9586563110351562, 0.9483203887939453, 0.960465133190155, 0.959431529045105, 0.9638242721557617, 0.9684754610061646, 0.9671834707260132, 0.9674418568611145, 0.9625322818756104, 0.9661498665809631, 0.9643411040306091, 0.9679586291313171, 0.9630491137504578, 0.97260981798172, 0.9558139443397522, 0.9674418568611145, 0.9687338471412659, 0.9718345999717712, 0.9656330943107605, 0.9739018082618713, 0.97364342212677, 0.9692506194114685, 0.9723514318466187, 0.975452184677124, 0.975452184677124, 0.9700258374214172, 0.9715762138366699], 'val_loss': [0.9507720470428467, 0.9461461901664734, 0.948462963104248, 0.9462807774543762, 0.9266735315322876, 0.9375524520874023, 0.9154703617095947, 0.9117509722709656, 0.9121681451797485, 0.8998995423316956, 0.8860162496566772, 0.8894810676574707, 0.8699625134468079, 0.8569806814193726, 0.8617736101150513, 0.8602196574211121, 0.8486616611480713, 0.8582413792610168, 0.8758566975593567, 0.8870885968208313, 0.9086737036705017, 0.9972192645072937, 0.9504327178001404, 1.0012354850769043, 0.99443519115448, 0.9997057914733887, 1.0406280755996704, 1.0278306007385254, 1.0710746049880981, 1.0388447046279907, 1.083953619003296, 1.0662972927093506, 1.0716089010238647, 1.08302640914917, 1.0781294107437134, 1.112658143043518, 1.09695303440094, 1.1235158443450928, 1.1045430898666382, 1.1130437850952148, 1.1220707893371582, 1.117343544960022, 1.1399552822113037, 1.2007538080215454, 1.1281694173812866, 1.1596627235412598, 1.1666806936264038, 1.1814299821853638, 1.1737974882125854, 1.1525779962539673, 1.164991021156311, 1.212419033050537, 1.2370425462722778, 1.2489310503005981, 1.2423454523086548, 1.1872063875198364, 1.223965048789978, 1.2590205669403076, 1.212196707725525, 1.244073510169983, 1.2359610795974731, 1.2267283201217651, 1.2695990800857544, 1.2502204179763794, 1.2539080381393433, 1.3143850564956665, 1.2444195747375488, 1.2771179676055908, 1.2724672555923462, 1.2662055492401123, 1.2768757343292236, 1.3026951551437378, 1.347620964050293, 1.2843592166900635, 1.2925268411636353, 1.317549467086792, 1.4325146675109863, 1.3341950178146362, 1.346704363822937, 1.3537468910217285, 1.3390918970108032, 1.3465583324432373, 1.3406935930252075, 1.3381515741348267, 1.3345417976379395, 1.3433631658554077, 1.4802250862121582, 1.358919382095337, 1.3610889911651611, 1.3609871864318848, 1.3970891237258911, 1.3842135667800903, 1.3818168640136719, 1.388190746307373, 1.4470478296279907, 1.4019381999969482, 1.4010661840438843, 1.4174776077270508, 1.4640823602676392, 1.4343537092208862], 'val_accuracy': [0.49793389439582825, 0.5010330677032471, 0.5051652789115906, 0.5041322112083435, 0.5299586653709412, 0.5154958963394165, 0.5506198406219482, 0.5557851195335388, 0.557851254940033, 0.577479362487793, 0.6074380278587341, 0.5981404781341553, 0.6415289044380188, 0.6683884263038635, 0.6663222908973694, 0.6714876294136047, 0.7045454382896423, 0.7014462947845459, 0.6880165338516235, 0.6962810158729553, 0.6890496015548706, 0.6384297609329224, 0.6942148804664612, 0.6714876294136047, 0.682851254940033, 0.6869834661483765, 0.6962810158729553, 0.6952479481697083, 0.6787189841270447, 0.6931818127632141, 0.6776859760284424, 0.692148745059967, 0.6900826692581177, 0.6900826692581177, 0.7004132270812988, 0.682851254940033, 0.6952479481697083, 0.682851254940033, 0.692148745059967, 0.69111567735672, 0.6983470916748047, 0.6849173307418823, 0.6890496015548706, 0.6818181872367859, 0.6818181872367859, 0.6776859760284424, 0.6735537052154541, 0.6766529083251953, 0.6869834661483765, 0.6787189841270447, 0.6900826692581177, 0.6849173307418823, 0.6652892827987671, 0.6621900796890259, 0.6652892827987671, 0.6776859760284424, 0.682851254940033, 0.672520637512207, 0.6890496015548706, 0.6807851195335388, 0.6787189841270447, 0.6807851195335388, 0.672520637512207, 0.6776859760284424, 0.6807851195335388, 0.6683884263038635, 0.6745867729187012, 0.672520637512207, 0.6807851195335388, 0.6859503984451294, 0.6859503984451294, 0.6776859760284424, 0.6735537052154541, 0.6787189841270447, 0.6776859760284424, 0.6818181872367859, 0.6477272510528564, 0.6745867729187012, 0.6756198406219482, 0.6776859760284424, 0.6756198406219482, 0.6776859760284424, 0.6766529083251953, 0.6735537052154541, 0.6714876294136047, 0.6787189841270447, 0.6580578684806824, 0.6735537052154541, 0.6673553586006165, 0.6766529083251953, 0.6714876294136047, 0.6735537052154541, 0.6694214940071106, 0.6673553586006165, 0.6714876294136047, 0.6745867729187012, 0.6714876294136047, 0.6735537052154541, 0.6683884263038635, 0.6663222908973694]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.3829 - accuracy: 0.9407"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 66ms/step - loss: 0.3829 - accuracy: 0.9407 - val_loss: 0.9586 - val_accuracy: 0.4881\n","Epoch 2/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3793 - accuracy: 0.9383 - val_loss: 0.9393 - val_accuracy: 0.4946\n","Epoch 3/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3603 - accuracy: 0.9415 - val_loss: 0.9332 - val_accuracy: 0.4989\n","Epoch 4/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.3595 - accuracy: 0.9423 - val_loss: 0.9354 - val_accuracy: 0.5000\n","Epoch 5/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3387 - accuracy: 0.9483 - val_loss: 0.9299 - val_accuracy: 0.5086\n","Epoch 6/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3281 - accuracy: 0.9537 - val_loss: 0.9124 - val_accuracy: 0.5162\n","Epoch 7/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3237 - accuracy: 0.9609 - val_loss: 0.8893 - val_accuracy: 0.5312\n","Epoch 8/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3234 - accuracy: 0.9617 - val_loss: 0.8722 - val_accuracy: 0.5399\n","Epoch 9/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3325 - accuracy: 0.9510 - val_loss: 0.8716 - val_accuracy: 0.5453\n","Epoch 10/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3162 - accuracy: 0.9588 - val_loss: 0.8268 - val_accuracy: 0.6045\n","Epoch 11/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3117 - accuracy: 0.9628 - val_loss: 0.8062 - val_accuracy: 0.6293\n","Epoch 12/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3055 - accuracy: 0.9663 - val_loss: 0.8237 - val_accuracy: 0.6099\n","Epoch 13/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3084 - accuracy: 0.9644 - val_loss: 0.7731 - val_accuracy: 0.6659\n","Epoch 14/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2995 - accuracy: 0.9690 - val_loss: 0.7399 - val_accuracy: 0.7134\n","Epoch 15/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2961 - accuracy: 0.9712 - val_loss: 0.7315 - val_accuracy: 0.7198\n","Epoch 16/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2962 - accuracy: 0.9704 - val_loss: 0.7012 - val_accuracy: 0.7565\n","Epoch 17/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2911 - accuracy: 0.9728 - val_loss: 0.6927 - val_accuracy: 0.7489\n","Epoch 18/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2927 - accuracy: 0.9706 - val_loss: 0.6831 - val_accuracy: 0.7705\n","Epoch 19/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2964 - accuracy: 0.9677 - val_loss: 0.6716 - val_accuracy: 0.7899\n","Epoch 20/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2964 - accuracy: 0.9674 - val_loss: 0.6872 - val_accuracy: 0.7866\n","Epoch 21/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3228 - accuracy: 0.9553 - val_loss: 0.7984 - val_accuracy: 0.7284\n","Epoch 22/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3007 - accuracy: 0.9644 - val_loss: 0.6817 - val_accuracy: 0.8006\n","Epoch 23/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.2809 - accuracy: 0.9733 - val_loss: 0.6984 - val_accuracy: 0.8071\n","Epoch 24/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2819 - accuracy: 0.9758 - val_loss: 0.7513 - val_accuracy: 0.7899\n","Epoch 25/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.2786 - accuracy: 0.9758 - val_loss: 0.7366 - val_accuracy: 0.8082\n","Epoch 26/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.2847 - accuracy: 0.9704 - val_loss: 0.7503 - val_accuracy: 0.8114\n","Epoch 27/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2794 - accuracy: 0.9739 - val_loss: 0.9109 - val_accuracy: 0.7586\n","Epoch 28/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2849 - accuracy: 0.9712 - val_loss: 0.7815 - val_accuracy: 0.8071\n","Epoch 29/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.2750 - accuracy: 0.9760 - val_loss: 0.8017 - val_accuracy: 0.8136\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2777 - accuracy: 0.9758 - val_loss: 0.8375 - val_accuracy: 0.7963\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2786 - accuracy: 0.9744 - val_loss: 0.8314 - val_accuracy: 0.8017\n","Epoch 32/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2718 - accuracy: 0.9779 - val_loss: 0.8554 - val_accuracy: 0.7996\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2949 - accuracy: 0.9669 - val_loss: 0.8448 - val_accuracy: 0.8028\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2825 - accuracy: 0.9747 - val_loss: 0.8563 - val_accuracy: 0.8050\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2742 - accuracy: 0.9749 - val_loss: 0.8969 - val_accuracy: 0.7909\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2672 - accuracy: 0.9803 - val_loss: 0.8695 - val_accuracy: 0.8060\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2634 - accuracy: 0.9817 - val_loss: 0.8636 - val_accuracy: 0.8082\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2804 - accuracy: 0.9739 - val_loss: 0.8917 - val_accuracy: 0.7877\n","Epoch 39/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2782 - accuracy: 0.9728 - val_loss: 0.9591 - val_accuracy: 0.7769\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2600 - accuracy: 0.9844 - val_loss: 0.8947 - val_accuracy: 0.8050\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2519 - accuracy: 0.9857 - val_loss: 0.8966 - val_accuracy: 0.8006\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2566 - accuracy: 0.9828 - val_loss: 0.8830 - val_accuracy: 0.8039\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2680 - accuracy: 0.9763 - val_loss: 0.8865 - val_accuracy: 0.8039\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2669 - accuracy: 0.9766 - val_loss: 0.8902 - val_accuracy: 0.7931\n","Epoch 45/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2535 - accuracy: 0.9863 - val_loss: 0.8888 - val_accuracy: 0.7963\n","Epoch 46/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2471 - accuracy: 0.9890 - val_loss: 0.8929 - val_accuracy: 0.7996\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2466 - accuracy: 0.9865 - val_loss: 0.9097 - val_accuracy: 0.7985\n","Epoch 48/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2616 - accuracy: 0.9795 - val_loss: 1.0791 - val_accuracy: 0.7705\n","Epoch 49/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2694 - accuracy: 0.9728 - val_loss: 0.9096 - val_accuracy: 0.8028\n","Epoch 50/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2520 - accuracy: 0.9860 - val_loss: 0.9199 - val_accuracy: 0.8028\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2471 - accuracy: 0.9852 - val_loss: 0.9047 - val_accuracy: 0.8103\n","Epoch 52/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2477 - accuracy: 0.9865 - val_loss: 0.9093 - val_accuracy: 0.8039\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2436 - accuracy: 0.9903 - val_loss: 0.9496 - val_accuracy: 0.7866\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2483 - accuracy: 0.9844 - val_loss: 0.9865 - val_accuracy: 0.7834\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2442 - accuracy: 0.9860 - val_loss: 0.9290 - val_accuracy: 0.7974\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2414 - accuracy: 0.9871 - val_loss: 0.9382 - val_accuracy: 0.8006\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2448 - accuracy: 0.9871 - val_loss: 0.9481 - val_accuracy: 0.7942\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2573 - accuracy: 0.9787 - val_loss: 0.9287 - val_accuracy: 0.8006\n","Epoch 59/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2620 - accuracy: 0.9776 - val_loss: 0.9409 - val_accuracy: 0.8017\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2418 - accuracy: 0.9881 - val_loss: 0.9344 - val_accuracy: 0.7931\n","Epoch 61/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2397 - accuracy: 0.9887 - val_loss: 0.9462 - val_accuracy: 0.8017\n","Epoch 62/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2407 - accuracy: 0.9871 - val_loss: 0.9628 - val_accuracy: 0.7985\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2423 - accuracy: 0.9863 - val_loss: 1.0167 - val_accuracy: 0.7845\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2566 - accuracy: 0.9768 - val_loss: 0.9573 - val_accuracy: 0.7953\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2447 - accuracy: 0.9865 - val_loss: 0.9352 - val_accuracy: 0.8060\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2418 - accuracy: 0.9879 - val_loss: 0.9856 - val_accuracy: 0.7909\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2346 - accuracy: 0.9903 - val_loss: 0.9829 - val_accuracy: 0.7931\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2340 - accuracy: 0.9876 - val_loss: 0.9617 - val_accuracy: 0.7931\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2338 - accuracy: 0.9881 - val_loss: 0.9759 - val_accuracy: 0.7953\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2310 - accuracy: 0.9898 - val_loss: 0.9793 - val_accuracy: 0.7953\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2329 - accuracy: 0.9881 - val_loss: 1.0499 - val_accuracy: 0.7759\n","Epoch 72/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2395 - accuracy: 0.9871 - val_loss: 1.0276 - val_accuracy: 0.7780\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2343 - accuracy: 0.9898 - val_loss: 0.9970 - val_accuracy: 0.7899\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2407 - accuracy: 0.9841 - val_loss: 0.9988 - val_accuracy: 0.7888\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2429 - accuracy: 0.9822 - val_loss: 1.0265 - val_accuracy: 0.7716\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2311 - accuracy: 0.9887 - val_loss: 1.0585 - val_accuracy: 0.7759\n","Epoch 77/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2406 - accuracy: 0.9836 - val_loss: 1.0167 - val_accuracy: 0.7802\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2375 - accuracy: 0.9868 - val_loss: 1.0165 - val_accuracy: 0.7942\n","Epoch 79/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2293 - accuracy: 0.9887 - val_loss: 0.9803 - val_accuracy: 0.7974\n","Epoch 80/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2307 - accuracy: 0.9892 - val_loss: 1.0134 - val_accuracy: 0.7942\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2280 - accuracy: 0.9914 - val_loss: 0.9921 - val_accuracy: 0.7856\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2248 - accuracy: 0.9906 - val_loss: 1.0069 - val_accuracy: 0.7942\n","Epoch 83/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2266 - accuracy: 0.9911 - val_loss: 1.0279 - val_accuracy: 0.7866\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2304 - accuracy: 0.9892 - val_loss: 1.0122 - val_accuracy: 0.7974\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2203 - accuracy: 0.9933 - val_loss: 1.0124 - val_accuracy: 0.7985\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2232 - accuracy: 0.9922 - val_loss: 1.0262 - val_accuracy: 0.7899\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2306 - accuracy: 0.9892 - val_loss: 1.0418 - val_accuracy: 0.7834\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2307 - accuracy: 0.9892 - val_loss: 1.0265 - val_accuracy: 0.7812\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2172 - accuracy: 0.9949 - val_loss: 1.0241 - val_accuracy: 0.7845\n","Epoch 90/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2223 - accuracy: 0.9908 - val_loss: 1.0982 - val_accuracy: 0.7683\n","Epoch 91/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2278 - accuracy: 0.9895 - val_loss: 1.0195 - val_accuracy: 0.7834\n","Epoch 92/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2200 - accuracy: 0.9922 - val_loss: 1.0249 - val_accuracy: 0.7920\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2228 - accuracy: 0.9914 - val_loss: 1.0396 - val_accuracy: 0.7920\n","Epoch 94/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2218 - accuracy: 0.9903 - val_loss: 1.0380 - val_accuracy: 0.7920\n","Epoch 95/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2238 - accuracy: 0.9908 - val_loss: 1.0423 - val_accuracy: 0.7812\n","Epoch 96/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2258 - accuracy: 0.9898 - val_loss: 1.0359 - val_accuracy: 0.7856\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2211 - accuracy: 0.9919 - val_loss: 1.0508 - val_accuracy: 0.7845\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2149 - accuracy: 0.9933 - val_loss: 1.0477 - val_accuracy: 0.7791\n","Epoch 99/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2122 - accuracy: 0.9962 - val_loss: 1.0504 - val_accuracy: 0.7877\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2152 - accuracy: 0.9933 - val_loss: 1.0602 - val_accuracy: 0.7856\n","{'loss': [0.3829183876514435, 0.3793233633041382, 0.36026445031166077, 0.3594585359096527, 0.3386518955230713, 0.32810381054878235, 0.32369086146354675, 0.3234173059463501, 0.33245429396629333, 0.3162386119365692, 0.31172043085098267, 0.305473268032074, 0.3084273040294647, 0.2994897961616516, 0.29607176780700684, 0.2962433695793152, 0.2911053001880646, 0.29265403747558594, 0.2963750660419464, 0.29644525051116943, 0.3227670192718506, 0.3007320761680603, 0.2808951735496521, 0.2819124460220337, 0.2786290645599365, 0.28473594784736633, 0.27938809990882874, 0.2849080264568329, 0.2750498056411743, 0.2776786684989929, 0.27856501936912537, 0.27176573872566223, 0.29489871859550476, 0.282472163438797, 0.2742478847503662, 0.2672066390514374, 0.26342108845710754, 0.2803545594215393, 0.2782018482685089, 0.25999462604522705, 0.25193893909454346, 0.2566383183002472, 0.26798611879348755, 0.26687440276145935, 0.25354018807411194, 0.24713167548179626, 0.24659310281276703, 0.2616044878959656, 0.2694304883480072, 0.25198623538017273, 0.24706080555915833, 0.24769791960716248, 0.2435751110315323, 0.2482660561800003, 0.2442001849412918, 0.24143491685390472, 0.24477137625217438, 0.2573434114456177, 0.26198846101760864, 0.24175086617469788, 0.23973001539707184, 0.2407148778438568, 0.24233341217041016, 0.2565784156322479, 0.24468208849430084, 0.24179154634475708, 0.23461385071277618, 0.23395374417304993, 0.23380665481090546, 0.23101820051670074, 0.23293210566043854, 0.23954010009765625, 0.23427781462669373, 0.24065330624580383, 0.24287179112434387, 0.23107343912124634, 0.24057483673095703, 0.2375486046075821, 0.22934594750404358, 0.2306573987007141, 0.2279801368713379, 0.2248462736606598, 0.22657281160354614, 0.23040878772735596, 0.22028233110904694, 0.22318464517593384, 0.2305849939584732, 0.2306584119796753, 0.21724191308021545, 0.22230932116508484, 0.2277955710887909, 0.21998406946659088, 0.22275255620479584, 0.22175659239292145, 0.22378990054130554, 0.22576406598091125, 0.22114166617393494, 0.21491886675357819, 0.2122199386358261, 0.21523746848106384], 'accuracy': [0.9407327771186829, 0.9383081793785095, 0.9415409564971924, 0.9423491358757019, 0.9482758641242981, 0.9536637663841248, 0.9609375, 0.9617456793785095, 0.9509698152542114, 0.9587823152542114, 0.9628232717514038, 0.9663254022598267, 0.9644396305084229, 0.9690194129943848, 0.9711745977401733, 0.970366358757019, 0.9727909564971924, 0.9706357717514038, 0.9676724076271057, 0.967402994632721, 0.9552801847457886, 0.9644396305084229, 0.9733297228813171, 0.9757543206214905, 0.9757543206214905, 0.970366358757019, 0.9738685488700867, 0.9711745977401733, 0.9760237336158752, 0.9757543206214905, 0.9744073152542114, 0.977909505367279, 0.9668642282485962, 0.9746767282485962, 0.974946141242981, 0.9803340435028076, 0.9816810488700867, 0.9738685488700867, 0.9727909564971924, 0.984375, 0.985722005367279, 0.982758641242981, 0.9762930870056152, 0.9765625, 0.9862607717514038, 0.9889547228813171, 0.9865301847457886, 0.9795258641242981, 0.9727909564971924, 0.985991358757019, 0.9851831793785095, 0.9865301847457886, 0.9903017282485962, 0.984375, 0.985991358757019, 0.9870689511299133, 0.9870689511299133, 0.9787176847457886, 0.9776400923728943, 0.9881465435028076, 0.9886853694915771, 0.9870689511299133, 0.9862607717514038, 0.9768319129943848, 0.9865301847457886, 0.9878771305084229, 0.9903017282485962, 0.9876077771186829, 0.9881465435028076, 0.9897629022598267, 0.9881465435028076, 0.9870689511299133, 0.9897629022598267, 0.9841055870056152, 0.9822198152542114, 0.9886853694915771, 0.9835668206214905, 0.9867995977401733, 0.9886853694915771, 0.9892241358757019, 0.9913793206214905, 0.990571141242981, 0.9911099076271057, 0.9892241358757019, 0.9932650923728943, 0.9921875, 0.9892241358757019, 0.9892241358757019, 0.9948814511299133, 0.990840494632721, 0.9894935488700867, 0.9921875, 0.9913793206214905, 0.9903017282485962, 0.990840494632721, 0.9897629022598267, 0.9919180870056152, 0.9932650923728943, 0.9962284564971924, 0.9932650923728943], 'val_loss': [0.9585663080215454, 0.9392953515052795, 0.9332237243652344, 0.9353619813919067, 0.929873526096344, 0.9124391674995422, 0.8893400430679321, 0.8721709847450256, 0.8715643286705017, 0.8267595767974854, 0.8061743974685669, 0.8237246870994568, 0.7731420397758484, 0.7398570775985718, 0.7315484285354614, 0.7012441158294678, 0.6927456855773926, 0.6830565333366394, 0.6716114282608032, 0.6871611475944519, 0.798360288143158, 0.6817134618759155, 0.6983904242515564, 0.7513266205787659, 0.7365950345993042, 0.7503174543380737, 0.9109038710594177, 0.7814637422561646, 0.8017468452453613, 0.8374872803688049, 0.8314287066459656, 0.8553884029388428, 0.8448026180267334, 0.8563075065612793, 0.8969129920005798, 0.8695107102394104, 0.8635637760162354, 0.8916807770729065, 0.9591161608695984, 0.8946831226348877, 0.8965573310852051, 0.8830427527427673, 0.8865290880203247, 0.8901779055595398, 0.8887519836425781, 0.8928587436676025, 0.90970778465271, 1.0790616273880005, 0.9096027612686157, 0.9199201464653015, 0.9047006368637085, 0.9093172550201416, 0.9495840668678284, 0.9865370988845825, 0.9290101528167725, 0.9382485747337341, 0.9480677247047424, 0.9287007451057434, 0.9408582448959351, 0.9344115853309631, 0.9462488889694214, 0.9628487229347229, 1.0167325735092163, 0.9573193788528442, 0.9351767897605896, 0.9856146574020386, 0.9829137325286865, 0.9616885185241699, 0.9759286046028137, 0.9793081879615784, 1.0499058961868286, 1.0275957584381104, 0.9970345497131348, 0.9987690448760986, 1.0264919996261597, 1.058517336845398, 1.0166515111923218, 1.0165040493011475, 0.9802654981613159, 1.013362169265747, 0.9920781254768372, 1.0068928003311157, 1.027937412261963, 1.012186884880066, 1.0124400854110718, 1.0262343883514404, 1.0417559146881104, 1.0264620780944824, 1.024090051651001, 1.0982143878936768, 1.0194871425628662, 1.0248650312423706, 1.0395623445510864, 1.0380123853683472, 1.0423051118850708, 1.0358922481536865, 1.0508025884628296, 1.0476617813110352, 1.0504010915756226, 1.0601855516433716], 'val_accuracy': [0.4881465435028076, 0.49461206793785095, 0.4989224076271057, 0.5, 0.5086206793785095, 0.5161637663841248, 0.53125, 0.5398706793785095, 0.545258641242981, 0.6045258641242981, 0.6293103694915771, 0.6099137663841248, 0.6659482717514038, 0.7133620977401733, 0.7198275923728943, 0.756465494632721, 0.7489224076271057, 0.7704741358757019, 0.7898706793785095, 0.7866379022598267, 0.7284482717514038, 0.8006465435028076, 0.8071120977401733, 0.7898706793785095, 0.8081896305084229, 0.8114224076271057, 0.7586206793785095, 0.8071120977401733, 0.8135775923728943, 0.7963362336158752, 0.8017241358757019, 0.7995689511299133, 0.8028017282485962, 0.8049569129943848, 0.7909482717514038, 0.806034505367279, 0.8081896305084229, 0.787715494632721, 0.7769396305084229, 0.8049569129943848, 0.8006465435028076, 0.8038793206214905, 0.8038793206214905, 0.7931034564971924, 0.7963362336158752, 0.7995689511299133, 0.798491358757019, 0.7704741358757019, 0.8028017282485962, 0.8028017282485962, 0.8103448152542114, 0.8038793206214905, 0.7866379022598267, 0.7834051847457886, 0.7974137663841248, 0.8006465435028076, 0.7941810488700867, 0.8006465435028076, 0.8017241358757019, 0.7931034564971924, 0.8017241358757019, 0.798491358757019, 0.7844827771186829, 0.795258641242981, 0.806034505367279, 0.7909482717514038, 0.7931034564971924, 0.7931034564971924, 0.795258641242981, 0.795258641242981, 0.7758620977401733, 0.7780172228813171, 0.7898706793785095, 0.7887930870056152, 0.7715517282485962, 0.7758620977401733, 0.7801724076271057, 0.7941810488700867, 0.7974137663841248, 0.7941810488700867, 0.7855603694915771, 0.7941810488700867, 0.7866379022598267, 0.7974137663841248, 0.798491358757019, 0.7898706793785095, 0.7834051847457886, 0.78125, 0.7844827771186829, 0.7683189511299133, 0.7834051847457886, 0.7920258641242981, 0.7920258641242981, 0.7920258641242981, 0.78125, 0.7855603694915771, 0.7844827771186829, 0.7790948152542114, 0.787715494632721, 0.7855603694915771]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 8s 59ms/step - loss: 0.3968 - accuracy: 0.9247 - val_loss: 0.9416 - val_accuracy: 0.5068\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 1s 22ms/step - loss: 0.3624 - accuracy: 0.9431 - val_loss: 0.9317 - val_accuracy: 0.5124\n","Epoch 3/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3425 - accuracy: 0.9474 - val_loss: 0.9298 - val_accuracy: 0.5158\n","Epoch 4/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3387 - accuracy: 0.9508 - val_loss: 0.9335 - val_accuracy: 0.5158\n","Epoch 5/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3483 - accuracy: 0.9411 - val_loss: 0.9167 - val_accuracy: 0.5260\n","Epoch 6/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3309 - accuracy: 0.9556 - val_loss: 0.9019 - val_accuracy: 0.5305\n","Epoch 7/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3244 - accuracy: 0.9567 - val_loss: 0.8998 - val_accuracy: 0.5351\n","Epoch 8/100\n","28/28 [==============================] - 1s 42ms/step - loss: 0.3190 - accuracy: 0.9598 - val_loss: 0.8768 - val_accuracy: 0.5509\n","Epoch 9/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3181 - accuracy: 0.9598 - val_loss: 0.8557 - val_accuracy: 0.5679\n","Epoch 10/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3137 - accuracy: 0.9607 - val_loss: 0.8525 - val_accuracy: 0.5713\n","Epoch 11/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3140 - accuracy: 0.9604 - val_loss: 0.8198 - val_accuracy: 0.6086\n","Epoch 12/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3224 - accuracy: 0.9567 - val_loss: 0.7853 - val_accuracy: 0.6584\n","Epoch 13/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3218 - accuracy: 0.9542 - val_loss: 0.7611 - val_accuracy: 0.6833\n","Epoch 14/100\n","28/28 [==============================] - 2s 58ms/step - loss: 0.3147 - accuracy: 0.9590 - val_loss: 0.7431 - val_accuracy: 0.7127\n","Epoch 15/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3011 - accuracy: 0.9666 - val_loss: 0.7597 - val_accuracy: 0.6889\n","Epoch 16/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.3067 - accuracy: 0.9658 - val_loss: 0.7024 - val_accuracy: 0.7534\n","Epoch 17/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2969 - accuracy: 0.9677 - val_loss: 0.7183 - val_accuracy: 0.7353\n","Epoch 18/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.3036 - accuracy: 0.9672 - val_loss: 0.6593 - val_accuracy: 0.7986\n","Epoch 19/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2896 - accuracy: 0.9726 - val_loss: 0.6803 - val_accuracy: 0.7771\n","Epoch 20/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2862 - accuracy: 0.9731 - val_loss: 0.6970 - val_accuracy: 0.7760\n","Epoch 21/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2936 - accuracy: 0.9697 - val_loss: 0.6967 - val_accuracy: 0.7794\n","Epoch 22/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2813 - accuracy: 0.9762 - val_loss: 0.6868 - val_accuracy: 0.7941\n","Epoch 23/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2873 - accuracy: 0.9714 - val_loss: 0.7714 - val_accuracy: 0.7715\n","Epoch 24/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2935 - accuracy: 0.9700 - val_loss: 0.7130 - val_accuracy: 0.7952\n","Epoch 25/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2902 - accuracy: 0.9720 - val_loss: 0.7040 - val_accuracy: 0.7964\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2918 - accuracy: 0.9703 - val_loss: 0.7462 - val_accuracy: 0.7975\n","Epoch 27/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2843 - accuracy: 0.9728 - val_loss: 0.7609 - val_accuracy: 0.7794\n","Epoch 28/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2729 - accuracy: 0.9748 - val_loss: 0.7722 - val_accuracy: 0.7907\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2723 - accuracy: 0.9788 - val_loss: 0.7855 - val_accuracy: 0.7873\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2756 - accuracy: 0.9774 - val_loss: 0.8126 - val_accuracy: 0.7907\n","Epoch 31/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2706 - accuracy: 0.9805 - val_loss: 0.8723 - val_accuracy: 0.7930\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2925 - accuracy: 0.9675 - val_loss: 0.8603 - val_accuracy: 0.7975\n","Epoch 33/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2729 - accuracy: 0.9782 - val_loss: 0.8724 - val_accuracy: 0.7919\n","Epoch 34/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2664 - accuracy: 0.9793 - val_loss: 0.8443 - val_accuracy: 0.7941\n","Epoch 35/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2606 - accuracy: 0.9830 - val_loss: 0.8383 - val_accuracy: 0.7941\n","Epoch 36/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2650 - accuracy: 0.9827 - val_loss: 0.8476 - val_accuracy: 0.7896\n","Epoch 37/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2652 - accuracy: 0.9799 - val_loss: 0.8787 - val_accuracy: 0.7805\n","Epoch 38/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2776 - accuracy: 0.9717 - val_loss: 0.8662 - val_accuracy: 0.7907\n","Epoch 39/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2704 - accuracy: 0.9731 - val_loss: 0.8825 - val_accuracy: 0.7839\n","Epoch 40/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2688 - accuracy: 0.9782 - val_loss: 0.9379 - val_accuracy: 0.7952\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2602 - accuracy: 0.9793 - val_loss: 0.8921 - val_accuracy: 0.7760\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2603 - accuracy: 0.9810 - val_loss: 0.8784 - val_accuracy: 0.7862\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2525 - accuracy: 0.9850 - val_loss: 0.9226 - val_accuracy: 0.7851\n","Epoch 44/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2560 - accuracy: 0.9819 - val_loss: 0.8879 - val_accuracy: 0.7839\n","Epoch 45/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2542 - accuracy: 0.9878 - val_loss: 0.9182 - val_accuracy: 0.7873\n","Epoch 46/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2520 - accuracy: 0.9850 - val_loss: 0.8918 - val_accuracy: 0.7885\n","Epoch 47/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2520 - accuracy: 0.9859 - val_loss: 1.0045 - val_accuracy: 0.7805\n","Epoch 48/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2575 - accuracy: 0.9802 - val_loss: 0.9309 - val_accuracy: 0.7771\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2469 - accuracy: 0.9859 - val_loss: 0.9145 - val_accuracy: 0.7783\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2565 - accuracy: 0.9805 - val_loss: 0.9292 - val_accuracy: 0.7715\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2474 - accuracy: 0.9853 - val_loss: 0.9295 - val_accuracy: 0.7771\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2490 - accuracy: 0.9825 - val_loss: 0.9302 - val_accuracy: 0.7760\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2455 - accuracy: 0.9878 - val_loss: 0.9671 - val_accuracy: 0.7692\n","Epoch 54/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2479 - accuracy: 0.9867 - val_loss: 0.9364 - val_accuracy: 0.7692\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2443 - accuracy: 0.9859 - val_loss: 0.9318 - val_accuracy: 0.7749\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2576 - accuracy: 0.9816 - val_loss: 1.1147 - val_accuracy: 0.7726\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2527 - accuracy: 0.9810 - val_loss: 0.9272 - val_accuracy: 0.7817\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2440 - accuracy: 0.9878 - val_loss: 0.9728 - val_accuracy: 0.7681\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2508 - accuracy: 0.9867 - val_loss: 0.9937 - val_accuracy: 0.7681\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2455 - accuracy: 0.9859 - val_loss: 0.9446 - val_accuracy: 0.7749\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2373 - accuracy: 0.9887 - val_loss: 0.9487 - val_accuracy: 0.7839\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2391 - accuracy: 0.9881 - val_loss: 0.9850 - val_accuracy: 0.7783\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2405 - accuracy: 0.9867 - val_loss: 0.9823 - val_accuracy: 0.7771\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2392 - accuracy: 0.9892 - val_loss: 0.9823 - val_accuracy: 0.7771\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2330 - accuracy: 0.9904 - val_loss: 1.0371 - val_accuracy: 0.7715\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2361 - accuracy: 0.9890 - val_loss: 1.0200 - val_accuracy: 0.7805\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2358 - accuracy: 0.9887 - val_loss: 1.0101 - val_accuracy: 0.7738\n","Epoch 68/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2367 - accuracy: 0.9881 - val_loss: 0.9847 - val_accuracy: 0.7851\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2259 - accuracy: 0.9941 - val_loss: 0.9881 - val_accuracy: 0.7851\n","Epoch 70/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2328 - accuracy: 0.9895 - val_loss: 1.0217 - val_accuracy: 0.7760\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2309 - accuracy: 0.9895 - val_loss: 1.0230 - val_accuracy: 0.7828\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2263 - accuracy: 0.9946 - val_loss: 0.9888 - val_accuracy: 0.7873\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2279 - accuracy: 0.9921 - val_loss: 0.9907 - val_accuracy: 0.7952\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2317 - accuracy: 0.9881 - val_loss: 0.9864 - val_accuracy: 0.7839\n","Epoch 75/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2333 - accuracy: 0.9878 - val_loss: 1.0044 - val_accuracy: 0.7828\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2277 - accuracy: 0.9918 - val_loss: 1.0419 - val_accuracy: 0.7760\n","Epoch 77/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2335 - accuracy: 0.9892 - val_loss: 1.0183 - val_accuracy: 0.7771\n","Epoch 78/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2269 - accuracy: 0.9915 - val_loss: 1.0281 - val_accuracy: 0.7817\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2249 - accuracy: 0.9907 - val_loss: 1.0401 - val_accuracy: 0.7794\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2291 - accuracy: 0.9912 - val_loss: 1.0442 - val_accuracy: 0.7715\n","Epoch 81/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2678 - accuracy: 0.9762 - val_loss: 1.1067 - val_accuracy: 0.7590\n","Epoch 82/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2336 - accuracy: 0.9898 - val_loss: 1.0249 - val_accuracy: 0.7749\n","Epoch 83/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2287 - accuracy: 0.9887 - val_loss: 1.0464 - val_accuracy: 0.7805\n","Epoch 84/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2289 - accuracy: 0.9901 - val_loss: 1.0621 - val_accuracy: 0.7771\n","Epoch 85/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2264 - accuracy: 0.9921 - val_loss: 1.0533 - val_accuracy: 0.7624\n","Epoch 86/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2281 - accuracy: 0.9904 - val_loss: 1.0249 - val_accuracy: 0.7738\n","Epoch 87/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2273 - accuracy: 0.9915 - val_loss: 1.0386 - val_accuracy: 0.7839\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2237 - accuracy: 0.9912 - val_loss: 1.0654 - val_accuracy: 0.7771\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2216 - accuracy: 0.9912 - val_loss: 1.0468 - val_accuracy: 0.7715\n","Epoch 90/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2200 - accuracy: 0.9941 - val_loss: 1.0978 - val_accuracy: 0.7794\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2243 - accuracy: 0.9907 - val_loss: 1.0694 - val_accuracy: 0.7726\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2295 - accuracy: 0.9887 - val_loss: 1.0705 - val_accuracy: 0.7647\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2184 - accuracy: 0.9943 - val_loss: 1.0856 - val_accuracy: 0.7715\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2156 - accuracy: 0.9935 - val_loss: 1.0685 - val_accuracy: 0.7715\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2165 - accuracy: 0.9938 - val_loss: 1.1008 - val_accuracy: 0.7715\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2168 - accuracy: 0.9932 - val_loss: 1.0896 - val_accuracy: 0.7783\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2149 - accuracy: 0.9938 - val_loss: 1.0658 - val_accuracy: 0.7771\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2175 - accuracy: 0.9921 - val_loss: 1.1646 - val_accuracy: 0.7692\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2150 - accuracy: 0.9949 - val_loss: 1.0872 - val_accuracy: 0.7658\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2174 - accuracy: 0.9907 - val_loss: 1.1715 - val_accuracy: 0.7726\n","{'loss': [0.39677688479423523, 0.36238232254981995, 0.34249258041381836, 0.3386986553668976, 0.34826505184173584, 0.3308500051498413, 0.32442188262939453, 0.3189918100833893, 0.31807824969291687, 0.31374457478523254, 0.31400278210639954, 0.32239267230033875, 0.32177749276161194, 0.3147229254245758, 0.30108320713043213, 0.30670061707496643, 0.29694676399230957, 0.30360400676727295, 0.28962403535842896, 0.28624624013900757, 0.293647825717926, 0.2812550961971283, 0.28732532262802124, 0.2934733033180237, 0.2901822626590729, 0.2918165326118469, 0.28428250551223755, 0.2728516161441803, 0.2723250985145569, 0.2755941152572632, 0.27064794301986694, 0.29245761036872864, 0.27287474274635315, 0.2664075493812561, 0.26057031750679016, 0.26498091220855713, 0.26516878604888916, 0.27758345007896423, 0.270404577255249, 0.2687641680240631, 0.2602344751358032, 0.26029476523399353, 0.2524818181991577, 0.25602394342422485, 0.25420430302619934, 0.25200191140174866, 0.25203126668930054, 0.2575337290763855, 0.2468586564064026, 0.2564839720726013, 0.24744848906993866, 0.24904286861419678, 0.2455129325389862, 0.24793502688407898, 0.24428841471672058, 0.25757551193237305, 0.2527117431163788, 0.24399206042289734, 0.2508277893066406, 0.24548114836215973, 0.23732291162014008, 0.23912788927555084, 0.24046505987644196, 0.23915301263332367, 0.23299597203731537, 0.23607568442821503, 0.23584020137786865, 0.23665785789489746, 0.22591719031333923, 0.23284894227981567, 0.23088395595550537, 0.22626656293869019, 0.22792033851146698, 0.23165950179100037, 0.2333187609910965, 0.22765441238880157, 0.23350659012794495, 0.22691097855567932, 0.22486533224582672, 0.229065403342247, 0.26779744029045105, 0.2335808128118515, 0.22873546183109283, 0.2289370745420456, 0.2264447659254074, 0.22805935144424438, 0.2272605150938034, 0.223671555519104, 0.22163094580173492, 0.21998894214630127, 0.22429364919662476, 0.2294674664735794, 0.21841992437839508, 0.21564114093780518, 0.21647387742996216, 0.21683141589164734, 0.2148607224225998, 0.21752190589904785, 0.21502716839313507, 0.21743488311767578], 'accuracy': [0.9247311949729919, 0.9431239366531372, 0.9473684430122375, 0.950764000415802, 0.9411431550979614, 0.9555743932723999, 0.9567062854766846, 0.9598188996315002, 0.9598188996315002, 0.9606677889823914, 0.9603848457336426, 0.9567062854766846, 0.9541596174240112, 0.9589700102806091, 0.9666100740432739, 0.9657611846923828, 0.9677419066429138, 0.9671760201454163, 0.9725523591041565, 0.9731183052062988, 0.9697226881980896, 0.9762309193611145, 0.9714204668998718, 0.9700056314468384, 0.9719864130020142, 0.9702886343002319, 0.9728353023529053, 0.974816083908081, 0.9787775874137878, 0.9773627519607544, 0.9804753661155701, 0.967458963394165, 0.9782116413116455, 0.9793435335159302, 0.9830220937728882, 0.9827390909194946, 0.9799094796180725, 0.9717034697532654, 0.9731183052062988, 0.9782116413116455, 0.9793435335159302, 0.9810413122177124, 0.9850028157234192, 0.9818902015686035, 0.9878324866294861, 0.9850028157234192, 0.9858517050743103, 0.9801924228668213, 0.9858517050743103, 0.9804753661155701, 0.9852858185768127, 0.9824561476707458, 0.9878324866294861, 0.9867005944252014, 0.9858517050743103, 0.9816072583198547, 0.9810413122177124, 0.9878324866294861, 0.9867005944252014, 0.9858517050743103, 0.9886813759803772, 0.9881154298782349, 0.9867005944252014, 0.9892473220825195, 0.9903791546821594, 0.988964319229126, 0.9886813759803772, 0.9881154298782349, 0.9940577149391174, 0.9895302653312683, 0.9895302653312683, 0.9946236610412598, 0.9920769929885864, 0.9881154298782349, 0.9878324866294861, 0.9917939901351929, 0.9892473220825195, 0.9915110468864441, 0.990662157535553, 0.9912280440330505, 0.9762309193611145, 0.9898132681846619, 0.9886813759803772, 0.9900962114334106, 0.9920769929885864, 0.9903791546821594, 0.9915110468864441, 0.9912280440330505, 0.9912280440330505, 0.9940577149391174, 0.990662157535553, 0.9886813759803772, 0.994340717792511, 0.9934917688369751, 0.9937747716903687, 0.9932088255882263, 0.9937747716903687, 0.9920769929885864, 0.9949066042900085, 0.990662157535553], 'val_loss': [0.9416128396987915, 0.9316651821136475, 0.9297654628753662, 0.9335038661956787, 0.9167212843894958, 0.901940643787384, 0.8998474478721619, 0.8767726421356201, 0.8556768894195557, 0.8525196313858032, 0.8198169469833374, 0.7852611541748047, 0.7611145973205566, 0.7430546283721924, 0.7596532106399536, 0.7023573517799377, 0.7182673215866089, 0.6592532396316528, 0.6802588701248169, 0.6969851851463318, 0.6967122554779053, 0.6867956519126892, 0.7714318037033081, 0.712957501411438, 0.7039525508880615, 0.7461679577827454, 0.760904848575592, 0.7721605896949768, 0.7855497598648071, 0.8125977516174316, 0.8723354339599609, 0.8602983951568604, 0.8723751902580261, 0.8442976474761963, 0.8383356928825378, 0.8475587368011475, 0.8786771893501282, 0.8662437200546265, 0.8824693560600281, 0.9378873109817505, 0.8921362161636353, 0.8784124851226807, 0.9226387739181519, 0.8878772258758545, 0.9182391166687012, 0.8917793035507202, 1.004477858543396, 0.9308677315711975, 0.9145189523696899, 0.9292184710502625, 0.9294808506965637, 0.9301795363426208, 0.9670827984809875, 0.9363515973091125, 0.9317939281463623, 1.1146901845932007, 0.9271958470344543, 0.9728184938430786, 0.9936531782150269, 0.9445896148681641, 0.9487314820289612, 0.9850398898124695, 0.9823470115661621, 0.982263445854187, 1.0370547771453857, 1.0200101137161255, 1.0101056098937988, 0.9847233295440674, 0.9881099462509155, 1.0216749906539917, 1.0230364799499512, 0.9888356924057007, 0.9906715154647827, 0.9864131212234497, 1.0044488906860352, 1.041852355003357, 1.0183392763137817, 1.0281105041503906, 1.0401279926300049, 1.0442280769348145, 1.1066588163375854, 1.0249077081680298, 1.0463989973068237, 1.062126874923706, 1.0532792806625366, 1.0248939990997314, 1.0386123657226562, 1.065422534942627, 1.0468188524246216, 1.0978105068206787, 1.0694063901901245, 1.0704960823059082, 1.0856109857559204, 1.0685032606124878, 1.1008232831954956, 1.0896058082580566, 1.0657546520233154, 1.164624810218811, 1.0871964693069458, 1.1714965105056763], 'val_accuracy': [0.5067873597145081, 0.5124434232711792, 0.5158371329307556, 0.5158371329307556, 0.5260180830955505, 0.5305429697036743, 0.5350678563117981, 0.5509049892425537, 0.5678732991218567, 0.5712669491767883, 0.6085972785949707, 0.6583710312843323, 0.6832579374313354, 0.7126696705818176, 0.6889140009880066, 0.7533936500549316, 0.7352941036224365, 0.7986425161361694, 0.7771493196487427, 0.7760180830955505, 0.779411792755127, 0.7941176295280457, 0.7714931964874268, 0.7952488660812378, 0.7963801026344299, 0.7975113391876221, 0.779411792755127, 0.790723979473114, 0.7873303294181824, 0.790723979473114, 0.7929864525794983, 0.7975113391876221, 0.7918552160263062, 0.7941176295280457, 0.7941176295280457, 0.7895927429199219, 0.7805429697036743, 0.790723979473114, 0.7839366793632507, 0.7952488660812378, 0.7760180830955505, 0.7861990928649902, 0.7850678563117981, 0.7839366793632507, 0.7873303294181824, 0.7884615659713745, 0.7805429697036743, 0.7771493196487427, 0.7782805562019348, 0.7714931964874268, 0.7771493196487427, 0.7760180830955505, 0.7692307829856873, 0.7692307829856873, 0.7748869061470032, 0.7726244330406189, 0.7816742062568665, 0.7680995464324951, 0.7680995464324951, 0.7748869061470032, 0.7839366793632507, 0.7782805562019348, 0.7771493196487427, 0.7771493196487427, 0.7714931964874268, 0.7805429697036743, 0.773755669593811, 0.7850678563117981, 0.7850678563117981, 0.7760180830955505, 0.7828054428100586, 0.7873303294181824, 0.7952488660812378, 0.7839366793632507, 0.7828054428100586, 0.7760180830955505, 0.7771493196487427, 0.7816742062568665, 0.779411792755127, 0.7714931964874268, 0.7590497732162476, 0.7748869061470032, 0.7805429697036743, 0.7771493196487427, 0.7624434232711792, 0.773755669593811, 0.7839366793632507, 0.7771493196487427, 0.7714931964874268, 0.779411792755127, 0.7726244330406189, 0.7647058963775635, 0.7714931964874268, 0.7714931964874268, 0.7714931964874268, 0.7782805562019348, 0.7771493196487427, 0.7692307829856873, 0.7658371329307556, 0.7726244330406189]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.4239 - accuracy: 0.9253"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 60ms/step - loss: 0.4253 - accuracy: 0.9251 - val_loss: 0.9552 - val_accuracy: 0.4959\n","Epoch 2/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4016 - accuracy: 0.9318 - val_loss: 0.9400 - val_accuracy: 0.4990\n","Epoch 3/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3869 - accuracy: 0.9307 - val_loss: 0.9415 - val_accuracy: 0.5000\n","Epoch 4/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.3862 - accuracy: 0.9346 - val_loss: 0.9376 - val_accuracy: 0.5062\n","Epoch 5/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3712 - accuracy: 0.9362 - val_loss: 0.9463 - val_accuracy: 0.5052\n","Epoch 6/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3639 - accuracy: 0.9442 - val_loss: 0.9374 - val_accuracy: 0.5083\n","Epoch 7/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3603 - accuracy: 0.9416 - val_loss: 0.9130 - val_accuracy: 0.5248\n","Epoch 8/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3565 - accuracy: 0.9468 - val_loss: 0.9259 - val_accuracy: 0.5279\n","Epoch 9/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3478 - accuracy: 0.9452 - val_loss: 0.8981 - val_accuracy: 0.5434\n","Epoch 10/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3559 - accuracy: 0.9416 - val_loss: 0.8568 - val_accuracy: 0.5744\n","Epoch 11/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3462 - accuracy: 0.9494 - val_loss: 0.8798 - val_accuracy: 0.5640\n","Epoch 12/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3401 - accuracy: 0.9499 - val_loss: 0.8196 - val_accuracy: 0.6405\n","Epoch 13/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3331 - accuracy: 0.9568 - val_loss: 0.8244 - val_accuracy: 0.6457\n","Epoch 14/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3258 - accuracy: 0.9537 - val_loss: 0.8335 - val_accuracy: 0.6395\n","Epoch 15/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3205 - accuracy: 0.9579 - val_loss: 0.8104 - val_accuracy: 0.6890\n","Epoch 16/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3173 - accuracy: 0.9620 - val_loss: 0.8278 - val_accuracy: 0.6849\n","Epoch 17/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3217 - accuracy: 0.9581 - val_loss: 0.8011 - val_accuracy: 0.7118\n","Epoch 18/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3153 - accuracy: 0.9594 - val_loss: 0.7832 - val_accuracy: 0.7541\n","Epoch 19/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3203 - accuracy: 0.9543 - val_loss: 0.8508 - val_accuracy: 0.7211\n","Epoch 20/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3146 - accuracy: 0.9589 - val_loss: 0.8262 - val_accuracy: 0.7655\n","Epoch 21/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3096 - accuracy: 0.9623 - val_loss: 0.8429 - val_accuracy: 0.7707\n","Epoch 22/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3056 - accuracy: 0.9628 - val_loss: 0.8897 - val_accuracy: 0.7500\n","Epoch 23/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3092 - accuracy: 0.9605 - val_loss: 0.9528 - val_accuracy: 0.7283\n","Epoch 24/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.3076 - accuracy: 0.9589 - val_loss: 0.9290 - val_accuracy: 0.7717\n","Epoch 25/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3077 - accuracy: 0.9625 - val_loss: 0.9826 - val_accuracy: 0.7500\n","Epoch 26/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3067 - accuracy: 0.9618 - val_loss: 0.9782 - val_accuracy: 0.7583\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3020 - accuracy: 0.9656 - val_loss: 1.0306 - val_accuracy: 0.7541\n","Epoch 28/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3100 - accuracy: 0.9664 - val_loss: 1.0293 - val_accuracy: 0.7583\n","Epoch 29/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2951 - accuracy: 0.9700 - val_loss: 1.0425 - val_accuracy: 0.7521\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2969 - accuracy: 0.9685 - val_loss: 1.0766 - val_accuracy: 0.7614\n","Epoch 31/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2921 - accuracy: 0.9669 - val_loss: 1.0518 - val_accuracy: 0.7748\n","Epoch 32/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2890 - accuracy: 0.9705 - val_loss: 1.0769 - val_accuracy: 0.7655\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2896 - accuracy: 0.9703 - val_loss: 1.1052 - val_accuracy: 0.7428\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2952 - accuracy: 0.9693 - val_loss: 1.0947 - val_accuracy: 0.7603\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3006 - accuracy: 0.9625 - val_loss: 1.1599 - val_accuracy: 0.7500\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2881 - accuracy: 0.9703 - val_loss: 1.1296 - val_accuracy: 0.7521\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2837 - accuracy: 0.9716 - val_loss: 1.1209 - val_accuracy: 0.7552\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2762 - accuracy: 0.9765 - val_loss: 1.1655 - val_accuracy: 0.7531\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2776 - accuracy: 0.9767 - val_loss: 1.1522 - val_accuracy: 0.7510\n","Epoch 40/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2785 - accuracy: 0.9721 - val_loss: 1.1349 - val_accuracy: 0.7479\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2768 - accuracy: 0.9742 - val_loss: 1.1687 - val_accuracy: 0.7417\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2952 - accuracy: 0.9669 - val_loss: 1.1994 - val_accuracy: 0.7314\n","Epoch 43/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2842 - accuracy: 0.9713 - val_loss: 1.1667 - val_accuracy: 0.7500\n","Epoch 44/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2729 - accuracy: 0.9770 - val_loss: 1.1716 - val_accuracy: 0.7438\n","Epoch 45/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2678 - accuracy: 0.9775 - val_loss: 1.2268 - val_accuracy: 0.7345\n","Epoch 46/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2929 - accuracy: 0.9654 - val_loss: 1.1884 - val_accuracy: 0.7417\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2788 - accuracy: 0.9703 - val_loss: 1.1455 - val_accuracy: 0.7572\n","Epoch 48/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2730 - accuracy: 0.9755 - val_loss: 1.1558 - val_accuracy: 0.7583\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2699 - accuracy: 0.9767 - val_loss: 1.2105 - val_accuracy: 0.7490\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2688 - accuracy: 0.9757 - val_loss: 1.1768 - val_accuracy: 0.7552\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2647 - accuracy: 0.9806 - val_loss: 1.1552 - val_accuracy: 0.7490\n","Epoch 52/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2654 - accuracy: 0.9783 - val_loss: 1.1974 - val_accuracy: 0.7438\n","Epoch 53/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2596 - accuracy: 0.9814 - val_loss: 1.2134 - val_accuracy: 0.7417\n","Epoch 54/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2600 - accuracy: 0.9801 - val_loss: 1.1884 - val_accuracy: 0.7521\n","Epoch 55/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2553 - accuracy: 0.9829 - val_loss: 1.2183 - val_accuracy: 0.7500\n","Epoch 56/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2715 - accuracy: 0.9744 - val_loss: 1.2290 - val_accuracy: 0.7469\n","Epoch 57/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2654 - accuracy: 0.9749 - val_loss: 1.1895 - val_accuracy: 0.7521\n","Epoch 58/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2557 - accuracy: 0.9819 - val_loss: 1.1947 - val_accuracy: 0.7490\n","Epoch 59/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2500 - accuracy: 0.9837 - val_loss: 1.1858 - val_accuracy: 0.7500\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2645 - accuracy: 0.9767 - val_loss: 1.2828 - val_accuracy: 0.7345\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2551 - accuracy: 0.9811 - val_loss: 1.2375 - val_accuracy: 0.7438\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2600 - accuracy: 0.9775 - val_loss: 1.1840 - val_accuracy: 0.7541\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2513 - accuracy: 0.9829 - val_loss: 1.1869 - val_accuracy: 0.7552\n","Epoch 64/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2435 - accuracy: 0.9884 - val_loss: 1.2975 - val_accuracy: 0.7376\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2455 - accuracy: 0.9855 - val_loss: 1.2100 - val_accuracy: 0.7479\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2436 - accuracy: 0.9832 - val_loss: 1.3161 - val_accuracy: 0.7335\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2518 - accuracy: 0.9801 - val_loss: 1.2422 - val_accuracy: 0.7376\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2461 - accuracy: 0.9845 - val_loss: 1.2157 - val_accuracy: 0.7562\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2456 - accuracy: 0.9860 - val_loss: 1.2464 - val_accuracy: 0.7448\n","Epoch 70/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2411 - accuracy: 0.9894 - val_loss: 1.2401 - val_accuracy: 0.7459\n","Epoch 71/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2450 - accuracy: 0.9840 - val_loss: 1.2483 - val_accuracy: 0.7469\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2440 - accuracy: 0.9860 - val_loss: 1.3339 - val_accuracy: 0.7304\n","Epoch 73/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2499 - accuracy: 0.9788 - val_loss: 1.2768 - val_accuracy: 0.7448\n","Epoch 74/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2455 - accuracy: 0.9837 - val_loss: 1.2780 - val_accuracy: 0.7438\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2507 - accuracy: 0.9827 - val_loss: 1.3241 - val_accuracy: 0.7355\n","Epoch 76/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2487 - accuracy: 0.9819 - val_loss: 1.2672 - val_accuracy: 0.7407\n","Epoch 77/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2447 - accuracy: 0.9853 - val_loss: 1.4023 - val_accuracy: 0.7159\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2537 - accuracy: 0.9786 - val_loss: 1.2971 - val_accuracy: 0.7428\n","Epoch 79/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2329 - accuracy: 0.9884 - val_loss: 1.3044 - val_accuracy: 0.7479\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2414 - accuracy: 0.9840 - val_loss: 1.3658 - val_accuracy: 0.7397\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2434 - accuracy: 0.9860 - val_loss: 1.3421 - val_accuracy: 0.7283\n","Epoch 82/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2314 - accuracy: 0.9899 - val_loss: 1.3167 - val_accuracy: 0.7262\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2354 - accuracy: 0.9899 - val_loss: 1.3059 - val_accuracy: 0.7386\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2448 - accuracy: 0.9804 - val_loss: 1.3500 - val_accuracy: 0.7293\n","Epoch 85/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2525 - accuracy: 0.9773 - val_loss: 1.2865 - val_accuracy: 0.7407\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2387 - accuracy: 0.9842 - val_loss: 1.3512 - val_accuracy: 0.7273\n","Epoch 87/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2462 - accuracy: 0.9806 - val_loss: 1.3277 - val_accuracy: 0.7314\n","Epoch 88/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2353 - accuracy: 0.9868 - val_loss: 1.3469 - val_accuracy: 0.7293\n","Epoch 89/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2524 - accuracy: 0.9817 - val_loss: 1.3208 - val_accuracy: 0.7448\n","Epoch 90/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2316 - accuracy: 0.9879 - val_loss: 1.3010 - val_accuracy: 0.7355\n","Epoch 91/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2485 - accuracy: 0.9786 - val_loss: 1.3187 - val_accuracy: 0.7510\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2316 - accuracy: 0.9879 - val_loss: 1.3083 - val_accuracy: 0.7438\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2233 - accuracy: 0.9925 - val_loss: 1.2941 - val_accuracy: 0.7428\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2231 - accuracy: 0.9912 - val_loss: 1.3304 - val_accuracy: 0.7355\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2228 - accuracy: 0.9925 - val_loss: 1.3465 - val_accuracy: 0.7345\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2253 - accuracy: 0.9891 - val_loss: 1.3492 - val_accuracy: 0.7252\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2230 - accuracy: 0.9897 - val_loss: 1.3280 - val_accuracy: 0.7438\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2228 - accuracy: 0.9891 - val_loss: 1.3322 - val_accuracy: 0.7397\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2205 - accuracy: 0.9912 - val_loss: 1.3619 - val_accuracy: 0.7335\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2212 - accuracy: 0.9915 - val_loss: 1.3388 - val_accuracy: 0.7469\n","{'loss': [0.4252585172653198, 0.40161561965942383, 0.386884480714798, 0.3862152099609375, 0.3711700737476349, 0.3639395236968994, 0.36030420660972595, 0.3565426170825958, 0.34784844517707825, 0.3559357225894928, 0.3462011516094208, 0.3401103615760803, 0.33307966589927673, 0.3258284032344818, 0.3205488324165344, 0.3173352777957916, 0.32167983055114746, 0.3153117299079895, 0.32025206089019775, 0.3146289885044098, 0.3096122145652771, 0.305632084608078, 0.3091850280761719, 0.30760839581489563, 0.3077400028705597, 0.30666494369506836, 0.3019547462463379, 0.3100222051143646, 0.29508861899375916, 0.2968786954879761, 0.29206183552742004, 0.2889864444732666, 0.2895718514919281, 0.2951958179473877, 0.3006460964679718, 0.288063645362854, 0.28366729617118835, 0.276226669549942, 0.27759161591529846, 0.2785041630268097, 0.2767685651779175, 0.29523447155952454, 0.2842119038105011, 0.27287739515304565, 0.2678215503692627, 0.29286110401153564, 0.27876797318458557, 0.27295902371406555, 0.26991134881973267, 0.2688090205192566, 0.2647174000740051, 0.26544034481048584, 0.25961360335350037, 0.2600100040435791, 0.2553153336048126, 0.27150893211364746, 0.265388548374176, 0.2557336091995239, 0.25003430247306824, 0.2644650638103485, 0.25506579875946045, 0.25998687744140625, 0.25125423073768616, 0.2435428500175476, 0.24549607932567596, 0.24356387555599213, 0.2517656683921814, 0.2460898607969284, 0.24562831223011017, 0.24108420312404633, 0.24499641358852386, 0.24397745728492737, 0.2499481737613678, 0.24546457827091217, 0.2507028579711914, 0.24866750836372375, 0.2447246015071869, 0.2537192106246948, 0.23289838433265686, 0.24143625795841217, 0.2433720976114273, 0.2313951849937439, 0.23537686467170715, 0.24480710923671722, 0.25253134965896606, 0.23869778215885162, 0.24616657197475433, 0.23534095287322998, 0.25237977504730225, 0.23161037266254425, 0.24849583208560944, 0.2315501719713211, 0.22327831387519836, 0.22310271859169006, 0.22275197505950928, 0.2253463864326477, 0.22297267615795135, 0.2227887511253357, 0.22048471868038177, 0.22123733162879944], 'accuracy': [0.9250646233558655, 0.9317829608917236, 0.9307493567466736, 0.9346253275871277, 0.9361757040023804, 0.9441860318183899, 0.9416020512580872, 0.9467700123786926, 0.9452196359634399, 0.9416020512580872, 0.9493539929389954, 0.9498708248138428, 0.9568475484848022, 0.9537467956542969, 0.9578811526298523, 0.9620155096054077, 0.9581395387649536, 0.959431529045105, 0.9542635679244995, 0.9589147567749023, 0.962273895740509, 0.9627906680107117, 0.960465133190155, 0.9589147567749023, 0.9625322818756104, 0.9617571234703064, 0.9656330943107605, 0.9664082527160645, 0.9700258374214172, 0.9684754610061646, 0.9669250845909119, 0.9705426096916199, 0.9702842235565186, 0.9692506194114685, 0.9625322818756104, 0.9702842235565186, 0.9715762138366699, 0.9764857888221741, 0.9767441749572754, 0.9720930457115173, 0.9741601943969727, 0.9669250845909119, 0.9713178277015686, 0.9770025610923767, 0.9775193929672241, 0.9653746485710144, 0.9702842235565186, 0.975452184677124, 0.9767441749572754, 0.9757105708122253, 0.9806201457977295, 0.9782945513725281, 0.9813953638076782, 0.9801033735275269, 0.9829457402229309, 0.974418580532074, 0.9749354124069214, 0.9819121360778809, 0.9837209582328796, 0.9767441749572754, 0.9811369776725769, 0.9775193929672241, 0.9829457402229309, 0.9883720874786377, 0.9855297207832336, 0.9832041263580322, 0.9801033735275269, 0.9844961166381836, 0.9860464930534363, 0.9894056916236877, 0.983979344367981, 0.9860464930534363, 0.9788113832473755, 0.9837209582328796, 0.9826873540878296, 0.9819121360778809, 0.9852713346481323, 0.9785529971122742, 0.9883720874786377, 0.983979344367981, 0.9860464930534363, 0.9899224638938904, 0.9899224638938904, 0.9803617596626282, 0.9772610068321228, 0.9842377305030823, 0.9806201457977295, 0.986821711063385, 0.9816537499427795, 0.9878553152084351, 0.9785529971122742, 0.9878553152084351, 0.9925064444541931, 0.9912144541740417, 0.9925064444541931, 0.9891473054885864, 0.9896640777587891, 0.9891473054885864, 0.9912144541740417, 0.9914728403091431], 'val_loss': [0.9552021026611328, 0.9400057196617126, 0.9414970278739929, 0.9376332759857178, 0.9463029503822327, 0.9373906850814819, 0.9130256175994873, 0.9258804321289062, 0.8981229066848755, 0.8567802906036377, 0.879831850528717, 0.8196192979812622, 0.824374794960022, 0.8334865570068359, 0.8104389905929565, 0.8277571201324463, 0.8011325001716614, 0.7831975221633911, 0.8508473038673401, 0.8262067437171936, 0.8428632020950317, 0.889682948589325, 0.9528483152389526, 0.929035484790802, 0.9825854897499084, 0.978246808052063, 1.0305743217468262, 1.0292714834213257, 1.0424576997756958, 1.0766388177871704, 1.051836609840393, 1.0768864154815674, 1.1051877737045288, 1.0947201251983643, 1.1599314212799072, 1.1296297311782837, 1.120901346206665, 1.165524959564209, 1.1521881818771362, 1.1348527669906616, 1.1686670780181885, 1.199373722076416, 1.1666843891143799, 1.1715738773345947, 1.226763367652893, 1.1883699893951416, 1.145491361618042, 1.1558465957641602, 1.2105389833450317, 1.176814079284668, 1.1552013158798218, 1.1973795890808105, 1.2134346961975098, 1.1883652210235596, 1.2182531356811523, 1.2289786338806152, 1.1894571781158447, 1.1947427988052368, 1.1858346462249756, 1.2828298807144165, 1.2375208139419556, 1.184036135673523, 1.186905026435852, 1.2975133657455444, 1.210007667541504, 1.3160525560379028, 1.2421561479568481, 1.215715765953064, 1.2463932037353516, 1.240116000175476, 1.2483407258987427, 1.3339163064956665, 1.2768105268478394, 1.2780261039733887, 1.3240625858306885, 1.26719069480896, 1.4022910594940186, 1.2971491813659668, 1.3044192790985107, 1.3657948970794678, 1.3420556783676147, 1.3166781663894653, 1.3058876991271973, 1.349960446357727, 1.2864508628845215, 1.351234793663025, 1.327717900276184, 1.3468741178512573, 1.3207579851150513, 1.300987958908081, 1.3187259435653687, 1.3083029985427856, 1.2941464185714722, 1.3303943872451782, 1.3465389013290405, 1.3492423295974731, 1.3280277252197266, 1.3321713209152222, 1.361918568611145, 1.338834285736084], 'val_accuracy': [0.4958677589893341, 0.49896693229675293, 0.5, 0.5061983466148376, 0.5051652789115906, 0.5082644820213318, 0.5247933864593506, 0.5278925895690918, 0.5433884263038635, 0.5743801593780518, 0.5640496015548706, 0.6404958963394165, 0.6456611752510071, 0.6394628286361694, 0.6890496015548706, 0.6849173307418823, 0.711776852607727, 0.7541322112083435, 0.7210744023323059, 0.7654958963394165, 0.7706611752510071, 0.75, 0.7283057570457458, 0.7716942429542542, 0.75, 0.7582644820213318, 0.7541322112083435, 0.7582644820213318, 0.7520661354064941, 0.7613636255264282, 0.7747933864593506, 0.7654958963394165, 0.7427685856819153, 0.7603305578231812, 0.75, 0.7520661354064941, 0.7551652789115906, 0.7530992031097412, 0.7510330677032471, 0.7479338645935059, 0.7417355179786682, 0.7314049601554871, 0.75, 0.7438016533851624, 0.7345041036605835, 0.7417355179786682, 0.7572314143180847, 0.7582644820213318, 0.7489669322967529, 0.7551652789115906, 0.7489669322967529, 0.7438016533851624, 0.7417355179786682, 0.7520661354064941, 0.75, 0.7469007968902588, 0.7520661354064941, 0.7489669322967529, 0.75, 0.7345041036605835, 0.7438016533851624, 0.7541322112083435, 0.7551652789115906, 0.7376033067703247, 0.7479338645935059, 0.7334710955619812, 0.7376033067703247, 0.7561983466148376, 0.7448347210884094, 0.7458677887916565, 0.7469007968902588, 0.73037189245224, 0.7448347210884094, 0.7438016533851624, 0.7355371713638306, 0.7407024502754211, 0.7159090638160706, 0.7427685856819153, 0.7479338645935059, 0.7396694421768188, 0.7283057570457458, 0.7262396812438965, 0.7386363744735718, 0.7293388247489929, 0.7407024502754211, 0.7272727489471436, 0.7314049601554871, 0.7293388247489929, 0.7448347210884094, 0.7355371713638306, 0.7510330677032471, 0.7438016533851624, 0.7427685856819153, 0.7355371713638306, 0.7345041036605835, 0.7252066135406494, 0.7438016533851624, 0.7396694421768188, 0.7334710955619812, 0.7469007968902588]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 0.2926 - accuracy: 0.9630"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 52ms/step - loss: 0.2899 - accuracy: 0.9639 - val_loss: 0.9646 - val_accuracy: 0.4903\n","Epoch 2/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2807 - accuracy: 0.9663 - val_loss: 0.9659 - val_accuracy: 0.4914\n","Epoch 3/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2653 - accuracy: 0.9714 - val_loss: 0.9572 - val_accuracy: 0.4989\n","Epoch 4/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2547 - accuracy: 0.9755 - val_loss: 0.9504 - val_accuracy: 0.5043\n","Epoch 5/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.2490 - accuracy: 0.9784 - val_loss: 0.9463 - val_accuracy: 0.5075\n","Epoch 6/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2612 - accuracy: 0.9752 - val_loss: 0.9461 - val_accuracy: 0.5086\n","Epoch 7/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2410 - accuracy: 0.9836 - val_loss: 0.9193 - val_accuracy: 0.5248\n","Epoch 8/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2474 - accuracy: 0.9790 - val_loss: 0.9012 - val_accuracy: 0.5345\n","Epoch 9/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2449 - accuracy: 0.9830 - val_loss: 0.8619 - val_accuracy: 0.5550\n","Epoch 10/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2410 - accuracy: 0.9820 - val_loss: 0.8521 - val_accuracy: 0.5700\n","Epoch 11/100\n","29/29 [==============================] - 2s 64ms/step - loss: 0.2454 - accuracy: 0.9801 - val_loss: 0.8154 - val_accuracy: 0.6067\n","Epoch 12/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.2322 - accuracy: 0.9855 - val_loss: 0.8072 - val_accuracy: 0.6131\n","Epoch 13/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.2341 - accuracy: 0.9873 - val_loss: 0.7508 - val_accuracy: 0.6595\n","Epoch 14/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2320 - accuracy: 0.9871 - val_loss: 0.6820 - val_accuracy: 0.7392\n","Epoch 15/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2307 - accuracy: 0.9841 - val_loss: 0.7571 - val_accuracy: 0.6746\n","Epoch 16/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2327 - accuracy: 0.9852 - val_loss: 0.6655 - val_accuracy: 0.7597\n","Epoch 17/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2261 - accuracy: 0.9871 - val_loss: 0.6398 - val_accuracy: 0.7856\n","Epoch 18/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2318 - accuracy: 0.9841 - val_loss: 0.6007 - val_accuracy: 0.8147\n","Epoch 19/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2280 - accuracy: 0.9876 - val_loss: 0.7216 - val_accuracy: 0.7575\n","Epoch 20/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2311 - accuracy: 0.9865 - val_loss: 0.6537 - val_accuracy: 0.8006\n","Epoch 21/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2457 - accuracy: 0.9766 - val_loss: 0.6225 - val_accuracy: 0.8330\n","Epoch 22/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2333 - accuracy: 0.9814 - val_loss: 0.6099 - val_accuracy: 0.8470\n","Epoch 23/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2270 - accuracy: 0.9846 - val_loss: 0.6668 - val_accuracy: 0.8254\n","Epoch 24/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2175 - accuracy: 0.9914 - val_loss: 0.7019 - val_accuracy: 0.8222\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2224 - accuracy: 0.9887 - val_loss: 0.7121 - val_accuracy: 0.8351\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2221 - accuracy: 0.9903 - val_loss: 0.7163 - val_accuracy: 0.8351\n","Epoch 27/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2187 - accuracy: 0.9903 - val_loss: 0.7133 - val_accuracy: 0.8459\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2150 - accuracy: 0.9930 - val_loss: 0.7421 - val_accuracy: 0.8416\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2254 - accuracy: 0.9860 - val_loss: 0.7715 - val_accuracy: 0.8448\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2214 - accuracy: 0.9871 - val_loss: 0.7810 - val_accuracy: 0.8319\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2531 - accuracy: 0.9741 - val_loss: 1.0622 - val_accuracy: 0.7640\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2439 - accuracy: 0.9766 - val_loss: 0.8164 - val_accuracy: 0.8308\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2223 - accuracy: 0.9873 - val_loss: 0.7924 - val_accuracy: 0.8427\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2187 - accuracy: 0.9911 - val_loss: 0.8431 - val_accuracy: 0.8254\n","Epoch 35/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2258 - accuracy: 0.9857 - val_loss: 0.8035 - val_accuracy: 0.8470\n","Epoch 36/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2162 - accuracy: 0.9887 - val_loss: 0.8096 - val_accuracy: 0.8427\n","Epoch 37/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.2125 - accuracy: 0.9935 - val_loss: 0.8026 - val_accuracy: 0.8502\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2136 - accuracy: 0.9908 - val_loss: 0.8184 - val_accuracy: 0.8459\n","Epoch 39/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2253 - accuracy: 0.9836 - val_loss: 0.8690 - val_accuracy: 0.8200\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2116 - accuracy: 0.9925 - val_loss: 0.8142 - val_accuracy: 0.8470\n","Epoch 41/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.2123 - accuracy: 0.9930 - val_loss: 0.8272 - val_accuracy: 0.8534\n","Epoch 42/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2148 - accuracy: 0.9911 - val_loss: 0.8402 - val_accuracy: 0.8351\n","Epoch 43/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2089 - accuracy: 0.9914 - val_loss: 0.8410 - val_accuracy: 0.8481\n","Epoch 44/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2096 - accuracy: 0.9933 - val_loss: 0.8301 - val_accuracy: 0.8448\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2071 - accuracy: 0.9927 - val_loss: 0.8326 - val_accuracy: 0.8427\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2101 - accuracy: 0.9911 - val_loss: 0.8229 - val_accuracy: 0.8502\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2011 - accuracy: 0.9960 - val_loss: 0.8334 - val_accuracy: 0.8416\n","Epoch 48/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2116 - accuracy: 0.9911 - val_loss: 0.8406 - val_accuracy: 0.8459\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2078 - accuracy: 0.9930 - val_loss: 0.9447 - val_accuracy: 0.8071\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2118 - accuracy: 0.9935 - val_loss: 0.8534 - val_accuracy: 0.8330\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2056 - accuracy: 0.9927 - val_loss: 0.8808 - val_accuracy: 0.8254\n","Epoch 52/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2099 - accuracy: 0.9911 - val_loss: 0.8590 - val_accuracy: 0.8459\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2043 - accuracy: 0.9935 - val_loss: 0.9045 - val_accuracy: 0.8222\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2075 - accuracy: 0.9933 - val_loss: 0.8768 - val_accuracy: 0.8351\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2277 - accuracy: 0.9820 - val_loss: 0.8930 - val_accuracy: 0.8222\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2043 - accuracy: 0.9935 - val_loss: 0.8626 - val_accuracy: 0.8416\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2067 - accuracy: 0.9906 - val_loss: 0.8746 - val_accuracy: 0.8330\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2009 - accuracy: 0.9930 - val_loss: 0.8786 - val_accuracy: 0.8384\n","Epoch 59/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1970 - accuracy: 0.9978 - val_loss: 0.8959 - val_accuracy: 0.8341\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2018 - accuracy: 0.9925 - val_loss: 0.8719 - val_accuracy: 0.8394\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1968 - accuracy: 0.9957 - val_loss: 0.8911 - val_accuracy: 0.8405\n","Epoch 62/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1988 - accuracy: 0.9968 - val_loss: 0.8923 - val_accuracy: 0.8351\n","Epoch 63/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2119 - accuracy: 0.9900 - val_loss: 0.8888 - val_accuracy: 0.8373\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2213 - accuracy: 0.9860 - val_loss: 0.9045 - val_accuracy: 0.8319\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2113 - accuracy: 0.9884 - val_loss: 0.8981 - val_accuracy: 0.8362\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1986 - accuracy: 0.9935 - val_loss: 0.9675 - val_accuracy: 0.8060\n","Epoch 67/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2063 - accuracy: 0.9914 - val_loss: 0.8881 - val_accuracy: 0.8265\n","Epoch 68/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2098 - accuracy: 0.9898 - val_loss: 0.8916 - val_accuracy: 0.8297\n","Epoch 69/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1941 - accuracy: 0.9960 - val_loss: 0.9200 - val_accuracy: 0.8287\n","Epoch 70/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2082 - accuracy: 0.9903 - val_loss: 1.0482 - val_accuracy: 0.7909\n","Epoch 71/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2003 - accuracy: 0.9935 - val_loss: 0.8906 - val_accuracy: 0.8297\n","Epoch 72/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1990 - accuracy: 0.9946 - val_loss: 0.8952 - val_accuracy: 0.8330\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1957 - accuracy: 0.9952 - val_loss: 0.8818 - val_accuracy: 0.8394\n","Epoch 74/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1904 - accuracy: 0.9973 - val_loss: 0.9102 - val_accuracy: 0.8373\n","Epoch 75/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1937 - accuracy: 0.9960 - val_loss: 0.9200 - val_accuracy: 0.8341\n","Epoch 76/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1963 - accuracy: 0.9949 - val_loss: 0.9903 - val_accuracy: 0.8103\n","Epoch 77/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2057 - accuracy: 0.9906 - val_loss: 1.0702 - val_accuracy: 0.7920\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2045 - accuracy: 0.9892 - val_loss: 0.9134 - val_accuracy: 0.8276\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1966 - accuracy: 0.9943 - val_loss: 0.9128 - val_accuracy: 0.8233\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1909 - accuracy: 0.9968 - val_loss: 0.9133 - val_accuracy: 0.8319\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1896 - accuracy: 0.9965 - val_loss: 0.8996 - val_accuracy: 0.8308\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1903 - accuracy: 0.9962 - val_loss: 0.9109 - val_accuracy: 0.8330\n","Epoch 83/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1924 - accuracy: 0.9962 - val_loss: 0.8976 - val_accuracy: 0.8308\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1914 - accuracy: 0.9968 - val_loss: 0.9011 - val_accuracy: 0.8373\n","Epoch 85/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1974 - accuracy: 0.9922 - val_loss: 1.0080 - val_accuracy: 0.8039\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1954 - accuracy: 0.9952 - val_loss: 0.9231 - val_accuracy: 0.8287\n","Epoch 87/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1908 - accuracy: 0.9949 - val_loss: 0.8984 - val_accuracy: 0.8287\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1879 - accuracy: 0.9965 - val_loss: 0.9123 - val_accuracy: 0.8244\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1877 - accuracy: 0.9968 - val_loss: 0.8964 - val_accuracy: 0.8330\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1904 - accuracy: 0.9954 - val_loss: 0.9226 - val_accuracy: 0.8233\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1959 - accuracy: 0.9927 - val_loss: 0.9040 - val_accuracy: 0.8341\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1849 - accuracy: 0.9965 - val_loss: 0.9013 - val_accuracy: 0.8351\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1854 - accuracy: 0.9978 - val_loss: 0.9341 - val_accuracy: 0.8319\n","Epoch 94/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1910 - accuracy: 0.9954 - val_loss: 0.9819 - val_accuracy: 0.8114\n","Epoch 95/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1945 - accuracy: 0.9933 - val_loss: 0.9418 - val_accuracy: 0.8265\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1851 - accuracy: 0.9965 - val_loss: 0.9243 - val_accuracy: 0.8319\n","Epoch 97/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1852 - accuracy: 0.9968 - val_loss: 0.9106 - val_accuracy: 0.8341\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1855 - accuracy: 0.9962 - val_loss: 0.9172 - val_accuracy: 0.8308\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1831 - accuracy: 0.9984 - val_loss: 0.9649 - val_accuracy: 0.8254\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1926 - accuracy: 0.9943 - val_loss: 0.9398 - val_accuracy: 0.8276\n","{'loss': [0.2899104356765747, 0.2806878685951233, 0.26532885432243347, 0.2547306418418884, 0.2490234673023224, 0.26123228669166565, 0.24096760153770447, 0.2474069893360138, 0.24488762021064758, 0.24102212488651276, 0.2454213798046112, 0.23219409584999084, 0.23408649861812592, 0.23200397193431854, 0.23073239624500275, 0.23265230655670166, 0.2260817289352417, 0.23181980848312378, 0.2280265837907791, 0.23113055527210236, 0.24571868777275085, 0.23334476351737976, 0.2270091325044632, 0.21748998761177063, 0.22236944735050201, 0.22211052477359772, 0.21872283518314362, 0.21496912837028503, 0.22536291182041168, 0.22141678631305695, 0.2531464397907257, 0.2439178228378296, 0.22226376831531525, 0.2186623513698578, 0.22577083110809326, 0.21624687314033508, 0.2125413715839386, 0.21360348165035248, 0.2252998799085617, 0.21155086159706116, 0.2123417854309082, 0.21482987701892853, 0.20894193649291992, 0.20955365896224976, 0.20707160234451294, 0.2101203352212906, 0.20112502574920654, 0.21161353588104248, 0.2077995240688324, 0.21182756125926971, 0.20558033883571625, 0.2098892331123352, 0.20425720512866974, 0.20751504600048065, 0.22768379747867584, 0.20429351925849915, 0.20673996210098267, 0.20089802145957947, 0.19703897833824158, 0.20182356238365173, 0.19678017497062683, 0.19882802665233612, 0.2119228094816208, 0.22132892906665802, 0.2113254964351654, 0.1985900104045868, 0.20634353160858154, 0.20978321135044098, 0.19408541917800903, 0.20823349058628082, 0.2003263235092163, 0.19898736476898193, 0.1957021951675415, 0.19043725728988647, 0.19373729825019836, 0.19627335667610168, 0.20565398037433624, 0.204524427652359, 0.1966390162706375, 0.19092126190662384, 0.1896490603685379, 0.19031359255313873, 0.19236703217029572, 0.19140523672103882, 0.19740726053714752, 0.1954200714826584, 0.19076314568519592, 0.18786384165287018, 0.18765375018119812, 0.19038565456867218, 0.19588230550289154, 0.1849280595779419, 0.1854369044303894, 0.1910066455602646, 0.19453516602516174, 0.1851169317960739, 0.18524152040481567, 0.18553943932056427, 0.18312595784664154, 0.19261077046394348], 'accuracy': [0.9639008641242981, 0.9663254022598267, 0.9714439511299133, 0.9754849076271057, 0.9784482717514038, 0.975215494632721, 0.9835668206214905, 0.9789870977401733, 0.983027994632721, 0.9819504022598267, 0.9800646305084229, 0.9854525923728943, 0.9873383641242981, 0.9870689511299133, 0.9841055870056152, 0.9851831793785095, 0.9870689511299133, 0.9841055870056152, 0.9876077771186829, 0.9865301847457886, 0.9765625, 0.9814116358757019, 0.9846444129943848, 0.9913793206214905, 0.9886853694915771, 0.9903017282485962, 0.9903017282485962, 0.9929956793785095, 0.985991358757019, 0.9870689511299133, 0.9741379022598267, 0.9765625, 0.9873383641242981, 0.9911099076271057, 0.985722005367279, 0.9886853694915771, 0.993534505367279, 0.990840494632721, 0.9835668206214905, 0.9924569129943848, 0.9929956793785095, 0.9911099076271057, 0.9913793206214905, 0.9932650923728943, 0.9927262663841248, 0.9911099076271057, 0.9959590435028076, 0.9911099076271057, 0.9929956793785095, 0.993534505367279, 0.9927262663841248, 0.9911099076271057, 0.993534505367279, 0.9932650923728943, 0.9819504022598267, 0.993534505367279, 0.990571141242981, 0.9929956793785095, 0.9978448152542114, 0.9924569129943848, 0.9956896305084229, 0.9967672228813171, 0.9900323152542114, 0.985991358757019, 0.9884159564971924, 0.993534505367279, 0.9913793206214905, 0.9897629022598267, 0.9959590435028076, 0.9903017282485962, 0.993534505367279, 0.9946120977401733, 0.9951508641242981, 0.9973060488700867, 0.9959590435028076, 0.9948814511299133, 0.990571141242981, 0.9892241358757019, 0.9943426847457886, 0.9967672228813171, 0.9964978694915771, 0.9962284564971924, 0.9962284564971924, 0.9967672228813171, 0.9921875, 0.9951508641242981, 0.9948814511299133, 0.9964978694915771, 0.9967672228813171, 0.9954202771186829, 0.9927262663841248, 0.9964978694915771, 0.9978448152542114, 0.9954202771186829, 0.9932650923728943, 0.9964978694915771, 0.9967672228813171, 0.9962284564971924, 0.998383641242981, 0.9943426847457886], 'val_loss': [0.9646047353744507, 0.9659414887428284, 0.9572007656097412, 0.9504392743110657, 0.946259081363678, 0.9461433291435242, 0.9193025231361389, 0.901196300983429, 0.8619368076324463, 0.852082371711731, 0.8154239654541016, 0.8072116374969482, 0.750813364982605, 0.6819618344306946, 0.7570796012878418, 0.6654502749443054, 0.6397951245307922, 0.6007367968559265, 0.7216067314147949, 0.6536611914634705, 0.6225370764732361, 0.6098859310150146, 0.666795015335083, 0.7019240260124207, 0.7120672464370728, 0.716257631778717, 0.7133215665817261, 0.7420595288276672, 0.771539568901062, 0.7810045480728149, 1.0621689558029175, 0.816439688205719, 0.7924307584762573, 0.8430569171905518, 0.803463339805603, 0.8095545768737793, 0.8025690317153931, 0.8183732032775879, 0.8689541816711426, 0.8141942024230957, 0.8272140026092529, 0.8401541113853455, 0.8410417437553406, 0.8300753235816956, 0.8326043486595154, 0.8228582739830017, 0.8333989381790161, 0.840634286403656, 0.9447042942047119, 0.853394627571106, 0.8807544708251953, 0.8589922189712524, 0.9045211672782898, 0.8768216371536255, 0.8930371403694153, 0.8625566959381104, 0.8746378421783447, 0.8786263465881348, 0.8959183692932129, 0.8718706965446472, 0.8911335468292236, 0.8923397660255432, 0.8888160586357117, 0.904495120048523, 0.8981316685676575, 0.9674897789955139, 0.8880648612976074, 0.8915621638298035, 0.9199779629707336, 1.048203468322754, 0.8905634880065918, 0.895169734954834, 0.8817972540855408, 0.9102318286895752, 0.9200332760810852, 0.9902812838554382, 1.0702050924301147, 0.9133657813072205, 0.912826657295227, 0.913343071937561, 0.8995633125305176, 0.9109318256378174, 0.8976056575775146, 0.9011164307594299, 1.0080461502075195, 0.9230529069900513, 0.8984023332595825, 0.9122636914253235, 0.8964022994041443, 0.922619640827179, 0.9039912223815918, 0.901329517364502, 0.9340704083442688, 0.981856644153595, 0.9418408870697021, 0.9242993593215942, 0.9105919003486633, 0.917207658290863, 0.9648982882499695, 0.9397873282432556], 'val_accuracy': [0.4903017282485962, 0.4913793206214905, 0.4989224076271057, 0.5043103694915771, 0.5075430870056152, 0.5086206793785095, 0.524784505367279, 0.5344827771186829, 0.5549569129943848, 0.5700430870056152, 0.6066810488700867, 0.6131465435028076, 0.6594827771186829, 0.7392241358757019, 0.6745689511299133, 0.7596982717514038, 0.7855603694915771, 0.8146551847457886, 0.7575430870056152, 0.8006465435028076, 0.8329741358757019, 0.8469827771186829, 0.8254310488700867, 0.8221982717514038, 0.8351293206214905, 0.8351293206214905, 0.8459051847457886, 0.8415948152542114, 0.8448275923728943, 0.8318965435028076, 0.764008641242981, 0.8308189511299133, 0.8426724076271057, 0.8254310488700867, 0.8469827771186829, 0.8426724076271057, 0.850215494632721, 0.8459051847457886, 0.8200430870056152, 0.8469827771186829, 0.8534482717514038, 0.8351293206214905, 0.8480603694915771, 0.8448275923728943, 0.8426724076271057, 0.850215494632721, 0.8415948152542114, 0.8459051847457886, 0.8071120977401733, 0.8329741358757019, 0.8254310488700867, 0.8459051847457886, 0.8221982717514038, 0.8351293206214905, 0.8221982717514038, 0.8415948152542114, 0.8329741358757019, 0.8383620977401733, 0.8340517282485962, 0.8394396305084229, 0.8405172228813171, 0.8351293206214905, 0.837284505367279, 0.8318965435028076, 0.8362069129943848, 0.806034505367279, 0.826508641242981, 0.829741358757019, 0.8286637663841248, 0.7909482717514038, 0.829741358757019, 0.8329741358757019, 0.8394396305084229, 0.837284505367279, 0.8340517282485962, 0.8103448152542114, 0.7920258641242981, 0.8275862336158752, 0.8232758641242981, 0.8318965435028076, 0.8308189511299133, 0.8329741358757019, 0.8308189511299133, 0.837284505367279, 0.8038793206214905, 0.8286637663841248, 0.8286637663841248, 0.8243534564971924, 0.8329741358757019, 0.8232758641242981, 0.8340517282485962, 0.8351293206214905, 0.8318965435028076, 0.8114224076271057, 0.826508641242981, 0.8318965435028076, 0.8340517282485962, 0.8308189511299133, 0.8254310488700867, 0.8275862336158752]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.3043 - accuracy: 0.9578"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 58ms/step - loss: 0.3043 - accuracy: 0.9578 - val_loss: 0.9529 - val_accuracy: 0.5090\n","Epoch 2/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2621 - accuracy: 0.9740 - val_loss: 0.9516 - val_accuracy: 0.5113\n","Epoch 3/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2671 - accuracy: 0.9740 - val_loss: 0.9518 - val_accuracy: 0.5124\n","Epoch 4/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.2551 - accuracy: 0.9785 - val_loss: 0.9417 - val_accuracy: 0.5192\n","Epoch 5/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2472 - accuracy: 0.9791 - val_loss: 0.9553 - val_accuracy: 0.5215\n","Epoch 6/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2600 - accuracy: 0.9726 - val_loss: 0.9327 - val_accuracy: 0.5305\n","Epoch 7/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2434 - accuracy: 0.9816 - val_loss: 0.9384 - val_accuracy: 0.5328\n","Epoch 8/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2398 - accuracy: 0.9847 - val_loss: 0.8971 - val_accuracy: 0.5509\n","Epoch 9/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2465 - accuracy: 0.9799 - val_loss: 0.8515 - val_accuracy: 0.5713\n","Epoch 10/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2483 - accuracy: 0.9796 - val_loss: 0.8197 - val_accuracy: 0.5984\n","Epoch 11/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2408 - accuracy: 0.9827 - val_loss: 0.8538 - val_accuracy: 0.5803\n","Epoch 12/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.2368 - accuracy: 0.9825 - val_loss: 0.8040 - val_accuracy: 0.6244\n","Epoch 13/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.2350 - accuracy: 0.9856 - val_loss: 0.7224 - val_accuracy: 0.6980\n","Epoch 14/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2405 - accuracy: 0.9830 - val_loss: 0.7224 - val_accuracy: 0.6946\n","Epoch 15/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2332 - accuracy: 0.9864 - val_loss: 0.7403 - val_accuracy: 0.6889\n","Epoch 16/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.2294 - accuracy: 0.9878 - val_loss: 0.7046 - val_accuracy: 0.7296\n","Epoch 17/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2327 - accuracy: 0.9850 - val_loss: 0.7700 - val_accuracy: 0.6980\n","Epoch 18/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2397 - accuracy: 0.9816 - val_loss: 0.6541 - val_accuracy: 0.7805\n","Epoch 19/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2272 - accuracy: 0.9895 - val_loss: 0.5977 - val_accuracy: 0.8258\n","Epoch 20/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2280 - accuracy: 0.9867 - val_loss: 0.6039 - val_accuracy: 0.8258\n","Epoch 21/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2221 - accuracy: 0.9907 - val_loss: 0.6860 - val_accuracy: 0.8066\n","Epoch 22/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.2193 - accuracy: 0.9904 - val_loss: 0.6168 - val_accuracy: 0.8348\n","Epoch 23/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2223 - accuracy: 0.9898 - val_loss: 0.7328 - val_accuracy: 0.8100\n","Epoch 24/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2248 - accuracy: 0.9870 - val_loss: 0.6538 - val_accuracy: 0.8371\n","Epoch 25/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2225 - accuracy: 0.9887 - val_loss: 0.6466 - val_accuracy: 0.8371\n","Epoch 26/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2261 - accuracy: 0.9890 - val_loss: 0.6574 - val_accuracy: 0.8416\n","Epoch 27/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2180 - accuracy: 0.9924 - val_loss: 0.6738 - val_accuracy: 0.8518\n","Epoch 28/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2157 - accuracy: 0.9909 - val_loss: 0.6956 - val_accuracy: 0.8462\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2302 - accuracy: 0.9833 - val_loss: 0.7191 - val_accuracy: 0.8382\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2251 - accuracy: 0.9864 - val_loss: 0.7425 - val_accuracy: 0.8405\n","Epoch 31/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2245 - accuracy: 0.9878 - val_loss: 0.7410 - val_accuracy: 0.8371\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2196 - accuracy: 0.9895 - val_loss: 0.7873 - val_accuracy: 0.8303\n","Epoch 33/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2114 - accuracy: 0.9935 - val_loss: 0.7729 - val_accuracy: 0.8224\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2120 - accuracy: 0.9907 - val_loss: 0.8627 - val_accuracy: 0.8326\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2208 - accuracy: 0.9898 - val_loss: 0.8909 - val_accuracy: 0.8190\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2180 - accuracy: 0.9881 - val_loss: 0.8809 - val_accuracy: 0.8190\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2311 - accuracy: 0.9813 - val_loss: 0.9410 - val_accuracy: 0.8179\n","Epoch 38/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2377 - accuracy: 0.9799 - val_loss: 0.7830 - val_accuracy: 0.8303\n","Epoch 39/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2162 - accuracy: 0.9890 - val_loss: 0.7925 - val_accuracy: 0.8224\n","Epoch 40/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2104 - accuracy: 0.9955 - val_loss: 0.8018 - val_accuracy: 0.8416\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2056 - accuracy: 0.9949 - val_loss: 0.8824 - val_accuracy: 0.8269\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2078 - accuracy: 0.9926 - val_loss: 0.8155 - val_accuracy: 0.8190\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2065 - accuracy: 0.9935 - val_loss: 0.8062 - val_accuracy: 0.8303\n","Epoch 44/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2092 - accuracy: 0.9943 - val_loss: 0.8726 - val_accuracy: 0.8213\n","Epoch 45/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2086 - accuracy: 0.9932 - val_loss: 0.8821 - val_accuracy: 0.8213\n","Epoch 46/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2076 - accuracy: 0.9924 - val_loss: 0.8041 - val_accuracy: 0.8416\n","Epoch 47/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2061 - accuracy: 0.9929 - val_loss: 0.8093 - val_accuracy: 0.8314\n","Epoch 48/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2029 - accuracy: 0.9955 - val_loss: 0.8411 - val_accuracy: 0.8314\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2063 - accuracy: 0.9926 - val_loss: 0.8294 - val_accuracy: 0.8371\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2018 - accuracy: 0.9952 - val_loss: 0.8344 - val_accuracy: 0.8258\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2104 - accuracy: 0.9915 - val_loss: 0.8367 - val_accuracy: 0.8167\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2000 - accuracy: 0.9958 - val_loss: 0.8515 - val_accuracy: 0.8360\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2003 - accuracy: 0.9958 - val_loss: 0.8629 - val_accuracy: 0.8213\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1989 - accuracy: 0.9963 - val_loss: 0.8313 - val_accuracy: 0.8303\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2105 - accuracy: 0.9907 - val_loss: 0.9184 - val_accuracy: 0.8201\n","Epoch 56/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2056 - accuracy: 0.9912 - val_loss: 0.9358 - val_accuracy: 0.8247\n","Epoch 57/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2127 - accuracy: 0.9904 - val_loss: 0.9325 - val_accuracy: 0.8201\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2052 - accuracy: 0.9918 - val_loss: 0.8699 - val_accuracy: 0.8235\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1978 - accuracy: 0.9955 - val_loss: 0.8985 - val_accuracy: 0.8201\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2045 - accuracy: 0.9924 - val_loss: 0.8711 - val_accuracy: 0.8088\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2226 - accuracy: 0.9842 - val_loss: 0.9745 - val_accuracy: 0.7919\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2038 - accuracy: 0.9926 - val_loss: 0.8509 - val_accuracy: 0.8303\n","Epoch 63/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1977 - accuracy: 0.9952 - val_loss: 0.9117 - val_accuracy: 0.8269\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2023 - accuracy: 0.9938 - val_loss: 0.8784 - val_accuracy: 0.8190\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1984 - accuracy: 0.9952 - val_loss: 1.0148 - val_accuracy: 0.8111\n","Epoch 66/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2055 - accuracy: 0.9909 - val_loss: 0.8684 - val_accuracy: 0.8247\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2005 - accuracy: 0.9941 - val_loss: 0.9518 - val_accuracy: 0.8145\n","Epoch 68/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1984 - accuracy: 0.9946 - val_loss: 0.8621 - val_accuracy: 0.8269\n","Epoch 69/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1973 - accuracy: 0.9949 - val_loss: 0.8769 - val_accuracy: 0.8201\n","Epoch 70/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.1949 - accuracy: 0.9966 - val_loss: 0.8910 - val_accuracy: 0.8258\n","Epoch 71/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.1949 - accuracy: 0.9966 - val_loss: 0.8973 - val_accuracy: 0.8111\n","Epoch 72/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1902 - accuracy: 0.9986 - val_loss: 0.8920 - val_accuracy: 0.8201\n","Epoch 73/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1906 - accuracy: 0.9969 - val_loss: 0.8825 - val_accuracy: 0.8213\n","Epoch 74/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1918 - accuracy: 0.9969 - val_loss: 0.8936 - val_accuracy: 0.8201\n","Epoch 75/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.1943 - accuracy: 0.9958 - val_loss: 0.9325 - val_accuracy: 0.8224\n","Epoch 76/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2097 - accuracy: 0.9881 - val_loss: 1.1700 - val_accuracy: 0.7907\n","Epoch 77/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2087 - accuracy: 0.9892 - val_loss: 1.0622 - val_accuracy: 0.8088\n","Epoch 78/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2000 - accuracy: 0.9921 - val_loss: 0.9094 - val_accuracy: 0.8156\n","Epoch 79/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1901 - accuracy: 0.9972 - val_loss: 0.8947 - val_accuracy: 0.8292\n","Epoch 80/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1884 - accuracy: 0.9975 - val_loss: 0.8848 - val_accuracy: 0.8167\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1907 - accuracy: 0.9966 - val_loss: 0.9126 - val_accuracy: 0.8235\n","Epoch 82/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.1872 - accuracy: 0.9977 - val_loss: 0.9137 - val_accuracy: 0.8100\n","Epoch 83/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1879 - accuracy: 0.9975 - val_loss: 0.9948 - val_accuracy: 0.8190\n","Epoch 84/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1953 - accuracy: 0.9955 - val_loss: 0.9195 - val_accuracy: 0.8190\n","Epoch 85/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1905 - accuracy: 0.9955 - val_loss: 1.0001 - val_accuracy: 0.8066\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1892 - accuracy: 0.9966 - val_loss: 0.9245 - val_accuracy: 0.8213\n","Epoch 87/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1911 - accuracy: 0.9952 - val_loss: 1.0480 - val_accuracy: 0.8077\n","Epoch 88/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1991 - accuracy: 0.9921 - val_loss: 0.9673 - val_accuracy: 0.8111\n","Epoch 89/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1861 - accuracy: 0.9986 - val_loss: 0.9815 - val_accuracy: 0.8088\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1909 - accuracy: 0.9946 - val_loss: 0.9931 - val_accuracy: 0.8145\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1976 - accuracy: 0.9921 - val_loss: 0.9679 - val_accuracy: 0.8077\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1935 - accuracy: 0.9946 - val_loss: 0.9685 - val_accuracy: 0.7986\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1848 - accuracy: 0.9975 - val_loss: 0.9290 - val_accuracy: 0.8111\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1887 - accuracy: 0.9969 - val_loss: 0.9758 - val_accuracy: 0.8190\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1835 - accuracy: 0.9977 - val_loss: 0.9372 - val_accuracy: 0.8111\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1854 - accuracy: 0.9960 - val_loss: 1.0406 - val_accuracy: 0.8111\n","Epoch 97/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1841 - accuracy: 0.9966 - val_loss: 1.0415 - val_accuracy: 0.8088\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1844 - accuracy: 0.9960 - val_loss: 0.9274 - val_accuracy: 0.8133\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1811 - accuracy: 0.9983 - val_loss: 0.9536 - val_accuracy: 0.8201\n","Epoch 100/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1928 - accuracy: 0.9926 - val_loss: 0.9966 - val_accuracy: 0.7896\n","{'loss': [0.3042895197868347, 0.26205483078956604, 0.26712846755981445, 0.25507256388664246, 0.24718670547008514, 0.2600348889827728, 0.2434394359588623, 0.2398374229669571, 0.24654968082904816, 0.24833467602729797, 0.24082763493061066, 0.2367647886276245, 0.23499912023544312, 0.240506112575531, 0.23318180441856384, 0.22936977446079254, 0.23271694779396057, 0.2397444248199463, 0.22724120318889618, 0.22799943387508392, 0.22214102745056152, 0.21926091611385345, 0.2223188877105713, 0.22477969527244568, 0.22246316075325012, 0.22614087164402008, 0.2179524302482605, 0.21567630767822266, 0.23022893071174622, 0.225136399269104, 0.22449153661727905, 0.21956612169742584, 0.21140004694461823, 0.21203793585300446, 0.22078190743923187, 0.21795697510242462, 0.23106810450553894, 0.23766256868839264, 0.2161649912595749, 0.2103911191225052, 0.20562070608139038, 0.20776261389255524, 0.2064976543188095, 0.20920442044734955, 0.20857670903205872, 0.207570880651474, 0.2060675024986267, 0.20290330052375793, 0.2062799036502838, 0.201799675822258, 0.2103947103023529, 0.20000268518924713, 0.20034858584403992, 0.19889692962169647, 0.2104995846748352, 0.2056361734867096, 0.21265476942062378, 0.20521517097949982, 0.1977812945842743, 0.2045026570558548, 0.22256717085838318, 0.2038293033838272, 0.19771108031272888, 0.20229919254779816, 0.1983530968427658, 0.20550338923931122, 0.2004651129245758, 0.19841235876083374, 0.1972988247871399, 0.19491052627563477, 0.19491493701934814, 0.19018711149692535, 0.19062522053718567, 0.19178831577301025, 0.19427579641342163, 0.20967261493206024, 0.20869801938533783, 0.19999481737613678, 0.19009028375148773, 0.18836286664009094, 0.19066046178340912, 0.18724192678928375, 0.1879255324602127, 0.1953199952840805, 0.19049996137619019, 0.18922767043113708, 0.1911490112543106, 0.1990659236907959, 0.18612371385097504, 0.19092021882534027, 0.19756671786308289, 0.19346438348293304, 0.18479077517986298, 0.18873929977416992, 0.18348592519760132, 0.18539343774318695, 0.18405908346176147, 0.18443745374679565, 0.1811394840478897, 0.1928260177373886], 'accuracy': [0.9578381180763245, 0.9739671945571899, 0.9739671945571899, 0.9784946441650391, 0.9790605306625366, 0.9725523591041565, 0.9816072583198547, 0.9847198724746704, 0.9799094796180725, 0.979626476764679, 0.9827390909194946, 0.9824561476707458, 0.9855687618255615, 0.9830220937728882, 0.9864176511764526, 0.9878324866294861, 0.9850028157234192, 0.9816072583198547, 0.9895302653312683, 0.9867005944252014, 0.990662157535553, 0.9903791546821594, 0.9898132681846619, 0.986983597278595, 0.9886813759803772, 0.988964319229126, 0.9923599362373352, 0.9909451007843018, 0.983305037021637, 0.9864176511764526, 0.9878324866294861, 0.9895302653312683, 0.9934917688369751, 0.990662157535553, 0.9898132681846619, 0.9881154298782349, 0.9813242554664612, 0.9799094796180725, 0.988964319229126, 0.9954725503921509, 0.9949066042900085, 0.992642879486084, 0.9934917688369751, 0.994340717792511, 0.9932088255882263, 0.9923599362373352, 0.9929258823394775, 0.9954725503921509, 0.992642879486084, 0.9951896071434021, 0.9915110468864441, 0.9957554936408997, 0.9957554936408997, 0.996321439743042, 0.990662157535553, 0.9912280440330505, 0.9903791546821594, 0.9917939901351929, 0.9954725503921509, 0.9923599362373352, 0.9841539263725281, 0.992642879486084, 0.9951896071434021, 0.9937747716903687, 0.9951896071434021, 0.9909451007843018, 0.9940577149391174, 0.9946236610412598, 0.9949066042900085, 0.9966044425964355, 0.9966044425964355, 0.9985851645469666, 0.9968873858451843, 0.9968873858451843, 0.9957554936408997, 0.9881154298782349, 0.9892473220825195, 0.9920769929885864, 0.9971703290939331, 0.9974533319473267, 0.9966044425964355, 0.9977362751960754, 0.9974533319473267, 0.9954725503921509, 0.9954725503921509, 0.9966044425964355, 0.9951896071434021, 0.9920769929885864, 0.9985851645469666, 0.9946236610412598, 0.9920769929885864, 0.9946236610412598, 0.9974533319473267, 0.9968873858451843, 0.9977362751960754, 0.9960384964942932, 0.9966044425964355, 0.9960384964942932, 0.9983022212982178, 0.992642879486084], 'val_loss': [0.9528851509094238, 0.9516130089759827, 0.9518136382102966, 0.9417038559913635, 0.9552885293960571, 0.9326979517936707, 0.9383912086486816, 0.8970707058906555, 0.8515079617500305, 0.8196950554847717, 0.8538368940353394, 0.804004430770874, 0.7223631143569946, 0.7223924994468689, 0.7402750849723816, 0.7046433687210083, 0.7699738144874573, 0.6540558934211731, 0.5977485179901123, 0.6038573980331421, 0.6860394477844238, 0.6167569160461426, 0.7328099012374878, 0.6538243889808655, 0.6466462016105652, 0.6574316024780273, 0.673800528049469, 0.6955706477165222, 0.7191345691680908, 0.7425041198730469, 0.7409505248069763, 0.7872991561889648, 0.7729395627975464, 0.8626835346221924, 0.8908600211143494, 0.8808794021606445, 0.9409778118133545, 0.782961905002594, 0.7924685478210449, 0.8017756938934326, 0.8823984861373901, 0.8155465722084045, 0.8062379360198975, 0.8726435303688049, 0.8820980191230774, 0.8040648698806763, 0.8092523813247681, 0.8410539627075195, 0.8294216394424438, 0.8344283103942871, 0.8367002606391907, 0.8515363931655884, 0.8629447817802429, 0.8313389420509338, 0.9184069037437439, 0.9357848763465881, 0.9325335621833801, 0.8699418306350708, 0.8984753489494324, 0.8711262941360474, 0.9745074510574341, 0.8509196043014526, 0.9117458462715149, 0.8783935904502869, 1.014773964881897, 0.868395209312439, 0.9517751336097717, 0.8621038198471069, 0.8769380450248718, 0.890969455242157, 0.8973132967948914, 0.8920180201530457, 0.8825047016143799, 0.8936436176300049, 0.9325060248374939, 1.16999089717865, 1.0622293949127197, 0.9093524217605591, 0.8947029709815979, 0.8847832083702087, 0.9125649333000183, 0.9136763215065002, 0.9948421716690063, 0.9194588661193848, 1.0000895261764526, 0.924473762512207, 1.0479681491851807, 0.9672549366950989, 0.9815158843994141, 0.9931309223175049, 0.9679356217384338, 0.9684733152389526, 0.9290301203727722, 0.9757575988769531, 0.9372182488441467, 1.0405505895614624, 1.0414835214614868, 0.927371084690094, 0.953586757183075, 0.9965635538101196], 'val_accuracy': [0.5090497732162476, 0.5113122463226318, 0.5124434232711792, 0.5192307829856873, 0.5214931964874268, 0.5305429697036743, 0.5328054428100586, 0.5509049892425537, 0.5712669491767883, 0.598416268825531, 0.5803167223930359, 0.6244344115257263, 0.6979637742042542, 0.6945701241493225, 0.6889140009880066, 0.7296379804611206, 0.6979637742042542, 0.7805429697036743, 0.8257918357849121, 0.8257918357849121, 0.8065611124038696, 0.8348416090011597, 0.8099547624588013, 0.837104082107544, 0.837104082107544, 0.8416289687156677, 0.8518099784851074, 0.8461538553237915, 0.8382353186607361, 0.8404977321624756, 0.837104082107544, 0.8303167223930359, 0.8223981857299805, 0.8325791954994202, 0.8190045356750488, 0.8190045356750488, 0.8178732991218567, 0.8303167223930359, 0.8223981857299805, 0.8416289687156677, 0.8269230723381042, 0.8190045356750488, 0.8303167223930359, 0.8212669491767883, 0.8212669491767883, 0.8416289687156677, 0.831447958946228, 0.831447958946228, 0.837104082107544, 0.8257918357849121, 0.8167420625686646, 0.8359728455543518, 0.8212669491767883, 0.8303167223930359, 0.820135772228241, 0.8246606588363647, 0.820135772228241, 0.8235294222831726, 0.820135772228241, 0.8088235259056091, 0.7918552160263062, 0.8303167223930359, 0.8269230723381042, 0.8190045356750488, 0.8110859990119934, 0.8246606588363647, 0.814479649066925, 0.8269230723381042, 0.820135772228241, 0.8257918357849121, 0.8110859990119934, 0.820135772228241, 0.8212669491767883, 0.820135772228241, 0.8223981857299805, 0.790723979473114, 0.8088235259056091, 0.8156108856201172, 0.8291855454444885, 0.8167420625686646, 0.8235294222831726, 0.8099547624588013, 0.8190045356750488, 0.8190045356750488, 0.8065611124038696, 0.8212669491767883, 0.807692289352417, 0.8110859990119934, 0.8088235259056091, 0.814479649066925, 0.807692289352417, 0.7986425161361694, 0.8110859990119934, 0.8190045356750488, 0.8110859990119934, 0.8110859990119934, 0.8088235259056091, 0.8133484125137329, 0.820135772228241, 0.7895927429199219]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.3787 - accuracy: 0.9436"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 60ms/step - loss: 0.3779 - accuracy: 0.9434 - val_loss: 0.9793 - val_accuracy: 0.4938\n","Epoch 2/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3165 - accuracy: 0.9581 - val_loss: 0.9712 - val_accuracy: 0.4979\n","Epoch 3/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2916 - accuracy: 0.9643 - val_loss: 0.9830 - val_accuracy: 0.4979\n","Epoch 4/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.2886 - accuracy: 0.9656 - val_loss: 0.9660 - val_accuracy: 0.5041\n","Epoch 5/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.2814 - accuracy: 0.9669 - val_loss: 0.9647 - val_accuracy: 0.5072\n","Epoch 6/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2667 - accuracy: 0.9716 - val_loss: 0.9367 - val_accuracy: 0.5207\n","Epoch 7/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2739 - accuracy: 0.9690 - val_loss: 0.9367 - val_accuracy: 0.5227\n","Epoch 8/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2656 - accuracy: 0.9718 - val_loss: 0.9414 - val_accuracy: 0.5331\n","Epoch 9/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2767 - accuracy: 0.9638 - val_loss: 0.9307 - val_accuracy: 0.5393\n","Epoch 10/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2637 - accuracy: 0.9742 - val_loss: 0.9126 - val_accuracy: 0.5486\n","Epoch 11/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2624 - accuracy: 0.9703 - val_loss: 0.9248 - val_accuracy: 0.5548\n","Epoch 12/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2948 - accuracy: 0.9563 - val_loss: 0.8648 - val_accuracy: 0.5857\n","Epoch 13/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2540 - accuracy: 0.9778 - val_loss: 0.7577 - val_accuracy: 0.7025\n","Epoch 14/100\n","31/31 [==============================] - 2s 50ms/step - loss: 0.2477 - accuracy: 0.9811 - val_loss: 0.7557 - val_accuracy: 0.7138\n","Epoch 15/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2449 - accuracy: 0.9819 - val_loss: 0.7503 - val_accuracy: 0.7262\n","Epoch 16/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2424 - accuracy: 0.9822 - val_loss: 0.7165 - val_accuracy: 0.7769\n","Epoch 17/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2589 - accuracy: 0.9736 - val_loss: 0.7526 - val_accuracy: 0.7541\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2452 - accuracy: 0.9806 - val_loss: 0.7606 - val_accuracy: 0.7665\n","Epoch 19/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2353 - accuracy: 0.9853 - val_loss: 0.8043 - val_accuracy: 0.7583\n","Epoch 20/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.2381 - accuracy: 0.9829 - val_loss: 0.8009 - val_accuracy: 0.7779\n","Epoch 21/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2344 - accuracy: 0.9840 - val_loss: 0.8512 - val_accuracy: 0.7696\n","Epoch 22/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2401 - accuracy: 0.9814 - val_loss: 0.8892 - val_accuracy: 0.7758\n","Epoch 23/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.2368 - accuracy: 0.9837 - val_loss: 0.8822 - val_accuracy: 0.7965\n","Epoch 24/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.2372 - accuracy: 0.9827 - val_loss: 0.8991 - val_accuracy: 0.8099\n","Epoch 25/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2284 - accuracy: 0.9871 - val_loss: 0.9485 - val_accuracy: 0.8099\n","Epoch 26/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.2299 - accuracy: 0.9840 - val_loss: 0.9472 - val_accuracy: 0.8192\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2358 - accuracy: 0.9835 - val_loss: 0.9678 - val_accuracy: 0.8130\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2277 - accuracy: 0.9866 - val_loss: 1.0711 - val_accuracy: 0.7769\n","Epoch 29/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2488 - accuracy: 0.9757 - val_loss: 1.0915 - val_accuracy: 0.7986\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2482 - accuracy: 0.9762 - val_loss: 1.1086 - val_accuracy: 0.7872\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2798 - accuracy: 0.9674 - val_loss: 1.0471 - val_accuracy: 0.7924\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2417 - accuracy: 0.9798 - val_loss: 1.1518 - val_accuracy: 0.7686\n","Epoch 33/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2395 - accuracy: 0.9829 - val_loss: 1.0440 - val_accuracy: 0.8110\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2305 - accuracy: 0.9858 - val_loss: 1.0679 - val_accuracy: 0.8048\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2308 - accuracy: 0.9842 - val_loss: 1.0851 - val_accuracy: 0.8006\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2267 - accuracy: 0.9860 - val_loss: 1.0704 - val_accuracy: 0.8027\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2216 - accuracy: 0.9894 - val_loss: 1.0496 - val_accuracy: 0.8099\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2258 - accuracy: 0.9866 - val_loss: 1.0979 - val_accuracy: 0.7944\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2225 - accuracy: 0.9902 - val_loss: 1.1066 - val_accuracy: 0.8079\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2257 - accuracy: 0.9866 - val_loss: 1.1285 - val_accuracy: 0.8048\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2223 - accuracy: 0.9899 - val_loss: 1.1047 - val_accuracy: 0.8058\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2277 - accuracy: 0.9858 - val_loss: 1.0811 - val_accuracy: 0.8089\n","Epoch 43/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2304 - accuracy: 0.9850 - val_loss: 1.2523 - val_accuracy: 0.7521\n","Epoch 44/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2449 - accuracy: 0.9767 - val_loss: 1.1053 - val_accuracy: 0.7975\n","Epoch 45/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2202 - accuracy: 0.9899 - val_loss: 1.0809 - val_accuracy: 0.8027\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2268 - accuracy: 0.9858 - val_loss: 1.0892 - val_accuracy: 0.8048\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2151 - accuracy: 0.9894 - val_loss: 1.0802 - val_accuracy: 0.8006\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2140 - accuracy: 0.9920 - val_loss: 1.1191 - val_accuracy: 0.7965\n","Epoch 49/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2183 - accuracy: 0.9886 - val_loss: 1.1817 - val_accuracy: 0.7831\n","Epoch 50/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2166 - accuracy: 0.9894 - val_loss: 1.1251 - val_accuracy: 0.7986\n","Epoch 51/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2227 - accuracy: 0.9842 - val_loss: 1.1184 - val_accuracy: 0.8058\n","Epoch 52/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2230 - accuracy: 0.9858 - val_loss: 1.1544 - val_accuracy: 0.7975\n","Epoch 53/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2206 - accuracy: 0.9873 - val_loss: 1.1721 - val_accuracy: 0.7955\n","Epoch 54/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2106 - accuracy: 0.9920 - val_loss: 1.1324 - val_accuracy: 0.7955\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2155 - accuracy: 0.9886 - val_loss: 1.1077 - val_accuracy: 0.8017\n","Epoch 56/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2154 - accuracy: 0.9897 - val_loss: 1.1470 - val_accuracy: 0.7934\n","Epoch 57/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2107 - accuracy: 0.9925 - val_loss: 1.1874 - val_accuracy: 0.8027\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2073 - accuracy: 0.9922 - val_loss: 1.1820 - val_accuracy: 0.8027\n","Epoch 59/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2139 - accuracy: 0.9891 - val_loss: 1.2221 - val_accuracy: 0.7789\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2276 - accuracy: 0.9811 - val_loss: 1.1231 - val_accuracy: 0.8089\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2248 - accuracy: 0.9827 - val_loss: 1.1851 - val_accuracy: 0.7975\n","Epoch 62/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2198 - accuracy: 0.9868 - val_loss: 1.2650 - val_accuracy: 0.7789\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2326 - accuracy: 0.9806 - val_loss: 1.2307 - val_accuracy: 0.7841\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2075 - accuracy: 0.9933 - val_loss: 1.1404 - val_accuracy: 0.8017\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2076 - accuracy: 0.9935 - val_loss: 1.1719 - val_accuracy: 0.7872\n","Epoch 66/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2161 - accuracy: 0.9886 - val_loss: 1.1682 - val_accuracy: 0.7975\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2499 - accuracy: 0.9832 - val_loss: 1.1852 - val_accuracy: 0.7851\n","Epoch 68/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2173 - accuracy: 0.9894 - val_loss: 1.1808 - val_accuracy: 0.7924\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2248 - accuracy: 0.9840 - val_loss: 1.2895 - val_accuracy: 0.7707\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2312 - accuracy: 0.9809 - val_loss: 1.1797 - val_accuracy: 0.7841\n","Epoch 71/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2093 - accuracy: 0.9922 - val_loss: 1.1909 - val_accuracy: 0.7738\n","Epoch 72/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2067 - accuracy: 0.9920 - val_loss: 1.1422 - val_accuracy: 0.8058\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2024 - accuracy: 0.9951 - val_loss: 1.1642 - val_accuracy: 0.7893\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2041 - accuracy: 0.9928 - val_loss: 1.1460 - val_accuracy: 0.7882\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2046 - accuracy: 0.9917 - val_loss: 1.1758 - val_accuracy: 0.7913\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2072 - accuracy: 0.9935 - val_loss: 1.1900 - val_accuracy: 0.7944\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2037 - accuracy: 0.9925 - val_loss: 1.1731 - val_accuracy: 0.8017\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2065 - accuracy: 0.9899 - val_loss: 1.2430 - val_accuracy: 0.7707\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2005 - accuracy: 0.9941 - val_loss: 1.1871 - val_accuracy: 0.8037\n","Epoch 80/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2019 - accuracy: 0.9930 - val_loss: 1.1709 - val_accuracy: 0.7975\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1998 - accuracy: 0.9925 - val_loss: 1.1607 - val_accuracy: 0.7934\n","Epoch 82/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1964 - accuracy: 0.9953 - val_loss: 1.1795 - val_accuracy: 0.7955\n","Epoch 83/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1945 - accuracy: 0.9959 - val_loss: 1.2179 - val_accuracy: 0.7903\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1998 - accuracy: 0.9938 - val_loss: 1.1793 - val_accuracy: 0.8058\n","Epoch 85/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1961 - accuracy: 0.9956 - val_loss: 1.1694 - val_accuracy: 0.7965\n","Epoch 86/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1945 - accuracy: 0.9964 - val_loss: 1.2411 - val_accuracy: 0.7831\n","Epoch 87/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1988 - accuracy: 0.9941 - val_loss: 1.2546 - val_accuracy: 0.7882\n","Epoch 88/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1957 - accuracy: 0.9946 - val_loss: 1.2152 - val_accuracy: 0.7872\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1956 - accuracy: 0.9941 - val_loss: 1.2201 - val_accuracy: 0.7851\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1985 - accuracy: 0.9938 - val_loss: 1.2349 - val_accuracy: 0.7872\n","Epoch 91/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1960 - accuracy: 0.9943 - val_loss: 1.2096 - val_accuracy: 0.7882\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1959 - accuracy: 0.9943 - val_loss: 1.1980 - val_accuracy: 0.7986\n","Epoch 93/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1961 - accuracy: 0.9935 - val_loss: 1.2269 - val_accuracy: 0.7851\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1953 - accuracy: 0.9953 - val_loss: 1.2078 - val_accuracy: 0.7975\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2006 - accuracy: 0.9930 - val_loss: 1.2579 - val_accuracy: 0.7944\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1929 - accuracy: 0.9946 - val_loss: 1.1940 - val_accuracy: 0.7986\n","Epoch 97/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1994 - accuracy: 0.9928 - val_loss: 1.2275 - val_accuracy: 0.8006\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1951 - accuracy: 0.9941 - val_loss: 1.2478 - val_accuracy: 0.7934\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1941 - accuracy: 0.9933 - val_loss: 1.2391 - val_accuracy: 0.7965\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1987 - accuracy: 0.9948 - val_loss: 1.2625 - val_accuracy: 0.7882\n","{'loss': [0.3778964877128601, 0.3165431022644043, 0.29156720638275146, 0.28862425684928894, 0.2813616693019867, 0.26672327518463135, 0.27390846610069275, 0.2655777931213379, 0.2767285704612732, 0.26367419958114624, 0.26242321729660034, 0.29477226734161377, 0.2539786100387573, 0.2477445900440216, 0.24494211375713348, 0.242421954870224, 0.2589115500450134, 0.24517469108104706, 0.23525531589984894, 0.2381359487771988, 0.23435761034488678, 0.24012070894241333, 0.23677566647529602, 0.23722907900810242, 0.22840695083141327, 0.22987045347690582, 0.2358330637216568, 0.22770921885967255, 0.24879202246665955, 0.2481653243303299, 0.2797744870185852, 0.24166634678840637, 0.23950840532779694, 0.2305063009262085, 0.23083195090293884, 0.2267407476902008, 0.22161714732646942, 0.22584716975688934, 0.22248560190200806, 0.22566485404968262, 0.22233177721500397, 0.22768759727478027, 0.23040880262851715, 0.24487189948558807, 0.22022950649261475, 0.22678197920322418, 0.21513399481773376, 0.2140149474143982, 0.21831822395324707, 0.21661487221717834, 0.22266750037670135, 0.22299724817276, 0.22061412036418915, 0.2106371968984604, 0.2154904007911682, 0.2154259830713272, 0.21073110401630402, 0.20734961330890656, 0.21387360990047455, 0.22760942578315735, 0.22479958832263947, 0.21982085704803467, 0.2325584441423416, 0.20745351910591125, 0.20761722326278687, 0.21614034473896027, 0.24991679191589355, 0.2173091471195221, 0.22475461661815643, 0.23121874034404755, 0.20931337773799896, 0.20673619210720062, 0.20244541764259338, 0.20406579971313477, 0.2045944482088089, 0.2071995884180069, 0.20366396009922028, 0.20652547478675842, 0.20053187012672424, 0.20189251005649567, 0.19983527064323425, 0.19636285305023193, 0.19447341561317444, 0.19980467855930328, 0.19606950879096985, 0.19449879229068756, 0.19875727593898773, 0.19570542871952057, 0.1956004649400711, 0.19852466881275177, 0.19602030515670776, 0.19594500958919525, 0.19606149196624756, 0.1952725648880005, 0.2005588859319687, 0.19293729960918427, 0.1993575543165207, 0.19508542120456696, 0.19405105710029602, 0.19874270260334015], 'accuracy': [0.9434108734130859, 0.9581395387649536, 0.9643411040306091, 0.9656330943107605, 0.9669250845909119, 0.9715762138366699, 0.9689922332763672, 0.9718345999717712, 0.9638242721557617, 0.9741601943969727, 0.9702842235565186, 0.9563307762145996, 0.9777777791023254, 0.9811369776725769, 0.9819121360778809, 0.9821705222129822, 0.97364342212677, 0.9806201457977295, 0.9852713346481323, 0.9829457402229309, 0.983979344367981, 0.9813953638076782, 0.9837209582328796, 0.9826873540878296, 0.9870800971984863, 0.983979344367981, 0.9834625124931335, 0.9865633249282837, 0.9757105708122253, 0.9762274026870728, 0.9674418568611145, 0.9798449873924255, 0.9829457402229309, 0.985788106918335, 0.9842377305030823, 0.9860464930534363, 0.9894056916236877, 0.9865633249282837, 0.9901808500289917, 0.9865633249282837, 0.9899224638938904, 0.985788106918335, 0.985012948513031, 0.9767441749572754, 0.9899224638938904, 0.985788106918335, 0.9894056916236877, 0.9919896721839905, 0.988630473613739, 0.9894056916236877, 0.9842377305030823, 0.985788106918335, 0.9873384833335876, 0.9919896721839905, 0.988630473613739, 0.9896640777587891, 0.9925064444541931, 0.9922480583190918, 0.9891473054885864, 0.9811369776725769, 0.9826873540878296, 0.986821711063385, 0.9806201457977295, 0.9932816624641418, 0.9935400485992432, 0.988630473613739, 0.9832041263580322, 0.9894056916236877, 0.983979344367981, 0.9808785319328308, 0.9922480583190918, 0.9919896721839905, 0.9950904250144958, 0.9927648305892944, 0.9917312860488892, 0.9935400485992432, 0.9925064444541931, 0.9899224638938904, 0.9940568208694458, 0.9930232763290405, 0.9925064444541931, 0.9953488111495972, 0.9958656430244446, 0.9937984347343445, 0.9956072568893433, 0.9963824152946472, 0.9940568208694458, 0.9945736527442932, 0.9940568208694458, 0.9937984347343445, 0.9943152666091919, 0.9943152666091919, 0.9935400485992432, 0.9953488111495972, 0.9930232763290405, 0.9945736527442932, 0.9927648305892944, 0.9940568208694458, 0.9932816624641418, 0.9948320388793945], 'val_loss': [0.9792969822883606, 0.9712434411048889, 0.9829773306846619, 0.9660432934761047, 0.9647102952003479, 0.9366756677627563, 0.9367433190345764, 0.9414300918579102, 0.9306583404541016, 0.9126115441322327, 0.9247612357139587, 0.8648259043693542, 0.7576941251754761, 0.755703866481781, 0.7503348588943481, 0.7165116667747498, 0.7525762915611267, 0.7605925798416138, 0.8043464422225952, 0.8008878231048584, 0.8512376546859741, 0.8891878128051758, 0.8822280168533325, 0.8991141319274902, 0.9484859704971313, 0.9471925497055054, 0.9677980542182922, 1.0711050033569336, 1.0915354490280151, 1.108573079109192, 1.0470693111419678, 1.1517740488052368, 1.0440294742584229, 1.0678585767745972, 1.0851396322250366, 1.0704350471496582, 1.0496302843093872, 1.0979206562042236, 1.1065645217895508, 1.1284809112548828, 1.104724407196045, 1.081050157546997, 1.252267599105835, 1.1053211688995361, 1.080883502960205, 1.089238166809082, 1.0802260637283325, 1.1190989017486572, 1.1816582679748535, 1.1251283884048462, 1.118353009223938, 1.154419183731079, 1.1721103191375732, 1.1323573589324951, 1.1077277660369873, 1.1470009088516235, 1.1874405145645142, 1.181967854499817, 1.2220550775527954, 1.1230907440185547, 1.185096025466919, 1.264994502067566, 1.2307062149047852, 1.1403801441192627, 1.171887993812561, 1.1681574583053589, 1.1851967573165894, 1.180779218673706, 1.2894526720046997, 1.17969810962677, 1.1908714771270752, 1.1422019004821777, 1.1641907691955566, 1.1460397243499756, 1.1757837533950806, 1.1900321245193481, 1.1730906963348389, 1.2430394887924194, 1.187148094177246, 1.1708548069000244, 1.1607391834259033, 1.179498314857483, 1.2179368734359741, 1.1793322563171387, 1.1694048643112183, 1.241119384765625, 1.254593014717102, 1.2151697874069214, 1.220056414604187, 1.2348625659942627, 1.2095903158187866, 1.197978138923645, 1.2268508672714233, 1.2078295946121216, 1.2579439878463745, 1.1940391063690186, 1.2275277376174927, 1.2477734088897705, 1.2390507459640503, 1.26252019405365], 'val_accuracy': [0.49380165338516235, 0.49793389439582825, 0.49793389439582825, 0.5041322112083435, 0.5072314143180847, 0.5206611752510071, 0.5227272510528564, 0.5330578684806824, 0.53925621509552, 0.5485537052154541, 0.5547520518302917, 0.58574378490448, 0.702479362487793, 0.7138429880142212, 0.7262396812438965, 0.7768595218658447, 0.7541322112083435, 0.7665289044380188, 0.7582644820213318, 0.7778925895690918, 0.76962810754776, 0.7758264541625977, 0.7964876294136047, 0.8099173307418823, 0.8099173307418823, 0.8192148804664612, 0.8130165338516235, 0.7768595218658447, 0.7985537052154541, 0.7871900796890259, 0.7923553586006165, 0.7685950398445129, 0.8109503984451294, 0.8047520518302917, 0.8006198406219482, 0.8026859760284424, 0.8099173307418823, 0.7944214940071106, 0.807851254940033, 0.8047520518302917, 0.8057851195335388, 0.80888432264328, 0.7520661354064941, 0.797520637512207, 0.8026859760284424, 0.8047520518302917, 0.8006198406219482, 0.7964876294136047, 0.7830578684806824, 0.7985537052154541, 0.8057851195335388, 0.797520637512207, 0.7954545617103577, 0.7954545617103577, 0.8016529083251953, 0.7933884263038635, 0.8026859760284424, 0.8026859760284424, 0.7789255976676941, 0.80888432264328, 0.797520637512207, 0.7789255976676941, 0.7840909361839294, 0.8016529083251953, 0.7871900796890259, 0.797520637512207, 0.7851239442825317, 0.7923553586006165, 0.7706611752510071, 0.7840909361839294, 0.7737603187561035, 0.8057851195335388, 0.78925621509552, 0.788223147392273, 0.7913222908973694, 0.7944214940071106, 0.8016529083251953, 0.7706611752510071, 0.8037189841270447, 0.797520637512207, 0.7933884263038635, 0.7954545617103577, 0.7902892827987671, 0.8057851195335388, 0.7964876294136047, 0.7830578684806824, 0.788223147392273, 0.7871900796890259, 0.7851239442825317, 0.7871900796890259, 0.788223147392273, 0.7985537052154541, 0.7851239442825317, 0.797520637512207, 0.7944214940071106, 0.7985537052154541, 0.8006198406219482, 0.7933884263038635, 0.7964876294136047, 0.788223147392273]}\n","32/32 [==============================] - 1s 5ms/step\n"]}]},{"cell_type":"code","source":["metrics_df_gru"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"id":"TzotHT30DBVI","executionInfo":{"status":"ok","timestamp":1717436211541,"user_tz":-360,"elapsed":10,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"50b3b797-70e5-4a0a-c580-0fcd44fab84f"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision    Recall        F1  Sensitivity  Specificity  \\\n","0        0  0.543551   0.542763  0.552764  0.547718     0.552764     0.534338   \n","1        1  0.540960   0.532294  0.675141  0.595268     0.675141     0.406780   \n","2        2  0.576305   0.572519  0.602410  0.587084     0.602410     0.550201   \n","3        0  0.587940   0.607362  0.497487  0.546961     0.497487     0.678392   \n","4        1  0.629237   0.614518  0.693503  0.651626     0.693503     0.564972   \n","5        2  0.652610   0.644487  0.680723  0.662109     0.680723     0.624498   \n","6        0  0.687605   0.721344  0.611390  0.661831     0.611390     0.763819   \n","7        1  0.706921   0.715125  0.687853  0.701224     0.687853     0.725989   \n","8        2  0.739960   0.721707  0.781124  0.750241     0.781124     0.698795   \n","9        0  0.749581   0.744262  0.760469  0.752278     0.760469     0.738693   \n","10       1  0.754944   0.715651  0.846045  0.775405     0.846045     0.663842   \n","11       2  0.791165   0.795918  0.783133  0.789474     0.783133     0.799197   \n","12       0  0.773869   0.766721  0.787270  0.776860     0.787270     0.760469   \n","13       1  0.808616   0.805594  0.813559  0.809557     0.813559     0.803672   \n","14       2  0.834337   0.828402  0.843373  0.835821     0.843373     0.825301   \n","\n","       Kappa  \n","0   0.087102  \n","1   0.081921  \n","2   0.152610  \n","3   0.175879  \n","4   0.258475  \n","5   0.305221  \n","6   0.375209  \n","7   0.413842  \n","8   0.479920  \n","9   0.499162  \n","10  0.509887  \n","11  0.582329  \n","12  0.547739  \n","13  0.617232  \n","14  0.668675  "],"text/html":["\n","  <div id=\"df-6fd5e4ac-9e53-4b88-83d7-917343386f3f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.543551</td>\n","      <td>0.542763</td>\n","      <td>0.552764</td>\n","      <td>0.547718</td>\n","      <td>0.552764</td>\n","      <td>0.534338</td>\n","      <td>0.087102</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.540960</td>\n","      <td>0.532294</td>\n","      <td>0.675141</td>\n","      <td>0.595268</td>\n","      <td>0.675141</td>\n","      <td>0.406780</td>\n","      <td>0.081921</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.576305</td>\n","      <td>0.572519</td>\n","      <td>0.602410</td>\n","      <td>0.587084</td>\n","      <td>0.602410</td>\n","      <td>0.550201</td>\n","      <td>0.152610</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.587940</td>\n","      <td>0.607362</td>\n","      <td>0.497487</td>\n","      <td>0.546961</td>\n","      <td>0.497487</td>\n","      <td>0.678392</td>\n","      <td>0.175879</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.629237</td>\n","      <td>0.614518</td>\n","      <td>0.693503</td>\n","      <td>0.651626</td>\n","      <td>0.693503</td>\n","      <td>0.564972</td>\n","      <td>0.258475</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.652610</td>\n","      <td>0.644487</td>\n","      <td>0.680723</td>\n","      <td>0.662109</td>\n","      <td>0.680723</td>\n","      <td>0.624498</td>\n","      <td>0.305221</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.687605</td>\n","      <td>0.721344</td>\n","      <td>0.611390</td>\n","      <td>0.661831</td>\n","      <td>0.611390</td>\n","      <td>0.763819</td>\n","      <td>0.375209</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.706921</td>\n","      <td>0.715125</td>\n","      <td>0.687853</td>\n","      <td>0.701224</td>\n","      <td>0.687853</td>\n","      <td>0.725989</td>\n","      <td>0.413842</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.739960</td>\n","      <td>0.721707</td>\n","      <td>0.781124</td>\n","      <td>0.750241</td>\n","      <td>0.781124</td>\n","      <td>0.698795</td>\n","      <td>0.479920</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.749581</td>\n","      <td>0.744262</td>\n","      <td>0.760469</td>\n","      <td>0.752278</td>\n","      <td>0.760469</td>\n","      <td>0.738693</td>\n","      <td>0.499162</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.754944</td>\n","      <td>0.715651</td>\n","      <td>0.846045</td>\n","      <td>0.775405</td>\n","      <td>0.846045</td>\n","      <td>0.663842</td>\n","      <td>0.509887</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.791165</td>\n","      <td>0.795918</td>\n","      <td>0.783133</td>\n","      <td>0.789474</td>\n","      <td>0.783133</td>\n","      <td>0.799197</td>\n","      <td>0.582329</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.773869</td>\n","      <td>0.766721</td>\n","      <td>0.787270</td>\n","      <td>0.776860</td>\n","      <td>0.787270</td>\n","      <td>0.760469</td>\n","      <td>0.547739</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.808616</td>\n","      <td>0.805594</td>\n","      <td>0.813559</td>\n","      <td>0.809557</td>\n","      <td>0.813559</td>\n","      <td>0.803672</td>\n","      <td>0.617232</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.834337</td>\n","      <td>0.828402</td>\n","      <td>0.843373</td>\n","      <td>0.835821</td>\n","      <td>0.843373</td>\n","      <td>0.825301</td>\n","      <td>0.668675</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6fd5e4ac-9e53-4b88-83d7-917343386f3f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-6fd5e4ac-9e53-4b88-83d7-917343386f3f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-6fd5e4ac-9e53-4b88-83d7-917343386f3f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-dfe9e163-debf-4bd4-9a3b-319ae680d3d1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dfe9e163-debf-4bd4-9a3b-319ae680d3d1')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-dfe9e163-debf-4bd4-9a3b-319ae680d3d1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_7edfeff9-f931-4f9f-9e16-8daa7600243c\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('metrics_df_gru')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_7edfeff9-f931-4f9f-9e16-8daa7600243c button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('metrics_df_gru');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"metrics_df_gru","summary":"{\n  \"name\": \"metrics_df_gru\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09811405030971604,\n        \"min\": 0.5409604519774012,\n        \"max\": 0.8343373493975904,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7495812395309883,\n          0.7911646586345381,\n          0.5435510887772195\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09664471691231567,\n        \"min\": 0.532293986636971,\n        \"max\": 0.8284023668639053,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7442622950819672,\n          0.7959183673469388,\n          0.5427631578947368\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10686755329993038,\n        \"min\": 0.49748743718592964,\n        \"max\": 0.846045197740113,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7604690117252931,\n          0.7831325301204819,\n          0.5527638190954773\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09660544464961449,\n        \"min\": 0.5469613259668508,\n        \"max\": 0.8358208955223881,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.752278376139188,\n          0.7894736842105263,\n          0.5477178423236515\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10686755329993038,\n        \"min\": 0.49748743718592964,\n        \"max\": 0.846045197740113,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7604690117252931,\n          0.7831325301204819,\n          0.5527638190954773\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11924492691597166,\n        \"min\": 0.4067796610169492,\n        \"max\": 0.8253012048192772,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7386934673366834,\n          0.7991967871485943,\n          0.5343383584589615\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19622810061943208,\n        \"min\": 0.08192090395480223,\n        \"max\": 0.6686746987951807,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.4991624790619765,\n          0.5823293172690763,\n          0.08710217755443883\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["metrics_df_gru.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Frequency Domain/GRU/alpha_frequency_gru.csv', index = False)"],"metadata":{"id":"xUYF0a4IDFCJ","executionInfo":{"status":"ok","timestamp":1717436211542,"user_tz":-360,"elapsed":7,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0qBg_yoVDF-4"},"execution_count":null,"outputs":[]}]}