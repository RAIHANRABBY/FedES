{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Mbfw8uvdftFM","executionInfo":{"status":"ok","timestamp":1717427088205,"user_tz":-360,"elapsed":1274,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sb"]},{"cell_type":"code","source":["\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"INiFJfLjgOkx","executionInfo":{"status":"ok","timestamp":1717427088652,"user_tz":-360,"elapsed":453,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import ExtraTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score, cross_val_predict"],"metadata":{"id":"lYo2Uq77gQSH","executionInfo":{"status":"ok","timestamp":1717427092254,"user_tz":-360,"elapsed":3606,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPool1D, Flatten, Dropout,LSTM"],"metadata":{"id":"g66575_xgVzz","executionInfo":{"status":"ok","timestamp":1717427097503,"user_tz":-360,"elapsed":5258,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MOCNWlamfr3v","executionInfo":{"status":"ok","timestamp":1717427148712,"user_tz":-360,"elapsed":51217,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"8e0babab-5645-484a-e38e-9b4dcafe4a34"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Raw_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/only data/raw_data.npz'\n","\n","Theta_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/feature domain/Beta_frequency.npz'\n","\n","\n","\n","# RAW = np.load(Raw_data, allow_pickle=True)  # Allow loading pickled object arrays\n","# X = RAW['X'].astype('float64')\n","# Y = RAW['Y'].astype('float64')\n","# group = RAW['Group'].astype('float64')"],"metadata":{"id":"iNy9eOGMf2qO","executionInfo":{"status":"ok","timestamp":1717427148712,"user_tz":-360,"elapsed":7,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["This is a good performing model"],"metadata":{"id":"PzeABzSyHgKg"}},{"cell_type":"code","source":["# %%capture\n","# !pip install wandb"],"metadata":{"id":"2w6s3AKGZFZ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import wandb\n","# !wandb login"],"metadata":{"id":"ctC5cKBgZHNk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# CNN-LSTM"],"metadata":{"id":"6DhAYwXUSE9z"}},{"cell_type":"code","source":["%%capture\n","!pip install tensorflow_addons"],"metadata":{"id":"frqG0yYGpe0q","executionInfo":{"status":"ok","timestamp":1717427578841,"user_tz":-360,"elapsed":5395,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(LSTM(256, return_sequences=True))\n","    model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dense(32, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_callback = ModelCheckpoint(\n","                f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Beta/CNN_LSTM/best_model_{run_name}.h5',\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Beta/CNN_LSTM/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Evaluate client model\n","            y_pred = (client_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"VvjC2xCQNHLP","executionInfo":{"status":"ok","timestamp":1717427622166,"user_tz":-360,"elapsed":587,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0c3a80e2-25cc-48c9-89ca-e9dc6f647b93"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["global_model, metrics_df = federated_learning(Theta_data)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVURUnmYNNNg","outputId":"8ea8d6e9-eb51-441a-9483-6fa9662f99eb","executionInfo":{"status":"ok","timestamp":1717428875010,"user_tz":-360,"elapsed":106207,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":13,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 0.6931 - accuracy: 0.5379"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 13s 85ms/step - loss: 0.6931 - accuracy: 0.5393 - val_loss: 0.6932 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6930 - accuracy: 0.5727 - val_loss: 0.6932 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6928 - accuracy: 0.5719 - val_loss: 0.6932 - val_accuracy: 0.4838\n","Epoch 4/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6926 - accuracy: 0.5878 - val_loss: 0.6932 - val_accuracy: 0.4806\n","Epoch 5/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6922 - accuracy: 0.5919 - val_loss: 0.6932 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6917 - accuracy: 0.5921 - val_loss: 0.6932 - val_accuracy: 0.4914\n","Epoch 7/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6911 - accuracy: 0.5905 - val_loss: 0.6931 - val_accuracy: 0.4925\n","Epoch 8/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6902 - accuracy: 0.5905 - val_loss: 0.6929 - val_accuracy: 0.4925\n","Epoch 9/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6892 - accuracy: 0.5938 - val_loss: 0.6926 - val_accuracy: 0.5151\n","Epoch 10/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6880 - accuracy: 0.5908 - val_loss: 0.6923 - val_accuracy: 0.5151\n","Epoch 11/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6869 - accuracy: 0.5940 - val_loss: 0.6916 - val_accuracy: 0.5334\n","Epoch 12/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6857 - accuracy: 0.5956 - val_loss: 0.6911 - val_accuracy: 0.5302\n","Epoch 13/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6845 - accuracy: 0.5964 - val_loss: 0.6900 - val_accuracy: 0.5474\n","Epoch 14/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6831 - accuracy: 0.5994 - val_loss: 0.6890 - val_accuracy: 0.5528\n","Epoch 15/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6814 - accuracy: 0.6021 - val_loss: 0.6881 - val_accuracy: 0.5593\n","Epoch 16/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6797 - accuracy: 0.6032 - val_loss: 0.6863 - val_accuracy: 0.5657\n","Epoch 17/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6767 - accuracy: 0.6080 - val_loss: 0.6841 - val_accuracy: 0.5722\n","Epoch 18/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6735 - accuracy: 0.6115 - val_loss: 0.6815 - val_accuracy: 0.5754\n","Epoch 19/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6694 - accuracy: 0.6123 - val_loss: 0.6776 - val_accuracy: 0.5905\n","Epoch 20/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6643 - accuracy: 0.6202 - val_loss: 0.6726 - val_accuracy: 0.6067\n","Epoch 21/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6599 - accuracy: 0.6156 - val_loss: 0.6694 - val_accuracy: 0.5938\n","Epoch 22/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6562 - accuracy: 0.6274 - val_loss: 0.6643 - val_accuracy: 0.6121\n","Epoch 23/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6545 - accuracy: 0.6212 - val_loss: 0.6619 - val_accuracy: 0.6088\n","Epoch 24/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6524 - accuracy: 0.6204 - val_loss: 0.6599 - val_accuracy: 0.6024\n","Epoch 25/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6501 - accuracy: 0.6255 - val_loss: 0.6565 - val_accuracy: 0.6153\n","Epoch 26/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6477 - accuracy: 0.6282 - val_loss: 0.6555 - val_accuracy: 0.6121\n","Epoch 27/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6445 - accuracy: 0.6317 - val_loss: 0.6555 - val_accuracy: 0.6002\n","Epoch 28/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6443 - accuracy: 0.6280 - val_loss: 0.6536 - val_accuracy: 0.6153\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6437 - accuracy: 0.6331 - val_loss: 0.6542 - val_accuracy: 0.6110\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6417 - accuracy: 0.6309 - val_loss: 0.6539 - val_accuracy: 0.6078\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6395 - accuracy: 0.6379 - val_loss: 0.6531 - val_accuracy: 0.6131\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6392 - accuracy: 0.6371 - val_loss: 0.6556 - val_accuracy: 0.6034\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6381 - accuracy: 0.6401 - val_loss: 0.6523 - val_accuracy: 0.6153\n","Epoch 34/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6363 - accuracy: 0.6352 - val_loss: 0.6521 - val_accuracy: 0.6207\n","Epoch 35/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6372 - accuracy: 0.6414 - val_loss: 0.6519 - val_accuracy: 0.6261\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6349 - accuracy: 0.6406 - val_loss: 0.6529 - val_accuracy: 0.6261\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6366 - accuracy: 0.6420 - val_loss: 0.6564 - val_accuracy: 0.6078\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6349 - accuracy: 0.6444 - val_loss: 0.6521 - val_accuracy: 0.6153\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6343 - accuracy: 0.6406 - val_loss: 0.6514 - val_accuracy: 0.6218\n","Epoch 40/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6318 - accuracy: 0.6452 - val_loss: 0.6517 - val_accuracy: 0.6272\n","Epoch 41/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6322 - accuracy: 0.6474 - val_loss: 0.6524 - val_accuracy: 0.6164\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6321 - accuracy: 0.6449 - val_loss: 0.6538 - val_accuracy: 0.6078\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6295 - accuracy: 0.6549 - val_loss: 0.6531 - val_accuracy: 0.6099\n","Epoch 44/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6298 - accuracy: 0.6511 - val_loss: 0.6518 - val_accuracy: 0.6282\n","Epoch 45/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6285 - accuracy: 0.6492 - val_loss: 0.6524 - val_accuracy: 0.6304\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6270 - accuracy: 0.6530 - val_loss: 0.6521 - val_accuracy: 0.6239\n","Epoch 47/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6280 - accuracy: 0.6455 - val_loss: 0.6523 - val_accuracy: 0.6315\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6257 - accuracy: 0.6517 - val_loss: 0.6529 - val_accuracy: 0.6250\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6226 - accuracy: 0.6627 - val_loss: 0.6551 - val_accuracy: 0.6110\n","Epoch 50/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6257 - accuracy: 0.6554 - val_loss: 0.6522 - val_accuracy: 0.6250\n","Epoch 51/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6236 - accuracy: 0.6544 - val_loss: 0.6534 - val_accuracy: 0.6228\n","Epoch 52/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6242 - accuracy: 0.6611 - val_loss: 0.6528 - val_accuracy: 0.6282\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6199 - accuracy: 0.6624 - val_loss: 0.6546 - val_accuracy: 0.6131\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6197 - accuracy: 0.6635 - val_loss: 0.6530 - val_accuracy: 0.6293\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6184 - accuracy: 0.6616 - val_loss: 0.6532 - val_accuracy: 0.6131\n","Epoch 56/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6201 - accuracy: 0.6603 - val_loss: 0.6525 - val_accuracy: 0.6185\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6183 - accuracy: 0.6633 - val_loss: 0.6551 - val_accuracy: 0.6185\n","Epoch 58/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6164 - accuracy: 0.6638 - val_loss: 0.6543 - val_accuracy: 0.6110\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6148 - accuracy: 0.6711 - val_loss: 0.6546 - val_accuracy: 0.6078\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6160 - accuracy: 0.6697 - val_loss: 0.6564 - val_accuracy: 0.6164\n","Epoch 61/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6137 - accuracy: 0.6678 - val_loss: 0.6546 - val_accuracy: 0.6282\n","Epoch 62/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6111 - accuracy: 0.6740 - val_loss: 0.6559 - val_accuracy: 0.6067\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6091 - accuracy: 0.6767 - val_loss: 0.6554 - val_accuracy: 0.6261\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6106 - accuracy: 0.6765 - val_loss: 0.6554 - val_accuracy: 0.6153\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6088 - accuracy: 0.6703 - val_loss: 0.6578 - val_accuracy: 0.6121\n","Epoch 66/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6064 - accuracy: 0.6786 - val_loss: 0.6580 - val_accuracy: 0.6099\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6044 - accuracy: 0.6794 - val_loss: 0.6561 - val_accuracy: 0.6218\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6030 - accuracy: 0.6867 - val_loss: 0.6581 - val_accuracy: 0.6175\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6029 - accuracy: 0.6821 - val_loss: 0.6568 - val_accuracy: 0.6282\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6017 - accuracy: 0.6808 - val_loss: 0.6590 - val_accuracy: 0.6218\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5979 - accuracy: 0.6907 - val_loss: 0.6587 - val_accuracy: 0.6239\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5997 - accuracy: 0.6837 - val_loss: 0.6590 - val_accuracy: 0.6185\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5970 - accuracy: 0.6897 - val_loss: 0.6578 - val_accuracy: 0.6239\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5956 - accuracy: 0.6967 - val_loss: 0.6622 - val_accuracy: 0.6218\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5935 - accuracy: 0.6953 - val_loss: 0.6584 - val_accuracy: 0.6261\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5928 - accuracy: 0.6891 - val_loss: 0.6586 - val_accuracy: 0.6218\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5914 - accuracy: 0.6921 - val_loss: 0.6648 - val_accuracy: 0.6218\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5881 - accuracy: 0.6956 - val_loss: 0.6645 - val_accuracy: 0.6261\n","Epoch 79/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5859 - accuracy: 0.7020 - val_loss: 0.6715 - val_accuracy: 0.6131\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5861 - accuracy: 0.6972 - val_loss: 0.6637 - val_accuracy: 0.6304\n","Epoch 81/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5847 - accuracy: 0.7002 - val_loss: 0.6662 - val_accuracy: 0.6282\n","Epoch 82/100\n","29/29 [==============================] - 7s 252ms/step - loss: 0.5825 - accuracy: 0.7004 - val_loss: 0.6670 - val_accuracy: 0.6358\n","Epoch 83/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5798 - accuracy: 0.7037 - val_loss: 0.6774 - val_accuracy: 0.6142\n","Epoch 84/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5768 - accuracy: 0.7091 - val_loss: 0.6678 - val_accuracy: 0.6379\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5820 - accuracy: 0.7031 - val_loss: 0.6748 - val_accuracy: 0.6131\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5719 - accuracy: 0.7144 - val_loss: 0.6699 - val_accuracy: 0.6261\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5717 - accuracy: 0.7115 - val_loss: 0.6716 - val_accuracy: 0.6282\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5709 - accuracy: 0.7109 - val_loss: 0.6875 - val_accuracy: 0.6067\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5719 - accuracy: 0.7139 - val_loss: 0.6707 - val_accuracy: 0.6304\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5670 - accuracy: 0.7177 - val_loss: 0.6749 - val_accuracy: 0.6282\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5644 - accuracy: 0.7263 - val_loss: 0.6779 - val_accuracy: 0.6272\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5669 - accuracy: 0.7074 - val_loss: 0.6781 - val_accuracy: 0.6282\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5661 - accuracy: 0.7233 - val_loss: 0.6762 - val_accuracy: 0.6239\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5578 - accuracy: 0.7325 - val_loss: 0.6761 - val_accuracy: 0.6379\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5588 - accuracy: 0.7225 - val_loss: 0.6795 - val_accuracy: 0.6228\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5562 - accuracy: 0.7249 - val_loss: 0.6832 - val_accuracy: 0.6239\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5539 - accuracy: 0.7311 - val_loss: 0.6801 - val_accuracy: 0.6315\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5544 - accuracy: 0.7328 - val_loss: 0.6857 - val_accuracy: 0.6272\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5521 - accuracy: 0.7325 - val_loss: 0.6849 - val_accuracy: 0.6261\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5478 - accuracy: 0.7392 - val_loss: 0.6916 - val_accuracy: 0.6239\n","{'loss': [0.6931033134460449, 0.693007230758667, 0.6928215622901917, 0.6925583481788635, 0.6922113299369812, 0.6916853785514832, 0.6910768151283264, 0.6901939511299133, 0.6892092227935791, 0.6879889369010925, 0.6869156360626221, 0.6857019662857056, 0.6844541430473328, 0.6830692291259766, 0.6813722848892212, 0.6796559691429138, 0.6767364144325256, 0.6734774112701416, 0.6693916320800781, 0.6643363833427429, 0.6598553657531738, 0.6561875343322754, 0.6545125842094421, 0.6524401903152466, 0.6501348614692688, 0.6476526856422424, 0.6444536447525024, 0.6442784070968628, 0.6437154412269592, 0.6417437195777893, 0.6395338773727417, 0.6391676664352417, 0.6380792856216431, 0.6362625360488892, 0.6372432708740234, 0.6349306702613831, 0.6365739107131958, 0.6348881125450134, 0.6342803835868835, 0.6317970156669617, 0.6322021484375, 0.6321303844451904, 0.6295110583305359, 0.6297563314437866, 0.628537654876709, 0.6270185708999634, 0.6280491352081299, 0.6256629824638367, 0.6225624680519104, 0.625670313835144, 0.6235643625259399, 0.6242471933364868, 0.6198773980140686, 0.6196796894073486, 0.6183752417564392, 0.6201168298721313, 0.6182743310928345, 0.6163906455039978, 0.6147910356521606, 0.6160231232643127, 0.6137000918388367, 0.6110831499099731, 0.6091461181640625, 0.6106408834457397, 0.60882967710495, 0.6064183712005615, 0.6044138669967651, 0.6030263304710388, 0.6028652787208557, 0.6016935706138611, 0.5979411602020264, 0.5996738076210022, 0.5970200300216675, 0.5956370234489441, 0.5934537053108215, 0.5928210020065308, 0.5914301872253418, 0.5881428122520447, 0.5859025120735168, 0.5861359238624573, 0.5846747159957886, 0.5825464725494385, 0.5797679424285889, 0.576770007610321, 0.5819824934005737, 0.5719006061553955, 0.571657657623291, 0.5708602666854858, 0.5718997716903687, 0.5669654607772827, 0.5644072890281677, 0.5668874979019165, 0.5660508275032043, 0.5577710866928101, 0.5587875247001648, 0.5562121868133545, 0.5538868308067322, 0.5543520450592041, 0.5520923137664795, 0.5477766394615173], 'accuracy': [0.5393319129943848, 0.5727370977401733, 0.571928858757019, 0.5878232717514038, 0.5918642282485962, 0.592133641242981, 0.5905172228813171, 0.5905172228813171, 0.59375, 0.5907866358757019, 0.5940194129943848, 0.5956357717514038, 0.5964439511299133, 0.5994073152542114, 0.6021012663841248, 0.603178858757019, 0.608027994632721, 0.6115301847457886, 0.6123383641242981, 0.6201508641242981, 0.615571141242981, 0.6274245977401733, 0.6212284564971924, 0.6204202771186829, 0.6255387663841248, 0.6282327771186829, 0.6317349076271057, 0.6279633641242981, 0.6330819129943848, 0.6309267282485962, 0.6379310488700867, 0.6371228694915771, 0.6400862336158752, 0.6352370977401733, 0.6414331793785095, 0.640625, 0.641972005367279, 0.6443965435028076, 0.640625, 0.6452047228813171, 0.6473599076271057, 0.6449353694915771, 0.654902994632721, 0.6511314511299133, 0.6492456793785095, 0.6530172228813171, 0.6454741358757019, 0.6516702771186829, 0.662715494632721, 0.6554418206214905, 0.6543642282485962, 0.6610991358757019, 0.662446141242981, 0.6635237336158752, 0.6616379022598267, 0.6602909564971924, 0.6632543206214905, 0.6637930870056152, 0.6710668206214905, 0.6697198152542114, 0.6678340435028076, 0.6740301847457886, 0.6767241358757019, 0.6764547228813171, 0.670258641242981, 0.6786099076271057, 0.6794180870056152, 0.6866918206214905, 0.6821120977401733, 0.6807650923728943, 0.6907327771186829, 0.6837284564971924, 0.6896551847457886, 0.696659505367279, 0.6953125, 0.689116358757019, 0.6920797228813171, 0.6955819129943848, 0.7020474076271057, 0.6971982717514038, 0.7001616358757019, 0.7004310488700867, 0.7036637663841248, 0.7090517282485962, 0.703125, 0.7144396305084229, 0.7114762663841248, 0.7109375, 0.7139008641242981, 0.7176724076271057, 0.7262930870056152, 0.7074353694915771, 0.7233297228813171, 0.7324892282485962, 0.7225215435028076, 0.724946141242981, 0.7311422228813171, 0.732758641242981, 0.7324892282485962, 0.7392241358757019], 'val_loss': [0.6931674480438232, 0.693189263343811, 0.6931961178779602, 0.6932273507118225, 0.693213701248169, 0.6932183504104614, 0.6931038498878479, 0.6929485201835632, 0.6925650835037231, 0.6923443078994751, 0.6916404366493225, 0.6911059021949768, 0.6900293231010437, 0.6890385746955872, 0.688069760799408, 0.6863437294960022, 0.684106707572937, 0.6814525723457336, 0.6776161789894104, 0.6726096868515015, 0.6694165468215942, 0.6643396019935608, 0.6619154214859009, 0.6599303483963013, 0.6565255522727966, 0.655484139919281, 0.655491292476654, 0.6535841226577759, 0.6541735529899597, 0.6539145112037659, 0.6530742049217224, 0.6555707454681396, 0.6523352861404419, 0.6520926356315613, 0.6518852114677429, 0.6528566479682922, 0.656381368637085, 0.6521278023719788, 0.6514402031898499, 0.6516845226287842, 0.6523723006248474, 0.6537944078445435, 0.653137743473053, 0.6517651677131653, 0.6523892879486084, 0.6521362066268921, 0.6523430347442627, 0.6528821587562561, 0.6550896167755127, 0.6522432565689087, 0.6534358263015747, 0.6528447866439819, 0.6546391248703003, 0.6530312895774841, 0.6532299518585205, 0.6525466442108154, 0.6550935506820679, 0.6542808413505554, 0.6545941829681396, 0.6563762426376343, 0.6545867919921875, 0.6559412479400635, 0.6554127335548401, 0.6553810834884644, 0.6578221917152405, 0.6580004096031189, 0.6560510993003845, 0.6580617427825928, 0.6567771434783936, 0.6590027213096619, 0.6587322354316711, 0.6590375304222107, 0.6578325033187866, 0.6621578931808472, 0.6584228277206421, 0.6585939526557922, 0.6648115515708923, 0.6644922494888306, 0.6715476512908936, 0.6636778116226196, 0.6661841869354248, 0.6669902801513672, 0.6774061918258667, 0.6678462028503418, 0.674761950969696, 0.6698711514472961, 0.6716037392616272, 0.687526285648346, 0.6706521511077881, 0.6749459505081177, 0.6779112815856934, 0.6780824065208435, 0.6762230396270752, 0.6760569214820862, 0.679460883140564, 0.6831998229026794, 0.6801441311836243, 0.6857375502586365, 0.6849493980407715, 0.691593587398529], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48383620381355286, 0.4806034564971924, 0.48491379618644714, 0.4913793206214905, 0.4924568831920624, 0.4924568831920624, 0.5150862336158752, 0.5150862336158752, 0.5334051847457886, 0.5301724076271057, 0.5474137663841248, 0.5528017282485962, 0.5592672228813171, 0.5657327771186829, 0.5721982717514038, 0.5754310488700867, 0.5905172228813171, 0.6066810488700867, 0.59375, 0.6120689511299133, 0.6088362336158752, 0.6023706793785095, 0.6153017282485962, 0.6120689511299133, 0.600215494632721, 0.6153017282485962, 0.610991358757019, 0.607758641242981, 0.6131465435028076, 0.6034482717514038, 0.6153017282485962, 0.6206896305084229, 0.6260775923728943, 0.6260775923728943, 0.607758641242981, 0.6153017282485962, 0.6217672228813171, 0.6271551847457886, 0.6163793206214905, 0.607758641242981, 0.6099137663841248, 0.6282327771186829, 0.6303879022598267, 0.6239224076271057, 0.631465494632721, 0.625, 0.610991358757019, 0.625, 0.6228448152542114, 0.6282327771186829, 0.6131465435028076, 0.6293103694915771, 0.6131465435028076, 0.618534505367279, 0.618534505367279, 0.610991358757019, 0.607758641242981, 0.6163793206214905, 0.6282327771186829, 0.6066810488700867, 0.6260775923728943, 0.6153017282485962, 0.6120689511299133, 0.6099137663841248, 0.6217672228813171, 0.6174569129943848, 0.6282327771186829, 0.6217672228813171, 0.6239224076271057, 0.618534505367279, 0.6239224076271057, 0.6217672228813171, 0.6260775923728943, 0.6217672228813171, 0.6217672228813171, 0.6260775923728943, 0.6131465435028076, 0.6303879022598267, 0.6282327771186829, 0.6357758641242981, 0.6142241358757019, 0.6379310488700867, 0.6131465435028076, 0.6260775923728943, 0.6282327771186829, 0.6066810488700867, 0.6303879022598267, 0.6282327771186829, 0.6271551847457886, 0.6282327771186829, 0.6239224076271057, 0.6379310488700867, 0.6228448152542114, 0.6239224076271057, 0.631465494632721, 0.6271551847457886, 0.6260775923728943, 0.6239224076271057]}\n","38/38 [==============================] - 1s 9ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5266"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 9s 77ms/step - loss: 0.6931 - accuracy: 0.5266 - val_loss: 0.6932 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5696 - val_loss: 0.6932 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6930 - accuracy: 0.5682 - val_loss: 0.6932 - val_accuracy: 0.4898\n","Epoch 4/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6929 - accuracy: 0.5693 - val_loss: 0.6932 - val_accuracy: 0.4887\n","Epoch 5/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6928 - accuracy: 0.5693 - val_loss: 0.6932 - val_accuracy: 0.4876\n","Epoch 6/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6925 - accuracy: 0.5722 - val_loss: 0.6932 - val_accuracy: 0.4966\n","Epoch 7/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6923 - accuracy: 0.5702 - val_loss: 0.6931 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6920 - accuracy: 0.5631 - val_loss: 0.6931 - val_accuracy: 0.5102\n","Epoch 9/100\n","28/28 [==============================] - 1s 41ms/step - loss: 0.6915 - accuracy: 0.5713 - val_loss: 0.6931 - val_accuracy: 0.5113\n","Epoch 10/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.6910 - accuracy: 0.5640 - val_loss: 0.6930 - val_accuracy: 0.5192\n","Epoch 11/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.6905 - accuracy: 0.5642 - val_loss: 0.6928 - val_accuracy: 0.5238\n","Epoch 12/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.6900 - accuracy: 0.5637 - val_loss: 0.6926 - val_accuracy: 0.5339\n","Epoch 13/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.6894 - accuracy: 0.5651 - val_loss: 0.6925 - val_accuracy: 0.5385\n","Epoch 14/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.6888 - accuracy: 0.5688 - val_loss: 0.6922 - val_accuracy: 0.5520\n","Epoch 15/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6882 - accuracy: 0.5676 - val_loss: 0.6919 - val_accuracy: 0.5509\n","Epoch 16/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.6875 - accuracy: 0.5713 - val_loss: 0.6915 - val_accuracy: 0.5667\n","Epoch 17/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6867 - accuracy: 0.5716 - val_loss: 0.6911 - val_accuracy: 0.5656\n","Epoch 18/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6861 - accuracy: 0.5778 - val_loss: 0.6905 - val_accuracy: 0.5679\n","Epoch 19/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.6851 - accuracy: 0.5767 - val_loss: 0.6899 - val_accuracy: 0.5747\n","Epoch 20/100\n","28/28 [==============================] - 1s 42ms/step - loss: 0.6837 - accuracy: 0.5894 - val_loss: 0.6890 - val_accuracy: 0.5781\n","Epoch 21/100\n","28/28 [==============================] - 1s 44ms/step - loss: 0.6822 - accuracy: 0.5908 - val_loss: 0.6880 - val_accuracy: 0.5814\n","Epoch 22/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.6805 - accuracy: 0.6055 - val_loss: 0.6866 - val_accuracy: 0.5928\n","Epoch 23/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6788 - accuracy: 0.6041 - val_loss: 0.6852 - val_accuracy: 0.5837\n","Epoch 24/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6765 - accuracy: 0.6087 - val_loss: 0.6842 - val_accuracy: 0.5860\n","Epoch 25/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6751 - accuracy: 0.6146 - val_loss: 0.6829 - val_accuracy: 0.5860\n","Epoch 26/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6727 - accuracy: 0.6154 - val_loss: 0.6818 - val_accuracy: 0.5871\n","Epoch 27/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.6709 - accuracy: 0.6183 - val_loss: 0.6811 - val_accuracy: 0.5713\n","Epoch 28/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6700 - accuracy: 0.6143 - val_loss: 0.6802 - val_accuracy: 0.5814\n","Epoch 29/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6692 - accuracy: 0.6084 - val_loss: 0.6802 - val_accuracy: 0.5735\n","Epoch 30/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6663 - accuracy: 0.6169 - val_loss: 0.6804 - val_accuracy: 0.5871\n","Epoch 31/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6653 - accuracy: 0.6118 - val_loss: 0.6788 - val_accuracy: 0.5848\n","Epoch 32/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6633 - accuracy: 0.6200 - val_loss: 0.6784 - val_accuracy: 0.5860\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6617 - accuracy: 0.6239 - val_loss: 0.6782 - val_accuracy: 0.5860\n","Epoch 34/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6610 - accuracy: 0.6194 - val_loss: 0.6775 - val_accuracy: 0.5894\n","Epoch 35/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6588 - accuracy: 0.6254 - val_loss: 0.6772 - val_accuracy: 0.5916\n","Epoch 36/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6576 - accuracy: 0.6231 - val_loss: 0.6770 - val_accuracy: 0.5860\n","Epoch 37/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6559 - accuracy: 0.6273 - val_loss: 0.6772 - val_accuracy: 0.5860\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6547 - accuracy: 0.6290 - val_loss: 0.6768 - val_accuracy: 0.5837\n","Epoch 39/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6521 - accuracy: 0.6282 - val_loss: 0.6768 - val_accuracy: 0.5939\n","Epoch 40/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6520 - accuracy: 0.6299 - val_loss: 0.6765 - val_accuracy: 0.5905\n","Epoch 41/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6517 - accuracy: 0.6293 - val_loss: 0.6784 - val_accuracy: 0.5792\n","Epoch 42/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6497 - accuracy: 0.6324 - val_loss: 0.6769 - val_accuracy: 0.5928\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6467 - accuracy: 0.6358 - val_loss: 0.6772 - val_accuracy: 0.5939\n","Epoch 44/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6447 - accuracy: 0.6355 - val_loss: 0.6779 - val_accuracy: 0.5837\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6441 - accuracy: 0.6341 - val_loss: 0.6776 - val_accuracy: 0.5905\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6434 - accuracy: 0.6361 - val_loss: 0.6778 - val_accuracy: 0.5939\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6434 - accuracy: 0.6364 - val_loss: 0.6783 - val_accuracy: 0.5928\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6397 - accuracy: 0.6415 - val_loss: 0.6781 - val_accuracy: 0.5939\n","Epoch 49/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6384 - accuracy: 0.6429 - val_loss: 0.6793 - val_accuracy: 0.5928\n","Epoch 50/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6371 - accuracy: 0.6486 - val_loss: 0.6796 - val_accuracy: 0.5950\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6374 - accuracy: 0.6466 - val_loss: 0.6806 - val_accuracy: 0.5882\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6338 - accuracy: 0.6545 - val_loss: 0.6805 - val_accuracy: 0.5905\n","Epoch 53/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6325 - accuracy: 0.6505 - val_loss: 0.6797 - val_accuracy: 0.5995\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6336 - accuracy: 0.6480 - val_loss: 0.6802 - val_accuracy: 0.5916\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6291 - accuracy: 0.6525 - val_loss: 0.6809 - val_accuracy: 0.5995\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6286 - accuracy: 0.6520 - val_loss: 0.6807 - val_accuracy: 0.5905\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6276 - accuracy: 0.6570 - val_loss: 0.6811 - val_accuracy: 0.5995\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6240 - accuracy: 0.6576 - val_loss: 0.6821 - val_accuracy: 0.5916\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6225 - accuracy: 0.6621 - val_loss: 0.6836 - val_accuracy: 0.5905\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6208 - accuracy: 0.6616 - val_loss: 0.6824 - val_accuracy: 0.5973\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6176 - accuracy: 0.6633 - val_loss: 0.6835 - val_accuracy: 0.5962\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6167 - accuracy: 0.6720 - val_loss: 0.6848 - val_accuracy: 0.5950\n","Epoch 63/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6166 - accuracy: 0.6686 - val_loss: 0.6863 - val_accuracy: 0.5928\n","Epoch 64/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6146 - accuracy: 0.6715 - val_loss: 0.6854 - val_accuracy: 0.5973\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6102 - accuracy: 0.6752 - val_loss: 0.6880 - val_accuracy: 0.5973\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6109 - accuracy: 0.6684 - val_loss: 0.6914 - val_accuracy: 0.5973\n","Epoch 67/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6112 - accuracy: 0.6675 - val_loss: 0.6882 - val_accuracy: 0.5939\n","Epoch 68/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6098 - accuracy: 0.6763 - val_loss: 0.6894 - val_accuracy: 0.5928\n","Epoch 69/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6019 - accuracy: 0.6836 - val_loss: 0.6893 - val_accuracy: 0.5939\n","Epoch 70/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6020 - accuracy: 0.6749 - val_loss: 0.6912 - val_accuracy: 0.5928\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6026 - accuracy: 0.6783 - val_loss: 0.6934 - val_accuracy: 0.5928\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5980 - accuracy: 0.6800 - val_loss: 0.6996 - val_accuracy: 0.5984\n","Epoch 73/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6036 - accuracy: 0.6737 - val_loss: 0.6969 - val_accuracy: 0.5882\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5944 - accuracy: 0.6910 - val_loss: 0.6945 - val_accuracy: 0.5916\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5943 - accuracy: 0.6831 - val_loss: 0.6978 - val_accuracy: 0.5950\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5930 - accuracy: 0.6882 - val_loss: 0.6959 - val_accuracy: 0.5939\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5907 - accuracy: 0.6865 - val_loss: 0.6977 - val_accuracy: 0.5973\n","Epoch 78/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5894 - accuracy: 0.6913 - val_loss: 0.6988 - val_accuracy: 0.5905\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5901 - accuracy: 0.6927 - val_loss: 0.7033 - val_accuracy: 0.5905\n","Epoch 80/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5851 - accuracy: 0.7015 - val_loss: 0.7005 - val_accuracy: 0.5928\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5807 - accuracy: 0.6975 - val_loss: 0.7017 - val_accuracy: 0.5916\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5810 - accuracy: 0.7001 - val_loss: 0.7054 - val_accuracy: 0.5882\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5768 - accuracy: 0.7015 - val_loss: 0.7067 - val_accuracy: 0.5916\n","Epoch 84/100\n","28/28 [==============================] - 1s 47ms/step - loss: 0.5750 - accuracy: 0.7029 - val_loss: 0.7088 - val_accuracy: 0.6029\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5719 - accuracy: 0.7043 - val_loss: 0.7092 - val_accuracy: 0.5973\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5721 - accuracy: 0.7006 - val_loss: 0.7098 - val_accuracy: 0.6007\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5721 - accuracy: 0.7037 - val_loss: 0.7112 - val_accuracy: 0.6007\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5686 - accuracy: 0.7003 - val_loss: 0.7135 - val_accuracy: 0.5973\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5617 - accuracy: 0.7108 - val_loss: 0.7148 - val_accuracy: 0.5905\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5601 - accuracy: 0.7196 - val_loss: 0.7147 - val_accuracy: 0.6007\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5589 - accuracy: 0.7131 - val_loss: 0.7161 - val_accuracy: 0.5995\n","Epoch 92/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5568 - accuracy: 0.7187 - val_loss: 0.7190 - val_accuracy: 0.6086\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5575 - accuracy: 0.7168 - val_loss: 0.7222 - val_accuracy: 0.6052\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5525 - accuracy: 0.7216 - val_loss: 0.7234 - val_accuracy: 0.5984\n","Epoch 95/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5517 - accuracy: 0.7247 - val_loss: 0.7347 - val_accuracy: 0.5995\n","Epoch 96/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5488 - accuracy: 0.7255 - val_loss: 0.7258 - val_accuracy: 0.6063\n","Epoch 97/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.5429 - accuracy: 0.7289 - val_loss: 0.7304 - val_accuracy: 0.6109\n","Epoch 98/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5482 - accuracy: 0.7199 - val_loss: 0.7245 - val_accuracy: 0.6063\n","Epoch 99/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.5475 - accuracy: 0.7227 - val_loss: 0.7317 - val_accuracy: 0.6154\n","Epoch 100/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5419 - accuracy: 0.7315 - val_loss: 0.7367 - val_accuracy: 0.6007\n","{'loss': [0.6931264996528625, 0.6930745244026184, 0.6929888725280762, 0.6928797364234924, 0.6927545070648193, 0.6925362944602966, 0.6922680139541626, 0.6919786334037781, 0.6915212273597717, 0.6910175681114197, 0.6904900670051575, 0.6899763345718384, 0.6894177794456482, 0.6887823343276978, 0.6882407069206238, 0.6874728798866272, 0.686732828617096, 0.6860519647598267, 0.6850786209106445, 0.6837310194969177, 0.6822437047958374, 0.6804929375648499, 0.6787552833557129, 0.6765034198760986, 0.675147294998169, 0.6727067828178406, 0.6709191799163818, 0.6700173616409302, 0.6692078113555908, 0.666296124458313, 0.665298581123352, 0.6632727384567261, 0.6616565585136414, 0.6609665155410767, 0.6588318347930908, 0.6575541496276855, 0.6559144854545593, 0.6546796560287476, 0.6520853638648987, 0.6520301699638367, 0.6517008543014526, 0.6497066020965576, 0.6466589570045471, 0.6447349786758423, 0.644110381603241, 0.6434386372566223, 0.6433653831481934, 0.6397250294685364, 0.6384275555610657, 0.6370834708213806, 0.6374253630638123, 0.6337561011314392, 0.6324989795684814, 0.6335775256156921, 0.6291050910949707, 0.6286361217498779, 0.6275566220283508, 0.6240187287330627, 0.6225189566612244, 0.6207613348960876, 0.6176101565361023, 0.6166566610336304, 0.6166020631790161, 0.6145952939987183, 0.6101586222648621, 0.610903263092041, 0.6111913919448853, 0.6097525358200073, 0.6019291281700134, 0.6020403504371643, 0.6026201248168945, 0.5980494022369385, 0.6036162972450256, 0.5943970084190369, 0.5942655205726624, 0.593031644821167, 0.5907000303268433, 0.5893727540969849, 0.590114951133728, 0.5850821137428284, 0.5806759595870972, 0.5809652805328369, 0.5767888426780701, 0.575018048286438, 0.5718689560890198, 0.5721182823181152, 0.5721222162246704, 0.5685798525810242, 0.5616891980171204, 0.5600696802139282, 0.5588645339012146, 0.5568227767944336, 0.5574955940246582, 0.552528977394104, 0.5516604781150818, 0.5488345623016357, 0.5428928732872009, 0.5481599569320679, 0.5474996566772461, 0.5419259071350098], 'accuracy': [0.5265987515449524, 0.569609522819519, 0.5681946873664856, 0.5693265199661255, 0.5693265199661255, 0.5721561908721924, 0.5701754093170166, 0.5631012916564941, 0.5713073015213013, 0.5639501810073853, 0.5642331838607788, 0.5636672377586365, 0.5650820732116699, 0.5687606334686279, 0.5676287412643433, 0.5713073015213013, 0.57159024477005, 0.5778155326843262, 0.5766836404800415, 0.5894170999526978, 0.5908319354057312, 0.6055461168289185, 0.604131281375885, 0.6086587309837341, 0.6146010160446167, 0.6154499053955078, 0.6182795763015747, 0.6143180727958679, 0.6083757877349854, 0.6168647408485413, 0.6117713451385498, 0.6199773550033569, 0.6239388585090637, 0.6194114089012146, 0.6253536939620972, 0.6230899691581726, 0.627334475517273, 0.6290322542190552, 0.6281833648681641, 0.6298811435699463, 0.629315197467804, 0.6324278712272644, 0.6358234286308289, 0.6355404853820801, 0.6341256499290466, 0.6361063718795776, 0.6363893747329712, 0.6414827108383179, 0.6428975462913513, 0.6485568881034851, 0.6465761065483093, 0.6544991731643677, 0.6505376100540161, 0.6479909420013428, 0.6525183916091919, 0.6519524455070496, 0.657045841217041, 0.6576117873191833, 0.6621392369270325, 0.6615732908248901, 0.6632710695266724, 0.6720430254936218, 0.6686474084854126, 0.6714770793914795, 0.6751556396484375, 0.6683644652366638, 0.6675155758857727, 0.6762874722480774, 0.6836445927619934, 0.674872636795044, 0.6782682538032532, 0.6799660325050354, 0.673740804195404, 0.6910017132759094, 0.6830786466598511, 0.6881720423698425, 0.6864742636680603, 0.6912846565246582, 0.6926994919776917, 0.7014714479446411, 0.6975098848342896, 0.7000566124916077, 0.7014714479446411, 0.7028862237930298, 0.7043010592460632, 0.7006224989891052, 0.7037351727485657, 0.7003395557403564, 0.7108092904090881, 0.7195811867713928, 0.7130730152130127, 0.7187322974205017, 0.7167515754699707, 0.7215619683265686, 0.7246745824813843, 0.7255234718322754, 0.7289190888404846, 0.7198641896247864, 0.7226938605308533, 0.731465756893158], 'val_loss': [0.6931502819061279, 0.6931532025337219, 0.6931566596031189, 0.6931615471839905, 0.6931703090667725, 0.6931638121604919, 0.6931487917900085, 0.6931008100509644, 0.6930856704711914, 0.6929713487625122, 0.692823052406311, 0.6926414370536804, 0.6924507021903992, 0.6921678185462952, 0.6919088959693909, 0.6915044784545898, 0.6910849213600159, 0.6905247569084167, 0.6898840069770813, 0.6890228986740112, 0.6879566311836243, 0.6866031289100647, 0.6852275729179382, 0.6841862201690674, 0.6829390525817871, 0.6817958950996399, 0.6810609102249146, 0.6802071332931519, 0.6802249550819397, 0.6804254651069641, 0.6787834763526917, 0.6784135699272156, 0.6781802773475647, 0.6774780750274658, 0.6772263646125793, 0.6769837141036987, 0.6772228479385376, 0.6767758727073669, 0.676764726638794, 0.6764600872993469, 0.6784180402755737, 0.6769432425498962, 0.6771937608718872, 0.6779244542121887, 0.6775569915771484, 0.6778466701507568, 0.6782853007316589, 0.6781414151191711, 0.6793146729469299, 0.6795799136161804, 0.6806161403656006, 0.6805263161659241, 0.6796809434890747, 0.6802137494087219, 0.6809124946594238, 0.680725634098053, 0.6810880899429321, 0.6820788979530334, 0.6835640072822571, 0.6824480891227722, 0.6835322976112366, 0.6848013401031494, 0.6862763166427612, 0.6854333877563477, 0.6880031824111938, 0.6913504600524902, 0.6882079243659973, 0.6894025206565857, 0.6893439888954163, 0.6911833882331848, 0.6934036612510681, 0.6995752453804016, 0.6968915462493896, 0.6945046186447144, 0.6977716088294983, 0.6958702206611633, 0.697719931602478, 0.6988109946250916, 0.7033053636550903, 0.7005122303962708, 0.7017499208450317, 0.7053772211074829, 0.7066660523414612, 0.7087615728378296, 0.7092276811599731, 0.7098069787025452, 0.7112358808517456, 0.7134947180747986, 0.7147918343544006, 0.7146840691566467, 0.7161136269569397, 0.7190366983413696, 0.7222448587417603, 0.7233877182006836, 0.7346857786178589, 0.7257577776908875, 0.7303982377052307, 0.7245436906814575, 0.731726884841919, 0.7367491126060486], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4898189902305603, 0.48868778347969055, 0.4875565469264984, 0.49660632014274597, 0.4954751133918762, 0.5101810097694397, 0.5113122463226318, 0.5192307829856873, 0.523755669593811, 0.5339366793632507, 0.5384615659713745, 0.5520362257957458, 0.5509049892425537, 0.5667420625686646, 0.5656108856201172, 0.5678732991218567, 0.5746606588363647, 0.5780543088912964, 0.581447958946228, 0.5927602052688599, 0.5837104320526123, 0.5859728455543518, 0.5859728455543518, 0.587104082107544, 0.5712669491767883, 0.581447958946228, 0.5735294222831726, 0.587104082107544, 0.5848416090011597, 0.5859728455543518, 0.5859728455543518, 0.5893664956092834, 0.5916289687156677, 0.5859728455543518, 0.5859728455543518, 0.5837104320526123, 0.5938913822174072, 0.5904977321624756, 0.5791855454444885, 0.5927602052688599, 0.5938913822174072, 0.5837104320526123, 0.5904977321624756, 0.5938913822174072, 0.5927602052688599, 0.5938913822174072, 0.5927602052688599, 0.5950226187705994, 0.5882353186607361, 0.5904977321624756, 0.5995475053787231, 0.5916289687156677, 0.5995475053787231, 0.5904977321624756, 0.5995475053787231, 0.5916289687156677, 0.5904977321624756, 0.5972850918769836, 0.5961538553237915, 0.5950226187705994, 0.5927602052688599, 0.5972850918769836, 0.5972850918769836, 0.5972850918769836, 0.5938913822174072, 0.5927602052688599, 0.5938913822174072, 0.5927602052688599, 0.5927602052688599, 0.598416268825531, 0.5882353186607361, 0.5916289687156677, 0.5950226187705994, 0.5938913822174072, 0.5972850918769836, 0.5904977321624756, 0.5904977321624756, 0.5927602052688599, 0.5916289687156677, 0.5882353186607361, 0.5916289687156677, 0.6029411554336548, 0.5972850918769836, 0.6006787419319153, 0.6006787419319153, 0.5972850918769836, 0.5904977321624756, 0.6006787419319153, 0.5995475053787231, 0.6085972785949707, 0.6052036285400391, 0.598416268825531, 0.5995475053787231, 0.6063348650932312, 0.610859751701355, 0.6063348650932312, 0.6153846383094788, 0.6006787419319153]}\n","45/45 [==============================] - 1s 7ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.4894"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 7s 66ms/step - loss: 0.6932 - accuracy: 0.4894 - val_loss: 0.6932 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6931 - accuracy: 0.5196 - val_loss: 0.6932 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6931 - accuracy: 0.5494 - val_loss: 0.6932 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6930 - accuracy: 0.5439 - val_loss: 0.6932 - val_accuracy: 0.4876\n","Epoch 5/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6929 - accuracy: 0.5571 - val_loss: 0.6932 - val_accuracy: 0.4897\n","Epoch 6/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6928 - accuracy: 0.5581 - val_loss: 0.6932 - val_accuracy: 0.4824\n","Epoch 7/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6927 - accuracy: 0.5581 - val_loss: 0.6932 - val_accuracy: 0.4773\n","Epoch 8/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6925 - accuracy: 0.5605 - val_loss: 0.6932 - val_accuracy: 0.4835\n","Epoch 9/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6923 - accuracy: 0.5646 - val_loss: 0.6932 - val_accuracy: 0.4897\n","Epoch 10/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6920 - accuracy: 0.5651 - val_loss: 0.6931 - val_accuracy: 0.4979\n","Epoch 11/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6916 - accuracy: 0.5695 - val_loss: 0.6929 - val_accuracy: 0.5041\n","Epoch 12/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6912 - accuracy: 0.5690 - val_loss: 0.6927 - val_accuracy: 0.5052\n","Epoch 13/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6906 - accuracy: 0.5721 - val_loss: 0.6924 - val_accuracy: 0.5155\n","Epoch 14/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6897 - accuracy: 0.5783 - val_loss: 0.6919 - val_accuracy: 0.5186\n","Epoch 15/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6886 - accuracy: 0.5860 - val_loss: 0.6910 - val_accuracy: 0.5671\n","Epoch 16/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6872 - accuracy: 0.5886 - val_loss: 0.6899 - val_accuracy: 0.5733\n","Epoch 17/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6853 - accuracy: 0.5935 - val_loss: 0.6883 - val_accuracy: 0.5744\n","Epoch 18/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6833 - accuracy: 0.5992 - val_loss: 0.6861 - val_accuracy: 0.5888\n","Epoch 19/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6808 - accuracy: 0.6065 - val_loss: 0.6835 - val_accuracy: 0.5909\n","Epoch 20/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6773 - accuracy: 0.6098 - val_loss: 0.6809 - val_accuracy: 0.5878\n","Epoch 21/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6752 - accuracy: 0.6075 - val_loss: 0.6784 - val_accuracy: 0.5857\n","Epoch 22/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6726 - accuracy: 0.6116 - val_loss: 0.6756 - val_accuracy: 0.5940\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6702 - accuracy: 0.6088 - val_loss: 0.6759 - val_accuracy: 0.5826\n","Epoch 24/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6679 - accuracy: 0.6168 - val_loss: 0.6719 - val_accuracy: 0.5878\n","Epoch 25/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6655 - accuracy: 0.6196 - val_loss: 0.6703 - val_accuracy: 0.5888\n","Epoch 26/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6636 - accuracy: 0.6165 - val_loss: 0.6697 - val_accuracy: 0.5899\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6620 - accuracy: 0.6160 - val_loss: 0.6682 - val_accuracy: 0.5909\n","Epoch 28/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6602 - accuracy: 0.6243 - val_loss: 0.6691 - val_accuracy: 0.5981\n","Epoch 29/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6594 - accuracy: 0.6227 - val_loss: 0.6674 - val_accuracy: 0.5909\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6558 - accuracy: 0.6276 - val_loss: 0.6674 - val_accuracy: 0.5909\n","Epoch 31/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6549 - accuracy: 0.6292 - val_loss: 0.6680 - val_accuracy: 0.5878\n","Epoch 32/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6514 - accuracy: 0.6310 - val_loss: 0.6663 - val_accuracy: 0.5961\n","Epoch 33/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6510 - accuracy: 0.6328 - val_loss: 0.6670 - val_accuracy: 0.5930\n","Epoch 34/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6478 - accuracy: 0.6339 - val_loss: 0.6673 - val_accuracy: 0.5930\n","Epoch 35/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6486 - accuracy: 0.6295 - val_loss: 0.6698 - val_accuracy: 0.5940\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6463 - accuracy: 0.6375 - val_loss: 0.6674 - val_accuracy: 0.5961\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6427 - accuracy: 0.6432 - val_loss: 0.6695 - val_accuracy: 0.5899\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6433 - accuracy: 0.6421 - val_loss: 0.6680 - val_accuracy: 0.5919\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6396 - accuracy: 0.6470 - val_loss: 0.6697 - val_accuracy: 0.5940\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6401 - accuracy: 0.6465 - val_loss: 0.6701 - val_accuracy: 0.5940\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6400 - accuracy: 0.6465 - val_loss: 0.6701 - val_accuracy: 0.5981\n","Epoch 42/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6347 - accuracy: 0.6509 - val_loss: 0.6708 - val_accuracy: 0.5992\n","Epoch 43/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6331 - accuracy: 0.6499 - val_loss: 0.6709 - val_accuracy: 0.6002\n","Epoch 44/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6338 - accuracy: 0.6475 - val_loss: 0.6709 - val_accuracy: 0.6043\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6318 - accuracy: 0.6574 - val_loss: 0.6739 - val_accuracy: 0.5888\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6294 - accuracy: 0.6540 - val_loss: 0.6702 - val_accuracy: 0.5950\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6284 - accuracy: 0.6618 - val_loss: 0.6718 - val_accuracy: 0.5961\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6251 - accuracy: 0.6602 - val_loss: 0.6738 - val_accuracy: 0.5950\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6227 - accuracy: 0.6625 - val_loss: 0.6744 - val_accuracy: 0.5930\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6231 - accuracy: 0.6674 - val_loss: 0.6754 - val_accuracy: 0.5971\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6202 - accuracy: 0.6651 - val_loss: 0.6734 - val_accuracy: 0.5919\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6181 - accuracy: 0.6685 - val_loss: 0.6756 - val_accuracy: 0.5919\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6170 - accuracy: 0.6734 - val_loss: 0.6768 - val_accuracy: 0.5971\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6166 - accuracy: 0.6724 - val_loss: 0.6784 - val_accuracy: 0.5992\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6131 - accuracy: 0.6744 - val_loss: 0.6780 - val_accuracy: 0.5961\n","Epoch 56/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6120 - accuracy: 0.6793 - val_loss: 0.6790 - val_accuracy: 0.5909\n","Epoch 57/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6112 - accuracy: 0.6736 - val_loss: 0.6785 - val_accuracy: 0.5909\n","Epoch 58/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6091 - accuracy: 0.6832 - val_loss: 0.6795 - val_accuracy: 0.5981\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6059 - accuracy: 0.6801 - val_loss: 0.6777 - val_accuracy: 0.5961\n","Epoch 60/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6058 - accuracy: 0.6809 - val_loss: 0.6805 - val_accuracy: 0.5940\n","Epoch 61/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6030 - accuracy: 0.6853 - val_loss: 0.6804 - val_accuracy: 0.5961\n","Epoch 62/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5987 - accuracy: 0.6868 - val_loss: 0.6835 - val_accuracy: 0.5899\n","Epoch 63/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5987 - accuracy: 0.6853 - val_loss: 0.6883 - val_accuracy: 0.5961\n","Epoch 64/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5999 - accuracy: 0.6817 - val_loss: 0.6820 - val_accuracy: 0.6002\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5925 - accuracy: 0.6930 - val_loss: 0.6898 - val_accuracy: 0.5909\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5910 - accuracy: 0.6886 - val_loss: 0.6846 - val_accuracy: 0.6043\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5934 - accuracy: 0.6902 - val_loss: 0.6859 - val_accuracy: 0.5992\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5869 - accuracy: 0.7016 - val_loss: 0.6871 - val_accuracy: 0.5981\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5837 - accuracy: 0.6956 - val_loss: 0.6926 - val_accuracy: 0.5940\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5835 - accuracy: 0.7008 - val_loss: 0.6897 - val_accuracy: 0.6033\n","Epoch 71/100\n","31/31 [==============================] - 1s 48ms/step - loss: 0.5815 - accuracy: 0.7054 - val_loss: 0.6895 - val_accuracy: 0.6054\n","Epoch 72/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5812 - accuracy: 0.7054 - val_loss: 0.6910 - val_accuracy: 0.5971\n","Epoch 73/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5821 - accuracy: 0.6990 - val_loss: 0.6888 - val_accuracy: 0.6116\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5769 - accuracy: 0.7021 - val_loss: 0.6920 - val_accuracy: 0.6043\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5761 - accuracy: 0.7070 - val_loss: 0.7017 - val_accuracy: 0.5899\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5731 - accuracy: 0.7121 - val_loss: 0.6980 - val_accuracy: 0.5940\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5709 - accuracy: 0.7085 - val_loss: 0.6935 - val_accuracy: 0.6085\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5652 - accuracy: 0.7114 - val_loss: 0.6934 - val_accuracy: 0.6012\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5660 - accuracy: 0.7075 - val_loss: 0.7109 - val_accuracy: 0.5919\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5653 - accuracy: 0.7168 - val_loss: 0.6991 - val_accuracy: 0.6023\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5614 - accuracy: 0.7165 - val_loss: 0.7011 - val_accuracy: 0.6012\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5550 - accuracy: 0.7202 - val_loss: 0.7037 - val_accuracy: 0.6023\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5570 - accuracy: 0.7181 - val_loss: 0.7113 - val_accuracy: 0.6012\n","Epoch 84/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5563 - accuracy: 0.7145 - val_loss: 0.7049 - val_accuracy: 0.6002\n","Epoch 85/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5524 - accuracy: 0.7202 - val_loss: 0.7052 - val_accuracy: 0.6012\n","Epoch 86/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5498 - accuracy: 0.7227 - val_loss: 0.7138 - val_accuracy: 0.5888\n","Epoch 87/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5465 - accuracy: 0.7282 - val_loss: 0.7106 - val_accuracy: 0.6012\n","Epoch 88/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5459 - accuracy: 0.7269 - val_loss: 0.7148 - val_accuracy: 0.6064\n","Epoch 89/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5480 - accuracy: 0.7284 - val_loss: 0.7138 - val_accuracy: 0.5961\n","Epoch 90/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5426 - accuracy: 0.7300 - val_loss: 0.7230 - val_accuracy: 0.6043\n","Epoch 91/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5362 - accuracy: 0.7357 - val_loss: 0.7238 - val_accuracy: 0.5868\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5360 - accuracy: 0.7351 - val_loss: 0.7167 - val_accuracy: 0.6064\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5324 - accuracy: 0.7328 - val_loss: 0.7173 - val_accuracy: 0.6054\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5365 - accuracy: 0.7385 - val_loss: 0.7164 - val_accuracy: 0.6054\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5257 - accuracy: 0.7380 - val_loss: 0.7311 - val_accuracy: 0.5971\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5293 - accuracy: 0.7385 - val_loss: 0.7208 - val_accuracy: 0.6043\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5272 - accuracy: 0.7411 - val_loss: 0.7242 - val_accuracy: 0.6002\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5175 - accuracy: 0.7488 - val_loss: 0.7271 - val_accuracy: 0.6074\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5269 - accuracy: 0.7372 - val_loss: 0.7667 - val_accuracy: 0.5971\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5179 - accuracy: 0.7452 - val_loss: 0.7286 - val_accuracy: 0.6023\n","{'loss': [0.6931536793708801, 0.6931174993515015, 0.6930740475654602, 0.6930245161056519, 0.692936360836029, 0.6928263902664185, 0.6926701068878174, 0.6925042271614075, 0.6922832131385803, 0.6920156478881836, 0.6916378140449524, 0.6911678314208984, 0.6906055808067322, 0.689673662185669, 0.6886397004127502, 0.6872048377990723, 0.6852580308914185, 0.6833139061927795, 0.6808127760887146, 0.6773276925086975, 0.6751506924629211, 0.672602117061615, 0.6701882481575012, 0.6679304838180542, 0.6654667854309082, 0.6635788679122925, 0.662029504776001, 0.6602388024330139, 0.6593587398529053, 0.655829668045044, 0.6548568606376648, 0.6514337062835693, 0.6510236859321594, 0.6478451490402222, 0.6485571265220642, 0.6463413238525391, 0.6426807045936584, 0.6433007121086121, 0.6396050453186035, 0.6400952935218811, 0.6400228142738342, 0.6347176432609558, 0.6331074237823486, 0.6338253617286682, 0.6317685842514038, 0.6293638348579407, 0.6284413933753967, 0.6251184344291687, 0.6226690411567688, 0.6231013536453247, 0.6201987862586975, 0.6180856823921204, 0.6170051097869873, 0.6165592670440674, 0.6130903959274292, 0.6120087504386902, 0.611167848110199, 0.6090623140335083, 0.6058944463729858, 0.6057551503181458, 0.6030165553092957, 0.5987080931663513, 0.5987323522567749, 0.5998780727386475, 0.5925367474555969, 0.5910308957099915, 0.5934062004089355, 0.5868767499923706, 0.5837464928627014, 0.5834769010543823, 0.5815477967262268, 0.5811573266983032, 0.5820645689964294, 0.5769227147102356, 0.5761460661888123, 0.5730794668197632, 0.5709150433540344, 0.5651921629905701, 0.5659612417221069, 0.5652652978897095, 0.5614327192306519, 0.5549547076225281, 0.5569765567779541, 0.5562776327133179, 0.5523861646652222, 0.5497830510139465, 0.5464956164360046, 0.5458754897117615, 0.5479674339294434, 0.5425612330436707, 0.5361561179161072, 0.5360158681869507, 0.5323760509490967, 0.5364646315574646, 0.5257007479667664, 0.5292580723762512, 0.527156412601471, 0.5174773335456848, 0.526935338973999, 0.5179399251937866], 'accuracy': [0.48940569162368774, 0.5196382403373718, 0.5493540167808533, 0.5439276695251465, 0.5571059584617615, 0.5581395626068115, 0.5581395626068115, 0.5604650974273682, 0.5645994544029236, 0.565116286277771, 0.5695090293884277, 0.5689922571182251, 0.5720930099487305, 0.578294575214386, 0.5860465168952942, 0.5886304974555969, 0.5935400724411011, 0.5992248058319092, 0.6064599752426147, 0.6098191142082214, 0.60749351978302, 0.6116279363632202, 0.6087855100631714, 0.6167958378791809, 0.6196382641792297, 0.6165374517440796, 0.616020679473877, 0.6242893934249878, 0.6227390170097351, 0.6276485919952393, 0.6291989684104919, 0.631007730960846, 0.6328165531158447, 0.6338501572608948, 0.6294573545455933, 0.6374676823616028, 0.6431524753570557, 0.6421188712120056, 0.6470284461975098, 0.6465116143226624, 0.6465116143226624, 0.6509044170379639, 0.6498708128929138, 0.6475452184677124, 0.6573643684387207, 0.6540051698684692, 0.6617571115493774, 0.6602067351341248, 0.6625322699546814, 0.6674418449401855, 0.6651162505149841, 0.6684754490852356, 0.6733850240707397, 0.6723514199256897, 0.6744186282157898, 0.6793281435966492, 0.6736434102058411, 0.6832041144371033, 0.6801033616065979, 0.6808785796165466, 0.6852713227272034, 0.686821699142456, 0.6852713227272034, 0.6816537380218506, 0.6930232644081116, 0.6886304616928101, 0.6901808977127075, 0.7015503644943237, 0.6956072449684143, 0.7007752060890198, 0.7054263353347778, 0.7054263353347778, 0.698966383934021, 0.7020671963691711, 0.7069767713546753, 0.7121447324752808, 0.708527147769928, 0.711369514465332, 0.7074935436248779, 0.7167958617210388, 0.7165374755859375, 0.7201550602912903, 0.7180878520011902, 0.7144702672958374, 0.7201550602912903, 0.722739040851593, 0.7281653881072998, 0.7268733978271484, 0.7284237742424011, 0.7299741506576538, 0.7356589436531067, 0.7351421117782593, 0.7328165173530579, 0.7385013103485107, 0.7379844784736633, 0.7385013103485107, 0.7410852909088135, 0.7488372325897217, 0.7372093200683594, 0.7452196478843689], 'val_loss': [0.6931557655334473, 0.6931708455085754, 0.6931799054145813, 0.6931884288787842, 0.6932085752487183, 0.6932220458984375, 0.6931994557380676, 0.6931911706924438, 0.693152129650116, 0.693078875541687, 0.6929194331169128, 0.6927057504653931, 0.6923711895942688, 0.6918832063674927, 0.6910259127616882, 0.6898585557937622, 0.6882914900779724, 0.6860783696174622, 0.6835152506828308, 0.6809173822402954, 0.6784425377845764, 0.6756296157836914, 0.6759384870529175, 0.6719053387641907, 0.6702843904495239, 0.6697381734848022, 0.6682208180427551, 0.6691153049468994, 0.667441725730896, 0.6673579216003418, 0.6679871678352356, 0.6662648916244507, 0.6669922471046448, 0.6672870516777039, 0.6698125600814819, 0.667378306388855, 0.6694531440734863, 0.6680268049240112, 0.6696721315383911, 0.670055627822876, 0.6701230406761169, 0.6708378791809082, 0.6708555817604065, 0.6708666682243347, 0.6739286184310913, 0.6702280044555664, 0.6718493103981018, 0.6737735271453857, 0.6744354367256165, 0.6753626465797424, 0.6734337210655212, 0.675553560256958, 0.6767642498016357, 0.6784210205078125, 0.6779741644859314, 0.6789875030517578, 0.6784663200378418, 0.6795422434806824, 0.6777183413505554, 0.6804601550102234, 0.6804158687591553, 0.6834629774093628, 0.6882509589195251, 0.6820089817047119, 0.6898183822631836, 0.6846070885658264, 0.6858648061752319, 0.6870737671852112, 0.6926348805427551, 0.6897402405738831, 0.6895133256912231, 0.6909841299057007, 0.6887585520744324, 0.6920440793037415, 0.7016503214836121, 0.6980374455451965, 0.6934981346130371, 0.6934084892272949, 0.7109172940254211, 0.6990508437156677, 0.701134443283081, 0.7037042379379272, 0.7113386988639832, 0.7048701643943787, 0.7052393555641174, 0.7137653231620789, 0.7105758786201477, 0.7147558331489563, 0.7137988209724426, 0.7229669094085693, 0.723797619342804, 0.7166815400123596, 0.7172884941101074, 0.7163973450660706, 0.7311168313026428, 0.7207586169242859, 0.7242476344108582, 0.7271474003791809, 0.7666509747505188, 0.7286452054977417], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.4876033067703247, 0.48966941237449646, 0.48243802785873413, 0.47727271914482117, 0.4834710657596588, 0.48966941237449646, 0.49793389439582825, 0.5041322112083435, 0.5051652789115906, 0.5154958963394165, 0.5185950398445129, 0.567148745059967, 0.5733470916748047, 0.5743801593780518, 0.5888429880142212, 0.5909090638160706, 0.5878099203109741, 0.58574378490448, 0.5940082669258118, 0.5826446413993835, 0.5878099203109741, 0.5888429880142212, 0.5898760557174683, 0.5909090638160706, 0.5981404781341553, 0.5909090638160706, 0.5909090638160706, 0.5878099203109741, 0.5960744023323059, 0.5929751992225647, 0.5929751992225647, 0.5940082669258118, 0.5960744023323059, 0.5898760557174683, 0.5919421315193176, 0.5940082669258118, 0.5940082669258118, 0.5981404781341553, 0.5991735458374023, 0.6002066135406494, 0.6043388247489929, 0.5888429880142212, 0.5950413346290588, 0.5960744023323059, 0.5950413346290588, 0.5929751992225647, 0.5971074104309082, 0.5919421315193176, 0.5919421315193176, 0.5971074104309082, 0.5991735458374023, 0.5960744023323059, 0.5909090638160706, 0.5909090638160706, 0.5981404781341553, 0.5960744023323059, 0.5940082669258118, 0.5960744023323059, 0.5898760557174683, 0.5960744023323059, 0.6002066135406494, 0.5909090638160706, 0.6043388247489929, 0.5991735458374023, 0.5981404781341553, 0.5940082669258118, 0.6033057570457458, 0.60537189245224, 0.5971074104309082, 0.6115702390670776, 0.6043388247489929, 0.5898760557174683, 0.5940082669258118, 0.6084710955619812, 0.6012396812438965, 0.5919421315193176, 0.6022727489471436, 0.6012396812438965, 0.6022727489471436, 0.6012396812438965, 0.6002066135406494, 0.6012396812438965, 0.5888429880142212, 0.6012396812438965, 0.6064049601554871, 0.5960744023323059, 0.6043388247489929, 0.586776852607727, 0.6064049601554871, 0.60537189245224, 0.60537189245224, 0.5971074104309082, 0.6043388247489929, 0.6002066135406494, 0.6074380278587341, 0.5971074104309082, 0.6022727489471436]}\n","32/32 [==============================] - 1s 8ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 8s 52ms/step - loss: 0.6265 - accuracy: 0.6668 - val_loss: 0.6920 - val_accuracy: 0.4881\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 2/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6062 - accuracy: 0.6934 - val_loss: 0.6944 - val_accuracy: 0.4881\n","Epoch 3/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6045 - accuracy: 0.6929 - val_loss: 0.6943 - val_accuracy: 0.4892\n","Epoch 4/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5959 - accuracy: 0.7004 - val_loss: 0.6907 - val_accuracy: 0.4946\n","Epoch 5/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5930 - accuracy: 0.6985 - val_loss: 0.6896 - val_accuracy: 0.4978\n","Epoch 6/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5920 - accuracy: 0.7004 - val_loss: 0.6868 - val_accuracy: 0.5097\n","Epoch 7/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5869 - accuracy: 0.7055 - val_loss: 0.6865 - val_accuracy: 0.5119\n","Epoch 8/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5840 - accuracy: 0.7066 - val_loss: 0.6854 - val_accuracy: 0.5097\n","Epoch 9/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5815 - accuracy: 0.7023 - val_loss: 0.6843 - val_accuracy: 0.5183\n","Epoch 10/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5816 - accuracy: 0.7045 - val_loss: 0.6790 - val_accuracy: 0.5323\n","Epoch 11/100\n","29/29 [==============================] - 1s 37ms/step - loss: 0.5729 - accuracy: 0.7082 - val_loss: 0.6741 - val_accuracy: 0.5474\n","Epoch 12/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5737 - accuracy: 0.7096 - val_loss: 0.6686 - val_accuracy: 0.5722\n","Epoch 13/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5703 - accuracy: 0.7144 - val_loss: 0.6592 - val_accuracy: 0.6196\n","Epoch 14/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.5636 - accuracy: 0.7190 - val_loss: 0.6552 - val_accuracy: 0.6218\n","Epoch 15/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5608 - accuracy: 0.7209 - val_loss: 0.6573 - val_accuracy: 0.6002\n","Epoch 16/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5589 - accuracy: 0.7166 - val_loss: 0.6490 - val_accuracy: 0.6175\n","Epoch 17/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.5572 - accuracy: 0.7209 - val_loss: 0.6409 - val_accuracy: 0.6282\n","Epoch 18/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5572 - accuracy: 0.7228 - val_loss: 0.6349 - val_accuracy: 0.6282\n","Epoch 19/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5495 - accuracy: 0.7290 - val_loss: 0.6346 - val_accuracy: 0.6282\n","Epoch 20/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5502 - accuracy: 0.7303 - val_loss: 0.6334 - val_accuracy: 0.6315\n","Epoch 21/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5469 - accuracy: 0.7365 - val_loss: 0.6329 - val_accuracy: 0.6293\n","Epoch 22/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5488 - accuracy: 0.7241 - val_loss: 0.6328 - val_accuracy: 0.6358\n","Epoch 23/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5435 - accuracy: 0.7336 - val_loss: 0.6240 - val_accuracy: 0.6670\n","Epoch 24/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5401 - accuracy: 0.7322 - val_loss: 0.6293 - val_accuracy: 0.6638\n","Epoch 25/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5352 - accuracy: 0.7395 - val_loss: 0.6305 - val_accuracy: 0.6573\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5346 - accuracy: 0.7376 - val_loss: 0.6395 - val_accuracy: 0.6584\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5330 - accuracy: 0.7433 - val_loss: 0.6351 - val_accuracy: 0.6649\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5317 - accuracy: 0.7414 - val_loss: 0.6411 - val_accuracy: 0.6595\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5298 - accuracy: 0.7419 - val_loss: 0.6420 - val_accuracy: 0.6670\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5302 - accuracy: 0.7443 - val_loss: 0.6772 - val_accuracy: 0.6466\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5264 - accuracy: 0.7398 - val_loss: 0.6591 - val_accuracy: 0.6519\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5186 - accuracy: 0.7546 - val_loss: 0.6468 - val_accuracy: 0.6606\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5149 - accuracy: 0.7565 - val_loss: 0.6462 - val_accuracy: 0.6627\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5179 - accuracy: 0.7508 - val_loss: 0.6590 - val_accuracy: 0.6595\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5191 - accuracy: 0.7492 - val_loss: 0.6500 - val_accuracy: 0.6562\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5091 - accuracy: 0.7610 - val_loss: 0.6627 - val_accuracy: 0.6595\n","Epoch 37/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5153 - accuracy: 0.7575 - val_loss: 0.6672 - val_accuracy: 0.6692\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5095 - accuracy: 0.7567 - val_loss: 0.6519 - val_accuracy: 0.6541\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5048 - accuracy: 0.7584 - val_loss: 0.6550 - val_accuracy: 0.6659\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5064 - accuracy: 0.7543 - val_loss: 0.6584 - val_accuracy: 0.6616\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5035 - accuracy: 0.7592 - val_loss: 0.6556 - val_accuracy: 0.6584\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4914 - accuracy: 0.7705 - val_loss: 0.6673 - val_accuracy: 0.6649\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4904 - accuracy: 0.7675 - val_loss: 0.6640 - val_accuracy: 0.6573\n","Epoch 44/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4909 - accuracy: 0.7718 - val_loss: 0.6694 - val_accuracy: 0.6562\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4945 - accuracy: 0.7732 - val_loss: 0.6715 - val_accuracy: 0.6627\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4893 - accuracy: 0.7702 - val_loss: 0.6865 - val_accuracy: 0.6659\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4826 - accuracy: 0.7699 - val_loss: 0.6760 - val_accuracy: 0.6659\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4792 - accuracy: 0.7751 - val_loss: 0.6817 - val_accuracy: 0.6627\n","Epoch 49/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4817 - accuracy: 0.7783 - val_loss: 0.6731 - val_accuracy: 0.6670\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4734 - accuracy: 0.7794 - val_loss: 0.6860 - val_accuracy: 0.6638\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4684 - accuracy: 0.7872 - val_loss: 0.6947 - val_accuracy: 0.6659\n","Epoch 52/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4678 - accuracy: 0.7853 - val_loss: 0.6811 - val_accuracy: 0.6659\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4720 - accuracy: 0.7807 - val_loss: 0.6867 - val_accuracy: 0.6681\n","Epoch 54/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4740 - accuracy: 0.7707 - val_loss: 0.6860 - val_accuracy: 0.6681\n","Epoch 55/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4659 - accuracy: 0.7848 - val_loss: 0.6856 - val_accuracy: 0.6703\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4591 - accuracy: 0.7920 - val_loss: 0.7045 - val_accuracy: 0.6595\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4592 - accuracy: 0.7877 - val_loss: 0.7188 - val_accuracy: 0.6595\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4595 - accuracy: 0.7831 - val_loss: 0.7388 - val_accuracy: 0.6638\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4545 - accuracy: 0.7877 - val_loss: 0.7115 - val_accuracy: 0.6638\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4509 - accuracy: 0.7985 - val_loss: 0.7044 - val_accuracy: 0.6638\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4502 - accuracy: 0.7928 - val_loss: 0.7105 - val_accuracy: 0.6595\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4494 - accuracy: 0.8001 - val_loss: 0.7065 - val_accuracy: 0.6670\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4478 - accuracy: 0.7939 - val_loss: 0.7107 - val_accuracy: 0.6595\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4345 - accuracy: 0.8017 - val_loss: 0.7095 - val_accuracy: 0.6692\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4416 - accuracy: 0.7993 - val_loss: 0.7585 - val_accuracy: 0.6595\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4398 - accuracy: 0.7966 - val_loss: 0.7329 - val_accuracy: 0.6627\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4318 - accuracy: 0.8068 - val_loss: 0.7315 - val_accuracy: 0.6616\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4307 - accuracy: 0.8066 - val_loss: 0.7218 - val_accuracy: 0.6659\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4338 - accuracy: 0.7958 - val_loss: 0.7319 - val_accuracy: 0.6670\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4281 - accuracy: 0.8074 - val_loss: 0.7328 - val_accuracy: 0.6627\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4276 - accuracy: 0.8012 - val_loss: 0.7212 - val_accuracy: 0.6659\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4179 - accuracy: 0.8136 - val_loss: 0.7422 - val_accuracy: 0.6509\n","Epoch 73/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4178 - accuracy: 0.8120 - val_loss: 0.7363 - val_accuracy: 0.6681\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4110 - accuracy: 0.8173 - val_loss: 0.7501 - val_accuracy: 0.6659\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4104 - accuracy: 0.8227 - val_loss: 0.7448 - val_accuracy: 0.6627\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4071 - accuracy: 0.8238 - val_loss: 0.7587 - val_accuracy: 0.6638\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4073 - accuracy: 0.8165 - val_loss: 0.7507 - val_accuracy: 0.6659\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4085 - accuracy: 0.8222 - val_loss: 0.7689 - val_accuracy: 0.6584\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4017 - accuracy: 0.8265 - val_loss: 0.7646 - val_accuracy: 0.6595\n","Epoch 80/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3934 - accuracy: 0.8241 - val_loss: 0.7773 - val_accuracy: 0.6670\n","Epoch 81/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3921 - accuracy: 0.8265 - val_loss: 0.7764 - val_accuracy: 0.6735\n","Epoch 82/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3928 - accuracy: 0.8260 - val_loss: 0.7659 - val_accuracy: 0.6681\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3984 - accuracy: 0.8252 - val_loss: 0.8010 - val_accuracy: 0.6562\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3944 - accuracy: 0.8252 - val_loss: 0.7745 - val_accuracy: 0.6713\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3888 - accuracy: 0.8270 - val_loss: 0.7801 - val_accuracy: 0.6692\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3829 - accuracy: 0.8324 - val_loss: 0.7828 - val_accuracy: 0.6595\n","Epoch 87/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3769 - accuracy: 0.8421 - val_loss: 0.7846 - val_accuracy: 0.6767\n","Epoch 88/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3784 - accuracy: 0.8400 - val_loss: 0.7903 - val_accuracy: 0.6616\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3724 - accuracy: 0.8362 - val_loss: 0.8037 - val_accuracy: 0.6606\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3673 - accuracy: 0.8378 - val_loss: 0.8028 - val_accuracy: 0.6638\n","Epoch 91/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3656 - accuracy: 0.8394 - val_loss: 0.8057 - val_accuracy: 0.6800\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3636 - accuracy: 0.8429 - val_loss: 0.8163 - val_accuracy: 0.6552\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3633 - accuracy: 0.8413 - val_loss: 0.8368 - val_accuracy: 0.6649\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3645 - accuracy: 0.8446 - val_loss: 0.8225 - val_accuracy: 0.6703\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3565 - accuracy: 0.8454 - val_loss: 0.8561 - val_accuracy: 0.6412\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3550 - accuracy: 0.8489 - val_loss: 0.8455 - val_accuracy: 0.6552\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3569 - accuracy: 0.8481 - val_loss: 0.8436 - val_accuracy: 0.6681\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3490 - accuracy: 0.8475 - val_loss: 0.8681 - val_accuracy: 0.6627\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3560 - accuracy: 0.8440 - val_loss: 0.8545 - val_accuracy: 0.6606\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3470 - accuracy: 0.8518 - val_loss: 0.8746 - val_accuracy: 0.6562\n","{'loss': [0.6265066266059875, 0.6062495708465576, 0.6045356392860413, 0.5958934426307678, 0.5930313467979431, 0.5920318365097046, 0.5869399905204773, 0.5839885473251343, 0.5815020799636841, 0.5815652012825012, 0.5728790760040283, 0.5737470388412476, 0.5702602863311768, 0.5636487603187561, 0.5608029365539551, 0.5589309334754944, 0.5572370886802673, 0.5572407245635986, 0.5495371222496033, 0.5502104759216309, 0.5469138026237488, 0.5488475561141968, 0.543488621711731, 0.5400911569595337, 0.5351586937904358, 0.5346256494522095, 0.5329803228378296, 0.531732439994812, 0.5297906398773193, 0.5302290320396423, 0.5263843536376953, 0.5185994505882263, 0.5148533582687378, 0.5179370641708374, 0.5190845727920532, 0.509084939956665, 0.5153337121009827, 0.5095270276069641, 0.5047684907913208, 0.5063824653625488, 0.5035056471824646, 0.49141332507133484, 0.4903745651245117, 0.49094754457473755, 0.4944913983345032, 0.4893089532852173, 0.48257002234458923, 0.4792012870311737, 0.48165205121040344, 0.47344493865966797, 0.4684450626373291, 0.4678363502025604, 0.4719521701335907, 0.4739530086517334, 0.46592339873313904, 0.4591384530067444, 0.4592287838459015, 0.4595186114311218, 0.4545060098171234, 0.45087626576423645, 0.4501720368862152, 0.4493980407714844, 0.44780999422073364, 0.4344978332519531, 0.441633015871048, 0.4397673010826111, 0.4317691922187805, 0.4307321012020111, 0.4337765872478485, 0.42813873291015625, 0.4276169538497925, 0.4179338216781616, 0.4178159236907959, 0.4110424518585205, 0.41035646200180054, 0.40713921189308167, 0.4072549641132355, 0.4084802269935608, 0.40169838070869446, 0.3933679461479187, 0.3921054005622864, 0.392798513174057, 0.3983692526817322, 0.39441418647766113, 0.3887571394443512, 0.3828796148300171, 0.3768872618675232, 0.3783969283103943, 0.37237417697906494, 0.36726710200309753, 0.36562657356262207, 0.3635973334312439, 0.36331236362457275, 0.36448729038238525, 0.3565244972705841, 0.3549848794937134, 0.35693150758743286, 0.3489864468574524, 0.35596245527267456, 0.3470030725002289], 'accuracy': [0.6667564511299133, 0.6934267282485962, 0.6928879022598267, 0.7004310488700867, 0.6985452771186829, 0.7004310488700867, 0.7055495977401733, 0.7066271305084229, 0.7023168206214905, 0.704472005367279, 0.7082435488700867, 0.709590494632721, 0.7144396305084229, 0.7190194129943848, 0.7209051847457886, 0.7165948152542114, 0.7209051847457886, 0.7227909564971924, 0.7289870977401733, 0.7303340435028076, 0.7365301847457886, 0.7241379022598267, 0.7335668206214905, 0.7322198152542114, 0.7394935488700867, 0.7376077771186829, 0.7432650923728943, 0.7413793206214905, 0.7419180870056152, 0.7443426847457886, 0.7397629022598267, 0.7545797228813171, 0.756465494632721, 0.7508081793785095, 0.7491918206214905, 0.7610452771186829, 0.7575430870056152, 0.7567349076271057, 0.7583512663841248, 0.7543103694915771, 0.759159505367279, 0.7704741358757019, 0.7675107717514038, 0.771821141242981, 0.7731680870056152, 0.7702047228813171, 0.7699353694915771, 0.775053858757019, 0.7782866358757019, 0.7793642282485962, 0.7871767282485962, 0.7852909564971924, 0.7807112336158752, 0.7707435488700867, 0.7847521305084229, 0.7920258641242981, 0.787715494632721, 0.7831357717514038, 0.787715494632721, 0.798491358757019, 0.7928340435028076, 0.8001077771186829, 0.7939116358757019, 0.8017241358757019, 0.7992995977401733, 0.7966055870056152, 0.8068426847457886, 0.8065732717514038, 0.7957974076271057, 0.8073814511299133, 0.8011853694915771, 0.8135775923728943, 0.8119612336158752, 0.8173491358757019, 0.8227370977401733, 0.8238146305084229, 0.8165409564971924, 0.8221982717514038, 0.826508641242981, 0.8240840435028076, 0.826508641242981, 0.8259698152542114, 0.8251616358757019, 0.8251616358757019, 0.8270474076271057, 0.8324353694915771, 0.842133641242981, 0.8399784564971924, 0.8362069129943848, 0.8378232717514038, 0.8394396305084229, 0.8429418206214905, 0.8413254022598267, 0.8445581793785095, 0.845366358757019, 0.8488685488700867, 0.8480603694915771, 0.8475215435028076, 0.8440194129943848, 0.8518319129943848], 'val_loss': [0.692007839679718, 0.6943746209144592, 0.6942597031593323, 0.690748929977417, 0.6895832419395447, 0.6867727637290955, 0.6864929795265198, 0.6854474544525146, 0.684285044670105, 0.6790354251861572, 0.6741423606872559, 0.6686116456985474, 0.6592456102371216, 0.6552332639694214, 0.6573437452316284, 0.6489576697349548, 0.6408839821815491, 0.634883463382721, 0.6346439123153687, 0.6333649754524231, 0.632866621017456, 0.6328226923942566, 0.6239876747131348, 0.6292929649353027, 0.6304681897163391, 0.6394915580749512, 0.6350562572479248, 0.6411239504814148, 0.6420366764068604, 0.6771596670150757, 0.6591033339500427, 0.6468110084533691, 0.6461506485939026, 0.6589579582214355, 0.649956226348877, 0.6626555323600769, 0.6671574115753174, 0.6519268751144409, 0.6549661159515381, 0.6583920121192932, 0.6555938720703125, 0.6673051118850708, 0.6640352606773376, 0.6693993210792542, 0.6714733839035034, 0.6864846348762512, 0.6759639382362366, 0.6817338466644287, 0.6731172204017639, 0.685990035533905, 0.6947058439254761, 0.6810861229896545, 0.6866732835769653, 0.685962438583374, 0.6856441497802734, 0.7045270204544067, 0.7187628149986267, 0.7387814521789551, 0.7114906311035156, 0.7044060826301575, 0.7104929089546204, 0.7064990401268005, 0.7107338905334473, 0.7094610333442688, 0.7584577798843384, 0.7328898310661316, 0.7314562797546387, 0.7217662334442139, 0.7319222092628479, 0.732815682888031, 0.7211941480636597, 0.7421507239341736, 0.7362581491470337, 0.7500972747802734, 0.744797945022583, 0.7586735486984253, 0.750659704208374, 0.7689279317855835, 0.7645962238311768, 0.7773482799530029, 0.7763595581054688, 0.7658568024635315, 0.8010167479515076, 0.7745451927185059, 0.7801296710968018, 0.7827867269515991, 0.784591794013977, 0.7903335690498352, 0.8037288784980774, 0.8028261661529541, 0.8056787252426147, 0.8162539005279541, 0.8368052840232849, 0.8224852085113525, 0.8560817837715149, 0.8455447554588318, 0.8436010479927063, 0.8680934906005859, 0.8544673323631287, 0.874626100063324], 'val_accuracy': [0.4881465435028076, 0.4881465435028076, 0.4892241358757019, 0.49461206793785095, 0.4978448152542114, 0.5096982717514038, 0.5118534564971924, 0.5096982717514038, 0.5183189511299133, 0.5323275923728943, 0.5474137663841248, 0.5721982717514038, 0.6196120977401733, 0.6217672228813171, 0.600215494632721, 0.6174569129943848, 0.6282327771186829, 0.6282327771186829, 0.6282327771186829, 0.631465494632721, 0.6293103694915771, 0.6357758641242981, 0.6670258641242981, 0.6637930870056152, 0.6573275923728943, 0.6584051847457886, 0.6648706793785095, 0.6594827771186829, 0.6670258641242981, 0.6465517282485962, 0.6519396305084229, 0.6605603694915771, 0.662715494632721, 0.6594827771186829, 0.65625, 0.6594827771186829, 0.6691810488700867, 0.6540948152542114, 0.6659482717514038, 0.6616379022598267, 0.6584051847457886, 0.6648706793785095, 0.6573275923728943, 0.65625, 0.662715494632721, 0.6659482717514038, 0.6659482717514038, 0.662715494632721, 0.6670258641242981, 0.6637930870056152, 0.6659482717514038, 0.6659482717514038, 0.6681034564971924, 0.6681034564971924, 0.670258641242981, 0.6594827771186829, 0.6594827771186829, 0.6637930870056152, 0.6637930870056152, 0.6637930870056152, 0.6594827771186829, 0.6670258641242981, 0.6594827771186829, 0.6691810488700867, 0.6594827771186829, 0.662715494632721, 0.6616379022598267, 0.6659482717514038, 0.6670258641242981, 0.662715494632721, 0.6659482717514038, 0.6508620977401733, 0.6681034564971924, 0.6659482717514038, 0.662715494632721, 0.6637930870056152, 0.6659482717514038, 0.6584051847457886, 0.6594827771186829, 0.6670258641242981, 0.673491358757019, 0.6681034564971924, 0.65625, 0.6713362336158752, 0.6691810488700867, 0.6594827771186829, 0.6767241358757019, 0.6616379022598267, 0.6605603694915771, 0.6637930870056152, 0.6799569129943848, 0.6551724076271057, 0.6648706793785095, 0.670258641242981, 0.6411637663841248, 0.6551724076271057, 0.6681034564971924, 0.662715494632721, 0.6605603694915771, 0.65625]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.6407 - accuracy: 0.6467"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 7s 71ms/step - loss: 0.6400 - accuracy: 0.6488 - val_loss: 0.6915 - val_accuracy: 0.5011\n","Epoch 2/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6177 - accuracy: 0.6814 - val_loss: 0.6926 - val_accuracy: 0.4966\n","Epoch 3/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.6148 - accuracy: 0.6771 - val_loss: 0.6906 - val_accuracy: 0.5057\n","Epoch 4/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6116 - accuracy: 0.6879 - val_loss: 0.6893 - val_accuracy: 0.5170\n","Epoch 5/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6049 - accuracy: 0.6873 - val_loss: 0.6889 - val_accuracy: 0.5170\n","Epoch 6/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6027 - accuracy: 0.6899 - val_loss: 0.6883 - val_accuracy: 0.5170\n","Epoch 7/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6013 - accuracy: 0.6896 - val_loss: 0.6863 - val_accuracy: 0.5181\n","Epoch 8/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6014 - accuracy: 0.6873 - val_loss: 0.6842 - val_accuracy: 0.5238\n","Epoch 9/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5967 - accuracy: 0.6899 - val_loss: 0.6821 - val_accuracy: 0.5328\n","Epoch 10/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5909 - accuracy: 0.6972 - val_loss: 0.6793 - val_accuracy: 0.5464\n","Epoch 11/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.5895 - accuracy: 0.6998 - val_loss: 0.6747 - val_accuracy: 0.5701\n","Epoch 12/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5885 - accuracy: 0.7046 - val_loss: 0.6722 - val_accuracy: 0.5814\n","Epoch 13/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5852 - accuracy: 0.6995 - val_loss: 0.6682 - val_accuracy: 0.5894\n","Epoch 14/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5843 - accuracy: 0.7006 - val_loss: 0.6649 - val_accuracy: 0.5928\n","Epoch 15/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5845 - accuracy: 0.7029 - val_loss: 0.6632 - val_accuracy: 0.5962\n","Epoch 16/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5807 - accuracy: 0.7071 - val_loss: 0.6598 - val_accuracy: 0.6041\n","Epoch 17/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5777 - accuracy: 0.6984 - val_loss: 0.6570 - val_accuracy: 0.6063\n","Epoch 18/100\n","28/28 [==============================] - 2s 91ms/step - loss: 0.5743 - accuracy: 0.7054 - val_loss: 0.6501 - val_accuracy: 0.6335\n","Epoch 19/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5769 - accuracy: 0.7018 - val_loss: 0.6488 - val_accuracy: 0.6290\n","Epoch 20/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.5715 - accuracy: 0.7091 - val_loss: 0.6474 - val_accuracy: 0.6448\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5711 - accuracy: 0.7074 - val_loss: 0.6436 - val_accuracy: 0.6437\n","Epoch 22/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5673 - accuracy: 0.7199 - val_loss: 0.6405 - val_accuracy: 0.6403\n","Epoch 23/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5682 - accuracy: 0.7094 - val_loss: 0.6389 - val_accuracy: 0.6346\n","Epoch 24/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5600 - accuracy: 0.7184 - val_loss: 0.6387 - val_accuracy: 0.6357\n","Epoch 25/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5600 - accuracy: 0.7199 - val_loss: 0.6465 - val_accuracy: 0.6278\n","Epoch 26/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5605 - accuracy: 0.7156 - val_loss: 0.6402 - val_accuracy: 0.6516\n","Epoch 27/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5603 - accuracy: 0.7148 - val_loss: 0.6413 - val_accuracy: 0.6527\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5510 - accuracy: 0.7182 - val_loss: 0.6424 - val_accuracy: 0.6527\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5560 - accuracy: 0.7210 - val_loss: 0.6445 - val_accuracy: 0.6346\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5540 - accuracy: 0.7286 - val_loss: 0.6490 - val_accuracy: 0.6493\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5463 - accuracy: 0.7264 - val_loss: 0.6511 - val_accuracy: 0.6312\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5454 - accuracy: 0.7298 - val_loss: 0.6504 - val_accuracy: 0.6527\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5382 - accuracy: 0.7354 - val_loss: 0.6533 - val_accuracy: 0.6482\n","Epoch 34/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5411 - accuracy: 0.7411 - val_loss: 0.6504 - val_accuracy: 0.6595\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5353 - accuracy: 0.7414 - val_loss: 0.6538 - val_accuracy: 0.6527\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5367 - accuracy: 0.7315 - val_loss: 0.6691 - val_accuracy: 0.6357\n","Epoch 37/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5321 - accuracy: 0.7411 - val_loss: 0.6558 - val_accuracy: 0.6606\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5283 - accuracy: 0.7465 - val_loss: 0.6592 - val_accuracy: 0.6538\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5285 - accuracy: 0.7434 - val_loss: 0.6689 - val_accuracy: 0.6403\n","Epoch 40/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5252 - accuracy: 0.7439 - val_loss: 0.6630 - val_accuracy: 0.6652\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5211 - accuracy: 0.7470 - val_loss: 0.6668 - val_accuracy: 0.6572\n","Epoch 42/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5228 - accuracy: 0.7470 - val_loss: 0.6652 - val_accuracy: 0.6640\n","Epoch 43/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5153 - accuracy: 0.7496 - val_loss: 0.6681 - val_accuracy: 0.6663\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5149 - accuracy: 0.7476 - val_loss: 0.6735 - val_accuracy: 0.6538\n","Epoch 45/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5069 - accuracy: 0.7507 - val_loss: 0.6681 - val_accuracy: 0.6652\n","Epoch 46/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5089 - accuracy: 0.7535 - val_loss: 0.6673 - val_accuracy: 0.6663\n","Epoch 47/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5093 - accuracy: 0.7530 - val_loss: 0.6805 - val_accuracy: 0.6505\n","Epoch 48/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5076 - accuracy: 0.7598 - val_loss: 0.6706 - val_accuracy: 0.6606\n","Epoch 49/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5040 - accuracy: 0.7524 - val_loss: 0.6768 - val_accuracy: 0.6606\n","Epoch 50/100\n","28/28 [==============================] - 1s 17ms/step - loss: 0.4982 - accuracy: 0.7660 - val_loss: 0.6743 - val_accuracy: 0.6640\n","Epoch 51/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4983 - accuracy: 0.7646 - val_loss: 0.6750 - val_accuracy: 0.6652\n","Epoch 52/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4953 - accuracy: 0.7637 - val_loss: 0.6803 - val_accuracy: 0.6640\n","Epoch 53/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4933 - accuracy: 0.7646 - val_loss: 0.6848 - val_accuracy: 0.6516\n","Epoch 54/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4953 - accuracy: 0.7589 - val_loss: 0.6773 - val_accuracy: 0.6652\n","Epoch 55/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4851 - accuracy: 0.7651 - val_loss: 0.6753 - val_accuracy: 0.6652\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4779 - accuracy: 0.7759 - val_loss: 0.6862 - val_accuracy: 0.6640\n","Epoch 57/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4765 - accuracy: 0.7725 - val_loss: 0.6804 - val_accuracy: 0.6731\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4749 - accuracy: 0.7711 - val_loss: 0.6990 - val_accuracy: 0.6550\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4749 - accuracy: 0.7697 - val_loss: 0.6980 - val_accuracy: 0.6640\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4643 - accuracy: 0.7722 - val_loss: 0.6889 - val_accuracy: 0.6629\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4630 - accuracy: 0.7790 - val_loss: 0.7067 - val_accuracy: 0.6652\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4683 - accuracy: 0.7827 - val_loss: 0.7011 - val_accuracy: 0.6629\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4674 - accuracy: 0.7799 - val_loss: 0.6986 - val_accuracy: 0.6697\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4566 - accuracy: 0.7886 - val_loss: 0.7032 - val_accuracy: 0.6663\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4549 - accuracy: 0.7855 - val_loss: 0.7080 - val_accuracy: 0.6527\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4583 - accuracy: 0.7816 - val_loss: 0.7159 - val_accuracy: 0.6731\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4469 - accuracy: 0.7937 - val_loss: 0.7047 - val_accuracy: 0.6640\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4442 - accuracy: 0.7889 - val_loss: 0.7157 - val_accuracy: 0.6674\n","Epoch 69/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4363 - accuracy: 0.7980 - val_loss: 0.7175 - val_accuracy: 0.6606\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4386 - accuracy: 0.7982 - val_loss: 0.7165 - val_accuracy: 0.6663\n","Epoch 71/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4363 - accuracy: 0.7889 - val_loss: 0.7226 - val_accuracy: 0.6753\n","Epoch 72/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4325 - accuracy: 0.8050 - val_loss: 0.7368 - val_accuracy: 0.6652\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4278 - accuracy: 0.7965 - val_loss: 0.7297 - val_accuracy: 0.6719\n","Epoch 74/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4239 - accuracy: 0.8098 - val_loss: 0.7434 - val_accuracy: 0.6742\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4252 - accuracy: 0.7965 - val_loss: 0.7444 - val_accuracy: 0.6719\n","Epoch 76/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4231 - accuracy: 0.8110 - val_loss: 0.7396 - val_accuracy: 0.6742\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4149 - accuracy: 0.8076 - val_loss: 0.7513 - val_accuracy: 0.6584\n","Epoch 78/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4209 - accuracy: 0.8081 - val_loss: 0.7396 - val_accuracy: 0.6742\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4122 - accuracy: 0.8113 - val_loss: 0.7681 - val_accuracy: 0.6708\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4044 - accuracy: 0.8115 - val_loss: 0.7419 - val_accuracy: 0.6708\n","Epoch 81/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4077 - accuracy: 0.8124 - val_loss: 0.7466 - val_accuracy: 0.6776\n","Epoch 82/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4093 - accuracy: 0.8138 - val_loss: 0.7596 - val_accuracy: 0.6550\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3997 - accuracy: 0.8127 - val_loss: 0.7567 - val_accuracy: 0.6618\n","Epoch 84/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4032 - accuracy: 0.8175 - val_loss: 0.7594 - val_accuracy: 0.6527\n","Epoch 85/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3946 - accuracy: 0.8172 - val_loss: 0.7589 - val_accuracy: 0.6731\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3929 - accuracy: 0.8246 - val_loss: 0.7683 - val_accuracy: 0.6776\n","Epoch 87/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3875 - accuracy: 0.8294 - val_loss: 0.7714 - val_accuracy: 0.6765\n","Epoch 88/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3804 - accuracy: 0.8308 - val_loss: 0.7619 - val_accuracy: 0.6799\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3941 - accuracy: 0.8110 - val_loss: 0.7833 - val_accuracy: 0.6742\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3855 - accuracy: 0.8164 - val_loss: 0.7895 - val_accuracy: 0.6731\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3745 - accuracy: 0.8316 - val_loss: 0.8172 - val_accuracy: 0.6731\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3747 - accuracy: 0.8305 - val_loss: 0.7897 - val_accuracy: 0.6708\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3745 - accuracy: 0.8314 - val_loss: 0.8122 - val_accuracy: 0.6776\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3789 - accuracy: 0.8291 - val_loss: 0.8066 - val_accuracy: 0.6595\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3804 - accuracy: 0.8260 - val_loss: 0.8043 - val_accuracy: 0.6606\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3674 - accuracy: 0.8328 - val_loss: 0.8242 - val_accuracy: 0.6652\n","Epoch 97/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3600 - accuracy: 0.8396 - val_loss: 0.8173 - val_accuracy: 0.6810\n","Epoch 98/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3569 - accuracy: 0.8449 - val_loss: 0.8061 - val_accuracy: 0.6833\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3582 - accuracy: 0.8396 - val_loss: 0.8458 - val_accuracy: 0.6708\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3597 - accuracy: 0.8415 - val_loss: 0.8062 - val_accuracy: 0.6765\n","{'loss': [0.6399994492530823, 0.6176683306694031, 0.6147634387016296, 0.6115797758102417, 0.6049222350120544, 0.6027102470397949, 0.6012803912162781, 0.6014103889465332, 0.596714437007904, 0.5909205675125122, 0.5895431637763977, 0.588527500629425, 0.5851758122444153, 0.584286630153656, 0.5845180153846741, 0.5806965827941895, 0.5776969194412231, 0.5743005871772766, 0.5768733620643616, 0.5715250372886658, 0.5711092948913574, 0.5672570466995239, 0.5682185888290405, 0.5600289702415466, 0.5599516034126282, 0.5605131387710571, 0.5603376030921936, 0.5510439276695251, 0.5559975504875183, 0.5540435910224915, 0.5463394522666931, 0.5453904271125793, 0.5381696224212646, 0.5410882234573364, 0.5352513194084167, 0.5366832613945007, 0.5320661664009094, 0.5282669067382812, 0.5285280346870422, 0.5252171754837036, 0.5211398005485535, 0.5228034257888794, 0.5153498649597168, 0.5149165987968445, 0.506925106048584, 0.508916437625885, 0.5092912316322327, 0.5075944066047668, 0.5040478110313416, 0.49817749857902527, 0.4983481466770172, 0.49530425667762756, 0.49326303601264954, 0.4953018128871918, 0.48514774441719055, 0.47791510820388794, 0.476489782333374, 0.4748902916908264, 0.4749389588832855, 0.4643322825431824, 0.4629933834075928, 0.46834269165992737, 0.4673937261104584, 0.45663443207740784, 0.45488786697387695, 0.4582885801792145, 0.44689372181892395, 0.44419777393341064, 0.4362598955631256, 0.43860378861427307, 0.43627259135246277, 0.43247631192207336, 0.42781147360801697, 0.42393261194229126, 0.42516952753067017, 0.4231140911579132, 0.4149249494075775, 0.42090412974357605, 0.41215014457702637, 0.4043709933757782, 0.4077031910419464, 0.4093174338340759, 0.39971333742141724, 0.40317171812057495, 0.3946102559566498, 0.3929228186607361, 0.38745513558387756, 0.3804248869419098, 0.3941490948200226, 0.3854815661907196, 0.37449920177459717, 0.37465381622314453, 0.37450289726257324, 0.37887412309646606, 0.3804008662700653, 0.36743468046188354, 0.36003807187080383, 0.3568927049636841, 0.3581637144088745, 0.359745591878891], 'accuracy': [0.6488398313522339, 0.6813808679580688, 0.6771363615989685, 0.6878890991210938, 0.6873231530189514, 0.6898698210716248, 0.689586877822876, 0.6873231530189514, 0.6898698210716248, 0.6972269415855408, 0.6997736096382141, 0.7045840620994568, 0.6994906663894653, 0.7006224989891052, 0.7028862237930298, 0.7071307301521301, 0.6983587741851807, 0.7054329514503479, 0.7017543911933899, 0.7091115117073059, 0.7074136734008789, 0.7198641896247864, 0.7093944549560547, 0.7184493541717529, 0.7198641896247864, 0.715619683265686, 0.7147707939147949, 0.7181664109230042, 0.7209960222244263, 0.7286360859870911, 0.7263723611831665, 0.7297679781913757, 0.7354272603988647, 0.7410866022109985, 0.7413695454597473, 0.731465756893158, 0.7410866022109985, 0.7464629411697388, 0.7433503270149231, 0.7439162135124207, 0.7470288872718811, 0.7470288872718811, 0.7495755553245544, 0.7475947737693787, 0.7507073879241943, 0.7535370588302612, 0.7529711127281189, 0.7597622871398926, 0.7524052262306213, 0.7659875750541687, 0.7645727396011353, 0.7637238502502441, 0.7645727396011353, 0.7589133977890015, 0.7651386260986328, 0.7758913636207581, 0.7724957466125488, 0.7710809111595154, 0.7696660757064819, 0.7722128033638, 0.7790039777755737, 0.7826825380325317, 0.7798528671264648, 0.7886247634887695, 0.7855121493339539, 0.7815506458282471, 0.793718159198761, 0.7889077663421631, 0.7979626655578613, 0.7982456088066101, 0.7889077663421631, 0.8050367832183838, 0.7965478301048279, 0.8098471760749817, 0.7965478301048279, 0.8109790682792664, 0.8075834512710571, 0.8081493973731995, 0.8112620115280151, 0.8115450143814087, 0.8123939037322998, 0.8138087391853333, 0.8126768469810486, 0.8174872398376465, 0.8172042965888977, 0.8245614171028137, 0.8293718099594116, 0.8307866454124451, 0.8109790682792664, 0.8163554072380066, 0.8316355347633362, 0.8305037021636963, 0.8313525915145874, 0.8290888667106628, 0.8259762525558472, 0.8327674269676208, 0.8395586013793945, 0.8449349403381348, 0.8395586013793945, 0.8415393233299255], 'val_loss': [0.6915355920791626, 0.6926379203796387, 0.6905765533447266, 0.689339816570282, 0.6889466047286987, 0.6883372068405151, 0.686291515827179, 0.6841553449630737, 0.6820762753486633, 0.6792615056037903, 0.6746991872787476, 0.6721845269203186, 0.6682389974594116, 0.6648776531219482, 0.6632357239723206, 0.6598370671272278, 0.6569506525993347, 0.650126039981842, 0.6488131880760193, 0.6473677754402161, 0.6435782313346863, 0.6405282020568848, 0.6388723850250244, 0.6387377381324768, 0.6465033888816833, 0.6401833295822144, 0.6412706971168518, 0.6424313187599182, 0.6445014476776123, 0.649000883102417, 0.6511418223381042, 0.6504326462745667, 0.6533133387565613, 0.6503959894180298, 0.6537614464759827, 0.6690611839294434, 0.6558013558387756, 0.6591765880584717, 0.6689268350601196, 0.6630271673202515, 0.6667605638504028, 0.6651938557624817, 0.6681485176086426, 0.6734928488731384, 0.6681097149848938, 0.6672839522361755, 0.6804827451705933, 0.670624315738678, 0.6767646074295044, 0.6743056178092957, 0.6750427484512329, 0.6802571415901184, 0.6848258376121521, 0.6773011684417725, 0.6753496527671814, 0.6861769556999207, 0.6804038882255554, 0.6990441083908081, 0.697956919670105, 0.6889111399650574, 0.7067382335662842, 0.7011132836341858, 0.6986056566238403, 0.7032366991043091, 0.7079561948776245, 0.7158892750740051, 0.7047430276870728, 0.7156733274459839, 0.7175266146659851, 0.7165369987487793, 0.7226430773735046, 0.7367620468139648, 0.7296664714813232, 0.7434225678443909, 0.7443816661834717, 0.7395558953285217, 0.7512845396995544, 0.7396206855773926, 0.7681125998497009, 0.7418531775474548, 0.7466056942939758, 0.7596262693405151, 0.7566911578178406, 0.7593790888786316, 0.7588788270950317, 0.7683449983596802, 0.7713561654090881, 0.7619206309318542, 0.7832825183868408, 0.789525032043457, 0.8171945214271545, 0.7896987199783325, 0.8121594190597534, 0.8066385984420776, 0.8042947053909302, 0.8241634964942932, 0.8172747492790222, 0.8061007261276245, 0.8457798957824707, 0.8061937093734741], 'val_accuracy': [0.5011312365531921, 0.49660632014274597, 0.5056561231613159, 0.516968309879303, 0.516968309879303, 0.516968309879303, 0.5180995464324951, 0.523755669593811, 0.5328054428100586, 0.5463801026344299, 0.570135772228241, 0.581447958946228, 0.5893664956092834, 0.5927602052688599, 0.5961538553237915, 0.6040723919868469, 0.6063348650932312, 0.6334841847419739, 0.6289592981338501, 0.6447963714599609, 0.6436651349067688, 0.6402714848518372, 0.6346153616905212, 0.6357465982437134, 0.627828061580658, 0.651583731174469, 0.6527149081230164, 0.6527149081230164, 0.6346153616905212, 0.6493212580680847, 0.6312217116355896, 0.6527149081230164, 0.6481900215148926, 0.6595022678375244, 0.6527149081230164, 0.6357465982437134, 0.6606335043907166, 0.6538461446762085, 0.6402714848518372, 0.6651583909988403, 0.6572397947311401, 0.6640271544456482, 0.6662895679473877, 0.6538461446762085, 0.6651583909988403, 0.6662895679473877, 0.6504524946212769, 0.6606335043907166, 0.6606335043907166, 0.6640271544456482, 0.6651583909988403, 0.6640271544456482, 0.651583731174469, 0.6651583909988403, 0.6651583909988403, 0.6640271544456482, 0.6730769276618958, 0.6549773812294006, 0.6640271544456482, 0.662895917892456, 0.6651583909988403, 0.662895917892456, 0.6696832776069641, 0.6662895679473877, 0.6527149081230164, 0.6730769276618958, 0.6640271544456482, 0.6674208045005798, 0.6606335043907166, 0.6662895679473877, 0.6753393411636353, 0.6651583909988403, 0.6719456911087036, 0.6742081642150879, 0.6719456911087036, 0.6742081642150879, 0.6583710312843323, 0.6742081642150879, 0.6708144545555115, 0.6708144545555115, 0.6776018142700195, 0.6549773812294006, 0.6617646813392639, 0.6527149081230164, 0.6730769276618958, 0.6776018142700195, 0.6764705777168274, 0.679864227771759, 0.6742081642150879, 0.6730769276618958, 0.6730769276618958, 0.6708144545555115, 0.6776018142700195, 0.6595022678375244, 0.6606335043907166, 0.6651583909988403, 0.6809954643249512, 0.6832579374313354, 0.6708144545555115, 0.6764705777168274]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 7s 50ms/step - loss: 0.6363 - accuracy: 0.6550 - val_loss: 0.6922 - val_accuracy: 0.4948\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 2/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6164 - accuracy: 0.6832 - val_loss: 0.6930 - val_accuracy: 0.4948\n","Epoch 3/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6123 - accuracy: 0.6819 - val_loss: 0.6913 - val_accuracy: 0.4979\n","Epoch 4/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6113 - accuracy: 0.6804 - val_loss: 0.6909 - val_accuracy: 0.5000\n","Epoch 5/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6051 - accuracy: 0.6853 - val_loss: 0.6871 - val_accuracy: 0.5227\n","Epoch 6/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6018 - accuracy: 0.6912 - val_loss: 0.6853 - val_accuracy: 0.5227\n","Epoch 7/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5989 - accuracy: 0.6935 - val_loss: 0.6859 - val_accuracy: 0.5207\n","Epoch 8/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5981 - accuracy: 0.6894 - val_loss: 0.6827 - val_accuracy: 0.5227\n","Epoch 9/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5919 - accuracy: 0.6938 - val_loss: 0.6780 - val_accuracy: 0.5548\n","Epoch 10/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5923 - accuracy: 0.6933 - val_loss: 0.6759 - val_accuracy: 0.5558\n","Epoch 11/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5908 - accuracy: 0.6946 - val_loss: 0.6718 - val_accuracy: 0.5713\n","Epoch 12/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5842 - accuracy: 0.7021 - val_loss: 0.6680 - val_accuracy: 0.5816\n","Epoch 13/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5835 - accuracy: 0.6979 - val_loss: 0.6637 - val_accuracy: 0.5909\n","Epoch 14/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5809 - accuracy: 0.7034 - val_loss: 0.6584 - val_accuracy: 0.6188\n","Epoch 15/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5808 - accuracy: 0.7013 - val_loss: 0.6558 - val_accuracy: 0.6198\n","Epoch 16/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5740 - accuracy: 0.7106 - val_loss: 0.6512 - val_accuracy: 0.6219\n","Epoch 17/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5761 - accuracy: 0.7023 - val_loss: 0.6470 - val_accuracy: 0.6312\n","Epoch 18/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5746 - accuracy: 0.7044 - val_loss: 0.6441 - val_accuracy: 0.6312\n","Epoch 19/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5701 - accuracy: 0.7132 - val_loss: 0.6406 - val_accuracy: 0.6240\n","Epoch 20/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5664 - accuracy: 0.7132 - val_loss: 0.6415 - val_accuracy: 0.6260\n","Epoch 21/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5610 - accuracy: 0.7147 - val_loss: 0.6388 - val_accuracy: 0.6384\n","Epoch 22/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5621 - accuracy: 0.7103 - val_loss: 0.6403 - val_accuracy: 0.6384\n","Epoch 23/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5621 - accuracy: 0.7207 - val_loss: 0.6438 - val_accuracy: 0.6281\n","Epoch 24/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5568 - accuracy: 0.7189 - val_loss: 0.6451 - val_accuracy: 0.6364\n","Epoch 25/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5538 - accuracy: 0.7225 - val_loss: 0.6485 - val_accuracy: 0.6229\n","Epoch 26/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5531 - accuracy: 0.7256 - val_loss: 0.6450 - val_accuracy: 0.6343\n","Epoch 27/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5486 - accuracy: 0.7251 - val_loss: 0.6515 - val_accuracy: 0.6364\n","Epoch 28/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5497 - accuracy: 0.7266 - val_loss: 0.6586 - val_accuracy: 0.6281\n","Epoch 29/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5451 - accuracy: 0.7251 - val_loss: 0.6532 - val_accuracy: 0.6353\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5428 - accuracy: 0.7271 - val_loss: 0.6536 - val_accuracy: 0.6353\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5452 - accuracy: 0.7256 - val_loss: 0.6631 - val_accuracy: 0.6322\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5400 - accuracy: 0.7258 - val_loss: 0.6824 - val_accuracy: 0.6271\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5396 - accuracy: 0.7339 - val_loss: 0.6620 - val_accuracy: 0.6312\n","Epoch 34/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5354 - accuracy: 0.7328 - val_loss: 0.6562 - val_accuracy: 0.6322\n","Epoch 35/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5313 - accuracy: 0.7346 - val_loss: 0.6616 - val_accuracy: 0.6364\n","Epoch 36/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5323 - accuracy: 0.7385 - val_loss: 0.6727 - val_accuracy: 0.6271\n","Epoch 37/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5269 - accuracy: 0.7388 - val_loss: 0.6654 - val_accuracy: 0.6384\n","Epoch 38/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5265 - accuracy: 0.7416 - val_loss: 0.6660 - val_accuracy: 0.6384\n","Epoch 39/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5187 - accuracy: 0.7470 - val_loss: 0.6668 - val_accuracy: 0.6395\n","Epoch 40/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5197 - accuracy: 0.7450 - val_loss: 0.6728 - val_accuracy: 0.6446\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5110 - accuracy: 0.7468 - val_loss: 0.6726 - val_accuracy: 0.6322\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5108 - accuracy: 0.7527 - val_loss: 0.6700 - val_accuracy: 0.6405\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5139 - accuracy: 0.7442 - val_loss: 0.6711 - val_accuracy: 0.6343\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5072 - accuracy: 0.7597 - val_loss: 0.6700 - val_accuracy: 0.6333\n","Epoch 45/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5030 - accuracy: 0.7558 - val_loss: 0.6771 - val_accuracy: 0.6477\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4993 - accuracy: 0.7550 - val_loss: 0.6881 - val_accuracy: 0.6333\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5017 - accuracy: 0.7623 - val_loss: 0.6812 - val_accuracy: 0.6384\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4976 - accuracy: 0.7566 - val_loss: 0.6829 - val_accuracy: 0.6415\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4904 - accuracy: 0.7605 - val_loss: 0.6937 - val_accuracy: 0.6415\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4851 - accuracy: 0.7677 - val_loss: 0.6847 - val_accuracy: 0.6364\n","Epoch 51/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4876 - accuracy: 0.7682 - val_loss: 0.6880 - val_accuracy: 0.6498\n","Epoch 52/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4887 - accuracy: 0.7612 - val_loss: 0.6886 - val_accuracy: 0.6550\n","Epoch 53/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4862 - accuracy: 0.7661 - val_loss: 0.6880 - val_accuracy: 0.6426\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4824 - accuracy: 0.7646 - val_loss: 0.6935 - val_accuracy: 0.6426\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4763 - accuracy: 0.7736 - val_loss: 0.6960 - val_accuracy: 0.6426\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4684 - accuracy: 0.7755 - val_loss: 0.7110 - val_accuracy: 0.6271\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4706 - accuracy: 0.7767 - val_loss: 0.7067 - val_accuracy: 0.6384\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4748 - accuracy: 0.7705 - val_loss: 0.7049 - val_accuracy: 0.6333\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4670 - accuracy: 0.7801 - val_loss: 0.7124 - val_accuracy: 0.6343\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4686 - accuracy: 0.7711 - val_loss: 0.6989 - val_accuracy: 0.6333\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4620 - accuracy: 0.7786 - val_loss: 0.7057 - val_accuracy: 0.6488\n","Epoch 62/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4576 - accuracy: 0.7757 - val_loss: 0.7196 - val_accuracy: 0.6436\n","Epoch 63/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4567 - accuracy: 0.7791 - val_loss: 0.7072 - val_accuracy: 0.6436\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4584 - accuracy: 0.7806 - val_loss: 0.7263 - val_accuracy: 0.6457\n","Epoch 65/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4511 - accuracy: 0.7853 - val_loss: 0.7138 - val_accuracy: 0.6374\n","Epoch 66/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4428 - accuracy: 0.7886 - val_loss: 0.7296 - val_accuracy: 0.6384\n","Epoch 67/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4508 - accuracy: 0.7873 - val_loss: 0.7194 - val_accuracy: 0.6581\n","Epoch 68/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4395 - accuracy: 0.7961 - val_loss: 0.7144 - val_accuracy: 0.6384\n","Epoch 69/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4431 - accuracy: 0.7837 - val_loss: 0.7374 - val_accuracy: 0.6591\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4441 - accuracy: 0.7871 - val_loss: 0.7292 - val_accuracy: 0.6426\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4367 - accuracy: 0.7889 - val_loss: 0.7303 - val_accuracy: 0.6436\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4282 - accuracy: 0.7995 - val_loss: 0.7572 - val_accuracy: 0.6322\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4375 - accuracy: 0.7884 - val_loss: 0.7537 - val_accuracy: 0.6374\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4302 - accuracy: 0.7915 - val_loss: 0.7458 - val_accuracy: 0.6312\n","Epoch 75/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4245 - accuracy: 0.8010 - val_loss: 0.7612 - val_accuracy: 0.6415\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4141 - accuracy: 0.8062 - val_loss: 0.7475 - val_accuracy: 0.6395\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4195 - accuracy: 0.8070 - val_loss: 0.7568 - val_accuracy: 0.6405\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4036 - accuracy: 0.8171 - val_loss: 0.7715 - val_accuracy: 0.6333\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4251 - accuracy: 0.7966 - val_loss: 0.7764 - val_accuracy: 0.6364\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4061 - accuracy: 0.8165 - val_loss: 0.7554 - val_accuracy: 0.6436\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3975 - accuracy: 0.8158 - val_loss: 0.7662 - val_accuracy: 0.6467\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4026 - accuracy: 0.8134 - val_loss: 0.7945 - val_accuracy: 0.6395\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4064 - accuracy: 0.8145 - val_loss: 0.7733 - val_accuracy: 0.6426\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3994 - accuracy: 0.8171 - val_loss: 0.7776 - val_accuracy: 0.6477\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3983 - accuracy: 0.8178 - val_loss: 0.7643 - val_accuracy: 0.6426\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3926 - accuracy: 0.8196 - val_loss: 0.7759 - val_accuracy: 0.6467\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3827 - accuracy: 0.8258 - val_loss: 0.8119 - val_accuracy: 0.6343\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3961 - accuracy: 0.8160 - val_loss: 0.8382 - val_accuracy: 0.6364\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3844 - accuracy: 0.8266 - val_loss: 0.7784 - val_accuracy: 0.6415\n","Epoch 90/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3956 - accuracy: 0.8145 - val_loss: 0.7957 - val_accuracy: 0.6601\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3875 - accuracy: 0.8248 - val_loss: 0.7857 - val_accuracy: 0.6519\n","Epoch 92/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3820 - accuracy: 0.8287 - val_loss: 0.7837 - val_accuracy: 0.6488\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3768 - accuracy: 0.8295 - val_loss: 0.8280 - val_accuracy: 0.6446\n","Epoch 94/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3797 - accuracy: 0.8251 - val_loss: 0.8142 - val_accuracy: 0.6415\n","Epoch 95/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3726 - accuracy: 0.8269 - val_loss: 0.7942 - val_accuracy: 0.6529\n","Epoch 96/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3685 - accuracy: 0.8320 - val_loss: 0.7944 - val_accuracy: 0.6488\n","Epoch 97/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3635 - accuracy: 0.8354 - val_loss: 0.8246 - val_accuracy: 0.6395\n","Epoch 98/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3798 - accuracy: 0.8323 - val_loss: 0.8059 - val_accuracy: 0.6560\n","Epoch 99/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3575 - accuracy: 0.8465 - val_loss: 0.8410 - val_accuracy: 0.6457\n","Epoch 100/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3606 - accuracy: 0.8357 - val_loss: 0.8378 - val_accuracy: 0.6415\n","{'loss': [0.6362563967704773, 0.6164079904556274, 0.6122584342956543, 0.6112595796585083, 0.6051081418991089, 0.601802408695221, 0.5989372134208679, 0.5981181859970093, 0.591864287853241, 0.5923210382461548, 0.5907731652259827, 0.5841696858406067, 0.5834753513336182, 0.5808852910995483, 0.5808117985725403, 0.5739741325378418, 0.5760737061500549, 0.5746336579322815, 0.5700671076774597, 0.5663927793502808, 0.5609531402587891, 0.56209796667099, 0.562052309513092, 0.5567587614059448, 0.5537771582603455, 0.5531365275382996, 0.5485754609107971, 0.5497123599052429, 0.5451220870018005, 0.5428463220596313, 0.5451581478118896, 0.5399793386459351, 0.5396116375923157, 0.5354415774345398, 0.5312904715538025, 0.5323417782783508, 0.5268608331680298, 0.5265191197395325, 0.5186558365821838, 0.519672155380249, 0.510998547077179, 0.5108014345169067, 0.5138633847236633, 0.50718092918396, 0.5030147433280945, 0.499313086271286, 0.501660168170929, 0.49761104583740234, 0.49042776226997375, 0.48511993885040283, 0.4876413941383362, 0.4887329638004303, 0.4862237274646759, 0.4823591709136963, 0.47632554173469543, 0.46836528182029724, 0.4705616235733032, 0.4747557044029236, 0.4669613242149353, 0.46856579184532166, 0.46202337741851807, 0.45756644010543823, 0.456705778837204, 0.4583834409713745, 0.45106035470962524, 0.4427899420261383, 0.45078977942466736, 0.4394769072532654, 0.4430818557739258, 0.44412288069725037, 0.43671634793281555, 0.42819327116012573, 0.43747183680534363, 0.43017128109931946, 0.42445454001426697, 0.41407081484794617, 0.4194878935813904, 0.40362417697906494, 0.4251452088356018, 0.40608131885528564, 0.3974935710430145, 0.402627170085907, 0.4064212143421173, 0.39938077330589294, 0.39832445979118347, 0.39257121086120605, 0.38272160291671753, 0.39606973528862, 0.38441964983940125, 0.3956408202648163, 0.3875125050544739, 0.38196614384651184, 0.37675097584724426, 0.37965142726898193, 0.37255001068115234, 0.36854588985443115, 0.3634707033634186, 0.3797825574874878, 0.35749730467796326, 0.3606080710887909], 'accuracy': [0.6550387740135193, 0.6832041144371033, 0.6819121241569519, 0.6803617477416992, 0.6852713227272034, 0.6912144422531128, 0.6935400366783142, 0.6894056797027588, 0.6937984228134155, 0.6932816505432129, 0.6945736408233643, 0.7020671963691711, 0.6979328393936157, 0.7033591866493225, 0.7012919783592224, 0.7105942964553833, 0.7023255825042725, 0.7043927907943726, 0.713178277015686, 0.713178277015686, 0.7147286534309387, 0.710335910320282, 0.7206718325614929, 0.7188630700111389, 0.7224805951118469, 0.7255814075469971, 0.7250645756721497, 0.7266150116920471, 0.7250645756721497, 0.7271317839622498, 0.7255814075469971, 0.7258397936820984, 0.7338501214981079, 0.7328165173530579, 0.7346253395080566, 0.7385013103485107, 0.7387596964836121, 0.7416020631790161, 0.7470284104347229, 0.7449612617492676, 0.7467700242996216, 0.7527132034301758, 0.7441860437393188, 0.7596899271011353, 0.7558139562606812, 0.7550387382507324, 0.762273907661438, 0.7565891742706299, 0.760465145111084, 0.7677002549171448, 0.7682170271873474, 0.7612403035163879, 0.7661498785018921, 0.7645995020866394, 0.773643434047699, 0.775452196598053, 0.7767441868782043, 0.7705426216125488, 0.7801033854484558, 0.7710594534873962, 0.7785529494285583, 0.7757105827331543, 0.7790697813034058, 0.7806201577186584, 0.7852713465690613, 0.788630485534668, 0.7873384952545166, 0.7961240410804749, 0.7837209105491638, 0.7870801091194153, 0.7888888716697693, 0.7994831800460815, 0.7883720993995667, 0.791472852230072, 0.801033616065979, 0.8062015771865845, 0.8069767355918884, 0.817054271697998, 0.7966408133506775, 0.8165374398231506, 0.8157622814178467, 0.8134366869926453, 0.8144702911376953, 0.817054271697998, 0.817829430103302, 0.8196382522583008, 0.8258398175239563, 0.816020667552948, 0.8266149759292603, 0.8144702911376953, 0.8248062133789062, 0.8286821842193604, 0.8294573426246643, 0.8250645995140076, 0.8268733620643616, 0.832041323184967, 0.8354005217552185, 0.8322997689247131, 0.8465116024017334, 0.8356589078903198], 'val_loss': [0.6922377943992615, 0.6930055022239685, 0.6912730932235718, 0.6908525228500366, 0.6871238946914673, 0.685349702835083, 0.6858519315719604, 0.6826992630958557, 0.6779670119285583, 0.675927996635437, 0.6718266606330872, 0.668012261390686, 0.6636552810668945, 0.6584459543228149, 0.6557614207267761, 0.6512062549591064, 0.6469879150390625, 0.6441419124603271, 0.640645444393158, 0.641486644744873, 0.6387688517570496, 0.640264093875885, 0.6437965631484985, 0.6450992226600647, 0.6484547257423401, 0.6450231075286865, 0.6514837741851807, 0.6586180925369263, 0.6532204747200012, 0.6535746455192566, 0.6630861759185791, 0.6824218034744263, 0.6619712710380554, 0.656171441078186, 0.6616395711898804, 0.6727077960968018, 0.6653521060943604, 0.6660425066947937, 0.66676265001297, 0.6727948188781738, 0.6726089715957642, 0.670028030872345, 0.6711018085479736, 0.6699561476707458, 0.6770724058151245, 0.6881088018417358, 0.6811516880989075, 0.6829037070274353, 0.6937347054481506, 0.6846609115600586, 0.6880000233650208, 0.6885713934898376, 0.6879985332489014, 0.6934768557548523, 0.6959858536720276, 0.7110099196434021, 0.7067025303840637, 0.7049476504325867, 0.7123638987541199, 0.6988568305969238, 0.7057130932807922, 0.719601035118103, 0.7072480916976929, 0.7262718081474304, 0.7137834429740906, 0.7295902967453003, 0.7193962335586548, 0.7143508195877075, 0.7373931407928467, 0.7291727066040039, 0.7302618026733398, 0.757210373878479, 0.7537272572517395, 0.7458480596542358, 0.761244535446167, 0.7475224733352661, 0.7567805647850037, 0.7714888453483582, 0.7763760089874268, 0.7554023861885071, 0.7661677002906799, 0.7944985628128052, 0.7733034491539001, 0.777561366558075, 0.7643066644668579, 0.7759363055229187, 0.8118903636932373, 0.8381763696670532, 0.7784271836280823, 0.7957046627998352, 0.7856509685516357, 0.7837408781051636, 0.8279726505279541, 0.8141903877258301, 0.7941970825195312, 0.7944117188453674, 0.8245603442192078, 0.8059380650520325, 0.8409596681594849, 0.8378221392631531], 'val_accuracy': [0.4948347210884094, 0.4948347210884094, 0.49793389439582825, 0.5, 0.5227272510528564, 0.5227272510528564, 0.5206611752510071, 0.5227272510528564, 0.5547520518302917, 0.5557851195335388, 0.5712810158729553, 0.5816115736961365, 0.5909090638160706, 0.6188016533851624, 0.6198347210884094, 0.6219007968902588, 0.6311983466148376, 0.6311983466148376, 0.6239669322967529, 0.6260330677032471, 0.6384297609329224, 0.6384297609329224, 0.6280992031097412, 0.6363636255264282, 0.6229338645935059, 0.6342975497245789, 0.6363636255264282, 0.6280992031097412, 0.6353305578231812, 0.6353305578231812, 0.6322314143180847, 0.6270661354064941, 0.6311983466148376, 0.6322314143180847, 0.6363636255264282, 0.6270661354064941, 0.6384297609329224, 0.6384297609329224, 0.6394628286361694, 0.64462810754776, 0.6322314143180847, 0.6404958963394165, 0.6342975497245789, 0.6332644820213318, 0.6477272510528564, 0.6332644820213318, 0.6384297609329224, 0.6415289044380188, 0.6415289044380188, 0.6363636255264282, 0.6497933864593506, 0.6549586653709412, 0.6425619721412659, 0.6425619721412659, 0.6425619721412659, 0.6270661354064941, 0.6384297609329224, 0.6332644820213318, 0.6342975497245789, 0.6332644820213318, 0.6487603187561035, 0.6435950398445129, 0.6435950398445129, 0.6456611752510071, 0.6373966932296753, 0.6384297609329224, 0.6580578684806824, 0.6384297609329224, 0.6590909361839294, 0.6425619721412659, 0.6435950398445129, 0.6322314143180847, 0.6373966932296753, 0.6311983466148376, 0.6415289044380188, 0.6394628286361694, 0.6404958963394165, 0.6332644820213318, 0.6363636255264282, 0.6435950398445129, 0.6466942429542542, 0.6394628286361694, 0.6425619721412659, 0.6477272510528564, 0.6425619721412659, 0.6466942429542542, 0.6342975497245789, 0.6363636255264282, 0.6415289044380188, 0.6601239442825317, 0.6518595218658447, 0.6487603187561035, 0.64462810754776, 0.6415289044380188, 0.6528925895690918, 0.6487603187561035, 0.6394628286361694, 0.6559917330741882, 0.6456611752510071, 0.6415289044380188]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.4198 - accuracy: 0.8023"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 6s 55ms/step - loss: 0.4198 - accuracy: 0.8023 - val_loss: 0.9013 - val_accuracy: 0.4860\n","Epoch 2/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4125 - accuracy: 0.8147 - val_loss: 0.9065 - val_accuracy: 0.4860\n","Epoch 3/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4096 - accuracy: 0.8103 - val_loss: 0.8812 - val_accuracy: 0.4860\n","Epoch 4/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4008 - accuracy: 0.8206 - val_loss: 0.8959 - val_accuracy: 0.4860\n","Epoch 5/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3955 - accuracy: 0.8171 - val_loss: 0.8726 - val_accuracy: 0.4860\n","Epoch 6/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3920 - accuracy: 0.8187 - val_loss: 0.8812 - val_accuracy: 0.4871\n","Epoch 7/100\n","29/29 [==============================] - 1s 44ms/step - loss: 0.3859 - accuracy: 0.8262 - val_loss: 0.8657 - val_accuracy: 0.4881\n","Epoch 8/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3775 - accuracy: 0.8343 - val_loss: 0.8727 - val_accuracy: 0.4914\n","Epoch 9/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3755 - accuracy: 0.8357 - val_loss: 0.8377 - val_accuracy: 0.4968\n","Epoch 10/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3764 - accuracy: 0.8319 - val_loss: 0.8703 - val_accuracy: 0.4968\n","Epoch 11/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3777 - accuracy: 0.8354 - val_loss: 0.8870 - val_accuracy: 0.4957\n","Epoch 12/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3733 - accuracy: 0.8373 - val_loss: 0.8218 - val_accuracy: 0.5140\n","Epoch 13/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3652 - accuracy: 0.8378 - val_loss: 0.8085 - val_accuracy: 0.5259\n","Epoch 14/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3873 - accuracy: 0.8260 - val_loss: 0.7235 - val_accuracy: 0.5550\n","Epoch 15/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3663 - accuracy: 0.8424 - val_loss: 0.7670 - val_accuracy: 0.5463\n","Epoch 16/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3625 - accuracy: 0.8402 - val_loss: 0.8231 - val_accuracy: 0.5399\n","Epoch 17/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3624 - accuracy: 0.8448 - val_loss: 0.7424 - val_accuracy: 0.5776\n","Epoch 18/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3615 - accuracy: 0.8427 - val_loss: 0.6871 - val_accuracy: 0.6272\n","Epoch 19/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3510 - accuracy: 0.8521 - val_loss: 0.6422 - val_accuracy: 0.6455\n","Epoch 20/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3503 - accuracy: 0.8489 - val_loss: 0.7405 - val_accuracy: 0.6142\n","Epoch 21/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3515 - accuracy: 0.8481 - val_loss: 0.6754 - val_accuracy: 0.6444\n","Epoch 22/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3497 - accuracy: 0.8483 - val_loss: 0.6289 - val_accuracy: 0.6864\n","Epoch 23/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3437 - accuracy: 0.8513 - val_loss: 0.6453 - val_accuracy: 0.6800\n","Epoch 24/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3537 - accuracy: 0.8491 - val_loss: 0.6369 - val_accuracy: 0.6983\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3413 - accuracy: 0.8559 - val_loss: 0.7149 - val_accuracy: 0.6735\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3441 - accuracy: 0.8510 - val_loss: 0.6944 - val_accuracy: 0.6832\n","Epoch 27/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3327 - accuracy: 0.8553 - val_loss: 0.6521 - val_accuracy: 0.7015\n","Epoch 28/100\n","29/29 [==============================] - 1s 39ms/step - loss: 0.3372 - accuracy: 0.8543 - val_loss: 0.6699 - val_accuracy: 0.7295\n","Epoch 29/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3280 - accuracy: 0.8599 - val_loss: 0.6751 - val_accuracy: 0.7252\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3383 - accuracy: 0.8640 - val_loss: 0.6729 - val_accuracy: 0.7231\n","Epoch 31/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3412 - accuracy: 0.8483 - val_loss: 0.6992 - val_accuracy: 0.6961\n","Epoch 32/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3327 - accuracy: 0.8572 - val_loss: 0.7017 - val_accuracy: 0.7177\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3306 - accuracy: 0.8599 - val_loss: 0.7000 - val_accuracy: 0.7198\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3226 - accuracy: 0.8583 - val_loss: 0.6940 - val_accuracy: 0.7241\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3170 - accuracy: 0.8728 - val_loss: 0.6952 - val_accuracy: 0.7295\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3114 - accuracy: 0.8661 - val_loss: 0.7021 - val_accuracy: 0.7220\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3147 - accuracy: 0.8680 - val_loss: 0.7736 - val_accuracy: 0.6950\n","Epoch 38/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3054 - accuracy: 0.8734 - val_loss: 0.7138 - val_accuracy: 0.7220\n","Epoch 39/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3099 - accuracy: 0.8685 - val_loss: 0.7385 - val_accuracy: 0.7080\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3104 - accuracy: 0.8677 - val_loss: 0.7249 - val_accuracy: 0.7015\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3238 - accuracy: 0.8618 - val_loss: 0.7464 - val_accuracy: 0.7047\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3059 - accuracy: 0.8693 - val_loss: 0.7450 - val_accuracy: 0.7274\n","Epoch 43/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2959 - accuracy: 0.8807 - val_loss: 0.7143 - val_accuracy: 0.7166\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2987 - accuracy: 0.8763 - val_loss: 0.7740 - val_accuracy: 0.7155\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2995 - accuracy: 0.8780 - val_loss: 0.7267 - val_accuracy: 0.7198\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2950 - accuracy: 0.8777 - val_loss: 0.7642 - val_accuracy: 0.7144\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2941 - accuracy: 0.8798 - val_loss: 0.7587 - val_accuracy: 0.7198\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2925 - accuracy: 0.8825 - val_loss: 0.7796 - val_accuracy: 0.7177\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2926 - accuracy: 0.8747 - val_loss: 0.7487 - val_accuracy: 0.7155\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2826 - accuracy: 0.8874 - val_loss: 0.7791 - val_accuracy: 0.7155\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2872 - accuracy: 0.8834 - val_loss: 0.7472 - val_accuracy: 0.7188\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2857 - accuracy: 0.8817 - val_loss: 0.7633 - val_accuracy: 0.7123\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2821 - accuracy: 0.8898 - val_loss: 0.7630 - val_accuracy: 0.7112\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2771 - accuracy: 0.8844 - val_loss: 0.7914 - val_accuracy: 0.7144\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2751 - accuracy: 0.8874 - val_loss: 0.7759 - val_accuracy: 0.7080\n","Epoch 56/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2715 - accuracy: 0.8842 - val_loss: 0.7651 - val_accuracy: 0.7274\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2682 - accuracy: 0.8904 - val_loss: 0.8233 - val_accuracy: 0.7047\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2800 - accuracy: 0.8842 - val_loss: 0.8061 - val_accuracy: 0.7209\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2723 - accuracy: 0.8906 - val_loss: 0.8175 - val_accuracy: 0.7241\n","Epoch 60/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2752 - accuracy: 0.8847 - val_loss: 0.8999 - val_accuracy: 0.6950\n","Epoch 61/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2624 - accuracy: 0.8941 - val_loss: 0.8205 - val_accuracy: 0.7188\n","Epoch 62/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2603 - accuracy: 0.8976 - val_loss: 0.8001 - val_accuracy: 0.7166\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2580 - accuracy: 0.8979 - val_loss: 0.8123 - val_accuracy: 0.7134\n","Epoch 64/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2651 - accuracy: 0.8914 - val_loss: 0.9005 - val_accuracy: 0.6918\n","Epoch 65/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2532 - accuracy: 0.8928 - val_loss: 0.8278 - val_accuracy: 0.7166\n","Epoch 66/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2541 - accuracy: 0.8968 - val_loss: 0.8318 - val_accuracy: 0.7047\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2562 - accuracy: 0.8947 - val_loss: 0.8660 - val_accuracy: 0.7101\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2526 - accuracy: 0.8930 - val_loss: 0.8245 - val_accuracy: 0.7188\n","Epoch 69/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2465 - accuracy: 0.8968 - val_loss: 0.8440 - val_accuracy: 0.7101\n","Epoch 70/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2410 - accuracy: 0.9027 - val_loss: 0.8973 - val_accuracy: 0.7091\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2450 - accuracy: 0.9068 - val_loss: 0.8354 - val_accuracy: 0.7155\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2494 - accuracy: 0.9022 - val_loss: 0.9022 - val_accuracy: 0.6853\n","Epoch 73/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2412 - accuracy: 0.9027 - val_loss: 0.8709 - val_accuracy: 0.7080\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2440 - accuracy: 0.9033 - val_loss: 0.9049 - val_accuracy: 0.6929\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2360 - accuracy: 0.9038 - val_loss: 0.8943 - val_accuracy: 0.7134\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2441 - accuracy: 0.8976 - val_loss: 0.9840 - val_accuracy: 0.7026\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2336 - accuracy: 0.8995 - val_loss: 0.8826 - val_accuracy: 0.7177\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2290 - accuracy: 0.9092 - val_loss: 0.8762 - val_accuracy: 0.7069\n","Epoch 79/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2268 - accuracy: 0.9076 - val_loss: 0.8891 - val_accuracy: 0.7166\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2294 - accuracy: 0.9089 - val_loss: 0.9529 - val_accuracy: 0.6972\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2293 - accuracy: 0.9084 - val_loss: 0.8833 - val_accuracy: 0.7155\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2281 - accuracy: 0.9057 - val_loss: 0.9002 - val_accuracy: 0.7155\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2303 - accuracy: 0.9036 - val_loss: 0.9203 - val_accuracy: 0.7015\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2202 - accuracy: 0.9116 - val_loss: 0.9024 - val_accuracy: 0.7177\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2152 - accuracy: 0.9146 - val_loss: 0.9136 - val_accuracy: 0.7177\n","Epoch 86/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2152 - accuracy: 0.9149 - val_loss: 0.9315 - val_accuracy: 0.7155\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2234 - accuracy: 0.9133 - val_loss: 0.9444 - val_accuracy: 0.7058\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2188 - accuracy: 0.9154 - val_loss: 0.9676 - val_accuracy: 0.6983\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2157 - accuracy: 0.9149 - val_loss: 0.9395 - val_accuracy: 0.7112\n","Epoch 90/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2168 - accuracy: 0.9168 - val_loss: 1.0223 - val_accuracy: 0.6929\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2161 - accuracy: 0.9189 - val_loss: 0.9391 - val_accuracy: 0.7004\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2085 - accuracy: 0.9178 - val_loss: 0.9537 - val_accuracy: 0.7091\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2061 - accuracy: 0.9173 - val_loss: 0.9487 - val_accuracy: 0.7026\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2035 - accuracy: 0.9197 - val_loss: 0.9733 - val_accuracy: 0.7123\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2005 - accuracy: 0.9205 - val_loss: 0.9742 - val_accuracy: 0.7047\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2077 - accuracy: 0.9151 - val_loss: 0.9496 - val_accuracy: 0.7252\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1972 - accuracy: 0.9208 - val_loss: 0.9565 - val_accuracy: 0.7069\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1990 - accuracy: 0.9254 - val_loss: 0.9936 - val_accuracy: 0.7134\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2085 - accuracy: 0.9159 - val_loss: 0.9838 - val_accuracy: 0.7198\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2202 - accuracy: 0.9079 - val_loss: 1.0932 - val_accuracy: 0.7026\n","{'loss': [0.4197571575641632, 0.4125313460826874, 0.4096389710903168, 0.4008098542690277, 0.39545750617980957, 0.3919928967952728, 0.3859157860279083, 0.37746259570121765, 0.37548816204071045, 0.3763929605484009, 0.37774789333343506, 0.3733255863189697, 0.365232914686203, 0.387254923582077, 0.36625897884368896, 0.36250683665275574, 0.3623616099357605, 0.36147189140319824, 0.3510052561759949, 0.35026612877845764, 0.3515344262123108, 0.34967654943466187, 0.3436676561832428, 0.3537328541278839, 0.34134674072265625, 0.344053715467453, 0.3326832950115204, 0.337158203125, 0.32804420590400696, 0.33830124139785767, 0.34115153551101685, 0.33274468779563904, 0.33063527941703796, 0.3226384222507477, 0.3169790208339691, 0.3113750219345093, 0.314720094203949, 0.3053576946258545, 0.30989277362823486, 0.31040361523628235, 0.32377535104751587, 0.3059433102607727, 0.2958512604236603, 0.2987438440322876, 0.29945018887519836, 0.2950438857078552, 0.2941383719444275, 0.29251524806022644, 0.29259026050567627, 0.2826297879219055, 0.2871767580509186, 0.28566065430641174, 0.2820586860179901, 0.27712446451187134, 0.27509748935699463, 0.27147504687309265, 0.2681581974029541, 0.2800131142139435, 0.2723414897918701, 0.27520594000816345, 0.26244160532951355, 0.2602732181549072, 0.2579652965068817, 0.26512759923934937, 0.253236323595047, 0.25413039326667786, 0.25619253516197205, 0.25260409712791443, 0.24654197692871094, 0.24101285636425018, 0.24503453075885773, 0.24938467144966125, 0.24117189645767212, 0.24398545920848846, 0.2359851896762848, 0.24411587417125702, 0.23363350331783295, 0.22901126742362976, 0.22682905197143555, 0.22940422594547272, 0.22933869063854218, 0.2280806005001068, 0.23026300966739655, 0.2201915979385376, 0.21518653631210327, 0.21523088216781616, 0.22337689995765686, 0.2188367247581482, 0.2156555950641632, 0.21677443385124207, 0.21613816916942596, 0.20853334665298462, 0.20605942606925964, 0.20345915853977203, 0.20054970681667328, 0.2077094465494156, 0.19720345735549927, 0.19904102385044098, 0.20852604508399963, 0.22015053033828735], 'accuracy': [0.8022629022598267, 0.8146551847457886, 0.8103448152542114, 0.8205819129943848, 0.8170797228813171, 0.818696141242981, 0.8262392282485962, 0.834321141242981, 0.8356680870056152, 0.8318965435028076, 0.8353987336158752, 0.837284505367279, 0.8378232717514038, 0.8259698152542114, 0.842402994632721, 0.8402478694915771, 0.8448275923728943, 0.8426724076271057, 0.8521012663841248, 0.8488685488700867, 0.8480603694915771, 0.8483297228813171, 0.8512930870056152, 0.8491379022598267, 0.8558728694915771, 0.8510237336158752, 0.8553340435028076, 0.8542564511299133, 0.8599137663841248, 0.8639547228813171, 0.8483297228813171, 0.8572198152542114, 0.8599137663841248, 0.8582974076271057, 0.8728448152542114, 0.8661099076271057, 0.8679956793785095, 0.873383641242981, 0.868534505367279, 0.8677262663841248, 0.8617995977401733, 0.8693426847457886, 0.8806573152542114, 0.876347005367279, 0.8779633641242981, 0.8776939511299133, 0.8798491358757019, 0.8825430870056152, 0.8747305870056152, 0.8873922228813171, 0.8833512663841248, 0.8817349076271057, 0.8898168206214905, 0.884428858757019, 0.8873922228813171, 0.884159505367279, 0.8903555870056152, 0.884159505367279, 0.890625, 0.8846982717514038, 0.8941271305084229, 0.8976293206214905, 0.8978987336158752, 0.8914331793785095, 0.8927801847457886, 0.896821141242981, 0.8946659564971924, 0.8930495977401733, 0.896821141242981, 0.9027478694915771, 0.9067887663841248, 0.9022090435028076, 0.9027478694915771, 0.9032866358757019, 0.9038254022598267, 0.8976293206214905, 0.8995150923728943, 0.9092133641242981, 0.907597005367279, 0.9089439511299133, 0.9084051847457886, 0.9057112336158752, 0.9035560488700867, 0.9116379022598267, 0.9146012663841248, 0.9148706793785095, 0.9132543206214905, 0.915409505367279, 0.9148706793785095, 0.9167564511299133, 0.9189116358757019, 0.9178340435028076, 0.9172952771186829, 0.9197198152542114, 0.920527994632721, 0.9151400923728943, 0.9207974076271057, 0.9253771305084229, 0.9159482717514038, 0.907866358757019], 'val_loss': [0.9013411402702332, 0.9064692854881287, 0.8811729550361633, 0.8959383964538574, 0.8725610971450806, 0.8812031149864197, 0.8657440543174744, 0.8727497458457947, 0.8377143740653992, 0.8703304529190063, 0.8870234489440918, 0.821763813495636, 0.8084952235221863, 0.7234623432159424, 0.7670428156852722, 0.8230639696121216, 0.7424390912055969, 0.6870787143707275, 0.6421819925308228, 0.7404854893684387, 0.6753972172737122, 0.6288809180259705, 0.6452608704566956, 0.6369171738624573, 0.71494060754776, 0.694374680519104, 0.6521413326263428, 0.6699159145355225, 0.6750513315200806, 0.6728922724723816, 0.6992347240447998, 0.7017166614532471, 0.7000491619110107, 0.6939664483070374, 0.6951567530632019, 0.7021318078041077, 0.7736391425132751, 0.7137917280197144, 0.7384573817253113, 0.7248591184616089, 0.7463501691818237, 0.7449992895126343, 0.7143019437789917, 0.7740389108657837, 0.7267433404922485, 0.7641791701316833, 0.7587319016456604, 0.7795574069023132, 0.7487489581108093, 0.7791334986686707, 0.7472031116485596, 0.7632648944854736, 0.7630015015602112, 0.7913930416107178, 0.7759353518486023, 0.7651292085647583, 0.8232584595680237, 0.8061252236366272, 0.817504346370697, 0.8999358415603638, 0.8204507231712341, 0.8001437783241272, 0.8122830986976624, 0.9004701972007751, 0.8278051614761353, 0.831797182559967, 0.8659666776657104, 0.824454128742218, 0.8439997434616089, 0.8972530961036682, 0.835350513458252, 0.9021633863449097, 0.8708928823471069, 0.9049146771430969, 0.8943454623222351, 0.9840297698974609, 0.8826291561126709, 0.8761905431747437, 0.8890620470046997, 0.9529234170913696, 0.8832720518112183, 0.9001675844192505, 0.9203177094459534, 0.9023596048355103, 0.9136335253715515, 0.9314815998077393, 0.9444060921669006, 0.9675682187080383, 0.9395429491996765, 1.0223153829574585, 0.9391181468963623, 0.953653872013092, 0.9487073421478271, 0.9733138084411621, 0.9742187261581421, 0.949579656124115, 0.9565243721008301, 0.9936478137969971, 0.9837543964385986, 1.0932461023330688], 'val_accuracy': [0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48706895112991333, 0.4881465435028076, 0.4913793206214905, 0.4967672526836395, 0.4967672526836395, 0.49568966031074524, 0.514008641242981, 0.5258620977401733, 0.5549569129943848, 0.5463362336158752, 0.5398706793785095, 0.5775862336158752, 0.6271551847457886, 0.6454741358757019, 0.6142241358757019, 0.6443965435028076, 0.6864224076271057, 0.6799569129943848, 0.6982758641242981, 0.673491358757019, 0.6831896305084229, 0.701508641242981, 0.7295258641242981, 0.725215494632721, 0.7230603694915771, 0.6961206793785095, 0.7176724076271057, 0.7198275923728943, 0.7241379022598267, 0.7295258641242981, 0.7219827771186829, 0.6950430870056152, 0.7219827771186829, 0.7079741358757019, 0.701508641242981, 0.704741358757019, 0.7273706793785095, 0.7165948152542114, 0.7155172228813171, 0.7198275923728943, 0.7144396305084229, 0.7198275923728943, 0.7176724076271057, 0.7155172228813171, 0.7155172228813171, 0.71875, 0.712284505367279, 0.7112069129943848, 0.7144396305084229, 0.7079741358757019, 0.7273706793785095, 0.704741358757019, 0.7209051847457886, 0.7241379022598267, 0.6950430870056152, 0.71875, 0.7165948152542114, 0.7133620977401733, 0.6918103694915771, 0.7165948152542114, 0.704741358757019, 0.7101293206214905, 0.71875, 0.7101293206214905, 0.7090517282485962, 0.7155172228813171, 0.6853448152542114, 0.7079741358757019, 0.6928879022598267, 0.7133620977401733, 0.7025862336158752, 0.7176724076271057, 0.7068965435028076, 0.7165948152542114, 0.6971982717514038, 0.7155172228813171, 0.7155172228813171, 0.701508641242981, 0.7176724076271057, 0.7176724076271057, 0.7155172228813171, 0.7058189511299133, 0.6982758641242981, 0.7112069129943848, 0.6928879022598267, 0.7004310488700867, 0.7090517282485962, 0.7025862336158752, 0.712284505367279, 0.704741358757019, 0.725215494632721, 0.7068965435028076, 0.7133620977401733, 0.7198275923728943, 0.7025862336158752]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.4359 - accuracy: 0.7909"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 7s 56ms/step - loss: 0.4373 - accuracy: 0.7889 - val_loss: 0.8731 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4245 - accuracy: 0.8039 - val_loss: 0.8527 - val_accuracy: 0.4966\n","Epoch 3/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4217 - accuracy: 0.8045 - val_loss: 0.8587 - val_accuracy: 0.4966\n","Epoch 4/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4169 - accuracy: 0.8045 - val_loss: 0.8616 - val_accuracy: 0.4977\n","Epoch 5/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4139 - accuracy: 0.8087 - val_loss: 0.8584 - val_accuracy: 0.4977\n","Epoch 6/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4058 - accuracy: 0.8096 - val_loss: 0.8402 - val_accuracy: 0.4977\n","Epoch 7/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4038 - accuracy: 0.8132 - val_loss: 0.8400 - val_accuracy: 0.5011\n","Epoch 8/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3991 - accuracy: 0.8189 - val_loss: 0.8539 - val_accuracy: 0.5023\n","Epoch 9/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4138 - accuracy: 0.8152 - val_loss: 0.8308 - val_accuracy: 0.5079\n","Epoch 10/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3978 - accuracy: 0.8206 - val_loss: 0.7933 - val_accuracy: 0.5136\n","Epoch 11/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4068 - accuracy: 0.8149 - val_loss: 0.8162 - val_accuracy: 0.5147\n","Epoch 12/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3883 - accuracy: 0.8226 - val_loss: 0.7759 - val_accuracy: 0.5215\n","Epoch 13/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3857 - accuracy: 0.8271 - val_loss: 0.7956 - val_accuracy: 0.5238\n","Epoch 14/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3844 - accuracy: 0.8280 - val_loss: 0.7396 - val_accuracy: 0.5452\n","Epoch 15/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3800 - accuracy: 0.8260 - val_loss: 0.7422 - val_accuracy: 0.5554\n","Epoch 16/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3755 - accuracy: 0.8291 - val_loss: 0.7205 - val_accuracy: 0.5645\n","Epoch 17/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3746 - accuracy: 0.8359 - val_loss: 0.6796 - val_accuracy: 0.5928\n","Epoch 18/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3769 - accuracy: 0.8274 - val_loss: 0.6645 - val_accuracy: 0.6109\n","Epoch 19/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3692 - accuracy: 0.8322 - val_loss: 0.6151 - val_accuracy: 0.6391\n","Epoch 20/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3706 - accuracy: 0.8362 - val_loss: 0.6002 - val_accuracy: 0.6437\n","Epoch 21/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3588 - accuracy: 0.8390 - val_loss: 0.6532 - val_accuracy: 0.6290\n","Epoch 22/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3610 - accuracy: 0.8410 - val_loss: 0.6221 - val_accuracy: 0.6482\n","Epoch 23/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3627 - accuracy: 0.8359 - val_loss: 0.5606 - val_accuracy: 0.7353\n","Epoch 24/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3680 - accuracy: 0.8413 - val_loss: 0.5627 - val_accuracy: 0.7308\n","Epoch 25/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3549 - accuracy: 0.8435 - val_loss: 0.5700 - val_accuracy: 0.7274\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3495 - accuracy: 0.8486 - val_loss: 0.6106 - val_accuracy: 0.7014\n","Epoch 27/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3485 - accuracy: 0.8523 - val_loss: 0.5782 - val_accuracy: 0.7421\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3494 - accuracy: 0.8449 - val_loss: 0.5908 - val_accuracy: 0.7330\n","Epoch 29/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3479 - accuracy: 0.8483 - val_loss: 0.5838 - val_accuracy: 0.7455\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3403 - accuracy: 0.8506 - val_loss: 0.5979 - val_accuracy: 0.7376\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3455 - accuracy: 0.8483 - val_loss: 0.6049 - val_accuracy: 0.7410\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3360 - accuracy: 0.8526 - val_loss: 0.6010 - val_accuracy: 0.7432\n","Epoch 33/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3455 - accuracy: 0.8466 - val_loss: 0.6082 - val_accuracy: 0.7477\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3341 - accuracy: 0.8546 - val_loss: 0.6224 - val_accuracy: 0.7229\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3409 - accuracy: 0.8497 - val_loss: 0.6152 - val_accuracy: 0.7285\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3437 - accuracy: 0.8506 - val_loss: 0.6049 - val_accuracy: 0.7432\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3451 - accuracy: 0.8506 - val_loss: 0.6362 - val_accuracy: 0.7093\n","Epoch 38/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3348 - accuracy: 0.8520 - val_loss: 0.6213 - val_accuracy: 0.7455\n","Epoch 39/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3213 - accuracy: 0.8662 - val_loss: 0.6268 - val_accuracy: 0.7455\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3377 - accuracy: 0.8577 - val_loss: 0.6271 - val_accuracy: 0.7410\n","Epoch 41/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3243 - accuracy: 0.8588 - val_loss: 0.6234 - val_accuracy: 0.7398\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3176 - accuracy: 0.8611 - val_loss: 0.6387 - val_accuracy: 0.7432\n","Epoch 43/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3106 - accuracy: 0.8690 - val_loss: 0.6598 - val_accuracy: 0.7251\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3183 - accuracy: 0.8551 - val_loss: 0.6367 - val_accuracy: 0.7342\n","Epoch 45/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3106 - accuracy: 0.8642 - val_loss: 0.6513 - val_accuracy: 0.7342\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3143 - accuracy: 0.8613 - val_loss: 0.6672 - val_accuracy: 0.7161\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3107 - accuracy: 0.8704 - val_loss: 0.6881 - val_accuracy: 0.6968\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3072 - accuracy: 0.8735 - val_loss: 0.6600 - val_accuracy: 0.7421\n","Epoch 49/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3028 - accuracy: 0.8715 - val_loss: 0.6479 - val_accuracy: 0.7342\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3026 - accuracy: 0.8724 - val_loss: 0.6416 - val_accuracy: 0.7387\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3041 - accuracy: 0.8681 - val_loss: 0.6576 - val_accuracy: 0.7421\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2962 - accuracy: 0.8735 - val_loss: 0.6607 - val_accuracy: 0.7342\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2967 - accuracy: 0.8718 - val_loss: 0.6889 - val_accuracy: 0.7206\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2918 - accuracy: 0.8735 - val_loss: 0.6738 - val_accuracy: 0.7455\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2878 - accuracy: 0.8783 - val_loss: 0.6690 - val_accuracy: 0.7455\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2853 - accuracy: 0.8843 - val_loss: 0.6972 - val_accuracy: 0.7398\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2905 - accuracy: 0.8778 - val_loss: 0.6917 - val_accuracy: 0.7398\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2823 - accuracy: 0.8837 - val_loss: 0.6805 - val_accuracy: 0.7410\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2802 - accuracy: 0.8851 - val_loss: 0.6799 - val_accuracy: 0.7398\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2755 - accuracy: 0.8837 - val_loss: 0.6836 - val_accuracy: 0.7330\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2776 - accuracy: 0.8868 - val_loss: 0.6968 - val_accuracy: 0.7410\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2746 - accuracy: 0.8905 - val_loss: 0.6960 - val_accuracy: 0.7376\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2810 - accuracy: 0.8814 - val_loss: 0.7093 - val_accuracy: 0.7376\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2727 - accuracy: 0.8851 - val_loss: 0.7229 - val_accuracy: 0.7183\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2737 - accuracy: 0.8879 - val_loss: 0.6954 - val_accuracy: 0.7432\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2669 - accuracy: 0.8888 - val_loss: 0.7186 - val_accuracy: 0.7161\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2740 - accuracy: 0.8857 - val_loss: 0.7110 - val_accuracy: 0.7353\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2668 - accuracy: 0.8922 - val_loss: 0.7043 - val_accuracy: 0.7330\n","Epoch 69/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2671 - accuracy: 0.8899 - val_loss: 0.7079 - val_accuracy: 0.7296\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2526 - accuracy: 0.8970 - val_loss: 0.7036 - val_accuracy: 0.7330\n","Epoch 71/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2569 - accuracy: 0.8964 - val_loss: 0.7169 - val_accuracy: 0.7330\n","Epoch 72/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2581 - accuracy: 0.8916 - val_loss: 0.7618 - val_accuracy: 0.6946\n","Epoch 73/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2545 - accuracy: 0.8976 - val_loss: 0.7159 - val_accuracy: 0.7410\n","Epoch 74/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2534 - accuracy: 0.8976 - val_loss: 0.7204 - val_accuracy: 0.7364\n","Epoch 75/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2427 - accuracy: 0.9032 - val_loss: 0.7361 - val_accuracy: 0.7274\n","Epoch 76/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2600 - accuracy: 0.8984 - val_loss: 0.7411 - val_accuracy: 0.7443\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2555 - accuracy: 0.8964 - val_loss: 0.7395 - val_accuracy: 0.7330\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2493 - accuracy: 0.9015 - val_loss: 0.7580 - val_accuracy: 0.7319\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2504 - accuracy: 0.8973 - val_loss: 0.7731 - val_accuracy: 0.7274\n","Epoch 80/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2383 - accuracy: 0.9032 - val_loss: 0.7668 - val_accuracy: 0.7059\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2563 - accuracy: 0.8984 - val_loss: 0.8163 - val_accuracy: 0.6957\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2636 - accuracy: 0.8995 - val_loss: 0.7899 - val_accuracy: 0.7262\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2291 - accuracy: 0.9097 - val_loss: 0.7937 - val_accuracy: 0.7342\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2440 - accuracy: 0.9018 - val_loss: 0.7825 - val_accuracy: 0.7296\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2473 - accuracy: 0.9004 - val_loss: 0.7603 - val_accuracy: 0.7296\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2289 - accuracy: 0.9123 - val_loss: 0.7856 - val_accuracy: 0.7262\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2322 - accuracy: 0.9027 - val_loss: 0.7949 - val_accuracy: 0.7319\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2302 - accuracy: 0.9092 - val_loss: 0.7852 - val_accuracy: 0.7296\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2239 - accuracy: 0.9137 - val_loss: 0.7941 - val_accuracy: 0.7274\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2385 - accuracy: 0.9012 - val_loss: 0.7858 - val_accuracy: 0.7274\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2184 - accuracy: 0.9145 - val_loss: 0.7994 - val_accuracy: 0.7296\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2109 - accuracy: 0.9177 - val_loss: 0.8032 - val_accuracy: 0.7353\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2261 - accuracy: 0.9072 - val_loss: 0.8115 - val_accuracy: 0.7308\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2279 - accuracy: 0.9083 - val_loss: 0.8261 - val_accuracy: 0.7138\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2140 - accuracy: 0.9140 - val_loss: 0.8199 - val_accuracy: 0.7274\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2122 - accuracy: 0.9168 - val_loss: 0.8053 - val_accuracy: 0.7319\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2039 - accuracy: 0.9202 - val_loss: 0.8164 - val_accuracy: 0.7274\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1950 - accuracy: 0.9253 - val_loss: 0.8175 - val_accuracy: 0.7353\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2056 - accuracy: 0.9208 - val_loss: 0.8292 - val_accuracy: 0.7342\n","Epoch 100/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2137 - accuracy: 0.9177 - val_loss: 0.8748 - val_accuracy: 0.7138\n","{'loss': [0.43734243512153625, 0.4245258867740631, 0.4217202961444855, 0.41690295934677124, 0.41393017768859863, 0.40575742721557617, 0.40379875898361206, 0.39911743998527527, 0.4137769043445587, 0.3978005051612854, 0.40683746337890625, 0.38825902342796326, 0.38574784994125366, 0.38439878821372986, 0.37996354699134827, 0.37550845742225647, 0.37461355328559875, 0.3769446015357971, 0.36924153566360474, 0.3706273138523102, 0.3587605357170105, 0.3610183894634247, 0.3627171814441681, 0.3680100739002228, 0.3548889458179474, 0.3495156168937683, 0.34853395819664, 0.34941086173057556, 0.34794172644615173, 0.3402605950832367, 0.3454705774784088, 0.336034893989563, 0.34553223848342896, 0.33406150341033936, 0.3409081995487213, 0.3437209129333496, 0.34507644176483154, 0.3347592055797577, 0.32126280665397644, 0.3377224802970886, 0.32427313923835754, 0.3175513744354248, 0.31056421995162964, 0.3182525336742401, 0.3105718791484833, 0.31425684690475464, 0.31068113446235657, 0.30721116065979004, 0.30277299880981445, 0.3026260733604431, 0.30411773920059204, 0.296186238527298, 0.2966543138027191, 0.2917688190937042, 0.2878454625606537, 0.28529664874076843, 0.29052844643592834, 0.2822968065738678, 0.2801836431026459, 0.275499165058136, 0.2776041626930237, 0.27463093400001526, 0.2809987962245941, 0.27270010113716125, 0.2737078368663788, 0.26685434579849243, 0.2740474045276642, 0.26682525873184204, 0.26712700724601746, 0.2526423931121826, 0.2568719983100891, 0.2581377923488617, 0.254478394985199, 0.2534281611442566, 0.24268174171447754, 0.25996026396751404, 0.2554980516433716, 0.24934923648834229, 0.25037527084350586, 0.23830294609069824, 0.25630873441696167, 0.26364007592201233, 0.2291322648525238, 0.2439756840467453, 0.24733087420463562, 0.2289121299982071, 0.232223778963089, 0.23024973273277283, 0.22394655644893646, 0.2384748011827469, 0.21840471029281616, 0.21086665987968445, 0.22614827752113342, 0.22789998352527618, 0.21403805911540985, 0.2121981829404831, 0.20390543341636658, 0.1949886679649353, 0.20557965338230133, 0.2136576622724533], 'accuracy': [0.7889077663421631, 0.8039049506187439, 0.8044708371162415, 0.8044708371162415, 0.8087153434753418, 0.8095642328262329, 0.8132427930831909, 0.8189020752906799, 0.8152235150337219, 0.8205999135971069, 0.8149405717849731, 0.8225806355476379, 0.8271080851554871, 0.8279569745063782, 0.8259762525558472, 0.8290888667106628, 0.8358800411224365, 0.8273910880088806, 0.8322014808654785, 0.8361629843711853, 0.8389926552772522, 0.8409733772277832, 0.8358800411224365, 0.8412563800811768, 0.8435201048851013, 0.848613440990448, 0.852292001247406, 0.8449349403381348, 0.8483304977416992, 0.8505942225456238, 0.8483304977416992, 0.8525750041007996, 0.846632719039917, 0.8545557260513306, 0.8497453331947327, 0.8505942225456238, 0.8505942225456238, 0.8520090579986572, 0.8661573529243469, 0.8576683402061462, 0.8588002324104309, 0.8610639572143555, 0.868986964225769, 0.8551216721534729, 0.8641765713691711, 0.8613469004631042, 0.8704017996788025, 0.8735144138336182, 0.8715336918830872, 0.8723825812339783, 0.8681380748748779, 0.8735144138336182, 0.8718166351318359, 0.8735144138336182, 0.8783248662948608, 0.8842670917510986, 0.8777589201927185, 0.8837012052536011, 0.8851160407066345, 0.8837012052536011, 0.8868138194084167, 0.8904923796653748, 0.8814374804496765, 0.8851160407066345, 0.8879456520080566, 0.8887945413589478, 0.8856819272041321, 0.892190158367157, 0.8899264335632324, 0.8970005512237549, 0.8964346647262573, 0.8916242122650146, 0.8975664973258972, 0.8975664973258972, 0.9032257795333862, 0.8984153866767883, 0.8964346647262573, 0.901528000831604, 0.8972835540771484, 0.9032257795333862, 0.8984153866767883, 0.899547278881073, 0.9097340106964111, 0.9018110036849976, 0.9003961682319641, 0.9122806787490845, 0.9026598930358887, 0.9091680645942688, 0.9136955142021179, 0.9012450575828552, 0.914544403553009, 0.9176570177078247, 0.9071873426437378, 0.9083191752433777, 0.9139785170555115, 0.9168081283569336, 0.9202037453651428, 0.9252971410751343, 0.9207696914672852, 0.9176570177078247], 'val_loss': [0.8730950951576233, 0.8527388572692871, 0.8586692214012146, 0.8616299033164978, 0.8584036231040955, 0.8402263522148132, 0.8400071263313293, 0.8539213538169861, 0.8308162093162537, 0.793340802192688, 0.8162018656730652, 0.775870144367218, 0.7955911755561829, 0.7395888566970825, 0.742203950881958, 0.7205325961112976, 0.6796170473098755, 0.6645203828811646, 0.6150695085525513, 0.600186288356781, 0.6532036066055298, 0.6221006512641907, 0.5605822801589966, 0.5626838207244873, 0.5699924230575562, 0.6105577945709229, 0.5782065987586975, 0.5908229351043701, 0.5837929844856262, 0.5978751182556152, 0.6048538684844971, 0.601006269454956, 0.6082204580307007, 0.6223945021629333, 0.6151678562164307, 0.6049134135246277, 0.6362201571464539, 0.621253252029419, 0.6268175840377808, 0.6271010637283325, 0.6233971118927002, 0.6386896371841431, 0.6598423719406128, 0.6366785168647766, 0.6513350605964661, 0.6672405004501343, 0.6880984306335449, 0.659984827041626, 0.6478564143180847, 0.6415599584579468, 0.6576048135757446, 0.660676896572113, 0.6888755559921265, 0.6737624406814575, 0.6690038442611694, 0.6972252130508423, 0.691733717918396, 0.6804502606391907, 0.6799415946006775, 0.6836219429969788, 0.6968065500259399, 0.6960187554359436, 0.7092645764350891, 0.7228976488113403, 0.6953668594360352, 0.7186434864997864, 0.7110271453857422, 0.7042935490608215, 0.7078580260276794, 0.7036439180374146, 0.7168616652488708, 0.7618347406387329, 0.7159457206726074, 0.7203525900840759, 0.7360674142837524, 0.741085410118103, 0.7395021319389343, 0.7580253481864929, 0.7731332778930664, 0.7667942047119141, 0.8163056969642639, 0.7899438738822937, 0.793716549873352, 0.7825013399124146, 0.7603162527084351, 0.7856088280677795, 0.7948719263076782, 0.7852115035057068, 0.7941179871559143, 0.7858359217643738, 0.7993788123130798, 0.8031677603721619, 0.8114915490150452, 0.8260676264762878, 0.8198962807655334, 0.8052605390548706, 0.816433310508728, 0.8175159692764282, 0.829211950302124, 0.8748223781585693], 'val_accuracy': [0.4954751133918762, 0.49660632014274597, 0.49660632014274597, 0.4977375566959381, 0.4977375566959381, 0.4977375566959381, 0.5011312365531921, 0.5022624731063843, 0.5079185366630554, 0.5135746598243713, 0.5147058963775635, 0.5214931964874268, 0.523755669593811, 0.5452488660812378, 0.5554298758506775, 0.564479649066925, 0.5927602052688599, 0.610859751701355, 0.639140248298645, 0.6436651349067688, 0.6289592981338501, 0.6481900215148926, 0.7352941036224365, 0.7307692170143127, 0.7273755669593811, 0.7013574838638306, 0.7420814633369446, 0.733031690120697, 0.7454751133918762, 0.7375565767288208, 0.7409502267837524, 0.7432126402854919, 0.7477375268936157, 0.7228506803512573, 0.7285068035125732, 0.7432126402854919, 0.709276020526886, 0.7454751133918762, 0.7454751133918762, 0.7409502267837524, 0.7398189902305603, 0.7432126402854919, 0.7251130938529968, 0.7341628670692444, 0.7341628670692444, 0.7160633206367493, 0.6968325972557068, 0.7420814633369446, 0.7341628670692444, 0.7386877536773682, 0.7420814633369446, 0.7341628670692444, 0.720588207244873, 0.7454751133918762, 0.7454751133918762, 0.7398189902305603, 0.7398189902305603, 0.7409502267837524, 0.7398189902305603, 0.733031690120697, 0.7409502267837524, 0.7375565767288208, 0.7375565767288208, 0.7183257937431335, 0.7432126402854919, 0.7160633206367493, 0.7352941036224365, 0.733031690120697, 0.7296379804611206, 0.733031690120697, 0.733031690120697, 0.6945701241493225, 0.7409502267837524, 0.7364253401756287, 0.7273755669593811, 0.7443438768386841, 0.733031690120697, 0.7319004535675049, 0.7273755669593811, 0.7058823704719543, 0.6957013607025146, 0.726244330406189, 0.7341628670692444, 0.7296379804611206, 0.7296379804611206, 0.726244330406189, 0.7319004535675049, 0.7296379804611206, 0.7273755669593811, 0.7273755669593811, 0.7296379804611206, 0.7352941036224365, 0.7307692170143127, 0.7138009071350098, 0.7273755669593811, 0.7319004535675049, 0.7273755669593811, 0.7352941036224365, 0.7341628670692444, 0.7138009071350098]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 9s 90ms/step - loss: 0.4506 - accuracy: 0.7868 - val_loss: 0.8818 - val_accuracy: 0.4876\n","Epoch 2/100\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 1s 22ms/step - loss: 0.4274 - accuracy: 0.7982 - val_loss: 0.8518 - val_accuracy: 0.4886\n","Epoch 3/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4239 - accuracy: 0.8016 - val_loss: 0.8588 - val_accuracy: 0.4886\n","Epoch 4/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4205 - accuracy: 0.7987 - val_loss: 0.8645 - val_accuracy: 0.4886\n","Epoch 5/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4106 - accuracy: 0.8145 - val_loss: 0.8728 - val_accuracy: 0.4897\n","Epoch 6/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4112 - accuracy: 0.8088 - val_loss: 0.8729 - val_accuracy: 0.4928\n","Epoch 7/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4015 - accuracy: 0.8150 - val_loss: 0.8699 - val_accuracy: 0.4938\n","Epoch 8/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3936 - accuracy: 0.8176 - val_loss: 0.8581 - val_accuracy: 0.4979\n","Epoch 9/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3990 - accuracy: 0.8173 - val_loss: 0.8429 - val_accuracy: 0.5000\n","Epoch 10/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3985 - accuracy: 0.8191 - val_loss: 0.8394 - val_accuracy: 0.5021\n","Epoch 11/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3896 - accuracy: 0.8238 - val_loss: 0.8290 - val_accuracy: 0.5072\n","Epoch 12/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3962 - accuracy: 0.8160 - val_loss: 0.8134 - val_accuracy: 0.5114\n","Epoch 13/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3899 - accuracy: 0.8235 - val_loss: 0.7797 - val_accuracy: 0.5207\n","Epoch 14/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3850 - accuracy: 0.8230 - val_loss: 0.7348 - val_accuracy: 0.5455\n","Epoch 15/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3878 - accuracy: 0.8217 - val_loss: 0.7726 - val_accuracy: 0.5537\n","Epoch 16/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3845 - accuracy: 0.8225 - val_loss: 0.7307 - val_accuracy: 0.5713\n","Epoch 17/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3809 - accuracy: 0.8233 - val_loss: 0.6464 - val_accuracy: 0.6157\n","Epoch 18/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3721 - accuracy: 0.8315 - val_loss: 0.6687 - val_accuracy: 0.6116\n","Epoch 19/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3682 - accuracy: 0.8364 - val_loss: 0.6661 - val_accuracy: 0.6291\n","Epoch 20/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.3722 - accuracy: 0.8256 - val_loss: 0.6620 - val_accuracy: 0.6343\n","Epoch 21/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.3747 - accuracy: 0.8326 - val_loss: 0.6175 - val_accuracy: 0.6787\n","Epoch 22/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3637 - accuracy: 0.8398 - val_loss: 0.5992 - val_accuracy: 0.6963\n","Epoch 23/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3680 - accuracy: 0.8380 - val_loss: 0.6125 - val_accuracy: 0.6890\n","Epoch 24/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3529 - accuracy: 0.8483 - val_loss: 0.6351 - val_accuracy: 0.6911\n","Epoch 25/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3526 - accuracy: 0.8463 - val_loss: 0.6288 - val_accuracy: 0.7004\n","Epoch 26/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3495 - accuracy: 0.8439 - val_loss: 0.6337 - val_accuracy: 0.7056\n","Epoch 27/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3538 - accuracy: 0.8393 - val_loss: 0.6339 - val_accuracy: 0.7004\n","Epoch 28/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3501 - accuracy: 0.8395 - val_loss: 0.6847 - val_accuracy: 0.6911\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3544 - accuracy: 0.8424 - val_loss: 0.7314 - val_accuracy: 0.6663\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3512 - accuracy: 0.8463 - val_loss: 0.6665 - val_accuracy: 0.7035\n","Epoch 31/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3391 - accuracy: 0.8517 - val_loss: 0.6505 - val_accuracy: 0.7128\n","Epoch 32/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3371 - accuracy: 0.8514 - val_loss: 0.6517 - val_accuracy: 0.7159\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3445 - accuracy: 0.8488 - val_loss: 0.6994 - val_accuracy: 0.7076\n","Epoch 34/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3348 - accuracy: 0.8532 - val_loss: 0.6613 - val_accuracy: 0.7221\n","Epoch 35/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3393 - accuracy: 0.8481 - val_loss: 0.6919 - val_accuracy: 0.7097\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3436 - accuracy: 0.8460 - val_loss: 0.6717 - val_accuracy: 0.7149\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3451 - accuracy: 0.8401 - val_loss: 0.6723 - val_accuracy: 0.7138\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3303 - accuracy: 0.8545 - val_loss: 0.6833 - val_accuracy: 0.7025\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3325 - accuracy: 0.8540 - val_loss: 0.7100 - val_accuracy: 0.6952\n","Epoch 40/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3291 - accuracy: 0.8581 - val_loss: 0.6779 - val_accuracy: 0.7169\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3202 - accuracy: 0.8633 - val_loss: 0.6985 - val_accuracy: 0.7076\n","Epoch 42/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3112 - accuracy: 0.8625 - val_loss: 0.6822 - val_accuracy: 0.7128\n","Epoch 43/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3128 - accuracy: 0.8682 - val_loss: 0.6946 - val_accuracy: 0.7035\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3094 - accuracy: 0.8695 - val_loss: 0.7028 - val_accuracy: 0.7149\n","Epoch 45/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3125 - accuracy: 0.8643 - val_loss: 0.6925 - val_accuracy: 0.7128\n","Epoch 46/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3068 - accuracy: 0.8620 - val_loss: 0.6993 - val_accuracy: 0.7159\n","Epoch 47/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2984 - accuracy: 0.8726 - val_loss: 0.7121 - val_accuracy: 0.7200\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3067 - accuracy: 0.8672 - val_loss: 0.7267 - val_accuracy: 0.7128\n","Epoch 49/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3170 - accuracy: 0.8630 - val_loss: 0.7730 - val_accuracy: 0.6901\n","Epoch 50/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2987 - accuracy: 0.8729 - val_loss: 0.7263 - val_accuracy: 0.7159\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2994 - accuracy: 0.8711 - val_loss: 0.7297 - val_accuracy: 0.7190\n","Epoch 52/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2998 - accuracy: 0.8685 - val_loss: 0.7528 - val_accuracy: 0.7118\n","Epoch 53/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2940 - accuracy: 0.8731 - val_loss: 0.7193 - val_accuracy: 0.7231\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2877 - accuracy: 0.8793 - val_loss: 0.7325 - val_accuracy: 0.7014\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2867 - accuracy: 0.8798 - val_loss: 0.7399 - val_accuracy: 0.7087\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2823 - accuracy: 0.8848 - val_loss: 0.7595 - val_accuracy: 0.7128\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3064 - accuracy: 0.8695 - val_loss: 0.7615 - val_accuracy: 0.7035\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2749 - accuracy: 0.8855 - val_loss: 0.7484 - val_accuracy: 0.7056\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2905 - accuracy: 0.8840 - val_loss: 0.7675 - val_accuracy: 0.7035\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2817 - accuracy: 0.8827 - val_loss: 0.7538 - val_accuracy: 0.6994\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2796 - accuracy: 0.8845 - val_loss: 0.7528 - val_accuracy: 0.7087\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2759 - accuracy: 0.8832 - val_loss: 0.7866 - val_accuracy: 0.7025\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2779 - accuracy: 0.8783 - val_loss: 0.7747 - val_accuracy: 0.7107\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2695 - accuracy: 0.8853 - val_loss: 0.7740 - val_accuracy: 0.7066\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2669 - accuracy: 0.8930 - val_loss: 0.8019 - val_accuracy: 0.7014\n","Epoch 66/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2784 - accuracy: 0.8876 - val_loss: 0.8062 - val_accuracy: 0.6808\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2691 - accuracy: 0.8897 - val_loss: 0.7931 - val_accuracy: 0.6942\n","Epoch 68/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2593 - accuracy: 0.8941 - val_loss: 0.8059 - val_accuracy: 0.7014\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2641 - accuracy: 0.8845 - val_loss: 0.8363 - val_accuracy: 0.6829\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2605 - accuracy: 0.8959 - val_loss: 0.8790 - val_accuracy: 0.6715\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2676 - accuracy: 0.8907 - val_loss: 0.7953 - val_accuracy: 0.7004\n","Epoch 72/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2600 - accuracy: 0.8910 - val_loss: 0.8555 - val_accuracy: 0.6849\n","Epoch 73/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2682 - accuracy: 0.8863 - val_loss: 0.8000 - val_accuracy: 0.7014\n","Epoch 74/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2557 - accuracy: 0.8930 - val_loss: 0.8410 - val_accuracy: 0.7004\n","Epoch 75/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2431 - accuracy: 0.9016 - val_loss: 0.8171 - val_accuracy: 0.7076\n","Epoch 76/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2463 - accuracy: 0.8984 - val_loss: 0.8087 - val_accuracy: 0.7107\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2545 - accuracy: 0.8951 - val_loss: 0.8428 - val_accuracy: 0.6921\n","Epoch 78/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2493 - accuracy: 0.8959 - val_loss: 0.8435 - val_accuracy: 0.7056\n","Epoch 79/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2484 - accuracy: 0.8995 - val_loss: 0.8528 - val_accuracy: 0.6994\n","Epoch 80/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2434 - accuracy: 0.9005 - val_loss: 0.9233 - val_accuracy: 0.6901\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2449 - accuracy: 0.9031 - val_loss: 0.8444 - val_accuracy: 0.7025\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2366 - accuracy: 0.9031 - val_loss: 0.8295 - val_accuracy: 0.7087\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2264 - accuracy: 0.9088 - val_loss: 0.8350 - val_accuracy: 0.7169\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2355 - accuracy: 0.9047 - val_loss: 0.8392 - val_accuracy: 0.7107\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2226 - accuracy: 0.9065 - val_loss: 0.9001 - val_accuracy: 0.7066\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2306 - accuracy: 0.9119 - val_loss: 0.8677 - val_accuracy: 0.6983\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2296 - accuracy: 0.9059 - val_loss: 0.8538 - val_accuracy: 0.6994\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2259 - accuracy: 0.9137 - val_loss: 0.8763 - val_accuracy: 0.7014\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2282 - accuracy: 0.9052 - val_loss: 0.8602 - val_accuracy: 0.7180\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2260 - accuracy: 0.9098 - val_loss: 0.8967 - val_accuracy: 0.6973\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2238 - accuracy: 0.9114 - val_loss: 0.9051 - val_accuracy: 0.6860\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2265 - accuracy: 0.9090 - val_loss: 0.9124 - val_accuracy: 0.6973\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2212 - accuracy: 0.9109 - val_loss: 0.8838 - val_accuracy: 0.7035\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2276 - accuracy: 0.9072 - val_loss: 0.8925 - val_accuracy: 0.7066\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2179 - accuracy: 0.9101 - val_loss: 0.8924 - val_accuracy: 0.7076\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2238 - accuracy: 0.9116 - val_loss: 0.9109 - val_accuracy: 0.6911\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2109 - accuracy: 0.9132 - val_loss: 0.9012 - val_accuracy: 0.7025\n","Epoch 98/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2131 - accuracy: 0.9134 - val_loss: 0.9316 - val_accuracy: 0.6870\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2079 - accuracy: 0.9163 - val_loss: 0.9210 - val_accuracy: 0.6849\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2085 - accuracy: 0.9214 - val_loss: 0.9355 - val_accuracy: 0.7045\n","{'loss': [0.4506126046180725, 0.4274168610572815, 0.42387938499450684, 0.42050689458847046, 0.41063377261161804, 0.41115111112594604, 0.4015352725982666, 0.39355912804603577, 0.3990408182144165, 0.3984639346599579, 0.3896213173866272, 0.3962323069572449, 0.3898807466030121, 0.38503962755203247, 0.38782474398612976, 0.3845348060131073, 0.38092178106307983, 0.3721495270729065, 0.36823925375938416, 0.37219542264938354, 0.3747018277645111, 0.3637009263038635, 0.3679535388946533, 0.35293763875961304, 0.35261476039886475, 0.34950801730155945, 0.3537621796131134, 0.3500989079475403, 0.3543548583984375, 0.35121873021125793, 0.3390636742115021, 0.3371226489543915, 0.34446772933006287, 0.33484572172164917, 0.3392615020275116, 0.3436182737350464, 0.3450913727283478, 0.33026614785194397, 0.33254730701446533, 0.32911360263824463, 0.32022759318351746, 0.31116944551467896, 0.3128446638584137, 0.30938804149627686, 0.3125383257865906, 0.3067801892757416, 0.2983625829219818, 0.3067317605018616, 0.3170064687728882, 0.2986726760864258, 0.29941776394844055, 0.2997601628303528, 0.2940303385257721, 0.2877328097820282, 0.28674232959747314, 0.2822748124599457, 0.30636540055274963, 0.274894654750824, 0.29050832986831665, 0.28170642256736755, 0.2796468734741211, 0.275860995054245, 0.2779085338115692, 0.2694651484489441, 0.266869455575943, 0.27841368317604065, 0.26909053325653076, 0.2592597007751465, 0.26409056782722473, 0.26052242517471313, 0.26757314801216125, 0.25999903678894043, 0.26820138096809387, 0.25570446252822876, 0.2431086003780365, 0.24627234041690826, 0.2545316517353058, 0.2493366301059723, 0.24836848676204681, 0.2434220016002655, 0.24493975937366486, 0.23655149340629578, 0.2263963371515274, 0.2355201542377472, 0.22259987890720367, 0.23060911893844604, 0.22956492006778717, 0.22590379416942596, 0.22823794186115265, 0.22596541047096252, 0.2237853854894638, 0.22654181718826294, 0.22124724090099335, 0.22757011651992798, 0.2179386019706726, 0.22383134067058563, 0.21085846424102783, 0.2131015807390213, 0.2078554779291153, 0.2085445374250412], 'accuracy': [0.786821722984314, 0.7981911897659302, 0.8015503883361816, 0.7987080216407776, 0.8144702911376953, 0.8087855577468872, 0.814987063407898, 0.8175710439682007, 0.8173126578330994, 0.8191214203834534, 0.8237726092338562, 0.816020667552948, 0.8235142230987549, 0.8229973912239075, 0.8217054009437561, 0.8224806189537048, 0.8232558369636536, 0.8315245509147644, 0.8364341259002686, 0.8255813717842102, 0.8325581550598145, 0.8397932648658752, 0.8379845023155212, 0.8483204245567322, 0.8462532162666321, 0.8439276218414307, 0.8392764925956726, 0.8395348787307739, 0.842377245426178, 0.8462532162666321, 0.8516795635223389, 0.8514211773872375, 0.8488371968269348, 0.8532299995422363, 0.8480620384216309, 0.8459948301315308, 0.8400516510009766, 0.8545219898223877, 0.8540051579475403, 0.8581395149230957, 0.8633074760437012, 0.8625323176383972, 0.8682170510292053, 0.8695090413093567, 0.8643410801887512, 0.8620154857635498, 0.8726097941398621, 0.8671834468841553, 0.8630490899085999, 0.8728682398796082, 0.8710594177246094, 0.8684754371643066, 0.8731266260147095, 0.879328191280365, 0.8798449635505676, 0.8847545385360718, 0.8695090413093567, 0.8855296969413757, 0.883979320526123, 0.8826873302459717, 0.8844961524009705, 0.8832041621208191, 0.8782945871353149, 0.8852713108062744, 0.8930232524871826, 0.8875969052314758, 0.8896640539169312, 0.8940568566322327, 0.8844961524009705, 0.8958656191825867, 0.8906976580619812, 0.8909560441970825, 0.8863049149513245, 0.8930232524871826, 0.9015504121780396, 0.8984495997428894, 0.8950904607772827, 0.8958656191825867, 0.8994832038879395, 0.9005168080329895, 0.9031007885932922, 0.9031007885932922, 0.9087855219841003, 0.9046511650085449, 0.9064599275588989, 0.9118863344192505, 0.9059431552886963, 0.9136950969696045, 0.9051679372787476, 0.9098191261291504, 0.9113695025444031, 0.9090439081192017, 0.9108527302742004, 0.9072351455688477, 0.9100775122642517, 0.9116278886795044, 0.9131782650947571, 0.9134367108345032, 0.9162790775299072, 0.9214470386505127], 'val_loss': [0.8818053603172302, 0.8518346548080444, 0.8588061332702637, 0.86446613073349, 0.8728143572807312, 0.8729295134544373, 0.8699458837509155, 0.8581255674362183, 0.8428542017936707, 0.8394425511360168, 0.8289719223976135, 0.8133793473243713, 0.7796874642372131, 0.7347550392150879, 0.7726233005523682, 0.7306844592094421, 0.6463763117790222, 0.6686757802963257, 0.6661150455474854, 0.6619917154312134, 0.6174824237823486, 0.5991601943969727, 0.6124582886695862, 0.6350622773170471, 0.6288459897041321, 0.6337185502052307, 0.6339027881622314, 0.6847357749938965, 0.7314059734344482, 0.6664984822273254, 0.6505426168441772, 0.6517172455787659, 0.6993563175201416, 0.6612653732299805, 0.6918722987174988, 0.6716961860656738, 0.6723222136497498, 0.6832724213600159, 0.7100211381912231, 0.6779022216796875, 0.6985109448432922, 0.6822280883789062, 0.6945725679397583, 0.7028195858001709, 0.6925406455993652, 0.6992715001106262, 0.7120867371559143, 0.7267445921897888, 0.7730103731155396, 0.726276695728302, 0.729729950428009, 0.7527856826782227, 0.7192642092704773, 0.732536792755127, 0.7399239540100098, 0.7595123052597046, 0.7615083456039429, 0.7484443783760071, 0.7675244212150574, 0.7537856698036194, 0.7527676820755005, 0.7866005301475525, 0.7746860384941101, 0.7739765644073486, 0.8018977642059326, 0.8061977624893188, 0.7930657863616943, 0.8058883547782898, 0.8363163471221924, 0.8789612054824829, 0.7952710390090942, 0.8555265069007874, 0.8000110387802124, 0.8410015106201172, 0.8170945644378662, 0.8086813688278198, 0.8427556753158569, 0.8435443639755249, 0.8528378009796143, 0.9233476519584656, 0.8443792462348938, 0.8295071721076965, 0.8349553346633911, 0.8392375111579895, 0.9000537991523743, 0.8676652908325195, 0.8537977337837219, 0.8762893080711365, 0.8601951003074646, 0.8966848254203796, 0.9050835967063904, 0.9123522639274597, 0.883750855922699, 0.8924858570098877, 0.8923596739768982, 0.9109463691711426, 0.9012333750724792, 0.9316421747207642, 0.9210098385810852, 0.9354559779167175], 'val_accuracy': [0.4876033067703247, 0.4886363744735718, 0.4886363744735718, 0.4886363744735718, 0.48966941237449646, 0.4927685856819153, 0.49380165338516235, 0.49793389439582825, 0.5, 0.5020661354064941, 0.5072314143180847, 0.5113636255264282, 0.5206611752510071, 0.5454545617103577, 0.5537189841270447, 0.5712810158729553, 0.6157024502754211, 0.6115702390670776, 0.6291322112083435, 0.6342975497245789, 0.6787189841270447, 0.6962810158729553, 0.6890496015548706, 0.69111567735672, 0.7004132270812988, 0.7055785059928894, 0.7004132270812988, 0.69111567735672, 0.6663222908973694, 0.7035123705863953, 0.7128099203109741, 0.7159090638160706, 0.7076446413993835, 0.7221074104309082, 0.7097107172012329, 0.7148760557174683, 0.7138429880142212, 0.702479362487793, 0.6952479481697083, 0.7169421315193176, 0.7076446413993835, 0.7128099203109741, 0.7035123705863953, 0.7148760557174683, 0.7128099203109741, 0.7159090638160706, 0.7200413346290588, 0.7128099203109741, 0.6900826692581177, 0.7159090638160706, 0.7190082669258118, 0.711776852607727, 0.7231404781341553, 0.7014462947845459, 0.7086777091026306, 0.7128099203109741, 0.7035123705863953, 0.7055785059928894, 0.7035123705863953, 0.6993801593780518, 0.7086777091026306, 0.702479362487793, 0.71074378490448, 0.7066115736961365, 0.7014462947845459, 0.6807851195335388, 0.6942148804664612, 0.7014462947845459, 0.682851254940033, 0.6714876294136047, 0.7004132270812988, 0.6849173307418823, 0.7014462947845459, 0.7004132270812988, 0.7076446413993835, 0.71074378490448, 0.692148745059967, 0.7055785059928894, 0.6993801593780518, 0.6900826692581177, 0.702479362487793, 0.7086777091026306, 0.7169421315193176, 0.71074378490448, 0.7066115736961365, 0.6983470916748047, 0.6993801593780518, 0.7014462947845459, 0.7179751992225647, 0.6973140239715576, 0.6859503984451294, 0.6973140239715576, 0.7035123705863953, 0.7066115736961365, 0.7076446413993835, 0.69111567735672, 0.702479362487793, 0.6869834661483765, 0.6849173307418823, 0.7045454382896423]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 8s 51ms/step - loss: 0.2902 - accuracy: 0.8809 - val_loss: 1.2891 - val_accuracy: 0.4860\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 2/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2707 - accuracy: 0.8828 - val_loss: 1.2916 - val_accuracy: 0.4860\n","Epoch 3/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2530 - accuracy: 0.8933 - val_loss: 1.3003 - val_accuracy: 0.4860\n","Epoch 4/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2507 - accuracy: 0.8960 - val_loss: 1.3071 - val_accuracy: 0.4860\n","Epoch 5/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2663 - accuracy: 0.8917 - val_loss: 1.2644 - val_accuracy: 0.4860\n","Epoch 6/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2558 - accuracy: 0.8933 - val_loss: 1.2938 - val_accuracy: 0.4860\n","Epoch 7/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2356 - accuracy: 0.9068 - val_loss: 1.2923 - val_accuracy: 0.4860\n","Epoch 8/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2431 - accuracy: 0.8974 - val_loss: 1.2665 - val_accuracy: 0.4903\n","Epoch 9/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2491 - accuracy: 0.8987 - val_loss: 1.2804 - val_accuracy: 0.4914\n","Epoch 10/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2360 - accuracy: 0.9044 - val_loss: 1.3086 - val_accuracy: 0.4935\n","Epoch 11/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.2286 - accuracy: 0.9033 - val_loss: 1.2792 - val_accuracy: 0.4968\n","Epoch 12/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2266 - accuracy: 0.9108 - val_loss: 1.2886 - val_accuracy: 0.4989\n","Epoch 13/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.2236 - accuracy: 0.9138 - val_loss: 1.2463 - val_accuracy: 0.5054\n","Epoch 14/100\n","29/29 [==============================] - 1s 42ms/step - loss: 0.2207 - accuracy: 0.9114 - val_loss: 1.2789 - val_accuracy: 0.5183\n","Epoch 15/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.2225 - accuracy: 0.9116 - val_loss: 1.1318 - val_accuracy: 0.5377\n","Epoch 16/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.2209 - accuracy: 0.9106 - val_loss: 1.1035 - val_accuracy: 0.5409\n","Epoch 17/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2226 - accuracy: 0.9060 - val_loss: 1.1031 - val_accuracy: 0.5560\n","Epoch 18/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2114 - accuracy: 0.9157 - val_loss: 1.0847 - val_accuracy: 0.5625\n","Epoch 19/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2152 - accuracy: 0.9151 - val_loss: 1.0433 - val_accuracy: 0.5819\n","Epoch 20/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2043 - accuracy: 0.9165 - val_loss: 0.9491 - val_accuracy: 0.6239\n","Epoch 21/100\n","29/29 [==============================] - 3s 92ms/step - loss: 0.2078 - accuracy: 0.9162 - val_loss: 0.9491 - val_accuracy: 0.6369\n","Epoch 22/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.2058 - accuracy: 0.9146 - val_loss: 0.7272 - val_accuracy: 0.6907\n","Epoch 23/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2103 - accuracy: 0.9138 - val_loss: 0.7943 - val_accuracy: 0.6810\n","Epoch 24/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2050 - accuracy: 0.9135 - val_loss: 0.6853 - val_accuracy: 0.7274\n","Epoch 25/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1967 - accuracy: 0.9230 - val_loss: 0.6465 - val_accuracy: 0.7468\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2036 - accuracy: 0.9181 - val_loss: 0.7159 - val_accuracy: 0.7381\n","Epoch 27/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1969 - accuracy: 0.9181 - val_loss: 0.7056 - val_accuracy: 0.7619\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2038 - accuracy: 0.9162 - val_loss: 0.6810 - val_accuracy: 0.7619\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1920 - accuracy: 0.9232 - val_loss: 0.7079 - val_accuracy: 0.7575\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1880 - accuracy: 0.9267 - val_loss: 0.7269 - val_accuracy: 0.7543\n","Epoch 31/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1972 - accuracy: 0.9248 - val_loss: 0.7372 - val_accuracy: 0.7608\n","Epoch 32/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.1933 - accuracy: 0.9216 - val_loss: 0.7221 - val_accuracy: 0.7672\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1847 - accuracy: 0.9305 - val_loss: 0.7328 - val_accuracy: 0.7619\n","Epoch 34/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1894 - accuracy: 0.9254 - val_loss: 0.7533 - val_accuracy: 0.7597\n","Epoch 35/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1798 - accuracy: 0.9318 - val_loss: 0.7680 - val_accuracy: 0.7608\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1985 - accuracy: 0.9200 - val_loss: 0.7679 - val_accuracy: 0.7586\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1780 - accuracy: 0.9313 - val_loss: 0.7811 - val_accuracy: 0.7586\n","Epoch 38/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.1880 - accuracy: 0.9235 - val_loss: 0.7536 - val_accuracy: 0.7705\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1954 - accuracy: 0.9238 - val_loss: 0.7923 - val_accuracy: 0.7640\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1809 - accuracy: 0.9294 - val_loss: 0.7791 - val_accuracy: 0.7683\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1833 - accuracy: 0.9259 - val_loss: 0.8175 - val_accuracy: 0.7489\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1846 - accuracy: 0.9270 - val_loss: 0.7806 - val_accuracy: 0.7608\n","Epoch 43/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1732 - accuracy: 0.9362 - val_loss: 0.8895 - val_accuracy: 0.7037\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1754 - accuracy: 0.9327 - val_loss: 0.8128 - val_accuracy: 0.7565\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1755 - accuracy: 0.9318 - val_loss: 0.7977 - val_accuracy: 0.7586\n","Epoch 46/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1650 - accuracy: 0.9380 - val_loss: 0.7943 - val_accuracy: 0.7694\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1735 - accuracy: 0.9364 - val_loss: 0.9639 - val_accuracy: 0.7403\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1968 - accuracy: 0.9248 - val_loss: 0.8066 - val_accuracy: 0.7651\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1828 - accuracy: 0.9275 - val_loss: 0.8168 - val_accuracy: 0.7500\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1756 - accuracy: 0.9270 - val_loss: 1.0032 - val_accuracy: 0.7263\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2080 - accuracy: 0.9146 - val_loss: 0.8063 - val_accuracy: 0.7575\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1686 - accuracy: 0.9370 - val_loss: 0.8175 - val_accuracy: 0.7629\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1658 - accuracy: 0.9372 - val_loss: 0.8288 - val_accuracy: 0.7489\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1640 - accuracy: 0.9386 - val_loss: 0.8630 - val_accuracy: 0.7522\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1598 - accuracy: 0.9370 - val_loss: 0.8417 - val_accuracy: 0.7619\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1585 - accuracy: 0.9380 - val_loss: 0.8907 - val_accuracy: 0.7500\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1495 - accuracy: 0.9434 - val_loss: 0.9250 - val_accuracy: 0.7468\n","Epoch 58/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1599 - accuracy: 0.9391 - val_loss: 0.8290 - val_accuracy: 0.7532\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1572 - accuracy: 0.9405 - val_loss: 0.8750 - val_accuracy: 0.7511\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1624 - accuracy: 0.9397 - val_loss: 0.9247 - val_accuracy: 0.7500\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1594 - accuracy: 0.9364 - val_loss: 0.8648 - val_accuracy: 0.7554\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1793 - accuracy: 0.9318 - val_loss: 1.0074 - val_accuracy: 0.7177\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1662 - accuracy: 0.9340 - val_loss: 0.8755 - val_accuracy: 0.7500\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1479 - accuracy: 0.9448 - val_loss: 0.8770 - val_accuracy: 0.7532\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1407 - accuracy: 0.9467 - val_loss: 0.8521 - val_accuracy: 0.7565\n","Epoch 66/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1406 - accuracy: 0.9432 - val_loss: 0.8786 - val_accuracy: 0.7468\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1403 - accuracy: 0.9450 - val_loss: 0.8673 - val_accuracy: 0.7554\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1358 - accuracy: 0.9512 - val_loss: 0.8668 - val_accuracy: 0.7511\n","Epoch 69/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1529 - accuracy: 0.9410 - val_loss: 0.8683 - val_accuracy: 0.7597\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1415 - accuracy: 0.9442 - val_loss: 0.9668 - val_accuracy: 0.7425\n","Epoch 71/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1457 - accuracy: 0.9456 - val_loss: 0.9160 - val_accuracy: 0.7522\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1336 - accuracy: 0.9515 - val_loss: 0.8813 - val_accuracy: 0.7565\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1413 - accuracy: 0.9483 - val_loss: 0.8804 - val_accuracy: 0.7662\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1361 - accuracy: 0.9477 - val_loss: 0.9111 - val_accuracy: 0.7565\n","Epoch 75/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1475 - accuracy: 0.9485 - val_loss: 0.9814 - val_accuracy: 0.7425\n","Epoch 76/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1321 - accuracy: 0.9529 - val_loss: 0.9361 - val_accuracy: 0.7619\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1268 - accuracy: 0.9523 - val_loss: 1.0274 - val_accuracy: 0.7392\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1294 - accuracy: 0.9515 - val_loss: 0.9456 - val_accuracy: 0.7489\n","Epoch 79/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1316 - accuracy: 0.9507 - val_loss: 0.9745 - val_accuracy: 0.7532\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1339 - accuracy: 0.9510 - val_loss: 0.9474 - val_accuracy: 0.7435\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1375 - accuracy: 0.9504 - val_loss: 1.0491 - val_accuracy: 0.7435\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1496 - accuracy: 0.9418 - val_loss: 1.0068 - val_accuracy: 0.7338\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1333 - accuracy: 0.9483 - val_loss: 0.9589 - val_accuracy: 0.7554\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1214 - accuracy: 0.9537 - val_loss: 0.9312 - val_accuracy: 0.7532\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1260 - accuracy: 0.9561 - val_loss: 1.0104 - val_accuracy: 0.7457\n","Epoch 86/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1319 - accuracy: 0.9507 - val_loss: 1.0132 - val_accuracy: 0.7478\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1556 - accuracy: 0.9423 - val_loss: 1.0700 - val_accuracy: 0.7360\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1412 - accuracy: 0.9507 - val_loss: 0.9768 - val_accuracy: 0.7608\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1198 - accuracy: 0.9515 - val_loss: 0.9882 - val_accuracy: 0.7478\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1172 - accuracy: 0.9588 - val_loss: 1.0043 - val_accuracy: 0.7500\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1153 - accuracy: 0.9574 - val_loss: 1.0021 - val_accuracy: 0.7446\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1128 - accuracy: 0.9596 - val_loss: 0.9988 - val_accuracy: 0.7543\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1174 - accuracy: 0.9553 - val_loss: 1.0318 - val_accuracy: 0.7457\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1201 - accuracy: 0.9542 - val_loss: 1.0317 - val_accuracy: 0.7489\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1138 - accuracy: 0.9569 - val_loss: 1.0571 - val_accuracy: 0.7500\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1113 - accuracy: 0.9588 - val_loss: 1.0145 - val_accuracy: 0.7608\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1270 - accuracy: 0.9520 - val_loss: 1.0529 - val_accuracy: 0.7511\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1241 - accuracy: 0.9529 - val_loss: 1.0242 - val_accuracy: 0.7608\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1138 - accuracy: 0.9555 - val_loss: 1.0147 - val_accuracy: 0.7435\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1145 - accuracy: 0.9545 - val_loss: 1.0167 - val_accuracy: 0.7532\n","{'loss': [0.2902098596096039, 0.2706807255744934, 0.25297436118125916, 0.2506757080554962, 0.26629146933555603, 0.2557653486728668, 0.23562607169151306, 0.24305857717990875, 0.2490713894367218, 0.23601362109184265, 0.22858154773712158, 0.22661760449409485, 0.22355495393276215, 0.22065985202789307, 0.2225397676229477, 0.22089312970638275, 0.2226128727197647, 0.2114187777042389, 0.21523848176002502, 0.20428505539894104, 0.20784033834934235, 0.2058488428592682, 0.21033772826194763, 0.2050274759531021, 0.1967301368713379, 0.20357798039913177, 0.1969427764415741, 0.20376639068126678, 0.1920037567615509, 0.18803898990154266, 0.19715166091918945, 0.19326239824295044, 0.18465127050876617, 0.18939270079135895, 0.17983399331569672, 0.19854675233364105, 0.17804546654224396, 0.18797089159488678, 0.19540835916996002, 0.1809009611606598, 0.18327581882476807, 0.18457962572574615, 0.17315740883350372, 0.17538954317569733, 0.17550814151763916, 0.16498377919197083, 0.1734916865825653, 0.19676335155963898, 0.1828402429819107, 0.17560690641403198, 0.2080342173576355, 0.16859206557273865, 0.1658051759004593, 0.16401724517345428, 0.15979057550430298, 0.15848179161548615, 0.14947964251041412, 0.1599278301000595, 0.15719422698020935, 0.16238299012184143, 0.1594070941209793, 0.17931479215621948, 0.16621309518814087, 0.14790503680706024, 0.14073149859905243, 0.14063617587089539, 0.14027367532253265, 0.13575823605060577, 0.15287843346595764, 0.14151394367218018, 0.14571180939674377, 0.13361981511116028, 0.1412564218044281, 0.13610684871673584, 0.14749804139137268, 0.13212303817272186, 0.1267920881509781, 0.12941902875900269, 0.13159812986850739, 0.1338878720998764, 0.13750481605529785, 0.14959336817264557, 0.1332748681306839, 0.12138313055038452, 0.12595060467720032, 0.13187403976917267, 0.15562190115451813, 0.1411621868610382, 0.11980626732110977, 0.11724290251731873, 0.11534188687801361, 0.11281173676252365, 0.11740371584892273, 0.12013688683509827, 0.11378192156553268, 0.1113019734621048, 0.12701238691806793, 0.12411011010408401, 0.11383439600467682, 0.11449827253818512], 'accuracy': [0.8809267282485962, 0.8828125, 0.8933189511299133, 0.8960129022598267, 0.8917025923728943, 0.8933189511299133, 0.9067887663841248, 0.8973599076271057, 0.8987069129943848, 0.9043642282485962, 0.9032866358757019, 0.9108297228813171, 0.9137930870056152, 0.9113685488700867, 0.9116379022598267, 0.9105603694915771, 0.9059805870056152, 0.915678858757019, 0.9151400923728943, 0.9164870977401733, 0.9162176847457886, 0.9146012663841248, 0.9137930870056152, 0.9135237336158752, 0.9229525923728943, 0.9181034564971924, 0.9181034564971924, 0.9162176847457886, 0.923222005367279, 0.9267241358757019, 0.9248383641242981, 0.9216055870056152, 0.9304956793785095, 0.9253771305084229, 0.9318426847457886, 0.9199892282485962, 0.931303858757019, 0.923491358757019, 0.9237607717514038, 0.9294180870056152, 0.9259159564971924, 0.9269935488700867, 0.936152994632721, 0.9326508641242981, 0.9318426847457886, 0.9380387663841248, 0.9364224076271057, 0.9248383641242981, 0.9275323152542114, 0.9269935488700867, 0.9146012663841248, 0.9369612336158752, 0.9372305870056152, 0.9385775923728943, 0.9369612336158752, 0.9380387663841248, 0.9434267282485962, 0.939116358757019, 0.9404633641242981, 0.9396551847457886, 0.9364224076271057, 0.9318426847457886, 0.9339978694915771, 0.9447737336158752, 0.946659505367279, 0.9431573152542114, 0.9450430870056152, 0.9512392282485962, 0.9410021305084229, 0.9442349076271057, 0.9455819129943848, 0.951508641242981, 0.9482758641242981, 0.9477370977401733, 0.9485452771186829, 0.9528555870056152, 0.9523168206214905, 0.951508641242981, 0.9507004022598267, 0.9509698152542114, 0.9504310488700867, 0.9418103694915771, 0.9482758641242981, 0.9536637663841248, 0.9560883641242981, 0.9507004022598267, 0.9423491358757019, 0.9507004022598267, 0.951508641242981, 0.9587823152542114, 0.9574353694915771, 0.959590494632721, 0.9552801847457886, 0.9542025923728943, 0.9568965435028076, 0.9587823152542114, 0.9520474076271057, 0.9528555870056152, 0.9555495977401733, 0.954472005367279], 'val_loss': [1.289095401763916, 1.2916210889816284, 1.300251841545105, 1.307063341140747, 1.264377236366272, 1.2938027381896973, 1.292333722114563, 1.26652991771698, 1.2804491519927979, 1.3085720539093018, 1.2792481184005737, 1.288572907447815, 1.246346354484558, 1.2788926362991333, 1.131770372390747, 1.1035096645355225, 1.1030505895614624, 1.0847342014312744, 1.0432907342910767, 0.9491334557533264, 0.949105441570282, 0.727150022983551, 0.7943448424339294, 0.6853227019309998, 0.6464830636978149, 0.7159253358840942, 0.7056101560592651, 0.6810193061828613, 0.7078567147254944, 0.7268708348274231, 0.7372406125068665, 0.7220726013183594, 0.7328422665596008, 0.7532577514648438, 0.7679736018180847, 0.7679115533828735, 0.7810600399971008, 0.7535876631736755, 0.7922875881195068, 0.7791419625282288, 0.8175073862075806, 0.7805889248847961, 0.8894801735877991, 0.8128044009208679, 0.7976565361022949, 0.7943094968795776, 0.9638697504997253, 0.8066052198410034, 0.8167910575866699, 1.003225564956665, 0.8062807321548462, 0.8175167441368103, 0.8287712335586548, 0.8629583716392517, 0.8416842818260193, 0.8906958103179932, 0.9250390529632568, 0.8289673328399658, 0.8750365972518921, 0.924660861492157, 0.8647697567939758, 1.0074422359466553, 0.8754753470420837, 0.876998245716095, 0.85205078125, 0.8785537481307983, 0.8672770261764526, 0.8667575120925903, 0.8682814836502075, 0.9668166637420654, 0.915972113609314, 0.8812810182571411, 0.8804066777229309, 0.9111112952232361, 0.9814225435256958, 0.936088502407074, 1.0273760557174683, 0.9455510377883911, 0.9745239019393921, 0.9474301338195801, 1.0490561723709106, 1.0068203210830688, 0.958860456943512, 0.9311927556991577, 1.010380744934082, 1.0131944417953491, 1.0700275897979736, 0.9767862558364868, 0.9882459044456482, 1.004286527633667, 1.0020980834960938, 0.9987834692001343, 1.0318068265914917, 1.0317412614822388, 1.057149887084961, 1.0145392417907715, 1.0528792142868042, 1.0241891145706177, 1.014690637588501, 1.0167205333709717], 'val_accuracy': [0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.4903017282485962, 0.4913793206214905, 0.49353447556495667, 0.4967672526836395, 0.4989224076271057, 0.5053879022598267, 0.5183189511299133, 0.537715494632721, 0.5409482717514038, 0.556034505367279, 0.5625, 0.5818965435028076, 0.6239224076271057, 0.6368534564971924, 0.6907327771186829, 0.681034505367279, 0.7273706793785095, 0.7467672228813171, 0.7381465435028076, 0.7618534564971924, 0.7618534564971924, 0.7575430870056152, 0.7543103694915771, 0.7607758641242981, 0.767241358757019, 0.7618534564971924, 0.7596982717514038, 0.7607758641242981, 0.7586206793785095, 0.7586206793785095, 0.7704741358757019, 0.764008641242981, 0.7683189511299133, 0.7489224076271057, 0.7607758641242981, 0.7036637663841248, 0.756465494632721, 0.7586206793785095, 0.7693965435028076, 0.7403017282485962, 0.7650862336158752, 0.75, 0.7262930870056152, 0.7575430870056152, 0.7629310488700867, 0.7489224076271057, 0.7521551847457886, 0.7618534564971924, 0.75, 0.7467672228813171, 0.7532327771186829, 0.7510775923728943, 0.75, 0.7553879022598267, 0.7176724076271057, 0.75, 0.7532327771186829, 0.756465494632721, 0.7467672228813171, 0.7553879022598267, 0.7510775923728943, 0.7596982717514038, 0.7424569129943848, 0.7521551847457886, 0.756465494632721, 0.7661637663841248, 0.756465494632721, 0.7424569129943848, 0.7618534564971924, 0.7392241358757019, 0.7489224076271057, 0.7532327771186829, 0.743534505367279, 0.743534505367279, 0.7338362336158752, 0.7553879022598267, 0.7532327771186829, 0.7456896305084229, 0.7478448152542114, 0.735991358757019, 0.7607758641242981, 0.7478448152542114, 0.75, 0.7446120977401733, 0.7543103694915771, 0.7456896305084229, 0.7489224076271057, 0.75, 0.7607758641242981, 0.7510775923728943, 0.7607758641242981, 0.743534505367279, 0.7532327771186829]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.2919 - accuracy: 0.8849"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 8s 62ms/step - loss: 0.2968 - accuracy: 0.8814 - val_loss: 1.2789 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2840 - accuracy: 0.8780 - val_loss: 1.2578 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2761 - accuracy: 0.8834 - val_loss: 1.2602 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2688 - accuracy: 0.8854 - val_loss: 1.2512 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2580 - accuracy: 0.8860 - val_loss: 1.2558 - val_accuracy: 0.4966\n","Epoch 6/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2707 - accuracy: 0.8848 - val_loss: 1.2321 - val_accuracy: 0.4977\n","Epoch 7/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2634 - accuracy: 0.8984 - val_loss: 1.2183 - val_accuracy: 0.4989\n","Epoch 8/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2645 - accuracy: 0.8899 - val_loss: 1.2336 - val_accuracy: 0.4989\n","Epoch 9/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2682 - accuracy: 0.8891 - val_loss: 1.2184 - val_accuracy: 0.5023\n","Epoch 10/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2453 - accuracy: 0.9021 - val_loss: 1.1907 - val_accuracy: 0.5068\n","Epoch 11/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2449 - accuracy: 0.8981 - val_loss: 1.1718 - val_accuracy: 0.5102\n","Epoch 12/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.2503 - accuracy: 0.8978 - val_loss: 1.1724 - val_accuracy: 0.5113\n","Epoch 13/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.2551 - accuracy: 0.8993 - val_loss: 1.1951 - val_accuracy: 0.5147\n","Epoch 14/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2400 - accuracy: 0.9018 - val_loss: 1.0883 - val_accuracy: 0.5351\n","Epoch 15/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2383 - accuracy: 0.9049 - val_loss: 1.0018 - val_accuracy: 0.5441\n","Epoch 16/100\n","28/28 [==============================] - 3s 114ms/step - loss: 0.2486 - accuracy: 0.8987 - val_loss: 0.9401 - val_accuracy: 0.5633\n","Epoch 17/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2396 - accuracy: 0.9049 - val_loss: 0.9817 - val_accuracy: 0.5532\n","Epoch 18/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2356 - accuracy: 0.9063 - val_loss: 0.9274 - val_accuracy: 0.5848\n","Epoch 19/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2237 - accuracy: 0.9128 - val_loss: 0.8821 - val_accuracy: 0.6109\n","Epoch 20/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2263 - accuracy: 0.9117 - val_loss: 0.6864 - val_accuracy: 0.6686\n","Epoch 21/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2284 - accuracy: 0.9089 - val_loss: 0.6910 - val_accuracy: 0.6753\n","Epoch 22/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2306 - accuracy: 0.9066 - val_loss: 0.8095 - val_accuracy: 0.6527\n","Epoch 23/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2252 - accuracy: 0.9097 - val_loss: 0.6379 - val_accuracy: 0.7014\n","Epoch 24/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2158 - accuracy: 0.9126 - val_loss: 0.5259 - val_accuracy: 0.7839\n","Epoch 25/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2347 - accuracy: 0.9066 - val_loss: 0.5564 - val_accuracy: 0.7749\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2209 - accuracy: 0.9140 - val_loss: 0.6067 - val_accuracy: 0.7489\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2237 - accuracy: 0.9095 - val_loss: 0.6372 - val_accuracy: 0.7342\n","Epoch 28/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.2237 - accuracy: 0.9179 - val_loss: 0.5615 - val_accuracy: 0.7952\n","Epoch 29/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2100 - accuracy: 0.9196 - val_loss: 0.6257 - val_accuracy: 0.7590\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2192 - accuracy: 0.9089 - val_loss: 0.6467 - val_accuracy: 0.7613\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2126 - accuracy: 0.9154 - val_loss: 0.5783 - val_accuracy: 0.7828\n","Epoch 32/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2132 - accuracy: 0.9157 - val_loss: 0.5903 - val_accuracy: 0.7986\n","Epoch 33/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1952 - accuracy: 0.9287 - val_loss: 0.5963 - val_accuracy: 0.7885\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2012 - accuracy: 0.9216 - val_loss: 0.6034 - val_accuracy: 0.7828\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1953 - accuracy: 0.9253 - val_loss: 0.6610 - val_accuracy: 0.7726\n","Epoch 36/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.1990 - accuracy: 0.9281 - val_loss: 0.6256 - val_accuracy: 0.7851\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1908 - accuracy: 0.9290 - val_loss: 0.6068 - val_accuracy: 0.7930\n","Epoch 38/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.2033 - accuracy: 0.9219 - val_loss: 0.6083 - val_accuracy: 0.8009\n","Epoch 39/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1992 - accuracy: 0.9216 - val_loss: 0.6272 - val_accuracy: 0.7919\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1977 - accuracy: 0.9247 - val_loss: 0.6943 - val_accuracy: 0.7489\n","Epoch 41/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1982 - accuracy: 0.9278 - val_loss: 0.7025 - val_accuracy: 0.7704\n","Epoch 42/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1960 - accuracy: 0.9225 - val_loss: 0.6504 - val_accuracy: 0.7760\n","Epoch 43/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1839 - accuracy: 0.9298 - val_loss: 0.6978 - val_accuracy: 0.7726\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1874 - accuracy: 0.9290 - val_loss: 0.6674 - val_accuracy: 0.7794\n","Epoch 45/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1868 - accuracy: 0.9332 - val_loss: 0.6341 - val_accuracy: 0.7952\n","Epoch 46/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1754 - accuracy: 0.9346 - val_loss: 0.6543 - val_accuracy: 0.7896\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1787 - accuracy: 0.9338 - val_loss: 0.6662 - val_accuracy: 0.7919\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1773 - accuracy: 0.9360 - val_loss: 0.6468 - val_accuracy: 0.7817\n","Epoch 49/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1997 - accuracy: 0.9222 - val_loss: 0.6703 - val_accuracy: 0.7817\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1777 - accuracy: 0.9307 - val_loss: 0.6514 - val_accuracy: 0.7941\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1757 - accuracy: 0.9352 - val_loss: 0.6601 - val_accuracy: 0.7885\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1768 - accuracy: 0.9349 - val_loss: 0.6767 - val_accuracy: 0.7805\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1850 - accuracy: 0.9400 - val_loss: 0.6852 - val_accuracy: 0.7862\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1725 - accuracy: 0.9406 - val_loss: 0.6498 - val_accuracy: 0.7986\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1654 - accuracy: 0.9426 - val_loss: 0.6716 - val_accuracy: 0.7794\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1876 - accuracy: 0.9259 - val_loss: 0.6943 - val_accuracy: 0.7851\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1629 - accuracy: 0.9400 - val_loss: 0.6854 - val_accuracy: 0.7851\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1644 - accuracy: 0.9355 - val_loss: 0.6806 - val_accuracy: 0.7885\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1625 - accuracy: 0.9394 - val_loss: 0.7063 - val_accuracy: 0.7794\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1644 - accuracy: 0.9358 - val_loss: 0.6847 - val_accuracy: 0.7783\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1563 - accuracy: 0.9474 - val_loss: 0.6876 - val_accuracy: 0.7794\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1531 - accuracy: 0.9468 - val_loss: 0.6911 - val_accuracy: 0.7964\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1699 - accuracy: 0.9380 - val_loss: 0.7248 - val_accuracy: 0.7771\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1533 - accuracy: 0.9488 - val_loss: 0.7015 - val_accuracy: 0.7839\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1601 - accuracy: 0.9434 - val_loss: 0.7116 - val_accuracy: 0.7862\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1514 - accuracy: 0.9499 - val_loss: 0.7006 - val_accuracy: 0.7839\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1544 - accuracy: 0.9440 - val_loss: 0.7303 - val_accuracy: 0.7771\n","Epoch 68/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1683 - accuracy: 0.9355 - val_loss: 0.7142 - val_accuracy: 0.7760\n","Epoch 69/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1582 - accuracy: 0.9437 - val_loss: 0.7581 - val_accuracy: 0.7670\n","Epoch 70/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1571 - accuracy: 0.9482 - val_loss: 0.7343 - val_accuracy: 0.7794\n","Epoch 71/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1566 - accuracy: 0.9451 - val_loss: 0.7635 - val_accuracy: 0.7624\n","Epoch 72/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1610 - accuracy: 0.9392 - val_loss: 0.7345 - val_accuracy: 0.7738\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1545 - accuracy: 0.9462 - val_loss: 0.7532 - val_accuracy: 0.7692\n","Epoch 74/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1450 - accuracy: 0.9502 - val_loss: 0.7480 - val_accuracy: 0.7839\n","Epoch 75/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1481 - accuracy: 0.9445 - val_loss: 0.7583 - val_accuracy: 0.7783\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1413 - accuracy: 0.9516 - val_loss: 0.7841 - val_accuracy: 0.7613\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1549 - accuracy: 0.9440 - val_loss: 0.7375 - val_accuracy: 0.7839\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1404 - accuracy: 0.9510 - val_loss: 0.7280 - val_accuracy: 0.7896\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1520 - accuracy: 0.9451 - val_loss: 0.7459 - val_accuracy: 0.7726\n","Epoch 80/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1269 - accuracy: 0.9542 - val_loss: 0.7285 - val_accuracy: 0.7862\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1318 - accuracy: 0.9516 - val_loss: 0.7361 - val_accuracy: 0.7771\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1358 - accuracy: 0.9502 - val_loss: 0.7605 - val_accuracy: 0.7896\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1326 - accuracy: 0.9561 - val_loss: 0.7811 - val_accuracy: 0.7839\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1301 - accuracy: 0.9525 - val_loss: 0.7548 - val_accuracy: 0.7817\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1458 - accuracy: 0.9519 - val_loss: 0.7951 - val_accuracy: 0.7794\n","Epoch 86/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1369 - accuracy: 0.9496 - val_loss: 0.7959 - val_accuracy: 0.7851\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1433 - accuracy: 0.9488 - val_loss: 0.8011 - val_accuracy: 0.7828\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1376 - accuracy: 0.9479 - val_loss: 0.7779 - val_accuracy: 0.7760\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1387 - accuracy: 0.9539 - val_loss: 0.7838 - val_accuracy: 0.7828\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1304 - accuracy: 0.9584 - val_loss: 0.9003 - val_accuracy: 0.7489\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1204 - accuracy: 0.9578 - val_loss: 0.8019 - val_accuracy: 0.7681\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1327 - accuracy: 0.9533 - val_loss: 0.8256 - val_accuracy: 0.7681\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1216 - accuracy: 0.9581 - val_loss: 0.8332 - val_accuracy: 0.7794\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1280 - accuracy: 0.9573 - val_loss: 0.8122 - val_accuracy: 0.7726\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1329 - accuracy: 0.9550 - val_loss: 0.8203 - val_accuracy: 0.7828\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.9621 - val_loss: 0.8163 - val_accuracy: 0.7715\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1192 - accuracy: 0.9578 - val_loss: 0.9670 - val_accuracy: 0.7489\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1397 - accuracy: 0.9505 - val_loss: 0.8157 - val_accuracy: 0.7692\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1124 - accuracy: 0.9652 - val_loss: 0.8292 - val_accuracy: 0.7794\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1186 - accuracy: 0.9590 - val_loss: 0.8465 - val_accuracy: 0.7647\n","{'loss': [0.29681330919265747, 0.2839754521846771, 0.2761337161064148, 0.26881691813468933, 0.25803500413894653, 0.2706873118877411, 0.2634370028972626, 0.2645419239997864, 0.2681627869606018, 0.2452898919582367, 0.24488481879234314, 0.2503156065940857, 0.25506436824798584, 0.2400263547897339, 0.23827631771564484, 0.24861235916614532, 0.23960132896900177, 0.2355842888355255, 0.2236834168434143, 0.22630225121974945, 0.22842083871364594, 0.2305808663368225, 0.2251908779144287, 0.2158021777868271, 0.23465420305728912, 0.22093020379543304, 0.22367388010025024, 0.22372804582118988, 0.21000680327415466, 0.21916493773460388, 0.21258819103240967, 0.2132311314344406, 0.1952374428510666, 0.20117859542369843, 0.19529925286769867, 0.19895265996456146, 0.1907631754875183, 0.20328032970428467, 0.19923163950443268, 0.19770307838916779, 0.19820941984653473, 0.1959669589996338, 0.18393638730049133, 0.18740332126617432, 0.1868341565132141, 0.1753573715686798, 0.1786748766899109, 0.17731787264347076, 0.1997377723455429, 0.17767977714538574, 0.17565949261188507, 0.1767836958169937, 0.1850016713142395, 0.17248016595840454, 0.16542170941829681, 0.1876179277896881, 0.16286468505859375, 0.16440513730049133, 0.16252461075782776, 0.16443368792533875, 0.15625259280204773, 0.15305328369140625, 0.16985192894935608, 0.15326695144176483, 0.16009536385536194, 0.15139609575271606, 0.154401957988739, 0.16830535233020782, 0.15820875763893127, 0.15705713629722595, 0.15661238133907318, 0.1610160619020462, 0.15449835360050201, 0.1450100988149643, 0.14814898371696472, 0.14129787683486938, 0.15491223335266113, 0.14044208824634552, 0.15197986364364624, 0.12692034244537354, 0.1318385899066925, 0.1358078122138977, 0.13256126642227173, 0.13011015951633453, 0.14580991864204407, 0.1368607133626938, 0.1432749480009079, 0.13762731850147247, 0.13869065046310425, 0.13043344020843506, 0.12036208808422089, 0.1327260285615921, 0.12162388116121292, 0.12804847955703735, 0.13290517032146454, 0.12584517896175385, 0.11923010647296906, 0.13966768980026245, 0.11240328103303909, 0.11858193576335907], 'accuracy': [0.8814374804496765, 0.8780418634414673, 0.8834182024002075, 0.8853989839553833, 0.8859649300575256, 0.884833037853241, 0.8984153866767883, 0.8899264335632324, 0.8890775442123413, 0.9020939469337463, 0.8981324434280396, 0.897849440574646, 0.8992642760276794, 0.9018110036849976, 0.9049236178398132, 0.8986983299255371, 0.9049236178398132, 0.9063384532928467, 0.9128466248512268, 0.9117147922515869, 0.90888512134552, 0.9066213965415955, 0.9097340106964111, 0.912563681602478, 0.9066213965415955, 0.9139785170555115, 0.9094510674476624, 0.9179400205612183, 0.9196377992630005, 0.90888512134552, 0.9153932929039001, 0.9156762957572937, 0.9286926984786987, 0.9216185808181763, 0.9252971410751343, 0.9281267523765564, 0.9289756417274475, 0.921901524066925, 0.9216185808181763, 0.9247311949729919, 0.9278438091278076, 0.9224674701690674, 0.9298245906829834, 0.9289756417274475, 0.9332201480865479, 0.9346349835395813, 0.9337860941886902, 0.9360498189926147, 0.9221844673156738, 0.9306734800338745, 0.9352009296417236, 0.9349179267883301, 0.9400113224983215, 0.9405772686004639, 0.9425579905509949, 0.9258630275726318, 0.9400113224983215, 0.9354838728904724, 0.9394453763961792, 0.9357668161392212, 0.9473684430122375, 0.9468024969100952, 0.9380305409431458, 0.9487832188606262, 0.943406879901886, 0.9499151110649109, 0.9439728260040283, 0.9354838728904724, 0.9436898827552795, 0.9482173323631287, 0.945104718208313, 0.9391624331474304, 0.9462365508079529, 0.9501980543136597, 0.9445387721061707, 0.9516128897666931, 0.9439728260040283, 0.9510469436645508, 0.945104718208313, 0.9541596174240112, 0.9516128897666931, 0.9501980543136597, 0.9561403393745422, 0.9524617791175842, 0.9518958926200867, 0.9496321678161621, 0.9487832188606262, 0.9479343295097351, 0.9538766145706177, 0.9584040641784668, 0.9578381180763245, 0.9533106684684753, 0.958121120929718, 0.9572722315788269, 0.9550085067749023, 0.9620826244354248, 0.9578381180763245, 0.9504810571670532, 0.9651952385902405, 0.9589700102806091], 'val_loss': [1.278914451599121, 1.2578003406524658, 1.2602289915084839, 1.2511903047561646, 1.2557991743087769, 1.2321255207061768, 1.218328833580017, 1.233565330505371, 1.2183928489685059, 1.1906847953796387, 1.1718147993087769, 1.1723848581314087, 1.1950803995132446, 1.0883283615112305, 1.0018399953842163, 0.9400956034660339, 0.9816868305206299, 0.9274434447288513, 0.882148265838623, 0.6863872408866882, 0.6910333633422852, 0.8095012903213501, 0.6378580331802368, 0.5258768796920776, 0.5563592910766602, 0.6067131757736206, 0.6372078061103821, 0.5614508390426636, 0.6257044672966003, 0.6466659903526306, 0.5782671570777893, 0.5903033018112183, 0.5963330268859863, 0.6033870577812195, 0.6609720587730408, 0.625619649887085, 0.6068105101585388, 0.6083126068115234, 0.6272270679473877, 0.6943101286888123, 0.7025216817855835, 0.6503894329071045, 0.6978318691253662, 0.6674392223358154, 0.6340729594230652, 0.6542887091636658, 0.6661930084228516, 0.6468162536621094, 0.6702971458435059, 0.6514124870300293, 0.6600757241249084, 0.676736056804657, 0.6851820945739746, 0.6498025059700012, 0.6716176271438599, 0.6943385601043701, 0.685368001461029, 0.6806291341781616, 0.7063374519348145, 0.6847225427627563, 0.6876227855682373, 0.6910743713378906, 0.7247679233551025, 0.7014716863632202, 0.711633563041687, 0.7005598545074463, 0.7303057909011841, 0.7141662836074829, 0.7581298351287842, 0.7342890501022339, 0.7635149955749512, 0.7345258593559265, 0.7532417178153992, 0.7479621171951294, 0.7582522630691528, 0.7840737700462341, 0.7374861240386963, 0.7280043959617615, 0.7459020018577576, 0.7284948825836182, 0.7361249923706055, 0.7604513764381409, 0.7810744643211365, 0.7547686696052551, 0.795070469379425, 0.7958974242210388, 0.8010959625244141, 0.7779077291488647, 0.7838069200515747, 0.9003235101699829, 0.801867663860321, 0.8255599141120911, 0.8332297801971436, 0.8121556639671326, 0.8202746510505676, 0.8162991404533386, 0.9670235514640808, 0.8157235980033875, 0.829216718673706, 0.8465259075164795], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.4977375566959381, 0.49886876344680786, 0.49886876344680786, 0.5022624731063843, 0.5067873597145081, 0.5101810097694397, 0.5113122463226318, 0.5147058963775635, 0.5350678563117981, 0.5441176295280457, 0.5633484125137329, 0.5531674027442932, 0.5848416090011597, 0.610859751701355, 0.668552041053772, 0.6753393411636353, 0.6527149081230164, 0.7013574838638306, 0.7839366793632507, 0.7748869061470032, 0.7488687634468079, 0.7341628670692444, 0.7952488660812378, 0.7590497732162476, 0.7613122463226318, 0.7828054428100586, 0.7986425161361694, 0.7884615659713745, 0.7828054428100586, 0.7726244330406189, 0.7850678563117981, 0.7929864525794983, 0.8009049892425537, 0.7918552160263062, 0.7488687634468079, 0.7703620195388794, 0.7760180830955505, 0.7726244330406189, 0.779411792755127, 0.7952488660812378, 0.7895927429199219, 0.7918552160263062, 0.7816742062568665, 0.7816742062568665, 0.7941176295280457, 0.7884615659713745, 0.7805429697036743, 0.7861990928649902, 0.7986425161361694, 0.779411792755127, 0.7850678563117981, 0.7850678563117981, 0.7884615659713745, 0.779411792755127, 0.7782805562019348, 0.779411792755127, 0.7963801026344299, 0.7771493196487427, 0.7839366793632507, 0.7861990928649902, 0.7839366793632507, 0.7771493196487427, 0.7760180830955505, 0.766968309879303, 0.779411792755127, 0.7624434232711792, 0.773755669593811, 0.7692307829856873, 0.7839366793632507, 0.7782805562019348, 0.7613122463226318, 0.7839366793632507, 0.7895927429199219, 0.7726244330406189, 0.7861990928649902, 0.7771493196487427, 0.7895927429199219, 0.7839366793632507, 0.7816742062568665, 0.779411792755127, 0.7850678563117981, 0.7828054428100586, 0.7760180830955505, 0.7828054428100586, 0.7488687634468079, 0.7680995464324951, 0.7680995464324951, 0.779411792755127, 0.7726244330406189, 0.7828054428100586, 0.7714931964874268, 0.7488687634468079, 0.7692307829856873, 0.779411792755127, 0.7647058963775635]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.3206 - accuracy: 0.8655"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 7s 49ms/step - loss: 0.3228 - accuracy: 0.8656 - val_loss: 1.2837 - val_accuracy: 0.4876\n","Epoch 2/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2979 - accuracy: 0.8762 - val_loss: 1.2682 - val_accuracy: 0.4876\n","Epoch 3/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2818 - accuracy: 0.8793 - val_loss: 1.2575 - val_accuracy: 0.4876\n","Epoch 4/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2850 - accuracy: 0.8798 - val_loss: 1.2545 - val_accuracy: 0.4886\n","Epoch 5/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2794 - accuracy: 0.8762 - val_loss: 1.2448 - val_accuracy: 0.4897\n","Epoch 6/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2721 - accuracy: 0.8902 - val_loss: 1.2706 - val_accuracy: 0.4897\n","Epoch 7/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2641 - accuracy: 0.8902 - val_loss: 1.2715 - val_accuracy: 0.4907\n","Epoch 8/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2727 - accuracy: 0.8829 - val_loss: 1.2499 - val_accuracy: 0.4948\n","Epoch 9/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2527 - accuracy: 0.8956 - val_loss: 1.2343 - val_accuracy: 0.4969\n","Epoch 10/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.2664 - accuracy: 0.8897 - val_loss: 1.2101 - val_accuracy: 0.5010\n","Epoch 11/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2547 - accuracy: 0.9008 - val_loss: 1.2316 - val_accuracy: 0.5000\n","Epoch 12/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.2510 - accuracy: 0.8946 - val_loss: 1.2095 - val_accuracy: 0.5052\n","Epoch 13/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.2548 - accuracy: 0.8974 - val_loss: 1.2159 - val_accuracy: 0.5145\n","Epoch 14/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.2392 - accuracy: 0.9028 - val_loss: 1.1707 - val_accuracy: 0.5186\n","Epoch 15/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.2440 - accuracy: 0.8987 - val_loss: 1.1576 - val_accuracy: 0.5258\n","Epoch 16/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2428 - accuracy: 0.8972 - val_loss: 1.0038 - val_accuracy: 0.5620\n","Epoch 17/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2448 - accuracy: 0.8946 - val_loss: 1.0843 - val_accuracy: 0.5558\n","Epoch 18/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2370 - accuracy: 0.8997 - val_loss: 0.9590 - val_accuracy: 0.5919\n","Epoch 19/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2341 - accuracy: 0.9010 - val_loss: 0.8797 - val_accuracy: 0.6095\n","Epoch 20/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2367 - accuracy: 0.9018 - val_loss: 0.8050 - val_accuracy: 0.6405\n","Epoch 21/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2309 - accuracy: 0.9047 - val_loss: 0.7149 - val_accuracy: 0.6839\n","Epoch 22/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2322 - accuracy: 0.9036 - val_loss: 0.7075 - val_accuracy: 0.7045\n","Epoch 23/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2297 - accuracy: 0.9065 - val_loss: 0.6587 - val_accuracy: 0.7448\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2353 - accuracy: 0.9013 - val_loss: 0.6371 - val_accuracy: 0.7428\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2280 - accuracy: 0.9059 - val_loss: 0.7041 - val_accuracy: 0.7118\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2099 - accuracy: 0.9137 - val_loss: 0.6674 - val_accuracy: 0.7438\n","Epoch 27/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2318 - accuracy: 0.9062 - val_loss: 0.6412 - val_accuracy: 0.7676\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2154 - accuracy: 0.9132 - val_loss: 0.6892 - val_accuracy: 0.7500\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2137 - accuracy: 0.9114 - val_loss: 0.6990 - val_accuracy: 0.7645\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2129 - accuracy: 0.9168 - val_loss: 0.6831 - val_accuracy: 0.7531\n","Epoch 31/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2188 - accuracy: 0.9124 - val_loss: 0.7399 - val_accuracy: 0.7479\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2165 - accuracy: 0.9121 - val_loss: 0.6950 - val_accuracy: 0.7521\n","Epoch 33/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2079 - accuracy: 0.9202 - val_loss: 0.6884 - val_accuracy: 0.7614\n","Epoch 34/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2035 - accuracy: 0.9202 - val_loss: 0.6948 - val_accuracy: 0.7624\n","Epoch 35/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2177 - accuracy: 0.9111 - val_loss: 0.6987 - val_accuracy: 0.7479\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2022 - accuracy: 0.9176 - val_loss: 0.6981 - val_accuracy: 0.7593\n","Epoch 37/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2054 - accuracy: 0.9189 - val_loss: 0.7293 - val_accuracy: 0.7541\n","Epoch 38/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2055 - accuracy: 0.9204 - val_loss: 0.7570 - val_accuracy: 0.7324\n","Epoch 39/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2023 - accuracy: 0.9207 - val_loss: 0.7315 - val_accuracy: 0.7459\n","Epoch 40/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2071 - accuracy: 0.9225 - val_loss: 0.7620 - val_accuracy: 0.7469\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1963 - accuracy: 0.9248 - val_loss: 0.7419 - val_accuracy: 0.7572\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1961 - accuracy: 0.9238 - val_loss: 0.7334 - val_accuracy: 0.7490\n","Epoch 43/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1891 - accuracy: 0.9274 - val_loss: 0.7711 - val_accuracy: 0.7531\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1854 - accuracy: 0.9258 - val_loss: 0.7378 - val_accuracy: 0.7562\n","Epoch 45/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.1879 - accuracy: 0.9276 - val_loss: 0.7548 - val_accuracy: 0.7479\n","Epoch 46/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1786 - accuracy: 0.9276 - val_loss: 0.7470 - val_accuracy: 0.7479\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1852 - accuracy: 0.9289 - val_loss: 0.7775 - val_accuracy: 0.7479\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2398 - accuracy: 0.9158 - val_loss: 0.9013 - val_accuracy: 0.7510\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2222 - accuracy: 0.9121 - val_loss: 1.0688 - val_accuracy: 0.6674\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2070 - accuracy: 0.9150 - val_loss: 0.9047 - val_accuracy: 0.7366\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2102 - accuracy: 0.9163 - val_loss: 0.8139 - val_accuracy: 0.7490\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1866 - accuracy: 0.9287 - val_loss: 0.8106 - val_accuracy: 0.7500\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1791 - accuracy: 0.9302 - val_loss: 0.8434 - val_accuracy: 0.7583\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1862 - accuracy: 0.9230 - val_loss: 0.8405 - val_accuracy: 0.7552\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1744 - accuracy: 0.9351 - val_loss: 0.8230 - val_accuracy: 0.7531\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1804 - accuracy: 0.9300 - val_loss: 0.8383 - val_accuracy: 0.7417\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1809 - accuracy: 0.9269 - val_loss: 0.8349 - val_accuracy: 0.7459\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1682 - accuracy: 0.9370 - val_loss: 0.8157 - val_accuracy: 0.7469\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1692 - accuracy: 0.9333 - val_loss: 0.8279 - val_accuracy: 0.7459\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1641 - accuracy: 0.9362 - val_loss: 0.8555 - val_accuracy: 0.7541\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1625 - accuracy: 0.9424 - val_loss: 0.8349 - val_accuracy: 0.7407\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1660 - accuracy: 0.9331 - val_loss: 0.8438 - val_accuracy: 0.7355\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1669 - accuracy: 0.9362 - val_loss: 0.8180 - val_accuracy: 0.7469\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1602 - accuracy: 0.9354 - val_loss: 0.8078 - val_accuracy: 0.7500\n","Epoch 65/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1613 - accuracy: 0.9375 - val_loss: 0.8593 - val_accuracy: 0.7407\n","Epoch 66/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1633 - accuracy: 0.9354 - val_loss: 0.8125 - val_accuracy: 0.7521\n","Epoch 67/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.1559 - accuracy: 0.9411 - val_loss: 0.8446 - val_accuracy: 0.7665\n","Epoch 68/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1566 - accuracy: 0.9393 - val_loss: 0.8561 - val_accuracy: 0.7521\n","Epoch 69/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1625 - accuracy: 0.9362 - val_loss: 0.8628 - val_accuracy: 0.7479\n","Epoch 70/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1522 - accuracy: 0.9398 - val_loss: 0.8758 - val_accuracy: 0.7490\n","Epoch 71/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1509 - accuracy: 0.9411 - val_loss: 0.8754 - val_accuracy: 0.7386\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1562 - accuracy: 0.9432 - val_loss: 0.8798 - val_accuracy: 0.7469\n","Epoch 73/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1712 - accuracy: 0.9300 - val_loss: 1.0054 - val_accuracy: 0.7324\n","Epoch 74/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1790 - accuracy: 0.9297 - val_loss: 0.9284 - val_accuracy: 0.7335\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1732 - accuracy: 0.9289 - val_loss: 0.9373 - val_accuracy: 0.7428\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1529 - accuracy: 0.9398 - val_loss: 0.8628 - val_accuracy: 0.7407\n","Epoch 77/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1662 - accuracy: 0.9362 - val_loss: 0.9624 - val_accuracy: 0.7407\n","Epoch 78/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1565 - accuracy: 0.9357 - val_loss: 0.8688 - val_accuracy: 0.7438\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1434 - accuracy: 0.9483 - val_loss: 0.8823 - val_accuracy: 0.7603\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1485 - accuracy: 0.9429 - val_loss: 0.8882 - val_accuracy: 0.7428\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1463 - accuracy: 0.9452 - val_loss: 0.8865 - val_accuracy: 0.7500\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1409 - accuracy: 0.9465 - val_loss: 0.8778 - val_accuracy: 0.7438\n","Epoch 83/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1504 - accuracy: 0.9393 - val_loss: 0.9212 - val_accuracy: 0.7221\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1424 - accuracy: 0.9444 - val_loss: 0.9111 - val_accuracy: 0.7541\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1369 - accuracy: 0.9450 - val_loss: 0.9014 - val_accuracy: 0.7345\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1373 - accuracy: 0.9463 - val_loss: 0.9182 - val_accuracy: 0.7397\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1362 - accuracy: 0.9452 - val_loss: 1.0596 - val_accuracy: 0.7159\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1811 - accuracy: 0.9289 - val_loss: 0.9832 - val_accuracy: 0.7428\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1386 - accuracy: 0.9463 - val_loss: 0.9237 - val_accuracy: 0.7366\n","Epoch 90/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1333 - accuracy: 0.9468 - val_loss: 0.9185 - val_accuracy: 0.7386\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1465 - accuracy: 0.9416 - val_loss: 0.9797 - val_accuracy: 0.7252\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1392 - accuracy: 0.9444 - val_loss: 0.9336 - val_accuracy: 0.7417\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1298 - accuracy: 0.9504 - val_loss: 0.9187 - val_accuracy: 0.7304\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1310 - accuracy: 0.9478 - val_loss: 1.0054 - val_accuracy: 0.7386\n","Epoch 95/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1481 - accuracy: 0.9406 - val_loss: 0.9253 - val_accuracy: 0.7428\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1358 - accuracy: 0.9514 - val_loss: 1.0762 - val_accuracy: 0.7479\n","Epoch 97/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.1448 - accuracy: 0.9398 - val_loss: 1.0437 - val_accuracy: 0.7355\n","Epoch 98/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1298 - accuracy: 0.9494 - val_loss: 0.9461 - val_accuracy: 0.7479\n","Epoch 99/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1260 - accuracy: 0.9561 - val_loss: 0.9605 - val_accuracy: 0.7397\n","Epoch 100/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.1337 - accuracy: 0.9475 - val_loss: 0.9695 - val_accuracy: 0.7376\n","{'loss': [0.322836309671402, 0.29791101813316345, 0.2817980945110321, 0.28502795100212097, 0.27940690517425537, 0.27211326360702515, 0.264119029045105, 0.2727361023426056, 0.252713143825531, 0.2663787305355072, 0.2546923756599426, 0.25104790925979614, 0.25482407212257385, 0.23921777307987213, 0.24396586418151855, 0.24281573295593262, 0.24482545256614685, 0.23704563081264496, 0.23405475914478302, 0.23665349185466766, 0.2309279441833496, 0.2322128862142563, 0.22969084978103638, 0.23534272611141205, 0.2280266135931015, 0.20985117554664612, 0.2318277209997177, 0.2153797447681427, 0.21366634964942932, 0.2128506600856781, 0.21875278651714325, 0.2164902687072754, 0.20789402723312378, 0.20351988077163696, 0.21770359575748444, 0.2022022008895874, 0.20543166995048523, 0.20550115406513214, 0.20229466259479523, 0.20712105929851532, 0.1963087022304535, 0.19606487452983856, 0.18905849754810333, 0.1854228675365448, 0.18789255619049072, 0.17856308817863464, 0.18524639308452606, 0.23983685672283173, 0.22224697470664978, 0.20704945921897888, 0.21019543707370758, 0.18661445379257202, 0.17911770939826965, 0.18616902828216553, 0.17439833283424377, 0.1804354041814804, 0.18093092739582062, 0.1682336926460266, 0.16920050978660583, 0.16412308812141418, 0.16249513626098633, 0.1659860908985138, 0.1668810397386551, 0.1601944863796234, 0.16134501993656158, 0.16325643658638, 0.15594710409641266, 0.15661099553108215, 0.16253788769245148, 0.1522139310836792, 0.15091678500175476, 0.15615873038768768, 0.1712053418159485, 0.17896819114685059, 0.17322784662246704, 0.15290777385234833, 0.16620740294456482, 0.15647701919078827, 0.14336173236370087, 0.1484586000442505, 0.14634229242801666, 0.14087295532226562, 0.15036217868328094, 0.14236189424991608, 0.1368938386440277, 0.13734373450279236, 0.13624539971351624, 0.18110568821430206, 0.1386100947856903, 0.13328924775123596, 0.146500363945961, 0.13915656507015228, 0.12978264689445496, 0.1310139298439026, 0.14805109798908234, 0.13578695058822632, 0.14479097723960876, 0.1297820657491684, 0.12596340477466583, 0.13372547924518585], 'accuracy': [0.8656330704689026, 0.8762273788452148, 0.879328191280365, 0.8798449635505676, 0.8762273788452148, 0.8901808857917786, 0.8901808857917786, 0.882945716381073, 0.8956072330474854, 0.8896640539169312, 0.9007751941680908, 0.8945736289024353, 0.8974159955978394, 0.9028424024581909, 0.8987079858779907, 0.897157609462738, 0.8945736289024353, 0.8997415900230408, 0.9010335803031921, 0.9018087983131409, 0.9046511650085449, 0.9036175608634949, 0.9064599275588989, 0.9012919664382935, 0.9059431552886963, 0.9136950969696045, 0.9062015414237976, 0.9131782650947571, 0.9113695025444031, 0.9167958498001099, 0.9124031066894531, 0.9121447205543518, 0.9201550483703613, 0.9201550483703613, 0.9111111164093018, 0.9175710678100586, 0.91886305809021, 0.9204134345054626, 0.920671820640564, 0.9224806427955627, 0.9248061776161194, 0.9237726330757141, 0.9273901581764221, 0.9258397817611694, 0.9276486039161682, 0.9276486039161682, 0.9289405941963196, 0.9157622456550598, 0.9121447205543518, 0.9149870872497559, 0.9162790775299072, 0.9286821484565735, 0.930232584476471, 0.9229974150657654, 0.9351420998573303, 0.9299741387367249, 0.9268733859062195, 0.9369509220123291, 0.9333333373069763, 0.9361757040023804, 0.9423772692680359, 0.933074951171875, 0.9361757040023804, 0.9354005455970764, 0.9374676942825317, 0.9354005455970764, 0.9410852789878845, 0.9392764568328857, 0.9361757040023804, 0.9397932887077332, 0.9410852789878845, 0.9431524276733398, 0.9299741387367249, 0.9297157526016235, 0.9289405941963196, 0.9397932887077332, 0.9361757040023804, 0.9356589317321777, 0.9483203887939453, 0.9428940415382385, 0.9452196359634399, 0.9465116262435913, 0.9392764568328857, 0.9444444179534912, 0.9449612498283386, 0.94625324010849, 0.9452196359634399, 0.9289405941963196, 0.94625324010849, 0.9467700123786926, 0.9416020512580872, 0.9444444179534912, 0.9503875970840454, 0.9478036165237427, 0.9405684471130371, 0.9514212012290955, 0.9397932887077332, 0.9493539929389954, 0.9560723304748535, 0.9475452303886414], 'val_loss': [1.2836873531341553, 1.268203854560852, 1.2574578523635864, 1.2544997930526733, 1.2447724342346191, 1.270625114440918, 1.2715274095535278, 1.2499058246612549, 1.2342942953109741, 1.210080623626709, 1.2315542697906494, 1.2094817161560059, 1.2159188985824585, 1.17069673538208, 1.1575626134872437, 1.003764033317566, 1.0842946767807007, 0.9589728713035583, 0.8796911239624023, 0.8049898743629456, 0.7148547172546387, 0.707462728023529, 0.6587470173835754, 0.6370629072189331, 0.7040678262710571, 0.6674429774284363, 0.6412187814712524, 0.689210057258606, 0.6990165114402771, 0.6830652356147766, 0.7398620247840881, 0.6950180530548096, 0.6883503198623657, 0.6948028206825256, 0.6986913681030273, 0.698098361492157, 0.7292914390563965, 0.7569992542266846, 0.7315113544464111, 0.7620286345481873, 0.7419028282165527, 0.7333733439445496, 0.7710957527160645, 0.7378425002098083, 0.7548395395278931, 0.7470210790634155, 0.7775253653526306, 0.9013435244560242, 1.0688347816467285, 0.9046956300735474, 0.8138625025749207, 0.8105554580688477, 0.8434287309646606, 0.8405493497848511, 0.8230370879173279, 0.8383163809776306, 0.8349218368530273, 0.8156709671020508, 0.8279306888580322, 0.8554670214653015, 0.8348833918571472, 0.8437747359275818, 0.8179803490638733, 0.8078081011772156, 0.8592725992202759, 0.8124620318412781, 0.8446016907691956, 0.8561224937438965, 0.8627562522888184, 0.8758237361907959, 0.875419020652771, 0.8797551393508911, 1.005405068397522, 0.9284056425094604, 0.9373195171356201, 0.862816572189331, 0.9624313116073608, 0.8687825202941895, 0.8822864294052124, 0.8882400989532471, 0.8865349888801575, 0.8777718544006348, 0.9212223291397095, 0.9110567569732666, 0.9014170169830322, 0.9182407855987549, 1.0596169233322144, 0.9831776022911072, 0.923749566078186, 0.9184778928756714, 0.9797450304031372, 0.933608889579773, 0.9187008738517761, 1.0054264068603516, 0.9252632260322571, 1.0761759281158447, 1.0436620712280273, 0.9461003541946411, 0.9604697823524475, 0.9694898128509521], 'val_accuracy': [0.4876033067703247, 0.4876033067703247, 0.4876033067703247, 0.4886363744735718, 0.48966941237449646, 0.48966941237449646, 0.49070248007774353, 0.4948347210884094, 0.4969008266925812, 0.5010330677032471, 0.5, 0.5051652789115906, 0.5144628286361694, 0.5185950398445129, 0.5258264541625977, 0.5619834661483765, 0.5557851195335388, 0.5919421315193176, 0.6095041036605835, 0.6404958963394165, 0.68388432264328, 0.7045454382896423, 0.7448347210884094, 0.7427685856819153, 0.711776852607727, 0.7438016533851624, 0.7675619721412659, 0.75, 0.7644628286361694, 0.7530992031097412, 0.7479338645935059, 0.7520661354064941, 0.7613636255264282, 0.7623966932296753, 0.7479338645935059, 0.7592975497245789, 0.7541322112083435, 0.7324380278587341, 0.7458677887916565, 0.7469007968902588, 0.7572314143180847, 0.7489669322967529, 0.7530992031097412, 0.7561983466148376, 0.7479338645935059, 0.7479338645935059, 0.7479338645935059, 0.7510330677032471, 0.6673553586006165, 0.7365702390670776, 0.7489669322967529, 0.75, 0.7582644820213318, 0.7551652789115906, 0.7530992031097412, 0.7417355179786682, 0.7458677887916565, 0.7469007968902588, 0.7458677887916565, 0.7541322112083435, 0.7407024502754211, 0.7355371713638306, 0.7469007968902588, 0.75, 0.7407024502754211, 0.7520661354064941, 0.7665289044380188, 0.7520661354064941, 0.7479338645935059, 0.7489669322967529, 0.7386363744735718, 0.7469007968902588, 0.7324380278587341, 0.7334710955619812, 0.7427685856819153, 0.7407024502754211, 0.7407024502754211, 0.7438016533851624, 0.7603305578231812, 0.7427685856819153, 0.75, 0.7438016533851624, 0.7221074104309082, 0.7541322112083435, 0.7345041036605835, 0.7396694421768188, 0.7159090638160706, 0.7427685856819153, 0.7365702390670776, 0.7386363744735718, 0.7252066135406494, 0.7417355179786682, 0.73037189245224, 0.7386363744735718, 0.7427685856819153, 0.7479338645935059, 0.7355371713638306, 0.7479338645935059, 0.7396694421768188, 0.7376033067703247]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.1915 - accuracy: 0.9255"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 8s 60ms/step - loss: 0.1910 - accuracy: 0.9270 - val_loss: 1.7010 - val_accuracy: 0.4860\n","Epoch 2/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1891 - accuracy: 0.9248 - val_loss: 1.7166 - val_accuracy: 0.4860\n","Epoch 3/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1806 - accuracy: 0.9337 - val_loss: 1.6859 - val_accuracy: 0.4860\n","Epoch 4/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1729 - accuracy: 0.9300 - val_loss: 1.6737 - val_accuracy: 0.4860\n","Epoch 5/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1673 - accuracy: 0.9356 - val_loss: 1.6975 - val_accuracy: 0.4860\n","Epoch 6/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1741 - accuracy: 0.9321 - val_loss: 1.6438 - val_accuracy: 0.4871\n","Epoch 7/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1717 - accuracy: 0.9337 - val_loss: 1.6844 - val_accuracy: 0.4860\n","Epoch 8/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1490 - accuracy: 0.9415 - val_loss: 1.6517 - val_accuracy: 0.4881\n","Epoch 9/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1495 - accuracy: 0.9464 - val_loss: 1.6004 - val_accuracy: 0.4946\n","Epoch 10/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1637 - accuracy: 0.9313 - val_loss: 1.6704 - val_accuracy: 0.4925\n","Epoch 11/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1571 - accuracy: 0.9383 - val_loss: 1.6190 - val_accuracy: 0.4978\n","Epoch 12/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.1430 - accuracy: 0.9472 - val_loss: 1.6188 - val_accuracy: 0.5022\n","Epoch 13/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1543 - accuracy: 0.9410 - val_loss: 1.5501 - val_accuracy: 0.5129\n","Epoch 14/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1432 - accuracy: 0.9459 - val_loss: 1.4547 - val_accuracy: 0.5312\n","Epoch 15/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1389 - accuracy: 0.9472 - val_loss: 1.4394 - val_accuracy: 0.5453\n","Epoch 16/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1358 - accuracy: 0.9480 - val_loss: 1.3655 - val_accuracy: 0.5582\n","Epoch 17/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1403 - accuracy: 0.9475 - val_loss: 1.3453 - val_accuracy: 0.5711\n","Epoch 18/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1358 - accuracy: 0.9499 - val_loss: 1.1632 - val_accuracy: 0.5970\n","Epoch 19/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.1380 - accuracy: 0.9480 - val_loss: 1.0756 - val_accuracy: 0.6250\n","Epoch 20/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.1331 - accuracy: 0.9502 - val_loss: 1.1223 - val_accuracy: 0.6315\n","Epoch 21/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.1192 - accuracy: 0.9555 - val_loss: 0.9069 - val_accuracy: 0.6853\n","Epoch 22/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.1306 - accuracy: 0.9499 - val_loss: 0.8135 - val_accuracy: 0.7144\n","Epoch 23/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.1282 - accuracy: 0.9537 - val_loss: 0.6853 - val_accuracy: 0.7446\n","Epoch 24/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1233 - accuracy: 0.9520 - val_loss: 0.7312 - val_accuracy: 0.7532\n","Epoch 25/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1287 - accuracy: 0.9550 - val_loss: 0.6525 - val_accuracy: 0.7856\n","Epoch 26/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1296 - accuracy: 0.9553 - val_loss: 0.7095 - val_accuracy: 0.7726\n","Epoch 27/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1205 - accuracy: 0.9520 - val_loss: 0.6146 - val_accuracy: 0.8136\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1224 - accuracy: 0.9550 - val_loss: 0.7023 - val_accuracy: 0.8028\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1184 - accuracy: 0.9577 - val_loss: 0.6857 - val_accuracy: 0.8103\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1449 - accuracy: 0.9426 - val_loss: 0.7550 - val_accuracy: 0.7856\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1396 - accuracy: 0.9507 - val_loss: 0.7520 - val_accuracy: 0.8028\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1309 - accuracy: 0.9518 - val_loss: 0.7624 - val_accuracy: 0.8017\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1947 - accuracy: 0.9294 - val_loss: 0.8479 - val_accuracy: 0.7748\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1434 - accuracy: 0.9415 - val_loss: 0.8452 - val_accuracy: 0.7877\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1164 - accuracy: 0.9553 - val_loss: 0.7985 - val_accuracy: 0.7705\n","Epoch 36/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1260 - accuracy: 0.9580 - val_loss: 0.7883 - val_accuracy: 0.8039\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1164 - accuracy: 0.9566 - val_loss: 0.7588 - val_accuracy: 0.8028\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1106 - accuracy: 0.9572 - val_loss: 0.7260 - val_accuracy: 0.8103\n","Epoch 39/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1197 - accuracy: 0.9550 - val_loss: 0.8966 - val_accuracy: 0.7845\n","Epoch 40/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1162 - accuracy: 0.9561 - val_loss: 0.7838 - val_accuracy: 0.7974\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1211 - accuracy: 0.9553 - val_loss: 0.8146 - val_accuracy: 0.7909\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1124 - accuracy: 0.9577 - val_loss: 0.8027 - val_accuracy: 0.7942\n","Epoch 43/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1083 - accuracy: 0.9601 - val_loss: 0.7506 - val_accuracy: 0.8050\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1095 - accuracy: 0.9593 - val_loss: 0.8581 - val_accuracy: 0.7974\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1183 - accuracy: 0.9547 - val_loss: 0.7945 - val_accuracy: 0.8103\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1024 - accuracy: 0.9601 - val_loss: 0.7586 - val_accuracy: 0.8050\n","Epoch 47/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0939 - accuracy: 0.9663 - val_loss: 0.7947 - val_accuracy: 0.8050\n","Epoch 48/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0952 - accuracy: 0.9698 - val_loss: 0.7714 - val_accuracy: 0.8082\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1085 - accuracy: 0.9647 - val_loss: 0.8104 - val_accuracy: 0.7942\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1096 - accuracy: 0.9591 - val_loss: 0.9845 - val_accuracy: 0.7823\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1050 - accuracy: 0.9596 - val_loss: 0.7845 - val_accuracy: 0.8050\n","Epoch 52/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0970 - accuracy: 0.9679 - val_loss: 0.8233 - val_accuracy: 0.7996\n","Epoch 53/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0985 - accuracy: 0.9669 - val_loss: 0.8220 - val_accuracy: 0.8006\n","Epoch 54/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0896 - accuracy: 0.9698 - val_loss: 0.8066 - val_accuracy: 0.8060\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0984 - accuracy: 0.9666 - val_loss: 0.8383 - val_accuracy: 0.8017\n","Epoch 56/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1059 - accuracy: 0.9588 - val_loss: 0.9027 - val_accuracy: 0.7877\n","Epoch 57/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1013 - accuracy: 0.9585 - val_loss: 0.8698 - val_accuracy: 0.7942\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0886 - accuracy: 0.9696 - val_loss: 0.8299 - val_accuracy: 0.7909\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0929 - accuracy: 0.9663 - val_loss: 0.8139 - val_accuracy: 0.8028\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0877 - accuracy: 0.9704 - val_loss: 0.8335 - val_accuracy: 0.8028\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1056 - accuracy: 0.9647 - val_loss: 0.8748 - val_accuracy: 0.7834\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0905 - accuracy: 0.9671 - val_loss: 0.8453 - val_accuracy: 0.8039\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0959 - accuracy: 0.9669 - val_loss: 0.9553 - val_accuracy: 0.7909\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1069 - accuracy: 0.9596 - val_loss: 0.8539 - val_accuracy: 0.8017\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0966 - accuracy: 0.9650 - val_loss: 0.8637 - val_accuracy: 0.7996\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0844 - accuracy: 0.9701 - val_loss: 0.8752 - val_accuracy: 0.7942\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0863 - accuracy: 0.9671 - val_loss: 0.9055 - val_accuracy: 0.7931\n","Epoch 68/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0906 - accuracy: 0.9647 - val_loss: 0.8644 - val_accuracy: 0.7974\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0853 - accuracy: 0.9685 - val_loss: 1.1337 - val_accuracy: 0.7662\n","Epoch 70/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1030 - accuracy: 0.9642 - val_loss: 0.9472 - val_accuracy: 0.7953\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0912 - accuracy: 0.9671 - val_loss: 0.8992 - val_accuracy: 0.8060\n","Epoch 72/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1078 - accuracy: 0.9609 - val_loss: 1.0052 - val_accuracy: 0.7705\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1337 - accuracy: 0.9523 - val_loss: 1.0629 - val_accuracy: 0.7802\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0869 - accuracy: 0.9671 - val_loss: 0.9129 - val_accuracy: 0.7931\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0816 - accuracy: 0.9706 - val_loss: 0.9752 - val_accuracy: 0.7942\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0825 - accuracy: 0.9739 - val_loss: 0.9014 - val_accuracy: 0.7963\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0865 - accuracy: 0.9666 - val_loss: 0.9732 - val_accuracy: 0.7963\n","Epoch 78/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0877 - accuracy: 0.9679 - val_loss: 0.9126 - val_accuracy: 0.7963\n","Epoch 79/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0815 - accuracy: 0.9704 - val_loss: 0.8999 - val_accuracy: 0.7888\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0803 - accuracy: 0.9696 - val_loss: 0.9724 - val_accuracy: 0.7909\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1004 - accuracy: 0.9690 - val_loss: 0.9629 - val_accuracy: 0.7888\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1040 - accuracy: 0.9639 - val_loss: 1.1296 - val_accuracy: 0.7662\n","Epoch 83/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0896 - accuracy: 0.9690 - val_loss: 1.0314 - val_accuracy: 0.7759\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0976 - accuracy: 0.9669 - val_loss: 0.9822 - val_accuracy: 0.7856\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0809 - accuracy: 0.9736 - val_loss: 0.9699 - val_accuracy: 0.7856\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0964 - accuracy: 0.9658 - val_loss: 0.9448 - val_accuracy: 0.8006\n","Epoch 87/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0802 - accuracy: 0.9717 - val_loss: 0.9820 - val_accuracy: 0.7953\n","Epoch 88/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0911 - accuracy: 0.9709 - val_loss: 1.0149 - val_accuracy: 0.7791\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0863 - accuracy: 0.9717 - val_loss: 0.9851 - val_accuracy: 0.8028\n","Epoch 90/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0822 - accuracy: 0.9696 - val_loss: 1.0038 - val_accuracy: 0.8017\n","Epoch 91/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0836 - accuracy: 0.9709 - val_loss: 0.9758 - val_accuracy: 0.7931\n","Epoch 92/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0852 - accuracy: 0.9704 - val_loss: 0.9791 - val_accuracy: 0.7920\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1025 - accuracy: 0.9696 - val_loss: 1.0154 - val_accuracy: 0.7791\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1115 - accuracy: 0.9620 - val_loss: 1.0713 - val_accuracy: 0.7737\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0938 - accuracy: 0.9690 - val_loss: 0.9895 - val_accuracy: 0.7942\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0775 - accuracy: 0.9760 - val_loss: 0.9764 - val_accuracy: 0.7823\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0900 - accuracy: 0.9714 - val_loss: 0.9961 - val_accuracy: 0.7909\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0806 - accuracy: 0.9709 - val_loss: 0.9794 - val_accuracy: 0.7845\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0846 - accuracy: 0.9720 - val_loss: 1.0592 - val_accuracy: 0.7877\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0911 - accuracy: 0.9688 - val_loss: 0.9349 - val_accuracy: 0.7963\n","{'loss': [0.1910131275653839, 0.18906527757644653, 0.18063238263130188, 0.17286668717861176, 0.16727668046951294, 0.17405061423778534, 0.17168273031711578, 0.14902958273887634, 0.14945754408836365, 0.16373521089553833, 0.15710076689720154, 0.1430094689130783, 0.15433400869369507, 0.14322172105312347, 0.1388857513666153, 0.13577985763549805, 0.1403302550315857, 0.13583062589168549, 0.13801120221614838, 0.13309171795845032, 0.1192290261387825, 0.13056014478206635, 0.1281665861606598, 0.12326272577047348, 0.12873117625713348, 0.1295548677444458, 0.12049374729394913, 0.12238593399524689, 0.11837288737297058, 0.14488622546195984, 0.13960425555706024, 0.13086560368537903, 0.19474312663078308, 0.14339277148246765, 0.1163727343082428, 0.12603047490119934, 0.1164071261882782, 0.11059772223234177, 0.11971864104270935, 0.11620897799730301, 0.12113255262374878, 0.11242929100990295, 0.10830105096101761, 0.10952811688184738, 0.1182686984539032, 0.10241273045539856, 0.09385877102613449, 0.09520662575960159, 0.10854144394397736, 0.1096356213092804, 0.10504820197820663, 0.09697572886943817, 0.09846323728561401, 0.08955921232700348, 0.09842071682214737, 0.10587484389543533, 0.10126104950904846, 0.08855915814638138, 0.09294389188289642, 0.08771567791700363, 0.10556989908218384, 0.09051123261451721, 0.09589730948209763, 0.10686466097831726, 0.0965569019317627, 0.08435828238725662, 0.08631046861410141, 0.09060584753751755, 0.0853339284658432, 0.10296736657619476, 0.0911877453327179, 0.10779447853565216, 0.13369284570217133, 0.08692637830972672, 0.08159041404724121, 0.08248689770698547, 0.08654014766216278, 0.08770308643579483, 0.08152230829000473, 0.08034901320934296, 0.10041756182909012, 0.1039973720908165, 0.08955425769090652, 0.0976116731762886, 0.08085272461175919, 0.09638535231351852, 0.08019421994686127, 0.09112871438264847, 0.08626673370599747, 0.0822381004691124, 0.08360099047422409, 0.08515945076942444, 0.10247396677732468, 0.11149713397026062, 0.09379687905311584, 0.07747345417737961, 0.08999092131853104, 0.08060026168823242, 0.08459809422492981, 0.0910874679684639], 'accuracy': [0.9269935488700867, 0.9248383641242981, 0.9337284564971924, 0.9299569129943848, 0.9356142282485962, 0.9321120977401733, 0.9337284564971924, 0.9415409564971924, 0.9463900923728943, 0.931303858757019, 0.9383081793785095, 0.9471982717514038, 0.9410021305084229, 0.9458512663841248, 0.9471982717514038, 0.9480064511299133, 0.9474676847457886, 0.9498922228813171, 0.9480064511299133, 0.9501616358757019, 0.9555495977401733, 0.9498922228813171, 0.9536637663841248, 0.9520474076271057, 0.9550107717514038, 0.9552801847457886, 0.9520474076271057, 0.9550107717514038, 0.9577047228813171, 0.9426185488700867, 0.9507004022598267, 0.951777994632721, 0.9294180870056152, 0.9415409564971924, 0.9552801847457886, 0.9579741358757019, 0.9566271305084229, 0.9571659564971924, 0.9550107717514038, 0.9560883641242981, 0.9552801847457886, 0.9577047228813171, 0.9601293206214905, 0.959321141242981, 0.954741358757019, 0.9601293206214905, 0.9663254022598267, 0.9698275923728943, 0.9647090435028076, 0.9590517282485962, 0.959590494632721, 0.9679418206214905, 0.9668642282485962, 0.9698275923728943, 0.9665948152542114, 0.9587823152542114, 0.9585129022598267, 0.9695581793785095, 0.9663254022598267, 0.970366358757019, 0.9647090435028076, 0.967133641242981, 0.9668642282485962, 0.959590494632721, 0.9649784564971924, 0.970097005367279, 0.967133641242981, 0.9647090435028076, 0.9684805870056152, 0.9641702771186829, 0.967133641242981, 0.9609375, 0.9523168206214905, 0.967133641242981, 0.9706357717514038, 0.9738685488700867, 0.9665948152542114, 0.9679418206214905, 0.970366358757019, 0.9695581793785095, 0.9690194129943848, 0.9639008641242981, 0.9690194129943848, 0.9668642282485962, 0.9735991358757019, 0.9657866358757019, 0.9717133641242981, 0.9709051847457886, 0.9717133641242981, 0.9695581793785095, 0.9709051847457886, 0.970366358757019, 0.9695581793785095, 0.9620150923728943, 0.9690194129943848, 0.9760237336158752, 0.9714439511299133, 0.9709051847457886, 0.9719827771186829, 0.96875], 'val_loss': [1.7009758949279785, 1.7165563106536865, 1.6859265565872192, 1.6736762523651123, 1.6974842548370361, 1.6438177824020386, 1.684426188468933, 1.6516542434692383, 1.600428819656372, 1.6703696250915527, 1.618970513343811, 1.6187876462936401, 1.5501145124435425, 1.4546765089035034, 1.43938148021698, 1.3655422925949097, 1.3452974557876587, 1.1631556749343872, 1.075595736503601, 1.1222543716430664, 0.906872034072876, 0.8135109543800354, 0.6852967739105225, 0.731150209903717, 0.6524986028671265, 0.709462583065033, 0.6146382093429565, 0.7022553086280823, 0.6856865286827087, 0.754973292350769, 0.7519989013671875, 0.7624272704124451, 0.847929060459137, 0.8452073335647583, 0.7984720468521118, 0.7883416414260864, 0.7588090300559998, 0.7260215282440186, 0.8965925574302673, 0.7838224768638611, 0.8145865201950073, 0.8026831150054932, 0.750641942024231, 0.8581212759017944, 0.7944840788841248, 0.7585800290107727, 0.7946991920471191, 0.7714064121246338, 0.8104113340377808, 0.9845339059829712, 0.7844564914703369, 0.8233151435852051, 0.8220165371894836, 0.806588351726532, 0.8383063673973083, 0.9027469754219055, 0.8697612881660461, 0.8299028277397156, 0.8138535618782043, 0.8335022926330566, 0.8748186826705933, 0.8452893495559692, 0.9552587270736694, 0.8538658022880554, 0.8636946082115173, 0.8752163648605347, 0.9055140018463135, 0.8644436001777649, 1.1337077617645264, 0.9471619129180908, 0.899178683757782, 1.0052188634872437, 1.062915563583374, 0.9128502011299133, 0.975175678730011, 0.9014240503311157, 0.973195493221283, 0.9125925302505493, 0.8998996019363403, 0.9723560810089111, 0.9628897905349731, 1.1295650005340576, 1.031378984451294, 0.982174813747406, 0.9699081182479858, 0.944827139377594, 0.9819706678390503, 1.0149155855178833, 0.9851006865501404, 1.0038037300109863, 0.9758105874061584, 0.979133129119873, 1.0154131650924683, 1.0713391304016113, 0.9894623756408691, 0.9763639569282532, 0.996111273765564, 0.9794197678565979, 1.0591933727264404, 0.934921383857727], 'val_accuracy': [0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48706895112991333, 0.48599138855934143, 0.4881465435028076, 0.49461206793785095, 0.4924568831920624, 0.4978448152542114, 0.5021551847457886, 0.5129310488700867, 0.53125, 0.545258641242981, 0.5581896305084229, 0.5711206793785095, 0.5969827771186829, 0.625, 0.631465494632721, 0.6853448152542114, 0.7144396305084229, 0.7446120977401733, 0.7532327771186829, 0.7855603694915771, 0.7726293206214905, 0.8135775923728943, 0.8028017282485962, 0.8103448152542114, 0.7855603694915771, 0.8028017282485962, 0.8017241358757019, 0.774784505367279, 0.787715494632721, 0.7704741358757019, 0.8038793206214905, 0.8028017282485962, 0.8103448152542114, 0.7844827771186829, 0.7974137663841248, 0.7909482717514038, 0.7941810488700867, 0.8049569129943848, 0.7974137663841248, 0.8103448152542114, 0.8049569129943848, 0.8049569129943848, 0.8081896305084229, 0.7941810488700867, 0.7823275923728943, 0.8049569129943848, 0.7995689511299133, 0.8006465435028076, 0.806034505367279, 0.8017241358757019, 0.787715494632721, 0.7941810488700867, 0.7909482717514038, 0.8028017282485962, 0.8028017282485962, 0.7834051847457886, 0.8038793206214905, 0.7909482717514038, 0.8017241358757019, 0.7995689511299133, 0.7941810488700867, 0.7931034564971924, 0.7974137663841248, 0.7661637663841248, 0.795258641242981, 0.806034505367279, 0.7704741358757019, 0.7801724076271057, 0.7931034564971924, 0.7941810488700867, 0.7963362336158752, 0.7963362336158752, 0.7963362336158752, 0.7887930870056152, 0.7909482717514038, 0.7887930870056152, 0.7661637663841248, 0.7758620977401733, 0.7855603694915771, 0.7855603694915771, 0.8006465435028076, 0.795258641242981, 0.7790948152542114, 0.8028017282485962, 0.8017241358757019, 0.7931034564971924, 0.7920258641242981, 0.7790948152542114, 0.7737069129943848, 0.7941810488700867, 0.7823275923728943, 0.7909482717514038, 0.7844827771186829, 0.787715494632721, 0.7963362336158752]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.2106 - accuracy: 0.9250"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 7s 56ms/step - loss: 0.2106 - accuracy: 0.9250 - val_loss: 1.6228 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1894 - accuracy: 0.9270 - val_loss: 1.6248 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1835 - accuracy: 0.9377 - val_loss: 1.6101 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1841 - accuracy: 0.9315 - val_loss: 1.6064 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1648 - accuracy: 0.9344 - val_loss: 1.5900 - val_accuracy: 0.4977\n","Epoch 6/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1670 - accuracy: 0.9363 - val_loss: 1.5887 - val_accuracy: 0.4977\n","Epoch 7/100\n","28/28 [==============================] - 1s 38ms/step - loss: 0.1578 - accuracy: 0.9420 - val_loss: 1.5363 - val_accuracy: 0.4989\n","Epoch 8/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.1642 - accuracy: 0.9369 - val_loss: 1.5591 - val_accuracy: 0.5000\n","Epoch 9/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1570 - accuracy: 0.9443 - val_loss: 1.6044 - val_accuracy: 0.5000\n","Epoch 10/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.1535 - accuracy: 0.9409 - val_loss: 1.5696 - val_accuracy: 0.5023\n","Epoch 11/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.1668 - accuracy: 0.9397 - val_loss: 1.5646 - val_accuracy: 0.5124\n","Epoch 12/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.1783 - accuracy: 0.9318 - val_loss: 1.3942 - val_accuracy: 0.5283\n","Epoch 13/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1469 - accuracy: 0.9451 - val_loss: 1.4082 - val_accuracy: 0.5283\n","Epoch 14/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1508 - accuracy: 0.9462 - val_loss: 1.3896 - val_accuracy: 0.5396\n","Epoch 15/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1697 - accuracy: 0.9321 - val_loss: 1.4012 - val_accuracy: 0.5385\n","Epoch 16/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1441 - accuracy: 0.9508 - val_loss: 1.3183 - val_accuracy: 0.5577\n","Epoch 17/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1405 - accuracy: 0.9488 - val_loss: 1.1740 - val_accuracy: 0.5837\n","Epoch 18/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1474 - accuracy: 0.9443 - val_loss: 1.0288 - val_accuracy: 0.6120\n","Epoch 19/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1488 - accuracy: 0.9420 - val_loss: 0.8408 - val_accuracy: 0.6697\n","Epoch 20/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1435 - accuracy: 0.9414 - val_loss: 0.8899 - val_accuracy: 0.6595\n","Epoch 21/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1337 - accuracy: 0.9510 - val_loss: 0.9923 - val_accuracy: 0.6493\n","Epoch 22/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.1352 - accuracy: 0.9502 - val_loss: 0.7072 - val_accuracy: 0.7149\n","Epoch 23/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.1303 - accuracy: 0.9559 - val_loss: 0.6386 - val_accuracy: 0.7568\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1427 - accuracy: 0.9493 - val_loss: 0.7586 - val_accuracy: 0.7262\n","Epoch 25/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1277 - accuracy: 0.9587 - val_loss: 0.5819 - val_accuracy: 0.7873\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1408 - accuracy: 0.9491 - val_loss: 0.6872 - val_accuracy: 0.7602\n","Epoch 27/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1394 - accuracy: 0.9451 - val_loss: 0.7374 - val_accuracy: 0.7590\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1343 - accuracy: 0.9502 - val_loss: 0.6770 - val_accuracy: 0.7760\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1245 - accuracy: 0.9570 - val_loss: 0.6253 - val_accuracy: 0.7862\n","Epoch 30/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1272 - accuracy: 0.9573 - val_loss: 0.5963 - val_accuracy: 0.8394\n","Epoch 31/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1466 - accuracy: 0.9445 - val_loss: 0.5963 - val_accuracy: 0.8303\n","Epoch 32/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1365 - accuracy: 0.9530 - val_loss: 0.6290 - val_accuracy: 0.8111\n","Epoch 33/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1271 - accuracy: 0.9544 - val_loss: 0.6000 - val_accuracy: 0.8247\n","Epoch 34/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1164 - accuracy: 0.9595 - val_loss: 0.6004 - val_accuracy: 0.8258\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1190 - accuracy: 0.9604 - val_loss: 0.7083 - val_accuracy: 0.7862\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1198 - accuracy: 0.9587 - val_loss: 0.6200 - val_accuracy: 0.8247\n","Epoch 37/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1165 - accuracy: 0.9593 - val_loss: 0.6367 - val_accuracy: 0.8145\n","Epoch 38/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1223 - accuracy: 0.9590 - val_loss: 0.6218 - val_accuracy: 0.8201\n","Epoch 39/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.1267 - accuracy: 0.9550 - val_loss: 0.6724 - val_accuracy: 0.7952\n","Epoch 40/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1162 - accuracy: 0.9590 - val_loss: 0.6411 - val_accuracy: 0.8292\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1163 - accuracy: 0.9598 - val_loss: 0.6888 - val_accuracy: 0.8054\n","Epoch 42/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1123 - accuracy: 0.9584 - val_loss: 0.6652 - val_accuracy: 0.8066\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1089 - accuracy: 0.9626 - val_loss: 0.6555 - val_accuracy: 0.8247\n","Epoch 44/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1148 - accuracy: 0.9604 - val_loss: 0.7210 - val_accuracy: 0.7873\n","Epoch 45/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1186 - accuracy: 0.9570 - val_loss: 0.6604 - val_accuracy: 0.8314\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1167 - accuracy: 0.9604 - val_loss: 0.6709 - val_accuracy: 0.8100\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1238 - accuracy: 0.9547 - val_loss: 0.6753 - val_accuracy: 0.8100\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1120 - accuracy: 0.9610 - val_loss: 0.7011 - val_accuracy: 0.7998\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1062 - accuracy: 0.9638 - val_loss: 0.7331 - val_accuracy: 0.7828\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1202 - accuracy: 0.9544 - val_loss: 0.6649 - val_accuracy: 0.8179\n","Epoch 51/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1115 - accuracy: 0.9626 - val_loss: 0.6688 - val_accuracy: 0.8100\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1095 - accuracy: 0.9646 - val_loss: 0.6608 - val_accuracy: 0.8258\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1188 - accuracy: 0.9539 - val_loss: 0.7179 - val_accuracy: 0.7907\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1382 - accuracy: 0.9440 - val_loss: 0.7473 - val_accuracy: 0.7952\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1032 - accuracy: 0.9632 - val_loss: 0.7103 - val_accuracy: 0.7952\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0988 - accuracy: 0.9677 - val_loss: 0.6807 - val_accuracy: 0.8077\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0992 - accuracy: 0.9700 - val_loss: 0.7348 - val_accuracy: 0.8066\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1029 - accuracy: 0.9641 - val_loss: 0.6965 - val_accuracy: 0.8281\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0912 - accuracy: 0.9709 - val_loss: 0.7164 - val_accuracy: 0.8167\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1114 - accuracy: 0.9598 - val_loss: 0.6793 - val_accuracy: 0.8258\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0976 - accuracy: 0.9697 - val_loss: 0.6961 - val_accuracy: 0.8247\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1098 - accuracy: 0.9578 - val_loss: 0.7062 - val_accuracy: 0.8179\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0908 - accuracy: 0.9686 - val_loss: 0.6965 - val_accuracy: 0.8201\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0963 - accuracy: 0.9660 - val_loss: 0.7108 - val_accuracy: 0.8100\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0865 - accuracy: 0.9751 - val_loss: 0.7128 - val_accuracy: 0.8009\n","Epoch 66/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0923 - accuracy: 0.9717 - val_loss: 0.7279 - val_accuracy: 0.8235\n","Epoch 67/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0967 - accuracy: 0.9697 - val_loss: 0.7008 - val_accuracy: 0.8088\n","Epoch 68/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0885 - accuracy: 0.9734 - val_loss: 0.7609 - val_accuracy: 0.7896\n","Epoch 69/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0877 - accuracy: 0.9711 - val_loss: 0.7787 - val_accuracy: 0.7817\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0838 - accuracy: 0.9720 - val_loss: 0.7387 - val_accuracy: 0.8100\n","Epoch 71/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0858 - accuracy: 0.9703 - val_loss: 0.7457 - val_accuracy: 0.8145\n","Epoch 72/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0866 - accuracy: 0.9720 - val_loss: 0.7525 - val_accuracy: 0.8179\n","Epoch 73/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0827 - accuracy: 0.9728 - val_loss: 0.7429 - val_accuracy: 0.8213\n","Epoch 74/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0888 - accuracy: 0.9743 - val_loss: 0.9156 - val_accuracy: 0.7794\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1100 - accuracy: 0.9556 - val_loss: 0.7632 - val_accuracy: 0.8179\n","Epoch 76/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0969 - accuracy: 0.9663 - val_loss: 0.7882 - val_accuracy: 0.8133\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0929 - accuracy: 0.9689 - val_loss: 0.8103 - val_accuracy: 0.7919\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0945 - accuracy: 0.9658 - val_loss: 0.7411 - val_accuracy: 0.8156\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0822 - accuracy: 0.9737 - val_loss: 0.7554 - val_accuracy: 0.8009\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0773 - accuracy: 0.9751 - val_loss: 0.7925 - val_accuracy: 0.8032\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0958 - accuracy: 0.9717 - val_loss: 0.9236 - val_accuracy: 0.7817\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0916 - accuracy: 0.9692 - val_loss: 0.7220 - val_accuracy: 0.8167\n","Epoch 83/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0883 - accuracy: 0.9737 - val_loss: 0.7804 - val_accuracy: 0.8043\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1084 - accuracy: 0.9635 - val_loss: 0.8776 - val_accuracy: 0.7998\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1385 - accuracy: 0.9573 - val_loss: 0.7992 - val_accuracy: 0.7919\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0831 - accuracy: 0.9717 - val_loss: 0.7396 - val_accuracy: 0.8190\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0759 - accuracy: 0.9751 - val_loss: 0.7648 - val_accuracy: 0.8156\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0754 - accuracy: 0.9762 - val_loss: 0.7878 - val_accuracy: 0.8156\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0777 - accuracy: 0.9754 - val_loss: 0.7789 - val_accuracy: 0.8100\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0752 - accuracy: 0.9751 - val_loss: 0.7916 - val_accuracy: 0.8066\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0894 - accuracy: 0.9697 - val_loss: 0.8109 - val_accuracy: 0.7998\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0731 - accuracy: 0.9782 - val_loss: 0.7636 - val_accuracy: 0.8133\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0698 - accuracy: 0.9788 - val_loss: 0.7615 - val_accuracy: 0.8133\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0859 - accuracy: 0.9740 - val_loss: 0.8159 - val_accuracy: 0.8020\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0917 - accuracy: 0.9658 - val_loss: 0.9303 - val_accuracy: 0.7658\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0837 - accuracy: 0.9697 - val_loss: 0.7770 - val_accuracy: 0.8122\n","Epoch 97/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0963 - accuracy: 0.9694 - val_loss: 0.8194 - val_accuracy: 0.8145\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0713 - accuracy: 0.9788 - val_loss: 0.8059 - val_accuracy: 0.8088\n","Epoch 99/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1266 - accuracy: 0.9618 - val_loss: 0.8054 - val_accuracy: 0.8077\n","Epoch 100/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0897 - accuracy: 0.9697 - val_loss: 0.8716 - val_accuracy: 0.7941\n","{'loss': [0.2105557769536972, 0.18942230939865112, 0.18346446752548218, 0.18412144482135773, 0.16484187543392181, 0.1669856458902359, 0.1577773243188858, 0.1642160564661026, 0.15695726871490479, 0.15352798998355865, 0.16675041615962982, 0.17831800878047943, 0.14686501026153564, 0.1507566273212433, 0.16967236995697021, 0.14408257603645325, 0.14051559567451477, 0.1474217176437378, 0.14878687262535095, 0.14351990818977356, 0.13365282118320465, 0.13516059517860413, 0.13026651740074158, 0.1426849663257599, 0.12773726880550385, 0.14081858098506927, 0.13938680291175842, 0.13429059088230133, 0.12453792989253998, 0.1272430717945099, 0.14658483862876892, 0.13646115362644196, 0.12705598771572113, 0.11639118194580078, 0.11903209239244461, 0.11976060271263123, 0.1164543628692627, 0.12227855622768402, 0.1267075091600418, 0.11618957668542862, 0.11627131700515747, 0.11230109632015228, 0.10893592983484268, 0.11476074159145355, 0.1185939833521843, 0.1167382076382637, 0.12382568418979645, 0.11197424679994583, 0.10619211196899414, 0.12018481642007828, 0.1115201860666275, 0.10950927436351776, 0.11875100433826447, 0.13823150098323822, 0.10324947535991669, 0.09877343475818634, 0.09917890280485153, 0.10294404625892639, 0.09117697924375534, 0.11143255978822708, 0.09759572148323059, 0.10979396104812622, 0.09078582376241684, 0.09625647962093353, 0.0864788368344307, 0.09228796511888504, 0.09667063504457474, 0.08852943032979965, 0.08769965916872025, 0.08384998142719269, 0.08580929040908813, 0.08659637719392776, 0.08272098749876022, 0.08882860094308853, 0.11004030704498291, 0.09685596823692322, 0.09291461110115051, 0.09445114433765411, 0.082175113260746, 0.07725056260824203, 0.09576769918203354, 0.09156182408332825, 0.0883488655090332, 0.10837966948747635, 0.13845887780189514, 0.08312460780143738, 0.07591225206851959, 0.07542853057384491, 0.07774186134338379, 0.07522466778755188, 0.08942437916994095, 0.07306379824876785, 0.06978432089090347, 0.08590193092823029, 0.09170056134462357, 0.08373907953500748, 0.09625766426324844, 0.071340411901474, 0.12658844888210297, 0.08974035829305649], 'accuracy': [0.9250141382217407, 0.9269949197769165, 0.937747597694397, 0.9315223693847656, 0.9343519806861877, 0.9363327622413635, 0.9419921040534973, 0.9368987083435059, 0.9442558288574219, 0.9408602118492126, 0.9397283792495728, 0.9318053126335144, 0.945104718208313, 0.9462365508079529, 0.9320882558822632, 0.950764000415802, 0.9487832188606262, 0.9442558288574219, 0.9419921040534973, 0.941426157951355, 0.9510469436645508, 0.9501980543136597, 0.9558573961257935, 0.9493491649627686, 0.9586870670318604, 0.9490662217140198, 0.945104718208313, 0.9501980543136597, 0.9569892287254333, 0.9572722315788269, 0.9445387721061707, 0.9530277252197266, 0.95444256067276, 0.9595359563827515, 0.9603848457336426, 0.9586870670318604, 0.9592529535293579, 0.9589700102806091, 0.9550085067749023, 0.9589700102806091, 0.9598188996315002, 0.9584040641784668, 0.9626485705375671, 0.9603848457336426, 0.9569892287254333, 0.9603848457336426, 0.9547255039215088, 0.9609507918357849, 0.963780403137207, 0.95444256067276, 0.9626485705375671, 0.9646292924880981, 0.9538766145706177, 0.9439728260040283, 0.9632145166397095, 0.9677419066429138, 0.9700056314468384, 0.9640634059906006, 0.9708545804023743, 0.9598188996315002, 0.9697226881980896, 0.9578381180763245, 0.9685908555984497, 0.9660441279411316, 0.9750990271568298, 0.9717034697532654, 0.9697226881980896, 0.9734012484550476, 0.971137523651123, 0.9719864130020142, 0.9702886343002319, 0.9719864130020142, 0.9728353023529053, 0.9742501378059387, 0.9555743932723999, 0.9663271307945251, 0.9688737988471985, 0.9657611846923828, 0.9736841917037964, 0.9750990271568298, 0.9717034697532654, 0.9691567420959473, 0.9736841917037964, 0.9634974598884583, 0.9572722315788269, 0.9717034697532654, 0.9750990271568298, 0.9762309193611145, 0.9753820300102234, 0.9750990271568298, 0.9697226881980896, 0.9782116413116455, 0.9787775874137878, 0.9739671945571899, 0.9657611846923828, 0.9697226881980896, 0.9694397449493408, 0.9787775874137878, 0.961799681186676, 0.9697226881980896], 'val_loss': [1.6227549314498901, 1.6248301267623901, 1.6100728511810303, 1.6064350605010986, 1.5900100469589233, 1.5886790752410889, 1.536293864250183, 1.5591275691986084, 1.6044236421585083, 1.5695884227752686, 1.5645594596862793, 1.3942185640335083, 1.4081789255142212, 1.3896359205245972, 1.401190161705017, 1.3183211088180542, 1.173995018005371, 1.0288060903549194, 0.8407909274101257, 0.8899457454681396, 0.9923378229141235, 0.7071919441223145, 0.638616681098938, 0.7585905194282532, 0.5818970203399658, 0.6871920228004456, 0.7373591661453247, 0.6769879460334778, 0.6253402233123779, 0.5963246822357178, 0.5962897539138794, 0.6289759874343872, 0.6000300049781799, 0.6004403233528137, 0.7083239555358887, 0.6200301051139832, 0.6366772055625916, 0.6218096613883972, 0.6723875999450684, 0.6411053538322449, 0.688758134841919, 0.6652190089225769, 0.6555048823356628, 0.7209946513175964, 0.6603664755821228, 0.6709036231040955, 0.6752991676330566, 0.7010963559150696, 0.733089804649353, 0.6649358868598938, 0.6687588691711426, 0.6607784628868103, 0.7178696990013123, 0.7472947239875793, 0.7103362679481506, 0.6806797981262207, 0.7347726821899414, 0.6965043544769287, 0.7164233326911926, 0.67928546667099, 0.6960585117340088, 0.7061818242073059, 0.6965174674987793, 0.7108436822891235, 0.7128084897994995, 0.7279163599014282, 0.7007508277893066, 0.760948121547699, 0.7787306904792786, 0.7386761903762817, 0.7456982731819153, 0.7525234222412109, 0.7428824305534363, 0.9155853390693665, 0.7631947994232178, 0.788159191608429, 0.8103288412094116, 0.7411118745803833, 0.7554032206535339, 0.7924705743789673, 0.9236074686050415, 0.7220206260681152, 0.7804386019706726, 0.8775604367256165, 0.7991751432418823, 0.7395716309547424, 0.7648264169692993, 0.7878085374832153, 0.7789111137390137, 0.7916154861450195, 0.8108584880828857, 0.763604462146759, 0.7614759206771851, 0.8158862590789795, 0.9303027391433716, 0.7770442366600037, 0.8193967938423157, 0.805879533290863, 0.8053833246231079, 0.871566891670227], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4977375566959381, 0.4977375566959381, 0.49886876344680786, 0.5, 0.5, 0.5022624731063843, 0.5124434232711792, 0.5282805562019348, 0.5282805562019348, 0.5395927429199219, 0.5384615659713745, 0.557692289352417, 0.5837104320526123, 0.6119909286499023, 0.6696832776069641, 0.6595022678375244, 0.6493212580680847, 0.7149321436882019, 0.7567873597145081, 0.726244330406189, 0.7873303294181824, 0.7601810097694397, 0.7590497732162476, 0.7760180830955505, 0.7861990928649902, 0.8393664956092834, 0.8303167223930359, 0.8110859990119934, 0.8246606588363647, 0.8257918357849121, 0.7861990928649902, 0.8246606588363647, 0.814479649066925, 0.820135772228241, 0.7952488660812378, 0.8291855454444885, 0.8054298758506775, 0.8065611124038696, 0.8246606588363647, 0.7873303294181824, 0.831447958946228, 0.8099547624588013, 0.8099547624588013, 0.7997737526893616, 0.7828054428100586, 0.8178732991218567, 0.8099547624588013, 0.8257918357849121, 0.790723979473114, 0.7952488660812378, 0.7952488660812378, 0.807692289352417, 0.8065611124038696, 0.8280543088912964, 0.8167420625686646, 0.8257918357849121, 0.8246606588363647, 0.8178732991218567, 0.820135772228241, 0.8099547624588013, 0.8009049892425537, 0.8235294222831726, 0.8088235259056091, 0.7895927429199219, 0.7816742062568665, 0.8099547624588013, 0.814479649066925, 0.8178732991218567, 0.8212669491767883, 0.779411792755127, 0.8178732991218567, 0.8133484125137329, 0.7918552160263062, 0.8156108856201172, 0.8009049892425537, 0.8031674027442932, 0.7816742062568665, 0.8167420625686646, 0.8042986392974854, 0.7997737526893616, 0.7918552160263062, 0.8190045356750488, 0.8156108856201172, 0.8156108856201172, 0.8099547624588013, 0.8065611124038696, 0.7997737526893616, 0.8133484125137329, 0.8133484125137329, 0.8020362257957458, 0.7658371329307556, 0.8122171759605408, 0.814479649066925, 0.8088235259056091, 0.807692289352417, 0.7941176295280457]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.2150 - accuracy: 0.9178"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 53ms/step - loss: 0.2153 - accuracy: 0.9173 - val_loss: 1.6959 - val_accuracy: 0.4866\n","Epoch 2/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1985 - accuracy: 0.9214 - val_loss: 1.6777 - val_accuracy: 0.4876\n","Epoch 3/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2010 - accuracy: 0.9233 - val_loss: 1.6471 - val_accuracy: 0.4876\n","Epoch 4/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.1889 - accuracy: 0.9235 - val_loss: 1.6337 - val_accuracy: 0.4886\n","Epoch 5/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1789 - accuracy: 0.9289 - val_loss: 1.6221 - val_accuracy: 0.4897\n","Epoch 6/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1709 - accuracy: 0.9313 - val_loss: 1.6128 - val_accuracy: 0.4897\n","Epoch 7/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1650 - accuracy: 0.9346 - val_loss: 1.6691 - val_accuracy: 0.4928\n","Epoch 8/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.1783 - accuracy: 0.9245 - val_loss: 1.6436 - val_accuracy: 0.4938\n","Epoch 9/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1687 - accuracy: 0.9307 - val_loss: 1.6482 - val_accuracy: 0.4959\n","Epoch 10/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1729 - accuracy: 0.9297 - val_loss: 1.5670 - val_accuracy: 0.5041\n","Epoch 11/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.1596 - accuracy: 0.9388 - val_loss: 1.5504 - val_accuracy: 0.5062\n","Epoch 12/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1546 - accuracy: 0.9382 - val_loss: 1.5745 - val_accuracy: 0.5083\n","Epoch 13/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.1548 - accuracy: 0.9395 - val_loss: 1.6180 - val_accuracy: 0.5103\n","Epoch 14/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.1631 - accuracy: 0.9377 - val_loss: 1.5474 - val_accuracy: 0.5227\n","Epoch 15/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.1595 - accuracy: 0.9398 - val_loss: 1.5582 - val_accuracy: 0.5258\n","Epoch 16/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.1654 - accuracy: 0.9362 - val_loss: 1.2882 - val_accuracy: 0.5579\n","Epoch 17/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.1511 - accuracy: 0.9393 - val_loss: 1.2401 - val_accuracy: 0.5847\n","Epoch 18/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1457 - accuracy: 0.9429 - val_loss: 1.1456 - val_accuracy: 0.6136\n","Epoch 19/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1548 - accuracy: 0.9465 - val_loss: 0.9882 - val_accuracy: 0.6457\n","Epoch 20/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1592 - accuracy: 0.9388 - val_loss: 1.0434 - val_accuracy: 0.6529\n","Epoch 21/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.1563 - accuracy: 0.9398 - val_loss: 0.7897 - val_accuracy: 0.7138\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1495 - accuracy: 0.9426 - val_loss: 0.8169 - val_accuracy: 0.7118\n","Epoch 23/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.1621 - accuracy: 0.9406 - val_loss: 0.6255 - val_accuracy: 0.7924\n","Epoch 24/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.1425 - accuracy: 0.9416 - val_loss: 0.6717 - val_accuracy: 0.7944\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1363 - accuracy: 0.9501 - val_loss: 0.6834 - val_accuracy: 0.7893\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1354 - accuracy: 0.9481 - val_loss: 0.7325 - val_accuracy: 0.7748\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1306 - accuracy: 0.9470 - val_loss: 0.6863 - val_accuracy: 0.7831\n","Epoch 28/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1387 - accuracy: 0.9478 - val_loss: 0.6856 - val_accuracy: 0.7934\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1258 - accuracy: 0.9522 - val_loss: 0.6815 - val_accuracy: 0.7851\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1316 - accuracy: 0.9455 - val_loss: 0.7355 - val_accuracy: 0.7789\n","Epoch 31/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1425 - accuracy: 0.9455 - val_loss: 0.8121 - val_accuracy: 0.7779\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1361 - accuracy: 0.9506 - val_loss: 0.9393 - val_accuracy: 0.7676\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1648 - accuracy: 0.9362 - val_loss: 0.7059 - val_accuracy: 0.7841\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1376 - accuracy: 0.9499 - val_loss: 0.7492 - val_accuracy: 0.7841\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1288 - accuracy: 0.9506 - val_loss: 0.7940 - val_accuracy: 0.7893\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1246 - accuracy: 0.9519 - val_loss: 0.7632 - val_accuracy: 0.7769\n","Epoch 37/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1278 - accuracy: 0.9532 - val_loss: 0.7650 - val_accuracy: 0.7913\n","Epoch 38/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1343 - accuracy: 0.9499 - val_loss: 0.7823 - val_accuracy: 0.7831\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1220 - accuracy: 0.9519 - val_loss: 0.7512 - val_accuracy: 0.7779\n","Epoch 40/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1200 - accuracy: 0.9535 - val_loss: 0.7822 - val_accuracy: 0.7707\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1180 - accuracy: 0.9535 - val_loss: 0.7849 - val_accuracy: 0.7924\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1267 - accuracy: 0.9514 - val_loss: 0.7851 - val_accuracy: 0.7882\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1249 - accuracy: 0.9530 - val_loss: 0.8374 - val_accuracy: 0.7758\n","Epoch 44/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1684 - accuracy: 0.9382 - val_loss: 1.0167 - val_accuracy: 0.7376\n","Epoch 45/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1580 - accuracy: 0.9331 - val_loss: 0.8013 - val_accuracy: 0.7676\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1168 - accuracy: 0.9561 - val_loss: 0.7644 - val_accuracy: 0.7748\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1139 - accuracy: 0.9571 - val_loss: 0.8048 - val_accuracy: 0.7851\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1268 - accuracy: 0.9537 - val_loss: 0.7674 - val_accuracy: 0.7810\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1128 - accuracy: 0.9602 - val_loss: 0.7626 - val_accuracy: 0.7831\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1544 - accuracy: 0.9432 - val_loss: 0.7879 - val_accuracy: 0.7758\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1198 - accuracy: 0.9594 - val_loss: 0.7676 - val_accuracy: 0.7831\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1077 - accuracy: 0.9599 - val_loss: 0.7862 - val_accuracy: 0.7810\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0994 - accuracy: 0.9641 - val_loss: 0.7968 - val_accuracy: 0.7934\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1141 - accuracy: 0.9597 - val_loss: 0.8074 - val_accuracy: 0.7789\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1035 - accuracy: 0.9589 - val_loss: 0.8050 - val_accuracy: 0.7727\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1025 - accuracy: 0.9646 - val_loss: 0.7851 - val_accuracy: 0.7769\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1055 - accuracy: 0.9597 - val_loss: 0.8777 - val_accuracy: 0.7810\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1023 - accuracy: 0.9630 - val_loss: 0.8719 - val_accuracy: 0.7645\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1107 - accuracy: 0.9563 - val_loss: 0.8495 - val_accuracy: 0.7758\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1048 - accuracy: 0.9612 - val_loss: 0.9103 - val_accuracy: 0.7738\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0957 - accuracy: 0.9687 - val_loss: 0.8800 - val_accuracy: 0.7820\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0968 - accuracy: 0.9618 - val_loss: 0.8328 - val_accuracy: 0.7717\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1119 - accuracy: 0.9618 - val_loss: 0.9897 - val_accuracy: 0.7665\n","Epoch 64/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1109 - accuracy: 0.9615 - val_loss: 0.9290 - val_accuracy: 0.7738\n","Epoch 65/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1246 - accuracy: 0.9519 - val_loss: 0.9626 - val_accuracy: 0.7696\n","Epoch 66/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1385 - accuracy: 0.9439 - val_loss: 0.9852 - val_accuracy: 0.7583\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1800 - accuracy: 0.9264 - val_loss: 0.8660 - val_accuracy: 0.7707\n","Epoch 68/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1092 - accuracy: 0.9589 - val_loss: 0.8605 - val_accuracy: 0.7851\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1007 - accuracy: 0.9672 - val_loss: 0.8864 - val_accuracy: 0.7696\n","Epoch 70/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1082 - accuracy: 0.9630 - val_loss: 0.8929 - val_accuracy: 0.7779\n","Epoch 71/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0936 - accuracy: 0.9677 - val_loss: 0.9234 - val_accuracy: 0.7521\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1006 - accuracy: 0.9638 - val_loss: 0.9302 - val_accuracy: 0.7583\n","Epoch 73/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0937 - accuracy: 0.9661 - val_loss: 0.9289 - val_accuracy: 0.7686\n","Epoch 74/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0937 - accuracy: 0.9667 - val_loss: 0.9116 - val_accuracy: 0.7800\n","Epoch 75/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0912 - accuracy: 0.9646 - val_loss: 0.9301 - val_accuracy: 0.7738\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0932 - accuracy: 0.9667 - val_loss: 1.0851 - val_accuracy: 0.7624\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1460 - accuracy: 0.9486 - val_loss: 0.9200 - val_accuracy: 0.7665\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0947 - accuracy: 0.9680 - val_loss: 1.0573 - val_accuracy: 0.7727\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1140 - accuracy: 0.9576 - val_loss: 0.9315 - val_accuracy: 0.7655\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0947 - accuracy: 0.9625 - val_loss: 0.9034 - val_accuracy: 0.7655\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0841 - accuracy: 0.9695 - val_loss: 0.9444 - val_accuracy: 0.7748\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0869 - accuracy: 0.9687 - val_loss: 0.9764 - val_accuracy: 0.7758\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0887 - accuracy: 0.9672 - val_loss: 0.9667 - val_accuracy: 0.7769\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0889 - accuracy: 0.9669 - val_loss: 0.9545 - val_accuracy: 0.7831\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0883 - accuracy: 0.9656 - val_loss: 0.9264 - val_accuracy: 0.7624\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0810 - accuracy: 0.9711 - val_loss: 0.9632 - val_accuracy: 0.7665\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0835 - accuracy: 0.9680 - val_loss: 0.9811 - val_accuracy: 0.7686\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0849 - accuracy: 0.9685 - val_loss: 1.0051 - val_accuracy: 0.7655\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0932 - accuracy: 0.9677 - val_loss: 0.9541 - val_accuracy: 0.7665\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0860 - accuracy: 0.9682 - val_loss: 0.9835 - val_accuracy: 0.7696\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0822 - accuracy: 0.9680 - val_loss: 0.9478 - val_accuracy: 0.7748\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0843 - accuracy: 0.9687 - val_loss: 1.0376 - val_accuracy: 0.7614\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0958 - accuracy: 0.9643 - val_loss: 1.0084 - val_accuracy: 0.7583\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0797 - accuracy: 0.9716 - val_loss: 0.9576 - val_accuracy: 0.7655\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0884 - accuracy: 0.9674 - val_loss: 1.0274 - val_accuracy: 0.7707\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0833 - accuracy: 0.9700 - val_loss: 1.0707 - val_accuracy: 0.7645\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1094 - accuracy: 0.9563 - val_loss: 1.0832 - val_accuracy: 0.7624\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0925 - accuracy: 0.9615 - val_loss: 1.2768 - val_accuracy: 0.7397\n","Epoch 99/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1124 - accuracy: 0.9623 - val_loss: 1.0581 - val_accuracy: 0.7665\n","Epoch 100/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1017 - accuracy: 0.9643 - val_loss: 1.0774 - val_accuracy: 0.7614\n","{'loss': [0.21528980135917664, 0.19851289689540863, 0.20101392269134521, 0.18894900381565094, 0.17892184853553772, 0.1708865761756897, 0.16503243148326874, 0.17831258475780487, 0.16872727870941162, 0.1729380488395691, 0.15959323942661285, 0.15455535054206848, 0.15475013852119446, 0.16311606764793396, 0.15947341918945312, 0.16543437540531158, 0.15108247101306915, 0.1457117199897766, 0.15477602183818817, 0.15919360518455505, 0.15631957352161407, 0.1494966745376587, 0.16210010647773743, 0.14254187047481537, 0.1362578421831131, 0.1353713721036911, 0.13059163093566895, 0.13870668411254883, 0.12576977908611298, 0.13156484067440033, 0.1425296813249588, 0.13614800572395325, 0.1648440659046173, 0.13764573633670807, 0.1287747174501419, 0.12463992089033127, 0.12784640491008759, 0.13425016403198242, 0.12198178470134735, 0.12002397328615189, 0.11802729964256287, 0.12671934068202972, 0.12490513175725937, 0.16843871772289276, 0.15802815556526184, 0.11677994579076767, 0.11389876902103424, 0.12675900757312775, 0.1128096729516983, 0.15436716377735138, 0.11976167559623718, 0.10770604759454727, 0.09940294921398163, 0.11412885785102844, 0.10346786677837372, 0.1025383323431015, 0.10550397634506226, 0.1023361086845398, 0.11065004020929337, 0.10475499927997589, 0.09573879837989807, 0.09678837656974792, 0.11189070343971252, 0.11094959080219269, 0.12456969171762466, 0.13851451873779297, 0.17999407649040222, 0.10921274125576019, 0.10067065805196762, 0.10822203755378723, 0.09359443932771683, 0.10062246024608612, 0.0937054306268692, 0.09374962002038956, 0.09118858724832535, 0.09321684390306473, 0.14604488015174866, 0.09465914964675903, 0.11399476230144501, 0.09468569606542587, 0.08409590274095535, 0.08690526336431503, 0.0886736735701561, 0.08888405561447144, 0.08830579370260239, 0.08104068785905838, 0.08352980017662048, 0.08491557836532593, 0.09318249672651291, 0.08600956946611404, 0.08217975497245789, 0.08425980806350708, 0.09581968933343887, 0.07965938001871109, 0.08837120980024338, 0.08326856046915054, 0.10943064838647842, 0.0924711525440216, 0.11242417991161346, 0.1016998291015625], 'accuracy': [0.9173126816749573, 0.9214470386505127, 0.9232558012008667, 0.923514187335968, 0.9289405941963196, 0.9312661290168762, 0.9346253275871277, 0.9245477914810181, 0.9307493567466736, 0.9297157526016235, 0.9387596845626831, 0.9382429122924805, 0.9395349025726318, 0.9377260804176331, 0.9397932887077332, 0.9361757040023804, 0.9392764568328857, 0.9428940415382385, 0.9465116262435913, 0.9387596845626831, 0.9397932887077332, 0.9426356554031372, 0.9405684471130371, 0.9416020512580872, 0.9501292109489441, 0.948062002658844, 0.947028398513794, 0.9478036165237427, 0.9521963596343994, 0.9454780220985413, 0.9454780220985413, 0.9506459832191467, 0.9361757040023804, 0.9498708248138428, 0.9506459832191467, 0.9519379734992981, 0.9532299637794495, 0.9498708248138428, 0.9519379734992981, 0.9534883499145508, 0.9534883499145508, 0.9514212012290955, 0.9529715776443481, 0.9382429122924805, 0.933074951171875, 0.9560723304748535, 0.9571059346199036, 0.9537467956542969, 0.9602067470550537, 0.9431524276733398, 0.959431529045105, 0.9599483013153076, 0.964082658290863, 0.9596899151802063, 0.9589147567749023, 0.9645994901657104, 0.9596899151802063, 0.9630491137504578, 0.9563307762145996, 0.961240291595459, 0.9687338471412659, 0.9617571234703064, 0.9617571234703064, 0.9614987373352051, 0.9519379734992981, 0.9439276456832886, 0.9263566136360168, 0.9589147567749023, 0.9671834707260132, 0.9630491137504578, 0.9677002429962158, 0.9638242721557617, 0.9661498665809631, 0.9666666388511658, 0.9645994901657104, 0.9666666388511658, 0.9485788345336914, 0.9679586291313171, 0.957622766494751, 0.9625322818756104, 0.9695090651512146, 0.9687338471412659, 0.9671834707260132, 0.9669250845909119, 0.9656330943107605, 0.9710594415664673, 0.9679586291313171, 0.9684754610061646, 0.9677002429962158, 0.9682170748710632, 0.9679586291313171, 0.9687338471412659, 0.9643411040306091, 0.9715762138366699, 0.9674418568611145, 0.9700258374214172, 0.9563307762145996, 0.9614987373352051, 0.962273895740509, 0.9643411040306091], 'val_loss': [1.6958624124526978, 1.6776628494262695, 1.647050380706787, 1.6336621046066284, 1.6220810413360596, 1.6127865314483643, 1.6691219806671143, 1.643557071685791, 1.6482123136520386, 1.56699800491333, 1.55038321018219, 1.5745121240615845, 1.61796236038208, 1.5474220514297485, 1.5582026243209839, 1.2881957292556763, 1.2400647401809692, 1.1456327438354492, 0.9882189631462097, 1.0434194803237915, 0.789749026298523, 0.816900908946991, 0.625533401966095, 0.6716862320899963, 0.6834477186203003, 0.7325436472892761, 0.6862828135490417, 0.6855810880661011, 0.6814767122268677, 0.7355082035064697, 0.812093198299408, 0.9392932057380676, 0.7059005498886108, 0.7491534948348999, 0.7939651012420654, 0.7632396221160889, 0.7650225758552551, 0.7822998762130737, 0.7511531114578247, 0.7822327017784119, 0.7849059104919434, 0.7851047515869141, 0.8374058604240417, 1.0167498588562012, 0.8012946248054504, 0.7643733620643616, 0.8047645688056946, 0.7673619389533997, 0.7625967860221863, 0.7879356741905212, 0.7675580382347107, 0.7861797213554382, 0.7967678904533386, 0.8073689937591553, 0.80500727891922, 0.7850967645645142, 0.8777065277099609, 0.8719014525413513, 0.8494554162025452, 0.9102752804756165, 0.879980206489563, 0.8328174948692322, 0.9897457957267761, 0.9290146827697754, 0.9625791907310486, 0.9852066040039062, 0.8659826517105103, 0.8605228662490845, 0.8863503336906433, 0.8929027318954468, 0.9233631491661072, 0.9302141070365906, 0.9289233684539795, 0.9115874767303467, 0.9301405549049377, 1.0851361751556396, 0.919972836971283, 1.0572751760482788, 0.9315255880355835, 0.9033963084220886, 0.9443877935409546, 0.9764271378517151, 0.9666765928268433, 0.9544661045074463, 0.9263765215873718, 0.9631572365760803, 0.9811384677886963, 1.0051445960998535, 0.9541308283805847, 0.9835444092750549, 0.9477598667144775, 1.0375664234161377, 1.0084428787231445, 0.9576366543769836, 1.0273820161819458, 1.070697546005249, 1.0832384824752808, 1.2768436670303345, 1.0580652952194214, 1.0773617029190063], 'val_accuracy': [0.48657023906707764, 0.4876033067703247, 0.4876033067703247, 0.4886363744735718, 0.48966941237449646, 0.48966941237449646, 0.4927685856819153, 0.49380165338516235, 0.4958677589893341, 0.5041322112083435, 0.5061983466148376, 0.5082644820213318, 0.5103305578231812, 0.5227272510528564, 0.5258264541625977, 0.557851254940033, 0.5847107172012329, 0.6136363744735718, 0.6456611752510071, 0.6528925895690918, 0.7138429880142212, 0.711776852607727, 0.7923553586006165, 0.7944214940071106, 0.78925621509552, 0.7747933864593506, 0.7830578684806824, 0.7933884263038635, 0.7851239442825317, 0.7789255976676941, 0.7778925895690918, 0.7675619721412659, 0.7840909361839294, 0.7840909361839294, 0.78925621509552, 0.7768595218658447, 0.7913222908973694, 0.7830578684806824, 0.7778925895690918, 0.7706611752510071, 0.7923553586006165, 0.788223147392273, 0.7758264541625977, 0.7376033067703247, 0.7675619721412659, 0.7747933864593506, 0.7851239442825317, 0.7809917330741882, 0.7830578684806824, 0.7758264541625977, 0.7830578684806824, 0.7809917330741882, 0.7933884263038635, 0.7789255976676941, 0.7727272510528564, 0.7768595218658447, 0.7809917330741882, 0.7644628286361694, 0.7758264541625977, 0.7737603187561035, 0.7820248007774353, 0.7716942429542542, 0.7665289044380188, 0.7737603187561035, 0.76962810754776, 0.7582644820213318, 0.7706611752510071, 0.7851239442825317, 0.76962810754776, 0.7778925895690918, 0.7520661354064941, 0.7582644820213318, 0.7685950398445129, 0.7799586653709412, 0.7737603187561035, 0.7623966932296753, 0.7665289044380188, 0.7727272510528564, 0.7654958963394165, 0.7654958963394165, 0.7747933864593506, 0.7758264541625977, 0.7768595218658447, 0.7830578684806824, 0.7623966932296753, 0.7665289044380188, 0.7685950398445129, 0.7654958963394165, 0.7665289044380188, 0.76962810754776, 0.7747933864593506, 0.7613636255264282, 0.7582644820213318, 0.7654958963394165, 0.7706611752510071, 0.7644628286361694, 0.7623966932296753, 0.7396694421768188, 0.7665289044380188, 0.7613636255264282]}\n","32/32 [==============================] - 1s 5ms/step\n"]}]},{"cell_type":"code","source":["\n","metrics_df.round(3)"],"metadata":{"id":"Ik5JoVP2NPvY","colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"status":"ok","timestamp":1717429484892,"user_tz":-360,"elapsed":461,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"91294581-256e-4310-ad67-dffadace7382"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.553      0.544   0.653  0.594        0.653        0.452   \n","1        1     0.611      0.585   0.764  0.663        0.764        0.458   \n","2        2     0.589      0.588   0.598  0.593        0.598        0.580   \n","3        0     0.609      0.585   0.750  0.657        0.750        0.467   \n","4        1     0.665      0.655   0.695  0.674        0.695        0.634   \n","5        2     0.645      0.682   0.542  0.604        0.542        0.747   \n","6        0     0.661      0.630   0.777  0.696        0.777        0.544   \n","7        1     0.699      0.655   0.842  0.737        0.842        0.556   \n","8        2     0.693      0.705   0.663  0.683        0.663        0.723   \n","9        0     0.703      0.675   0.782  0.725        0.782        0.623   \n","10       1     0.741      0.707   0.822  0.760        0.822        0.660   \n","11       2     0.733      0.743   0.713  0.727        0.713        0.753   \n","12       0     0.759      0.741   0.796  0.767        0.796        0.722   \n","13       1     0.785      0.763   0.825  0.793        0.825        0.744   \n","14       2     0.762      0.728   0.837  0.779        0.837        0.687   \n","\n","    Kappa  \n","0   0.106  \n","1   0.222  \n","2   0.179  \n","3   0.218  \n","4   0.329  \n","5   0.289  \n","6   0.322  \n","7   0.398  \n","8   0.386  \n","9   0.405  \n","10  0.482  \n","11  0.466  \n","12  0.518  \n","13  0.569  \n","14  0.524  "],"text/html":["\n","  <div id=\"df-49eb39f4-cd21-41ff-8c50-55287bdf65fc\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.553</td>\n","      <td>0.544</td>\n","      <td>0.653</td>\n","      <td>0.594</td>\n","      <td>0.653</td>\n","      <td>0.452</td>\n","      <td>0.106</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.611</td>\n","      <td>0.585</td>\n","      <td>0.764</td>\n","      <td>0.663</td>\n","      <td>0.764</td>\n","      <td>0.458</td>\n","      <td>0.222</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.589</td>\n","      <td>0.588</td>\n","      <td>0.598</td>\n","      <td>0.593</td>\n","      <td>0.598</td>\n","      <td>0.580</td>\n","      <td>0.179</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.609</td>\n","      <td>0.585</td>\n","      <td>0.750</td>\n","      <td>0.657</td>\n","      <td>0.750</td>\n","      <td>0.467</td>\n","      <td>0.218</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.665</td>\n","      <td>0.655</td>\n","      <td>0.695</td>\n","      <td>0.674</td>\n","      <td>0.695</td>\n","      <td>0.634</td>\n","      <td>0.329</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.645</td>\n","      <td>0.682</td>\n","      <td>0.542</td>\n","      <td>0.604</td>\n","      <td>0.542</td>\n","      <td>0.747</td>\n","      <td>0.289</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.661</td>\n","      <td>0.630</td>\n","      <td>0.777</td>\n","      <td>0.696</td>\n","      <td>0.777</td>\n","      <td>0.544</td>\n","      <td>0.322</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.699</td>\n","      <td>0.655</td>\n","      <td>0.842</td>\n","      <td>0.737</td>\n","      <td>0.842</td>\n","      <td>0.556</td>\n","      <td>0.398</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.693</td>\n","      <td>0.705</td>\n","      <td>0.663</td>\n","      <td>0.683</td>\n","      <td>0.663</td>\n","      <td>0.723</td>\n","      <td>0.386</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.703</td>\n","      <td>0.675</td>\n","      <td>0.782</td>\n","      <td>0.725</td>\n","      <td>0.782</td>\n","      <td>0.623</td>\n","      <td>0.405</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.741</td>\n","      <td>0.707</td>\n","      <td>0.822</td>\n","      <td>0.760</td>\n","      <td>0.822</td>\n","      <td>0.660</td>\n","      <td>0.482</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.733</td>\n","      <td>0.743</td>\n","      <td>0.713</td>\n","      <td>0.727</td>\n","      <td>0.713</td>\n","      <td>0.753</td>\n","      <td>0.466</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.759</td>\n","      <td>0.741</td>\n","      <td>0.796</td>\n","      <td>0.767</td>\n","      <td>0.796</td>\n","      <td>0.722</td>\n","      <td>0.518</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.785</td>\n","      <td>0.763</td>\n","      <td>0.825</td>\n","      <td>0.793</td>\n","      <td>0.825</td>\n","      <td>0.744</td>\n","      <td>0.569</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.762</td>\n","      <td>0.728</td>\n","      <td>0.837</td>\n","      <td>0.779</td>\n","      <td>0.837</td>\n","      <td>0.687</td>\n","      <td>0.524</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49eb39f4-cd21-41ff-8c50-55287bdf65fc')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-49eb39f4-cd21-41ff-8c50-55287bdf65fc button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-49eb39f4-cd21-41ff-8c50-55287bdf65fc');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5179e8ae-eb52-4758-a435-8c6f47802647\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5179e8ae-eb52-4758-a435-8c6f47802647')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5179e8ae-eb52-4758-a435-8c6f47802647 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06948675790256388,\n        \"min\": 0.553,\n        \"max\": 0.785,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.703,\n          0.733,\n          0.553\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06759804167352215,\n        \"min\": 0.544,\n        \"max\": 0.763,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.763,\n          0.743,\n          0.544\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09111018969723783,\n        \"min\": 0.542,\n        \"max\": 0.842,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.782,\n          0.713,\n          0.653\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06635854988512893,\n        \"min\": 0.593,\n        \"max\": 0.793,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.725,\n          0.727,\n          0.594\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09111018969723783,\n        \"min\": 0.542,\n        \"max\": 0.842,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.782,\n          0.713,\n          0.653\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10878659756387184,\n        \"min\": 0.452,\n        \"max\": 0.753,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.623,\n          0.753,\n          0.452\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13880246326893414,\n        \"min\": 0.106,\n        \"max\": 0.569,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.405,\n          0.466,\n          0.106\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["metrics_df.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Frequency Domain/CNN_LSTM/Beta_CNN_LSTM.csv', index = False)"],"metadata":{"id":"Ncf_cMAQF6g4","executionInfo":{"status":"ok","timestamp":1717429492623,"user_tz":-360,"elapsed":499,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["#Draw CNN_LSTM"],"metadata":{"id":"VNy6-RxAKjH8"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import re\n","import os\n","\n","# Function to read CSV logs and extract accuracy and validation accuracy\n","def read_logs(log_dir, num_clients, local_epochs):\n","    dataframes = []\n","    for epoch in range(local_epochs):\n","        for client in range(num_clients):\n","            log_file = os.path.join(log_dir, f'training_log_epoch_{epoch}_client_{client}.csv')\n","            if os.path.exists(log_file):\n","                df = pd.read_csv(log_file, sep=';')\n","                df['epoch_number'] = epoch\n","                df['client_number'] = client\n","                dataframes.append(df)\n","            else:\n","                print(f\"Log file not found: {log_file}\")\n","\n","    return pd.concat(dataframes) if dataframes else pd.DataFrame()\n","\n","# Function to plot the training and validation accuracy\n","def plot_accuracy(all_metrics_df, unique_epochs, output_dir):\n","    # Set the Seaborn style\n","    sns.set(style=\"whitegrid\")\n","\n","    # Create subplots for each epoch\n","    fig, axes = plt.subplots(2, len(unique_epochs), figsize=(len(unique_epochs) * 3, 4.5), sharex=True)\n","\n","    # Set the color palette\n","    palette = sns.color_palette(\"Set1\", n_colors=all_metrics_df['client_number'].nunique())\n","\n","    # Store the lines and labels for the legend\n","    lines = []\n","    labels = []\n","\n","    # Iterate through each epoch and plot the training and validation accuracy\n","    for i, epoch in enumerate(unique_epochs):\n","        epoch_df = all_metrics_df[all_metrics_df['epoch_number'] == epoch]\n","        for j, client in enumerate(epoch_df['client_number'].unique()):\n","            client_df = epoch_df[epoch_df['client_number'] == client].dropna(subset=['accuracy', 'val_accuracy'])\n","            if not client_df.empty:\n","                line, = axes[0, i].plot(client_df.index, client_df['accuracy'], label=f'Client {client}', alpha=0.6, color=palette[j], linewidth=2.0)\n","                axes[1, i].plot(client_df.index, client_df['val_accuracy'], label=f'Client {client}', alpha=0.6, color=palette[j], linewidth=2.0)\n","\n","                if i == 0:\n","                    lines.append(line)\n","                    labels.append(f'Client {client}')\n","\n","        axes[0, i].set_title(f'Epoch {epoch}', fontsize=12, fontweight='bold')\n","        axes[0, i].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","        axes[1, i].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","        axes[1, i].set_xlabel('Steps', fontsize=10, fontweight='bold')\n","        axes[0, i].grid(True)\n","        axes[1, i].grid(True)\n","        axes[0, i].tick_params(axis='both', which='major', labelsize=10)\n","        axes[1, i].tick_params(axis='both', which='major', labelsize=10)\n","\n","    # Add a single legend for the entire figure\n","    fig.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, 1.0), ncol=len(labels), fontsize=10, frameon=True)\n","\n","    # Add row labels\n","    fig.text(0.04, 0.75, 'Training Accuracy', ha='center', va='center', rotation='vertical', fontsize=12, fontweight='bold')\n","    fig.text(0.04, 0.25, 'Validation Accuracy', ha='center', va='center', rotation='vertical', fontsize=12, fontweight='bold')\n","\n","    plt.tight_layout(rect=[0.05, 0, 1, 0.95])\n","    plt.subplots_adjust(hspace=0.2, top=0.88)  # Add some space between the rows and reduce space between the legend and plot\n","\n","    # Save the figure in high DPI PNG and PDF\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    fig.savefig(os.path.join(output_dir, 'accuracy_plot.png'), dpi=300, format='png')\n","    fig.savefig(os.path.join(output_dir, 'accuracy_plot.pdf'), dpi=300, format='pdf')\n","\n","    plt.show()\n","\n","# Directory where CSV logs are saved\n","log_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Beta'\n","\n","# Output directory for saving plots\n","output_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Beta/plots'\n","\n","# Number of clients and local epochs\n","num_clients = 3\n","local_epochs = 5\n","\n","# Read logs and generate the dataframe\n","all_metrics_df = read_logs(log_dir, num_clients, local_epochs)\n","\n","# Get unique epochs from the dataframe\n","unique_epochs = sorted(all_metrics_df['epoch_number'].unique())\n","\n","# Plot the accuracy\n","plot_accuracy(all_metrics_df, unique_epochs, output_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":462},"id":"e-S2thS6KnXT","executionInfo":{"status":"ok","timestamp":1716752066509,"user_tz":-360,"elapsed":5189,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}},"outputId":"2317441e-7595-44cf-d77e-de00b3f3de1b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x450 with 10 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import re\n","import os\n","\n","# Function to read CSV logs and extract accuracy and validation accuracy\n","def read_logs(log_dir, num_clients, local_epochs):\n","    dataframes = []\n","    for epoch in range(local_epochs):\n","        for client in range(num_clients):\n","            log_file = os.path.join(log_dir, f'training_log_epoch_{epoch}_client_{client}.csv')\n","            if os.path.exists(log_file):\n","                df = pd.read_csv(log_file, sep=';')\n","                df['epoch_number'] = epoch\n","                df['client_number'] = client\n","                dataframes.append(df)\n","            else:\n","                print(f\"Log file not found: {log_file}\")\n","\n","    return pd.concat(dataframes) if dataframes else pd.DataFrame()\n","\n","# Function to plot the training and validation accuracy for the final epoch\n","def plot_final_epoch_accuracy(all_metrics_df, output_dir):\n","    # Set the Seaborn style\n","    sns.set(style=\"whitegrid\")\n","\n","    # Get the final epoch number\n","    final_epoch = all_metrics_df['epoch_number'].max()\n","\n","    # Filter the data for the final epoch\n","    final_epoch_df = all_metrics_df[all_metrics_df['epoch_number'] == final_epoch]\n","\n","    # Calculate the average training and validation accuracy for the final epoch\n","    avg_train_accuracy = final_epoch_df['accuracy'].mean()\n","    avg_val_accuracy = final_epoch_df['val_accuracy'].mean()\n","\n","    print(f\"Final Epoch: {final_epoch}\")\n","    print(f\"Average Training Accuracy: {avg_train_accuracy:.4f}\")\n","    print(f\"Average Validation Accuracy: {avg_val_accuracy:.4f}\")\n","\n","    # Create subplots for the final epoch\n","    fig, axes = plt.subplots(1, 2, figsize=(12, 4.5), sharex=True)\n","\n","    # Set the color palette\n","    palette = sns.color_palette(\"Set1\", n_colors=final_epoch_df['client_number'].nunique())\n","\n","    # Store the lines and labels for the legend\n","    lines = []\n","    labels = []\n","\n","    # Plot the training and validation accuracy for the final epoch\n","    for client in final_epoch_df['client_number'].unique():\n","        client_df = final_epoch_df[final_epoch_df['client_number'] == client].dropna(subset=['accuracy', 'val_accuracy'])\n","        if not client_df.empty:\n","            line, = axes[0].plot(client_df.index, client_df['accuracy'], label=f'Client {client}', alpha=0.6, color=palette[client], linewidth=2.0)\n","            axes[1].plot(client_df.index, client_df['val_accuracy'], label=f'Client {client}', alpha=0.6, color=palette[client], linewidth=2.0)\n","\n","            if len(lines) < final_epoch_df['client_number'].nunique():\n","                lines.append(line)\n","                labels.append(f'Client {client}')\n","\n","    axes[0].set_title(f'Training Accuracy (Epoch {final_epoch})', fontsize=12, fontweight='bold')\n","    axes[0].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","\n","    axes[1].set_title(f'Validation Accuracy (Epoch {final_epoch})', fontsize=12, fontweight='bold')\n","\n","\n","    for ax in axes:\n","        ax.set_xlabel('Steps', fontsize=10, fontweight='bold')\n","        ax.grid(True)\n","        ax.tick_params(axis='both', which='major', labelsize=10)\n","\n","    # Add a single legend for the entire figure\n","    fig.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, 1.05), ncol=len(labels), fontsize=10, frameon=True)\n","\n","    plt.tight_layout(rect=[0.05, 0.05, 1, 0.95])\n","    plt.subplots_adjust(hspace=0.2, top=0.85)  # Add some space between the rows and reduce space between the legend and plot\n","\n","    # Save the figure in high DPI PNG and PDF\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    fig.savefig(os.path.join(output_dir, 'final_epoch_accuracy_plot.png'), dpi=300, format='png')\n","    fig.savefig(os.path.join(output_dir, 'final_epoch_accuracy_plot.pdf'), dpi=300, format='pdf')\n","\n","    plt.show()\n","\n","# Directory where CSV logs are saved\n","log_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Beta'\n","\n","# Output directory for saving plots\n","output_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Beta/plots'\n","\n","# Number of clients and local epochs\n","num_clients = 3\n","local_epochs = 5\n","\n","# Read logs and generate the dataframe\n","all_metrics_df = read_logs(log_dir, num_clients, local_epochs)\n","\n","# Plot the accuracy for the final epoch\n","plot_final_epoch_accuracy(all_metrics_df, output_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"id":"NlC1cJDfRFjG","executionInfo":{"status":"ok","timestamp":1716752185517,"user_tz":-360,"elapsed":3105,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}},"outputId":"2242a445-3bb9-4d84-f492-92bc7f4614c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Final Epoch: 4\n","Average Training Accuracy: 0.9229\n","Average Validation Accuracy: 0.7394\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x450 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["# CNN"],"metadata":{"id":"QUuWzfMHSNmi"}},{"cell_type":"code","source":["%%capture\n","!pip install tensorflow_addons"],"metadata":{"id":"j4-_GkkrpZrA","executionInfo":{"status":"ok","timestamp":1717429504383,"user_tz":-360,"elapsed":8023,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    # model.add(Dropout(0.5))\n","    # model.add(LSTM(256, return_sequences=True))\n","    # model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Beta/CNN/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Beta/CNN/training_log_{run_name}.csv', append=True, separator=';')\n","\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"8xrx_fxBSWGd","executionInfo":{"status":"ok","timestamp":1717429672766,"user_tz":-360,"elapsed":429,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["global_model_CNN, metrics_df_CNN = federated_learning(Theta_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H1TaNdIbSfkq","outputId":"e5065731-4ad6-4e08-b97e-07c2c699cb26","executionInfo":{"status":"ok","timestamp":1717430478453,"user_tz":-360,"elapsed":801951,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 5s 27ms/step - loss: 1.7723 - accuracy: 0.5587 - val_loss: 1.7675 - val_accuracy: 0.5409\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 1.7684 - accuracy: 0.5078"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 12ms/step - loss: 1.7594 - accuracy: 0.5959 - val_loss: 1.7569 - val_accuracy: 0.5065\n","Epoch 3/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.7473 - accuracy: 0.5911 - val_loss: 1.7464 - val_accuracy: 0.4978\n","Epoch 4/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.7354 - accuracy: 0.5956 - val_loss: 1.7361 - val_accuracy: 0.5000\n","Epoch 5/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.7235 - accuracy: 0.5978 - val_loss: 1.7258 - val_accuracy: 0.5022\n","Epoch 6/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.7114 - accuracy: 0.5999 - val_loss: 1.7155 - val_accuracy: 0.5075\n","Epoch 7/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.6995 - accuracy: 0.6118 - val_loss: 1.7053 - val_accuracy: 0.5129\n","Epoch 8/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.6874 - accuracy: 0.6059 - val_loss: 1.6954 - val_accuracy: 0.5237\n","Epoch 9/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.6753 - accuracy: 0.6072 - val_loss: 1.6854 - val_accuracy: 0.5237\n","Epoch 10/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.6629 - accuracy: 0.6121 - val_loss: 1.6748 - val_accuracy: 0.5302\n","Epoch 11/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.6509 - accuracy: 0.6126 - val_loss: 1.6646 - val_accuracy: 0.5388\n","Epoch 12/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.6387 - accuracy: 0.6196 - val_loss: 1.6546 - val_accuracy: 0.5453\n","Epoch 13/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.6266 - accuracy: 0.6183 - val_loss: 1.6434 - val_accuracy: 0.5765\n","Epoch 14/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.6147 - accuracy: 0.6226 - val_loss: 1.6332 - val_accuracy: 0.5690\n","Epoch 15/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.6027 - accuracy: 0.6228 - val_loss: 1.6214 - val_accuracy: 0.6034\n","Epoch 16/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.5929 - accuracy: 0.6226 - val_loss: 1.6105 - val_accuracy: 0.6034\n","Epoch 17/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.5814 - accuracy: 0.6282 - val_loss: 1.6003 - val_accuracy: 0.6067\n","Epoch 18/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.5700 - accuracy: 0.6285 - val_loss: 1.5894 - val_accuracy: 0.6002\n","Epoch 19/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.5588 - accuracy: 0.6331 - val_loss: 1.5783 - val_accuracy: 0.6024\n","Epoch 20/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.5487 - accuracy: 0.6347 - val_loss: 1.5684 - val_accuracy: 0.6034\n","Epoch 21/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.5389 - accuracy: 0.6339 - val_loss: 1.5590 - val_accuracy: 0.6002\n","Epoch 22/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.5291 - accuracy: 0.6387 - val_loss: 1.5487 - val_accuracy: 0.6131\n","Epoch 23/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5193 - accuracy: 0.6379 - val_loss: 1.5383 - val_accuracy: 0.6153\n","Epoch 24/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.5101 - accuracy: 0.6385 - val_loss: 1.5310 - val_accuracy: 0.5970\n","Epoch 25/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.5016 - accuracy: 0.6420 - val_loss: 1.5212 - val_accuracy: 0.6056\n","Epoch 26/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.4913 - accuracy: 0.6412 - val_loss: 1.5128 - val_accuracy: 0.6239\n","Epoch 27/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.4825 - accuracy: 0.6460 - val_loss: 1.5047 - val_accuracy: 0.6228\n","Epoch 28/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.4736 - accuracy: 0.6509 - val_loss: 1.4970 - val_accuracy: 0.6207\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.4651 - accuracy: 0.6525 - val_loss: 1.4896 - val_accuracy: 0.6228\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.4555 - accuracy: 0.6514 - val_loss: 1.4829 - val_accuracy: 0.6228\n","Epoch 31/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.4479 - accuracy: 0.6487 - val_loss: 1.4771 - val_accuracy: 0.6261\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.4390 - accuracy: 0.6562 - val_loss: 1.4693 - val_accuracy: 0.6250\n","Epoch 33/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.4304 - accuracy: 0.6536 - val_loss: 1.4620 - val_accuracy: 0.6272\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.4217 - accuracy: 0.6579 - val_loss: 1.4555 - val_accuracy: 0.6239\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.4153 - accuracy: 0.6576 - val_loss: 1.4509 - val_accuracy: 0.6121\n","Epoch 36/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.4064 - accuracy: 0.6611 - val_loss: 1.4431 - val_accuracy: 0.6261\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3993 - accuracy: 0.6579 - val_loss: 1.4369 - val_accuracy: 0.6207\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.3910 - accuracy: 0.6654 - val_loss: 1.4315 - val_accuracy: 0.6218\n","Epoch 39/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.3816 - accuracy: 0.6692 - val_loss: 1.4313 - val_accuracy: 0.6185\n","Epoch 40/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3746 - accuracy: 0.6689 - val_loss: 1.4188 - val_accuracy: 0.6207\n","Epoch 41/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.3674 - accuracy: 0.6754 - val_loss: 1.4142 - val_accuracy: 0.6175\n","Epoch 42/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3586 - accuracy: 0.6775 - val_loss: 1.4068 - val_accuracy: 0.6164\n","Epoch 43/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3502 - accuracy: 0.6786 - val_loss: 1.4036 - val_accuracy: 0.6239\n","Epoch 44/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.3432 - accuracy: 0.6802 - val_loss: 1.4011 - val_accuracy: 0.6239\n","Epoch 45/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.3361 - accuracy: 0.6797 - val_loss: 1.3953 - val_accuracy: 0.6067\n","Epoch 46/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3297 - accuracy: 0.6824 - val_loss: 1.3863 - val_accuracy: 0.6131\n","Epoch 47/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3216 - accuracy: 0.6897 - val_loss: 1.3992 - val_accuracy: 0.6142\n","Epoch 48/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.3179 - accuracy: 0.6856 - val_loss: 1.3766 - val_accuracy: 0.6142\n","Epoch 49/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3056 - accuracy: 0.6894 - val_loss: 1.3733 - val_accuracy: 0.6272\n","Epoch 50/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.2988 - accuracy: 0.6907 - val_loss: 1.3685 - val_accuracy: 0.6164\n","Epoch 51/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.2926 - accuracy: 0.6897 - val_loss: 1.3613 - val_accuracy: 0.6239\n","Epoch 52/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2868 - accuracy: 0.6942 - val_loss: 1.3574 - val_accuracy: 0.6196\n","Epoch 53/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2784 - accuracy: 0.6937 - val_loss: 1.3521 - val_accuracy: 0.6218\n","Epoch 54/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2711 - accuracy: 0.6985 - val_loss: 1.3520 - val_accuracy: 0.6261\n","Epoch 55/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2637 - accuracy: 0.7023 - val_loss: 1.3438 - val_accuracy: 0.6228\n","Epoch 56/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2573 - accuracy: 0.7034 - val_loss: 1.3428 - val_accuracy: 0.6175\n","Epoch 57/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.2498 - accuracy: 0.7020 - val_loss: 1.3364 - val_accuracy: 0.6293\n","Epoch 58/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.2419 - accuracy: 0.7091 - val_loss: 1.3305 - val_accuracy: 0.6218\n","Epoch 59/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.2354 - accuracy: 0.7088 - val_loss: 1.3326 - val_accuracy: 0.6228\n","Epoch 60/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.2283 - accuracy: 0.7134 - val_loss: 1.3212 - val_accuracy: 0.6218\n","Epoch 61/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2216 - accuracy: 0.7136 - val_loss: 1.3180 - val_accuracy: 0.6282\n","Epoch 62/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2152 - accuracy: 0.7139 - val_loss: 1.3144 - val_accuracy: 0.6282\n","Epoch 63/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.2067 - accuracy: 0.7231 - val_loss: 1.3133 - val_accuracy: 0.6336\n","Epoch 64/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2019 - accuracy: 0.7179 - val_loss: 1.3093 - val_accuracy: 0.6315\n","Epoch 65/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.1966 - accuracy: 0.7190 - val_loss: 1.3052 - val_accuracy: 0.6250\n","Epoch 66/100\n","29/29 [==============================] - 1s 42ms/step - loss: 1.1888 - accuracy: 0.7190 - val_loss: 1.3044 - val_accuracy: 0.6261\n","Epoch 67/100\n","29/29 [==============================] - 1s 31ms/step - loss: 1.1817 - accuracy: 0.7239 - val_loss: 1.2962 - val_accuracy: 0.6272\n","Epoch 68/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.1741 - accuracy: 0.7258 - val_loss: 1.2961 - val_accuracy: 0.6239\n","Epoch 69/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1663 - accuracy: 0.7276 - val_loss: 1.2898 - val_accuracy: 0.6293\n","Epoch 70/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.1609 - accuracy: 0.7293 - val_loss: 1.2930 - val_accuracy: 0.6347\n","Epoch 71/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1547 - accuracy: 0.7330 - val_loss: 1.2878 - val_accuracy: 0.6304\n","Epoch 72/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1493 - accuracy: 0.7290 - val_loss: 1.2808 - val_accuracy: 0.6315\n","Epoch 73/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.1404 - accuracy: 0.7355 - val_loss: 1.2796 - val_accuracy: 0.6293\n","Epoch 74/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.1353 - accuracy: 0.7408 - val_loss: 1.2774 - val_accuracy: 0.6207\n","Epoch 75/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.1280 - accuracy: 0.7381 - val_loss: 1.2728 - val_accuracy: 0.6347\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1213 - accuracy: 0.7446 - val_loss: 1.2696 - val_accuracy: 0.6293\n","Epoch 77/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1148 - accuracy: 0.7435 - val_loss: 1.2678 - val_accuracy: 0.6293\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1082 - accuracy: 0.7441 - val_loss: 1.2644 - val_accuracy: 0.6347\n","Epoch 79/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1006 - accuracy: 0.7438 - val_loss: 1.2662 - val_accuracy: 0.6261\n","Epoch 80/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0946 - accuracy: 0.7543 - val_loss: 1.2642 - val_accuracy: 0.6282\n","Epoch 81/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0887 - accuracy: 0.7581 - val_loss: 1.2637 - val_accuracy: 0.6293\n","Epoch 82/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0828 - accuracy: 0.7530 - val_loss: 1.2582 - val_accuracy: 0.6347\n","Epoch 83/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0766 - accuracy: 0.7578 - val_loss: 1.2623 - val_accuracy: 0.6250\n","Epoch 84/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0730 - accuracy: 0.7546 - val_loss: 1.2756 - val_accuracy: 0.6164\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0693 - accuracy: 0.7492 - val_loss: 1.2500 - val_accuracy: 0.6379\n","Epoch 86/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0608 - accuracy: 0.7530 - val_loss: 1.2619 - val_accuracy: 0.6207\n","Epoch 87/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0531 - accuracy: 0.7589 - val_loss: 1.2503 - val_accuracy: 0.6315\n","Epoch 88/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0469 - accuracy: 0.7632 - val_loss: 1.2444 - val_accuracy: 0.6293\n","Epoch 89/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0397 - accuracy: 0.7680 - val_loss: 1.2470 - val_accuracy: 0.6390\n","Epoch 90/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0335 - accuracy: 0.7699 - val_loss: 1.2501 - val_accuracy: 0.6261\n","Epoch 91/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0286 - accuracy: 0.7683 - val_loss: 1.2522 - val_accuracy: 0.6218\n","Epoch 92/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0199 - accuracy: 0.7724 - val_loss: 1.2458 - val_accuracy: 0.6304\n","Epoch 93/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0133 - accuracy: 0.7761 - val_loss: 1.2470 - val_accuracy: 0.6315\n","Epoch 94/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0080 - accuracy: 0.7732 - val_loss: 1.2469 - val_accuracy: 0.6282\n","Epoch 95/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0056 - accuracy: 0.7775 - val_loss: 1.2415 - val_accuracy: 0.6325\n","Epoch 96/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9995 - accuracy: 0.7767 - val_loss: 1.2384 - val_accuracy: 0.6304\n","Epoch 97/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9963 - accuracy: 0.7826 - val_loss: 1.2418 - val_accuracy: 0.6282\n","Epoch 98/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9839 - accuracy: 0.7877 - val_loss: 1.2360 - val_accuracy: 0.6293\n","Epoch 99/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9806 - accuracy: 0.7848 - val_loss: 1.2405 - val_accuracy: 0.6293\n","Epoch 100/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9746 - accuracy: 0.7874 - val_loss: 1.2459 - val_accuracy: 0.6325\n","{'loss': [1.7723021507263184, 1.7594168186187744, 1.747316598892212, 1.7353637218475342, 1.7234858274459839, 1.7114262580871582, 1.6994943618774414, 1.6873979568481445, 1.6753031015396118, 1.662878394126892, 1.6509357690811157, 1.6386874914169312, 1.6266204118728638, 1.614652395248413, 1.6027346849441528, 1.5929131507873535, 1.5813863277435303, 1.570007562637329, 1.5588312149047852, 1.5487035512924194, 1.5389248132705688, 1.529056429862976, 1.5192983150482178, 1.5100914239883423, 1.5016210079193115, 1.4913419485092163, 1.4825247526168823, 1.4736133813858032, 1.4650979042053223, 1.4555013179779053, 1.447904348373413, 1.4390034675598145, 1.4303644895553589, 1.4216582775115967, 1.4153382778167725, 1.4064360857009888, 1.399307131767273, 1.3910328149795532, 1.3816018104553223, 1.374566674232483, 1.3673624992370605, 1.3586006164550781, 1.3502311706542969, 1.343214511871338, 1.336136817932129, 1.3297110795974731, 1.3215734958648682, 1.3178551197052002, 1.3055816888809204, 1.2988303899765015, 1.2925695180892944, 1.286834955215454, 1.2783986330032349, 1.271087884902954, 1.2637418508529663, 1.2572658061981201, 1.2498037815093994, 1.2418932914733887, 1.2353918552398682, 1.228301763534546, 1.2216284275054932, 1.2152189016342163, 1.2066600322723389, 1.2019332647323608, 1.196569561958313, 1.1888434886932373, 1.1816879510879517, 1.1740938425064087, 1.1662713289260864, 1.1608974933624268, 1.1546745300292969, 1.1493490934371948, 1.1404101848602295, 1.1353263854980469, 1.128038763999939, 1.1212552785873413, 1.1147578954696655, 1.10819673538208, 1.10056734085083, 1.0945706367492676, 1.0887442827224731, 1.0828206539154053, 1.0765992403030396, 1.0729731321334839, 1.0693120956420898, 1.0608270168304443, 1.0531259775161743, 1.046943187713623, 1.0396558046340942, 1.033547282218933, 1.0286232233047485, 1.0198593139648438, 1.0133010149002075, 1.0080313682556152, 1.005635142326355, 0.9995039701461792, 0.9962556958198547, 0.9839344024658203, 0.9806447625160217, 0.9746212959289551], 'accuracy': [0.5587284564971924, 0.5959051847457886, 0.5910560488700867, 0.5956357717514038, 0.5977909564971924, 0.599946141242981, 0.6117995977401733, 0.6058728694915771, 0.6072198152542114, 0.6120689511299133, 0.6126077771186829, 0.6196120977401733, 0.6182650923728943, 0.6225754022598267, 0.6228448152542114, 0.6225754022598267, 0.6282327771186829, 0.6285021305084229, 0.6330819129943848, 0.6346982717514038, 0.6338900923728943, 0.6387392282485962, 0.6379310488700867, 0.6384698152542114, 0.641972005367279, 0.6411637663841248, 0.6460129022598267, 0.6508620977401733, 0.6524784564971924, 0.6514008641242981, 0.6487069129943848, 0.65625, 0.6535560488700867, 0.657866358757019, 0.657597005367279, 0.6610991358757019, 0.657866358757019, 0.665409505367279, 0.6691810488700867, 0.6689116358757019, 0.6753771305084229, 0.6775323152542114, 0.6786099076271057, 0.6802262663841248, 0.6796875, 0.6823814511299133, 0.6896551847457886, 0.6856142282485962, 0.6893857717514038, 0.6907327771186829, 0.6896551847457886, 0.6942349076271057, 0.693696141242981, 0.6985452771186829, 0.7023168206214905, 0.7033944129943848, 0.7020474076271057, 0.7090517282485962, 0.7087823152542114, 0.7133620977401733, 0.7136314511299133, 0.7139008641242981, 0.7230603694915771, 0.7179418206214905, 0.7190194129943848, 0.7190194129943848, 0.7238685488700867, 0.7257543206214905, 0.7276400923728943, 0.7292564511299133, 0.733027994632721, 0.7289870977401733, 0.7354525923728943, 0.740840494632721, 0.7381465435028076, 0.7446120977401733, 0.743534505367279, 0.7440732717514038, 0.743803858757019, 0.7543103694915771, 0.7580819129943848, 0.7529633641242981, 0.7578125, 0.7545797228813171, 0.7491918206214905, 0.7529633641242981, 0.7588900923728943, 0.7632004022598267, 0.7680495977401733, 0.7699353694915771, 0.7683189511299133, 0.7723599076271057, 0.7761314511299133, 0.7731680870056152, 0.7774784564971924, 0.7766702771186829, 0.782597005367279, 0.787715494632721, 0.7847521305084229, 0.787446141242981], 'val_loss': [1.7675199508666992, 1.7569160461425781, 1.746448040008545, 1.7360608577728271, 1.7257637977600098, 1.7155020236968994, 1.705289602279663, 1.6954073905944824, 1.685400128364563, 1.6748417615890503, 1.6645500659942627, 1.654577612876892, 1.643353819847107, 1.6331586837768555, 1.6213805675506592, 1.610477089881897, 1.6003296375274658, 1.5894081592559814, 1.5782716274261475, 1.5684078931808472, 1.5590275526046753, 1.5487279891967773, 1.5383211374282837, 1.5309977531433105, 1.5211548805236816, 1.512827754020691, 1.5046918392181396, 1.496982216835022, 1.4895793199539185, 1.4829126596450806, 1.47710120677948, 1.469316840171814, 1.4619930982589722, 1.455504298210144, 1.4509060382843018, 1.4431098699569702, 1.436851978302002, 1.4315451383590698, 1.4313418865203857, 1.4188157320022583, 1.4142361879348755, 1.4068220853805542, 1.4035528898239136, 1.401090383529663, 1.3952867984771729, 1.3863191604614258, 1.399153709411621, 1.3766483068466187, 1.3733159303665161, 1.36851167678833, 1.3612998723983765, 1.3573933839797974, 1.3520809412002563, 1.3519790172576904, 1.3437869548797607, 1.3428181409835815, 1.336425542831421, 1.3304582834243774, 1.3325963020324707, 1.3211874961853027, 1.317994236946106, 1.314361810684204, 1.313326120376587, 1.3093031644821167, 1.3051857948303223, 1.3043558597564697, 1.2962433099746704, 1.2960596084594727, 1.2897980213165283, 1.2930010557174683, 1.2877558469772339, 1.2808409929275513, 1.2795525789260864, 1.277372121810913, 1.272843360900879, 1.2695995569229126, 1.2677865028381348, 1.2643992900848389, 1.2661621570587158, 1.264172911643982, 1.2637394666671753, 1.2582030296325684, 1.2623012065887451, 1.275563359260559, 1.2500163316726685, 1.2619458436965942, 1.2503098249435425, 1.244372844696045, 1.2470414638519287, 1.2500715255737305, 1.25223708152771, 1.24576735496521, 1.2470133304595947, 1.2468842267990112, 1.241475224494934, 1.2384499311447144, 1.2418416738510132, 1.235966444015503, 1.2404539585113525, 1.245871663093567], 'val_accuracy': [0.5409482717514038, 0.506465494632721, 0.4978448152542114, 0.5, 0.5021551847457886, 0.5075430870056152, 0.5129310488700867, 0.5237069129943848, 0.5237069129943848, 0.5301724076271057, 0.5387930870056152, 0.545258641242981, 0.576508641242981, 0.568965494632721, 0.6034482717514038, 0.6034482717514038, 0.6066810488700867, 0.600215494632721, 0.6023706793785095, 0.6034482717514038, 0.600215494632721, 0.6131465435028076, 0.6153017282485962, 0.5969827771186829, 0.6056034564971924, 0.6239224076271057, 0.6228448152542114, 0.6206896305084229, 0.6228448152542114, 0.6228448152542114, 0.6260775923728943, 0.625, 0.6271551847457886, 0.6239224076271057, 0.6120689511299133, 0.6260775923728943, 0.6206896305084229, 0.6217672228813171, 0.618534505367279, 0.6206896305084229, 0.6174569129943848, 0.6163793206214905, 0.6239224076271057, 0.6239224076271057, 0.6066810488700867, 0.6131465435028076, 0.6142241358757019, 0.6142241358757019, 0.6271551847457886, 0.6163793206214905, 0.6239224076271057, 0.6196120977401733, 0.6217672228813171, 0.6260775923728943, 0.6228448152542114, 0.6174569129943848, 0.6293103694915771, 0.6217672228813171, 0.6228448152542114, 0.6217672228813171, 0.6282327771186829, 0.6282327771186829, 0.6336206793785095, 0.631465494632721, 0.625, 0.6260775923728943, 0.6271551847457886, 0.6239224076271057, 0.6293103694915771, 0.6346982717514038, 0.6303879022598267, 0.631465494632721, 0.6293103694915771, 0.6206896305084229, 0.6346982717514038, 0.6293103694915771, 0.6293103694915771, 0.6346982717514038, 0.6260775923728943, 0.6282327771186829, 0.6293103694915771, 0.6346982717514038, 0.625, 0.6163793206214905, 0.6379310488700867, 0.6206896305084229, 0.631465494632721, 0.6293103694915771, 0.639008641242981, 0.6260775923728943, 0.6217672228813171, 0.6303879022598267, 0.631465494632721, 0.6282327771186829, 0.6325430870056152, 0.6303879022598267, 0.6282327771186829, 0.6293103694915771, 0.6293103694915771, 0.6325430870056152]}\n","38/38 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 6s 31ms/step - loss: 1.7729 - accuracy: 0.5501 - val_loss: 1.7678 - val_accuracy: 0.5339\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 1.7642 - accuracy: 0.6406"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 12ms/step - loss: 1.7609 - accuracy: 0.5789 - val_loss: 1.7577 - val_accuracy: 0.5113\n","Epoch 3/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.7497 - accuracy: 0.5789 - val_loss: 1.7476 - val_accuracy: 0.5124\n","Epoch 4/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.7386 - accuracy: 0.5741 - val_loss: 1.7377 - val_accuracy: 0.5124\n","Epoch 5/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.7276 - accuracy: 0.5818 - val_loss: 1.7279 - val_accuracy: 0.5068\n","Epoch 6/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.7167 - accuracy: 0.5976 - val_loss: 1.7182 - val_accuracy: 0.5170\n","Epoch 7/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.7059 - accuracy: 0.5922 - val_loss: 1.7086 - val_accuracy: 0.5170\n","Epoch 8/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6951 - accuracy: 0.5920 - val_loss: 1.6991 - val_accuracy: 0.5113\n","Epoch 9/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.6844 - accuracy: 0.6019 - val_loss: 1.6897 - val_accuracy: 0.5147\n","Epoch 10/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6737 - accuracy: 0.6087 - val_loss: 1.6802 - val_accuracy: 0.5305\n","Epoch 11/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6631 - accuracy: 0.6027 - val_loss: 1.6711 - val_accuracy: 0.5215\n","Epoch 12/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.6525 - accuracy: 0.6095 - val_loss: 1.6616 - val_accuracy: 0.5419\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.6422 - accuracy: 0.6061 - val_loss: 1.6524 - val_accuracy: 0.5577\n","Epoch 14/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.6317 - accuracy: 0.6104 - val_loss: 1.6435 - val_accuracy: 0.5351\n","Epoch 15/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.6214 - accuracy: 0.6143 - val_loss: 1.6341 - val_accuracy: 0.5667\n","Epoch 16/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.6107 - accuracy: 0.6118 - val_loss: 1.6249 - val_accuracy: 0.5713\n","Epoch 17/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6009 - accuracy: 0.6149 - val_loss: 1.6158 - val_accuracy: 0.5690\n","Epoch 18/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5907 - accuracy: 0.6183 - val_loss: 1.6065 - val_accuracy: 0.5724\n","Epoch 19/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.5810 - accuracy: 0.6217 - val_loss: 1.5977 - val_accuracy: 0.5667\n","Epoch 20/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5729 - accuracy: 0.6075 - val_loss: 1.5889 - val_accuracy: 0.5713\n","Epoch 21/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5617 - accuracy: 0.6203 - val_loss: 1.5802 - val_accuracy: 0.5701\n","Epoch 22/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5519 - accuracy: 0.6222 - val_loss: 1.5712 - val_accuracy: 0.5792\n","Epoch 23/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.5424 - accuracy: 0.6228 - val_loss: 1.5629 - val_accuracy: 0.5826\n","Epoch 24/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.5340 - accuracy: 0.6194 - val_loss: 1.5549 - val_accuracy: 0.5814\n","Epoch 25/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.5239 - accuracy: 0.6279 - val_loss: 1.5466 - val_accuracy: 0.5871\n","Epoch 26/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.5147 - accuracy: 0.6282 - val_loss: 1.5389 - val_accuracy: 0.5735\n","Epoch 27/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.5059 - accuracy: 0.6296 - val_loss: 1.5315 - val_accuracy: 0.5814\n","Epoch 28/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4970 - accuracy: 0.6307 - val_loss: 1.5240 - val_accuracy: 0.5735\n","Epoch 29/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.4879 - accuracy: 0.6316 - val_loss: 1.5180 - val_accuracy: 0.5814\n","Epoch 30/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.4789 - accuracy: 0.6333 - val_loss: 1.5105 - val_accuracy: 0.5724\n","Epoch 31/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.4711 - accuracy: 0.6304 - val_loss: 1.5037 - val_accuracy: 0.5735\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.4640 - accuracy: 0.6372 - val_loss: 1.4968 - val_accuracy: 0.5781\n","Epoch 33/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.4550 - accuracy: 0.6423 - val_loss: 1.4902 - val_accuracy: 0.5758\n","Epoch 34/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4454 - accuracy: 0.6398 - val_loss: 1.4836 - val_accuracy: 0.5792\n","Epoch 35/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4386 - accuracy: 0.6401 - val_loss: 1.4779 - val_accuracy: 0.5769\n","Epoch 36/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4318 - accuracy: 0.6353 - val_loss: 1.4726 - val_accuracy: 0.5792\n","Epoch 37/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4215 - accuracy: 0.6480 - val_loss: 1.4649 - val_accuracy: 0.5871\n","Epoch 38/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.4133 - accuracy: 0.6508 - val_loss: 1.4599 - val_accuracy: 0.5848\n","Epoch 39/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4061 - accuracy: 0.6531 - val_loss: 1.4526 - val_accuracy: 0.5871\n","Epoch 40/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3990 - accuracy: 0.6525 - val_loss: 1.4478 - val_accuracy: 0.5803\n","Epoch 41/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.3906 - accuracy: 0.6528 - val_loss: 1.4419 - val_accuracy: 0.5792\n","Epoch 42/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.3824 - accuracy: 0.6585 - val_loss: 1.4359 - val_accuracy: 0.5837\n","Epoch 43/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3754 - accuracy: 0.6542 - val_loss: 1.4331 - val_accuracy: 0.5860\n","Epoch 44/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3670 - accuracy: 0.6610 - val_loss: 1.4301 - val_accuracy: 0.5814\n","Epoch 45/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.3593 - accuracy: 0.6647 - val_loss: 1.4185 - val_accuracy: 0.5848\n","Epoch 46/100\n","28/28 [==============================] - 1s 39ms/step - loss: 1.3514 - accuracy: 0.6636 - val_loss: 1.4130 - val_accuracy: 0.5882\n","Epoch 47/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3439 - accuracy: 0.6669 - val_loss: 1.4099 - val_accuracy: 0.5962\n","Epoch 48/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3370 - accuracy: 0.6633 - val_loss: 1.4027 - val_accuracy: 0.5894\n","Epoch 49/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3309 - accuracy: 0.6678 - val_loss: 1.3992 - val_accuracy: 0.5916\n","Epoch 50/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3214 - accuracy: 0.6698 - val_loss: 1.3930 - val_accuracy: 0.5939\n","Epoch 51/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3134 - accuracy: 0.6732 - val_loss: 1.3887 - val_accuracy: 0.5860\n","Epoch 52/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3067 - accuracy: 0.6766 - val_loss: 1.3853 - val_accuracy: 0.5882\n","Epoch 53/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2991 - accuracy: 0.6760 - val_loss: 1.3800 - val_accuracy: 0.5894\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2942 - accuracy: 0.6811 - val_loss: 1.3740 - val_accuracy: 0.6007\n","Epoch 55/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2841 - accuracy: 0.6842 - val_loss: 1.3712 - val_accuracy: 0.5973\n","Epoch 56/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2774 - accuracy: 0.6831 - val_loss: 1.3653 - val_accuracy: 0.5984\n","Epoch 57/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2691 - accuracy: 0.6862 - val_loss: 1.3604 - val_accuracy: 0.5916\n","Epoch 58/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.2625 - accuracy: 0.6907 - val_loss: 1.3565 - val_accuracy: 0.5984\n","Epoch 59/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2573 - accuracy: 0.6904 - val_loss: 1.3540 - val_accuracy: 0.5939\n","Epoch 60/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2494 - accuracy: 0.6958 - val_loss: 1.3501 - val_accuracy: 0.5962\n","Epoch 61/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2421 - accuracy: 0.6944 - val_loss: 1.3436 - val_accuracy: 0.6063\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2348 - accuracy: 0.6935 - val_loss: 1.3392 - val_accuracy: 0.6063\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2269 - accuracy: 0.6989 - val_loss: 1.3359 - val_accuracy: 0.6041\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2193 - accuracy: 0.7071 - val_loss: 1.3387 - val_accuracy: 0.6018\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2131 - accuracy: 0.7085 - val_loss: 1.3292 - val_accuracy: 0.5995\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2081 - accuracy: 0.7035 - val_loss: 1.3337 - val_accuracy: 0.6052\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1991 - accuracy: 0.7114 - val_loss: 1.3242 - val_accuracy: 0.6029\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1925 - accuracy: 0.7122 - val_loss: 1.3195 - val_accuracy: 0.6029\n","Epoch 69/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1865 - accuracy: 0.7173 - val_loss: 1.3178 - val_accuracy: 0.6018\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1776 - accuracy: 0.7187 - val_loss: 1.3110 - val_accuracy: 0.6063\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1728 - accuracy: 0.7210 - val_loss: 1.3092 - val_accuracy: 0.6041\n","Epoch 72/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1642 - accuracy: 0.7224 - val_loss: 1.3061 - val_accuracy: 0.6007\n","Epoch 73/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1587 - accuracy: 0.7230 - val_loss: 1.3026 - val_accuracy: 0.6007\n","Epoch 74/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1513 - accuracy: 0.7281 - val_loss: 1.3036 - val_accuracy: 0.6029\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1443 - accuracy: 0.7312 - val_loss: 1.2982 - val_accuracy: 0.6086\n","Epoch 76/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1381 - accuracy: 0.7292 - val_loss: 1.2939 - val_accuracy: 0.6086\n","Epoch 77/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1302 - accuracy: 0.7337 - val_loss: 1.2919 - val_accuracy: 0.6052\n","Epoch 78/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.1242 - accuracy: 0.7332 - val_loss: 1.2920 - val_accuracy: 0.6120\n","Epoch 79/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.1170 - accuracy: 0.7346 - val_loss: 1.2911 - val_accuracy: 0.6131\n","Epoch 80/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1094 - accuracy: 0.7411 - val_loss: 1.2910 - val_accuracy: 0.6029\n","Epoch 81/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1027 - accuracy: 0.7453 - val_loss: 1.2822 - val_accuracy: 0.6041\n","Epoch 82/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0969 - accuracy: 0.7400 - val_loss: 1.2889 - val_accuracy: 0.5984\n","Epoch 83/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0888 - accuracy: 0.7462 - val_loss: 1.2781 - val_accuracy: 0.6041\n","Epoch 84/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0831 - accuracy: 0.7473 - val_loss: 1.2756 - val_accuracy: 0.6075\n","Epoch 85/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0785 - accuracy: 0.7442 - val_loss: 1.2774 - val_accuracy: 0.6075\n","Epoch 86/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0761 - accuracy: 0.7456 - val_loss: 1.3078 - val_accuracy: 0.6041\n","Epoch 87/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0657 - accuracy: 0.7473 - val_loss: 1.2746 - val_accuracy: 0.5995\n","Epoch 88/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0558 - accuracy: 0.7617 - val_loss: 1.2697 - val_accuracy: 0.6097\n","Epoch 89/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0496 - accuracy: 0.7612 - val_loss: 1.2722 - val_accuracy: 0.6143\n","Epoch 90/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0436 - accuracy: 0.7524 - val_loss: 1.2697 - val_accuracy: 0.6097\n","Epoch 91/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0404 - accuracy: 0.7623 - val_loss: 1.2685 - val_accuracy: 0.6165\n","Epoch 92/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0317 - accuracy: 0.7657 - val_loss: 1.2616 - val_accuracy: 0.6052\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0236 - accuracy: 0.7731 - val_loss: 1.2655 - val_accuracy: 0.6165\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0188 - accuracy: 0.7714 - val_loss: 1.2631 - val_accuracy: 0.6041\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0130 - accuracy: 0.7753 - val_loss: 1.2648 - val_accuracy: 0.6109\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0091 - accuracy: 0.7711 - val_loss: 1.2646 - val_accuracy: 0.6086\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0004 - accuracy: 0.7807 - val_loss: 1.2579 - val_accuracy: 0.6165\n","Epoch 98/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.9948 - accuracy: 0.7787 - val_loss: 1.2601 - val_accuracy: 0.6176\n","Epoch 99/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9874 - accuracy: 0.7858 - val_loss: 1.2714 - val_accuracy: 0.6063\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9805 - accuracy: 0.7861 - val_loss: 1.2559 - val_accuracy: 0.6120\n","{'loss': [1.7729178667068481, 1.7609293460845947, 1.749703049659729, 1.738555669784546, 1.727603554725647, 1.716745376586914, 1.7058719396591187, 1.6951098442077637, 1.6844220161437988, 1.6736624240875244, 1.6631163358688354, 1.652524471282959, 1.6422247886657715, 1.6317328214645386, 1.6214191913604736, 1.6107357740402222, 1.600921630859375, 1.5906927585601807, 1.5809776782989502, 1.5728858709335327, 1.5616501569747925, 1.5518752336502075, 1.542423129081726, 1.5339910984039307, 1.523931622505188, 1.5146673917770386, 1.5058878660202026, 1.4970000982284546, 1.4878549575805664, 1.478859782218933, 1.4711461067199707, 1.463982105255127, 1.455004096031189, 1.4453868865966797, 1.4385653734207153, 1.4317551851272583, 1.4214993715286255, 1.4133100509643555, 1.4060924053192139, 1.3989667892456055, 1.390567660331726, 1.3823720216751099, 1.3754262924194336, 1.3669612407684326, 1.3593417406082153, 1.3514050245285034, 1.3438670635223389, 1.3369759321212769, 1.3309158086776733, 1.3213531970977783, 1.3133898973464966, 1.306727409362793, 1.2991225719451904, 1.2941547632217407, 1.2841018438339233, 1.2774436473846436, 1.2691236734390259, 1.2625024318695068, 1.257301926612854, 1.249369740486145, 1.2420614957809448, 1.2347511053085327, 1.226891040802002, 1.21934974193573, 1.21310555934906, 1.2081259489059448, 1.1991466283798218, 1.1925156116485596, 1.1864932775497437, 1.1776330471038818, 1.1727933883666992, 1.1641526222229004, 1.1586785316467285, 1.1513168811798096, 1.1442663669586182, 1.1381251811981201, 1.130181908607483, 1.1241908073425293, 1.117039442062378, 1.1093506813049316, 1.1027275323867798, 1.0969160795211792, 1.0888102054595947, 1.0831094980239868, 1.0785036087036133, 1.0761206150054932, 1.065659523010254, 1.0557515621185303, 1.0496151447296143, 1.043550729751587, 1.0404062271118164, 1.0316704511642456, 1.023560643196106, 1.0188366174697876, 1.0130233764648438, 1.0091346502304077, 1.0004419088363647, 0.9947737455368042, 0.9873549342155457, 0.9805240035057068], 'accuracy': [0.5500848889350891, 0.5789473652839661, 0.5789473652839661, 0.5741369724273682, 0.581777036190033, 0.5976231098175049, 0.5922467708587646, 0.5919637680053711, 0.6018675565719604, 0.6086587309837341, 0.6027164459228516, 0.6095076203346252, 0.6061120629310608, 0.6103565096855164, 0.6143180727958679, 0.6117713451385498, 0.6148839592933655, 0.6182795763015747, 0.6216751337051392, 0.6075268983840942, 0.6202603578567505, 0.6222410798072815, 0.6228070259094238, 0.6194114089012146, 0.6279004216194153, 0.6281833648681641, 0.6295982003211975, 0.6307300329208374, 0.6315789222717285, 0.6332767605781555, 0.6304470896720886, 0.6372382640838623, 0.6423316597938538, 0.6397849321365356, 0.6400679349899292, 0.6352574825286865, 0.6479909420013428, 0.6508206129074097, 0.6530843377113342, 0.6525183916091919, 0.6528013348579407, 0.6584606766700745, 0.6542161703109741, 0.6610073447227478, 0.6646859049797058, 0.6635540723800659, 0.6669496297836304, 0.6632710695266724, 0.6677985191345215, 0.6697793006896973, 0.6731748580932617, 0.676570475101471, 0.6760045289993286, 0.6810979247093201, 0.6842105388641357, 0.6830786466598511, 0.6861912608146667, 0.6907187104225159, 0.6904357671737671, 0.6958121061325073, 0.6943972706794739, 0.6935483813285828, 0.698924720287323, 0.7071307301521301, 0.7085455656051636, 0.7034521698951721, 0.7113752365112305, 0.7122241258621216, 0.7173174619674683, 0.7187322974205017, 0.7209960222244263, 0.7224108576774597, 0.722976803779602, 0.7280701994895935, 0.7311828136444092, 0.7292020320892334, 0.7337294816970825, 0.7331635355949402, 0.7345783710479736, 0.7410866022109985, 0.7453310489654541, 0.7399547100067139, 0.7461799383163452, 0.7473118305206299, 0.7441992163658142, 0.7456140518188477, 0.7473118305206299, 0.7617430686950684, 0.761177122592926, 0.7524052262306213, 0.7623090147972107, 0.7657045722007751, 0.7730616927146912, 0.7713639140129089, 0.7753254175186157, 0.7710809111595154, 0.780701756477356, 0.7787209749221802, 0.7857951521873474, 0.7860780954360962], 'val_loss': [1.7678382396697998, 1.7576797008514404, 1.7476181983947754, 1.7376935482025146, 1.7279337644577026, 1.7181799411773682, 1.708573818206787, 1.6990801095962524, 1.689720630645752, 1.680230975151062, 1.6710726022720337, 1.6616483926773071, 1.6523783206939697, 1.643452525138855, 1.6340513229370117, 1.6249275207519531, 1.6157524585723877, 1.6065112352371216, 1.597687840461731, 1.5888978242874146, 1.5801938772201538, 1.5711835622787476, 1.562946081161499, 1.5548932552337646, 1.5466457605361938, 1.5388760566711426, 1.5315324068069458, 1.5239883661270142, 1.5179541110992432, 1.5105339288711548, 1.5036659240722656, 1.4967528581619263, 1.4901906251907349, 1.4836007356643677, 1.4778692722320557, 1.472632646560669, 1.464896321296692, 1.4598958492279053, 1.4526448249816895, 1.447826862335205, 1.4418882131576538, 1.4359338283538818, 1.4330639839172363, 1.4300622940063477, 1.4185222387313843, 1.4129689931869507, 1.4098570346832275, 1.402714490890503, 1.3991663455963135, 1.3929734230041504, 1.3887001276016235, 1.38526451587677, 1.3799501657485962, 1.3739713430404663, 1.3711521625518799, 1.365273356437683, 1.3604024648666382, 1.3565089702606201, 1.3540176153182983, 1.3500990867614746, 1.3435531854629517, 1.339178204536438, 1.3358529806137085, 1.338677167892456, 1.3292182683944702, 1.3337010145187378, 1.324153184890747, 1.3194903135299683, 1.3177579641342163, 1.3109773397445679, 1.3091648817062378, 1.3061374425888062, 1.3025903701782227, 1.3035634756088257, 1.298191785812378, 1.2939268350601196, 1.291885495185852, 1.2919623851776123, 1.2911404371261597, 1.2910497188568115, 1.2821872234344482, 1.2888725996017456, 1.2780778408050537, 1.2756388187408447, 1.2774442434310913, 1.30782151222229, 1.2746435403823853, 1.269663691520691, 1.2722359895706177, 1.2696943283081055, 1.26850426197052, 1.2615691423416138, 1.2655110359191895, 1.2630850076675415, 1.2647711038589478, 1.2645788192749023, 1.2579370737075806, 1.260062336921692, 1.2713913917541504, 1.255913257598877], 'val_accuracy': [0.5339366793632507, 0.5113122463226318, 0.5124434232711792, 0.5124434232711792, 0.5067873597145081, 0.516968309879303, 0.516968309879303, 0.5113122463226318, 0.5147058963775635, 0.5305429697036743, 0.5214931964874268, 0.5418552160263062, 0.557692289352417, 0.5350678563117981, 0.5667420625686646, 0.5712669491767883, 0.5690045356750488, 0.5723981857299805, 0.5667420625686646, 0.5712669491767883, 0.570135772228241, 0.5791855454444885, 0.5825791954994202, 0.581447958946228, 0.587104082107544, 0.5735294222831726, 0.581447958946228, 0.5735294222831726, 0.581447958946228, 0.5723981857299805, 0.5735294222831726, 0.5780543088912964, 0.5757918357849121, 0.5791855454444885, 0.5769230723381042, 0.5791855454444885, 0.587104082107544, 0.5848416090011597, 0.587104082107544, 0.5803167223930359, 0.5791855454444885, 0.5837104320526123, 0.5859728455543518, 0.581447958946228, 0.5848416090011597, 0.5882353186607361, 0.5961538553237915, 0.5893664956092834, 0.5916289687156677, 0.5938913822174072, 0.5859728455543518, 0.5882353186607361, 0.5893664956092834, 0.6006787419319153, 0.5972850918769836, 0.598416268825531, 0.5916289687156677, 0.598416268825531, 0.5938913822174072, 0.5961538553237915, 0.6063348650932312, 0.6063348650932312, 0.6040723919868469, 0.6018099784851074, 0.5995475053787231, 0.6052036285400391, 0.6029411554336548, 0.6029411554336548, 0.6018099784851074, 0.6063348650932312, 0.6040723919868469, 0.6006787419319153, 0.6006787419319153, 0.6029411554336548, 0.6085972785949707, 0.6085972785949707, 0.6052036285400391, 0.6119909286499023, 0.6131221652030945, 0.6029411554336548, 0.6040723919868469, 0.598416268825531, 0.6040723919868469, 0.6074660420417786, 0.6074660420417786, 0.6040723919868469, 0.5995475053787231, 0.6097285151481628, 0.6142534017562866, 0.6097285151481628, 0.6165158152580261, 0.6052036285400391, 0.6165158152580261, 0.6040723919868469, 0.610859751701355, 0.6085972785949707, 0.6165158152580261, 0.6176470518112183, 0.6063348650932312, 0.6119909286499023]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 7s 27ms/step - loss: 1.7726 - accuracy: 0.5230 - val_loss: 1.7668 - val_accuracy: 0.5403\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 1.7656 - accuracy: 0.5625"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 13ms/step - loss: 1.7597 - accuracy: 0.5848 - val_loss: 1.7555 - val_accuracy: 0.5114\n","Epoch 3/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.7473 - accuracy: 0.5891 - val_loss: 1.7445 - val_accuracy: 0.5021\n","Epoch 4/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.7350 - accuracy: 0.5902 - val_loss: 1.7335 - val_accuracy: 0.5072\n","Epoch 5/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.7228 - accuracy: 0.5943 - val_loss: 1.7226 - val_accuracy: 0.5114\n","Epoch 6/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.7106 - accuracy: 0.5953 - val_loss: 1.7119 - val_accuracy: 0.5155\n","Epoch 7/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.6987 - accuracy: 0.6026 - val_loss: 1.7013 - val_accuracy: 0.5217\n","Epoch 8/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.6867 - accuracy: 0.6065 - val_loss: 1.6908 - val_accuracy: 0.5207\n","Epoch 9/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.6750 - accuracy: 0.6031 - val_loss: 1.6802 - val_accuracy: 0.5331\n","Epoch 10/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.6631 - accuracy: 0.6021 - val_loss: 1.6698 - val_accuracy: 0.5351\n","Epoch 11/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.6520 - accuracy: 0.6028 - val_loss: 1.6593 - val_accuracy: 0.5496\n","Epoch 12/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.6400 - accuracy: 0.6047 - val_loss: 1.6489 - val_accuracy: 0.5517\n","Epoch 13/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.6285 - accuracy: 0.6044 - val_loss: 1.6384 - val_accuracy: 0.5610\n","Epoch 14/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.6170 - accuracy: 0.6070 - val_loss: 1.6276 - val_accuracy: 0.5764\n","Epoch 15/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.6057 - accuracy: 0.6103 - val_loss: 1.6174 - val_accuracy: 0.5692\n","Epoch 16/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.5943 - accuracy: 0.6145 - val_loss: 1.6068 - val_accuracy: 0.5940\n","Epoch 17/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.5848 - accuracy: 0.6114 - val_loss: 1.5956 - val_accuracy: 0.5868\n","Epoch 18/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.5726 - accuracy: 0.6150 - val_loss: 1.5850 - val_accuracy: 0.5837\n","Epoch 19/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.5620 - accuracy: 0.6145 - val_loss: 1.5744 - val_accuracy: 0.5899\n","Epoch 20/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.5534 - accuracy: 0.6142 - val_loss: 1.5647 - val_accuracy: 0.5857\n","Epoch 21/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.5415 - accuracy: 0.6178 - val_loss: 1.5557 - val_accuracy: 0.5909\n","Epoch 22/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.5308 - accuracy: 0.6235 - val_loss: 1.5449 - val_accuracy: 0.5899\n","Epoch 23/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.5204 - accuracy: 0.6282 - val_loss: 1.5375 - val_accuracy: 0.5930\n","Epoch 24/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.5116 - accuracy: 0.6243 - val_loss: 1.5279 - val_accuracy: 0.5857\n","Epoch 25/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.5007 - accuracy: 0.6287 - val_loss: 1.5191 - val_accuracy: 0.5857\n","Epoch 26/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.4912 - accuracy: 0.6346 - val_loss: 1.5107 - val_accuracy: 0.5919\n","Epoch 27/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.4808 - accuracy: 0.6354 - val_loss: 1.5039 - val_accuracy: 0.5868\n","Epoch 28/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.4710 - accuracy: 0.6357 - val_loss: 1.4962 - val_accuracy: 0.5919\n","Epoch 29/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.4621 - accuracy: 0.6344 - val_loss: 1.4914 - val_accuracy: 0.5930\n","Epoch 30/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.4523 - accuracy: 0.6419 - val_loss: 1.4819 - val_accuracy: 0.5930\n","Epoch 31/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.4443 - accuracy: 0.6401 - val_loss: 1.4752 - val_accuracy: 0.5940\n","Epoch 32/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.4338 - accuracy: 0.6455 - val_loss: 1.4700 - val_accuracy: 0.5909\n","Epoch 33/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.4247 - accuracy: 0.6506 - val_loss: 1.4626 - val_accuracy: 0.5888\n","Epoch 34/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.4158 - accuracy: 0.6486 - val_loss: 1.4560 - val_accuracy: 0.5878\n","Epoch 35/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.4063 - accuracy: 0.6553 - val_loss: 1.4497 - val_accuracy: 0.5878\n","Epoch 36/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.3977 - accuracy: 0.6545 - val_loss: 1.4437 - val_accuracy: 0.5930\n","Epoch 37/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3895 - accuracy: 0.6532 - val_loss: 1.4373 - val_accuracy: 0.5950\n","Epoch 38/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.3815 - accuracy: 0.6558 - val_loss: 1.4328 - val_accuracy: 0.5930\n","Epoch 39/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3716 - accuracy: 0.6615 - val_loss: 1.4296 - val_accuracy: 0.5961\n","Epoch 40/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.3641 - accuracy: 0.6641 - val_loss: 1.4225 - val_accuracy: 0.5930\n","Epoch 41/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.3554 - accuracy: 0.6682 - val_loss: 1.4171 - val_accuracy: 0.5930\n","Epoch 42/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.3462 - accuracy: 0.6708 - val_loss: 1.4106 - val_accuracy: 0.5909\n","Epoch 43/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3378 - accuracy: 0.6780 - val_loss: 1.4070 - val_accuracy: 0.5930\n","Epoch 44/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.3314 - accuracy: 0.6729 - val_loss: 1.4015 - val_accuracy: 0.5919\n","Epoch 45/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.3223 - accuracy: 0.6783 - val_loss: 1.3980 - val_accuracy: 0.5888\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3145 - accuracy: 0.6806 - val_loss: 1.3920 - val_accuracy: 0.5868\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3050 - accuracy: 0.6819 - val_loss: 1.3875 - val_accuracy: 0.5909\n","Epoch 48/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2982 - accuracy: 0.6822 - val_loss: 1.3828 - val_accuracy: 0.5878\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2908 - accuracy: 0.6814 - val_loss: 1.3845 - val_accuracy: 0.5950\n","Epoch 50/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.2832 - accuracy: 0.6848 - val_loss: 1.3739 - val_accuracy: 0.6012\n","Epoch 51/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2735 - accuracy: 0.6951 - val_loss: 1.3716 - val_accuracy: 0.5878\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2654 - accuracy: 0.6966 - val_loss: 1.3647 - val_accuracy: 0.6002\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2579 - accuracy: 0.6992 - val_loss: 1.3636 - val_accuracy: 0.5930\n","Epoch 54/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2508 - accuracy: 0.6987 - val_loss: 1.3594 - val_accuracy: 0.6085\n","Epoch 55/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2440 - accuracy: 0.6982 - val_loss: 1.3543 - val_accuracy: 0.5971\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2359 - accuracy: 0.6979 - val_loss: 1.3494 - val_accuracy: 0.6012\n","Epoch 57/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2273 - accuracy: 0.7034 - val_loss: 1.3441 - val_accuracy: 0.6023\n","Epoch 58/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2210 - accuracy: 0.7052 - val_loss: 1.3424 - val_accuracy: 0.6064\n","Epoch 59/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.2138 - accuracy: 0.7018 - val_loss: 1.3398 - val_accuracy: 0.6033\n","Epoch 60/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.2056 - accuracy: 0.7054 - val_loss: 1.3340 - val_accuracy: 0.6136\n","Epoch 61/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1984 - accuracy: 0.7065 - val_loss: 1.3381 - val_accuracy: 0.6054\n","Epoch 62/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1902 - accuracy: 0.7134 - val_loss: 1.3279 - val_accuracy: 0.6043\n","Epoch 63/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1825 - accuracy: 0.7124 - val_loss: 1.3265 - val_accuracy: 0.6085\n","Epoch 64/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1759 - accuracy: 0.7155 - val_loss: 1.3197 - val_accuracy: 0.6147\n","Epoch 65/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1674 - accuracy: 0.7165 - val_loss: 1.3177 - val_accuracy: 0.6043\n","Epoch 66/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1603 - accuracy: 0.7163 - val_loss: 1.3170 - val_accuracy: 0.6074\n","Epoch 67/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1539 - accuracy: 0.7202 - val_loss: 1.3148 - val_accuracy: 0.5950\n","Epoch 68/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1499 - accuracy: 0.7199 - val_loss: 1.3114 - val_accuracy: 0.5919\n","Epoch 69/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1397 - accuracy: 0.7227 - val_loss: 1.3034 - val_accuracy: 0.6054\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1350 - accuracy: 0.7225 - val_loss: 1.3012 - val_accuracy: 0.6136\n","Epoch 71/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.1256 - accuracy: 0.7282 - val_loss: 1.2975 - val_accuracy: 0.6095\n","Epoch 72/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1190 - accuracy: 0.7279 - val_loss: 1.2991 - val_accuracy: 0.5961\n","Epoch 73/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1119 - accuracy: 0.7336 - val_loss: 1.3027 - val_accuracy: 0.5888\n","Epoch 74/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1032 - accuracy: 0.7382 - val_loss: 1.2991 - val_accuracy: 0.6116\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1009 - accuracy: 0.7328 - val_loss: 1.2932 - val_accuracy: 0.5899\n","Epoch 76/100\n","31/31 [==============================] - 1s 28ms/step - loss: 1.0894 - accuracy: 0.7388 - val_loss: 1.2854 - val_accuracy: 0.6157\n","Epoch 77/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0818 - accuracy: 0.7424 - val_loss: 1.2974 - val_accuracy: 0.5837\n","Epoch 78/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0823 - accuracy: 0.7346 - val_loss: 1.2828 - val_accuracy: 0.6136\n","Epoch 79/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0694 - accuracy: 0.7447 - val_loss: 1.2812 - val_accuracy: 0.5981\n","Epoch 80/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.0631 - accuracy: 0.7455 - val_loss: 1.2804 - val_accuracy: 0.5992\n","Epoch 81/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0586 - accuracy: 0.7401 - val_loss: 1.2717 - val_accuracy: 0.6136\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0479 - accuracy: 0.7530 - val_loss: 1.2732 - val_accuracy: 0.6157\n","Epoch 83/100\n","31/31 [==============================] - 1s 29ms/step - loss: 1.0407 - accuracy: 0.7550 - val_loss: 1.2763 - val_accuracy: 0.5950\n","Epoch 84/100\n","31/31 [==============================] - 1s 31ms/step - loss: 1.0364 - accuracy: 0.7558 - val_loss: 1.2721 - val_accuracy: 0.6198\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0317 - accuracy: 0.7504 - val_loss: 1.2674 - val_accuracy: 0.6136\n","Epoch 86/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0243 - accuracy: 0.7550 - val_loss: 1.2635 - val_accuracy: 0.6209\n","Epoch 87/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0156 - accuracy: 0.7589 - val_loss: 1.2666 - val_accuracy: 0.6043\n","Epoch 88/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0102 - accuracy: 0.7618 - val_loss: 1.2624 - val_accuracy: 0.6157\n","Epoch 89/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0015 - accuracy: 0.7633 - val_loss: 1.2678 - val_accuracy: 0.5950\n","Epoch 90/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0001 - accuracy: 0.7592 - val_loss: 1.2579 - val_accuracy: 0.6229\n","Epoch 91/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9900 - accuracy: 0.7646 - val_loss: 1.2673 - val_accuracy: 0.6054\n","Epoch 92/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9827 - accuracy: 0.7708 - val_loss: 1.2567 - val_accuracy: 0.6178\n","Epoch 93/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9779 - accuracy: 0.7693 - val_loss: 1.2748 - val_accuracy: 0.5888\n","Epoch 94/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9692 - accuracy: 0.7773 - val_loss: 1.2528 - val_accuracy: 0.6178\n","Epoch 95/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9661 - accuracy: 0.7736 - val_loss: 1.2592 - val_accuracy: 0.6105\n","Epoch 96/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9593 - accuracy: 0.7770 - val_loss: 1.2601 - val_accuracy: 0.6095\n","Epoch 97/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9487 - accuracy: 0.7912 - val_loss: 1.2554 - val_accuracy: 0.6054\n","Epoch 98/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9446 - accuracy: 0.7817 - val_loss: 1.2622 - val_accuracy: 0.6116\n","Epoch 99/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9401 - accuracy: 0.7881 - val_loss: 1.2671 - val_accuracy: 0.6085\n","Epoch 100/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9370 - accuracy: 0.7860 - val_loss: 1.2515 - val_accuracy: 0.6188\n","{'loss': [1.7725574970245361, 1.7597219944000244, 1.7472652196884155, 1.734961748123169, 1.7227635383605957, 1.710622787475586, 1.6986628770828247, 1.6866737604141235, 1.675048589706421, 1.6631287336349487, 1.6519898176193237, 1.6399742364883423, 1.6284781694412231, 1.6170088052749634, 1.6056606769561768, 1.594286561012268, 1.5847935676574707, 1.572580337524414, 1.5620373487472534, 1.5533804893493652, 1.5414777994155884, 1.530796766281128, 1.5204408168792725, 1.51158607006073, 1.5006574392318726, 1.4912022352218628, 1.4808317422866821, 1.4710063934326172, 1.462119460105896, 1.4522664546966553, 1.4442508220672607, 1.4337817430496216, 1.424713373184204, 1.4157891273498535, 1.4063208103179932, 1.3976529836654663, 1.3894612789154053, 1.381523847579956, 1.371558666229248, 1.3641092777252197, 1.3554000854492188, 1.3462132215499878, 1.337790846824646, 1.3313616514205933, 1.3223085403442383, 1.314549446105957, 1.3049696683883667, 1.2982244491577148, 1.2908260822296143, 1.2832330465316772, 1.2735220193862915, 1.2654181718826294, 1.257857084274292, 1.2508153915405273, 1.244000792503357, 1.2358756065368652, 1.227349877357483, 1.2209607362747192, 1.213768482208252, 1.205557942390442, 1.1984059810638428, 1.1902393102645874, 1.1825459003448486, 1.1758534908294678, 1.1674035787582397, 1.1602938175201416, 1.1539397239685059, 1.149930715560913, 1.1397089958190918, 1.1350181102752686, 1.1256141662597656, 1.119009017944336, 1.1118642091751099, 1.1032145023345947, 1.1009365320205688, 1.0893735885620117, 1.0817533731460571, 1.0823265314102173, 1.0693957805633545, 1.063122272491455, 1.058567762374878, 1.0479152202606201, 1.0406856536865234, 1.0364301204681396, 1.0316768884658813, 1.0242624282836914, 1.0156179666519165, 1.0102037191390991, 1.0014963150024414, 1.0000940561294556, 0.9900195002555847, 0.9826772809028625, 0.9778759479522705, 0.9691670536994934, 0.9660990238189697, 0.9592788219451904, 0.9487144947052002, 0.9446049332618713, 0.9401031732559204, 0.9370279908180237], 'accuracy': [0.5229974389076233, 0.5847545266151428, 0.5891472697257996, 0.5901808738708496, 0.594315230846405, 0.5953488349914551, 0.6025840044021606, 0.6064599752426147, 0.6031007766723633, 0.6020671725273132, 0.602842390537262, 0.604651153087616, 0.6043927669525146, 0.6069767475128174, 0.6103359460830688, 0.6144703030586243, 0.6113694906234741, 0.6149870753288269, 0.6144703030586243, 0.6142118573188782, 0.617829442024231, 0.6235142350196838, 0.6281653642654419, 0.6242893934249878, 0.6286821961402893, 0.6346253156661987, 0.6354005336761475, 0.6356589198112488, 0.6343669295310974, 0.6418604850769043, 0.6400516629219055, 0.6454780101776123, 0.6506459712982178, 0.6485788226127625, 0.6552971601486206, 0.6545219421386719, 0.6532299518585205, 0.6558139324188232, 0.6614987254142761, 0.6640827059745789, 0.6682170629501343, 0.670801043510437, 0.6780361533164978, 0.6728681921958923, 0.6782945990562439, 0.6806201338768005, 0.6819121241569519, 0.682170569896698, 0.6813953518867493, 0.6847545504570007, 0.6950904130935669, 0.6966408491134644, 0.6992248296737671, 0.6987079977989197, 0.698191225528717, 0.6979328393936157, 0.7033591866493225, 0.7051679491996765, 0.7018088102340698, 0.7054263353347778, 0.7064599394798279, 0.7134366631507874, 0.7124031186103821, 0.7155038714408875, 0.7165374755859375, 0.7162790894508362, 0.7201550602912903, 0.7198966145515442, 0.722739040851593, 0.7224805951118469, 0.7281653881072998, 0.7279070019721985, 0.7335917353630066, 0.7382428646087646, 0.7328165173530579, 0.7387596964836121, 0.7423772811889648, 0.7346253395080566, 0.7447028160095215, 0.7454780340194702, 0.7400516867637634, 0.7529715895652771, 0.7550387382507324, 0.7558139562606812, 0.7503876090049744, 0.7550387382507324, 0.7589147090911865, 0.7617571353912354, 0.763307511806488, 0.7591731548309326, 0.7645995020866394, 0.7708010077476501, 0.7692506313323975, 0.777260959148407, 0.773643434047699, 0.7770025730133057, 0.7912144660949707, 0.7816537618637085, 0.7881137132644653, 0.7860465049743652], 'val_loss': [1.7667604684829712, 1.7555347681045532, 1.7444829940795898, 1.7334990501403809, 1.722636103630066, 1.7119184732437134, 1.7012783288955688, 1.6908211708068848, 1.6801875829696655, 1.669774055480957, 1.6592905521392822, 1.648911476135254, 1.6384401321411133, 1.6276118755340576, 1.6174119710922241, 1.6067569255828857, 1.595556616783142, 1.5849614143371582, 1.5743845701217651, 1.5646880865097046, 1.5556846857070923, 1.5449399948120117, 1.5375231504440308, 1.527868390083313, 1.5191129446029663, 1.5107417106628418, 1.5039169788360596, 1.4961718320846558, 1.4914205074310303, 1.4818521738052368, 1.4752439260482788, 1.4699875116348267, 1.4626069068908691, 1.456048846244812, 1.4496804475784302, 1.4436593055725098, 1.4373000860214233, 1.4328045845031738, 1.4295966625213623, 1.4224811792373657, 1.4171106815338135, 1.4105801582336426, 1.4070239067077637, 1.4015179872512817, 1.3979538679122925, 1.3919538259506226, 1.3874799013137817, 1.3827584981918335, 1.3844959735870361, 1.3739196062088013, 1.3716306686401367, 1.3647208213806152, 1.363592267036438, 1.3593852519989014, 1.3542548418045044, 1.3493942022323608, 1.344138503074646, 1.3423893451690674, 1.3397654294967651, 1.333972454071045, 1.3380777835845947, 1.327947735786438, 1.3264983892440796, 1.3197089433670044, 1.3176624774932861, 1.3170229196548462, 1.3148047924041748, 1.311376929283142, 1.3033864498138428, 1.3012065887451172, 1.2974594831466675, 1.2990888357162476, 1.3027344942092896, 1.2991399765014648, 1.2931843996047974, 1.2853715419769287, 1.2973946332931519, 1.2828116416931152, 1.2812011241912842, 1.280364751815796, 1.2717398405075073, 1.273212194442749, 1.2762837409973145, 1.2721209526062012, 1.2674249410629272, 1.2635127305984497, 1.2665842771530151, 1.2623939514160156, 1.2678415775299072, 1.2578834295272827, 1.267305850982666, 1.256739616394043, 1.274753451347351, 1.2527894973754883, 1.2592482566833496, 1.2601099014282227, 1.2553664445877075, 1.262216567993164, 1.2671420574188232, 1.2515474557876587], 'val_accuracy': [0.5402892827987671, 0.5113636255264282, 0.5020661354064941, 0.5072314143180847, 0.5113636255264282, 0.5154958963394165, 0.5216942429542542, 0.5206611752510071, 0.5330578684806824, 0.5351239442825317, 0.5495867729187012, 0.5516529083251953, 0.5609503984451294, 0.5764462947845459, 0.5692148804664612, 0.5940082669258118, 0.586776852607727, 0.5836777091026306, 0.5898760557174683, 0.58574378490448, 0.5909090638160706, 0.5898760557174683, 0.5929751992225647, 0.58574378490448, 0.58574378490448, 0.5919421315193176, 0.586776852607727, 0.5919421315193176, 0.5929751992225647, 0.5929751992225647, 0.5940082669258118, 0.5909090638160706, 0.5888429880142212, 0.5878099203109741, 0.5878099203109741, 0.5929751992225647, 0.5950413346290588, 0.5929751992225647, 0.5960744023323059, 0.5929751992225647, 0.5929751992225647, 0.5909090638160706, 0.5929751992225647, 0.5919421315193176, 0.5888429880142212, 0.586776852607727, 0.5909090638160706, 0.5878099203109741, 0.5950413346290588, 0.6012396812438965, 0.5878099203109741, 0.6002066135406494, 0.5929751992225647, 0.6084710955619812, 0.5971074104309082, 0.6012396812438965, 0.6022727489471436, 0.6064049601554871, 0.6033057570457458, 0.6136363744735718, 0.60537189245224, 0.6043388247489929, 0.6084710955619812, 0.6146694421768188, 0.6043388247489929, 0.6074380278587341, 0.5950413346290588, 0.5919421315193176, 0.60537189245224, 0.6136363744735718, 0.6095041036605835, 0.5960744023323059, 0.5888429880142212, 0.6115702390670776, 0.5898760557174683, 0.6157024502754211, 0.5836777091026306, 0.6136363744735718, 0.5981404781341553, 0.5991735458374023, 0.6136363744735718, 0.6157024502754211, 0.5950413346290588, 0.6198347210884094, 0.6136363744735718, 0.6208677887916565, 0.6043388247489929, 0.6157024502754211, 0.5950413346290588, 0.6229338645935059, 0.60537189245224, 0.6177685856819153, 0.5888429880142212, 0.6177685856819153, 0.6105371713638306, 0.6095041036605835, 0.60537189245224, 0.6115702390670776, 0.6084710955619812, 0.6188016533851624]}\n","32/32 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 4s 33ms/step - loss: 1.0402 - accuracy: 0.7320 - val_loss: 1.2248 - val_accuracy: 0.4871\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 13ms/step - loss: 1.0264 - accuracy: 0.7408 - val_loss: 1.2148 - val_accuracy: 0.4871\n","Epoch 3/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0180 - accuracy: 0.7446 - val_loss: 1.2174 - val_accuracy: 0.4871\n","Epoch 4/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0097 - accuracy: 0.7538 - val_loss: 1.2107 - val_accuracy: 0.4881\n","Epoch 5/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0040 - accuracy: 0.7557 - val_loss: 1.2107 - val_accuracy: 0.4871\n","Epoch 6/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9986 - accuracy: 0.7535 - val_loss: 1.1951 - val_accuracy: 0.4914\n","Epoch 7/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9903 - accuracy: 0.7613 - val_loss: 1.1902 - val_accuracy: 0.4914\n","Epoch 8/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9847 - accuracy: 0.7635 - val_loss: 1.1915 - val_accuracy: 0.4935\n","Epoch 9/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9793 - accuracy: 0.7621 - val_loss: 1.1721 - val_accuracy: 0.5065\n","Epoch 10/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9752 - accuracy: 0.7613 - val_loss: 1.1866 - val_accuracy: 0.5000\n","Epoch 11/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9654 - accuracy: 0.7721 - val_loss: 1.1560 - val_accuracy: 0.5248\n","Epoch 12/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9611 - accuracy: 0.7702 - val_loss: 1.1520 - val_accuracy: 0.5356\n","Epoch 13/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9579 - accuracy: 0.7619 - val_loss: 1.1390 - val_accuracy: 0.5506\n","Epoch 14/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9495 - accuracy: 0.7729 - val_loss: 1.1322 - val_accuracy: 0.5679\n","Epoch 15/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9433 - accuracy: 0.7788 - val_loss: 1.1172 - val_accuracy: 0.5819\n","Epoch 16/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9371 - accuracy: 0.7815 - val_loss: 1.1165 - val_accuracy: 0.5862\n","Epoch 17/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9315 - accuracy: 0.7799 - val_loss: 1.1028 - val_accuracy: 0.5970\n","Epoch 18/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9278 - accuracy: 0.7767 - val_loss: 1.0892 - val_accuracy: 0.6099\n","Epoch 19/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9239 - accuracy: 0.7812 - val_loss: 1.0783 - val_accuracy: 0.6218\n","Epoch 20/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.9183 - accuracy: 0.7821 - val_loss: 1.0630 - val_accuracy: 0.6487\n","Epoch 21/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9116 - accuracy: 0.7791 - val_loss: 1.0700 - val_accuracy: 0.6347\n","Epoch 22/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9046 - accuracy: 0.7869 - val_loss: 1.0569 - val_accuracy: 0.6519\n","Epoch 23/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9003 - accuracy: 0.7907 - val_loss: 1.0625 - val_accuracy: 0.6444\n","Epoch 24/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8948 - accuracy: 0.7912 - val_loss: 1.0686 - val_accuracy: 0.6509\n","Epoch 25/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8913 - accuracy: 0.7950 - val_loss: 1.0541 - val_accuracy: 0.6595\n","Epoch 26/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8826 - accuracy: 0.7969 - val_loss: 1.0747 - val_accuracy: 0.6541\n","Epoch 27/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8811 - accuracy: 0.7950 - val_loss: 1.0635 - val_accuracy: 0.6703\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8725 - accuracy: 0.8025 - val_loss: 1.0641 - val_accuracy: 0.6659\n","Epoch 29/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8674 - accuracy: 0.8028 - val_loss: 1.0593 - val_accuracy: 0.6703\n","Epoch 30/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8634 - accuracy: 0.8052 - val_loss: 1.0872 - val_accuracy: 0.6627\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8586 - accuracy: 0.8031 - val_loss: 1.0701 - val_accuracy: 0.6584\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8585 - accuracy: 0.8025 - val_loss: 1.0627 - val_accuracy: 0.6595\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8476 - accuracy: 0.8112 - val_loss: 1.0667 - val_accuracy: 0.6670\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8404 - accuracy: 0.8147 - val_loss: 1.0643 - val_accuracy: 0.6616\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8420 - accuracy: 0.8074 - val_loss: 1.1194 - val_accuracy: 0.6476\n","Epoch 36/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8343 - accuracy: 0.8095 - val_loss: 1.0698 - val_accuracy: 0.6724\n","Epoch 37/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8263 - accuracy: 0.8195 - val_loss: 1.0899 - val_accuracy: 0.6616\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8244 - accuracy: 0.8176 - val_loss: 1.0862 - val_accuracy: 0.6541\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8196 - accuracy: 0.8187 - val_loss: 1.0824 - val_accuracy: 0.6659\n","Epoch 40/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8144 - accuracy: 0.8217 - val_loss: 1.1516 - val_accuracy: 0.6509\n","Epoch 41/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8211 - accuracy: 0.8187 - val_loss: 1.0681 - val_accuracy: 0.6638\n","Epoch 42/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8067 - accuracy: 0.8233 - val_loss: 1.0767 - val_accuracy: 0.6692\n","Epoch 43/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7990 - accuracy: 0.8276 - val_loss: 1.0679 - val_accuracy: 0.6659\n","Epoch 44/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7981 - accuracy: 0.8279 - val_loss: 1.0775 - val_accuracy: 0.6692\n","Epoch 45/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7902 - accuracy: 0.8322 - val_loss: 1.0777 - val_accuracy: 0.6659\n","Epoch 46/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7863 - accuracy: 0.8327 - val_loss: 1.0929 - val_accuracy: 0.6584\n","Epoch 47/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7837 - accuracy: 0.8370 - val_loss: 1.0739 - val_accuracy: 0.6713\n","Epoch 48/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7767 - accuracy: 0.8429 - val_loss: 1.0830 - val_accuracy: 0.6638\n","Epoch 49/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7768 - accuracy: 0.8394 - val_loss: 1.0844 - val_accuracy: 0.6681\n","Epoch 50/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7703 - accuracy: 0.8376 - val_loss: 1.0805 - val_accuracy: 0.6659\n","Epoch 51/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7637 - accuracy: 0.8494 - val_loss: 1.0840 - val_accuracy: 0.6703\n","Epoch 52/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7577 - accuracy: 0.8486 - val_loss: 1.0961 - val_accuracy: 0.6573\n","Epoch 53/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7623 - accuracy: 0.8413 - val_loss: 1.0778 - val_accuracy: 0.6638\n","Epoch 54/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7582 - accuracy: 0.8456 - val_loss: 1.1379 - val_accuracy: 0.6530\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7511 - accuracy: 0.8413 - val_loss: 1.0873 - val_accuracy: 0.6670\n","Epoch 56/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7447 - accuracy: 0.8483 - val_loss: 1.0884 - val_accuracy: 0.6703\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7388 - accuracy: 0.8553 - val_loss: 1.0849 - val_accuracy: 0.6735\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7360 - accuracy: 0.8516 - val_loss: 1.0828 - val_accuracy: 0.6670\n","Epoch 59/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7336 - accuracy: 0.8532 - val_loss: 1.1692 - val_accuracy: 0.6444\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7274 - accuracy: 0.8580 - val_loss: 1.0962 - val_accuracy: 0.6703\n","Epoch 61/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7212 - accuracy: 0.8583 - val_loss: 1.0846 - val_accuracy: 0.6703\n","Epoch 62/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7171 - accuracy: 0.8570 - val_loss: 1.1009 - val_accuracy: 0.6681\n","Epoch 63/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7126 - accuracy: 0.8648 - val_loss: 1.1367 - val_accuracy: 0.6541\n","Epoch 64/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7110 - accuracy: 0.8610 - val_loss: 1.1279 - val_accuracy: 0.6606\n","Epoch 65/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7063 - accuracy: 0.8664 - val_loss: 1.1049 - val_accuracy: 0.6616\n","Epoch 66/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7006 - accuracy: 0.8658 - val_loss: 1.1273 - val_accuracy: 0.6638\n","Epoch 67/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6993 - accuracy: 0.8696 - val_loss: 1.1129 - val_accuracy: 0.6746\n","Epoch 68/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6952 - accuracy: 0.8675 - val_loss: 1.0938 - val_accuracy: 0.6746\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7004 - accuracy: 0.8607 - val_loss: 1.1646 - val_accuracy: 0.6487\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6895 - accuracy: 0.8685 - val_loss: 1.1214 - val_accuracy: 0.6638\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6812 - accuracy: 0.8763 - val_loss: 1.1167 - val_accuracy: 0.6681\n","Epoch 72/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6774 - accuracy: 0.8747 - val_loss: 1.1698 - val_accuracy: 0.6541\n","Epoch 73/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6802 - accuracy: 0.8747 - val_loss: 1.1153 - val_accuracy: 0.6713\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6698 - accuracy: 0.8785 - val_loss: 1.1104 - val_accuracy: 0.6681\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6810 - accuracy: 0.8688 - val_loss: 1.1105 - val_accuracy: 0.6681\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6669 - accuracy: 0.8785 - val_loss: 1.1157 - val_accuracy: 0.6724\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6596 - accuracy: 0.8823 - val_loss: 1.1239 - val_accuracy: 0.6638\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6562 - accuracy: 0.8847 - val_loss: 1.1307 - val_accuracy: 0.6713\n","Epoch 79/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6505 - accuracy: 0.8844 - val_loss: 1.1209 - val_accuracy: 0.6713\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6499 - accuracy: 0.8855 - val_loss: 1.1363 - val_accuracy: 0.6713\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6509 - accuracy: 0.8836 - val_loss: 1.1262 - val_accuracy: 0.6821\n","Epoch 82/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6453 - accuracy: 0.8842 - val_loss: 1.1591 - val_accuracy: 0.6627\n","Epoch 83/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6409 - accuracy: 0.8836 - val_loss: 1.1274 - val_accuracy: 0.6703\n","Epoch 84/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6374 - accuracy: 0.8850 - val_loss: 1.1798 - val_accuracy: 0.6509\n","Epoch 85/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6344 - accuracy: 0.8901 - val_loss: 1.1716 - val_accuracy: 0.6649\n","Epoch 86/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6249 - accuracy: 0.8971 - val_loss: 1.1575 - val_accuracy: 0.6692\n","Epoch 87/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6214 - accuracy: 0.8955 - val_loss: 1.1490 - val_accuracy: 0.6735\n","Epoch 88/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6189 - accuracy: 0.9003 - val_loss: 1.1556 - val_accuracy: 0.6649\n","Epoch 89/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6175 - accuracy: 0.8974 - val_loss: 1.1543 - val_accuracy: 0.6713\n","Epoch 90/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6137 - accuracy: 0.8990 - val_loss: 1.1653 - val_accuracy: 0.6681\n","Epoch 91/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6095 - accuracy: 0.9022 - val_loss: 1.1541 - val_accuracy: 0.6735\n","Epoch 92/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6058 - accuracy: 0.9036 - val_loss: 1.2508 - val_accuracy: 0.6412\n","Epoch 93/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6088 - accuracy: 0.9009 - val_loss: 1.1708 - val_accuracy: 0.6810\n","Epoch 94/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6064 - accuracy: 0.9003 - val_loss: 1.2072 - val_accuracy: 0.6606\n","Epoch 95/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5964 - accuracy: 0.9033 - val_loss: 1.1643 - val_accuracy: 0.6843\n","Epoch 96/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5933 - accuracy: 0.9033 - val_loss: 1.2062 - val_accuracy: 0.6584\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5934 - accuracy: 0.9041 - val_loss: 1.1670 - val_accuracy: 0.6832\n","Epoch 98/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5924 - accuracy: 0.9009 - val_loss: 1.2477 - val_accuracy: 0.6455\n","Epoch 99/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5899 - accuracy: 0.9038 - val_loss: 1.1742 - val_accuracy: 0.6767\n","Epoch 100/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5812 - accuracy: 0.9046 - val_loss: 1.2285 - val_accuracy: 0.6659\n","{'loss': [1.0402408838272095, 1.0264060497283936, 1.0179660320281982, 1.0096964836120605, 1.0040221214294434, 0.9985514283180237, 0.9903066158294678, 0.9847469925880432, 0.9793382883071899, 0.975243330001831, 0.9653549790382385, 0.9611213803291321, 0.9578718543052673, 0.9494880437850952, 0.9433373808860779, 0.9371274709701538, 0.9315369725227356, 0.9277915954589844, 0.9239115715026855, 0.9182512760162354, 0.911605954170227, 0.9045901298522949, 0.9002801775932312, 0.8948308229446411, 0.8913425803184509, 0.8826274871826172, 0.8811001777648926, 0.8725478053092957, 0.8673941493034363, 0.8633831739425659, 0.8586103320121765, 0.858502984046936, 0.8476282358169556, 0.8404163718223572, 0.8419991135597229, 0.8343039155006409, 0.8262614011764526, 0.8243502378463745, 0.8196473717689514, 0.8144075274467468, 0.8210569620132446, 0.8066744804382324, 0.7990231513977051, 0.7980663180351257, 0.7901813983917236, 0.7862632274627686, 0.7836836576461792, 0.7766976356506348, 0.7768489718437195, 0.7702668309211731, 0.7637250423431396, 0.7576998472213745, 0.762262761592865, 0.7582327723503113, 0.7510802149772644, 0.7447166442871094, 0.7387656569480896, 0.7359812259674072, 0.7336157560348511, 0.7274404168128967, 0.7211579084396362, 0.7171076536178589, 0.7125608325004578, 0.7109584808349609, 0.7063134908676147, 0.7005735039710999, 0.6992515921592712, 0.6952099800109863, 0.7003869414329529, 0.6895122528076172, 0.6812294125556946, 0.6773631572723389, 0.6801777482032776, 0.6698479056358337, 0.6810446381568909, 0.6668857932090759, 0.6595750451087952, 0.6562256813049316, 0.6504918336868286, 0.6498978137969971, 0.6509422063827515, 0.6452984809875488, 0.6409105062484741, 0.6373841762542725, 0.6343798637390137, 0.624920129776001, 0.6213887333869934, 0.6189185976982117, 0.6175318360328674, 0.613692045211792, 0.6095103025436401, 0.6057502627372742, 0.6088476777076721, 0.6063778400421143, 0.5963965654373169, 0.5932884216308594, 0.5933699607849121, 0.5923889875411987, 0.5899274349212646, 0.5811935067176819], 'accuracy': [0.7319504022598267, 0.740840494632721, 0.7446120977401733, 0.7537715435028076, 0.7556573152542114, 0.7535021305084229, 0.7613146305084229, 0.7634698152542114, 0.7621228694915771, 0.7613146305084229, 0.772090494632721, 0.7702047228813171, 0.7618534564971924, 0.7728987336158752, 0.7788254022598267, 0.7815194129943848, 0.779902994632721, 0.7766702771186829, 0.78125, 0.7820581793785095, 0.7790948152542114, 0.7869073152542114, 0.790678858757019, 0.7912176847457886, 0.7949892282485962, 0.796875, 0.7949892282485962, 0.8025323152542114, 0.8028017282485962, 0.8052262663841248, 0.803071141242981, 0.8025323152542114, 0.811152994632721, 0.8146551847457886, 0.8073814511299133, 0.8095366358757019, 0.8195043206214905, 0.8176185488700867, 0.818696141242981, 0.821659505367279, 0.818696141242981, 0.8232758641242981, 0.8275862336158752, 0.8278555870056152, 0.8321659564971924, 0.8327047228813171, 0.8370150923728943, 0.8429418206214905, 0.8394396305084229, 0.837553858757019, 0.8494073152542114, 0.8485991358757019, 0.8413254022598267, 0.8456357717514038, 0.8413254022598267, 0.8483297228813171, 0.8553340435028076, 0.8515625, 0.853178858757019, 0.858027994632721, 0.8582974076271057, 0.8569504022598267, 0.8647629022598267, 0.860991358757019, 0.8663793206214905, 0.865840494632721, 0.8696120977401733, 0.8674569129943848, 0.860722005367279, 0.868534505367279, 0.876347005367279, 0.8747305870056152, 0.8747305870056152, 0.8785021305084229, 0.868803858757019, 0.8785021305084229, 0.8822737336158752, 0.8846982717514038, 0.884428858757019, 0.8855064511299133, 0.8836206793785095, 0.884159505367279, 0.8836206793785095, 0.8849676847457886, 0.8900862336158752, 0.897090494632721, 0.8954741358757019, 0.9003232717514038, 0.8973599076271057, 0.8989762663841248, 0.9022090435028076, 0.9035560488700867, 0.9008620977401733, 0.9003232717514038, 0.9032866358757019, 0.9032866358757019, 0.9040948152542114, 0.9008620977401733, 0.9038254022598267, 0.904633641242981], 'val_loss': [1.2248127460479736, 1.2147802114486694, 1.2174314260482788, 1.2107388973236084, 1.2107198238372803, 1.1950838565826416, 1.1901962757110596, 1.1914703845977783, 1.1721184253692627, 1.1865873336791992, 1.1559773683547974, 1.1519520282745361, 1.1389501094818115, 1.1322375535964966, 1.1171724796295166, 1.1164891719818115, 1.1027745008468628, 1.08921480178833, 1.078319787979126, 1.062951683998108, 1.0699505805969238, 1.0568532943725586, 1.0625303983688354, 1.0685579776763916, 1.0541086196899414, 1.0746732950210571, 1.0634984970092773, 1.0641266107559204, 1.0593169927597046, 1.0871871709823608, 1.0701146125793457, 1.0627281665802002, 1.0667481422424316, 1.0643256902694702, 1.1194208860397339, 1.0698232650756836, 1.0898609161376953, 1.0861542224884033, 1.0823527574539185, 1.1516258716583252, 1.0681153535842896, 1.0766977071762085, 1.0679091215133667, 1.0775103569030762, 1.0776972770690918, 1.0929226875305176, 1.0739107131958008, 1.083000659942627, 1.0844401121139526, 1.0805251598358154, 1.0840086936950684, 1.0961265563964844, 1.0777643918991089, 1.1378602981567383, 1.0872684717178345, 1.0883691310882568, 1.0848920345306396, 1.0828014612197876, 1.1692216396331787, 1.0962125062942505, 1.0845988988876343, 1.1008769273757935, 1.1367411613464355, 1.1279408931732178, 1.1049363613128662, 1.1273162364959717, 1.1129282712936401, 1.093794822692871, 1.1645618677139282, 1.1213504076004028, 1.1166613101959229, 1.1697951555252075, 1.115289568901062, 1.1104474067687988, 1.1105444431304932, 1.1157480478286743, 1.123929738998413, 1.1306884288787842, 1.1208919286727905, 1.1362541913986206, 1.1261504888534546, 1.1590619087219238, 1.1274173259735107, 1.1797946691513062, 1.1716079711914062, 1.1574978828430176, 1.1489733457565308, 1.1555911302566528, 1.1542749404907227, 1.165324091911316, 1.1541128158569336, 1.2508337497711182, 1.1708264350891113, 1.2071574926376343, 1.1642768383026123, 1.2061702013015747, 1.1670137643814087, 1.2477290630340576, 1.1742186546325684, 1.2284719944000244], 'val_accuracy': [0.48706895112991333, 0.48706895112991333, 0.48706895112991333, 0.4881465435028076, 0.48706895112991333, 0.4913793206214905, 0.4913793206214905, 0.49353447556495667, 0.506465494632721, 0.5, 0.524784505367279, 0.5355603694915771, 0.5506465435028076, 0.5678879022598267, 0.5818965435028076, 0.5862069129943848, 0.5969827771186829, 0.6099137663841248, 0.6217672228813171, 0.6487069129943848, 0.6346982717514038, 0.6519396305084229, 0.6443965435028076, 0.6508620977401733, 0.6594827771186829, 0.6540948152542114, 0.670258641242981, 0.6659482717514038, 0.670258641242981, 0.662715494632721, 0.6584051847457886, 0.6594827771186829, 0.6670258641242981, 0.6616379022598267, 0.6476293206214905, 0.6724137663841248, 0.6616379022598267, 0.6540948152542114, 0.6659482717514038, 0.6508620977401733, 0.6637930870056152, 0.6691810488700867, 0.6659482717514038, 0.6691810488700867, 0.6659482717514038, 0.6584051847457886, 0.6713362336158752, 0.6637930870056152, 0.6681034564971924, 0.6659482717514038, 0.670258641242981, 0.6573275923728943, 0.6637930870056152, 0.6530172228813171, 0.6670258641242981, 0.670258641242981, 0.673491358757019, 0.6670258641242981, 0.6443965435028076, 0.670258641242981, 0.670258641242981, 0.6681034564971924, 0.6540948152542114, 0.6605603694915771, 0.6616379022598267, 0.6637930870056152, 0.6745689511299133, 0.6745689511299133, 0.6487069129943848, 0.6637930870056152, 0.6681034564971924, 0.6540948152542114, 0.6713362336158752, 0.6681034564971924, 0.6681034564971924, 0.6724137663841248, 0.6637930870056152, 0.6713362336158752, 0.6713362336158752, 0.6713362336158752, 0.6821120977401733, 0.662715494632721, 0.670258641242981, 0.6508620977401733, 0.6648706793785095, 0.6691810488700867, 0.673491358757019, 0.6648706793785095, 0.6713362336158752, 0.6681034564971924, 0.673491358757019, 0.6411637663841248, 0.681034505367279, 0.6605603694915771, 0.6842672228813171, 0.6584051847457886, 0.6831896305084229, 0.6454741358757019, 0.6767241358757019, 0.6659482717514038]}\n","38/38 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 1.0566 - accuracy: 0.7187"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 7s 76ms/step - loss: 1.0566 - accuracy: 0.7187 - val_loss: 1.2136 - val_accuracy: 0.4966\n","Epoch 2/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.0408 - accuracy: 0.7230 - val_loss: 1.2102 - val_accuracy: 0.4977\n","Epoch 3/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.0330 - accuracy: 0.7315 - val_loss: 1.2024 - val_accuracy: 0.4977\n","Epoch 4/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0256 - accuracy: 0.7394 - val_loss: 1.1997 - val_accuracy: 0.4977\n","Epoch 5/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.0206 - accuracy: 0.7340 - val_loss: 1.1871 - val_accuracy: 0.5011\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0135 - accuracy: 0.7383 - val_loss: 1.1893 - val_accuracy: 0.5000\n","Epoch 7/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.0062 - accuracy: 0.7470 - val_loss: 1.1759 - val_accuracy: 0.5045\n","Epoch 8/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9996 - accuracy: 0.7456 - val_loss: 1.1795 - val_accuracy: 0.5023\n","Epoch 9/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9958 - accuracy: 0.7510 - val_loss: 1.1771 - val_accuracy: 0.5057\n","Epoch 10/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.9893 - accuracy: 0.7507 - val_loss: 1.1655 - val_accuracy: 0.5124\n","Epoch 11/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9806 - accuracy: 0.7598 - val_loss: 1.1606 - val_accuracy: 0.5192\n","Epoch 12/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9792 - accuracy: 0.7538 - val_loss: 1.1520 - val_accuracy: 0.5328\n","Epoch 13/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9726 - accuracy: 0.7550 - val_loss: 1.1437 - val_accuracy: 0.5373\n","Epoch 14/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9643 - accuracy: 0.7651 - val_loss: 1.1369 - val_accuracy: 0.5452\n","Epoch 15/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9616 - accuracy: 0.7632 - val_loss: 1.1257 - val_accuracy: 0.5645\n","Epoch 16/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9540 - accuracy: 0.7654 - val_loss: 1.1157 - val_accuracy: 0.5667\n","Epoch 17/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9496 - accuracy: 0.7643 - val_loss: 1.1059 - val_accuracy: 0.5814\n","Epoch 18/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9414 - accuracy: 0.7725 - val_loss: 1.1012 - val_accuracy: 0.5871\n","Epoch 19/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9408 - accuracy: 0.7714 - val_loss: 1.0764 - val_accuracy: 0.6278\n","Epoch 20/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9341 - accuracy: 0.7765 - val_loss: 1.0689 - val_accuracy: 0.6312\n","Epoch 21/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9285 - accuracy: 0.7719 - val_loss: 1.0715 - val_accuracy: 0.6176\n","Epoch 22/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9192 - accuracy: 0.7790 - val_loss: 1.0494 - val_accuracy: 0.6584\n","Epoch 23/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9173 - accuracy: 0.7736 - val_loss: 1.0754 - val_accuracy: 0.6244\n","Epoch 24/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9129 - accuracy: 0.7793 - val_loss: 1.0655 - val_accuracy: 0.6425\n","Epoch 25/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9091 - accuracy: 0.7736 - val_loss: 1.0522 - val_accuracy: 0.6437\n","Epoch 26/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9037 - accuracy: 0.7784 - val_loss: 1.0401 - val_accuracy: 0.6867\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8977 - accuracy: 0.7849 - val_loss: 1.0367 - val_accuracy: 0.6787\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8902 - accuracy: 0.7906 - val_loss: 1.0416 - val_accuracy: 0.6708\n","Epoch 29/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8840 - accuracy: 0.7912 - val_loss: 1.0337 - val_accuracy: 0.6889\n","Epoch 30/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8791 - accuracy: 0.7946 - val_loss: 1.0356 - val_accuracy: 0.6686\n","Epoch 31/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8748 - accuracy: 0.7960 - val_loss: 1.0374 - val_accuracy: 0.6606\n","Epoch 32/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8704 - accuracy: 0.7954 - val_loss: 1.0353 - val_accuracy: 0.6606\n","Epoch 33/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8647 - accuracy: 0.7968 - val_loss: 1.0440 - val_accuracy: 0.6561\n","Epoch 34/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8607 - accuracy: 0.8016 - val_loss: 1.0375 - val_accuracy: 0.6674\n","Epoch 35/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8556 - accuracy: 0.8014 - val_loss: 1.0381 - val_accuracy: 0.6697\n","Epoch 36/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8506 - accuracy: 0.8076 - val_loss: 1.0561 - val_accuracy: 0.6708\n","Epoch 37/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8492 - accuracy: 0.8045 - val_loss: 1.0460 - val_accuracy: 0.6629\n","Epoch 38/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8476 - accuracy: 0.8016 - val_loss: 1.0377 - val_accuracy: 0.6719\n","Epoch 39/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8365 - accuracy: 0.8053 - val_loss: 1.0301 - val_accuracy: 0.6878\n","Epoch 40/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.8301 - accuracy: 0.8115 - val_loss: 1.0310 - val_accuracy: 0.6934\n","Epoch 41/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8271 - accuracy: 0.8084 - val_loss: 1.0302 - val_accuracy: 0.6867\n","Epoch 42/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8218 - accuracy: 0.8130 - val_loss: 1.0444 - val_accuracy: 0.6708\n","Epoch 43/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8158 - accuracy: 0.8183 - val_loss: 1.0302 - val_accuracy: 0.6833\n","Epoch 44/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8096 - accuracy: 0.8161 - val_loss: 1.0304 - val_accuracy: 0.6900\n","Epoch 45/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8136 - accuracy: 0.8104 - val_loss: 1.0457 - val_accuracy: 0.6629\n","Epoch 46/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8070 - accuracy: 0.8183 - val_loss: 1.0408 - val_accuracy: 0.6957\n","Epoch 47/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7973 - accuracy: 0.8240 - val_loss: 1.0289 - val_accuracy: 0.6946\n","Epoch 48/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7903 - accuracy: 0.8246 - val_loss: 1.0300 - val_accuracy: 0.6776\n","Epoch 49/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7867 - accuracy: 0.8234 - val_loss: 1.0310 - val_accuracy: 0.6844\n","Epoch 50/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7871 - accuracy: 0.8240 - val_loss: 1.0292 - val_accuracy: 0.6889\n","Epoch 51/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7788 - accuracy: 0.8311 - val_loss: 1.0339 - val_accuracy: 0.6719\n","Epoch 52/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7731 - accuracy: 0.8316 - val_loss: 1.0352 - val_accuracy: 0.6776\n","Epoch 53/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7682 - accuracy: 0.8339 - val_loss: 1.0341 - val_accuracy: 0.6753\n","Epoch 54/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7606 - accuracy: 0.8424 - val_loss: 1.0537 - val_accuracy: 0.6765\n","Epoch 55/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7612 - accuracy: 0.8325 - val_loss: 1.0370 - val_accuracy: 0.6946\n","Epoch 56/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7566 - accuracy: 0.8359 - val_loss: 1.0417 - val_accuracy: 0.6765\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7514 - accuracy: 0.8407 - val_loss: 1.0472 - val_accuracy: 0.6889\n","Epoch 58/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7576 - accuracy: 0.8311 - val_loss: 1.0519 - val_accuracy: 0.6787\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7434 - accuracy: 0.8387 - val_loss: 1.0371 - val_accuracy: 0.6889\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7381 - accuracy: 0.8447 - val_loss: 1.0365 - val_accuracy: 0.6833\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7339 - accuracy: 0.8475 - val_loss: 1.0364 - val_accuracy: 0.6900\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7299 - accuracy: 0.8483 - val_loss: 1.0433 - val_accuracy: 0.6900\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7258 - accuracy: 0.8506 - val_loss: 1.0406 - val_accuracy: 0.6821\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7187 - accuracy: 0.8514 - val_loss: 1.0401 - val_accuracy: 0.6810\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7234 - accuracy: 0.8466 - val_loss: 1.0651 - val_accuracy: 0.6697\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7140 - accuracy: 0.8574 - val_loss: 1.0426 - val_accuracy: 0.6900\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7083 - accuracy: 0.8585 - val_loss: 1.0482 - val_accuracy: 0.6765\n","Epoch 68/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7044 - accuracy: 0.8580 - val_loss: 1.0455 - val_accuracy: 0.6855\n","Epoch 69/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7069 - accuracy: 0.8565 - val_loss: 1.0480 - val_accuracy: 0.6765\n","Epoch 70/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6969 - accuracy: 0.8625 - val_loss: 1.0479 - val_accuracy: 0.6844\n","Epoch 71/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6923 - accuracy: 0.8659 - val_loss: 1.0495 - val_accuracy: 0.6810\n","Epoch 72/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6860 - accuracy: 0.8696 - val_loss: 1.0603 - val_accuracy: 0.6821\n","Epoch 73/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6833 - accuracy: 0.8664 - val_loss: 1.0540 - val_accuracy: 0.6776\n","Epoch 74/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6876 - accuracy: 0.8664 - val_loss: 1.0646 - val_accuracy: 0.6708\n","Epoch 75/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6744 - accuracy: 0.8758 - val_loss: 1.0589 - val_accuracy: 0.6844\n","Epoch 76/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6691 - accuracy: 0.8786 - val_loss: 1.0622 - val_accuracy: 0.6799\n","Epoch 77/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6677 - accuracy: 0.8792 - val_loss: 1.0936 - val_accuracy: 0.6674\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6678 - accuracy: 0.8763 - val_loss: 1.0615 - val_accuracy: 0.6844\n","Epoch 79/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6626 - accuracy: 0.8814 - val_loss: 1.0628 - val_accuracy: 0.6810\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6542 - accuracy: 0.8871 - val_loss: 1.0709 - val_accuracy: 0.6833\n","Epoch 81/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6514 - accuracy: 0.8831 - val_loss: 1.0845 - val_accuracy: 0.6787\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6505 - accuracy: 0.8846 - val_loss: 1.0836 - val_accuracy: 0.6787\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6433 - accuracy: 0.8916 - val_loss: 1.1151 - val_accuracy: 0.6731\n","Epoch 84/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6399 - accuracy: 0.8899 - val_loss: 1.0788 - val_accuracy: 0.6923\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6370 - accuracy: 0.8905 - val_loss: 1.0801 - val_accuracy: 0.6765\n","Epoch 86/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6312 - accuracy: 0.8953 - val_loss: 1.0975 - val_accuracy: 0.6708\n","Epoch 87/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6284 - accuracy: 0.8953 - val_loss: 1.0888 - val_accuracy: 0.6844\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6286 - accuracy: 0.8930 - val_loss: 1.0892 - val_accuracy: 0.6844\n","Epoch 89/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6223 - accuracy: 0.8953 - val_loss: 1.1007 - val_accuracy: 0.6799\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6167 - accuracy: 0.8976 - val_loss: 1.1001 - val_accuracy: 0.6855\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6185 - accuracy: 0.8964 - val_loss: 1.1004 - val_accuracy: 0.6799\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6098 - accuracy: 0.9029 - val_loss: 1.1089 - val_accuracy: 0.6833\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6064 - accuracy: 0.9052 - val_loss: 1.0989 - val_accuracy: 0.6923\n","Epoch 94/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6044 - accuracy: 0.9012 - val_loss: 1.1313 - val_accuracy: 0.6776\n","Epoch 95/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6013 - accuracy: 0.9069 - val_loss: 1.1207 - val_accuracy: 0.6799\n","Epoch 96/100\n","28/28 [==============================] - 1s 38ms/step - loss: 0.6015 - accuracy: 0.9049 - val_loss: 1.1429 - val_accuracy: 0.6753\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5972 - accuracy: 0.9055 - val_loss: 1.1706 - val_accuracy: 0.6663\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5961 - accuracy: 0.9066 - val_loss: 1.1354 - val_accuracy: 0.6753\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5937 - accuracy: 0.9055 - val_loss: 1.1272 - val_accuracy: 0.6753\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5854 - accuracy: 0.9109 - val_loss: 1.1463 - val_accuracy: 0.6753\n","{'loss': [1.0566381216049194, 1.040824294090271, 1.032975196838379, 1.0256330966949463, 1.0205823183059692, 1.013501524925232, 1.0061707496643066, 0.9995865225791931, 0.9957523345947266, 0.989295244216919, 0.9805718064308167, 0.9791507124900818, 0.9725736379623413, 0.9642972350120544, 0.9616181254386902, 0.9539652466773987, 0.949559211730957, 0.9413614869117737, 0.9408068656921387, 0.934130072593689, 0.9285144805908203, 0.919191300868988, 0.9173323512077332, 0.9128895401954651, 0.9090937972068787, 0.9037343859672546, 0.8976954817771912, 0.890217125415802, 0.8840391635894775, 0.8791250586509705, 0.874764621257782, 0.8704243302345276, 0.8647075295448303, 0.8606549501419067, 0.8555508255958557, 0.8506098985671997, 0.8492361903190613, 0.8475502729415894, 0.8364559412002563, 0.8300995230674744, 0.8271345496177673, 0.8218004703521729, 0.8158389329910278, 0.8095548152923584, 0.8136233687400818, 0.8070491552352905, 0.7972850203514099, 0.7903369069099426, 0.7866851091384888, 0.7871335744857788, 0.7787898778915405, 0.7730807065963745, 0.7682186365127563, 0.7606024742126465, 0.7611647248268127, 0.7565774321556091, 0.7513891458511353, 0.7575874924659729, 0.7433848977088928, 0.7381229400634766, 0.7339074015617371, 0.7298682332038879, 0.7257640361785889, 0.7187256813049316, 0.7234463691711426, 0.7140340209007263, 0.7082709670066833, 0.7043669819831848, 0.7069475054740906, 0.6968677639961243, 0.6922847032546997, 0.686017632484436, 0.6833453178405762, 0.6875700950622559, 0.6743963956832886, 0.669122576713562, 0.667687177658081, 0.6678066253662109, 0.6625760793685913, 0.6542114019393921, 0.6514087915420532, 0.6504661440849304, 0.6432681083679199, 0.6399063467979431, 0.6370002031326294, 0.6312317252159119, 0.6283625364303589, 0.6285600066184998, 0.6223467588424683, 0.6167464256286621, 0.618515133857727, 0.6098093390464783, 0.606429934501648, 0.6043843030929565, 0.6012997031211853, 0.6015387177467346, 0.5971813797950745, 0.5960865616798401, 0.5936797857284546, 0.5853878855705261], 'accuracy': [0.7187322974205017, 0.722976803779602, 0.731465756893158, 0.7393888235092163, 0.7340124249458313, 0.7382569313049316, 0.7470288872718811, 0.7456140518188477, 0.7509903907775879, 0.7507073879241943, 0.7597622871398926, 0.7538200616836548, 0.7549518942832947, 0.7651386260986328, 0.7631579041481018, 0.7654216289520264, 0.7642897367477417, 0.7724957466125488, 0.7713639140129089, 0.7764572501182556, 0.7719298005104065, 0.7790039777755737, 0.7736276388168335, 0.7792869210243225, 0.7736276388168335, 0.7784380316734314, 0.7849462628364563, 0.7906055450439453, 0.7911714911460876, 0.7945670485496521, 0.7959818840026855, 0.7954159379005432, 0.7968307733535767, 0.8016412258148193, 0.8013582229614258, 0.8075834512710571, 0.8044708371162415, 0.8016412258148193, 0.8053197264671326, 0.8115450143814087, 0.808432400226593, 0.8129597902297974, 0.8183361887931824, 0.8160724639892578, 0.810413122177124, 0.8183361887931824, 0.8239954710006714, 0.8245614171028137, 0.823429524898529, 0.8239954710006714, 0.8310695886611938, 0.8316355347633362, 0.8338992595672607, 0.8423882126808167, 0.8324844241142273, 0.8358800411224365, 0.8406904339790344, 0.8310695886611938, 0.8387096524238586, 0.8446519374847412, 0.8474816083908081, 0.8483304977416992, 0.8505942225456238, 0.8514431118965149, 0.846632719039917, 0.8573853969573975, 0.8585172891616821, 0.8579513430595398, 0.8565365076065063, 0.8624787926673889, 0.8658743500709534, 0.8695529103279114, 0.8664402961730957, 0.8664402961730957, 0.8757781386375427, 0.8786078095436096, 0.879173755645752, 0.8763440847396851, 0.8814374804496765, 0.8870967626571655, 0.8831352591514587, 0.8845500946044922, 0.8916242122650146, 0.8899264335632324, 0.8904923796653748, 0.8953027725219727, 0.8953027725219727, 0.8930390477180481, 0.8953027725219727, 0.8975664973258972, 0.8964346647262573, 0.9029428362846375, 0.905206561088562, 0.9012450575828552, 0.9069043397903442, 0.9049236178398132, 0.9054895043373108, 0.9066213965415955, 0.9054895043373108, 0.9108659029006958], 'val_loss': [1.2135953903198242, 1.210206151008606, 1.2024022340774536, 1.1996583938598633, 1.1871417760849, 1.1892907619476318, 1.1759284734725952, 1.1794997453689575, 1.177069067955017, 1.1654669046401978, 1.1606194972991943, 1.151960015296936, 1.1436985731124878, 1.1368762254714966, 1.125718116760254, 1.1157443523406982, 1.1058645248413086, 1.1012489795684814, 1.0764003992080688, 1.0689431428909302, 1.0714879035949707, 1.049394130706787, 1.0753883123397827, 1.0654582977294922, 1.0522102117538452, 1.0401184558868408, 1.0367116928100586, 1.0415674448013306, 1.033676028251648, 1.0355558395385742, 1.0374335050582886, 1.0352520942687988, 1.0440064668655396, 1.0375421047210693, 1.0381449460983276, 1.056114673614502, 1.0460315942764282, 1.0377147197723389, 1.0301103591918945, 1.0309760570526123, 1.0302042961120605, 1.0443779230117798, 1.0302432775497437, 1.030412197113037, 1.045670986175537, 1.0407938957214355, 1.028907060623169, 1.0299761295318604, 1.0309571027755737, 1.0291610956192017, 1.0338988304138184, 1.0351808071136475, 1.034124493598938, 1.053666591644287, 1.0370362997055054, 1.041723370552063, 1.0472291707992554, 1.0519075393676758, 1.03705894947052, 1.0365341901779175, 1.0364023447036743, 1.0433317422866821, 1.040563702583313, 1.0401370525360107, 1.0651103258132935, 1.042602777481079, 1.048241138458252, 1.0455057621002197, 1.0480008125305176, 1.0479286909103394, 1.0495469570159912, 1.0603227615356445, 1.0539557933807373, 1.0646106004714966, 1.0588537454605103, 1.0622494220733643, 1.0935875177383423, 1.061481237411499, 1.062842845916748, 1.0709025859832764, 1.084492564201355, 1.0835825204849243, 1.1150813102722168, 1.0787889957427979, 1.0801115036010742, 1.0975110530853271, 1.0888336896896362, 1.0892045497894287, 1.1007367372512817, 1.1001125574111938, 1.1003916263580322, 1.1088645458221436, 1.098946452140808, 1.131304383277893, 1.1206518411636353, 1.1428886651992798, 1.1705714464187622, 1.1354162693023682, 1.1271774768829346, 1.1463098526000977], 'val_accuracy': [0.49660632014274597, 0.4977375566959381, 0.4977375566959381, 0.4977375566959381, 0.5011312365531921, 0.5, 0.5045248866081238, 0.5022624731063843, 0.5056561231613159, 0.5124434232711792, 0.5192307829856873, 0.5328054428100586, 0.5373303294181824, 0.5452488660812378, 0.564479649066925, 0.5667420625686646, 0.581447958946228, 0.587104082107544, 0.627828061580658, 0.6312217116355896, 0.6176470518112183, 0.6583710312843323, 0.6244344115257263, 0.6425339579582214, 0.6436651349067688, 0.6866515874862671, 0.6787330508232117, 0.6708144545555115, 0.6889140009880066, 0.668552041053772, 0.6606335043907166, 0.6606335043907166, 0.6561086177825928, 0.6674208045005798, 0.6696832776069641, 0.6708144545555115, 0.662895917892456, 0.6719456911087036, 0.6877828240394592, 0.6934388875961304, 0.6866515874862671, 0.6708144545555115, 0.6832579374313354, 0.6900452375411987, 0.662895917892456, 0.6957013607025146, 0.6945701241493225, 0.6776018142700195, 0.6843891143798828, 0.6889140009880066, 0.6719456911087036, 0.6776018142700195, 0.6753393411636353, 0.6764705777168274, 0.6945701241493225, 0.6764705777168274, 0.6889140009880066, 0.6787330508232117, 0.6889140009880066, 0.6832579374313354, 0.6900452375411987, 0.6900452375411987, 0.6821267008781433, 0.6809954643249512, 0.6696832776069641, 0.6900452375411987, 0.6764705777168274, 0.685520350933075, 0.6764705777168274, 0.6843891143798828, 0.6809954643249512, 0.6821267008781433, 0.6776018142700195, 0.6708144545555115, 0.6843891143798828, 0.679864227771759, 0.6674208045005798, 0.6843891143798828, 0.6809954643249512, 0.6832579374313354, 0.6787330508232117, 0.6787330508232117, 0.6730769276618958, 0.692307710647583, 0.6764705777168274, 0.6708144545555115, 0.6843891143798828, 0.6843891143798828, 0.679864227771759, 0.685520350933075, 0.679864227771759, 0.6832579374313354, 0.692307710647583, 0.6776018142700195, 0.679864227771759, 0.6753393411636353, 0.6662895679473877, 0.6753393411636353, 0.6753393411636353, 0.6753393411636353]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 4s 36ms/step - loss: 1.0548 - accuracy: 0.7140 - val_loss: 1.2126 - val_accuracy: 0.4886\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 1s 16ms/step - loss: 1.0393 - accuracy: 0.7233 - val_loss: 1.2121 - val_accuracy: 0.4886\n","Epoch 3/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.0333 - accuracy: 0.7238 - val_loss: 1.1968 - val_accuracy: 0.4897\n","Epoch 4/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0239 - accuracy: 0.7372 - val_loss: 1.2031 - val_accuracy: 0.4886\n","Epoch 5/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0160 - accuracy: 0.7364 - val_loss: 1.1996 - val_accuracy: 0.4897\n","Epoch 6/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.0092 - accuracy: 0.7351 - val_loss: 1.1850 - val_accuracy: 0.4990\n","Epoch 7/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0014 - accuracy: 0.7421 - val_loss: 1.1821 - val_accuracy: 0.5031\n","Epoch 8/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9941 - accuracy: 0.7478 - val_loss: 1.1789 - val_accuracy: 0.5041\n","Epoch 9/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9887 - accuracy: 0.7501 - val_loss: 1.1664 - val_accuracy: 0.5207\n","Epoch 10/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9851 - accuracy: 0.7478 - val_loss: 1.1582 - val_accuracy: 0.5186\n","Epoch 11/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9762 - accuracy: 0.7514 - val_loss: 1.1563 - val_accuracy: 0.5269\n","Epoch 12/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9688 - accuracy: 0.7535 - val_loss: 1.1463 - val_accuracy: 0.5331\n","Epoch 13/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9661 - accuracy: 0.7527 - val_loss: 1.1230 - val_accuracy: 0.5640\n","Epoch 14/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9629 - accuracy: 0.7463 - val_loss: 1.1207 - val_accuracy: 0.5692\n","Epoch 15/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9524 - accuracy: 0.7592 - val_loss: 1.1060 - val_accuracy: 0.5826\n","Epoch 16/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9459 - accuracy: 0.7602 - val_loss: 1.0977 - val_accuracy: 0.6002\n","Epoch 17/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9419 - accuracy: 0.7566 - val_loss: 1.0821 - val_accuracy: 0.6281\n","Epoch 18/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9369 - accuracy: 0.7594 - val_loss: 1.0834 - val_accuracy: 0.6126\n","Epoch 19/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9299 - accuracy: 0.7633 - val_loss: 1.0833 - val_accuracy: 0.6116\n","Epoch 20/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9261 - accuracy: 0.7649 - val_loss: 1.0615 - val_accuracy: 0.6653\n","Epoch 21/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9183 - accuracy: 0.7708 - val_loss: 1.0580 - val_accuracy: 0.6581\n","Epoch 22/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9118 - accuracy: 0.7724 - val_loss: 1.0741 - val_accuracy: 0.6271\n","Epoch 23/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9109 - accuracy: 0.7770 - val_loss: 1.0641 - val_accuracy: 0.6498\n","Epoch 24/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9021 - accuracy: 0.7703 - val_loss: 1.0523 - val_accuracy: 0.6581\n","Epoch 25/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8979 - accuracy: 0.7780 - val_loss: 1.0538 - val_accuracy: 0.6539\n","Epoch 26/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8899 - accuracy: 0.7770 - val_loss: 1.0579 - val_accuracy: 0.6612\n","Epoch 27/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8834 - accuracy: 0.7835 - val_loss: 1.0621 - val_accuracy: 0.6570\n","Epoch 28/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8820 - accuracy: 0.7798 - val_loss: 1.0534 - val_accuracy: 0.6612\n","Epoch 29/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8733 - accuracy: 0.7817 - val_loss: 1.0515 - val_accuracy: 0.6539\n","Epoch 30/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8706 - accuracy: 0.7832 - val_loss: 1.0559 - val_accuracy: 0.6591\n","Epoch 31/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8626 - accuracy: 0.7935 - val_loss: 1.0596 - val_accuracy: 0.6591\n","Epoch 32/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8617 - accuracy: 0.7912 - val_loss: 1.0621 - val_accuracy: 0.6601\n","Epoch 33/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8565 - accuracy: 0.7938 - val_loss: 1.0617 - val_accuracy: 0.6612\n","Epoch 34/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8510 - accuracy: 0.7928 - val_loss: 1.0541 - val_accuracy: 0.6632\n","Epoch 35/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8454 - accuracy: 0.7966 - val_loss: 1.0672 - val_accuracy: 0.6612\n","Epoch 36/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8417 - accuracy: 0.7930 - val_loss: 1.0738 - val_accuracy: 0.6736\n","Epoch 37/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8399 - accuracy: 0.7987 - val_loss: 1.0807 - val_accuracy: 0.6612\n","Epoch 38/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8351 - accuracy: 0.7990 - val_loss: 1.0682 - val_accuracy: 0.6694\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8339 - accuracy: 0.7946 - val_loss: 1.0743 - val_accuracy: 0.6622\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8392 - accuracy: 0.7917 - val_loss: 1.0854 - val_accuracy: 0.6529\n","Epoch 41/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8161 - accuracy: 0.8052 - val_loss: 1.0594 - val_accuracy: 0.6632\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8106 - accuracy: 0.8085 - val_loss: 1.0538 - val_accuracy: 0.6622\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8069 - accuracy: 0.8134 - val_loss: 1.0548 - val_accuracy: 0.6622\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8006 - accuracy: 0.8214 - val_loss: 1.0531 - val_accuracy: 0.6705\n","Epoch 45/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7954 - accuracy: 0.8196 - val_loss: 1.0541 - val_accuracy: 0.6663\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7911 - accuracy: 0.8194 - val_loss: 1.0554 - val_accuracy: 0.6663\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7884 - accuracy: 0.8145 - val_loss: 1.0489 - val_accuracy: 0.6736\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7813 - accuracy: 0.8207 - val_loss: 1.0554 - val_accuracy: 0.6643\n","Epoch 49/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7778 - accuracy: 0.8256 - val_loss: 1.0569 - val_accuracy: 0.6622\n","Epoch 50/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7717 - accuracy: 0.8256 - val_loss: 1.0568 - val_accuracy: 0.6705\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7694 - accuracy: 0.8289 - val_loss: 1.0629 - val_accuracy: 0.6653\n","Epoch 52/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7696 - accuracy: 0.8289 - val_loss: 1.0578 - val_accuracy: 0.6632\n","Epoch 53/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7638 - accuracy: 0.8279 - val_loss: 1.0600 - val_accuracy: 0.6694\n","Epoch 54/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7620 - accuracy: 0.8307 - val_loss: 1.0607 - val_accuracy: 0.6663\n","Epoch 55/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7762 - accuracy: 0.8137 - val_loss: 1.0753 - val_accuracy: 0.6653\n","Epoch 56/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7509 - accuracy: 0.8364 - val_loss: 1.0806 - val_accuracy: 0.6529\n","Epoch 57/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7452 - accuracy: 0.8349 - val_loss: 1.0574 - val_accuracy: 0.6653\n","Epoch 58/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7398 - accuracy: 0.8475 - val_loss: 1.0593 - val_accuracy: 0.6705\n","Epoch 59/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7349 - accuracy: 0.8455 - val_loss: 1.0662 - val_accuracy: 0.6715\n","Epoch 60/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7331 - accuracy: 0.8411 - val_loss: 1.0687 - val_accuracy: 0.6694\n","Epoch 61/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7330 - accuracy: 0.8424 - val_loss: 1.0650 - val_accuracy: 0.6632\n","Epoch 62/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7232 - accuracy: 0.8483 - val_loss: 1.0697 - val_accuracy: 0.6632\n","Epoch 63/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7180 - accuracy: 0.8494 - val_loss: 1.0665 - val_accuracy: 0.6694\n","Epoch 64/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7150 - accuracy: 0.8504 - val_loss: 1.0939 - val_accuracy: 0.6725\n","Epoch 65/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7157 - accuracy: 0.8491 - val_loss: 1.0713 - val_accuracy: 0.6663\n","Epoch 66/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7053 - accuracy: 0.8610 - val_loss: 1.0729 - val_accuracy: 0.6674\n","Epoch 67/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7035 - accuracy: 0.8628 - val_loss: 1.0797 - val_accuracy: 0.6674\n","Epoch 68/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7020 - accuracy: 0.8610 - val_loss: 1.0777 - val_accuracy: 0.6653\n","Epoch 69/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6957 - accuracy: 0.8576 - val_loss: 1.0794 - val_accuracy: 0.6725\n","Epoch 70/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6951 - accuracy: 0.8568 - val_loss: 1.1215 - val_accuracy: 0.6457\n","Epoch 71/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6914 - accuracy: 0.8548 - val_loss: 1.1085 - val_accuracy: 0.6488\n","Epoch 72/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6857 - accuracy: 0.8633 - val_loss: 1.0929 - val_accuracy: 0.6694\n","Epoch 73/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6768 - accuracy: 0.8695 - val_loss: 1.0927 - val_accuracy: 0.6622\n","Epoch 74/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6752 - accuracy: 0.8721 - val_loss: 1.0898 - val_accuracy: 0.6653\n","Epoch 75/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6746 - accuracy: 0.8680 - val_loss: 1.1163 - val_accuracy: 0.6519\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6754 - accuracy: 0.8721 - val_loss: 1.0908 - val_accuracy: 0.6612\n","Epoch 77/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6653 - accuracy: 0.8705 - val_loss: 1.1127 - val_accuracy: 0.6539\n","Epoch 78/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6649 - accuracy: 0.8708 - val_loss: 1.1081 - val_accuracy: 0.6653\n","Epoch 79/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6590 - accuracy: 0.8742 - val_loss: 1.1110 - val_accuracy: 0.6684\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6523 - accuracy: 0.8770 - val_loss: 1.0943 - val_accuracy: 0.6684\n","Epoch 81/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6467 - accuracy: 0.8832 - val_loss: 1.1117 - val_accuracy: 0.6705\n","Epoch 82/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6463 - accuracy: 0.8822 - val_loss: 1.1142 - val_accuracy: 0.6591\n","Epoch 83/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6427 - accuracy: 0.8840 - val_loss: 1.1110 - val_accuracy: 0.6632\n","Epoch 84/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6369 - accuracy: 0.8842 - val_loss: 1.1570 - val_accuracy: 0.6467\n","Epoch 85/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6401 - accuracy: 0.8814 - val_loss: 1.1417 - val_accuracy: 0.6477\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6305 - accuracy: 0.8891 - val_loss: 1.1485 - val_accuracy: 0.6612\n","Epoch 87/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6333 - accuracy: 0.8814 - val_loss: 1.1311 - val_accuracy: 0.6570\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6283 - accuracy: 0.8855 - val_loss: 1.1298 - val_accuracy: 0.6622\n","Epoch 89/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6268 - accuracy: 0.8860 - val_loss: 1.1309 - val_accuracy: 0.6632\n","Epoch 90/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6234 - accuracy: 0.8868 - val_loss: 1.1509 - val_accuracy: 0.6612\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6265 - accuracy: 0.8822 - val_loss: 1.1584 - val_accuracy: 0.6498\n","Epoch 92/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6154 - accuracy: 0.8897 - val_loss: 1.1459 - val_accuracy: 0.6622\n","Epoch 93/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6130 - accuracy: 0.8879 - val_loss: 1.1561 - val_accuracy: 0.6705\n","Epoch 94/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6090 - accuracy: 0.8951 - val_loss: 1.1602 - val_accuracy: 0.6622\n","Epoch 95/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6020 - accuracy: 0.8984 - val_loss: 1.1475 - val_accuracy: 0.6601\n","Epoch 96/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5988 - accuracy: 0.8972 - val_loss: 1.1442 - val_accuracy: 0.6632\n","Epoch 97/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5960 - accuracy: 0.9018 - val_loss: 1.1635 - val_accuracy: 0.6663\n","Epoch 98/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5921 - accuracy: 0.9008 - val_loss: 1.1729 - val_accuracy: 0.6684\n","Epoch 99/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6034 - accuracy: 0.8884 - val_loss: 1.1967 - val_accuracy: 0.6529\n","Epoch 100/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5882 - accuracy: 0.9010 - val_loss: 1.1825 - val_accuracy: 0.6632\n","{'loss': [1.0548441410064697, 1.039276361465454, 1.0333250761032104, 1.0238673686981201, 1.015953779220581, 1.009187936782837, 1.0013571977615356, 0.9941103458404541, 0.9887307286262512, 0.9851439595222473, 0.976154088973999, 0.9687805771827698, 0.9660711288452148, 0.9628714323043823, 0.9524109363555908, 0.9458684325218201, 0.9419272541999817, 0.9368869066238403, 0.929922878742218, 0.9261398911476135, 0.9182995557785034, 0.9117855429649353, 0.9109137058258057, 0.9021388292312622, 0.897881805896759, 0.8898565173149109, 0.8833866119384766, 0.8819772601127625, 0.8733205199241638, 0.8705575466156006, 0.8625895380973816, 0.8617062568664551, 0.8565180897712708, 0.8510065078735352, 0.8454163670539856, 0.8417283296585083, 0.8398844003677368, 0.8350536823272705, 0.8339253664016724, 0.839221715927124, 0.8160990476608276, 0.8105815649032593, 0.806856095790863, 0.8006040453910828, 0.7953893542289734, 0.7911091446876526, 0.7884474396705627, 0.7813198566436768, 0.7777988314628601, 0.7717151641845703, 0.769365131855011, 0.7695904970169067, 0.7637916207313538, 0.7620157599449158, 0.7761848568916321, 0.7509475946426392, 0.7452215552330017, 0.7397946715354919, 0.7349096536636353, 0.7331082224845886, 0.7329514622688293, 0.7231839299201965, 0.7180294990539551, 0.714950442314148, 0.7156957387924194, 0.705303430557251, 0.7035207152366638, 0.7020062208175659, 0.6957361698150635, 0.6951113343238831, 0.6914215683937073, 0.6856516599655151, 0.6768383979797363, 0.6751960515975952, 0.6745874285697937, 0.6753819584846497, 0.6652725338935852, 0.6648567318916321, 0.6590355634689331, 0.6522989869117737, 0.6467360258102417, 0.646263599395752, 0.6427127718925476, 0.6369005441665649, 0.6401000618934631, 0.630466103553772, 0.6333486437797546, 0.6282580494880676, 0.6268191337585449, 0.6234474778175354, 0.6264843344688416, 0.6154297590255737, 0.6130191087722778, 0.6090142726898193, 0.6019672751426697, 0.5988274812698364, 0.5959744453430176, 0.5921180844306946, 0.6033918261528015, 0.5881993770599365], 'accuracy': [0.7139534950256348, 0.7232558131217957, 0.7237725853919983, 0.7372093200683594, 0.7364341020584106, 0.7351421117782593, 0.7421188354492188, 0.7478036284446716, 0.750129222869873, 0.7478036284446716, 0.7514212131500244, 0.7534883618354797, 0.7527132034301758, 0.746253252029419, 0.7591731548309326, 0.7602066993713379, 0.7565891742706299, 0.7594315409660339, 0.763307511806488, 0.7648578882217407, 0.7708010077476501, 0.7723514437675476, 0.7770025730133057, 0.7702842354774475, 0.7780361771583557, 0.7770025730133057, 0.7834625244140625, 0.7798449397087097, 0.7816537618637085, 0.7832041382789612, 0.7935400605201721, 0.7912144660949707, 0.7937984466552734, 0.7927648425102234, 0.7966408133506775, 0.7930232286453247, 0.7987080216407776, 0.7989664077758789, 0.7945736646652222, 0.7917312383651733, 0.8051679730415344, 0.8085271120071411, 0.8134366869926453, 0.8214470148086548, 0.8196382522583008, 0.8193798661231995, 0.8144702911376953, 0.8206718564033508, 0.8255813717842102, 0.8255813717842102, 0.8289405703544617, 0.8289405703544617, 0.8279069662094116, 0.8307493329048157, 0.8136950731277466, 0.8364341259002686, 0.8348837494850159, 0.8475452065467834, 0.8454780578613281, 0.8410852551460266, 0.842377245426178, 0.8483204245567322, 0.8493540287017822, 0.8503875732421875, 0.8490955829620361, 0.8609819412231445, 0.8627907037734985, 0.8609819412231445, 0.8576227426528931, 0.8568475246429443, 0.854780375957489, 0.8633074760437012, 0.8695090413093567, 0.8720930218696594, 0.867958664894104, 0.8720930218696594, 0.8705426454544067, 0.8708010315895081, 0.8741602301597595, 0.8770025968551636, 0.8832041621208191, 0.882170557975769, 0.883979320526123, 0.8842377066612244, 0.8813953399658203, 0.8891472816467285, 0.8813953399658203, 0.8855296969413757, 0.8860465288162231, 0.8868216872215271, 0.882170557975769, 0.8896640539169312, 0.8878552913665771, 0.8950904607772827, 0.8984495997428894, 0.897157609462738, 0.9018087983131409, 0.9007751941680908, 0.8883720636367798, 0.9010335803031921], 'val_loss': [1.2125757932662964, 1.2120777368545532, 1.1968401670455933, 1.2031023502349854, 1.1995781660079956, 1.1849884986877441, 1.1821129322052002, 1.1789110898971558, 1.166368842124939, 1.1582367420196533, 1.1562913656234741, 1.1462730169296265, 1.122970700263977, 1.120688557624817, 1.1059958934783936, 1.0976577997207642, 1.0821332931518555, 1.0834012031555176, 1.0833477973937988, 1.0615304708480835, 1.0579652786254883, 1.0740870237350464, 1.0640668869018555, 1.052322506904602, 1.053773045539856, 1.057946801185608, 1.0620917081832886, 1.0533798933029175, 1.0515244007110596, 1.055867075920105, 1.0596017837524414, 1.0620533227920532, 1.061686635017395, 1.054068684577942, 1.0672497749328613, 1.0737782716751099, 1.080712080001831, 1.068243384361267, 1.0742837190628052, 1.0854229927062988, 1.0593593120574951, 1.0537906885147095, 1.0548155307769775, 1.053082823753357, 1.0540804862976074, 1.0553951263427734, 1.0488548278808594, 1.0554338693618774, 1.0568897724151611, 1.0567522048950195, 1.062855839729309, 1.0578447580337524, 1.0599929094314575, 1.0607351064682007, 1.075250506401062, 1.080643892288208, 1.057441234588623, 1.0592600107192993, 1.0662107467651367, 1.0686819553375244, 1.0649888515472412, 1.0696862936019897, 1.0665254592895508, 1.0939282178878784, 1.0712919235229492, 1.0729329586029053, 1.0797377824783325, 1.0777270793914795, 1.0793944597244263, 1.1215336322784424, 1.1084564924240112, 1.0929114818572998, 1.0927295684814453, 1.0897761583328247, 1.1163225173950195, 1.0908427238464355, 1.1126619577407837, 1.108117699623108, 1.111049771308899, 1.0942645072937012, 1.1116663217544556, 1.1141709089279175, 1.1109787225723267, 1.1570364236831665, 1.1417206525802612, 1.1484673023223877, 1.1311296224594116, 1.129804253578186, 1.1309269666671753, 1.1509252786636353, 1.1583878993988037, 1.145898461341858, 1.1561475992202759, 1.1601810455322266, 1.1474581956863403, 1.1441713571548462, 1.1634926795959473, 1.1728745698928833, 1.196719765663147, 1.1825493574142456], 'val_accuracy': [0.4886363744735718, 0.4886363744735718, 0.48966941237449646, 0.4886363744735718, 0.48966941237449646, 0.49896693229675293, 0.5030992031097412, 0.5041322112083435, 0.5206611752510071, 0.5185950398445129, 0.5268595218658447, 0.5330578684806824, 0.5640496015548706, 0.5692148804664612, 0.5826446413993835, 0.6002066135406494, 0.6280992031097412, 0.6126033067703247, 0.6115702390670776, 0.6652892827987671, 0.6580578684806824, 0.6270661354064941, 0.6497933864593506, 0.6580578684806824, 0.6539255976676941, 0.6611570119857788, 0.6570248007774353, 0.6611570119857788, 0.6539255976676941, 0.6590909361839294, 0.6590909361839294, 0.6601239442825317, 0.6611570119857788, 0.663223147392273, 0.6611570119857788, 0.6735537052154541, 0.6611570119857788, 0.6694214940071106, 0.6621900796890259, 0.6528925895690918, 0.663223147392273, 0.6621900796890259, 0.6621900796890259, 0.6704545617103577, 0.6663222908973694, 0.6663222908973694, 0.6735537052154541, 0.66425621509552, 0.6621900796890259, 0.6704545617103577, 0.6652892827987671, 0.663223147392273, 0.6694214940071106, 0.6663222908973694, 0.6652892827987671, 0.6528925895690918, 0.6652892827987671, 0.6704545617103577, 0.6714876294136047, 0.6694214940071106, 0.663223147392273, 0.663223147392273, 0.6694214940071106, 0.672520637512207, 0.6663222908973694, 0.6673553586006165, 0.6673553586006165, 0.6652892827987671, 0.672520637512207, 0.6456611752510071, 0.6487603187561035, 0.6694214940071106, 0.6621900796890259, 0.6652892827987671, 0.6518595218658447, 0.6611570119857788, 0.6539255976676941, 0.6652892827987671, 0.6683884263038635, 0.6683884263038635, 0.6704545617103577, 0.6590909361839294, 0.663223147392273, 0.6466942429542542, 0.6477272510528564, 0.6611570119857788, 0.6570248007774353, 0.6621900796890259, 0.663223147392273, 0.6611570119857788, 0.6497933864593506, 0.6621900796890259, 0.6704545617103577, 0.6621900796890259, 0.6601239442825317, 0.663223147392273, 0.6663222908973694, 0.6683884263038635, 0.6528925895690918, 0.663223147392273]}\n","32/32 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 6s 30ms/step - loss: 0.6810 - accuracy: 0.8510 - val_loss: 1.5402 - val_accuracy: 0.4860\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.5672 - accuracy: 0.9297"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 11ms/step - loss: 0.6608 - accuracy: 0.8640 - val_loss: 1.5401 - val_accuracy: 0.4860\n","Epoch 3/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6447 - accuracy: 0.8726 - val_loss: 1.5461 - val_accuracy: 0.4860\n","Epoch 4/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6380 - accuracy: 0.8753 - val_loss: 1.5441 - val_accuracy: 0.4860\n","Epoch 5/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6321 - accuracy: 0.8782 - val_loss: 1.5354 - val_accuracy: 0.4860\n","Epoch 6/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6353 - accuracy: 0.8745 - val_loss: 1.5631 - val_accuracy: 0.4860\n","Epoch 7/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6336 - accuracy: 0.8704 - val_loss: 1.5479 - val_accuracy: 0.4860\n","Epoch 8/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6236 - accuracy: 0.8788 - val_loss: 1.5406 - val_accuracy: 0.4860\n","Epoch 9/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6163 - accuracy: 0.8844 - val_loss: 1.5422 - val_accuracy: 0.4860\n","Epoch 10/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6183 - accuracy: 0.8852 - val_loss: 1.5714 - val_accuracy: 0.4860\n","Epoch 11/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6154 - accuracy: 0.8842 - val_loss: 1.4867 - val_accuracy: 0.4914\n","Epoch 12/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6105 - accuracy: 0.8909 - val_loss: 1.4863 - val_accuracy: 0.4892\n","Epoch 13/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6026 - accuracy: 0.8939 - val_loss: 1.4904 - val_accuracy: 0.4925\n","Epoch 14/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5991 - accuracy: 0.8930 - val_loss: 1.3830 - val_accuracy: 0.5086\n","Epoch 15/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5968 - accuracy: 0.8957 - val_loss: 1.4265 - val_accuracy: 0.5172\n","Epoch 16/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5942 - accuracy: 0.8939 - val_loss: 1.3213 - val_accuracy: 0.5399\n","Epoch 17/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5963 - accuracy: 0.8898 - val_loss: 1.2182 - val_accuracy: 0.5593\n","Epoch 18/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5862 - accuracy: 0.8998 - val_loss: 1.2408 - val_accuracy: 0.5636\n","Epoch 19/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5839 - accuracy: 0.9011 - val_loss: 1.1770 - val_accuracy: 0.5862\n","Epoch 20/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5811 - accuracy: 0.9025 - val_loss: 1.1061 - val_accuracy: 0.6153\n","Epoch 21/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5792 - accuracy: 0.9014 - val_loss: 1.0908 - val_accuracy: 0.6207\n","Epoch 22/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5724 - accuracy: 0.9068 - val_loss: 0.9903 - val_accuracy: 0.6703\n","Epoch 23/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5701 - accuracy: 0.9065 - val_loss: 0.9726 - val_accuracy: 0.6821\n","Epoch 24/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5669 - accuracy: 0.9095 - val_loss: 0.9413 - val_accuracy: 0.7047\n","Epoch 25/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5646 - accuracy: 0.9081 - val_loss: 0.9622 - val_accuracy: 0.7058\n","Epoch 26/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5610 - accuracy: 0.9081 - val_loss: 0.9840 - val_accuracy: 0.7004\n","Epoch 27/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5597 - accuracy: 0.9127 - val_loss: 0.9653 - val_accuracy: 0.7328\n","Epoch 28/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5580 - accuracy: 0.9076 - val_loss: 0.9243 - val_accuracy: 0.7338\n","Epoch 29/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5571 - accuracy: 0.9098 - val_loss: 0.9274 - val_accuracy: 0.7371\n","Epoch 30/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.5507 - accuracy: 0.9122 - val_loss: 0.9237 - val_accuracy: 0.7500\n","Epoch 31/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5461 - accuracy: 0.9162 - val_loss: 0.9520 - val_accuracy: 0.7338\n","Epoch 32/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5455 - accuracy: 0.9135 - val_loss: 0.9391 - val_accuracy: 0.7468\n","Epoch 33/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5441 - accuracy: 0.9176 - val_loss: 0.9726 - val_accuracy: 0.7338\n","Epoch 34/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5402 - accuracy: 0.9149 - val_loss: 0.9840 - val_accuracy: 0.7263\n","Epoch 35/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5411 - accuracy: 0.9143 - val_loss: 0.9587 - val_accuracy: 0.7392\n","Epoch 36/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5349 - accuracy: 0.9181 - val_loss: 0.9544 - val_accuracy: 0.7457\n","Epoch 37/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5492 - accuracy: 0.9071 - val_loss: 1.0035 - val_accuracy: 0.7198\n","Epoch 38/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5315 - accuracy: 0.9197 - val_loss: 0.9853 - val_accuracy: 0.7328\n","Epoch 39/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5256 - accuracy: 0.9224 - val_loss: 0.9677 - val_accuracy: 0.7435\n","Epoch 40/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5224 - accuracy: 0.9243 - val_loss: 0.9668 - val_accuracy: 0.7414\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5179 - accuracy: 0.9246 - val_loss: 0.9618 - val_accuracy: 0.7511\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5143 - accuracy: 0.9275 - val_loss: 0.9622 - val_accuracy: 0.7500\n","Epoch 43/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5143 - accuracy: 0.9265 - val_loss: 1.0027 - val_accuracy: 0.7425\n","Epoch 44/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5190 - accuracy: 0.9240 - val_loss: 1.0105 - val_accuracy: 0.7252\n","Epoch 45/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5107 - accuracy: 0.9265 - val_loss: 0.9880 - val_accuracy: 0.7425\n","Epoch 46/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5078 - accuracy: 0.9305 - val_loss: 1.0292 - val_accuracy: 0.7284\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5068 - accuracy: 0.9310 - val_loss: 0.9996 - val_accuracy: 0.7317\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5089 - accuracy: 0.9308 - val_loss: 1.0103 - val_accuracy: 0.7403\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5083 - accuracy: 0.9281 - val_loss: 1.0065 - val_accuracy: 0.7403\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5088 - accuracy: 0.9227 - val_loss: 1.0094 - val_accuracy: 0.7403\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5051 - accuracy: 0.9265 - val_loss: 1.0094 - val_accuracy: 0.7425\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5207 - accuracy: 0.9230 - val_loss: 1.0383 - val_accuracy: 0.7263\n","Epoch 53/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5386 - accuracy: 0.9073 - val_loss: 1.0350 - val_accuracy: 0.7284\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4972 - accuracy: 0.9337 - val_loss: 1.0509 - val_accuracy: 0.7263\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4891 - accuracy: 0.9378 - val_loss: 1.0362 - val_accuracy: 0.7306\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4894 - accuracy: 0.9340 - val_loss: 1.0070 - val_accuracy: 0.7435\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4836 - accuracy: 0.9386 - val_loss: 1.0124 - val_accuracy: 0.7435\n","Epoch 58/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4829 - accuracy: 0.9364 - val_loss: 1.0140 - val_accuracy: 0.7392\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4825 - accuracy: 0.9375 - val_loss: 1.0425 - val_accuracy: 0.7328\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4808 - accuracy: 0.9367 - val_loss: 1.0618 - val_accuracy: 0.7360\n","Epoch 61/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4806 - accuracy: 0.9378 - val_loss: 1.0269 - val_accuracy: 0.7392\n","Epoch 62/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4781 - accuracy: 0.9383 - val_loss: 1.1029 - val_accuracy: 0.7198\n","Epoch 63/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4786 - accuracy: 0.9380 - val_loss: 1.0293 - val_accuracy: 0.7392\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4707 - accuracy: 0.9429 - val_loss: 1.0743 - val_accuracy: 0.7209\n","Epoch 65/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4687 - accuracy: 0.9405 - val_loss: 1.0415 - val_accuracy: 0.7403\n","Epoch 66/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4629 - accuracy: 0.9485 - val_loss: 1.0460 - val_accuracy: 0.7403\n","Epoch 67/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4625 - accuracy: 0.9453 - val_loss: 1.0267 - val_accuracy: 0.7414\n","Epoch 68/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4622 - accuracy: 0.9461 - val_loss: 1.0501 - val_accuracy: 0.7381\n","Epoch 69/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4611 - accuracy: 0.9413 - val_loss: 1.0693 - val_accuracy: 0.7425\n","Epoch 70/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4575 - accuracy: 0.9496 - val_loss: 1.0679 - val_accuracy: 0.7371\n","Epoch 71/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4578 - accuracy: 0.9445 - val_loss: 1.0386 - val_accuracy: 0.7414\n","Epoch 72/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4552 - accuracy: 0.9459 - val_loss: 1.0609 - val_accuracy: 0.7371\n","Epoch 73/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4541 - accuracy: 0.9469 - val_loss: 1.0737 - val_accuracy: 0.7425\n","Epoch 74/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4540 - accuracy: 0.9480 - val_loss: 1.1190 - val_accuracy: 0.7284\n","Epoch 75/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4518 - accuracy: 0.9461 - val_loss: 1.0781 - val_accuracy: 0.7317\n","Epoch 76/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4542 - accuracy: 0.9448 - val_loss: 1.0684 - val_accuracy: 0.7381\n","Epoch 77/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4494 - accuracy: 0.9507 - val_loss: 1.0907 - val_accuracy: 0.7295\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4438 - accuracy: 0.9518 - val_loss: 1.0740 - val_accuracy: 0.7414\n","Epoch 79/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4424 - accuracy: 0.9499 - val_loss: 1.0826 - val_accuracy: 0.7360\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4462 - accuracy: 0.9523 - val_loss: 1.0814 - val_accuracy: 0.7306\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4393 - accuracy: 0.9507 - val_loss: 1.1237 - val_accuracy: 0.7177\n","Epoch 82/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4436 - accuracy: 0.9488 - val_loss: 1.0910 - val_accuracy: 0.7360\n","Epoch 83/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4388 - accuracy: 0.9520 - val_loss: 1.1358 - val_accuracy: 0.7198\n","Epoch 84/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4315 - accuracy: 0.9531 - val_loss: 1.1200 - val_accuracy: 0.7392\n","Epoch 85/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4318 - accuracy: 0.9574 - val_loss: 1.1534 - val_accuracy: 0.7209\n","Epoch 86/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4295 - accuracy: 0.9547 - val_loss: 1.1046 - val_accuracy: 0.7392\n","Epoch 87/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4286 - accuracy: 0.9572 - val_loss: 1.1152 - val_accuracy: 0.7435\n","Epoch 88/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4232 - accuracy: 0.9596 - val_loss: 1.1143 - val_accuracy: 0.7317\n","Epoch 89/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4216 - accuracy: 0.9604 - val_loss: 1.1083 - val_accuracy: 0.7414\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4213 - accuracy: 0.9577 - val_loss: 1.1154 - val_accuracy: 0.7392\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4232 - accuracy: 0.9542 - val_loss: 1.1201 - val_accuracy: 0.7317\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4181 - accuracy: 0.9615 - val_loss: 1.1284 - val_accuracy: 0.7371\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4289 - accuracy: 0.9550 - val_loss: 1.1275 - val_accuracy: 0.7435\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4181 - accuracy: 0.9623 - val_loss: 1.1808 - val_accuracy: 0.7263\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4199 - accuracy: 0.9577 - val_loss: 1.1248 - val_accuracy: 0.7392\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4377 - accuracy: 0.9480 - val_loss: 1.1375 - val_accuracy: 0.7381\n","Epoch 97/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4367 - accuracy: 0.9464 - val_loss: 1.1677 - val_accuracy: 0.7295\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4275 - accuracy: 0.9550 - val_loss: 1.1485 - val_accuracy: 0.7349\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4282 - accuracy: 0.9504 - val_loss: 1.1395 - val_accuracy: 0.7328\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4235 - accuracy: 0.9550 - val_loss: 1.1488 - val_accuracy: 0.7360\n","{'loss': [0.6810449361801147, 0.660823404788971, 0.6446654200553894, 0.6379559636116028, 0.6320800185203552, 0.6353363394737244, 0.6336459517478943, 0.623627245426178, 0.6162612438201904, 0.6183134317398071, 0.6154389977455139, 0.6104596257209778, 0.602642297744751, 0.5991421341896057, 0.5967590808868408, 0.5941500663757324, 0.5963444709777832, 0.5861989259719849, 0.5838617086410522, 0.5811105966567993, 0.5791894793510437, 0.5724273920059204, 0.5701068639755249, 0.5668962597846985, 0.5645797848701477, 0.561005175113678, 0.5596961379051208, 0.5579617023468018, 0.5570633411407471, 0.5507129430770874, 0.5461423993110657, 0.545454740524292, 0.5440946817398071, 0.5401645302772522, 0.5411315560340881, 0.5349394083023071, 0.5491907596588135, 0.5315489172935486, 0.5256078839302063, 0.5224425196647644, 0.5178706049919128, 0.5142630934715271, 0.5142595171928406, 0.5190415978431702, 0.5107144117355347, 0.5078237056732178, 0.5068124532699585, 0.5088726878166199, 0.5082648992538452, 0.5087844133377075, 0.5051010251045227, 0.5207091569900513, 0.5385812520980835, 0.49718376994132996, 0.4890531599521637, 0.4893718361854553, 0.4835771322250366, 0.4829290509223938, 0.48253968358039856, 0.4807628095149994, 0.4805651009082794, 0.4780585467815399, 0.4786275625228882, 0.4707361161708832, 0.46871545910835266, 0.46294063329696655, 0.46246930956840515, 0.46218591928482056, 0.46114230155944824, 0.45746251940727234, 0.457825630903244, 0.4551885724067688, 0.4541400074958801, 0.45396360754966736, 0.4518272578716278, 0.4542297422885895, 0.44944342970848083, 0.44377902150154114, 0.44243887066841125, 0.44615769386291504, 0.439314603805542, 0.44360390305519104, 0.4387861490249634, 0.4314666986465454, 0.4317566752433777, 0.4294879734516144, 0.4285503923892975, 0.4232202470302582, 0.4215867221355438, 0.42127132415771484, 0.4232398271560669, 0.41808322072029114, 0.4289367198944092, 0.4181164503097534, 0.4199053943157196, 0.4376611113548279, 0.4366779327392578, 0.42752161622047424, 0.42815282940864563, 0.4235376715660095], 'accuracy': [0.8510237336158752, 0.8639547228813171, 0.8725754022598267, 0.8752694129943848, 0.8782327771186829, 0.8744612336158752, 0.8704202771186829, 0.8787715435028076, 0.884428858757019, 0.8852370977401733, 0.884159505367279, 0.8908944129943848, 0.8938577771186829, 0.8930495977401733, 0.8957435488700867, 0.8938577771186829, 0.8898168206214905, 0.899784505367279, 0.9011314511299133, 0.9024784564971924, 0.9014008641242981, 0.9067887663841248, 0.9065194129943848, 0.9094827771186829, 0.9081357717514038, 0.9081357717514038, 0.912715494632721, 0.907597005367279, 0.9097521305084229, 0.9121767282485962, 0.9162176847457886, 0.9135237336158752, 0.9175646305084229, 0.9148706793785095, 0.9143319129943848, 0.9181034564971924, 0.9070581793785095, 0.9197198152542114, 0.9224137663841248, 0.9242995977401733, 0.9245689511299133, 0.9275323152542114, 0.9264547228813171, 0.9240301847457886, 0.9264547228813171, 0.9304956793785095, 0.931034505367279, 0.9307650923728943, 0.928071141242981, 0.9226831793785095, 0.9264547228813171, 0.9229525923728943, 0.9073275923728943, 0.9337284564971924, 0.9377694129943848, 0.9339978694915771, 0.9385775923728943, 0.9364224076271057, 0.9375, 0.9366918206214905, 0.9377694129943848, 0.9383081793785095, 0.9380387663841248, 0.9428879022598267, 0.9404633641242981, 0.9485452771186829, 0.9453125, 0.9461206793785095, 0.9412715435028076, 0.9496228694915771, 0.9445043206214905, 0.9458512663841248, 0.946928858757019, 0.9480064511299133, 0.9461206793785095, 0.9447737336158752, 0.9507004022598267, 0.951777994632721, 0.9498922228813171, 0.9523168206214905, 0.9507004022598267, 0.9488146305084229, 0.9520474076271057, 0.953125, 0.9574353694915771, 0.954741358757019, 0.9571659564971924, 0.959590494632721, 0.9603987336158752, 0.9577047228813171, 0.9542025923728943, 0.9614762663841248, 0.9550107717514038, 0.962284505367279, 0.9577047228813171, 0.9480064511299133, 0.9463900923728943, 0.9550107717514038, 0.9504310488700867, 0.9550107717514038], 'val_loss': [1.5402214527130127, 1.540084719657898, 1.5461074113845825, 1.544097661972046, 1.5353623628616333, 1.5630638599395752, 1.547942876815796, 1.5405890941619873, 1.5421998500823975, 1.5714085102081299, 1.4867160320281982, 1.4863494634628296, 1.4903590679168701, 1.3829913139343262, 1.4265074729919434, 1.3212995529174805, 1.2182003259658813, 1.2407560348510742, 1.1770308017730713, 1.106138825416565, 1.0908433198928833, 0.9903320670127869, 0.9725835919380188, 0.9413089752197266, 0.962168276309967, 0.9839537143707275, 0.9652529358863831, 0.9242833256721497, 0.9273563623428345, 0.9236819744110107, 0.9520363807678223, 0.9391270279884338, 0.9726090431213379, 0.9839980006217957, 0.9587289690971375, 0.954409658908844, 1.0034655332565308, 0.9853435158729553, 0.9677368402481079, 0.966750979423523, 0.961843729019165, 0.9621841907501221, 1.0026503801345825, 1.0105185508728027, 0.987953245639801, 1.0292067527770996, 0.9995638132095337, 1.0102828741073608, 1.0064761638641357, 1.0094276666641235, 1.0094490051269531, 1.038300633430481, 1.034952163696289, 1.0508687496185303, 1.036187767982483, 1.0069644451141357, 1.012414574623108, 1.013957142829895, 1.042528510093689, 1.0617570877075195, 1.0269012451171875, 1.1028939485549927, 1.0293253660202026, 1.0742688179016113, 1.0414905548095703, 1.0459517240524292, 1.0267479419708252, 1.0501477718353271, 1.0692932605743408, 1.0679361820220947, 1.0386011600494385, 1.0608550310134888, 1.0737309455871582, 1.1190295219421387, 1.0780959129333496, 1.068416953086853, 1.090728998184204, 1.0740110874176025, 1.0825841426849365, 1.0813826322555542, 1.123660683631897, 1.0909732580184937, 1.1358271837234497, 1.1199926137924194, 1.153425693511963, 1.1046295166015625, 1.115239143371582, 1.1143466234207153, 1.1083197593688965, 1.1154053211212158, 1.1200852394104004, 1.1283735036849976, 1.127522587776184, 1.1808494329452515, 1.1247690916061401, 1.137467384338379, 1.1676687002182007, 1.1484532356262207, 1.1395128965377808, 1.1487902402877808], 'val_accuracy': [0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.4913793206214905, 0.4892241358757019, 0.4924568831920624, 0.5086206793785095, 0.517241358757019, 0.5398706793785095, 0.5592672228813171, 0.5635775923728943, 0.5862069129943848, 0.6153017282485962, 0.6206896305084229, 0.670258641242981, 0.6821120977401733, 0.704741358757019, 0.7058189511299133, 0.7004310488700867, 0.732758641242981, 0.7338362336158752, 0.7370689511299133, 0.75, 0.7338362336158752, 0.7467672228813171, 0.7338362336158752, 0.7262930870056152, 0.7392241358757019, 0.7456896305084229, 0.7198275923728943, 0.732758641242981, 0.743534505367279, 0.7413793206214905, 0.7510775923728943, 0.75, 0.7424569129943848, 0.725215494632721, 0.7424569129943848, 0.7284482717514038, 0.7316810488700867, 0.7403017282485962, 0.7403017282485962, 0.7403017282485962, 0.7424569129943848, 0.7262930870056152, 0.7284482717514038, 0.7262930870056152, 0.7306034564971924, 0.743534505367279, 0.743534505367279, 0.7392241358757019, 0.732758641242981, 0.735991358757019, 0.7392241358757019, 0.7198275923728943, 0.7392241358757019, 0.7209051847457886, 0.7403017282485962, 0.7403017282485962, 0.7413793206214905, 0.7381465435028076, 0.7424569129943848, 0.7370689511299133, 0.7413793206214905, 0.7370689511299133, 0.7424569129943848, 0.7284482717514038, 0.7316810488700867, 0.7381465435028076, 0.7295258641242981, 0.7413793206214905, 0.735991358757019, 0.7306034564971924, 0.7176724076271057, 0.735991358757019, 0.7198275923728943, 0.7392241358757019, 0.7209051847457886, 0.7392241358757019, 0.743534505367279, 0.7316810488700867, 0.7413793206214905, 0.7392241358757019, 0.7316810488700867, 0.7370689511299133, 0.743534505367279, 0.7262930870056152, 0.7392241358757019, 0.7381465435028076, 0.7295258641242981, 0.7349137663841248, 0.732758641242981, 0.735991358757019]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 3s 28ms/step - loss: 0.6810 - accuracy: 0.8463 - val_loss: 1.5090 - val_accuracy: 0.4955\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.7176 - accuracy: 0.8125"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 12ms/step - loss: 0.6522 - accuracy: 0.8659 - val_loss: 1.5098 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6452 - accuracy: 0.8684 - val_loss: 1.5032 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6423 - accuracy: 0.8639 - val_loss: 1.5167 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6445 - accuracy: 0.8645 - val_loss: 1.5018 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6323 - accuracy: 0.8713 - val_loss: 1.5136 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6285 - accuracy: 0.8744 - val_loss: 1.5198 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6224 - accuracy: 0.8806 - val_loss: 1.4890 - val_accuracy: 0.4955\n","Epoch 9/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6196 - accuracy: 0.8823 - val_loss: 1.4823 - val_accuracy: 0.4977\n","Epoch 10/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6173 - accuracy: 0.8797 - val_loss: 1.4736 - val_accuracy: 0.4977\n","Epoch 11/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6186 - accuracy: 0.8795 - val_loss: 1.4924 - val_accuracy: 0.4966\n","Epoch 12/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6104 - accuracy: 0.8834 - val_loss: 1.4402 - val_accuracy: 0.5011\n","Epoch 13/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6071 - accuracy: 0.8862 - val_loss: 1.4426 - val_accuracy: 0.5034\n","Epoch 14/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6004 - accuracy: 0.8874 - val_loss: 1.3822 - val_accuracy: 0.5079\n","Epoch 15/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5958 - accuracy: 0.8956 - val_loss: 1.3593 - val_accuracy: 0.5147\n","Epoch 16/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5933 - accuracy: 0.8947 - val_loss: 1.3175 - val_accuracy: 0.5271\n","Epoch 17/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.5897 - accuracy: 0.8947 - val_loss: 1.2313 - val_accuracy: 0.5600\n","Epoch 18/100\n","28/28 [==============================] - 1s 37ms/step - loss: 0.5858 - accuracy: 0.8990 - val_loss: 1.2308 - val_accuracy: 0.5667\n","Epoch 19/100\n","28/28 [==============================] - 1s 39ms/step - loss: 0.5905 - accuracy: 0.8947 - val_loss: 1.2545 - val_accuracy: 0.5679\n","Epoch 20/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5972 - accuracy: 0.8877 - val_loss: 1.1492 - val_accuracy: 0.5962\n","Epoch 21/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.5897 - accuracy: 0.8899 - val_loss: 1.0840 - val_accuracy: 0.6312\n","Epoch 22/100\n","28/28 [==============================] - 1s 41ms/step - loss: 0.5762 - accuracy: 0.8973 - val_loss: 1.0119 - val_accuracy: 0.6595\n","Epoch 23/100\n","28/28 [==============================] - 1s 42ms/step - loss: 0.5711 - accuracy: 0.9075 - val_loss: 0.9686 - val_accuracy: 0.6855\n","Epoch 24/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.5699 - accuracy: 0.9106 - val_loss: 0.8874 - val_accuracy: 0.7262\n","Epoch 25/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5698 - accuracy: 0.9024 - val_loss: 0.9467 - val_accuracy: 0.7104\n","Epoch 26/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5624 - accuracy: 0.9083 - val_loss: 0.8954 - val_accuracy: 0.7285\n","Epoch 27/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5582 - accuracy: 0.9117 - val_loss: 0.8900 - val_accuracy: 0.7319\n","Epoch 28/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5586 - accuracy: 0.9103 - val_loss: 0.8866 - val_accuracy: 0.7410\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5568 - accuracy: 0.9126 - val_loss: 0.8939 - val_accuracy: 0.7342\n","Epoch 30/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5513 - accuracy: 0.9154 - val_loss: 0.8976 - val_accuracy: 0.7353\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5484 - accuracy: 0.9143 - val_loss: 0.9078 - val_accuracy: 0.7342\n","Epoch 32/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5525 - accuracy: 0.9089 - val_loss: 0.9422 - val_accuracy: 0.7217\n","Epoch 33/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5451 - accuracy: 0.9177 - val_loss: 0.9514 - val_accuracy: 0.7274\n","Epoch 34/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5453 - accuracy: 0.9145 - val_loss: 0.9058 - val_accuracy: 0.7568\n","Epoch 35/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.5370 - accuracy: 0.9185 - val_loss: 0.9180 - val_accuracy: 0.7590\n","Epoch 36/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5353 - accuracy: 0.9225 - val_loss: 0.9209 - val_accuracy: 0.7590\n","Epoch 37/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5320 - accuracy: 0.9188 - val_loss: 0.9286 - val_accuracy: 0.7545\n","Epoch 38/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5356 - accuracy: 0.9188 - val_loss: 0.9263 - val_accuracy: 0.7376\n","Epoch 39/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5340 - accuracy: 0.9185 - val_loss: 0.9390 - val_accuracy: 0.7364\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5320 - accuracy: 0.9233 - val_loss: 0.9232 - val_accuracy: 0.7455\n","Epoch 41/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.5286 - accuracy: 0.9205 - val_loss: 0.9222 - val_accuracy: 0.7613\n","Epoch 42/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5276 - accuracy: 0.9230 - val_loss: 0.9364 - val_accuracy: 0.7579\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5190 - accuracy: 0.9267 - val_loss: 0.9368 - val_accuracy: 0.7557\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5164 - accuracy: 0.9259 - val_loss: 0.9373 - val_accuracy: 0.7557\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5126 - accuracy: 0.9278 - val_loss: 0.9374 - val_accuracy: 0.7511\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5115 - accuracy: 0.9281 - val_loss: 0.9461 - val_accuracy: 0.7613\n","Epoch 47/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5081 - accuracy: 0.9256 - val_loss: 0.9497 - val_accuracy: 0.7534\n","Epoch 48/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5015 - accuracy: 0.9332 - val_loss: 0.9465 - val_accuracy: 0.7534\n","Epoch 49/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5010 - accuracy: 0.9352 - val_loss: 0.9509 - val_accuracy: 0.7534\n","Epoch 50/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4977 - accuracy: 0.9324 - val_loss: 0.9685 - val_accuracy: 0.7511\n","Epoch 51/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4988 - accuracy: 0.9324 - val_loss: 0.9585 - val_accuracy: 0.7500\n","Epoch 52/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4955 - accuracy: 0.9344 - val_loss: 0.9653 - val_accuracy: 0.7534\n","Epoch 53/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4918 - accuracy: 0.9358 - val_loss: 0.9672 - val_accuracy: 0.7387\n","Epoch 54/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4935 - accuracy: 0.9366 - val_loss: 0.9696 - val_accuracy: 0.7432\n","Epoch 55/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4882 - accuracy: 0.9394 - val_loss: 1.0000 - val_accuracy: 0.7387\n","Epoch 56/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4897 - accuracy: 0.9372 - val_loss: 0.9893 - val_accuracy: 0.7489\n","Epoch 57/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4861 - accuracy: 0.9386 - val_loss: 0.9763 - val_accuracy: 0.7443\n","Epoch 58/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4842 - accuracy: 0.9392 - val_loss: 0.9992 - val_accuracy: 0.7398\n","Epoch 59/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4800 - accuracy: 0.9392 - val_loss: 0.9830 - val_accuracy: 0.7489\n","Epoch 60/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4969 - accuracy: 0.9261 - val_loss: 0.9990 - val_accuracy: 0.7330\n","Epoch 61/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4781 - accuracy: 0.9383 - val_loss: 0.9918 - val_accuracy: 0.7443\n","Epoch 62/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4726 - accuracy: 0.9443 - val_loss: 1.0598 - val_accuracy: 0.7127\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4886 - accuracy: 0.9360 - val_loss: 0.9995 - val_accuracy: 0.7432\n","Epoch 64/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4755 - accuracy: 0.9363 - val_loss: 0.9928 - val_accuracy: 0.7500\n","Epoch 65/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4686 - accuracy: 0.9451 - val_loss: 0.9909 - val_accuracy: 0.7534\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4660 - accuracy: 0.9440 - val_loss: 1.0079 - val_accuracy: 0.7443\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4706 - accuracy: 0.9411 - val_loss: 1.0212 - val_accuracy: 0.7398\n","Epoch 68/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4783 - accuracy: 0.9394 - val_loss: 1.0796 - val_accuracy: 0.7217\n","Epoch 69/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4708 - accuracy: 0.9400 - val_loss: 1.0244 - val_accuracy: 0.7364\n","Epoch 70/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.4630 - accuracy: 0.9471 - val_loss: 1.0633 - val_accuracy: 0.7285\n","Epoch 71/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.4602 - accuracy: 0.9491 - val_loss: 1.0325 - val_accuracy: 0.7421\n","Epoch 72/100\n","28/28 [==============================] - 1s 37ms/step - loss: 0.4554 - accuracy: 0.9488 - val_loss: 1.0157 - val_accuracy: 0.7398\n","Epoch 73/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.4564 - accuracy: 0.9488 - val_loss: 1.1046 - val_accuracy: 0.7183\n","Epoch 74/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4504 - accuracy: 0.9499 - val_loss: 1.0270 - val_accuracy: 0.7477\n","Epoch 75/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4487 - accuracy: 0.9522 - val_loss: 1.0251 - val_accuracy: 0.7455\n","Epoch 76/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4515 - accuracy: 0.9474 - val_loss: 1.0788 - val_accuracy: 0.7195\n","Epoch 77/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4521 - accuracy: 0.9513 - val_loss: 1.0381 - val_accuracy: 0.7421\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4407 - accuracy: 0.9576 - val_loss: 1.0296 - val_accuracy: 0.7410\n","Epoch 79/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4441 - accuracy: 0.9510 - val_loss: 1.0551 - val_accuracy: 0.7398\n","Epoch 80/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4455 - accuracy: 0.9496 - val_loss: 1.1041 - val_accuracy: 0.7195\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4485 - accuracy: 0.9468 - val_loss: 1.1015 - val_accuracy: 0.7104\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4449 - accuracy: 0.9544 - val_loss: 1.0548 - val_accuracy: 0.7376\n","Epoch 83/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4355 - accuracy: 0.9564 - val_loss: 1.0508 - val_accuracy: 0.7387\n","Epoch 84/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4349 - accuracy: 0.9573 - val_loss: 1.1430 - val_accuracy: 0.7081\n","Epoch 85/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4360 - accuracy: 0.9525 - val_loss: 1.0591 - val_accuracy: 0.7251\n","Epoch 86/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4360 - accuracy: 0.9564 - val_loss: 1.0693 - val_accuracy: 0.7364\n","Epoch 87/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4286 - accuracy: 0.9604 - val_loss: 1.0648 - val_accuracy: 0.7342\n","Epoch 88/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4278 - accuracy: 0.9618 - val_loss: 1.0706 - val_accuracy: 0.7296\n","Epoch 89/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4290 - accuracy: 0.9550 - val_loss: 1.0694 - val_accuracy: 0.7387\n","Epoch 90/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4244 - accuracy: 0.9626 - val_loss: 1.0760 - val_accuracy: 0.7308\n","Epoch 91/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4198 - accuracy: 0.9635 - val_loss: 1.0778 - val_accuracy: 0.7421\n","Epoch 92/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4225 - accuracy: 0.9610 - val_loss: 1.0964 - val_accuracy: 0.7353\n","Epoch 93/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4216 - accuracy: 0.9610 - val_loss: 1.0814 - val_accuracy: 0.7296\n","Epoch 94/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4189 - accuracy: 0.9615 - val_loss: 1.0865 - val_accuracy: 0.7342\n","Epoch 95/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4143 - accuracy: 0.9618 - val_loss: 1.0880 - val_accuracy: 0.7330\n","Epoch 96/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4146 - accuracy: 0.9621 - val_loss: 1.1071 - val_accuracy: 0.7364\n","Epoch 97/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4159 - accuracy: 0.9626 - val_loss: 1.1257 - val_accuracy: 0.7229\n","Epoch 98/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4126 - accuracy: 0.9615 - val_loss: 1.1000 - val_accuracy: 0.7319\n","Epoch 99/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4089 - accuracy: 0.9643 - val_loss: 1.1107 - val_accuracy: 0.7319\n","Epoch 100/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4140 - accuracy: 0.9629 - val_loss: 1.1333 - val_accuracy: 0.7308\n","{'loss': [0.6810441613197327, 0.65215665102005, 0.6452167630195618, 0.6423211097717285, 0.6445091366767883, 0.6323388814926147, 0.6284770965576172, 0.6223921179771423, 0.6196224093437195, 0.6173309087753296, 0.6186250448226929, 0.610355794429779, 0.6071326732635498, 0.6003580093383789, 0.595838189125061, 0.5932760238647461, 0.5896544456481934, 0.5858401656150818, 0.5904616117477417, 0.5972017645835876, 0.589695930480957, 0.5762054920196533, 0.5711315274238586, 0.5699362754821777, 0.569752037525177, 0.562387228012085, 0.5582059621810913, 0.5586323738098145, 0.5568146705627441, 0.5513350963592529, 0.5483922362327576, 0.5525456070899963, 0.5450952649116516, 0.5452673435211182, 0.5370281338691711, 0.5353387594223022, 0.5319676995277405, 0.5355662107467651, 0.5339992046356201, 0.5319831371307373, 0.5285956263542175, 0.5275904536247253, 0.5189793705940247, 0.5164302587509155, 0.5125805139541626, 0.5115007162094116, 0.5081298351287842, 0.5014779567718506, 0.5010142922401428, 0.4977482855319977, 0.4987778067588806, 0.49547863006591797, 0.49182990193367004, 0.4935453534126282, 0.4882242977619171, 0.4897404909133911, 0.48610180616378784, 0.48416683077812195, 0.47998374700546265, 0.4968608617782593, 0.47814783453941345, 0.4726268947124481, 0.48863810300827026, 0.4754981994628906, 0.46864789724349976, 0.46597278118133545, 0.4705814719200134, 0.47834205627441406, 0.47084176540374756, 0.46304115653038025, 0.4601706862449646, 0.4554400146007538, 0.4564187824726105, 0.4503774046897888, 0.44866806268692017, 0.4515376091003418, 0.4521114230155945, 0.4406530559062958, 0.4440653324127197, 0.4455168545246124, 0.44849833846092224, 0.44487544894218445, 0.43548646569252014, 0.4349166750907898, 0.4360119700431824, 0.4360211193561554, 0.42859306931495667, 0.42784079909324646, 0.4289666712284088, 0.4243842363357544, 0.419761061668396, 0.42251378297805786, 0.4216459393501282, 0.4188917875289917, 0.41434308886528015, 0.414569228887558, 0.4159125089645386, 0.41255292296409607, 0.4089359641075134, 0.41397804021835327], 'accuracy': [0.8463497161865234, 0.8658743500709534, 0.8684210777282715, 0.8638936281204224, 0.8644595146179199, 0.8712506890296936, 0.8743633031845093, 0.8805885910987854, 0.8822863698005676, 0.8797396421432495, 0.8794566988945007, 0.8834182024002075, 0.8862478733062744, 0.8873797655105591, 0.8955857157707214, 0.8947368264198303, 0.8947368264198303, 0.8989813327789307, 0.8947368264198303, 0.8876627087593079, 0.8899264335632324, 0.8972835540771484, 0.9074702858924866, 0.9105829000473022, 0.9023768901824951, 0.9083191752433777, 0.9117147922515869, 0.9102999567985535, 0.912563681602478, 0.9153932929039001, 0.9142614603042603, 0.90888512134552, 0.9176570177078247, 0.914544403553009, 0.9185059666633606, 0.9224674701690674, 0.9187889099121094, 0.9187889099121094, 0.9185059666633606, 0.9233163595199585, 0.9204866886138916, 0.9230334162712097, 0.926711916923523, 0.9258630275726318, 0.9278438091278076, 0.9281267523765564, 0.9255800843238831, 0.9332201480865479, 0.9352009296417236, 0.9323712587356567, 0.9323712587356567, 0.9343519806861877, 0.9357668161392212, 0.9366157054901123, 0.9394453763961792, 0.9371816515922546, 0.9385964870452881, 0.9391624331474304, 0.9391624331474304, 0.9261460304260254, 0.9383135437965393, 0.9442558288574219, 0.9360498189926147, 0.9363327622413635, 0.945104718208313, 0.9439728260040283, 0.9411431550979614, 0.9394453763961792, 0.9400113224983215, 0.947085440158844, 0.9490662217140198, 0.9487832188606262, 0.9487832188606262, 0.9499151110649109, 0.9521788358688354, 0.9473684430122375, 0.9513299465179443, 0.9575551748275757, 0.9510469436645508, 0.9496321678161621, 0.9468024969100952, 0.95444256067276, 0.9564233422279358, 0.9572722315788269, 0.9524617791175842, 0.9564233422279358, 0.9603848457336426, 0.961799681186676, 0.9550085067749023, 0.9626485705375671, 0.9634974598884583, 0.9609507918357849, 0.9609507918357849, 0.9615166783332825, 0.961799681186676, 0.9620826244354248, 0.9626485705375671, 0.9615166783332825, 0.9643463492393494, 0.9629315137863159], 'val_loss': [1.5090304613113403, 1.5098199844360352, 1.5031564235687256, 1.5167351961135864, 1.5018067359924316, 1.5135828256607056, 1.5197978019714355, 1.4890003204345703, 1.4823306798934937, 1.4736043214797974, 1.4923759698867798, 1.440198540687561, 1.4426305294036865, 1.3822135925292969, 1.3593305349349976, 1.3174586296081543, 1.2313309907913208, 1.2308132648468018, 1.2544864416122437, 1.1492193937301636, 1.084031343460083, 1.0119338035583496, 0.9686217308044434, 0.8873898386955261, 0.9466988444328308, 0.8954265713691711, 0.889980673789978, 0.8865814208984375, 0.8938950896263123, 0.8975905179977417, 0.9078425168991089, 0.9422484636306763, 0.9514086842536926, 0.90580153465271, 0.9179632067680359, 0.9208996295928955, 0.9286278486251831, 0.9263247847557068, 0.9390449523925781, 0.9232390522956848, 0.9221810102462769, 0.9363913536071777, 0.9367671012878418, 0.9373151063919067, 0.9373775124549866, 0.9460963010787964, 0.9497418403625488, 0.9464791417121887, 0.9509062170982361, 0.9684677720069885, 0.9585471749305725, 0.9653202295303345, 0.9672008752822876, 0.9695886373519897, 0.9999895095825195, 0.9893205761909485, 0.9762961268424988, 0.9992193579673767, 0.9830366373062134, 0.9989593029022217, 0.9918330311775208, 1.059800148010254, 0.999530553817749, 0.9928068518638611, 0.9909130334854126, 1.0078731775283813, 1.0211982727050781, 1.079647421836853, 1.0244262218475342, 1.0632892847061157, 1.0324853658676147, 1.015735387802124, 1.1045660972595215, 1.0270252227783203, 1.0251268148422241, 1.0787525177001953, 1.038067102432251, 1.0296058654785156, 1.0550662279129028, 1.104107141494751, 1.1014915704727173, 1.0547624826431274, 1.0508360862731934, 1.142996072769165, 1.0590989589691162, 1.0693048238754272, 1.0647717714309692, 1.070631980895996, 1.0694093704223633, 1.0759875774383545, 1.0778104066848755, 1.0963588953018188, 1.0813684463500977, 1.086505651473999, 1.088016390800476, 1.1070570945739746, 1.125661015510559, 1.0999946594238281, 1.1107455492019653, 1.1332706212997437], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4977375566959381, 0.4977375566959381, 0.49660632014274597, 0.5011312365531921, 0.5033936500549316, 0.5079185366630554, 0.5147058963775635, 0.5271493196487427, 0.5599547624588013, 0.5667420625686646, 0.5678732991218567, 0.5961538553237915, 0.6312217116355896, 0.6595022678375244, 0.685520350933075, 0.726244330406189, 0.7104072570800781, 0.7285068035125732, 0.7319004535675049, 0.7409502267837524, 0.7341628670692444, 0.7352941036224365, 0.7341628670692444, 0.7217194437980652, 0.7273755669593811, 0.7567873597145081, 0.7590497732162476, 0.7590497732162476, 0.7545248866081238, 0.7375565767288208, 0.7364253401756287, 0.7454751133918762, 0.7613122463226318, 0.7579185366630554, 0.7556561231613159, 0.7556561231613159, 0.7511312365531921, 0.7613122463226318, 0.7533936500549316, 0.7533936500549316, 0.7533936500549316, 0.7511312365531921, 0.75, 0.7533936500549316, 0.7386877536773682, 0.7432126402854919, 0.7386877536773682, 0.7488687634468079, 0.7443438768386841, 0.7398189902305603, 0.7488687634468079, 0.733031690120697, 0.7443438768386841, 0.7126696705818176, 0.7432126402854919, 0.75, 0.7533936500549316, 0.7443438768386841, 0.7398189902305603, 0.7217194437980652, 0.7364253401756287, 0.7285068035125732, 0.7420814633369446, 0.7398189902305603, 0.7183257937431335, 0.7477375268936157, 0.7454751133918762, 0.7194570302963257, 0.7420814633369446, 0.7409502267837524, 0.7398189902305603, 0.7194570302963257, 0.7104072570800781, 0.7375565767288208, 0.7386877536773682, 0.7081447839736938, 0.7251130938529968, 0.7364253401756287, 0.7341628670692444, 0.7296379804611206, 0.7386877536773682, 0.7307692170143127, 0.7420814633369446, 0.7352941036224365, 0.7296379804611206, 0.7341628670692444, 0.733031690120697, 0.7364253401756287, 0.7228506803512573, 0.7319004535675049, 0.7319004535675049, 0.7307692170143127]}\n","45/45 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 4s 27ms/step - loss: 0.6976 - accuracy: 0.8382 - val_loss: 1.5450 - val_accuracy: 0.4876\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.7152 - accuracy: 0.8906"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 12ms/step - loss: 0.6721 - accuracy: 0.8478 - val_loss: 1.5091 - val_accuracy: 0.4876\n","Epoch 3/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6671 - accuracy: 0.8470 - val_loss: 1.5368 - val_accuracy: 0.4886\n","Epoch 4/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6479 - accuracy: 0.8623 - val_loss: 1.5128 - val_accuracy: 0.4886\n","Epoch 5/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6527 - accuracy: 0.8599 - val_loss: 1.5428 - val_accuracy: 0.4886\n","Epoch 6/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6442 - accuracy: 0.8623 - val_loss: 1.5483 - val_accuracy: 0.4886\n","Epoch 7/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6372 - accuracy: 0.8698 - val_loss: 1.5158 - val_accuracy: 0.4897\n","Epoch 8/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6298 - accuracy: 0.8721 - val_loss: 1.5495 - val_accuracy: 0.4897\n","Epoch 9/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6266 - accuracy: 0.8757 - val_loss: 1.5729 - val_accuracy: 0.4897\n","Epoch 10/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6248 - accuracy: 0.8736 - val_loss: 1.5422 - val_accuracy: 0.4907\n","Epoch 11/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6200 - accuracy: 0.8801 - val_loss: 1.4825 - val_accuracy: 0.5010\n","Epoch 12/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6185 - accuracy: 0.8775 - val_loss: 1.3948 - val_accuracy: 0.5134\n","Epoch 13/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6193 - accuracy: 0.8775 - val_loss: 1.4463 - val_accuracy: 0.5114\n","Epoch 14/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6100 - accuracy: 0.8842 - val_loss: 1.3677 - val_accuracy: 0.5196\n","Epoch 15/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6043 - accuracy: 0.8876 - val_loss: 1.2937 - val_accuracy: 0.5320\n","Epoch 16/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6048 - accuracy: 0.8860 - val_loss: 1.3755 - val_accuracy: 0.5248\n","Epoch 17/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6015 - accuracy: 0.8868 - val_loss: 1.2743 - val_accuracy: 0.5537\n","Epoch 18/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5935 - accuracy: 0.8956 - val_loss: 1.1284 - val_accuracy: 0.5847\n","Epoch 19/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5896 - accuracy: 0.8979 - val_loss: 1.0883 - val_accuracy: 0.6033\n","Epoch 20/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5888 - accuracy: 0.8912 - val_loss: 1.0286 - val_accuracy: 0.6281\n","Epoch 21/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5883 - accuracy: 0.8951 - val_loss: 0.9621 - val_accuracy: 0.6756\n","Epoch 22/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5843 - accuracy: 0.8990 - val_loss: 1.0118 - val_accuracy: 0.6570\n","Epoch 23/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5801 - accuracy: 0.8938 - val_loss: 1.0054 - val_accuracy: 0.6777\n","Epoch 24/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5876 - accuracy: 0.8891 - val_loss: 0.9592 - val_accuracy: 0.7242\n","Epoch 25/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5907 - accuracy: 0.8879 - val_loss: 0.9468 - val_accuracy: 0.7180\n","Epoch 26/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5810 - accuracy: 0.8943 - val_loss: 0.9369 - val_accuracy: 0.7273\n","Epoch 27/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5829 - accuracy: 0.8948 - val_loss: 0.9386 - val_accuracy: 0.7242\n","Epoch 28/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5682 - accuracy: 0.9016 - val_loss: 0.9634 - val_accuracy: 0.7087\n","Epoch 29/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5640 - accuracy: 0.9052 - val_loss: 0.9572 - val_accuracy: 0.7045\n","Epoch 30/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5625 - accuracy: 0.9067 - val_loss: 0.9851 - val_accuracy: 0.7231\n","Epoch 31/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5588 - accuracy: 0.9054 - val_loss: 0.9731 - val_accuracy: 0.7056\n","Epoch 32/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5591 - accuracy: 0.9010 - val_loss: 0.9853 - val_accuracy: 0.7242\n","Epoch 33/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5550 - accuracy: 0.9090 - val_loss: 0.9647 - val_accuracy: 0.7262\n","Epoch 34/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5543 - accuracy: 0.9059 - val_loss: 0.9720 - val_accuracy: 0.7066\n","Epoch 35/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5531 - accuracy: 0.9090 - val_loss: 0.9820 - val_accuracy: 0.7221\n","Epoch 36/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5498 - accuracy: 0.9098 - val_loss: 0.9626 - val_accuracy: 0.7273\n","Epoch 37/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5421 - accuracy: 0.9129 - val_loss: 0.9929 - val_accuracy: 0.7066\n","Epoch 38/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5436 - accuracy: 0.9121 - val_loss: 1.0313 - val_accuracy: 0.6994\n","Epoch 39/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5426 - accuracy: 0.9093 - val_loss: 0.9880 - val_accuracy: 0.7252\n","Epoch 40/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5508 - accuracy: 0.9075 - val_loss: 1.0010 - val_accuracy: 0.7045\n","Epoch 41/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5317 - accuracy: 0.9194 - val_loss: 0.9959 - val_accuracy: 0.7252\n","Epoch 42/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5367 - accuracy: 0.9145 - val_loss: 0.9870 - val_accuracy: 0.7242\n","Epoch 43/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5292 - accuracy: 0.9163 - val_loss: 1.0098 - val_accuracy: 0.7056\n","Epoch 44/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5223 - accuracy: 0.9217 - val_loss: 1.0029 - val_accuracy: 0.7128\n","Epoch 45/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5209 - accuracy: 0.9243 - val_loss: 1.0084 - val_accuracy: 0.7004\n","Epoch 46/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5238 - accuracy: 0.9214 - val_loss: 1.0069 - val_accuracy: 0.7066\n","Epoch 47/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5174 - accuracy: 0.9202 - val_loss: 1.0130 - val_accuracy: 0.7180\n","Epoch 48/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5203 - accuracy: 0.9194 - val_loss: 1.0186 - val_accuracy: 0.7252\n","Epoch 49/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5160 - accuracy: 0.9227 - val_loss: 1.0270 - val_accuracy: 0.7200\n","Epoch 50/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5165 - accuracy: 0.9222 - val_loss: 1.0154 - val_accuracy: 0.7159\n","Epoch 51/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5094 - accuracy: 0.9214 - val_loss: 1.0313 - val_accuracy: 0.7149\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5058 - accuracy: 0.9284 - val_loss: 1.0123 - val_accuracy: 0.7169\n","Epoch 53/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5069 - accuracy: 0.9279 - val_loss: 1.0251 - val_accuracy: 0.7169\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5006 - accuracy: 0.9289 - val_loss: 1.0223 - val_accuracy: 0.7169\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4999 - accuracy: 0.9282 - val_loss: 1.0266 - val_accuracy: 0.7221\n","Epoch 56/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4950 - accuracy: 0.9305 - val_loss: 1.0229 - val_accuracy: 0.7128\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4922 - accuracy: 0.9318 - val_loss: 1.0313 - val_accuracy: 0.7087\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4938 - accuracy: 0.9310 - val_loss: 1.0323 - val_accuracy: 0.7087\n","Epoch 59/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4891 - accuracy: 0.9307 - val_loss: 1.0342 - val_accuracy: 0.7107\n","Epoch 60/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4967 - accuracy: 0.9276 - val_loss: 1.0865 - val_accuracy: 0.7014\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4980 - accuracy: 0.9266 - val_loss: 1.0657 - val_accuracy: 0.6911\n","Epoch 62/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4938 - accuracy: 0.9284 - val_loss: 1.0608 - val_accuracy: 0.7076\n","Epoch 63/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4819 - accuracy: 0.9351 - val_loss: 1.0472 - val_accuracy: 0.7066\n","Epoch 64/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4812 - accuracy: 0.9333 - val_loss: 1.0536 - val_accuracy: 0.6983\n","Epoch 65/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4851 - accuracy: 0.9274 - val_loss: 1.0463 - val_accuracy: 0.7056\n","Epoch 66/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4754 - accuracy: 0.9362 - val_loss: 1.0631 - val_accuracy: 0.7169\n","Epoch 67/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4764 - accuracy: 0.9344 - val_loss: 1.0695 - val_accuracy: 0.7180\n","Epoch 68/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4816 - accuracy: 0.9323 - val_loss: 1.0828 - val_accuracy: 0.7118\n","Epoch 69/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4762 - accuracy: 0.9367 - val_loss: 1.0796 - val_accuracy: 0.7107\n","Epoch 70/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4696 - accuracy: 0.9354 - val_loss: 1.0805 - val_accuracy: 0.7159\n","Epoch 71/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4672 - accuracy: 0.9406 - val_loss: 1.0603 - val_accuracy: 0.7097\n","Epoch 72/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4682 - accuracy: 0.9393 - val_loss: 1.1157 - val_accuracy: 0.7149\n","Epoch 73/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4659 - accuracy: 0.9380 - val_loss: 1.0919 - val_accuracy: 0.7190\n","Epoch 74/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4607 - accuracy: 0.9416 - val_loss: 1.0841 - val_accuracy: 0.7045\n","Epoch 75/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4599 - accuracy: 0.9447 - val_loss: 1.0882 - val_accuracy: 0.7025\n","Epoch 76/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4606 - accuracy: 0.9439 - val_loss: 1.1179 - val_accuracy: 0.7045\n","Epoch 77/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4590 - accuracy: 0.9444 - val_loss: 1.0863 - val_accuracy: 0.7025\n","Epoch 78/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4619 - accuracy: 0.9380 - val_loss: 1.1381 - val_accuracy: 0.6983\n","Epoch 79/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4648 - accuracy: 0.9364 - val_loss: 1.0970 - val_accuracy: 0.7066\n","Epoch 80/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4545 - accuracy: 0.9475 - val_loss: 1.1889 - val_accuracy: 0.7014\n","Epoch 81/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4535 - accuracy: 0.9447 - val_loss: 1.1317 - val_accuracy: 0.7087\n","Epoch 82/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4488 - accuracy: 0.9468 - val_loss: 1.2093 - val_accuracy: 0.7056\n","Epoch 83/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4590 - accuracy: 0.9370 - val_loss: 1.1701 - val_accuracy: 0.6973\n","Epoch 84/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4620 - accuracy: 0.9372 - val_loss: 1.1304 - val_accuracy: 0.6983\n","Epoch 85/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4492 - accuracy: 0.9442 - val_loss: 1.1414 - val_accuracy: 0.7066\n","Epoch 86/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4404 - accuracy: 0.9496 - val_loss: 1.1287 - val_accuracy: 0.7025\n","Epoch 87/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4378 - accuracy: 0.9499 - val_loss: 1.1428 - val_accuracy: 0.7076\n","Epoch 88/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4374 - accuracy: 0.9514 - val_loss: 1.2001 - val_accuracy: 0.6849\n","Epoch 89/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4396 - accuracy: 0.9496 - val_loss: 1.1707 - val_accuracy: 0.7025\n","Epoch 90/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4367 - accuracy: 0.9512 - val_loss: 1.1436 - val_accuracy: 0.7056\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4411 - accuracy: 0.9455 - val_loss: 1.1441 - val_accuracy: 0.7097\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4338 - accuracy: 0.9488 - val_loss: 1.1514 - val_accuracy: 0.7097\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4327 - accuracy: 0.9517 - val_loss: 1.1575 - val_accuracy: 0.7118\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4307 - accuracy: 0.9509 - val_loss: 1.1440 - val_accuracy: 0.6963\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4289 - accuracy: 0.9499 - val_loss: 1.1656 - val_accuracy: 0.7169\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4231 - accuracy: 0.9537 - val_loss: 1.2326 - val_accuracy: 0.7045\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4234 - accuracy: 0.9589 - val_loss: 1.1718 - val_accuracy: 0.6994\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4367 - accuracy: 0.9455 - val_loss: 1.2284 - val_accuracy: 0.6952\n","Epoch 99/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4382 - accuracy: 0.9494 - val_loss: 1.2478 - val_accuracy: 0.7056\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4242 - accuracy: 0.9530 - val_loss: 1.2255 - val_accuracy: 0.6921\n","{'loss': [0.6976162195205688, 0.6721088290214539, 0.6670665740966797, 0.6478918790817261, 0.652722179889679, 0.6442151069641113, 0.6372088193893433, 0.629848062992096, 0.6266199350357056, 0.6247674822807312, 0.6199584007263184, 0.6184952259063721, 0.6192795038223267, 0.6100403666496277, 0.6042528748512268, 0.604846179485321, 0.601510763168335, 0.5935229659080505, 0.589622437953949, 0.5888184905052185, 0.588268518447876, 0.5842901468276978, 0.5800596475601196, 0.5876166224479675, 0.5906667709350586, 0.5809532403945923, 0.5829315781593323, 0.5682324767112732, 0.5639562010765076, 0.5625433921813965, 0.5588465332984924, 0.5590630769729614, 0.5550127029418945, 0.5543139576911926, 0.5530648827552795, 0.5497702956199646, 0.5420656204223633, 0.5435740351676941, 0.5426056385040283, 0.5508437752723694, 0.5317420959472656, 0.5366557836532593, 0.5292438268661499, 0.5223209261894226, 0.5208982229232788, 0.5237950086593628, 0.5174190402030945, 0.520343542098999, 0.5160014033317566, 0.5165165662765503, 0.5094494819641113, 0.5057992935180664, 0.5068784356117249, 0.5006088614463806, 0.4999345541000366, 0.49498748779296875, 0.4922494888305664, 0.49384185671806335, 0.48906558752059937, 0.49670499563217163, 0.49797916412353516, 0.49379244446754456, 0.4818662703037262, 0.48124000430107117, 0.4851361811161041, 0.4753856956958771, 0.4764058589935303, 0.4816489815711975, 0.4762251079082489, 0.4695844054222107, 0.46717244386672974, 0.46818894147872925, 0.46589213609695435, 0.4607124626636505, 0.4599103331565857, 0.4605585038661957, 0.4590111970901489, 0.4618922472000122, 0.46475309133529663, 0.4544994831085205, 0.4535222053527832, 0.44882985949516296, 0.458957701921463, 0.46197274327278137, 0.4492107629776001, 0.4403788447380066, 0.4378277659416199, 0.4374150335788727, 0.4395929276943207, 0.4366742670536041, 0.4410833716392517, 0.4338313937187195, 0.43268200755119324, 0.4306526184082031, 0.4288685619831085, 0.4231444299221039, 0.42344483733177185, 0.4366776645183563, 0.43819019198417664, 0.4242320656776428], 'accuracy': [0.8382428884506226, 0.8478035926818848, 0.8470284342765808, 0.8622739315032959, 0.8599483370780945, 0.8622739315032959, 0.869767427444458, 0.8720930218696594, 0.8757106065750122, 0.8736433982849121, 0.880103349685669, 0.8775193691253662, 0.8775193691253662, 0.8842377066612244, 0.8875969052314758, 0.8860465288162231, 0.8868216872215271, 0.8956072330474854, 0.8979328274726868, 0.8912144899368286, 0.8950904607772827, 0.8989664316177368, 0.8937984704971313, 0.8891472816467285, 0.8878552913665771, 0.894315242767334, 0.8948320150375366, 0.9015504121780396, 0.9051679372787476, 0.906718373298645, 0.9054263830184937, 0.9010335803031921, 0.9090439081192017, 0.9059431552886963, 0.9090439081192017, 0.9098191261291504, 0.9129198789596558, 0.9121447205543518, 0.9093023538589478, 0.907493531703949, 0.9193798303604126, 0.9144702553749084, 0.9162790775299072, 0.921705424785614, 0.9242894053459167, 0.9214470386505127, 0.9201550483703613, 0.9193798303604126, 0.9227390289306641, 0.9222221970558167, 0.9214470386505127, 0.9284237623214722, 0.9279069900512695, 0.9289405941963196, 0.9281653761863708, 0.9304909706115723, 0.9317829608917236, 0.9310077428817749, 0.9307493567466736, 0.9276486039161682, 0.9266149997711182, 0.9284237623214722, 0.9351420998573303, 0.9333333373069763, 0.9273901581764221, 0.9361757040023804, 0.9343669414520264, 0.9322997331619263, 0.9366925358772278, 0.9354005455970764, 0.9405684471130371, 0.9392764568328857, 0.9379844665527344, 0.9416020512580872, 0.9447028636932373, 0.9439276456832886, 0.9444444179534912, 0.9379844665527344, 0.9364340901374817, 0.9475452303886414, 0.9447028636932373, 0.9467700123786926, 0.9369509220123291, 0.9372093081474304, 0.9441860318183899, 0.9496123790740967, 0.9498708248138428, 0.9514212012290955, 0.9496123790740967, 0.9511628150939941, 0.9454780220985413, 0.9488372206687927, 0.9516795873641968, 0.950904369354248, 0.9498708248138428, 0.9537467956542969, 0.9589147567749023, 0.9454780220985413, 0.9493539929389954, 0.9529715776443481], 'val_loss': [1.5450369119644165, 1.5091077089309692, 1.5368252992630005, 1.512758731842041, 1.5427948236465454, 1.5482935905456543, 1.5158162117004395, 1.549474835395813, 1.5728930234909058, 1.5422208309173584, 1.4824740886688232, 1.3948193788528442, 1.4463354349136353, 1.367714285850525, 1.2936546802520752, 1.3754684925079346, 1.2742846012115479, 1.128419280052185, 1.0882766246795654, 1.0286281108856201, 0.9621089100837708, 1.0117733478546143, 1.0054197311401367, 0.9591904282569885, 0.9468449950218201, 0.9369430541992188, 0.9385563135147095, 0.9633584022521973, 0.9572447538375854, 0.9851380586624146, 0.9730597138404846, 0.9853246808052063, 0.9646746516227722, 0.9720308780670166, 0.9819919466972351, 0.9626412987709045, 0.9928867220878601, 1.0313143730163574, 0.9880057573318481, 1.0010216236114502, 0.9959172010421753, 0.9869888424873352, 1.009832739830017, 1.0028589963912964, 1.0084471702575684, 1.0069235563278198, 1.0129865407943726, 1.018562912940979, 1.027042031288147, 1.0154476165771484, 1.031345009803772, 1.0122737884521484, 1.025120735168457, 1.0223314762115479, 1.0265601873397827, 1.0228872299194336, 1.0312907695770264, 1.03231680393219, 1.0342272520065308, 1.0865107774734497, 1.065731167793274, 1.0607727766036987, 1.0472208261489868, 1.0536009073257446, 1.0463435649871826, 1.0631333589553833, 1.0694772005081177, 1.0827966928482056, 1.0795948505401611, 1.0805062055587769, 1.0603046417236328, 1.1156740188598633, 1.0919378995895386, 1.0841413736343384, 1.0881803035736084, 1.117880940437317, 1.0862746238708496, 1.138051152229309, 1.0969723463058472, 1.1888539791107178, 1.131710171699524, 1.2092652320861816, 1.170120358467102, 1.1303932666778564, 1.1413720846176147, 1.1286709308624268, 1.1427621841430664, 1.2000772953033447, 1.170709252357483, 1.1435892581939697, 1.1441001892089844, 1.151370644569397, 1.1575055122375488, 1.1440438032150269, 1.1656368970870972, 1.232552409172058, 1.1718204021453857, 1.228391408920288, 1.24784255027771, 1.2254682779312134], 'val_accuracy': [0.4876033067703247, 0.4876033067703247, 0.4886363744735718, 0.4886363744735718, 0.4886363744735718, 0.4886363744735718, 0.48966941237449646, 0.48966941237449646, 0.48966941237449646, 0.49070248007774353, 0.5010330677032471, 0.5134297609329224, 0.5113636255264282, 0.51962810754776, 0.5320248007774353, 0.5247933864593506, 0.5537189841270447, 0.5847107172012329, 0.6033057570457458, 0.6280992031097412, 0.6756198406219482, 0.6570248007774353, 0.6776859760284424, 0.7241735458374023, 0.7179751992225647, 0.7272727489471436, 0.7241735458374023, 0.7086777091026306, 0.7045454382896423, 0.7231404781341553, 0.7055785059928894, 0.7241735458374023, 0.7262396812438965, 0.7066115736961365, 0.7221074104309082, 0.7272727489471436, 0.7066115736961365, 0.6993801593780518, 0.7252066135406494, 0.7045454382896423, 0.7252066135406494, 0.7241735458374023, 0.7055785059928894, 0.7128099203109741, 0.7004132270812988, 0.7066115736961365, 0.7179751992225647, 0.7252066135406494, 0.7200413346290588, 0.7159090638160706, 0.7148760557174683, 0.7169421315193176, 0.7169421315193176, 0.7169421315193176, 0.7221074104309082, 0.7128099203109741, 0.7086777091026306, 0.7086777091026306, 0.71074378490448, 0.7014462947845459, 0.69111567735672, 0.7076446413993835, 0.7066115736961365, 0.6983470916748047, 0.7055785059928894, 0.7169421315193176, 0.7179751992225647, 0.711776852607727, 0.71074378490448, 0.7159090638160706, 0.7097107172012329, 0.7148760557174683, 0.7190082669258118, 0.7045454382896423, 0.702479362487793, 0.7045454382896423, 0.702479362487793, 0.6983470916748047, 0.7066115736961365, 0.7014462947845459, 0.7086777091026306, 0.7055785059928894, 0.6973140239715576, 0.6983470916748047, 0.7066115736961365, 0.702479362487793, 0.7076446413993835, 0.6849173307418823, 0.702479362487793, 0.7055785059928894, 0.7097107172012329, 0.7097107172012329, 0.711776852607727, 0.6962810158729553, 0.7169421315193176, 0.7045454382896423, 0.6993801593780518, 0.6952479481697083, 0.7055785059928894, 0.692148745059967]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 27ms/step - loss: 0.5106 - accuracy: 0.9124 - val_loss: 2.1826 - val_accuracy: 0.4860\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.4696 - accuracy: 0.9219"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 10ms/step - loss: 0.4802 - accuracy: 0.9262 - val_loss: 2.1644 - val_accuracy: 0.4860\n","Epoch 3/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4737 - accuracy: 0.9286 - val_loss: 2.1728 - val_accuracy: 0.4860\n","Epoch 4/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4637 - accuracy: 0.9305 - val_loss: 2.1636 - val_accuracy: 0.4860\n","Epoch 5/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4667 - accuracy: 0.9321 - val_loss: 2.1744 - val_accuracy: 0.4860\n","Epoch 6/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4580 - accuracy: 0.9397 - val_loss: 2.1748 - val_accuracy: 0.4860\n","Epoch 7/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4499 - accuracy: 0.9405 - val_loss: 2.1790 - val_accuracy: 0.4860\n","Epoch 8/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4491 - accuracy: 0.9405 - val_loss: 2.1368 - val_accuracy: 0.4860\n","Epoch 9/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4508 - accuracy: 0.9413 - val_loss: 2.1001 - val_accuracy: 0.4871\n","Epoch 10/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4489 - accuracy: 0.9445 - val_loss: 2.1915 - val_accuracy: 0.4860\n","Epoch 11/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4436 - accuracy: 0.9483 - val_loss: 2.1419 - val_accuracy: 0.4881\n","Epoch 12/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4437 - accuracy: 0.9399 - val_loss: 2.0140 - val_accuracy: 0.4946\n","Epoch 13/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4424 - accuracy: 0.9423 - val_loss: 1.9751 - val_accuracy: 0.4978\n","Epoch 14/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4380 - accuracy: 0.9467 - val_loss: 1.8110 - val_accuracy: 0.5162\n","Epoch 15/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4386 - accuracy: 0.9464 - val_loss: 1.8407 - val_accuracy: 0.5183\n","Epoch 16/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4286 - accuracy: 0.9529 - val_loss: 1.7519 - val_accuracy: 0.5302\n","Epoch 17/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4286 - accuracy: 0.9480 - val_loss: 1.6897 - val_accuracy: 0.5453\n","Epoch 18/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4256 - accuracy: 0.9515 - val_loss: 1.5521 - val_accuracy: 0.5636\n","Epoch 19/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4266 - accuracy: 0.9537 - val_loss: 1.3420 - val_accuracy: 0.6024\n","Epoch 20/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4280 - accuracy: 0.9510 - val_loss: 1.1935 - val_accuracy: 0.6422\n","Epoch 21/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4204 - accuracy: 0.9550 - val_loss: 1.2145 - val_accuracy: 0.6476\n","Epoch 22/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4197 - accuracy: 0.9558 - val_loss: 1.0928 - val_accuracy: 0.6756\n","Epoch 23/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4201 - accuracy: 0.9547 - val_loss: 1.0055 - val_accuracy: 0.7209\n","Epoch 24/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4174 - accuracy: 0.9550 - val_loss: 0.9606 - val_accuracy: 0.7446\n","Epoch 25/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4112 - accuracy: 0.9601 - val_loss: 0.9214 - val_accuracy: 0.7522\n","Epoch 26/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4115 - accuracy: 0.9601 - val_loss: 0.9905 - val_accuracy: 0.7403\n","Epoch 27/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4104 - accuracy: 0.9609 - val_loss: 0.8781 - val_accuracy: 0.7769\n","Epoch 28/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4130 - accuracy: 0.9561 - val_loss: 0.8582 - val_accuracy: 0.8017\n","Epoch 29/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4193 - accuracy: 0.9588 - val_loss: 0.9055 - val_accuracy: 0.7716\n","Epoch 30/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4138 - accuracy: 0.9574 - val_loss: 0.9357 - val_accuracy: 0.7726\n","Epoch 31/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4079 - accuracy: 0.9604 - val_loss: 0.8889 - val_accuracy: 0.7866\n","Epoch 32/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4024 - accuracy: 0.9623 - val_loss: 0.9228 - val_accuracy: 0.7823\n","Epoch 33/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4069 - accuracy: 0.9617 - val_loss: 0.9142 - val_accuracy: 0.7866\n","Epoch 34/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4082 - accuracy: 0.9599 - val_loss: 0.9690 - val_accuracy: 0.7694\n","Epoch 35/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4058 - accuracy: 0.9599 - val_loss: 0.9224 - val_accuracy: 0.7985\n","Epoch 36/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3977 - accuracy: 0.9655 - val_loss: 0.9759 - val_accuracy: 0.7694\n","Epoch 37/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3953 - accuracy: 0.9639 - val_loss: 0.9266 - val_accuracy: 0.7866\n","Epoch 38/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3966 - accuracy: 0.9644 - val_loss: 0.9588 - val_accuracy: 0.7899\n","Epoch 39/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3989 - accuracy: 0.9679 - val_loss: 0.9563 - val_accuracy: 0.7812\n","Epoch 40/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4063 - accuracy: 0.9566 - val_loss: 0.9446 - val_accuracy: 0.7845\n","Epoch 41/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4047 - accuracy: 0.9539 - val_loss: 0.9516 - val_accuracy: 0.7942\n","Epoch 42/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4194 - accuracy: 0.9499 - val_loss: 0.9734 - val_accuracy: 0.7920\n","Epoch 43/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4022 - accuracy: 0.9604 - val_loss: 0.9424 - val_accuracy: 0.7931\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3902 - accuracy: 0.9655 - val_loss: 0.9513 - val_accuracy: 0.7823\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3907 - accuracy: 0.9639 - val_loss: 0.9572 - val_accuracy: 0.7877\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3810 - accuracy: 0.9723 - val_loss: 1.0235 - val_accuracy: 0.7662\n","Epoch 47/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3818 - accuracy: 0.9698 - val_loss: 0.9738 - val_accuracy: 0.7953\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3787 - accuracy: 0.9717 - val_loss: 0.9588 - val_accuracy: 0.7931\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3832 - accuracy: 0.9671 - val_loss: 1.0455 - val_accuracy: 0.7726\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3827 - accuracy: 0.9682 - val_loss: 1.0769 - val_accuracy: 0.7543\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3889 - accuracy: 0.9644 - val_loss: 1.0173 - val_accuracy: 0.7705\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3782 - accuracy: 0.9698 - val_loss: 0.9713 - val_accuracy: 0.7812\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3750 - accuracy: 0.9714 - val_loss: 0.9646 - val_accuracy: 0.7866\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3761 - accuracy: 0.9731 - val_loss: 0.9864 - val_accuracy: 0.7705\n","Epoch 55/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3725 - accuracy: 0.9728 - val_loss: 0.9992 - val_accuracy: 0.7791\n","Epoch 56/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3742 - accuracy: 0.9706 - val_loss: 0.9742 - val_accuracy: 0.7931\n","Epoch 57/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3698 - accuracy: 0.9744 - val_loss: 1.0054 - val_accuracy: 0.7823\n","Epoch 58/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3713 - accuracy: 0.9760 - val_loss: 1.0457 - val_accuracy: 0.7662\n","Epoch 59/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3715 - accuracy: 0.9712 - val_loss: 0.9840 - val_accuracy: 0.7856\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3651 - accuracy: 0.9760 - val_loss: 1.0028 - val_accuracy: 0.7769\n","Epoch 61/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3676 - accuracy: 0.9755 - val_loss: 1.0243 - val_accuracy: 0.7812\n","Epoch 62/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3629 - accuracy: 0.9776 - val_loss: 0.9847 - val_accuracy: 0.7877\n","Epoch 63/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3622 - accuracy: 0.9763 - val_loss: 1.0156 - val_accuracy: 0.7683\n","Epoch 64/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3621 - accuracy: 0.9747 - val_loss: 0.9970 - val_accuracy: 0.7888\n","Epoch 65/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3649 - accuracy: 0.9747 - val_loss: 1.0168 - val_accuracy: 0.7748\n","Epoch 66/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3588 - accuracy: 0.9763 - val_loss: 0.9980 - val_accuracy: 0.7866\n","Epoch 67/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3603 - accuracy: 0.9760 - val_loss: 0.9972 - val_accuracy: 0.7823\n","Epoch 68/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3647 - accuracy: 0.9701 - val_loss: 1.0984 - val_accuracy: 0.7629\n","Epoch 69/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3619 - accuracy: 0.9739 - val_loss: 1.0237 - val_accuracy: 0.7737\n","Epoch 70/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3668 - accuracy: 0.9731 - val_loss: 1.0554 - val_accuracy: 0.7812\n","Epoch 71/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3591 - accuracy: 0.9749 - val_loss: 1.0682 - val_accuracy: 0.7748\n","Epoch 72/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3559 - accuracy: 0.9793 - val_loss: 1.0110 - val_accuracy: 0.7823\n","Epoch 73/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3548 - accuracy: 0.9768 - val_loss: 1.0064 - val_accuracy: 0.7866\n","Epoch 74/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3528 - accuracy: 0.9811 - val_loss: 1.0660 - val_accuracy: 0.7705\n","Epoch 75/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3593 - accuracy: 0.9793 - val_loss: 1.0385 - val_accuracy: 0.7759\n","Epoch 76/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3594 - accuracy: 0.9731 - val_loss: 1.0520 - val_accuracy: 0.7769\n","Epoch 77/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3593 - accuracy: 0.9747 - val_loss: 1.1436 - val_accuracy: 0.7565\n","Epoch 78/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3506 - accuracy: 0.9793 - val_loss: 1.2443 - val_accuracy: 0.7457\n","Epoch 79/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3656 - accuracy: 0.9720 - val_loss: 1.1018 - val_accuracy: 0.7629\n","Epoch 80/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3580 - accuracy: 0.9779 - val_loss: 1.0858 - val_accuracy: 0.7651\n","Epoch 81/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3522 - accuracy: 0.9793 - val_loss: 1.0454 - val_accuracy: 0.7791\n","Epoch 82/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3450 - accuracy: 0.9803 - val_loss: 1.0426 - val_accuracy: 0.7812\n","Epoch 83/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3483 - accuracy: 0.9801 - val_loss: 1.0794 - val_accuracy: 0.7694\n","Epoch 84/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3509 - accuracy: 0.9798 - val_loss: 1.0734 - val_accuracy: 0.7662\n","Epoch 85/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3434 - accuracy: 0.9814 - val_loss: 1.0523 - val_accuracy: 0.7769\n","Epoch 86/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3473 - accuracy: 0.9763 - val_loss: 1.0743 - val_accuracy: 0.7791\n","Epoch 87/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3403 - accuracy: 0.9814 - val_loss: 1.0832 - val_accuracy: 0.7737\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3412 - accuracy: 0.9811 - val_loss: 1.0869 - val_accuracy: 0.7759\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3395 - accuracy: 0.9817 - val_loss: 1.0882 - val_accuracy: 0.7705\n","Epoch 90/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3399 - accuracy: 0.9809 - val_loss: 1.0975 - val_accuracy: 0.7759\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3425 - accuracy: 0.9803 - val_loss: 1.0867 - val_accuracy: 0.7694\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3392 - accuracy: 0.9784 - val_loss: 1.1250 - val_accuracy: 0.7662\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3354 - accuracy: 0.9811 - val_loss: 1.0915 - val_accuracy: 0.7834\n","Epoch 94/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3354 - accuracy: 0.9825 - val_loss: 1.0866 - val_accuracy: 0.7726\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3343 - accuracy: 0.9820 - val_loss: 1.1062 - val_accuracy: 0.7726\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3367 - accuracy: 0.9811 - val_loss: 1.1219 - val_accuracy: 0.7662\n","Epoch 97/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3340 - accuracy: 0.9811 - val_loss: 1.0805 - val_accuracy: 0.7791\n","Epoch 98/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3341 - accuracy: 0.9820 - val_loss: 1.1950 - val_accuracy: 0.7586\n","Epoch 99/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3323 - accuracy: 0.9830 - val_loss: 1.0973 - val_accuracy: 0.7748\n","Epoch 100/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3290 - accuracy: 0.9849 - val_loss: 1.1015 - val_accuracy: 0.7726\n","{'loss': [0.5106159448623657, 0.48018020391464233, 0.47374483942985535, 0.4637320637702942, 0.4667467176914215, 0.45802733302116394, 0.4498509168624878, 0.44908687472343445, 0.45077767968177795, 0.448904812335968, 0.4435952305793762, 0.4436836838722229, 0.4424149990081787, 0.4380255937576294, 0.43862494826316833, 0.42859458923339844, 0.428552508354187, 0.425636887550354, 0.4265541136264801, 0.42799052596092224, 0.4204031825065613, 0.4196867048740387, 0.4201185405254364, 0.4173625111579895, 0.4111696481704712, 0.41146472096443176, 0.4104376435279846, 0.4129638373851776, 0.4193357229232788, 0.413764625787735, 0.40791627764701843, 0.4024335741996765, 0.4069322347640991, 0.40823894739151, 0.4058496952056885, 0.39770132303237915, 0.3953166902065277, 0.39662596583366394, 0.3989298939704895, 0.40632402896881104, 0.40469667315483093, 0.41936182975769043, 0.40223050117492676, 0.39016035199165344, 0.3906875550746918, 0.38102924823760986, 0.38184940814971924, 0.37870508432388306, 0.3831501305103302, 0.3827137053012848, 0.3888978064060211, 0.3781716823577881, 0.3750493824481964, 0.37605056166648865, 0.37253716588020325, 0.37416014075279236, 0.36978185176849365, 0.37129464745521545, 0.3714686632156372, 0.3651491403579712, 0.36764854192733765, 0.36289745569229126, 0.36222752928733826, 0.36207345128059387, 0.36489930748939514, 0.3587956726551056, 0.36029329895973206, 0.36469897627830505, 0.3619314134120941, 0.3668403625488281, 0.3590676784515381, 0.35586488246917725, 0.3548329770565033, 0.3528016209602356, 0.35931727290153503, 0.3594144582748413, 0.35932135581970215, 0.3505779802799225, 0.36563876271247864, 0.3579762578010559, 0.35223478078842163, 0.34500056505203247, 0.3483451306819916, 0.35090070962905884, 0.34340041875839233, 0.347290962934494, 0.3402569591999054, 0.34122365713119507, 0.33951565623283386, 0.3399140536785126, 0.342454731464386, 0.33918771147727966, 0.33542758226394653, 0.3354043662548065, 0.3343031406402588, 0.3366812467575073, 0.33404192328453064, 0.33407896757125854, 0.3323015570640564, 0.3290494978427887], 'accuracy': [0.912446141242981, 0.9261853694915771, 0.9286099076271057, 0.9304956793785095, 0.9321120977401733, 0.9396551847457886, 0.9404633641242981, 0.9404633641242981, 0.9412715435028076, 0.9445043206214905, 0.9482758641242981, 0.9399245977401733, 0.9423491358757019, 0.946659505367279, 0.9463900923728943, 0.9528555870056152, 0.9480064511299133, 0.951508641242981, 0.9536637663841248, 0.9509698152542114, 0.9550107717514038, 0.9558189511299133, 0.954741358757019, 0.9550107717514038, 0.9601293206214905, 0.9601293206214905, 0.9609375, 0.9560883641242981, 0.9587823152542114, 0.9574353694915771, 0.9603987336158752, 0.962284505367279, 0.9617456793785095, 0.9598599076271057, 0.9598599076271057, 0.9655172228813171, 0.9639008641242981, 0.9644396305084229, 0.9679418206214905, 0.9566271305084229, 0.9539331793785095, 0.9498922228813171, 0.9603987336158752, 0.9655172228813171, 0.9639008641242981, 0.9722521305084229, 0.9698275923728943, 0.9717133641242981, 0.967133641242981, 0.9682112336158752, 0.9644396305084229, 0.9698275923728943, 0.9714439511299133, 0.9730603694915771, 0.9727909564971924, 0.9706357717514038, 0.9744073152542114, 0.9760237336158752, 0.9711745977401733, 0.9760237336158752, 0.9754849076271057, 0.9776400923728943, 0.9762930870056152, 0.9746767282485962, 0.9746767282485962, 0.9762930870056152, 0.9760237336158752, 0.970097005367279, 0.9738685488700867, 0.9730603694915771, 0.974946141242981, 0.9792564511299133, 0.9768319129943848, 0.9811422228813171, 0.9792564511299133, 0.9730603694915771, 0.9746767282485962, 0.9792564511299133, 0.9719827771186829, 0.977909505367279, 0.9792564511299133, 0.9803340435028076, 0.9800646305084229, 0.9797952771186829, 0.9814116358757019, 0.9762930870056152, 0.9814116358757019, 0.9811422228813171, 0.9816810488700867, 0.9808728694915771, 0.9803340435028076, 0.9784482717514038, 0.9811422228813171, 0.9824892282485962, 0.9819504022598267, 0.9811422228813171, 0.9811422228813171, 0.9819504022598267, 0.983027994632721, 0.9849137663841248], 'val_loss': [2.182570457458496, 2.1643898487091064, 2.1727964878082275, 2.1636359691619873, 2.174410820007324, 2.174818277359009, 2.1790030002593994, 2.136817693710327, 2.1000924110412598, 2.1915063858032227, 2.141906261444092, 2.0139951705932617, 1.9751099348068237, 1.8109512329101562, 1.8407464027404785, 1.7519060373306274, 1.689665675163269, 1.5520644187927246, 1.341989278793335, 1.1935112476348877, 1.2144951820373535, 1.092808485031128, 1.0054610967636108, 0.9606077075004578, 0.9213523864746094, 0.9904722571372986, 0.8781261444091797, 0.8581766486167908, 0.9054793119430542, 0.9357037544250488, 0.8889390826225281, 0.9227551221847534, 0.9141733646392822, 0.9689705967903137, 0.9223795533180237, 0.9758541584014893, 0.926575779914856, 0.9587962627410889, 0.9563401937484741, 0.9446081519126892, 0.9515559077262878, 0.9734128713607788, 0.9424297213554382, 0.9513010382652283, 0.9572079181671143, 1.0234936475753784, 0.9738126993179321, 0.9587681889533997, 1.0455371141433716, 1.0769333839416504, 1.0173215866088867, 0.9712598323822021, 0.9646226167678833, 0.9864239692687988, 0.999179482460022, 0.9742445349693298, 1.0053651332855225, 1.045709490776062, 0.9840302467346191, 1.0027657747268677, 1.0242689847946167, 0.9847230315208435, 1.0156315565109253, 0.9969953298568726, 1.0167663097381592, 0.9979833960533142, 0.9972203969955444, 1.0984196662902832, 1.0237081050872803, 1.0553873777389526, 1.0681928396224976, 1.0109654664993286, 1.0063772201538086, 1.0660361051559448, 1.0385016202926636, 1.0520167350769043, 1.143602967262268, 1.244337797164917, 1.1017619371414185, 1.0857961177825928, 1.0454106330871582, 1.0426198244094849, 1.0794312953948975, 1.073377251625061, 1.0523256063461304, 1.0742977857589722, 1.083228588104248, 1.0869295597076416, 1.0881552696228027, 1.0974913835525513, 1.0867407321929932, 1.1250227689743042, 1.0915337800979614, 1.0866334438323975, 1.106238603591919, 1.1219210624694824, 1.0805294513702393, 1.1950489282608032, 1.0973191261291504, 1.1014500856399536], 'val_accuracy': [0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48706895112991333, 0.48599138855934143, 0.4881465435028076, 0.49461206793785095, 0.4978448152542114, 0.5161637663841248, 0.5183189511299133, 0.5301724076271057, 0.545258641242981, 0.5635775923728943, 0.6023706793785095, 0.642241358757019, 0.6476293206214905, 0.6756465435028076, 0.7209051847457886, 0.7446120977401733, 0.7521551847457886, 0.7403017282485962, 0.7769396305084229, 0.8017241358757019, 0.7715517282485962, 0.7726293206214905, 0.7866379022598267, 0.7823275923728943, 0.7866379022598267, 0.7693965435028076, 0.798491358757019, 0.7693965435028076, 0.7866379022598267, 0.7898706793785095, 0.78125, 0.7844827771186829, 0.7941810488700867, 0.7920258641242981, 0.7931034564971924, 0.7823275923728943, 0.787715494632721, 0.7661637663841248, 0.795258641242981, 0.7931034564971924, 0.7726293206214905, 0.7543103694915771, 0.7704741358757019, 0.78125, 0.7866379022598267, 0.7704741358757019, 0.7790948152542114, 0.7931034564971924, 0.7823275923728943, 0.7661637663841248, 0.7855603694915771, 0.7769396305084229, 0.78125, 0.787715494632721, 0.7683189511299133, 0.7887930870056152, 0.774784505367279, 0.7866379022598267, 0.7823275923728943, 0.7629310488700867, 0.7737069129943848, 0.78125, 0.774784505367279, 0.7823275923728943, 0.7866379022598267, 0.7704741358757019, 0.7758620977401733, 0.7769396305084229, 0.756465494632721, 0.7456896305084229, 0.7629310488700867, 0.7650862336158752, 0.7790948152542114, 0.78125, 0.7693965435028076, 0.7661637663841248, 0.7769396305084229, 0.7790948152542114, 0.7737069129943848, 0.7758620977401733, 0.7704741358757019, 0.7758620977401733, 0.7693965435028076, 0.7661637663841248, 0.7834051847457886, 0.7726293206214905, 0.7726293206214905, 0.7661637663841248, 0.7790948152542114, 0.7586206793785095, 0.774784505367279, 0.7726293206214905]}\n","38/38 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 3s 29ms/step - loss: 0.4871 - accuracy: 0.9202 - val_loss: 2.0742 - val_accuracy: 0.4955\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.5660 - accuracy: 0.8594"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 13ms/step - loss: 0.4840 - accuracy: 0.9270 - val_loss: 2.1496 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4664 - accuracy: 0.9327 - val_loss: 2.0667 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4598 - accuracy: 0.9355 - val_loss: 2.0979 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4550 - accuracy: 0.9386 - val_loss: 2.1054 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4552 - accuracy: 0.9406 - val_loss: 2.1194 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4644 - accuracy: 0.9335 - val_loss: 2.1720 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4585 - accuracy: 0.9406 - val_loss: 2.0736 - val_accuracy: 0.4955\n","Epoch 9/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4462 - accuracy: 0.9437 - val_loss: 2.0972 - val_accuracy: 0.4955\n","Epoch 10/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4449 - accuracy: 0.9460 - val_loss: 2.0702 - val_accuracy: 0.4966\n","Epoch 11/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4377 - accuracy: 0.9488 - val_loss: 2.0620 - val_accuracy: 0.4977\n","Epoch 12/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4370 - accuracy: 0.9510 - val_loss: 2.0409 - val_accuracy: 0.4977\n","Epoch 13/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4389 - accuracy: 0.9508 - val_loss: 1.9807 - val_accuracy: 0.5045\n","Epoch 14/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4348 - accuracy: 0.9468 - val_loss: 1.8374 - val_accuracy: 0.5124\n","Epoch 15/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4299 - accuracy: 0.9561 - val_loss: 1.7532 - val_accuracy: 0.5170\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4296 - accuracy: 0.9542 - val_loss: 1.7783 - val_accuracy: 0.5215\n","Epoch 17/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4330 - accuracy: 0.9499 - val_loss: 1.7674 - val_accuracy: 0.5441\n","Epoch 18/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4348 - accuracy: 0.9491 - val_loss: 1.5690 - val_accuracy: 0.5577\n","Epoch 19/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4253 - accuracy: 0.9556 - val_loss: 1.4574 - val_accuracy: 0.5747\n","Epoch 20/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4214 - accuracy: 0.9593 - val_loss: 1.2891 - val_accuracy: 0.6324\n","Epoch 21/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.4214 - accuracy: 0.9553 - val_loss: 1.0404 - val_accuracy: 0.6810\n","Epoch 22/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4285 - accuracy: 0.9505 - val_loss: 1.2934 - val_accuracy: 0.6346\n","Epoch 23/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.4325 - accuracy: 0.9493 - val_loss: 1.0341 - val_accuracy: 0.7115\n","Epoch 24/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4354 - accuracy: 0.9477 - val_loss: 1.0199 - val_accuracy: 0.7296\n","Epoch 25/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4161 - accuracy: 0.9604 - val_loss: 0.9982 - val_accuracy: 0.7308\n","Epoch 26/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4143 - accuracy: 0.9590 - val_loss: 0.9474 - val_accuracy: 0.7568\n","Epoch 27/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.4082 - accuracy: 0.9638 - val_loss: 0.8654 - val_accuracy: 0.7738\n","Epoch 28/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.4145 - accuracy: 0.9547 - val_loss: 0.8421 - val_accuracy: 0.7907\n","Epoch 29/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4129 - accuracy: 0.9550 - val_loss: 0.8968 - val_accuracy: 0.7783\n","Epoch 30/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4085 - accuracy: 0.9626 - val_loss: 0.8918 - val_accuracy: 0.7873\n","Epoch 31/100\n","28/28 [==============================] - 1s 37ms/step - loss: 0.4018 - accuracy: 0.9675 - val_loss: 0.8981 - val_accuracy: 0.7839\n","Epoch 32/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4023 - accuracy: 0.9649 - val_loss: 0.8903 - val_accuracy: 0.7839\n","Epoch 33/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4045 - accuracy: 0.9626 - val_loss: 0.8716 - val_accuracy: 0.7930\n","Epoch 34/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3985 - accuracy: 0.9635 - val_loss: 0.8733 - val_accuracy: 0.7919\n","Epoch 35/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3971 - accuracy: 0.9663 - val_loss: 0.9006 - val_accuracy: 0.7862\n","Epoch 36/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3985 - accuracy: 0.9641 - val_loss: 0.8999 - val_accuracy: 0.7896\n","Epoch 37/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4021 - accuracy: 0.9610 - val_loss: 0.8883 - val_accuracy: 0.7873\n","Epoch 38/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3919 - accuracy: 0.9692 - val_loss: 0.9094 - val_accuracy: 0.7839\n","Epoch 39/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4023 - accuracy: 0.9607 - val_loss: 0.9630 - val_accuracy: 0.7704\n","Epoch 40/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4321 - accuracy: 0.9482 - val_loss: 1.0696 - val_accuracy: 0.7500\n","Epoch 41/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4373 - accuracy: 0.9440 - val_loss: 0.9680 - val_accuracy: 0.7726\n","Epoch 42/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4055 - accuracy: 0.9643 - val_loss: 0.9418 - val_accuracy: 0.7817\n","Epoch 43/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3924 - accuracy: 0.9686 - val_loss: 0.9546 - val_accuracy: 0.7749\n","Epoch 44/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3927 - accuracy: 0.9677 - val_loss: 0.9489 - val_accuracy: 0.7715\n","Epoch 45/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3864 - accuracy: 0.9700 - val_loss: 0.9150 - val_accuracy: 0.7873\n","Epoch 46/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3838 - accuracy: 0.9711 - val_loss: 0.9151 - val_accuracy: 0.7896\n","Epoch 47/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3821 - accuracy: 0.9723 - val_loss: 0.9513 - val_accuracy: 0.7805\n","Epoch 48/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3806 - accuracy: 0.9728 - val_loss: 0.9672 - val_accuracy: 0.7771\n","Epoch 49/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3854 - accuracy: 0.9692 - val_loss: 0.9201 - val_accuracy: 0.7896\n","Epoch 50/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3794 - accuracy: 0.9728 - val_loss: 0.9271 - val_accuracy: 0.7851\n","Epoch 51/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3768 - accuracy: 0.9743 - val_loss: 0.9304 - val_accuracy: 0.7794\n","Epoch 52/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3769 - accuracy: 0.9743 - val_loss: 0.9376 - val_accuracy: 0.7817\n","Epoch 53/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3759 - accuracy: 0.9748 - val_loss: 0.9539 - val_accuracy: 0.7749\n","Epoch 54/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3834 - accuracy: 0.9672 - val_loss: 1.0252 - val_accuracy: 0.7636\n","Epoch 55/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3905 - accuracy: 0.9638 - val_loss: 0.9434 - val_accuracy: 0.7851\n","Epoch 56/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3768 - accuracy: 0.9700 - val_loss: 0.9460 - val_accuracy: 0.7805\n","Epoch 57/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3719 - accuracy: 0.9757 - val_loss: 0.9540 - val_accuracy: 0.7862\n","Epoch 58/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3725 - accuracy: 0.9748 - val_loss: 0.9449 - val_accuracy: 0.7851\n","Epoch 59/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3724 - accuracy: 0.9726 - val_loss: 0.9487 - val_accuracy: 0.7828\n","Epoch 60/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3749 - accuracy: 0.9726 - val_loss: 0.9624 - val_accuracy: 0.7805\n","Epoch 61/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3715 - accuracy: 0.9743 - val_loss: 0.9908 - val_accuracy: 0.7681\n","Epoch 62/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3679 - accuracy: 0.9762 - val_loss: 0.9565 - val_accuracy: 0.7794\n","Epoch 63/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3665 - accuracy: 0.9740 - val_loss: 0.9600 - val_accuracy: 0.7839\n","Epoch 64/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3627 - accuracy: 0.9793 - val_loss: 0.9838 - val_accuracy: 0.7805\n","Epoch 65/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3664 - accuracy: 0.9779 - val_loss: 0.9686 - val_accuracy: 0.7738\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3622 - accuracy: 0.9802 - val_loss: 0.9703 - val_accuracy: 0.7805\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3650 - accuracy: 0.9743 - val_loss: 0.9649 - val_accuracy: 0.7805\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3638 - accuracy: 0.9765 - val_loss: 1.0217 - val_accuracy: 0.7738\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3639 - accuracy: 0.9723 - val_loss: 0.9947 - val_accuracy: 0.7783\n","Epoch 70/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3642 - accuracy: 0.9728 - val_loss: 0.9975 - val_accuracy: 0.7590\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3637 - accuracy: 0.9768 - val_loss: 1.0296 - val_accuracy: 0.7692\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3606 - accuracy: 0.9754 - val_loss: 0.9976 - val_accuracy: 0.7783\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3637 - accuracy: 0.9745 - val_loss: 0.9862 - val_accuracy: 0.7794\n","Epoch 74/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3593 - accuracy: 0.9740 - val_loss: 0.9950 - val_accuracy: 0.7794\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3545 - accuracy: 0.9805 - val_loss: 1.0118 - val_accuracy: 0.7760\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3581 - accuracy: 0.9785 - val_loss: 1.0285 - val_accuracy: 0.7670\n","Epoch 77/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3535 - accuracy: 0.9774 - val_loss: 0.9954 - val_accuracy: 0.7715\n","Epoch 78/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3520 - accuracy: 0.9813 - val_loss: 0.9891 - val_accuracy: 0.7726\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3560 - accuracy: 0.9754 - val_loss: 0.9990 - val_accuracy: 0.7760\n","Epoch 80/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3525 - accuracy: 0.9793 - val_loss: 1.0214 - val_accuracy: 0.7704\n","Epoch 81/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3513 - accuracy: 0.9793 - val_loss: 1.0025 - val_accuracy: 0.7760\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3484 - accuracy: 0.9791 - val_loss: 1.0240 - val_accuracy: 0.7749\n","Epoch 83/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3448 - accuracy: 0.9816 - val_loss: 1.0070 - val_accuracy: 0.7771\n","Epoch 84/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3483 - accuracy: 0.9802 - val_loss: 1.0708 - val_accuracy: 0.7647\n","Epoch 85/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3481 - accuracy: 0.9791 - val_loss: 1.0254 - val_accuracy: 0.7749\n","Epoch 86/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3473 - accuracy: 0.9805 - val_loss: 1.0265 - val_accuracy: 0.7692\n","Epoch 87/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3520 - accuracy: 0.9762 - val_loss: 1.0894 - val_accuracy: 0.7602\n","Epoch 88/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3501 - accuracy: 0.9776 - val_loss: 1.0534 - val_accuracy: 0.7738\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3459 - accuracy: 0.9799 - val_loss: 1.0259 - val_accuracy: 0.7726\n","Epoch 90/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3477 - accuracy: 0.9765 - val_loss: 1.0593 - val_accuracy: 0.7726\n","Epoch 91/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3405 - accuracy: 0.9836 - val_loss: 1.0544 - val_accuracy: 0.7760\n","Epoch 92/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3435 - accuracy: 0.9816 - val_loss: 1.0400 - val_accuracy: 0.7726\n","Epoch 93/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3360 - accuracy: 0.9850 - val_loss: 1.0345 - val_accuracy: 0.7692\n","Epoch 94/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3378 - accuracy: 0.9827 - val_loss: 1.0405 - val_accuracy: 0.7636\n","Epoch 95/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3360 - accuracy: 0.9839 - val_loss: 1.0491 - val_accuracy: 0.7771\n","Epoch 96/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3335 - accuracy: 0.9859 - val_loss: 1.0540 - val_accuracy: 0.7670\n","Epoch 97/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3350 - accuracy: 0.9833 - val_loss: 1.0503 - val_accuracy: 0.7613\n","Epoch 98/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3352 - accuracy: 0.9825 - val_loss: 1.0570 - val_accuracy: 0.7670\n","Epoch 99/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3350 - accuracy: 0.9847 - val_loss: 1.1308 - val_accuracy: 0.7658\n","Epoch 100/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3437 - accuracy: 0.9805 - val_loss: 1.1267 - val_accuracy: 0.7579\n","{'loss': [0.48712804913520813, 0.4840201139450073, 0.46637651324272156, 0.4597581923007965, 0.455022931098938, 0.45520836114883423, 0.46438413858413696, 0.45846027135849, 0.4462321996688843, 0.44492435455322266, 0.4376596510410309, 0.43698015809059143, 0.43891641497612, 0.43484556674957275, 0.42993128299713135, 0.42962661385536194, 0.43298396468162537, 0.43475496768951416, 0.4253365397453308, 0.4213919937610626, 0.4214426279067993, 0.42854955792427063, 0.4324786961078644, 0.43535712361335754, 0.41605162620544434, 0.4142521917819977, 0.408245325088501, 0.4145340919494629, 0.41290149092674255, 0.40847551822662354, 0.4017565846443176, 0.4023367762565613, 0.40449196100234985, 0.39850640296936035, 0.39706751704216003, 0.3985404670238495, 0.40206047892570496, 0.3918936550617218, 0.40225034952163696, 0.43206360936164856, 0.4372870922088623, 0.40549859404563904, 0.39235562086105347, 0.39273801445961, 0.38640096783638, 0.38377314805984497, 0.3821152448654175, 0.3805643916130066, 0.3853849172592163, 0.3794304132461548, 0.37675055861473083, 0.3769371211528778, 0.37593260407447815, 0.3833683431148529, 0.3904896676540375, 0.3768140375614166, 0.3719208538532257, 0.3725093603134155, 0.37238946557044983, 0.3749191462993622, 0.3715358078479767, 0.36786022782325745, 0.36653104424476624, 0.36272260546684265, 0.3663897216320038, 0.36217260360717773, 0.36498457193374634, 0.3638019561767578, 0.3639196753501892, 0.36418676376342773, 0.3637142777442932, 0.36058497428894043, 0.36371171474456787, 0.3593076467514038, 0.3544623851776123, 0.3580704927444458, 0.35352903604507446, 0.35198140144348145, 0.3559952974319458, 0.3524508476257324, 0.3512883484363556, 0.3483637273311615, 0.3447639048099518, 0.34833160042762756, 0.3481234610080719, 0.34733325242996216, 0.3519788682460785, 0.35009607672691345, 0.345940500497818, 0.347719669342041, 0.34051498770713806, 0.3434722423553467, 0.3359682857990265, 0.3377668559551239, 0.335951566696167, 0.33347493410110474, 0.335043340921402, 0.33521243929862976, 0.3349866569042206, 0.3437040448188782], 'accuracy': [0.9202037453651428, 0.9269949197769165, 0.9326542019844055, 0.9354838728904724, 0.9385964870452881, 0.9405772686004639, 0.9335030913352966, 0.9405772686004639, 0.9436898827552795, 0.9459536075592041, 0.9487832188606262, 0.9510469436645508, 0.950764000415802, 0.9468024969100952, 0.9561403393745422, 0.9541596174240112, 0.9499151110649109, 0.9490662217140198, 0.9555743932723999, 0.9592529535293579, 0.9552914500236511, 0.9504810571670532, 0.9493491649627686, 0.9476513862609863, 0.9603848457336426, 0.9589700102806091, 0.963780403137207, 0.9547255039215088, 0.9550085067749023, 0.9626485705375671, 0.967458963394165, 0.9649122953414917, 0.9626485705375671, 0.9634974598884583, 0.9663271307945251, 0.9640634059906006, 0.9609507918357849, 0.9691567420959473, 0.9606677889823914, 0.9482173323631287, 0.9439728260040283, 0.9643463492393494, 0.9685908555984497, 0.9677419066429138, 0.9700056314468384, 0.971137523651123, 0.9722693562507629, 0.9728353023529053, 0.9691567420959473, 0.9728353023529053, 0.9742501378059387, 0.9742501378059387, 0.974816083908081, 0.9671760201454163, 0.963780403137207, 0.9700056314468384, 0.9756649732589722, 0.974816083908081, 0.9725523591041565, 0.9725523591041565, 0.9742501378059387, 0.9762309193611145, 0.9739671945571899, 0.9793435335159302, 0.9779286980628967, 0.9801924228668213, 0.9742501378059387, 0.9765138626098633, 0.9722693562507629, 0.9728353023529053, 0.9767968058586121, 0.9753820300102234, 0.9745330810546875, 0.9739671945571899, 0.9804753661155701, 0.9784946441650391, 0.9773627519607544, 0.9813242554664612, 0.9753820300102234, 0.9793435335159302, 0.9793435335159302, 0.9790605306625366, 0.9816072583198547, 0.9801924228668213, 0.9790605306625366, 0.9804753661155701, 0.9762309193611145, 0.977645754814148, 0.9799094796180725, 0.9765138626098633, 0.9835879802703857, 0.9816072583198547, 0.9850028157234192, 0.9827390909194946, 0.9838709831237793, 0.9858517050743103, 0.983305037021637, 0.9824561476707458, 0.9847198724746704, 0.9804753661155701], 'val_loss': [2.074221611022949, 2.149622917175293, 2.0667216777801514, 2.0979106426239014, 2.1053998470306396, 2.1193900108337402, 2.1720077991485596, 2.073603391647339, 2.09716534614563, 2.070160388946533, 2.062009811401367, 2.0409183502197266, 1.9806703329086304, 1.8374483585357666, 1.7532055377960205, 1.7782564163208008, 1.7674164772033691, 1.5689691305160522, 1.4573808908462524, 1.289055585861206, 1.0404175519943237, 1.2934374809265137, 1.0340731143951416, 1.0199260711669922, 0.9982025027275085, 0.9474106431007385, 0.8653533458709717, 0.8420614004135132, 0.8968135714530945, 0.8918165564537048, 0.8980987668037415, 0.8903219699859619, 0.871577799320221, 0.8732710480690002, 0.900634229183197, 0.899895966053009, 0.88825523853302, 0.9094124436378479, 0.9630283117294312, 1.0695816278457642, 0.9679972529411316, 0.9417803883552551, 0.9545546174049377, 0.9489098191261292, 0.9150457382202148, 0.9151246547698975, 0.9512801170349121, 0.96723473072052, 0.9201451539993286, 0.927141547203064, 0.930385172367096, 0.9375926852226257, 0.9538804888725281, 1.0252184867858887, 0.9434181451797485, 0.9460150003433228, 0.9539883136749268, 0.9449376463890076, 0.9486646056175232, 0.9623693227767944, 0.990778923034668, 0.9564513564109802, 0.959980845451355, 0.9838014245033264, 0.9686021208763123, 0.9702929854393005, 0.9648677110671997, 1.0216565132141113, 0.9947375655174255, 0.997536301612854, 1.029632329940796, 0.9975586533546448, 0.9862088561058044, 0.9949909448623657, 1.0117782354354858, 1.0284979343414307, 0.9953901171684265, 0.9891225695610046, 0.9990428686141968, 1.021406888961792, 1.0025376081466675, 1.0239940881729126, 1.0069628953933716, 1.0707587003707886, 1.0253931283950806, 1.0264681577682495, 1.0893924236297607, 1.0534499883651733, 1.0259404182434082, 1.0592589378356934, 1.0544071197509766, 1.0399553775787354, 1.0345364809036255, 1.0405257940292358, 1.049147367477417, 1.0540062189102173, 1.0503363609313965, 1.0569688081741333, 1.1308053731918335, 1.1266729831695557], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.4977375566959381, 0.4977375566959381, 0.5045248866081238, 0.5124434232711792, 0.516968309879303, 0.5214931964874268, 0.5441176295280457, 0.557692289352417, 0.5746606588363647, 0.6323529481887817, 0.6809954643249512, 0.6346153616905212, 0.7115384340286255, 0.7296379804611206, 0.7307692170143127, 0.7567873597145081, 0.773755669593811, 0.790723979473114, 0.7782805562019348, 0.7873303294181824, 0.7839366793632507, 0.7839366793632507, 0.7929864525794983, 0.7918552160263062, 0.7861990928649902, 0.7895927429199219, 0.7873303294181824, 0.7839366793632507, 0.7703620195388794, 0.75, 0.7726244330406189, 0.7816742062568665, 0.7748869061470032, 0.7714931964874268, 0.7873303294181824, 0.7895927429199219, 0.7805429697036743, 0.7771493196487427, 0.7895927429199219, 0.7850678563117981, 0.779411792755127, 0.7816742062568665, 0.7748869061470032, 0.7635746598243713, 0.7850678563117981, 0.7805429697036743, 0.7861990928649902, 0.7850678563117981, 0.7828054428100586, 0.7805429697036743, 0.7680995464324951, 0.779411792755127, 0.7839366793632507, 0.7805429697036743, 0.773755669593811, 0.7805429697036743, 0.7805429697036743, 0.773755669593811, 0.7782805562019348, 0.7590497732162476, 0.7692307829856873, 0.7782805562019348, 0.779411792755127, 0.779411792755127, 0.7760180830955505, 0.766968309879303, 0.7714931964874268, 0.7726244330406189, 0.7760180830955505, 0.7703620195388794, 0.7760180830955505, 0.7748869061470032, 0.7771493196487427, 0.7647058963775635, 0.7748869061470032, 0.7692307829856873, 0.7601810097694397, 0.773755669593811, 0.7726244330406189, 0.7726244330406189, 0.7760180830955505, 0.7726244330406189, 0.7692307829856873, 0.7635746598243713, 0.7771493196487427, 0.766968309879303, 0.7613122463226318, 0.766968309879303, 0.7658371329307556, 0.7579185366630554]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 4s 27ms/step - loss: 0.5182 - accuracy: 0.9065 - val_loss: 2.1051 - val_accuracy: 0.4876\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.5049 - accuracy: 0.9141"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 11ms/step - loss: 0.4996 - accuracy: 0.9150 - val_loss: 2.1408 - val_accuracy: 0.4876\n","Epoch 3/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4800 - accuracy: 0.9196 - val_loss: 2.1044 - val_accuracy: 0.4886\n","Epoch 4/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4798 - accuracy: 0.9196 - val_loss: 2.1248 - val_accuracy: 0.4886\n","Epoch 5/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4684 - accuracy: 0.9302 - val_loss: 2.1556 - val_accuracy: 0.4886\n","Epoch 6/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4683 - accuracy: 0.9295 - val_loss: 2.1575 - val_accuracy: 0.4886\n","Epoch 7/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4611 - accuracy: 0.9295 - val_loss: 2.1941 - val_accuracy: 0.4886\n","Epoch 8/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4656 - accuracy: 0.9271 - val_loss: 2.1827 - val_accuracy: 0.4897\n","Epoch 9/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4707 - accuracy: 0.9279 - val_loss: 2.0899 - val_accuracy: 0.4928\n","Epoch 10/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4566 - accuracy: 0.9331 - val_loss: 2.1379 - val_accuracy: 0.4907\n","Epoch 11/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4636 - accuracy: 0.9310 - val_loss: 2.1047 - val_accuracy: 0.4948\n","Epoch 12/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4530 - accuracy: 0.9351 - val_loss: 2.0226 - val_accuracy: 0.5031\n","Epoch 13/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4469 - accuracy: 0.9395 - val_loss: 1.9859 - val_accuracy: 0.5083\n","Epoch 14/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4446 - accuracy: 0.9452 - val_loss: 1.9837 - val_accuracy: 0.5093\n","Epoch 15/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4562 - accuracy: 0.9339 - val_loss: 1.7391 - val_accuracy: 0.5227\n","Epoch 16/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4413 - accuracy: 0.9413 - val_loss: 1.7399 - val_accuracy: 0.5341\n","Epoch 17/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4462 - accuracy: 0.9367 - val_loss: 1.9226 - val_accuracy: 0.5269\n","Epoch 18/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4534 - accuracy: 0.9339 - val_loss: 1.5667 - val_accuracy: 0.5671\n","Epoch 19/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4409 - accuracy: 0.9421 - val_loss: 1.4176 - val_accuracy: 0.5888\n","Epoch 20/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4354 - accuracy: 0.9486 - val_loss: 1.1085 - val_accuracy: 0.6570\n","Epoch 21/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4330 - accuracy: 0.9475 - val_loss: 1.1385 - val_accuracy: 0.6632\n","Epoch 22/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4331 - accuracy: 0.9470 - val_loss: 0.9981 - val_accuracy: 0.7180\n","Epoch 23/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4289 - accuracy: 0.9509 - val_loss: 0.9711 - val_accuracy: 0.7376\n","Epoch 24/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4280 - accuracy: 0.9509 - val_loss: 1.1471 - val_accuracy: 0.6849\n","Epoch 25/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4338 - accuracy: 0.9460 - val_loss: 0.9822 - val_accuracy: 0.7469\n","Epoch 26/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4242 - accuracy: 0.9522 - val_loss: 0.9591 - val_accuracy: 0.7500\n","Epoch 27/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4199 - accuracy: 0.9561 - val_loss: 0.9198 - val_accuracy: 0.7696\n","Epoch 28/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4213 - accuracy: 0.9514 - val_loss: 0.9888 - val_accuracy: 0.7531\n","Epoch 29/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4238 - accuracy: 0.9514 - val_loss: 0.9233 - val_accuracy: 0.7593\n","Epoch 30/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4206 - accuracy: 0.9545 - val_loss: 0.9349 - val_accuracy: 0.7717\n","Epoch 31/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4185 - accuracy: 0.9540 - val_loss: 0.9610 - val_accuracy: 0.7645\n","Epoch 32/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4141 - accuracy: 0.9543 - val_loss: 0.9521 - val_accuracy: 0.7717\n","Epoch 33/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4213 - accuracy: 0.9532 - val_loss: 0.9775 - val_accuracy: 0.7624\n","Epoch 34/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4129 - accuracy: 0.9579 - val_loss: 0.9709 - val_accuracy: 0.7583\n","Epoch 35/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4103 - accuracy: 0.9587 - val_loss: 0.9836 - val_accuracy: 0.7645\n","Epoch 36/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4142 - accuracy: 0.9568 - val_loss: 1.0064 - val_accuracy: 0.7500\n","Epoch 37/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4117 - accuracy: 0.9514 - val_loss: 0.9736 - val_accuracy: 0.7614\n","Epoch 38/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4091 - accuracy: 0.9553 - val_loss: 0.9780 - val_accuracy: 0.7572\n","Epoch 39/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4029 - accuracy: 0.9633 - val_loss: 0.9688 - val_accuracy: 0.7645\n","Epoch 40/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4028 - accuracy: 0.9571 - val_loss: 1.0264 - val_accuracy: 0.7459\n","Epoch 41/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4034 - accuracy: 0.9592 - val_loss: 1.0094 - val_accuracy: 0.7634\n","Epoch 42/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4012 - accuracy: 0.9602 - val_loss: 0.9955 - val_accuracy: 0.7583\n","Epoch 43/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4034 - accuracy: 0.9581 - val_loss: 0.9913 - val_accuracy: 0.7583\n","Epoch 44/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4048 - accuracy: 0.9566 - val_loss: 1.0119 - val_accuracy: 0.7500\n","Epoch 45/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3996 - accuracy: 0.9589 - val_loss: 1.0022 - val_accuracy: 0.7510\n","Epoch 46/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3959 - accuracy: 0.9638 - val_loss: 0.9904 - val_accuracy: 0.7562\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3962 - accuracy: 0.9597 - val_loss: 1.0114 - val_accuracy: 0.7583\n","Epoch 48/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3944 - accuracy: 0.9623 - val_loss: 0.9930 - val_accuracy: 0.7634\n","Epoch 49/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3960 - accuracy: 0.9605 - val_loss: 1.0601 - val_accuracy: 0.7521\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3966 - accuracy: 0.9610 - val_loss: 1.0054 - val_accuracy: 0.7541\n","Epoch 51/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3944 - accuracy: 0.9628 - val_loss: 1.0016 - val_accuracy: 0.7562\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4188 - accuracy: 0.9512 - val_loss: 1.1727 - val_accuracy: 0.7262\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4228 - accuracy: 0.9434 - val_loss: 1.0486 - val_accuracy: 0.7572\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3929 - accuracy: 0.9636 - val_loss: 1.0247 - val_accuracy: 0.7614\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3904 - accuracy: 0.9636 - val_loss: 1.0647 - val_accuracy: 0.7521\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3854 - accuracy: 0.9649 - val_loss: 1.0208 - val_accuracy: 0.7541\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3835 - accuracy: 0.9664 - val_loss: 1.0320 - val_accuracy: 0.7572\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3819 - accuracy: 0.9656 - val_loss: 1.0769 - val_accuracy: 0.7469\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3841 - accuracy: 0.9641 - val_loss: 1.0869 - val_accuracy: 0.7438\n","Epoch 60/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4081 - accuracy: 0.9519 - val_loss: 1.0699 - val_accuracy: 0.7552\n","Epoch 61/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3900 - accuracy: 0.9623 - val_loss: 1.1234 - val_accuracy: 0.7459\n","Epoch 62/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3898 - accuracy: 0.9610 - val_loss: 1.0689 - val_accuracy: 0.7459\n","Epoch 63/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3775 - accuracy: 0.9695 - val_loss: 1.0642 - val_accuracy: 0.7541\n","Epoch 64/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3764 - accuracy: 0.9693 - val_loss: 1.0346 - val_accuracy: 0.7572\n","Epoch 65/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3722 - accuracy: 0.9703 - val_loss: 1.0549 - val_accuracy: 0.7552\n","Epoch 66/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3762 - accuracy: 0.9654 - val_loss: 1.0753 - val_accuracy: 0.7500\n","Epoch 67/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3722 - accuracy: 0.9687 - val_loss: 1.0750 - val_accuracy: 0.7490\n","Epoch 68/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3697 - accuracy: 0.9724 - val_loss: 1.0587 - val_accuracy: 0.7521\n","Epoch 69/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3696 - accuracy: 0.9708 - val_loss: 1.0477 - val_accuracy: 0.7500\n","Epoch 70/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3738 - accuracy: 0.9685 - val_loss: 1.0774 - val_accuracy: 0.7459\n","Epoch 71/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3679 - accuracy: 0.9700 - val_loss: 1.0706 - val_accuracy: 0.7510\n","Epoch 72/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3718 - accuracy: 0.9674 - val_loss: 1.0783 - val_accuracy: 0.7531\n","Epoch 73/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3681 - accuracy: 0.9700 - val_loss: 1.0718 - val_accuracy: 0.7521\n","Epoch 74/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3661 - accuracy: 0.9687 - val_loss: 1.1013 - val_accuracy: 0.7479\n","Epoch 75/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3679 - accuracy: 0.9700 - val_loss: 1.0871 - val_accuracy: 0.7438\n","Epoch 76/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3639 - accuracy: 0.9716 - val_loss: 1.0835 - val_accuracy: 0.7510\n","Epoch 77/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3654 - accuracy: 0.9718 - val_loss: 1.0820 - val_accuracy: 0.7469\n","Epoch 78/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3610 - accuracy: 0.9755 - val_loss: 1.0957 - val_accuracy: 0.7490\n","Epoch 79/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3595 - accuracy: 0.9716 - val_loss: 1.1368 - val_accuracy: 0.7417\n","Epoch 80/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3620 - accuracy: 0.9718 - val_loss: 1.1745 - val_accuracy: 0.7417\n","Epoch 81/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3621 - accuracy: 0.9713 - val_loss: 1.1697 - val_accuracy: 0.7521\n","Epoch 82/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3576 - accuracy: 0.9729 - val_loss: 1.0913 - val_accuracy: 0.7541\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3559 - accuracy: 0.9739 - val_loss: 1.1306 - val_accuracy: 0.7448\n","Epoch 84/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3576 - accuracy: 0.9724 - val_loss: 1.0832 - val_accuracy: 0.7469\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3570 - accuracy: 0.9739 - val_loss: 1.1017 - val_accuracy: 0.7417\n","Epoch 86/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3685 - accuracy: 0.9669 - val_loss: 1.1139 - val_accuracy: 0.7510\n","Epoch 87/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.3577 - accuracy: 0.9711 - val_loss: 1.1100 - val_accuracy: 0.7438\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3566 - accuracy: 0.9698 - val_loss: 1.1725 - val_accuracy: 0.7469\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3578 - accuracy: 0.9739 - val_loss: 1.1514 - val_accuracy: 0.7345\n","Epoch 90/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3595 - accuracy: 0.9711 - val_loss: 1.2669 - val_accuracy: 0.7262\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4231 - accuracy: 0.9442 - val_loss: 1.2213 - val_accuracy: 0.7438\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3623 - accuracy: 0.9682 - val_loss: 1.1887 - val_accuracy: 0.7366\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3532 - accuracy: 0.9742 - val_loss: 1.2305 - val_accuracy: 0.7355\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3531 - accuracy: 0.9739 - val_loss: 1.1873 - val_accuracy: 0.7366\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3571 - accuracy: 0.9731 - val_loss: 1.2010 - val_accuracy: 0.7345\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3481 - accuracy: 0.9744 - val_loss: 1.1660 - val_accuracy: 0.7366\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3460 - accuracy: 0.9770 - val_loss: 1.1650 - val_accuracy: 0.7521\n","Epoch 98/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3489 - accuracy: 0.9775 - val_loss: 1.1793 - val_accuracy: 0.7314\n","Epoch 99/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3469 - accuracy: 0.9755 - val_loss: 1.1636 - val_accuracy: 0.7314\n","Epoch 100/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3497 - accuracy: 0.9747 - val_loss: 1.1449 - val_accuracy: 0.7376\n","{'loss': [0.518155038356781, 0.4996021091938019, 0.4800487756729126, 0.4798019826412201, 0.46841487288475037, 0.46831443905830383, 0.4610646665096283, 0.4656161665916443, 0.4706892967224121, 0.4565696716308594, 0.46359938383102417, 0.4529522657394409, 0.4469016492366791, 0.4446103870868683, 0.4562312960624695, 0.44133061170578003, 0.44616127014160156, 0.4533585011959076, 0.4408978521823883, 0.43535473942756653, 0.4330451488494873, 0.4331479072570801, 0.42893895506858826, 0.42795050144195557, 0.43375739455223083, 0.42423611879348755, 0.4199216663837433, 0.4213311970233917, 0.4238257110118866, 0.42061465978622437, 0.4184955656528473, 0.41413816809654236, 0.42125383019447327, 0.41288602352142334, 0.41027122735977173, 0.414162814617157, 0.4116726517677307, 0.4090910255908966, 0.40292486548423767, 0.40277767181396484, 0.40339505672454834, 0.4012424051761627, 0.40344417095184326, 0.404761403799057, 0.39960435032844543, 0.39585816860198975, 0.3961506187915802, 0.394447386264801, 0.39596906304359436, 0.3965809643268585, 0.39436110854148865, 0.4188413918018341, 0.4227668046951294, 0.3928740918636322, 0.39038363099098206, 0.38540008664131165, 0.38353231549263, 0.38186725974082947, 0.3841087818145752, 0.4080668091773987, 0.3899935781955719, 0.3897849917411804, 0.3775382339954376, 0.37641170620918274, 0.37221288681030273, 0.3762389123439789, 0.372196763753891, 0.36968138813972473, 0.36958372592926025, 0.37379541993141174, 0.3678561747074127, 0.37176328897476196, 0.3680705726146698, 0.3661455810070038, 0.36789169907569885, 0.3639175295829773, 0.3654378056526184, 0.36103421449661255, 0.3595006763935089, 0.3620361387729645, 0.3620610237121582, 0.35759130120277405, 0.35591235756874084, 0.3575555384159088, 0.3570449650287628, 0.36853697896003723, 0.3577134311199188, 0.3566257655620575, 0.35782355070114136, 0.35945188999176025, 0.4231496751308441, 0.3622915744781494, 0.3531622290611267, 0.35307931900024414, 0.3570809066295624, 0.34808048605918884, 0.3459511697292328, 0.34894073009490967, 0.34689274430274963, 0.3497045636177063], 'accuracy': [0.9064599275588989, 0.9149870872497559, 0.9196382164955139, 0.9196382164955139, 0.930232584476471, 0.9294573664665222, 0.9294573664665222, 0.9271317720413208, 0.9279069900512695, 0.933074951171875, 0.9310077428817749, 0.9351420998573303, 0.9395349025726318, 0.9452196359634399, 0.933850109577179, 0.9413436651229858, 0.9366925358772278, 0.933850109577179, 0.9421188831329346, 0.9485788345336914, 0.9475452303886414, 0.947028398513794, 0.950904369354248, 0.950904369354248, 0.9459948539733887, 0.9521963596343994, 0.9560723304748535, 0.9514212012290955, 0.9514212012290955, 0.9545219540596008, 0.9540051817893982, 0.9542635679244995, 0.9532299637794495, 0.9578811526298523, 0.9586563110351562, 0.9568475484848022, 0.9514212012290955, 0.9552971720695496, 0.9633074998855591, 0.9571059346199036, 0.9591731429100037, 0.9602067470550537, 0.9581395387649536, 0.9565891623497009, 0.9589147567749023, 0.9638242721557617, 0.9596899151802063, 0.962273895740509, 0.960465133190155, 0.9609819054603577, 0.9627906680107117, 0.9511628150939941, 0.9434108734130859, 0.9635658860206604, 0.9635658860206604, 0.9648578763008118, 0.9664082527160645, 0.9656330943107605, 0.964082658290863, 0.9519379734992981, 0.962273895740509, 0.9609819054603577, 0.9695090651512146, 0.9692506194114685, 0.9702842235565186, 0.9653746485710144, 0.9687338471412659, 0.9723514318466187, 0.970801055431366, 0.9684754610061646, 0.9700258374214172, 0.9674418568611145, 0.9700258374214172, 0.9687338471412659, 0.9700258374214172, 0.9715762138366699, 0.9718345999717712, 0.975452184677124, 0.9715762138366699, 0.9718345999717712, 0.9713178277015686, 0.9728682041168213, 0.9739018082618713, 0.9723514318466187, 0.9739018082618713, 0.9669250845909119, 0.9710594415664673, 0.9697674512863159, 0.9739018082618713, 0.9710594415664673, 0.9441860318183899, 0.9682170748710632, 0.9741601943969727, 0.9739018082618713, 0.9731265902519226, 0.974418580532074, 0.9770025610923767, 0.9775193929672241, 0.975452184677124, 0.9746770262718201], 'val_loss': [2.105133533477783, 2.1407995223999023, 2.104408025741577, 2.124824047088623, 2.1556336879730225, 2.1575281620025635, 2.194100856781006, 2.182677745819092, 2.0898945331573486, 2.1378612518310547, 2.1047422885894775, 2.0225772857666016, 1.9859017133712769, 1.9836657047271729, 1.7390879392623901, 1.7398625612258911, 1.9226081371307373, 1.5666875839233398, 1.4175654649734497, 1.1085095405578613, 1.1384620666503906, 0.9981124401092529, 0.9711003303527832, 1.1470787525177002, 0.9822142124176025, 0.9591436386108398, 0.9197936058044434, 0.9888392686843872, 0.9233438968658447, 0.934892475605011, 0.9609645009040833, 0.9521427750587463, 0.9775444269180298, 0.9708764553070068, 0.983605146408081, 1.0064183473587036, 0.973606526851654, 0.9779791235923767, 0.9687761068344116, 1.026431918144226, 1.009433388710022, 0.9955183267593384, 0.9912758469581604, 1.0119208097457886, 1.0022356510162354, 0.990421712398529, 1.011365294456482, 0.9930070042610168, 1.0601482391357422, 1.0053917169570923, 1.0015523433685303, 1.1726518869400024, 1.04855215549469, 1.0246833562850952, 1.0646554231643677, 1.020772933959961, 1.0320353507995605, 1.076892375946045, 1.0868953466415405, 1.0699434280395508, 1.1233681440353394, 1.0688563585281372, 1.0641770362854004, 1.0346328020095825, 1.054914951324463, 1.0753259658813477, 1.0750463008880615, 1.058726191520691, 1.0476912260055542, 1.0773512125015259, 1.070592999458313, 1.0783488750457764, 1.0718426704406738, 1.1012667417526245, 1.0871434211730957, 1.083541989326477, 1.082045078277588, 1.0956929922103882, 1.1367805004119873, 1.17448091506958, 1.1696910858154297, 1.0913426876068115, 1.1305738687515259, 1.0831736326217651, 1.101741075515747, 1.113922357559204, 1.1100115776062012, 1.172495722770691, 1.151397705078125, 1.266869068145752, 1.2213293313980103, 1.188690423965454, 1.2304646968841553, 1.1872600317001343, 1.200960636138916, 1.1659646034240723, 1.1650062799453735, 1.1793363094329834, 1.1636146306991577, 1.1449365615844727], 'val_accuracy': [0.4876033067703247, 0.4876033067703247, 0.4886363744735718, 0.4886363744735718, 0.4886363744735718, 0.4886363744735718, 0.4886363744735718, 0.48966941237449646, 0.4927685856819153, 0.49070248007774353, 0.4948347210884094, 0.5030992031097412, 0.5082644820213318, 0.5092975497245789, 0.5227272510528564, 0.5340909361839294, 0.5268595218658447, 0.567148745059967, 0.5888429880142212, 0.6570248007774353, 0.663223147392273, 0.7179751992225647, 0.7376033067703247, 0.6849173307418823, 0.7469007968902588, 0.75, 0.76962810754776, 0.7530992031097412, 0.7592975497245789, 0.7716942429542542, 0.7644628286361694, 0.7716942429542542, 0.7623966932296753, 0.7582644820213318, 0.7644628286361694, 0.75, 0.7613636255264282, 0.7572314143180847, 0.7644628286361694, 0.7458677887916565, 0.7634297609329224, 0.7582644820213318, 0.7582644820213318, 0.75, 0.7510330677032471, 0.7561983466148376, 0.7582644820213318, 0.7634297609329224, 0.7520661354064941, 0.7541322112083435, 0.7561983466148376, 0.7262396812438965, 0.7572314143180847, 0.7613636255264282, 0.7520661354064941, 0.7541322112083435, 0.7572314143180847, 0.7469007968902588, 0.7438016533851624, 0.7551652789115906, 0.7458677887916565, 0.7458677887916565, 0.7541322112083435, 0.7572314143180847, 0.7551652789115906, 0.75, 0.7489669322967529, 0.7520661354064941, 0.75, 0.7458677887916565, 0.7510330677032471, 0.7530992031097412, 0.7520661354064941, 0.7479338645935059, 0.7438016533851624, 0.7510330677032471, 0.7469007968902588, 0.7489669322967529, 0.7417355179786682, 0.7417355179786682, 0.7520661354064941, 0.7541322112083435, 0.7448347210884094, 0.7469007968902588, 0.7417355179786682, 0.7510330677032471, 0.7438016533851624, 0.7469007968902588, 0.7345041036605835, 0.7262396812438965, 0.7438016533851624, 0.7365702390670776, 0.7355371713638306, 0.7365702390670776, 0.7345041036605835, 0.7365702390670776, 0.7520661354064941, 0.7314049601554871, 0.7314049601554871, 0.7376033067703247]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 28ms/step - loss: 0.4201 - accuracy: 0.9413 - val_loss: 2.6394 - val_accuracy: 0.4860\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.4176 - accuracy: 0.9688"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 12ms/step - loss: 0.3928 - accuracy: 0.9558 - val_loss: 2.6091 - val_accuracy: 0.4860\n","Epoch 3/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3752 - accuracy: 0.9652 - val_loss: 2.6542 - val_accuracy: 0.4860\n","Epoch 4/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3744 - accuracy: 0.9639 - val_loss: 2.5989 - val_accuracy: 0.4860\n","Epoch 5/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3712 - accuracy: 0.9639 - val_loss: 2.6349 - val_accuracy: 0.4860\n","Epoch 6/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3652 - accuracy: 0.9688 - val_loss: 2.6953 - val_accuracy: 0.4860\n","Epoch 7/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3729 - accuracy: 0.9636 - val_loss: 2.7144 - val_accuracy: 0.4860\n","Epoch 8/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3762 - accuracy: 0.9631 - val_loss: 2.6764 - val_accuracy: 0.4860\n","Epoch 9/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3605 - accuracy: 0.9712 - val_loss: 2.5703 - val_accuracy: 0.4860\n","Epoch 10/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3574 - accuracy: 0.9731 - val_loss: 2.5589 - val_accuracy: 0.4871\n","Epoch 11/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3522 - accuracy: 0.9744 - val_loss: 2.5067 - val_accuracy: 0.4914\n","Epoch 12/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3525 - accuracy: 0.9752 - val_loss: 2.4950 - val_accuracy: 0.4935\n","Epoch 13/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3502 - accuracy: 0.9766 - val_loss: 2.3716 - val_accuracy: 0.5032\n","Epoch 14/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3502 - accuracy: 0.9760 - val_loss: 2.3867 - val_accuracy: 0.5086\n","Epoch 15/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3513 - accuracy: 0.9714 - val_loss: 2.2827 - val_accuracy: 0.5172\n","Epoch 16/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3532 - accuracy: 0.9728 - val_loss: 2.0792 - val_accuracy: 0.5560\n","Epoch 17/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3557 - accuracy: 0.9712 - val_loss: 2.1066 - val_accuracy: 0.5571\n","Epoch 18/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3613 - accuracy: 0.9725 - val_loss: 1.6960 - val_accuracy: 0.5765\n","Epoch 19/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3537 - accuracy: 0.9725 - val_loss: 1.3830 - val_accuracy: 0.6401\n","Epoch 20/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3504 - accuracy: 0.9749 - val_loss: 1.4234 - val_accuracy: 0.6358\n","Epoch 21/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3472 - accuracy: 0.9758 - val_loss: 1.2987 - val_accuracy: 0.6541\n","Epoch 22/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3443 - accuracy: 0.9774 - val_loss: 1.2176 - val_accuracy: 0.6843\n","Epoch 23/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3458 - accuracy: 0.9774 - val_loss: 0.9972 - val_accuracy: 0.7425\n","Epoch 24/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3386 - accuracy: 0.9801 - val_loss: 1.1011 - val_accuracy: 0.7166\n","Epoch 25/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3404 - accuracy: 0.9798 - val_loss: 0.9463 - val_accuracy: 0.7791\n","Epoch 26/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3351 - accuracy: 0.9822 - val_loss: 0.8111 - val_accuracy: 0.8308\n","Epoch 27/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3369 - accuracy: 0.9793 - val_loss: 0.8327 - val_accuracy: 0.8319\n","Epoch 28/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3348 - accuracy: 0.9795 - val_loss: 0.8342 - val_accuracy: 0.8330\n","Epoch 29/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3342 - accuracy: 0.9809 - val_loss: 0.8880 - val_accuracy: 0.8179\n","Epoch 30/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3344 - accuracy: 0.9809 - val_loss: 0.9227 - val_accuracy: 0.8093\n","Epoch 31/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3332 - accuracy: 0.9809 - val_loss: 0.8698 - val_accuracy: 0.8265\n","Epoch 32/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3343 - accuracy: 0.9809 - val_loss: 0.9180 - val_accuracy: 0.8179\n","Epoch 33/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3324 - accuracy: 0.9830 - val_loss: 0.9552 - val_accuracy: 0.8060\n","Epoch 34/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3316 - accuracy: 0.9822 - val_loss: 0.8960 - val_accuracy: 0.8244\n","Epoch 35/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3324 - accuracy: 0.9787 - val_loss: 0.9135 - val_accuracy: 0.8168\n","Epoch 36/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3274 - accuracy: 0.9830 - val_loss: 0.9619 - val_accuracy: 0.8028\n","Epoch 37/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3248 - accuracy: 0.9844 - val_loss: 0.9129 - val_accuracy: 0.8265\n","Epoch 38/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3243 - accuracy: 0.9838 - val_loss: 0.8920 - val_accuracy: 0.8297\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3245 - accuracy: 0.9825 - val_loss: 0.8993 - val_accuracy: 0.8297\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3233 - accuracy: 0.9836 - val_loss: 0.9103 - val_accuracy: 0.8265\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3218 - accuracy: 0.9849 - val_loss: 0.9091 - val_accuracy: 0.8265\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3230 - accuracy: 0.9825 - val_loss: 0.9067 - val_accuracy: 0.8276\n","Epoch 43/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3213 - accuracy: 0.9841 - val_loss: 1.0284 - val_accuracy: 0.8006\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3224 - accuracy: 0.9838 - val_loss: 0.9365 - val_accuracy: 0.8157\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3206 - accuracy: 0.9841 - val_loss: 0.9184 - val_accuracy: 0.8244\n","Epoch 46/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3165 - accuracy: 0.9863 - val_loss: 0.9366 - val_accuracy: 0.8200\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3221 - accuracy: 0.9844 - val_loss: 0.9196 - val_accuracy: 0.8254\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3151 - accuracy: 0.9873 - val_loss: 0.9365 - val_accuracy: 0.8297\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3165 - accuracy: 0.9857 - val_loss: 0.9333 - val_accuracy: 0.8276\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3137 - accuracy: 0.9873 - val_loss: 0.9393 - val_accuracy: 0.8244\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3134 - accuracy: 0.9860 - val_loss: 0.9807 - val_accuracy: 0.8125\n","Epoch 52/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3191 - accuracy: 0.9833 - val_loss: 0.9345 - val_accuracy: 0.8265\n","Epoch 53/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3145 - accuracy: 0.9865 - val_loss: 0.9422 - val_accuracy: 0.8200\n","Epoch 54/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3156 - accuracy: 0.9860 - val_loss: 0.9937 - val_accuracy: 0.8103\n","Epoch 55/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3156 - accuracy: 0.9838 - val_loss: 0.9675 - val_accuracy: 0.8168\n","Epoch 56/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3125 - accuracy: 0.9857 - val_loss: 0.9545 - val_accuracy: 0.8200\n","Epoch 57/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3151 - accuracy: 0.9849 - val_loss: 1.0488 - val_accuracy: 0.7996\n","Epoch 58/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3139 - accuracy: 0.9868 - val_loss: 0.9587 - val_accuracy: 0.8157\n","Epoch 59/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3084 - accuracy: 0.9876 - val_loss: 0.9572 - val_accuracy: 0.8211\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3127 - accuracy: 0.9846 - val_loss: 0.9721 - val_accuracy: 0.8136\n","Epoch 61/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3111 - accuracy: 0.9852 - val_loss: 1.0602 - val_accuracy: 0.7996\n","Epoch 62/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3101 - accuracy: 0.9863 - val_loss: 1.0923 - val_accuracy: 0.7996\n","Epoch 63/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3199 - accuracy: 0.9809 - val_loss: 1.2174 - val_accuracy: 0.7812\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3529 - accuracy: 0.9749 - val_loss: 1.3752 - val_accuracy: 0.7672\n","Epoch 65/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3636 - accuracy: 0.9717 - val_loss: 1.1560 - val_accuracy: 0.7769\n","Epoch 66/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3278 - accuracy: 0.9838 - val_loss: 0.9637 - val_accuracy: 0.8071\n","Epoch 67/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3074 - accuracy: 0.9868 - val_loss: 0.9683 - val_accuracy: 0.8168\n","Epoch 68/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3114 - accuracy: 0.9825 - val_loss: 1.1893 - val_accuracy: 0.7737\n","Epoch 69/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3097 - accuracy: 0.9849 - val_loss: 0.9793 - val_accuracy: 0.8114\n","Epoch 70/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3027 - accuracy: 0.9881 - val_loss: 0.9851 - val_accuracy: 0.8028\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3071 - accuracy: 0.9857 - val_loss: 1.0165 - val_accuracy: 0.8060\n","Epoch 72/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3034 - accuracy: 0.9868 - val_loss: 1.0264 - val_accuracy: 0.8060\n","Epoch 73/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3022 - accuracy: 0.9890 - val_loss: 0.9795 - val_accuracy: 0.8168\n","Epoch 74/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3011 - accuracy: 0.9879 - val_loss: 1.0165 - val_accuracy: 0.8050\n","Epoch 75/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2983 - accuracy: 0.9903 - val_loss: 0.9737 - val_accuracy: 0.8222\n","Epoch 76/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3008 - accuracy: 0.9890 - val_loss: 0.9800 - val_accuracy: 0.8060\n","Epoch 77/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3009 - accuracy: 0.9881 - val_loss: 1.0433 - val_accuracy: 0.8039\n","Epoch 78/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2970 - accuracy: 0.9906 - val_loss: 1.0060 - val_accuracy: 0.8082\n","Epoch 79/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.9890 - val_loss: 1.0293 - val_accuracy: 0.8017\n","Epoch 80/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3001 - accuracy: 0.9887 - val_loss: 1.0052 - val_accuracy: 0.8114\n","Epoch 81/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2991 - accuracy: 0.9895 - val_loss: 1.0216 - val_accuracy: 0.8039\n","Epoch 82/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3014 - accuracy: 0.9860 - val_loss: 1.2813 - val_accuracy: 0.7575\n","Epoch 83/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3081 - accuracy: 0.9833 - val_loss: 1.0513 - val_accuracy: 0.8082\n","Epoch 84/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2979 - accuracy: 0.9871 - val_loss: 1.0234 - val_accuracy: 0.8147\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2955 - accuracy: 0.9884 - val_loss: 0.9965 - val_accuracy: 0.8103\n","Epoch 86/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2915 - accuracy: 0.9916 - val_loss: 1.0317 - val_accuracy: 0.8114\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3803 - accuracy: 0.9609 - val_loss: 1.1629 - val_accuracy: 0.7866\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3284 - accuracy: 0.9795 - val_loss: 1.1205 - val_accuracy: 0.7899\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3252 - accuracy: 0.9784 - val_loss: 1.0631 - val_accuracy: 0.8039\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3129 - accuracy: 0.9820 - val_loss: 1.1331 - val_accuracy: 0.7694\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3331 - accuracy: 0.9782 - val_loss: 1.1031 - val_accuracy: 0.7920\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2969 - accuracy: 0.9890 - val_loss: 0.9949 - val_accuracy: 0.8103\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2939 - accuracy: 0.9898 - val_loss: 0.9923 - val_accuracy: 0.8017\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2908 - accuracy: 0.9906 - val_loss: 1.0470 - val_accuracy: 0.8017\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2937 - accuracy: 0.9887 - val_loss: 0.9916 - val_accuracy: 0.8136\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2893 - accuracy: 0.9922 - val_loss: 1.0008 - val_accuracy: 0.8093\n","Epoch 97/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2884 - accuracy: 0.9927 - val_loss: 1.0575 - val_accuracy: 0.7974\n","Epoch 98/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2889 - accuracy: 0.9900 - val_loss: 0.9934 - val_accuracy: 0.8028\n","Epoch 99/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2882 - accuracy: 0.9919 - val_loss: 1.0144 - val_accuracy: 0.8093\n","Epoch 100/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2872 - accuracy: 0.9922 - val_loss: 1.0355 - val_accuracy: 0.8017\n","{'loss': [0.42014217376708984, 0.39280009269714355, 0.37523123621940613, 0.37437641620635986, 0.37122565507888794, 0.3652195632457733, 0.37289121747016907, 0.37622958421707153, 0.3605096936225891, 0.35735005140304565, 0.35217180848121643, 0.3525276482105255, 0.35021233558654785, 0.35015276074409485, 0.35127702355384827, 0.3531835675239563, 0.355735182762146, 0.36125272512435913, 0.3536989986896515, 0.350424200296402, 0.34719300270080566, 0.34433409571647644, 0.3457503020763397, 0.3385579586029053, 0.340411514043808, 0.33514827489852905, 0.33685705065727234, 0.3348080515861511, 0.334213525056839, 0.33435842394828796, 0.33318912982940674, 0.3343202769756317, 0.3323606252670288, 0.33164775371551514, 0.33236345648765564, 0.32736408710479736, 0.3248405158519745, 0.3242637515068054, 0.3244875967502594, 0.32330915331840515, 0.32177650928497314, 0.322999507188797, 0.3212939500808716, 0.322429895401001, 0.3205500543117523, 0.3165166676044464, 0.3221113681793213, 0.3150869607925415, 0.31652596592903137, 0.31373509764671326, 0.3134431540966034, 0.31912195682525635, 0.3145143389701843, 0.3155711591243744, 0.3156023323535919, 0.31249523162841797, 0.3150964081287384, 0.3139243721961975, 0.30837512016296387, 0.3127281367778778, 0.31111592054367065, 0.31012001633644104, 0.31987181305885315, 0.3528887629508972, 0.3636317551136017, 0.3278330862522125, 0.30738675594329834, 0.31137633323669434, 0.3096511662006378, 0.3026742935180664, 0.3070899248123169, 0.30335551500320435, 0.3021504878997803, 0.30113983154296875, 0.2982824444770813, 0.300800085067749, 0.30091866850852966, 0.2970379889011383, 0.3006652593612671, 0.3001362681388855, 0.29905396699905396, 0.3013913929462433, 0.30813971161842346, 0.29787370562553406, 0.29548949003219604, 0.2914923429489136, 0.38030198216438293, 0.32840338349342346, 0.325219988822937, 0.3129335045814514, 0.3331182301044464, 0.2969001531600952, 0.29391223192214966, 0.290756493806839, 0.29370689392089844, 0.28927361965179443, 0.28836148977279663, 0.28892284631729126, 0.28817716240882874, 0.2871912717819214], 'accuracy': [0.9412715435028076, 0.9558189511299133, 0.9652478694915771, 0.9639008641242981, 0.9639008641242981, 0.96875, 0.9636314511299133, 0.9630926847457886, 0.9711745977401733, 0.9730603694915771, 0.9744073152542114, 0.975215494632721, 0.9765625, 0.9760237336158752, 0.9714439511299133, 0.9727909564971924, 0.9711745977401733, 0.9725215435028076, 0.9725215435028076, 0.974946141242981, 0.9757543206214905, 0.9773706793785095, 0.9773706793785095, 0.9800646305084229, 0.9797952771186829, 0.9822198152542114, 0.9792564511299133, 0.9795258641242981, 0.9808728694915771, 0.9808728694915771, 0.9808728694915771, 0.9808728694915771, 0.983027994632721, 0.9822198152542114, 0.9787176847457886, 0.983027994632721, 0.984375, 0.9838362336158752, 0.9824892282485962, 0.9835668206214905, 0.9849137663841248, 0.9824892282485962, 0.9841055870056152, 0.9838362336158752, 0.9841055870056152, 0.9862607717514038, 0.984375, 0.9873383641242981, 0.985722005367279, 0.9873383641242981, 0.985991358757019, 0.9832974076271057, 0.9865301847457886, 0.985991358757019, 0.9838362336158752, 0.985722005367279, 0.9849137663841248, 0.9867995977401733, 0.9876077771186829, 0.9846444129943848, 0.9851831793785095, 0.9862607717514038, 0.9808728694915771, 0.974946141242981, 0.9717133641242981, 0.9838362336158752, 0.9867995977401733, 0.9824892282485962, 0.9849137663841248, 0.9881465435028076, 0.985722005367279, 0.9867995977401733, 0.9889547228813171, 0.9878771305084229, 0.9903017282485962, 0.9889547228813171, 0.9881465435028076, 0.990571141242981, 0.9889547228813171, 0.9886853694915771, 0.9894935488700867, 0.985991358757019, 0.9832974076271057, 0.9870689511299133, 0.9884159564971924, 0.9916487336158752, 0.9609375, 0.9795258641242981, 0.9784482717514038, 0.9819504022598267, 0.978178858757019, 0.9889547228813171, 0.9897629022598267, 0.990571141242981, 0.9886853694915771, 0.9921875, 0.9927262663841248, 0.9900323152542114, 0.9919180870056152, 0.9921875], 'val_loss': [2.63942289352417, 2.6091341972351074, 2.6542062759399414, 2.598895311355591, 2.6349332332611084, 2.695300579071045, 2.7144343852996826, 2.676351547241211, 2.5702805519104004, 2.5589184761047363, 2.5067055225372314, 2.495020627975464, 2.371648073196411, 2.386723041534424, 2.2826642990112305, 2.079239845275879, 2.106632947921753, 1.6960314512252808, 1.3830459117889404, 1.423355221748352, 1.2987487316131592, 1.2176483869552612, 0.9971944689750671, 1.1010606288909912, 0.9463102221488953, 0.8111036419868469, 0.8326547145843506, 0.8341883420944214, 0.8880004286766052, 0.9227015376091003, 0.8698201775550842, 0.9180176854133606, 0.955190122127533, 0.8959884643554688, 0.9135204553604126, 0.9618679285049438, 0.9128569960594177, 0.8920333385467529, 0.8992818593978882, 0.9102703332901001, 0.9090595841407776, 0.9067164659500122, 1.0284323692321777, 0.9365454912185669, 0.9183608889579773, 0.9366118907928467, 0.9196391701698303, 0.9365168809890747, 0.9332513213157654, 0.9392806887626648, 0.9807372093200684, 0.9344668388366699, 0.9421965479850769, 0.9936766028404236, 0.9675242304801941, 0.9544790387153625, 1.0487816333770752, 0.9587295055389404, 0.9571713209152222, 0.9721137881278992, 1.0602015256881714, 1.092265248298645, 1.217374563217163, 1.3752188682556152, 1.1559983491897583, 0.963704526424408, 0.9682548642158508, 1.1893450021743774, 0.979349672794342, 0.985088586807251, 1.0164545774459839, 1.0264296531677246, 0.9795379638671875, 1.0164586305618286, 0.9737299084663391, 0.9800227880477905, 1.043311357498169, 1.0060151815414429, 1.0293024778366089, 1.0052456855773926, 1.0216047763824463, 1.2813491821289062, 1.0512877702713013, 1.0233553647994995, 0.9965134263038635, 1.0317078828811646, 1.1629468202590942, 1.120479941368103, 1.0630507469177246, 1.1330702304840088, 1.1030899286270142, 0.994914174079895, 0.9922948479652405, 1.047012448310852, 0.9916322231292725, 1.000796914100647, 1.057520866394043, 0.99341881275177, 1.0144492387771606, 1.0354561805725098], 'val_accuracy': [0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48706895112991333, 0.4913793206214905, 0.49353447556495667, 0.5032327771186829, 0.5086206793785095, 0.517241358757019, 0.556034505367279, 0.5571120977401733, 0.576508641242981, 0.6400862336158752, 0.6357758641242981, 0.6540948152542114, 0.6842672228813171, 0.7424569129943848, 0.7165948152542114, 0.7790948152542114, 0.8308189511299133, 0.8318965435028076, 0.8329741358757019, 0.8178879022598267, 0.8092672228813171, 0.826508641242981, 0.8178879022598267, 0.806034505367279, 0.8243534564971924, 0.8168103694915771, 0.8028017282485962, 0.826508641242981, 0.829741358757019, 0.829741358757019, 0.826508641242981, 0.826508641242981, 0.8275862336158752, 0.8006465435028076, 0.8157327771186829, 0.8243534564971924, 0.8200430870056152, 0.8254310488700867, 0.829741358757019, 0.8275862336158752, 0.8243534564971924, 0.8125, 0.826508641242981, 0.8200430870056152, 0.8103448152542114, 0.8168103694915771, 0.8200430870056152, 0.7995689511299133, 0.8157327771186829, 0.8211206793785095, 0.8135775923728943, 0.7995689511299133, 0.7995689511299133, 0.78125, 0.767241358757019, 0.7769396305084229, 0.8071120977401733, 0.8168103694915771, 0.7737069129943848, 0.8114224076271057, 0.8028017282485962, 0.806034505367279, 0.806034505367279, 0.8168103694915771, 0.8049569129943848, 0.8221982717514038, 0.806034505367279, 0.8038793206214905, 0.8081896305084229, 0.8017241358757019, 0.8114224076271057, 0.8038793206214905, 0.7575430870056152, 0.8081896305084229, 0.8146551847457886, 0.8103448152542114, 0.8114224076271057, 0.7866379022598267, 0.7898706793785095, 0.8038793206214905, 0.7693965435028076, 0.7920258641242981, 0.8103448152542114, 0.8017241358757019, 0.8017241358757019, 0.8135775923728943, 0.8092672228813171, 0.7974137663841248, 0.8028017282485962, 0.8092672228813171, 0.8017241358757019]}\n","38/38 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 3s 30ms/step - loss: 0.3950 - accuracy: 0.9553 - val_loss: 2.5900 - val_accuracy: 0.4955\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.3692 - accuracy: 0.9766"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 13ms/step - loss: 0.3775 - accuracy: 0.9635 - val_loss: 2.5759 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3664 - accuracy: 0.9700 - val_loss: 2.5927 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3688 - accuracy: 0.9677 - val_loss: 2.6003 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3643 - accuracy: 0.9709 - val_loss: 2.5721 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3604 - accuracy: 0.9720 - val_loss: 2.5721 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3592 - accuracy: 0.9723 - val_loss: 2.5840 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3682 - accuracy: 0.9677 - val_loss: 2.5369 - val_accuracy: 0.4966\n","Epoch 9/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3629 - accuracy: 0.9689 - val_loss: 2.4826 - val_accuracy: 0.4955\n","Epoch 10/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3612 - accuracy: 0.9689 - val_loss: 2.5868 - val_accuracy: 0.4966\n","Epoch 11/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3598 - accuracy: 0.9717 - val_loss: 2.4569 - val_accuracy: 0.4977\n","Epoch 12/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3486 - accuracy: 0.9793 - val_loss: 2.4972 - val_accuracy: 0.5011\n","Epoch 13/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3474 - accuracy: 0.9774 - val_loss: 2.3351 - val_accuracy: 0.5079\n","Epoch 14/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3464 - accuracy: 0.9785 - val_loss: 2.1984 - val_accuracy: 0.5113\n","Epoch 15/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3442 - accuracy: 0.9810 - val_loss: 2.1702 - val_accuracy: 0.5170\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3437 - accuracy: 0.9779 - val_loss: 2.1468 - val_accuracy: 0.5317\n","Epoch 17/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3473 - accuracy: 0.9774 - val_loss: 2.0118 - val_accuracy: 0.5373\n","Epoch 18/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3442 - accuracy: 0.9793 - val_loss: 1.7547 - val_accuracy: 0.5735\n","Epoch 19/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3403 - accuracy: 0.9819 - val_loss: 1.5916 - val_accuracy: 0.6086\n","Epoch 20/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3378 - accuracy: 0.9819 - val_loss: 1.3624 - val_accuracy: 0.6448\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3370 - accuracy: 0.9802 - val_loss: 1.3537 - val_accuracy: 0.6505\n","Epoch 22/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3384 - accuracy: 0.9802 - val_loss: 1.1816 - val_accuracy: 0.6867\n","Epoch 23/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3336 - accuracy: 0.9830 - val_loss: 0.8725 - val_accuracy: 0.7726\n","Epoch 24/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3341 - accuracy: 0.9816 - val_loss: 0.9800 - val_accuracy: 0.7489\n","Epoch 25/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3356 - accuracy: 0.9808 - val_loss: 0.8337 - val_accuracy: 0.8020\n","Epoch 26/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3330 - accuracy: 0.9810 - val_loss: 0.8807 - val_accuracy: 0.7828\n","Epoch 27/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3295 - accuracy: 0.9833 - val_loss: 0.7952 - val_accuracy: 0.8100\n","Epoch 28/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3336 - accuracy: 0.9822 - val_loss: 0.8620 - val_accuracy: 0.7986\n","Epoch 29/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3300 - accuracy: 0.9844 - val_loss: 0.8556 - val_accuracy: 0.8167\n","Epoch 30/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3363 - accuracy: 0.9816 - val_loss: 0.9924 - val_accuracy: 0.7828\n","Epoch 31/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4006 - accuracy: 0.9527 - val_loss: 1.2042 - val_accuracy: 0.7681\n","Epoch 32/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4152 - accuracy: 0.9573 - val_loss: 0.9556 - val_accuracy: 0.7907\n","Epoch 33/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3702 - accuracy: 0.9714 - val_loss: 0.8760 - val_accuracy: 0.8156\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3387 - accuracy: 0.9776 - val_loss: 0.8942 - val_accuracy: 0.8077\n","Epoch 35/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3248 - accuracy: 0.9873 - val_loss: 0.8483 - val_accuracy: 0.8247\n","Epoch 36/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3247 - accuracy: 0.9847 - val_loss: 0.8521 - val_accuracy: 0.8190\n","Epoch 37/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3253 - accuracy: 0.9853 - val_loss: 0.8651 - val_accuracy: 0.8224\n","Epoch 38/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3232 - accuracy: 0.9859 - val_loss: 0.8924 - val_accuracy: 0.8043\n","Epoch 39/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3237 - accuracy: 0.9842 - val_loss: 0.8775 - val_accuracy: 0.8066\n","Epoch 40/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3200 - accuracy: 0.9864 - val_loss: 0.8728 - val_accuracy: 0.8224\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3227 - accuracy: 0.9844 - val_loss: 0.8674 - val_accuracy: 0.8088\n","Epoch 42/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3194 - accuracy: 0.9853 - val_loss: 0.8809 - val_accuracy: 0.8054\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3189 - accuracy: 0.9867 - val_loss: 0.8785 - val_accuracy: 0.8077\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3207 - accuracy: 0.9847 - val_loss: 0.8923 - val_accuracy: 0.8020\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3189 - accuracy: 0.9847 - val_loss: 0.8744 - val_accuracy: 0.8122\n","Epoch 46/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3153 - accuracy: 0.9873 - val_loss: 0.8776 - val_accuracy: 0.8167\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3229 - accuracy: 0.9833 - val_loss: 0.9910 - val_accuracy: 0.7896\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3212 - accuracy: 0.9844 - val_loss: 0.8856 - val_accuracy: 0.8088\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3210 - accuracy: 0.9842 - val_loss: 0.8968 - val_accuracy: 0.8122\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3140 - accuracy: 0.9881 - val_loss: 0.8833 - val_accuracy: 0.8167\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3144 - accuracy: 0.9864 - val_loss: 0.8779 - val_accuracy: 0.8224\n","Epoch 52/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3165 - accuracy: 0.9878 - val_loss: 0.8784 - val_accuracy: 0.8156\n","Epoch 53/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3122 - accuracy: 0.9884 - val_loss: 0.8917 - val_accuracy: 0.8167\n","Epoch 54/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3111 - accuracy: 0.9898 - val_loss: 0.8915 - val_accuracy: 0.8190\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3151 - accuracy: 0.9844 - val_loss: 0.8969 - val_accuracy: 0.8156\n","Epoch 56/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3200 - accuracy: 0.9850 - val_loss: 0.9357 - val_accuracy: 0.8100\n","Epoch 57/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3216 - accuracy: 0.9816 - val_loss: 0.9065 - val_accuracy: 0.8054\n","Epoch 58/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3100 - accuracy: 0.9898 - val_loss: 0.8980 - val_accuracy: 0.8133\n","Epoch 59/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3123 - accuracy: 0.9861 - val_loss: 0.9112 - val_accuracy: 0.8111\n","Epoch 60/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3134 - accuracy: 0.9867 - val_loss: 0.9018 - val_accuracy: 0.8032\n","Epoch 61/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3090 - accuracy: 0.9884 - val_loss: 0.9013 - val_accuracy: 0.8088\n","Epoch 62/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3069 - accuracy: 0.9887 - val_loss: 0.9079 - val_accuracy: 0.7975\n","Epoch 63/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3107 - accuracy: 0.9867 - val_loss: 0.9428 - val_accuracy: 0.8020\n","Epoch 64/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3064 - accuracy: 0.9890 - val_loss: 0.9027 - val_accuracy: 0.8133\n","Epoch 65/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3054 - accuracy: 0.9904 - val_loss: 0.9171 - val_accuracy: 0.8122\n","Epoch 66/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3041 - accuracy: 0.9907 - val_loss: 0.9022 - val_accuracy: 0.8167\n","Epoch 67/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3046 - accuracy: 0.9901 - val_loss: 0.9049 - val_accuracy: 0.7986\n","Epoch 68/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3037 - accuracy: 0.9892 - val_loss: 0.9204 - val_accuracy: 0.8066\n","Epoch 69/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3035 - accuracy: 0.9901 - val_loss: 0.9178 - val_accuracy: 0.8077\n","Epoch 70/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3058 - accuracy: 0.9875 - val_loss: 0.9363 - val_accuracy: 0.8066\n","Epoch 71/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3045 - accuracy: 0.9904 - val_loss: 0.9204 - val_accuracy: 0.8088\n","Epoch 72/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3025 - accuracy: 0.9898 - val_loss: 0.9493 - val_accuracy: 0.8009\n","Epoch 73/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3018 - accuracy: 0.9904 - val_loss: 0.9203 - val_accuracy: 0.8032\n","Epoch 74/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2989 - accuracy: 0.9907 - val_loss: 0.9327 - val_accuracy: 0.7975\n","Epoch 75/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3061 - accuracy: 0.9867 - val_loss: 0.9777 - val_accuracy: 0.7896\n","Epoch 76/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3019 - accuracy: 0.9895 - val_loss: 1.0521 - val_accuracy: 0.7794\n","Epoch 77/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3060 - accuracy: 0.9881 - val_loss: 0.9297 - val_accuracy: 0.8111\n","Epoch 78/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2991 - accuracy: 0.9898 - val_loss: 0.9367 - val_accuracy: 0.8088\n","Epoch 79/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2967 - accuracy: 0.9921 - val_loss: 0.9461 - val_accuracy: 0.8077\n","Epoch 80/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2962 - accuracy: 0.9924 - val_loss: 0.9367 - val_accuracy: 0.8066\n","Epoch 81/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2993 - accuracy: 0.9887 - val_loss: 0.9389 - val_accuracy: 0.8077\n","Epoch 82/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2967 - accuracy: 0.9915 - val_loss: 0.9367 - val_accuracy: 0.8077\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2952 - accuracy: 0.9918 - val_loss: 0.9740 - val_accuracy: 0.7952\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2968 - accuracy: 0.9907 - val_loss: 0.9599 - val_accuracy: 0.8054\n","Epoch 85/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2991 - accuracy: 0.9878 - val_loss: 0.9733 - val_accuracy: 0.7885\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2937 - accuracy: 0.9901 - val_loss: 0.9570 - val_accuracy: 0.8009\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2916 - accuracy: 0.9912 - val_loss: 0.9540 - val_accuracy: 0.8032\n","Epoch 88/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2935 - accuracy: 0.9909 - val_loss: 0.9584 - val_accuracy: 0.7986\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3085 - accuracy: 0.9873 - val_loss: 1.0840 - val_accuracy: 0.7919\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3602 - accuracy: 0.9748 - val_loss: 1.4580 - val_accuracy: 0.7070\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3887 - accuracy: 0.9533 - val_loss: 1.1127 - val_accuracy: 0.7794\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3871 - accuracy: 0.9624 - val_loss: 1.1386 - val_accuracy: 0.7681\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3435 - accuracy: 0.9765 - val_loss: 1.0004 - val_accuracy: 0.7952\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3170 - accuracy: 0.9788 - val_loss: 0.9789 - val_accuracy: 0.7907\n","Epoch 95/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3014 - accuracy: 0.9833 - val_loss: 0.9957 - val_accuracy: 0.8009\n","Epoch 96/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2920 - accuracy: 0.9924 - val_loss: 0.9513 - val_accuracy: 0.8156\n","Epoch 97/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2888 - accuracy: 0.9943 - val_loss: 1.0177 - val_accuracy: 0.7930\n","Epoch 98/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2891 - accuracy: 0.9921 - val_loss: 0.9521 - val_accuracy: 0.8167\n","Epoch 99/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2876 - accuracy: 0.9926 - val_loss: 0.9611 - val_accuracy: 0.7986\n","Epoch 100/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2875 - accuracy: 0.9935 - val_loss: 0.9675 - val_accuracy: 0.8111\n","{'loss': [0.39497998356819153, 0.3775436282157898, 0.36638087034225464, 0.36881548166275024, 0.36427542567253113, 0.360356867313385, 0.35917890071868896, 0.3682427406311035, 0.36286598443984985, 0.3612286448478699, 0.3598184585571289, 0.34855857491493225, 0.347420334815979, 0.346381276845932, 0.3442394435405731, 0.34373629093170166, 0.34733644127845764, 0.34417393803596497, 0.34032565355300903, 0.33783864974975586, 0.3370424807071686, 0.33840394020080566, 0.3336179852485657, 0.3340814411640167, 0.3356434404850006, 0.33300188183784485, 0.32950669527053833, 0.33356648683547974, 0.3299880027770996, 0.3363026976585388, 0.40061864256858826, 0.41515129804611206, 0.3701808750629425, 0.3387083411216736, 0.32476332783699036, 0.3246881067752838, 0.32532113790512085, 0.3231655955314636, 0.3237152397632599, 0.3200060725212097, 0.32265421748161316, 0.31940504908561707, 0.31885477900505066, 0.3207181990146637, 0.3189105987548828, 0.31525105237960815, 0.32290834188461304, 0.3211684823036194, 0.3210073709487915, 0.3140055239200592, 0.3144439160823822, 0.3164879381656647, 0.3122014105319977, 0.31105488538742065, 0.3150758743286133, 0.3199843764305115, 0.3216008245944977, 0.3100372552871704, 0.3122526705265045, 0.31335657835006714, 0.3090488612651825, 0.3068745732307434, 0.3106643855571747, 0.30642804503440857, 0.3053634464740753, 0.30407026410102844, 0.30458277463912964, 0.30374008417129517, 0.3035362660884857, 0.3058156669139862, 0.3044796884059906, 0.30249348282814026, 0.3018423914909363, 0.2989334166049957, 0.3060856759548187, 0.3019034266471863, 0.30603018403053284, 0.2991067171096802, 0.2966734766960144, 0.29618123173713684, 0.29925668239593506, 0.2966982126235962, 0.29524508118629456, 0.2968253195285797, 0.29905858635902405, 0.29367315769195557, 0.29159170389175415, 0.29348281025886536, 0.30846107006073, 0.36017319560050964, 0.3887166380882263, 0.38710713386535645, 0.3434745669364929, 0.31696516275405884, 0.30143070220947266, 0.29203665256500244, 0.28882646560668945, 0.28910157084465027, 0.2876284718513489, 0.28745773434638977], 'accuracy': [0.9552914500236511, 0.9634974598884583, 0.9700056314468384, 0.9677419066429138, 0.9708545804023743, 0.9719864130020142, 0.9722693562507629, 0.9677419066429138, 0.9688737988471985, 0.9688737988471985, 0.9717034697532654, 0.9793435335159302, 0.9773627519607544, 0.9784946441650391, 0.9810413122177124, 0.9779286980628967, 0.9773627519607544, 0.9793435335159302, 0.9818902015686035, 0.9818902015686035, 0.9801924228668213, 0.9801924228668213, 0.9830220937728882, 0.9816072583198547, 0.9807583689689636, 0.9810413122177124, 0.983305037021637, 0.9821732044219971, 0.9844368696212769, 0.9816072583198547, 0.9527447819709778, 0.9572722315788269, 0.9714204668998718, 0.977645754814148, 0.9872665405273438, 0.9847198724746704, 0.9852858185768127, 0.9858517050743103, 0.9841539263725281, 0.9864176511764526, 0.9844368696212769, 0.9852858185768127, 0.9867005944252014, 0.9847198724746704, 0.9847198724746704, 0.9872665405273438, 0.983305037021637, 0.9844368696212769, 0.9841539263725281, 0.9881154298782349, 0.9864176511764526, 0.9878324866294861, 0.9883984327316284, 0.9898132681846619, 0.9844368696212769, 0.9850028157234192, 0.9816072583198547, 0.9898132681846619, 0.9861347079277039, 0.9867005944252014, 0.9883984327316284, 0.9886813759803772, 0.9867005944252014, 0.988964319229126, 0.9903791546821594, 0.990662157535553, 0.9900962114334106, 0.9892473220825195, 0.9900962114334106, 0.9875495433807373, 0.9903791546821594, 0.9898132681846619, 0.9903791546821594, 0.990662157535553, 0.9867005944252014, 0.9895302653312683, 0.9881154298782349, 0.9898132681846619, 0.9920769929885864, 0.9923599362373352, 0.9886813759803772, 0.9915110468864441, 0.9917939901351929, 0.990662157535553, 0.9878324866294861, 0.9900962114334106, 0.9912280440330505, 0.9909451007843018, 0.9872665405273438, 0.974816083908081, 0.9533106684684753, 0.9623655676841736, 0.9765138626098633, 0.9787775874137878, 0.983305037021637, 0.9923599362373352, 0.994340717792511, 0.9920769929885864, 0.992642879486084, 0.9934917688369751], 'val_loss': [2.5899739265441895, 2.575913906097412, 2.592676877975464, 2.6002910137176514, 2.572073221206665, 2.572148084640503, 2.5839879512786865, 2.536921501159668, 2.48264217376709, 2.586826801300049, 2.45694899559021, 2.4971563816070557, 2.335076093673706, 2.1983888149261475, 2.170210838317871, 2.1468429565429688, 2.0118188858032227, 1.7546724081039429, 1.591566562652588, 1.3624125719070435, 1.3537300825119019, 1.1815619468688965, 0.8724972605705261, 0.9799670577049255, 0.8336896300315857, 0.8806649446487427, 0.7952002882957458, 0.8620474338531494, 0.855627715587616, 0.9924417734146118, 1.2041854858398438, 0.9555684328079224, 0.8759963512420654, 0.8942441344261169, 0.8483490943908691, 0.8520756363868713, 0.865138828754425, 0.8923657536506653, 0.8774837255477905, 0.8727691769599915, 0.8673895001411438, 0.8808600902557373, 0.8784750699996948, 0.8923326134681702, 0.8744493126869202, 0.877648115158081, 0.9909520149230957, 0.885569155216217, 0.8967555165290833, 0.8833098411560059, 0.8778711557388306, 0.8783895373344421, 0.8916661739349365, 0.8914746046066284, 0.8968928456306458, 0.9356802701950073, 0.9065340757369995, 0.8979952931404114, 0.9112424254417419, 0.9017791152000427, 0.9013087749481201, 0.9079012870788574, 0.9428089261054993, 0.9027179479598999, 0.9170639514923096, 0.9021585583686829, 0.9049175977706909, 0.9204105734825134, 0.9178110957145691, 0.9363343119621277, 0.9203664660453796, 0.9492697715759277, 0.9203378558158875, 0.9327040910720825, 0.9776835441589355, 1.0520840883255005, 0.9296895861625671, 0.9367021322250366, 0.9460857510566711, 0.9366735219955444, 0.9389243721961975, 0.936663806438446, 0.9740267395973206, 0.959945797920227, 0.9733078479766846, 0.9569860696792603, 0.954037070274353, 0.958410918712616, 1.084022045135498, 1.4579732418060303, 1.1127244234085083, 1.1386120319366455, 1.0003529787063599, 0.9788571000099182, 0.9957061409950256, 0.9513087272644043, 1.0176879167556763, 0.9520581960678101, 0.9610508680343628, 0.9675480723381042], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.4954751133918762, 0.49660632014274597, 0.4977375566959381, 0.5011312365531921, 0.5079185366630554, 0.5113122463226318, 0.516968309879303, 0.5316742062568665, 0.5373303294181824, 0.5735294222831726, 0.6085972785949707, 0.6447963714599609, 0.6504524946212769, 0.6866515874862671, 0.7726244330406189, 0.7488687634468079, 0.8020362257957458, 0.7828054428100586, 0.8099547624588013, 0.7986425161361694, 0.8167420625686646, 0.7828054428100586, 0.7680995464324951, 0.790723979473114, 0.8156108856201172, 0.807692289352417, 0.8246606588363647, 0.8190045356750488, 0.8223981857299805, 0.8042986392974854, 0.8065611124038696, 0.8223981857299805, 0.8088235259056091, 0.8054298758506775, 0.807692289352417, 0.8020362257957458, 0.8122171759605408, 0.8167420625686646, 0.7895927429199219, 0.8088235259056091, 0.8122171759605408, 0.8167420625686646, 0.8223981857299805, 0.8156108856201172, 0.8167420625686646, 0.8190045356750488, 0.8156108856201172, 0.8099547624588013, 0.8054298758506775, 0.8133484125137329, 0.8110859990119934, 0.8031674027442932, 0.8088235259056091, 0.7975113391876221, 0.8020362257957458, 0.8133484125137329, 0.8122171759605408, 0.8167420625686646, 0.7986425161361694, 0.8065611124038696, 0.807692289352417, 0.8065611124038696, 0.8088235259056091, 0.8009049892425537, 0.8031674027442932, 0.7975113391876221, 0.7895927429199219, 0.779411792755127, 0.8110859990119934, 0.8088235259056091, 0.807692289352417, 0.8065611124038696, 0.807692289352417, 0.807692289352417, 0.7952488660812378, 0.8054298758506775, 0.7884615659713745, 0.8009049892425537, 0.8031674027442932, 0.7986425161361694, 0.7918552160263062, 0.7070135474205017, 0.779411792755127, 0.7680995464324951, 0.7952488660812378, 0.790723979473114, 0.8009049892425537, 0.8156108856201172, 0.7929864525794983, 0.8167420625686646, 0.7986425161361694, 0.8110859990119934]}\n","45/45 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 3s 28ms/step - loss: 0.4355 - accuracy: 0.9346 - val_loss: 2.6381 - val_accuracy: 0.4876\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.3983 - accuracy: 0.9453"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 13ms/step - loss: 0.3996 - accuracy: 0.9486 - val_loss: 2.6156 - val_accuracy: 0.4876\n","Epoch 3/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3881 - accuracy: 0.9550 - val_loss: 2.6055 - val_accuracy: 0.4886\n","Epoch 4/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3835 - accuracy: 0.9568 - val_loss: 2.5851 - val_accuracy: 0.4886\n","Epoch 5/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3864 - accuracy: 0.9530 - val_loss: 2.5821 - val_accuracy: 0.4886\n","Epoch 6/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3851 - accuracy: 0.9571 - val_loss: 2.5644 - val_accuracy: 0.4886\n","Epoch 7/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3862 - accuracy: 0.9540 - val_loss: 2.5898 - val_accuracy: 0.4897\n","Epoch 8/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3744 - accuracy: 0.9610 - val_loss: 2.5983 - val_accuracy: 0.4907\n","Epoch 9/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3735 - accuracy: 0.9630 - val_loss: 2.4792 - val_accuracy: 0.4959\n","Epoch 10/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3750 - accuracy: 0.9630 - val_loss: 2.5137 - val_accuracy: 0.4969\n","Epoch 11/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3745 - accuracy: 0.9594 - val_loss: 2.4969 - val_accuracy: 0.5010\n","Epoch 12/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3651 - accuracy: 0.9664 - val_loss: 2.4197 - val_accuracy: 0.5083\n","Epoch 13/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3637 - accuracy: 0.9682 - val_loss: 2.4469 - val_accuracy: 0.5083\n","Epoch 14/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3622 - accuracy: 0.9698 - val_loss: 2.2561 - val_accuracy: 0.5145\n","Epoch 15/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3612 - accuracy: 0.9659 - val_loss: 2.0758 - val_accuracy: 0.5289\n","Epoch 16/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3598 - accuracy: 0.9693 - val_loss: 1.8507 - val_accuracy: 0.5506\n","Epoch 17/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3624 - accuracy: 0.9700 - val_loss: 1.8253 - val_accuracy: 0.5620\n","Epoch 18/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3570 - accuracy: 0.9708 - val_loss: 1.6012 - val_accuracy: 0.5961\n","Epoch 19/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3582 - accuracy: 0.9703 - val_loss: 1.6465 - val_accuracy: 0.5950\n","Epoch 20/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3679 - accuracy: 0.9618 - val_loss: 1.7148 - val_accuracy: 0.6074\n","Epoch 21/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3847 - accuracy: 0.9579 - val_loss: 1.3807 - val_accuracy: 0.6477\n","Epoch 22/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3738 - accuracy: 0.9594 - val_loss: 1.1740 - val_accuracy: 0.7025\n","Epoch 23/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3518 - accuracy: 0.9713 - val_loss: 0.8976 - val_accuracy: 0.7872\n","Epoch 24/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3770 - accuracy: 0.9630 - val_loss: 0.9100 - val_accuracy: 0.7924\n","Epoch 25/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3587 - accuracy: 0.9695 - val_loss: 0.8826 - val_accuracy: 0.7975\n","Epoch 26/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3575 - accuracy: 0.9721 - val_loss: 0.9179 - val_accuracy: 0.8006\n","Epoch 27/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3522 - accuracy: 0.9693 - val_loss: 0.9722 - val_accuracy: 0.7924\n","Epoch 28/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3498 - accuracy: 0.9703 - val_loss: 0.9015 - val_accuracy: 0.8017\n","Epoch 29/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3549 - accuracy: 0.9677 - val_loss: 0.9372 - val_accuracy: 0.8048\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3491 - accuracy: 0.9739 - val_loss: 1.0048 - val_accuracy: 0.7614\n","Epoch 31/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3602 - accuracy: 0.9641 - val_loss: 0.9553 - val_accuracy: 0.7944\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3439 - accuracy: 0.9760 - val_loss: 0.9170 - val_accuracy: 0.8037\n","Epoch 33/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3471 - accuracy: 0.9744 - val_loss: 0.9117 - val_accuracy: 0.8068\n","Epoch 34/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3417 - accuracy: 0.9767 - val_loss: 0.9161 - val_accuracy: 0.8058\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3395 - accuracy: 0.9762 - val_loss: 0.9439 - val_accuracy: 0.7986\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3449 - accuracy: 0.9731 - val_loss: 0.9590 - val_accuracy: 0.8006\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3381 - accuracy: 0.9767 - val_loss: 0.9620 - val_accuracy: 0.8006\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3415 - accuracy: 0.9773 - val_loss: 0.9574 - val_accuracy: 0.7944\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3461 - accuracy: 0.9724 - val_loss: 0.9892 - val_accuracy: 0.7934\n","Epoch 40/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3368 - accuracy: 0.9752 - val_loss: 0.9946 - val_accuracy: 0.7831\n","Epoch 41/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3430 - accuracy: 0.9729 - val_loss: 0.9956 - val_accuracy: 0.7924\n","Epoch 42/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3366 - accuracy: 0.9767 - val_loss: 1.0471 - val_accuracy: 0.7758\n","Epoch 43/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3387 - accuracy: 0.9762 - val_loss: 0.9776 - val_accuracy: 0.7820\n","Epoch 44/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3438 - accuracy: 0.9724 - val_loss: 1.0079 - val_accuracy: 0.7934\n","Epoch 45/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3330 - accuracy: 0.9796 - val_loss: 1.0264 - val_accuracy: 0.7913\n","Epoch 46/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3327 - accuracy: 0.9796 - val_loss: 0.9738 - val_accuracy: 0.7893\n","Epoch 47/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3323 - accuracy: 0.9770 - val_loss: 0.9680 - val_accuracy: 0.7996\n","Epoch 48/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3298 - accuracy: 0.9801 - val_loss: 1.0273 - val_accuracy: 0.7810\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3311 - accuracy: 0.9783 - val_loss: 0.9722 - val_accuracy: 0.7924\n","Epoch 50/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3293 - accuracy: 0.9798 - val_loss: 0.9742 - val_accuracy: 0.7955\n","Epoch 51/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3280 - accuracy: 0.9819 - val_loss: 0.9878 - val_accuracy: 0.7758\n","Epoch 52/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3279 - accuracy: 0.9814 - val_loss: 1.0079 - val_accuracy: 0.7924\n","Epoch 53/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3316 - accuracy: 0.9778 - val_loss: 0.9879 - val_accuracy: 0.7913\n","Epoch 54/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3317 - accuracy: 0.9786 - val_loss: 0.9922 - val_accuracy: 0.7862\n","Epoch 55/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3298 - accuracy: 0.9778 - val_loss: 0.9724 - val_accuracy: 0.7903\n","Epoch 56/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3326 - accuracy: 0.9739 - val_loss: 1.0703 - val_accuracy: 0.7893\n","Epoch 57/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3305 - accuracy: 0.9778 - val_loss: 1.0574 - val_accuracy: 0.7924\n","Epoch 58/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3371 - accuracy: 0.9739 - val_loss: 1.2466 - val_accuracy: 0.7593\n","Epoch 59/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3513 - accuracy: 0.9659 - val_loss: 1.1322 - val_accuracy: 0.7758\n","Epoch 60/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3228 - accuracy: 0.9824 - val_loss: 1.0303 - val_accuracy: 0.7789\n","Epoch 61/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3261 - accuracy: 0.9786 - val_loss: 1.0296 - val_accuracy: 0.7851\n","Epoch 62/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3231 - accuracy: 0.9796 - val_loss: 1.0879 - val_accuracy: 0.7614\n","Epoch 63/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3233 - accuracy: 0.9801 - val_loss: 1.0225 - val_accuracy: 0.7862\n","Epoch 64/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3222 - accuracy: 0.9809 - val_loss: 1.0359 - val_accuracy: 0.7820\n","Epoch 65/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3180 - accuracy: 0.9822 - val_loss: 1.0383 - val_accuracy: 0.7862\n","Epoch 66/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3174 - accuracy: 0.9832 - val_loss: 1.1067 - val_accuracy: 0.7634\n","Epoch 67/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3257 - accuracy: 0.9786 - val_loss: 1.0206 - val_accuracy: 0.7944\n","Epoch 68/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3184 - accuracy: 0.9824 - val_loss: 1.0356 - val_accuracy: 0.7872\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3151 - accuracy: 0.9850 - val_loss: 1.0333 - val_accuracy: 0.7872\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3139 - accuracy: 0.9840 - val_loss: 1.0189 - val_accuracy: 0.7913\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3179 - accuracy: 0.9840 - val_loss: 1.0488 - val_accuracy: 0.7820\n","Epoch 72/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3347 - accuracy: 0.9796 - val_loss: 1.4780 - val_accuracy: 0.7417\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4199 - accuracy: 0.9522 - val_loss: 1.2346 - val_accuracy: 0.7572\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3811 - accuracy: 0.9602 - val_loss: 1.0673 - val_accuracy: 0.7717\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3344 - accuracy: 0.9744 - val_loss: 1.0984 - val_accuracy: 0.7676\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3233 - accuracy: 0.9793 - val_loss: 1.0605 - val_accuracy: 0.7779\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3134 - accuracy: 0.9860 - val_loss: 1.0503 - val_accuracy: 0.7779\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3098 - accuracy: 0.9863 - val_loss: 1.0591 - val_accuracy: 0.7686\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3102 - accuracy: 0.9853 - val_loss: 1.0611 - val_accuracy: 0.7779\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3090 - accuracy: 0.9866 - val_loss: 1.0721 - val_accuracy: 0.7686\n","Epoch 81/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3104 - accuracy: 0.9853 - val_loss: 1.1464 - val_accuracy: 0.7562\n","Epoch 82/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3195 - accuracy: 0.9801 - val_loss: 1.2624 - val_accuracy: 0.7521\n","Epoch 83/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3167 - accuracy: 0.9819 - val_loss: 1.1002 - val_accuracy: 0.7686\n","Epoch 84/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3119 - accuracy: 0.9837 - val_loss: 1.0631 - val_accuracy: 0.7748\n","Epoch 85/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3087 - accuracy: 0.9873 - val_loss: 1.0820 - val_accuracy: 0.7820\n","Epoch 86/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3104 - accuracy: 0.9817 - val_loss: 1.0759 - val_accuracy: 0.7758\n","Epoch 87/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3381 - accuracy: 0.9716 - val_loss: 1.2661 - val_accuracy: 0.7366\n","Epoch 88/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3218 - accuracy: 0.9786 - val_loss: 1.1009 - val_accuracy: 0.7820\n","Epoch 89/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3130 - accuracy: 0.9801 - val_loss: 1.2709 - val_accuracy: 0.7717\n","Epoch 90/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3352 - accuracy: 0.9726 - val_loss: 1.1347 - val_accuracy: 0.7707\n","Epoch 91/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3053 - accuracy: 0.9863 - val_loss: 1.1400 - val_accuracy: 0.7696\n","Epoch 92/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3053 - accuracy: 0.9879 - val_loss: 1.0712 - val_accuracy: 0.7841\n","Epoch 93/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3043 - accuracy: 0.9879 - val_loss: 1.0713 - val_accuracy: 0.7810\n","Epoch 94/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3052 - accuracy: 0.9886 - val_loss: 1.1292 - val_accuracy: 0.7769\n","Epoch 95/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3035 - accuracy: 0.9879 - val_loss: 1.1048 - val_accuracy: 0.7727\n","Epoch 96/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3039 - accuracy: 0.9842 - val_loss: 1.0904 - val_accuracy: 0.7769\n","Epoch 97/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3018 - accuracy: 0.9879 - val_loss: 1.0894 - val_accuracy: 0.7707\n","Epoch 98/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3016 - accuracy: 0.9845 - val_loss: 1.0950 - val_accuracy: 0.7727\n","Epoch 99/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3019 - accuracy: 0.9881 - val_loss: 1.0764 - val_accuracy: 0.7800\n","Epoch 100/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3013 - accuracy: 0.9881 - val_loss: 1.1306 - val_accuracy: 0.7727\n","{'loss': [0.4354890286922455, 0.399618923664093, 0.3880819082260132, 0.3835301697254181, 0.38640710711479187, 0.385088711977005, 0.3861650228500366, 0.3743695318698883, 0.373454749584198, 0.37500667572021484, 0.3744846284389496, 0.36510252952575684, 0.36370426416397095, 0.3622489273548126, 0.3611917793750763, 0.3598261773586273, 0.362426221370697, 0.3569573163986206, 0.35824844241142273, 0.367905855178833, 0.38469600677490234, 0.3737575113773346, 0.35177791118621826, 0.3769620656967163, 0.3587498366832733, 0.3575073778629303, 0.3522198796272278, 0.3498455882072449, 0.35492971539497375, 0.34912025928497314, 0.3602468967437744, 0.3439139723777771, 0.347077876329422, 0.3417454659938812, 0.33952784538269043, 0.34486839175224304, 0.33811986446380615, 0.341463178396225, 0.3460853397846222, 0.33678504824638367, 0.34300392866134644, 0.3365620970726013, 0.3387269079685211, 0.3437952399253845, 0.3330133557319641, 0.33273589611053467, 0.3323393762111664, 0.32978224754333496, 0.3311072289943695, 0.32931825518608093, 0.32797297835350037, 0.32791754603385925, 0.33163636922836304, 0.331651896238327, 0.3298298418521881, 0.33264070749282837, 0.33050963282585144, 0.3371170163154602, 0.35126760601997375, 0.32277926802635193, 0.32610824704170227, 0.3231469392776489, 0.32329556345939636, 0.3222224712371826, 0.3180326521396637, 0.3174382150173187, 0.32571354508399963, 0.3183526396751404, 0.31512323021888733, 0.3139215409755707, 0.31790992617607117, 0.3346756100654602, 0.4199369251728058, 0.38106122612953186, 0.3344338834285736, 0.3232761025428772, 0.31343933939933777, 0.30979546904563904, 0.31015509366989136, 0.3090165853500366, 0.3104429543018341, 0.31952306628227234, 0.3167363703250885, 0.3119352161884308, 0.30874863266944885, 0.31037771701812744, 0.33807340264320374, 0.321818470954895, 0.3130039870738983, 0.33521178364753723, 0.30528393387794495, 0.3052564263343811, 0.30434441566467285, 0.30518782138824463, 0.3035458028316498, 0.3039024770259857, 0.3017750382423401, 0.30162808299064636, 0.3019033968448639, 0.30127912759780884], 'accuracy': [0.9346253275871277, 0.9485788345336914, 0.9550387859344482, 0.9568475484848022, 0.9529715776443481, 0.9571059346199036, 0.9540051817893982, 0.9609819054603577, 0.9630491137504578, 0.9630491137504578, 0.959431529045105, 0.9664082527160645, 0.9682170748710632, 0.9697674512863159, 0.9658914804458618, 0.9692506194114685, 0.9700258374214172, 0.970801055431366, 0.9702842235565186, 0.9617571234703064, 0.9578811526298523, 0.959431529045105, 0.9713178277015686, 0.9630491137504578, 0.9695090651512146, 0.9720930457115173, 0.9692506194114685, 0.9702842235565186, 0.9677002429962158, 0.9739018082618713, 0.964082658290863, 0.9759690165519714, 0.974418580532074, 0.9767441749572754, 0.9762274026870728, 0.9731265902519226, 0.9767441749572754, 0.9772610068321228, 0.9723514318466187, 0.9751937985420227, 0.9728682041168213, 0.9767441749572754, 0.9762274026870728, 0.9723514318466187, 0.9795865416526794, 0.9795865416526794, 0.9770025610923767, 0.9801033735275269, 0.9782945513725281, 0.9798449873924255, 0.9819121360778809, 0.9813953638076782, 0.9777777791023254, 0.9785529971122742, 0.9777777791023254, 0.9739018082618713, 0.9777777791023254, 0.9739018082618713, 0.9658914804458618, 0.9824289679527283, 0.9785529971122742, 0.9795865416526794, 0.9801033735275269, 0.9808785319328308, 0.9821705222129822, 0.9832041263580322, 0.9785529971122742, 0.9824289679527283, 0.985012948513031, 0.983979344367981, 0.983979344367981, 0.9795865416526794, 0.9521963596343994, 0.9602067470550537, 0.974418580532074, 0.9793281555175781, 0.9860464930534363, 0.9863049387931824, 0.9852713346481323, 0.9865633249282837, 0.9852713346481323, 0.9801033735275269, 0.9819121360778809, 0.9837209582328796, 0.9873384833335876, 0.9816537499427795, 0.9715762138366699, 0.9785529971122742, 0.9801033735275269, 0.97260981798172, 0.9863049387931824, 0.9878553152084351, 0.9878553152084351, 0.988630473613739, 0.9878553152084351, 0.9842377305030823, 0.9878553152084351, 0.9844961166381836, 0.9881137013435364, 0.9881137013435364], 'val_loss': [2.6381235122680664, 2.6156322956085205, 2.605513095855713, 2.5850629806518555, 2.5821287631988525, 2.564425230026245, 2.5898172855377197, 2.598317861557007, 2.4791858196258545, 2.5136585235595703, 2.4968607425689697, 2.419687032699585, 2.44692325592041, 2.2560555934906006, 2.0758137702941895, 1.850682258605957, 1.8253028392791748, 1.6012003421783447, 1.6464564800262451, 1.7147752046585083, 1.3806945085525513, 1.1740435361862183, 0.8975775241851807, 0.90999835729599, 0.8825504779815674, 0.9178546667098999, 0.9721723794937134, 0.9014582633972168, 0.9372096657752991, 1.0048094987869263, 0.9553366899490356, 0.917008638381958, 0.9116692543029785, 0.9161419868469238, 0.9438758492469788, 0.958970308303833, 0.962029218673706, 0.9573691487312317, 0.9891547560691833, 0.994558572769165, 0.9955697059631348, 1.047057867050171, 0.9775848984718323, 1.0078909397125244, 1.0264414548873901, 0.973775327205658, 0.9680342674255371, 1.0272845029830933, 0.9721617698669434, 0.9741765856742859, 0.9877797365188599, 1.0079283714294434, 0.9878913164138794, 0.9921914935112, 0.9723820090293884, 1.07029390335083, 1.0574030876159668, 1.246551752090454, 1.1321628093719482, 1.0302597284317017, 1.0296300649642944, 1.0878562927246094, 1.0225167274475098, 1.0358750820159912, 1.0382784605026245, 1.1067073345184326, 1.0206173658370972, 1.0356152057647705, 1.0332753658294678, 1.0188727378845215, 1.0487715005874634, 1.478007197380066, 1.2345584630966187, 1.0673342943191528, 1.0984492301940918, 1.0604864358901978, 1.0502800941467285, 1.059062123298645, 1.0611227750778198, 1.0721392631530762, 1.1464409828186035, 1.2624329328536987, 1.1001825332641602, 1.0630521774291992, 1.0819729566574097, 1.0758861303329468, 1.2661083936691284, 1.1008884906768799, 1.270888328552246, 1.1347384452819824, 1.1400010585784912, 1.0712167024612427, 1.0712552070617676, 1.1292208433151245, 1.1048496961593628, 1.0903801918029785, 1.0893664360046387, 1.0950331687927246, 1.0764477252960205, 1.1305845975875854], 'val_accuracy': [0.4876033067703247, 0.4876033067703247, 0.4886363744735718, 0.4886363744735718, 0.4886363744735718, 0.4886363744735718, 0.48966941237449646, 0.49070248007774353, 0.4958677589893341, 0.4969008266925812, 0.5010330677032471, 0.5082644820213318, 0.5082644820213318, 0.5144628286361694, 0.5289255976676941, 0.5506198406219482, 0.5619834661483765, 0.5960744023323059, 0.5950413346290588, 0.6074380278587341, 0.6477272510528564, 0.702479362487793, 0.7871900796890259, 0.7923553586006165, 0.797520637512207, 0.8006198406219482, 0.7923553586006165, 0.8016529083251953, 0.8047520518302917, 0.7613636255264282, 0.7944214940071106, 0.8037189841270447, 0.8068181872367859, 0.8057851195335388, 0.7985537052154541, 0.8006198406219482, 0.8006198406219482, 0.7944214940071106, 0.7933884263038635, 0.7830578684806824, 0.7923553586006165, 0.7758264541625977, 0.7820248007774353, 0.7933884263038635, 0.7913222908973694, 0.78925621509552, 0.7995867729187012, 0.7809917330741882, 0.7923553586006165, 0.7954545617103577, 0.7758264541625977, 0.7923553586006165, 0.7913222908973694, 0.7861570119857788, 0.7902892827987671, 0.78925621509552, 0.7923553586006165, 0.7592975497245789, 0.7758264541625977, 0.7789255976676941, 0.7851239442825317, 0.7613636255264282, 0.7861570119857788, 0.7820248007774353, 0.7861570119857788, 0.7634297609329224, 0.7944214940071106, 0.7871900796890259, 0.7871900796890259, 0.7913222908973694, 0.7820248007774353, 0.7417355179786682, 0.7572314143180847, 0.7716942429542542, 0.7675619721412659, 0.7778925895690918, 0.7778925895690918, 0.7685950398445129, 0.7778925895690918, 0.7685950398445129, 0.7561983466148376, 0.7520661354064941, 0.7685950398445129, 0.7747933864593506, 0.7820248007774353, 0.7758264541625977, 0.7365702390670776, 0.7820248007774353, 0.7716942429542542, 0.7706611752510071, 0.76962810754776, 0.7840909361839294, 0.7809917330741882, 0.7768595218658447, 0.7727272510528564, 0.7768595218658447, 0.7706611752510071, 0.7727272510528564, 0.7799586653709412, 0.7727272510528564]}\n","32/32 [==============================] - 0s 4ms/step\n"]}]},{"cell_type":"code","source":["metrics_df_CNN.round(3)"],"metadata":{"id":"y3RXIk-qZ7ts","colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"status":"ok","timestamp":1717430479186,"user_tz":-360,"elapsed":737,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"23638555-7f2e-43ba-b9b3-d01f1cfb7271"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.562      0.551   0.665  0.603        0.665        0.459   \n","1        1     0.630      0.631   0.627  0.629        0.627        0.633   \n","2        2     0.606      0.610   0.588  0.599        0.588        0.624   \n","3        0     0.604      0.590   0.680  0.632        0.680        0.528   \n","4        1     0.677      0.691   0.640  0.664        0.640        0.713   \n","5        2     0.645      0.684   0.538  0.602        0.538        0.751   \n","6        0     0.678      0.651   0.767  0.705        0.767        0.590   \n","7        1     0.735      0.734   0.737  0.736        0.737        0.733   \n","8        2     0.730      0.731   0.727  0.729        0.727        0.733   \n","9        0     0.759      0.740   0.799  0.768        0.799        0.719   \n","10       1     0.778      0.781   0.773  0.777        0.773        0.784   \n","11       2     0.785      0.757   0.839  0.796        0.839        0.731   \n","12       0     0.763      0.719   0.863  0.784        0.863        0.663   \n","13       1     0.811      0.783   0.860  0.820        0.860        0.761   \n","14       2     0.816      0.811   0.825  0.818        0.825        0.807   \n","\n","    Kappa  \n","0   0.124  \n","1   0.260  \n","2   0.213  \n","3   0.208  \n","4   0.353  \n","5   0.289  \n","6   0.357  \n","7   0.470  \n","8   0.460  \n","9   0.518  \n","10  0.556  \n","11  0.570  \n","12  0.526  \n","13  0.621  \n","14  0.633  "],"text/html":["\n","  <div id=\"df-67c8ed00-2525-48cc-b027-9f6a65249bbf\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.562</td>\n","      <td>0.551</td>\n","      <td>0.665</td>\n","      <td>0.603</td>\n","      <td>0.665</td>\n","      <td>0.459</td>\n","      <td>0.124</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.630</td>\n","      <td>0.631</td>\n","      <td>0.627</td>\n","      <td>0.629</td>\n","      <td>0.627</td>\n","      <td>0.633</td>\n","      <td>0.260</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.606</td>\n","      <td>0.610</td>\n","      <td>0.588</td>\n","      <td>0.599</td>\n","      <td>0.588</td>\n","      <td>0.624</td>\n","      <td>0.213</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.604</td>\n","      <td>0.590</td>\n","      <td>0.680</td>\n","      <td>0.632</td>\n","      <td>0.680</td>\n","      <td>0.528</td>\n","      <td>0.208</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.677</td>\n","      <td>0.691</td>\n","      <td>0.640</td>\n","      <td>0.664</td>\n","      <td>0.640</td>\n","      <td>0.713</td>\n","      <td>0.353</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.645</td>\n","      <td>0.684</td>\n","      <td>0.538</td>\n","      <td>0.602</td>\n","      <td>0.538</td>\n","      <td>0.751</td>\n","      <td>0.289</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.678</td>\n","      <td>0.651</td>\n","      <td>0.767</td>\n","      <td>0.705</td>\n","      <td>0.767</td>\n","      <td>0.590</td>\n","      <td>0.357</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.735</td>\n","      <td>0.734</td>\n","      <td>0.737</td>\n","      <td>0.736</td>\n","      <td>0.737</td>\n","      <td>0.733</td>\n","      <td>0.470</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.730</td>\n","      <td>0.731</td>\n","      <td>0.727</td>\n","      <td>0.729</td>\n","      <td>0.727</td>\n","      <td>0.733</td>\n","      <td>0.460</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.759</td>\n","      <td>0.740</td>\n","      <td>0.799</td>\n","      <td>0.768</td>\n","      <td>0.799</td>\n","      <td>0.719</td>\n","      <td>0.518</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.778</td>\n","      <td>0.781</td>\n","      <td>0.773</td>\n","      <td>0.777</td>\n","      <td>0.773</td>\n","      <td>0.784</td>\n","      <td>0.556</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.785</td>\n","      <td>0.757</td>\n","      <td>0.839</td>\n","      <td>0.796</td>\n","      <td>0.839</td>\n","      <td>0.731</td>\n","      <td>0.570</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.763</td>\n","      <td>0.719</td>\n","      <td>0.863</td>\n","      <td>0.784</td>\n","      <td>0.863</td>\n","      <td>0.663</td>\n","      <td>0.526</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.811</td>\n","      <td>0.783</td>\n","      <td>0.860</td>\n","      <td>0.820</td>\n","      <td>0.860</td>\n","      <td>0.761</td>\n","      <td>0.621</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.816</td>\n","      <td>0.811</td>\n","      <td>0.825</td>\n","      <td>0.818</td>\n","      <td>0.825</td>\n","      <td>0.807</td>\n","      <td>0.633</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67c8ed00-2525-48cc-b027-9f6a65249bbf')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-67c8ed00-2525-48cc-b027-9f6a65249bbf button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-67c8ed00-2525-48cc-b027-9f6a65249bbf');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c758a2ab-f636-4fb0-8080-e24c6e1a9851\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c758a2ab-f636-4fb0-8080-e24c6e1a9851')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c758a2ab-f636-4fb0-8080-e24c6e1a9851 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df_CNN\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08206222958102907,\n        \"min\": 0.562,\n        \"max\": 0.816,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.759,\n          0.785,\n          0.562\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07695620275752399,\n        \"min\": 0.551,\n        \"max\": 0.811,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.74,\n          0.757,\n          0.551\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1021069933708661,\n        \"min\": 0.538,\n        \"max\": 0.863,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.799,\n          0.839,\n          0.665\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08269410067056951,\n        \"min\": 0.599,\n        \"max\": 0.82,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.768,\n          0.796,\n          0.603\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1021069933708661,\n        \"min\": 0.538,\n        \"max\": 0.863,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.799,\n          0.839,\n          0.665\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09819766266251428,\n        \"min\": 0.459,\n        \"max\": 0.807,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.784,\n          0.663,\n          0.459\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16409703865468778,\n        \"min\": 0.124,\n        \"max\": 0.633,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.518,\n          0.57,\n          0.124\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["metrics_df_CNN.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Frequency Domain/CNN/Beta_frequency_CNN.csv', index = False)"],"metadata":{"id":"_iOLsKpkfzdG","executionInfo":{"status":"ok","timestamp":1717430479187,"user_tz":-360,"elapsed":20,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ieXSN-9PI4Dx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# GRU"],"metadata":{"id":"1rGGNOIGntWb"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout, GRU\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model_gru(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(GRU(256, return_sequences=True))\n","    model.add(GRU(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning_gru(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model_gru(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model_gru(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Beta/CNN_GRU/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Beta/CNN_GRU/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"CsY0qrbpnxMJ","executionInfo":{"status":"ok","timestamp":1717430479188,"user_tz":-360,"elapsed":20,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["global_model_gru, metrics_df_gru = federated_learning_gru(Theta_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sgema9kan1tX","executionInfo":{"status":"ok","timestamp":1717431650184,"user_tz":-360,"elapsed":46831,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"93a85327-4368-45d6-eaa8-8f4a0de74b35"},"execution_count":24,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 7s 48ms/step - loss: 1.4330 - accuracy: 0.4817 - val_loss: 1.4299 - val_accuracy: 0.5916\n","Epoch 2/100\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 0s 13ms/step - loss: 1.4265 - accuracy: 0.5242 - val_loss: 1.4237 - val_accuracy: 0.4989\n","Epoch 3/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.4200 - accuracy: 0.5420 - val_loss: 1.4176 - val_accuracy: 0.5022\n","Epoch 4/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.4136 - accuracy: 0.5690 - val_loss: 1.4116 - val_accuracy: 0.4903\n","Epoch 5/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.4071 - accuracy: 0.5797 - val_loss: 1.4055 - val_accuracy: 0.4978\n","Epoch 6/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.4006 - accuracy: 0.5870 - val_loss: 1.3995 - val_accuracy: 0.4978\n","Epoch 7/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3942 - accuracy: 0.5857 - val_loss: 1.3936 - val_accuracy: 0.5086\n","Epoch 8/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3875 - accuracy: 0.5902 - val_loss: 1.3875 - val_accuracy: 0.5259\n","Epoch 9/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3811 - accuracy: 0.5894 - val_loss: 1.3815 - val_accuracy: 0.5237\n","Epoch 10/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3748 - accuracy: 0.5902 - val_loss: 1.3755 - val_accuracy: 0.5280\n","Epoch 11/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3685 - accuracy: 0.5962 - val_loss: 1.3694 - val_accuracy: 0.5474\n","Epoch 12/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3620 - accuracy: 0.5973 - val_loss: 1.3635 - val_accuracy: 0.5485\n","Epoch 13/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3555 - accuracy: 0.5919 - val_loss: 1.3572 - val_accuracy: 0.5614\n","Epoch 14/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3493 - accuracy: 0.5973 - val_loss: 1.3511 - val_accuracy: 0.5690\n","Epoch 15/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3428 - accuracy: 0.5994 - val_loss: 1.3448 - val_accuracy: 0.5787\n","Epoch 16/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3361 - accuracy: 0.5973 - val_loss: 1.3384 - val_accuracy: 0.5841\n","Epoch 17/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3295 - accuracy: 0.5991 - val_loss: 1.3320 - val_accuracy: 0.5948\n","Epoch 18/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.3226 - accuracy: 0.5970 - val_loss: 1.3254 - val_accuracy: 0.5959\n","Epoch 19/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.3149 - accuracy: 0.6032 - val_loss: 1.3179 - val_accuracy: 0.5991\n","Epoch 20/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3077 - accuracy: 0.6056 - val_loss: 1.3107 - val_accuracy: 0.5970\n","Epoch 21/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2990 - accuracy: 0.6126 - val_loss: 1.3026 - val_accuracy: 0.6034\n","Epoch 22/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.2903 - accuracy: 0.6153 - val_loss: 1.2948 - val_accuracy: 0.6045\n","Epoch 23/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.2826 - accuracy: 0.6191 - val_loss: 1.2861 - val_accuracy: 0.6024\n","Epoch 24/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.2741 - accuracy: 0.6177 - val_loss: 1.2782 - val_accuracy: 0.6067\n","Epoch 25/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2660 - accuracy: 0.6258 - val_loss: 1.2708 - val_accuracy: 0.6121\n","Epoch 26/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2597 - accuracy: 0.6212 - val_loss: 1.2648 - val_accuracy: 0.6078\n","Epoch 27/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2516 - accuracy: 0.6277 - val_loss: 1.2575 - val_accuracy: 0.6110\n","Epoch 28/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.2459 - accuracy: 0.6285 - val_loss: 1.2515 - val_accuracy: 0.6175\n","Epoch 29/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2387 - accuracy: 0.6323 - val_loss: 1.2469 - val_accuracy: 0.6185\n","Epoch 30/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.2336 - accuracy: 0.6336 - val_loss: 1.2411 - val_accuracy: 0.6207\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2265 - accuracy: 0.6363 - val_loss: 1.2393 - val_accuracy: 0.5970\n","Epoch 32/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.2220 - accuracy: 0.6369 - val_loss: 1.2333 - val_accuracy: 0.6239\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2168 - accuracy: 0.6352 - val_loss: 1.2268 - val_accuracy: 0.6164\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2082 - accuracy: 0.6374 - val_loss: 1.2223 - val_accuracy: 0.6164\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2044 - accuracy: 0.6414 - val_loss: 1.2184 - val_accuracy: 0.6164\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1988 - accuracy: 0.6503 - val_loss: 1.2140 - val_accuracy: 0.6142\n","Epoch 37/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1954 - accuracy: 0.6422 - val_loss: 1.2102 - val_accuracy: 0.6207\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1900 - accuracy: 0.6412 - val_loss: 1.2067 - val_accuracy: 0.6196\n","Epoch 39/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.1863 - accuracy: 0.6428 - val_loss: 1.2044 - val_accuracy: 0.6304\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1791 - accuracy: 0.6511 - val_loss: 1.2010 - val_accuracy: 0.6088\n","Epoch 41/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1769 - accuracy: 0.6490 - val_loss: 1.1951 - val_accuracy: 0.6153\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1700 - accuracy: 0.6514 - val_loss: 1.1910 - val_accuracy: 0.6261\n","Epoch 43/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1658 - accuracy: 0.6522 - val_loss: 1.1884 - val_accuracy: 0.6228\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1591 - accuracy: 0.6514 - val_loss: 1.1859 - val_accuracy: 0.6067\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1558 - accuracy: 0.6568 - val_loss: 1.1806 - val_accuracy: 0.6239\n","Epoch 46/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1509 - accuracy: 0.6622 - val_loss: 1.1774 - val_accuracy: 0.6250\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1458 - accuracy: 0.6616 - val_loss: 1.1744 - val_accuracy: 0.6250\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1413 - accuracy: 0.6573 - val_loss: 1.1709 - val_accuracy: 0.6261\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1365 - accuracy: 0.6576 - val_loss: 1.1674 - val_accuracy: 0.6239\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1317 - accuracy: 0.6633 - val_loss: 1.1650 - val_accuracy: 0.6185\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1250 - accuracy: 0.6630 - val_loss: 1.1612 - val_accuracy: 0.6228\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1207 - accuracy: 0.6681 - val_loss: 1.1595 - val_accuracy: 0.6185\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1176 - accuracy: 0.6624 - val_loss: 1.1575 - val_accuracy: 0.6142\n","Epoch 54/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1128 - accuracy: 0.6665 - val_loss: 1.1535 - val_accuracy: 0.6175\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1099 - accuracy: 0.6676 - val_loss: 1.1505 - val_accuracy: 0.6228\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1052 - accuracy: 0.6657 - val_loss: 1.1488 - val_accuracy: 0.6153\n","Epoch 57/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0988 - accuracy: 0.6756 - val_loss: 1.1463 - val_accuracy: 0.6185\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0946 - accuracy: 0.6797 - val_loss: 1.1445 - val_accuracy: 0.6207\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0895 - accuracy: 0.6762 - val_loss: 1.1414 - val_accuracy: 0.6282\n","Epoch 60/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0866 - accuracy: 0.6730 - val_loss: 1.1377 - val_accuracy: 0.6272\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0792 - accuracy: 0.6843 - val_loss: 1.1356 - val_accuracy: 0.6282\n","Epoch 62/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0762 - accuracy: 0.6797 - val_loss: 1.1324 - val_accuracy: 0.6315\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0715 - accuracy: 0.6818 - val_loss: 1.1323 - val_accuracy: 0.6315\n","Epoch 64/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0674 - accuracy: 0.6872 - val_loss: 1.1288 - val_accuracy: 0.6304\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0626 - accuracy: 0.6878 - val_loss: 1.1266 - val_accuracy: 0.6315\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0578 - accuracy: 0.6888 - val_loss: 1.1259 - val_accuracy: 0.6293\n","Epoch 67/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.0560 - accuracy: 0.6859 - val_loss: 1.1229 - val_accuracy: 0.6336\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0469 - accuracy: 0.6899 - val_loss: 1.1211 - val_accuracy: 0.6325\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0471 - accuracy: 0.6929 - val_loss: 1.1195 - val_accuracy: 0.6282\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0419 - accuracy: 0.6964 - val_loss: 1.1199 - val_accuracy: 0.6315\n","Epoch 71/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0355 - accuracy: 0.6991 - val_loss: 1.1161 - val_accuracy: 0.6239\n","Epoch 72/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0286 - accuracy: 0.6988 - val_loss: 1.1134 - val_accuracy: 0.6272\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0277 - accuracy: 0.6948 - val_loss: 1.1120 - val_accuracy: 0.6261\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0210 - accuracy: 0.7061 - val_loss: 1.1088 - val_accuracy: 0.6315\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0162 - accuracy: 0.7010 - val_loss: 1.1091 - val_accuracy: 0.6293\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0136 - accuracy: 0.7053 - val_loss: 1.1116 - val_accuracy: 0.6272\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0072 - accuracy: 0.7061 - val_loss: 1.1040 - val_accuracy: 0.6261\n","Epoch 78/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0035 - accuracy: 0.7085 - val_loss: 1.1079 - val_accuracy: 0.6272\n","Epoch 79/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9953 - accuracy: 0.7077 - val_loss: 1.1028 - val_accuracy: 0.6379\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9896 - accuracy: 0.7131 - val_loss: 1.1008 - val_accuracy: 0.6315\n","Epoch 81/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9901 - accuracy: 0.7120 - val_loss: 1.0998 - val_accuracy: 0.6239\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9836 - accuracy: 0.7182 - val_loss: 1.0982 - val_accuracy: 0.6239\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9797 - accuracy: 0.7185 - val_loss: 1.0972 - val_accuracy: 0.6250\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9791 - accuracy: 0.7201 - val_loss: 1.0933 - val_accuracy: 0.6207\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9718 - accuracy: 0.7174 - val_loss: 1.0931 - val_accuracy: 0.6304\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9658 - accuracy: 0.7279 - val_loss: 1.0971 - val_accuracy: 0.6293\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9647 - accuracy: 0.7196 - val_loss: 1.0930 - val_accuracy: 0.6228\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9551 - accuracy: 0.7282 - val_loss: 1.0935 - val_accuracy: 0.6272\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9527 - accuracy: 0.7271 - val_loss: 1.0921 - val_accuracy: 0.6207\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9494 - accuracy: 0.7266 - val_loss: 1.0897 - val_accuracy: 0.6196\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9437 - accuracy: 0.7228 - val_loss: 1.0882 - val_accuracy: 0.6250\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9379 - accuracy: 0.7325 - val_loss: 1.0882 - val_accuracy: 0.6175\n","Epoch 93/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9291 - accuracy: 0.7408 - val_loss: 1.0864 - val_accuracy: 0.6207\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9289 - accuracy: 0.7390 - val_loss: 1.0851 - val_accuracy: 0.6196\n","Epoch 95/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9201 - accuracy: 0.7349 - val_loss: 1.0894 - val_accuracy: 0.6131\n","Epoch 96/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9174 - accuracy: 0.7376 - val_loss: 1.0869 - val_accuracy: 0.6228\n","Epoch 97/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9095 - accuracy: 0.7438 - val_loss: 1.0878 - val_accuracy: 0.6218\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9036 - accuracy: 0.7457 - val_loss: 1.0873 - val_accuracy: 0.6185\n","Epoch 99/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8978 - accuracy: 0.7497 - val_loss: 1.1036 - val_accuracy: 0.6196\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8975 - accuracy: 0.7484 - val_loss: 1.0862 - val_accuracy: 0.6196\n","{'loss': [1.4329906702041626, 1.4264973402023315, 1.4199731349945068, 1.413590669631958, 1.4071002006530762, 1.4005658626556396, 1.3941570520401, 1.3875033855438232, 1.3810796737670898, 1.3748317956924438, 1.3684629201889038, 1.362046241760254, 1.3554949760437012, 1.3492546081542969, 1.342756748199463, 1.3361456394195557, 1.3295435905456543, 1.322638988494873, 1.3149418830871582, 1.307709813117981, 1.2989944219589233, 1.290349006652832, 1.282570719718933, 1.2741367816925049, 1.2659871578216553, 1.259663462638855, 1.2515639066696167, 1.245877981185913, 1.2386822700500488, 1.233625888824463, 1.226479411125183, 1.2219531536102295, 1.2168257236480713, 1.2081857919692993, 1.204418659210205, 1.1987789869308472, 1.1953524351119995, 1.1900367736816406, 1.1862785816192627, 1.1791281700134277, 1.1769002676010132, 1.1700100898742676, 1.1657679080963135, 1.159072756767273, 1.155761957168579, 1.150852918624878, 1.1457860469818115, 1.1412713527679443, 1.1364995241165161, 1.1317311525344849, 1.124976634979248, 1.120707631111145, 1.1175786256790161, 1.1127619743347168, 1.109920620918274, 1.1052441596984863, 1.0987803936004639, 1.0946135520935059, 1.0894505977630615, 1.0865951776504517, 1.0792046785354614, 1.0762420892715454, 1.0715304613113403, 1.067380428314209, 1.0625510215759277, 1.0578384399414062, 1.055952787399292, 1.0469006299972534, 1.047078251838684, 1.0418814420700073, 1.035469889640808, 1.0286073684692383, 1.0277388095855713, 1.0210227966308594, 1.0161720514297485, 1.013612985610962, 1.0071876049041748, 1.003491997718811, 0.9952813982963562, 0.9895961284637451, 0.9900567531585693, 0.9835820198059082, 0.9796561598777771, 0.9791289567947388, 0.971762478351593, 0.9657629728317261, 0.9647480249404907, 0.9550845623016357, 0.9527454972267151, 0.9493794441223145, 0.9437478184700012, 0.937903881072998, 0.9290995597839355, 0.9289163947105408, 0.9200555682182312, 0.9173606634140015, 0.9094573259353638, 0.9035583138465881, 0.8977826237678528, 0.8975035548210144], 'accuracy': [0.48168104887008667, 0.5242456793785095, 0.5420258641242981, 0.568965494632721, 0.579741358757019, 0.5870150923728943, 0.5856680870056152, 0.5902478694915771, 0.5894396305084229, 0.5902478694915771, 0.5961745977401733, 0.5972521305084229, 0.5918642282485962, 0.5972521305084229, 0.5994073152542114, 0.5972521305084229, 0.5991379022598267, 0.5969827771186829, 0.603178858757019, 0.6056034564971924, 0.6126077771186829, 0.6153017282485962, 0.6190732717514038, 0.6177262663841248, 0.6258081793785095, 0.6212284564971924, 0.6276939511299133, 0.6285021305084229, 0.6322737336158752, 0.6336206793785095, 0.6363146305084229, 0.6368534564971924, 0.6352370977401733, 0.6373922228813171, 0.6414331793785095, 0.6503232717514038, 0.642241358757019, 0.6411637663841248, 0.6427801847457886, 0.6511314511299133, 0.6489762663841248, 0.6514008641242981, 0.6522090435028076, 0.6514008641242981, 0.6567887663841248, 0.6621767282485962, 0.6616379022598267, 0.6573275923728943, 0.657597005367279, 0.6632543206214905, 0.6629849076271057, 0.6681034564971924, 0.662446141242981, 0.6664870977401733, 0.6675646305084229, 0.665678858757019, 0.6756465435028076, 0.6796875, 0.6761853694915771, 0.6729525923728943, 0.6842672228813171, 0.6796875, 0.6818426847457886, 0.6872305870056152, 0.6877694129943848, 0.688847005367279, 0.685883641242981, 0.6899245977401733, 0.6928879022598267, 0.6963900923728943, 0.6990840435028076, 0.6988146305084229, 0.6947737336158752, 0.7060883641242981, 0.7009698152542114, 0.7052801847457886, 0.7060883641242981, 0.7085129022598267, 0.7077047228813171, 0.7130926847457886, 0.7120150923728943, 0.7182112336158752, 0.7184805870056152, 0.720097005367279, 0.717402994632721, 0.727909505367279, 0.7195581793785095, 0.728178858757019, 0.7271012663841248, 0.7265625, 0.7227909564971924, 0.7324892282485962, 0.740840494632721, 0.7389547228813171, 0.7349137663841248, 0.7376077771186829, 0.743803858757019, 0.7456896305084229, 0.7497305870056152, 0.748383641242981], 'val_loss': [1.429905652999878, 1.4237462282180786, 1.4176056385040283, 1.4115636348724365, 1.4054954051971436, 1.3995243310928345, 1.3935524225234985, 1.387514591217041, 1.3815120458602905, 1.375512719154358, 1.3694406747817993, 1.3635472059249878, 1.3572359085083008, 1.3510992527008057, 1.344842553138733, 1.3383896350860596, 1.331999659538269, 1.3253651857376099, 1.3178595304489136, 1.3107450008392334, 1.3025845289230347, 1.2948098182678223, 1.2861064672470093, 1.2782058715820312, 1.270777940750122, 1.2647627592086792, 1.2575221061706543, 1.2514814138412476, 1.246852159500122, 1.2410931587219238, 1.2392823696136475, 1.2332673072814941, 1.2268140316009521, 1.2222506999969482, 1.2183873653411865, 1.2140274047851562, 1.2101988792419434, 1.20667564868927, 1.2044003009796143, 1.2010401487350464, 1.1951305866241455, 1.190956950187683, 1.1883782148361206, 1.1859050989151, 1.1805745363235474, 1.1774007081985474, 1.1744319200515747, 1.1709349155426025, 1.1673922538757324, 1.1649503707885742, 1.1612417697906494, 1.1595343351364136, 1.1575167179107666, 1.1534959077835083, 1.150511622428894, 1.1487895250320435, 1.1462647914886475, 1.1445138454437256, 1.1413605213165283, 1.137712836265564, 1.1355547904968262, 1.1324093341827393, 1.1322546005249023, 1.1288431882858276, 1.1265515089035034, 1.1258713006973267, 1.1228538751602173, 1.121086597442627, 1.119505524635315, 1.119850993156433, 1.1160625219345093, 1.113404631614685, 1.1119544506072998, 1.1088204383850098, 1.1090970039367676, 1.1115835905075073, 1.103987693786621, 1.107898473739624, 1.1027891635894775, 1.1007678508758545, 1.0998156070709229, 1.0981591939926147, 1.0971657037734985, 1.0933127403259277, 1.0930613279342651, 1.0970903635025024, 1.0929701328277588, 1.093530535697937, 1.092113971710205, 1.0897059440612793, 1.0881835222244263, 1.0881619453430176, 1.086353063583374, 1.0850545167922974, 1.0894386768341064, 1.086943507194519, 1.0877989530563354, 1.0872951745986938, 1.1036217212677002, 1.0861589908599854], 'val_accuracy': [0.5915948152542114, 0.4989224076271057, 0.5021551847457886, 0.4903017282485962, 0.4978448152542114, 0.4978448152542114, 0.5086206793785095, 0.5258620977401733, 0.5237069129943848, 0.5280172228813171, 0.5474137663841248, 0.548491358757019, 0.5614224076271057, 0.568965494632721, 0.5786637663841248, 0.5840517282485962, 0.5948275923728943, 0.5959051847457886, 0.5991379022598267, 0.5969827771186829, 0.6034482717514038, 0.6045258641242981, 0.6023706793785095, 0.6066810488700867, 0.6120689511299133, 0.607758641242981, 0.610991358757019, 0.6174569129943848, 0.618534505367279, 0.6206896305084229, 0.5969827771186829, 0.6239224076271057, 0.6163793206214905, 0.6163793206214905, 0.6163793206214905, 0.6142241358757019, 0.6206896305084229, 0.6196120977401733, 0.6303879022598267, 0.6088362336158752, 0.6153017282485962, 0.6260775923728943, 0.6228448152542114, 0.6066810488700867, 0.6239224076271057, 0.625, 0.625, 0.6260775923728943, 0.6239224076271057, 0.618534505367279, 0.6228448152542114, 0.618534505367279, 0.6142241358757019, 0.6174569129943848, 0.6228448152542114, 0.6153017282485962, 0.618534505367279, 0.6206896305084229, 0.6282327771186829, 0.6271551847457886, 0.6282327771186829, 0.631465494632721, 0.631465494632721, 0.6303879022598267, 0.631465494632721, 0.6293103694915771, 0.6336206793785095, 0.6325430870056152, 0.6282327771186829, 0.631465494632721, 0.6239224076271057, 0.6271551847457886, 0.6260775923728943, 0.631465494632721, 0.6293103694915771, 0.6271551847457886, 0.6260775923728943, 0.6271551847457886, 0.6379310488700867, 0.631465494632721, 0.6239224076271057, 0.6239224076271057, 0.625, 0.6206896305084229, 0.6303879022598267, 0.6293103694915771, 0.6228448152542114, 0.6271551847457886, 0.6206896305084229, 0.6196120977401733, 0.625, 0.6174569129943848, 0.6206896305084229, 0.6196120977401733, 0.6131465435028076, 0.6228448152542114, 0.6217672228813171, 0.618534505367279, 0.6196120977401733, 0.6196120977401733]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 7s 51ms/step - loss: 1.4333 - accuracy: 0.4929 - val_loss: 1.4302 - val_accuracy: 0.5373\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 2/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4270 - accuracy: 0.5167 - val_loss: 1.4242 - val_accuracy: 0.5305\n","Epoch 3/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.4209 - accuracy: 0.5379 - val_loss: 1.4183 - val_accuracy: 0.5113\n","Epoch 4/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.4148 - accuracy: 0.5447 - val_loss: 1.4124 - val_accuracy: 0.5079\n","Epoch 5/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.4087 - accuracy: 0.5538 - val_loss: 1.4065 - val_accuracy: 0.5113\n","Epoch 6/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.4027 - accuracy: 0.5628 - val_loss: 1.4008 - val_accuracy: 0.5113\n","Epoch 7/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3967 - accuracy: 0.5572 - val_loss: 1.3950 - val_accuracy: 0.5170\n","Epoch 8/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3906 - accuracy: 0.5656 - val_loss: 1.3893 - val_accuracy: 0.5181\n","Epoch 9/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3845 - accuracy: 0.5741 - val_loss: 1.3836 - val_accuracy: 0.5170\n","Epoch 10/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3787 - accuracy: 0.5727 - val_loss: 1.3780 - val_accuracy: 0.5215\n","Epoch 11/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3727 - accuracy: 0.5722 - val_loss: 1.3724 - val_accuracy: 0.5238\n","Epoch 12/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3668 - accuracy: 0.5722 - val_loss: 1.3668 - val_accuracy: 0.5283\n","Epoch 13/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3608 - accuracy: 0.5753 - val_loss: 1.3612 - val_accuracy: 0.5351\n","Epoch 14/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3552 - accuracy: 0.5739 - val_loss: 1.3557 - val_accuracy: 0.5373\n","Epoch 15/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.3491 - accuracy: 0.5750 - val_loss: 1.3501 - val_accuracy: 0.5486\n","Epoch 16/100\n","28/28 [==============================] - 1s 31ms/step - loss: 1.3433 - accuracy: 0.5826 - val_loss: 1.3446 - val_accuracy: 0.5645\n","Epoch 17/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.3373 - accuracy: 0.5823 - val_loss: 1.3390 - val_accuracy: 0.5713\n","Epoch 18/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3311 - accuracy: 0.5872 - val_loss: 1.3335 - val_accuracy: 0.5701\n","Epoch 19/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3249 - accuracy: 0.5866 - val_loss: 1.3278 - val_accuracy: 0.5656\n","Epoch 20/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3189 - accuracy: 0.5897 - val_loss: 1.3221 - val_accuracy: 0.5701\n","Epoch 21/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.3125 - accuracy: 0.5979 - val_loss: 1.3162 - val_accuracy: 0.5781\n","Epoch 22/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.3059 - accuracy: 0.5937 - val_loss: 1.3103 - val_accuracy: 0.5792\n","Epoch 23/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.3001 - accuracy: 0.5968 - val_loss: 1.3044 - val_accuracy: 0.5803\n","Epoch 24/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.2931 - accuracy: 0.6010 - val_loss: 1.2988 - val_accuracy: 0.5837\n","Epoch 25/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.2867 - accuracy: 0.6050 - val_loss: 1.2930 - val_accuracy: 0.5803\n","Epoch 26/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.2800 - accuracy: 0.6038 - val_loss: 1.2875 - val_accuracy: 0.5803\n","Epoch 27/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.2746 - accuracy: 0.6067 - val_loss: 1.2819 - val_accuracy: 0.5848\n","Epoch 28/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2673 - accuracy: 0.6140 - val_loss: 1.2766 - val_accuracy: 0.5814\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2620 - accuracy: 0.6126 - val_loss: 1.2720 - val_accuracy: 0.5814\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2554 - accuracy: 0.6143 - val_loss: 1.2667 - val_accuracy: 0.5837\n","Epoch 31/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.2494 - accuracy: 0.6191 - val_loss: 1.2617 - val_accuracy: 0.5724\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2439 - accuracy: 0.6169 - val_loss: 1.2572 - val_accuracy: 0.5792\n","Epoch 33/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.2379 - accuracy: 0.6154 - val_loss: 1.2554 - val_accuracy: 0.5758\n","Epoch 34/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.2310 - accuracy: 0.6205 - val_loss: 1.2506 - val_accuracy: 0.5747\n","Epoch 35/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2260 - accuracy: 0.6234 - val_loss: 1.2456 - val_accuracy: 0.5882\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2213 - accuracy: 0.6231 - val_loss: 1.2433 - val_accuracy: 0.5781\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2145 - accuracy: 0.6239 - val_loss: 1.2364 - val_accuracy: 0.5871\n","Epoch 38/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2100 - accuracy: 0.6245 - val_loss: 1.2327 - val_accuracy: 0.5905\n","Epoch 39/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.2044 - accuracy: 0.6276 - val_loss: 1.2291 - val_accuracy: 0.5984\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1978 - accuracy: 0.6282 - val_loss: 1.2255 - val_accuracy: 0.5950\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1936 - accuracy: 0.6310 - val_loss: 1.2216 - val_accuracy: 0.5950\n","Epoch 42/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1880 - accuracy: 0.6310 - val_loss: 1.2225 - val_accuracy: 0.5826\n","Epoch 43/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1848 - accuracy: 0.6290 - val_loss: 1.2146 - val_accuracy: 0.5882\n","Epoch 44/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1793 - accuracy: 0.6344 - val_loss: 1.2113 - val_accuracy: 0.5962\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1725 - accuracy: 0.6372 - val_loss: 1.2077 - val_accuracy: 0.5939\n","Epoch 46/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1697 - accuracy: 0.6316 - val_loss: 1.2042 - val_accuracy: 0.5939\n","Epoch 47/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1649 - accuracy: 0.6412 - val_loss: 1.2007 - val_accuracy: 0.5973\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1587 - accuracy: 0.6387 - val_loss: 1.1974 - val_accuracy: 0.5962\n","Epoch 49/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1528 - accuracy: 0.6398 - val_loss: 1.1940 - val_accuracy: 0.5973\n","Epoch 50/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1515 - accuracy: 0.6423 - val_loss: 1.1919 - val_accuracy: 0.5894\n","Epoch 51/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1451 - accuracy: 0.6457 - val_loss: 1.1876 - val_accuracy: 0.5905\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1415 - accuracy: 0.6463 - val_loss: 1.1842 - val_accuracy: 0.5950\n","Epoch 53/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1341 - accuracy: 0.6463 - val_loss: 1.1810 - val_accuracy: 0.5950\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1288 - accuracy: 0.6525 - val_loss: 1.1825 - val_accuracy: 0.5814\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1258 - accuracy: 0.6545 - val_loss: 1.1770 - val_accuracy: 0.5950\n","Epoch 56/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.1197 - accuracy: 0.6553 - val_loss: 1.1728 - val_accuracy: 0.5995\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1158 - accuracy: 0.6599 - val_loss: 1.1701 - val_accuracy: 0.5848\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1116 - accuracy: 0.6556 - val_loss: 1.1668 - val_accuracy: 0.5916\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1030 - accuracy: 0.6613 - val_loss: 1.1637 - val_accuracy: 0.5916\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1014 - accuracy: 0.6607 - val_loss: 1.1611 - val_accuracy: 0.5905\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0925 - accuracy: 0.6723 - val_loss: 1.1612 - val_accuracy: 0.5871\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0906 - accuracy: 0.6607 - val_loss: 1.1579 - val_accuracy: 0.5871\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0824 - accuracy: 0.6681 - val_loss: 1.1542 - val_accuracy: 0.5939\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0825 - accuracy: 0.6667 - val_loss: 1.1511 - val_accuracy: 0.5962\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0748 - accuracy: 0.6777 - val_loss: 1.1492 - val_accuracy: 0.5928\n","Epoch 66/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0706 - accuracy: 0.6692 - val_loss: 1.1467 - val_accuracy: 0.5939\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0644 - accuracy: 0.6771 - val_loss: 1.1447 - val_accuracy: 0.5905\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0596 - accuracy: 0.6805 - val_loss: 1.1463 - val_accuracy: 0.5894\n","Epoch 69/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.0589 - accuracy: 0.6797 - val_loss: 1.1392 - val_accuracy: 0.6052\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0503 - accuracy: 0.6842 - val_loss: 1.1394 - val_accuracy: 0.5973\n","Epoch 71/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0423 - accuracy: 0.6890 - val_loss: 1.1356 - val_accuracy: 0.5995\n","Epoch 72/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0405 - accuracy: 0.6924 - val_loss: 1.1386 - val_accuracy: 0.5905\n","Epoch 73/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0373 - accuracy: 0.6845 - val_loss: 1.1366 - val_accuracy: 0.5962\n","Epoch 74/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0329 - accuracy: 0.6851 - val_loss: 1.1324 - val_accuracy: 0.5973\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0250 - accuracy: 0.6967 - val_loss: 1.1268 - val_accuracy: 0.6007\n","Epoch 76/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.0202 - accuracy: 0.6941 - val_loss: 1.1257 - val_accuracy: 0.6075\n","Epoch 77/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0155 - accuracy: 0.6975 - val_loss: 1.1233 - val_accuracy: 0.6041\n","Epoch 78/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0119 - accuracy: 0.6930 - val_loss: 1.1214 - val_accuracy: 0.6018\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0073 - accuracy: 0.6969 - val_loss: 1.1229 - val_accuracy: 0.5928\n","Epoch 80/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0004 - accuracy: 0.7015 - val_loss: 1.1176 - val_accuracy: 0.6075\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9992 - accuracy: 0.7035 - val_loss: 1.1149 - val_accuracy: 0.6029\n","Epoch 82/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9933 - accuracy: 0.6984 - val_loss: 1.1138 - val_accuracy: 0.6052\n","Epoch 83/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9872 - accuracy: 0.7029 - val_loss: 1.1148 - val_accuracy: 0.6075\n","Epoch 84/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9833 - accuracy: 0.7037 - val_loss: 1.1226 - val_accuracy: 0.5905\n","Epoch 85/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.9779 - accuracy: 0.7035 - val_loss: 1.1208 - val_accuracy: 0.5894\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9769 - accuracy: 0.7049 - val_loss: 1.1091 - val_accuracy: 0.6075\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9667 - accuracy: 0.7156 - val_loss: 1.1117 - val_accuracy: 0.5973\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9633 - accuracy: 0.7233 - val_loss: 1.1064 - val_accuracy: 0.6052\n","Epoch 89/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9584 - accuracy: 0.7151 - val_loss: 1.1083 - val_accuracy: 0.6063\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9548 - accuracy: 0.7142 - val_loss: 1.1054 - val_accuracy: 0.6041\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9523 - accuracy: 0.7170 - val_loss: 1.1060 - val_accuracy: 0.5973\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9459 - accuracy: 0.7244 - val_loss: 1.1033 - val_accuracy: 0.5962\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9429 - accuracy: 0.7162 - val_loss: 1.1010 - val_accuracy: 0.6075\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9356 - accuracy: 0.7199 - val_loss: 1.1018 - val_accuracy: 0.5995\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9291 - accuracy: 0.7286 - val_loss: 1.1019 - val_accuracy: 0.5995\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9257 - accuracy: 0.7269 - val_loss: 1.0975 - val_accuracy: 0.5973\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9220 - accuracy: 0.7267 - val_loss: 1.0971 - val_accuracy: 0.6041\n","Epoch 98/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9140 - accuracy: 0.7301 - val_loss: 1.1002 - val_accuracy: 0.5984\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9074 - accuracy: 0.7405 - val_loss: 1.1005 - val_accuracy: 0.6041\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9056 - accuracy: 0.7295 - val_loss: 1.1186 - val_accuracy: 0.5928\n","{'loss': [1.4332807064056396, 1.427032470703125, 1.420943021774292, 1.4148328304290771, 1.4086989164352417, 1.4026820659637451, 1.3966877460479736, 1.3906199932098389, 1.3845024108886719, 1.3786673545837402, 1.3726950883865356, 1.3667644262313843, 1.3607531785964966, 1.3551579713821411, 1.3491061925888062, 1.3433423042297363, 1.3372890949249268, 1.3311171531677246, 1.3249118328094482, 1.3188990354537964, 1.312469482421875, 1.3059275150299072, 1.300074577331543, 1.293142318725586, 1.2867385149002075, 1.2800368070602417, 1.2746301889419556, 1.267297387123108, 1.2619638442993164, 1.255440354347229, 1.2494004964828491, 1.243857502937317, 1.2378970384597778, 1.231016755104065, 1.226016640663147, 1.2212858200073242, 1.2144941091537476, 1.2100400924682617, 1.2044483423233032, 1.1978304386138916, 1.1936427354812622, 1.188038945198059, 1.1848286390304565, 1.1792551279067993, 1.1724857091903687, 1.169703483581543, 1.1648528575897217, 1.1587109565734863, 1.1527608633041382, 1.1514941453933716, 1.1450902223587036, 1.141467571258545, 1.134138822555542, 1.1288310289382935, 1.1257877349853516, 1.119715929031372, 1.1158475875854492, 1.1115832328796387, 1.1029764413833618, 1.1014189720153809, 1.092469573020935, 1.090625524520874, 1.0823925733566284, 1.0824568271636963, 1.0747908353805542, 1.0706278085708618, 1.0643659830093384, 1.0596261024475098, 1.058938980102539, 1.0502862930297852, 1.0422831773757935, 1.0405019521713257, 1.0373390913009644, 1.0329499244689941, 1.0249751806259155, 1.020209789276123, 1.01547110080719, 1.0119304656982422, 1.0073217153549194, 1.000364065170288, 0.9992344379425049, 0.9932948350906372, 0.9871510863304138, 0.9832829833030701, 0.9779142737388611, 0.9768932461738586, 0.9667023420333862, 0.9633227586746216, 0.9584425687789917, 0.9548351168632507, 0.9522740244865417, 0.9458966255187988, 0.9428719282150269, 0.9355536699295044, 0.9290722608566284, 0.9256821870803833, 0.9219908714294434, 0.9139963388442993, 0.9073625206947327, 0.9056283831596375], 'accuracy': [0.49292585253715515, 0.516694962978363, 0.5379173755645752, 0.5447085499763489, 0.5537634491920471, 0.5628183484077454, 0.5571590065956116, 0.5656480193138123, 0.5741369724273682, 0.5727221369743347, 0.5721561908721924, 0.5721561908721924, 0.5752688050270081, 0.5738539695739746, 0.5749858617782593, 0.5826259255409241, 0.5823429822921753, 0.5871533751487732, 0.5865874290466309, 0.5897000432014465, 0.5979060530662537, 0.5936615467071533, 0.5967742204666138, 0.6010186672210693, 0.6049801707267761, 0.6038483381271362, 0.6066780090332031, 0.6140350699424744, 0.6126202344894409, 0.6143180727958679, 0.6191284656524658, 0.6168647408485413, 0.6154499053955078, 0.6205433011054993, 0.6233729720115662, 0.6230899691581726, 0.6239388585090637, 0.624504804611206, 0.6276174187660217, 0.6281833648681641, 0.631013035774231, 0.631013035774231, 0.6290322542190552, 0.6344085931777954, 0.6372382640838623, 0.6315789222717285, 0.6411997675895691, 0.6386530995368958, 0.6397849321365356, 0.6423316597938538, 0.6457272171974182, 0.6462931632995605, 0.6462931632995605, 0.6525183916091919, 0.6544991731643677, 0.6553480625152588, 0.6598755121231079, 0.6556310057640076, 0.6612903475761414, 0.660724401473999, 0.6723259687423706, 0.660724401473999, 0.668081521987915, 0.6666666865348816, 0.6777023077011108, 0.6692133545875549, 0.6771363615989685, 0.6805319786071777, 0.6796830892562866, 0.6842105388641357, 0.6890209317207336, 0.6924165487289429, 0.6844934821128845, 0.6850594282150269, 0.6966609954833984, 0.6941143274307251, 0.6975098848342896, 0.6929824352264404, 0.696943998336792, 0.7014714479446411, 0.7034521698951721, 0.6983587741851807, 0.7028862237930298, 0.7037351727485657, 0.7034521698951721, 0.7048670053482056, 0.715619683265686, 0.7232597470283508, 0.7150537371635437, 0.7142048478126526, 0.7170345187187195, 0.7243916392326355, 0.7161856293678284, 0.7198641896247864, 0.7286360859870911, 0.7269383072853088, 0.7266553640365601, 0.7300509214401245, 0.7405206561088562, 0.7294849753379822], 'val_loss': [1.4301546812057495, 1.4241787195205688, 1.4182522296905518, 1.4123752117156982, 1.4065393209457397, 1.4007596969604492, 1.3950090408325195, 1.3893089294433594, 1.3836426734924316, 1.3780019283294678, 1.3723511695861816, 1.3667984008789062, 1.36118483543396, 1.3556759357452393, 1.3501124382019043, 1.3445502519607544, 1.3390357494354248, 1.333455204963684, 1.327765941619873, 1.3220990896224976, 1.3161641359329224, 1.3103315830230713, 1.3044496774673462, 1.2987537384033203, 1.2929741144180298, 1.2874822616577148, 1.2818825244903564, 1.2766064405441284, 1.271997094154358, 1.2666701078414917, 1.2617350816726685, 1.2571667432785034, 1.255385160446167, 1.2506464719772339, 1.2456308603286743, 1.2432960271835327, 1.2364240884780884, 1.2327316999435425, 1.2291171550750732, 1.2255321741104126, 1.221574306488037, 1.2224863767623901, 1.2146002054214478, 1.2112915515899658, 1.2077076435089111, 1.2042142152786255, 1.200726866722107, 1.1973756551742554, 1.1939512491226196, 1.1919012069702148, 1.187603235244751, 1.184237003326416, 1.1809747219085693, 1.1824551820755005, 1.176962971687317, 1.172758936882019, 1.170074701309204, 1.1667770147323608, 1.163712501525879, 1.161097764968872, 1.1611535549163818, 1.1578969955444336, 1.1541956663131714, 1.1511495113372803, 1.1492199897766113, 1.1467334032058716, 1.1446506977081299, 1.1462723016738892, 1.139235496520996, 1.139420747756958, 1.1355897188186646, 1.1386258602142334, 1.1366006135940552, 1.1324472427368164, 1.1267900466918945, 1.125673770904541, 1.1232534646987915, 1.1213606595993042, 1.1228992938995361, 1.1176286935806274, 1.1148936748504639, 1.1138088703155518, 1.1148422956466675, 1.1226390600204468, 1.1207891702651978, 1.1091395616531372, 1.1117247343063354, 1.106380581855774, 1.1083018779754639, 1.1054365634918213, 1.1059616804122925, 1.1033167839050293, 1.1010102033615112, 1.1018024682998657, 1.1018904447555542, 1.0974771976470947, 1.0970876216888428, 1.1001700162887573, 1.1004884243011475, 1.118636965751648], 'val_accuracy': [0.5373303294181824, 0.5305429697036743, 0.5113122463226318, 0.5079185366630554, 0.5113122463226318, 0.5113122463226318, 0.516968309879303, 0.5180995464324951, 0.516968309879303, 0.5214931964874268, 0.523755669593811, 0.5282805562019348, 0.5350678563117981, 0.5373303294181824, 0.5486425161361694, 0.564479649066925, 0.5712669491767883, 0.570135772228241, 0.5656108856201172, 0.570135772228241, 0.5780543088912964, 0.5791855454444885, 0.5803167223930359, 0.5837104320526123, 0.5803167223930359, 0.5803167223930359, 0.5848416090011597, 0.581447958946228, 0.581447958946228, 0.5837104320526123, 0.5723981857299805, 0.5791855454444885, 0.5757918357849121, 0.5746606588363647, 0.5882353186607361, 0.5780543088912964, 0.587104082107544, 0.5904977321624756, 0.598416268825531, 0.5950226187705994, 0.5950226187705994, 0.5825791954994202, 0.5882353186607361, 0.5961538553237915, 0.5938913822174072, 0.5938913822174072, 0.5972850918769836, 0.5961538553237915, 0.5972850918769836, 0.5893664956092834, 0.5904977321624756, 0.5950226187705994, 0.5950226187705994, 0.581447958946228, 0.5950226187705994, 0.5995475053787231, 0.5848416090011597, 0.5916289687156677, 0.5916289687156677, 0.5904977321624756, 0.587104082107544, 0.587104082107544, 0.5938913822174072, 0.5961538553237915, 0.5927602052688599, 0.5938913822174072, 0.5904977321624756, 0.5893664956092834, 0.6052036285400391, 0.5972850918769836, 0.5995475053787231, 0.5904977321624756, 0.5961538553237915, 0.5972850918769836, 0.6006787419319153, 0.6074660420417786, 0.6040723919868469, 0.6018099784851074, 0.5927602052688599, 0.6074660420417786, 0.6029411554336548, 0.6052036285400391, 0.6074660420417786, 0.5904977321624756, 0.5893664956092834, 0.6074660420417786, 0.5972850918769836, 0.6052036285400391, 0.6063348650932312, 0.6040723919868469, 0.5972850918769836, 0.5961538553237915, 0.6074660420417786, 0.5995475053787231, 0.5995475053787231, 0.5972850918769836, 0.6040723919868469, 0.598416268825531, 0.6040723919868469, 0.5927602052688599]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 8s 49ms/step - loss: 1.4330 - accuracy: 0.5003 - val_loss: 1.4295 - val_accuracy: 0.4917\n","Epoch 2/100\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 0s 13ms/step - loss: 1.4263 - accuracy: 0.5217 - val_loss: 1.4229 - val_accuracy: 0.4876\n","Epoch 3/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.4196 - accuracy: 0.5413 - val_loss: 1.4163 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.4129 - accuracy: 0.5651 - val_loss: 1.4098 - val_accuracy: 0.4804\n","Epoch 5/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4064 - accuracy: 0.5563 - val_loss: 1.4034 - val_accuracy: 0.4793\n","Epoch 6/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3999 - accuracy: 0.5543 - val_loss: 1.3970 - val_accuracy: 0.4824\n","Epoch 7/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3933 - accuracy: 0.5599 - val_loss: 1.3907 - val_accuracy: 0.4845\n","Epoch 8/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3868 - accuracy: 0.5705 - val_loss: 1.3844 - val_accuracy: 0.4907\n","Epoch 9/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.3804 - accuracy: 0.5625 - val_loss: 1.3781 - val_accuracy: 0.4948\n","Epoch 10/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.3740 - accuracy: 0.5605 - val_loss: 1.3719 - val_accuracy: 0.4990\n","Epoch 11/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.3675 - accuracy: 0.5664 - val_loss: 1.3656 - val_accuracy: 0.5072\n","Epoch 12/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.3611 - accuracy: 0.5623 - val_loss: 1.3594 - val_accuracy: 0.5134\n","Epoch 13/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.3548 - accuracy: 0.5693 - val_loss: 1.3532 - val_accuracy: 0.5196\n","Epoch 14/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.3484 - accuracy: 0.5760 - val_loss: 1.3470 - val_accuracy: 0.5300\n","Epoch 15/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.3419 - accuracy: 0.5739 - val_loss: 1.3406 - val_accuracy: 0.5640\n","Epoch 16/100\n","31/31 [==============================] - 1s 35ms/step - loss: 1.3352 - accuracy: 0.5850 - val_loss: 1.3342 - val_accuracy: 0.5775\n","Epoch 17/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.3286 - accuracy: 0.5920 - val_loss: 1.3278 - val_accuracy: 0.5837\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3221 - accuracy: 0.5925 - val_loss: 1.3212 - val_accuracy: 0.5837\n","Epoch 19/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3150 - accuracy: 0.5982 - val_loss: 1.3144 - val_accuracy: 0.5971\n","Epoch 20/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3084 - accuracy: 0.5969 - val_loss: 1.3075 - val_accuracy: 0.5857\n","Epoch 21/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3012 - accuracy: 0.6028 - val_loss: 1.3005 - val_accuracy: 0.5940\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2939 - accuracy: 0.5990 - val_loss: 1.2932 - val_accuracy: 0.5961\n","Epoch 23/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2862 - accuracy: 0.6070 - val_loss: 1.2858 - val_accuracy: 0.5981\n","Epoch 24/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2795 - accuracy: 0.6028 - val_loss: 1.2790 - val_accuracy: 0.6012\n","Epoch 25/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2713 - accuracy: 0.6003 - val_loss: 1.2721 - val_accuracy: 0.6012\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2638 - accuracy: 0.6057 - val_loss: 1.2658 - val_accuracy: 0.5775\n","Epoch 27/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.2563 - accuracy: 0.6171 - val_loss: 1.2585 - val_accuracy: 0.6012\n","Epoch 28/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2484 - accuracy: 0.6140 - val_loss: 1.2519 - val_accuracy: 0.5961\n","Epoch 29/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.2422 - accuracy: 0.6145 - val_loss: 1.2475 - val_accuracy: 0.5878\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2354 - accuracy: 0.6204 - val_loss: 1.2405 - val_accuracy: 0.6012\n","Epoch 31/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2281 - accuracy: 0.6165 - val_loss: 1.2353 - val_accuracy: 0.5981\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2210 - accuracy: 0.6227 - val_loss: 1.2307 - val_accuracy: 0.5971\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2150 - accuracy: 0.6176 - val_loss: 1.2263 - val_accuracy: 0.5971\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2089 - accuracy: 0.6207 - val_loss: 1.2230 - val_accuracy: 0.5868\n","Epoch 35/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.2029 - accuracy: 0.6284 - val_loss: 1.2177 - val_accuracy: 0.5919\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1980 - accuracy: 0.6295 - val_loss: 1.2145 - val_accuracy: 0.5878\n","Epoch 37/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1899 - accuracy: 0.6351 - val_loss: 1.2080 - val_accuracy: 0.5971\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1848 - accuracy: 0.6328 - val_loss: 1.2050 - val_accuracy: 0.5930\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1775 - accuracy: 0.6364 - val_loss: 1.2003 - val_accuracy: 0.5919\n","Epoch 40/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1710 - accuracy: 0.6424 - val_loss: 1.1964 - val_accuracy: 0.5940\n","Epoch 41/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.1672 - accuracy: 0.6388 - val_loss: 1.1960 - val_accuracy: 0.5981\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1627 - accuracy: 0.6429 - val_loss: 1.1883 - val_accuracy: 0.5981\n","Epoch 43/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1558 - accuracy: 0.6437 - val_loss: 1.1842 - val_accuracy: 0.5981\n","Epoch 44/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1505 - accuracy: 0.6390 - val_loss: 1.1811 - val_accuracy: 0.5992\n","Epoch 45/100\n","31/31 [==============================] - 1s 44ms/step - loss: 1.1422 - accuracy: 0.6525 - val_loss: 1.1790 - val_accuracy: 0.6033\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1387 - accuracy: 0.6478 - val_loss: 1.1775 - val_accuracy: 0.6012\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1340 - accuracy: 0.6532 - val_loss: 1.1733 - val_accuracy: 0.5888\n","Epoch 48/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1275 - accuracy: 0.6465 - val_loss: 1.1754 - val_accuracy: 0.5806\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1222 - accuracy: 0.6532 - val_loss: 1.1724 - val_accuracy: 0.5816\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1196 - accuracy: 0.6556 - val_loss: 1.1630 - val_accuracy: 0.5950\n","Epoch 51/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1091 - accuracy: 0.6649 - val_loss: 1.1616 - val_accuracy: 0.5992\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1055 - accuracy: 0.6574 - val_loss: 1.1586 - val_accuracy: 0.5899\n","Epoch 53/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1015 - accuracy: 0.6625 - val_loss: 1.1568 - val_accuracy: 0.5971\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0953 - accuracy: 0.6602 - val_loss: 1.1540 - val_accuracy: 0.5971\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0891 - accuracy: 0.6677 - val_loss: 1.1512 - val_accuracy: 0.5940\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0836 - accuracy: 0.6708 - val_loss: 1.1482 - val_accuracy: 0.5971\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0788 - accuracy: 0.6736 - val_loss: 1.1464 - val_accuracy: 0.6002\n","Epoch 58/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0755 - accuracy: 0.6646 - val_loss: 1.1419 - val_accuracy: 0.5868\n","Epoch 59/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0703 - accuracy: 0.6705 - val_loss: 1.1413 - val_accuracy: 0.5940\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0646 - accuracy: 0.6775 - val_loss: 1.1410 - val_accuracy: 0.5992\n","Epoch 61/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0569 - accuracy: 0.6762 - val_loss: 1.1365 - val_accuracy: 0.5971\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0494 - accuracy: 0.6876 - val_loss: 1.1346 - val_accuracy: 0.5857\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0492 - accuracy: 0.6817 - val_loss: 1.1342 - val_accuracy: 0.5930\n","Epoch 64/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0450 - accuracy: 0.6806 - val_loss: 1.1325 - val_accuracy: 0.5940\n","Epoch 65/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0339 - accuracy: 0.6842 - val_loss: 1.1298 - val_accuracy: 0.5940\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0297 - accuracy: 0.6889 - val_loss: 1.1287 - val_accuracy: 0.5950\n","Epoch 67/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0334 - accuracy: 0.6824 - val_loss: 1.1286 - val_accuracy: 0.5930\n","Epoch 68/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0277 - accuracy: 0.6902 - val_loss: 1.1247 - val_accuracy: 0.5919\n","Epoch 69/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0170 - accuracy: 0.6922 - val_loss: 1.1211 - val_accuracy: 0.5909\n","Epoch 70/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0124 - accuracy: 0.6899 - val_loss: 1.1180 - val_accuracy: 0.6033\n","Epoch 71/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0091 - accuracy: 0.6951 - val_loss: 1.1193 - val_accuracy: 0.5909\n","Epoch 72/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0049 - accuracy: 0.6956 - val_loss: 1.1176 - val_accuracy: 0.6002\n","Epoch 73/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9976 - accuracy: 0.7018 - val_loss: 1.1172 - val_accuracy: 0.5971\n","Epoch 74/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9934 - accuracy: 0.7013 - val_loss: 1.1146 - val_accuracy: 0.6023\n","Epoch 75/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9880 - accuracy: 0.6984 - val_loss: 1.1148 - val_accuracy: 0.6012\n","Epoch 76/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9846 - accuracy: 0.7008 - val_loss: 1.1136 - val_accuracy: 0.6033\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9804 - accuracy: 0.7021 - val_loss: 1.1144 - val_accuracy: 0.5930\n","Epoch 78/100\n","31/31 [==============================] - 1s 41ms/step - loss: 0.9795 - accuracy: 0.7005 - val_loss: 1.1200 - val_accuracy: 0.6064\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9701 - accuracy: 0.7059 - val_loss: 1.1084 - val_accuracy: 0.5981\n","Epoch 80/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9646 - accuracy: 0.7083 - val_loss: 1.1053 - val_accuracy: 0.6085\n","Epoch 81/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9621 - accuracy: 0.7083 - val_loss: 1.1139 - val_accuracy: 0.5971\n","Epoch 82/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9547 - accuracy: 0.7140 - val_loss: 1.1038 - val_accuracy: 0.6126\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9502 - accuracy: 0.7096 - val_loss: 1.1075 - val_accuracy: 0.6074\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9450 - accuracy: 0.7119 - val_loss: 1.1120 - val_accuracy: 0.5981\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9418 - accuracy: 0.7202 - val_loss: 1.1111 - val_accuracy: 0.6136\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9390 - accuracy: 0.7147 - val_loss: 1.0995 - val_accuracy: 0.6136\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9280 - accuracy: 0.7176 - val_loss: 1.1038 - val_accuracy: 0.6116\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9284 - accuracy: 0.7189 - val_loss: 1.0966 - val_accuracy: 0.6095\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9218 - accuracy: 0.7240 - val_loss: 1.1045 - val_accuracy: 0.6012\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9160 - accuracy: 0.7274 - val_loss: 1.1005 - val_accuracy: 0.6012\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9199 - accuracy: 0.7243 - val_loss: 1.1314 - val_accuracy: 0.6116\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9193 - accuracy: 0.7217 - val_loss: 1.0956 - val_accuracy: 0.6126\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9024 - accuracy: 0.7341 - val_loss: 1.0937 - val_accuracy: 0.6116\n","Epoch 94/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8974 - accuracy: 0.7377 - val_loss: 1.1013 - val_accuracy: 0.6198\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8959 - accuracy: 0.7339 - val_loss: 1.0957 - val_accuracy: 0.6116\n","Epoch 96/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8912 - accuracy: 0.7349 - val_loss: 1.1043 - val_accuracy: 0.6147\n","Epoch 97/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8889 - accuracy: 0.7318 - val_loss: 1.0960 - val_accuracy: 0.6157\n","Epoch 98/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8759 - accuracy: 0.7450 - val_loss: 1.0988 - val_accuracy: 0.6116\n","Epoch 99/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8807 - accuracy: 0.7421 - val_loss: 1.0949 - val_accuracy: 0.6157\n","Epoch 100/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8714 - accuracy: 0.7421 - val_loss: 1.0986 - val_accuracy: 0.6178\n","{'loss': [1.4329938888549805, 1.4262669086456299, 1.4196112155914307, 1.4129416942596436, 1.4064160585403442, 1.399867057800293, 1.393314242362976, 1.3868212699890137, 1.3803596496582031, 1.3740119934082031, 1.3675260543823242, 1.3611340522766113, 1.3548243045806885, 1.3483591079711914, 1.3418644666671753, 1.335202932357788, 1.3286325931549072, 1.322124719619751, 1.3150012493133545, 1.3084040880203247, 1.3011869192123413, 1.293885350227356, 1.2861725091934204, 1.2794724702835083, 1.2712870836257935, 1.2638218402862549, 1.2563464641571045, 1.2483834028244019, 1.2422384023666382, 1.2354228496551514, 1.228149652481079, 1.2210334539413452, 1.21503484249115, 1.2088589668273926, 1.2028989791870117, 1.1979594230651855, 1.1899021863937378, 1.1848379373550415, 1.1775151491165161, 1.171046495437622, 1.1672403812408447, 1.1627452373504639, 1.1558351516723633, 1.1504698991775513, 1.1421922445297241, 1.1386823654174805, 1.1339600086212158, 1.1275138854980469, 1.1222398281097412, 1.119583010673523, 1.109134554862976, 1.1055080890655518, 1.1015383005142212, 1.0953447818756104, 1.089072346687317, 1.083604335784912, 1.0787944793701172, 1.0755027532577515, 1.0703139305114746, 1.0646089315414429, 1.0569030046463013, 1.049441933631897, 1.049157738685608, 1.045009970664978, 1.0339187383651733, 1.0297499895095825, 1.0334227085113525, 1.0277113914489746, 1.0169613361358643, 1.0124071836471558, 1.0091328620910645, 1.0049395561218262, 0.9976082444190979, 0.9934319853782654, 0.9880281090736389, 0.9845600128173828, 0.9803966879844666, 0.9794844388961792, 0.9701089262962341, 0.9646053314208984, 0.9621129631996155, 0.9546845555305481, 0.9502289295196533, 0.9449994564056396, 0.9417568445205688, 0.938974916934967, 0.9280317425727844, 0.9283618330955505, 0.9218135476112366, 0.9159751534461975, 0.9199219942092896, 0.9192769527435303, 0.9023882150650024, 0.8974350690841675, 0.8959383964538574, 0.8911789655685425, 0.888852596282959, 0.8758972883224487, 0.8806563019752502, 0.8714262843132019], 'accuracy': [0.5002583861351013, 0.5217054486274719, 0.5413436889648438, 0.565116286277771, 0.5563307404518127, 0.5542635917663574, 0.5599483251571655, 0.5705426335334778, 0.5625323057174683, 0.5604650974273682, 0.5664082765579224, 0.5622739195823669, 0.5692506432533264, 0.5759689807891846, 0.5739018321037292, 0.5850129127502441, 0.5919896364212036, 0.592506468296051, 0.5981912016868591, 0.5968992114067078, 0.602842390537262, 0.5989664196968079, 0.6069767475128174, 0.602842390537262, 0.6002584099769592, 0.605684757232666, 0.617054283618927, 0.6139534711837769, 0.6144703030586243, 0.6204134225845337, 0.6165374517440796, 0.6227390170097351, 0.6175710558891296, 0.620671808719635, 0.6284237504005432, 0.6294573545455933, 0.6351421475410461, 0.6328165531158447, 0.6364341378211975, 0.6423772573471069, 0.6387596726417542, 0.6428940296173096, 0.6436692476272583, 0.6390180587768555, 0.6524547934532166, 0.6478036046028137, 0.6532299518585205, 0.6465116143226624, 0.6532299518585205, 0.6555555462837219, 0.6648578643798828, 0.6573643684387207, 0.6625322699546814, 0.6602067351341248, 0.6677002310752869, 0.670801043510437, 0.6736434102058411, 0.6645994782447815, 0.6705426573753357, 0.6775193810462952, 0.6762273907661438, 0.6875969171524048, 0.6816537380218506, 0.6806201338768005, 0.6842377185821533, 0.6888889074325562, 0.6824289560317993, 0.6901808977127075, 0.6922480463981628, 0.6899224519729614, 0.6950904130935669, 0.6956072449684143, 0.7018088102340698, 0.7012919783592224, 0.6984496116638184, 0.7007752060890198, 0.7020671963691711, 0.7005168199539185, 0.7059431672096252, 0.7082687616348267, 0.7082687616348267, 0.7139534950256348, 0.709560751914978, 0.7118862867355347, 0.7201550602912903, 0.7147286534309387, 0.7175710797309875, 0.7188630700111389, 0.7240310311317444, 0.7273901700973511, 0.7242894172668457, 0.721705436706543, 0.7341085076332092, 0.737726092338562, 0.7338501214981079, 0.734883725643158, 0.7317829728126526, 0.7449612617492676, 0.7421188354492188, 0.7421188354492188], 'val_loss': [1.4294899702072144, 1.4228767156600952, 1.4163249731063843, 1.4098464250564575, 1.403406023979187, 1.3970228433609009, 1.3906781673431396, 1.384385347366333, 1.3781273365020752, 1.3718856573104858, 1.3656151294708252, 1.3594129085540771, 1.3531692028045654, 1.3469879627227783, 1.3406097888946533, 1.334241271018982, 1.327771544456482, 1.3212227821350098, 1.3143932819366455, 1.30752432346344, 1.3004525899887085, 1.29320228099823, 1.2858128547668457, 1.279015302658081, 1.2721188068389893, 1.2657588720321655, 1.2584811449050903, 1.25187349319458, 1.2475157976150513, 1.2405027151107788, 1.2353472709655762, 1.230747103691101, 1.2262994050979614, 1.2230054140090942, 1.2176690101623535, 1.2144501209259033, 1.2080239057540894, 1.2049809694290161, 1.2003130912780762, 1.1963757276535034, 1.196012020111084, 1.1883152723312378, 1.1841623783111572, 1.1810661554336548, 1.1790342330932617, 1.1774803400039673, 1.173276662826538, 1.1753846406936646, 1.1723923683166504, 1.1630489826202393, 1.1615500450134277, 1.1585956811904907, 1.156842827796936, 1.153975009918213, 1.151222825050354, 1.1481727361679077, 1.1463581323623657, 1.1418607234954834, 1.1412923336029053, 1.1409705877304077, 1.1364995241165161, 1.1346218585968018, 1.1341609954833984, 1.13249933719635, 1.129846453666687, 1.128747820854187, 1.128584623336792, 1.1246981620788574, 1.1211460828781128, 1.1180286407470703, 1.1192835569381714, 1.1176098585128784, 1.1172142028808594, 1.1146228313446045, 1.114769458770752, 1.1135879755020142, 1.1144413948059082, 1.119988203048706, 1.1084189414978027, 1.105299949645996, 1.1139371395111084, 1.103800892829895, 1.1075265407562256, 1.1119961738586426, 1.11111319065094, 1.099537968635559, 1.103763222694397, 1.0966061353683472, 1.1044856309890747, 1.1004810333251953, 1.131382942199707, 1.095600962638855, 1.0936630964279175, 1.1013189554214478, 1.0956660509109497, 1.1043459177017212, 1.0959694385528564, 1.098848819732666, 1.0948511362075806, 1.0986067056655884], 'val_accuracy': [0.4917355477809906, 0.4876033067703247, 0.48553720116615295, 0.48037189245224, 0.4793388545513153, 0.48243802785873413, 0.4845041334629059, 0.49070248007774353, 0.4948347210884094, 0.49896693229675293, 0.5072314143180847, 0.5134297609329224, 0.51962810754776, 0.5299586653709412, 0.5640496015548706, 0.577479362487793, 0.5836777091026306, 0.5836777091026306, 0.5971074104309082, 0.58574378490448, 0.5940082669258118, 0.5960744023323059, 0.5981404781341553, 0.6012396812438965, 0.6012396812438965, 0.577479362487793, 0.6012396812438965, 0.5960744023323059, 0.5878099203109741, 0.6012396812438965, 0.5981404781341553, 0.5971074104309082, 0.5971074104309082, 0.586776852607727, 0.5919421315193176, 0.5878099203109741, 0.5971074104309082, 0.5929751992225647, 0.5919421315193176, 0.5940082669258118, 0.5981404781341553, 0.5981404781341553, 0.5981404781341553, 0.5991735458374023, 0.6033057570457458, 0.6012396812438965, 0.5888429880142212, 0.5805785059928894, 0.5816115736961365, 0.5950413346290588, 0.5991735458374023, 0.5898760557174683, 0.5971074104309082, 0.5971074104309082, 0.5940082669258118, 0.5971074104309082, 0.6002066135406494, 0.586776852607727, 0.5940082669258118, 0.5991735458374023, 0.5971074104309082, 0.58574378490448, 0.5929751992225647, 0.5940082669258118, 0.5940082669258118, 0.5950413346290588, 0.5929751992225647, 0.5919421315193176, 0.5909090638160706, 0.6033057570457458, 0.5909090638160706, 0.6002066135406494, 0.5971074104309082, 0.6022727489471436, 0.6012396812438965, 0.6033057570457458, 0.5929751992225647, 0.6064049601554871, 0.5981404781341553, 0.6084710955619812, 0.5971074104309082, 0.6126033067703247, 0.6074380278587341, 0.5981404781341553, 0.6136363744735718, 0.6136363744735718, 0.6115702390670776, 0.6095041036605835, 0.6012396812438965, 0.6012396812438965, 0.6115702390670776, 0.6126033067703247, 0.6115702390670776, 0.6198347210884094, 0.6115702390670776, 0.6146694421768188, 0.6157024502754211, 0.6115702390670776, 0.6157024502754211, 0.6177685856819153]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.9629 - accuracy: 0.6860"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 6s 49ms/step - loss: 0.9624 - accuracy: 0.6875 - val_loss: 1.0617 - val_accuracy: 0.4892\n","Epoch 2/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.9548 - accuracy: 0.6945 - val_loss: 1.0580 - val_accuracy: 0.4925\n","Epoch 3/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.9461 - accuracy: 0.6975 - val_loss: 1.0554 - val_accuracy: 0.4946\n","Epoch 4/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9402 - accuracy: 0.7053 - val_loss: 1.0528 - val_accuracy: 0.4935\n","Epoch 5/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.9394 - accuracy: 0.6996 - val_loss: 1.0458 - val_accuracy: 0.5065\n","Epoch 6/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.9325 - accuracy: 0.7034 - val_loss: 1.0409 - val_accuracy: 0.5140\n","Epoch 7/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.9204 - accuracy: 0.7115 - val_loss: 1.0368 - val_accuracy: 0.5216\n","Epoch 8/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.9190 - accuracy: 0.7061 - val_loss: 1.0313 - val_accuracy: 0.5388\n","Epoch 9/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9135 - accuracy: 0.7131 - val_loss: 1.0288 - val_accuracy: 0.5366\n","Epoch 10/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.9091 - accuracy: 0.7088 - val_loss: 1.0162 - val_accuracy: 0.5916\n","Epoch 11/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9079 - accuracy: 0.7136 - val_loss: 1.0121 - val_accuracy: 0.5862\n","Epoch 12/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8988 - accuracy: 0.7204 - val_loss: 1.0019 - val_accuracy: 0.6121\n","Epoch 13/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8976 - accuracy: 0.7147 - val_loss: 1.0027 - val_accuracy: 0.5948\n","Epoch 14/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8861 - accuracy: 0.7271 - val_loss: 0.9908 - val_accuracy: 0.6088\n","Epoch 15/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8832 - accuracy: 0.7260 - val_loss: 0.9807 - val_accuracy: 0.6304\n","Epoch 16/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8819 - accuracy: 0.7231 - val_loss: 0.9780 - val_accuracy: 0.6293\n","Epoch 17/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.8781 - accuracy: 0.7274 - val_loss: 0.9716 - val_accuracy: 0.6390\n","Epoch 18/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8730 - accuracy: 0.7266 - val_loss: 0.9585 - val_accuracy: 0.6519\n","Epoch 19/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8670 - accuracy: 0.7314 - val_loss: 0.9590 - val_accuracy: 0.6519\n","Epoch 20/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8606 - accuracy: 0.7325 - val_loss: 0.9514 - val_accuracy: 0.6552\n","Epoch 21/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8617 - accuracy: 0.7344 - val_loss: 0.9561 - val_accuracy: 0.6584\n","Epoch 22/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8599 - accuracy: 0.7282 - val_loss: 0.9418 - val_accuracy: 0.6659\n","Epoch 23/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8522 - accuracy: 0.7352 - val_loss: 0.9503 - val_accuracy: 0.6562\n","Epoch 24/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8490 - accuracy: 0.7344 - val_loss: 0.9414 - val_accuracy: 0.6616\n","Epoch 25/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8400 - accuracy: 0.7452 - val_loss: 0.9423 - val_accuracy: 0.6649\n","Epoch 26/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8289 - accuracy: 0.7487 - val_loss: 0.9435 - val_accuracy: 0.6573\n","Epoch 27/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8347 - accuracy: 0.7433 - val_loss: 0.9541 - val_accuracy: 0.6519\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8261 - accuracy: 0.7454 - val_loss: 0.9418 - val_accuracy: 0.6616\n","Epoch 29/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8239 - accuracy: 0.7484 - val_loss: 0.9465 - val_accuracy: 0.6703\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8201 - accuracy: 0.7519 - val_loss: 0.9448 - val_accuracy: 0.6703\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8176 - accuracy: 0.7478 - val_loss: 0.9476 - val_accuracy: 0.6670\n","Epoch 32/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8134 - accuracy: 0.7524 - val_loss: 0.9665 - val_accuracy: 0.6519\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8104 - accuracy: 0.7524 - val_loss: 0.9530 - val_accuracy: 0.6649\n","Epoch 34/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.8057 - accuracy: 0.7548 - val_loss: 0.9460 - val_accuracy: 0.6756\n","Epoch 35/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7974 - accuracy: 0.7670 - val_loss: 0.9506 - val_accuracy: 0.6724\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7925 - accuracy: 0.7645 - val_loss: 0.9747 - val_accuracy: 0.6466\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7935 - accuracy: 0.7589 - val_loss: 0.9704 - val_accuracy: 0.6541\n","Epoch 38/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7852 - accuracy: 0.7680 - val_loss: 0.9550 - val_accuracy: 0.6681\n","Epoch 39/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7821 - accuracy: 0.7659 - val_loss: 0.9560 - val_accuracy: 0.6713\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7773 - accuracy: 0.7707 - val_loss: 0.9625 - val_accuracy: 0.6595\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7755 - accuracy: 0.7740 - val_loss: 0.9587 - val_accuracy: 0.6692\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7759 - accuracy: 0.7697 - val_loss: 0.9582 - val_accuracy: 0.6692\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7672 - accuracy: 0.7734 - val_loss: 0.9638 - val_accuracy: 0.6681\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7607 - accuracy: 0.7837 - val_loss: 0.9636 - val_accuracy: 0.6649\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7593 - accuracy: 0.7769 - val_loss: 0.9623 - val_accuracy: 0.6573\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7506 - accuracy: 0.7869 - val_loss: 0.9643 - val_accuracy: 0.6724\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7530 - accuracy: 0.7794 - val_loss: 0.9655 - val_accuracy: 0.6670\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7496 - accuracy: 0.7812 - val_loss: 0.9621 - val_accuracy: 0.6724\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7634 - accuracy: 0.7648 - val_loss: 0.9625 - val_accuracy: 0.6681\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7563 - accuracy: 0.7783 - val_loss: 0.9577 - val_accuracy: 0.6713\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7370 - accuracy: 0.7893 - val_loss: 0.9587 - val_accuracy: 0.6703\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7375 - accuracy: 0.7874 - val_loss: 0.9639 - val_accuracy: 0.6713\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7292 - accuracy: 0.7939 - val_loss: 0.9759 - val_accuracy: 0.6595\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7293 - accuracy: 0.7909 - val_loss: 0.9708 - val_accuracy: 0.6670\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7245 - accuracy: 0.7947 - val_loss: 0.9735 - val_accuracy: 0.6638\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7171 - accuracy: 0.8033 - val_loss: 0.9820 - val_accuracy: 0.6552\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7185 - accuracy: 0.8004 - val_loss: 0.9700 - val_accuracy: 0.6692\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7140 - accuracy: 0.7918 - val_loss: 0.9800 - val_accuracy: 0.6584\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7134 - accuracy: 0.7953 - val_loss: 0.9943 - val_accuracy: 0.6509\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7093 - accuracy: 0.8004 - val_loss: 0.9718 - val_accuracy: 0.6681\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6968 - accuracy: 0.8060 - val_loss: 0.9760 - val_accuracy: 0.6681\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6964 - accuracy: 0.8017 - val_loss: 0.9794 - val_accuracy: 0.6670\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6956 - accuracy: 0.8098 - val_loss: 0.9911 - val_accuracy: 0.6724\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6923 - accuracy: 0.8039 - val_loss: 0.9867 - val_accuracy: 0.6681\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6806 - accuracy: 0.8160 - val_loss: 0.9816 - val_accuracy: 0.6606\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6829 - accuracy: 0.8128 - val_loss: 0.9878 - val_accuracy: 0.6595\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6783 - accuracy: 0.8058 - val_loss: 0.9832 - val_accuracy: 0.6681\n","Epoch 68/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6714 - accuracy: 0.8214 - val_loss: 0.9849 - val_accuracy: 0.6692\n","Epoch 69/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6701 - accuracy: 0.8214 - val_loss: 0.9935 - val_accuracy: 0.6595\n","Epoch 70/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6650 - accuracy: 0.8249 - val_loss: 1.0168 - val_accuracy: 0.6444\n","Epoch 71/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6689 - accuracy: 0.8214 - val_loss: 0.9912 - val_accuracy: 0.6692\n","Epoch 72/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6670 - accuracy: 0.8198 - val_loss: 1.0128 - val_accuracy: 0.6455\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6598 - accuracy: 0.8252 - val_loss: 1.0072 - val_accuracy: 0.6552\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6501 - accuracy: 0.8230 - val_loss: 1.0113 - val_accuracy: 0.6584\n","Epoch 75/100\n","29/29 [==============================] - 2s 57ms/step - loss: 0.6563 - accuracy: 0.8238 - val_loss: 0.9954 - val_accuracy: 0.6810\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6489 - accuracy: 0.8265 - val_loss: 1.0007 - val_accuracy: 0.6746\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6504 - accuracy: 0.8198 - val_loss: 0.9997 - val_accuracy: 0.6681\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6482 - accuracy: 0.8270 - val_loss: 1.0150 - val_accuracy: 0.6487\n","Epoch 79/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6369 - accuracy: 0.8305 - val_loss: 1.0103 - val_accuracy: 0.6606\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6368 - accuracy: 0.8341 - val_loss: 1.0165 - val_accuracy: 0.6746\n","Epoch 81/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6327 - accuracy: 0.8324 - val_loss: 1.0113 - val_accuracy: 0.6843\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6239 - accuracy: 0.8389 - val_loss: 1.0254 - val_accuracy: 0.6541\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6278 - accuracy: 0.8308 - val_loss: 1.0310 - val_accuracy: 0.6466\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6185 - accuracy: 0.8400 - val_loss: 1.0205 - val_accuracy: 0.6681\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6200 - accuracy: 0.8338 - val_loss: 1.0164 - val_accuracy: 0.6756\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6167 - accuracy: 0.8373 - val_loss: 1.0188 - val_accuracy: 0.6627\n","Epoch 87/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6133 - accuracy: 0.8397 - val_loss: 1.0335 - val_accuracy: 0.6735\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6188 - accuracy: 0.8351 - val_loss: 1.0379 - val_accuracy: 0.6735\n","Epoch 89/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6056 - accuracy: 0.8438 - val_loss: 1.0252 - val_accuracy: 0.6864\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6060 - accuracy: 0.8416 - val_loss: 1.0312 - val_accuracy: 0.6584\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5930 - accuracy: 0.8502 - val_loss: 1.0331 - val_accuracy: 0.6692\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6057 - accuracy: 0.8402 - val_loss: 1.0440 - val_accuracy: 0.6606\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6008 - accuracy: 0.8405 - val_loss: 1.0257 - val_accuracy: 0.6713\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5840 - accuracy: 0.8586 - val_loss: 1.0415 - val_accuracy: 0.6746\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5813 - accuracy: 0.8534 - val_loss: 1.0470 - val_accuracy: 0.6810\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5855 - accuracy: 0.8481 - val_loss: 1.0593 - val_accuracy: 0.6810\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5746 - accuracy: 0.8532 - val_loss: 1.0635 - val_accuracy: 0.6466\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5823 - accuracy: 0.8502 - val_loss: 1.0720 - val_accuracy: 0.6541\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5712 - accuracy: 0.8572 - val_loss: 1.0633 - val_accuracy: 0.6778\n","Epoch 100/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5678 - accuracy: 0.8575 - val_loss: 1.0687 - val_accuracy: 0.6606\n","{'loss': [0.9623832702636719, 0.9547509551048279, 0.9460688829421997, 0.940212607383728, 0.9393957853317261, 0.9324968457221985, 0.9204056859016418, 0.9189645051956177, 0.913506805896759, 0.9091330766677856, 0.9078805446624756, 0.8988479375839233, 0.8976039290428162, 0.8860657215118408, 0.8832107782363892, 0.8819447159767151, 0.8780596256256104, 0.8729559183120728, 0.8669837713241577, 0.8605511784553528, 0.8617438077926636, 0.8598716855049133, 0.8522408604621887, 0.8490250706672668, 0.8399863839149475, 0.8288652300834656, 0.8346999883651733, 0.8260725736618042, 0.8239182233810425, 0.8201079964637756, 0.8176282048225403, 0.8133987188339233, 0.810370147228241, 0.8056705594062805, 0.7973591089248657, 0.7924764752388, 0.7934843301773071, 0.785233736038208, 0.7821224331855774, 0.7773346304893494, 0.7755146026611328, 0.7758723497390747, 0.7671549320220947, 0.7607332468032837, 0.7593141198158264, 0.7506344318389893, 0.7530268430709839, 0.7496285438537598, 0.7634114027023315, 0.7563461065292358, 0.7370073795318604, 0.7374699115753174, 0.7292104959487915, 0.7293495535850525, 0.7244973182678223, 0.7170814275741577, 0.7184650301933289, 0.7139822840690613, 0.7134097814559937, 0.7092507481575012, 0.6968194842338562, 0.6964023113250732, 0.695554792881012, 0.6922595500946045, 0.6806301474571228, 0.6829397678375244, 0.6783210039138794, 0.6713962554931641, 0.6701339483261108, 0.6649616360664368, 0.6688500046730042, 0.6670448184013367, 0.6598361730575562, 0.6501262187957764, 0.6562766432762146, 0.6489465236663818, 0.6503524780273438, 0.6482306718826294, 0.6368955969810486, 0.636810302734375, 0.6327464580535889, 0.6238701343536377, 0.6278144121170044, 0.6185473799705505, 0.6199797987937927, 0.6166509389877319, 0.6132711172103882, 0.6188040971755981, 0.6055508852005005, 0.6059553623199463, 0.5929879546165466, 0.6057336926460266, 0.6008137464523315, 0.5839788317680359, 0.5812938213348389, 0.5855470895767212, 0.5746263265609741, 0.5823301076889038, 0.5712438225746155, 0.5677547454833984], 'accuracy': [0.6875, 0.6945043206214905, 0.6974676847457886, 0.7052801847457886, 0.6996228694915771, 0.7033944129943848, 0.7114762663841248, 0.7060883641242981, 0.7130926847457886, 0.7087823152542114, 0.7136314511299133, 0.720366358757019, 0.7147090435028076, 0.7271012663841248, 0.7260237336158752, 0.7230603694915771, 0.7273706793785095, 0.7265625, 0.7314116358757019, 0.7324892282485962, 0.734375, 0.728178858757019, 0.7351831793785095, 0.734375, 0.7451508641242981, 0.748652994632721, 0.7432650923728943, 0.7454202771186829, 0.748383641242981, 0.7518857717514038, 0.7478448152542114, 0.7524245977401733, 0.7524245977401733, 0.7548491358757019, 0.766972005367279, 0.7645474076271057, 0.7588900923728943, 0.7680495977401733, 0.7658944129943848, 0.7707435488700867, 0.7739762663841248, 0.7696659564971924, 0.7734375, 0.7836745977401733, 0.7769396305084229, 0.7869073152542114, 0.7793642282485962, 0.78125, 0.7648168206214905, 0.7782866358757019, 0.7893319129943848, 0.787446141242981, 0.7939116358757019, 0.7909482717514038, 0.7947198152542114, 0.803340494632721, 0.8003771305084229, 0.7917564511299133, 0.795258641242981, 0.8003771305084229, 0.806034505367279, 0.8017241358757019, 0.8098060488700867, 0.8038793206214905, 0.8160021305084229, 0.8127694129943848, 0.8057650923728943, 0.8213900923728943, 0.8213900923728943, 0.8248922228813171, 0.8213900923728943, 0.8197737336158752, 0.8251616358757019, 0.8230064511299133, 0.8238146305084229, 0.826508641242981, 0.8197737336158752, 0.8270474076271057, 0.8305495977401733, 0.8340517282485962, 0.8324353694915771, 0.8389008641242981, 0.8308189511299133, 0.8399784564971924, 0.8337823152542114, 0.837284505367279, 0.8397090435028076, 0.8351293206214905, 0.84375, 0.8415948152542114, 0.850215494632721, 0.8402478694915771, 0.8405172228813171, 0.8585668206214905, 0.8534482717514038, 0.8480603694915771, 0.853178858757019, 0.850215494632721, 0.8572198152542114, 0.8574892282485962], 'val_loss': [1.061658501625061, 1.0580339431762695, 1.0553562641143799, 1.0527626276016235, 1.0458033084869385, 1.0409067869186401, 1.036793828010559, 1.0312608480453491, 1.0287995338439941, 1.0161817073822021, 1.0120811462402344, 1.0019046068191528, 1.0026683807373047, 0.9907750487327576, 0.9807308912277222, 0.9780154824256897, 0.9715625047683716, 0.9584965109825134, 0.9589786529541016, 0.951418399810791, 0.9560709595680237, 0.9418297410011292, 0.9503304958343506, 0.9413856863975525, 0.9422552585601807, 0.9435349702835083, 0.9541175961494446, 0.9418248534202576, 0.9464551210403442, 0.944774866104126, 0.9476457238197327, 0.9664722084999084, 0.952996551990509, 0.9460076689720154, 0.9505758881568909, 0.9746509194374084, 0.9704034328460693, 0.9550484418869019, 0.9560399055480957, 0.9625171422958374, 0.9587477445602417, 0.9581732153892517, 0.9637633562088013, 0.9635520577430725, 0.9623417854309082, 0.9642501473426819, 0.9654872417449951, 0.9620590209960938, 0.9624978303909302, 0.9576906561851501, 0.9587231874465942, 0.9638864398002625, 0.9758551120758057, 0.9707702994346619, 0.9735400676727295, 0.9819508194923401, 0.9699829816818237, 0.9800432324409485, 0.9942739605903625, 0.9717947840690613, 0.9759804010391235, 0.9794445633888245, 0.991061270236969, 0.9867146611213684, 0.9815927147865295, 0.9878381490707397, 0.983197808265686, 0.9848784804344177, 0.9935109615325928, 1.016759991645813, 0.9912168979644775, 1.0128445625305176, 1.0072182416915894, 1.0112978219985962, 0.995388925075531, 1.0007290840148926, 0.9997128248214722, 1.0149662494659424, 1.010327696800232, 1.0164843797683716, 1.011330485343933, 1.0254242420196533, 1.0310227870941162, 1.020469307899475, 1.0163755416870117, 1.0188006162643433, 1.0335100889205933, 1.0379321575164795, 1.0251623392105103, 1.031203031539917, 1.033132791519165, 1.044020652770996, 1.0257052183151245, 1.0414878129959106, 1.0469695329666138, 1.059281826019287, 1.063543438911438, 1.0720020532608032, 1.0633113384246826, 1.06867516040802], 'val_accuracy': [0.4892241358757019, 0.4924568831920624, 0.49461206793785095, 0.49353447556495667, 0.506465494632721, 0.514008641242981, 0.5215517282485962, 0.5387930870056152, 0.5366379022598267, 0.5915948152542114, 0.5862069129943848, 0.6120689511299133, 0.5948275923728943, 0.6088362336158752, 0.6303879022598267, 0.6293103694915771, 0.639008641242981, 0.6519396305084229, 0.6519396305084229, 0.6551724076271057, 0.6584051847457886, 0.6659482717514038, 0.65625, 0.6616379022598267, 0.6648706793785095, 0.6573275923728943, 0.6519396305084229, 0.6616379022598267, 0.670258641242981, 0.670258641242981, 0.6670258641242981, 0.6519396305084229, 0.6648706793785095, 0.6756465435028076, 0.6724137663841248, 0.6465517282485962, 0.6540948152542114, 0.6681034564971924, 0.6713362336158752, 0.6594827771186829, 0.6691810488700867, 0.6691810488700867, 0.6681034564971924, 0.6648706793785095, 0.6573275923728943, 0.6724137663841248, 0.6670258641242981, 0.6724137663841248, 0.6681034564971924, 0.6713362336158752, 0.670258641242981, 0.6713362336158752, 0.6594827771186829, 0.6670258641242981, 0.6637930870056152, 0.6551724076271057, 0.6691810488700867, 0.6584051847457886, 0.6508620977401733, 0.6681034564971924, 0.6681034564971924, 0.6670258641242981, 0.6724137663841248, 0.6681034564971924, 0.6605603694915771, 0.6594827771186829, 0.6681034564971924, 0.6691810488700867, 0.6594827771186829, 0.6443965435028076, 0.6691810488700867, 0.6454741358757019, 0.6551724076271057, 0.6584051847457886, 0.681034505367279, 0.6745689511299133, 0.6681034564971924, 0.6487069129943848, 0.6605603694915771, 0.6745689511299133, 0.6842672228813171, 0.6540948152542114, 0.6465517282485962, 0.6681034564971924, 0.6756465435028076, 0.662715494632721, 0.673491358757019, 0.673491358757019, 0.6864224076271057, 0.6584051847457886, 0.6691810488700867, 0.6605603694915771, 0.6713362336158752, 0.6745689511299133, 0.681034505367279, 0.681034505367279, 0.6465517282485962, 0.6540948152542114, 0.6778017282485962, 0.6605603694915771]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.9736 - accuracy: 0.6828"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 8s 51ms/step - loss: 0.9738 - accuracy: 0.6802 - val_loss: 1.0605 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9679 - accuracy: 0.6890 - val_loss: 1.0558 - val_accuracy: 0.5045\n","Epoch 3/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.9615 - accuracy: 0.6882 - val_loss: 1.0539 - val_accuracy: 0.5057\n","Epoch 4/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.9537 - accuracy: 0.6941 - val_loss: 1.0506 - val_accuracy: 0.5124\n","Epoch 5/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.9505 - accuracy: 0.6921 - val_loss: 1.0452 - val_accuracy: 0.5215\n","Epoch 6/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9452 - accuracy: 0.6919 - val_loss: 1.0437 - val_accuracy: 0.5170\n","Epoch 7/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.9400 - accuracy: 0.6947 - val_loss: 1.0361 - val_accuracy: 0.5328\n","Epoch 8/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.9332 - accuracy: 0.7018 - val_loss: 1.0310 - val_accuracy: 0.5509\n","Epoch 9/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9296 - accuracy: 0.6989 - val_loss: 1.0266 - val_accuracy: 0.5498\n","Epoch 10/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9265 - accuracy: 0.7006 - val_loss: 1.0233 - val_accuracy: 0.5441\n","Epoch 11/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9192 - accuracy: 0.7029 - val_loss: 1.0176 - val_accuracy: 0.5566\n","Epoch 12/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9153 - accuracy: 0.7168 - val_loss: 1.0090 - val_accuracy: 0.5939\n","Epoch 13/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9111 - accuracy: 0.7063 - val_loss: 1.0072 - val_accuracy: 0.5713\n","Epoch 14/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9059 - accuracy: 0.7153 - val_loss: 0.9952 - val_accuracy: 0.6222\n","Epoch 15/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9025 - accuracy: 0.7083 - val_loss: 0.9927 - val_accuracy: 0.6120\n","Epoch 16/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8949 - accuracy: 0.7179 - val_loss: 0.9839 - val_accuracy: 0.6346\n","Epoch 17/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.8868 - accuracy: 0.7196 - val_loss: 0.9759 - val_accuracy: 0.6459\n","Epoch 18/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8878 - accuracy: 0.7190 - val_loss: 0.9704 - val_accuracy: 0.6437\n","Epoch 19/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8862 - accuracy: 0.7170 - val_loss: 0.9652 - val_accuracy: 0.6482\n","Epoch 20/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.8777 - accuracy: 0.7230 - val_loss: 0.9580 - val_accuracy: 0.6527\n","Epoch 21/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8728 - accuracy: 0.7235 - val_loss: 0.9628 - val_accuracy: 0.6448\n","Epoch 22/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8701 - accuracy: 0.7261 - val_loss: 0.9476 - val_accuracy: 0.6550\n","Epoch 23/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8686 - accuracy: 0.7190 - val_loss: 0.9456 - val_accuracy: 0.6595\n","Epoch 24/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8580 - accuracy: 0.7340 - val_loss: 0.9409 - val_accuracy: 0.6606\n","Epoch 25/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8494 - accuracy: 0.7405 - val_loss: 0.9386 - val_accuracy: 0.6606\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8527 - accuracy: 0.7295 - val_loss: 0.9385 - val_accuracy: 0.6606\n","Epoch 27/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8486 - accuracy: 0.7298 - val_loss: 0.9372 - val_accuracy: 0.6584\n","Epoch 28/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.8417 - accuracy: 0.7411 - val_loss: 0.9384 - val_accuracy: 0.6663\n","Epoch 29/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8367 - accuracy: 0.7470 - val_loss: 0.9369 - val_accuracy: 0.6618\n","Epoch 30/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.8401 - accuracy: 0.7351 - val_loss: 0.9357 - val_accuracy: 0.6629\n","Epoch 31/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8338 - accuracy: 0.7354 - val_loss: 0.9323 - val_accuracy: 0.6606\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8260 - accuracy: 0.7484 - val_loss: 0.9337 - val_accuracy: 0.6640\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8235 - accuracy: 0.7493 - val_loss: 0.9334 - val_accuracy: 0.6618\n","Epoch 34/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8223 - accuracy: 0.7383 - val_loss: 0.9340 - val_accuracy: 0.6629\n","Epoch 35/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.8168 - accuracy: 0.7470 - val_loss: 0.9300 - val_accuracy: 0.6742\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8092 - accuracy: 0.7533 - val_loss: 0.9407 - val_accuracy: 0.6606\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8084 - accuracy: 0.7484 - val_loss: 0.9376 - val_accuracy: 0.6674\n","Epoch 38/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8035 - accuracy: 0.7507 - val_loss: 0.9318 - val_accuracy: 0.6652\n","Epoch 39/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7899 - accuracy: 0.7674 - val_loss: 0.9254 - val_accuracy: 0.6776\n","Epoch 40/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7907 - accuracy: 0.7606 - val_loss: 0.9263 - val_accuracy: 0.6606\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7917 - accuracy: 0.7533 - val_loss: 0.9332 - val_accuracy: 0.6742\n","Epoch 42/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7897 - accuracy: 0.7518 - val_loss: 0.9393 - val_accuracy: 0.6584\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7809 - accuracy: 0.7626 - val_loss: 0.9239 - val_accuracy: 0.6595\n","Epoch 44/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7774 - accuracy: 0.7612 - val_loss: 0.9268 - val_accuracy: 0.6595\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7783 - accuracy: 0.7649 - val_loss: 0.9240 - val_accuracy: 0.6765\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7717 - accuracy: 0.7612 - val_loss: 0.9221 - val_accuracy: 0.6708\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7724 - accuracy: 0.7583 - val_loss: 0.9548 - val_accuracy: 0.6425\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7519 - accuracy: 0.7776 - val_loss: 0.9340 - val_accuracy: 0.6471\n","Epoch 49/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7570 - accuracy: 0.7668 - val_loss: 0.9356 - val_accuracy: 0.6606\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7508 - accuracy: 0.7784 - val_loss: 0.9276 - val_accuracy: 0.6742\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7476 - accuracy: 0.7790 - val_loss: 0.9342 - val_accuracy: 0.6742\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7421 - accuracy: 0.7784 - val_loss: 0.9673 - val_accuracy: 0.6357\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7391 - accuracy: 0.7816 - val_loss: 0.9307 - val_accuracy: 0.6731\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7336 - accuracy: 0.7841 - val_loss: 0.9328 - val_accuracy: 0.6742\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7265 - accuracy: 0.7903 - val_loss: 0.9414 - val_accuracy: 0.6606\n","Epoch 56/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7265 - accuracy: 0.7838 - val_loss: 0.9245 - val_accuracy: 0.6821\n","Epoch 57/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7243 - accuracy: 0.7909 - val_loss: 0.9225 - val_accuracy: 0.6878\n","Epoch 58/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7203 - accuracy: 0.7900 - val_loss: 0.9229 - val_accuracy: 0.6810\n","Epoch 59/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.7173 - accuracy: 0.7883 - val_loss: 0.9277 - val_accuracy: 0.6799\n","Epoch 60/100\n","28/28 [==============================] - 1s 41ms/step - loss: 0.7191 - accuracy: 0.7875 - val_loss: 0.9277 - val_accuracy: 0.6742\n","Epoch 61/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.7005 - accuracy: 0.7982 - val_loss: 0.9504 - val_accuracy: 0.6459\n","Epoch 62/100\n","28/28 [==============================] - 1s 46ms/step - loss: 0.7025 - accuracy: 0.7909 - val_loss: 0.9544 - val_accuracy: 0.6686\n","Epoch 63/100\n","28/28 [==============================] - 1s 40ms/step - loss: 0.7027 - accuracy: 0.7965 - val_loss: 0.9341 - val_accuracy: 0.6799\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6980 - accuracy: 0.7951 - val_loss: 0.9364 - val_accuracy: 0.6753\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6864 - accuracy: 0.8059 - val_loss: 0.9587 - val_accuracy: 0.6561\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6876 - accuracy: 0.8002 - val_loss: 0.9465 - val_accuracy: 0.6787\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6831 - accuracy: 0.8050 - val_loss: 0.9386 - val_accuracy: 0.6867\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6865 - accuracy: 0.7982 - val_loss: 0.9494 - val_accuracy: 0.6810\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6798 - accuracy: 0.8087 - val_loss: 0.9333 - val_accuracy: 0.6799\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6790 - accuracy: 0.8115 - val_loss: 0.9382 - val_accuracy: 0.6855\n","Epoch 71/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6753 - accuracy: 0.8056 - val_loss: 0.9513 - val_accuracy: 0.6753\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6681 - accuracy: 0.8135 - val_loss: 0.9412 - val_accuracy: 0.6821\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6636 - accuracy: 0.8161 - val_loss: 0.9437 - val_accuracy: 0.6753\n","Epoch 74/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6502 - accuracy: 0.8226 - val_loss: 0.9537 - val_accuracy: 0.6844\n","Epoch 75/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6598 - accuracy: 0.8161 - val_loss: 0.9942 - val_accuracy: 0.6448\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6487 - accuracy: 0.8212 - val_loss: 0.9672 - val_accuracy: 0.6640\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6470 - accuracy: 0.8280 - val_loss: 0.9538 - val_accuracy: 0.6719\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6493 - accuracy: 0.8212 - val_loss: 0.9693 - val_accuracy: 0.6674\n","Epoch 79/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6443 - accuracy: 0.8166 - val_loss: 0.9681 - val_accuracy: 0.6776\n","Epoch 80/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6468 - accuracy: 0.8135 - val_loss: 0.9860 - val_accuracy: 0.6686\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6366 - accuracy: 0.8223 - val_loss: 0.9662 - val_accuracy: 0.6765\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6183 - accuracy: 0.8413 - val_loss: 0.9723 - val_accuracy: 0.6799\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6245 - accuracy: 0.8336 - val_loss: 0.9683 - val_accuracy: 0.6810\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6147 - accuracy: 0.8430 - val_loss: 0.9668 - val_accuracy: 0.6765\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6153 - accuracy: 0.8373 - val_loss: 0.9765 - val_accuracy: 0.6810\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6106 - accuracy: 0.8398 - val_loss: 0.9768 - val_accuracy: 0.6810\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6060 - accuracy: 0.8435 - val_loss: 0.9939 - val_accuracy: 0.6606\n","Epoch 88/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6031 - accuracy: 0.8413 - val_loss: 0.9892 - val_accuracy: 0.6765\n","Epoch 89/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6008 - accuracy: 0.8461 - val_loss: 0.9876 - val_accuracy: 0.6787\n","Epoch 90/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6007 - accuracy: 0.8390 - val_loss: 0.9732 - val_accuracy: 0.6833\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6041 - accuracy: 0.8333 - val_loss: 1.0007 - val_accuracy: 0.6708\n","Epoch 92/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5950 - accuracy: 0.8424 - val_loss: 0.9973 - val_accuracy: 0.6708\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5903 - accuracy: 0.8483 - val_loss: 1.0096 - val_accuracy: 0.6652\n","Epoch 94/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5826 - accuracy: 0.8512 - val_loss: 1.0327 - val_accuracy: 0.6471\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5909 - accuracy: 0.8458 - val_loss: 0.9948 - val_accuracy: 0.6787\n","Epoch 96/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5808 - accuracy: 0.8478 - val_loss: 1.0349 - val_accuracy: 0.6629\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5804 - accuracy: 0.8509 - val_loss: 1.0129 - val_accuracy: 0.6606\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5718 - accuracy: 0.8520 - val_loss: 1.0190 - val_accuracy: 0.6584\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5743 - accuracy: 0.8489 - val_loss: 1.0431 - val_accuracy: 0.6561\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5677 - accuracy: 0.8594 - val_loss: 1.0378 - val_accuracy: 0.6640\n","{'loss': [0.9737587571144104, 0.9678859114646912, 0.9615078568458557, 0.9536730647087097, 0.9504922032356262, 0.9451509714126587, 0.940007746219635, 0.9331523180007935, 0.9296046495437622, 0.9264689683914185, 0.919236958026886, 0.9153170585632324, 0.9110554456710815, 0.905861496925354, 0.9025014042854309, 0.8948907852172852, 0.8867817521095276, 0.8878160119056702, 0.8862289786338806, 0.8777261972427368, 0.8727704286575317, 0.8701049089431763, 0.8686164617538452, 0.8580490946769714, 0.8493592739105225, 0.8527480959892273, 0.8486011624336243, 0.8417018055915833, 0.836723804473877, 0.8400579690933228, 0.8338098526000977, 0.8260237574577332, 0.8235210180282593, 0.8222835063934326, 0.8167571425437927, 0.8092079162597656, 0.8084063529968262, 0.8034520745277405, 0.7898662090301514, 0.7906950116157532, 0.7916958332061768, 0.7896768450737, 0.7808687686920166, 0.7773888111114502, 0.7783353924751282, 0.7716951370239258, 0.7723680734634399, 0.7518991231918335, 0.7569783926010132, 0.7507708072662354, 0.7475944757461548, 0.7420839667320251, 0.739063024520874, 0.73357093334198, 0.7265095114707947, 0.7264752984046936, 0.7242761850357056, 0.7202585339546204, 0.7172607779502869, 0.7190709114074707, 0.7005159258842468, 0.7025341987609863, 0.7026663422584534, 0.6980434060096741, 0.6864209771156311, 0.6875922679901123, 0.6831281781196594, 0.6864657402038574, 0.6798273324966431, 0.679048478603363, 0.6752873659133911, 0.6681134104728699, 0.6635949015617371, 0.6501529216766357, 0.6597904562950134, 0.6486767530441284, 0.6469531059265137, 0.6493311524391174, 0.6442529559135437, 0.6467816829681396, 0.636591374874115, 0.6183188557624817, 0.6244572997093201, 0.6146674156188965, 0.6152905821800232, 0.6105530261993408, 0.6059767007827759, 0.6030590534210205, 0.6008185148239136, 0.6007332801818848, 0.6041489839553833, 0.5949571132659912, 0.5903262495994568, 0.582556962966919, 0.5908588767051697, 0.5808317065238953, 0.5803541541099548, 0.5718145966529846, 0.5743111968040466, 0.5676974654197693], 'accuracy': [0.680249035358429, 0.6890209317207336, 0.6881720423698425, 0.6941143274307251, 0.6921335458755493, 0.6918506026268005, 0.6946802735328674, 0.7017543911933899, 0.698924720287323, 0.7006224989891052, 0.7028862237930298, 0.7167515754699707, 0.706281840801239, 0.7153367400169373, 0.70826256275177, 0.7178834080696106, 0.7195811867713928, 0.7190153002738953, 0.7170345187187195, 0.722976803779602, 0.7235427498817444, 0.7260894179344177, 0.7190153002738953, 0.7340124249458313, 0.7405206561088562, 0.7294849753379822, 0.7297679781913757, 0.7410866022109985, 0.7470288872718811, 0.735144317150116, 0.7354272603988647, 0.7484436631202698, 0.7492926120758057, 0.7382569313049316, 0.7470288872718811, 0.7532541155815125, 0.7484436631202698, 0.7507073879241943, 0.7674023509025574, 0.7606111764907837, 0.7532541155815125, 0.751839280128479, 0.7625919580459595, 0.761177122592926, 0.764855682849884, 0.761177122592926, 0.7583475112915039, 0.7775891423225403, 0.7668364644050598, 0.7784380316734314, 0.7790039777755737, 0.7784380316734314, 0.7815506458282471, 0.7840973138809204, 0.7903226017951965, 0.7838143706321716, 0.7908884882926941, 0.790039598941803, 0.7883418202400208, 0.7874929308891296, 0.7982456088066101, 0.7908884882926941, 0.7965478301048279, 0.7951329946517944, 0.8058856725692749, 0.8002263903617859, 0.8050367832183838, 0.7982456088066101, 0.8087153434753418, 0.8115450143814087, 0.8056027293205261, 0.8135257363319397, 0.8160724639892578, 0.8225806355476379, 0.8160724639892578, 0.8211658000946045, 0.8279569745063782, 0.8211658000946045, 0.8166383504867554, 0.8135257363319397, 0.8222976922988892, 0.8412563800811768, 0.833616316318512, 0.842954158782959, 0.83729487657547, 0.8398415446281433, 0.8435201048851013, 0.8412563800811768, 0.8460667729377747, 0.8389926552772522, 0.8333333134651184, 0.8423882126808167, 0.8483304977416992, 0.8511601686477661, 0.8457838296890259, 0.8477645516395569, 0.8508771657943726, 0.8520090579986572, 0.8488964438438416, 0.8593661785125732], 'val_loss': [1.0605419874191284, 1.0557971000671387, 1.0539343357086182, 1.05063796043396, 1.045164942741394, 1.043656349182129, 1.0360677242279053, 1.0310380458831787, 1.0265626907348633, 1.0232617855072021, 1.0175532102584839, 1.0090386867523193, 1.0072087049484253, 0.9951806664466858, 0.9926867485046387, 0.9838944673538208, 0.9758846163749695, 0.9704108834266663, 0.9651696681976318, 0.9580339789390564, 0.9627799987792969, 0.947609543800354, 0.9456225633621216, 0.9409262537956238, 0.9385706782341003, 0.9385361075401306, 0.9372038245201111, 0.9383904933929443, 0.9369372129440308, 0.9356762766838074, 0.9323129653930664, 0.9337019920349121, 0.933367908000946, 0.9339659214019775, 0.9299880266189575, 0.9407005906105042, 0.9375526905059814, 0.9318417310714722, 0.9253605604171753, 0.926321804523468, 0.9331530332565308, 0.9392605423927307, 0.9239493012428284, 0.9268481731414795, 0.9239894151687622, 0.9220501184463501, 0.9547961354255676, 0.9339574575424194, 0.9355968236923218, 0.9275859594345093, 0.9342014789581299, 0.9673224687576294, 0.9307098984718323, 0.9328405857086182, 0.941415011882782, 0.9245468974113464, 0.9224616885185242, 0.9229164719581604, 0.9277142286300659, 0.9276782274246216, 0.9503658413887024, 0.9543874263763428, 0.9341431260108948, 0.9364104270935059, 0.9587231278419495, 0.9465100169181824, 0.938581109046936, 0.9493952989578247, 0.9332656264305115, 0.9382264018058777, 0.9513222575187683, 0.9412252306938171, 0.9437033534049988, 0.95372474193573, 0.994234025478363, 0.9671574831008911, 0.9538379907608032, 0.9692643880844116, 0.9680957794189453, 0.9859553575515747, 0.9661809802055359, 0.9723132252693176, 0.9683271646499634, 0.9668095111846924, 0.9764751195907593, 0.9768383502960205, 0.9939159154891968, 0.9892178177833557, 0.9875571131706238, 0.9731846451759338, 1.0007108449935913, 0.9973031878471375, 1.009628415107727, 1.0327421426773071, 0.994769275188446, 1.034927487373352, 1.012938380241394, 1.0189530849456787, 1.0430721044540405, 1.0378390550613403], 'val_accuracy': [0.4954751133918762, 0.5045248866081238, 0.5056561231613159, 0.5124434232711792, 0.5214931964874268, 0.516968309879303, 0.5328054428100586, 0.5509049892425537, 0.5497737526893616, 0.5441176295280457, 0.5565611124038696, 0.5938913822174072, 0.5712669491767883, 0.622171938419342, 0.6119909286499023, 0.6346153616905212, 0.6459276080131531, 0.6436651349067688, 0.6481900215148926, 0.6527149081230164, 0.6447963714599609, 0.6549773812294006, 0.6595022678375244, 0.6606335043907166, 0.6606335043907166, 0.6606335043907166, 0.6583710312843323, 0.6662895679473877, 0.6617646813392639, 0.662895917892456, 0.6606335043907166, 0.6640271544456482, 0.6617646813392639, 0.662895917892456, 0.6742081642150879, 0.6606335043907166, 0.6674208045005798, 0.6651583909988403, 0.6776018142700195, 0.6606335043907166, 0.6742081642150879, 0.6583710312843323, 0.6595022678375244, 0.6595022678375244, 0.6764705777168274, 0.6708144545555115, 0.6425339579582214, 0.6470588445663452, 0.6606335043907166, 0.6742081642150879, 0.6742081642150879, 0.6357465982437134, 0.6730769276618958, 0.6742081642150879, 0.6606335043907166, 0.6821267008781433, 0.6877828240394592, 0.6809954643249512, 0.679864227771759, 0.6742081642150879, 0.6459276080131531, 0.668552041053772, 0.679864227771759, 0.6753393411636353, 0.6561086177825928, 0.6787330508232117, 0.6866515874862671, 0.6809954643249512, 0.679864227771759, 0.685520350933075, 0.6753393411636353, 0.6821267008781433, 0.6753393411636353, 0.6843891143798828, 0.6447963714599609, 0.6640271544456482, 0.6719456911087036, 0.6674208045005798, 0.6776018142700195, 0.668552041053772, 0.6764705777168274, 0.679864227771759, 0.6809954643249512, 0.6764705777168274, 0.6809954643249512, 0.6809954643249512, 0.6606335043907166, 0.6764705777168274, 0.6787330508232117, 0.6832579374313354, 0.6708144545555115, 0.6708144545555115, 0.6651583909988403, 0.6470588445663452, 0.6787330508232117, 0.662895917892456, 0.6606335043907166, 0.6583710312843323, 0.6561086177825928, 0.6640271544456482]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 8s 46ms/step - loss: 0.9789 - accuracy: 0.6765 - val_loss: 1.0614 - val_accuracy: 0.4928\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 2/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9667 - accuracy: 0.6855 - val_loss: 1.0563 - val_accuracy: 0.5000\n","Epoch 3/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9597 - accuracy: 0.6922 - val_loss: 1.0541 - val_accuracy: 0.4969\n","Epoch 4/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9570 - accuracy: 0.6842 - val_loss: 1.0477 - val_accuracy: 0.5165\n","Epoch 5/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9513 - accuracy: 0.6925 - val_loss: 1.0425 - val_accuracy: 0.5227\n","Epoch 6/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9443 - accuracy: 0.6907 - val_loss: 1.0390 - val_accuracy: 0.5248\n","Epoch 7/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9412 - accuracy: 0.6969 - val_loss: 1.0341 - val_accuracy: 0.5341\n","Epoch 8/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9357 - accuracy: 0.6959 - val_loss: 1.0268 - val_accuracy: 0.5527\n","Epoch 9/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9272 - accuracy: 0.7049 - val_loss: 1.0234 - val_accuracy: 0.5558\n","Epoch 10/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9228 - accuracy: 0.7044 - val_loss: 1.0174 - val_accuracy: 0.5630\n","Epoch 11/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9182 - accuracy: 0.7134 - val_loss: 1.0091 - val_accuracy: 0.6033\n","Epoch 12/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.9127 - accuracy: 0.7083 - val_loss: 1.0026 - val_accuracy: 0.6085\n","Epoch 13/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.9113 - accuracy: 0.7078 - val_loss: 0.9942 - val_accuracy: 0.6374\n","Epoch 14/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9036 - accuracy: 0.7137 - val_loss: 0.9872 - val_accuracy: 0.6539\n","Epoch 15/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9043 - accuracy: 0.7062 - val_loss: 0.9806 - val_accuracy: 0.6508\n","Epoch 16/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8994 - accuracy: 0.7124 - val_loss: 0.9767 - val_accuracy: 0.6488\n","Epoch 17/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8926 - accuracy: 0.7116 - val_loss: 0.9710 - val_accuracy: 0.6508\n","Epoch 18/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8893 - accuracy: 0.7147 - val_loss: 0.9655 - val_accuracy: 0.6488\n","Epoch 19/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8818 - accuracy: 0.7245 - val_loss: 0.9637 - val_accuracy: 0.6446\n","Epoch 20/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8788 - accuracy: 0.7155 - val_loss: 0.9598 - val_accuracy: 0.6539\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8796 - accuracy: 0.7140 - val_loss: 0.9606 - val_accuracy: 0.6426\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8719 - accuracy: 0.7209 - val_loss: 0.9558 - val_accuracy: 0.6488\n","Epoch 23/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8642 - accuracy: 0.7279 - val_loss: 0.9553 - val_accuracy: 0.6612\n","Epoch 24/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8671 - accuracy: 0.7176 - val_loss: 0.9552 - val_accuracy: 0.6550\n","Epoch 25/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8596 - accuracy: 0.7233 - val_loss: 0.9525 - val_accuracy: 0.6560\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8523 - accuracy: 0.7305 - val_loss: 0.9537 - val_accuracy: 0.6477\n","Epoch 27/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8509 - accuracy: 0.7248 - val_loss: 0.9583 - val_accuracy: 0.6508\n","Epoch 28/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8459 - accuracy: 0.7261 - val_loss: 0.9567 - val_accuracy: 0.6519\n","Epoch 29/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8431 - accuracy: 0.7367 - val_loss: 0.9519 - val_accuracy: 0.6550\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8355 - accuracy: 0.7258 - val_loss: 0.9526 - val_accuracy: 0.6560\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8273 - accuracy: 0.7429 - val_loss: 0.9543 - val_accuracy: 0.6570\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8256 - accuracy: 0.7346 - val_loss: 0.9535 - val_accuracy: 0.6591\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8159 - accuracy: 0.7439 - val_loss: 0.9600 - val_accuracy: 0.6550\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8196 - accuracy: 0.7411 - val_loss: 0.9593 - val_accuracy: 0.6508\n","Epoch 35/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8214 - accuracy: 0.7406 - val_loss: 0.9534 - val_accuracy: 0.6622\n","Epoch 36/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8131 - accuracy: 0.7439 - val_loss: 0.9594 - val_accuracy: 0.6653\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8042 - accuracy: 0.7426 - val_loss: 0.9742 - val_accuracy: 0.6426\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8111 - accuracy: 0.7385 - val_loss: 0.9509 - val_accuracy: 0.6653\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8022 - accuracy: 0.7496 - val_loss: 0.9555 - val_accuracy: 0.6477\n","Epoch 40/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7978 - accuracy: 0.7481 - val_loss: 0.9493 - val_accuracy: 0.6508\n","Epoch 41/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7960 - accuracy: 0.7491 - val_loss: 0.9515 - val_accuracy: 0.6622\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7811 - accuracy: 0.7599 - val_loss: 0.9762 - val_accuracy: 0.6601\n","Epoch 43/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7833 - accuracy: 0.7499 - val_loss: 0.9538 - val_accuracy: 0.6643\n","Epoch 44/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7813 - accuracy: 0.7548 - val_loss: 0.9612 - val_accuracy: 0.6539\n","Epoch 45/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7723 - accuracy: 0.7602 - val_loss: 0.9564 - val_accuracy: 0.6581\n","Epoch 46/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7659 - accuracy: 0.7612 - val_loss: 0.9521 - val_accuracy: 0.6694\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7610 - accuracy: 0.7615 - val_loss: 0.9571 - val_accuracy: 0.6508\n","Epoch 48/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7608 - accuracy: 0.7641 - val_loss: 0.9645 - val_accuracy: 0.6705\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7534 - accuracy: 0.7687 - val_loss: 0.9579 - val_accuracy: 0.6643\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7506 - accuracy: 0.7669 - val_loss: 0.9563 - val_accuracy: 0.6601\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7506 - accuracy: 0.7656 - val_loss: 0.9726 - val_accuracy: 0.6539\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7422 - accuracy: 0.7721 - val_loss: 0.9802 - val_accuracy: 0.6467\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7408 - accuracy: 0.7718 - val_loss: 0.9562 - val_accuracy: 0.6674\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7300 - accuracy: 0.7819 - val_loss: 0.9644 - val_accuracy: 0.6539\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7298 - accuracy: 0.7837 - val_loss: 0.9566 - val_accuracy: 0.6632\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7255 - accuracy: 0.7747 - val_loss: 0.9698 - val_accuracy: 0.6508\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7253 - accuracy: 0.7806 - val_loss: 0.9618 - val_accuracy: 0.6663\n","Epoch 58/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7203 - accuracy: 0.7814 - val_loss: 0.9695 - val_accuracy: 0.6622\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7182 - accuracy: 0.7793 - val_loss: 0.9670 - val_accuracy: 0.6622\n","Epoch 60/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7171 - accuracy: 0.7775 - val_loss: 0.9664 - val_accuracy: 0.6736\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7091 - accuracy: 0.7791 - val_loss: 0.9776 - val_accuracy: 0.6550\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7115 - accuracy: 0.7796 - val_loss: 1.0079 - val_accuracy: 0.6457\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7216 - accuracy: 0.7734 - val_loss: 0.9786 - val_accuracy: 0.6653\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6933 - accuracy: 0.7979 - val_loss: 0.9720 - val_accuracy: 0.6612\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6921 - accuracy: 0.7972 - val_loss: 0.9839 - val_accuracy: 0.6643\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6999 - accuracy: 0.7860 - val_loss: 0.9726 - val_accuracy: 0.6643\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6887 - accuracy: 0.7990 - val_loss: 0.9824 - val_accuracy: 0.6519\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6789 - accuracy: 0.7969 - val_loss: 0.9735 - val_accuracy: 0.6674\n","Epoch 69/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6779 - accuracy: 0.8005 - val_loss: 0.9763 - val_accuracy: 0.6756\n","Epoch 70/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6807 - accuracy: 0.7974 - val_loss: 0.9750 - val_accuracy: 0.6839\n","Epoch 71/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6760 - accuracy: 0.7956 - val_loss: 0.9822 - val_accuracy: 0.6601\n","Epoch 72/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6703 - accuracy: 0.7997 - val_loss: 0.9731 - val_accuracy: 0.6767\n","Epoch 73/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6610 - accuracy: 0.8085 - val_loss: 0.9758 - val_accuracy: 0.6829\n","Epoch 74/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6636 - accuracy: 0.8036 - val_loss: 0.9857 - val_accuracy: 0.6612\n","Epoch 75/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6600 - accuracy: 0.8129 - val_loss: 0.9816 - val_accuracy: 0.6715\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6477 - accuracy: 0.8106 - val_loss: 0.9816 - val_accuracy: 0.6725\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6487 - accuracy: 0.8083 - val_loss: 0.9814 - val_accuracy: 0.6818\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6466 - accuracy: 0.8080 - val_loss: 0.9890 - val_accuracy: 0.6777\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6346 - accuracy: 0.8196 - val_loss: 0.9879 - val_accuracy: 0.6746\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6375 - accuracy: 0.8145 - val_loss: 0.9917 - val_accuracy: 0.6705\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6356 - accuracy: 0.8168 - val_loss: 0.9952 - val_accuracy: 0.6798\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6255 - accuracy: 0.8243 - val_loss: 1.0128 - val_accuracy: 0.6694\n","Epoch 83/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6309 - accuracy: 0.8176 - val_loss: 1.0135 - val_accuracy: 0.6581\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6140 - accuracy: 0.8295 - val_loss: 1.0153 - val_accuracy: 0.6622\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6198 - accuracy: 0.8274 - val_loss: 1.0336 - val_accuracy: 0.6725\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6090 - accuracy: 0.8331 - val_loss: 1.0161 - val_accuracy: 0.6756\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6189 - accuracy: 0.8214 - val_loss: 1.0444 - val_accuracy: 0.6560\n","Epoch 88/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5997 - accuracy: 0.8292 - val_loss: 1.0129 - val_accuracy: 0.6715\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6155 - accuracy: 0.8199 - val_loss: 1.0226 - val_accuracy: 0.6663\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6009 - accuracy: 0.8331 - val_loss: 1.0292 - val_accuracy: 0.6777\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6072 - accuracy: 0.8243 - val_loss: 1.0342 - val_accuracy: 0.6601\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5945 - accuracy: 0.8339 - val_loss: 1.0386 - val_accuracy: 0.6653\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5858 - accuracy: 0.8395 - val_loss: 1.0263 - val_accuracy: 0.6684\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5846 - accuracy: 0.8362 - val_loss: 1.0309 - val_accuracy: 0.6674\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5874 - accuracy: 0.8370 - val_loss: 1.0461 - val_accuracy: 0.6777\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5799 - accuracy: 0.8380 - val_loss: 1.0517 - val_accuracy: 0.6529\n","Epoch 97/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5660 - accuracy: 0.8568 - val_loss: 1.0451 - val_accuracy: 0.6581\n","Epoch 98/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5690 - accuracy: 0.8429 - val_loss: 1.0487 - val_accuracy: 0.6705\n","Epoch 99/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5660 - accuracy: 0.8537 - val_loss: 1.0549 - val_accuracy: 0.6632\n","Epoch 100/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5562 - accuracy: 0.8535 - val_loss: 1.0636 - val_accuracy: 0.6674\n","{'loss': [0.9788560271263123, 0.9667292833328247, 0.9596716165542603, 0.9569800496101379, 0.9513124227523804, 0.944310188293457, 0.9412147998809814, 0.9356648325920105, 0.9271668791770935, 0.9227885603904724, 0.9181547164916992, 0.9127413630485535, 0.9113253355026245, 0.9035897850990295, 0.9043015837669373, 0.8993704915046692, 0.8925999999046326, 0.8893383741378784, 0.8817827105522156, 0.8787806630134583, 0.8795660138130188, 0.8718500137329102, 0.8642284274101257, 0.867106020450592, 0.8595678806304932, 0.8522812128067017, 0.8509420156478882, 0.8459058403968811, 0.8430560231208801, 0.8355118036270142, 0.8272697925567627, 0.8256008625030518, 0.8158960342407227, 0.8195789456367493, 0.8213991522789001, 0.813099205493927, 0.8042135834693909, 0.8110533356666565, 0.8021577596664429, 0.7978132963180542, 0.7960160374641418, 0.7811471819877625, 0.7833244204521179, 0.7812768220901489, 0.7723399996757507, 0.7658888697624207, 0.7609612345695496, 0.7608005404472351, 0.7534445524215698, 0.7505743503570557, 0.7506334781646729, 0.7421878576278687, 0.740833580493927, 0.729956865310669, 0.7297942638397217, 0.7255222201347351, 0.7253060340881348, 0.7202826142311096, 0.7181786298751831, 0.71708744764328, 0.7090685367584229, 0.7115271091461182, 0.7215926051139832, 0.6932817697525024, 0.6920965909957886, 0.6999076008796692, 0.6886623501777649, 0.6788992285728455, 0.677894651889801, 0.6807114481925964, 0.6759822368621826, 0.670274019241333, 0.6609833836555481, 0.6635778546333313, 0.6599708199501038, 0.6477494835853577, 0.648738443851471, 0.6466240286827087, 0.6346424221992493, 0.6374859809875488, 0.6355690360069275, 0.6254506707191467, 0.6308844685554504, 0.6139687299728394, 0.6198150515556335, 0.6090198755264282, 0.6188849210739136, 0.599712610244751, 0.6155001521110535, 0.6008939146995544, 0.6071673631668091, 0.594490110874176, 0.5858279466629028, 0.5845869779586792, 0.5874220728874207, 0.5799432396888733, 0.5660102367401123, 0.5689741373062134, 0.5659556984901428, 0.5562248229980469], 'accuracy': [0.6764857769012451, 0.6855297088623047, 0.6922480463981628, 0.6842377185821533, 0.6925064325332642, 0.6906976699829102, 0.6968992352485657, 0.6958656311035156, 0.7049095630645752, 0.7043927907943726, 0.7134366631507874, 0.7082687616348267, 0.7077519297599792, 0.7136951088905334, 0.7062015533447266, 0.7124031186103821, 0.7116279006004333, 0.7147286534309387, 0.724547803401947, 0.7155038714408875, 0.7139534950256348, 0.7209302186965942, 0.7279070019721985, 0.7175710797309875, 0.7232558131217957, 0.7304909825325012, 0.7248061895370483, 0.7260981798171997, 0.736692488193512, 0.7258397936820984, 0.7428940534591675, 0.7346253395080566, 0.7439276576042175, 0.7410852909088135, 0.7405684590339661, 0.7439276576042175, 0.7426356673240662, 0.7385013103485107, 0.7496123909950256, 0.748062014579773, 0.749095618724823, 0.7599483132362366, 0.749870777130127, 0.7547803521156311, 0.7602066993713379, 0.7612403035163879, 0.7614986896514893, 0.764082670211792, 0.7687338590621948, 0.766925036907196, 0.7656330466270447, 0.7720929980278015, 0.7718346118927002, 0.7819121479988098, 0.7837209105491638, 0.7746769785881042, 0.7806201577186584, 0.7813953757286072, 0.7793281674385071, 0.7775194048881531, 0.7790697813034058, 0.7795865535736084, 0.7733849883079529, 0.7979328036308289, 0.7971576452255249, 0.7860465049743652, 0.7989664077758789, 0.7968991994857788, 0.8005167841911316, 0.7974160313606262, 0.7956072092056274, 0.7997416257858276, 0.8085271120071411, 0.8036175966262817, 0.8129199147224426, 0.8105943202972412, 0.8082687258720398, 0.8080103397369385, 0.8196382522583008, 0.8144702911376953, 0.8167958855628967, 0.8242893815040588, 0.8175710439682007, 0.8294573426246643, 0.827390193939209, 0.8330749273300171, 0.8214470148086548, 0.829198956489563, 0.8198966383934021, 0.8330749273300171, 0.8242893815040588, 0.8338501453399658, 0.8395348787307739, 0.8361757397651672, 0.8369508981704712, 0.8379845023155212, 0.8568475246429443, 0.8428940773010254, 0.853746771812439, 0.8534883856773376], 'val_loss': [1.061435341835022, 1.0562771558761597, 1.0541342496871948, 1.0476500988006592, 1.0425288677215576, 1.0389537811279297, 1.0340540409088135, 1.026824951171875, 1.023379921913147, 1.017443299293518, 1.00913667678833, 1.0025606155395508, 0.9942498207092285, 0.9871948957443237, 0.9806081056594849, 0.9766702651977539, 0.9710097312927246, 0.9655055403709412, 0.9637014865875244, 0.9598459005355835, 0.9606291651725769, 0.955800473690033, 0.9553343653678894, 0.9551829099655151, 0.9525054693222046, 0.9536688327789307, 0.9583000540733337, 0.956718921661377, 0.9518997073173523, 0.9525591731071472, 0.9542651176452637, 0.9535138010978699, 0.9600282311439514, 0.9593008756637573, 0.9533737897872925, 0.9594343900680542, 0.9741930961608887, 0.9509328007698059, 0.9555021524429321, 0.9492797255516052, 0.9514886140823364, 0.9762046337127686, 0.9537732601165771, 0.9612119197845459, 0.9564253091812134, 0.9521375298500061, 0.9571366906166077, 0.9644738435745239, 0.9578933715820312, 0.9563313126564026, 0.9726174473762512, 0.9802150130271912, 0.9562094807624817, 0.964358389377594, 0.9565728902816772, 0.9698401093482971, 0.9618315100669861, 0.9695224165916443, 0.9669879078865051, 0.9664092659950256, 0.9775538444519043, 1.0079185962677002, 0.9786336421966553, 0.972037136554718, 0.9838640689849854, 0.9725636839866638, 0.9823632836341858, 0.973465621471405, 0.9763107299804688, 0.9750256538391113, 0.9822279810905457, 0.9731267690658569, 0.9757911562919617, 0.9856592416763306, 0.9815922379493713, 0.981632649898529, 0.9814350008964539, 0.9889605641365051, 0.9879209399223328, 0.9917252063751221, 0.9951720833778381, 1.0128417015075684, 1.0135424137115479, 1.0153156518936157, 1.033644437789917, 1.016080379486084, 1.0444096326828003, 1.0129204988479614, 1.022605538368225, 1.0292279720306396, 1.034246802330017, 1.0385853052139282, 1.0262515544891357, 1.0308966636657715, 1.046107530593872, 1.0516891479492188, 1.0450904369354248, 1.0487220287322998, 1.054906964302063, 1.0635524988174438], 'val_accuracy': [0.4927685856819153, 0.5, 0.4969008266925812, 0.5165289044380188, 0.5227272510528564, 0.5247933864593506, 0.5340909361839294, 0.5526859760284424, 0.5557851195335388, 0.5630165338516235, 0.6033057570457458, 0.6084710955619812, 0.6373966932296753, 0.6539255976676941, 0.6508264541625977, 0.6487603187561035, 0.6508264541625977, 0.6487603187561035, 0.64462810754776, 0.6539255976676941, 0.6425619721412659, 0.6487603187561035, 0.6611570119857788, 0.6549586653709412, 0.6559917330741882, 0.6477272510528564, 0.6508264541625977, 0.6518595218658447, 0.6549586653709412, 0.6559917330741882, 0.6570248007774353, 0.6590909361839294, 0.6549586653709412, 0.6508264541625977, 0.6621900796890259, 0.6652892827987671, 0.6425619721412659, 0.6652892827987671, 0.6477272510528564, 0.6508264541625977, 0.6621900796890259, 0.6601239442825317, 0.66425621509552, 0.6539255976676941, 0.6580578684806824, 0.6694214940071106, 0.6508264541625977, 0.6704545617103577, 0.66425621509552, 0.6601239442825317, 0.6539255976676941, 0.6466942429542542, 0.6673553586006165, 0.6539255976676941, 0.663223147392273, 0.6508264541625977, 0.6663222908973694, 0.6621900796890259, 0.6621900796890259, 0.6735537052154541, 0.6549586653709412, 0.6456611752510071, 0.6652892827987671, 0.6611570119857788, 0.66425621509552, 0.66425621509552, 0.6518595218658447, 0.6673553586006165, 0.6756198406219482, 0.68388432264328, 0.6601239442825317, 0.6766529083251953, 0.682851254940033, 0.6611570119857788, 0.6714876294136047, 0.672520637512207, 0.6818181872367859, 0.6776859760284424, 0.6745867729187012, 0.6704545617103577, 0.6797520518302917, 0.6694214940071106, 0.6580578684806824, 0.6621900796890259, 0.672520637512207, 0.6756198406219482, 0.6559917330741882, 0.6714876294136047, 0.6663222908973694, 0.6776859760284424, 0.6601239442825317, 0.6652892827987671, 0.6683884263038635, 0.6673553586006165, 0.6776859760284424, 0.6528925895690918, 0.6580578684806824, 0.6704545617103577, 0.663223147392273, 0.6673553586006165]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 0.6520 - accuracy: 0.8073"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 6s 59ms/step - loss: 0.6551 - accuracy: 0.8033 - val_loss: 1.0913 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6384 - accuracy: 0.8063 - val_loss: 1.0992 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6237 - accuracy: 0.8203 - val_loss: 1.1032 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6198 - accuracy: 0.8206 - val_loss: 1.1058 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6264 - accuracy: 0.8227 - val_loss: 1.1101 - val_accuracy: 0.4860\n","Epoch 6/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6101 - accuracy: 0.8284 - val_loss: 1.1103 - val_accuracy: 0.4860\n","Epoch 7/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6109 - accuracy: 0.8244 - val_loss: 1.1102 - val_accuracy: 0.4860\n","Epoch 8/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6073 - accuracy: 0.8287 - val_loss: 1.1030 - val_accuracy: 0.4892\n","Epoch 9/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6063 - accuracy: 0.8284 - val_loss: 1.1060 - val_accuracy: 0.4925\n","Epoch 10/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5985 - accuracy: 0.8359 - val_loss: 1.0952 - val_accuracy: 0.4957\n","Epoch 11/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5884 - accuracy: 0.8448 - val_loss: 1.0844 - val_accuracy: 0.4968\n","Epoch 12/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5912 - accuracy: 0.8373 - val_loss: 1.0882 - val_accuracy: 0.4989\n","Epoch 13/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5839 - accuracy: 0.8354 - val_loss: 1.0722 - val_accuracy: 0.5054\n","Epoch 14/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5799 - accuracy: 0.8408 - val_loss: 1.0765 - val_accuracy: 0.5140\n","Epoch 15/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.5705 - accuracy: 0.8456 - val_loss: 1.0132 - val_accuracy: 0.5366\n","Epoch 16/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5688 - accuracy: 0.8508 - val_loss: 1.0546 - val_accuracy: 0.5345\n","Epoch 17/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5802 - accuracy: 0.8400 - val_loss: 1.0688 - val_accuracy: 0.5409\n","Epoch 18/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5760 - accuracy: 0.8400 - val_loss: 0.9582 - val_accuracy: 0.5787\n","Epoch 19/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5723 - accuracy: 0.8419 - val_loss: 0.9023 - val_accuracy: 0.6078\n","Epoch 20/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5614 - accuracy: 0.8473 - val_loss: 0.9146 - val_accuracy: 0.6175\n","Epoch 21/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5629 - accuracy: 0.8494 - val_loss: 0.8856 - val_accuracy: 0.6466\n","Epoch 22/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5547 - accuracy: 0.8545 - val_loss: 0.8988 - val_accuracy: 0.6358\n","Epoch 23/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5578 - accuracy: 0.8537 - val_loss: 0.8463 - val_accuracy: 0.6767\n","Epoch 24/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.5464 - accuracy: 0.8516 - val_loss: 0.8222 - val_accuracy: 0.6907\n","Epoch 25/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.5513 - accuracy: 0.8543 - val_loss: 0.8256 - val_accuracy: 0.6940\n","Epoch 26/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5358 - accuracy: 0.8605 - val_loss: 0.8154 - val_accuracy: 0.7112\n","Epoch 27/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5422 - accuracy: 0.8591 - val_loss: 0.8354 - val_accuracy: 0.7123\n","Epoch 28/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5316 - accuracy: 0.8699 - val_loss: 0.8285 - val_accuracy: 0.7198\n","Epoch 29/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.5414 - accuracy: 0.8621 - val_loss: 0.8398 - val_accuracy: 0.7274\n","Epoch 30/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5265 - accuracy: 0.8661 - val_loss: 0.8396 - val_accuracy: 0.7188\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5256 - accuracy: 0.8669 - val_loss: 0.8451 - val_accuracy: 0.7274\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5215 - accuracy: 0.8637 - val_loss: 0.8481 - val_accuracy: 0.7188\n","Epoch 33/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5190 - accuracy: 0.8640 - val_loss: 0.8586 - val_accuracy: 0.7295\n","Epoch 34/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5266 - accuracy: 0.8693 - val_loss: 0.8936 - val_accuracy: 0.7177\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5238 - accuracy: 0.8618 - val_loss: 0.8793 - val_accuracy: 0.7231\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5067 - accuracy: 0.8723 - val_loss: 0.8736 - val_accuracy: 0.7209\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5099 - accuracy: 0.8704 - val_loss: 0.8855 - val_accuracy: 0.7188\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5051 - accuracy: 0.8702 - val_loss: 0.8926 - val_accuracy: 0.7037\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5071 - accuracy: 0.8720 - val_loss: 0.8916 - val_accuracy: 0.7284\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5095 - accuracy: 0.8699 - val_loss: 0.8748 - val_accuracy: 0.7295\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4978 - accuracy: 0.8785 - val_loss: 0.9002 - val_accuracy: 0.7198\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4994 - accuracy: 0.8685 - val_loss: 0.8825 - val_accuracy: 0.7252\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4877 - accuracy: 0.8755 - val_loss: 0.8890 - val_accuracy: 0.7284\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4793 - accuracy: 0.8839 - val_loss: 0.9730 - val_accuracy: 0.6756\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4919 - accuracy: 0.8777 - val_loss: 0.9027 - val_accuracy: 0.7209\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4854 - accuracy: 0.8820 - val_loss: 0.9382 - val_accuracy: 0.7134\n","Epoch 47/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4808 - accuracy: 0.8809 - val_loss: 0.9008 - val_accuracy: 0.7144\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4830 - accuracy: 0.8834 - val_loss: 0.9124 - val_accuracy: 0.7144\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4812 - accuracy: 0.8815 - val_loss: 0.9191 - val_accuracy: 0.7241\n","Epoch 50/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4821 - accuracy: 0.8823 - val_loss: 0.9834 - val_accuracy: 0.6810\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4853 - accuracy: 0.8796 - val_loss: 0.9203 - val_accuracy: 0.7144\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4857 - accuracy: 0.8812 - val_loss: 1.0151 - val_accuracy: 0.6756\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4760 - accuracy: 0.8777 - val_loss: 0.9293 - val_accuracy: 0.7112\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4629 - accuracy: 0.8882 - val_loss: 0.9099 - val_accuracy: 0.7231\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4630 - accuracy: 0.8909 - val_loss: 0.9282 - val_accuracy: 0.7188\n","Epoch 56/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4678 - accuracy: 0.8879 - val_loss: 0.9300 - val_accuracy: 0.7177\n","Epoch 57/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4564 - accuracy: 0.8925 - val_loss: 0.9420 - val_accuracy: 0.7155\n","Epoch 58/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4578 - accuracy: 0.8957 - val_loss: 0.9266 - val_accuracy: 0.7080\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4520 - accuracy: 0.8963 - val_loss: 0.9189 - val_accuracy: 0.7188\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4507 - accuracy: 0.8898 - val_loss: 0.9342 - val_accuracy: 0.7209\n","Epoch 61/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4392 - accuracy: 0.9001 - val_loss: 0.9556 - val_accuracy: 0.7198\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4389 - accuracy: 0.8987 - val_loss: 0.9396 - val_accuracy: 0.7091\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4358 - accuracy: 0.9003 - val_loss: 0.9467 - val_accuracy: 0.7112\n","Epoch 64/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4322 - accuracy: 0.9009 - val_loss: 1.0040 - val_accuracy: 0.6821\n","Epoch 65/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4358 - accuracy: 0.8960 - val_loss: 0.9463 - val_accuracy: 0.7220\n","Epoch 66/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4324 - accuracy: 0.9044 - val_loss: 0.9504 - val_accuracy: 0.7209\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4371 - accuracy: 0.8987 - val_loss: 1.0034 - val_accuracy: 0.6886\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4346 - accuracy: 0.8984 - val_loss: 0.9571 - val_accuracy: 0.7198\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4243 - accuracy: 0.8990 - val_loss: 0.9567 - val_accuracy: 0.7144\n","Epoch 70/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4221 - accuracy: 0.9052 - val_loss: 1.0088 - val_accuracy: 0.7091\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4211 - accuracy: 0.9076 - val_loss: 0.9811 - val_accuracy: 0.7198\n","Epoch 72/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4232 - accuracy: 0.9041 - val_loss: 1.0195 - val_accuracy: 0.7112\n","Epoch 73/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4235 - accuracy: 0.9017 - val_loss: 0.9764 - val_accuracy: 0.7198\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4115 - accuracy: 0.9106 - val_loss: 0.9925 - val_accuracy: 0.7155\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4214 - accuracy: 0.9030 - val_loss: 1.0802 - val_accuracy: 0.7209\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4319 - accuracy: 0.8949 - val_loss: 1.0273 - val_accuracy: 0.7188\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4145 - accuracy: 0.9071 - val_loss: 1.0056 - val_accuracy: 0.7080\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4078 - accuracy: 0.9068 - val_loss: 1.0058 - val_accuracy: 0.7155\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3979 - accuracy: 0.9186 - val_loss: 1.0082 - val_accuracy: 0.7112\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3936 - accuracy: 0.9195 - val_loss: 0.9999 - val_accuracy: 0.7198\n","Epoch 81/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3915 - accuracy: 0.9173 - val_loss: 1.0108 - val_accuracy: 0.7177\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3957 - accuracy: 0.9195 - val_loss: 1.0251 - val_accuracy: 0.7112\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3999 - accuracy: 0.9130 - val_loss: 1.0793 - val_accuracy: 0.6972\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3999 - accuracy: 0.9138 - val_loss: 1.0901 - val_accuracy: 0.6929\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4046 - accuracy: 0.9168 - val_loss: 1.0785 - val_accuracy: 0.7037\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3886 - accuracy: 0.9208 - val_loss: 1.0779 - val_accuracy: 0.7037\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3948 - accuracy: 0.9138 - val_loss: 1.0175 - val_accuracy: 0.7144\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3909 - accuracy: 0.9232 - val_loss: 1.0376 - val_accuracy: 0.7263\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3870 - accuracy: 0.9168 - val_loss: 1.0486 - val_accuracy: 0.7155\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3782 - accuracy: 0.9240 - val_loss: 1.0315 - val_accuracy: 0.7220\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3818 - accuracy: 0.9197 - val_loss: 1.0593 - val_accuracy: 0.7188\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3785 - accuracy: 0.9251 - val_loss: 1.0478 - val_accuracy: 0.7263\n","Epoch 93/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3844 - accuracy: 0.9205 - val_loss: 1.0485 - val_accuracy: 0.7231\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3781 - accuracy: 0.9246 - val_loss: 1.0587 - val_accuracy: 0.7274\n","Epoch 95/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3736 - accuracy: 0.9275 - val_loss: 1.0481 - val_accuracy: 0.7241\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3661 - accuracy: 0.9254 - val_loss: 1.0543 - val_accuracy: 0.7252\n","Epoch 97/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3744 - accuracy: 0.9259 - val_loss: 1.0832 - val_accuracy: 0.7166\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3677 - accuracy: 0.9300 - val_loss: 1.0587 - val_accuracy: 0.7188\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3637 - accuracy: 0.9297 - val_loss: 1.0966 - val_accuracy: 0.7177\n","Epoch 100/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3656 - accuracy: 0.9329 - val_loss: 1.0706 - val_accuracy: 0.7241\n","{'loss': [0.6550533771514893, 0.6384408473968506, 0.6237229108810425, 0.6197633147239685, 0.6263574361801147, 0.6100806593894958, 0.6108953356742859, 0.6073006987571716, 0.6063219308853149, 0.5985414981842041, 0.5883525609970093, 0.5911707878112793, 0.5838630199432373, 0.5799420475959778, 0.5704882144927979, 0.5688090324401855, 0.5801838636398315, 0.5760000944137573, 0.5722765326499939, 0.5614122152328491, 0.5629184246063232, 0.5547189116477966, 0.5578006505966187, 0.5464385747909546, 0.5512552261352539, 0.5357689261436462, 0.5422413945198059, 0.5315540432929993, 0.5413612127304077, 0.5265346765518188, 0.5256226658821106, 0.5215056538581848, 0.5189962983131409, 0.5266497135162354, 0.5237987637519836, 0.506673276424408, 0.5099337100982666, 0.505095362663269, 0.5071014165878296, 0.5094500184059143, 0.49777546525001526, 0.4993501901626587, 0.4876604378223419, 0.4792972505092621, 0.49187973141670227, 0.48541438579559326, 0.48083123564720154, 0.48296189308166504, 0.4811657667160034, 0.48209160566329956, 0.48533904552459717, 0.48572948575019836, 0.4760071039199829, 0.46288996934890747, 0.4630320072174072, 0.467797189950943, 0.4564256966114044, 0.4578101634979248, 0.4519876539707184, 0.4507061541080475, 0.43921953439712524, 0.4389428198337555, 0.4357948303222656, 0.43220895528793335, 0.4358167052268982, 0.43236416578292847, 0.437104195356369, 0.4346402585506439, 0.4242592453956604, 0.4220593571662903, 0.4210686981678009, 0.42322486639022827, 0.423469215631485, 0.4115426540374756, 0.42142176628112793, 0.43193861842155457, 0.4145173132419586, 0.4078315198421478, 0.39786455035209656, 0.3935730755329132, 0.3915117084980011, 0.3956558406352997, 0.3998982012271881, 0.3998637795448303, 0.4045916199684143, 0.3886367976665497, 0.39482244849205017, 0.3908885717391968, 0.387034147977829, 0.378162145614624, 0.3817651867866516, 0.3785180449485779, 0.38440364599227905, 0.37811869382858276, 0.3735848665237427, 0.36606165766716003, 0.374438613653183, 0.3677147626876831, 0.36367541551589966, 0.3656098544597626], 'accuracy': [0.803340494632721, 0.806303858757019, 0.8203125, 0.8205819129943848, 0.8227370977401733, 0.8283944129943848, 0.8243534564971924, 0.8286637663841248, 0.8283944129943848, 0.8359375, 0.8448275923728943, 0.837284505367279, 0.8353987336158752, 0.8407866358757019, 0.8456357717514038, 0.8507543206214905, 0.8399784564971924, 0.8399784564971924, 0.8418642282485962, 0.8472521305084229, 0.8494073152542114, 0.8545258641242981, 0.8537176847457886, 0.8515625, 0.8542564511299133, 0.8604525923728943, 0.8591055870056152, 0.8698814511299133, 0.8620689511299133, 0.8661099076271057, 0.8669180870056152, 0.8636853694915771, 0.8639547228813171, 0.8693426847457886, 0.8617995977401733, 0.8723060488700867, 0.8704202771186829, 0.8701508641242981, 0.8720366358757019, 0.8698814511299133, 0.8785021305084229, 0.868534505367279, 0.8755387663841248, 0.8838900923728943, 0.8776939511299133, 0.8820043206214905, 0.8809267282485962, 0.8833512663841248, 0.881465494632721, 0.8822737336158752, 0.8795797228813171, 0.881196141242981, 0.8776939511299133, 0.8882004022598267, 0.8908944129943848, 0.8879310488700867, 0.8925107717514038, 0.8957435488700867, 0.8962823152542114, 0.8898168206214905, 0.900053858757019, 0.8987069129943848, 0.9003232717514038, 0.9008620977401733, 0.8960129022598267, 0.9043642282485962, 0.8987069129943848, 0.8984375, 0.8989762663841248, 0.9051724076271057, 0.907597005367279, 0.9040948152542114, 0.9016702771186829, 0.9105603694915771, 0.9030172228813171, 0.8949353694915771, 0.9070581793785095, 0.9067887663841248, 0.9186422228813171, 0.9194504022598267, 0.9172952771186829, 0.9194504022598267, 0.9129849076271057, 0.9137930870056152, 0.9167564511299133, 0.9207974076271057, 0.9137930870056152, 0.923222005367279, 0.9167564511299133, 0.9240301847457886, 0.9197198152542114, 0.9251077771186829, 0.920527994632721, 0.9245689511299133, 0.9275323152542114, 0.9253771305084229, 0.9259159564971924, 0.9299569129943848, 0.9296875, 0.9329202771186829], 'val_loss': [1.0913358926773071, 1.0992140769958496, 1.10316002368927, 1.1057597398757935, 1.1101466417312622, 1.1102622747421265, 1.1102285385131836, 1.1029506921768188, 1.1059857606887817, 1.0952478647232056, 1.084445834159851, 1.0882220268249512, 1.0722044706344604, 1.0764926671981812, 1.0131826400756836, 1.0546175241470337, 1.068763017654419, 0.958229124546051, 0.9023392200469971, 0.9145627021789551, 0.8855839967727661, 0.8988178968429565, 0.8462536931037903, 0.8221927285194397, 0.8256195783615112, 0.8154457211494446, 0.8354191184043884, 0.8285030722618103, 0.8397619724273682, 0.8396300077438354, 0.8450717329978943, 0.848124623298645, 0.8585765957832336, 0.8936240673065186, 0.8793079853057861, 0.8735973834991455, 0.8855000734329224, 0.8925578594207764, 0.8916106224060059, 0.8747697472572327, 0.9001916646957397, 0.8825377225875854, 0.8890107870101929, 0.9730352759361267, 0.9027092456817627, 0.9381738901138306, 0.9007524847984314, 0.9123552441596985, 0.9191325902938843, 0.9833723306655884, 0.9202933311462402, 1.0151289701461792, 0.9293428659439087, 0.9098796844482422, 0.9281811118125916, 0.9300318360328674, 0.9419839978218079, 0.9265827536582947, 0.9188553094863892, 0.9341906309127808, 0.95560222864151, 0.9396264553070068, 0.9466683864593506, 1.0040103197097778, 0.9462836980819702, 0.9504188299179077, 1.0033668279647827, 0.957108736038208, 0.9567145705223083, 1.0088469982147217, 0.9811092615127563, 1.019519329071045, 0.9764123558998108, 0.9924502968788147, 1.0801880359649658, 1.0273023843765259, 1.0056289434432983, 1.005819320678711, 1.008237361907959, 0.9999325275421143, 1.0107886791229248, 1.0251277685165405, 1.0793306827545166, 1.0900774002075195, 1.0784767866134644, 1.0779238939285278, 1.0175068378448486, 1.0376267433166504, 1.0486449003219604, 1.0314970016479492, 1.0593034029006958, 1.0478137731552124, 1.0484846830368042, 1.058666706085205, 1.048094391822815, 1.054279088973999, 1.0832045078277588, 1.0587174892425537, 1.0966038703918457, 1.07058846950531], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.4892241358757019, 0.4924568831920624, 0.49568966031074524, 0.4967672526836395, 0.4989224076271057, 0.5053879022598267, 0.514008641242981, 0.5366379022598267, 0.5344827771186829, 0.5409482717514038, 0.5786637663841248, 0.607758641242981, 0.6174569129943848, 0.6465517282485962, 0.6357758641242981, 0.6767241358757019, 0.6907327771186829, 0.693965494632721, 0.7112069129943848, 0.712284505367279, 0.7198275923728943, 0.7273706793785095, 0.71875, 0.7273706793785095, 0.71875, 0.7295258641242981, 0.7176724076271057, 0.7230603694915771, 0.7209051847457886, 0.71875, 0.7036637663841248, 0.7284482717514038, 0.7295258641242981, 0.7198275923728943, 0.725215494632721, 0.7284482717514038, 0.6756465435028076, 0.7209051847457886, 0.7133620977401733, 0.7144396305084229, 0.7144396305084229, 0.7241379022598267, 0.681034505367279, 0.7144396305084229, 0.6756465435028076, 0.7112069129943848, 0.7230603694915771, 0.71875, 0.7176724076271057, 0.7155172228813171, 0.7079741358757019, 0.71875, 0.7209051847457886, 0.7198275923728943, 0.7090517282485962, 0.7112069129943848, 0.6821120977401733, 0.7219827771186829, 0.7209051847457886, 0.6885775923728943, 0.7198275923728943, 0.7144396305084229, 0.7090517282485962, 0.7198275923728943, 0.7112069129943848, 0.7198275923728943, 0.7155172228813171, 0.7209051847457886, 0.71875, 0.7079741358757019, 0.7155172228813171, 0.7112069129943848, 0.7198275923728943, 0.7176724076271057, 0.7112069129943848, 0.6971982717514038, 0.6928879022598267, 0.7036637663841248, 0.7036637663841248, 0.7144396305084229, 0.7262930870056152, 0.7155172228813171, 0.7219827771186829, 0.71875, 0.7262930870056152, 0.7230603694915771, 0.7273706793785095, 0.7241379022598267, 0.725215494632721, 0.7165948152542114, 0.71875, 0.7176724076271057, 0.7241379022598267]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.6639 - accuracy: 0.8017"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 7s 51ms/step - loss: 0.6587 - accuracy: 0.8033 - val_loss: 1.0869 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6436 - accuracy: 0.8178 - val_loss: 1.0675 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6313 - accuracy: 0.8186 - val_loss: 1.0793 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6293 - accuracy: 0.8164 - val_loss: 1.0871 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6284 - accuracy: 0.8169 - val_loss: 1.0868 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6156 - accuracy: 0.8234 - val_loss: 1.0872 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6072 - accuracy: 0.8297 - val_loss: 1.0896 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6041 - accuracy: 0.8311 - val_loss: 1.1004 - val_accuracy: 0.4955\n","Epoch 9/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6113 - accuracy: 0.8234 - val_loss: 1.0973 - val_accuracy: 0.4966\n","Epoch 10/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.5960 - accuracy: 0.8319 - val_loss: 1.0757 - val_accuracy: 0.5011\n","Epoch 11/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.5921 - accuracy: 0.8302 - val_loss: 1.0773 - val_accuracy: 0.5034\n","Epoch 12/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5936 - accuracy: 0.8333 - val_loss: 1.0787 - val_accuracy: 0.5057\n","Epoch 13/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5869 - accuracy: 0.8316 - val_loss: 1.0790 - val_accuracy: 0.5113\n","Epoch 14/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5845 - accuracy: 0.8444 - val_loss: 1.0289 - val_accuracy: 0.5294\n","Epoch 15/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5808 - accuracy: 0.8364 - val_loss: 1.0282 - val_accuracy: 0.5328\n","Epoch 16/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5821 - accuracy: 0.8314 - val_loss: 1.0043 - val_accuracy: 0.5430\n","Epoch 17/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5665 - accuracy: 0.8523 - val_loss: 0.9696 - val_accuracy: 0.5713\n","Epoch 18/100\n","28/28 [==============================] - 2s 60ms/step - loss: 0.5681 - accuracy: 0.8458 - val_loss: 0.9164 - val_accuracy: 0.5905\n","Epoch 19/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5686 - accuracy: 0.8376 - val_loss: 0.8948 - val_accuracy: 0.6041\n","Epoch 20/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5651 - accuracy: 0.8410 - val_loss: 0.8619 - val_accuracy: 0.6188\n","Epoch 21/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5638 - accuracy: 0.8489 - val_loss: 0.8937 - val_accuracy: 0.6131\n","Epoch 22/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5569 - accuracy: 0.8526 - val_loss: 0.8337 - val_accuracy: 0.6448\n","Epoch 23/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5556 - accuracy: 0.8512 - val_loss: 0.8063 - val_accuracy: 0.6765\n","Epoch 24/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5489 - accuracy: 0.8512 - val_loss: 0.7981 - val_accuracy: 0.6867\n","Epoch 25/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5522 - accuracy: 0.8503 - val_loss: 0.7517 - val_accuracy: 0.7376\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5490 - accuracy: 0.8551 - val_loss: 0.7882 - val_accuracy: 0.7127\n","Epoch 27/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5418 - accuracy: 0.8582 - val_loss: 0.8223 - val_accuracy: 0.6878\n","Epoch 28/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5401 - accuracy: 0.8563 - val_loss: 0.7651 - val_accuracy: 0.7353\n","Epoch 29/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5351 - accuracy: 0.8636 - val_loss: 0.7992 - val_accuracy: 0.7070\n","Epoch 30/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5335 - accuracy: 0.8633 - val_loss: 0.7832 - val_accuracy: 0.7455\n","Epoch 31/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5289 - accuracy: 0.8650 - val_loss: 0.7881 - val_accuracy: 0.7410\n","Epoch 32/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5284 - accuracy: 0.8642 - val_loss: 0.7994 - val_accuracy: 0.7217\n","Epoch 33/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5188 - accuracy: 0.8701 - val_loss: 0.7944 - val_accuracy: 0.7455\n","Epoch 34/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5136 - accuracy: 0.8693 - val_loss: 0.7960 - val_accuracy: 0.7308\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5115 - accuracy: 0.8693 - val_loss: 0.8268 - val_accuracy: 0.7398\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5177 - accuracy: 0.8710 - val_loss: 0.8089 - val_accuracy: 0.7432\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5124 - accuracy: 0.8639 - val_loss: 0.8168 - val_accuracy: 0.7206\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5066 - accuracy: 0.8713 - val_loss: 0.8135 - val_accuracy: 0.7217\n","Epoch 39/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5043 - accuracy: 0.8761 - val_loss: 0.8235 - val_accuracy: 0.7398\n","Epoch 40/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5068 - accuracy: 0.8713 - val_loss: 0.8781 - val_accuracy: 0.7059\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5003 - accuracy: 0.8715 - val_loss: 0.8236 - val_accuracy: 0.7353\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5026 - accuracy: 0.8698 - val_loss: 0.8547 - val_accuracy: 0.7048\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4975 - accuracy: 0.8761 - val_loss: 0.8249 - val_accuracy: 0.7206\n","Epoch 44/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4985 - accuracy: 0.8775 - val_loss: 0.8323 - val_accuracy: 0.7410\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4859 - accuracy: 0.8797 - val_loss: 0.8452 - val_accuracy: 0.7127\n","Epoch 46/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4954 - accuracy: 0.8783 - val_loss: 0.8322 - val_accuracy: 0.7172\n","Epoch 47/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4844 - accuracy: 0.8848 - val_loss: 0.8537 - val_accuracy: 0.7229\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4744 - accuracy: 0.8848 - val_loss: 0.8418 - val_accuracy: 0.7308\n","Epoch 49/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4708 - accuracy: 0.8834 - val_loss: 0.8603 - val_accuracy: 0.7308\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4735 - accuracy: 0.8829 - val_loss: 0.8552 - val_accuracy: 0.7319\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4672 - accuracy: 0.8865 - val_loss: 0.8392 - val_accuracy: 0.7387\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4645 - accuracy: 0.8913 - val_loss: 0.8889 - val_accuracy: 0.6946\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4707 - accuracy: 0.8916 - val_loss: 0.8750 - val_accuracy: 0.7308\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4745 - accuracy: 0.8882 - val_loss: 0.8602 - val_accuracy: 0.7240\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4599 - accuracy: 0.8939 - val_loss: 0.8919 - val_accuracy: 0.7104\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4518 - accuracy: 0.8970 - val_loss: 0.8567 - val_accuracy: 0.7262\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4595 - accuracy: 0.8916 - val_loss: 0.8755 - val_accuracy: 0.7262\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4567 - accuracy: 0.8947 - val_loss: 0.8754 - val_accuracy: 0.7296\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4598 - accuracy: 0.8899 - val_loss: 0.8812 - val_accuracy: 0.7308\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4511 - accuracy: 0.8925 - val_loss: 0.8814 - val_accuracy: 0.7274\n","Epoch 61/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4452 - accuracy: 0.8981 - val_loss: 0.8722 - val_accuracy: 0.7342\n","Epoch 62/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4350 - accuracy: 0.9027 - val_loss: 0.8696 - val_accuracy: 0.7262\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4437 - accuracy: 0.8978 - val_loss: 0.8838 - val_accuracy: 0.7319\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4390 - accuracy: 0.9029 - val_loss: 0.9372 - val_accuracy: 0.6889\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4310 - accuracy: 0.9080 - val_loss: 0.9119 - val_accuracy: 0.7059\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4290 - accuracy: 0.9018 - val_loss: 0.9340 - val_accuracy: 0.6900\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4306 - accuracy: 0.9063 - val_loss: 0.9017 - val_accuracy: 0.7342\n","Epoch 68/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4248 - accuracy: 0.9055 - val_loss: 0.9063 - val_accuracy: 0.7183\n","Epoch 69/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4335 - accuracy: 0.8956 - val_loss: 0.9097 - val_accuracy: 0.7217\n","Epoch 70/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4217 - accuracy: 0.9052 - val_loss: 0.8969 - val_accuracy: 0.7296\n","Epoch 71/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4191 - accuracy: 0.9083 - val_loss: 0.9013 - val_accuracy: 0.7319\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4195 - accuracy: 0.9109 - val_loss: 0.8992 - val_accuracy: 0.7240\n","Epoch 73/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4145 - accuracy: 0.9114 - val_loss: 0.9211 - val_accuracy: 0.7296\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4083 - accuracy: 0.9100 - val_loss: 0.9083 - val_accuracy: 0.7330\n","Epoch 75/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4224 - accuracy: 0.9089 - val_loss: 1.0614 - val_accuracy: 0.6867\n","Epoch 76/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4213 - accuracy: 0.9080 - val_loss: 0.9012 - val_accuracy: 0.7342\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4068 - accuracy: 0.9188 - val_loss: 0.9187 - val_accuracy: 0.7330\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4102 - accuracy: 0.9038 - val_loss: 0.9257 - val_accuracy: 0.7353\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4055 - accuracy: 0.9143 - val_loss: 0.9304 - val_accuracy: 0.7251\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4110 - accuracy: 0.9148 - val_loss: 0.9215 - val_accuracy: 0.7195\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4153 - accuracy: 0.9061 - val_loss: 0.9637 - val_accuracy: 0.7161\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3983 - accuracy: 0.9140 - val_loss: 0.9271 - val_accuracy: 0.7443\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3963 - accuracy: 0.9168 - val_loss: 0.9351 - val_accuracy: 0.7240\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3956 - accuracy: 0.9154 - val_loss: 0.9424 - val_accuracy: 0.7195\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3952 - accuracy: 0.9131 - val_loss: 0.9505 - val_accuracy: 0.7262\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3951 - accuracy: 0.9143 - val_loss: 0.9515 - val_accuracy: 0.7161\n","Epoch 87/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3770 - accuracy: 0.9233 - val_loss: 0.9510 - val_accuracy: 0.7319\n","Epoch 88/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3821 - accuracy: 0.9219 - val_loss: 0.9680 - val_accuracy: 0.7262\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3903 - accuracy: 0.9109 - val_loss: 0.9617 - val_accuracy: 0.7195\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3864 - accuracy: 0.9171 - val_loss: 0.9720 - val_accuracy: 0.7240\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3764 - accuracy: 0.9261 - val_loss: 1.0389 - val_accuracy: 0.7014\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3889 - accuracy: 0.9188 - val_loss: 0.9689 - val_accuracy: 0.7296\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3769 - accuracy: 0.9233 - val_loss: 0.9639 - val_accuracy: 0.7195\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3671 - accuracy: 0.9256 - val_loss: 0.9655 - val_accuracy: 0.7262\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3653 - accuracy: 0.9312 - val_loss: 1.0150 - val_accuracy: 0.7025\n","Epoch 96/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3639 - accuracy: 0.9290 - val_loss: 0.9947 - val_accuracy: 0.7172\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3695 - accuracy: 0.9278 - val_loss: 0.9950 - val_accuracy: 0.7229\n","Epoch 98/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3577 - accuracy: 0.9346 - val_loss: 1.0084 - val_accuracy: 0.7127\n","Epoch 99/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3627 - accuracy: 0.9276 - val_loss: 1.0028 - val_accuracy: 0.7217\n","Epoch 100/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3594 - accuracy: 0.9293 - val_loss: 1.0468 - val_accuracy: 0.7070\n","{'loss': [0.6586731672286987, 0.6436311602592468, 0.6312969326972961, 0.6293205618858337, 0.6284127235412598, 0.6156200170516968, 0.6071958541870117, 0.6041313409805298, 0.6112743616104126, 0.596005916595459, 0.5920732021331787, 0.5936275124549866, 0.5869237184524536, 0.5844918489456177, 0.5807786583900452, 0.5821408033370972, 0.5664634108543396, 0.568107545375824, 0.5686017274856567, 0.5651159286499023, 0.5638089776039124, 0.556891679763794, 0.5555684566497803, 0.5488744378089905, 0.5521753430366516, 0.5489506721496582, 0.5418395400047302, 0.5400874018669128, 0.535144567489624, 0.5334518551826477, 0.528910756111145, 0.5284003019332886, 0.5187980532646179, 0.5135657787322998, 0.5114771723747253, 0.5177273750305176, 0.5124432444572449, 0.5066242814064026, 0.5042773485183716, 0.5067803859710693, 0.5002609491348267, 0.5026001930236816, 0.49745580554008484, 0.49846601486206055, 0.48590943217277527, 0.4954402446746826, 0.484365850687027, 0.47443315386772156, 0.4708103835582733, 0.47349974513053894, 0.4672032594680786, 0.4644969403743744, 0.47068923711776733, 0.4744521677494049, 0.4598942995071411, 0.4518163204193115, 0.4595451354980469, 0.4566645324230194, 0.4597782790660858, 0.4510975182056427, 0.4451581537723541, 0.43496525287628174, 0.44372648000717163, 0.4389965534210205, 0.4310080409049988, 0.42899090051651, 0.4306054413318634, 0.42480558156967163, 0.433510959148407, 0.42174676060676575, 0.41906851530075073, 0.4195404052734375, 0.41451650857925415, 0.40829330682754517, 0.4224391281604767, 0.4212730824947357, 0.4067930281162262, 0.410188764333725, 0.4054519832134247, 0.4110122621059418, 0.41533929109573364, 0.3983204960823059, 0.39626452326774597, 0.39556336402893066, 0.3952394127845764, 0.39513033628463745, 0.3769668638706207, 0.38208332657814026, 0.39032694697380066, 0.3863530457019806, 0.3764341473579407, 0.38894960284233093, 0.3768603205680847, 0.36713138222694397, 0.36534252762794495, 0.3639112114906311, 0.36954835057258606, 0.35769104957580566, 0.3627055883407593, 0.3593769371509552], 'accuracy': [0.8033390045166016, 0.81777024269104, 0.8186191320419312, 0.8163554072380066, 0.8169213533401489, 0.823429524898529, 0.8296547532081604, 0.8310695886611938, 0.823429524898529, 0.831918478012085, 0.8302206993103027, 0.8333333134651184, 0.8316355347633362, 0.8443689942359924, 0.8364459276199341, 0.8313525915145874, 0.852292001247406, 0.8457838296890259, 0.8375778198242188, 0.8409733772277832, 0.8488964438438416, 0.8525750041007996, 0.8511601686477661, 0.8511601686477661, 0.850311279296875, 0.8551216721534729, 0.8582342863082886, 0.8562535643577576, 0.8636106252670288, 0.86332768201828, 0.8650254607200623, 0.8641765713691711, 0.8701188564300537, 0.8692699670791626, 0.8692699670791626, 0.8709677457809448, 0.8638936281204224, 0.8712506890296936, 0.8760611414909363, 0.8712506890296936, 0.8715336918830872, 0.8698358535766602, 0.8760611414909363, 0.8774759769439697, 0.8797396421432495, 0.8783248662948608, 0.884833037853241, 0.884833037853241, 0.8834182024002075, 0.88285231590271, 0.8865308165550232, 0.8913412690162659, 0.8916242122650146, 0.8882286548614502, 0.8938879370689392, 0.8970005512237549, 0.8916242122650146, 0.8947368264198303, 0.8899264335632324, 0.8924731016159058, 0.8981324434280396, 0.9026598930358887, 0.897849440574646, 0.9029428362846375, 0.9080362319946289, 0.9018110036849976, 0.9063384532928467, 0.9054895043373108, 0.8955857157707214, 0.905206561088562, 0.9083191752433777, 0.9108659029006958, 0.9114317893981934, 0.9100169539451599, 0.90888512134552, 0.9080362319946289, 0.9187889099121094, 0.9037917256355286, 0.9142614603042603, 0.9148274064064026, 0.9060554504394531, 0.9139785170555115, 0.9168081283569336, 0.9153932929039001, 0.9131296277046204, 0.9142614603042603, 0.9233163595199585, 0.921901524066925, 0.9108659029006958, 0.9170911312103271, 0.9261460304260254, 0.9187889099121094, 0.9233163595199585, 0.9255800843238831, 0.9312393665313721, 0.9289756417274475, 0.9278438091278076, 0.9346349835395813, 0.9275608658790588, 0.9292586445808411], 'val_loss': [1.0868580341339111, 1.0674513578414917, 1.0792667865753174, 1.087081789970398, 1.0868306159973145, 1.0871572494506836, 1.0896257162094116, 1.1003612279891968, 1.0972943305969238, 1.0757348537445068, 1.0772682428359985, 1.078724980354309, 1.0789552927017212, 1.0289028882980347, 1.0281697511672974, 1.0042595863342285, 0.969609797000885, 0.9163904190063477, 0.8948066234588623, 0.8618633151054382, 0.8936653137207031, 0.8337037563323975, 0.80634605884552, 0.7981235384941101, 0.7517282366752625, 0.7881509065628052, 0.8223305344581604, 0.7650694847106934, 0.7991501688957214, 0.7832323908805847, 0.7881312370300293, 0.7994246482849121, 0.7944378852844238, 0.7959731221199036, 0.8268125653266907, 0.8089443445205688, 0.8167835474014282, 0.8135114908218384, 0.8234679102897644, 0.8780725002288818, 0.8235831260681152, 0.8547496795654297, 0.8248616456985474, 0.8322688937187195, 0.8452009558677673, 0.8321834802627563, 0.853675127029419, 0.8418189287185669, 0.8602514266967773, 0.8551924228668213, 0.8391686081886292, 0.8888632655143738, 0.8749763369560242, 0.8602321743965149, 0.8919146060943604, 0.8567007184028625, 0.8755006194114685, 0.87543785572052, 0.8811596035957336, 0.8813742995262146, 0.8722455501556396, 0.8696089386940002, 0.8837727904319763, 0.9372448325157166, 0.9119292497634888, 0.9339778423309326, 0.9017389416694641, 0.9063184261322021, 0.9097158908843994, 0.8969372510910034, 0.901293158531189, 0.899220883846283, 0.9211475253105164, 0.9083253145217896, 1.0614186525344849, 0.9012302756309509, 0.9186980724334717, 0.9256841540336609, 0.9303972721099854, 0.9214534759521484, 0.96368807554245, 0.9270992279052734, 0.935123085975647, 0.9423558115959167, 0.9504743218421936, 0.9515384435653687, 0.9509504437446594, 0.968007504940033, 0.9616550803184509, 0.9720171093940735, 1.0389344692230225, 0.9689493179321289, 0.9638973474502563, 0.9654640555381775, 1.015005350112915, 0.9946895241737366, 0.9950059652328491, 1.0083742141723633, 1.0027501583099365, 1.0467995405197144], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.5011312365531921, 0.5033936500549316, 0.5056561231613159, 0.5113122463226318, 0.529411792755127, 0.5328054428100586, 0.5429864525794983, 0.5712669491767883, 0.5904977321624756, 0.6040723919868469, 0.6187782883644104, 0.6131221652030945, 0.6447963714599609, 0.6764705777168274, 0.6866515874862671, 0.7375565767288208, 0.7126696705818176, 0.6877828240394592, 0.7352941036224365, 0.7070135474205017, 0.7454751133918762, 0.7409502267837524, 0.7217194437980652, 0.7454751133918762, 0.7307692170143127, 0.7398189902305603, 0.7432126402854919, 0.720588207244873, 0.7217194437980652, 0.7398189902305603, 0.7058823704719543, 0.7352941036224365, 0.7047511339187622, 0.720588207244873, 0.7409502267837524, 0.7126696705818176, 0.7171945571899414, 0.7228506803512573, 0.7307692170143127, 0.7307692170143127, 0.7319004535675049, 0.7386877536773682, 0.6945701241493225, 0.7307692170143127, 0.7239819169044495, 0.7104072570800781, 0.726244330406189, 0.726244330406189, 0.7296379804611206, 0.7307692170143127, 0.7273755669593811, 0.7341628670692444, 0.726244330406189, 0.7319004535675049, 0.6889140009880066, 0.7058823704719543, 0.6900452375411987, 0.7341628670692444, 0.7183257937431335, 0.7217194437980652, 0.7296379804611206, 0.7319004535675049, 0.7239819169044495, 0.7296379804611206, 0.733031690120697, 0.6866515874862671, 0.7341628670692444, 0.733031690120697, 0.7352941036224365, 0.7251130938529968, 0.7194570302963257, 0.7160633206367493, 0.7443438768386841, 0.7239819169044495, 0.7194570302963257, 0.726244330406189, 0.7160633206367493, 0.7319004535675049, 0.726244330406189, 0.7194570302963257, 0.7239819169044495, 0.7013574838638306, 0.7296379804611206, 0.7194570302963257, 0.726244330406189, 0.7024886608123779, 0.7171945571899414, 0.7228506803512573, 0.7126696705818176, 0.7217194437980652, 0.7070135474205017]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.6806 - accuracy: 0.7930"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 7s 61ms/step - loss: 0.6794 - accuracy: 0.7935 - val_loss: 1.0953 - val_accuracy: 0.4876\n","Epoch 2/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6613 - accuracy: 0.7953 - val_loss: 1.0926 - val_accuracy: 0.4876\n","Epoch 3/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6416 - accuracy: 0.8072 - val_loss: 1.0886 - val_accuracy: 0.4876\n","Epoch 4/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6393 - accuracy: 0.8109 - val_loss: 1.0926 - val_accuracy: 0.4876\n","Epoch 5/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6329 - accuracy: 0.8163 - val_loss: 1.0915 - val_accuracy: 0.4886\n","Epoch 6/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6227 - accuracy: 0.8163 - val_loss: 1.0838 - val_accuracy: 0.4897\n","Epoch 7/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6315 - accuracy: 0.8103 - val_loss: 1.0906 - val_accuracy: 0.4897\n","Epoch 8/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6190 - accuracy: 0.8145 - val_loss: 1.0913 - val_accuracy: 0.4928\n","Epoch 9/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6141 - accuracy: 0.8266 - val_loss: 1.0928 - val_accuracy: 0.4948\n","Epoch 10/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6082 - accuracy: 0.8276 - val_loss: 1.0985 - val_accuracy: 0.4979\n","Epoch 11/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6134 - accuracy: 0.8202 - val_loss: 1.0953 - val_accuracy: 0.4979\n","Epoch 12/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6053 - accuracy: 0.8227 - val_loss: 1.0903 - val_accuracy: 0.5072\n","Epoch 13/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6039 - accuracy: 0.8274 - val_loss: 1.0942 - val_accuracy: 0.5134\n","Epoch 14/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5998 - accuracy: 0.8230 - val_loss: 1.0496 - val_accuracy: 0.5269\n","Epoch 15/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5857 - accuracy: 0.8331 - val_loss: 0.9969 - val_accuracy: 0.5537\n","Epoch 16/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5958 - accuracy: 0.8256 - val_loss: 0.9510 - val_accuracy: 0.5713\n","Epoch 17/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5851 - accuracy: 0.8305 - val_loss: 0.9249 - val_accuracy: 0.5795\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5840 - accuracy: 0.8351 - val_loss: 0.9338 - val_accuracy: 0.5723\n","Epoch 19/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5767 - accuracy: 0.8357 - val_loss: 0.8186 - val_accuracy: 0.6601\n","Epoch 20/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5707 - accuracy: 0.8375 - val_loss: 0.8678 - val_accuracy: 0.6353\n","Epoch 21/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5751 - accuracy: 0.8375 - val_loss: 0.8384 - val_accuracy: 0.6705\n","Epoch 22/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5750 - accuracy: 0.8326 - val_loss: 0.8296 - val_accuracy: 0.6880\n","Epoch 23/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5643 - accuracy: 0.8398 - val_loss: 0.8200 - val_accuracy: 0.7128\n","Epoch 24/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5615 - accuracy: 0.8437 - val_loss: 0.8218 - val_accuracy: 0.7097\n","Epoch 25/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5574 - accuracy: 0.8460 - val_loss: 0.8372 - val_accuracy: 0.7014\n","Epoch 26/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5611 - accuracy: 0.8506 - val_loss: 0.8328 - val_accuracy: 0.7190\n","Epoch 27/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5517 - accuracy: 0.8432 - val_loss: 0.8352 - val_accuracy: 0.7169\n","Epoch 28/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5450 - accuracy: 0.8553 - val_loss: 0.8406 - val_accuracy: 0.7128\n","Epoch 29/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5437 - accuracy: 0.8514 - val_loss: 0.8559 - val_accuracy: 0.7180\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5490 - accuracy: 0.8499 - val_loss: 0.9955 - val_accuracy: 0.6467\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5488 - accuracy: 0.8455 - val_loss: 0.8647 - val_accuracy: 0.7138\n","Epoch 32/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5374 - accuracy: 0.8525 - val_loss: 0.8657 - val_accuracy: 0.7221\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5288 - accuracy: 0.8618 - val_loss: 0.8728 - val_accuracy: 0.7169\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5267 - accuracy: 0.8594 - val_loss: 0.8806 - val_accuracy: 0.7180\n","Epoch 35/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5276 - accuracy: 0.8589 - val_loss: 0.8937 - val_accuracy: 0.7097\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5229 - accuracy: 0.8597 - val_loss: 0.8845 - val_accuracy: 0.7149\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5122 - accuracy: 0.8705 - val_loss: 0.9089 - val_accuracy: 0.7035\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5170 - accuracy: 0.8643 - val_loss: 0.9103 - val_accuracy: 0.7138\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5165 - accuracy: 0.8659 - val_loss: 0.9107 - val_accuracy: 0.7118\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5090 - accuracy: 0.8674 - val_loss: 0.9012 - val_accuracy: 0.7149\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4979 - accuracy: 0.8770 - val_loss: 0.9064 - val_accuracy: 0.7087\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4994 - accuracy: 0.8726 - val_loss: 0.9337 - val_accuracy: 0.7076\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4986 - accuracy: 0.8703 - val_loss: 0.9089 - val_accuracy: 0.7107\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5012 - accuracy: 0.8680 - val_loss: 0.8992 - val_accuracy: 0.7190\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4992 - accuracy: 0.8677 - val_loss: 0.9569 - val_accuracy: 0.7107\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5106 - accuracy: 0.8618 - val_loss: 0.9098 - val_accuracy: 0.7056\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5030 - accuracy: 0.8667 - val_loss: 0.9463 - val_accuracy: 0.6983\n","Epoch 48/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4827 - accuracy: 0.8747 - val_loss: 0.9271 - val_accuracy: 0.7025\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4782 - accuracy: 0.8829 - val_loss: 0.9615 - val_accuracy: 0.7118\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4834 - accuracy: 0.8775 - val_loss: 0.9560 - val_accuracy: 0.7138\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4829 - accuracy: 0.8798 - val_loss: 0.9463 - val_accuracy: 0.6952\n","Epoch 52/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5114 - accuracy: 0.8594 - val_loss: 0.9406 - val_accuracy: 0.7128\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4810 - accuracy: 0.8760 - val_loss: 0.9263 - val_accuracy: 0.7200\n","Epoch 54/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4710 - accuracy: 0.8848 - val_loss: 0.9296 - val_accuracy: 0.7138\n","Epoch 55/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4609 - accuracy: 0.8961 - val_loss: 0.9533 - val_accuracy: 0.7087\n","Epoch 56/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4696 - accuracy: 0.8884 - val_loss: 0.9481 - val_accuracy: 0.7025\n","Epoch 57/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4656 - accuracy: 0.8850 - val_loss: 0.9427 - val_accuracy: 0.7045\n","Epoch 58/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4694 - accuracy: 0.8822 - val_loss: 0.9535 - val_accuracy: 0.7076\n","Epoch 59/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4583 - accuracy: 0.8853 - val_loss: 0.9991 - val_accuracy: 0.7097\n","Epoch 60/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4801 - accuracy: 0.8744 - val_loss: 0.9676 - val_accuracy: 0.6994\n","Epoch 61/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4675 - accuracy: 0.8822 - val_loss: 0.9446 - val_accuracy: 0.7107\n","Epoch 62/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4549 - accuracy: 0.8873 - val_loss: 0.9432 - val_accuracy: 0.7025\n","Epoch 63/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4528 - accuracy: 0.8933 - val_loss: 1.0198 - val_accuracy: 0.7138\n","Epoch 64/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4567 - accuracy: 0.8822 - val_loss: 0.9548 - val_accuracy: 0.6942\n","Epoch 65/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4488 - accuracy: 0.8917 - val_loss: 0.9897 - val_accuracy: 0.6973\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4408 - accuracy: 0.8982 - val_loss: 0.9772 - val_accuracy: 0.7004\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4392 - accuracy: 0.8964 - val_loss: 0.9662 - val_accuracy: 0.7066\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4372 - accuracy: 0.8964 - val_loss: 0.9757 - val_accuracy: 0.7066\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4304 - accuracy: 0.8990 - val_loss: 0.9841 - val_accuracy: 0.7097\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4381 - accuracy: 0.8977 - val_loss: 0.9833 - val_accuracy: 0.7014\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4257 - accuracy: 0.9031 - val_loss: 0.9845 - val_accuracy: 0.7056\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4251 - accuracy: 0.9039 - val_loss: 0.9858 - val_accuracy: 0.7025\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4302 - accuracy: 0.9008 - val_loss: 0.9968 - val_accuracy: 0.7025\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4263 - accuracy: 0.9018 - val_loss: 0.9904 - val_accuracy: 0.6963\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4263 - accuracy: 0.8948 - val_loss: 0.9946 - val_accuracy: 0.7035\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4217 - accuracy: 0.9054 - val_loss: 1.0086 - val_accuracy: 0.6880\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4173 - accuracy: 0.9044 - val_loss: 0.9919 - val_accuracy: 0.7056\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4120 - accuracy: 0.9109 - val_loss: 0.9972 - val_accuracy: 0.7035\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4252 - accuracy: 0.9026 - val_loss: 1.0828 - val_accuracy: 0.7149\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4168 - accuracy: 0.9088 - val_loss: 1.0459 - val_accuracy: 0.7004\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4090 - accuracy: 0.9054 - val_loss: 1.0332 - val_accuracy: 0.7056\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4088 - accuracy: 0.9067 - val_loss: 1.0196 - val_accuracy: 0.6983\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4000 - accuracy: 0.9124 - val_loss: 1.0441 - val_accuracy: 0.7035\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4003 - accuracy: 0.9103 - val_loss: 1.0384 - val_accuracy: 0.7087\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3959 - accuracy: 0.9176 - val_loss: 1.0364 - val_accuracy: 0.7045\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3992 - accuracy: 0.9145 - val_loss: 1.0532 - val_accuracy: 0.6994\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4001 - accuracy: 0.9093 - val_loss: 1.0468 - val_accuracy: 0.6973\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3895 - accuracy: 0.9194 - val_loss: 1.0387 - val_accuracy: 0.6973\n","Epoch 89/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4005 - accuracy: 0.9132 - val_loss: 1.1322 - val_accuracy: 0.6839\n","Epoch 90/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4011 - accuracy: 0.9098 - val_loss: 1.0639 - val_accuracy: 0.6942\n","Epoch 91/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4068 - accuracy: 0.9085 - val_loss: 1.0789 - val_accuracy: 0.7004\n","Epoch 92/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3973 - accuracy: 0.9132 - val_loss: 1.0739 - val_accuracy: 0.7056\n","Epoch 93/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3819 - accuracy: 0.9214 - val_loss: 1.1514 - val_accuracy: 0.6880\n","Epoch 94/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3987 - accuracy: 0.9096 - val_loss: 1.0984 - val_accuracy: 0.7107\n","Epoch 95/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3818 - accuracy: 0.9230 - val_loss: 1.0810 - val_accuracy: 0.7035\n","Epoch 96/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3826 - accuracy: 0.9155 - val_loss: 1.1819 - val_accuracy: 0.6880\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3847 - accuracy: 0.9160 - val_loss: 1.0964 - val_accuracy: 0.6983\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3762 - accuracy: 0.9230 - val_loss: 1.0829 - val_accuracy: 0.7025\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3744 - accuracy: 0.9204 - val_loss: 1.1029 - val_accuracy: 0.6952\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3668 - accuracy: 0.9302 - val_loss: 1.1477 - val_accuracy: 0.6849\n","{'loss': [0.6793844103813171, 0.6613248586654663, 0.6415693163871765, 0.6392860412597656, 0.6329168081283569, 0.6226988434791565, 0.6315175294876099, 0.6189820766448975, 0.6141273975372314, 0.6082215309143066, 0.6134217381477356, 0.6053044199943542, 0.6039018630981445, 0.5997827053070068, 0.5856769680976868, 0.5958420038223267, 0.5850728750228882, 0.5839826464653015, 0.5767379999160767, 0.5706959962844849, 0.5750918388366699, 0.5750294327735901, 0.5643288493156433, 0.561535120010376, 0.5574262738227844, 0.5611011981964111, 0.5516794323921204, 0.5450205206871033, 0.5436661839485168, 0.5489974617958069, 0.5488000512123108, 0.5374134182929993, 0.5288266539573669, 0.5266676545143127, 0.5275919437408447, 0.5228875279426575, 0.5121703743934631, 0.5170450806617737, 0.5165338516235352, 0.5090175867080688, 0.4978559911251068, 0.4993557929992676, 0.49862372875213623, 0.5012432932853699, 0.4991518259048462, 0.5106075406074524, 0.5029609203338623, 0.48273423314094543, 0.47820067405700684, 0.48343098163604736, 0.48294565081596375, 0.5113626718521118, 0.480978786945343, 0.4710133969783783, 0.4609428942203522, 0.4696498215198517, 0.46564653515815735, 0.46940144896507263, 0.4582533836364746, 0.48008307814598083, 0.46745890378952026, 0.4549412727355957, 0.4528125524520874, 0.45669832825660706, 0.4487580358982086, 0.44077688455581665, 0.4392264187335968, 0.43722233176231384, 0.43041133880615234, 0.43807730078697205, 0.4257040023803711, 0.4251388907432556, 0.43021848797798157, 0.4262894093990326, 0.42628058791160583, 0.4216573238372803, 0.41731080412864685, 0.4119578003883362, 0.4251956641674042, 0.4168499708175659, 0.4090169668197632, 0.40884318947792053, 0.4000053107738495, 0.40027233958244324, 0.3958510160446167, 0.3992268145084381, 0.4000898003578186, 0.3895222246646881, 0.40054669976234436, 0.4011220335960388, 0.40679389238357544, 0.3973330855369568, 0.38190126419067383, 0.39872801303863525, 0.3817988932132721, 0.3825886845588684, 0.38469016551971436, 0.37615203857421875, 0.3744266927242279, 0.36682191491127014], 'accuracy': [0.7935400605201721, 0.7953488230705261, 0.8072351217269897, 0.8108527064323425, 0.8162790536880493, 0.8162790536880493, 0.8103359341621399, 0.8144702911376953, 0.8266149759292603, 0.8276485800743103, 0.8201550245285034, 0.8227390050888062, 0.827390193939209, 0.8229973912239075, 0.8330749273300171, 0.8255813717842102, 0.8304909467697144, 0.8351421356201172, 0.8356589078903198, 0.8374677300453186, 0.8374677300453186, 0.8325581550598145, 0.8397932648658752, 0.8436692357063293, 0.8459948301315308, 0.8506460189819336, 0.8431524634361267, 0.8552971482276917, 0.8514211773872375, 0.8498708009719849, 0.8454780578613281, 0.8524547815322876, 0.8617570996284485, 0.8594315052032471, 0.8589147329330444, 0.8596899509429932, 0.8705426454544067, 0.8643410801887512, 0.8658914566040039, 0.8674418330192566, 0.8770025968551636, 0.8726097941398621, 0.8702842593193054, 0.867958664894104, 0.8677002787590027, 0.8617570996284485, 0.8666666746139526, 0.8746770024299622, 0.882945716381073, 0.8775193691253662, 0.8798449635505676, 0.8594315052032471, 0.8759689927101135, 0.8847545385360718, 0.896124005317688, 0.8883720636367798, 0.8850129246711731, 0.882170557975769, 0.8852713108062744, 0.8744186162948608, 0.882170557975769, 0.8873385190963745, 0.8932816386222839, 0.882170557975769, 0.8917312622070312, 0.8981912136077881, 0.8963824510574341, 0.8963824510574341, 0.8989664316177368, 0.8976744413375854, 0.9031007885932922, 0.9038759469985962, 0.9007751941680908, 0.9018087983131409, 0.8948320150375366, 0.9054263830184937, 0.9043927788734436, 0.9108527302742004, 0.9025839567184448, 0.9087855219841003, 0.9054263830184937, 0.906718373298645, 0.9124031066894531, 0.910335898399353, 0.9175710678100586, 0.9144702553749084, 0.9093023538589478, 0.9193798303604126, 0.9131782650947571, 0.9098191261291504, 0.908527135848999, 0.9131782650947571, 0.9214470386505127, 0.9095607399940491, 0.9229974150657654, 0.9155038595199585, 0.9160206913948059, 0.9229974150657654, 0.9204134345054626, 0.930232584476471], 'val_loss': [1.095270037651062, 1.0925946235656738, 1.0886116027832031, 1.0925945043563843, 1.0914504528045654, 1.0837757587432861, 1.090563178062439, 1.0913244485855103, 1.09275221824646, 1.09850013256073, 1.0952953100204468, 1.0903089046478271, 1.0941911935806274, 1.0495961904525757, 0.9968825578689575, 0.9509548544883728, 0.9248848557472229, 0.9338054060935974, 0.8185699582099915, 0.8678207397460938, 0.8384134769439697, 0.8296129107475281, 0.8200314044952393, 0.8218220472335815, 0.8371682167053223, 0.8328079581260681, 0.8351650834083557, 0.8406389951705933, 0.8559123873710632, 0.9955217838287354, 0.8647003769874573, 0.865653932094574, 0.8728107810020447, 0.880569338798523, 0.8937082290649414, 0.8844738006591797, 0.908888578414917, 0.910283625125885, 0.9107279777526855, 0.9012343287467957, 0.9063764214515686, 0.9336948990821838, 0.9089420437812805, 0.8991919159889221, 0.956872284412384, 0.9097703099250793, 0.9462950229644775, 0.9270676970481873, 0.9615050554275513, 0.9560431838035583, 0.9462759494781494, 0.9405823945999146, 0.9263293147087097, 0.929621696472168, 0.9532777070999146, 0.9480566382408142, 0.9426846504211426, 0.9535415172576904, 0.9990706443786621, 0.9675569534301758, 0.944625198841095, 0.9431887269020081, 1.0197505950927734, 0.9548227787017822, 0.9897103309631348, 0.9772108197212219, 0.9662177562713623, 0.9757407903671265, 0.984063446521759, 0.9832698106765747, 0.9844871759414673, 0.9857891201972961, 0.9967989325523376, 0.9903873205184937, 0.9946160912513733, 1.0086181163787842, 0.9918928146362305, 0.9971520900726318, 1.0828365087509155, 1.0458946228027344, 1.0331705808639526, 1.0196152925491333, 1.044100284576416, 1.0384254455566406, 1.0363543033599854, 1.0532134771347046, 1.046809196472168, 1.0386782884597778, 1.1321860551834106, 1.0638638734817505, 1.0788706541061401, 1.0738637447357178, 1.1514453887939453, 1.0984023809432983, 1.0809845924377441, 1.1819188594818115, 1.0963729619979858, 1.0828969478607178, 1.1028504371643066, 1.1477168798446655], 'val_accuracy': [0.4876033067703247, 0.4876033067703247, 0.4876033067703247, 0.4876033067703247, 0.4886363744735718, 0.48966941237449646, 0.48966941237449646, 0.4927685856819153, 0.4948347210884094, 0.49793389439582825, 0.49793389439582825, 0.5072314143180847, 0.5134297609329224, 0.5268595218658447, 0.5537189841270447, 0.5712810158729553, 0.5795454382896423, 0.5723140239715576, 0.6601239442825317, 0.6353305578231812, 0.6704545617103577, 0.6880165338516235, 0.7128099203109741, 0.7097107172012329, 0.7014462947845459, 0.7190082669258118, 0.7169421315193176, 0.7128099203109741, 0.7179751992225647, 0.6466942429542542, 0.7138429880142212, 0.7221074104309082, 0.7169421315193176, 0.7179751992225647, 0.7097107172012329, 0.7148760557174683, 0.7035123705863953, 0.7138429880142212, 0.711776852607727, 0.7148760557174683, 0.7086777091026306, 0.7076446413993835, 0.71074378490448, 0.7190082669258118, 0.71074378490448, 0.7055785059928894, 0.6983470916748047, 0.702479362487793, 0.711776852607727, 0.7138429880142212, 0.6952479481697083, 0.7128099203109741, 0.7200413346290588, 0.7138429880142212, 0.7086777091026306, 0.702479362487793, 0.7045454382896423, 0.7076446413993835, 0.7097107172012329, 0.6993801593780518, 0.71074378490448, 0.702479362487793, 0.7138429880142212, 0.6942148804664612, 0.6973140239715576, 0.7004132270812988, 0.7066115736961365, 0.7066115736961365, 0.7097107172012329, 0.7014462947845459, 0.7055785059928894, 0.702479362487793, 0.702479362487793, 0.6962810158729553, 0.7035123705863953, 0.6880165338516235, 0.7055785059928894, 0.7035123705863953, 0.7148760557174683, 0.7004132270812988, 0.7055785059928894, 0.6983470916748047, 0.7035123705863953, 0.7086777091026306, 0.7045454382896423, 0.6993801593780518, 0.6973140239715576, 0.6973140239715576, 0.68388432264328, 0.6942148804664612, 0.7004132270812988, 0.7055785059928894, 0.6880165338516235, 0.71074378490448, 0.7035123705863953, 0.6880165338516235, 0.6983470916748047, 0.702479362487793, 0.6952479481697083, 0.6849173307418823]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.4761 - accuracy: 0.8775"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 7s 52ms/step - loss: 0.4772 - accuracy: 0.8769 - val_loss: 1.4568 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4491 - accuracy: 0.8917 - val_loss: 1.4462 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4341 - accuracy: 0.8941 - val_loss: 1.4421 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4375 - accuracy: 0.8933 - val_loss: 1.4687 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4238 - accuracy: 0.8987 - val_loss: 1.4752 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4172 - accuracy: 0.9027 - val_loss: 1.4685 - val_accuracy: 0.4860\n","Epoch 7/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4162 - accuracy: 0.9009 - val_loss: 1.4939 - val_accuracy: 0.4860\n","Epoch 8/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4198 - accuracy: 0.8968 - val_loss: 1.4878 - val_accuracy: 0.4860\n","Epoch 9/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4050 - accuracy: 0.9073 - val_loss: 1.4859 - val_accuracy: 0.4871\n","Epoch 10/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4142 - accuracy: 0.9033 - val_loss: 1.4729 - val_accuracy: 0.4903\n","Epoch 11/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4006 - accuracy: 0.9106 - val_loss: 1.5090 - val_accuracy: 0.4914\n","Epoch 12/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4123 - accuracy: 0.9044 - val_loss: 1.4507 - val_accuracy: 0.4968\n","Epoch 13/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4065 - accuracy: 0.9068 - val_loss: 1.4824 - val_accuracy: 0.4978\n","Epoch 14/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3905 - accuracy: 0.9168 - val_loss: 1.5137 - val_accuracy: 0.5000\n","Epoch 15/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3981 - accuracy: 0.9122 - val_loss: 1.4401 - val_accuracy: 0.5097\n","Epoch 16/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.3953 - accuracy: 0.9071 - val_loss: 1.5132 - val_accuracy: 0.5119\n","Epoch 17/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3908 - accuracy: 0.9100 - val_loss: 1.2157 - val_accuracy: 0.5539\n","Epoch 18/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3938 - accuracy: 0.9127 - val_loss: 1.1684 - val_accuracy: 0.5744\n","Epoch 19/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3841 - accuracy: 0.9154 - val_loss: 1.1485 - val_accuracy: 0.5927\n","Epoch 20/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3891 - accuracy: 0.9116 - val_loss: 0.9388 - val_accuracy: 0.6530\n","Epoch 21/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3845 - accuracy: 0.9165 - val_loss: 1.0798 - val_accuracy: 0.6282\n","Epoch 22/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3838 - accuracy: 0.9189 - val_loss: 0.8910 - val_accuracy: 0.6843\n","Epoch 23/100\n","29/29 [==============================] - 1s 53ms/step - loss: 0.3804 - accuracy: 0.9184 - val_loss: 0.8541 - val_accuracy: 0.7015\n","Epoch 24/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3843 - accuracy: 0.9143 - val_loss: 0.8005 - val_accuracy: 0.7220\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3784 - accuracy: 0.9130 - val_loss: 0.8181 - val_accuracy: 0.7220\n","Epoch 26/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3679 - accuracy: 0.9227 - val_loss: 0.7823 - val_accuracy: 0.7446\n","Epoch 27/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3705 - accuracy: 0.9221 - val_loss: 0.9039 - val_accuracy: 0.7101\n","Epoch 28/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3671 - accuracy: 0.9254 - val_loss: 0.8057 - val_accuracy: 0.7565\n","Epoch 29/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3636 - accuracy: 0.9278 - val_loss: 0.7742 - val_accuracy: 0.7737\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3529 - accuracy: 0.9294 - val_loss: 0.7882 - val_accuracy: 0.7629\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3580 - accuracy: 0.9254 - val_loss: 0.7735 - val_accuracy: 0.7716\n","Epoch 32/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3563 - accuracy: 0.9265 - val_loss: 0.7732 - val_accuracy: 0.7899\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3519 - accuracy: 0.9283 - val_loss: 0.7939 - val_accuracy: 0.7662\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3498 - accuracy: 0.9327 - val_loss: 0.7968 - val_accuracy: 0.7812\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3522 - accuracy: 0.9286 - val_loss: 0.8258 - val_accuracy: 0.7705\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3481 - accuracy: 0.9332 - val_loss: 0.8336 - val_accuracy: 0.7651\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3521 - accuracy: 0.9308 - val_loss: 0.7989 - val_accuracy: 0.7769\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3487 - accuracy: 0.9327 - val_loss: 0.8187 - val_accuracy: 0.7823\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3497 - accuracy: 0.9348 - val_loss: 0.8191 - val_accuracy: 0.7802\n","Epoch 40/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3444 - accuracy: 0.9345 - val_loss: 0.8233 - val_accuracy: 0.7780\n","Epoch 41/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3412 - accuracy: 0.9324 - val_loss: 0.8162 - val_accuracy: 0.7651\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3364 - accuracy: 0.9378 - val_loss: 0.8395 - val_accuracy: 0.7812\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3410 - accuracy: 0.9386 - val_loss: 0.8488 - val_accuracy: 0.7640\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3315 - accuracy: 0.9413 - val_loss: 0.8480 - val_accuracy: 0.7705\n","Epoch 45/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3447 - accuracy: 0.9321 - val_loss: 0.8734 - val_accuracy: 0.7856\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3378 - accuracy: 0.9380 - val_loss: 0.8585 - val_accuracy: 0.7716\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3387 - accuracy: 0.9324 - val_loss: 0.8785 - val_accuracy: 0.7802\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3281 - accuracy: 0.9423 - val_loss: 0.8696 - val_accuracy: 0.7759\n","Epoch 49/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3292 - accuracy: 0.9402 - val_loss: 0.9421 - val_accuracy: 0.7802\n","Epoch 50/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3236 - accuracy: 0.9413 - val_loss: 0.8629 - val_accuracy: 0.7759\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3337 - accuracy: 0.9364 - val_loss: 0.9674 - val_accuracy: 0.7640\n","Epoch 52/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3414 - accuracy: 0.9305 - val_loss: 0.8720 - val_accuracy: 0.7737\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3253 - accuracy: 0.9410 - val_loss: 0.8669 - val_accuracy: 0.7694\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3154 - accuracy: 0.9461 - val_loss: 0.8711 - val_accuracy: 0.7619\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3096 - accuracy: 0.9475 - val_loss: 0.8958 - val_accuracy: 0.7694\n","Epoch 56/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3256 - accuracy: 0.9383 - val_loss: 0.9532 - val_accuracy: 0.7716\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3259 - accuracy: 0.9386 - val_loss: 0.9313 - val_accuracy: 0.7737\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3192 - accuracy: 0.9383 - val_loss: 0.8752 - val_accuracy: 0.7694\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3068 - accuracy: 0.9461 - val_loss: 0.9068 - val_accuracy: 0.7683\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3103 - accuracy: 0.9467 - val_loss: 0.9140 - val_accuracy: 0.7619\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3030 - accuracy: 0.9491 - val_loss: 0.8981 - val_accuracy: 0.7759\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3037 - accuracy: 0.9512 - val_loss: 0.8874 - val_accuracy: 0.7726\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3001 - accuracy: 0.9515 - val_loss: 0.9193 - val_accuracy: 0.7716\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3013 - accuracy: 0.9518 - val_loss: 0.9122 - val_accuracy: 0.7737\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3032 - accuracy: 0.9507 - val_loss: 0.9656 - val_accuracy: 0.7629\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3041 - accuracy: 0.9496 - val_loss: 0.9135 - val_accuracy: 0.7694\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2948 - accuracy: 0.9523 - val_loss: 0.9220 - val_accuracy: 0.7662\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3037 - accuracy: 0.9485 - val_loss: 0.9456 - val_accuracy: 0.7586\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3000 - accuracy: 0.9542 - val_loss: 0.9479 - val_accuracy: 0.7640\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2963 - accuracy: 0.9510 - val_loss: 0.9353 - val_accuracy: 0.7737\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2891 - accuracy: 0.9569 - val_loss: 0.9356 - val_accuracy: 0.7737\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2888 - accuracy: 0.9523 - val_loss: 0.9354 - val_accuracy: 0.7726\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3000 - accuracy: 0.9472 - val_loss: 1.0349 - val_accuracy: 0.7554\n","Epoch 74/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3047 - accuracy: 0.9461 - val_loss: 1.0169 - val_accuracy: 0.7672\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3021 - accuracy: 0.9475 - val_loss: 1.0057 - val_accuracy: 0.7662\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3003 - accuracy: 0.9477 - val_loss: 1.0124 - val_accuracy: 0.7823\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2909 - accuracy: 0.9547 - val_loss: 0.9913 - val_accuracy: 0.7619\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2921 - accuracy: 0.9555 - val_loss: 0.9957 - val_accuracy: 0.7575\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2887 - accuracy: 0.9591 - val_loss: 0.9700 - val_accuracy: 0.7716\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2932 - accuracy: 0.9518 - val_loss: 1.1572 - val_accuracy: 0.7489\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2909 - accuracy: 0.9555 - val_loss: 0.9996 - val_accuracy: 0.7543\n","Epoch 82/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2990 - accuracy: 0.9472 - val_loss: 1.0140 - val_accuracy: 0.7672\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2801 - accuracy: 0.9591 - val_loss: 1.0231 - val_accuracy: 0.7683\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2783 - accuracy: 0.9593 - val_loss: 1.0192 - val_accuracy: 0.7575\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2774 - accuracy: 0.9585 - val_loss: 1.0292 - val_accuracy: 0.7683\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2917 - accuracy: 0.9526 - val_loss: 1.1140 - val_accuracy: 0.7500\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3129 - accuracy: 0.9453 - val_loss: 1.0260 - val_accuracy: 0.7619\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2913 - accuracy: 0.9561 - val_loss: 1.0791 - val_accuracy: 0.7629\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2908 - accuracy: 0.9534 - val_loss: 1.0139 - val_accuracy: 0.7597\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2800 - accuracy: 0.9569 - val_loss: 1.0794 - val_accuracy: 0.7748\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2878 - accuracy: 0.9572 - val_loss: 1.0894 - val_accuracy: 0.7435\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2884 - accuracy: 0.9553 - val_loss: 1.0103 - val_accuracy: 0.7640\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2809 - accuracy: 0.9566 - val_loss: 1.0472 - val_accuracy: 0.7511\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2942 - accuracy: 0.9504 - val_loss: 1.0393 - val_accuracy: 0.7619\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2658 - accuracy: 0.9661 - val_loss: 1.0130 - val_accuracy: 0.7554\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2725 - accuracy: 0.9593 - val_loss: 0.9959 - val_accuracy: 0.7651\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2734 - accuracy: 0.9604 - val_loss: 1.0024 - val_accuracy: 0.7651\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2740 - accuracy: 0.9572 - val_loss: 1.0575 - val_accuracy: 0.7565\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2610 - accuracy: 0.9650 - val_loss: 1.0280 - val_accuracy: 0.7608\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2593 - accuracy: 0.9679 - val_loss: 1.0252 - val_accuracy: 0.7575\n","{'loss': [0.4771936535835266, 0.4490949809551239, 0.4340875446796417, 0.4375177025794983, 0.4238439202308655, 0.4172339141368866, 0.41620072722435, 0.4198114573955536, 0.4049927592277527, 0.4141806960105896, 0.4006376266479492, 0.4122505486011505, 0.4065200090408325, 0.39045220613479614, 0.3981180191040039, 0.3953403830528259, 0.3907979726791382, 0.3937555253505707, 0.3840547800064087, 0.38911888003349304, 0.3844878375530243, 0.38375550508499146, 0.380448579788208, 0.38429951667785645, 0.3784043490886688, 0.3679437041282654, 0.3704698085784912, 0.3671320676803589, 0.36357444524765015, 0.3529328405857086, 0.35798296332359314, 0.35633307695388794, 0.3519012928009033, 0.34984806180000305, 0.3521682918071747, 0.34813886880874634, 0.35207363963127136, 0.34872180223464966, 0.3496517241001129, 0.34443190693855286, 0.3412243723869324, 0.3363877534866333, 0.3409682512283325, 0.3315105140209198, 0.34469372034072876, 0.33779749274253845, 0.3386833071708679, 0.3280715048313141, 0.3291808068752289, 0.32357028126716614, 0.333711177110672, 0.34139055013656616, 0.3252953886985779, 0.31542056798934937, 0.30964335799217224, 0.32556894421577454, 0.32586371898651123, 0.3192393183708191, 0.3068487346172333, 0.3102538287639618, 0.3029949367046356, 0.30366256833076477, 0.3001176118850708, 0.3013487458229065, 0.3031681776046753, 0.30409982800483704, 0.2948245406150818, 0.30372852087020874, 0.30003124475479126, 0.2963162660598755, 0.28910043835639954, 0.28882676362991333, 0.2999635636806488, 0.3047209680080414, 0.30208179354667664, 0.30034133791923523, 0.290863573551178, 0.29208534955978394, 0.28871798515319824, 0.293166846036911, 0.29092490673065186, 0.298980176448822, 0.28011712431907654, 0.27826082706451416, 0.2773962914943695, 0.29165616631507874, 0.3129037916660309, 0.29127246141433716, 0.29075053334236145, 0.27999961376190186, 0.28776466846466064, 0.28836172819137573, 0.280887246131897, 0.2942016124725342, 0.26580432057380676, 0.2725430130958557, 0.27341651916503906, 0.27403587102890015, 0.26102763414382935, 0.2592725157737732], 'accuracy': [0.8768857717514038, 0.8917025923728943, 0.8941271305084229, 0.8933189511299133, 0.8987069129943848, 0.9027478694915771, 0.9008620977401733, 0.896821141242981, 0.9073275923728943, 0.9032866358757019, 0.9105603694915771, 0.9043642282485962, 0.9067887663841248, 0.9167564511299133, 0.9121767282485962, 0.9070581793785095, 0.9100215435028076, 0.912715494632721, 0.915409505367279, 0.9116379022598267, 0.9164870977401733, 0.9189116358757019, 0.9183728694915771, 0.9143319129943848, 0.9129849076271057, 0.9226831793785095, 0.9221444129943848, 0.9253771305084229, 0.9278017282485962, 0.9294180870056152, 0.9253771305084229, 0.9264547228813171, 0.928340494632721, 0.9326508641242981, 0.9286099076271057, 0.9331896305084229, 0.9307650923728943, 0.9326508641242981, 0.9348060488700867, 0.9345366358757019, 0.9323814511299133, 0.9377694129943848, 0.9385775923728943, 0.9412715435028076, 0.9321120977401733, 0.9380387663841248, 0.9323814511299133, 0.9423491358757019, 0.9401939511299133, 0.9412715435028076, 0.9364224076271057, 0.9304956793785095, 0.9410021305084229, 0.9461206793785095, 0.9474676847457886, 0.9383081793785095, 0.9385775923728943, 0.9383081793785095, 0.9461206793785095, 0.946659505367279, 0.9490840435028076, 0.9512392282485962, 0.951508641242981, 0.951777994632721, 0.9507004022598267, 0.9496228694915771, 0.9523168206214905, 0.9485452771186829, 0.9542025923728943, 0.9509698152542114, 0.9568965435028076, 0.9523168206214905, 0.9471982717514038, 0.9461206793785095, 0.9474676847457886, 0.9477370977401733, 0.954741358757019, 0.9555495977401733, 0.9590517282485962, 0.951777994632721, 0.9555495977401733, 0.9471982717514038, 0.9590517282485962, 0.959321141242981, 0.9585129022598267, 0.9525862336158752, 0.9453125, 0.9560883641242981, 0.9533944129943848, 0.9568965435028076, 0.9571659564971924, 0.9552801847457886, 0.9566271305084229, 0.9504310488700867, 0.9660560488700867, 0.959321141242981, 0.9603987336158752, 0.9571659564971924, 0.9649784564971924, 0.9679418206214905], 'val_loss': [1.456825613975525, 1.4462409019470215, 1.4421358108520508, 1.4686510562896729, 1.4751780033111572, 1.4685111045837402, 1.4939032793045044, 1.4877701997756958, 1.4858757257461548, 1.472907543182373, 1.5089926719665527, 1.4506759643554688, 1.4823514223098755, 1.5137468576431274, 1.4401198625564575, 1.5131993293762207, 1.215729832649231, 1.168393850326538, 1.1485275030136108, 0.9387702941894531, 1.079770803451538, 0.8909861445426941, 0.8541257381439209, 0.8004792332649231, 0.8180878758430481, 0.782295823097229, 0.9038708209991455, 0.8056944608688354, 0.7742263674736023, 0.7882164120674133, 0.773475706577301, 0.7731800079345703, 0.7938545346260071, 0.7968028783798218, 0.8257864713668823, 0.8336092829704285, 0.7989150881767273, 0.8187421560287476, 0.819138765335083, 0.8232618570327759, 0.8162028193473816, 0.8395297527313232, 0.8488040566444397, 0.8480015993118286, 0.8733912110328674, 0.8585436344146729, 0.8785499334335327, 0.869633138179779, 0.9420945644378662, 0.8629130125045776, 0.9673690795898438, 0.871979296207428, 0.8669434785842896, 0.871096134185791, 0.8958287239074707, 0.9531661868095398, 0.931303083896637, 0.8751527667045593, 0.9068114757537842, 0.9140169024467468, 0.8981474041938782, 0.8873710036277771, 0.9192721843719482, 0.912238359451294, 0.9656271934509277, 0.9135046601295471, 0.9220446944236755, 0.9455851912498474, 0.9479027986526489, 0.9353173971176147, 0.9355823397636414, 0.9354414343833923, 1.0349082946777344, 1.0169060230255127, 1.0057462453842163, 1.0124386548995972, 0.9912971258163452, 0.9956950545310974, 0.9700184464454651, 1.1571727991104126, 0.9995976090431213, 1.0140244960784912, 1.0230560302734375, 1.0192443132400513, 1.029163122177124, 1.1140109300613403, 1.025968074798584, 1.0791456699371338, 1.0139139890670776, 1.0794227123260498, 1.0894304513931274, 1.0102732181549072, 1.0471855401992798, 1.039312720298767, 1.0129939317703247, 0.9959116578102112, 1.0024420022964478, 1.0575228929519653, 1.0280176401138306, 1.025220513343811], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48706895112991333, 0.4903017282485962, 0.4913793206214905, 0.4967672526836395, 0.4978448152542114, 0.5, 0.5096982717514038, 0.5118534564971924, 0.5538793206214905, 0.5743534564971924, 0.5926724076271057, 0.6530172228813171, 0.6282327771186829, 0.6842672228813171, 0.701508641242981, 0.7219827771186829, 0.7219827771186829, 0.7446120977401733, 0.7101293206214905, 0.756465494632721, 0.7737069129943848, 0.7629310488700867, 0.7715517282485962, 0.7898706793785095, 0.7661637663841248, 0.78125, 0.7704741358757019, 0.7650862336158752, 0.7769396305084229, 0.7823275923728943, 0.7801724076271057, 0.7780172228813171, 0.7650862336158752, 0.78125, 0.764008641242981, 0.7704741358757019, 0.7855603694915771, 0.7715517282485962, 0.7801724076271057, 0.7758620977401733, 0.7801724076271057, 0.7758620977401733, 0.764008641242981, 0.7737069129943848, 0.7693965435028076, 0.7618534564971924, 0.7693965435028076, 0.7715517282485962, 0.7737069129943848, 0.7693965435028076, 0.7683189511299133, 0.7618534564971924, 0.7758620977401733, 0.7726293206214905, 0.7715517282485962, 0.7737069129943848, 0.7629310488700867, 0.7693965435028076, 0.7661637663841248, 0.7586206793785095, 0.764008641242981, 0.7737069129943848, 0.7737069129943848, 0.7726293206214905, 0.7553879022598267, 0.767241358757019, 0.7661637663841248, 0.7823275923728943, 0.7618534564971924, 0.7575430870056152, 0.7715517282485962, 0.7489224076271057, 0.7543103694915771, 0.767241358757019, 0.7683189511299133, 0.7575430870056152, 0.7683189511299133, 0.75, 0.7618534564971924, 0.7629310488700867, 0.7596982717514038, 0.774784505367279, 0.743534505367279, 0.764008641242981, 0.7510775923728943, 0.7618534564971924, 0.7553879022598267, 0.7650862336158752, 0.7650862336158752, 0.756465494632721, 0.7607758641242981, 0.7575430870056152]}\n","38/38 [==============================] - 2s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 8s 51ms/step - loss: 0.4551 - accuracy: 0.8865 - val_loss: 1.4211 - val_accuracy: 0.4955\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 2/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4319 - accuracy: 0.8990 - val_loss: 1.4301 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4277 - accuracy: 0.8993 - val_loss: 1.4267 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4225 - accuracy: 0.9004 - val_loss: 1.4126 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4231 - accuracy: 0.9010 - val_loss: 1.4240 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4109 - accuracy: 0.9018 - val_loss: 1.4602 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4035 - accuracy: 0.9140 - val_loss: 1.4524 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4123 - accuracy: 0.9035 - val_loss: 1.4600 - val_accuracy: 0.4955\n","Epoch 9/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3998 - accuracy: 0.9092 - val_loss: 1.4598 - val_accuracy: 0.4955\n","Epoch 10/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4060 - accuracy: 0.9078 - val_loss: 1.4564 - val_accuracy: 0.4966\n","Epoch 11/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4026 - accuracy: 0.9075 - val_loss: 1.4769 - val_accuracy: 0.5000\n","Epoch 12/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4165 - accuracy: 0.9058 - val_loss: 1.3891 - val_accuracy: 0.5057\n","Epoch 13/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4156 - accuracy: 0.8970 - val_loss: 1.4701 - val_accuracy: 0.5011\n","Epoch 14/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3915 - accuracy: 0.9134 - val_loss: 1.4796 - val_accuracy: 0.5068\n","Epoch 15/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3892 - accuracy: 0.9171 - val_loss: 1.3787 - val_accuracy: 0.5170\n","Epoch 16/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3865 - accuracy: 0.9188 - val_loss: 1.3572 - val_accuracy: 0.5317\n","Epoch 17/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3784 - accuracy: 0.9208 - val_loss: 1.3679 - val_accuracy: 0.5351\n","Epoch 18/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3798 - accuracy: 0.9194 - val_loss: 1.2549 - val_accuracy: 0.5633\n","Epoch 19/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3743 - accuracy: 0.9225 - val_loss: 1.2073 - val_accuracy: 0.5792\n","Epoch 20/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3686 - accuracy: 0.9256 - val_loss: 1.1627 - val_accuracy: 0.5962\n","Epoch 21/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3810 - accuracy: 0.9168 - val_loss: 0.9716 - val_accuracy: 0.6516\n","Epoch 22/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3725 - accuracy: 0.9211 - val_loss: 1.0158 - val_accuracy: 0.6459\n","Epoch 23/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3630 - accuracy: 0.9276 - val_loss: 0.8655 - val_accuracy: 0.6957\n","Epoch 24/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3622 - accuracy: 0.9278 - val_loss: 0.8777 - val_accuracy: 0.6980\n","Epoch 25/100\n","28/28 [==============================] - 1s 52ms/step - loss: 0.3711 - accuracy: 0.9205 - val_loss: 0.7494 - val_accuracy: 0.7421\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3649 - accuracy: 0.9273 - val_loss: 0.7805 - val_accuracy: 0.7296\n","Epoch 27/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3665 - accuracy: 0.9225 - val_loss: 0.7264 - val_accuracy: 0.7624\n","Epoch 28/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3744 - accuracy: 0.9196 - val_loss: 0.7112 - val_accuracy: 0.7851\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3516 - accuracy: 0.9284 - val_loss: 0.7334 - val_accuracy: 0.7704\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3673 - accuracy: 0.9230 - val_loss: 0.8121 - val_accuracy: 0.7545\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3595 - accuracy: 0.9256 - val_loss: 0.7463 - val_accuracy: 0.7647\n","Epoch 32/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3511 - accuracy: 0.9310 - val_loss: 0.7372 - val_accuracy: 0.7862\n","Epoch 33/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3554 - accuracy: 0.9312 - val_loss: 0.7705 - val_accuracy: 0.7873\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3579 - accuracy: 0.9293 - val_loss: 0.7470 - val_accuracy: 0.7828\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3514 - accuracy: 0.9278 - val_loss: 0.7415 - val_accuracy: 0.7851\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3449 - accuracy: 0.9295 - val_loss: 0.7564 - val_accuracy: 0.7760\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3388 - accuracy: 0.9349 - val_loss: 0.8341 - val_accuracy: 0.7579\n","Epoch 38/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3482 - accuracy: 0.9307 - val_loss: 0.7678 - val_accuracy: 0.7817\n","Epoch 39/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3388 - accuracy: 0.9355 - val_loss: 0.7800 - val_accuracy: 0.7896\n","Epoch 40/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3380 - accuracy: 0.9375 - val_loss: 0.8411 - val_accuracy: 0.7704\n","Epoch 41/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3455 - accuracy: 0.9329 - val_loss: 0.7888 - val_accuracy: 0.7919\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3479 - accuracy: 0.9273 - val_loss: 0.8354 - val_accuracy: 0.7523\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3385 - accuracy: 0.9355 - val_loss: 0.7899 - val_accuracy: 0.7862\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3293 - accuracy: 0.9380 - val_loss: 0.9044 - val_accuracy: 0.7330\n","Epoch 45/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3247 - accuracy: 0.9417 - val_loss: 0.8253 - val_accuracy: 0.7545\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3204 - accuracy: 0.9451 - val_loss: 0.8089 - val_accuracy: 0.7839\n","Epoch 47/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3246 - accuracy: 0.9426 - val_loss: 0.8254 - val_accuracy: 0.7602\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3256 - accuracy: 0.9386 - val_loss: 0.8036 - val_accuracy: 0.7681\n","Epoch 49/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3238 - accuracy: 0.9400 - val_loss: 0.8545 - val_accuracy: 0.7557\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3172 - accuracy: 0.9445 - val_loss: 0.8470 - val_accuracy: 0.7738\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3234 - accuracy: 0.9423 - val_loss: 0.8567 - val_accuracy: 0.7579\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3146 - accuracy: 0.9505 - val_loss: 0.8280 - val_accuracy: 0.7749\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3170 - accuracy: 0.9428 - val_loss: 0.8229 - val_accuracy: 0.7738\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3275 - accuracy: 0.9352 - val_loss: 0.8385 - val_accuracy: 0.7647\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3367 - accuracy: 0.9358 - val_loss: 0.8480 - val_accuracy: 0.7715\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3185 - accuracy: 0.9426 - val_loss: 0.8434 - val_accuracy: 0.7681\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3102 - accuracy: 0.9499 - val_loss: 0.8345 - val_accuracy: 0.7839\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3129 - accuracy: 0.9445 - val_loss: 0.8468 - val_accuracy: 0.7557\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3034 - accuracy: 0.9468 - val_loss: 0.8267 - val_accuracy: 0.7794\n","Epoch 60/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3003 - accuracy: 0.9550 - val_loss: 0.8377 - val_accuracy: 0.7760\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3131 - accuracy: 0.9431 - val_loss: 0.8524 - val_accuracy: 0.7579\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3054 - accuracy: 0.9513 - val_loss: 0.8434 - val_accuracy: 0.7704\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3061 - accuracy: 0.9437 - val_loss: 0.8550 - val_accuracy: 0.7602\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3058 - accuracy: 0.9462 - val_loss: 0.8697 - val_accuracy: 0.7771\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3087 - accuracy: 0.9462 - val_loss: 0.8611 - val_accuracy: 0.7658\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3033 - accuracy: 0.9477 - val_loss: 0.9279 - val_accuracy: 0.7387\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3038 - accuracy: 0.9508 - val_loss: 0.8855 - val_accuracy: 0.7658\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2991 - accuracy: 0.9519 - val_loss: 0.8876 - val_accuracy: 0.7523\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2910 - accuracy: 0.9550 - val_loss: 0.8594 - val_accuracy: 0.7794\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3010 - accuracy: 0.9510 - val_loss: 0.8707 - val_accuracy: 0.7658\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2870 - accuracy: 0.9587 - val_loss: 0.8845 - val_accuracy: 0.7647\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2866 - accuracy: 0.9550 - val_loss: 0.9140 - val_accuracy: 0.7477\n","Epoch 73/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3093 - accuracy: 0.9451 - val_loss: 0.8994 - val_accuracy: 0.7681\n","Epoch 74/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3032 - accuracy: 0.9508 - val_loss: 0.8959 - val_accuracy: 0.7692\n","Epoch 75/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2996 - accuracy: 0.9544 - val_loss: 1.1176 - val_accuracy: 0.7296\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3223 - accuracy: 0.9431 - val_loss: 0.9098 - val_accuracy: 0.7432\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2907 - accuracy: 0.9561 - val_loss: 0.9067 - val_accuracy: 0.7421\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2883 - accuracy: 0.9505 - val_loss: 0.8826 - val_accuracy: 0.7602\n","Epoch 79/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2872 - accuracy: 0.9547 - val_loss: 0.8817 - val_accuracy: 0.7760\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2848 - accuracy: 0.9576 - val_loss: 0.9188 - val_accuracy: 0.7715\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2811 - accuracy: 0.9581 - val_loss: 0.9556 - val_accuracy: 0.7636\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2939 - accuracy: 0.9539 - val_loss: 0.9548 - val_accuracy: 0.7443\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3068 - accuracy: 0.9496 - val_loss: 0.9245 - val_accuracy: 0.7624\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2735 - accuracy: 0.9618 - val_loss: 0.9444 - val_accuracy: 0.7670\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2786 - accuracy: 0.9607 - val_loss: 0.9127 - val_accuracy: 0.7681\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2652 - accuracy: 0.9663 - val_loss: 0.9086 - val_accuracy: 0.7681\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2755 - accuracy: 0.9612 - val_loss: 0.9172 - val_accuracy: 0.7704\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2744 - accuracy: 0.9652 - val_loss: 0.9431 - val_accuracy: 0.7738\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2731 - accuracy: 0.9624 - val_loss: 0.9186 - val_accuracy: 0.7670\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2749 - accuracy: 0.9587 - val_loss: 0.9166 - val_accuracy: 0.7749\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2741 - accuracy: 0.9641 - val_loss: 0.9139 - val_accuracy: 0.7738\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2667 - accuracy: 0.9658 - val_loss: 0.9335 - val_accuracy: 0.7670\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2738 - accuracy: 0.9612 - val_loss: 0.9041 - val_accuracy: 0.7738\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2639 - accuracy: 0.9621 - val_loss: 0.9415 - val_accuracy: 0.7647\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2692 - accuracy: 0.9621 - val_loss: 0.9382 - val_accuracy: 0.7760\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2606 - accuracy: 0.9677 - val_loss: 1.0046 - val_accuracy: 0.7624\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2693 - accuracy: 0.9638 - val_loss: 0.9794 - val_accuracy: 0.7557\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2688 - accuracy: 0.9612 - val_loss: 0.9822 - val_accuracy: 0.7568\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2647 - accuracy: 0.9652 - val_loss: 1.0017 - val_accuracy: 0.7466\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2708 - accuracy: 0.9626 - val_loss: 0.9495 - val_accuracy: 0.7624\n","{'loss': [0.4551219344139099, 0.4318679869174957, 0.42766642570495605, 0.4225216209888458, 0.42312395572662354, 0.4109267592430115, 0.40349510312080383, 0.41232627630233765, 0.39983999729156494, 0.40596574544906616, 0.4026426672935486, 0.4164576232433319, 0.41561296582221985, 0.39151471853256226, 0.3891949951648712, 0.3864600360393524, 0.3784204423427582, 0.37981051206588745, 0.374299556016922, 0.36855897307395935, 0.3810342848300934, 0.3724916875362396, 0.3629804849624634, 0.36215245723724365, 0.3711450397968292, 0.3649101257324219, 0.36650893092155457, 0.3743659257888794, 0.3515584170818329, 0.36726170778274536, 0.35948312282562256, 0.3511376678943634, 0.3553581237792969, 0.3579190969467163, 0.35142406821250916, 0.3448822796344757, 0.3388383388519287, 0.3481798768043518, 0.3388158977031708, 0.33798015117645264, 0.34546959400177, 0.3479447662830353, 0.33848005533218384, 0.3293321430683136, 0.3247438967227936, 0.3203696310520172, 0.3245741128921509, 0.3256132900714874, 0.3237874507904053, 0.31717532873153687, 0.32343921065330505, 0.3146328330039978, 0.3169645071029663, 0.32749226689338684, 0.3367193639278412, 0.318533718585968, 0.3101528286933899, 0.31292924284935, 0.3034120798110962, 0.30028441548347473, 0.3130553662776947, 0.30540791153907776, 0.3060734272003174, 0.3057628571987152, 0.3087412714958191, 0.30329957604408264, 0.3037720322608948, 0.29910731315612793, 0.29104602336883545, 0.3009709119796753, 0.2869669795036316, 0.2866162657737732, 0.3092922270298004, 0.30321747064590454, 0.2996041774749756, 0.32225698232650757, 0.2906961739063263, 0.2882736623287201, 0.28724002838134766, 0.28476598858833313, 0.2810904383659363, 0.2939424514770508, 0.3067712187767029, 0.27351948618888855, 0.2785549461841583, 0.26522883772850037, 0.27551957964897156, 0.2743675410747528, 0.27312758564949036, 0.27490776777267456, 0.2741045653820038, 0.2666556239128113, 0.2737882435321808, 0.2639162540435791, 0.26924988627433777, 0.26059964299201965, 0.2693360447883606, 0.2688356637954712, 0.2647191882133484, 0.2708040475845337], 'accuracy': [0.8865308165550232, 0.8989813327789307, 0.8992642760276794, 0.9003961682319641, 0.9009620547294617, 0.9018110036849976, 0.9139785170555115, 0.9035087823867798, 0.9091680645942688, 0.9077532291412354, 0.9074702858924866, 0.9057725071907043, 0.8970005512237549, 0.9134125709533691, 0.9170911312103271, 0.9187889099121094, 0.9207696914672852, 0.9193548560142517, 0.9224674701690674, 0.9255800843238831, 0.9168081283569336, 0.9210526347160339, 0.9275608658790588, 0.9278438091278076, 0.9204866886138916, 0.9272778630256653, 0.9224674701690674, 0.9196377992630005, 0.92840975522995, 0.9230334162712097, 0.9255800843238831, 0.9309564232826233, 0.9312393665313721, 0.9292586445808411, 0.9278438091278076, 0.9295415878295898, 0.9349179267883301, 0.9306734800338745, 0.9354838728904724, 0.9374646544456482, 0.9329372048377991, 0.9272778630256653, 0.9354838728904724, 0.9380305409431458, 0.9417091012001038, 0.945104718208313, 0.9425579905509949, 0.9385964870452881, 0.9400113224983215, 0.9445387721061707, 0.9422750473022461, 0.9504810571670532, 0.9428409934043884, 0.9352009296417236, 0.9357668161392212, 0.9425579905509949, 0.9499151110649109, 0.9445387721061707, 0.9468024969100952, 0.9550085067749023, 0.9431239366531372, 0.9513299465179443, 0.9436898827552795, 0.9462365508079529, 0.9462365508079529, 0.9476513862609863, 0.950764000415802, 0.9518958926200867, 0.9550085067749023, 0.9510469436645508, 0.9586870670318604, 0.9550085067749023, 0.945104718208313, 0.950764000415802, 0.95444256067276, 0.9431239366531372, 0.9561403393745422, 0.9504810571670532, 0.9547255039215088, 0.9575551748275757, 0.958121120929718, 0.9538766145706177, 0.9496321678161621, 0.961799681186676, 0.9606677889823914, 0.9663271307945251, 0.9612337350845337, 0.9651952385902405, 0.9623655676841736, 0.9586870670318604, 0.9640634059906006, 0.9657611846923828, 0.9612337350845337, 0.9620826244354248, 0.9620826244354248, 0.9677419066429138, 0.963780403137207, 0.9612337350845337, 0.9651952385902405, 0.9626485705375671], 'val_loss': [1.4211173057556152, 1.4301085472106934, 1.4266678094863892, 1.412645936012268, 1.4240200519561768, 1.4602289199829102, 1.4524154663085938, 1.4600039720535278, 1.4597673416137695, 1.4564000368118286, 1.4769079685211182, 1.3891336917877197, 1.4701347351074219, 1.4796125888824463, 1.378719449043274, 1.3572299480438232, 1.3678685426712036, 1.2548755407333374, 1.207300066947937, 1.1626523733139038, 0.9716070294380188, 1.0158179998397827, 0.8655115962028503, 0.8777093887329102, 0.7493647336959839, 0.780497670173645, 0.7263537049293518, 0.7112398743629456, 0.7334450483322144, 0.8120893836021423, 0.7463092803955078, 0.7372303009033203, 0.7705027461051941, 0.7470481395721436, 0.741509199142456, 0.7564203143119812, 0.8341183662414551, 0.7677574753761292, 0.7799762487411499, 0.8410965800285339, 0.7887598872184753, 0.8354155421257019, 0.7898619771003723, 0.9044156074523926, 0.8253240585327148, 0.8089420795440674, 0.8254079818725586, 0.8035675287246704, 0.8544877171516418, 0.8469784259796143, 0.8567447066307068, 0.8280220627784729, 0.8229112029075623, 0.8384764194488525, 0.8479850888252258, 0.8433549404144287, 0.8344828486442566, 0.8467704057693481, 0.8267372250556946, 0.8377394676208496, 0.8524367213249207, 0.843368649482727, 0.8550286889076233, 0.8697115778923035, 0.8611483573913574, 0.9278698563575745, 0.8854511380195618, 0.8876198530197144, 0.8594256639480591, 0.8706735968589783, 0.8845133185386658, 0.9140135645866394, 0.8994014263153076, 0.8959275484085083, 1.1176384687423706, 0.9097881317138672, 0.9066882133483887, 0.8826006650924683, 0.8817205429077148, 0.9188091158866882, 0.9556418061256409, 0.9547711610794067, 0.9245200753211975, 0.9443964958190918, 0.91265469789505, 0.9085955619812012, 0.9171960949897766, 0.9431338906288147, 0.9186118245124817, 0.916550874710083, 0.913886547088623, 0.9335244297981262, 0.9040799140930176, 0.9414687156677246, 0.9381659030914307, 1.0046478509902954, 0.9793500304222107, 0.9822169542312622, 1.0017036199569702, 0.949537992477417], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.5, 0.5056561231613159, 0.5011312365531921, 0.5067873597145081, 0.516968309879303, 0.5316742062568665, 0.5350678563117981, 0.5633484125137329, 0.5791855454444885, 0.5961538553237915, 0.651583731174469, 0.6459276080131531, 0.6957013607025146, 0.6979637742042542, 0.7420814633369446, 0.7296379804611206, 0.7624434232711792, 0.7850678563117981, 0.7703620195388794, 0.7545248866081238, 0.7647058963775635, 0.7861990928649902, 0.7873303294181824, 0.7828054428100586, 0.7850678563117981, 0.7760180830955505, 0.7579185366630554, 0.7816742062568665, 0.7895927429199219, 0.7703620195388794, 0.7918552160263062, 0.7522624731063843, 0.7861990928649902, 0.733031690120697, 0.7545248866081238, 0.7839366793632507, 0.7601810097694397, 0.7680995464324951, 0.7556561231613159, 0.773755669593811, 0.7579185366630554, 0.7748869061470032, 0.773755669593811, 0.7647058963775635, 0.7714931964874268, 0.7680995464324951, 0.7839366793632507, 0.7556561231613159, 0.779411792755127, 0.7760180830955505, 0.7579185366630554, 0.7703620195388794, 0.7601810097694397, 0.7771493196487427, 0.7658371329307556, 0.7386877536773682, 0.7658371329307556, 0.7522624731063843, 0.779411792755127, 0.7658371329307556, 0.7647058963775635, 0.7477375268936157, 0.7680995464324951, 0.7692307829856873, 0.7296379804611206, 0.7432126402854919, 0.7420814633369446, 0.7601810097694397, 0.7760180830955505, 0.7714931964874268, 0.7635746598243713, 0.7443438768386841, 0.7624434232711792, 0.766968309879303, 0.7680995464324951, 0.7680995464324951, 0.7703620195388794, 0.773755669593811, 0.766968309879303, 0.7748869061470032, 0.773755669593811, 0.766968309879303, 0.773755669593811, 0.7647058963775635, 0.7760180830955505, 0.7624434232711792, 0.7556561231613159, 0.7567873597145081, 0.7466063499450684, 0.7624434232711792]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.4712 - accuracy: 0.8728"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 7s 50ms/step - loss: 0.4682 - accuracy: 0.8747 - val_loss: 1.4235 - val_accuracy: 0.4866\n","Epoch 2/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4546 - accuracy: 0.8835 - val_loss: 1.4376 - val_accuracy: 0.4876\n","Epoch 3/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4519 - accuracy: 0.8827 - val_loss: 1.4368 - val_accuracy: 0.4876\n","Epoch 4/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4377 - accuracy: 0.8884 - val_loss: 1.4374 - val_accuracy: 0.4876\n","Epoch 5/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4296 - accuracy: 0.8943 - val_loss: 1.4586 - val_accuracy: 0.4876\n","Epoch 6/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4245 - accuracy: 0.8935 - val_loss: 1.4490 - val_accuracy: 0.4897\n","Epoch 7/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4264 - accuracy: 0.8956 - val_loss: 1.4563 - val_accuracy: 0.4897\n","Epoch 8/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4299 - accuracy: 0.8959 - val_loss: 1.4749 - val_accuracy: 0.4897\n","Epoch 9/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4296 - accuracy: 0.8941 - val_loss: 1.4561 - val_accuracy: 0.4907\n","Epoch 10/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4132 - accuracy: 0.9008 - val_loss: 1.4818 - val_accuracy: 0.4907\n","Epoch 11/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4081 - accuracy: 0.9021 - val_loss: 1.4991 - val_accuracy: 0.4959\n","Epoch 12/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4110 - accuracy: 0.9039 - val_loss: 1.4447 - val_accuracy: 0.5021\n","Epoch 13/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4013 - accuracy: 0.9090 - val_loss: 1.4359 - val_accuracy: 0.5083\n","Epoch 14/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4017 - accuracy: 0.9023 - val_loss: 1.4204 - val_accuracy: 0.5145\n","Epoch 15/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4033 - accuracy: 0.9085 - val_loss: 1.4206 - val_accuracy: 0.5258\n","Epoch 16/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3968 - accuracy: 0.9065 - val_loss: 1.3129 - val_accuracy: 0.5486\n","Epoch 17/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3953 - accuracy: 0.9062 - val_loss: 1.3361 - val_accuracy: 0.5527\n","Epoch 18/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3854 - accuracy: 0.9106 - val_loss: 1.1992 - val_accuracy: 0.5795\n","Epoch 19/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3788 - accuracy: 0.9194 - val_loss: 1.1643 - val_accuracy: 0.5930\n","Epoch 20/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3886 - accuracy: 0.9132 - val_loss: 1.0821 - val_accuracy: 0.6219\n","Epoch 21/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3896 - accuracy: 0.9111 - val_loss: 0.9527 - val_accuracy: 0.6601\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3807 - accuracy: 0.9152 - val_loss: 0.9835 - val_accuracy: 0.6601\n","Epoch 23/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3877 - accuracy: 0.9116 - val_loss: 0.8321 - val_accuracy: 0.7273\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3732 - accuracy: 0.9165 - val_loss: 0.8928 - val_accuracy: 0.7159\n","Epoch 25/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3729 - accuracy: 0.9173 - val_loss: 0.8597 - val_accuracy: 0.7376\n","Epoch 26/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3660 - accuracy: 0.9245 - val_loss: 0.8521 - val_accuracy: 0.7448\n","Epoch 27/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3717 - accuracy: 0.9178 - val_loss: 0.8559 - val_accuracy: 0.7562\n","Epoch 28/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3702 - accuracy: 0.9199 - val_loss: 0.8657 - val_accuracy: 0.7479\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3658 - accuracy: 0.9212 - val_loss: 0.9469 - val_accuracy: 0.7242\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3665 - accuracy: 0.9253 - val_loss: 0.8817 - val_accuracy: 0.7366\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3581 - accuracy: 0.9269 - val_loss: 0.9443 - val_accuracy: 0.7459\n","Epoch 32/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3559 - accuracy: 0.9251 - val_loss: 0.8972 - val_accuracy: 0.7583\n","Epoch 33/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3631 - accuracy: 0.9261 - val_loss: 0.9090 - val_accuracy: 0.7417\n","Epoch 34/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3589 - accuracy: 0.9251 - val_loss: 0.9031 - val_accuracy: 0.7500\n","Epoch 35/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3715 - accuracy: 0.9165 - val_loss: 0.9385 - val_accuracy: 0.7521\n","Epoch 36/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3539 - accuracy: 0.9256 - val_loss: 0.9155 - val_accuracy: 0.7469\n","Epoch 37/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3589 - accuracy: 0.9209 - val_loss: 0.9998 - val_accuracy: 0.7211\n","Epoch 38/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3528 - accuracy: 0.9264 - val_loss: 0.9163 - val_accuracy: 0.7397\n","Epoch 39/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3540 - accuracy: 0.9227 - val_loss: 0.9831 - val_accuracy: 0.7552\n","Epoch 40/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3529 - accuracy: 0.9245 - val_loss: 1.0217 - val_accuracy: 0.7200\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3533 - accuracy: 0.9264 - val_loss: 0.9422 - val_accuracy: 0.7521\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3445 - accuracy: 0.9292 - val_loss: 0.9466 - val_accuracy: 0.7552\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3530 - accuracy: 0.9235 - val_loss: 0.9722 - val_accuracy: 0.7376\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3370 - accuracy: 0.9354 - val_loss: 0.9842 - val_accuracy: 0.7428\n","Epoch 45/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3417 - accuracy: 0.9320 - val_loss: 0.9924 - val_accuracy: 0.7345\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3333 - accuracy: 0.9370 - val_loss: 0.9854 - val_accuracy: 0.7314\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3362 - accuracy: 0.9367 - val_loss: 0.9744 - val_accuracy: 0.7397\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3358 - accuracy: 0.9292 - val_loss: 1.0249 - val_accuracy: 0.7521\n","Epoch 49/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3417 - accuracy: 0.9297 - val_loss: 0.9881 - val_accuracy: 0.7314\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3411 - accuracy: 0.9274 - val_loss: 1.0310 - val_accuracy: 0.7448\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3365 - accuracy: 0.9333 - val_loss: 0.9786 - val_accuracy: 0.7541\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3308 - accuracy: 0.9362 - val_loss: 0.9722 - val_accuracy: 0.7572\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3222 - accuracy: 0.9419 - val_loss: 0.9593 - val_accuracy: 0.7479\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3175 - accuracy: 0.9398 - val_loss: 1.0114 - val_accuracy: 0.7479\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3284 - accuracy: 0.9393 - val_loss: 1.0053 - val_accuracy: 0.7304\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3299 - accuracy: 0.9326 - val_loss: 1.0586 - val_accuracy: 0.7521\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3742 - accuracy: 0.9090 - val_loss: 0.9812 - val_accuracy: 0.7355\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3749 - accuracy: 0.9160 - val_loss: 1.0033 - val_accuracy: 0.7376\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3235 - accuracy: 0.9406 - val_loss: 0.9746 - val_accuracy: 0.7490\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3177 - accuracy: 0.9442 - val_loss: 1.0423 - val_accuracy: 0.7262\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3257 - accuracy: 0.9375 - val_loss: 1.0171 - val_accuracy: 0.7335\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3198 - accuracy: 0.9398 - val_loss: 1.0190 - val_accuracy: 0.7304\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3178 - accuracy: 0.9426 - val_loss: 1.0430 - val_accuracy: 0.7438\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3190 - accuracy: 0.9390 - val_loss: 1.0257 - val_accuracy: 0.7562\n","Epoch 65/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3160 - accuracy: 0.9429 - val_loss: 1.0125 - val_accuracy: 0.7366\n","Epoch 66/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3119 - accuracy: 0.9437 - val_loss: 1.0352 - val_accuracy: 0.7407\n","Epoch 67/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3073 - accuracy: 0.9444 - val_loss: 1.0118 - val_accuracy: 0.7417\n","Epoch 68/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3056 - accuracy: 0.9475 - val_loss: 1.0386 - val_accuracy: 0.7521\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3032 - accuracy: 0.9481 - val_loss: 1.0900 - val_accuracy: 0.7231\n","Epoch 70/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3144 - accuracy: 0.9426 - val_loss: 1.0549 - val_accuracy: 0.7386\n","Epoch 71/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3020 - accuracy: 0.9439 - val_loss: 1.0739 - val_accuracy: 0.7438\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2953 - accuracy: 0.9514 - val_loss: 1.0700 - val_accuracy: 0.7459\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2979 - accuracy: 0.9532 - val_loss: 1.0584 - val_accuracy: 0.7324\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3240 - accuracy: 0.9344 - val_loss: 1.0460 - val_accuracy: 0.7490\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2965 - accuracy: 0.9517 - val_loss: 1.1089 - val_accuracy: 0.7324\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3161 - accuracy: 0.9413 - val_loss: 1.0530 - val_accuracy: 0.7407\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3135 - accuracy: 0.9437 - val_loss: 1.0595 - val_accuracy: 0.7407\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3109 - accuracy: 0.9426 - val_loss: 1.0537 - val_accuracy: 0.7469\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2878 - accuracy: 0.9540 - val_loss: 1.0552 - val_accuracy: 0.7490\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3000 - accuracy: 0.9437 - val_loss: 1.0677 - val_accuracy: 0.7283\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2886 - accuracy: 0.9532 - val_loss: 1.1087 - val_accuracy: 0.7211\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2942 - accuracy: 0.9506 - val_loss: 1.0756 - val_accuracy: 0.7490\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3018 - accuracy: 0.9444 - val_loss: 1.1024 - val_accuracy: 0.7407\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2968 - accuracy: 0.9481 - val_loss: 1.0979 - val_accuracy: 0.7242\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2845 - accuracy: 0.9543 - val_loss: 1.1350 - val_accuracy: 0.7283\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2913 - accuracy: 0.9532 - val_loss: 1.0974 - val_accuracy: 0.7500\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3166 - accuracy: 0.9370 - val_loss: 1.1516 - val_accuracy: 0.7293\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2912 - accuracy: 0.9530 - val_loss: 1.1076 - val_accuracy: 0.7273\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3020 - accuracy: 0.9429 - val_loss: 1.0808 - val_accuracy: 0.7469\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2850 - accuracy: 0.9550 - val_loss: 1.0806 - val_accuracy: 0.7479\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2769 - accuracy: 0.9615 - val_loss: 1.1027 - val_accuracy: 0.7438\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2940 - accuracy: 0.9478 - val_loss: 1.1244 - val_accuracy: 0.7459\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2840 - accuracy: 0.9537 - val_loss: 1.1204 - val_accuracy: 0.7510\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2796 - accuracy: 0.9563 - val_loss: 1.0865 - val_accuracy: 0.7541\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3037 - accuracy: 0.9470 - val_loss: 1.1624 - val_accuracy: 0.7283\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2929 - accuracy: 0.9494 - val_loss: 1.1859 - val_accuracy: 0.7355\n","Epoch 97/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2768 - accuracy: 0.9558 - val_loss: 1.1216 - val_accuracy: 0.7490\n","Epoch 98/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2744 - accuracy: 0.9556 - val_loss: 1.1155 - val_accuracy: 0.7531\n","Epoch 99/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2732 - accuracy: 0.9602 - val_loss: 1.0916 - val_accuracy: 0.7417\n","Epoch 100/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2644 - accuracy: 0.9587 - val_loss: 1.1253 - val_accuracy: 0.7510\n","{'loss': [0.46819692850112915, 0.4545518159866333, 0.4519447088241577, 0.4377095401287079, 0.42963287234306335, 0.42454078793525696, 0.42636168003082275, 0.4298536479473114, 0.4295670688152313, 0.41321516036987305, 0.40809938311576843, 0.4110185205936432, 0.4012964367866516, 0.40169328451156616, 0.40327927470207214, 0.39678823947906494, 0.3952852189540863, 0.38540446758270264, 0.3788197338581085, 0.38863128423690796, 0.38955941796302795, 0.38065290451049805, 0.38768935203552246, 0.37316522002220154, 0.3728901743888855, 0.36603981256484985, 0.37170013785362244, 0.37022483348846436, 0.3657626509666443, 0.36647936701774597, 0.3581392467021942, 0.3558555245399475, 0.36308956146240234, 0.3588974177837372, 0.37147602438926697, 0.3538743853569031, 0.35885587334632874, 0.35284850001335144, 0.35399147868156433, 0.35286906361579895, 0.35330548882484436, 0.3445321321487427, 0.3530419170856476, 0.33704161643981934, 0.34172654151916504, 0.33327844738960266, 0.33615702390670776, 0.33584028482437134, 0.3417312800884247, 0.3411259949207306, 0.3364562690258026, 0.33081939816474915, 0.32217684388160706, 0.3174732029438019, 0.32844433188438416, 0.3298797905445099, 0.37415775656700134, 0.37491634488105774, 0.3235008120536804, 0.3176816999912262, 0.32567301392555237, 0.3197924494743347, 0.3178425431251526, 0.31899261474609375, 0.3159753680229187, 0.31193190813064575, 0.30725589394569397, 0.30559927225112915, 0.3032175600528717, 0.31443148851394653, 0.3020479381084442, 0.2952994108200073, 0.29794493317604065, 0.32395538687705994, 0.29650256037712097, 0.31608694791793823, 0.313534677028656, 0.31092458963394165, 0.2877766788005829, 0.2999580204486847, 0.28864288330078125, 0.29416781663894653, 0.3018491864204407, 0.2968326508998871, 0.2844737470149994, 0.2913282811641693, 0.3165521025657654, 0.29116520285606384, 0.30195102095603943, 0.2850341498851776, 0.27691560983657837, 0.2939988374710083, 0.28395166993141174, 0.279629647731781, 0.3036648631095886, 0.2928890287876129, 0.27681154012680054, 0.2744198441505432, 0.27323850989341736, 0.2643984854221344], 'accuracy': [0.8746770024299622, 0.8834625482559204, 0.8826873302459717, 0.8883720636367798, 0.894315242767334, 0.8935400247573853, 0.8956072330474854, 0.8958656191825867, 0.8940568566322327, 0.9007751941680908, 0.9020671844482422, 0.9038759469985962, 0.9090439081192017, 0.9023255705833435, 0.908527135848999, 0.9064599275588989, 0.9062015414237976, 0.9105943441390991, 0.9193798303604126, 0.9131782650947571, 0.9111111164093018, 0.9152454733848572, 0.9116278886795044, 0.9165374636650085, 0.9173126816749573, 0.9245477914810181, 0.9178294539451599, 0.91989666223526, 0.9211886525154114, 0.9253230094909668, 0.9268733859062195, 0.9250646233558655, 0.9260981678962708, 0.9250646233558655, 0.9165374636650085, 0.9255813956260681, 0.9209302067756653, 0.9263566136360168, 0.9227390289306641, 0.9245477914810181, 0.9263566136360168, 0.9291989803314209, 0.923514187335968, 0.9354005455970764, 0.932041347026825, 0.9369509220123291, 0.9366925358772278, 0.9291989803314209, 0.9297157526016235, 0.9273901581764221, 0.9333333373069763, 0.9361757040023804, 0.9418604373931885, 0.9397932887077332, 0.9392764568328857, 0.9325581192970276, 0.9090439081192017, 0.9160206913948059, 0.9405684471130371, 0.9441860318183899, 0.9374676942825317, 0.9397932887077332, 0.9426356554031372, 0.9390180706977844, 0.9428940415382385, 0.9436692595481873, 0.9444444179534912, 0.9475452303886414, 0.948062002658844, 0.9426356554031372, 0.9439276456832886, 0.9514212012290955, 0.9532299637794495, 0.9343669414520264, 0.9516795873641968, 0.9413436651229858, 0.9436692595481873, 0.9426356554031372, 0.9540051817893982, 0.9436692595481873, 0.9532299637794495, 0.9506459832191467, 0.9444444179534912, 0.948062002658844, 0.9542635679244995, 0.9532299637794495, 0.9369509220123291, 0.9529715776443481, 0.9428940415382385, 0.9550387859344482, 0.9614987373352051, 0.9478036165237427, 0.9537467956542969, 0.9563307762145996, 0.947028398513794, 0.9493539929389954, 0.9558139443397522, 0.9555555582046509, 0.9602067470550537, 0.9586563110351562], 'val_loss': [1.4235403537750244, 1.4376249313354492, 1.4368408918380737, 1.4373643398284912, 1.458632469177246, 1.449018120765686, 1.4562546014785767, 1.4749350547790527, 1.4560914039611816, 1.4817781448364258, 1.4991381168365479, 1.4447013139724731, 1.4358936548233032, 1.4204498529434204, 1.4206334352493286, 1.3129361867904663, 1.336104154586792, 1.1991593837738037, 1.1642754077911377, 1.082098364830017, 0.9527371525764465, 0.9834705591201782, 0.8320973515510559, 0.8927655816078186, 0.859677255153656, 0.8521327376365662, 0.8559221625328064, 0.8657069206237793, 0.9468693733215332, 0.88174968957901, 0.9443017244338989, 0.8971746563911438, 0.9090395569801331, 0.9030807018280029, 0.9385471343994141, 0.9155495166778564, 0.9998310804367065, 0.9162563681602478, 0.9830537438392639, 1.0216695070266724, 0.9422063827514648, 0.9465607404708862, 0.972208559513092, 0.9842385649681091, 0.9923520088195801, 0.9854399561882019, 0.9744309186935425, 1.0248796939849854, 0.9881353974342346, 1.0309951305389404, 0.9786211848258972, 0.9722490906715393, 0.959254264831543, 1.0114377737045288, 1.0053179264068604, 1.0585602521896362, 0.9811866879463196, 1.0032604932785034, 0.974585235118866, 1.0423405170440674, 1.01706862449646, 1.0190263986587524, 1.0430116653442383, 1.0256975889205933, 1.0125004053115845, 1.0352498292922974, 1.0117517709732056, 1.0385819673538208, 1.0900076627731323, 1.0548789501190186, 1.0739171504974365, 1.0699901580810547, 1.0584198236465454, 1.0460078716278076, 1.1089236736297607, 1.0529911518096924, 1.0594663619995117, 1.0537335872650146, 1.0551564693450928, 1.0676684379577637, 1.1087206602096558, 1.0756056308746338, 1.1024423837661743, 1.0979175567626953, 1.1350388526916504, 1.0974280834197998, 1.1515889167785645, 1.1075536012649536, 1.080816626548767, 1.0806396007537842, 1.1026701927185059, 1.124350905418396, 1.1203796863555908, 1.0865055322647095, 1.1624255180358887, 1.1859444379806519, 1.121640920639038, 1.1155396699905396, 1.0916417837142944, 1.1252789497375488], 'val_accuracy': [0.48657023906707764, 0.4876033067703247, 0.4876033067703247, 0.4876033067703247, 0.4876033067703247, 0.48966941237449646, 0.48966941237449646, 0.48966941237449646, 0.49070248007774353, 0.49070248007774353, 0.4958677589893341, 0.5020661354064941, 0.5082644820213318, 0.5144628286361694, 0.5258264541625977, 0.5485537052154541, 0.5526859760284424, 0.5795454382896423, 0.5929751992225647, 0.6219007968902588, 0.6601239442825317, 0.6601239442825317, 0.7272727489471436, 0.7159090638160706, 0.7376033067703247, 0.7448347210884094, 0.7561983466148376, 0.7479338645935059, 0.7241735458374023, 0.7365702390670776, 0.7458677887916565, 0.7582644820213318, 0.7417355179786682, 0.75, 0.7520661354064941, 0.7469007968902588, 0.7210744023323059, 0.7396694421768188, 0.7551652789115906, 0.7200413346290588, 0.7520661354064941, 0.7551652789115906, 0.7376033067703247, 0.7427685856819153, 0.7345041036605835, 0.7314049601554871, 0.7396694421768188, 0.7520661354064941, 0.7314049601554871, 0.7448347210884094, 0.7541322112083435, 0.7572314143180847, 0.7479338645935059, 0.7479338645935059, 0.73037189245224, 0.7520661354064941, 0.7355371713638306, 0.7376033067703247, 0.7489669322967529, 0.7262396812438965, 0.7334710955619812, 0.73037189245224, 0.7438016533851624, 0.7561983466148376, 0.7365702390670776, 0.7407024502754211, 0.7417355179786682, 0.7520661354064941, 0.7231404781341553, 0.7386363744735718, 0.7438016533851624, 0.7458677887916565, 0.7324380278587341, 0.7489669322967529, 0.7324380278587341, 0.7407024502754211, 0.7407024502754211, 0.7469007968902588, 0.7489669322967529, 0.7283057570457458, 0.7210744023323059, 0.7489669322967529, 0.7407024502754211, 0.7241735458374023, 0.7283057570457458, 0.75, 0.7293388247489929, 0.7272727489471436, 0.7469007968902588, 0.7479338645935059, 0.7438016533851624, 0.7458677887916565, 0.7510330677032471, 0.7541322112083435, 0.7283057570457458, 0.7355371713638306, 0.7489669322967529, 0.7530992031097412, 0.7417355179786682, 0.7510330677032471]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.3614 - accuracy: 0.9272"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 7s 48ms/step - loss: 0.3604 - accuracy: 0.9281 - val_loss: 1.7651 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3454 - accuracy: 0.9353 - val_loss: 1.7871 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3248 - accuracy: 0.9340 - val_loss: 1.8062 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3248 - accuracy: 0.9378 - val_loss: 1.7687 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3136 - accuracy: 0.9448 - val_loss: 1.8046 - val_accuracy: 0.4860\n","Epoch 6/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3211 - accuracy: 0.9367 - val_loss: 1.7813 - val_accuracy: 0.4860\n","Epoch 7/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3217 - accuracy: 0.9337 - val_loss: 1.8220 - val_accuracy: 0.4860\n","Epoch 8/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3260 - accuracy: 0.9386 - val_loss: 1.8095 - val_accuracy: 0.4871\n","Epoch 9/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3059 - accuracy: 0.9442 - val_loss: 1.8236 - val_accuracy: 0.4892\n","Epoch 10/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.3017 - accuracy: 0.9437 - val_loss: 1.7814 - val_accuracy: 0.4914\n","Epoch 11/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3071 - accuracy: 0.9440 - val_loss: 1.7894 - val_accuracy: 0.4946\n","Epoch 12/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2922 - accuracy: 0.9507 - val_loss: 1.7414 - val_accuracy: 0.5011\n","Epoch 13/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2909 - accuracy: 0.9542 - val_loss: 1.8021 - val_accuracy: 0.5022\n","Epoch 14/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2947 - accuracy: 0.9507 - val_loss: 1.7850 - val_accuracy: 0.5075\n","Epoch 15/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.2983 - accuracy: 0.9461 - val_loss: 1.7290 - val_accuracy: 0.5108\n","Epoch 16/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3044 - accuracy: 0.9402 - val_loss: 1.6108 - val_accuracy: 0.5356\n","Epoch 17/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.2921 - accuracy: 0.9499 - val_loss: 1.5340 - val_accuracy: 0.5496\n","Epoch 18/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.2854 - accuracy: 0.9550 - val_loss: 1.4958 - val_accuracy: 0.5679\n","Epoch 19/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.2854 - accuracy: 0.9547 - val_loss: 1.2511 - val_accuracy: 0.6121\n","Epoch 20/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2876 - accuracy: 0.9550 - val_loss: 1.4529 - val_accuracy: 0.5905\n","Epoch 21/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2724 - accuracy: 0.9591 - val_loss: 1.0367 - val_accuracy: 0.6778\n","Epoch 22/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.2907 - accuracy: 0.9445 - val_loss: 0.9799 - val_accuracy: 0.7037\n","Epoch 23/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2815 - accuracy: 0.9553 - val_loss: 0.8284 - val_accuracy: 0.7468\n","Epoch 24/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2785 - accuracy: 0.9558 - val_loss: 0.8251 - val_accuracy: 0.7511\n","Epoch 25/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2733 - accuracy: 0.9558 - val_loss: 0.8153 - val_accuracy: 0.7748\n","Epoch 26/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2853 - accuracy: 0.9545 - val_loss: 0.6972 - val_accuracy: 0.8200\n","Epoch 27/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2824 - accuracy: 0.9512 - val_loss: 0.6895 - val_accuracy: 0.8179\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2957 - accuracy: 0.9472 - val_loss: 0.8850 - val_accuracy: 0.7629\n","Epoch 29/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2780 - accuracy: 0.9561 - val_loss: 0.7426 - val_accuracy: 0.8233\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2666 - accuracy: 0.9634 - val_loss: 0.7277 - val_accuracy: 0.8222\n","Epoch 31/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2636 - accuracy: 0.9620 - val_loss: 0.7270 - val_accuracy: 0.8254\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2810 - accuracy: 0.9547 - val_loss: 0.7397 - val_accuracy: 0.8168\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2713 - accuracy: 0.9609 - val_loss: 0.7545 - val_accuracy: 0.8168\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2841 - accuracy: 0.9502 - val_loss: 0.7882 - val_accuracy: 0.8114\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2726 - accuracy: 0.9599 - val_loss: 0.7526 - val_accuracy: 0.8254\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2666 - accuracy: 0.9644 - val_loss: 0.7673 - val_accuracy: 0.8211\n","Epoch 37/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2678 - accuracy: 0.9620 - val_loss: 0.7875 - val_accuracy: 0.8190\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2746 - accuracy: 0.9553 - val_loss: 0.7841 - val_accuracy: 0.8244\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2608 - accuracy: 0.9628 - val_loss: 0.9017 - val_accuracy: 0.8179\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2799 - accuracy: 0.9588 - val_loss: 0.7779 - val_accuracy: 0.8190\n","Epoch 41/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2583 - accuracy: 0.9639 - val_loss: 0.7747 - val_accuracy: 0.8114\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2610 - accuracy: 0.9628 - val_loss: 0.8110 - val_accuracy: 0.8060\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2569 - accuracy: 0.9658 - val_loss: 0.8429 - val_accuracy: 0.8060\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2544 - accuracy: 0.9623 - val_loss: 0.8084 - val_accuracy: 0.8071\n","Epoch 45/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2635 - accuracy: 0.9617 - val_loss: 0.8540 - val_accuracy: 0.8017\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2620 - accuracy: 0.9588 - val_loss: 0.8138 - val_accuracy: 0.8114\n","Epoch 47/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2599 - accuracy: 0.9604 - val_loss: 0.9081 - val_accuracy: 0.7953\n","Epoch 48/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2693 - accuracy: 0.9553 - val_loss: 0.9048 - val_accuracy: 0.7823\n","Epoch 49/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2583 - accuracy: 0.9650 - val_loss: 0.8423 - val_accuracy: 0.7953\n","Epoch 50/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2461 - accuracy: 0.9661 - val_loss: 0.8439 - val_accuracy: 0.8017\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2517 - accuracy: 0.9650 - val_loss: 0.8726 - val_accuracy: 0.8157\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2461 - accuracy: 0.9706 - val_loss: 0.8791 - val_accuracy: 0.7996\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2502 - accuracy: 0.9671 - val_loss: 0.8459 - val_accuracy: 0.8125\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2483 - accuracy: 0.9674 - val_loss: 0.9183 - val_accuracy: 0.7985\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2502 - accuracy: 0.9658 - val_loss: 0.9023 - val_accuracy: 0.7877\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2558 - accuracy: 0.9620 - val_loss: 0.8664 - val_accuracy: 0.7974\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2486 - accuracy: 0.9677 - val_loss: 0.9002 - val_accuracy: 0.7877\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2470 - accuracy: 0.9677 - val_loss: 0.8995 - val_accuracy: 0.8060\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2449 - accuracy: 0.9714 - val_loss: 0.8836 - val_accuracy: 0.7985\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2382 - accuracy: 0.9720 - val_loss: 0.8526 - val_accuracy: 0.7985\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2567 - accuracy: 0.9636 - val_loss: 0.8649 - val_accuracy: 0.7985\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2464 - accuracy: 0.9639 - val_loss: 0.9918 - val_accuracy: 0.7953\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2542 - accuracy: 0.9671 - val_loss: 0.8463 - val_accuracy: 0.8211\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2332 - accuracy: 0.9728 - val_loss: 0.8555 - val_accuracy: 0.8179\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2341 - accuracy: 0.9720 - val_loss: 0.8750 - val_accuracy: 0.8050\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2623 - accuracy: 0.9588 - val_loss: 0.8628 - val_accuracy: 0.8136\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2540 - accuracy: 0.9617 - val_loss: 0.8587 - val_accuracy: 0.8017\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2387 - accuracy: 0.9720 - val_loss: 0.8484 - val_accuracy: 0.8125\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2580 - accuracy: 0.9626 - val_loss: 0.9521 - val_accuracy: 0.7791\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2639 - accuracy: 0.9582 - val_loss: 1.0274 - val_accuracy: 0.7812\n","Epoch 71/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2475 - accuracy: 0.9650 - val_loss: 0.9950 - val_accuracy: 0.8039\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2407 - accuracy: 0.9690 - val_loss: 0.8782 - val_accuracy: 0.8114\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2309 - accuracy: 0.9731 - val_loss: 0.8614 - val_accuracy: 0.8093\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2400 - accuracy: 0.9723 - val_loss: 0.8933 - val_accuracy: 0.8082\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2321 - accuracy: 0.9709 - val_loss: 0.8709 - val_accuracy: 0.8136\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2268 - accuracy: 0.9749 - val_loss: 0.8890 - val_accuracy: 0.8103\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2280 - accuracy: 0.9766 - val_loss: 0.8891 - val_accuracy: 0.8028\n","Epoch 78/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2268 - accuracy: 0.9741 - val_loss: 0.8625 - val_accuracy: 0.8071\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2290 - accuracy: 0.9720 - val_loss: 0.8848 - val_accuracy: 0.8082\n","Epoch 80/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2385 - accuracy: 0.9712 - val_loss: 0.9967 - val_accuracy: 0.7845\n","Epoch 81/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2525 - accuracy: 0.9650 - val_loss: 1.0311 - val_accuracy: 0.7726\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2332 - accuracy: 0.9736 - val_loss: 0.8884 - val_accuracy: 0.7996\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2358 - accuracy: 0.9714 - val_loss: 0.8763 - val_accuracy: 0.7985\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2262 - accuracy: 0.9760 - val_loss: 0.9459 - val_accuracy: 0.7996\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2260 - accuracy: 0.9758 - val_loss: 1.0884 - val_accuracy: 0.7963\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2365 - accuracy: 0.9709 - val_loss: 0.8969 - val_accuracy: 0.8147\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2206 - accuracy: 0.9790 - val_loss: 0.9641 - val_accuracy: 0.7942\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2164 - accuracy: 0.9809 - val_loss: 0.9183 - val_accuracy: 0.8006\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2176 - accuracy: 0.9766 - val_loss: 0.9410 - val_accuracy: 0.7974\n","Epoch 90/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2220 - accuracy: 0.9739 - val_loss: 0.9170 - val_accuracy: 0.8028\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2197 - accuracy: 0.9774 - val_loss: 0.9281 - val_accuracy: 0.8017\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2323 - accuracy: 0.9696 - val_loss: 0.9688 - val_accuracy: 0.7963\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2304 - accuracy: 0.9768 - val_loss: 1.0944 - val_accuracy: 0.7726\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2473 - accuracy: 0.9688 - val_loss: 0.9205 - val_accuracy: 0.7953\n","Epoch 95/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2364 - accuracy: 0.9669 - val_loss: 1.0144 - val_accuracy: 0.7845\n","Epoch 96/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2220 - accuracy: 0.9758 - val_loss: 1.0165 - val_accuracy: 0.7791\n","Epoch 97/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2190 - accuracy: 0.9749 - val_loss: 0.9331 - val_accuracy: 0.8082\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2180 - accuracy: 0.9793 - val_loss: 0.9878 - val_accuracy: 0.7823\n","Epoch 99/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2123 - accuracy: 0.9809 - val_loss: 0.9524 - val_accuracy: 0.7974\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2145 - accuracy: 0.9763 - val_loss: 0.9845 - val_accuracy: 0.7974\n","{'loss': [0.36044660210609436, 0.345379501581192, 0.32478970289230347, 0.3248293101787567, 0.31360384821891785, 0.321076899766922, 0.3216705620288849, 0.32595953345298767, 0.30594900250434875, 0.30167004466056824, 0.3070679008960724, 0.2921713888645172, 0.29088401794433594, 0.2947269380092621, 0.2983439862728119, 0.30441245436668396, 0.29205945134162903, 0.2854378819465637, 0.28538838028907776, 0.287588506937027, 0.27240297198295593, 0.29071933031082153, 0.28150609135627747, 0.2784620523452759, 0.2733354866504669, 0.2852989435195923, 0.2824125289916992, 0.2956855297088623, 0.278009831905365, 0.2666328251361847, 0.26357969641685486, 0.2809881269931793, 0.27134934067726135, 0.28407448530197144, 0.2726462185382843, 0.26663443446159363, 0.2677608132362366, 0.27459025382995605, 0.2607681453227997, 0.2799367308616638, 0.2583356201648712, 0.2610124349594116, 0.25693491101264954, 0.254421591758728, 0.2635193467140198, 0.2619655728340149, 0.2598755657672882, 0.2693198025226593, 0.25833556056022644, 0.24613796174526215, 0.25166869163513184, 0.24606186151504517, 0.2502186596393585, 0.2483370453119278, 0.2502487301826477, 0.25583377480506897, 0.24864926934242249, 0.24698346853256226, 0.24491944909095764, 0.238165482878685, 0.25668346881866455, 0.24644654989242554, 0.25415411591529846, 0.2332003265619278, 0.2340898960828781, 0.2622528076171875, 0.2539710998535156, 0.23865029215812683, 0.258017897605896, 0.26389697194099426, 0.24751082062721252, 0.24066190421581268, 0.23088690638542175, 0.23995161056518555, 0.23210395872592926, 0.22681154310703278, 0.22798311710357666, 0.2268429398536682, 0.2290186733007431, 0.23852279782295227, 0.25253793597221375, 0.2331528216600418, 0.23583316802978516, 0.22620514035224915, 0.22599460184574127, 0.23647162318229675, 0.22062718868255615, 0.2164144366979599, 0.2176082879304886, 0.2219793051481247, 0.2196989357471466, 0.2322818785905838, 0.230415940284729, 0.24729587137699127, 0.23640771210193634, 0.22195573151111603, 0.21899913251399994, 0.21798595786094666, 0.21226005256175995, 0.2145286649465561], 'accuracy': [0.928071141242981, 0.9353448152542114, 0.9339978694915771, 0.9377694129943848, 0.9447737336158752, 0.9366918206214905, 0.9337284564971924, 0.9385775923728943, 0.9442349076271057, 0.943696141242981, 0.943965494632721, 0.9507004022598267, 0.9542025923728943, 0.9507004022598267, 0.9461206793785095, 0.9401939511299133, 0.9498922228813171, 0.9550107717514038, 0.954741358757019, 0.9550107717514038, 0.9590517282485962, 0.9445043206214905, 0.9552801847457886, 0.9558189511299133, 0.9558189511299133, 0.954472005367279, 0.9512392282485962, 0.9471982717514038, 0.9560883641242981, 0.9633620977401733, 0.9620150923728943, 0.954741358757019, 0.9609375, 0.9501616358757019, 0.9598599076271057, 0.9644396305084229, 0.9620150923728943, 0.9552801847457886, 0.9628232717514038, 0.9587823152542114, 0.9639008641242981, 0.9628232717514038, 0.9657866358757019, 0.962284505367279, 0.9617456793785095, 0.9587823152542114, 0.9603987336158752, 0.9552801847457886, 0.9649784564971924, 0.9660560488700867, 0.9649784564971924, 0.9706357717514038, 0.967133641242981, 0.967402994632721, 0.9657866358757019, 0.9620150923728943, 0.9676724076271057, 0.9676724076271057, 0.9714439511299133, 0.9719827771186829, 0.9636314511299133, 0.9639008641242981, 0.967133641242981, 0.9727909564971924, 0.9719827771186829, 0.9587823152542114, 0.9617456793785095, 0.9719827771186829, 0.962553858757019, 0.9582435488700867, 0.9649784564971924, 0.9690194129943848, 0.9730603694915771, 0.9722521305084229, 0.9709051847457886, 0.974946141242981, 0.9765625, 0.9741379022598267, 0.9719827771186829, 0.9711745977401733, 0.9649784564971924, 0.9735991358757019, 0.9714439511299133, 0.9760237336158752, 0.9757543206214905, 0.9709051847457886, 0.9789870977401733, 0.9808728694915771, 0.9765625, 0.9738685488700867, 0.9773706793785095, 0.9695581793785095, 0.9768319129943848, 0.96875, 0.9668642282485962, 0.9757543206214905, 0.974946141242981, 0.9792564511299133, 0.9808728694915771, 0.9762930870056152], 'val_loss': [1.765133261680603, 1.7870928049087524, 1.806152105331421, 1.768726110458374, 1.8046104907989502, 1.7813054323196411, 1.8219736814498901, 1.8095405101776123, 1.8235526084899902, 1.7813547849655151, 1.7893974781036377, 1.7413694858551025, 1.8020626306533813, 1.7849708795547485, 1.728968858718872, 1.6107854843139648, 1.5339652299880981, 1.495840311050415, 1.2510838508605957, 1.4529142379760742, 1.036651372909546, 0.9799234867095947, 0.8283736705780029, 0.8250625133514404, 0.8153373599052429, 0.6972364783287048, 0.689540684223175, 0.8849518299102783, 0.7426311373710632, 0.7276735901832581, 0.7270361185073853, 0.7396501898765564, 0.7545213103294373, 0.7881603240966797, 0.7525864839553833, 0.7673333883285522, 0.7874637246131897, 0.7840548753738403, 0.9017068147659302, 0.7779421210289001, 0.7747327089309692, 0.8110025525093079, 0.8429484367370605, 0.8083938360214233, 0.854049563407898, 0.8138420581817627, 0.9080608487129211, 0.9047885537147522, 0.8422566652297974, 0.8439304828643799, 0.8726430535316467, 0.879126787185669, 0.8458642363548279, 0.9183377027511597, 0.9023216366767883, 0.8664074540138245, 0.9002113938331604, 0.8994952440261841, 0.8836466670036316, 0.8525659441947937, 0.864949643611908, 0.9918031096458435, 0.8463380336761475, 0.8554537296295166, 0.8749975562095642, 0.8628197908401489, 0.858690619468689, 0.8483899235725403, 0.9520906805992126, 1.0273505449295044, 0.9950450658798218, 0.8782183527946472, 0.8613624572753906, 0.8933425545692444, 0.8708539009094238, 0.888983964920044, 0.8891088962554932, 0.8625248074531555, 0.8848162889480591, 0.9967455267906189, 1.0310651063919067, 0.8884342908859253, 0.8763408064842224, 0.9458857178688049, 1.088376522064209, 0.8969261050224304, 0.9640629887580872, 0.9183054566383362, 0.9410368800163269, 0.9170231223106384, 0.9281420111656189, 0.968817412853241, 1.0944194793701172, 0.9204673171043396, 1.0143821239471436, 1.016456961631775, 0.9331055283546448, 0.9877794981002808, 0.9523897767066956, 0.9845371842384338], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48706895112991333, 0.4892241358757019, 0.4913793206214905, 0.49461206793785095, 0.5010775923728943, 0.5021551847457886, 0.5075430870056152, 0.5107758641242981, 0.5355603694915771, 0.5495689511299133, 0.5678879022598267, 0.6120689511299133, 0.5905172228813171, 0.6778017282485962, 0.7036637663841248, 0.7467672228813171, 0.7510775923728943, 0.774784505367279, 0.8200430870056152, 0.8178879022598267, 0.7629310488700867, 0.8232758641242981, 0.8221982717514038, 0.8254310488700867, 0.8168103694915771, 0.8168103694915771, 0.8114224076271057, 0.8254310488700867, 0.8211206793785095, 0.818965494632721, 0.8243534564971924, 0.8178879022598267, 0.818965494632721, 0.8114224076271057, 0.806034505367279, 0.806034505367279, 0.8071120977401733, 0.8017241358757019, 0.8114224076271057, 0.795258641242981, 0.7823275923728943, 0.795258641242981, 0.8017241358757019, 0.8157327771186829, 0.7995689511299133, 0.8125, 0.798491358757019, 0.787715494632721, 0.7974137663841248, 0.787715494632721, 0.806034505367279, 0.798491358757019, 0.798491358757019, 0.798491358757019, 0.795258641242981, 0.8211206793785095, 0.8178879022598267, 0.8049569129943848, 0.8135775923728943, 0.8017241358757019, 0.8125, 0.7790948152542114, 0.78125, 0.8038793206214905, 0.8114224076271057, 0.8092672228813171, 0.8081896305084229, 0.8135775923728943, 0.8103448152542114, 0.8028017282485962, 0.8071120977401733, 0.8081896305084229, 0.7844827771186829, 0.7726293206214905, 0.7995689511299133, 0.798491358757019, 0.7995689511299133, 0.7963362336158752, 0.8146551847457886, 0.7941810488700867, 0.8006465435028076, 0.7974137663841248, 0.8028017282485962, 0.8017241358757019, 0.7963362336158752, 0.7726293206214905, 0.795258641242981, 0.7844827771186829, 0.7790948152542114, 0.8081896305084229, 0.7823275923728943, 0.7974137663841248, 0.7974137663841248]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.3508 - accuracy: 0.9261"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 9s 58ms/step - loss: 0.3485 - accuracy: 0.9273 - val_loss: 1.7290 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3395 - accuracy: 0.9281 - val_loss: 1.7398 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3219 - accuracy: 0.9372 - val_loss: 1.7405 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3169 - accuracy: 0.9443 - val_loss: 1.7739 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3100 - accuracy: 0.9426 - val_loss: 1.7919 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3103 - accuracy: 0.9431 - val_loss: 1.7715 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3016 - accuracy: 0.9479 - val_loss: 1.7690 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3020 - accuracy: 0.9462 - val_loss: 1.7942 - val_accuracy: 0.4955\n","Epoch 9/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3134 - accuracy: 0.9417 - val_loss: 1.7850 - val_accuracy: 0.4966\n","Epoch 10/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3219 - accuracy: 0.9392 - val_loss: 1.7385 - val_accuracy: 0.5000\n","Epoch 11/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2977 - accuracy: 0.9474 - val_loss: 1.7766 - val_accuracy: 0.4989\n","Epoch 12/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2889 - accuracy: 0.9553 - val_loss: 1.7605 - val_accuracy: 0.5011\n","Epoch 13/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2967 - accuracy: 0.9468 - val_loss: 1.7635 - val_accuracy: 0.5023\n","Epoch 14/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2940 - accuracy: 0.9502 - val_loss: 1.6881 - val_accuracy: 0.5147\n","Epoch 15/100\n","28/28 [==============================] - 2s 68ms/step - loss: 0.2876 - accuracy: 0.9522 - val_loss: 1.6490 - val_accuracy: 0.5238\n","Epoch 16/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2833 - accuracy: 0.9533 - val_loss: 1.6656 - val_accuracy: 0.5317\n","Epoch 17/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.2803 - accuracy: 0.9590 - val_loss: 1.6143 - val_accuracy: 0.5419\n","Epoch 18/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.2860 - accuracy: 0.9508 - val_loss: 1.4036 - val_accuracy: 0.5792\n","Epoch 19/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.2819 - accuracy: 0.9570 - val_loss: 1.3851 - val_accuracy: 0.5905\n","Epoch 20/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.2882 - accuracy: 0.9533 - val_loss: 1.3605 - val_accuracy: 0.5995\n","Epoch 21/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.2738 - accuracy: 0.9564 - val_loss: 1.1006 - val_accuracy: 0.6482\n","Epoch 22/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2814 - accuracy: 0.9539 - val_loss: 1.0587 - val_accuracy: 0.6663\n","Epoch 23/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2810 - accuracy: 0.9530 - val_loss: 1.0597 - val_accuracy: 0.6833\n","Epoch 24/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.2712 - accuracy: 0.9564 - val_loss: 0.7713 - val_accuracy: 0.7670\n","Epoch 25/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2728 - accuracy: 0.9610 - val_loss: 0.8959 - val_accuracy: 0.7285\n","Epoch 26/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2809 - accuracy: 0.9539 - val_loss: 0.7964 - val_accuracy: 0.7466\n","Epoch 27/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.2746 - accuracy: 0.9595 - val_loss: 0.7748 - val_accuracy: 0.7771\n","Epoch 28/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2736 - accuracy: 0.9561 - val_loss: 0.7231 - val_accuracy: 0.7952\n","Epoch 29/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2701 - accuracy: 0.9595 - val_loss: 0.7025 - val_accuracy: 0.8020\n","Epoch 30/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2595 - accuracy: 0.9646 - val_loss: 0.6815 - val_accuracy: 0.8235\n","Epoch 31/100\n","28/28 [==============================] - 1s 17ms/step - loss: 0.2598 - accuracy: 0.9655 - val_loss: 0.7032 - val_accuracy: 0.8190\n","Epoch 32/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2634 - accuracy: 0.9610 - val_loss: 0.7154 - val_accuracy: 0.8258\n","Epoch 33/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2637 - accuracy: 0.9604 - val_loss: 0.7097 - val_accuracy: 0.8292\n","Epoch 34/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2608 - accuracy: 0.9624 - val_loss: 0.6931 - val_accuracy: 0.8360\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2564 - accuracy: 0.9660 - val_loss: 0.7146 - val_accuracy: 0.8281\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2561 - accuracy: 0.9658 - val_loss: 0.6951 - val_accuracy: 0.8190\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2551 - accuracy: 0.9669 - val_loss: 0.7362 - val_accuracy: 0.8201\n","Epoch 38/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2563 - accuracy: 0.9663 - val_loss: 0.7779 - val_accuracy: 0.8054\n","Epoch 39/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2523 - accuracy: 0.9672 - val_loss: 0.7143 - val_accuracy: 0.8247\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2864 - accuracy: 0.9536 - val_loss: 0.7584 - val_accuracy: 0.8111\n","Epoch 41/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2619 - accuracy: 0.9643 - val_loss: 0.7274 - val_accuracy: 0.8247\n","Epoch 42/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2675 - accuracy: 0.9578 - val_loss: 0.7681 - val_accuracy: 0.8066\n","Epoch 43/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2522 - accuracy: 0.9669 - val_loss: 0.7682 - val_accuracy: 0.8032\n","Epoch 44/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2491 - accuracy: 0.9643 - val_loss: 0.7332 - val_accuracy: 0.8235\n","Epoch 45/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2613 - accuracy: 0.9624 - val_loss: 0.7830 - val_accuracy: 0.8088\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2593 - accuracy: 0.9604 - val_loss: 0.7507 - val_accuracy: 0.8224\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2619 - accuracy: 0.9601 - val_loss: 0.7685 - val_accuracy: 0.8145\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2435 - accuracy: 0.9726 - val_loss: 0.8017 - val_accuracy: 0.7975\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2447 - accuracy: 0.9714 - val_loss: 0.7902 - val_accuracy: 0.8077\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2371 - accuracy: 0.9720 - val_loss: 0.7629 - val_accuracy: 0.8235\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2441 - accuracy: 0.9666 - val_loss: 0.7955 - val_accuracy: 0.8032\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2584 - accuracy: 0.9672 - val_loss: 0.7826 - val_accuracy: 0.8145\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2779 - accuracy: 0.9564 - val_loss: 0.8007 - val_accuracy: 0.7919\n","Epoch 54/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2516 - accuracy: 0.9677 - val_loss: 0.7630 - val_accuracy: 0.8258\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2439 - accuracy: 0.9683 - val_loss: 0.7632 - val_accuracy: 0.8133\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2499 - accuracy: 0.9643 - val_loss: 0.7721 - val_accuracy: 0.8201\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2432 - accuracy: 0.9686 - val_loss: 0.7536 - val_accuracy: 0.8213\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2469 - accuracy: 0.9683 - val_loss: 0.7637 - val_accuracy: 0.8201\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2369 - accuracy: 0.9726 - val_loss: 0.8162 - val_accuracy: 0.8303\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2486 - accuracy: 0.9689 - val_loss: 0.7767 - val_accuracy: 0.8156\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2416 - accuracy: 0.9709 - val_loss: 0.8227 - val_accuracy: 0.7952\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2414 - accuracy: 0.9660 - val_loss: 0.8275 - val_accuracy: 0.7941\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2393 - accuracy: 0.9694 - val_loss: 0.8600 - val_accuracy: 0.7885\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2436 - accuracy: 0.9711 - val_loss: 0.9117 - val_accuracy: 0.7692\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2408 - accuracy: 0.9711 - val_loss: 0.7892 - val_accuracy: 0.8054\n","Epoch 66/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2329 - accuracy: 0.9734 - val_loss: 0.8132 - val_accuracy: 0.8133\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2267 - accuracy: 0.9737 - val_loss: 0.7978 - val_accuracy: 0.8156\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2281 - accuracy: 0.9745 - val_loss: 0.7964 - val_accuracy: 0.8269\n","Epoch 69/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2280 - accuracy: 0.9759 - val_loss: 0.8071 - val_accuracy: 0.8100\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2365 - accuracy: 0.9740 - val_loss: 0.8248 - val_accuracy: 0.8009\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2325 - accuracy: 0.9680 - val_loss: 0.9016 - val_accuracy: 0.7771\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2262 - accuracy: 0.9762 - val_loss: 0.7934 - val_accuracy: 0.8133\n","Epoch 73/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2360 - accuracy: 0.9706 - val_loss: 0.8180 - val_accuracy: 0.8020\n","Epoch 74/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2223 - accuracy: 0.9785 - val_loss: 0.8049 - val_accuracy: 0.8179\n","Epoch 75/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2248 - accuracy: 0.9754 - val_loss: 0.9026 - val_accuracy: 0.7749\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2527 - accuracy: 0.9632 - val_loss: 0.8654 - val_accuracy: 0.7862\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2404 - accuracy: 0.9666 - val_loss: 0.8785 - val_accuracy: 0.7986\n","Epoch 78/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2378 - accuracy: 0.9734 - val_loss: 0.9094 - val_accuracy: 0.7839\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2297 - accuracy: 0.9743 - val_loss: 0.8133 - val_accuracy: 0.8247\n","Epoch 80/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2254 - accuracy: 0.9759 - val_loss: 0.8490 - val_accuracy: 0.8077\n","Epoch 81/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2394 - accuracy: 0.9643 - val_loss: 0.8311 - val_accuracy: 0.8066\n","Epoch 82/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2198 - accuracy: 0.9768 - val_loss: 0.8152 - val_accuracy: 0.8213\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2175 - accuracy: 0.9796 - val_loss: 0.8062 - val_accuracy: 0.8269\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2183 - accuracy: 0.9788 - val_loss: 0.8197 - val_accuracy: 0.8247\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2173 - accuracy: 0.9765 - val_loss: 0.8315 - val_accuracy: 0.8088\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2191 - accuracy: 0.9785 - val_loss: 0.9784 - val_accuracy: 0.7704\n","Epoch 87/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2177 - accuracy: 0.9779 - val_loss: 0.8596 - val_accuracy: 0.8043\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2257 - accuracy: 0.9731 - val_loss: 0.8607 - val_accuracy: 0.8100\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2253 - accuracy: 0.9731 - val_loss: 0.8209 - val_accuracy: 0.8122\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2168 - accuracy: 0.9802 - val_loss: 0.8501 - val_accuracy: 0.8133\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2179 - accuracy: 0.9765 - val_loss: 0.8771 - val_accuracy: 0.8009\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2128 - accuracy: 0.9822 - val_loss: 0.8381 - val_accuracy: 0.8224\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2096 - accuracy: 0.9819 - val_loss: 0.9546 - val_accuracy: 0.7805\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2415 - accuracy: 0.9740 - val_loss: 0.9928 - val_accuracy: 0.7817\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2230 - accuracy: 0.9765 - val_loss: 0.8672 - val_accuracy: 0.8066\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2402 - accuracy: 0.9686 - val_loss: 0.9946 - val_accuracy: 0.7749\n","Epoch 97/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2373 - accuracy: 0.9731 - val_loss: 0.8787 - val_accuracy: 0.8088\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2337 - accuracy: 0.9745 - val_loss: 0.9356 - val_accuracy: 0.8043\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2215 - accuracy: 0.9745 - val_loss: 0.8810 - val_accuracy: 0.8100\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2104 - accuracy: 0.9813 - val_loss: 0.8931 - val_accuracy: 0.7952\n","{'loss': [0.3484579622745514, 0.3394814729690552, 0.3219060003757477, 0.31686273217201233, 0.3100392818450928, 0.31032758951187134, 0.30158233642578125, 0.3020229935646057, 0.3133765161037445, 0.3219406306743622, 0.29774126410484314, 0.28892233967781067, 0.29673081636428833, 0.29397961497306824, 0.2876022756099701, 0.28326404094696045, 0.28028780221939087, 0.28595489263534546, 0.2818816602230072, 0.28818297386169434, 0.2738029658794403, 0.2814018726348877, 0.281037300825119, 0.2711732089519501, 0.27276238799095154, 0.2808879017829895, 0.27460023760795593, 0.2736077308654785, 0.2700660526752472, 0.2595086097717285, 0.2597518265247345, 0.2634086608886719, 0.26373445987701416, 0.2608238160610199, 0.2564103603363037, 0.25610432028770447, 0.25505155324935913, 0.2563236951828003, 0.2523159980773926, 0.28644296526908875, 0.26187562942504883, 0.26748621463775635, 0.25224292278289795, 0.2491283416748047, 0.2612546384334564, 0.2593271732330322, 0.2619074285030365, 0.24349331855773926, 0.2446523904800415, 0.2370995730161667, 0.24406827986240387, 0.25842171907424927, 0.27787795662879944, 0.25163447856903076, 0.24389541149139404, 0.24987566471099854, 0.2432311475276947, 0.2468568980693817, 0.23691058158874512, 0.24864108860492706, 0.24155281484127045, 0.24142956733703613, 0.2392875999212265, 0.2436380833387375, 0.24083781242370605, 0.2328677624464035, 0.22674569487571716, 0.2281007617712021, 0.22802236676216125, 0.23653163015842438, 0.23250041902065277, 0.2261880785226822, 0.23604066669940948, 0.22230656445026398, 0.22480647265911102, 0.2526685297489166, 0.24038197100162506, 0.2377951741218567, 0.22971567511558533, 0.2253996580839157, 0.23942174017429352, 0.2197774350643158, 0.21753594279289246, 0.21831080317497253, 0.21728508174419403, 0.21906347572803497, 0.2177278995513916, 0.2256745845079422, 0.22525213658809662, 0.21682173013687134, 0.21793100237846375, 0.21276497840881348, 0.20959512889385223, 0.2414678931236267, 0.22303186357021332, 0.2402157038450241, 0.23727566003799438, 0.23367777466773987, 0.22145052254199982, 0.21043866872787476], 'accuracy': [0.9272778630256653, 0.9281267523765564, 0.9371816515922546, 0.9442558288574219, 0.9425579905509949, 0.9431239366531372, 0.9479343295097351, 0.9462365508079529, 0.9417091012001038, 0.9391624331474304, 0.9473684430122375, 0.9552914500236511, 0.9468024969100952, 0.9501980543136597, 0.9521788358688354, 0.9533106684684753, 0.9589700102806091, 0.950764000415802, 0.9569892287254333, 0.9533106684684753, 0.9564233422279358, 0.9538766145706177, 0.9530277252197266, 0.9564233422279358, 0.9609507918357849, 0.9538766145706177, 0.9595359563827515, 0.9561403393745422, 0.9595359563827515, 0.9646292924880981, 0.965478241443634, 0.9609507918357849, 0.9603848457336426, 0.9623655676841736, 0.9660441279411316, 0.9657611846923828, 0.9668930172920227, 0.9663271307945251, 0.9671760201454163, 0.9535936713218689, 0.9643463492393494, 0.9578381180763245, 0.9668930172920227, 0.9643463492393494, 0.9623655676841736, 0.9603848457336426, 0.960101842880249, 0.9725523591041565, 0.9714204668998718, 0.9719864130020142, 0.9666100740432739, 0.9671760201454163, 0.9564233422279358, 0.9677419066429138, 0.9683078527450562, 0.9643463492393494, 0.9685908555984497, 0.9683078527450562, 0.9725523591041565, 0.9688737988471985, 0.9708545804023743, 0.9660441279411316, 0.9694397449493408, 0.971137523651123, 0.971137523651123, 0.9734012484550476, 0.9736841917037964, 0.9745330810546875, 0.975947916507721, 0.9739671945571899, 0.9680249094963074, 0.9762309193611145, 0.9705715775489807, 0.9784946441650391, 0.9753820300102234, 0.9632145166397095, 0.9666100740432739, 0.9734012484550476, 0.9742501378059387, 0.975947916507721, 0.9643463492393494, 0.9767968058586121, 0.979626476764679, 0.9787775874137878, 0.9765138626098633, 0.9784946441650391, 0.9779286980628967, 0.9731183052062988, 0.9731183052062988, 0.9801924228668213, 0.9765138626098633, 0.9821732044219971, 0.9818902015686035, 0.9739671945571899, 0.9765138626098633, 0.9685908555984497, 0.9731183052062988, 0.9745330810546875, 0.9745330810546875, 0.9813242554664612], 'val_loss': [1.728959560394287, 1.7397922277450562, 1.740507960319519, 1.7739311456680298, 1.7919095754623413, 1.7714680433273315, 1.7689725160598755, 1.7942078113555908, 1.784985899925232, 1.7385035753250122, 1.7766188383102417, 1.7605317831039429, 1.7635093927383423, 1.688084363937378, 1.648971438407898, 1.665584683418274, 1.6142578125, 1.4036325216293335, 1.385119915008545, 1.3604710102081299, 1.100577473640442, 1.0586565732955933, 1.0597383975982666, 0.7712645530700684, 0.895878791809082, 0.796359121799469, 0.7748451232910156, 0.7231083512306213, 0.7025187015533447, 0.6814510226249695, 0.7032399773597717, 0.7153931856155396, 0.7097151279449463, 0.6931139826774597, 0.7145770788192749, 0.695088803768158, 0.736159086227417, 0.7778909206390381, 0.714320719242096, 0.7583974599838257, 0.7274340391159058, 0.7680726051330566, 0.7682052254676819, 0.7332471609115601, 0.7829951643943787, 0.7507230043411255, 0.7685325741767883, 0.8017158508300781, 0.7902017831802368, 0.7628827095031738, 0.795512318611145, 0.7826371788978577, 0.800679624080658, 0.7629740238189697, 0.7631543278694153, 0.7720656991004944, 0.753626823425293, 0.7637491226196289, 0.8161603212356567, 0.7766796946525574, 0.8226649761199951, 0.8274521231651306, 0.8599884510040283, 0.9116666913032532, 0.7891862988471985, 0.8131994009017944, 0.7978447079658508, 0.7964184880256653, 0.8071074485778809, 0.8248456120491028, 0.9016314148902893, 0.793406069278717, 0.8180447220802307, 0.8048944473266602, 0.9026117920875549, 0.8654144406318665, 0.8785104155540466, 0.9094067811965942, 0.8132869005203247, 0.8489736318588257, 0.8310830593109131, 0.8152017593383789, 0.806170642375946, 0.8196566700935364, 0.8314778804779053, 0.9783753752708435, 0.8595826029777527, 0.8607099652290344, 0.8209081292152405, 0.8501045107841492, 0.8770818114280701, 0.8381032347679138, 0.9545788168907166, 0.9928423166275024, 0.867179811000824, 0.9946181774139404, 0.8786545991897583, 0.9356481432914734, 0.8809640407562256, 0.8930875062942505], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.5, 0.49886876344680786, 0.5011312365531921, 0.5022624731063843, 0.5147058963775635, 0.523755669593811, 0.5316742062568665, 0.5418552160263062, 0.5791855454444885, 0.5904977321624756, 0.5995475053787231, 0.6481900215148926, 0.6662895679473877, 0.6832579374313354, 0.766968309879303, 0.7285068035125732, 0.7466063499450684, 0.7771493196487427, 0.7952488660812378, 0.8020362257957458, 0.8235294222831726, 0.8190045356750488, 0.8257918357849121, 0.8291855454444885, 0.8359728455543518, 0.8280543088912964, 0.8190045356750488, 0.820135772228241, 0.8054298758506775, 0.8246606588363647, 0.8110859990119934, 0.8246606588363647, 0.8065611124038696, 0.8031674027442932, 0.8235294222831726, 0.8088235259056091, 0.8223981857299805, 0.814479649066925, 0.7975113391876221, 0.807692289352417, 0.8235294222831726, 0.8031674027442932, 0.814479649066925, 0.7918552160263062, 0.8257918357849121, 0.8133484125137329, 0.820135772228241, 0.8212669491767883, 0.820135772228241, 0.8303167223930359, 0.8156108856201172, 0.7952488660812378, 0.7941176295280457, 0.7884615659713745, 0.7692307829856873, 0.8054298758506775, 0.8133484125137329, 0.8156108856201172, 0.8269230723381042, 0.8099547624588013, 0.8009049892425537, 0.7771493196487427, 0.8133484125137329, 0.8020362257957458, 0.8178732991218567, 0.7748869061470032, 0.7861990928649902, 0.7986425161361694, 0.7839366793632507, 0.8246606588363647, 0.807692289352417, 0.8065611124038696, 0.8212669491767883, 0.8269230723381042, 0.8246606588363647, 0.8088235259056091, 0.7703620195388794, 0.8042986392974854, 0.8099547624588013, 0.8122171759605408, 0.8133484125137329, 0.8009049892425537, 0.8223981857299805, 0.7805429697036743, 0.7816742062568665, 0.8065611124038696, 0.7748869061470032, 0.8088235259056091, 0.8042986392974854, 0.8099547624588013, 0.7952488660812378]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.3738 - accuracy: 0.9186"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 8s 56ms/step - loss: 0.3713 - accuracy: 0.9189 - val_loss: 1.7380 - val_accuracy: 0.4866\n","Epoch 2/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3635 - accuracy: 0.9196 - val_loss: 1.7390 - val_accuracy: 0.4876\n","Epoch 3/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3536 - accuracy: 0.9235 - val_loss: 1.7483 - val_accuracy: 0.4876\n","Epoch 4/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3234 - accuracy: 0.9344 - val_loss: 1.7434 - val_accuracy: 0.4876\n","Epoch 5/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3267 - accuracy: 0.9354 - val_loss: 1.7625 - val_accuracy: 0.4876\n","Epoch 6/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3322 - accuracy: 0.9295 - val_loss: 1.8208 - val_accuracy: 0.4876\n","Epoch 7/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3282 - accuracy: 0.9328 - val_loss: 1.7632 - val_accuracy: 0.4897\n","Epoch 8/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3260 - accuracy: 0.9349 - val_loss: 1.8000 - val_accuracy: 0.4897\n","Epoch 9/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3160 - accuracy: 0.9390 - val_loss: 1.7836 - val_accuracy: 0.4897\n","Epoch 10/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3124 - accuracy: 0.9357 - val_loss: 1.7811 - val_accuracy: 0.4917\n","Epoch 11/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.3063 - accuracy: 0.9426 - val_loss: 1.7563 - val_accuracy: 0.5031\n","Epoch 12/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.3290 - accuracy: 0.9331 - val_loss: 1.7685 - val_accuracy: 0.5041\n","Epoch 13/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.3121 - accuracy: 0.9395 - val_loss: 1.6828 - val_accuracy: 0.5103\n","Epoch 14/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3028 - accuracy: 0.9424 - val_loss: 1.7017 - val_accuracy: 0.5176\n","Epoch 15/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2940 - accuracy: 0.9488 - val_loss: 1.6861 - val_accuracy: 0.5289\n","Epoch 16/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3018 - accuracy: 0.9429 - val_loss: 1.5249 - val_accuracy: 0.5527\n","Epoch 17/100\n","31/31 [==============================] - 2s 73ms/step - loss: 0.2944 - accuracy: 0.9494 - val_loss: 1.5679 - val_accuracy: 0.5558\n","Epoch 18/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.2871 - accuracy: 0.9519 - val_loss: 1.2417 - val_accuracy: 0.6085\n","Epoch 19/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2874 - accuracy: 0.9473 - val_loss: 1.1869 - val_accuracy: 0.6260\n","Epoch 20/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2928 - accuracy: 0.9488 - val_loss: 1.2758 - val_accuracy: 0.6260\n","Epoch 21/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3116 - accuracy: 0.9390 - val_loss: 0.9721 - val_accuracy: 0.6921\n","Epoch 22/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2845 - accuracy: 0.9530 - val_loss: 0.9492 - val_accuracy: 0.7004\n","Epoch 23/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2937 - accuracy: 0.9444 - val_loss: 0.8676 - val_accuracy: 0.7469\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2915 - accuracy: 0.9486 - val_loss: 1.0283 - val_accuracy: 0.7066\n","Epoch 25/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3012 - accuracy: 0.9452 - val_loss: 0.8786 - val_accuracy: 0.7521\n","Epoch 26/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3149 - accuracy: 0.9398 - val_loss: 0.9218 - val_accuracy: 0.7531\n","Epoch 27/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.2893 - accuracy: 0.9483 - val_loss: 0.8818 - val_accuracy: 0.7975\n","Epoch 28/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2903 - accuracy: 0.9514 - val_loss: 1.0563 - val_accuracy: 0.7087\n","Epoch 29/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2917 - accuracy: 0.9470 - val_loss: 0.8567 - val_accuracy: 0.7924\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2789 - accuracy: 0.9543 - val_loss: 0.8704 - val_accuracy: 0.7934\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2812 - accuracy: 0.9494 - val_loss: 0.9332 - val_accuracy: 0.7820\n","Epoch 32/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2863 - accuracy: 0.9506 - val_loss: 0.9010 - val_accuracy: 0.7862\n","Epoch 33/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2883 - accuracy: 0.9463 - val_loss: 1.2043 - val_accuracy: 0.7118\n","Epoch 34/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2866 - accuracy: 0.9496 - val_loss: 0.9083 - val_accuracy: 0.7717\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2746 - accuracy: 0.9561 - val_loss: 0.8830 - val_accuracy: 0.7924\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2657 - accuracy: 0.9605 - val_loss: 0.9135 - val_accuracy: 0.7913\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2814 - accuracy: 0.9519 - val_loss: 1.0103 - val_accuracy: 0.7593\n","Epoch 38/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2787 - accuracy: 0.9548 - val_loss: 0.9657 - val_accuracy: 0.7996\n","Epoch 39/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2901 - accuracy: 0.9447 - val_loss: 0.9174 - val_accuracy: 0.7779\n","Epoch 40/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2642 - accuracy: 0.9605 - val_loss: 0.9266 - val_accuracy: 0.7913\n","Epoch 41/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2705 - accuracy: 0.9537 - val_loss: 0.8852 - val_accuracy: 0.7882\n","Epoch 42/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2662 - accuracy: 0.9576 - val_loss: 0.9301 - val_accuracy: 0.7882\n","Epoch 43/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2652 - accuracy: 0.9581 - val_loss: 0.9336 - val_accuracy: 0.7872\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2631 - accuracy: 0.9649 - val_loss: 1.0416 - val_accuracy: 0.7686\n","Epoch 45/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2799 - accuracy: 0.9556 - val_loss: 1.0932 - val_accuracy: 0.7531\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2716 - accuracy: 0.9553 - val_loss: 1.0620 - val_accuracy: 0.7552\n","Epoch 47/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2704 - accuracy: 0.9532 - val_loss: 1.0525 - val_accuracy: 0.7634\n","Epoch 48/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2640 - accuracy: 0.9581 - val_loss: 0.9926 - val_accuracy: 0.7862\n","Epoch 49/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2680 - accuracy: 0.9579 - val_loss: 0.9427 - val_accuracy: 0.7851\n","Epoch 50/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2551 - accuracy: 0.9630 - val_loss: 1.0193 - val_accuracy: 0.7841\n","Epoch 51/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2613 - accuracy: 0.9612 - val_loss: 0.9698 - val_accuracy: 0.7862\n","Epoch 52/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2602 - accuracy: 0.9597 - val_loss: 0.9544 - val_accuracy: 0.7851\n","Epoch 53/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2500 - accuracy: 0.9649 - val_loss: 0.9612 - val_accuracy: 0.7934\n","Epoch 54/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2497 - accuracy: 0.9638 - val_loss: 0.9746 - val_accuracy: 0.7862\n","Epoch 55/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2489 - accuracy: 0.9633 - val_loss: 1.0079 - val_accuracy: 0.7924\n","Epoch 56/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2551 - accuracy: 0.9625 - val_loss: 1.0670 - val_accuracy: 0.7738\n","Epoch 57/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2598 - accuracy: 0.9599 - val_loss: 0.9903 - val_accuracy: 0.7882\n","Epoch 58/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2856 - accuracy: 0.9506 - val_loss: 1.1568 - val_accuracy: 0.7417\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2640 - accuracy: 0.9605 - val_loss: 1.0487 - val_accuracy: 0.7779\n","Epoch 60/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2618 - accuracy: 0.9610 - val_loss: 0.9579 - val_accuracy: 0.7831\n","Epoch 61/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2486 - accuracy: 0.9638 - val_loss: 1.0397 - val_accuracy: 0.7779\n","Epoch 62/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2516 - accuracy: 0.9674 - val_loss: 1.0446 - val_accuracy: 0.7738\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2472 - accuracy: 0.9654 - val_loss: 1.0980 - val_accuracy: 0.7645\n","Epoch 64/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2547 - accuracy: 0.9625 - val_loss: 1.0292 - val_accuracy: 0.7738\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2530 - accuracy: 0.9677 - val_loss: 1.0610 - val_accuracy: 0.7665\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2402 - accuracy: 0.9705 - val_loss: 1.0362 - val_accuracy: 0.7707\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2528 - accuracy: 0.9602 - val_loss: 1.0958 - val_accuracy: 0.7614\n","Epoch 68/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2418 - accuracy: 0.9641 - val_loss: 1.0426 - val_accuracy: 0.7707\n","Epoch 69/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2591 - accuracy: 0.9566 - val_loss: 1.0234 - val_accuracy: 0.7717\n","Epoch 70/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2411 - accuracy: 0.9674 - val_loss: 1.0543 - val_accuracy: 0.7738\n","Epoch 71/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2441 - accuracy: 0.9646 - val_loss: 1.0350 - val_accuracy: 0.7810\n","Epoch 72/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2432 - accuracy: 0.9661 - val_loss: 1.0568 - val_accuracy: 0.7634\n","Epoch 73/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2573 - accuracy: 0.9607 - val_loss: 1.0754 - val_accuracy: 0.7603\n","Epoch 74/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2390 - accuracy: 0.9685 - val_loss: 1.1071 - val_accuracy: 0.7665\n","Epoch 75/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2396 - accuracy: 0.9680 - val_loss: 1.0076 - val_accuracy: 0.7820\n","Epoch 76/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2382 - accuracy: 0.9703 - val_loss: 1.0249 - val_accuracy: 0.7769\n","Epoch 77/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2566 - accuracy: 0.9568 - val_loss: 1.0510 - val_accuracy: 0.7789\n","Epoch 78/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2511 - accuracy: 0.9576 - val_loss: 1.0329 - val_accuracy: 0.7789\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2463 - accuracy: 0.9636 - val_loss: 1.0640 - val_accuracy: 0.7665\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2434 - accuracy: 0.9646 - val_loss: 1.1839 - val_accuracy: 0.7510\n","Epoch 81/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2431 - accuracy: 0.9687 - val_loss: 1.0416 - val_accuracy: 0.7789\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2295 - accuracy: 0.9726 - val_loss: 1.0526 - val_accuracy: 0.7727\n","Epoch 83/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2295 - accuracy: 0.9716 - val_loss: 1.1241 - val_accuracy: 0.7655\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2489 - accuracy: 0.9597 - val_loss: 1.1144 - val_accuracy: 0.7572\n","Epoch 85/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2348 - accuracy: 0.9705 - val_loss: 1.0483 - val_accuracy: 0.7769\n","Epoch 86/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2309 - accuracy: 0.9718 - val_loss: 1.0526 - val_accuracy: 0.7707\n","Epoch 87/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2280 - accuracy: 0.9734 - val_loss: 1.0584 - val_accuracy: 0.7820\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2269 - accuracy: 0.9721 - val_loss: 1.0676 - val_accuracy: 0.7748\n","Epoch 89/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2375 - accuracy: 0.9721 - val_loss: 1.0585 - val_accuracy: 0.7727\n","Epoch 90/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2234 - accuracy: 0.9736 - val_loss: 1.0436 - val_accuracy: 0.7800\n","Epoch 91/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2321 - accuracy: 0.9685 - val_loss: 1.0956 - val_accuracy: 0.7676\n","Epoch 92/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2301 - accuracy: 0.9721 - val_loss: 1.0847 - val_accuracy: 0.7738\n","Epoch 93/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2233 - accuracy: 0.9755 - val_loss: 1.1100 - val_accuracy: 0.7676\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2201 - accuracy: 0.9765 - val_loss: 1.1273 - val_accuracy: 0.7686\n","Epoch 95/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2219 - accuracy: 0.9742 - val_loss: 1.0546 - val_accuracy: 0.7800\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2300 - accuracy: 0.9703 - val_loss: 1.0922 - val_accuracy: 0.7789\n","Epoch 97/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2257 - accuracy: 0.9739 - val_loss: 1.1413 - val_accuracy: 0.7779\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2568 - accuracy: 0.9630 - val_loss: 1.1536 - val_accuracy: 0.7583\n","Epoch 99/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2348 - accuracy: 0.9700 - val_loss: 1.2327 - val_accuracy: 0.7562\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2308 - accuracy: 0.9726 - val_loss: 1.0984 - val_accuracy: 0.7748\n","{'loss': [0.37132591009140015, 0.363490492105484, 0.35357946157455444, 0.3234098553657532, 0.326679527759552, 0.3321771025657654, 0.3282369375228882, 0.32599157094955444, 0.3160099685192108, 0.3123808801174164, 0.3063133955001831, 0.328952431678772, 0.31205910444259644, 0.30276912450790405, 0.29403144121170044, 0.30182838439941406, 0.29441505670547485, 0.28714117407798767, 0.2873935401439667, 0.29275748133659363, 0.31157028675079346, 0.28454479575157166, 0.29368606209754944, 0.2914566695690155, 0.30121928453445435, 0.3149019479751587, 0.28927814960479736, 0.290286660194397, 0.29166433215141296, 0.27892252802848816, 0.28120157122612, 0.286336749792099, 0.28828296065330505, 0.2865913212299347, 0.27460533380508423, 0.26574501395225525, 0.28137585520744324, 0.2786991596221924, 0.2900659739971161, 0.26424339413642883, 0.27052319049835205, 0.2661554217338562, 0.2652495503425598, 0.26305171847343445, 0.27989572286605835, 0.27157798409461975, 0.2704063653945923, 0.2640398144721985, 0.2679866850376129, 0.25514131784439087, 0.26129740476608276, 0.26023241877555847, 0.2500459551811218, 0.24971318244934082, 0.24886281788349152, 0.2551051378250122, 0.2597971260547638, 0.28561052680015564, 0.2639685273170471, 0.2618388831615448, 0.24861302971839905, 0.25158682465553284, 0.24720260500907898, 0.2546755075454712, 0.25298503041267395, 0.24018390476703644, 0.2527755796909332, 0.2417767345905304, 0.25908994674682617, 0.24107800424098969, 0.2440980225801468, 0.24321594834327698, 0.2573312520980835, 0.23896543681621552, 0.23955345153808594, 0.2381596863269806, 0.25664713978767395, 0.2511376440525055, 0.24625839293003082, 0.2433881312608719, 0.2430766224861145, 0.22949980199337006, 0.22952698171138763, 0.2488592267036438, 0.23475557565689087, 0.2309046983718872, 0.22797253727912903, 0.22686004638671875, 0.23745925724506378, 0.22337128221988678, 0.23210960626602173, 0.2301214635372162, 0.2232503592967987, 0.22006142139434814, 0.2218504250049591, 0.22999870777130127, 0.22574901580810547, 0.2568279504776001, 0.23482578992843628, 0.23079703748226166], 'accuracy': [0.91886305809021, 0.9196382164955139, 0.923514187335968, 0.9343669414520264, 0.9354005455970764, 0.9294573664665222, 0.9328165650367737, 0.934883713722229, 0.9390180706977844, 0.9356589317321777, 0.9426356554031372, 0.933074951171875, 0.9395349025726318, 0.9423772692680359, 0.9488372206687927, 0.9428940415382385, 0.9493539929389954, 0.9519379734992981, 0.94728684425354, 0.9488372206687927, 0.9390180706977844, 0.9529715776443481, 0.9444444179534912, 0.9485788345336914, 0.9452196359634399, 0.9397932887077332, 0.9483203887939453, 0.9514212012290955, 0.947028398513794, 0.9542635679244995, 0.9493539929389954, 0.9506459832191467, 0.94625324010849, 0.9496123790740967, 0.9560723304748535, 0.960465133190155, 0.9519379734992981, 0.9547803401947021, 0.9447028636932373, 0.960465133190155, 0.9537467956542969, 0.957622766494751, 0.9581395387649536, 0.9648578763008118, 0.9555555582046509, 0.9552971720695496, 0.9532299637794495, 0.9581395387649536, 0.9578811526298523, 0.9630491137504578, 0.961240291595459, 0.9596899151802063, 0.9648578763008118, 0.9638242721557617, 0.9633074998855591, 0.9625322818756104, 0.9599483013153076, 0.9506459832191467, 0.960465133190155, 0.9609819054603577, 0.9638242721557617, 0.9674418568611145, 0.9653746485710144, 0.9625322818756104, 0.9677002429962158, 0.9705426096916199, 0.9602067470550537, 0.964082658290863, 0.9565891623497009, 0.9674418568611145, 0.9645994901657104, 0.9661498665809631, 0.9607235193252563, 0.9684754610061646, 0.9679586291313171, 0.9702842235565186, 0.9568475484848022, 0.957622766494751, 0.9635658860206604, 0.9645994901657104, 0.9687338471412659, 0.97260981798172, 0.9715762138366699, 0.9596899151802063, 0.9705426096916199, 0.9718345999717712, 0.9733850359916687, 0.9720930457115173, 0.9720930457115173, 0.97364342212677, 0.9684754610061646, 0.9720930457115173, 0.975452184677124, 0.9764857888221741, 0.9741601943969727, 0.9702842235565186, 0.9739018082618713, 0.9630491137504578, 0.9700258374214172, 0.97260981798172], 'val_loss': [1.738046407699585, 1.739011526107788, 1.7482831478118896, 1.743393898010254, 1.7625166177749634, 1.8208341598510742, 1.7631858587265015, 1.7999778985977173, 1.7835651636123657, 1.781113624572754, 1.7562810182571411, 1.7684718370437622, 1.6827874183654785, 1.7017407417297363, 1.68606698513031, 1.5248970985412598, 1.567914366722107, 1.2417120933532715, 1.1868698596954346, 1.2757970094680786, 0.9721271991729736, 0.9492357969284058, 0.8676438331604004, 1.0282559394836426, 0.8785629272460938, 0.9217861294746399, 0.8817575573921204, 1.0563417673110962, 0.8566911816596985, 0.8704321980476379, 0.9332299828529358, 0.9009637832641602, 1.2042622566223145, 0.9083402752876282, 0.8830345273017883, 0.9134730696678162, 1.0102885961532593, 0.9656558632850647, 0.9174448251724243, 0.926612138748169, 0.885196328163147, 0.9300805330276489, 0.9336091876029968, 1.041603684425354, 1.0932303667068481, 1.0619535446166992, 1.0525199174880981, 0.9925714731216431, 0.9426816701889038, 1.0192618370056152, 0.9698380827903748, 0.9544276595115662, 0.9611813426017761, 0.9745535254478455, 1.0079262256622314, 1.0670418739318848, 0.9902945160865784, 1.1567646265029907, 1.048746109008789, 0.9579354524612427, 1.0396580696105957, 1.0446367263793945, 1.0980348587036133, 1.0291801691055298, 1.0610270500183105, 1.0361700057983398, 1.0958353281021118, 1.0426058769226074, 1.0233995914459229, 1.0543427467346191, 1.0350139141082764, 1.0568032264709473, 1.0753847360610962, 1.1071146726608276, 1.0076404809951782, 1.0248794555664062, 1.0509980916976929, 1.032895803451538, 1.0640150308609009, 1.1839215755462646, 1.0416138172149658, 1.0525976419448853, 1.1241273880004883, 1.1143711805343628, 1.0482678413391113, 1.0526403188705444, 1.0583738088607788, 1.0676285028457642, 1.0585073232650757, 1.0435796976089478, 1.0955584049224854, 1.0847301483154297, 1.110029935836792, 1.1272896528244019, 1.054580807685852, 1.092163324356079, 1.1413462162017822, 1.15358567237854, 1.2326661348342896, 1.0983762741088867], 'val_accuracy': [0.48657023906707764, 0.4876033067703247, 0.4876033067703247, 0.4876033067703247, 0.4876033067703247, 0.4876033067703247, 0.48966941237449646, 0.48966941237449646, 0.48966941237449646, 0.4917355477809906, 0.5030992031097412, 0.5041322112083435, 0.5103305578231812, 0.5175619721412659, 0.5289255976676941, 0.5526859760284424, 0.5557851195335388, 0.6084710955619812, 0.6260330677032471, 0.6260330677032471, 0.692148745059967, 0.7004132270812988, 0.7469007968902588, 0.7066115736961365, 0.7520661354064941, 0.7530992031097412, 0.797520637512207, 0.7086777091026306, 0.7923553586006165, 0.7933884263038635, 0.7820248007774353, 0.7861570119857788, 0.711776852607727, 0.7716942429542542, 0.7923553586006165, 0.7913222908973694, 0.7592975497245789, 0.7995867729187012, 0.7778925895690918, 0.7913222908973694, 0.788223147392273, 0.788223147392273, 0.7871900796890259, 0.7685950398445129, 0.7530992031097412, 0.7551652789115906, 0.7634297609329224, 0.7861570119857788, 0.7851239442825317, 0.7840909361839294, 0.7861570119857788, 0.7851239442825317, 0.7933884263038635, 0.7861570119857788, 0.7923553586006165, 0.7737603187561035, 0.788223147392273, 0.7417355179786682, 0.7778925895690918, 0.7830578684806824, 0.7778925895690918, 0.7737603187561035, 0.7644628286361694, 0.7737603187561035, 0.7665289044380188, 0.7706611752510071, 0.7613636255264282, 0.7706611752510071, 0.7716942429542542, 0.7737603187561035, 0.7809917330741882, 0.7634297609329224, 0.7603305578231812, 0.7665289044380188, 0.7820248007774353, 0.7768595218658447, 0.7789255976676941, 0.7789255976676941, 0.7665289044380188, 0.7510330677032471, 0.7789255976676941, 0.7727272510528564, 0.7654958963394165, 0.7572314143180847, 0.7768595218658447, 0.7706611752510071, 0.7820248007774353, 0.7747933864593506, 0.7727272510528564, 0.7799586653709412, 0.7675619721412659, 0.7737603187561035, 0.7675619721412659, 0.7685950398445129, 0.7799586653709412, 0.7789255976676941, 0.7778925895690918, 0.7582644820213318, 0.7561983466148376, 0.7747933864593506]}\n","32/32 [==============================] - 1s 4ms/step\n"]}]},{"cell_type":"code","source":["metrics_df_gru"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"id":"elwZkGLZn45y","executionInfo":{"status":"ok","timestamp":1717431650212,"user_tz":-360,"elapsed":18,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"17419848-aab9-49ea-9e8d-6f3c2340b13b"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision    Recall        F1  Sensitivity  Specificity  \\\n","0        0  0.546064   0.542636  0.586265  0.563607     0.586265     0.505863   \n","1        1  0.611582   0.593381  0.709040  0.646075     0.709040     0.514124   \n","2        2  0.597390   0.607064  0.552209  0.578339     0.552209     0.642570   \n","3        0  0.603015   0.594470  0.648241  0.620192     0.648241     0.557789   \n","4        1  0.670198   0.663058  0.692090  0.677263     0.692090     0.648305   \n","5        2  0.639558   0.634429  0.658635  0.646305     0.658635     0.620482   \n","6        0  0.683417   0.672441  0.715243  0.693182     0.715243     0.651591   \n","7        1  0.723164   0.719444  0.731638  0.725490     0.731638     0.714689   \n","8        2  0.715863   0.727273  0.690763  0.708548     0.690763     0.740964   \n","9        0  0.740369   0.715789  0.797320  0.754358     0.797320     0.683417   \n","10       1  0.744350   0.769470  0.697740  0.731852     0.697740     0.790960   \n","11       2  0.756024   0.773019  0.724900  0.748187     0.724900     0.787149   \n","12       0  0.783920   0.749632  0.852596  0.797806     0.852596     0.715243   \n","13       1  0.797316   0.770914  0.846045  0.806734     0.846045     0.748588   \n","14       2  0.795181   0.820961  0.755020  0.786611     0.755020     0.835341   \n","\n","       Kappa  \n","0   0.092127  \n","1   0.223164  \n","2   0.194779  \n","3   0.206030  \n","4   0.340395  \n","5   0.279116  \n","6   0.366834  \n","7   0.446328  \n","8   0.431727  \n","9   0.480737  \n","10  0.488701  \n","11  0.512048  \n","12  0.567839  \n","13  0.594633  \n","14  0.590361  "],"text/html":["\n","  <div id=\"df-ac63b2d7-7faa-477d-8a50-47d6019c8725\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.546064</td>\n","      <td>0.542636</td>\n","      <td>0.586265</td>\n","      <td>0.563607</td>\n","      <td>0.586265</td>\n","      <td>0.505863</td>\n","      <td>0.092127</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.611582</td>\n","      <td>0.593381</td>\n","      <td>0.709040</td>\n","      <td>0.646075</td>\n","      <td>0.709040</td>\n","      <td>0.514124</td>\n","      <td>0.223164</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.597390</td>\n","      <td>0.607064</td>\n","      <td>0.552209</td>\n","      <td>0.578339</td>\n","      <td>0.552209</td>\n","      <td>0.642570</td>\n","      <td>0.194779</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.603015</td>\n","      <td>0.594470</td>\n","      <td>0.648241</td>\n","      <td>0.620192</td>\n","      <td>0.648241</td>\n","      <td>0.557789</td>\n","      <td>0.206030</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.670198</td>\n","      <td>0.663058</td>\n","      <td>0.692090</td>\n","      <td>0.677263</td>\n","      <td>0.692090</td>\n","      <td>0.648305</td>\n","      <td>0.340395</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.639558</td>\n","      <td>0.634429</td>\n","      <td>0.658635</td>\n","      <td>0.646305</td>\n","      <td>0.658635</td>\n","      <td>0.620482</td>\n","      <td>0.279116</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.683417</td>\n","      <td>0.672441</td>\n","      <td>0.715243</td>\n","      <td>0.693182</td>\n","      <td>0.715243</td>\n","      <td>0.651591</td>\n","      <td>0.366834</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.723164</td>\n","      <td>0.719444</td>\n","      <td>0.731638</td>\n","      <td>0.725490</td>\n","      <td>0.731638</td>\n","      <td>0.714689</td>\n","      <td>0.446328</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.715863</td>\n","      <td>0.727273</td>\n","      <td>0.690763</td>\n","      <td>0.708548</td>\n","      <td>0.690763</td>\n","      <td>0.740964</td>\n","      <td>0.431727</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.740369</td>\n","      <td>0.715789</td>\n","      <td>0.797320</td>\n","      <td>0.754358</td>\n","      <td>0.797320</td>\n","      <td>0.683417</td>\n","      <td>0.480737</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.744350</td>\n","      <td>0.769470</td>\n","      <td>0.697740</td>\n","      <td>0.731852</td>\n","      <td>0.697740</td>\n","      <td>0.790960</td>\n","      <td>0.488701</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.756024</td>\n","      <td>0.773019</td>\n","      <td>0.724900</td>\n","      <td>0.748187</td>\n","      <td>0.724900</td>\n","      <td>0.787149</td>\n","      <td>0.512048</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.783920</td>\n","      <td>0.749632</td>\n","      <td>0.852596</td>\n","      <td>0.797806</td>\n","      <td>0.852596</td>\n","      <td>0.715243</td>\n","      <td>0.567839</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.797316</td>\n","      <td>0.770914</td>\n","      <td>0.846045</td>\n","      <td>0.806734</td>\n","      <td>0.846045</td>\n","      <td>0.748588</td>\n","      <td>0.594633</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.795181</td>\n","      <td>0.820961</td>\n","      <td>0.755020</td>\n","      <td>0.786611</td>\n","      <td>0.755020</td>\n","      <td>0.835341</td>\n","      <td>0.590361</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac63b2d7-7faa-477d-8a50-47d6019c8725')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ac63b2d7-7faa-477d-8a50-47d6019c8725 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ac63b2d7-7faa-477d-8a50-47d6019c8725');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c784bb78-15ed-4d13-9582-91e848501bb0\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c784bb78-15ed-4d13-9582-91e848501bb0')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c784bb78-15ed-4d13-9582-91e848501bb0 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_cdce2a6f-3a87-4064-9aae-a111fa52f14f\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('metrics_df_gru')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_cdce2a6f-3a87-4064-9aae-a111fa52f14f button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('metrics_df_gru');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"metrics_df_gru","summary":"{\n  \"name\": \"metrics_df_gru\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07963748572159135,\n        \"min\": 0.5460636515912898,\n        \"max\": 0.797316384180791,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7403685092127303,\n          0.7560240963855421,\n          0.5460636515912898\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08218441348157515,\n        \"min\": 0.5426356589147286,\n        \"max\": 0.8209606986899564,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7157894736842105,\n          0.7730192719486081,\n          0.5426356589147286\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08311368244540646,\n        \"min\": 0.5522088353413654,\n        \"max\": 0.8525963149078727,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7973199329983249,\n          0.7248995983935743,\n          0.5862646566164154\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.076338540027181,\n        \"min\": 0.5636070853462157,\n        \"max\": 0.8067340067340067,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7543581616481775,\n          0.7481865284974093,\n          0.5636070853462157\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08311368244540646,\n        \"min\": 0.5522088353413654,\n        \"max\": 0.8525963149078727,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7973199329983249,\n          0.7248995983935743,\n          0.5862646566164154\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09935800884229369,\n        \"min\": 0.5058626465661642,\n        \"max\": 0.8353413654618473,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.6834170854271356,\n          0.7871485943775101,\n          0.5058626465661642\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1592749714431827,\n        \"min\": 0.09212730318257956,\n        \"max\": 0.594632768361582,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.4807370184254607,\n          0.5120481927710843,\n          0.09212730318257956\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["metrics_df_gru.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Frequency Domain/GRU/Beta_frequency_gru.csv', index = False)"],"metadata":{"id":"G63Cpe5vn2PS","executionInfo":{"status":"ok","timestamp":1717431650230,"user_tz":-360,"elapsed":29,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":26,"outputs":[]}]}