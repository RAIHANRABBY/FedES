{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":696,"status":"ok","timestamp":1717435499996,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"},"user_tz":-360},"id":"Mbfw8uvdftFM"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sb"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":480,"status":"ok","timestamp":1717435500474,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"},"user_tz":-360},"id":"INiFJfLjgOkx"},"outputs":[],"source":["from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3342,"status":"ok","timestamp":1717435503813,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"},"user_tz":-360},"id":"lYo2Uq77gQSH"},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import ExtraTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score, cross_val_predict"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2848,"status":"ok","timestamp":1717435506657,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"},"user_tz":-360},"id":"g66575_xgVzz"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPool1D, Flatten, Dropout,LSTM"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19309,"status":"ok","timestamp":1717435525955,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"},"user_tz":-360},"id":"MOCNWlamfr3v","outputId":"bcf3e621-b988-48f7-c814-91eba3a821cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1717435551004,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"},"user_tz":-360},"id":"iNy9eOGMf2qO"},"outputs":[],"source":["# Raw_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/only data/raw_data.npz'\n","\n","Theta_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/feature domain/Delta_frequency.npz'\n","\n","\n","\n","# RAW = np.load(Raw_data, allow_pickle=True)  # Allow loading pickled object arrays\n","# X = RAW['X'].astype('float64')\n","# Y = RAW['Y'].astype('float64')\n","# group = RAW['Group'].astype('float64')"]},{"cell_type":"markdown","metadata":{"id":"PzeABzSyHgKg"},"source":["This is a good performing model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PTmHq1-S6XWL"},"outputs":[],"source":["# %%capture\n","# !pip install wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XX0yEFJG6QYM"},"outputs":[],"source":["# import wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54787,"status":"ok","timestamp":1716626562113,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"},"user_tz":-360},"id":"mmlbTHI36aVt","outputId":"fb67369e-14fa-465a-ad7b-08f498bf586f"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["# !wandb login"]},{"cell_type":"markdown","metadata":{"id":"6DhAYwXUSE9z"},"source":["# CNN-LSTM"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6176,"status":"ok","timestamp":1717435532723,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"},"user_tz":-360},"id":"KHQiu_151nP4"},"outputs":[],"source":["%%capture\n","!pip install tensorflow_addons"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1717430559014,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"},"user_tz":-360},"id":"VvjC2xCQNHLP","outputId":"87c5e078-ba18-4d6b-b316-f1d7f28b8d88"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(LSTM(256, return_sequences=True))\n","    model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dense(32, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_callback = ModelCheckpoint(\n","                f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Delta/CNN_LSTM/best_model_{run_name}.h5',\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Delta/CNN_LSTM/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Evaluate client model\n","            y_pred = (client_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1183014,"status":"ok","timestamp":1717431742021,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"},"user_tz":-360},"id":"ZVURUnmYNNNg","outputId":"a7c2b6b7-df4a-4a5b-ae10-34d5e761577e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.4964"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 27s 262ms/step - loss: 0.6931 - accuracy: 0.4943 - val_loss: 0.6931 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 2s 53ms/step - loss: 0.6931 - accuracy: 0.5081 - val_loss: 0.6931 - val_accuracy: 0.5248\n","Epoch 3/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.6931 - accuracy: 0.5051 - val_loss: 0.6931 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 40ms/step - loss: 0.6931 - accuracy: 0.5038 - val_loss: 0.6931 - val_accuracy: 0.5636\n","Epoch 5/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6930 - accuracy: 0.5019 - val_loss: 0.6931 - val_accuracy: 0.5248\n","Epoch 6/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6930 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.6929 - accuracy: 0.5073 - val_loss: 0.6931 - val_accuracy: 0.5312\n","Epoch 8/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6929 - accuracy: 0.5100 - val_loss: 0.6931 - val_accuracy: 0.5550\n","Epoch 9/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6928 - accuracy: 0.5094 - val_loss: 0.6930 - val_accuracy: 0.5506\n","Epoch 10/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6927 - accuracy: 0.5113 - val_loss: 0.6930 - val_accuracy: 0.5463\n","Epoch 11/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6925 - accuracy: 0.5094 - val_loss: 0.6929 - val_accuracy: 0.5485\n","Epoch 12/100\n","29/29 [==============================] - 1s 36ms/step - loss: 0.6924 - accuracy: 0.5035 - val_loss: 0.6928 - val_accuracy: 0.5571\n","Epoch 13/100\n","29/29 [==============================] - 1s 41ms/step - loss: 0.6922 - accuracy: 0.5100 - val_loss: 0.6927 - val_accuracy: 0.5593\n","Epoch 14/100\n","29/29 [==============================] - 1s 38ms/step - loss: 0.6921 - accuracy: 0.5116 - val_loss: 0.6925 - val_accuracy: 0.5560\n","Epoch 15/100\n","29/29 [==============================] - 1s 39ms/step - loss: 0.6919 - accuracy: 0.5078 - val_loss: 0.6924 - val_accuracy: 0.5528\n","Epoch 16/100\n","29/29 [==============================] - 1s 40ms/step - loss: 0.6916 - accuracy: 0.5108 - val_loss: 0.6921 - val_accuracy: 0.5560\n","Epoch 17/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.6914 - accuracy: 0.5154 - val_loss: 0.6919 - val_accuracy: 0.5528\n","Epoch 18/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6913 - accuracy: 0.5172 - val_loss: 0.6917 - val_accuracy: 0.5528\n","Epoch 19/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6911 - accuracy: 0.5132 - val_loss: 0.6913 - val_accuracy: 0.5593\n","Epoch 20/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6908 - accuracy: 0.5202 - val_loss: 0.6910 - val_accuracy: 0.5550\n","Epoch 21/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6905 - accuracy: 0.5264 - val_loss: 0.6908 - val_accuracy: 0.5528\n","Epoch 22/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6900 - accuracy: 0.5256 - val_loss: 0.6905 - val_accuracy: 0.5539\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6897 - accuracy: 0.5288 - val_loss: 0.6903 - val_accuracy: 0.5356\n","Epoch 24/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6895 - accuracy: 0.5312 - val_loss: 0.6900 - val_accuracy: 0.5312\n","Epoch 25/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6890 - accuracy: 0.5280 - val_loss: 0.6896 - val_accuracy: 0.5291\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6888 - accuracy: 0.5304 - val_loss: 0.6895 - val_accuracy: 0.5205\n","Epoch 27/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6883 - accuracy: 0.5356 - val_loss: 0.6892 - val_accuracy: 0.5399\n","Epoch 28/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6881 - accuracy: 0.5337 - val_loss: 0.6889 - val_accuracy: 0.5237\n","Epoch 29/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6874 - accuracy: 0.5345 - val_loss: 0.6888 - val_accuracy: 0.5216\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6867 - accuracy: 0.5364 - val_loss: 0.6884 - val_accuracy: 0.5442\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6864 - accuracy: 0.5409 - val_loss: 0.6882 - val_accuracy: 0.5431\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6855 - accuracy: 0.5445 - val_loss: 0.6878 - val_accuracy: 0.5388\n","Epoch 33/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6848 - accuracy: 0.5418 - val_loss: 0.6880 - val_accuracy: 0.5237\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6840 - accuracy: 0.5496 - val_loss: 0.6872 - val_accuracy: 0.5485\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6831 - accuracy: 0.5528 - val_loss: 0.6870 - val_accuracy: 0.5420\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6822 - accuracy: 0.5480 - val_loss: 0.6866 - val_accuracy: 0.5496\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6812 - accuracy: 0.5544 - val_loss: 0.6870 - val_accuracy: 0.5453\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6800 - accuracy: 0.5558 - val_loss: 0.6867 - val_accuracy: 0.5506\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6792 - accuracy: 0.5558 - val_loss: 0.6866 - val_accuracy: 0.5571\n","Epoch 40/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6785 - accuracy: 0.5577 - val_loss: 0.6871 - val_accuracy: 0.5571\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6763 - accuracy: 0.5636 - val_loss: 0.6869 - val_accuracy: 0.5571\n","Epoch 42/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6771 - accuracy: 0.5582 - val_loss: 0.6879 - val_accuracy: 0.5528\n","Epoch 43/100\n","29/29 [==============================] - 2s 71ms/step - loss: 0.6751 - accuracy: 0.5603 - val_loss: 0.6894 - val_accuracy: 0.5690\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6738 - accuracy: 0.5647 - val_loss: 0.6888 - val_accuracy: 0.5560\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6720 - accuracy: 0.5633 - val_loss: 0.6901 - val_accuracy: 0.5506\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6702 - accuracy: 0.5692 - val_loss: 0.6902 - val_accuracy: 0.5614\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6698 - accuracy: 0.5709 - val_loss: 0.6913 - val_accuracy: 0.5528\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6703 - accuracy: 0.5760 - val_loss: 0.6914 - val_accuracy: 0.5603\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6658 - accuracy: 0.5784 - val_loss: 0.6914 - val_accuracy: 0.5539\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6654 - accuracy: 0.5805 - val_loss: 0.6948 - val_accuracy: 0.5603\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6673 - accuracy: 0.5741 - val_loss: 0.6940 - val_accuracy: 0.5582\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6659 - accuracy: 0.5795 - val_loss: 0.6938 - val_accuracy: 0.5560\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6644 - accuracy: 0.5787 - val_loss: 0.6951 - val_accuracy: 0.5539\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6630 - accuracy: 0.5811 - val_loss: 0.6958 - val_accuracy: 0.5485\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6614 - accuracy: 0.5867 - val_loss: 0.6980 - val_accuracy: 0.5528\n","Epoch 56/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6611 - accuracy: 0.5865 - val_loss: 0.6997 - val_accuracy: 0.5485\n","Epoch 57/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6607 - accuracy: 0.5811 - val_loss: 0.6980 - val_accuracy: 0.5496\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6583 - accuracy: 0.5884 - val_loss: 0.6990 - val_accuracy: 0.5453\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6574 - accuracy: 0.5908 - val_loss: 0.7003 - val_accuracy: 0.5496\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6581 - accuracy: 0.5940 - val_loss: 0.6996 - val_accuracy: 0.5463\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6533 - accuracy: 0.5975 - val_loss: 0.7013 - val_accuracy: 0.5517\n","Epoch 62/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6549 - accuracy: 0.5991 - val_loss: 0.7072 - val_accuracy: 0.5636\n","Epoch 63/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6527 - accuracy: 0.5956 - val_loss: 0.7052 - val_accuracy: 0.5506\n","Epoch 64/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6549 - accuracy: 0.5900 - val_loss: 0.7066 - val_accuracy: 0.5539\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6511 - accuracy: 0.6061 - val_loss: 0.7053 - val_accuracy: 0.5496\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6481 - accuracy: 0.6016 - val_loss: 0.7066 - val_accuracy: 0.5485\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6491 - accuracy: 0.6005 - val_loss: 0.7064 - val_accuracy: 0.5506\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6483 - accuracy: 0.6024 - val_loss: 0.7097 - val_accuracy: 0.5485\n","Epoch 69/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6445 - accuracy: 0.6048 - val_loss: 0.7093 - val_accuracy: 0.5431\n","Epoch 70/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6452 - accuracy: 0.6094 - val_loss: 0.7124 - val_accuracy: 0.5463\n","Epoch 71/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6441 - accuracy: 0.6053 - val_loss: 0.7138 - val_accuracy: 0.5463\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6443 - accuracy: 0.6051 - val_loss: 0.7110 - val_accuracy: 0.5442\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6419 - accuracy: 0.6107 - val_loss: 0.7147 - val_accuracy: 0.5453\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6408 - accuracy: 0.6129 - val_loss: 0.7155 - val_accuracy: 0.5506\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6408 - accuracy: 0.6102 - val_loss: 0.7168 - val_accuracy: 0.5431\n","Epoch 76/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6408 - accuracy: 0.6105 - val_loss: 0.7172 - val_accuracy: 0.5506\n","Epoch 77/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.6382 - accuracy: 0.6096 - val_loss: 0.7180 - val_accuracy: 0.5474\n","Epoch 78/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6354 - accuracy: 0.6131 - val_loss: 0.7229 - val_accuracy: 0.5496\n","Epoch 79/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6371 - accuracy: 0.6218 - val_loss: 0.7252 - val_accuracy: 0.5528\n","Epoch 80/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.6366 - accuracy: 0.6204 - val_loss: 0.7205 - val_accuracy: 0.5517\n","Epoch 81/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6332 - accuracy: 0.6234 - val_loss: 0.7247 - val_accuracy: 0.5356\n","Epoch 82/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6336 - accuracy: 0.6175 - val_loss: 0.7211 - val_accuracy: 0.5474\n","Epoch 83/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6307 - accuracy: 0.6188 - val_loss: 0.7227 - val_accuracy: 0.5517\n","Epoch 84/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6301 - accuracy: 0.6304 - val_loss: 0.7265 - val_accuracy: 0.5506\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6299 - accuracy: 0.6269 - val_loss: 0.7300 - val_accuracy: 0.5377\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6287 - accuracy: 0.6196 - val_loss: 0.7281 - val_accuracy: 0.5409\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6317 - accuracy: 0.6231 - val_loss: 0.7388 - val_accuracy: 0.5496\n","Epoch 88/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6271 - accuracy: 0.6234 - val_loss: 0.7346 - val_accuracy: 0.5582\n","Epoch 89/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6262 - accuracy: 0.6250 - val_loss: 0.7313 - val_accuracy: 0.5593\n","Epoch 90/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6235 - accuracy: 0.6328 - val_loss: 0.7318 - val_accuracy: 0.5453\n","Epoch 91/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6254 - accuracy: 0.6347 - val_loss: 0.7397 - val_accuracy: 0.5647\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6205 - accuracy: 0.6339 - val_loss: 0.7364 - val_accuracy: 0.5582\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6186 - accuracy: 0.6298 - val_loss: 0.7360 - val_accuracy: 0.5550\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6213 - accuracy: 0.6315 - val_loss: 0.7355 - val_accuracy: 0.5560\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6189 - accuracy: 0.6301 - val_loss: 0.7483 - val_accuracy: 0.5528\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6210 - accuracy: 0.6339 - val_loss: 0.7445 - val_accuracy: 0.5442\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6149 - accuracy: 0.6342 - val_loss: 0.7437 - val_accuracy: 0.5517\n","Epoch 98/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6185 - accuracy: 0.6263 - val_loss: 0.7417 - val_accuracy: 0.5550\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6154 - accuracy: 0.6436 - val_loss: 0.7469 - val_accuracy: 0.5506\n","Epoch 100/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6103 - accuracy: 0.6433 - val_loss: 0.7510 - val_accuracy: 0.5420\n","{'loss': [0.6931387186050415, 0.6931211352348328, 0.6931056976318359, 0.6930639147758484, 0.6930447816848755, 0.6930117011070251, 0.6929271221160889, 0.6928658485412598, 0.6927717328071594, 0.692672610282898, 0.6925187706947327, 0.6923847794532776, 0.6922138929367065, 0.6920878887176514, 0.6918667554855347, 0.6916273236274719, 0.6913950443267822, 0.6912921667098999, 0.6911062002182007, 0.6907846331596375, 0.69049072265625, 0.6900374889373779, 0.6897100210189819, 0.6895097494125366, 0.6890298128128052, 0.688784122467041, 0.6883113980293274, 0.6880615949630737, 0.6873517036437988, 0.6866880655288696, 0.6863625049591064, 0.685549259185791, 0.6847894787788391, 0.6840425133705139, 0.6831092238426208, 0.6822346448898315, 0.6811546087265015, 0.6799849271774292, 0.6791738867759705, 0.6785194873809814, 0.6763231158256531, 0.677105724811554, 0.6750593781471252, 0.6738482117652893, 0.6720396876335144, 0.6702447533607483, 0.6697936654090881, 0.6703327894210815, 0.6658107042312622, 0.665448009967804, 0.6672990322113037, 0.6659208536148071, 0.6643911600112915, 0.6630399227142334, 0.6614106893539429, 0.6610583066940308, 0.6607303023338318, 0.6583229303359985, 0.6574439406394958, 0.6580531001091003, 0.6533452868461609, 0.6548807621002197, 0.6527343392372131, 0.654868483543396, 0.6510557532310486, 0.6480621099472046, 0.649111270904541, 0.6483431458473206, 0.6444897055625916, 0.6452194452285767, 0.6441337466239929, 0.644256055355072, 0.6419147253036499, 0.6407888531684875, 0.6408271789550781, 0.6408231258392334, 0.6382269263267517, 0.6354100704193115, 0.6371150612831116, 0.6365584135055542, 0.6332019567489624, 0.6336425542831421, 0.6306869983673096, 0.6301407217979431, 0.6299100518226624, 0.6286869645118713, 0.631653904914856, 0.6271178126335144, 0.6262323260307312, 0.6235263347625732, 0.6253517270088196, 0.6205483675003052, 0.618593156337738, 0.6212544441223145, 0.6188800930976868, 0.620962917804718, 0.6148728132247925, 0.6184664368629456, 0.6154126524925232, 0.6103174090385437], 'accuracy': [0.4943426847457886, 0.5080819129943848, 0.5051185488700867, 0.5037715435028076, 0.5018857717514038, 0.5, 0.5072737336158752, 0.5099676847457886, 0.509428858757019, 0.5113146305084229, 0.509428858757019, 0.5035021305084229, 0.5099676847457886, 0.5115840435028076, 0.5078125, 0.5107758641242981, 0.5153555870056152, 0.517241358757019, 0.5132004022598267, 0.5202047228813171, 0.5264008641242981, 0.5255926847457886, 0.5288254022598267, 0.53125, 0.5280172228813171, 0.5304418206214905, 0.5355603694915771, 0.5336745977401733, 0.5344827771186829, 0.5363685488700867, 0.5409482717514038, 0.5444504022598267, 0.5417564511299133, 0.5495689511299133, 0.5528017282485962, 0.5479525923728943, 0.5544180870056152, 0.5557650923728943, 0.5557650923728943, 0.5576508641242981, 0.5635775923728943, 0.5581896305084229, 0.5603448152542114, 0.5646551847457886, 0.5633081793785095, 0.5692349076271057, 0.5708512663841248, 0.5759698152542114, 0.5783944129943848, 0.5805495977401733, 0.5740840435028076, 0.579472005367279, 0.5786637663841248, 0.5810883641242981, 0.5867456793785095, 0.5864762663841248, 0.5810883641242981, 0.5883620977401733, 0.5907866358757019, 0.5940194129943848, 0.5975215435028076, 0.5991379022598267, 0.5956357717514038, 0.5899784564971924, 0.6061422228813171, 0.6015625, 0.6004849076271057, 0.6023706793785095, 0.6047952771186829, 0.609375, 0.6053340435028076, 0.6050646305084229, 0.610722005367279, 0.6128771305084229, 0.6101831793785095, 0.6104525923728943, 0.6096444129943848, 0.6131465435028076, 0.6217672228813171, 0.6204202771186829, 0.623383641242981, 0.6174569129943848, 0.618803858757019, 0.6303879022598267, 0.6268857717514038, 0.6196120977401733, 0.6231142282485962, 0.623383641242981, 0.625, 0.6328125, 0.6346982717514038, 0.6338900923728943, 0.6298491358757019, 0.631465494632721, 0.6301185488700867, 0.6338900923728943, 0.634159505367279, 0.626347005367279, 0.6435883641242981, 0.6433189511299133], 'val_loss': [0.6931483745574951, 0.6931415796279907, 0.6931456923484802, 0.6931354999542236, 0.6931241154670715, 0.6931149959564209, 0.6930946111679077, 0.6930623650550842, 0.693024754524231, 0.6929762363433838, 0.6929043531417847, 0.692819356918335, 0.6926986575126648, 0.6925070285797119, 0.6923575401306152, 0.6921331286430359, 0.6919090151786804, 0.6916617751121521, 0.6913091540336609, 0.6910491585731506, 0.6907914280891418, 0.6905083656311035, 0.6902542114257812, 0.6899588108062744, 0.6896335482597351, 0.6894837617874146, 0.6891880035400391, 0.6889472007751465, 0.6888025403022766, 0.6884372234344482, 0.6881859302520752, 0.687760591506958, 0.6880438327789307, 0.6871736645698547, 0.6869761347770691, 0.6866124868392944, 0.6870302557945251, 0.6866999268531799, 0.6866351366043091, 0.6871421337127686, 0.6868923902511597, 0.687899649143219, 0.6893970966339111, 0.6887950301170349, 0.6901186108589172, 0.6901901960372925, 0.6913031339645386, 0.6913576722145081, 0.6913967728614807, 0.6947591304779053, 0.6940391063690186, 0.6937724947929382, 0.6951356530189514, 0.6957718133926392, 0.6979952454566956, 0.6997267603874207, 0.6979631185531616, 0.6990357637405396, 0.7003142833709717, 0.6995671987533569, 0.7012683749198914, 0.7072412371635437, 0.7051737308502197, 0.7066105604171753, 0.7053098082542419, 0.7065995931625366, 0.706426203250885, 0.709743857383728, 0.7093002796173096, 0.7123989462852478, 0.7138409614562988, 0.7110352516174316, 0.714686930179596, 0.7154592871665955, 0.7168071269989014, 0.7171912789344788, 0.7180196642875671, 0.7228705286979675, 0.7252359986305237, 0.7205391526222229, 0.7246652841567993, 0.7211114764213562, 0.7227310538291931, 0.7265315055847168, 0.7299972772598267, 0.7281127572059631, 0.7388303875923157, 0.7346462607383728, 0.7313172817230225, 0.7318064570426941, 0.7397013306617737, 0.7363803386688232, 0.7360265254974365, 0.735541045665741, 0.7483471035957336, 0.7445318102836609, 0.7436902523040771, 0.7416924834251404, 0.7468860745429993, 0.7510164976119995], 'val_accuracy': [0.48491379618644714, 0.524784505367279, 0.48491379618644714, 0.5635775923728943, 0.524784505367279, 0.48491379618644714, 0.53125, 0.5549569129943848, 0.5506465435028076, 0.5463362336158752, 0.548491358757019, 0.5571120977401733, 0.5592672228813171, 0.556034505367279, 0.5528017282485962, 0.556034505367279, 0.5528017282485962, 0.5528017282485962, 0.5592672228813171, 0.5549569129943848, 0.5528017282485962, 0.5538793206214905, 0.5355603694915771, 0.53125, 0.5290948152542114, 0.5204741358757019, 0.5398706793785095, 0.5237069129943848, 0.5215517282485962, 0.5441810488700867, 0.5431034564971924, 0.5387930870056152, 0.5237069129943848, 0.548491358757019, 0.5420258641242981, 0.5495689511299133, 0.545258641242981, 0.5506465435028076, 0.5571120977401733, 0.5571120977401733, 0.5571120977401733, 0.5528017282485962, 0.568965494632721, 0.556034505367279, 0.5506465435028076, 0.5614224076271057, 0.5528017282485962, 0.5603448152542114, 0.5538793206214905, 0.5603448152542114, 0.5581896305084229, 0.556034505367279, 0.5538793206214905, 0.548491358757019, 0.5528017282485962, 0.548491358757019, 0.5495689511299133, 0.545258641242981, 0.5495689511299133, 0.5463362336158752, 0.5517241358757019, 0.5635775923728943, 0.5506465435028076, 0.5538793206214905, 0.5495689511299133, 0.548491358757019, 0.5506465435028076, 0.548491358757019, 0.5431034564971924, 0.5463362336158752, 0.5463362336158752, 0.5441810488700867, 0.545258641242981, 0.5506465435028076, 0.5431034564971924, 0.5506465435028076, 0.5474137663841248, 0.5495689511299133, 0.5528017282485962, 0.5517241358757019, 0.5355603694915771, 0.5474137663841248, 0.5517241358757019, 0.5506465435028076, 0.537715494632721, 0.5409482717514038, 0.5495689511299133, 0.5581896305084229, 0.5592672228813171, 0.545258641242981, 0.5646551847457886, 0.5581896305084229, 0.5549569129943848, 0.556034505367279, 0.5528017282485962, 0.5441810488700867, 0.5517241358757019, 0.5549569129943848, 0.5506465435028076, 0.5420258641242981]}\n","38/38 [==============================] - 1s 9ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4850"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 9s 76ms/step - loss: 0.6931 - accuracy: 0.4850 - val_loss: 0.6931 - val_accuracy: 0.5102\n","Epoch 2/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5257 - val_loss: 0.6931 - val_accuracy: 0.5090\n","Epoch 3/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5289 - val_loss: 0.6931 - val_accuracy: 0.5090\n","Epoch 4/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6930 - accuracy: 0.5241 - val_loss: 0.6931 - val_accuracy: 0.5068\n","Epoch 5/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6929 - accuracy: 0.5337 - val_loss: 0.6931 - val_accuracy: 0.5124\n","Epoch 6/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6928 - accuracy: 0.5328 - val_loss: 0.6931 - val_accuracy: 0.5068\n","Epoch 7/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6927 - accuracy: 0.5388 - val_loss: 0.6931 - val_accuracy: 0.5068\n","Epoch 8/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6925 - accuracy: 0.5340 - val_loss: 0.6931 - val_accuracy: 0.5068\n","Epoch 9/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6924 - accuracy: 0.5354 - val_loss: 0.6930 - val_accuracy: 0.5102\n","Epoch 10/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6921 - accuracy: 0.5348 - val_loss: 0.6930 - val_accuracy: 0.5124\n","Epoch 11/100\n","28/28 [==============================] - 1s 41ms/step - loss: 0.6918 - accuracy: 0.5357 - val_loss: 0.6929 - val_accuracy: 0.5147\n","Epoch 12/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.6915 - accuracy: 0.5345 - val_loss: 0.6928 - val_accuracy: 0.5238\n","Epoch 13/100\n","28/28 [==============================] - 1s 43ms/step - loss: 0.6912 - accuracy: 0.5365 - val_loss: 0.6926 - val_accuracy: 0.5249\n","Epoch 14/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.6909 - accuracy: 0.5342 - val_loss: 0.6925 - val_accuracy: 0.5215\n","Epoch 15/100\n","28/28 [==============================] - 1s 46ms/step - loss: 0.6907 - accuracy: 0.5371 - val_loss: 0.6923 - val_accuracy: 0.5260\n","Epoch 16/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.6904 - accuracy: 0.5359 - val_loss: 0.6922 - val_accuracy: 0.5249\n","Epoch 17/100\n","28/28 [==============================] - 1s 40ms/step - loss: 0.6901 - accuracy: 0.5371 - val_loss: 0.6920 - val_accuracy: 0.5305\n","Epoch 18/100\n","28/28 [==============================] - 1s 50ms/step - loss: 0.6899 - accuracy: 0.5359 - val_loss: 0.6919 - val_accuracy: 0.5351\n","Epoch 19/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6895 - accuracy: 0.5388 - val_loss: 0.6918 - val_accuracy: 0.5317\n","Epoch 20/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6892 - accuracy: 0.5410 - val_loss: 0.6917 - val_accuracy: 0.5385\n","Epoch 21/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6888 - accuracy: 0.5368 - val_loss: 0.6916 - val_accuracy: 0.5373\n","Epoch 22/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6884 - accuracy: 0.5405 - val_loss: 0.6915 - val_accuracy: 0.5441\n","Epoch 23/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6880 - accuracy: 0.5427 - val_loss: 0.6915 - val_accuracy: 0.5441\n","Epoch 24/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.6871 - accuracy: 0.5433 - val_loss: 0.6915 - val_accuracy: 0.5486\n","Epoch 25/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.6868 - accuracy: 0.5484 - val_loss: 0.6915 - val_accuracy: 0.5509\n","Epoch 26/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6862 - accuracy: 0.5495 - val_loss: 0.6918 - val_accuracy: 0.5509\n","Epoch 27/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6857 - accuracy: 0.5546 - val_loss: 0.6917 - val_accuracy: 0.5498\n","Epoch 28/100\n","28/28 [==============================] - 1s 42ms/step - loss: 0.6849 - accuracy: 0.5557 - val_loss: 0.6919 - val_accuracy: 0.5554\n","Epoch 29/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.6843 - accuracy: 0.5543 - val_loss: 0.6922 - val_accuracy: 0.5532\n","Epoch 30/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6836 - accuracy: 0.5557 - val_loss: 0.6926 - val_accuracy: 0.5509\n","Epoch 31/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6827 - accuracy: 0.5577 - val_loss: 0.6921 - val_accuracy: 0.5509\n","Epoch 32/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6818 - accuracy: 0.5523 - val_loss: 0.6931 - val_accuracy: 0.5486\n","Epoch 33/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6809 - accuracy: 0.5608 - val_loss: 0.6930 - val_accuracy: 0.5464\n","Epoch 34/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6804 - accuracy: 0.5631 - val_loss: 0.6928 - val_accuracy: 0.5520\n","Epoch 35/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6788 - accuracy: 0.5665 - val_loss: 0.6924 - val_accuracy: 0.5543\n","Epoch 36/100\n","28/28 [==============================] - 1s 49ms/step - loss: 0.6779 - accuracy: 0.5651 - val_loss: 0.6913 - val_accuracy: 0.5588\n","Epoch 37/100\n","28/28 [==============================] - 1s 43ms/step - loss: 0.6780 - accuracy: 0.5671 - val_loss: 0.6912 - val_accuracy: 0.5611\n","Epoch 38/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.6764 - accuracy: 0.5665 - val_loss: 0.6933 - val_accuracy: 0.5441\n","Epoch 39/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6760 - accuracy: 0.5603 - val_loss: 0.6899 - val_accuracy: 0.5588\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6741 - accuracy: 0.5710 - val_loss: 0.6928 - val_accuracy: 0.5566\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6728 - accuracy: 0.5772 - val_loss: 0.6928 - val_accuracy: 0.5554\n","Epoch 42/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6725 - accuracy: 0.5705 - val_loss: 0.6902 - val_accuracy: 0.5622\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6708 - accuracy: 0.5730 - val_loss: 0.6931 - val_accuracy: 0.5600\n","Epoch 44/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6712 - accuracy: 0.5750 - val_loss: 0.6910 - val_accuracy: 0.5622\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6701 - accuracy: 0.5736 - val_loss: 0.6948 - val_accuracy: 0.5543\n","Epoch 46/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6698 - accuracy: 0.5775 - val_loss: 0.6919 - val_accuracy: 0.5622\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6675 - accuracy: 0.5781 - val_loss: 0.6928 - val_accuracy: 0.5566\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6672 - accuracy: 0.5795 - val_loss: 0.6950 - val_accuracy: 0.5543\n","Epoch 49/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6673 - accuracy: 0.5801 - val_loss: 0.6958 - val_accuracy: 0.5554\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6659 - accuracy: 0.5750 - val_loss: 0.6937 - val_accuracy: 0.5577\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6677 - accuracy: 0.5801 - val_loss: 0.6992 - val_accuracy: 0.5520\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6638 - accuracy: 0.5804 - val_loss: 0.6955 - val_accuracy: 0.5554\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6630 - accuracy: 0.5855 - val_loss: 0.7006 - val_accuracy: 0.5520\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6647 - accuracy: 0.5806 - val_loss: 0.6968 - val_accuracy: 0.5554\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6657 - accuracy: 0.5756 - val_loss: 0.6959 - val_accuracy: 0.5554\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6642 - accuracy: 0.5826 - val_loss: 0.6995 - val_accuracy: 0.5520\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6615 - accuracy: 0.5812 - val_loss: 0.6990 - val_accuracy: 0.5520\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6605 - accuracy: 0.5838 - val_loss: 0.7015 - val_accuracy: 0.5577\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6591 - accuracy: 0.5874 - val_loss: 0.6984 - val_accuracy: 0.5543\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6594 - accuracy: 0.5897 - val_loss: 0.6991 - val_accuracy: 0.5486\n","Epoch 61/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.6597 - accuracy: 0.5925 - val_loss: 0.7030 - val_accuracy: 0.5543\n","Epoch 62/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6568 - accuracy: 0.5891 - val_loss: 0.7006 - val_accuracy: 0.5509\n","Epoch 63/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6581 - accuracy: 0.5886 - val_loss: 0.6990 - val_accuracy: 0.5543\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6582 - accuracy: 0.5880 - val_loss: 0.6979 - val_accuracy: 0.5543\n","Epoch 65/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6558 - accuracy: 0.5911 - val_loss: 0.7068 - val_accuracy: 0.5611\n","Epoch 66/100\n","28/28 [==============================] - 1s 39ms/step - loss: 0.6609 - accuracy: 0.5829 - val_loss: 0.7087 - val_accuracy: 0.5633\n","Epoch 67/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6542 - accuracy: 0.5937 - val_loss: 0.7073 - val_accuracy: 0.5532\n","Epoch 68/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6518 - accuracy: 0.5945 - val_loss: 0.7025 - val_accuracy: 0.5566\n","Epoch 69/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6563 - accuracy: 0.5939 - val_loss: 0.7042 - val_accuracy: 0.5611\n","Epoch 70/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6519 - accuracy: 0.5993 - val_loss: 0.7089 - val_accuracy: 0.5600\n","Epoch 71/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6521 - accuracy: 0.5976 - val_loss: 0.7053 - val_accuracy: 0.5633\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6517 - accuracy: 0.5988 - val_loss: 0.7027 - val_accuracy: 0.5633\n","Epoch 73/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6522 - accuracy: 0.6005 - val_loss: 0.7058 - val_accuracy: 0.5667\n","Epoch 74/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6481 - accuracy: 0.6010 - val_loss: 0.7076 - val_accuracy: 0.5611\n","Epoch 75/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6487 - accuracy: 0.6019 - val_loss: 0.7009 - val_accuracy: 0.5667\n","Epoch 76/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6474 - accuracy: 0.6036 - val_loss: 0.7046 - val_accuracy: 0.5701\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6443 - accuracy: 0.6089 - val_loss: 0.7054 - val_accuracy: 0.5701\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6437 - accuracy: 0.6058 - val_loss: 0.7043 - val_accuracy: 0.5611\n","Epoch 79/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6446 - accuracy: 0.6044 - val_loss: 0.7055 - val_accuracy: 0.5622\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6427 - accuracy: 0.6078 - val_loss: 0.7097 - val_accuracy: 0.5656\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6430 - accuracy: 0.6058 - val_loss: 0.7108 - val_accuracy: 0.5690\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6448 - accuracy: 0.6050 - val_loss: 0.7112 - val_accuracy: 0.5690\n","Epoch 83/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6429 - accuracy: 0.6104 - val_loss: 0.7124 - val_accuracy: 0.5769\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6404 - accuracy: 0.6140 - val_loss: 0.7212 - val_accuracy: 0.5724\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6412 - accuracy: 0.6115 - val_loss: 0.7129 - val_accuracy: 0.5577\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6393 - accuracy: 0.6118 - val_loss: 0.7093 - val_accuracy: 0.5758\n","Epoch 87/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6361 - accuracy: 0.6186 - val_loss: 0.7210 - val_accuracy: 0.5758\n","Epoch 88/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6404 - accuracy: 0.6101 - val_loss: 0.7165 - val_accuracy: 0.5645\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6358 - accuracy: 0.6203 - val_loss: 0.7215 - val_accuracy: 0.5701\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6344 - accuracy: 0.6186 - val_loss: 0.7155 - val_accuracy: 0.5667\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6359 - accuracy: 0.6217 - val_loss: 0.7175 - val_accuracy: 0.5645\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6333 - accuracy: 0.6197 - val_loss: 0.7140 - val_accuracy: 0.5735\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6344 - accuracy: 0.6197 - val_loss: 0.7168 - val_accuracy: 0.5633\n","Epoch 94/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.6326 - accuracy: 0.6197 - val_loss: 0.7177 - val_accuracy: 0.5690\n","Epoch 95/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.6344 - accuracy: 0.6259 - val_loss: 0.7130 - val_accuracy: 0.5633\n","Epoch 96/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6320 - accuracy: 0.6200 - val_loss: 0.7126 - val_accuracy: 0.5747\n","Epoch 97/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6275 - accuracy: 0.6299 - val_loss: 0.7251 - val_accuracy: 0.5713\n","Epoch 98/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6277 - accuracy: 0.6310 - val_loss: 0.7259 - val_accuracy: 0.5633\n","Epoch 99/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6275 - accuracy: 0.6347 - val_loss: 0.7252 - val_accuracy: 0.5667\n","Epoch 100/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6283 - accuracy: 0.6279 - val_loss: 0.7186 - val_accuracy: 0.5724\n","{'loss': [0.6931410431861877, 0.6931031346321106, 0.693060576915741, 0.6930239200592041, 0.6929384469985962, 0.6928423643112183, 0.6927093267440796, 0.6925336122512817, 0.6923518180847168, 0.6921152472496033, 0.6918198466300964, 0.6915005445480347, 0.6912358403205872, 0.6909287571907043, 0.6907030940055847, 0.6903606057167053, 0.6901199221611023, 0.6898943781852722, 0.689531683921814, 0.6892170906066895, 0.6887804865837097, 0.6884386539459229, 0.6879878640174866, 0.6871468424797058, 0.6867709159851074, 0.6862068772315979, 0.6857245564460754, 0.6848578453063965, 0.6842652559280396, 0.6836392879486084, 0.6827200651168823, 0.6818194389343262, 0.680904746055603, 0.6804234385490417, 0.6787727475166321, 0.677903950214386, 0.6779571771621704, 0.6763904094696045, 0.6760224103927612, 0.6741284728050232, 0.6727732419967651, 0.6725234985351562, 0.6708272099494934, 0.6712333559989929, 0.6700511574745178, 0.6698232293128967, 0.6674667000770569, 0.6672226786613464, 0.6673406958580017, 0.6658735275268555, 0.6676552295684814, 0.6637917160987854, 0.6630415320396423, 0.664694607257843, 0.6656794548034668, 0.6642348766326904, 0.6614585518836975, 0.6604939103126526, 0.6590527296066284, 0.6594107151031494, 0.6596669554710388, 0.6568050384521484, 0.6580610871315002, 0.6582117676734924, 0.6557575464248657, 0.660902202129364, 0.6542302370071411, 0.6517747640609741, 0.656259298324585, 0.6519224047660828, 0.6521100401878357, 0.651687502861023, 0.6522499322891235, 0.6481490135192871, 0.6487168669700623, 0.6474462747573853, 0.644295334815979, 0.6436685919761658, 0.6446413397789001, 0.6426516771316528, 0.6429868340492249, 0.644751787185669, 0.6428824663162231, 0.6404281854629517, 0.6411832571029663, 0.639311671257019, 0.6361101865768433, 0.6403998732566833, 0.6358410716056824, 0.6343756914138794, 0.6358519196510315, 0.6333366632461548, 0.6343557238578796, 0.6325873732566833, 0.6344427466392517, 0.6319626569747925, 0.6274586915969849, 0.6277374029159546, 0.6275407075881958, 0.6282973885536194], 'accuracy': [0.4850028157234192, 0.5257498621940613, 0.528862476348877, 0.524052083492279, 0.5336728692054749, 0.5328239798545837, 0.5387662649154663, 0.5339558720588684, 0.5353707075119019, 0.5348047614097595, 0.5356536507606506, 0.534521758556366, 0.5365025401115417, 0.5342388153076172, 0.5370684862136841, 0.5359365940093994, 0.5370684862136841, 0.5359365940093994, 0.5387662649154663, 0.5410299897193909, 0.5367854833602905, 0.5404640436172485, 0.5427277684211731, 0.5432937145233154, 0.5483871102333069, 0.5495189428329468, 0.5546123385429382, 0.5557441711425781, 0.5543293952941895, 0.5557441711425781, 0.5577249526977539, 0.5523486137390137, 0.5608375668525696, 0.5631012916564941, 0.5664969086647034, 0.5650820732116699, 0.5670627951622009, 0.5664969086647034, 0.5602716207504272, 0.5710243582725525, 0.5772495865821838, 0.5704584121704102, 0.5730050802230835, 0.5749858617782593, 0.5735710263252258, 0.5775325298309326, 0.578098475933075, 0.5795133113861084, 0.5800792574882507, 0.5749858617782593, 0.5800792574882507, 0.5803622007369995, 0.585455596446991, 0.5806451439857483, 0.5755518078804016, 0.5826259255409241, 0.5812110900878906, 0.583757758140564, 0.587436318397522, 0.5897000432014465, 0.5925297141075134, 0.5891340970993042, 0.5885682106018066, 0.5880022644996643, 0.59111487865448, 0.5829088687896729, 0.5936615467071533, 0.5945104956626892, 0.5939445495605469, 0.5993208885192871, 0.5976231098175049, 0.5987549424171448, 0.600452721118927, 0.6010186672210693, 0.6018675565719604, 0.6035653352737427, 0.6089417338371277, 0.6058290600776672, 0.6044142842292786, 0.607809841632843, 0.6058290600776672, 0.6049801707267761, 0.6103565096855164, 0.6140350699424744, 0.611488401889801, 0.6117713451385498, 0.6185625195503235, 0.6100735664367676, 0.6202603578567505, 0.6185625195503235, 0.6216751337051392, 0.6196944117546082, 0.6196944117546082, 0.6196944117546082, 0.6259196400642395, 0.6199773550033569, 0.6298811435699463, 0.631013035774231, 0.634691596031189, 0.6279004216194153], 'val_loss': [0.6931442618370056, 0.693139910697937, 0.6931337118148804, 0.6931276917457581, 0.6931132078170776, 0.6931063532829285, 0.6930803656578064, 0.693054735660553, 0.6930084228515625, 0.6929535865783691, 0.6928845643997192, 0.692766547203064, 0.6926326751708984, 0.6924713253974915, 0.6923187375068665, 0.69220370054245, 0.692029595375061, 0.6918965578079224, 0.6917892098426819, 0.6916594505310059, 0.6915643811225891, 0.6915443539619446, 0.6915140151977539, 0.691518247127533, 0.6915261149406433, 0.6917842030525208, 0.6916689872741699, 0.6918905377388, 0.6921634674072266, 0.6926218271255493, 0.6920726895332336, 0.6930503845214844, 0.6929539442062378, 0.6928223371505737, 0.6924171447753906, 0.6913233995437622, 0.6912125945091248, 0.6933462023735046, 0.6898983716964722, 0.6928251385688782, 0.6928334832191467, 0.6901916265487671, 0.6930871605873108, 0.6909542083740234, 0.694805383682251, 0.6918690800666809, 0.6928271651268005, 0.694997251033783, 0.6958263516426086, 0.6936553716659546, 0.6991999745368958, 0.6955183148384094, 0.7005899548530579, 0.6967506408691406, 0.6958509087562561, 0.6995143294334412, 0.6990423202514648, 0.7014634013175964, 0.6984195113182068, 0.6991326808929443, 0.7030118107795715, 0.7005578875541687, 0.6989803314208984, 0.6978935599327087, 0.7068138122558594, 0.7086650729179382, 0.7073498368263245, 0.7024650573730469, 0.7041590213775635, 0.7089201807975769, 0.7053386569023132, 0.7026832699775696, 0.7058423161506653, 0.7075530886650085, 0.7009333968162537, 0.7045921683311462, 0.705392062664032, 0.7042703628540039, 0.7054756879806519, 0.7097381353378296, 0.7107588648796082, 0.711181640625, 0.7124128937721252, 0.7212443351745605, 0.7129084467887878, 0.7093218564987183, 0.7209509015083313, 0.7164991497993469, 0.7214729189872742, 0.7154535055160522, 0.7175377011299133, 0.7140061855316162, 0.716818630695343, 0.717738151550293, 0.7130317091941833, 0.7125832438468933, 0.7251241207122803, 0.7258824110031128, 0.7251668572425842, 0.7185871005058289], 'val_accuracy': [0.5101810097694397, 0.5090497732162476, 0.5090497732162476, 0.5067873597145081, 0.5124434232711792, 0.5067873597145081, 0.5067873597145081, 0.5067873597145081, 0.5101810097694397, 0.5124434232711792, 0.5147058963775635, 0.523755669593811, 0.5248869061470032, 0.5214931964874268, 0.5260180830955505, 0.5248869061470032, 0.5305429697036743, 0.5350678563117981, 0.5316742062568665, 0.5384615659713745, 0.5373303294181824, 0.5441176295280457, 0.5441176295280457, 0.5486425161361694, 0.5509049892425537, 0.5509049892425537, 0.5497737526893616, 0.5554298758506775, 0.5531674027442932, 0.5509049892425537, 0.5509049892425537, 0.5486425161361694, 0.5463801026344299, 0.5520362257957458, 0.5542986392974854, 0.5588235259056091, 0.5610859990119934, 0.5441176295280457, 0.5588235259056091, 0.5565611124038696, 0.5554298758506775, 0.5622171759605408, 0.5599547624588013, 0.5622171759605408, 0.5542986392974854, 0.5622171759605408, 0.5565611124038696, 0.5542986392974854, 0.5554298758506775, 0.557692289352417, 0.5520362257957458, 0.5554298758506775, 0.5520362257957458, 0.5554298758506775, 0.5554298758506775, 0.5520362257957458, 0.5520362257957458, 0.557692289352417, 0.5542986392974854, 0.5486425161361694, 0.5542986392974854, 0.5509049892425537, 0.5542986392974854, 0.5542986392974854, 0.5610859990119934, 0.5633484125137329, 0.5531674027442932, 0.5565611124038696, 0.5610859990119934, 0.5599547624588013, 0.5633484125137329, 0.5633484125137329, 0.5667420625686646, 0.5610859990119934, 0.5667420625686646, 0.570135772228241, 0.570135772228241, 0.5610859990119934, 0.5622171759605408, 0.5656108856201172, 0.5690045356750488, 0.5690045356750488, 0.5769230723381042, 0.5723981857299805, 0.557692289352417, 0.5757918357849121, 0.5757918357849121, 0.564479649066925, 0.570135772228241, 0.5667420625686646, 0.564479649066925, 0.5735294222831726, 0.5633484125137329, 0.5690045356750488, 0.5633484125137329, 0.5746606588363647, 0.5712669491767883, 0.5633484125137329, 0.5667420625686646, 0.5723981857299805]}\n","45/45 [==============================] - 1s 8ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5052"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 10s 92ms/step - loss: 0.6931 - accuracy: 0.5052 - val_loss: 0.6931 - val_accuracy: 0.5165\n","Epoch 2/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5307 - val_loss: 0.6931 - val_accuracy: 0.5165\n","Epoch 3/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6930 - accuracy: 0.5393 - val_loss: 0.6931 - val_accuracy: 0.5165\n","Epoch 4/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6929 - accuracy: 0.5429 - val_loss: 0.6931 - val_accuracy: 0.5093\n","Epoch 5/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6928 - accuracy: 0.5401 - val_loss: 0.6931 - val_accuracy: 0.5124\n","Epoch 6/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.6926 - accuracy: 0.5388 - val_loss: 0.6931 - val_accuracy: 0.5176\n","Epoch 7/100\n","31/31 [==============================] - 1s 39ms/step - loss: 0.6922 - accuracy: 0.5421 - val_loss: 0.6930 - val_accuracy: 0.5217\n","Epoch 8/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6919 - accuracy: 0.5362 - val_loss: 0.6930 - val_accuracy: 0.5155\n","Epoch 9/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6913 - accuracy: 0.5364 - val_loss: 0.6929 - val_accuracy: 0.5186\n","Epoch 10/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6907 - accuracy: 0.5372 - val_loss: 0.6929 - val_accuracy: 0.5217\n","Epoch 11/100\n","31/31 [==============================] - 2s 57ms/step - loss: 0.6901 - accuracy: 0.5377 - val_loss: 0.6928 - val_accuracy: 0.5258\n","Epoch 12/100\n","31/31 [==============================] - 1s 42ms/step - loss: 0.6897 - accuracy: 0.5370 - val_loss: 0.6928 - val_accuracy: 0.5310\n","Epoch 13/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.6892 - accuracy: 0.5359 - val_loss: 0.6928 - val_accuracy: 0.5269\n","Epoch 14/100\n","31/31 [==============================] - 1s 45ms/step - loss: 0.6889 - accuracy: 0.5382 - val_loss: 0.6928 - val_accuracy: 0.5269\n","Epoch 15/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6888 - accuracy: 0.5390 - val_loss: 0.6929 - val_accuracy: 0.5248\n","Epoch 16/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6886 - accuracy: 0.5388 - val_loss: 0.6930 - val_accuracy: 0.5227\n","Epoch 17/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6885 - accuracy: 0.5442 - val_loss: 0.6930 - val_accuracy: 0.5248\n","Epoch 18/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6881 - accuracy: 0.5465 - val_loss: 0.6933 - val_accuracy: 0.5289\n","Epoch 19/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6875 - accuracy: 0.5496 - val_loss: 0.6933 - val_accuracy: 0.5248\n","Epoch 20/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6873 - accuracy: 0.5457 - val_loss: 0.6936 - val_accuracy: 0.5227\n","Epoch 21/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6869 - accuracy: 0.5452 - val_loss: 0.6940 - val_accuracy: 0.5227\n","Epoch 22/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6862 - accuracy: 0.5475 - val_loss: 0.6942 - val_accuracy: 0.5258\n","Epoch 23/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6859 - accuracy: 0.5501 - val_loss: 0.6942 - val_accuracy: 0.5238\n","Epoch 24/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6855 - accuracy: 0.5537 - val_loss: 0.6946 - val_accuracy: 0.5279\n","Epoch 25/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6849 - accuracy: 0.5535 - val_loss: 0.6951 - val_accuracy: 0.5310\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6844 - accuracy: 0.5556 - val_loss: 0.6953 - val_accuracy: 0.5279\n","Epoch 27/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6840 - accuracy: 0.5592 - val_loss: 0.6952 - val_accuracy: 0.5310\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6832 - accuracy: 0.5597 - val_loss: 0.6960 - val_accuracy: 0.5289\n","Epoch 29/100\n","31/31 [==============================] - 1s 38ms/step - loss: 0.6828 - accuracy: 0.5633 - val_loss: 0.6963 - val_accuracy: 0.5320\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6822 - accuracy: 0.5581 - val_loss: 0.6953 - val_accuracy: 0.5289\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6813 - accuracy: 0.5602 - val_loss: 0.6960 - val_accuracy: 0.5300\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6809 - accuracy: 0.5669 - val_loss: 0.6962 - val_accuracy: 0.5300\n","Epoch 33/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6806 - accuracy: 0.5610 - val_loss: 0.6974 - val_accuracy: 0.5331\n","Epoch 34/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6798 - accuracy: 0.5682 - val_loss: 0.6954 - val_accuracy: 0.5279\n","Epoch 35/100\n","31/31 [==============================] - 2s 51ms/step - loss: 0.6789 - accuracy: 0.5695 - val_loss: 0.6965 - val_accuracy: 0.5341\n","Epoch 36/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6773 - accuracy: 0.5698 - val_loss: 0.6962 - val_accuracy: 0.5341\n","Epoch 37/100\n","31/31 [==============================] - 1s 38ms/step - loss: 0.6773 - accuracy: 0.5693 - val_loss: 0.6972 - val_accuracy: 0.5351\n","Epoch 38/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6765 - accuracy: 0.5669 - val_loss: 0.6967 - val_accuracy: 0.5331\n","Epoch 39/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6758 - accuracy: 0.5718 - val_loss: 0.6987 - val_accuracy: 0.5341\n","Epoch 40/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6748 - accuracy: 0.5651 - val_loss: 0.6967 - val_accuracy: 0.5351\n","Epoch 41/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6756 - accuracy: 0.5739 - val_loss: 0.7003 - val_accuracy: 0.5279\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6748 - accuracy: 0.5708 - val_loss: 0.6974 - val_accuracy: 0.5300\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6742 - accuracy: 0.5726 - val_loss: 0.6997 - val_accuracy: 0.5341\n","Epoch 44/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6733 - accuracy: 0.5767 - val_loss: 0.6973 - val_accuracy: 0.5351\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6726 - accuracy: 0.5708 - val_loss: 0.6996 - val_accuracy: 0.5269\n","Epoch 46/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6713 - accuracy: 0.5775 - val_loss: 0.6979 - val_accuracy: 0.5279\n","Epoch 47/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6704 - accuracy: 0.5796 - val_loss: 0.7001 - val_accuracy: 0.5269\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6699 - accuracy: 0.5778 - val_loss: 0.6987 - val_accuracy: 0.5331\n","Epoch 49/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6693 - accuracy: 0.5814 - val_loss: 0.6968 - val_accuracy: 0.5289\n","Epoch 50/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6688 - accuracy: 0.5775 - val_loss: 0.6966 - val_accuracy: 0.5258\n","Epoch 51/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6672 - accuracy: 0.5842 - val_loss: 0.7040 - val_accuracy: 0.5248\n","Epoch 52/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6679 - accuracy: 0.5876 - val_loss: 0.7017 - val_accuracy: 0.5258\n","Epoch 53/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6668 - accuracy: 0.5868 - val_loss: 0.7049 - val_accuracy: 0.5248\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6661 - accuracy: 0.5832 - val_loss: 0.6974 - val_accuracy: 0.5310\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6652 - accuracy: 0.5884 - val_loss: 0.6996 - val_accuracy: 0.5258\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6652 - accuracy: 0.5837 - val_loss: 0.6983 - val_accuracy: 0.5269\n","Epoch 57/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6646 - accuracy: 0.5845 - val_loss: 0.7021 - val_accuracy: 0.5196\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6631 - accuracy: 0.5925 - val_loss: 0.7031 - val_accuracy: 0.5227\n","Epoch 59/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6626 - accuracy: 0.5904 - val_loss: 0.7096 - val_accuracy: 0.5165\n","Epoch 60/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6607 - accuracy: 0.5987 - val_loss: 0.7096 - val_accuracy: 0.5227\n","Epoch 61/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6608 - accuracy: 0.5928 - val_loss: 0.7048 - val_accuracy: 0.5176\n","Epoch 62/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6588 - accuracy: 0.5979 - val_loss: 0.7105 - val_accuracy: 0.5186\n","Epoch 63/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6603 - accuracy: 0.5902 - val_loss: 0.7081 - val_accuracy: 0.5207\n","Epoch 64/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.6600 - accuracy: 0.5920 - val_loss: 0.7046 - val_accuracy: 0.5269\n","Epoch 65/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6579 - accuracy: 0.5977 - val_loss: 0.7074 - val_accuracy: 0.5248\n","Epoch 66/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6600 - accuracy: 0.5935 - val_loss: 0.7079 - val_accuracy: 0.5269\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6564 - accuracy: 0.5935 - val_loss: 0.7165 - val_accuracy: 0.5238\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6571 - accuracy: 0.5961 - val_loss: 0.7154 - val_accuracy: 0.5248\n","Epoch 69/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6563 - accuracy: 0.6031 - val_loss: 0.7198 - val_accuracy: 0.5227\n","Epoch 70/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6560 - accuracy: 0.6070 - val_loss: 0.7133 - val_accuracy: 0.5269\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6555 - accuracy: 0.6005 - val_loss: 0.7152 - val_accuracy: 0.5289\n","Epoch 72/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6524 - accuracy: 0.6049 - val_loss: 0.7146 - val_accuracy: 0.5238\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6514 - accuracy: 0.6080 - val_loss: 0.7099 - val_accuracy: 0.5248\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6513 - accuracy: 0.6093 - val_loss: 0.7256 - val_accuracy: 0.5279\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6531 - accuracy: 0.6080 - val_loss: 0.7235 - val_accuracy: 0.5238\n","Epoch 76/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6500 - accuracy: 0.6101 - val_loss: 0.7239 - val_accuracy: 0.5238\n","Epoch 77/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6503 - accuracy: 0.6111 - val_loss: 0.7174 - val_accuracy: 0.5320\n","Epoch 78/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6473 - accuracy: 0.6155 - val_loss: 0.7223 - val_accuracy: 0.5279\n","Epoch 79/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6454 - accuracy: 0.6124 - val_loss: 0.7151 - val_accuracy: 0.5300\n","Epoch 80/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6483 - accuracy: 0.6085 - val_loss: 0.7162 - val_accuracy: 0.5269\n","Epoch 81/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6437 - accuracy: 0.6186 - val_loss: 0.7241 - val_accuracy: 0.5310\n","Epoch 82/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6436 - accuracy: 0.6173 - val_loss: 0.7213 - val_accuracy: 0.5289\n","Epoch 83/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6453 - accuracy: 0.6129 - val_loss: 0.7245 - val_accuracy: 0.5320\n","Epoch 84/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6425 - accuracy: 0.6173 - val_loss: 0.7219 - val_accuracy: 0.5341\n","Epoch 85/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6411 - accuracy: 0.6227 - val_loss: 0.7248 - val_accuracy: 0.5300\n","Epoch 86/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6423 - accuracy: 0.6202 - val_loss: 0.7176 - val_accuracy: 0.5331\n","Epoch 87/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6379 - accuracy: 0.6217 - val_loss: 0.7281 - val_accuracy: 0.5248\n","Epoch 88/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6374 - accuracy: 0.6269 - val_loss: 0.7311 - val_accuracy: 0.5351\n","Epoch 89/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6382 - accuracy: 0.6176 - val_loss: 0.7369 - val_accuracy: 0.5341\n","Epoch 90/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6352 - accuracy: 0.6238 - val_loss: 0.7343 - val_accuracy: 0.5310\n","Epoch 91/100\n","31/31 [==============================] - 1s 45ms/step - loss: 0.6342 - accuracy: 0.6194 - val_loss: 0.7308 - val_accuracy: 0.5393\n","Epoch 92/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6337 - accuracy: 0.6289 - val_loss: 0.7440 - val_accuracy: 0.5331\n","Epoch 93/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6314 - accuracy: 0.6181 - val_loss: 0.7434 - val_accuracy: 0.5331\n","Epoch 94/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6321 - accuracy: 0.6269 - val_loss: 0.7490 - val_accuracy: 0.5279\n","Epoch 95/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6299 - accuracy: 0.6227 - val_loss: 0.7445 - val_accuracy: 0.5341\n","Epoch 96/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6286 - accuracy: 0.6282 - val_loss: 0.7504 - val_accuracy: 0.5300\n","Epoch 97/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6272 - accuracy: 0.6331 - val_loss: 0.7537 - val_accuracy: 0.5289\n","Epoch 98/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6244 - accuracy: 0.6318 - val_loss: 0.7498 - val_accuracy: 0.5248\n","Epoch 99/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6286 - accuracy: 0.6227 - val_loss: 0.7559 - val_accuracy: 0.5196\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6227 - accuracy: 0.6341 - val_loss: 0.7539 - val_accuracy: 0.5310\n","{'loss': [0.6931422352790833, 0.6930818557739258, 0.6930117607116699, 0.692899227142334, 0.6927623152732849, 0.6925532221794128, 0.6922246813774109, 0.6918571591377258, 0.6912714242935181, 0.6906955242156982, 0.6901138424873352, 0.6896636486053467, 0.6892056465148926, 0.6888665556907654, 0.6888201236724854, 0.6885637640953064, 0.6884653568267822, 0.6881169080734253, 0.6875207424163818, 0.6873096823692322, 0.6868728399276733, 0.686228334903717, 0.6859427094459534, 0.6854568123817444, 0.6848790645599365, 0.684414803981781, 0.6839966177940369, 0.6832398772239685, 0.68276447057724, 0.6821688413619995, 0.6813210248947144, 0.6808967590332031, 0.6806321144104004, 0.6798269748687744, 0.678861141204834, 0.677337646484375, 0.6772741079330444, 0.6765310764312744, 0.6758236289024353, 0.6747756600379944, 0.6755554676055908, 0.6748192310333252, 0.6741505265235901, 0.6732794046401978, 0.6726114153862, 0.6712895035743713, 0.6704410910606384, 0.6698616743087769, 0.6693112254142761, 0.6688485145568848, 0.6672337055206299, 0.6679468154907227, 0.6668321490287781, 0.6660995483398438, 0.6652466058731079, 0.6652443408966064, 0.6646322011947632, 0.663135826587677, 0.66256183385849, 0.6606559753417969, 0.6608165502548218, 0.6587953567504883, 0.6603329181671143, 0.6599592566490173, 0.6578854322433472, 0.6599907279014587, 0.656394898891449, 0.6570842266082764, 0.656338095664978, 0.656035304069519, 0.6554669141769409, 0.6524198651313782, 0.6514175534248352, 0.6513062119483948, 0.6530527472496033, 0.6499539613723755, 0.650334358215332, 0.6473081707954407, 0.645407497882843, 0.6483154892921448, 0.6436647772789001, 0.6435970067977905, 0.6452616453170776, 0.6424539685249329, 0.6410520076751709, 0.6423071026802063, 0.6379145979881287, 0.6374480128288269, 0.6382256746292114, 0.6351673007011414, 0.6342235207557678, 0.6337023377418518, 0.6314007043838501, 0.6321208477020264, 0.6299143433570862, 0.6285723447799683, 0.6271976232528687, 0.6243810653686523, 0.628596305847168, 0.6226509213447571], 'accuracy': [0.5051679611206055, 0.5307493805885315, 0.5392764806747437, 0.5428940653800964, 0.5400516986846924, 0.538759708404541, 0.5421188473701477, 0.5361757278442383, 0.5364341139793396, 0.5372093319892883, 0.537726104259491, 0.5369508862495422, 0.535917341709137, 0.5382428765296936, 0.5390180945396423, 0.538759708404541, 0.5441860556602478, 0.5465116500854492, 0.5496124029159546, 0.5457364320755005, 0.5452196598052979, 0.5475451946258545, 0.5501291751861572, 0.55374675989151, 0.5534883737564087, 0.5555555820465088, 0.5591731071472168, 0.5596899390220642, 0.5633074641227722, 0.5581395626068115, 0.5602067112922668, 0.566925048828125, 0.5609819293022156, 0.5682170391082764, 0.5695090293884277, 0.569767415523529, 0.5692506432533264, 0.566925048828125, 0.5718346238136292, 0.565116286277771, 0.5739018321037292, 0.5708010196685791, 0.5726098418235779, 0.5767441987991333, 0.5708010196685791, 0.5775193572044373, 0.5795865654945374, 0.5777778029441833, 0.5813953280448914, 0.5775193572044373, 0.5842377543449402, 0.5875968933105469, 0.5868217349052429, 0.5832041501998901, 0.5883721113204956, 0.5837209224700928, 0.5844961404800415, 0.592506468296051, 0.5904392600059509, 0.5987080335617065, 0.5927648544311523, 0.5979328155517578, 0.5901808738708496, 0.5919896364212036, 0.5976744294166565, 0.5935400724411011, 0.5935400724411011, 0.5961240530014038, 0.6031007766723633, 0.6069767475128174, 0.6005167961120605, 0.6049095392227173, 0.6080103516578674, 0.6093023419380188, 0.6080103516578674, 0.6100775003433228, 0.6111111044883728, 0.6155038475990295, 0.6124030947685242, 0.6085271239280701, 0.6186046600341797, 0.6173126697540283, 0.6129198670387268, 0.6173126697540283, 0.6227390170097351, 0.6201550364494324, 0.6217054128646851, 0.6268733739852905, 0.6175710558891296, 0.6237726211547852, 0.6193798184394836, 0.6289405822753906, 0.6180878281593323, 0.6268733739852905, 0.6227390170097351, 0.6281653642654419, 0.633074939250946, 0.6317829489707947, 0.6227390170097351, 0.6341085433959961], 'val_loss': [0.6931365728378296, 0.6931239366531372, 0.6931078433990479, 0.693096935749054, 0.6930830478668213, 0.6930641531944275, 0.693030834197998, 0.6929863095283508, 0.6929382681846619, 0.6928735375404358, 0.692814290523529, 0.6927856802940369, 0.6927911043167114, 0.6928151845932007, 0.6929327845573425, 0.6929824352264404, 0.692992091178894, 0.6933158040046692, 0.6933303475379944, 0.6935664415359497, 0.6940056681632996, 0.694208562374115, 0.6941679120063782, 0.6945556402206421, 0.6951106190681458, 0.695306658744812, 0.6951982975006104, 0.695969820022583, 0.6962506771087646, 0.6952884197235107, 0.6959870457649231, 0.6961970329284668, 0.6973960399627686, 0.6953571438789368, 0.6965017914772034, 0.6962020397186279, 0.697174072265625, 0.696663498878479, 0.6987189054489136, 0.6967458128929138, 0.7002512812614441, 0.6974287629127502, 0.6996914148330688, 0.6973004341125488, 0.6996358036994934, 0.6978748440742493, 0.7001272439956665, 0.6987056732177734, 0.6968282461166382, 0.696590781211853, 0.703960657119751, 0.7017208337783813, 0.7049208879470825, 0.6973813772201538, 0.6995654702186584, 0.6983171105384827, 0.7020505666732788, 0.7031038403511047, 0.7095624208450317, 0.709592342376709, 0.7047737240791321, 0.7104892134666443, 0.7080960869789124, 0.7045978903770447, 0.7073589563369751, 0.7079059481620789, 0.7165265679359436, 0.7154378890991211, 0.7198098301887512, 0.7132501602172852, 0.7152314186096191, 0.7145750522613525, 0.7098615765571594, 0.7256028652191162, 0.7235223054885864, 0.7238908410072327, 0.7174310684204102, 0.7223088145256042, 0.7150814533233643, 0.7161760330200195, 0.7241262793540955, 0.7212567329406738, 0.7244882583618164, 0.7219263315200806, 0.7247607111930847, 0.717605710029602, 0.7280997037887573, 0.7311403155326843, 0.7369225025177002, 0.734304666519165, 0.73081374168396, 0.7439695596694946, 0.7434284687042236, 0.7490494847297668, 0.7444710731506348, 0.7503909468650818, 0.7537499666213989, 0.7497878670692444, 0.7558783888816833, 0.7538954019546509], 'val_accuracy': [0.5165289044380188, 0.5165289044380188, 0.5165289044380188, 0.5092975497245789, 0.5123966932296753, 0.5175619721412659, 0.5216942429542542, 0.5154958963394165, 0.5185950398445129, 0.5216942429542542, 0.5258264541625977, 0.5309917330741882, 0.5268595218658447, 0.5268595218658447, 0.5247933864593506, 0.5227272510528564, 0.5247933864593506, 0.5289255976676941, 0.5247933864593506, 0.5227272510528564, 0.5227272510528564, 0.5258264541625977, 0.5237603187561035, 0.5278925895690918, 0.5309917330741882, 0.5278925895690918, 0.5309917330741882, 0.5289255976676941, 0.5320248007774353, 0.5289255976676941, 0.5299586653709412, 0.5299586653709412, 0.5330578684806824, 0.5278925895690918, 0.5340909361839294, 0.5340909361839294, 0.5351239442825317, 0.5330578684806824, 0.5340909361839294, 0.5351239442825317, 0.5278925895690918, 0.5299586653709412, 0.5340909361839294, 0.5351239442825317, 0.5268595218658447, 0.5278925895690918, 0.5268595218658447, 0.5330578684806824, 0.5289255976676941, 0.5258264541625977, 0.5247933864593506, 0.5258264541625977, 0.5247933864593506, 0.5309917330741882, 0.5258264541625977, 0.5268595218658447, 0.51962810754776, 0.5227272510528564, 0.5165289044380188, 0.5227272510528564, 0.5175619721412659, 0.5185950398445129, 0.5206611752510071, 0.5268595218658447, 0.5247933864593506, 0.5268595218658447, 0.5237603187561035, 0.5247933864593506, 0.5227272510528564, 0.5268595218658447, 0.5289255976676941, 0.5237603187561035, 0.5247933864593506, 0.5278925895690918, 0.5237603187561035, 0.5237603187561035, 0.5320248007774353, 0.5278925895690918, 0.5299586653709412, 0.5268595218658447, 0.5309917330741882, 0.5289255976676941, 0.5320248007774353, 0.5340909361839294, 0.5299586653709412, 0.5330578684806824, 0.5247933864593506, 0.5351239442825317, 0.5340909361839294, 0.5309917330741882, 0.53925621509552, 0.5330578684806824, 0.5330578684806824, 0.5278925895690918, 0.5340909361839294, 0.5299586653709412, 0.5289255976676941, 0.5247933864593506, 0.51962810754776, 0.5309917330741882]}\n","32/32 [==============================] - 1s 8ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.6667 - accuracy: 0.5884"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 10s 51ms/step - loss: 0.6667 - accuracy: 0.5884 - val_loss: 0.6905 - val_accuracy: 0.5269\n","Epoch 2/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6579 - accuracy: 0.5991 - val_loss: 0.6900 - val_accuracy: 0.5269\n","Epoch 3/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.6552 - accuracy: 0.5959 - val_loss: 0.6899 - val_accuracy: 0.5334\n","Epoch 4/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6516 - accuracy: 0.6051 - val_loss: 0.6898 - val_accuracy: 0.5312\n","Epoch 5/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6506 - accuracy: 0.6072 - val_loss: 0.6893 - val_accuracy: 0.5334\n","Epoch 6/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6485 - accuracy: 0.6040 - val_loss: 0.6884 - val_accuracy: 0.5614\n","Epoch 7/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.6461 - accuracy: 0.6172 - val_loss: 0.6872 - val_accuracy: 0.5679\n","Epoch 8/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6464 - accuracy: 0.6083 - val_loss: 0.6873 - val_accuracy: 0.5690\n","Epoch 9/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6458 - accuracy: 0.6115 - val_loss: 0.6870 - val_accuracy: 0.5657\n","Epoch 10/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6453 - accuracy: 0.6158 - val_loss: 0.6859 - val_accuracy: 0.5754\n","Epoch 11/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6427 - accuracy: 0.6153 - val_loss: 0.6852 - val_accuracy: 0.5744\n","Epoch 12/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6416 - accuracy: 0.6140 - val_loss: 0.6842 - val_accuracy: 0.5787\n","Epoch 13/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6402 - accuracy: 0.6083 - val_loss: 0.6839 - val_accuracy: 0.5754\n","Epoch 14/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6376 - accuracy: 0.6166 - val_loss: 0.6811 - val_accuracy: 0.5797\n","Epoch 15/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6363 - accuracy: 0.6161 - val_loss: 0.6824 - val_accuracy: 0.5797\n","Epoch 16/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6370 - accuracy: 0.6199 - val_loss: 0.6815 - val_accuracy: 0.5754\n","Epoch 17/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6343 - accuracy: 0.6220 - val_loss: 0.6808 - val_accuracy: 0.5700\n","Epoch 18/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6345 - accuracy: 0.6156 - val_loss: 0.6835 - val_accuracy: 0.5722\n","Epoch 19/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6291 - accuracy: 0.6272 - val_loss: 0.6812 - val_accuracy: 0.5776\n","Epoch 20/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6303 - accuracy: 0.6188 - val_loss: 0.6837 - val_accuracy: 0.5711\n","Epoch 21/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6281 - accuracy: 0.6288 - val_loss: 0.6841 - val_accuracy: 0.5744\n","Epoch 22/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6268 - accuracy: 0.6274 - val_loss: 0.6855 - val_accuracy: 0.5819\n","Epoch 23/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6249 - accuracy: 0.6288 - val_loss: 0.6840 - val_accuracy: 0.5873\n","Epoch 24/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6250 - accuracy: 0.6274 - val_loss: 0.6944 - val_accuracy: 0.5819\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6272 - accuracy: 0.6288 - val_loss: 0.6945 - val_accuracy: 0.5776\n","Epoch 26/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6230 - accuracy: 0.6355 - val_loss: 0.6890 - val_accuracy: 0.5884\n","Epoch 27/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6250 - accuracy: 0.6312 - val_loss: 0.6944 - val_accuracy: 0.5797\n","Epoch 28/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6193 - accuracy: 0.6315 - val_loss: 0.6977 - val_accuracy: 0.5808\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6188 - accuracy: 0.6398 - val_loss: 0.6974 - val_accuracy: 0.5797\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6189 - accuracy: 0.6334 - val_loss: 0.7017 - val_accuracy: 0.5819\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6171 - accuracy: 0.6371 - val_loss: 0.7033 - val_accuracy: 0.5776\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6137 - accuracy: 0.6414 - val_loss: 0.7013 - val_accuracy: 0.5841\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6132 - accuracy: 0.6398 - val_loss: 0.7120 - val_accuracy: 0.5754\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6154 - accuracy: 0.6382 - val_loss: 0.7065 - val_accuracy: 0.5679\n","Epoch 35/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6142 - accuracy: 0.6371 - val_loss: 0.7114 - val_accuracy: 0.5711\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6113 - accuracy: 0.6401 - val_loss: 0.7097 - val_accuracy: 0.5830\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6138 - accuracy: 0.6482 - val_loss: 0.7106 - val_accuracy: 0.5744\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6129 - accuracy: 0.6433 - val_loss: 0.7140 - val_accuracy: 0.5808\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6067 - accuracy: 0.6441 - val_loss: 0.7088 - val_accuracy: 0.5808\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6074 - accuracy: 0.6420 - val_loss: 0.7132 - val_accuracy: 0.5765\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6028 - accuracy: 0.6579 - val_loss: 0.7106 - val_accuracy: 0.5819\n","Epoch 42/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6059 - accuracy: 0.6527 - val_loss: 0.7207 - val_accuracy: 0.5905\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6051 - accuracy: 0.6401 - val_loss: 0.7163 - val_accuracy: 0.5830\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6000 - accuracy: 0.6536 - val_loss: 0.7295 - val_accuracy: 0.5776\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6053 - accuracy: 0.6538 - val_loss: 0.7233 - val_accuracy: 0.5797\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6003 - accuracy: 0.6538 - val_loss: 0.7212 - val_accuracy: 0.5841\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5968 - accuracy: 0.6630 - val_loss: 0.7247 - val_accuracy: 0.5797\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5981 - accuracy: 0.6584 - val_loss: 0.7321 - val_accuracy: 0.5787\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5994 - accuracy: 0.6525 - val_loss: 0.7285 - val_accuracy: 0.5819\n","Epoch 50/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.5933 - accuracy: 0.6562 - val_loss: 0.7271 - val_accuracy: 0.5851\n","Epoch 51/100\n","29/29 [==============================] - 1s 38ms/step - loss: 0.5949 - accuracy: 0.6600 - val_loss: 0.7326 - val_accuracy: 0.5744\n","Epoch 52/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5941 - accuracy: 0.6587 - val_loss: 0.7368 - val_accuracy: 0.5711\n","Epoch 53/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5932 - accuracy: 0.6668 - val_loss: 0.7485 - val_accuracy: 0.5754\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5907 - accuracy: 0.6705 - val_loss: 0.7349 - val_accuracy: 0.5819\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5900 - accuracy: 0.6643 - val_loss: 0.7463 - val_accuracy: 0.5722\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5887 - accuracy: 0.6673 - val_loss: 0.7350 - val_accuracy: 0.5744\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5909 - accuracy: 0.6657 - val_loss: 0.7442 - val_accuracy: 0.5700\n","Epoch 58/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5864 - accuracy: 0.6692 - val_loss: 0.7414 - val_accuracy: 0.5765\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5866 - accuracy: 0.6659 - val_loss: 0.7464 - val_accuracy: 0.5690\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5854 - accuracy: 0.6705 - val_loss: 0.7410 - val_accuracy: 0.5744\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5831 - accuracy: 0.6732 - val_loss: 0.7511 - val_accuracy: 0.5851\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5799 - accuracy: 0.6649 - val_loss: 0.7459 - val_accuracy: 0.5797\n","Epoch 63/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5811 - accuracy: 0.6697 - val_loss: 0.7418 - val_accuracy: 0.5776\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5811 - accuracy: 0.6708 - val_loss: 0.7460 - val_accuracy: 0.5873\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5805 - accuracy: 0.6735 - val_loss: 0.7441 - val_accuracy: 0.5765\n","Epoch 66/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5771 - accuracy: 0.6783 - val_loss: 0.7507 - val_accuracy: 0.5873\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5772 - accuracy: 0.6835 - val_loss: 0.7543 - val_accuracy: 0.5819\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5802 - accuracy: 0.6713 - val_loss: 0.7552 - val_accuracy: 0.5722\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5741 - accuracy: 0.6843 - val_loss: 0.7644 - val_accuracy: 0.5765\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5688 - accuracy: 0.6864 - val_loss: 0.7504 - val_accuracy: 0.5905\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5672 - accuracy: 0.6875 - val_loss: 0.7621 - val_accuracy: 0.5700\n","Epoch 72/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5731 - accuracy: 0.6835 - val_loss: 0.7646 - val_accuracy: 0.5754\n","Epoch 73/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5681 - accuracy: 0.6856 - val_loss: 0.7625 - val_accuracy: 0.5873\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5722 - accuracy: 0.6791 - val_loss: 0.7652 - val_accuracy: 0.5754\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5700 - accuracy: 0.6859 - val_loss: 0.7628 - val_accuracy: 0.5776\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5627 - accuracy: 0.6827 - val_loss: 0.7681 - val_accuracy: 0.5711\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5658 - accuracy: 0.6867 - val_loss: 0.7747 - val_accuracy: 0.5787\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5645 - accuracy: 0.6864 - val_loss: 0.7881 - val_accuracy: 0.5582\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5620 - accuracy: 0.6937 - val_loss: 0.7666 - val_accuracy: 0.5894\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5642 - accuracy: 0.6870 - val_loss: 0.7771 - val_accuracy: 0.5819\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5572 - accuracy: 0.6878 - val_loss: 0.7813 - val_accuracy: 0.5776\n","Epoch 82/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5571 - accuracy: 0.6899 - val_loss: 0.7795 - val_accuracy: 0.5700\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5547 - accuracy: 0.7012 - val_loss: 0.7753 - val_accuracy: 0.5819\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5654 - accuracy: 0.6851 - val_loss: 0.7828 - val_accuracy: 0.5787\n","Epoch 85/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5530 - accuracy: 0.6948 - val_loss: 0.7893 - val_accuracy: 0.5765\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5519 - accuracy: 0.6996 - val_loss: 0.8003 - val_accuracy: 0.5819\n","Epoch 87/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5517 - accuracy: 0.7026 - val_loss: 0.7908 - val_accuracy: 0.5851\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5506 - accuracy: 0.6980 - val_loss: 0.7932 - val_accuracy: 0.5884\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5456 - accuracy: 0.6902 - val_loss: 0.7935 - val_accuracy: 0.5894\n","Epoch 90/100\n","29/29 [==============================] - 1s 44ms/step - loss: 0.5487 - accuracy: 0.7045 - val_loss: 0.7867 - val_accuracy: 0.5927\n","Epoch 91/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5516 - accuracy: 0.7053 - val_loss: 0.7925 - val_accuracy: 0.5948\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5414 - accuracy: 0.7088 - val_loss: 0.7928 - val_accuracy: 0.5916\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5462 - accuracy: 0.7010 - val_loss: 0.8282 - val_accuracy: 0.5550\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5410 - accuracy: 0.7072 - val_loss: 0.7943 - val_accuracy: 0.5787\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5435 - accuracy: 0.7031 - val_loss: 0.7986 - val_accuracy: 0.5873\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5455 - accuracy: 0.6945 - val_loss: 0.8076 - val_accuracy: 0.5819\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5449 - accuracy: 0.6950 - val_loss: 0.8192 - val_accuracy: 0.5787\n","Epoch 98/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5389 - accuracy: 0.7045 - val_loss: 0.8061 - val_accuracy: 0.6013\n","Epoch 99/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5335 - accuracy: 0.7158 - val_loss: 0.8171 - val_accuracy: 0.5722\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5382 - accuracy: 0.7047 - val_loss: 0.8218 - val_accuracy: 0.5808\n","{'loss': [0.6667063236236572, 0.6579042077064514, 0.6552250385284424, 0.6515627503395081, 0.6505836248397827, 0.6485171318054199, 0.6460506319999695, 0.6464475989341736, 0.6457525491714478, 0.645305871963501, 0.6427406668663025, 0.6415743231773376, 0.6401785016059875, 0.6376248002052307, 0.6363101601600647, 0.636957049369812, 0.6343156099319458, 0.6344679594039917, 0.629082441329956, 0.630307674407959, 0.6280611157417297, 0.626819372177124, 0.6248787045478821, 0.6249819397926331, 0.6271974444389343, 0.6230259537696838, 0.6250050663948059, 0.6193442940711975, 0.6188055276870728, 0.6188799142837524, 0.6171481013298035, 0.6137211918830872, 0.6131813526153564, 0.6154497861862183, 0.6142457723617554, 0.6113045811653137, 0.6138110160827637, 0.6129039525985718, 0.6066564917564392, 0.6074241995811462, 0.6027557849884033, 0.6059430837631226, 0.6051157712936401, 0.5999778509140015, 0.6053352952003479, 0.6003261804580688, 0.5967618227005005, 0.5980635285377502, 0.5994126796722412, 0.5933271050453186, 0.5949268937110901, 0.5940737128257751, 0.5932327508926392, 0.5906774401664734, 0.5900136828422546, 0.5887039303779602, 0.5909488797187805, 0.586395800113678, 0.5866304636001587, 0.5854229927062988, 0.5831462740898132, 0.5798798203468323, 0.5810540914535522, 0.5810836553573608, 0.5805455446243286, 0.577126681804657, 0.5771850347518921, 0.5801741480827332, 0.5741376280784607, 0.5687843561172485, 0.567183256149292, 0.5730550289154053, 0.5680986046791077, 0.5722255706787109, 0.5699818134307861, 0.5626964569091797, 0.5657593011856079, 0.5644579529762268, 0.5620269179344177, 0.5641863346099854, 0.557228147983551, 0.5570608973503113, 0.554715096950531, 0.565435528755188, 0.5530308485031128, 0.5518600940704346, 0.5517397522926331, 0.550637423992157, 0.5455535650253296, 0.5487287044525146, 0.5516367554664612, 0.5413953065872192, 0.5462278723716736, 0.5410347580909729, 0.5434936285018921, 0.5455359220504761, 0.5448750257492065, 0.5389280319213867, 0.5335003137588501, 0.5382351279258728], 'accuracy': [0.5883620977401733, 0.5991379022598267, 0.5959051847457886, 0.6050646305084229, 0.6072198152542114, 0.6039870977401733, 0.6171875, 0.6082974076271057, 0.6115301847457886, 0.615840494632721, 0.6153017282485962, 0.6139547228813171, 0.6082974076271057, 0.6166487336158752, 0.6161099076271057, 0.6198814511299133, 0.6220366358757019, 0.615571141242981, 0.6271551847457886, 0.618803858757019, 0.6287715435028076, 0.6274245977401733, 0.6287715435028076, 0.6274245977401733, 0.6287715435028076, 0.6355064511299133, 0.631196141242981, 0.631465494632721, 0.6398168206214905, 0.6333512663841248, 0.6371228694915771, 0.6414331793785095, 0.6398168206214905, 0.6382004022598267, 0.6371228694915771, 0.6400862336158752, 0.6481680870056152, 0.6433189511299133, 0.6441271305084229, 0.641972005367279, 0.657866358757019, 0.6527478694915771, 0.6400862336158752, 0.6535560488700867, 0.6538254022598267, 0.6538254022598267, 0.6629849076271057, 0.6584051847457886, 0.6524784564971924, 0.65625, 0.6600215435028076, 0.6586745977401733, 0.6667564511299133, 0.670527994632721, 0.6643319129943848, 0.6672952771186829, 0.665678858757019, 0.6691810488700867, 0.6659482717514038, 0.670527994632721, 0.673222005367279, 0.6648706793785095, 0.6697198152542114, 0.6707974076271057, 0.673491358757019, 0.678340494632721, 0.6834590435028076, 0.6713362336158752, 0.6842672228813171, 0.6864224076271057, 0.6875, 0.6834590435028076, 0.6856142282485962, 0.6791487336158752, 0.685883641242981, 0.6826508641242981, 0.6866918206214905, 0.6864224076271057, 0.693696141242981, 0.6869612336158752, 0.6877694129943848, 0.6899245977401733, 0.7012392282485962, 0.6850754022598267, 0.6947737336158752, 0.6996228694915771, 0.7025862336158752, 0.6980064511299133, 0.6901939511299133, 0.704472005367279, 0.7052801847457886, 0.7087823152542114, 0.7009698152542114, 0.7071659564971924, 0.703125, 0.6945043206214905, 0.6950430870056152, 0.704472005367279, 0.7157866358757019, 0.704741358757019], 'val_loss': [0.6905186772346497, 0.6900206208229065, 0.6899226903915405, 0.689844012260437, 0.6892978549003601, 0.688414990901947, 0.687211811542511, 0.6872550845146179, 0.6870086789131165, 0.6859111189842224, 0.6852490901947021, 0.6842371225357056, 0.6838905215263367, 0.6810913681983948, 0.6823899745941162, 0.6815410852432251, 0.6807812452316284, 0.6835348010063171, 0.6811816692352295, 0.6836615204811096, 0.6840591430664062, 0.6855049133300781, 0.6839590668678284, 0.6943793892860413, 0.6944887042045593, 0.689009428024292, 0.6943669319152832, 0.6977232098579407, 0.6973958015441895, 0.7017461657524109, 0.7032908797264099, 0.7012662291526794, 0.712011456489563, 0.7065489292144775, 0.7113692164421082, 0.7097433805465698, 0.7106437087059021, 0.7139647006988525, 0.708821713924408, 0.7132152318954468, 0.7106472253799438, 0.7207496762275696, 0.7162965536117554, 0.7294838428497314, 0.7233082056045532, 0.7212094068527222, 0.7246564030647278, 0.7321266531944275, 0.7284842133522034, 0.7270636558532715, 0.7326340079307556, 0.7368356585502625, 0.748491108417511, 0.7348830699920654, 0.7462754249572754, 0.7350119352340698, 0.7442046999931335, 0.7414150834083557, 0.7464407086372375, 0.7410029768943787, 0.7510796785354614, 0.7458802461624146, 0.7418369650840759, 0.746006429195404, 0.7441306114196777, 0.7507150769233704, 0.7542856335639954, 0.7551862597465515, 0.7644248008728027, 0.7504347562789917, 0.7620819211006165, 0.7646153569221497, 0.7624709606170654, 0.7652360796928406, 0.7628443241119385, 0.7681440711021423, 0.774680495262146, 0.7881075143814087, 0.7666123509407043, 0.7770992517471313, 0.7812901735305786, 0.7794851660728455, 0.7753303647041321, 0.782800018787384, 0.7892710566520691, 0.8003010153770447, 0.7907905578613281, 0.7931675910949707, 0.7934837937355042, 0.7867105007171631, 0.7924767732620239, 0.7927806973457336, 0.8282005786895752, 0.7943176627159119, 0.7986269593238831, 0.8076244592666626, 0.819206953048706, 0.8060622215270996, 0.8170729279518127, 0.8217624425888062], 'val_accuracy': [0.5269396305084229, 0.5269396305084229, 0.5334051847457886, 0.53125, 0.5334051847457886, 0.5614224076271057, 0.5678879022598267, 0.568965494632721, 0.5657327771186829, 0.5754310488700867, 0.5743534564971924, 0.5786637663841248, 0.5754310488700867, 0.579741358757019, 0.579741358757019, 0.5754310488700867, 0.5700430870056152, 0.5721982717514038, 0.5775862336158752, 0.5711206793785095, 0.5743534564971924, 0.5818965435028076, 0.587284505367279, 0.5818965435028076, 0.5775862336158752, 0.5883620977401733, 0.579741358757019, 0.5808189511299133, 0.579741358757019, 0.5818965435028076, 0.5775862336158752, 0.5840517282485962, 0.5754310488700867, 0.5678879022598267, 0.5711206793785095, 0.5829741358757019, 0.5743534564971924, 0.5808189511299133, 0.5808189511299133, 0.576508641242981, 0.5818965435028076, 0.5905172228813171, 0.5829741358757019, 0.5775862336158752, 0.579741358757019, 0.5840517282485962, 0.579741358757019, 0.5786637663841248, 0.5818965435028076, 0.5851293206214905, 0.5743534564971924, 0.5711206793785095, 0.5754310488700867, 0.5818965435028076, 0.5721982717514038, 0.5743534564971924, 0.5700430870056152, 0.576508641242981, 0.568965494632721, 0.5743534564971924, 0.5851293206214905, 0.579741358757019, 0.5775862336158752, 0.587284505367279, 0.576508641242981, 0.587284505367279, 0.5818965435028076, 0.5721982717514038, 0.576508641242981, 0.5905172228813171, 0.5700430870056152, 0.5754310488700867, 0.587284505367279, 0.5754310488700867, 0.5775862336158752, 0.5711206793785095, 0.5786637663841248, 0.5581896305084229, 0.5894396305084229, 0.5818965435028076, 0.5775862336158752, 0.5700430870056152, 0.5818965435028076, 0.5786637663841248, 0.576508641242981, 0.5818965435028076, 0.5851293206214905, 0.5883620977401733, 0.5894396305084229, 0.5926724076271057, 0.5948275923728943, 0.5915948152542114, 0.5549569129943848, 0.5786637663841248, 0.587284505367279, 0.5818965435028076, 0.5786637663841248, 0.6012930870056152, 0.5721982717514038, 0.5808189511299133]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.6621 - accuracy: 0.5772"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 9s 62ms/step - loss: 0.6609 - accuracy: 0.5829 - val_loss: 0.6913 - val_accuracy: 0.5102\n","Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6512 - accuracy: 0.6055 - val_loss: 0.6910 - val_accuracy: 0.5124\n","Epoch 3/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6510 - accuracy: 0.6106 - val_loss: 0.6912 - val_accuracy: 0.5090\n","Epoch 4/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6506 - accuracy: 0.6081 - val_loss: 0.6894 - val_accuracy: 0.5351\n","Epoch 5/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6490 - accuracy: 0.6112 - val_loss: 0.6891 - val_accuracy: 0.5305\n","Epoch 6/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6467 - accuracy: 0.6160 - val_loss: 0.6891 - val_accuracy: 0.5260\n","Epoch 7/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6443 - accuracy: 0.6101 - val_loss: 0.6876 - val_accuracy: 0.5430\n","Epoch 8/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6468 - accuracy: 0.6106 - val_loss: 0.6870 - val_accuracy: 0.5407\n","Epoch 9/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6424 - accuracy: 0.6160 - val_loss: 0.6858 - val_accuracy: 0.5520\n","Epoch 10/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6410 - accuracy: 0.6143 - val_loss: 0.6852 - val_accuracy: 0.5509\n","Epoch 11/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6421 - accuracy: 0.6126 - val_loss: 0.6832 - val_accuracy: 0.5475\n","Epoch 12/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6381 - accuracy: 0.6217 - val_loss: 0.6818 - val_accuracy: 0.5554\n","Epoch 13/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6384 - accuracy: 0.6197 - val_loss: 0.6804 - val_accuracy: 0.5577\n","Epoch 14/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6384 - accuracy: 0.6169 - val_loss: 0.6785 - val_accuracy: 0.5554\n","Epoch 15/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6387 - accuracy: 0.6205 - val_loss: 0.6758 - val_accuracy: 0.5701\n","Epoch 16/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6354 - accuracy: 0.6177 - val_loss: 0.6794 - val_accuracy: 0.5554\n","Epoch 17/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6359 - accuracy: 0.6268 - val_loss: 0.6754 - val_accuracy: 0.5690\n","Epoch 18/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.6324 - accuracy: 0.6220 - val_loss: 0.6746 - val_accuracy: 0.5747\n","Epoch 19/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6310 - accuracy: 0.6290 - val_loss: 0.6697 - val_accuracy: 0.5905\n","Epoch 20/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6285 - accuracy: 0.6353 - val_loss: 0.6707 - val_accuracy: 0.5871\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6299 - accuracy: 0.6262 - val_loss: 0.6694 - val_accuracy: 0.5860\n","Epoch 22/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6266 - accuracy: 0.6344 - val_loss: 0.6699 - val_accuracy: 0.5905\n","Epoch 23/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.6270 - accuracy: 0.6273 - val_loss: 0.6675 - val_accuracy: 0.5950\n","Epoch 24/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6273 - accuracy: 0.6296 - val_loss: 0.6721 - val_accuracy: 0.5939\n","Epoch 25/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6256 - accuracy: 0.6336 - val_loss: 0.6722 - val_accuracy: 0.5984\n","Epoch 26/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6258 - accuracy: 0.6338 - val_loss: 0.6765 - val_accuracy: 0.5950\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6246 - accuracy: 0.6353 - val_loss: 0.6712 - val_accuracy: 0.5894\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6218 - accuracy: 0.6299 - val_loss: 0.6792 - val_accuracy: 0.5916\n","Epoch 29/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6225 - accuracy: 0.6372 - val_loss: 0.6806 - val_accuracy: 0.6007\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6192 - accuracy: 0.6361 - val_loss: 0.6699 - val_accuracy: 0.6007\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6192 - accuracy: 0.6347 - val_loss: 0.6785 - val_accuracy: 0.5950\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6172 - accuracy: 0.6319 - val_loss: 0.6719 - val_accuracy: 0.5973\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6166 - accuracy: 0.6355 - val_loss: 0.6753 - val_accuracy: 0.5894\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6170 - accuracy: 0.6319 - val_loss: 0.6800 - val_accuracy: 0.5928\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6118 - accuracy: 0.6454 - val_loss: 0.6801 - val_accuracy: 0.6007\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6112 - accuracy: 0.6466 - val_loss: 0.6830 - val_accuracy: 0.5916\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6137 - accuracy: 0.6330 - val_loss: 0.6833 - val_accuracy: 0.5962\n","Epoch 38/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6107 - accuracy: 0.6483 - val_loss: 0.6923 - val_accuracy: 0.5905\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6114 - accuracy: 0.6469 - val_loss: 0.6810 - val_accuracy: 0.5962\n","Epoch 40/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6089 - accuracy: 0.6466 - val_loss: 0.6877 - val_accuracy: 0.6018\n","Epoch 41/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6062 - accuracy: 0.6497 - val_loss: 0.6811 - val_accuracy: 0.6063\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6067 - accuracy: 0.6525 - val_loss: 0.6945 - val_accuracy: 0.5984\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6059 - accuracy: 0.6471 - val_loss: 0.6865 - val_accuracy: 0.6018\n","Epoch 44/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6045 - accuracy: 0.6607 - val_loss: 0.6855 - val_accuracy: 0.6063\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6038 - accuracy: 0.6497 - val_loss: 0.6930 - val_accuracy: 0.6007\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6040 - accuracy: 0.6460 - val_loss: 0.6948 - val_accuracy: 0.5950\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6015 - accuracy: 0.6548 - val_loss: 0.6925 - val_accuracy: 0.5939\n","Epoch 48/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.6003 - accuracy: 0.6542 - val_loss: 0.6966 - val_accuracy: 0.6041\n","Epoch 49/100\n","28/28 [==============================] - 2s 62ms/step - loss: 0.5985 - accuracy: 0.6551 - val_loss: 0.6930 - val_accuracy: 0.6041\n","Epoch 50/100\n","28/28 [==============================] - 1s 47ms/step - loss: 0.6019 - accuracy: 0.6508 - val_loss: 0.6896 - val_accuracy: 0.6041\n","Epoch 51/100\n","28/28 [==============================] - 1s 40ms/step - loss: 0.5967 - accuracy: 0.6568 - val_loss: 0.6964 - val_accuracy: 0.5939\n","Epoch 52/100\n","28/28 [==============================] - 1s 44ms/step - loss: 0.5950 - accuracy: 0.6593 - val_loss: 0.7001 - val_accuracy: 0.5939\n","Epoch 53/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.5965 - accuracy: 0.6596 - val_loss: 0.7070 - val_accuracy: 0.5792\n","Epoch 54/100\n","28/28 [==============================] - 1s 39ms/step - loss: 0.5994 - accuracy: 0.6432 - val_loss: 0.7146 - val_accuracy: 0.5962\n","Epoch 55/100\n","28/28 [==============================] - 2s 74ms/step - loss: 0.5977 - accuracy: 0.6531 - val_loss: 0.7117 - val_accuracy: 0.6143\n","Epoch 56/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5970 - accuracy: 0.6624 - val_loss: 0.7041 - val_accuracy: 0.6052\n","Epoch 57/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5941 - accuracy: 0.6633 - val_loss: 0.7054 - val_accuracy: 0.5995\n","Epoch 58/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5878 - accuracy: 0.6726 - val_loss: 0.7109 - val_accuracy: 0.6086\n","Epoch 59/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5872 - accuracy: 0.6636 - val_loss: 0.7103 - val_accuracy: 0.6052\n","Epoch 60/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5896 - accuracy: 0.6712 - val_loss: 0.7092 - val_accuracy: 0.5995\n","Epoch 61/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.5900 - accuracy: 0.6732 - val_loss: 0.7126 - val_accuracy: 0.6165\n","Epoch 62/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5828 - accuracy: 0.6831 - val_loss: 0.7088 - val_accuracy: 0.5848\n","Epoch 63/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5866 - accuracy: 0.6675 - val_loss: 0.7111 - val_accuracy: 0.6086\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5896 - accuracy: 0.6621 - val_loss: 0.7074 - val_accuracy: 0.5939\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5830 - accuracy: 0.6726 - val_loss: 0.7173 - val_accuracy: 0.6165\n","Epoch 66/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5777 - accuracy: 0.6811 - val_loss: 0.7210 - val_accuracy: 0.5826\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5823 - accuracy: 0.6664 - val_loss: 0.7149 - val_accuracy: 0.6097\n","Epoch 68/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5818 - accuracy: 0.6695 - val_loss: 0.7209 - val_accuracy: 0.5962\n","Epoch 69/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5770 - accuracy: 0.6698 - val_loss: 0.7303 - val_accuracy: 0.6029\n","Epoch 70/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5719 - accuracy: 0.6831 - val_loss: 0.7196 - val_accuracy: 0.5882\n","Epoch 71/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5765 - accuracy: 0.6692 - val_loss: 0.7145 - val_accuracy: 0.5894\n","Epoch 72/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5788 - accuracy: 0.6769 - val_loss: 0.7241 - val_accuracy: 0.6041\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5725 - accuracy: 0.6760 - val_loss: 0.7319 - val_accuracy: 0.6063\n","Epoch 74/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5676 - accuracy: 0.6862 - val_loss: 0.7283 - val_accuracy: 0.5860\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5739 - accuracy: 0.6842 - val_loss: 0.7388 - val_accuracy: 0.5995\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5680 - accuracy: 0.6797 - val_loss: 0.7318 - val_accuracy: 0.5860\n","Epoch 77/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5704 - accuracy: 0.6930 - val_loss: 0.7332 - val_accuracy: 0.5973\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5785 - accuracy: 0.6769 - val_loss: 0.7579 - val_accuracy: 0.5701\n","Epoch 79/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5736 - accuracy: 0.6766 - val_loss: 0.7486 - val_accuracy: 0.5735\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5710 - accuracy: 0.6831 - val_loss: 0.7504 - val_accuracy: 0.5950\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5648 - accuracy: 0.6831 - val_loss: 0.7344 - val_accuracy: 0.5995\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5679 - accuracy: 0.6879 - val_loss: 0.7448 - val_accuracy: 0.5939\n","Epoch 83/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5620 - accuracy: 0.7026 - val_loss: 0.7467 - val_accuracy: 0.5871\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5607 - accuracy: 0.6904 - val_loss: 0.7489 - val_accuracy: 0.5860\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5617 - accuracy: 0.6927 - val_loss: 0.7491 - val_accuracy: 0.5792\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5538 - accuracy: 0.6950 - val_loss: 0.7415 - val_accuracy: 0.5803\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5552 - accuracy: 0.6944 - val_loss: 0.7426 - val_accuracy: 0.5803\n","Epoch 88/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5574 - accuracy: 0.6989 - val_loss: 0.7493 - val_accuracy: 0.5781\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5551 - accuracy: 0.6865 - val_loss: 0.7484 - val_accuracy: 0.5905\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5499 - accuracy: 0.6986 - val_loss: 0.7586 - val_accuracy: 0.5871\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5514 - accuracy: 0.6950 - val_loss: 0.7527 - val_accuracy: 0.5837\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5546 - accuracy: 0.6950 - val_loss: 0.7540 - val_accuracy: 0.5781\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5479 - accuracy: 0.7085 - val_loss: 0.7708 - val_accuracy: 0.5781\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5514 - accuracy: 0.7029 - val_loss: 0.7746 - val_accuracy: 0.5690\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5472 - accuracy: 0.7060 - val_loss: 0.7618 - val_accuracy: 0.5747\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5448 - accuracy: 0.7037 - val_loss: 0.7673 - val_accuracy: 0.5747\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5475 - accuracy: 0.7003 - val_loss: 0.7761 - val_accuracy: 0.5848\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5418 - accuracy: 0.7083 - val_loss: 0.7550 - val_accuracy: 0.5962\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5435 - accuracy: 0.7026 - val_loss: 0.7761 - val_accuracy: 0.5973\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5440 - accuracy: 0.7074 - val_loss: 0.7645 - val_accuracy: 0.5905\n","{'loss': [0.660855233669281, 0.651192843914032, 0.6510355472564697, 0.6505723595619202, 0.6490105986595154, 0.6466637849807739, 0.6442558765411377, 0.6467602849006653, 0.6423811912536621, 0.6409695744514465, 0.6421125531196594, 0.638076663017273, 0.6384407877922058, 0.6384058594703674, 0.6387079954147339, 0.6353872418403625, 0.6358842849731445, 0.6323604583740234, 0.6310093998908997, 0.6284754872322083, 0.6299123167991638, 0.6266398429870605, 0.6270484328269958, 0.6273285150527954, 0.6256389617919922, 0.6257519125938416, 0.6246489882469177, 0.6217895150184631, 0.6224879622459412, 0.6191712021827698, 0.619194746017456, 0.6171965599060059, 0.6166107058525085, 0.617002546787262, 0.6117657423019409, 0.6111761331558228, 0.6136699914932251, 0.6107312440872192, 0.6113505959510803, 0.6088705062866211, 0.6062023043632507, 0.6066927909851074, 0.6058549880981445, 0.6045459508895874, 0.603807270526886, 0.6040316224098206, 0.6014846563339233, 0.6002876162528992, 0.5985304117202759, 0.6019474267959595, 0.5966883301734924, 0.5949866771697998, 0.5965190529823303, 0.5994039177894592, 0.5977079272270203, 0.596984326839447, 0.5940650105476379, 0.5877925157546997, 0.5871995091438293, 0.589638888835907, 0.5899540185928345, 0.5827915072441101, 0.5866202712059021, 0.5895825624465942, 0.5829823017120361, 0.5776755213737488, 0.5823293924331665, 0.5818439722061157, 0.5770325064659119, 0.5718779563903809, 0.5765374302864075, 0.5787546038627625, 0.5724816918373108, 0.5676049590110779, 0.5738661885261536, 0.5679863691329956, 0.5703780651092529, 0.5784586071968079, 0.5735677480697632, 0.5710444450378418, 0.564776599407196, 0.5679230093955994, 0.5620272159576416, 0.5606670379638672, 0.561694324016571, 0.5538177490234375, 0.5552080273628235, 0.5573651790618896, 0.5551146268844604, 0.5499297380447388, 0.5513773560523987, 0.5546183586120605, 0.5479304790496826, 0.5513865947723389, 0.5471891760826111, 0.5447705984115601, 0.5474567413330078, 0.5417811870574951, 0.54353266954422, 0.5439949035644531], 'accuracy': [0.5829088687896729, 0.6055461168289185, 0.6106395125389099, 0.6080927848815918, 0.6112054586410522, 0.6160158514976501, 0.6100735664367676, 0.6106395125389099, 0.6160158514976501, 0.6143180727958679, 0.6126202344894409, 0.6216751337051392, 0.6196944117546082, 0.6168647408485413, 0.6205433011054993, 0.6177136301994324, 0.6267685294151306, 0.6219581365585327, 0.6290322542190552, 0.6352574825286865, 0.6262025833129883, 0.6344085931777954, 0.627334475517273, 0.6295982003211975, 0.6335597038269043, 0.6338426470756531, 0.6352574825286865, 0.6298811435699463, 0.6372382640838623, 0.6361063718795776, 0.634691596031189, 0.6318619251251221, 0.6355404853820801, 0.6318619251251221, 0.6454442739486694, 0.6465761065483093, 0.632993757724762, 0.6482738852500916, 0.6468591094017029, 0.6465761065483093, 0.649688720703125, 0.6525183916091919, 0.6471420526504517, 0.660724401473999, 0.649688720703125, 0.646010160446167, 0.6547821164131165, 0.6542161703109741, 0.6550650596618652, 0.6508206129074097, 0.6567628979682922, 0.6593095660209656, 0.6595925092697144, 0.6431805491447449, 0.6530843377113342, 0.6624221801757812, 0.6632710695266724, 0.6726089119911194, 0.6635540723800659, 0.6711941361427307, 0.6731748580932617, 0.6830786466598511, 0.6675155758857727, 0.6621392369270325, 0.6726089119911194, 0.6810979247093201, 0.666383683681488, 0.6694962978363037, 0.6697793006896973, 0.6830786466598511, 0.6692133545875549, 0.6768534183502197, 0.6760045289993286, 0.6861912608146667, 0.6842105388641357, 0.6796830892562866, 0.6929824352264404, 0.6768534183502197, 0.676570475101471, 0.6830786466598511, 0.6830786466598511, 0.6878890991210938, 0.702603280544281, 0.6904357671737671, 0.6926994919776917, 0.6949632167816162, 0.6943972706794739, 0.698924720287323, 0.6864742636680603, 0.6986417770385742, 0.6949632167816162, 0.6949632167816162, 0.7085455656051636, 0.7028862237930298, 0.7059988975524902, 0.7037351727485657, 0.7003395557403564, 0.70826256275177, 0.702603280544281, 0.7074136734008789], 'val_loss': [0.6912758946418762, 0.6910448670387268, 0.6912044882774353, 0.6894153356552124, 0.6891221404075623, 0.6890614628791809, 0.6876354813575745, 0.6869524121284485, 0.6857762932777405, 0.685194194316864, 0.6832383275032043, 0.6818217039108276, 0.6803610920906067, 0.6784862279891968, 0.6757774353027344, 0.679395854473114, 0.6754197478294373, 0.674593985080719, 0.6696588397026062, 0.6706969141960144, 0.6694003343582153, 0.6698799133300781, 0.6674860119819641, 0.6720668077468872, 0.672247052192688, 0.6765385270118713, 0.6711713075637817, 0.6791731715202332, 0.680618405342102, 0.6699323058128357, 0.6784513592720032, 0.6719382405281067, 0.6752573847770691, 0.6800398826599121, 0.6800634264945984, 0.6829867362976074, 0.6833405494689941, 0.6923497915267944, 0.6809751987457275, 0.6876927614212036, 0.6811131238937378, 0.6944921016693115, 0.6865299940109253, 0.6855443120002747, 0.6929650902748108, 0.6948451399803162, 0.6924823522567749, 0.6966297030448914, 0.6930089592933655, 0.689562201499939, 0.6963984966278076, 0.7000909447669983, 0.7070339322090149, 0.7146105170249939, 0.7117493748664856, 0.704050600528717, 0.7053546905517578, 0.7108864784240723, 0.710332989692688, 0.7091957330703735, 0.7125630974769592, 0.7088244557380676, 0.7110989093780518, 0.7073565721511841, 0.7173370122909546, 0.7209921479225159, 0.7148597240447998, 0.720916211605072, 0.7302690148353577, 0.7196333408355713, 0.7144566774368286, 0.7240824103355408, 0.7318598628044128, 0.7283238172531128, 0.7388176321983337, 0.7318156957626343, 0.7332145571708679, 0.757864773273468, 0.7486244440078735, 0.7504023909568787, 0.7344065308570862, 0.7448147535324097, 0.7467304468154907, 0.7489091157913208, 0.7491077184677124, 0.7414682507514954, 0.7425641417503357, 0.7492510080337524, 0.7483940720558167, 0.7586300373077393, 0.7527289986610413, 0.7539546489715576, 0.7707792520523071, 0.7746179103851318, 0.7618016004562378, 0.7672527432441711, 0.7760983109474182, 0.755023717880249, 0.7760534286499023, 0.7645365595817566], 'val_accuracy': [0.5101810097694397, 0.5124434232711792, 0.5090497732162476, 0.5350678563117981, 0.5305429697036743, 0.5260180830955505, 0.5429864525794983, 0.540723979473114, 0.5520362257957458, 0.5509049892425537, 0.5475113391876221, 0.5554298758506775, 0.557692289352417, 0.5554298758506775, 0.570135772228241, 0.5554298758506775, 0.5690045356750488, 0.5746606588363647, 0.5904977321624756, 0.587104082107544, 0.5859728455543518, 0.5904977321624756, 0.5950226187705994, 0.5938913822174072, 0.598416268825531, 0.5950226187705994, 0.5893664956092834, 0.5916289687156677, 0.6006787419319153, 0.6006787419319153, 0.5950226187705994, 0.5972850918769836, 0.5893664956092834, 0.5927602052688599, 0.6006787419319153, 0.5916289687156677, 0.5961538553237915, 0.5904977321624756, 0.5961538553237915, 0.6018099784851074, 0.6063348650932312, 0.598416268825531, 0.6018099784851074, 0.6063348650932312, 0.6006787419319153, 0.5950226187705994, 0.5938913822174072, 0.6040723919868469, 0.6040723919868469, 0.6040723919868469, 0.5938913822174072, 0.5938913822174072, 0.5791855454444885, 0.5961538553237915, 0.6142534017562866, 0.6052036285400391, 0.5995475053787231, 0.6085972785949707, 0.6052036285400391, 0.5995475053787231, 0.6165158152580261, 0.5848416090011597, 0.6085972785949707, 0.5938913822174072, 0.6165158152580261, 0.5825791954994202, 0.6097285151481628, 0.5961538553237915, 0.6029411554336548, 0.5882353186607361, 0.5893664956092834, 0.6040723919868469, 0.6063348650932312, 0.5859728455543518, 0.5995475053787231, 0.5859728455543518, 0.5972850918769836, 0.570135772228241, 0.5735294222831726, 0.5950226187705994, 0.5995475053787231, 0.5938913822174072, 0.587104082107544, 0.5859728455543518, 0.5791855454444885, 0.5803167223930359, 0.5803167223930359, 0.5780543088912964, 0.5904977321624756, 0.587104082107544, 0.5837104320526123, 0.5780543088912964, 0.5780543088912964, 0.5690045356750488, 0.5746606588363647, 0.5746606588363647, 0.5848416090011597, 0.5961538553237915, 0.5972850918769836, 0.5904977321624756]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.6647 - accuracy: 0.5943"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 10s 75ms/step - loss: 0.6641 - accuracy: 0.5941 - val_loss: 0.6914 - val_accuracy: 0.5217\n","Epoch 2/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6535 - accuracy: 0.5990 - val_loss: 0.6915 - val_accuracy: 0.5176\n","Epoch 3/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6526 - accuracy: 0.6047 - val_loss: 0.6913 - val_accuracy: 0.5217\n","Epoch 4/100\n","31/31 [==============================] - 1s 48ms/step - loss: 0.6518 - accuracy: 0.6101 - val_loss: 0.6910 - val_accuracy: 0.5269\n","Epoch 5/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.6510 - accuracy: 0.6067 - val_loss: 0.6910 - val_accuracy: 0.5258\n","Epoch 6/100\n","31/31 [==============================] - 1s 45ms/step - loss: 0.6504 - accuracy: 0.6142 - val_loss: 0.6901 - val_accuracy: 0.5362\n","Epoch 7/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6465 - accuracy: 0.6147 - val_loss: 0.6899 - val_accuracy: 0.5362\n","Epoch 8/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6465 - accuracy: 0.6145 - val_loss: 0.6893 - val_accuracy: 0.5362\n","Epoch 9/100\n","31/31 [==============================] - 1s 38ms/step - loss: 0.6461 - accuracy: 0.6127 - val_loss: 0.6886 - val_accuracy: 0.5413\n","Epoch 10/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6457 - accuracy: 0.6207 - val_loss: 0.6878 - val_accuracy: 0.5413\n","Epoch 11/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6470 - accuracy: 0.6142 - val_loss: 0.6876 - val_accuracy: 0.5444\n","Epoch 12/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6443 - accuracy: 0.6132 - val_loss: 0.6869 - val_accuracy: 0.5434\n","Epoch 13/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6394 - accuracy: 0.6256 - val_loss: 0.6871 - val_accuracy: 0.5558\n","Epoch 14/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6396 - accuracy: 0.6202 - val_loss: 0.6860 - val_accuracy: 0.5537\n","Epoch 15/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6390 - accuracy: 0.6253 - val_loss: 0.6853 - val_accuracy: 0.5455\n","Epoch 16/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6372 - accuracy: 0.6176 - val_loss: 0.6867 - val_accuracy: 0.5671\n","Epoch 17/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6382 - accuracy: 0.6233 - val_loss: 0.6853 - val_accuracy: 0.5558\n","Epoch 18/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6385 - accuracy: 0.6191 - val_loss: 0.6857 - val_accuracy: 0.5661\n","Epoch 19/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6362 - accuracy: 0.6214 - val_loss: 0.6871 - val_accuracy: 0.5640\n","Epoch 20/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6365 - accuracy: 0.6191 - val_loss: 0.6913 - val_accuracy: 0.5713\n","Epoch 21/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6333 - accuracy: 0.6165 - val_loss: 0.6921 - val_accuracy: 0.5610\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6327 - accuracy: 0.6230 - val_loss: 0.6980 - val_accuracy: 0.5599\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6295 - accuracy: 0.6217 - val_loss: 0.7059 - val_accuracy: 0.5640\n","Epoch 24/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6299 - accuracy: 0.6292 - val_loss: 0.6964 - val_accuracy: 0.5671\n","Epoch 25/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6303 - accuracy: 0.6328 - val_loss: 0.6938 - val_accuracy: 0.5568\n","Epoch 26/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6299 - accuracy: 0.6264 - val_loss: 0.6993 - val_accuracy: 0.5589\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6321 - accuracy: 0.6346 - val_loss: 0.7143 - val_accuracy: 0.5620\n","Epoch 28/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6270 - accuracy: 0.6276 - val_loss: 0.7040 - val_accuracy: 0.5661\n","Epoch 29/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6244 - accuracy: 0.6331 - val_loss: 0.7153 - val_accuracy: 0.5599\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6230 - accuracy: 0.6377 - val_loss: 0.7221 - val_accuracy: 0.5568\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6255 - accuracy: 0.6292 - val_loss: 0.7244 - val_accuracy: 0.5610\n","Epoch 32/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6177 - accuracy: 0.6372 - val_loss: 0.7113 - val_accuracy: 0.5661\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6205 - accuracy: 0.6320 - val_loss: 0.7298 - val_accuracy: 0.5558\n","Epoch 34/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6197 - accuracy: 0.6426 - val_loss: 0.7153 - val_accuracy: 0.5620\n","Epoch 35/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6204 - accuracy: 0.6370 - val_loss: 0.7208 - val_accuracy: 0.5610\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6193 - accuracy: 0.6359 - val_loss: 0.7301 - val_accuracy: 0.5527\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6159 - accuracy: 0.6406 - val_loss: 0.7159 - val_accuracy: 0.5610\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6163 - accuracy: 0.6349 - val_loss: 0.7151 - val_accuracy: 0.5640\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6136 - accuracy: 0.6380 - val_loss: 0.7115 - val_accuracy: 0.5671\n","Epoch 40/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6162 - accuracy: 0.6426 - val_loss: 0.7448 - val_accuracy: 0.5579\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6149 - accuracy: 0.6398 - val_loss: 0.7266 - val_accuracy: 0.5475\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6189 - accuracy: 0.6357 - val_loss: 0.7096 - val_accuracy: 0.5568\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6212 - accuracy: 0.6380 - val_loss: 0.7074 - val_accuracy: 0.5640\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6124 - accuracy: 0.6486 - val_loss: 0.7293 - val_accuracy: 0.5506\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6093 - accuracy: 0.6463 - val_loss: 0.7317 - val_accuracy: 0.5548\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6082 - accuracy: 0.6444 - val_loss: 0.7323 - val_accuracy: 0.5527\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6091 - accuracy: 0.6447 - val_loss: 0.7242 - val_accuracy: 0.5589\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6053 - accuracy: 0.6411 - val_loss: 0.7353 - val_accuracy: 0.5610\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6034 - accuracy: 0.6501 - val_loss: 0.7445 - val_accuracy: 0.5568\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6025 - accuracy: 0.6548 - val_loss: 0.7271 - val_accuracy: 0.5558\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6067 - accuracy: 0.6535 - val_loss: 0.7384 - val_accuracy: 0.5527\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6022 - accuracy: 0.6512 - val_loss: 0.7484 - val_accuracy: 0.5548\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6035 - accuracy: 0.6509 - val_loss: 0.7442 - val_accuracy: 0.5517\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6066 - accuracy: 0.6444 - val_loss: 0.7256 - val_accuracy: 0.5537\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6000 - accuracy: 0.6574 - val_loss: 0.7420 - val_accuracy: 0.5579\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5960 - accuracy: 0.6571 - val_loss: 0.7454 - val_accuracy: 0.5444\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5942 - accuracy: 0.6589 - val_loss: 0.7431 - val_accuracy: 0.5537\n","Epoch 58/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5935 - accuracy: 0.6543 - val_loss: 0.7446 - val_accuracy: 0.5558\n","Epoch 59/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5971 - accuracy: 0.6571 - val_loss: 0.7294 - val_accuracy: 0.5579\n","Epoch 60/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5982 - accuracy: 0.6545 - val_loss: 0.7378 - val_accuracy: 0.5537\n","Epoch 61/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.5952 - accuracy: 0.6602 - val_loss: 0.7523 - val_accuracy: 0.5599\n","Epoch 62/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5931 - accuracy: 0.6574 - val_loss: 0.7518 - val_accuracy: 0.5465\n","Epoch 63/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5925 - accuracy: 0.6576 - val_loss: 0.7522 - val_accuracy: 0.5527\n","Epoch 64/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5930 - accuracy: 0.6556 - val_loss: 0.7551 - val_accuracy: 0.5403\n","Epoch 65/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5889 - accuracy: 0.6687 - val_loss: 0.7510 - val_accuracy: 0.5579\n","Epoch 66/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5886 - accuracy: 0.6628 - val_loss: 0.7564 - val_accuracy: 0.5506\n","Epoch 67/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5863 - accuracy: 0.6672 - val_loss: 0.7524 - val_accuracy: 0.5558\n","Epoch 68/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5820 - accuracy: 0.6636 - val_loss: 0.7561 - val_accuracy: 0.5579\n","Epoch 69/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5839 - accuracy: 0.6623 - val_loss: 0.7503 - val_accuracy: 0.5465\n","Epoch 70/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5862 - accuracy: 0.6680 - val_loss: 0.7695 - val_accuracy: 0.5517\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5807 - accuracy: 0.6693 - val_loss: 0.7695 - val_accuracy: 0.5424\n","Epoch 72/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5796 - accuracy: 0.6721 - val_loss: 0.7623 - val_accuracy: 0.5599\n","Epoch 73/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5776 - accuracy: 0.6726 - val_loss: 0.7665 - val_accuracy: 0.5486\n","Epoch 74/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5789 - accuracy: 0.6721 - val_loss: 0.7730 - val_accuracy: 0.5424\n","Epoch 75/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5789 - accuracy: 0.6667 - val_loss: 0.7812 - val_accuracy: 0.5527\n","Epoch 76/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.5794 - accuracy: 0.6791 - val_loss: 0.7842 - val_accuracy: 0.5393\n","Epoch 77/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5734 - accuracy: 0.6762 - val_loss: 0.7914 - val_accuracy: 0.5403\n","Epoch 78/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5756 - accuracy: 0.6793 - val_loss: 0.7680 - val_accuracy: 0.5568\n","Epoch 79/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5710 - accuracy: 0.6773 - val_loss: 0.7779 - val_accuracy: 0.5517\n","Epoch 80/100\n","31/31 [==============================] - 1s 39ms/step - loss: 0.5681 - accuracy: 0.6811 - val_loss: 0.7982 - val_accuracy: 0.5372\n","Epoch 81/100\n","31/31 [==============================] - 1s 41ms/step - loss: 0.5702 - accuracy: 0.6817 - val_loss: 0.7710 - val_accuracy: 0.5455\n","Epoch 82/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5679 - accuracy: 0.6850 - val_loss: 0.8200 - val_accuracy: 0.5310\n","Epoch 83/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5708 - accuracy: 0.6842 - val_loss: 0.7742 - val_accuracy: 0.5496\n","Epoch 84/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5703 - accuracy: 0.6814 - val_loss: 0.8179 - val_accuracy: 0.5558\n","Epoch 85/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5683 - accuracy: 0.6824 - val_loss: 0.8074 - val_accuracy: 0.5217\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5634 - accuracy: 0.6894 - val_loss: 0.7833 - val_accuracy: 0.5506\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5630 - accuracy: 0.6904 - val_loss: 0.7978 - val_accuracy: 0.5506\n","Epoch 88/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5636 - accuracy: 0.6922 - val_loss: 0.7990 - val_accuracy: 0.5486\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5592 - accuracy: 0.6933 - val_loss: 0.8307 - val_accuracy: 0.5289\n","Epoch 90/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5565 - accuracy: 0.6995 - val_loss: 0.8035 - val_accuracy: 0.5424\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5583 - accuracy: 0.6997 - val_loss: 0.8033 - val_accuracy: 0.5362\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5591 - accuracy: 0.6941 - val_loss: 0.7917 - val_accuracy: 0.5558\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5593 - accuracy: 0.6912 - val_loss: 0.8153 - val_accuracy: 0.5475\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5571 - accuracy: 0.6984 - val_loss: 0.7845 - val_accuracy: 0.5372\n","Epoch 95/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5510 - accuracy: 0.7059 - val_loss: 0.7799 - val_accuracy: 0.5537\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5542 - accuracy: 0.6966 - val_loss: 0.8166 - val_accuracy: 0.5475\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5591 - accuracy: 0.6979 - val_loss: 0.8161 - val_accuracy: 0.5486\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5518 - accuracy: 0.6961 - val_loss: 0.8127 - val_accuracy: 0.5351\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5587 - accuracy: 0.6938 - val_loss: 0.7961 - val_accuracy: 0.5558\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5507 - accuracy: 0.6941 - val_loss: 0.8149 - val_accuracy: 0.5382\n","{'loss': [0.6641314625740051, 0.6535224318504333, 0.6526002287864685, 0.6518393158912659, 0.6510373950004578, 0.6504412293434143, 0.646536111831665, 0.6464681029319763, 0.646069347858429, 0.6457080245018005, 0.6470169425010681, 0.6442577242851257, 0.6394386291503906, 0.6396169662475586, 0.639042854309082, 0.6371903419494629, 0.638163149356842, 0.6384813785552979, 0.6362492442131042, 0.6364943385124207, 0.6332575678825378, 0.6326532363891602, 0.6295050978660583, 0.6299023628234863, 0.6303415894508362, 0.6298654079437256, 0.6321158409118652, 0.6270389556884766, 0.6244440078735352, 0.6229904294013977, 0.6255350112915039, 0.6177007555961609, 0.6204578876495361, 0.619660496711731, 0.6204286217689514, 0.6192653179168701, 0.6158525943756104, 0.6162822842597961, 0.6135660409927368, 0.6162218451499939, 0.6148547530174255, 0.6189329028129578, 0.62122642993927, 0.6123868227005005, 0.6092641949653625, 0.60820072889328, 0.6091150641441345, 0.6052820682525635, 0.6033695936203003, 0.6024505496025085, 0.6066731214523315, 0.6022080779075623, 0.6034854650497437, 0.606552004814148, 0.5999997854232788, 0.5960449576377869, 0.5941979885101318, 0.5935243368148804, 0.597131609916687, 0.5981957316398621, 0.5951748490333557, 0.5931141972541809, 0.5924640893936157, 0.593038022518158, 0.5889284610748291, 0.5886133313179016, 0.5863382816314697, 0.5820022225379944, 0.5839011669158936, 0.5861798524856567, 0.5807241201400757, 0.5796334743499756, 0.5775858163833618, 0.5789388418197632, 0.5788864493370056, 0.5793843269348145, 0.5733592510223389, 0.5755540728569031, 0.5710019469261169, 0.5681240558624268, 0.570239782333374, 0.5679178237915039, 0.5707955360412598, 0.570270299911499, 0.56827312707901, 0.5633926391601562, 0.5630027055740356, 0.5636236071586609, 0.5591532588005066, 0.5565140247344971, 0.5582528114318848, 0.5590994954109192, 0.559349775314331, 0.5571455955505371, 0.5510441660881042, 0.5541959404945374, 0.5590829849243164, 0.5517635941505432, 0.558681845664978, 0.5506569147109985], 'accuracy': [0.5940568447113037, 0.5989664196968079, 0.604651153087616, 0.6100775003433228, 0.6067183613777161, 0.6142118573188782, 0.6147286891937256, 0.6144703030586243, 0.6126614809036255, 0.620671808719635, 0.6142118573188782, 0.6131783127784729, 0.6255813837051392, 0.6201550364494324, 0.6253229975700378, 0.6175710558891296, 0.6232557892799377, 0.6191214323043823, 0.6214470267295837, 0.6191214323043823, 0.6165374517440796, 0.6229974031448364, 0.6217054128646851, 0.6291989684104919, 0.6328165531158447, 0.6263566017150879, 0.6346253156661987, 0.6276485919952393, 0.633074939250946, 0.6377260684967041, 0.6291989684104919, 0.6372092962265015, 0.632041335105896, 0.6426356434822083, 0.6369509100914001, 0.6359173059463501, 0.6405684947967529, 0.6348837018013, 0.6379845142364502, 0.6426356434822083, 0.6397932767868042, 0.6356589198112488, 0.6379845142364502, 0.6485788226127625, 0.646253228187561, 0.644444465637207, 0.6447028517723083, 0.6410852670669556, 0.6501291990280151, 0.654780387878418, 0.6534883975982666, 0.6511628031730652, 0.6509044170379639, 0.644444465637207, 0.6573643684387207, 0.6571059226989746, 0.6589147448539734, 0.6542635560035706, 0.6571059226989746, 0.6545219421386719, 0.6602067351341248, 0.6573643684387207, 0.657622754573822, 0.6555555462837219, 0.6687338352203369, 0.6627907156944275, 0.6671834588050842, 0.6635658740997314, 0.6622738838195801, 0.667958676815033, 0.6692506670951843, 0.6720930337905884, 0.672609806060791, 0.6720930337905884, 0.6666666865348816, 0.6790697574615479, 0.6762273907661438, 0.6793281435966492, 0.6772609949111938, 0.681136965751648, 0.6816537380218506, 0.685012936592102, 0.6842377185821533, 0.6813953518867493, 0.6824289560317993, 0.6894056797027588, 0.6904392838478088, 0.6922480463981628, 0.6932816505432129, 0.6994832158088684, 0.6997416019439697, 0.6940568685531616, 0.6912144422531128, 0.6984496116638184, 0.7059431672096252, 0.6966408491134644, 0.6979328393936157, 0.6961240172386169, 0.6937984228134155, 0.6940568685531616], 'val_loss': [0.6913567185401917, 0.6914942860603333, 0.6913148164749146, 0.6909690499305725, 0.6910006999969482, 0.6901394128799438, 0.689947783946991, 0.6892950534820557, 0.6886071562767029, 0.6877798438072205, 0.6875953078269958, 0.6868559718132019, 0.6870976090431213, 0.6859574317932129, 0.6852643489837646, 0.6867339611053467, 0.685265839099884, 0.6856672763824463, 0.687138557434082, 0.691256046295166, 0.6920674443244934, 0.6980481147766113, 0.7059425711631775, 0.6963679194450378, 0.693833589553833, 0.6993486285209656, 0.7142750024795532, 0.7039796710014343, 0.7152523994445801, 0.7221108675003052, 0.7244222164154053, 0.7112669944763184, 0.7297516465187073, 0.715273380279541, 0.7207527756690979, 0.7300785183906555, 0.7158749103546143, 0.7150501608848572, 0.7114806771278381, 0.7447880506515503, 0.726553738117218, 0.7096220850944519, 0.7073643803596497, 0.7293057441711426, 0.7317180633544922, 0.7322712540626526, 0.7241880893707275, 0.7353371977806091, 0.7444605827331543, 0.727130651473999, 0.7383983135223389, 0.7483556270599365, 0.744163990020752, 0.7256489396095276, 0.741953432559967, 0.7454360723495483, 0.7431008219718933, 0.7445971965789795, 0.7294360995292664, 0.7378442883491516, 0.7522619962692261, 0.7518399953842163, 0.7521806359291077, 0.7550822496414185, 0.7510311007499695, 0.7564318180084229, 0.7523596882820129, 0.756110668182373, 0.7503470182418823, 0.769463837146759, 0.7695150971412659, 0.7623319029808044, 0.7665209770202637, 0.7729986310005188, 0.781230092048645, 0.784227192401886, 0.7914124131202698, 0.7679818272590637, 0.7778791785240173, 0.798243522644043, 0.7709896564483643, 0.8199870586395264, 0.7741809487342834, 0.8178631067276001, 0.8073947429656982, 0.7833462357521057, 0.7977899312973022, 0.7990022897720337, 0.8307253122329712, 0.8035423159599304, 0.8032909035682678, 0.791749894618988, 0.8153071999549866, 0.7845132946968079, 0.7799370288848877, 0.81659334897995, 0.8161472678184509, 0.8127211928367615, 0.7960628271102905, 0.8148690462112427], 'val_accuracy': [0.5216942429542542, 0.5175619721412659, 0.5216942429542542, 0.5268595218658447, 0.5258264541625977, 0.5361570119857788, 0.5361570119857788, 0.5361570119857788, 0.5413222908973694, 0.5413222908973694, 0.5444214940071106, 0.5433884263038635, 0.5557851195335388, 0.5537189841270447, 0.5454545617103577, 0.567148745059967, 0.5557851195335388, 0.56611567735672, 0.5640496015548706, 0.5712810158729553, 0.5609503984451294, 0.5599173307418823, 0.5640496015548706, 0.567148745059967, 0.5568181872367859, 0.55888432264328, 0.5619834661483765, 0.56611567735672, 0.5599173307418823, 0.5568181872367859, 0.5609503984451294, 0.56611567735672, 0.5557851195335388, 0.5619834661483765, 0.5609503984451294, 0.5526859760284424, 0.5609503984451294, 0.5640496015548706, 0.567148745059967, 0.557851254940033, 0.547520637512207, 0.5568181872367859, 0.5640496015548706, 0.5506198406219482, 0.5547520518302917, 0.5526859760284424, 0.55888432264328, 0.5609503984451294, 0.5568181872367859, 0.5557851195335388, 0.5526859760284424, 0.5547520518302917, 0.5516529083251953, 0.5537189841270447, 0.557851254940033, 0.5444214940071106, 0.5537189841270447, 0.5557851195335388, 0.557851254940033, 0.5537189841270447, 0.5599173307418823, 0.5464876294136047, 0.5526859760284424, 0.5402892827987671, 0.557851254940033, 0.5506198406219482, 0.5557851195335388, 0.557851254940033, 0.5464876294136047, 0.5516529083251953, 0.5423553586006165, 0.5599173307418823, 0.5485537052154541, 0.5423553586006165, 0.5526859760284424, 0.53925621509552, 0.5402892827987671, 0.5568181872367859, 0.5516529083251953, 0.5371900796890259, 0.5454545617103577, 0.5309917330741882, 0.5495867729187012, 0.5557851195335388, 0.5216942429542542, 0.5506198406219482, 0.5506198406219482, 0.5485537052154541, 0.5289255976676941, 0.5423553586006165, 0.5361570119857788, 0.5557851195335388, 0.547520637512207, 0.5371900796890259, 0.5537189841270447, 0.547520637512207, 0.5485537052154541, 0.5351239442825317, 0.5557851195335388, 0.538223147392273]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/29 [========================>.....] - ETA: 0s - loss: 0.5832 - accuracy: 0.6703"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 64ms/step - loss: 0.5832 - accuracy: 0.6727 - val_loss: 0.6857 - val_accuracy: 0.5905\n","Epoch 2/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5740 - accuracy: 0.6791 - val_loss: 0.6851 - val_accuracy: 0.5528\n","Epoch 3/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5715 - accuracy: 0.6800 - val_loss: 0.6851 - val_accuracy: 0.5700\n","Epoch 4/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5719 - accuracy: 0.6875 - val_loss: 0.6834 - val_accuracy: 0.5690\n","Epoch 5/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.5689 - accuracy: 0.6765 - val_loss: 0.6818 - val_accuracy: 0.5938\n","Epoch 6/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5660 - accuracy: 0.6848 - val_loss: 0.6805 - val_accuracy: 0.5776\n","Epoch 7/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5668 - accuracy: 0.6910 - val_loss: 0.6788 - val_accuracy: 0.6024\n","Epoch 8/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.5606 - accuracy: 0.6891 - val_loss: 0.6785 - val_accuracy: 0.6099\n","Epoch 9/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5597 - accuracy: 0.6902 - val_loss: 0.6741 - val_accuracy: 0.6034\n","Epoch 10/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5598 - accuracy: 0.6818 - val_loss: 0.6786 - val_accuracy: 0.5927\n","Epoch 11/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5605 - accuracy: 0.6872 - val_loss: 0.6816 - val_accuracy: 0.5991\n","Epoch 12/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5642 - accuracy: 0.6759 - val_loss: 0.6805 - val_accuracy: 0.5851\n","Epoch 13/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5573 - accuracy: 0.6827 - val_loss: 0.6700 - val_accuracy: 0.6207\n","Epoch 14/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5492 - accuracy: 0.7058 - val_loss: 0.6785 - val_accuracy: 0.6164\n","Epoch 15/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5515 - accuracy: 0.6953 - val_loss: 0.6718 - val_accuracy: 0.6185\n","Epoch 16/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5469 - accuracy: 0.6953 - val_loss: 0.6747 - val_accuracy: 0.6207\n","Epoch 17/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5526 - accuracy: 0.6983 - val_loss: 0.6704 - val_accuracy: 0.6045\n","Epoch 18/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5478 - accuracy: 0.7007 - val_loss: 0.6881 - val_accuracy: 0.5991\n","Epoch 19/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5425 - accuracy: 0.7066 - val_loss: 0.6811 - val_accuracy: 0.6024\n","Epoch 20/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5480 - accuracy: 0.7031 - val_loss: 0.6924 - val_accuracy: 0.6024\n","Epoch 21/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5450 - accuracy: 0.7061 - val_loss: 0.6705 - val_accuracy: 0.6131\n","Epoch 22/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5456 - accuracy: 0.6942 - val_loss: 0.6882 - val_accuracy: 0.6282\n","Epoch 23/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5372 - accuracy: 0.7037 - val_loss: 0.7039 - val_accuracy: 0.6099\n","Epoch 24/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5395 - accuracy: 0.6996 - val_loss: 0.6952 - val_accuracy: 0.6164\n","Epoch 25/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5308 - accuracy: 0.7169 - val_loss: 0.6967 - val_accuracy: 0.6110\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5389 - accuracy: 0.7034 - val_loss: 0.7042 - val_accuracy: 0.6164\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5387 - accuracy: 0.7166 - val_loss: 0.7127 - val_accuracy: 0.6175\n","Epoch 28/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5316 - accuracy: 0.7093 - val_loss: 0.7336 - val_accuracy: 0.6013\n","Epoch 29/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5315 - accuracy: 0.7077 - val_loss: 0.7210 - val_accuracy: 0.6228\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5365 - accuracy: 0.7104 - val_loss: 0.7333 - val_accuracy: 0.6239\n","Epoch 31/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5334 - accuracy: 0.7171 - val_loss: 0.7528 - val_accuracy: 0.5991\n","Epoch 32/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5416 - accuracy: 0.7101 - val_loss: 0.7301 - val_accuracy: 0.6034\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5255 - accuracy: 0.7239 - val_loss: 0.7378 - val_accuracy: 0.6164\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5294 - accuracy: 0.7123 - val_loss: 0.7405 - val_accuracy: 0.6228\n","Epoch 35/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5242 - accuracy: 0.7126 - val_loss: 0.7489 - val_accuracy: 0.6056\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5263 - accuracy: 0.7152 - val_loss: 0.7481 - val_accuracy: 0.6024\n","Epoch 37/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5211 - accuracy: 0.7206 - val_loss: 0.7559 - val_accuracy: 0.6067\n","Epoch 38/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5214 - accuracy: 0.7271 - val_loss: 0.7705 - val_accuracy: 0.5927\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5236 - accuracy: 0.7188 - val_loss: 0.7699 - val_accuracy: 0.5776\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5201 - accuracy: 0.7177 - val_loss: 0.7643 - val_accuracy: 0.6131\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5252 - accuracy: 0.7198 - val_loss: 0.7653 - val_accuracy: 0.6045\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5173 - accuracy: 0.7298 - val_loss: 0.7654 - val_accuracy: 0.6024\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5212 - accuracy: 0.7217 - val_loss: 0.7571 - val_accuracy: 0.6153\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5176 - accuracy: 0.7252 - val_loss: 0.7757 - val_accuracy: 0.6088\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5165 - accuracy: 0.7317 - val_loss: 0.7852 - val_accuracy: 0.6045\n","Epoch 46/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5087 - accuracy: 0.7314 - val_loss: 0.7756 - val_accuracy: 0.6024\n","Epoch 47/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5105 - accuracy: 0.7276 - val_loss: 0.7863 - val_accuracy: 0.5991\n","Epoch 48/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5077 - accuracy: 0.7290 - val_loss: 0.7675 - val_accuracy: 0.6196\n","Epoch 49/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5071 - accuracy: 0.7317 - val_loss: 0.7650 - val_accuracy: 0.6034\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5054 - accuracy: 0.7223 - val_loss: 0.7577 - val_accuracy: 0.6250\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5000 - accuracy: 0.7295 - val_loss: 0.7722 - val_accuracy: 0.5970\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5039 - accuracy: 0.7338 - val_loss: 0.7939 - val_accuracy: 0.5938\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5035 - accuracy: 0.7314 - val_loss: 0.7742 - val_accuracy: 0.6207\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5027 - accuracy: 0.7398 - val_loss: 0.7965 - val_accuracy: 0.6185\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5063 - accuracy: 0.7263 - val_loss: 0.8019 - val_accuracy: 0.6034\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4990 - accuracy: 0.7317 - val_loss: 0.7957 - val_accuracy: 0.6045\n","Epoch 57/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4975 - accuracy: 0.7435 - val_loss: 0.8009 - val_accuracy: 0.6002\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4995 - accuracy: 0.7381 - val_loss: 0.8037 - val_accuracy: 0.5981\n","Epoch 59/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4919 - accuracy: 0.7422 - val_loss: 0.7897 - val_accuracy: 0.6218\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4947 - accuracy: 0.7330 - val_loss: 0.8315 - val_accuracy: 0.5916\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4950 - accuracy: 0.7395 - val_loss: 0.8031 - val_accuracy: 0.6078\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4907 - accuracy: 0.7457 - val_loss: 0.8067 - val_accuracy: 0.6185\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4859 - accuracy: 0.7416 - val_loss: 0.8028 - val_accuracy: 0.6218\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4901 - accuracy: 0.7422 - val_loss: 0.8158 - val_accuracy: 0.6099\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4898 - accuracy: 0.7438 - val_loss: 0.8387 - val_accuracy: 0.5981\n","Epoch 66/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4860 - accuracy: 0.7408 - val_loss: 0.8204 - val_accuracy: 0.6185\n","Epoch 67/100\n","29/29 [==============================] - 1s 36ms/step - loss: 0.4900 - accuracy: 0.7462 - val_loss: 0.8400 - val_accuracy: 0.6002\n","Epoch 68/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4896 - accuracy: 0.7406 - val_loss: 0.8116 - val_accuracy: 0.6121\n","Epoch 69/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4879 - accuracy: 0.7414 - val_loss: 0.8274 - val_accuracy: 0.6261\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4811 - accuracy: 0.7481 - val_loss: 0.8457 - val_accuracy: 0.5938\n","Epoch 71/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4790 - accuracy: 0.7516 - val_loss: 0.8296 - val_accuracy: 0.6002\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4781 - accuracy: 0.7516 - val_loss: 0.8445 - val_accuracy: 0.6185\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4850 - accuracy: 0.7408 - val_loss: 0.8648 - val_accuracy: 0.5765\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4785 - accuracy: 0.7530 - val_loss: 0.8325 - val_accuracy: 0.6207\n","Epoch 75/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4718 - accuracy: 0.7565 - val_loss: 0.8896 - val_accuracy: 0.5787\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4765 - accuracy: 0.7535 - val_loss: 0.8738 - val_accuracy: 0.5754\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4652 - accuracy: 0.7586 - val_loss: 0.8536 - val_accuracy: 0.6099\n","Epoch 78/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4774 - accuracy: 0.7535 - val_loss: 0.8674 - val_accuracy: 0.5991\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4709 - accuracy: 0.7551 - val_loss: 0.8503 - val_accuracy: 0.6239\n","Epoch 80/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4783 - accuracy: 0.7452 - val_loss: 0.8627 - val_accuracy: 0.6088\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4668 - accuracy: 0.7573 - val_loss: 0.8616 - val_accuracy: 0.6121\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4643 - accuracy: 0.7608 - val_loss: 0.8576 - val_accuracy: 0.5959\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4636 - accuracy: 0.7627 - val_loss: 0.8553 - val_accuracy: 0.6078\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4729 - accuracy: 0.7640 - val_loss: 0.8689 - val_accuracy: 0.6153\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4633 - accuracy: 0.7602 - val_loss: 0.8599 - val_accuracy: 0.6175\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4620 - accuracy: 0.7640 - val_loss: 0.8518 - val_accuracy: 0.6067\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4563 - accuracy: 0.7667 - val_loss: 0.9079 - val_accuracy: 0.5722\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4564 - accuracy: 0.7648 - val_loss: 0.9270 - val_accuracy: 0.5722\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4588 - accuracy: 0.7627 - val_loss: 0.9383 - val_accuracy: 0.5754\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4584 - accuracy: 0.7726 - val_loss: 0.8717 - val_accuracy: 0.6056\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4547 - accuracy: 0.7732 - val_loss: 0.9019 - val_accuracy: 0.6110\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4709 - accuracy: 0.7605 - val_loss: 0.9160 - val_accuracy: 0.5981\n","Epoch 93/100\n","29/29 [==============================] - 1s 44ms/step - loss: 0.4638 - accuracy: 0.7570 - val_loss: 0.8712 - val_accuracy: 0.6304\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4528 - accuracy: 0.7713 - val_loss: 0.9440 - val_accuracy: 0.5765\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4557 - accuracy: 0.7721 - val_loss: 0.8955 - val_accuracy: 0.6056\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4448 - accuracy: 0.7769 - val_loss: 0.8970 - val_accuracy: 0.6002\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4462 - accuracy: 0.7786 - val_loss: 0.8944 - val_accuracy: 0.6002\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4522 - accuracy: 0.7697 - val_loss: 0.9122 - val_accuracy: 0.6002\n","Epoch 99/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4476 - accuracy: 0.7818 - val_loss: 0.9588 - val_accuracy: 0.5787\n","Epoch 100/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4435 - accuracy: 0.7769 - val_loss: 0.9113 - val_accuracy: 0.5938\n","{'loss': [0.5832076072692871, 0.5740237832069397, 0.5714772939682007, 0.5719083547592163, 0.5689445734024048, 0.5659514665603638, 0.5667815208435059, 0.5606200695037842, 0.5597230792045593, 0.5597534775733948, 0.5605407953262329, 0.5642395615577698, 0.5573055148124695, 0.549201250076294, 0.5515331625938416, 0.5468834638595581, 0.552619457244873, 0.5477725863456726, 0.5424740314483643, 0.5480201840400696, 0.5449665188789368, 0.5455840826034546, 0.5372104048728943, 0.5394625663757324, 0.530823826789856, 0.5389118790626526, 0.538718581199646, 0.5316134095191956, 0.5315499901771545, 0.5364595651626587, 0.5334042310714722, 0.5415645241737366, 0.5255008339881897, 0.5294350385665894, 0.5242186784744263, 0.5263373255729675, 0.5211384296417236, 0.5213583707809448, 0.5236009955406189, 0.5201143026351929, 0.5251997709274292, 0.5173067450523376, 0.5211802124977112, 0.5176146626472473, 0.516499936580658, 0.5087361931800842, 0.5105408430099487, 0.5077495574951172, 0.5071091055870056, 0.5054249167442322, 0.5000429153442383, 0.5039082169532776, 0.5035485625267029, 0.5026510953903198, 0.5063003897666931, 0.49902617931365967, 0.4974670112133026, 0.49948450922966003, 0.4918520748615265, 0.4946584403514862, 0.4950163960456848, 0.4906868636608124, 0.4858704209327698, 0.4901440441608429, 0.48975664377212524, 0.48595818877220154, 0.4899626076221466, 0.48957404494285583, 0.48785266280174255, 0.481112539768219, 0.4789734482765198, 0.47810763120651245, 0.4850286543369293, 0.47846782207489014, 0.4717928469181061, 0.47652143239974976, 0.46520283818244934, 0.4773656725883484, 0.4709276556968689, 0.478329598903656, 0.46677038073539734, 0.4643268287181854, 0.4636058211326599, 0.47285157442092896, 0.46330633759498596, 0.4620046317577362, 0.45634791254997253, 0.45641061663627625, 0.45882314443588257, 0.4584352672100067, 0.45470067858695984, 0.47093498706817627, 0.46380430459976196, 0.45279037952423096, 0.45572730898857117, 0.4448402225971222, 0.44623425602912903, 0.4522189199924469, 0.4476470351219177, 0.44345822930336], 'accuracy': [0.6726831793785095, 0.6791487336158752, 0.6799569129943848, 0.6875, 0.6764547228813171, 0.6848060488700867, 0.6910021305084229, 0.689116358757019, 0.6901939511299133, 0.6818426847457886, 0.6872305870056152, 0.6759159564971924, 0.6826508641242981, 0.7058189511299133, 0.6953125, 0.6953125, 0.6982758641242981, 0.7007004022598267, 0.7066271305084229, 0.703125, 0.7060883641242981, 0.6942349076271057, 0.7036637663841248, 0.6996228694915771, 0.7168642282485962, 0.7033944129943848, 0.7165948152542114, 0.709321141242981, 0.7077047228813171, 0.7103987336158752, 0.717133641242981, 0.7101293206214905, 0.7238685488700867, 0.712284505367279, 0.712553858757019, 0.7152478694915771, 0.7206357717514038, 0.7271012663841248, 0.71875, 0.7176724076271057, 0.7198275923728943, 0.7297952771186829, 0.7217133641242981, 0.725215494632721, 0.7316810488700867, 0.7314116358757019, 0.7276400923728943, 0.7289870977401733, 0.7316810488700867, 0.7222521305084229, 0.7295258641242981, 0.7338362336158752, 0.7314116358757019, 0.7397629022598267, 0.7262930870056152, 0.7316810488700867, 0.743534505367279, 0.7381465435028076, 0.7421875, 0.733027994632721, 0.7394935488700867, 0.7456896305084229, 0.7416487336158752, 0.7421875, 0.743803858757019, 0.740840494632721, 0.7462284564971924, 0.740571141242981, 0.7413793206214905, 0.7481142282485962, 0.751616358757019, 0.751616358757019, 0.740840494632721, 0.7529633641242981, 0.756465494632721, 0.7535021305084229, 0.7586206793785095, 0.7535021305084229, 0.7551185488700867, 0.7451508641242981, 0.7572737336158752, 0.7607758641242981, 0.7626616358757019, 0.764008641242981, 0.7602370977401733, 0.764008641242981, 0.7667025923728943, 0.7648168206214905, 0.7626616358757019, 0.7726293206214905, 0.7731680870056152, 0.7605064511299133, 0.7570043206214905, 0.7712823152542114, 0.772090494632721, 0.7769396305084229, 0.7785560488700867, 0.7696659564971924, 0.7817887663841248, 0.7769396305084229], 'val_loss': [0.685650646686554, 0.6851039528846741, 0.6850752830505371, 0.6833610534667969, 0.6818172931671143, 0.6805087924003601, 0.6788097620010376, 0.6785179376602173, 0.674129843711853, 0.6786495447158813, 0.6815534830093384, 0.6805408596992493, 0.6700407862663269, 0.6785396337509155, 0.6717888116836548, 0.6747230887413025, 0.6704321503639221, 0.6880803108215332, 0.6810802817344666, 0.6923801302909851, 0.6705424785614014, 0.6882488131523132, 0.7038633227348328, 0.6952279806137085, 0.6967004537582397, 0.7042433619499207, 0.7126637697219849, 0.7335571646690369, 0.720962643623352, 0.733349084854126, 0.752825915813446, 0.7300741076469421, 0.7377704977989197, 0.740509569644928, 0.7489103674888611, 0.7480598092079163, 0.7559448480606079, 0.7705162763595581, 0.7699041962623596, 0.7642684578895569, 0.7653093934059143, 0.7653715014457703, 0.7571372389793396, 0.7756555080413818, 0.7852279543876648, 0.7755842804908752, 0.7862780094146729, 0.767454206943512, 0.7649665474891663, 0.757741391658783, 0.7722201943397522, 0.7938798666000366, 0.7741701006889343, 0.7965235710144043, 0.8019087314605713, 0.7957483530044556, 0.8009077310562134, 0.8037174344062805, 0.7897226214408875, 0.8314516544342041, 0.8031325936317444, 0.8066641092300415, 0.8027552962303162, 0.8158018589019775, 0.8387203812599182, 0.820386528968811, 0.8399585485458374, 0.8115519285202026, 0.8274195194244385, 0.8457456231117249, 0.829597532749176, 0.8444547057151794, 0.8648096919059753, 0.8325494527816772, 0.8896171450614929, 0.8738180994987488, 0.8535910844802856, 0.867363452911377, 0.8503055572509766, 0.8626567721366882, 0.861611008644104, 0.857639729976654, 0.8552613854408264, 0.8689221739768982, 0.859944760799408, 0.8517593145370483, 0.9078630208969116, 0.92701256275177, 0.9383043646812439, 0.8716663718223572, 0.9018865823745728, 0.9160133600234985, 0.8711580634117126, 0.9439942836761475, 0.8954856395721436, 0.8970105648040771, 0.8944385051727295, 0.912189245223999, 0.958838164806366, 0.9112802743911743], 'val_accuracy': [0.5905172228813171, 0.5528017282485962, 0.5700430870056152, 0.568965494632721, 0.59375, 0.5775862336158752, 0.6023706793785095, 0.6099137663841248, 0.6034482717514038, 0.5926724076271057, 0.5991379022598267, 0.5851293206214905, 0.6206896305084229, 0.6163793206214905, 0.618534505367279, 0.6206896305084229, 0.6045258641242981, 0.5991379022598267, 0.6023706793785095, 0.6023706793785095, 0.6131465435028076, 0.6282327771186829, 0.6099137663841248, 0.6163793206214905, 0.610991358757019, 0.6163793206214905, 0.6174569129943848, 0.6012930870056152, 0.6228448152542114, 0.6239224076271057, 0.5991379022598267, 0.6034482717514038, 0.6163793206214905, 0.6228448152542114, 0.6056034564971924, 0.6023706793785095, 0.6066810488700867, 0.5926724076271057, 0.5775862336158752, 0.6131465435028076, 0.6045258641242981, 0.6023706793785095, 0.6153017282485962, 0.6088362336158752, 0.6045258641242981, 0.6023706793785095, 0.5991379022598267, 0.6196120977401733, 0.6034482717514038, 0.625, 0.5969827771186829, 0.59375, 0.6206896305084229, 0.618534505367279, 0.6034482717514038, 0.6045258641242981, 0.600215494632721, 0.5980603694915771, 0.6217672228813171, 0.5915948152542114, 0.607758641242981, 0.618534505367279, 0.6217672228813171, 0.6099137663841248, 0.5980603694915771, 0.618534505367279, 0.600215494632721, 0.6120689511299133, 0.6260775923728943, 0.59375, 0.600215494632721, 0.618534505367279, 0.576508641242981, 0.6206896305084229, 0.5786637663841248, 0.5754310488700867, 0.6099137663841248, 0.5991379022598267, 0.6239224076271057, 0.6088362336158752, 0.6120689511299133, 0.5959051847457886, 0.607758641242981, 0.6153017282485962, 0.6174569129943848, 0.6066810488700867, 0.5721982717514038, 0.5721982717514038, 0.5754310488700867, 0.6056034564971924, 0.610991358757019, 0.5980603694915771, 0.6303879022598267, 0.576508641242981, 0.6056034564971924, 0.600215494632721, 0.600215494632721, 0.600215494632721, 0.5786637663841248, 0.59375]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.5866 - accuracy: 0.6767"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 54ms/step - loss: 0.5877 - accuracy: 0.6743 - val_loss: 0.6840 - val_accuracy: 0.5645\n","Epoch 2/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5736 - accuracy: 0.6797 - val_loss: 0.6851 - val_accuracy: 0.5238\n","Epoch 3/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5636 - accuracy: 0.6899 - val_loss: 0.6807 - val_accuracy: 0.5554\n","Epoch 4/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5693 - accuracy: 0.6811 - val_loss: 0.6797 - val_accuracy: 0.5758\n","Epoch 5/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5662 - accuracy: 0.6766 - val_loss: 0.6786 - val_accuracy: 0.5486\n","Epoch 6/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5602 - accuracy: 0.6969 - val_loss: 0.6752 - val_accuracy: 0.5758\n","Epoch 7/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5682 - accuracy: 0.6919 - val_loss: 0.6739 - val_accuracy: 0.5566\n","Epoch 8/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5592 - accuracy: 0.6868 - val_loss: 0.6688 - val_accuracy: 0.6199\n","Epoch 9/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5640 - accuracy: 0.6870 - val_loss: 0.6665 - val_accuracy: 0.6244\n","Epoch 10/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5613 - accuracy: 0.6958 - val_loss: 0.6630 - val_accuracy: 0.6007\n","Epoch 11/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5598 - accuracy: 0.6935 - val_loss: 0.6626 - val_accuracy: 0.5882\n","Epoch 12/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5626 - accuracy: 0.6935 - val_loss: 0.6592 - val_accuracy: 0.6029\n","Epoch 13/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5506 - accuracy: 0.6995 - val_loss: 0.6551 - val_accuracy: 0.6256\n","Epoch 14/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5515 - accuracy: 0.6964 - val_loss: 0.6482 - val_accuracy: 0.6471\n","Epoch 15/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5526 - accuracy: 0.6961 - val_loss: 0.6477 - val_accuracy: 0.6369\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5526 - accuracy: 0.7051 - val_loss: 0.6512 - val_accuracy: 0.6018\n","Epoch 17/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5494 - accuracy: 0.7051 - val_loss: 0.6479 - val_accuracy: 0.6143\n","Epoch 18/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5483 - accuracy: 0.7009 - val_loss: 0.6455 - val_accuracy: 0.6335\n","Epoch 19/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5389 - accuracy: 0.7054 - val_loss: 0.6436 - val_accuracy: 0.6346\n","Epoch 20/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5450 - accuracy: 0.6986 - val_loss: 0.6423 - val_accuracy: 0.6233\n","Epoch 21/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5490 - accuracy: 0.7088 - val_loss: 0.6435 - val_accuracy: 0.6188\n","Epoch 22/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5453 - accuracy: 0.6989 - val_loss: 0.6456 - val_accuracy: 0.6233\n","Epoch 23/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5372 - accuracy: 0.7139 - val_loss: 0.6453 - val_accuracy: 0.6357\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5411 - accuracy: 0.7085 - val_loss: 0.6561 - val_accuracy: 0.6380\n","Epoch 25/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5463 - accuracy: 0.6995 - val_loss: 0.6481 - val_accuracy: 0.6357\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5382 - accuracy: 0.7105 - val_loss: 0.6519 - val_accuracy: 0.6233\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5341 - accuracy: 0.7117 - val_loss: 0.6570 - val_accuracy: 0.6301\n","Epoch 28/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5302 - accuracy: 0.7142 - val_loss: 0.6677 - val_accuracy: 0.6437\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5286 - accuracy: 0.7165 - val_loss: 0.6625 - val_accuracy: 0.6403\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5334 - accuracy: 0.7077 - val_loss: 0.6631 - val_accuracy: 0.6425\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5319 - accuracy: 0.7193 - val_loss: 0.6852 - val_accuracy: 0.6403\n","Epoch 32/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5286 - accuracy: 0.7063 - val_loss: 0.6691 - val_accuracy: 0.6357\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5273 - accuracy: 0.7187 - val_loss: 0.7021 - val_accuracy: 0.6188\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5256 - accuracy: 0.7261 - val_loss: 0.6875 - val_accuracy: 0.6357\n","Epoch 35/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5215 - accuracy: 0.7201 - val_loss: 0.6804 - val_accuracy: 0.6572\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5251 - accuracy: 0.7241 - val_loss: 0.7043 - val_accuracy: 0.6324\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5221 - accuracy: 0.7218 - val_loss: 0.6961 - val_accuracy: 0.6256\n","Epoch 38/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5252 - accuracy: 0.7264 - val_loss: 0.7007 - val_accuracy: 0.6301\n","Epoch 39/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5229 - accuracy: 0.7190 - val_loss: 0.7192 - val_accuracy: 0.6425\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5187 - accuracy: 0.7346 - val_loss: 0.6831 - val_accuracy: 0.6369\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5201 - accuracy: 0.7247 - val_loss: 0.7310 - val_accuracy: 0.6222\n","Epoch 42/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5236 - accuracy: 0.7252 - val_loss: 0.7240 - val_accuracy: 0.5939\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5182 - accuracy: 0.7201 - val_loss: 0.7020 - val_accuracy: 0.6391\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5120 - accuracy: 0.7255 - val_loss: 0.7436 - val_accuracy: 0.6199\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5213 - accuracy: 0.7168 - val_loss: 0.7047 - val_accuracy: 0.6233\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5137 - accuracy: 0.7346 - val_loss: 0.7089 - val_accuracy: 0.6165\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5102 - accuracy: 0.7334 - val_loss: 0.6964 - val_accuracy: 0.6210\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5127 - accuracy: 0.7292 - val_loss: 0.7199 - val_accuracy: 0.6278\n","Epoch 49/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5154 - accuracy: 0.7247 - val_loss: 0.7251 - val_accuracy: 0.6199\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5094 - accuracy: 0.7292 - val_loss: 0.7126 - val_accuracy: 0.6176\n","Epoch 51/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5018 - accuracy: 0.7397 - val_loss: 0.7198 - val_accuracy: 0.6301\n","Epoch 52/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5003 - accuracy: 0.7340 - val_loss: 0.7205 - val_accuracy: 0.6222\n","Epoch 53/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5020 - accuracy: 0.7332 - val_loss: 0.7183 - val_accuracy: 0.6357\n","Epoch 54/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5059 - accuracy: 0.7377 - val_loss: 0.7335 - val_accuracy: 0.6471\n","Epoch 55/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5006 - accuracy: 0.7368 - val_loss: 0.7212 - val_accuracy: 0.6086\n","Epoch 56/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5063 - accuracy: 0.7397 - val_loss: 0.7416 - val_accuracy: 0.6267\n","Epoch 57/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5021 - accuracy: 0.7357 - val_loss: 0.7199 - val_accuracy: 0.6380\n","Epoch 58/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4970 - accuracy: 0.7374 - val_loss: 0.7250 - val_accuracy: 0.6210\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4994 - accuracy: 0.7383 - val_loss: 0.7162 - val_accuracy: 0.6335\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5029 - accuracy: 0.7385 - val_loss: 0.7306 - val_accuracy: 0.6233\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4917 - accuracy: 0.7473 - val_loss: 0.7631 - val_accuracy: 0.5973\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4924 - accuracy: 0.7507 - val_loss: 0.7366 - val_accuracy: 0.6256\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4914 - accuracy: 0.7434 - val_loss: 0.7403 - val_accuracy: 0.6165\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4929 - accuracy: 0.7516 - val_loss: 0.7225 - val_accuracy: 0.6312\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4847 - accuracy: 0.7524 - val_loss: 0.7622 - val_accuracy: 0.6437\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4921 - accuracy: 0.7496 - val_loss: 0.7422 - val_accuracy: 0.6222\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4867 - accuracy: 0.7436 - val_loss: 0.7492 - val_accuracy: 0.6267\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4867 - accuracy: 0.7603 - val_loss: 0.7449 - val_accuracy: 0.6244\n","Epoch 69/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4916 - accuracy: 0.7462 - val_loss: 0.7880 - val_accuracy: 0.6143\n","Epoch 70/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4909 - accuracy: 0.7439 - val_loss: 0.7590 - val_accuracy: 0.6346\n","Epoch 71/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4854 - accuracy: 0.7569 - val_loss: 0.7556 - val_accuracy: 0.6301\n","Epoch 72/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4737 - accuracy: 0.7550 - val_loss: 0.7591 - val_accuracy: 0.6086\n","Epoch 73/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4896 - accuracy: 0.7482 - val_loss: 0.7545 - val_accuracy: 0.6324\n","Epoch 74/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4809 - accuracy: 0.7487 - val_loss: 0.7745 - val_accuracy: 0.6312\n","Epoch 75/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4813 - accuracy: 0.7501 - val_loss: 0.7671 - val_accuracy: 0.6267\n","Epoch 76/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4776 - accuracy: 0.7657 - val_loss: 0.7947 - val_accuracy: 0.6278\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4819 - accuracy: 0.7453 - val_loss: 0.7606 - val_accuracy: 0.6120\n","Epoch 78/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4755 - accuracy: 0.7649 - val_loss: 0.7901 - val_accuracy: 0.6176\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4825 - accuracy: 0.7530 - val_loss: 0.7587 - val_accuracy: 0.6301\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4712 - accuracy: 0.7552 - val_loss: 0.7709 - val_accuracy: 0.6176\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4775 - accuracy: 0.7566 - val_loss: 0.7995 - val_accuracy: 0.6097\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4641 - accuracy: 0.7694 - val_loss: 0.7711 - val_accuracy: 0.6312\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4697 - accuracy: 0.7620 - val_loss: 0.8148 - val_accuracy: 0.6109\n","Epoch 84/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4794 - accuracy: 0.7544 - val_loss: 0.8032 - val_accuracy: 0.6210\n","Epoch 85/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4642 - accuracy: 0.7677 - val_loss: 0.8085 - val_accuracy: 0.6097\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4700 - accuracy: 0.7634 - val_loss: 0.7886 - val_accuracy: 0.6188\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4645 - accuracy: 0.7637 - val_loss: 0.7981 - val_accuracy: 0.6120\n","Epoch 88/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4698 - accuracy: 0.7708 - val_loss: 0.7721 - val_accuracy: 0.6335\n","Epoch 89/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4572 - accuracy: 0.7660 - val_loss: 0.7977 - val_accuracy: 0.6301\n","Epoch 90/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4586 - accuracy: 0.7731 - val_loss: 0.7877 - val_accuracy: 0.6290\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4634 - accuracy: 0.7620 - val_loss: 0.8008 - val_accuracy: 0.6369\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4538 - accuracy: 0.7680 - val_loss: 0.7973 - val_accuracy: 0.6267\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4498 - accuracy: 0.7779 - val_loss: 0.7961 - val_accuracy: 0.6278\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4510 - accuracy: 0.7739 - val_loss: 0.8156 - val_accuracy: 0.6176\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4612 - accuracy: 0.7651 - val_loss: 0.8141 - val_accuracy: 0.6210\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4610 - accuracy: 0.7668 - val_loss: 0.8050 - val_accuracy: 0.6131\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4634 - accuracy: 0.7575 - val_loss: 0.7948 - val_accuracy: 0.6290\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4531 - accuracy: 0.7807 - val_loss: 0.8241 - val_accuracy: 0.6222\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4417 - accuracy: 0.7801 - val_loss: 0.8067 - val_accuracy: 0.6312\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4508 - accuracy: 0.7728 - val_loss: 0.8183 - val_accuracy: 0.6335\n","{'loss': [0.5877009034156799, 0.5735811591148376, 0.5635881423950195, 0.5693111419677734, 0.5661935210227966, 0.5602433681488037, 0.5681705474853516, 0.5591894388198853, 0.5639814734458923, 0.5612529516220093, 0.5597963333129883, 0.5625504851341248, 0.5505638122558594, 0.5514801144599915, 0.5525950193405151, 0.5525695085525513, 0.5493631958961487, 0.5483289361000061, 0.5388840436935425, 0.5450310111045837, 0.5490468144416809, 0.5452976226806641, 0.5371856689453125, 0.541084885597229, 0.546261727809906, 0.5381526947021484, 0.5341210961341858, 0.5302190184593201, 0.5285784006118774, 0.533376932144165, 0.5318781137466431, 0.5286386609077454, 0.5272813439369202, 0.5256133079528809, 0.5215315818786621, 0.5250546336174011, 0.5221376419067383, 0.5251702666282654, 0.5229388475418091, 0.5187151432037354, 0.5200589895248413, 0.5236067771911621, 0.5182448625564575, 0.5119909644126892, 0.5212945342063904, 0.5136725902557373, 0.5101622939109802, 0.5127298831939697, 0.5153744220733643, 0.5093832612037659, 0.5018278956413269, 0.5003171563148499, 0.5019747018814087, 0.5058593153953552, 0.5005854964256287, 0.5062856674194336, 0.5020624399185181, 0.4970434308052063, 0.4994141757488251, 0.5029215216636658, 0.49174055457115173, 0.4923960864543915, 0.49141639471054077, 0.49291908740997314, 0.48474743962287903, 0.4920935034751892, 0.48668742179870605, 0.48670676350593567, 0.4916485846042633, 0.49090269207954407, 0.48535019159317017, 0.47371426224708557, 0.4896274507045746, 0.4809403121471405, 0.48134127259254456, 0.47756627202033997, 0.48185107111930847, 0.4754883646965027, 0.4824647307395935, 0.4712120294570923, 0.4774748384952545, 0.46410417556762695, 0.46974313259124756, 0.4794350862503052, 0.4642099440097809, 0.46997976303100586, 0.4644794762134552, 0.46984630823135376, 0.4571598172187805, 0.45859840512275696, 0.4633556306362152, 0.4538448452949524, 0.44979128241539, 0.45095396041870117, 0.46121928095817566, 0.46097275614738464, 0.46342936158180237, 0.4531126618385315, 0.4417490065097809, 0.4508269727230072], 'accuracy': [0.6743067502975464, 0.6796830892562866, 0.6898698210716248, 0.6810979247093201, 0.676570475101471, 0.696943998336792, 0.6918506026268005, 0.6867572069168091, 0.6870402097702026, 0.6958121061325073, 0.6935483813285828, 0.6935483813285828, 0.6994906663894653, 0.6963780522346497, 0.6960950493812561, 0.7051499485969543, 0.7051499485969543, 0.7009055018424988, 0.7054329514503479, 0.6986417770385742, 0.7088285088539124, 0.698924720287323, 0.7139219045639038, 0.7085455656051636, 0.6994906663894653, 0.7105262875556946, 0.7116581797599792, 0.7142048478126526, 0.7164685726165771, 0.7076966762542725, 0.719298243522644, 0.706281840801239, 0.7187322974205017, 0.7260894179344177, 0.7201471328735352, 0.7241086363792419, 0.7218449115753174, 0.7263723611831665, 0.7190153002738953, 0.7345783710479736, 0.7246745824813843, 0.7252405285835266, 0.7201471328735352, 0.7255234718322754, 0.7167515754699707, 0.7345783710479736, 0.7334465384483337, 0.7292020320892334, 0.7246745824813843, 0.7292020320892334, 0.7396717667579651, 0.7340124249458313, 0.7331635355949402, 0.7376909852027893, 0.7368420958518982, 0.7396717667579651, 0.7357102632522583, 0.7374080419540405, 0.7382569313049316, 0.7385398745536804, 0.7473118305206299, 0.7507073879241943, 0.7433503270149231, 0.7515563368797302, 0.7524052262306213, 0.7495755553245544, 0.7436332702636719, 0.7603282332420349, 0.7461799383163452, 0.7439162135124207, 0.7569326758384705, 0.7549518942832947, 0.748160719871521, 0.7487266659736633, 0.7501415014266968, 0.7657045722007751, 0.7453310489654541, 0.764855682849884, 0.7529711127281189, 0.7552348375320435, 0.7566496729850769, 0.7693831324577332, 0.7620260119438171, 0.7543859481811523, 0.7676853537559509, 0.7634408473968506, 0.7637238502502441, 0.7707979679107666, 0.7659875750541687, 0.7730616927146912, 0.7620260119438171, 0.7679682970046997, 0.7778720855712891, 0.7739105820655823, 0.7651386260986328, 0.7668364644050598, 0.757498562335968, 0.780701756477356, 0.7801358103752136, 0.7727787494659424], 'val_loss': [0.6840025782585144, 0.6850948333740234, 0.6807072758674622, 0.6797463297843933, 0.6786317229270935, 0.6752431392669678, 0.6739335656166077, 0.6687830686569214, 0.6665225625038147, 0.6629764437675476, 0.6626034379005432, 0.6591945886611938, 0.6551347374916077, 0.6482365727424622, 0.6477184891700745, 0.6511999368667603, 0.6478996276855469, 0.6454555988311768, 0.6435599327087402, 0.6423247456550598, 0.6434991359710693, 0.6456075310707092, 0.6452789902687073, 0.656144380569458, 0.6481133103370667, 0.6518791317939758, 0.6569567322731018, 0.6677052974700928, 0.6624742150306702, 0.6631292700767517, 0.6852469444274902, 0.6690903902053833, 0.7021429538726807, 0.6874507665634155, 0.6804344058036804, 0.7042565941810608, 0.6960793137550354, 0.70068359375, 0.7192116975784302, 0.6831488013267517, 0.7310205101966858, 0.7239905595779419, 0.7020215392112732, 0.7436148524284363, 0.7046545147895813, 0.7088868618011475, 0.6963706612586975, 0.7198655009269714, 0.7250562310218811, 0.7125595808029175, 0.719811201095581, 0.7205015420913696, 0.7182919383049011, 0.7334684729576111, 0.7212380170822144, 0.7416297197341919, 0.7199018001556396, 0.7250496745109558, 0.7161868810653687, 0.7305517196655273, 0.7630975842475891, 0.7366122007369995, 0.7403353452682495, 0.7224530577659607, 0.7621763348579407, 0.7421786189079285, 0.7492234706878662, 0.7448525428771973, 0.7880010008811951, 0.7589900493621826, 0.755574643611908, 0.7591125965118408, 0.7544756531715393, 0.7745491862297058, 0.7670969367027283, 0.7946890592575073, 0.7606484293937683, 0.7900943160057068, 0.7587049603462219, 0.7709360122680664, 0.7994816899299622, 0.7711129188537598, 0.8148449063301086, 0.8032041788101196, 0.8085214495658875, 0.788588285446167, 0.7981002330780029, 0.772055447101593, 0.7977392077445984, 0.7876764535903931, 0.8007885217666626, 0.7973449230194092, 0.7960710525512695, 0.815579354763031, 0.8140664100646973, 0.8049516677856445, 0.7947501540184021, 0.8241367936134338, 0.8067355155944824, 0.8183253407478333], 'val_accuracy': [0.564479649066925, 0.523755669593811, 0.5554298758506775, 0.5757918357849121, 0.5486425161361694, 0.5757918357849121, 0.5565611124038696, 0.6199095249176025, 0.6244344115257263, 0.6006787419319153, 0.5882353186607361, 0.6029411554336548, 0.6255655884742737, 0.6470588445663452, 0.6368778347969055, 0.6018099784851074, 0.6142534017562866, 0.6334841847419739, 0.6346153616905212, 0.6233031749725342, 0.6187782883644104, 0.6233031749725342, 0.6357465982437134, 0.6380090713500977, 0.6357465982437134, 0.6233031749725342, 0.6300904750823975, 0.6436651349067688, 0.6402714848518372, 0.6425339579582214, 0.6402714848518372, 0.6357465982437134, 0.6187782883644104, 0.6357465982437134, 0.6572397947311401, 0.6323529481887817, 0.6255655884742737, 0.6300904750823975, 0.6425339579582214, 0.6368778347969055, 0.622171938419342, 0.5938913822174072, 0.639140248298645, 0.6199095249176025, 0.6233031749725342, 0.6165158152580261, 0.6210407018661499, 0.627828061580658, 0.6199095249176025, 0.6176470518112183, 0.6300904750823975, 0.622171938419342, 0.6357465982437134, 0.6470588445663452, 0.6085972785949707, 0.6266968250274658, 0.6380090713500977, 0.6210407018661499, 0.6334841847419739, 0.6233031749725342, 0.5972850918769836, 0.6255655884742737, 0.6165158152580261, 0.6312217116355896, 0.6436651349067688, 0.622171938419342, 0.6266968250274658, 0.6244344115257263, 0.6142534017562866, 0.6346153616905212, 0.6300904750823975, 0.6085972785949707, 0.6323529481887817, 0.6312217116355896, 0.6266968250274658, 0.627828061580658, 0.6119909286499023, 0.6176470518112183, 0.6300904750823975, 0.6176470518112183, 0.6097285151481628, 0.6312217116355896, 0.610859751701355, 0.6210407018661499, 0.6097285151481628, 0.6187782883644104, 0.6119909286499023, 0.6334841847419739, 0.6300904750823975, 0.6289592981338501, 0.6368778347969055, 0.6266968250274658, 0.627828061580658, 0.6176470518112183, 0.6210407018661499, 0.6131221652030945, 0.6289592981338501, 0.622171938419342, 0.6312217116355896, 0.6334841847419739]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.5925 - accuracy: 0.6635"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 67ms/step - loss: 0.5900 - accuracy: 0.6638 - val_loss: 0.6857 - val_accuracy: 0.5548\n","Epoch 2/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5860 - accuracy: 0.6708 - val_loss: 0.6872 - val_accuracy: 0.5279\n","Epoch 3/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5838 - accuracy: 0.6700 - val_loss: 0.6865 - val_accuracy: 0.5289\n","Epoch 4/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5754 - accuracy: 0.6783 - val_loss: 0.6829 - val_accuracy: 0.5558\n","Epoch 5/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5738 - accuracy: 0.6734 - val_loss: 0.6826 - val_accuracy: 0.5403\n","Epoch 6/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5761 - accuracy: 0.6791 - val_loss: 0.6801 - val_accuracy: 0.5764\n","Epoch 7/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5741 - accuracy: 0.6827 - val_loss: 0.6781 - val_accuracy: 0.5671\n","Epoch 8/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5704 - accuracy: 0.6827 - val_loss: 0.6760 - val_accuracy: 0.5661\n","Epoch 9/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5846 - accuracy: 0.6827 - val_loss: 0.6746 - val_accuracy: 0.5826\n","Epoch 10/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5683 - accuracy: 0.6780 - val_loss: 0.6731 - val_accuracy: 0.5775\n","Epoch 11/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5690 - accuracy: 0.6762 - val_loss: 0.6695 - val_accuracy: 0.5754\n","Epoch 12/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5663 - accuracy: 0.6811 - val_loss: 0.6679 - val_accuracy: 0.5837\n","Epoch 13/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5631 - accuracy: 0.6832 - val_loss: 0.6665 - val_accuracy: 0.5775\n","Epoch 14/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5633 - accuracy: 0.6827 - val_loss: 0.6638 - val_accuracy: 0.5775\n","Epoch 15/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5632 - accuracy: 0.6881 - val_loss: 0.6662 - val_accuracy: 0.5837\n","Epoch 16/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5625 - accuracy: 0.6791 - val_loss: 0.6618 - val_accuracy: 0.5919\n","Epoch 17/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5595 - accuracy: 0.6969 - val_loss: 0.6644 - val_accuracy: 0.5847\n","Epoch 18/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5573 - accuracy: 0.6915 - val_loss: 0.6792 - val_accuracy: 0.5775\n","Epoch 19/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5596 - accuracy: 0.6974 - val_loss: 0.6719 - val_accuracy: 0.5651\n","Epoch 20/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5543 - accuracy: 0.6951 - val_loss: 0.6856 - val_accuracy: 0.5744\n","Epoch 21/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5589 - accuracy: 0.6951 - val_loss: 0.6795 - val_accuracy: 0.5682\n","Epoch 22/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5525 - accuracy: 0.7010 - val_loss: 0.6946 - val_accuracy: 0.5857\n","Epoch 23/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5563 - accuracy: 0.6953 - val_loss: 0.6851 - val_accuracy: 0.5878\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5520 - accuracy: 0.6899 - val_loss: 0.7127 - val_accuracy: 0.5909\n","Epoch 25/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5559 - accuracy: 0.6917 - val_loss: 0.6985 - val_accuracy: 0.5723\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5502 - accuracy: 0.6992 - val_loss: 0.7116 - val_accuracy: 0.5816\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5457 - accuracy: 0.6938 - val_loss: 0.7136 - val_accuracy: 0.5764\n","Epoch 28/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5440 - accuracy: 0.7021 - val_loss: 0.7321 - val_accuracy: 0.5764\n","Epoch 29/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5514 - accuracy: 0.6948 - val_loss: 0.7211 - val_accuracy: 0.5764\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5408 - accuracy: 0.7096 - val_loss: 0.7277 - val_accuracy: 0.5826\n","Epoch 31/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5481 - accuracy: 0.7083 - val_loss: 0.7164 - val_accuracy: 0.5764\n","Epoch 32/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5410 - accuracy: 0.7049 - val_loss: 0.7585 - val_accuracy: 0.5713\n","Epoch 33/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5373 - accuracy: 0.7142 - val_loss: 0.7252 - val_accuracy: 0.5692\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5399 - accuracy: 0.7103 - val_loss: 0.7231 - val_accuracy: 0.5754\n","Epoch 35/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5386 - accuracy: 0.7101 - val_loss: 0.7734 - val_accuracy: 0.5651\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5375 - accuracy: 0.7090 - val_loss: 0.7311 - val_accuracy: 0.5733\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5398 - accuracy: 0.7163 - val_loss: 0.7553 - val_accuracy: 0.5733\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5343 - accuracy: 0.7137 - val_loss: 0.7483 - val_accuracy: 0.5661\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5296 - accuracy: 0.7109 - val_loss: 0.7901 - val_accuracy: 0.5589\n","Epoch 40/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5331 - accuracy: 0.7018 - val_loss: 0.7752 - val_accuracy: 0.5620\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5310 - accuracy: 0.7132 - val_loss: 0.7835 - val_accuracy: 0.5733\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5279 - accuracy: 0.7150 - val_loss: 0.7443 - val_accuracy: 0.5764\n","Epoch 43/100\n","31/31 [==============================] - 1s 45ms/step - loss: 0.5280 - accuracy: 0.7178 - val_loss: 0.7885 - val_accuracy: 0.5950\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5320 - accuracy: 0.7132 - val_loss: 0.7660 - val_accuracy: 0.5754\n","Epoch 45/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5344 - accuracy: 0.7134 - val_loss: 0.7622 - val_accuracy: 0.5764\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5245 - accuracy: 0.7124 - val_loss: 0.7748 - val_accuracy: 0.5857\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5286 - accuracy: 0.7090 - val_loss: 0.7733 - val_accuracy: 0.5599\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5329 - accuracy: 0.7059 - val_loss: 0.7725 - val_accuracy: 0.5723\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5230 - accuracy: 0.7163 - val_loss: 0.8122 - val_accuracy: 0.5424\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5191 - accuracy: 0.7209 - val_loss: 0.7599 - val_accuracy: 0.5568\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5224 - accuracy: 0.7196 - val_loss: 0.7882 - val_accuracy: 0.5733\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5197 - accuracy: 0.7271 - val_loss: 0.8046 - val_accuracy: 0.5744\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5187 - accuracy: 0.7225 - val_loss: 0.7573 - val_accuracy: 0.5775\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5222 - accuracy: 0.7295 - val_loss: 0.8220 - val_accuracy: 0.5713\n","Epoch 55/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5160 - accuracy: 0.7271 - val_loss: 0.7828 - val_accuracy: 0.5537\n","Epoch 56/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5134 - accuracy: 0.7264 - val_loss: 0.7843 - val_accuracy: 0.5496\n","Epoch 57/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5125 - accuracy: 0.7279 - val_loss: 0.7913 - val_accuracy: 0.5682\n","Epoch 58/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5154 - accuracy: 0.7181 - val_loss: 0.8483 - val_accuracy: 0.5527\n","Epoch 59/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5110 - accuracy: 0.7320 - val_loss: 0.7829 - val_accuracy: 0.5640\n","Epoch 60/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5112 - accuracy: 0.7238 - val_loss: 0.8041 - val_accuracy: 0.5475\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5040 - accuracy: 0.7437 - val_loss: 0.7853 - val_accuracy: 0.5754\n","Epoch 62/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5179 - accuracy: 0.7189 - val_loss: 0.7690 - val_accuracy: 0.5682\n","Epoch 63/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5318 - accuracy: 0.7147 - val_loss: 0.8794 - val_accuracy: 0.5754\n","Epoch 64/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5210 - accuracy: 0.7199 - val_loss: 0.8378 - val_accuracy: 0.5548\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5047 - accuracy: 0.7362 - val_loss: 0.8177 - val_accuracy: 0.5795\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5026 - accuracy: 0.7297 - val_loss: 0.8168 - val_accuracy: 0.5785\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4960 - accuracy: 0.7450 - val_loss: 0.8018 - val_accuracy: 0.5702\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5009 - accuracy: 0.7364 - val_loss: 0.8258 - val_accuracy: 0.5868\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4986 - accuracy: 0.7372 - val_loss: 0.8608 - val_accuracy: 0.5785\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5034 - accuracy: 0.7261 - val_loss: 0.8067 - val_accuracy: 0.5754\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4969 - accuracy: 0.7354 - val_loss: 0.7965 - val_accuracy: 0.5723\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4963 - accuracy: 0.7406 - val_loss: 0.8095 - val_accuracy: 0.5671\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4948 - accuracy: 0.7341 - val_loss: 0.8140 - val_accuracy: 0.5640\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5003 - accuracy: 0.7336 - val_loss: 0.8665 - val_accuracy: 0.5558\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4828 - accuracy: 0.7419 - val_loss: 0.8553 - val_accuracy: 0.5537\n","Epoch 76/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4887 - accuracy: 0.7491 - val_loss: 0.8501 - val_accuracy: 0.5713\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4860 - accuracy: 0.7470 - val_loss: 0.8675 - val_accuracy: 0.5589\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4859 - accuracy: 0.7406 - val_loss: 0.8604 - val_accuracy: 0.5589\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4886 - accuracy: 0.7450 - val_loss: 0.8276 - val_accuracy: 0.5620\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4898 - accuracy: 0.7434 - val_loss: 0.8922 - val_accuracy: 0.5620\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4934 - accuracy: 0.7416 - val_loss: 0.8454 - val_accuracy: 0.5651\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4855 - accuracy: 0.7463 - val_loss: 0.8512 - val_accuracy: 0.5733\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4832 - accuracy: 0.7509 - val_loss: 0.9284 - val_accuracy: 0.5589\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4904 - accuracy: 0.7465 - val_loss: 0.8387 - val_accuracy: 0.5661\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4814 - accuracy: 0.7553 - val_loss: 0.8685 - val_accuracy: 0.5785\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4825 - accuracy: 0.7561 - val_loss: 0.9243 - val_accuracy: 0.5806\n","Epoch 87/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4864 - accuracy: 0.7457 - val_loss: 0.9103 - val_accuracy: 0.5702\n","Epoch 88/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4793 - accuracy: 0.7519 - val_loss: 0.8864 - val_accuracy: 0.5847\n","Epoch 89/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4771 - accuracy: 0.7530 - val_loss: 0.8299 - val_accuracy: 0.5579\n","Epoch 90/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4827 - accuracy: 0.7527 - val_loss: 0.8857 - val_accuracy: 0.5537\n","Epoch 91/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4732 - accuracy: 0.7527 - val_loss: 0.8614 - val_accuracy: 0.5733\n","Epoch 92/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5014 - accuracy: 0.7346 - val_loss: 0.8833 - val_accuracy: 0.5413\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4916 - accuracy: 0.7478 - val_loss: 0.8967 - val_accuracy: 0.5702\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4750 - accuracy: 0.7530 - val_loss: 0.9263 - val_accuracy: 0.5506\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4687 - accuracy: 0.7579 - val_loss: 0.8874 - val_accuracy: 0.5775\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4743 - accuracy: 0.7589 - val_loss: 0.8976 - val_accuracy: 0.5548\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4679 - accuracy: 0.7618 - val_loss: 0.8716 - val_accuracy: 0.5589\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4704 - accuracy: 0.7566 - val_loss: 0.8797 - val_accuracy: 0.5630\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4713 - accuracy: 0.7649 - val_loss: 0.8743 - val_accuracy: 0.5506\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4660 - accuracy: 0.7532 - val_loss: 0.9189 - val_accuracy: 0.5548\n","{'loss': [0.5900400876998901, 0.5859953761100769, 0.5837554335594177, 0.5753756165504456, 0.5738438367843628, 0.5761219263076782, 0.5741056799888611, 0.5704233050346375, 0.5846031308174133, 0.5683165192604065, 0.5689741373062134, 0.5663086771965027, 0.5630925893783569, 0.5632873177528381, 0.5631884932518005, 0.5625104904174805, 0.5595108270645142, 0.5573208928108215, 0.5595608949661255, 0.5543270111083984, 0.5588914752006531, 0.5525115728378296, 0.5562946200370789, 0.5520153045654297, 0.5558962821960449, 0.5501683354377747, 0.5456736087799072, 0.5439851880073547, 0.5513540506362915, 0.5408222675323486, 0.5480801463127136, 0.5410121083259583, 0.537308394908905, 0.5399374961853027, 0.5386454463005066, 0.5375407338142395, 0.5397763848304749, 0.5342820286750793, 0.5295663475990295, 0.5331445932388306, 0.5310212969779968, 0.5278878808021545, 0.5280201435089111, 0.5319620370864868, 0.5344283580780029, 0.524516761302948, 0.5286392569541931, 0.5328622460365295, 0.5229573845863342, 0.5191217660903931, 0.522448718547821, 0.5196627974510193, 0.5187332034111023, 0.5222029685974121, 0.5159841775894165, 0.5133880972862244, 0.5125116109848022, 0.5153855085372925, 0.5109747648239136, 0.5111894607543945, 0.5040009617805481, 0.5178638100624084, 0.5318419933319092, 0.5210481882095337, 0.5046703219413757, 0.5026100873947144, 0.4960242211818695, 0.5008544325828552, 0.4986448287963867, 0.5033639073371887, 0.4969152510166168, 0.49625295400619507, 0.4947776794433594, 0.5003307461738586, 0.4828042984008789, 0.4886811077594757, 0.4860244393348694, 0.48590540885925293, 0.4886295199394226, 0.4897524416446686, 0.4934439957141876, 0.4854795038700104, 0.4832261800765991, 0.4903835952281952, 0.48139050602912903, 0.48246002197265625, 0.48641952872276306, 0.4793154001235962, 0.47708427906036377, 0.48269712924957275, 0.47321730852127075, 0.5013822913169861, 0.4916495978832245, 0.47500112652778625, 0.46868908405303955, 0.4743292033672333, 0.46791237592697144, 0.47039005160331726, 0.4713125228881836, 0.4660404324531555], 'accuracy': [0.6638242602348328, 0.670801043510437, 0.6700258255004883, 0.6782945990562439, 0.6733850240707397, 0.6790697574615479, 0.6826873421669006, 0.6826873421669006, 0.6826873421669006, 0.6780361533164978, 0.6762273907661438, 0.681136965751648, 0.6832041144371033, 0.6826873421669006, 0.6881136894226074, 0.6790697574615479, 0.6968992352485657, 0.6914728879928589, 0.6974160075187683, 0.6950904130935669, 0.6950904130935669, 0.7010335922241211, 0.695348858833313, 0.6899224519729614, 0.6917312741279602, 0.6992248296737671, 0.6937984228134155, 0.7020671963691711, 0.6948320269584656, 0.709560751914978, 0.7082687616348267, 0.7049095630645752, 0.7142118811607361, 0.710335910320282, 0.7100775241851807, 0.7090439200401306, 0.7162790894508362, 0.7136951088905334, 0.7108527421951294, 0.7018088102340698, 0.713178277015686, 0.7149870991706848, 0.7178294658660889, 0.713178277015686, 0.7134366631507874, 0.7124031186103821, 0.7090439200401306, 0.7059431672096252, 0.7162790894508362, 0.7209302186965942, 0.7196382284164429, 0.7271317839622498, 0.7224805951118469, 0.7294573783874512, 0.7271317839622498, 0.726356565952301, 0.7279070019721985, 0.7180878520011902, 0.7320413589477539, 0.7237725853919983, 0.7436692714691162, 0.7188630700111389, 0.7147286534309387, 0.7198966145515442, 0.7361757159233093, 0.7297157645225525, 0.7449612617492676, 0.7364341020584106, 0.7372093200683594, 0.7260981798171997, 0.7354004979133606, 0.7405684590339661, 0.7341085076332092, 0.7335917353630066, 0.7418604493141174, 0.749095618724823, 0.7470284104347229, 0.7405684590339661, 0.7449612617492676, 0.7434108257293701, 0.7416020631790161, 0.746253252029419, 0.750904381275177, 0.7465116381645203, 0.7552971839904785, 0.7560723423957825, 0.7457364201545715, 0.751937985420227, 0.7529715895652771, 0.7527132034301758, 0.7527132034301758, 0.7346253395080566, 0.7478036284446716, 0.7529715895652771, 0.7578811645507812, 0.7589147090911865, 0.7617571353912354, 0.7565891742706299, 0.7648578882217407, 0.7532299757003784], 'val_loss': [0.6857486367225647, 0.6872049570083618, 0.6865007281303406, 0.6829025149345398, 0.6826420426368713, 0.6801322102546692, 0.6781168580055237, 0.6760124564170837, 0.6745703220367432, 0.6731348633766174, 0.6694623231887817, 0.6678840517997742, 0.666467547416687, 0.6637902855873108, 0.6661506295204163, 0.6617792844772339, 0.6643590331077576, 0.6791591644287109, 0.671859085559845, 0.6856409907341003, 0.6794954538345337, 0.6945757269859314, 0.6851023435592651, 0.7126586437225342, 0.6984961628913879, 0.7115924954414368, 0.7135913372039795, 0.7321068644523621, 0.7210555672645569, 0.727675199508667, 0.7163945436477661, 0.7585175633430481, 0.7252174019813538, 0.723148763179779, 0.7734265327453613, 0.7311253547668457, 0.7552627921104431, 0.7483370900154114, 0.7901473045349121, 0.7751618027687073, 0.7834635972976685, 0.744272768497467, 0.7885274887084961, 0.7659738063812256, 0.7621729969978333, 0.7748035788536072, 0.773314356803894, 0.7724933624267578, 0.8122328519821167, 0.7599191069602966, 0.7881886959075928, 0.8046157360076904, 0.7573153972625732, 0.8219670057296753, 0.7827613949775696, 0.7843059301376343, 0.7913098931312561, 0.8482677340507507, 0.7829114198684692, 0.8040778040885925, 0.78531813621521, 0.7690208554267883, 0.8793519735336304, 0.8378238081932068, 0.8176769614219666, 0.8167857527732849, 0.8018086552619934, 0.8257869482040405, 0.8608204126358032, 0.8066734075546265, 0.796501636505127, 0.8095259666442871, 0.8139728307723999, 0.8664862513542175, 0.8552747368812561, 0.8501396775245667, 0.8674609661102295, 0.8604151010513306, 0.8275748491287231, 0.8921632170677185, 0.8454012870788574, 0.8512117862701416, 0.9284091591835022, 0.83867347240448, 0.8685222864151001, 0.9242757558822632, 0.910336971282959, 0.8863687515258789, 0.8298820853233337, 0.8856675624847412, 0.8613919615745544, 0.8832881450653076, 0.896675705909729, 0.926273763179779, 0.8874170184135437, 0.8975738286972046, 0.8715804815292358, 0.8796713948249817, 0.8742927312850952, 0.9189339280128479], 'val_accuracy': [0.5547520518302917, 0.5278925895690918, 0.5289255976676941, 0.5557851195335388, 0.5402892827987671, 0.5764462947845459, 0.567148745059967, 0.56611567735672, 0.5826446413993835, 0.577479362487793, 0.5754132270812988, 0.5836777091026306, 0.577479362487793, 0.577479362487793, 0.5836777091026306, 0.5919421315193176, 0.5847107172012329, 0.577479362487793, 0.5650826692581177, 0.5743801593780518, 0.5681818127632141, 0.58574378490448, 0.5878099203109741, 0.5909090638160706, 0.5723140239715576, 0.5816115736961365, 0.5764462947845459, 0.5764462947845459, 0.5764462947845459, 0.5826446413993835, 0.5764462947845459, 0.5712810158729553, 0.5692148804664612, 0.5754132270812988, 0.5650826692581177, 0.5733470916748047, 0.5733470916748047, 0.56611567735672, 0.55888432264328, 0.5619834661483765, 0.5733470916748047, 0.5764462947845459, 0.5950413346290588, 0.5754132270812988, 0.5764462947845459, 0.58574378490448, 0.5599173307418823, 0.5723140239715576, 0.5423553586006165, 0.5568181872367859, 0.5733470916748047, 0.5743801593780518, 0.577479362487793, 0.5712810158729553, 0.5537189841270447, 0.5495867729187012, 0.5681818127632141, 0.5526859760284424, 0.5640496015548706, 0.547520637512207, 0.5754132270812988, 0.5681818127632141, 0.5754132270812988, 0.5547520518302917, 0.5795454382896423, 0.5785123705863953, 0.5702479481697083, 0.586776852607727, 0.5785123705863953, 0.5754132270812988, 0.5723140239715576, 0.567148745059967, 0.5640496015548706, 0.5557851195335388, 0.5537189841270447, 0.5712810158729553, 0.55888432264328, 0.55888432264328, 0.5619834661483765, 0.5619834661483765, 0.5650826692581177, 0.5733470916748047, 0.55888432264328, 0.56611567735672, 0.5785123705863953, 0.5805785059928894, 0.5702479481697083, 0.5847107172012329, 0.557851254940033, 0.5537189841270447, 0.5733470916748047, 0.5413222908973694, 0.5702479481697083, 0.5506198406219482, 0.577479362487793, 0.5547520518302917, 0.55888432264328, 0.5630165338516235, 0.5506198406219482, 0.5547520518302917]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.5037 - accuracy: 0.7321"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 6s 54ms/step - loss: 0.5023 - accuracy: 0.7325 - val_loss: 0.6829 - val_accuracy: 0.5356\n","Epoch 2/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4977 - accuracy: 0.7454 - val_loss: 0.6843 - val_accuracy: 0.5776\n","Epoch 3/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5041 - accuracy: 0.7268 - val_loss: 0.6875 - val_accuracy: 0.5054\n","Epoch 4/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4859 - accuracy: 0.7465 - val_loss: 0.6815 - val_accuracy: 0.5237\n","Epoch 5/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4849 - accuracy: 0.7460 - val_loss: 0.6777 - val_accuracy: 0.5345\n","Epoch 6/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4840 - accuracy: 0.7497 - val_loss: 0.6722 - val_accuracy: 0.6002\n","Epoch 7/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4828 - accuracy: 0.7500 - val_loss: 0.6758 - val_accuracy: 0.5733\n","Epoch 8/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4755 - accuracy: 0.7546 - val_loss: 0.6782 - val_accuracy: 0.5506\n","Epoch 9/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4731 - accuracy: 0.7562 - val_loss: 0.6706 - val_accuracy: 0.5700\n","Epoch 10/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4792 - accuracy: 0.7527 - val_loss: 0.6694 - val_accuracy: 0.5927\n","Epoch 11/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4718 - accuracy: 0.7516 - val_loss: 0.6698 - val_accuracy: 0.6325\n","Epoch 12/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4677 - accuracy: 0.7632 - val_loss: 0.6665 - val_accuracy: 0.6347\n","Epoch 13/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4684 - accuracy: 0.7554 - val_loss: 0.6712 - val_accuracy: 0.5851\n","Epoch 14/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4637 - accuracy: 0.7567 - val_loss: 0.6882 - val_accuracy: 0.5700\n","Epoch 15/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4662 - accuracy: 0.7610 - val_loss: 0.6749 - val_accuracy: 0.6519\n","Epoch 16/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4606 - accuracy: 0.7689 - val_loss: 0.6727 - val_accuracy: 0.6207\n","Epoch 17/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4587 - accuracy: 0.7691 - val_loss: 0.6807 - val_accuracy: 0.6228\n","Epoch 18/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4621 - accuracy: 0.7654 - val_loss: 0.6795 - val_accuracy: 0.6250\n","Epoch 19/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4627 - accuracy: 0.7578 - val_loss: 0.6906 - val_accuracy: 0.6347\n","Epoch 20/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4624 - accuracy: 0.7678 - val_loss: 0.6990 - val_accuracy: 0.6390\n","Epoch 21/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4626 - accuracy: 0.7627 - val_loss: 0.7204 - val_accuracy: 0.6228\n","Epoch 22/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4539 - accuracy: 0.7675 - val_loss: 0.6912 - val_accuracy: 0.6649\n","Epoch 23/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4500 - accuracy: 0.7702 - val_loss: 0.6996 - val_accuracy: 0.6552\n","Epoch 24/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4622 - accuracy: 0.7621 - val_loss: 0.6953 - val_accuracy: 0.6681\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4516 - accuracy: 0.7751 - val_loss: 0.7124 - val_accuracy: 0.6487\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4446 - accuracy: 0.7791 - val_loss: 0.7298 - val_accuracy: 0.6616\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4566 - accuracy: 0.7686 - val_loss: 0.7484 - val_accuracy: 0.6562\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4434 - accuracy: 0.7721 - val_loss: 0.7382 - val_accuracy: 0.6670\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4421 - accuracy: 0.7769 - val_loss: 0.7488 - val_accuracy: 0.6541\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4441 - accuracy: 0.7742 - val_loss: 0.7730 - val_accuracy: 0.6595\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4381 - accuracy: 0.7745 - val_loss: 0.7987 - val_accuracy: 0.6347\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4375 - accuracy: 0.7821 - val_loss: 0.7795 - val_accuracy: 0.6552\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4301 - accuracy: 0.7831 - val_loss: 0.8098 - val_accuracy: 0.6315\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4372 - accuracy: 0.7748 - val_loss: 0.8267 - val_accuracy: 0.6196\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4395 - accuracy: 0.7780 - val_loss: 0.8172 - val_accuracy: 0.6304\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4281 - accuracy: 0.7818 - val_loss: 0.8040 - val_accuracy: 0.6562\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4330 - accuracy: 0.7842 - val_loss: 0.8066 - val_accuracy: 0.6627\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4352 - accuracy: 0.7742 - val_loss: 0.8147 - val_accuracy: 0.6530\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4300 - accuracy: 0.7861 - val_loss: 0.8175 - val_accuracy: 0.6638\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4357 - accuracy: 0.7848 - val_loss: 0.8388 - val_accuracy: 0.6498\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4360 - accuracy: 0.7856 - val_loss: 0.8438 - val_accuracy: 0.6455\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4285 - accuracy: 0.7812 - val_loss: 0.8125 - val_accuracy: 0.6573\n","Epoch 43/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4303 - accuracy: 0.7893 - val_loss: 0.8050 - val_accuracy: 0.6584\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4267 - accuracy: 0.7777 - val_loss: 0.8858 - val_accuracy: 0.6121\n","Epoch 45/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4192 - accuracy: 0.7918 - val_loss: 0.8311 - val_accuracy: 0.6498\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4351 - accuracy: 0.7764 - val_loss: 0.8301 - val_accuracy: 0.6573\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4252 - accuracy: 0.7950 - val_loss: 0.8146 - val_accuracy: 0.6616\n","Epoch 48/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4134 - accuracy: 0.7939 - val_loss: 0.8942 - val_accuracy: 0.6056\n","Epoch 49/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4141 - accuracy: 0.8020 - val_loss: 0.8251 - val_accuracy: 0.6498\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4169 - accuracy: 0.7971 - val_loss: 0.8339 - val_accuracy: 0.6509\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4294 - accuracy: 0.7853 - val_loss: 0.8227 - val_accuracy: 0.6584\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4160 - accuracy: 0.7899 - val_loss: 0.8582 - val_accuracy: 0.6228\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4096 - accuracy: 0.7928 - val_loss: 0.8786 - val_accuracy: 0.6207\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4047 - accuracy: 0.8068 - val_loss: 0.8351 - val_accuracy: 0.6487\n","Epoch 55/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4039 - accuracy: 0.7939 - val_loss: 0.8239 - val_accuracy: 0.6466\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4140 - accuracy: 0.7907 - val_loss: 0.8589 - val_accuracy: 0.6347\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4068 - accuracy: 0.7920 - val_loss: 0.8998 - val_accuracy: 0.6207\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4020 - accuracy: 0.8012 - val_loss: 0.8434 - val_accuracy: 0.6595\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3976 - accuracy: 0.8033 - val_loss: 0.9022 - val_accuracy: 0.6250\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4029 - accuracy: 0.7969 - val_loss: 0.8536 - val_accuracy: 0.6595\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3931 - accuracy: 0.8020 - val_loss: 0.8582 - val_accuracy: 0.6444\n","Epoch 62/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3967 - accuracy: 0.8074 - val_loss: 0.8954 - val_accuracy: 0.6196\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3920 - accuracy: 0.8068 - val_loss: 0.9254 - val_accuracy: 0.6175\n","Epoch 64/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3900 - accuracy: 0.8052 - val_loss: 0.8524 - val_accuracy: 0.6444\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3952 - accuracy: 0.8001 - val_loss: 0.8927 - val_accuracy: 0.6390\n","Epoch 66/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3918 - accuracy: 0.8068 - val_loss: 0.8875 - val_accuracy: 0.6261\n","Epoch 67/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3872 - accuracy: 0.8071 - val_loss: 0.8911 - val_accuracy: 0.6228\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3857 - accuracy: 0.8085 - val_loss: 0.9101 - val_accuracy: 0.6293\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3852 - accuracy: 0.8128 - val_loss: 0.8638 - val_accuracy: 0.6422\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3908 - accuracy: 0.8087 - val_loss: 0.8827 - val_accuracy: 0.6519\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3860 - accuracy: 0.8006 - val_loss: 0.8973 - val_accuracy: 0.6336\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3801 - accuracy: 0.8074 - val_loss: 0.8738 - val_accuracy: 0.6401\n","Epoch 73/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3823 - accuracy: 0.8117 - val_loss: 0.9031 - val_accuracy: 0.6390\n","Epoch 74/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3809 - accuracy: 0.8122 - val_loss: 0.8700 - val_accuracy: 0.6509\n","Epoch 75/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3854 - accuracy: 0.8068 - val_loss: 0.9448 - val_accuracy: 0.6379\n","Epoch 76/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3924 - accuracy: 0.8082 - val_loss: 0.9193 - val_accuracy: 0.6562\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3798 - accuracy: 0.8160 - val_loss: 0.8882 - val_accuracy: 0.6509\n","Epoch 78/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3832 - accuracy: 0.8101 - val_loss: 0.9327 - val_accuracy: 0.6487\n","Epoch 79/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3954 - accuracy: 0.8079 - val_loss: 0.9151 - val_accuracy: 0.6444\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3873 - accuracy: 0.8125 - val_loss: 0.9097 - val_accuracy: 0.6519\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3770 - accuracy: 0.8182 - val_loss: 0.9833 - val_accuracy: 0.6099\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3742 - accuracy: 0.8157 - val_loss: 0.9837 - val_accuracy: 0.6099\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3748 - accuracy: 0.8206 - val_loss: 0.8843 - val_accuracy: 0.6595\n","Epoch 84/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3710 - accuracy: 0.8182 - val_loss: 0.8855 - val_accuracy: 0.6519\n","Epoch 85/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3697 - accuracy: 0.8209 - val_loss: 0.9197 - val_accuracy: 0.6433\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3642 - accuracy: 0.8279 - val_loss: 0.9848 - val_accuracy: 0.6304\n","Epoch 87/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3750 - accuracy: 0.8179 - val_loss: 0.9570 - val_accuracy: 0.6369\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3686 - accuracy: 0.8179 - val_loss: 0.9669 - val_accuracy: 0.6239\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3650 - accuracy: 0.8198 - val_loss: 0.9220 - val_accuracy: 0.6455\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3692 - accuracy: 0.8233 - val_loss: 0.9249 - val_accuracy: 0.6379\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3599 - accuracy: 0.8230 - val_loss: 0.9094 - val_accuracy: 0.6412\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3549 - accuracy: 0.8314 - val_loss: 1.0364 - val_accuracy: 0.6045\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3625 - accuracy: 0.8244 - val_loss: 0.9669 - val_accuracy: 0.6336\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3592 - accuracy: 0.8289 - val_loss: 0.9837 - val_accuracy: 0.6261\n","Epoch 95/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3457 - accuracy: 0.8381 - val_loss: 0.9454 - val_accuracy: 0.6336\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3521 - accuracy: 0.8300 - val_loss: 0.9746 - val_accuracy: 0.6422\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3497 - accuracy: 0.8381 - val_loss: 0.9968 - val_accuracy: 0.6325\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3549 - accuracy: 0.8297 - val_loss: 0.9534 - val_accuracy: 0.6379\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3586 - accuracy: 0.8268 - val_loss: 0.9206 - val_accuracy: 0.6573\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3533 - accuracy: 0.8322 - val_loss: 0.9451 - val_accuracy: 0.6552\n","{'loss': [0.5023136734962463, 0.4977312684059143, 0.5040500164031982, 0.48587292432785034, 0.4849356710910797, 0.4840167164802551, 0.48281922936439514, 0.4755287170410156, 0.4731327295303345, 0.47919392585754395, 0.4718434810638428, 0.46770554780960083, 0.4683911204338074, 0.4637492299079895, 0.4661610424518585, 0.46059778332710266, 0.4587305188179016, 0.4621182084083557, 0.4626975357532501, 0.46242374181747437, 0.4625581204891205, 0.4538774788379669, 0.4500119686126709, 0.4621843099594116, 0.45157158374786377, 0.4446175694465637, 0.45662277936935425, 0.4433673322200775, 0.4421205520629883, 0.4441100060939789, 0.4381374418735504, 0.4374675154685974, 0.4301226735115051, 0.4371797740459442, 0.439457505941391, 0.42805784940719604, 0.43296554684638977, 0.4351765513420105, 0.4299861788749695, 0.43565598130226135, 0.43596336245536804, 0.4284944534301758, 0.4303034543991089, 0.42668184638023376, 0.4191519618034363, 0.43510904908180237, 0.42522215843200684, 0.41336697340011597, 0.41405999660491943, 0.4168906807899475, 0.42941319942474365, 0.4160432517528534, 0.4095947742462158, 0.40468791127204895, 0.40394264459609985, 0.41401034593582153, 0.406834214925766, 0.40198880434036255, 0.3975687325000763, 0.40288999676704407, 0.39307931065559387, 0.3967156708240509, 0.39203763008117676, 0.38997530937194824, 0.3951610326766968, 0.39175981283187866, 0.38723689317703247, 0.38573402166366577, 0.38518497347831726, 0.3908095061779022, 0.38600003719329834, 0.3800521194934845, 0.38225552439689636, 0.3809398114681244, 0.3853890597820282, 0.3923771381378174, 0.3798300325870514, 0.3832198977470398, 0.3954382538795471, 0.3872848153114319, 0.37698647379875183, 0.3741770386695862, 0.37478235363960266, 0.37095966935157776, 0.36974814534187317, 0.36418086290359497, 0.37499088048934937, 0.36860835552215576, 0.36496827006340027, 0.36916711926460266, 0.3598795533180237, 0.35491010546684265, 0.362457811832428, 0.35918915271759033, 0.345699667930603, 0.35209405422210693, 0.3496764004230499, 0.3549368381500244, 0.3585904836654663, 0.35329538583755493], 'accuracy': [0.7324892282485962, 0.7454202771186829, 0.7268319129943848, 0.7464978694915771, 0.7459590435028076, 0.7497305870056152, 0.75, 0.7545797228813171, 0.756196141242981, 0.7526939511299133, 0.751616358757019, 0.7632004022598267, 0.7553879022598267, 0.7567349076271057, 0.7610452771186829, 0.7688577771186829, 0.7691271305084229, 0.7653555870056152, 0.7578125, 0.7677801847457886, 0.7626616358757019, 0.7675107717514038, 0.7702047228813171, 0.7621228694915771, 0.775053858757019, 0.7790948152542114, 0.7685883641242981, 0.772090494632721, 0.7769396305084229, 0.7742456793785095, 0.7745150923728943, 0.7820581793785095, 0.7831357717514038, 0.774784505367279, 0.7780172228813171, 0.7817887663841248, 0.7842133641242981, 0.7742456793785095, 0.7860991358757019, 0.7847521305084229, 0.7855603694915771, 0.78125, 0.7893319129943848, 0.7777478694915771, 0.7917564511299133, 0.7764008641242981, 0.7949892282485962, 0.7939116358757019, 0.8019935488700867, 0.7971444129943848, 0.7852909564971924, 0.7898706793785095, 0.7928340435028076, 0.8068426847457886, 0.7939116358757019, 0.790678858757019, 0.7920258641242981, 0.8011853694915771, 0.803340494632721, 0.796875, 0.8019935488700867, 0.8073814511299133, 0.8068426847457886, 0.8052262663841248, 0.8001077771186829, 0.8068426847457886, 0.8071120977401733, 0.8084590435028076, 0.8127694129943848, 0.8087284564971924, 0.8006465435028076, 0.8073814511299133, 0.8116918206214905, 0.8122305870056152, 0.8068426847457886, 0.8081896305084229, 0.8160021305084229, 0.8100754022598267, 0.8079202771186829, 0.8125, 0.8181573152542114, 0.8157327771186829, 0.8205819129943848, 0.8181573152542114, 0.8208512663841248, 0.8278555870056152, 0.8178879022598267, 0.8178879022598267, 0.8197737336158752, 0.8232758641242981, 0.8230064511299133, 0.8313577771186829, 0.8243534564971924, 0.8289331793785095, 0.8380926847457886, 0.8300107717514038, 0.8380926847457886, 0.829741358757019, 0.826777994632721, 0.8321659564971924], 'val_loss': [0.6829202771186829, 0.684281051158905, 0.6875084042549133, 0.6814857721328735, 0.6776784658432007, 0.6722487807273865, 0.6757755875587463, 0.6781811714172363, 0.6706106066703796, 0.6694030165672302, 0.669776976108551, 0.6665208339691162, 0.6711816191673279, 0.6881657242774963, 0.674872100353241, 0.6727237701416016, 0.6806966066360474, 0.6795247793197632, 0.6905555129051208, 0.6990306377410889, 0.7203758955001831, 0.6911727786064148, 0.6996241211891174, 0.6953309774398804, 0.7123876214027405, 0.729785144329071, 0.7483813762664795, 0.7382485866546631, 0.7488185167312622, 0.7730291485786438, 0.7986927032470703, 0.7794653177261353, 0.8097682595252991, 0.8266503810882568, 0.8171533346176147, 0.8039732575416565, 0.8065775036811829, 0.8147269487380981, 0.8174742460250854, 0.8387614488601685, 0.8438407182693481, 0.8125198483467102, 0.8050119876861572, 0.8857676982879639, 0.8310868740081787, 0.8300958871841431, 0.8145669102668762, 0.8941530585289001, 0.8251439332962036, 0.8339012861251831, 0.8227028846740723, 0.858201801776886, 0.8785550594329834, 0.8350816369056702, 0.8238524198532104, 0.858850359916687, 0.8997747302055359, 0.8434278964996338, 0.9022315740585327, 0.8535940051078796, 0.8582261204719543, 0.895353376865387, 0.9253732562065125, 0.8524284958839417, 0.892746090888977, 0.8875120878219604, 0.8911264538764954, 0.910123348236084, 0.8637508749961853, 0.8826560378074646, 0.8972674608230591, 0.8737931251525879, 0.9031181335449219, 0.8699741959571838, 0.9448064565658569, 0.9192636609077454, 0.8881641626358032, 0.9327059984207153, 0.9150990843772888, 0.9097301363945007, 0.983307421207428, 0.9837459325790405, 0.8843403458595276, 0.8855028748512268, 0.9197158217430115, 0.984824001789093, 0.9569672346115112, 0.9668834209442139, 0.9219716787338257, 0.9248907566070557, 0.9093522429466248, 1.0363595485687256, 0.9669499397277832, 0.9837404489517212, 0.9454327821731567, 0.9745792746543884, 0.9967774748802185, 0.9534080028533936, 0.9206332564353943, 0.9451050758361816], 'val_accuracy': [0.5355603694915771, 0.5775862336158752, 0.5053879022598267, 0.5237069129943848, 0.5344827771186829, 0.600215494632721, 0.5732758641242981, 0.5506465435028076, 0.5700430870056152, 0.5926724076271057, 0.6325430870056152, 0.6346982717514038, 0.5851293206214905, 0.5700430870056152, 0.6519396305084229, 0.6206896305084229, 0.6228448152542114, 0.625, 0.6346982717514038, 0.639008641242981, 0.6228448152542114, 0.6648706793785095, 0.6551724076271057, 0.6681034564971924, 0.6487069129943848, 0.6616379022598267, 0.65625, 0.6670258641242981, 0.6540948152542114, 0.6594827771186829, 0.6346982717514038, 0.6551724076271057, 0.631465494632721, 0.6196120977401733, 0.6303879022598267, 0.65625, 0.662715494632721, 0.6530172228813171, 0.6637930870056152, 0.649784505367279, 0.6454741358757019, 0.6573275923728943, 0.6584051847457886, 0.6120689511299133, 0.649784505367279, 0.6573275923728943, 0.6616379022598267, 0.6056034564971924, 0.649784505367279, 0.6508620977401733, 0.6584051847457886, 0.6228448152542114, 0.6206896305084229, 0.6487069129943848, 0.6465517282485962, 0.6346982717514038, 0.6206896305084229, 0.6594827771186829, 0.625, 0.6594827771186829, 0.6443965435028076, 0.6196120977401733, 0.6174569129943848, 0.6443965435028076, 0.639008641242981, 0.6260775923728943, 0.6228448152542114, 0.6293103694915771, 0.642241358757019, 0.6519396305084229, 0.6336206793785095, 0.6400862336158752, 0.639008641242981, 0.6508620977401733, 0.6379310488700867, 0.65625, 0.6508620977401733, 0.6487069129943848, 0.6443965435028076, 0.6519396305084229, 0.6099137663841248, 0.6099137663841248, 0.6594827771186829, 0.6519396305084229, 0.6433189511299133, 0.6303879022598267, 0.6368534564971924, 0.6239224076271057, 0.6454741358757019, 0.6379310488700867, 0.6411637663841248, 0.6045258641242981, 0.6336206793785095, 0.6260775923728943, 0.6336206793785095, 0.642241358757019, 0.6325430870056152, 0.6379310488700867, 0.6573275923728943, 0.6551724076271057]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","24/28 [========================>.....] - ETA: 0s - loss: 0.5074 - accuracy: 0.7383"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 54ms/step - loss: 0.5091 - accuracy: 0.7377 - val_loss: 0.6731 - val_accuracy: 0.5758\n","Epoch 2/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4992 - accuracy: 0.7436 - val_loss: 0.6732 - val_accuracy: 0.5837\n","Epoch 3/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4887 - accuracy: 0.7499 - val_loss: 0.6692 - val_accuracy: 0.5984\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4849 - accuracy: 0.7510 - val_loss: 0.6668 - val_accuracy: 0.6176\n","Epoch 5/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4882 - accuracy: 0.7459 - val_loss: 0.6623 - val_accuracy: 0.5962\n","Epoch 6/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4847 - accuracy: 0.7490 - val_loss: 0.6608 - val_accuracy: 0.6075\n","Epoch 7/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4765 - accuracy: 0.7637 - val_loss: 0.6526 - val_accuracy: 0.6063\n","Epoch 8/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4961 - accuracy: 0.7530 - val_loss: 0.6551 - val_accuracy: 0.6154\n","Epoch 9/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4711 - accuracy: 0.7632 - val_loss: 0.6472 - val_accuracy: 0.6414\n","Epoch 10/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4765 - accuracy: 0.7561 - val_loss: 0.6450 - val_accuracy: 0.5882\n","Epoch 11/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4745 - accuracy: 0.7592 - val_loss: 0.6411 - val_accuracy: 0.6007\n","Epoch 12/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4681 - accuracy: 0.7654 - val_loss: 0.6334 - val_accuracy: 0.6278\n","Epoch 13/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4708 - accuracy: 0.7666 - val_loss: 0.6305 - val_accuracy: 0.6267\n","Epoch 14/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4769 - accuracy: 0.7552 - val_loss: 0.6240 - val_accuracy: 0.6527\n","Epoch 15/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4700 - accuracy: 0.7595 - val_loss: 0.6193 - val_accuracy: 0.6482\n","Epoch 16/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4596 - accuracy: 0.7728 - val_loss: 0.6190 - val_accuracy: 0.6437\n","Epoch 17/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4698 - accuracy: 0.7705 - val_loss: 0.6206 - val_accuracy: 0.6380\n","Epoch 18/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4634 - accuracy: 0.7674 - val_loss: 0.6137 - val_accuracy: 0.6686\n","Epoch 19/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4570 - accuracy: 0.7671 - val_loss: 0.6106 - val_accuracy: 0.6674\n","Epoch 20/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4654 - accuracy: 0.7722 - val_loss: 0.6226 - val_accuracy: 0.6391\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4624 - accuracy: 0.7651 - val_loss: 0.6120 - val_accuracy: 0.6652\n","Epoch 22/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4560 - accuracy: 0.7773 - val_loss: 0.6255 - val_accuracy: 0.6640\n","Epoch 23/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.4562 - accuracy: 0.7736 - val_loss: 0.6592 - val_accuracy: 0.6776\n","Epoch 24/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4425 - accuracy: 0.7864 - val_loss: 0.6291 - val_accuracy: 0.6686\n","Epoch 25/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4472 - accuracy: 0.7756 - val_loss: 0.6484 - val_accuracy: 0.6618\n","Epoch 26/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4540 - accuracy: 0.7708 - val_loss: 0.6570 - val_accuracy: 0.6606\n","Epoch 27/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4463 - accuracy: 0.7773 - val_loss: 0.6647 - val_accuracy: 0.6719\n","Epoch 28/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4497 - accuracy: 0.7790 - val_loss: 0.6562 - val_accuracy: 0.6787\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4407 - accuracy: 0.7782 - val_loss: 0.7077 - val_accuracy: 0.6719\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4495 - accuracy: 0.7719 - val_loss: 0.6941 - val_accuracy: 0.6674\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4541 - accuracy: 0.7816 - val_loss: 0.7203 - val_accuracy: 0.6742\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4543 - accuracy: 0.7796 - val_loss: 0.6936 - val_accuracy: 0.6595\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4365 - accuracy: 0.7830 - val_loss: 0.7180 - val_accuracy: 0.6742\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4343 - accuracy: 0.7858 - val_loss: 0.7041 - val_accuracy: 0.6697\n","Epoch 35/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4434 - accuracy: 0.7838 - val_loss: 0.7367 - val_accuracy: 0.6799\n","Epoch 36/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4422 - accuracy: 0.7818 - val_loss: 0.6901 - val_accuracy: 0.6652\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4390 - accuracy: 0.7892 - val_loss: 0.7266 - val_accuracy: 0.6640\n","Epoch 38/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4356 - accuracy: 0.7849 - val_loss: 0.7229 - val_accuracy: 0.6719\n","Epoch 39/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4270 - accuracy: 0.7920 - val_loss: 0.7161 - val_accuracy: 0.6765\n","Epoch 40/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4296 - accuracy: 0.7903 - val_loss: 0.7394 - val_accuracy: 0.6538\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4290 - accuracy: 0.7954 - val_loss: 0.7450 - val_accuracy: 0.6652\n","Epoch 42/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4336 - accuracy: 0.7855 - val_loss: 0.7239 - val_accuracy: 0.6652\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4263 - accuracy: 0.7866 - val_loss: 0.7408 - val_accuracy: 0.6595\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4284 - accuracy: 0.8011 - val_loss: 0.7249 - val_accuracy: 0.6538\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4270 - accuracy: 0.7892 - val_loss: 0.7512 - val_accuracy: 0.6776\n","Epoch 46/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4314 - accuracy: 0.7929 - val_loss: 0.7345 - val_accuracy: 0.6652\n","Epoch 47/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4178 - accuracy: 0.7997 - val_loss: 0.7254 - val_accuracy: 0.6550\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4194 - accuracy: 0.7949 - val_loss: 0.7267 - val_accuracy: 0.6686\n","Epoch 49/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4269 - accuracy: 0.7864 - val_loss: 0.7256 - val_accuracy: 0.6606\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4151 - accuracy: 0.7977 - val_loss: 0.7631 - val_accuracy: 0.6414\n","Epoch 51/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4221 - accuracy: 0.7965 - val_loss: 0.7918 - val_accuracy: 0.6606\n","Epoch 52/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4100 - accuracy: 0.8033 - val_loss: 0.7411 - val_accuracy: 0.6629\n","Epoch 53/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4076 - accuracy: 0.8045 - val_loss: 0.7666 - val_accuracy: 0.6708\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4130 - accuracy: 0.8028 - val_loss: 0.7194 - val_accuracy: 0.6640\n","Epoch 55/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4168 - accuracy: 0.7971 - val_loss: 0.8084 - val_accuracy: 0.6471\n","Epoch 56/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4089 - accuracy: 0.8053 - val_loss: 0.7457 - val_accuracy: 0.6538\n","Epoch 57/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4176 - accuracy: 0.8008 - val_loss: 0.7423 - val_accuracy: 0.6493\n","Epoch 58/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4263 - accuracy: 0.8022 - val_loss: 0.7507 - val_accuracy: 0.6595\n","Epoch 59/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4161 - accuracy: 0.8014 - val_loss: 0.7546 - val_accuracy: 0.6572\n","Epoch 60/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4247 - accuracy: 0.7974 - val_loss: 0.7922 - val_accuracy: 0.6584\n","Epoch 61/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4060 - accuracy: 0.8019 - val_loss: 0.7646 - val_accuracy: 0.6448\n","Epoch 62/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3964 - accuracy: 0.8166 - val_loss: 0.7989 - val_accuracy: 0.6482\n","Epoch 63/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4031 - accuracy: 0.7997 - val_loss: 0.8411 - val_accuracy: 0.6256\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4015 - accuracy: 0.8158 - val_loss: 0.7971 - val_accuracy: 0.6550\n","Epoch 65/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4060 - accuracy: 0.8042 - val_loss: 0.7617 - val_accuracy: 0.6527\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3977 - accuracy: 0.8113 - val_loss: 0.8008 - val_accuracy: 0.6629\n","Epoch 67/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4011 - accuracy: 0.8096 - val_loss: 0.7869 - val_accuracy: 0.6595\n","Epoch 68/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4119 - accuracy: 0.7971 - val_loss: 0.8679 - val_accuracy: 0.6290\n","Epoch 69/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4072 - accuracy: 0.7982 - val_loss: 0.8021 - val_accuracy: 0.6595\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3938 - accuracy: 0.8113 - val_loss: 0.7956 - val_accuracy: 0.6538\n","Epoch 71/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3918 - accuracy: 0.8090 - val_loss: 0.8186 - val_accuracy: 0.6357\n","Epoch 72/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4001 - accuracy: 0.8033 - val_loss: 0.7776 - val_accuracy: 0.6505\n","Epoch 73/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4000 - accuracy: 0.8113 - val_loss: 0.8108 - val_accuracy: 0.6572\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3943 - accuracy: 0.8127 - val_loss: 0.8302 - val_accuracy: 0.6448\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3844 - accuracy: 0.8138 - val_loss: 0.8407 - val_accuracy: 0.6391\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3882 - accuracy: 0.8158 - val_loss: 0.8554 - val_accuracy: 0.6414\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3815 - accuracy: 0.8172 - val_loss: 0.8171 - val_accuracy: 0.6527\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3913 - accuracy: 0.8050 - val_loss: 0.8043 - val_accuracy: 0.6550\n","Epoch 79/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3867 - accuracy: 0.8206 - val_loss: 0.8217 - val_accuracy: 0.6414\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3761 - accuracy: 0.8231 - val_loss: 0.8554 - val_accuracy: 0.6369\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3784 - accuracy: 0.8209 - val_loss: 0.8913 - val_accuracy: 0.6267\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3757 - accuracy: 0.8274 - val_loss: 0.8775 - val_accuracy: 0.6584\n","Epoch 83/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3867 - accuracy: 0.8175 - val_loss: 0.8827 - val_accuracy: 0.6256\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3757 - accuracy: 0.8297 - val_loss: 0.8214 - val_accuracy: 0.6437\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3745 - accuracy: 0.8288 - val_loss: 0.8906 - val_accuracy: 0.6425\n","Epoch 86/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3823 - accuracy: 0.8189 - val_loss: 0.8532 - val_accuracy: 0.6550\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3794 - accuracy: 0.8195 - val_loss: 0.8371 - val_accuracy: 0.6403\n","Epoch 88/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3985 - accuracy: 0.8155 - val_loss: 0.8687 - val_accuracy: 0.6606\n","Epoch 89/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3748 - accuracy: 0.8209 - val_loss: 0.8336 - val_accuracy: 0.6505\n","Epoch 90/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3750 - accuracy: 0.8260 - val_loss: 0.8516 - val_accuracy: 0.6561\n","Epoch 91/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3789 - accuracy: 0.8254 - val_loss: 0.8325 - val_accuracy: 0.6550\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3625 - accuracy: 0.8333 - val_loss: 0.8708 - val_accuracy: 0.6471\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3638 - accuracy: 0.8302 - val_loss: 0.8180 - val_accuracy: 0.6448\n","Epoch 94/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3657 - accuracy: 0.8302 - val_loss: 0.8362 - val_accuracy: 0.6493\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3765 - accuracy: 0.8257 - val_loss: 0.8583 - val_accuracy: 0.6493\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3619 - accuracy: 0.8314 - val_loss: 0.8304 - val_accuracy: 0.6482\n","Epoch 97/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3622 - accuracy: 0.8308 - val_loss: 0.9077 - val_accuracy: 0.6290\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3601 - accuracy: 0.8314 - val_loss: 0.9258 - val_accuracy: 0.6403\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3544 - accuracy: 0.8362 - val_loss: 0.8793 - val_accuracy: 0.6527\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3584 - accuracy: 0.8319 - val_loss: 0.9082 - val_accuracy: 0.6267\n","{'loss': [0.5090556740760803, 0.49917373061180115, 0.4886869192123413, 0.48488926887512207, 0.48820289969444275, 0.48470327258110046, 0.4764980375766754, 0.4960997998714447, 0.4710598289966583, 0.47654515504837036, 0.4745292067527771, 0.4681398272514343, 0.4708110988140106, 0.4768524169921875, 0.4700280725955963, 0.4595961570739746, 0.46978774666786194, 0.46339505910873413, 0.4570091664791107, 0.4653789699077606, 0.4624404013156891, 0.4559549391269684, 0.4562329947948456, 0.44253110885620117, 0.44722241163253784, 0.4540207087993622, 0.4463222920894623, 0.44972869753837585, 0.44066449999809265, 0.4494870901107788, 0.45411020517349243, 0.4543274939060211, 0.4365319311618805, 0.43430793285369873, 0.44339802861213684, 0.44217705726623535, 0.43897590041160583, 0.4356016516685486, 0.42700934410095215, 0.4296184778213501, 0.4290263056755066, 0.4335613548755646, 0.4263229966163635, 0.4283810257911682, 0.42704465985298157, 0.43144017457962036, 0.41776156425476074, 0.4193955957889557, 0.42690402269363403, 0.4151214361190796, 0.42208942770957947, 0.4099957346916199, 0.4076286554336548, 0.4129824638366699, 0.41682735085487366, 0.40893062949180603, 0.41757258772850037, 0.4262761175632477, 0.4161446690559387, 0.4246538579463959, 0.40595129132270813, 0.39635059237480164, 0.40312716364860535, 0.4014987647533417, 0.4059757590293884, 0.3976575434207916, 0.4011489450931549, 0.41193974018096924, 0.40722891688346863, 0.3938298225402832, 0.39177191257476807, 0.40013614296913147, 0.4000242054462433, 0.3943313658237457, 0.3843764066696167, 0.3882315158843994, 0.38149845600128174, 0.39126819372177124, 0.3866555392742157, 0.37613245844841003, 0.37838974595069885, 0.3756885826587677, 0.38667044043540955, 0.3756546378135681, 0.37446129322052, 0.38228386640548706, 0.37936127185821533, 0.3985026776790619, 0.37478840351104736, 0.3749624490737915, 0.37894389033317566, 0.3625088334083557, 0.36380788683891296, 0.36568328738212585, 0.37646007537841797, 0.3619246482849121, 0.3621752858161926, 0.3600817322731018, 0.3543619215488434, 0.35841307044029236], 'accuracy': [0.7376909852027893, 0.7436332702636719, 0.7498584985733032, 0.7509903907775879, 0.7458969950675964, 0.7490096092224121, 0.7637238502502441, 0.7529711127281189, 0.7631579041481018, 0.7560837864875793, 0.759196400642395, 0.7654216289520264, 0.7665534615516663, 0.7552348375320435, 0.7594793438911438, 0.7727787494659424, 0.7705150246620178, 0.7674023509025574, 0.7671194076538086, 0.7722128033638, 0.7651386260986328, 0.7773061394691467, 0.7736276388168335, 0.786361038684845, 0.7756083607673645, 0.7707979679107666, 0.7773061394691467, 0.7790039777755737, 0.7781550884246826, 0.7719298005104065, 0.7815506458282471, 0.7795698642730713, 0.7829654812812805, 0.7857951521873474, 0.7838143706321716, 0.7818335890769958, 0.7891907095909119, 0.7849462628364563, 0.7920203804969788, 0.7903226017951965, 0.7954159379005432, 0.7855121493339539, 0.7866440415382385, 0.801075279712677, 0.7891907095909119, 0.7928692698478699, 0.7996604442596436, 0.7948500514030457, 0.786361038684845, 0.7976796627044678, 0.7965478301048279, 0.8033390045166016, 0.8044708371162415, 0.8027730584144592, 0.7971137762069702, 0.8053197264671326, 0.8007922768592834, 0.8022071123123169, 0.8013582229614258, 0.797396719455719, 0.8019241690635681, 0.8166383504867554, 0.7996604442596436, 0.8157894611358643, 0.8041878938674927, 0.8112620115280151, 0.8095642328262329, 0.7971137762069702, 0.7982456088066101, 0.8112620115280151, 0.8089982867240906, 0.8033390045166016, 0.8112620115280151, 0.8126768469810486, 0.8138087391853333, 0.8157894611358643, 0.8172042965888977, 0.8050367832183838, 0.8205999135971069, 0.8231465816497803, 0.8208828568458557, 0.8273910880088806, 0.8174872398376465, 0.8296547532081604, 0.8288058638572693, 0.8189020752906799, 0.8194680213928223, 0.8155065178871155, 0.8208828568458557, 0.8259762525558472, 0.8254103064537048, 0.8333333134651184, 0.8302206993103027, 0.8302206993103027, 0.8256932497024536, 0.8313525915145874, 0.8307866454124451, 0.8313525915145874, 0.8361629843711853, 0.831918478012085], 'val_loss': [0.6731466054916382, 0.6732115149497986, 0.6691584587097168, 0.6667560338973999, 0.6623490452766418, 0.6607505083084106, 0.6526461839675903, 0.6550776958465576, 0.6471826434135437, 0.6449573040008545, 0.641095757484436, 0.633402943611145, 0.630501389503479, 0.6240296363830566, 0.6192699670791626, 0.6189942359924316, 0.6206421852111816, 0.6136769652366638, 0.6105539798736572, 0.6225929260253906, 0.6119955778121948, 0.6255229711532593, 0.6592340469360352, 0.629143238067627, 0.6483877301216125, 0.6570490598678589, 0.6647299528121948, 0.6561939120292664, 0.7076780796051025, 0.6941092610359192, 0.7203307747840881, 0.6935860514640808, 0.7179893255233765, 0.7041297554969788, 0.7366694211959839, 0.6901242136955261, 0.7266243696212769, 0.7229189872741699, 0.7160924673080444, 0.7394120097160339, 0.7449747920036316, 0.7239084243774414, 0.7408385872840881, 0.724938154220581, 0.7512009739875793, 0.7345166206359863, 0.7254385352134705, 0.7266501784324646, 0.725647509098053, 0.763126790523529, 0.7918198704719543, 0.741119384765625, 0.766588568687439, 0.719413161277771, 0.8083609342575073, 0.7457075715065002, 0.7423223257064819, 0.750657320022583, 0.7545922994613647, 0.7922053337097168, 0.7646202445030212, 0.7988780736923218, 0.8410853147506714, 0.7971492409706116, 0.7617279291152954, 0.8008090257644653, 0.7868798971176147, 0.86794513463974, 0.8020565509796143, 0.7955788969993591, 0.8186478018760681, 0.7775794267654419, 0.8108258247375488, 0.8301833271980286, 0.840689480304718, 0.8554437756538391, 0.8170803785324097, 0.8042525053024292, 0.8217328786849976, 0.8554007411003113, 0.8912655711174011, 0.8774928450584412, 0.8826838731765747, 0.821398913860321, 0.8906195163726807, 0.8532055616378784, 0.837095320224762, 0.8686843514442444, 0.8336257338523865, 0.8516280651092529, 0.8324568271636963, 0.8707636594772339, 0.8180218935012817, 0.8362201452255249, 0.8582939505577087, 0.8304134011268616, 0.9076824188232422, 0.9257698655128479, 0.8793242573738098, 0.9082134962081909], 'val_accuracy': [0.5757918357849121, 0.5837104320526123, 0.598416268825531, 0.6176470518112183, 0.5961538553237915, 0.6074660420417786, 0.6063348650932312, 0.6153846383094788, 0.6414027214050293, 0.5882353186607361, 0.6006787419319153, 0.627828061580658, 0.6266968250274658, 0.6527149081230164, 0.6481900215148926, 0.6436651349067688, 0.6380090713500977, 0.668552041053772, 0.6674208045005798, 0.639140248298645, 0.6651583909988403, 0.6640271544456482, 0.6776018142700195, 0.668552041053772, 0.6617646813392639, 0.6606335043907166, 0.6719456911087036, 0.6787330508232117, 0.6719456911087036, 0.6674208045005798, 0.6742081642150879, 0.6595022678375244, 0.6742081642150879, 0.6696832776069641, 0.679864227771759, 0.6651583909988403, 0.6640271544456482, 0.6719456911087036, 0.6764705777168274, 0.6538461446762085, 0.6651583909988403, 0.6651583909988403, 0.6595022678375244, 0.6538461446762085, 0.6776018142700195, 0.6651583909988403, 0.6549773812294006, 0.668552041053772, 0.6606335043907166, 0.6414027214050293, 0.6606335043907166, 0.662895917892456, 0.6708144545555115, 0.6640271544456482, 0.6470588445663452, 0.6538461446762085, 0.6493212580680847, 0.6595022678375244, 0.6572397947311401, 0.6583710312843323, 0.6447963714599609, 0.6481900215148926, 0.6255655884742737, 0.6549773812294006, 0.6527149081230164, 0.662895917892456, 0.6595022678375244, 0.6289592981338501, 0.6595022678375244, 0.6538461446762085, 0.6357465982437134, 0.6504524946212769, 0.6572397947311401, 0.6447963714599609, 0.639140248298645, 0.6414027214050293, 0.6527149081230164, 0.6549773812294006, 0.6414027214050293, 0.6368778347969055, 0.6266968250274658, 0.6583710312843323, 0.6255655884742737, 0.6436651349067688, 0.6425339579582214, 0.6549773812294006, 0.6402714848518372, 0.6606335043907166, 0.6504524946212769, 0.6561086177825928, 0.6549773812294006, 0.6470588445663452, 0.6447963714599609, 0.6493212580680847, 0.6493212580680847, 0.6481900215148926, 0.6289592981338501, 0.6402714848518372, 0.6527149081230164, 0.6266968250274658]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.5326 - accuracy: 0.7221"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 66ms/step - loss: 0.5328 - accuracy: 0.7225 - val_loss: 0.6782 - val_accuracy: 0.5940\n","Epoch 2/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5131 - accuracy: 0.7359 - val_loss: 0.6783 - val_accuracy: 0.5320\n","Epoch 3/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5073 - accuracy: 0.7367 - val_loss: 0.6791 - val_accuracy: 0.5382\n","Epoch 4/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5010 - accuracy: 0.7328 - val_loss: 0.6742 - val_accuracy: 0.5548\n","Epoch 5/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4989 - accuracy: 0.7323 - val_loss: 0.6714 - val_accuracy: 0.5857\n","Epoch 6/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5029 - accuracy: 0.7357 - val_loss: 0.6683 - val_accuracy: 0.5630\n","Epoch 7/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5011 - accuracy: 0.7411 - val_loss: 0.6672 - val_accuracy: 0.5517\n","Epoch 8/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4875 - accuracy: 0.7494 - val_loss: 0.6674 - val_accuracy: 0.5465\n","Epoch 9/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4905 - accuracy: 0.7375 - val_loss: 0.6614 - val_accuracy: 0.5651\n","Epoch 10/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5032 - accuracy: 0.7346 - val_loss: 0.6555 - val_accuracy: 0.5775\n","Epoch 11/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4924 - accuracy: 0.7450 - val_loss: 0.6534 - val_accuracy: 0.5785\n","Epoch 12/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4839 - accuracy: 0.7501 - val_loss: 0.6510 - val_accuracy: 0.6209\n","Epoch 13/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4992 - accuracy: 0.7367 - val_loss: 0.6741 - val_accuracy: 0.5537\n","Epoch 14/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5155 - accuracy: 0.7230 - val_loss: 0.6513 - val_accuracy: 0.6136\n","Epoch 15/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4971 - accuracy: 0.7323 - val_loss: 0.6454 - val_accuracy: 0.6033\n","Epoch 16/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4849 - accuracy: 0.7519 - val_loss: 0.6777 - val_accuracy: 0.5754\n","Epoch 17/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4878 - accuracy: 0.7457 - val_loss: 0.6409 - val_accuracy: 0.6167\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4824 - accuracy: 0.7419 - val_loss: 0.6977 - val_accuracy: 0.5651\n","Epoch 19/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4875 - accuracy: 0.7406 - val_loss: 0.6516 - val_accuracy: 0.6240\n","Epoch 20/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4769 - accuracy: 0.7545 - val_loss: 0.6636 - val_accuracy: 0.6064\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4716 - accuracy: 0.7540 - val_loss: 0.6892 - val_accuracy: 0.6002\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4685 - accuracy: 0.7543 - val_loss: 0.6999 - val_accuracy: 0.5981\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4749 - accuracy: 0.7633 - val_loss: 0.6866 - val_accuracy: 0.6188\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4728 - accuracy: 0.7540 - val_loss: 0.7165 - val_accuracy: 0.6240\n","Epoch 25/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4699 - accuracy: 0.7548 - val_loss: 0.7237 - val_accuracy: 0.6312\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4721 - accuracy: 0.7512 - val_loss: 0.7601 - val_accuracy: 0.5909\n","Epoch 27/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4793 - accuracy: 0.7548 - val_loss: 0.7255 - val_accuracy: 0.6198\n","Epoch 28/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4675 - accuracy: 0.7638 - val_loss: 0.7692 - val_accuracy: 0.6281\n","Epoch 29/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4778 - accuracy: 0.7483 - val_loss: 0.7560 - val_accuracy: 0.6198\n","Epoch 30/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4706 - accuracy: 0.7579 - val_loss: 0.7642 - val_accuracy: 0.5888\n","Epoch 31/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4640 - accuracy: 0.7612 - val_loss: 0.7192 - val_accuracy: 0.6229\n","Epoch 32/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4571 - accuracy: 0.7669 - val_loss: 0.7608 - val_accuracy: 0.5971\n","Epoch 33/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4611 - accuracy: 0.7690 - val_loss: 0.7268 - val_accuracy: 0.6229\n","Epoch 34/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4592 - accuracy: 0.7680 - val_loss: 0.7436 - val_accuracy: 0.6012\n","Epoch 35/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4603 - accuracy: 0.7677 - val_loss: 0.8064 - val_accuracy: 0.5961\n","Epoch 36/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4608 - accuracy: 0.7641 - val_loss: 0.7820 - val_accuracy: 0.6116\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4514 - accuracy: 0.7757 - val_loss: 0.7631 - val_accuracy: 0.6033\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4432 - accuracy: 0.7713 - val_loss: 0.8064 - val_accuracy: 0.5950\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4434 - accuracy: 0.7721 - val_loss: 0.7747 - val_accuracy: 0.6023\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4512 - accuracy: 0.7729 - val_loss: 0.8194 - val_accuracy: 0.6188\n","Epoch 41/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4472 - accuracy: 0.7721 - val_loss: 0.8271 - val_accuracy: 0.6188\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4427 - accuracy: 0.7695 - val_loss: 0.7812 - val_accuracy: 0.6229\n","Epoch 43/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4523 - accuracy: 0.7713 - val_loss: 0.7833 - val_accuracy: 0.6002\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4406 - accuracy: 0.7773 - val_loss: 0.8174 - val_accuracy: 0.5940\n","Epoch 45/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4481 - accuracy: 0.7755 - val_loss: 0.8080 - val_accuracy: 0.6085\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4629 - accuracy: 0.7568 - val_loss: 0.8478 - val_accuracy: 0.6126\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4510 - accuracy: 0.7749 - val_loss: 0.8063 - val_accuracy: 0.5992\n","Epoch 48/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4341 - accuracy: 0.7793 - val_loss: 0.8001 - val_accuracy: 0.6095\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4379 - accuracy: 0.7765 - val_loss: 0.8972 - val_accuracy: 0.6043\n","Epoch 50/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4507 - accuracy: 0.7755 - val_loss: 0.8138 - val_accuracy: 0.6157\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4316 - accuracy: 0.7801 - val_loss: 0.8059 - val_accuracy: 0.5971\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4340 - accuracy: 0.7798 - val_loss: 0.7985 - val_accuracy: 0.5961\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4319 - accuracy: 0.7840 - val_loss: 0.8038 - val_accuracy: 0.5992\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4328 - accuracy: 0.7814 - val_loss: 0.8556 - val_accuracy: 0.5940\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4329 - accuracy: 0.7765 - val_loss: 0.8180 - val_accuracy: 0.6085\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4332 - accuracy: 0.7848 - val_loss: 0.8832 - val_accuracy: 0.5816\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4370 - accuracy: 0.7744 - val_loss: 0.8020 - val_accuracy: 0.5899\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4393 - accuracy: 0.7770 - val_loss: 0.8593 - val_accuracy: 0.5950\n","Epoch 59/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4333 - accuracy: 0.7850 - val_loss: 0.8124 - val_accuracy: 0.6198\n","Epoch 60/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4328 - accuracy: 0.7899 - val_loss: 0.8282 - val_accuracy: 0.6116\n","Epoch 61/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4291 - accuracy: 0.7855 - val_loss: 0.8066 - val_accuracy: 0.5930\n","Epoch 62/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4327 - accuracy: 0.7884 - val_loss: 0.8328 - val_accuracy: 0.5992\n","Epoch 63/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4211 - accuracy: 0.7922 - val_loss: 0.8165 - val_accuracy: 0.6074\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4170 - accuracy: 0.7884 - val_loss: 0.8170 - val_accuracy: 0.5930\n","Epoch 65/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4176 - accuracy: 0.7946 - val_loss: 0.8493 - val_accuracy: 0.5899\n","Epoch 66/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4156 - accuracy: 0.7935 - val_loss: 0.8994 - val_accuracy: 0.5857\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4118 - accuracy: 0.7987 - val_loss: 0.8559 - val_accuracy: 0.6085\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4123 - accuracy: 0.7956 - val_loss: 0.8937 - val_accuracy: 0.6085\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4207 - accuracy: 0.7912 - val_loss: 0.9503 - val_accuracy: 0.5785\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4169 - accuracy: 0.7897 - val_loss: 0.9221 - val_accuracy: 0.5795\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4219 - accuracy: 0.7850 - val_loss: 0.9076 - val_accuracy: 0.5806\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4093 - accuracy: 0.7966 - val_loss: 0.8803 - val_accuracy: 0.5971\n","Epoch 73/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4082 - accuracy: 0.7987 - val_loss: 0.8912 - val_accuracy: 0.6043\n","Epoch 74/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4169 - accuracy: 0.7946 - val_loss: 0.8980 - val_accuracy: 0.6147\n","Epoch 75/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4089 - accuracy: 0.8016 - val_loss: 0.8812 - val_accuracy: 0.5878\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4113 - accuracy: 0.7964 - val_loss: 0.9092 - val_accuracy: 0.5909\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4218 - accuracy: 0.7868 - val_loss: 0.8499 - val_accuracy: 0.5919\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4086 - accuracy: 0.7946 - val_loss: 0.8252 - val_accuracy: 0.5981\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4101 - accuracy: 0.7953 - val_loss: 0.9087 - val_accuracy: 0.5992\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4030 - accuracy: 0.7920 - val_loss: 0.9960 - val_accuracy: 0.5837\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4105 - accuracy: 0.7992 - val_loss: 0.8995 - val_accuracy: 0.6126\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4085 - accuracy: 0.8008 - val_loss: 0.8693 - val_accuracy: 0.6043\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4030 - accuracy: 0.7995 - val_loss: 0.9155 - val_accuracy: 0.6033\n","Epoch 84/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4015 - accuracy: 0.8031 - val_loss: 0.9020 - val_accuracy: 0.5909\n","Epoch 85/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3967 - accuracy: 0.8067 - val_loss: 0.8970 - val_accuracy: 0.6002\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4046 - accuracy: 0.8072 - val_loss: 0.8868 - val_accuracy: 0.6126\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4052 - accuracy: 0.8010 - val_loss: 0.8706 - val_accuracy: 0.6095\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3978 - accuracy: 0.7984 - val_loss: 0.8915 - val_accuracy: 0.6054\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3908 - accuracy: 0.8070 - val_loss: 0.9440 - val_accuracy: 0.6064\n","Epoch 90/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3889 - accuracy: 0.8078 - val_loss: 0.9202 - val_accuracy: 0.5992\n","Epoch 91/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3872 - accuracy: 0.8088 - val_loss: 0.9642 - val_accuracy: 0.6002\n","Epoch 92/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3873 - accuracy: 0.8085 - val_loss: 0.9324 - val_accuracy: 0.5940\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3805 - accuracy: 0.8152 - val_loss: 0.9968 - val_accuracy: 0.5899\n","Epoch 94/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3937 - accuracy: 0.8083 - val_loss: 0.9482 - val_accuracy: 0.5950\n","Epoch 95/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3855 - accuracy: 0.8116 - val_loss: 0.9678 - val_accuracy: 0.6095\n","Epoch 96/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3953 - accuracy: 0.8065 - val_loss: 0.9127 - val_accuracy: 0.6012\n","Epoch 97/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3815 - accuracy: 0.8142 - val_loss: 0.9839 - val_accuracy: 0.5930\n","Epoch 98/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3875 - accuracy: 0.8054 - val_loss: 0.9419 - val_accuracy: 0.5775\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3733 - accuracy: 0.8189 - val_loss: 0.9221 - val_accuracy: 0.5775\n","Epoch 100/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3890 - accuracy: 0.8057 - val_loss: 0.9728 - val_accuracy: 0.5868\n","{'loss': [0.5327591896057129, 0.5130840539932251, 0.5072948336601257, 0.5009541511535645, 0.4988791048526764, 0.5029271245002747, 0.5011354088783264, 0.48746031522750854, 0.49049511551856995, 0.5031750798225403, 0.49242478609085083, 0.483881413936615, 0.499230295419693, 0.5155389904975891, 0.4970851242542267, 0.484885036945343, 0.48778703808784485, 0.4823712110519409, 0.48754018545150757, 0.47685402631759644, 0.4716474711894989, 0.4684615135192871, 0.4748634696006775, 0.47283339500427246, 0.46986833214759827, 0.4720577597618103, 0.47927555441856384, 0.4675462543964386, 0.47779953479766846, 0.47057071328163147, 0.4640316367149353, 0.4571459889411926, 0.46105554699897766, 0.45924341678619385, 0.46026232838630676, 0.4608251750469208, 0.4513978660106659, 0.44317299127578735, 0.44336965680122375, 0.4512024521827698, 0.4471528232097626, 0.4427295923233032, 0.4523446559906006, 0.4406404495239258, 0.4481227397918701, 0.46290460228919983, 0.4509601891040802, 0.4341244697570801, 0.437928706407547, 0.45072755217552185, 0.43162524700164795, 0.4340425133705139, 0.4319353997707367, 0.43282660841941833, 0.4328690469264984, 0.43320509791374207, 0.4370475709438324, 0.439260333776474, 0.43326878547668457, 0.432752400636673, 0.4291031062602997, 0.4327448904514313, 0.421115905046463, 0.41701287031173706, 0.41762775182724, 0.4155882000923157, 0.41176822781562805, 0.41232118010520935, 0.4207459092140198, 0.4168650805950165, 0.4219135046005249, 0.40934717655181885, 0.4082048535346985, 0.4168994426727295, 0.4088757038116455, 0.4113028049468994, 0.42181065678596497, 0.40855351090431213, 0.41007697582244873, 0.4030096232891083, 0.41051730513572693, 0.4085131883621216, 0.4029911756515503, 0.40147876739501953, 0.39672210812568665, 0.4046381413936615, 0.4051811695098877, 0.3977620303630829, 0.39081141352653503, 0.3889428973197937, 0.38718920946121216, 0.38730093836784363, 0.38054749369621277, 0.39369767904281616, 0.3854834735393524, 0.39530253410339355, 0.38148194551467896, 0.3875018358230591, 0.3732541799545288, 0.388975590467453], 'accuracy': [0.7224805951118469, 0.735917329788208, 0.736692488193512, 0.7328165173530579, 0.7322997450828552, 0.7356589436531067, 0.7410852909088135, 0.7493540048599243, 0.7374677062034607, 0.7346253395080566, 0.7449612617492676, 0.750129222869873, 0.736692488193512, 0.7229974269866943, 0.7322997450828552, 0.751937985420227, 0.7457364201545715, 0.7418604493141174, 0.7405684590339661, 0.7545219659805298, 0.7540051937103271, 0.7542635798454285, 0.763307511806488, 0.7540051937103271, 0.7547803521156311, 0.7511627674102783, 0.7547803521156311, 0.7638242840766907, 0.7483204007148743, 0.7578811645507812, 0.7612403035163879, 0.766925036907196, 0.7689922451972961, 0.7679586410522461, 0.7677002549171448, 0.764082670211792, 0.7757105827331543, 0.7713178396224976, 0.7720929980278015, 0.7728682160377502, 0.7720929980278015, 0.7695090174674988, 0.7713178396224976, 0.777260959148407, 0.775452196598053, 0.7568475604057312, 0.7749354243278503, 0.7793281674385071, 0.776485800743103, 0.775452196598053, 0.7801033854484558, 0.7798449397087097, 0.7839793562889099, 0.7813953757286072, 0.776485800743103, 0.7847545146942139, 0.7744185924530029, 0.7770025730133057, 0.7850129008293152, 0.7899224758148193, 0.7855297327041626, 0.7883720993995667, 0.7922480702400208, 0.7883720993995667, 0.7945736646652222, 0.7935400605201721, 0.7987080216407776, 0.7956072092056274, 0.7912144660949707, 0.789664089679718, 0.7850129008293152, 0.7966408133506775, 0.7987080216407776, 0.7945736646652222, 0.8015503883361816, 0.7963824272155762, 0.786821722984314, 0.7945736646652222, 0.7953488230705261, 0.7919896841049194, 0.7992247939109802, 0.8007751703262329, 0.7994831800460815, 0.8031007647514343, 0.8067183494567871, 0.8072351217269897, 0.801033616065979, 0.7984496355056763, 0.8069767355918884, 0.8077519536018372, 0.8087855577468872, 0.8085271120071411, 0.8152454495429993, 0.8082687258720398, 0.8116279244422913, 0.8064599633216858, 0.814211905002594, 0.8054263591766357, 0.818863034248352, 0.8056847453117371], 'val_loss': [0.6782085299491882, 0.6782850623130798, 0.6790890693664551, 0.6741510629653931, 0.6714298129081726, 0.6683114171028137, 0.6672101020812988, 0.6673822402954102, 0.661368727684021, 0.6554669737815857, 0.6534213423728943, 0.6509894132614136, 0.6740944385528564, 0.6512839794158936, 0.6454043388366699, 0.6777239441871643, 0.6408637762069702, 0.6976510286331177, 0.6516246795654297, 0.6636192798614502, 0.6891759634017944, 0.6999129056930542, 0.6866142153739929, 0.7165132761001587, 0.7237446904182434, 0.760079026222229, 0.7254677414894104, 0.769249677658081, 0.7559814453125, 0.7642265558242798, 0.7191558480262756, 0.7607630491256714, 0.7267615795135498, 0.743610143661499, 0.8063740134239197, 0.7820443511009216, 0.7630902528762817, 0.806350588798523, 0.7747142314910889, 0.8194467425346375, 0.8270507454872131, 0.7812274098396301, 0.7832674384117126, 0.817393958568573, 0.8080336451530457, 0.8477988839149475, 0.8062699437141418, 0.8001107573509216, 0.8972497582435608, 0.8137734532356262, 0.8058937191963196, 0.7985334396362305, 0.8038365244865417, 0.8556227684020996, 0.8180151581764221, 0.8832287788391113, 0.8019614219665527, 0.8592918515205383, 0.8123918175697327, 0.828244149684906, 0.8066354393959045, 0.8328378796577454, 0.8165164589881897, 0.8169788718223572, 0.8493295311927795, 0.8994293808937073, 0.8559271693229675, 0.8936794400215149, 0.9503141641616821, 0.9220969676971436, 0.9076261520385742, 0.8803492784500122, 0.8912373185157776, 0.8979611396789551, 0.8811849355697632, 0.9091832637786865, 0.8499335050582886, 0.8252308368682861, 0.9087209105491638, 0.9959946274757385, 0.8995422720909119, 0.8693327307701111, 0.9154923558235168, 0.9019761681556702, 0.8970431685447693, 0.8868353962898254, 0.8705770373344421, 0.8914579153060913, 0.9440072178840637, 0.9202096462249756, 0.9642422795295715, 0.9324227571487427, 0.9967744946479797, 0.9482061266899109, 0.9678046703338623, 0.9127445816993713, 0.9838817715644836, 0.9419359564781189, 0.9221117496490479, 0.9728376269340515], 'val_accuracy': [0.5940082669258118, 0.5320248007774353, 0.538223147392273, 0.5547520518302917, 0.58574378490448, 0.5630165338516235, 0.5516529083251953, 0.5464876294136047, 0.5650826692581177, 0.577479362487793, 0.5785123705863953, 0.6208677887916565, 0.5537189841270447, 0.6136363744735718, 0.6033057570457458, 0.5754132270812988, 0.6167355179786682, 0.5650826692581177, 0.6239669322967529, 0.6064049601554871, 0.6002066135406494, 0.5981404781341553, 0.6188016533851624, 0.6239669322967529, 0.6311983466148376, 0.5909090638160706, 0.6198347210884094, 0.6280992031097412, 0.6198347210884094, 0.5888429880142212, 0.6229338645935059, 0.5971074104309082, 0.6229338645935059, 0.6012396812438965, 0.5960744023323059, 0.6115702390670776, 0.6033057570457458, 0.5950413346290588, 0.6022727489471436, 0.6188016533851624, 0.6188016533851624, 0.6229338645935059, 0.6002066135406494, 0.5940082669258118, 0.6084710955619812, 0.6126033067703247, 0.5991735458374023, 0.6095041036605835, 0.6043388247489929, 0.6157024502754211, 0.5971074104309082, 0.5960744023323059, 0.5991735458374023, 0.5940082669258118, 0.6084710955619812, 0.5816115736961365, 0.5898760557174683, 0.5950413346290588, 0.6198347210884094, 0.6115702390670776, 0.5929751992225647, 0.5991735458374023, 0.6074380278587341, 0.5929751992225647, 0.5898760557174683, 0.58574378490448, 0.6084710955619812, 0.6084710955619812, 0.5785123705863953, 0.5795454382896423, 0.5805785059928894, 0.5971074104309082, 0.6043388247489929, 0.6146694421768188, 0.5878099203109741, 0.5909090638160706, 0.5919421315193176, 0.5981404781341553, 0.5991735458374023, 0.5836777091026306, 0.6126033067703247, 0.6043388247489929, 0.6033057570457458, 0.5909090638160706, 0.6002066135406494, 0.6126033067703247, 0.6095041036605835, 0.60537189245224, 0.6064049601554871, 0.5991735458374023, 0.6002066135406494, 0.5940082669258118, 0.5898760557174683, 0.5950413346290588, 0.6095041036605835, 0.6012396812438965, 0.5929751992225647, 0.577479362487793, 0.577479362487793, 0.586776852607727]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.4354 - accuracy: 0.7921"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 68ms/step - loss: 0.4345 - accuracy: 0.7923 - val_loss: 0.7094 - val_accuracy: 0.5011\n","Epoch 2/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.4144 - accuracy: 0.7977 - val_loss: 0.6900 - val_accuracy: 0.5086\n","Epoch 3/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.4064 - accuracy: 0.7977 - val_loss: 0.6831 - val_accuracy: 0.5226\n","Epoch 4/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3976 - accuracy: 0.8015 - val_loss: 0.7000 - val_accuracy: 0.5108\n","Epoch 5/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3978 - accuracy: 0.7980 - val_loss: 0.6927 - val_accuracy: 0.5216\n","Epoch 6/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4037 - accuracy: 0.8050 - val_loss: 0.6740 - val_accuracy: 0.5528\n","Epoch 7/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4017 - accuracy: 0.8001 - val_loss: 0.6695 - val_accuracy: 0.5927\n","Epoch 8/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4034 - accuracy: 0.7985 - val_loss: 0.6740 - val_accuracy: 0.5614\n","Epoch 9/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3855 - accuracy: 0.8122 - val_loss: 0.6944 - val_accuracy: 0.5334\n","Epoch 10/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3883 - accuracy: 0.8071 - val_loss: 0.7351 - val_accuracy: 0.5291\n","Epoch 11/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3841 - accuracy: 0.8066 - val_loss: 0.6781 - val_accuracy: 0.5765\n","Epoch 12/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3826 - accuracy: 0.8128 - val_loss: 0.6735 - val_accuracy: 0.6185\n","Epoch 13/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3922 - accuracy: 0.8141 - val_loss: 0.6746 - val_accuracy: 0.6379\n","Epoch 14/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3804 - accuracy: 0.8219 - val_loss: 0.7112 - val_accuracy: 0.5830\n","Epoch 15/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3866 - accuracy: 0.8060 - val_loss: 0.6874 - val_accuracy: 0.6218\n","Epoch 16/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3753 - accuracy: 0.8206 - val_loss: 0.7039 - val_accuracy: 0.5981\n","Epoch 17/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3755 - accuracy: 0.8173 - val_loss: 0.6870 - val_accuracy: 0.6606\n","Epoch 18/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3731 - accuracy: 0.8171 - val_loss: 0.7261 - val_accuracy: 0.6110\n","Epoch 19/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3677 - accuracy: 0.8211 - val_loss: 0.6925 - val_accuracy: 0.6584\n","Epoch 20/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3700 - accuracy: 0.8168 - val_loss: 0.7149 - val_accuracy: 0.6519\n","Epoch 21/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3638 - accuracy: 0.8235 - val_loss: 0.7638 - val_accuracy: 0.6347\n","Epoch 22/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3644 - accuracy: 0.8257 - val_loss: 0.7395 - val_accuracy: 0.6487\n","Epoch 23/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3602 - accuracy: 0.8273 - val_loss: 0.7253 - val_accuracy: 0.6767\n","Epoch 24/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3631 - accuracy: 0.8265 - val_loss: 0.7334 - val_accuracy: 0.6907\n","Epoch 25/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3605 - accuracy: 0.8246 - val_loss: 0.7376 - val_accuracy: 0.6940\n","Epoch 26/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3568 - accuracy: 0.8254 - val_loss: 0.8146 - val_accuracy: 0.6315\n","Epoch 27/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3583 - accuracy: 0.8295 - val_loss: 0.8476 - val_accuracy: 0.6347\n","Epoch 28/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3681 - accuracy: 0.8206 - val_loss: 0.8790 - val_accuracy: 0.6401\n","Epoch 29/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3607 - accuracy: 0.8257 - val_loss: 0.7659 - val_accuracy: 0.6983\n","Epoch 30/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3638 - accuracy: 0.8262 - val_loss: 0.7782 - val_accuracy: 0.6897\n","Epoch 31/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3713 - accuracy: 0.8244 - val_loss: 0.8084 - val_accuracy: 0.6907\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3619 - accuracy: 0.8235 - val_loss: 0.8882 - val_accuracy: 0.6455\n","Epoch 33/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3631 - accuracy: 0.8265 - val_loss: 0.7983 - val_accuracy: 0.6875\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3527 - accuracy: 0.8327 - val_loss: 0.8424 - val_accuracy: 0.6853\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3485 - accuracy: 0.8346 - val_loss: 0.8686 - val_accuracy: 0.6498\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3485 - accuracy: 0.8308 - val_loss: 0.9501 - val_accuracy: 0.6304\n","Epoch 37/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3490 - accuracy: 0.8338 - val_loss: 0.8124 - val_accuracy: 0.7015\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3509 - accuracy: 0.8346 - val_loss: 0.8508 - val_accuracy: 0.6767\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3469 - accuracy: 0.8335 - val_loss: 1.0393 - val_accuracy: 0.6207\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3453 - accuracy: 0.8330 - val_loss: 0.8299 - val_accuracy: 0.6853\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3467 - accuracy: 0.8343 - val_loss: 0.8508 - val_accuracy: 0.6789\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3439 - accuracy: 0.8346 - val_loss: 0.8356 - val_accuracy: 0.6929\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3371 - accuracy: 0.8365 - val_loss: 0.8559 - val_accuracy: 0.6746\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3370 - accuracy: 0.8392 - val_loss: 0.8458 - val_accuracy: 0.6875\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3397 - accuracy: 0.8367 - val_loss: 0.8014 - val_accuracy: 0.6853\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3307 - accuracy: 0.8408 - val_loss: 0.8351 - val_accuracy: 0.6767\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3375 - accuracy: 0.8311 - val_loss: 0.9160 - val_accuracy: 0.6595\n","Epoch 48/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3409 - accuracy: 0.8295 - val_loss: 0.8723 - val_accuracy: 0.6756\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3298 - accuracy: 0.8429 - val_loss: 0.8955 - val_accuracy: 0.6832\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3249 - accuracy: 0.8456 - val_loss: 0.9190 - val_accuracy: 0.6800\n","Epoch 51/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3340 - accuracy: 0.8397 - val_loss: 0.9111 - val_accuracy: 0.6584\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3433 - accuracy: 0.8378 - val_loss: 0.9505 - val_accuracy: 0.6789\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3402 - accuracy: 0.8416 - val_loss: 0.8287 - val_accuracy: 0.6950\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3406 - accuracy: 0.8381 - val_loss: 0.8742 - val_accuracy: 0.6692\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3502 - accuracy: 0.8427 - val_loss: 0.9278 - val_accuracy: 0.6412\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3378 - accuracy: 0.8330 - val_loss: 0.8885 - val_accuracy: 0.6756\n","Epoch 57/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3421 - accuracy: 0.8435 - val_loss: 0.8341 - val_accuracy: 0.6800\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3286 - accuracy: 0.8397 - val_loss: 1.0426 - val_accuracy: 0.6153\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3308 - accuracy: 0.8392 - val_loss: 0.8247 - val_accuracy: 0.6983\n","Epoch 60/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3224 - accuracy: 0.8448 - val_loss: 0.8866 - val_accuracy: 0.6800\n","Epoch 61/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3358 - accuracy: 0.8359 - val_loss: 0.8698 - val_accuracy: 0.6789\n","Epoch 62/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3267 - accuracy: 0.8462 - val_loss: 0.8349 - val_accuracy: 0.6821\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3177 - accuracy: 0.8464 - val_loss: 0.8842 - val_accuracy: 0.6789\n","Epoch 64/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3186 - accuracy: 0.8502 - val_loss: 0.9887 - val_accuracy: 0.6832\n","Epoch 65/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3237 - accuracy: 0.8464 - val_loss: 0.9110 - val_accuracy: 0.6681\n","Epoch 66/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3158 - accuracy: 0.8529 - val_loss: 0.9461 - val_accuracy: 0.6584\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3171 - accuracy: 0.8491 - val_loss: 0.9827 - val_accuracy: 0.6552\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3178 - accuracy: 0.8489 - val_loss: 0.8952 - val_accuracy: 0.6810\n","Epoch 69/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3080 - accuracy: 0.8580 - val_loss: 0.8935 - val_accuracy: 0.6735\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2992 - accuracy: 0.8691 - val_loss: 0.9561 - val_accuracy: 0.6573\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3035 - accuracy: 0.8559 - val_loss: 1.0292 - val_accuracy: 0.6347\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3050 - accuracy: 0.8615 - val_loss: 0.8877 - val_accuracy: 0.6832\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3121 - accuracy: 0.8521 - val_loss: 0.9062 - val_accuracy: 0.6746\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3138 - accuracy: 0.8499 - val_loss: 1.0047 - val_accuracy: 0.6692\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3207 - accuracy: 0.8435 - val_loss: 0.9382 - val_accuracy: 0.6713\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3064 - accuracy: 0.8605 - val_loss: 0.9227 - val_accuracy: 0.6746\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3052 - accuracy: 0.8570 - val_loss: 1.0574 - val_accuracy: 0.6261\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3042 - accuracy: 0.8583 - val_loss: 0.9571 - val_accuracy: 0.6659\n","Epoch 79/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3043 - accuracy: 0.8548 - val_loss: 0.9362 - val_accuracy: 0.6649\n","Epoch 80/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2963 - accuracy: 0.8626 - val_loss: 1.1101 - val_accuracy: 0.6175\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2941 - accuracy: 0.8688 - val_loss: 0.9581 - val_accuracy: 0.6756\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2916 - accuracy: 0.8615 - val_loss: 1.0087 - val_accuracy: 0.6627\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2954 - accuracy: 0.8610 - val_loss: 1.1039 - val_accuracy: 0.6293\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3120 - accuracy: 0.8545 - val_loss: 0.9299 - val_accuracy: 0.6821\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2897 - accuracy: 0.8640 - val_loss: 0.9653 - val_accuracy: 0.6649\n","Epoch 86/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2865 - accuracy: 0.8666 - val_loss: 0.9457 - val_accuracy: 0.6627\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2865 - accuracy: 0.8640 - val_loss: 0.9155 - val_accuracy: 0.6778\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2921 - accuracy: 0.8588 - val_loss: 1.0020 - val_accuracy: 0.6616\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2784 - accuracy: 0.8742 - val_loss: 1.0052 - val_accuracy: 0.6616\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2798 - accuracy: 0.8675 - val_loss: 0.9660 - val_accuracy: 0.6789\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2828 - accuracy: 0.8720 - val_loss: 1.0209 - val_accuracy: 0.6670\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2821 - accuracy: 0.8728 - val_loss: 0.9508 - val_accuracy: 0.6713\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2892 - accuracy: 0.8653 - val_loss: 0.9896 - val_accuracy: 0.6659\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2756 - accuracy: 0.8693 - val_loss: 0.9619 - val_accuracy: 0.6767\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2868 - accuracy: 0.8677 - val_loss: 1.1020 - val_accuracy: 0.6422\n","Epoch 96/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2739 - accuracy: 0.8766 - val_loss: 1.0553 - val_accuracy: 0.6487\n","Epoch 97/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2854 - accuracy: 0.8650 - val_loss: 1.0237 - val_accuracy: 0.6659\n","Epoch 98/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2810 - accuracy: 0.8734 - val_loss: 1.0032 - val_accuracy: 0.6713\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2836 - accuracy: 0.8715 - val_loss: 0.9929 - val_accuracy: 0.6724\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2804 - accuracy: 0.8699 - val_loss: 0.9555 - val_accuracy: 0.6713\n","{'loss': [0.4344843626022339, 0.41444340348243713, 0.40638741850852966, 0.3976077437400818, 0.3978234529495239, 0.40365874767303467, 0.40171292424201965, 0.4034219980239868, 0.3854660391807556, 0.38834935426712036, 0.3841155767440796, 0.38258641958236694, 0.3921850025653839, 0.3803848922252655, 0.3865840435028076, 0.3752950131893158, 0.37545642256736755, 0.3731479048728943, 0.36768022179603577, 0.3699951469898224, 0.3637552261352539, 0.36440667510032654, 0.3602158725261688, 0.3631320893764496, 0.36053788661956787, 0.35681554675102234, 0.35826575756073, 0.368072509765625, 0.3606940507888794, 0.36383938789367676, 0.3712838590145111, 0.36186832189559937, 0.3631347119808197, 0.3526534140110016, 0.3485304117202759, 0.34853047132492065, 0.34903469681739807, 0.3508879542350769, 0.3469458222389221, 0.34527388215065, 0.34666794538497925, 0.34385159611701965, 0.3370812237262726, 0.33700597286224365, 0.33968690037727356, 0.33072471618652344, 0.33751794695854187, 0.3409448564052582, 0.3297886550426483, 0.324891597032547, 0.3339660167694092, 0.34327566623687744, 0.3401837646961212, 0.3405909240245819, 0.3501880466938019, 0.33781173825263977, 0.3421188294887543, 0.32862111926078796, 0.33080166578292847, 0.32243961095809937, 0.3357880115509033, 0.3266967236995697, 0.3176916241645813, 0.31861457228660583, 0.32369211316108704, 0.31576135754585266, 0.31713706254959106, 0.31776881217956543, 0.3079846203327179, 0.2991645038127899, 0.3034861981868744, 0.3049706816673279, 0.31207898259162903, 0.31379008293151855, 0.3207104504108429, 0.3064170479774475, 0.30521076917648315, 0.3041572570800781, 0.3042559325695038, 0.2963302433490753, 0.294141948223114, 0.2916243076324463, 0.295427531003952, 0.311966210603714, 0.2897363007068634, 0.28653767704963684, 0.2865223288536072, 0.29210248589515686, 0.27842676639556885, 0.2798110842704773, 0.28284913301467896, 0.28213685750961304, 0.28918108344078064, 0.27562710642814636, 0.2868081033229828, 0.27388593554496765, 0.2853766083717346, 0.2810242772102356, 0.2836237847805023, 0.28039735555648804], 'accuracy': [0.7922952771186829, 0.7976831793785095, 0.7976831793785095, 0.8014547228813171, 0.7979525923728943, 0.8049569129943848, 0.8001077771186829, 0.798491358757019, 0.8122305870056152, 0.8071120977401733, 0.8065732717514038, 0.8127694129943848, 0.814116358757019, 0.821928858757019, 0.806034505367279, 0.8205819129943848, 0.8173491358757019, 0.8170797228813171, 0.8211206793785095, 0.8168103694915771, 0.8235452771186829, 0.8257004022598267, 0.8273168206214905, 0.826508641242981, 0.8246228694915771, 0.8254310488700867, 0.829472005367279, 0.8205819129943848, 0.8257004022598267, 0.8262392282485962, 0.8243534564971924, 0.8235452771186829, 0.826508641242981, 0.8327047228813171, 0.834590494632721, 0.8308189511299133, 0.8337823152542114, 0.834590494632721, 0.8335129022598267, 0.8329741358757019, 0.834321141242981, 0.834590494632721, 0.8364762663841248, 0.8391702771186829, 0.8367456793785095, 0.8407866358757019, 0.8310883641242981, 0.829472005367279, 0.8429418206214905, 0.8456357717514038, 0.8397090435028076, 0.8378232717514038, 0.8415948152542114, 0.8380926847457886, 0.8426724076271057, 0.8329741358757019, 0.8434805870056152, 0.8397090435028076, 0.8391702771186829, 0.8448275923728943, 0.8359375, 0.8461745977401733, 0.8464439511299133, 0.850215494632721, 0.8464439511299133, 0.852909505367279, 0.8491379022598267, 0.8488685488700867, 0.858027994632721, 0.8690732717514038, 0.8558728694915771, 0.8615301847457886, 0.8521012663841248, 0.849946141242981, 0.8434805870056152, 0.8604525923728943, 0.8569504022598267, 0.8582974076271057, 0.8547952771186829, 0.8626077771186829, 0.868803858757019, 0.8615301847457886, 0.860991358757019, 0.8545258641242981, 0.8639547228813171, 0.8666487336158752, 0.8639547228813171, 0.8588362336158752, 0.8741918206214905, 0.8674569129943848, 0.8720366358757019, 0.8728448152542114, 0.8653017282485962, 0.8693426847457886, 0.8677262663841248, 0.876616358757019, 0.8650323152542114, 0.873383641242981, 0.8714978694915771, 0.8698814511299133], 'val_loss': [0.709441065788269, 0.690033495426178, 0.6830726265907288, 0.7000331282615662, 0.6927287578582764, 0.6739914417266846, 0.6695181727409363, 0.6739521026611328, 0.6944098472595215, 0.7350926995277405, 0.6781045794487, 0.6734519004821777, 0.6745902299880981, 0.7112244367599487, 0.6873636841773987, 0.7039411664009094, 0.6869950294494629, 0.7260857820510864, 0.6925176978111267, 0.7149131298065186, 0.7637900710105896, 0.739493727684021, 0.7253126502037048, 0.7333645820617676, 0.7375900745391846, 0.8145970106124878, 0.8476465344429016, 0.8790488243103027, 0.7659034132957458, 0.7782087922096252, 0.8084335923194885, 0.8881545066833496, 0.7983444333076477, 0.8423895835876465, 0.8685930371284485, 0.950142502784729, 0.8123571276664734, 0.8508433103561401, 1.0393471717834473, 0.8299056887626648, 0.8507550358772278, 0.8355836272239685, 0.8558784127235413, 0.8458204865455627, 0.8014054298400879, 0.8351367712020874, 0.9159770607948303, 0.8723142743110657, 0.8954859972000122, 0.9190444350242615, 0.9110801815986633, 0.95053631067276, 0.828741192817688, 0.8742214441299438, 0.9278372526168823, 0.8884539008140564, 0.8340783715248108, 1.042581558227539, 0.8246995806694031, 0.8865888118743896, 0.8697852492332458, 0.8348755240440369, 0.8841502666473389, 0.9886564612388611, 0.9109793901443481, 0.9460658431053162, 0.9826629161834717, 0.8952107429504395, 0.8935425281524658, 0.9560675024986267, 1.0292168855667114, 0.8877307176589966, 0.9061775803565979, 1.0047048330307007, 0.938211977481842, 0.9226930737495422, 1.057374119758606, 0.9570536613464355, 0.9362143278121948, 1.1101040840148926, 0.9580917954444885, 1.0086852312088013, 1.1038779020309448, 0.929948091506958, 0.9652904868125916, 0.9456933736801147, 0.9155380725860596, 1.0020477771759033, 1.0052449703216553, 0.9660070538520813, 1.0208871364593506, 0.9507702589035034, 0.9895884990692139, 0.9619439840316772, 1.1020032167434692, 1.055281162261963, 1.0237011909484863, 1.0031577348709106, 0.9928765892982483, 0.9555421471595764], 'val_accuracy': [0.5010775923728943, 0.5086206793785095, 0.5226293206214905, 0.5107758641242981, 0.5215517282485962, 0.5528017282485962, 0.5926724076271057, 0.5614224076271057, 0.5334051847457886, 0.5290948152542114, 0.576508641242981, 0.618534505367279, 0.6379310488700867, 0.5829741358757019, 0.6217672228813171, 0.5980603694915771, 0.6605603694915771, 0.610991358757019, 0.6584051847457886, 0.6519396305084229, 0.6346982717514038, 0.6487069129943848, 0.6767241358757019, 0.6907327771186829, 0.693965494632721, 0.631465494632721, 0.6346982717514038, 0.6400862336158752, 0.6982758641242981, 0.6896551847457886, 0.6907327771186829, 0.6454741358757019, 0.6875, 0.6853448152542114, 0.649784505367279, 0.6303879022598267, 0.701508641242981, 0.6767241358757019, 0.6206896305084229, 0.6853448152542114, 0.6788793206214905, 0.6928879022598267, 0.6745689511299133, 0.6875, 0.6853448152542114, 0.6767241358757019, 0.6594827771186829, 0.6756465435028076, 0.6831896305084229, 0.6799569129943848, 0.6584051847457886, 0.6788793206214905, 0.6950430870056152, 0.6691810488700867, 0.6411637663841248, 0.6756465435028076, 0.6799569129943848, 0.6153017282485962, 0.6982758641242981, 0.6799569129943848, 0.6788793206214905, 0.6821120977401733, 0.6788793206214905, 0.6831896305084229, 0.6681034564971924, 0.6584051847457886, 0.6551724076271057, 0.681034505367279, 0.673491358757019, 0.6573275923728943, 0.6346982717514038, 0.6831896305084229, 0.6745689511299133, 0.6691810488700867, 0.6713362336158752, 0.6745689511299133, 0.6260775923728943, 0.6659482717514038, 0.6648706793785095, 0.6174569129943848, 0.6756465435028076, 0.662715494632721, 0.6293103694915771, 0.6821120977401733, 0.6648706793785095, 0.662715494632721, 0.6778017282485962, 0.6616379022598267, 0.6616379022598267, 0.6788793206214905, 0.6670258641242981, 0.6713362336158752, 0.6659482717514038, 0.6767241358757019, 0.642241358757019, 0.6487069129943848, 0.6659482717514038, 0.6713362336158752, 0.6724137663841248, 0.6713362336158752]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.4365 - accuracy: 0.7885"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 56ms/step - loss: 0.4379 - accuracy: 0.7861 - val_loss: 0.6692 - val_accuracy: 0.5441\n","Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4111 - accuracy: 0.8090 - val_loss: 0.6658 - val_accuracy: 0.5566\n","Epoch 3/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4054 - accuracy: 0.8081 - val_loss: 0.6714 - val_accuracy: 0.5430\n","Epoch 4/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4179 - accuracy: 0.8065 - val_loss: 0.6818 - val_accuracy: 0.5373\n","Epoch 5/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4101 - accuracy: 0.8065 - val_loss: 0.6532 - val_accuracy: 0.5860\n","Epoch 6/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4048 - accuracy: 0.8053 - val_loss: 0.6518 - val_accuracy: 0.5860\n","Epoch 7/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3976 - accuracy: 0.8132 - val_loss: 0.6460 - val_accuracy: 0.5882\n","Epoch 8/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3991 - accuracy: 0.8076 - val_loss: 0.6331 - val_accuracy: 0.6493\n","Epoch 9/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3945 - accuracy: 0.8155 - val_loss: 0.6290 - val_accuracy: 0.6109\n","Epoch 10/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3836 - accuracy: 0.8132 - val_loss: 0.6192 - val_accuracy: 0.6550\n","Epoch 11/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3898 - accuracy: 0.8183 - val_loss: 0.6232 - val_accuracy: 0.6154\n","Epoch 12/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3834 - accuracy: 0.8237 - val_loss: 0.6203 - val_accuracy: 0.6120\n","Epoch 13/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3904 - accuracy: 0.8183 - val_loss: 0.6111 - val_accuracy: 0.6561\n","Epoch 14/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3864 - accuracy: 0.8212 - val_loss: 0.6075 - val_accuracy: 0.6369\n","Epoch 15/100\n","28/28 [==============================] - 1s 38ms/step - loss: 0.3881 - accuracy: 0.8149 - val_loss: 0.6750 - val_accuracy: 0.5928\n","Epoch 16/100\n","28/28 [==============================] - 1s 47ms/step - loss: 0.3858 - accuracy: 0.8240 - val_loss: 0.5894 - val_accuracy: 0.6731\n","Epoch 17/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3892 - accuracy: 0.8104 - val_loss: 0.5920 - val_accuracy: 0.6697\n","Epoch 18/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3773 - accuracy: 0.8237 - val_loss: 0.6239 - val_accuracy: 0.6538\n","Epoch 19/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3876 - accuracy: 0.8161 - val_loss: 0.6115 - val_accuracy: 0.6776\n","Epoch 20/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3807 - accuracy: 0.8240 - val_loss: 0.6311 - val_accuracy: 0.6674\n","Epoch 21/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3766 - accuracy: 0.8166 - val_loss: 0.6006 - val_accuracy: 0.6968\n","Epoch 22/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3667 - accuracy: 0.8280 - val_loss: 0.6226 - val_accuracy: 0.7036\n","Epoch 23/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3685 - accuracy: 0.8263 - val_loss: 0.6421 - val_accuracy: 0.6946\n","Epoch 24/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3678 - accuracy: 0.8260 - val_loss: 0.6426 - val_accuracy: 0.6697\n","Epoch 25/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3702 - accuracy: 0.8268 - val_loss: 0.6139 - val_accuracy: 0.6934\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3731 - accuracy: 0.8263 - val_loss: 0.6561 - val_accuracy: 0.6776\n","Epoch 27/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3649 - accuracy: 0.8322 - val_loss: 0.7096 - val_accuracy: 0.6821\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3778 - accuracy: 0.8243 - val_loss: 0.6633 - val_accuracy: 0.6968\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3616 - accuracy: 0.8342 - val_loss: 0.7124 - val_accuracy: 0.6765\n","Epoch 30/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3694 - accuracy: 0.8271 - val_loss: 0.7172 - val_accuracy: 0.7070\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3581 - accuracy: 0.8291 - val_loss: 0.8057 - val_accuracy: 0.6584\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3639 - accuracy: 0.8297 - val_loss: 0.7056 - val_accuracy: 0.6833\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3485 - accuracy: 0.8418 - val_loss: 0.7104 - val_accuracy: 0.7070\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3595 - accuracy: 0.8379 - val_loss: 0.6967 - val_accuracy: 0.7002\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3525 - accuracy: 0.8288 - val_loss: 0.7207 - val_accuracy: 0.7048\n","Epoch 36/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3494 - accuracy: 0.8359 - val_loss: 0.7224 - val_accuracy: 0.7093\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3606 - accuracy: 0.8410 - val_loss: 0.7316 - val_accuracy: 0.6980\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3649 - accuracy: 0.8379 - val_loss: 0.7230 - val_accuracy: 0.6810\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3523 - accuracy: 0.8435 - val_loss: 0.7017 - val_accuracy: 0.6946\n","Epoch 40/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3491 - accuracy: 0.8486 - val_loss: 0.7092 - val_accuracy: 0.6867\n","Epoch 41/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3495 - accuracy: 0.8373 - val_loss: 0.7810 - val_accuracy: 0.6652\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3505 - accuracy: 0.8404 - val_loss: 0.7160 - val_accuracy: 0.6934\n","Epoch 43/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3428 - accuracy: 0.8444 - val_loss: 0.7446 - val_accuracy: 0.7002\n","Epoch 44/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3481 - accuracy: 0.8404 - val_loss: 0.8835 - val_accuracy: 0.6663\n","Epoch 45/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3416 - accuracy: 0.8345 - val_loss: 0.7375 - val_accuracy: 0.6934\n","Epoch 46/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3339 - accuracy: 0.8475 - val_loss: 0.8137 - val_accuracy: 0.6550\n","Epoch 47/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3429 - accuracy: 0.8387 - val_loss: 0.7526 - val_accuracy: 0.6753\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3486 - accuracy: 0.8376 - val_loss: 0.7505 - val_accuracy: 0.6900\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3489 - accuracy: 0.8404 - val_loss: 0.7228 - val_accuracy: 0.6900\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3415 - accuracy: 0.8424 - val_loss: 0.7622 - val_accuracy: 0.6923\n","Epoch 51/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3526 - accuracy: 0.8376 - val_loss: 0.7525 - val_accuracy: 0.6799\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3356 - accuracy: 0.8455 - val_loss: 0.7898 - val_accuracy: 0.6719\n","Epoch 53/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3218 - accuracy: 0.8574 - val_loss: 0.7727 - val_accuracy: 0.6833\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3234 - accuracy: 0.8548 - val_loss: 0.7360 - val_accuracy: 0.7036\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3261 - accuracy: 0.8537 - val_loss: 0.7712 - val_accuracy: 0.6833\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3322 - accuracy: 0.8472 - val_loss: 0.7550 - val_accuracy: 0.7014\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3364 - accuracy: 0.8432 - val_loss: 0.7134 - val_accuracy: 0.6889\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3298 - accuracy: 0.8588 - val_loss: 0.7597 - val_accuracy: 0.6731\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3279 - accuracy: 0.8517 - val_loss: 0.7633 - val_accuracy: 0.6821\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3243 - accuracy: 0.8531 - val_loss: 0.7562 - val_accuracy: 0.6878\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3181 - accuracy: 0.8534 - val_loss: 0.7846 - val_accuracy: 0.6787\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3333 - accuracy: 0.8506 - val_loss: 0.9466 - val_accuracy: 0.6391\n","Epoch 63/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3247 - accuracy: 0.8506 - val_loss: 0.7806 - val_accuracy: 0.6753\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3183 - accuracy: 0.8554 - val_loss: 0.8104 - val_accuracy: 0.6855\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3203 - accuracy: 0.8551 - val_loss: 0.7722 - val_accuracy: 0.6923\n","Epoch 66/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3222 - accuracy: 0.8602 - val_loss: 0.7524 - val_accuracy: 0.7014\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3187 - accuracy: 0.8529 - val_loss: 0.8350 - val_accuracy: 0.6821\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3174 - accuracy: 0.8625 - val_loss: 0.7757 - val_accuracy: 0.6844\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3231 - accuracy: 0.8577 - val_loss: 0.7649 - val_accuracy: 0.7014\n","Epoch 70/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3285 - accuracy: 0.8472 - val_loss: 0.8892 - val_accuracy: 0.6765\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3134 - accuracy: 0.8594 - val_loss: 0.9529 - val_accuracy: 0.6380\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3146 - accuracy: 0.8582 - val_loss: 0.8574 - val_accuracy: 0.6640\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3067 - accuracy: 0.8608 - val_loss: 0.8286 - val_accuracy: 0.6663\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2997 - accuracy: 0.8611 - val_loss: 0.8754 - val_accuracy: 0.6584\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3074 - accuracy: 0.8642 - val_loss: 0.9479 - val_accuracy: 0.6505\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3247 - accuracy: 0.8540 - val_loss: 0.7915 - val_accuracy: 0.7036\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3195 - accuracy: 0.8596 - val_loss: 0.7976 - val_accuracy: 0.6991\n","Epoch 78/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3101 - accuracy: 0.8628 - val_loss: 0.8707 - val_accuracy: 0.6618\n","Epoch 79/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3093 - accuracy: 0.8563 - val_loss: 0.8156 - val_accuracy: 0.7036\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3041 - accuracy: 0.8650 - val_loss: 0.7776 - val_accuracy: 0.7048\n","Epoch 81/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3026 - accuracy: 0.8650 - val_loss: 0.7715 - val_accuracy: 0.6968\n","Epoch 82/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2942 - accuracy: 0.8741 - val_loss: 0.7879 - val_accuracy: 0.6968\n","Epoch 83/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3070 - accuracy: 0.8594 - val_loss: 0.8235 - val_accuracy: 0.6968\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3250 - accuracy: 0.8531 - val_loss: 0.8585 - val_accuracy: 0.6821\n","Epoch 85/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3029 - accuracy: 0.8653 - val_loss: 0.8664 - val_accuracy: 0.6527\n","Epoch 86/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3007 - accuracy: 0.8628 - val_loss: 0.8658 - val_accuracy: 0.6584\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3072 - accuracy: 0.8650 - val_loss: 0.8646 - val_accuracy: 0.6934\n","Epoch 88/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3002 - accuracy: 0.8667 - val_loss: 0.9108 - val_accuracy: 0.6799\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2986 - accuracy: 0.8701 - val_loss: 0.9425 - val_accuracy: 0.6403\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2906 - accuracy: 0.8704 - val_loss: 0.8180 - val_accuracy: 0.6833\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2906 - accuracy: 0.8721 - val_loss: 0.8812 - val_accuracy: 0.6867\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2920 - accuracy: 0.8659 - val_loss: 0.8003 - val_accuracy: 0.7014\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2850 - accuracy: 0.8772 - val_loss: 0.9059 - val_accuracy: 0.6640\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2794 - accuracy: 0.8800 - val_loss: 0.7876 - val_accuracy: 0.7025\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2850 - accuracy: 0.8758 - val_loss: 0.8359 - val_accuracy: 0.6708\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2888 - accuracy: 0.8704 - val_loss: 0.8258 - val_accuracy: 0.7014\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2898 - accuracy: 0.8650 - val_loss: 0.9445 - val_accuracy: 0.6505\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3010 - accuracy: 0.8667 - val_loss: 0.8139 - val_accuracy: 0.6980\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3106 - accuracy: 0.8664 - val_loss: 0.8834 - val_accuracy: 0.6686\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2911 - accuracy: 0.8715 - val_loss: 1.1804 - val_accuracy: 0.6335\n","{'loss': [0.43786972761154175, 0.41107115149497986, 0.40540245175361633, 0.4178672432899475, 0.410138875246048, 0.40483343601226807, 0.397566020488739, 0.39912107586860657, 0.3945099413394928, 0.3835996389389038, 0.3897522985935211, 0.3834279775619507, 0.39039966464042664, 0.38635754585266113, 0.38808709383010864, 0.38576382398605347, 0.38922497630119324, 0.37729015946388245, 0.38758784532546997, 0.3806720972061157, 0.37661686539649963, 0.3667180836200714, 0.36853066086769104, 0.3678077161312103, 0.3701937198638916, 0.37312352657318115, 0.36494001746177673, 0.3777514100074768, 0.3615786135196686, 0.3694177269935608, 0.35813722014427185, 0.3638957440853119, 0.3484618365764618, 0.35953834652900696, 0.3524714410305023, 0.34944552183151245, 0.36059141159057617, 0.36488839983940125, 0.3522806167602539, 0.34913355112075806, 0.34947189688682556, 0.3504958152770996, 0.3428449034690857, 0.34806594252586365, 0.34160616993904114, 0.33388206362724304, 0.34287312626838684, 0.34857380390167236, 0.348940372467041, 0.3414519131183624, 0.3525710701942444, 0.3355678617954254, 0.3218251168727875, 0.3233987092971802, 0.32608136534690857, 0.33223873376846313, 0.3364373445510864, 0.32983729243278503, 0.3278913199901581, 0.32428526878356934, 0.31814044713974, 0.3333163857460022, 0.3246532082557678, 0.3183335065841675, 0.32032233476638794, 0.3222115635871887, 0.31867480278015137, 0.31739887595176697, 0.3230521082878113, 0.32847151160240173, 0.3134254515171051, 0.3146418333053589, 0.30668893456459045, 0.29973727464675903, 0.3073587119579315, 0.3246857821941376, 0.3194567859172821, 0.3101373612880707, 0.30927059054374695, 0.30410775542259216, 0.30257466435432434, 0.2942228615283966, 0.30698147416114807, 0.3249579966068268, 0.30294954776763916, 0.300685316324234, 0.30718401074409485, 0.300192266702652, 0.29858243465423584, 0.2905876636505127, 0.29055386781692505, 0.29203251004219055, 0.28501859307289124, 0.27941009402275085, 0.28496280312538147, 0.28881028294563293, 0.2897963523864746, 0.3010315001010895, 0.3105875551700592, 0.2910667955875397], 'accuracy': [0.7860780954360962, 0.8089982867240906, 0.8081493973731995, 0.8064516186714172, 0.8064516186714172, 0.8053197264671326, 0.8132427930831909, 0.8075834512710571, 0.8155065178871155, 0.8132427930831909, 0.8183361887931824, 0.8237125277519226, 0.8183361887931824, 0.8211658000946045, 0.8149405717849731, 0.8239954710006714, 0.810413122177124, 0.8237125277519226, 0.8160724639892578, 0.8239954710006714, 0.8166383504867554, 0.8279569745063782, 0.826259195804596, 0.8259762525558472, 0.8268251419067383, 0.826259195804596, 0.8322014808654785, 0.8242784142494202, 0.8341822028160095, 0.8271080851554871, 0.8290888667106628, 0.8296547532081604, 0.8418223261833191, 0.8378607630729675, 0.8288058638572693, 0.8358800411224365, 0.8409733772277832, 0.8378607630729675, 0.8435201048851013, 0.848613440990448, 0.83729487657547, 0.8404074907302856, 0.8443689942359924, 0.8404074907302856, 0.8344652056694031, 0.8474816083908081, 0.8387096524238586, 0.8375778198242188, 0.8404074907302856, 0.8423882126808167, 0.8375778198242188, 0.8455008268356323, 0.8573853969573975, 0.8548387289047241, 0.8537068367004395, 0.8471986651420593, 0.8432371020317078, 0.8588002324104309, 0.8517261147499084, 0.8531408905982971, 0.8534238934516907, 0.8505942225456238, 0.8505942225456238, 0.8554046154022217, 0.8551216721534729, 0.8602150678634644, 0.8528579473495483, 0.8624787926673889, 0.8576683402061462, 0.8471986651420593, 0.8593661785125732, 0.8582342863082886, 0.8607810139656067, 0.8610639572143555, 0.8641765713691711, 0.853989839553833, 0.859649121761322, 0.8627617359161377, 0.8562535643577576, 0.8650254607200623, 0.8650254607200623, 0.8740803599357605, 0.8593661785125732, 0.8531408905982971, 0.865308403968811, 0.8627617359161377, 0.8650254607200623, 0.8667232394218445, 0.8701188564300537, 0.8704017996788025, 0.8720995783805847, 0.8658743500709534, 0.8771929740905762, 0.8800226449966431, 0.8757781386375427, 0.8704017996788025, 0.8650254607200623, 0.8667232394218445, 0.8664402961730957, 0.8715336918830872], 'val_loss': [0.6691629886627197, 0.6658155918121338, 0.6713652014732361, 0.6818328499794006, 0.6531716585159302, 0.6518105864524841, 0.6460208296775818, 0.6330864429473877, 0.6289747357368469, 0.6192431449890137, 0.6232182383537292, 0.6202967166900635, 0.6111266613006592, 0.607532262802124, 0.6750430464744568, 0.5894442796707153, 0.5920084714889526, 0.6239314675331116, 0.6114689707756042, 0.6311137080192566, 0.6006442904472351, 0.6226257681846619, 0.6420995593070984, 0.6425790786743164, 0.6138959527015686, 0.6560617089271545, 0.7096276879310608, 0.6633007526397705, 0.7123703360557556, 0.7171629071235657, 0.8056938052177429, 0.7055763602256775, 0.7104414701461792, 0.6966618895530701, 0.7207031846046448, 0.7223916053771973, 0.7316070199012756, 0.7230061888694763, 0.7017417550086975, 0.709182858467102, 0.7809638381004333, 0.7159832119941711, 0.7445504665374756, 0.8835437297821045, 0.7375335097312927, 0.8137408494949341, 0.7525591254234314, 0.7504674196243286, 0.7228098511695862, 0.7622186541557312, 0.7524778842926025, 0.7897865772247314, 0.7726991176605225, 0.7359731197357178, 0.7712080478668213, 0.7550256252288818, 0.7134373188018799, 0.7597032189369202, 0.7633026242256165, 0.7562375068664551, 0.7846295237541199, 0.9465717077255249, 0.7805873155593872, 0.8104369640350342, 0.7722397446632385, 0.7523743510246277, 0.8350221514701843, 0.7756977081298828, 0.7649316787719727, 0.8892358541488647, 0.9528694748878479, 0.8573511838912964, 0.828583300113678, 0.8754470348358154, 0.9479432106018066, 0.79154372215271, 0.7976096272468567, 0.8707078695297241, 0.8156396746635437, 0.7776447534561157, 0.7715075612068176, 0.7879308462142944, 0.8235191106796265, 0.8584727048873901, 0.8663908839225769, 0.8657926917076111, 0.8645917177200317, 0.9108108878135681, 0.9424597024917603, 0.8179782629013062, 0.8812305331230164, 0.8003025650978088, 0.9059209823608398, 0.787580668926239, 0.8359235525131226, 0.825814425945282, 0.9444733262062073, 0.8139265775680542, 0.883376955986023, 1.1804414987564087], 'val_accuracy': [0.5441176295280457, 0.5565611124038696, 0.5429864525794983, 0.5373303294181824, 0.5859728455543518, 0.5859728455543518, 0.5882353186607361, 0.6493212580680847, 0.610859751701355, 0.6549773812294006, 0.6153846383094788, 0.6119909286499023, 0.6561086177825928, 0.6368778347969055, 0.5927602052688599, 0.6730769276618958, 0.6696832776069641, 0.6538461446762085, 0.6776018142700195, 0.6674208045005798, 0.6968325972557068, 0.7036198973655701, 0.6945701241493225, 0.6696832776069641, 0.6934388875961304, 0.6776018142700195, 0.6821267008781433, 0.6968325972557068, 0.6764705777168274, 0.7070135474205017, 0.6583710312843323, 0.6832579374313354, 0.7070135474205017, 0.7002262473106384, 0.7047511339187622, 0.709276020526886, 0.6979637742042542, 0.6809954643249512, 0.6945701241493225, 0.6866515874862671, 0.6651583909988403, 0.6934388875961304, 0.7002262473106384, 0.6662895679473877, 0.6934388875961304, 0.6549773812294006, 0.6753393411636353, 0.6900452375411987, 0.6900452375411987, 0.692307710647583, 0.679864227771759, 0.6719456911087036, 0.6832579374313354, 0.7036198973655701, 0.6832579374313354, 0.7013574838638306, 0.6889140009880066, 0.6730769276618958, 0.6821267008781433, 0.6877828240394592, 0.6787330508232117, 0.639140248298645, 0.6753393411636353, 0.685520350933075, 0.692307710647583, 0.7013574838638306, 0.6821267008781433, 0.6843891143798828, 0.7013574838638306, 0.6764705777168274, 0.6380090713500977, 0.6640271544456482, 0.6662895679473877, 0.6583710312843323, 0.6504524946212769, 0.7036198973655701, 0.6990950107574463, 0.6617646813392639, 0.7036198973655701, 0.7047511339187622, 0.6968325972557068, 0.6968325972557068, 0.6968325972557068, 0.6821267008781433, 0.6527149081230164, 0.6583710312843323, 0.6934388875961304, 0.679864227771759, 0.6402714848518372, 0.6832579374313354, 0.6866515874862671, 0.7013574838638306, 0.6640271544456482, 0.7024886608123779, 0.6708144545555115, 0.7013574838638306, 0.6504524946212769, 0.6979637742042542, 0.668552041053772, 0.6334841847419739]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.4484 - accuracy: 0.7794"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 65ms/step - loss: 0.4493 - accuracy: 0.7788 - val_loss: 0.6742 - val_accuracy: 0.5279\n","Epoch 2/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4368 - accuracy: 0.7739 - val_loss: 0.6649 - val_accuracy: 0.6064\n","Epoch 3/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4249 - accuracy: 0.7863 - val_loss: 0.6744 - val_accuracy: 0.5269\n","Epoch 4/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4274 - accuracy: 0.7917 - val_loss: 0.6785 - val_accuracy: 0.5217\n","Epoch 5/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4190 - accuracy: 0.7964 - val_loss: 0.6571 - val_accuracy: 0.6167\n","Epoch 6/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4250 - accuracy: 0.7801 - val_loss: 0.6529 - val_accuracy: 0.6167\n","Epoch 7/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4240 - accuracy: 0.7910 - val_loss: 0.6581 - val_accuracy: 0.5661\n","Epoch 8/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4024 - accuracy: 0.8013 - val_loss: 0.6593 - val_accuracy: 0.5599\n","Epoch 9/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4168 - accuracy: 0.7889 - val_loss: 0.6498 - val_accuracy: 0.6064\n","Epoch 10/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4099 - accuracy: 0.7959 - val_loss: 0.6759 - val_accuracy: 0.5496\n","Epoch 11/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4075 - accuracy: 0.7935 - val_loss: 0.6613 - val_accuracy: 0.5599\n","Epoch 12/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4058 - accuracy: 0.8065 - val_loss: 0.6517 - val_accuracy: 0.5857\n","Epoch 13/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4029 - accuracy: 0.7907 - val_loss: 0.6256 - val_accuracy: 0.6395\n","Epoch 14/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4063 - accuracy: 0.8016 - val_loss: 0.6358 - val_accuracy: 0.6167\n","Epoch 15/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3928 - accuracy: 0.8057 - val_loss: 0.6698 - val_accuracy: 0.5816\n","Epoch 16/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4015 - accuracy: 0.8026 - val_loss: 0.6497 - val_accuracy: 0.6095\n","Epoch 17/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3978 - accuracy: 0.8065 - val_loss: 0.6298 - val_accuracy: 0.6405\n","Epoch 18/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4014 - accuracy: 0.7966 - val_loss: 0.6675 - val_accuracy: 0.6519\n","Epoch 19/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4039 - accuracy: 0.8036 - val_loss: 0.6543 - val_accuracy: 0.6384\n","Epoch 20/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4179 - accuracy: 0.7959 - val_loss: 0.6554 - val_accuracy: 0.6519\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3884 - accuracy: 0.8047 - val_loss: 0.6999 - val_accuracy: 0.6343\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3956 - accuracy: 0.7979 - val_loss: 0.7183 - val_accuracy: 0.6333\n","Epoch 23/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3874 - accuracy: 0.8083 - val_loss: 0.7398 - val_accuracy: 0.6477\n","Epoch 24/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4010 - accuracy: 0.7951 - val_loss: 0.7351 - val_accuracy: 0.6415\n","Epoch 25/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3843 - accuracy: 0.8160 - val_loss: 0.7879 - val_accuracy: 0.6519\n","Epoch 26/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3790 - accuracy: 0.8165 - val_loss: 0.7277 - val_accuracy: 0.6333\n","Epoch 27/100\n","31/31 [==============================] - 1s 39ms/step - loss: 0.3798 - accuracy: 0.8196 - val_loss: 0.7369 - val_accuracy: 0.6591\n","Epoch 28/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.3806 - accuracy: 0.8178 - val_loss: 0.7712 - val_accuracy: 0.6353\n","Epoch 29/100\n","31/31 [==============================] - 1s 35ms/step - loss: 0.3916 - accuracy: 0.8098 - val_loss: 0.8678 - val_accuracy: 0.6302\n","Epoch 30/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.3979 - accuracy: 0.8054 - val_loss: 0.8555 - val_accuracy: 0.6260\n","Epoch 31/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3767 - accuracy: 0.8160 - val_loss: 0.8584 - val_accuracy: 0.6302\n","Epoch 32/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3755 - accuracy: 0.8222 - val_loss: 0.8421 - val_accuracy: 0.6271\n","Epoch 33/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3779 - accuracy: 0.8165 - val_loss: 0.8178 - val_accuracy: 0.6384\n","Epoch 34/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3668 - accuracy: 0.8220 - val_loss: 0.9129 - val_accuracy: 0.6229\n","Epoch 35/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3771 - accuracy: 0.8163 - val_loss: 0.8449 - val_accuracy: 0.6405\n","Epoch 36/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3773 - accuracy: 0.8075 - val_loss: 0.8661 - val_accuracy: 0.6250\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3624 - accuracy: 0.8251 - val_loss: 0.9124 - val_accuracy: 0.6312\n","Epoch 38/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3657 - accuracy: 0.8284 - val_loss: 0.8074 - val_accuracy: 0.6519\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3634 - accuracy: 0.8230 - val_loss: 0.8140 - val_accuracy: 0.6467\n","Epoch 40/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3602 - accuracy: 0.8248 - val_loss: 0.8293 - val_accuracy: 0.6436\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3704 - accuracy: 0.8207 - val_loss: 0.8455 - val_accuracy: 0.6508\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3664 - accuracy: 0.8209 - val_loss: 0.8140 - val_accuracy: 0.6353\n","Epoch 43/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3660 - accuracy: 0.8269 - val_loss: 0.9025 - val_accuracy: 0.6395\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3638 - accuracy: 0.8199 - val_loss: 0.8758 - val_accuracy: 0.6415\n","Epoch 45/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3835 - accuracy: 0.8176 - val_loss: 0.8992 - val_accuracy: 0.6250\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3597 - accuracy: 0.8238 - val_loss: 1.0446 - val_accuracy: 0.6105\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3578 - accuracy: 0.8295 - val_loss: 0.8796 - val_accuracy: 0.6477\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3494 - accuracy: 0.8274 - val_loss: 0.8968 - val_accuracy: 0.6457\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3539 - accuracy: 0.8292 - val_loss: 0.9431 - val_accuracy: 0.6219\n","Epoch 50/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3812 - accuracy: 0.8101 - val_loss: 0.9738 - val_accuracy: 0.6167\n","Epoch 51/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3595 - accuracy: 0.8323 - val_loss: 0.8536 - val_accuracy: 0.6426\n","Epoch 52/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3573 - accuracy: 0.8302 - val_loss: 0.8602 - val_accuracy: 0.6229\n","Epoch 53/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3636 - accuracy: 0.8349 - val_loss: 0.9014 - val_accuracy: 0.6353\n","Epoch 54/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3586 - accuracy: 0.8323 - val_loss: 0.9117 - val_accuracy: 0.6198\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3484 - accuracy: 0.8354 - val_loss: 0.8851 - val_accuracy: 0.6446\n","Epoch 56/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3525 - accuracy: 0.8297 - val_loss: 0.8537 - val_accuracy: 0.6250\n","Epoch 57/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3967 - accuracy: 0.8181 - val_loss: 0.8848 - val_accuracy: 0.6229\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3595 - accuracy: 0.8238 - val_loss: 0.8122 - val_accuracy: 0.6322\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3501 - accuracy: 0.8313 - val_loss: 0.8956 - val_accuracy: 0.6395\n","Epoch 60/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3394 - accuracy: 0.8401 - val_loss: 1.0061 - val_accuracy: 0.6322\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3553 - accuracy: 0.8323 - val_loss: 0.8554 - val_accuracy: 0.6539\n","Epoch 62/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3507 - accuracy: 0.8377 - val_loss: 0.8800 - val_accuracy: 0.6508\n","Epoch 63/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3491 - accuracy: 0.8333 - val_loss: 0.8428 - val_accuracy: 0.6281\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3504 - accuracy: 0.8333 - val_loss: 0.8746 - val_accuracy: 0.6250\n","Epoch 65/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3371 - accuracy: 0.8426 - val_loss: 0.8850 - val_accuracy: 0.6405\n","Epoch 66/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3330 - accuracy: 0.8434 - val_loss: 0.9801 - val_accuracy: 0.6250\n","Epoch 67/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3426 - accuracy: 0.8395 - val_loss: 0.8808 - val_accuracy: 0.6322\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3358 - accuracy: 0.8416 - val_loss: 0.8929 - val_accuracy: 0.6250\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3526 - accuracy: 0.8331 - val_loss: 0.9044 - val_accuracy: 0.6333\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3466 - accuracy: 0.8370 - val_loss: 0.8728 - val_accuracy: 0.6446\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3335 - accuracy: 0.8416 - val_loss: 0.9093 - val_accuracy: 0.6333\n","Epoch 72/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3491 - accuracy: 0.8359 - val_loss: 0.8755 - val_accuracy: 0.6488\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3349 - accuracy: 0.8442 - val_loss: 0.9331 - val_accuracy: 0.6209\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3331 - accuracy: 0.8452 - val_loss: 0.9424 - val_accuracy: 0.6353\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3278 - accuracy: 0.8470 - val_loss: 0.9681 - val_accuracy: 0.6260\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3348 - accuracy: 0.8403 - val_loss: 1.0042 - val_accuracy: 0.6136\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3330 - accuracy: 0.8470 - val_loss: 0.9333 - val_accuracy: 0.6405\n","Epoch 78/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3393 - accuracy: 0.8450 - val_loss: 1.0242 - val_accuracy: 0.6250\n","Epoch 79/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3172 - accuracy: 0.8496 - val_loss: 0.9357 - val_accuracy: 0.6167\n","Epoch 80/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3213 - accuracy: 0.8439 - val_loss: 0.9310 - val_accuracy: 0.6322\n","Epoch 81/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3192 - accuracy: 0.8483 - val_loss: 1.0401 - val_accuracy: 0.6271\n","Epoch 82/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3247 - accuracy: 0.8566 - val_loss: 0.8875 - val_accuracy: 0.6374\n","Epoch 83/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3234 - accuracy: 0.8561 - val_loss: 0.9410 - val_accuracy: 0.6333\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3223 - accuracy: 0.8473 - val_loss: 0.9054 - val_accuracy: 0.6250\n","Epoch 85/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3170 - accuracy: 0.8509 - val_loss: 0.9488 - val_accuracy: 0.6157\n","Epoch 86/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3178 - accuracy: 0.8509 - val_loss: 0.9318 - val_accuracy: 0.6198\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3423 - accuracy: 0.8370 - val_loss: 0.9765 - val_accuracy: 0.6136\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3310 - accuracy: 0.8398 - val_loss: 1.0677 - val_accuracy: 0.6312\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3368 - accuracy: 0.8447 - val_loss: 0.9960 - val_accuracy: 0.6322\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3323 - accuracy: 0.8457 - val_loss: 1.0022 - val_accuracy: 0.6240\n","Epoch 91/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3220 - accuracy: 0.8470 - val_loss: 0.9506 - val_accuracy: 0.6291\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3260 - accuracy: 0.8455 - val_loss: 0.9471 - val_accuracy: 0.6312\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3261 - accuracy: 0.8429 - val_loss: 1.0771 - val_accuracy: 0.6364\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3242 - accuracy: 0.8478 - val_loss: 0.9577 - val_accuracy: 0.6302\n","Epoch 95/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3141 - accuracy: 0.8519 - val_loss: 0.9523 - val_accuracy: 0.6281\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3139 - accuracy: 0.8550 - val_loss: 0.9817 - val_accuracy: 0.6291\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3092 - accuracy: 0.8571 - val_loss: 1.1043 - val_accuracy: 0.6085\n","Epoch 98/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3033 - accuracy: 0.8561 - val_loss: 1.0073 - val_accuracy: 0.6178\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3118 - accuracy: 0.8587 - val_loss: 1.0100 - val_accuracy: 0.6260\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3060 - accuracy: 0.8599 - val_loss: 1.0643 - val_accuracy: 0.6157\n","{'loss': [0.4492875635623932, 0.4368448257446289, 0.4248964190483093, 0.42741093039512634, 0.41904348134994507, 0.424977570772171, 0.4240490198135376, 0.40241739153862, 0.4168020486831665, 0.4098549485206604, 0.4074859023094177, 0.4058346152305603, 0.4029243290424347, 0.40634116530418396, 0.3928222060203552, 0.40153804421424866, 0.39776748418807983, 0.4013903737068176, 0.40386876463890076, 0.4179045855998993, 0.3883788287639618, 0.3956272006034851, 0.38741856813430786, 0.40096065402030945, 0.3843204081058502, 0.3789840638637543, 0.3798205554485321, 0.38057929277420044, 0.3915650248527527, 0.39786916971206665, 0.37672483921051025, 0.37554314732551575, 0.3778722584247589, 0.3668265640735626, 0.37708133459091187, 0.3773488998413086, 0.36235010623931885, 0.3657045066356659, 0.3634374141693115, 0.3602384328842163, 0.3704100251197815, 0.3664094805717468, 0.3659863770008087, 0.36381763219833374, 0.38345617055892944, 0.35968148708343506, 0.35775452852249146, 0.3494035601615906, 0.35385262966156006, 0.3812229037284851, 0.3594895601272583, 0.3572867512702942, 0.36357375979423523, 0.35864928364753723, 0.34840652346611023, 0.35245421528816223, 0.39669767022132874, 0.35950347781181335, 0.35014957189559937, 0.3394063711166382, 0.35532137751579285, 0.3507348299026489, 0.3490692675113678, 0.35035544633865356, 0.3370869755744934, 0.333028644323349, 0.3425845503807068, 0.3357868790626526, 0.3526464104652405, 0.3465826213359833, 0.3335454761981964, 0.34911149740219116, 0.3349206745624542, 0.33311915397644043, 0.32775819301605225, 0.3348471224308014, 0.3329644501209259, 0.33926036953926086, 0.31716132164001465, 0.3212793171405792, 0.31920164823532104, 0.32471826672554016, 0.32344698905944824, 0.3223266303539276, 0.3170301020145416, 0.31783801317214966, 0.3422927260398865, 0.33095067739486694, 0.3367685377597809, 0.3323497474193573, 0.32201942801475525, 0.3259850740432739, 0.3261468708515167, 0.3241923153400421, 0.3141483962535858, 0.31391072273254395, 0.30920591950416565, 0.3033478856086731, 0.3117717206478119, 0.30601587891578674], 'accuracy': [0.7788113951683044, 0.7739018201828003, 0.7863048911094666, 0.7917312383651733, 0.7963824272155762, 0.7801033854484558, 0.7909560799598694, 0.8012920022010803, 0.7888888716697693, 0.7958656549453735, 0.7935400605201721, 0.8064599633216858, 0.7906976938247681, 0.8015503883361816, 0.8056847453117371, 0.8025839924812317, 0.8064599633216858, 0.7966408133506775, 0.8036175966262817, 0.7958656549453735, 0.804651141166687, 0.7979328036308289, 0.8082687258720398, 0.7950904369354248, 0.816020667552948, 0.8165374398231506, 0.8196382522583008, 0.817829430103302, 0.8098191022872925, 0.8054263591766357, 0.816020667552948, 0.8222222328186035, 0.8165374398231506, 0.8219638466835022, 0.8162790536880493, 0.8074935674667358, 0.8250645995140076, 0.828423798084259, 0.8229973912239075, 0.8248062133789062, 0.8206718564033508, 0.8209302425384521, 0.8268733620643616, 0.8198966383934021, 0.8175710439682007, 0.8237726092338562, 0.8294573426246643, 0.827390193939209, 0.829198956489563, 0.8100775480270386, 0.8322997689247131, 0.830232560634613, 0.8348837494850159, 0.8322997689247131, 0.8354005217552185, 0.8297157883644104, 0.8180878758430481, 0.8237726092338562, 0.8312661647796631, 0.8400516510009766, 0.8322997689247131, 0.8377261161804199, 0.8333333134651184, 0.8333333134651184, 0.8426356315612793, 0.843410849571228, 0.8395348787307739, 0.841602087020874, 0.8330749273300171, 0.8369508981704712, 0.841602087020874, 0.8359172940254211, 0.8441860675811768, 0.845219612121582, 0.8470284342765808, 0.8403100967407227, 0.8470284342765808, 0.8449612259864807, 0.8496124148368835, 0.8439276218414307, 0.8483204245567322, 0.856589138507843, 0.8560723662376404, 0.8472868204116821, 0.8509044051170349, 0.8509044051170349, 0.8369508981704712, 0.8397932648658752, 0.8447028398513794, 0.8457364439964294, 0.8470284342765808, 0.8454780578613281, 0.8428940773010254, 0.8478035926818848, 0.851938009262085, 0.8550387620925903, 0.8571059703826904, 0.8560723662376404, 0.8586563467979431, 0.8599483370780945], 'val_loss': [0.6742076277732849, 0.6648939847946167, 0.674414873123169, 0.678521990776062, 0.6571142077445984, 0.6528880000114441, 0.6581300497055054, 0.6592591404914856, 0.6498485803604126, 0.6759379506111145, 0.6612840294837952, 0.6517413258552551, 0.6255643963813782, 0.635783314704895, 0.6698060035705566, 0.6496973633766174, 0.6298110485076904, 0.6675321459770203, 0.6542537212371826, 0.6554149389266968, 0.6999294757843018, 0.7183383703231812, 0.7398248314857483, 0.7350636720657349, 0.7878607511520386, 0.727671205997467, 0.7369301319122314, 0.7712205052375793, 0.867809534072876, 0.8555476069450378, 0.858386218547821, 0.8421462774276733, 0.8177668452262878, 0.9129071831703186, 0.8449162840843201, 0.8660759925842285, 0.9123836159706116, 0.8074034452438354, 0.8140439987182617, 0.8292504549026489, 0.8454703092575073, 0.8139835000038147, 0.9024767279624939, 0.8758341670036316, 0.8991724848747253, 1.0445756912231445, 0.8795960545539856, 0.8967840075492859, 0.943108856678009, 0.9737883806228638, 0.8535709977149963, 0.8601651787757874, 0.901382327079773, 0.9117205739021301, 0.8850905299186707, 0.8537261486053467, 0.8848418593406677, 0.812230110168457, 0.8956477046012878, 1.0061368942260742, 0.85539311170578, 0.8800039291381836, 0.842831552028656, 0.8745855093002319, 0.8849695920944214, 0.9800693392753601, 0.880779504776001, 0.8928941488265991, 0.9043527245521545, 0.8727554678916931, 0.9092836380004883, 0.8755101561546326, 0.9331355094909668, 0.942427933216095, 0.9681126475334167, 1.004227876663208, 0.9333374500274658, 1.0241578817367554, 0.9356591105461121, 0.9309805631637573, 1.04013192653656, 0.8875201344490051, 0.9409865736961365, 0.9054375290870667, 0.9488394856452942, 0.9318234920501709, 0.9765483140945435, 1.0676521062850952, 0.9960012435913086, 1.0022293329238892, 0.9506288170814514, 0.9471436738967896, 1.077128291130066, 0.9576647281646729, 0.9522561430931091, 0.9817081093788147, 1.1042875051498413, 1.0072999000549316, 1.0100207328796387, 1.0643208026885986], 'val_accuracy': [0.5278925895690918, 0.6064049601554871, 0.5268595218658447, 0.5216942429542542, 0.6167355179786682, 0.6167355179786682, 0.56611567735672, 0.5599173307418823, 0.6064049601554871, 0.5495867729187012, 0.5599173307418823, 0.58574378490448, 0.6394628286361694, 0.6167355179786682, 0.5816115736961365, 0.6095041036605835, 0.6404958963394165, 0.6518595218658447, 0.6384297609329224, 0.6518595218658447, 0.6342975497245789, 0.6332644820213318, 0.6477272510528564, 0.6415289044380188, 0.6518595218658447, 0.6332644820213318, 0.6590909361839294, 0.6353305578231812, 0.6301652789115906, 0.6260330677032471, 0.6301652789115906, 0.6270661354064941, 0.6384297609329224, 0.6229338645935059, 0.6404958963394165, 0.625, 0.6311983466148376, 0.6518595218658447, 0.6466942429542542, 0.6435950398445129, 0.6508264541625977, 0.6353305578231812, 0.6394628286361694, 0.6415289044380188, 0.625, 0.6105371713638306, 0.6477272510528564, 0.6456611752510071, 0.6219007968902588, 0.6167355179786682, 0.6425619721412659, 0.6229338645935059, 0.6353305578231812, 0.6198347210884094, 0.64462810754776, 0.625, 0.6229338645935059, 0.6322314143180847, 0.6394628286361694, 0.6322314143180847, 0.6539255976676941, 0.6508264541625977, 0.6280992031097412, 0.625, 0.6404958963394165, 0.625, 0.6322314143180847, 0.625, 0.6332644820213318, 0.64462810754776, 0.6332644820213318, 0.6487603187561035, 0.6208677887916565, 0.6353305578231812, 0.6260330677032471, 0.6136363744735718, 0.6404958963394165, 0.625, 0.6167355179786682, 0.6322314143180847, 0.6270661354064941, 0.6373966932296753, 0.6332644820213318, 0.625, 0.6157024502754211, 0.6198347210884094, 0.6136363744735718, 0.6311983466148376, 0.6322314143180847, 0.6239669322967529, 0.6291322112083435, 0.6311983466148376, 0.6363636255264282, 0.6301652789115906, 0.6280992031097412, 0.6291322112083435, 0.6084710955619812, 0.6177685856819153, 0.6260330677032471, 0.6157024502754211]}\n","32/32 [==============================] - 1s 3ms/step\n"]}],"source":["global_model, metrics_df = federated_learning(Theta_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1022,"status":"ok","timestamp":1717431743032,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"},"user_tz":-360},"id":"Ik5JoVP2NPvY","outputId":"3d454b33-7a57-4235-b3f9-be4b9a43882f"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"metrics_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04164109691615906,\n        \"min\": 0.528,\n        \"max\": 0.676,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.593,\n          0.629,\n          0.549\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.043170205775125335,\n        \"min\": 0.525,\n        \"max\": 0.697,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.59,\n          0.598,\n          0.556\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15281866004236153,\n        \"min\": 0.356,\n        \"max\": 0.897,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.608,\n          0.787,\n          0.487\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07558703592548129,\n        \"min\": 0.451,\n        \"max\": 0.703,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.599,\n          0.679,\n          0.52\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15281866004236153,\n        \"min\": 0.356,\n        \"max\": 0.897,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.608,\n          0.787,\n          0.487\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13346945432605634,\n        \"min\": 0.292,\n        \"max\": 0.777,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.578,\n          0.47,\n          0.611\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08294616728135583,\n        \"min\": 0.055,\n        \"max\": 0.351,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.186,\n          0.257,\n          0.099\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe"},"text/html":["\n","  <div id=\"df-94dccdb8-533d-463a-8340-325d96fd4cc7\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.549</td>\n","      <td>0.556</td>\n","      <td>0.487</td>\n","      <td>0.520</td>\n","      <td>0.487</td>\n","      <td>0.611</td>\n","      <td>0.099</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.566</td>\n","      <td>0.615</td>\n","      <td>0.356</td>\n","      <td>0.451</td>\n","      <td>0.356</td>\n","      <td>0.777</td>\n","      <td>0.133</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.557</td>\n","      <td>0.570</td>\n","      <td>0.466</td>\n","      <td>0.513</td>\n","      <td>0.466</td>\n","      <td>0.649</td>\n","      <td>0.114</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.528</td>\n","      <td>0.525</td>\n","      <td>0.586</td>\n","      <td>0.554</td>\n","      <td>0.586</td>\n","      <td>0.469</td>\n","      <td>0.055</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.546</td>\n","      <td>0.552</td>\n","      <td>0.484</td>\n","      <td>0.516</td>\n","      <td>0.484</td>\n","      <td>0.607</td>\n","      <td>0.092</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.598</td>\n","      <td>0.586</td>\n","      <td>0.673</td>\n","      <td>0.626</td>\n","      <td>0.673</td>\n","      <td>0.524</td>\n","      <td>0.197</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.560</td>\n","      <td>0.550</td>\n","      <td>0.663</td>\n","      <td>0.601</td>\n","      <td>0.663</td>\n","      <td>0.457</td>\n","      <td>0.121</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.579</td>\n","      <td>0.578</td>\n","      <td>0.583</td>\n","      <td>0.581</td>\n","      <td>0.583</td>\n","      <td>0.575</td>\n","      <td>0.158</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.614</td>\n","      <td>0.584</td>\n","      <td>0.799</td>\n","      <td>0.675</td>\n","      <td>0.799</td>\n","      <td>0.430</td>\n","      <td>0.229</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.593</td>\n","      <td>0.590</td>\n","      <td>0.608</td>\n","      <td>0.599</td>\n","      <td>0.608</td>\n","      <td>0.578</td>\n","      <td>0.186</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.581</td>\n","      <td>0.557</td>\n","      <td>0.792</td>\n","      <td>0.654</td>\n","      <td>0.792</td>\n","      <td>0.370</td>\n","      <td>0.162</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.629</td>\n","      <td>0.598</td>\n","      <td>0.787</td>\n","      <td>0.679</td>\n","      <td>0.787</td>\n","      <td>0.470</td>\n","      <td>0.257</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.657</td>\n","      <td>0.697</td>\n","      <td>0.554</td>\n","      <td>0.618</td>\n","      <td>0.554</td>\n","      <td>0.759</td>\n","      <td>0.313</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.595</td>\n","      <td>0.559</td>\n","      <td>0.897</td>\n","      <td>0.689</td>\n","      <td>0.897</td>\n","      <td>0.292</td>\n","      <td>0.189</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.676</td>\n","      <td>0.648</td>\n","      <td>0.769</td>\n","      <td>0.703</td>\n","      <td>0.769</td>\n","      <td>0.582</td>\n","      <td>0.351</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94dccdb8-533d-463a-8340-325d96fd4cc7')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-94dccdb8-533d-463a-8340-325d96fd4cc7 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-94dccdb8-533d-463a-8340-325d96fd4cc7');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-1d1dbe9e-55c9-4efe-baac-76e6dceae1b5\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1d1dbe9e-55c9-4efe-baac-76e6dceae1b5')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-1d1dbe9e-55c9-4efe-baac-76e6dceae1b5 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.549      0.556   0.487  0.520        0.487        0.611   \n","1        1     0.566      0.615   0.356  0.451        0.356        0.777   \n","2        2     0.557      0.570   0.466  0.513        0.466        0.649   \n","3        0     0.528      0.525   0.586  0.554        0.586        0.469   \n","4        1     0.546      0.552   0.484  0.516        0.484        0.607   \n","5        2     0.598      0.586   0.673  0.626        0.673        0.524   \n","6        0     0.560      0.550   0.663  0.601        0.663        0.457   \n","7        1     0.579      0.578   0.583  0.581        0.583        0.575   \n","8        2     0.614      0.584   0.799  0.675        0.799        0.430   \n","9        0     0.593      0.590   0.608  0.599        0.608        0.578   \n","10       1     0.581      0.557   0.792  0.654        0.792        0.370   \n","11       2     0.629      0.598   0.787  0.679        0.787        0.470   \n","12       0     0.657      0.697   0.554  0.618        0.554        0.759   \n","13       1     0.595      0.559   0.897  0.689        0.897        0.292   \n","14       2     0.676      0.648   0.769  0.703        0.769        0.582   \n","\n","    Kappa  \n","0   0.099  \n","1   0.133  \n","2   0.114  \n","3   0.055  \n","4   0.092  \n","5   0.197  \n","6   0.121  \n","7   0.158  \n","8   0.229  \n","9   0.186  \n","10  0.162  \n","11  0.257  \n","12  0.313  \n","13  0.189  \n","14  0.351  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["\n","metrics_df.round(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ncf_cMAQF6g4"},"outputs":[],"source":["metrics_df.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Frequency Domain/CNN_LSTM/Delta_CNN_LSTM.csv', index = False)"]},{"cell_type":"markdown","metadata":{"id":"-JYOb1ECSWiK"},"source":["# Draw Plot"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":462},"executionInfo":{"elapsed":5539,"status":"ok","timestamp":1716751976597,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"},"user_tz":-360},"id":"gJsXPPS1SZVN","outputId":"49a4f72f-e33e-4603-a33c-9ebf3769e9ef"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 1500x450 with 10 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import re\n","import os\n","\n","# Function to read CSV logs and extract accuracy and validation accuracy\n","def read_logs(log_dir, num_clients, local_epochs):\n","    dataframes = []\n","    for epoch in range(local_epochs):\n","        for client in range(num_clients):\n","            log_file = os.path.join(log_dir, f'training_log_epoch_{epoch}_client_{client}.csv')\n","            if os.path.exists(log_file):\n","                df = pd.read_csv(log_file, sep=';')\n","                df['epoch_number'] = epoch\n","                df['client_number'] = client\n","                dataframes.append(df)\n","            else:\n","                print(f\"Log file not found: {log_file}\")\n","\n","    return pd.concat(dataframes) if dataframes else pd.DataFrame()\n","\n","# Function to plot the training and validation accuracy\n","def plot_accuracy(all_metrics_df, unique_epochs, output_dir):\n","    # Set the Seaborn style\n","    sns.set(style=\"whitegrid\")\n","\n","    # Create subplots for each epoch\n","    fig, axes = plt.subplots(2, len(unique_epochs), figsize=(len(unique_epochs) * 3, 4.5), sharex=True)\n","\n","    # Set the color palette\n","    palette = sns.color_palette(\"Set1\", n_colors=all_metrics_df['client_number'].nunique())\n","\n","    # Store the lines and labels for the legend\n","    lines = []\n","    labels = []\n","\n","    # Iterate through each epoch and plot the training and validation accuracy\n","    for i, epoch in enumerate(unique_epochs):\n","        epoch_df = all_metrics_df[all_metrics_df['epoch_number'] == epoch]\n","        for j, client in enumerate(epoch_df['client_number'].unique()):\n","            client_df = epoch_df[epoch_df['client_number'] == client].dropna(subset=['accuracy', 'val_accuracy'])\n","            if not client_df.empty:\n","                line, = axes[0, i].plot(client_df.index, client_df['accuracy'], label=f'Client {client}', alpha=0.6, color=palette[j], linewidth=2.0)\n","                axes[1, i].plot(client_df.index, client_df['val_accuracy'], label=f'Client {client}', alpha=0.6, color=palette[j], linewidth=2.0)\n","\n","                if i == 0:\n","                    lines.append(line)\n","                    labels.append(f'Client {client}')\n","\n","        axes[0, i].set_title(f'Epoch {epoch}', fontsize=12, fontweight='bold')\n","        axes[0, i].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","        axes[1, i].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","        axes[1, i].set_xlabel('Steps', fontsize=10, fontweight='bold')\n","        axes[0, i].grid(True)\n","        axes[1, i].grid(True)\n","        axes[0, i].tick_params(axis='both', which='major', labelsize=10)\n","        axes[1, i].tick_params(axis='both', which='major', labelsize=10)\n","\n","    # Add a single legend for the entire figure\n","    fig.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, 1.0), ncol=len(labels), fontsize=10, frameon=True)\n","\n","    # Add row labels\n","    fig.text(0.04, 0.75, 'Training Accuracy', ha='center', va='center', rotation='vertical', fontsize=12, fontweight='bold')\n","    fig.text(0.04, 0.25, 'Validation Accuracy', ha='center', va='center', rotation='vertical', fontsize=12, fontweight='bold')\n","\n","    plt.tight_layout(rect=[0.05, 0, 1, 0.95])\n","    plt.subplots_adjust(hspace=0.2, top=0.88)  # Add some space between the rows and reduce space between the legend and plot\n","\n","    # Save the figure in high DPI PNG and PDF\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    fig.savefig(os.path.join(output_dir, 'accuracy_plot.png'), dpi=300, format='png')\n","    fig.savefig(os.path.join(output_dir, 'accuracy_plot.pdf'), dpi=300, format='pdf')\n","\n","    plt.show()\n","\n","# Directory where CSV logs are saved\n","log_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Delta'\n","\n","# Output directory for saving plots\n","output_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Delta/plots'\n","\n","# Number of clients and local epochs\n","num_clients = 3\n","local_epochs = 5\n","\n","# Read logs and generate the dataframe\n","all_metrics_df = read_logs(log_dir, num_clients, local_epochs)\n","\n","# Get unique epochs from the dataframe\n","unique_epochs = sorted(all_metrics_df['epoch_number'].unique())\n","\n","# Plot the accuracy\n","plot_accuracy(all_metrics_df, unique_epochs, output_dir)\n"]},{"cell_type":"markdown","metadata":{"id":"QUuWzfMHSNmi"},"source":["# CNN"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":793,"status":"ok","timestamp":1717435553682,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"},"user_tz":-360},"id":"8xrx_fxBSWGd"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    # model.add(Dropout(0.5))\n","    # model.add(LSTM(256, return_sequences=True))\n","    # model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Delta/CNN/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Delta/CNN/training_log_{run_name}.csv', append=True, separator=';')\n","\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H1TaNdIbSfkq","executionInfo":{"status":"ok","timestamp":1717436273452,"user_tz":-360,"elapsed":719774,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}},"outputId":"1f390718-574b-4dd3-f782-77c63ac17e32"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 1.7713 - accuracy: 0.5019"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 13s 104ms/step - loss: 1.7713 - accuracy: 0.5019 - val_loss: 1.7664 - val_accuracy: 0.4752\n","Epoch 2/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.7596 - accuracy: 0.5038 - val_loss: 1.7556 - val_accuracy: 0.4698\n","Epoch 3/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.7483 - accuracy: 0.5038 - val_loss: 1.7450 - val_accuracy: 0.5399\n","Epoch 4/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.7374 - accuracy: 0.5151 - val_loss: 1.7345 - val_accuracy: 0.5668\n","Epoch 5/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.7264 - accuracy: 0.5145 - val_loss: 1.7240 - val_accuracy: 0.5582\n","Epoch 6/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.7157 - accuracy: 0.5251 - val_loss: 1.7137 - val_accuracy: 0.5506\n","Epoch 7/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.7050 - accuracy: 0.5307 - val_loss: 1.7034 - val_accuracy: 0.5463\n","Epoch 8/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.6948 - accuracy: 0.5261 - val_loss: 1.6932 - val_accuracy: 0.5582\n","Epoch 9/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.6843 - accuracy: 0.5383 - val_loss: 1.6832 - val_accuracy: 0.5485\n","Epoch 10/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.6739 - accuracy: 0.5334 - val_loss: 1.6732 - val_accuracy: 0.5506\n","Epoch 11/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.6637 - accuracy: 0.5458 - val_loss: 1.6634 - val_accuracy: 0.5582\n","Epoch 12/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.6537 - accuracy: 0.5420 - val_loss: 1.6537 - val_accuracy: 0.5517\n","Epoch 13/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.6437 - accuracy: 0.5477 - val_loss: 1.6438 - val_accuracy: 0.5593\n","Epoch 14/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.6338 - accuracy: 0.5477 - val_loss: 1.6343 - val_accuracy: 0.5582\n","Epoch 15/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.6239 - accuracy: 0.5533 - val_loss: 1.6246 - val_accuracy: 0.5668\n","Epoch 16/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.6145 - accuracy: 0.5512 - val_loss: 1.6153 - val_accuracy: 0.5614\n","Epoch 17/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.6047 - accuracy: 0.5536 - val_loss: 1.6058 - val_accuracy: 0.5614\n","Epoch 18/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.5952 - accuracy: 0.5547 - val_loss: 1.5968 - val_accuracy: 0.5625\n","Epoch 19/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.5857 - accuracy: 0.5614 - val_loss: 1.5874 - val_accuracy: 0.5582\n","Epoch 20/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.5764 - accuracy: 0.5566 - val_loss: 1.5783 - val_accuracy: 0.5657\n","Epoch 21/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.5672 - accuracy: 0.5617 - val_loss: 1.5698 - val_accuracy: 0.5668\n","Epoch 22/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.5581 - accuracy: 0.5657 - val_loss: 1.5607 - val_accuracy: 0.5593\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.5490 - accuracy: 0.5682 - val_loss: 1.5522 - val_accuracy: 0.5582\n","Epoch 24/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.5399 - accuracy: 0.5706 - val_loss: 1.5438 - val_accuracy: 0.5625\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.5309 - accuracy: 0.5722 - val_loss: 1.5352 - val_accuracy: 0.5474\n","Epoch 26/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.5224 - accuracy: 0.5695 - val_loss: 1.5268 - val_accuracy: 0.5366\n","Epoch 27/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.5135 - accuracy: 0.5789 - val_loss: 1.5199 - val_accuracy: 0.5571\n","Epoch 28/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.5049 - accuracy: 0.5687 - val_loss: 1.5125 - val_accuracy: 0.5657\n","Epoch 29/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.4962 - accuracy: 0.5687 - val_loss: 1.5035 - val_accuracy: 0.5463\n","Epoch 30/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.4876 - accuracy: 0.5765 - val_loss: 1.4965 - val_accuracy: 0.5409\n","Epoch 31/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.4788 - accuracy: 0.5841 - val_loss: 1.4889 - val_accuracy: 0.5528\n","Epoch 32/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.4702 - accuracy: 0.5811 - val_loss: 1.4821 - val_accuracy: 0.5517\n","Epoch 33/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.4620 - accuracy: 0.5849 - val_loss: 1.4749 - val_accuracy: 0.5528\n","Epoch 34/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.4540 - accuracy: 0.5870 - val_loss: 1.4680 - val_accuracy: 0.5571\n","Epoch 35/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.4454 - accuracy: 0.5870 - val_loss: 1.4623 - val_accuracy: 0.5582\n","Epoch 36/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.4368 - accuracy: 0.5919 - val_loss: 1.4523 - val_accuracy: 0.5560\n","Epoch 37/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.4299 - accuracy: 0.5881 - val_loss: 1.4459 - val_accuracy: 0.5593\n","Epoch 38/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.4208 - accuracy: 0.5935 - val_loss: 1.4402 - val_accuracy: 0.5582\n","Epoch 39/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.4129 - accuracy: 0.5878 - val_loss: 1.4367 - val_accuracy: 0.5636\n","Epoch 40/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.4049 - accuracy: 0.5946 - val_loss: 1.4309 - val_accuracy: 0.5571\n","Epoch 41/100\n","29/29 [==============================] - 1s 33ms/step - loss: 1.3973 - accuracy: 0.5983 - val_loss: 1.4232 - val_accuracy: 0.5679\n","Epoch 42/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.3893 - accuracy: 0.5986 - val_loss: 1.4135 - val_accuracy: 0.5593\n","Epoch 43/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.3817 - accuracy: 0.5970 - val_loss: 1.4088 - val_accuracy: 0.5560\n","Epoch 44/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3736 - accuracy: 0.6053 - val_loss: 1.4020 - val_accuracy: 0.5582\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3665 - accuracy: 0.6037 - val_loss: 1.3960 - val_accuracy: 0.5571\n","Epoch 46/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3580 - accuracy: 0.6021 - val_loss: 1.3902 - val_accuracy: 0.5582\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3510 - accuracy: 0.6037 - val_loss: 1.3840 - val_accuracy: 0.5517\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3432 - accuracy: 0.6072 - val_loss: 1.3794 - val_accuracy: 0.5582\n","Epoch 49/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3358 - accuracy: 0.6096 - val_loss: 1.3769 - val_accuracy: 0.5625\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3281 - accuracy: 0.6140 - val_loss: 1.3680 - val_accuracy: 0.5593\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3209 - accuracy: 0.6153 - val_loss: 1.3639 - val_accuracy: 0.5539\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3144 - accuracy: 0.6175 - val_loss: 1.3599 - val_accuracy: 0.5506\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3063 - accuracy: 0.6185 - val_loss: 1.3554 - val_accuracy: 0.5614\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3018 - accuracy: 0.6123 - val_loss: 1.3492 - val_accuracy: 0.5571\n","Epoch 55/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2924 - accuracy: 0.6191 - val_loss: 1.3492 - val_accuracy: 0.5528\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2854 - accuracy: 0.6172 - val_loss: 1.3380 - val_accuracy: 0.5582\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2783 - accuracy: 0.6185 - val_loss: 1.3442 - val_accuracy: 0.5550\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2732 - accuracy: 0.6156 - val_loss: 1.3385 - val_accuracy: 0.5582\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2660 - accuracy: 0.6263 - val_loss: 1.3251 - val_accuracy: 0.5485\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2608 - accuracy: 0.6242 - val_loss: 1.3177 - val_accuracy: 0.5647\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2515 - accuracy: 0.6253 - val_loss: 1.3194 - val_accuracy: 0.5668\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2458 - accuracy: 0.6296 - val_loss: 1.3148 - val_accuracy: 0.5506\n","Epoch 63/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2394 - accuracy: 0.6234 - val_loss: 1.3129 - val_accuracy: 0.5690\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2344 - accuracy: 0.6255 - val_loss: 1.3113 - val_accuracy: 0.5506\n","Epoch 65/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2266 - accuracy: 0.6347 - val_loss: 1.3046 - val_accuracy: 0.5657\n","Epoch 66/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.2192 - accuracy: 0.6331 - val_loss: 1.2987 - val_accuracy: 0.5603\n","Epoch 67/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.2137 - accuracy: 0.6328 - val_loss: 1.2940 - val_accuracy: 0.5571\n","Epoch 68/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.2072 - accuracy: 0.6344 - val_loss: 1.2890 - val_accuracy: 0.5571\n","Epoch 69/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.2001 - accuracy: 0.6339 - val_loss: 1.2879 - val_accuracy: 0.5636\n","Epoch 70/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.1963 - accuracy: 0.6323 - val_loss: 1.2796 - val_accuracy: 0.5690\n","Epoch 71/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.1886 - accuracy: 0.6433 - val_loss: 1.2843 - val_accuracy: 0.5625\n","Epoch 72/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.1832 - accuracy: 0.6436 - val_loss: 1.2769 - val_accuracy: 0.5539\n","Epoch 73/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.1757 - accuracy: 0.6457 - val_loss: 1.2700 - val_accuracy: 0.5636\n","Epoch 74/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.1713 - accuracy: 0.6471 - val_loss: 1.2693 - val_accuracy: 0.5517\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1648 - accuracy: 0.6441 - val_loss: 1.2670 - val_accuracy: 0.5711\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1593 - accuracy: 0.6441 - val_loss: 1.2610 - val_accuracy: 0.5744\n","Epoch 77/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1535 - accuracy: 0.6433 - val_loss: 1.2615 - val_accuracy: 0.5593\n","Epoch 78/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.1474 - accuracy: 0.6503 - val_loss: 1.2614 - val_accuracy: 0.5636\n","Epoch 79/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.1412 - accuracy: 0.6468 - val_loss: 1.2613 - val_accuracy: 0.5679\n","Epoch 80/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.1381 - accuracy: 0.6525 - val_loss: 1.2525 - val_accuracy: 0.5571\n","Epoch 81/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.1323 - accuracy: 0.6554 - val_loss: 1.2575 - val_accuracy: 0.5711\n","Epoch 82/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.1249 - accuracy: 0.6522 - val_loss: 1.2554 - val_accuracy: 0.5744\n","Epoch 83/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.1205 - accuracy: 0.6463 - val_loss: 1.2409 - val_accuracy: 0.5539\n","Epoch 84/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.1159 - accuracy: 0.6487 - val_loss: 1.2487 - val_accuracy: 0.5700\n","Epoch 85/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.1081 - accuracy: 0.6549 - val_loss: 1.2383 - val_accuracy: 0.5550\n","Epoch 86/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.1063 - accuracy: 0.6514 - val_loss: 1.2345 - val_accuracy: 0.5603\n","Epoch 87/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0985 - accuracy: 0.6646 - val_loss: 1.2409 - val_accuracy: 0.5657\n","Epoch 88/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0937 - accuracy: 0.6603 - val_loss: 1.2330 - val_accuracy: 0.5582\n","Epoch 89/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0886 - accuracy: 0.6668 - val_loss: 1.2299 - val_accuracy: 0.5722\n","Epoch 90/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0826 - accuracy: 0.6584 - val_loss: 1.2352 - val_accuracy: 0.5700\n","Epoch 91/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0776 - accuracy: 0.6676 - val_loss: 1.2337 - val_accuracy: 0.5539\n","Epoch 92/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0727 - accuracy: 0.6641 - val_loss: 1.2309 - val_accuracy: 0.5550\n","Epoch 93/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0672 - accuracy: 0.6686 - val_loss: 1.2353 - val_accuracy: 0.5744\n","Epoch 94/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0609 - accuracy: 0.6713 - val_loss: 1.2246 - val_accuracy: 0.5668\n","Epoch 95/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0566 - accuracy: 0.6700 - val_loss: 1.2159 - val_accuracy: 0.5787\n","Epoch 96/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0535 - accuracy: 0.6719 - val_loss: 1.2207 - val_accuracy: 0.5560\n","Epoch 97/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0452 - accuracy: 0.6754 - val_loss: 1.2192 - val_accuracy: 0.5550\n","Epoch 98/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0413 - accuracy: 0.6730 - val_loss: 1.2240 - val_accuracy: 0.5539\n","Epoch 99/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0373 - accuracy: 0.6732 - val_loss: 1.2328 - val_accuracy: 0.5636\n","Epoch 100/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0331 - accuracy: 0.6802 - val_loss: 1.2196 - val_accuracy: 0.5539\n","{'loss': [1.77125883102417, 1.7596091032028198, 1.748339056968689, 1.737379550933838, 1.7264198064804077, 1.7156705856323242, 1.7050449848175049, 1.6947516202926636, 1.6843092441558838, 1.673946738243103, 1.663689374923706, 1.6536610126495361, 1.6436866521835327, 1.6337558031082153, 1.623932957649231, 1.6144788265228271, 1.6046812534332275, 1.5951530933380127, 1.585737705230713, 1.576433777809143, 1.567195177078247, 1.5580652952194214, 1.5489641427993774, 1.5398615598678589, 1.5309126377105713, 1.5223784446716309, 1.5135247707366943, 1.504938006401062, 1.4961796998977661, 1.487583875656128, 1.4788063764572144, 1.4702178239822388, 1.462049961090088, 1.4540413618087769, 1.4453749656677246, 1.4367955923080444, 1.4298794269561768, 1.4207727909088135, 1.4129087924957275, 1.4048599004745483, 1.3972676992416382, 1.3892890214920044, 1.3816678524017334, 1.3736003637313843, 1.3664588928222656, 1.3580210208892822, 1.3509739637374878, 1.3432163000106812, 1.335827350616455, 1.3281340599060059, 1.3209059238433838, 1.3144420385360718, 1.3063486814498901, 1.301833152770996, 1.2924383878707886, 1.285404920578003, 1.2783403396606445, 1.2731503248214722, 1.2659541368484497, 1.2608399391174316, 1.251505732536316, 1.2458404302597046, 1.2394369840621948, 1.2343875169754028, 1.2265980243682861, 1.2191963195800781, 1.2136934995651245, 1.2071585655212402, 1.2000869512557983, 1.196262001991272, 1.188620686531067, 1.1831661462783813, 1.1757291555404663, 1.1713124513626099, 1.1648039817810059, 1.1593270301818848, 1.1534502506256104, 1.1473815441131592, 1.1411705017089844, 1.138088345527649, 1.1322659254074097, 1.1249221563339233, 1.1205382347106934, 1.115911602973938, 1.1080727577209473, 1.106324315071106, 1.098536729812622, 1.0937050580978394, 1.0885659456253052, 1.0825728178024292, 1.077603816986084, 1.0727441310882568, 1.067203402519226, 1.0609105825424194, 1.056614875793457, 1.0535465478897095, 1.0451605319976807, 1.041327714920044, 1.0372614860534668, 1.0330522060394287], 'accuracy': [0.5018857717514038, 0.5037715435028076, 0.5037715435028076, 0.5150862336158752, 0.5145474076271057, 0.525053858757019, 0.5307112336158752, 0.5261314511299133, 0.5382543206214905, 0.5334051847457886, 0.5457974076271057, 0.5420258641242981, 0.5476831793785095, 0.5476831793785095, 0.553340494632721, 0.5511853694915771, 0.5536099076271057, 0.5546875, 0.5614224076271057, 0.5565732717514038, 0.5616918206214905, 0.5657327771186829, 0.5681573152542114, 0.5705819129943848, 0.5721982717514038, 0.5695043206214905, 0.5789331793785095, 0.568696141242981, 0.568696141242981, 0.576508641242981, 0.5840517282485962, 0.5810883641242981, 0.5848599076271057, 0.5870150923728943, 0.5870150923728943, 0.5918642282485962, 0.5880926847457886, 0.5934805870056152, 0.5878232717514038, 0.5945581793785095, 0.5983297228813171, 0.5985991358757019, 0.5969827771186829, 0.6053340435028076, 0.6037176847457886, 0.6021012663841248, 0.6037176847457886, 0.6072198152542114, 0.6096444129943848, 0.6139547228813171, 0.6153017282485962, 0.6174569129943848, 0.618534505367279, 0.6123383641242981, 0.6190732717514038, 0.6171875, 0.618534505367279, 0.615571141242981, 0.626347005367279, 0.6241918206214905, 0.6252694129943848, 0.6295797228813171, 0.623383641242981, 0.6255387663841248, 0.6346982717514038, 0.6330819129943848, 0.6328125, 0.634428858757019, 0.6338900923728943, 0.6322737336158752, 0.6433189511299133, 0.6435883641242981, 0.6457435488700867, 0.647090494632721, 0.6441271305084229, 0.6441271305084229, 0.6433189511299133, 0.6503232717514038, 0.646821141242981, 0.6524784564971924, 0.6554418206214905, 0.6522090435028076, 0.6462823152542114, 0.6487069129943848, 0.654902994632721, 0.6514008641242981, 0.6646012663841248, 0.6602909564971924, 0.6667564511299133, 0.6584051847457886, 0.6675646305084229, 0.6640625, 0.6686422228813171, 0.6713362336158752, 0.6699892282485962, 0.671875, 0.6753771305084229, 0.6729525923728943, 0.673222005367279, 0.6802262663841248], 'val_loss': [1.7663718461990356, 1.755629539489746, 1.7449895143508911, 1.734450340270996, 1.7240025997161865, 1.713669776916504, 1.703419804573059, 1.6931779384613037, 1.6831786632537842, 1.673231601715088, 1.663370966911316, 1.653741478919983, 1.6437851190567017, 1.6343222856521606, 1.6245867013931274, 1.6153372526168823, 1.60581374168396, 1.5967597961425781, 1.587424397468567, 1.5783123970031738, 1.5698399543762207, 1.5606610774993896, 1.5522116422653198, 1.543766975402832, 1.5351990461349487, 1.5268363952636719, 1.5198683738708496, 1.5125000476837158, 1.5034979581832886, 1.4965041875839233, 1.488886833190918, 1.4820821285247803, 1.4748958349227905, 1.4680380821228027, 1.462309718132019, 1.4523106813430786, 1.445910930633545, 1.4402118921279907, 1.4367259740829468, 1.4309498071670532, 1.4232429265975952, 1.4134620428085327, 1.4088159799575806, 1.4020434617996216, 1.396045207977295, 1.390232801437378, 1.3840264081954956, 1.3794076442718506, 1.3769118785858154, 1.3679628372192383, 1.3639260530471802, 1.3599035739898682, 1.3554459810256958, 1.349234700202942, 1.349223256111145, 1.3380321264266968, 1.3442245721817017, 1.338463306427002, 1.3250908851623535, 1.3176522254943848, 1.3193928003311157, 1.3147567510604858, 1.3129172325134277, 1.3113133907318115, 1.3046014308929443, 1.298691987991333, 1.293972373008728, 1.2890263795852661, 1.2878525257110596, 1.2796443700790405, 1.2842583656311035, 1.2768806219100952, 1.26995849609375, 1.2693477869033813, 1.2670166492462158, 1.261042594909668, 1.2615290880203247, 1.2614006996154785, 1.26133394241333, 1.2524549961090088, 1.2574836015701294, 1.2553508281707764, 1.2409193515777588, 1.2486754655838013, 1.2382876873016357, 1.234505534172058, 1.2408982515335083, 1.233046293258667, 1.2299338579177856, 1.2351515293121338, 1.2337417602539062, 1.230919361114502, 1.235304355621338, 1.2246185541152954, 1.2159343957901, 1.2206627130508423, 1.219204306602478, 1.2240016460418701, 1.2327637672424316, 1.2195537090301514], 'val_accuracy': [0.47521552443504333, 0.4698275923728943, 0.5398706793785095, 0.5668103694915771, 0.5581896305084229, 0.5506465435028076, 0.5463362336158752, 0.5581896305084229, 0.548491358757019, 0.5506465435028076, 0.5581896305084229, 0.5517241358757019, 0.5592672228813171, 0.5581896305084229, 0.5668103694915771, 0.5614224076271057, 0.5614224076271057, 0.5625, 0.5581896305084229, 0.5657327771186829, 0.5668103694915771, 0.5592672228813171, 0.5581896305084229, 0.5625, 0.5474137663841248, 0.5366379022598267, 0.5571120977401733, 0.5657327771186829, 0.5463362336158752, 0.5409482717514038, 0.5528017282485962, 0.5517241358757019, 0.5528017282485962, 0.5571120977401733, 0.5581896305084229, 0.556034505367279, 0.5592672228813171, 0.5581896305084229, 0.5635775923728943, 0.5571120977401733, 0.5678879022598267, 0.5592672228813171, 0.556034505367279, 0.5581896305084229, 0.5571120977401733, 0.5581896305084229, 0.5517241358757019, 0.5581896305084229, 0.5625, 0.5592672228813171, 0.5538793206214905, 0.5506465435028076, 0.5614224076271057, 0.5571120977401733, 0.5528017282485962, 0.5581896305084229, 0.5549569129943848, 0.5581896305084229, 0.548491358757019, 0.5646551847457886, 0.5668103694915771, 0.5506465435028076, 0.568965494632721, 0.5506465435028076, 0.5657327771186829, 0.5603448152542114, 0.5571120977401733, 0.5571120977401733, 0.5635775923728943, 0.568965494632721, 0.5625, 0.5538793206214905, 0.5635775923728943, 0.5517241358757019, 0.5711206793785095, 0.5743534564971924, 0.5592672228813171, 0.5635775923728943, 0.5678879022598267, 0.5571120977401733, 0.5711206793785095, 0.5743534564971924, 0.5538793206214905, 0.5700430870056152, 0.5549569129943848, 0.5603448152542114, 0.5657327771186829, 0.5581896305084229, 0.5721982717514038, 0.5700430870056152, 0.5538793206214905, 0.5549569129943848, 0.5743534564971924, 0.5668103694915771, 0.5786637663841248, 0.556034505367279, 0.5549569129943848, 0.5538793206214905, 0.5635775923728943, 0.5538793206214905]}\n","38/38 [==============================] - 0s 8ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 1.7715 - accuracy: 0.5048"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 6s 138ms/step - loss: 1.7715 - accuracy: 0.5048 - val_loss: 1.7667 - val_accuracy: 0.5283\n","Epoch 2/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.7599 - accuracy: 0.4983 - val_loss: 1.7564 - val_accuracy: 0.5419\n","Epoch 3/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.7488 - accuracy: 0.5153 - val_loss: 1.7461 - val_accuracy: 0.5294\n","Epoch 4/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.7379 - accuracy: 0.5190 - val_loss: 1.7359 - val_accuracy: 0.5238\n","Epoch 5/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.7274 - accuracy: 0.5184 - val_loss: 1.7257 - val_accuracy: 0.5260\n","Epoch 6/100\n","28/28 [==============================] - 0s 9ms/step - loss: 1.7168 - accuracy: 0.5357 - val_loss: 1.7157 - val_accuracy: 0.5238\n","Epoch 7/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.7062 - accuracy: 0.5354 - val_loss: 1.7058 - val_accuracy: 0.5283\n","Epoch 8/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6961 - accuracy: 0.5379 - val_loss: 1.6959 - val_accuracy: 0.5328\n","Epoch 9/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6858 - accuracy: 0.5422 - val_loss: 1.6862 - val_accuracy: 0.5351\n","Epoch 10/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6758 - accuracy: 0.5526 - val_loss: 1.6765 - val_accuracy: 0.5351\n","Epoch 11/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6658 - accuracy: 0.5515 - val_loss: 1.6669 - val_accuracy: 0.5328\n","Epoch 12/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6559 - accuracy: 0.5453 - val_loss: 1.6575 - val_accuracy: 0.5396\n","Epoch 13/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6461 - accuracy: 0.5515 - val_loss: 1.6481 - val_accuracy: 0.5328\n","Epoch 14/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6364 - accuracy: 0.5603 - val_loss: 1.6387 - val_accuracy: 0.5396\n","Epoch 15/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6269 - accuracy: 0.5478 - val_loss: 1.6296 - val_accuracy: 0.5385\n","Epoch 16/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6173 - accuracy: 0.5591 - val_loss: 1.6204 - val_accuracy: 0.5396\n","Epoch 17/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6080 - accuracy: 0.5549 - val_loss: 1.6113 - val_accuracy: 0.5407\n","Epoch 18/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5985 - accuracy: 0.5566 - val_loss: 1.6023 - val_accuracy: 0.5498\n","Epoch 19/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5892 - accuracy: 0.5634 - val_loss: 1.5935 - val_accuracy: 0.5464\n","Epoch 20/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.5799 - accuracy: 0.5580 - val_loss: 1.5848 - val_accuracy: 0.5498\n","Epoch 21/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5707 - accuracy: 0.5696 - val_loss: 1.5759 - val_accuracy: 0.5532\n","Epoch 22/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.5618 - accuracy: 0.5645 - val_loss: 1.5672 - val_accuracy: 0.5554\n","Epoch 23/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5525 - accuracy: 0.5656 - val_loss: 1.5591 - val_accuracy: 0.5554\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5437 - accuracy: 0.5645 - val_loss: 1.5505 - val_accuracy: 0.5520\n","Epoch 25/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5352 - accuracy: 0.5679 - val_loss: 1.5421 - val_accuracy: 0.5464\n","Epoch 26/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5266 - accuracy: 0.5679 - val_loss: 1.5338 - val_accuracy: 0.5532\n","Epoch 27/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.5181 - accuracy: 0.5699 - val_loss: 1.5267 - val_accuracy: 0.5611\n","Epoch 28/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5087 - accuracy: 0.5682 - val_loss: 1.5176 - val_accuracy: 0.5532\n","Epoch 29/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5005 - accuracy: 0.5693 - val_loss: 1.5103 - val_accuracy: 0.5577\n","Epoch 30/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4920 - accuracy: 0.5696 - val_loss: 1.5046 - val_accuracy: 0.5509\n","Epoch 31/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4835 - accuracy: 0.5770 - val_loss: 1.4950 - val_accuracy: 0.5633\n","Epoch 32/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4750 - accuracy: 0.5719 - val_loss: 1.4897 - val_accuracy: 0.5532\n","Epoch 33/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4673 - accuracy: 0.5784 - val_loss: 1.4809 - val_accuracy: 0.5566\n","Epoch 34/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.4596 - accuracy: 0.5739 - val_loss: 1.4753 - val_accuracy: 0.5532\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.4515 - accuracy: 0.5761 - val_loss: 1.4667 - val_accuracy: 0.5520\n","Epoch 36/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4431 - accuracy: 0.5804 - val_loss: 1.4595 - val_accuracy: 0.5532\n","Epoch 37/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4350 - accuracy: 0.5778 - val_loss: 1.4534 - val_accuracy: 0.5554\n","Epoch 38/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.4274 - accuracy: 0.5770 - val_loss: 1.4471 - val_accuracy: 0.5532\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.4197 - accuracy: 0.5846 - val_loss: 1.4415 - val_accuracy: 0.5509\n","Epoch 40/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4119 - accuracy: 0.5772 - val_loss: 1.4342 - val_accuracy: 0.5498\n","Epoch 41/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4045 - accuracy: 0.5917 - val_loss: 1.4282 - val_accuracy: 0.5520\n","Epoch 42/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3972 - accuracy: 0.5883 - val_loss: 1.4219 - val_accuracy: 0.5520\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3896 - accuracy: 0.5925 - val_loss: 1.4156 - val_accuracy: 0.5520\n","Epoch 44/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.3821 - accuracy: 0.5894 - val_loss: 1.4085 - val_accuracy: 0.5464\n","Epoch 45/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3751 - accuracy: 0.5886 - val_loss: 1.4039 - val_accuracy: 0.5543\n","Epoch 46/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3674 - accuracy: 0.5939 - val_loss: 1.3982 - val_accuracy: 0.5498\n","Epoch 47/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3612 - accuracy: 0.5942 - val_loss: 1.3941 - val_accuracy: 0.5520\n","Epoch 48/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3533 - accuracy: 0.5973 - val_loss: 1.3878 - val_accuracy: 0.5475\n","Epoch 49/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3457 - accuracy: 0.5973 - val_loss: 1.3848 - val_accuracy: 0.5543\n","Epoch 50/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3405 - accuracy: 0.5925 - val_loss: 1.3778 - val_accuracy: 0.5554\n","Epoch 51/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3323 - accuracy: 0.6019 - val_loss: 1.3694 - val_accuracy: 0.5633\n","Epoch 52/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3254 - accuracy: 0.6007 - val_loss: 1.3656 - val_accuracy: 0.5622\n","Epoch 53/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.3191 - accuracy: 0.6007 - val_loss: 1.3620 - val_accuracy: 0.5633\n","Epoch 54/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3119 - accuracy: 0.6055 - val_loss: 1.3607 - val_accuracy: 0.5667\n","Epoch 55/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3051 - accuracy: 0.6129 - val_loss: 1.3515 - val_accuracy: 0.5554\n","Epoch 56/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2988 - accuracy: 0.6098 - val_loss: 1.3466 - val_accuracy: 0.5600\n","Epoch 57/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2934 - accuracy: 0.6072 - val_loss: 1.3452 - val_accuracy: 0.5679\n","Epoch 58/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2862 - accuracy: 0.6146 - val_loss: 1.3371 - val_accuracy: 0.5588\n","Epoch 59/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2789 - accuracy: 0.6160 - val_loss: 1.3315 - val_accuracy: 0.5633\n","Epoch 60/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2722 - accuracy: 0.6188 - val_loss: 1.3277 - val_accuracy: 0.5543\n","Epoch 61/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2669 - accuracy: 0.6217 - val_loss: 1.3241 - val_accuracy: 0.5554\n","Epoch 62/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2594 - accuracy: 0.6152 - val_loss: 1.3191 - val_accuracy: 0.5588\n","Epoch 63/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2533 - accuracy: 0.6239 - val_loss: 1.3194 - val_accuracy: 0.5600\n","Epoch 64/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2479 - accuracy: 0.6180 - val_loss: 1.3129 - val_accuracy: 0.5554\n","Epoch 65/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2401 - accuracy: 0.6287 - val_loss: 1.3058 - val_accuracy: 0.5633\n","Epoch 66/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2352 - accuracy: 0.6248 - val_loss: 1.3051 - val_accuracy: 0.5588\n","Epoch 67/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2294 - accuracy: 0.6262 - val_loss: 1.2989 - val_accuracy: 0.5622\n","Epoch 68/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2234 - accuracy: 0.6248 - val_loss: 1.2967 - val_accuracy: 0.5645\n","Epoch 69/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2163 - accuracy: 0.6341 - val_loss: 1.2924 - val_accuracy: 0.5520\n","Epoch 70/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2103 - accuracy: 0.6358 - val_loss: 1.2874 - val_accuracy: 0.5645\n","Epoch 71/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2040 - accuracy: 0.6330 - val_loss: 1.2853 - val_accuracy: 0.5600\n","Epoch 72/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1979 - accuracy: 0.6395 - val_loss: 1.2818 - val_accuracy: 0.5554\n","Epoch 73/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1925 - accuracy: 0.6355 - val_loss: 1.2792 - val_accuracy: 0.5622\n","Epoch 74/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1873 - accuracy: 0.6313 - val_loss: 1.2801 - val_accuracy: 0.5554\n","Epoch 75/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1819 - accuracy: 0.6271 - val_loss: 1.2754 - val_accuracy: 0.5498\n","Epoch 76/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1751 - accuracy: 0.6423 - val_loss: 1.2711 - val_accuracy: 0.5645\n","Epoch 77/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1695 - accuracy: 0.6375 - val_loss: 1.2685 - val_accuracy: 0.5656\n","Epoch 78/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.1643 - accuracy: 0.6423 - val_loss: 1.2657 - val_accuracy: 0.5724\n","Epoch 79/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1595 - accuracy: 0.6404 - val_loss: 1.2629 - val_accuracy: 0.5701\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1523 - accuracy: 0.6491 - val_loss: 1.2577 - val_accuracy: 0.5645\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1476 - accuracy: 0.6426 - val_loss: 1.2587 - val_accuracy: 0.5600\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1424 - accuracy: 0.6488 - val_loss: 1.2550 - val_accuracy: 0.5566\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1364 - accuracy: 0.6508 - val_loss: 1.2527 - val_accuracy: 0.5633\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1319 - accuracy: 0.6483 - val_loss: 1.2498 - val_accuracy: 0.5645\n","Epoch 85/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1253 - accuracy: 0.6497 - val_loss: 1.2458 - val_accuracy: 0.5622\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1202 - accuracy: 0.6483 - val_loss: 1.2448 - val_accuracy: 0.5543\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1147 - accuracy: 0.6556 - val_loss: 1.2424 - val_accuracy: 0.5645\n","Epoch 88/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1089 - accuracy: 0.6551 - val_loss: 1.2420 - val_accuracy: 0.5622\n","Epoch 89/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1048 - accuracy: 0.6551 - val_loss: 1.2378 - val_accuracy: 0.5554\n","Epoch 90/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0992 - accuracy: 0.6653 - val_loss: 1.2326 - val_accuracy: 0.5611\n","Epoch 91/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0936 - accuracy: 0.6655 - val_loss: 1.2403 - val_accuracy: 0.5588\n","Epoch 92/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0903 - accuracy: 0.6619 - val_loss: 1.2341 - val_accuracy: 0.5679\n","Epoch 93/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0832 - accuracy: 0.6616 - val_loss: 1.2364 - val_accuracy: 0.5566\n","Epoch 94/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0777 - accuracy: 0.6695 - val_loss: 1.2234 - val_accuracy: 0.5656\n","Epoch 95/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0736 - accuracy: 0.6616 - val_loss: 1.2270 - val_accuracy: 0.5611\n","Epoch 96/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0693 - accuracy: 0.6709 - val_loss: 1.2291 - val_accuracy: 0.5543\n","Epoch 97/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0629 - accuracy: 0.6729 - val_loss: 1.2223 - val_accuracy: 0.5532\n","Epoch 98/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0607 - accuracy: 0.6686 - val_loss: 1.2265 - val_accuracy: 0.5611\n","Epoch 99/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0529 - accuracy: 0.6760 - val_loss: 1.2205 - val_accuracy: 0.5475\n","Epoch 100/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0489 - accuracy: 0.6749 - val_loss: 1.2226 - val_accuracy: 0.5645\n","{'loss': [1.7714922428131104, 1.7599406242370605, 1.7488163709640503, 1.737923264503479, 1.7273646593093872, 1.716752052307129, 1.7062373161315918, 1.6960885524749756, 1.6857587099075317, 1.6757551431655884, 1.665811538696289, 1.6558605432510376, 1.64605712890625, 1.6363929510116577, 1.6268882751464844, 1.6172841787338257, 1.6079881191253662, 1.5985219478607178, 1.5891807079315186, 1.5799304246902466, 1.5707292556762695, 1.5618082284927368, 1.552549123764038, 1.5437071323394775, 1.535203456878662, 1.5266318321228027, 1.5180881023406982, 1.5087037086486816, 1.5005168914794922, 1.4920250177383423, 1.4834651947021484, 1.474976658821106, 1.467309594154358, 1.4596412181854248, 1.4515246152877808, 1.4431027173995972, 1.4350091218948364, 1.427409291267395, 1.4197145700454712, 1.4118810892105103, 1.4045140743255615, 1.3971730470657349, 1.3896255493164062, 1.3821183443069458, 1.3750718832015991, 1.367384910583496, 1.3611814975738525, 1.3533157110214233, 1.3457190990447998, 1.340512752532959, 1.332262396812439, 1.3253884315490723, 1.31905996799469, 1.3118892908096313, 1.3051271438598633, 1.2988321781158447, 1.2933807373046875, 1.2862428426742554, 1.2788748741149902, 1.2722008228302002, 1.2668871879577637, 1.259429693222046, 1.2532762289047241, 1.2479194402694702, 1.2400939464569092, 1.2352018356323242, 1.2294338941574097, 1.2233774662017822, 1.2162628173828125, 1.2103040218353271, 1.2039920091629028, 1.1979042291641235, 1.1924920082092285, 1.1872904300689697, 1.1819015741348267, 1.1751171350479126, 1.1695291996002197, 1.1642597913742065, 1.1595251560211182, 1.1522928476333618, 1.147605299949646, 1.142393708229065, 1.1364153623580933, 1.1318747997283936, 1.1253434419631958, 1.120230793952942, 1.1147136688232422, 1.1088663339614868, 1.104836106300354, 1.099207878112793, 1.09355628490448, 1.0903252363204956, 1.0831559896469116, 1.0777369737625122, 1.0736117362976074, 1.06930673122406, 1.0629156827926636, 1.0607266426086426, 1.052884817123413, 1.0488709211349487], 'accuracy': [0.5048103928565979, 0.4983022212982178, 0.5152801275253296, 0.5189586877822876, 0.5183927416801453, 0.5356536507606506, 0.5353707075119019, 0.5379173755645752, 0.5421618819236755, 0.5526315569877625, 0.5514997243881226, 0.5452744960784912, 0.5514997243881226, 0.5602716207504272, 0.5478211641311646, 0.5591397881507874, 0.554895281791687, 0.556593120098114, 0.5633842945098877, 0.5580078959465027, 0.569609522819519, 0.5645161271095276, 0.5656480193138123, 0.5645161271095276, 0.5679117441177368, 0.5679117441177368, 0.5698924660682678, 0.5681946873664856, 0.5693265199661255, 0.569609522819519, 0.5769665837287903, 0.5718732476234436, 0.5783814191818237, 0.5738539695739746, 0.5761176943778992, 0.5803622007369995, 0.5778155326843262, 0.5769665837287903, 0.5846067070960999, 0.5772495865821838, 0.5916808247566223, 0.5882852077484131, 0.5925297141075134, 0.5894170999526978, 0.5885682106018066, 0.5939445495605469, 0.5942274928092957, 0.5973401069641113, 0.5973401069641113, 0.5925297141075134, 0.6018675565719604, 0.6007357239723206, 0.6007357239723206, 0.6055461168289185, 0.6129032373428345, 0.6097906231880188, 0.6072438955307007, 0.6146010160446167, 0.6160158514976501, 0.618845522403717, 0.6216751337051392, 0.615166962146759, 0.6239388585090637, 0.6179966330528259, 0.6287493109703064, 0.6247877478599548, 0.6262025833129883, 0.6247877478599548, 0.6341256499290466, 0.6358234286308289, 0.632993757724762, 0.6395019888877869, 0.6355404853820801, 0.6312959790229797, 0.6270514726638794, 0.6423316597938538, 0.6375212073326111, 0.6423316597938538, 0.640350878238678, 0.6491228342056274, 0.6426146030426025, 0.6488398313522339, 0.6508206129074097, 0.6482738852500916, 0.649688720703125, 0.6482738852500916, 0.6556310057640076, 0.6550650596618652, 0.6550650596618652, 0.6652518510818481, 0.6655347943305969, 0.6618562340736389, 0.6615732908248901, 0.6694962978363037, 0.6615732908248901, 0.6709111332893372, 0.6728919148445129, 0.6686474084854126, 0.6760045289993286, 0.674872636795044], 'val_loss': [1.766745686531067, 1.7563824653625488, 1.7460840940475464, 1.7358673810958862, 1.7257457971572876, 1.7157307863235474, 1.7057836055755615, 1.695936918258667, 1.686188817024231, 1.6765244007110596, 1.6669394969940186, 1.657523274421692, 1.6480817794799805, 1.638735294342041, 1.6296201944351196, 1.6203986406326294, 1.6113405227661133, 1.6023420095443726, 1.5934656858444214, 1.5848150253295898, 1.5759333372116089, 1.567244529724121, 1.5591367483139038, 1.550491213798523, 1.542140245437622, 1.5338032245635986, 1.526685118675232, 1.5176337957382202, 1.5102806091308594, 1.5046195983886719, 1.4950034618377686, 1.4896656274795532, 1.4808986186981201, 1.4753198623657227, 1.466735601425171, 1.4594918489456177, 1.4534000158309937, 1.447091817855835, 1.4414621591567993, 1.4342492818832397, 1.428242802619934, 1.4218740463256836, 1.4156368970870972, 1.4084676504135132, 1.4039334058761597, 1.398173451423645, 1.3941075801849365, 1.3878233432769775, 1.3847997188568115, 1.3778189420700073, 1.3693681955337524, 1.3656307458877563, 1.3619928359985352, 1.3606629371643066, 1.3514537811279297, 1.346577525138855, 1.3452160358428955, 1.3370873928070068, 1.331539273262024, 1.3276755809783936, 1.3241149187088013, 1.319117784500122, 1.3193954229354858, 1.3128598928451538, 1.3057688474655151, 1.3050578832626343, 1.298903226852417, 1.2966707944869995, 1.2924472093582153, 1.287372350692749, 1.285317301750183, 1.2818055152893066, 1.2791622877120972, 1.2801355123519897, 1.2754273414611816, 1.2710955142974854, 1.2685309648513794, 1.2656574249267578, 1.2629474401474, 1.257696509361267, 1.2586688995361328, 1.2550100088119507, 1.252662181854248, 1.2498472929000854, 1.245815396308899, 1.2447704076766968, 1.2423741817474365, 1.2419836521148682, 1.2377760410308838, 1.2326186895370483, 1.2402641773223877, 1.234062671661377, 1.2363861799240112, 1.223366141319275, 1.2270267009735107, 1.2291266918182373, 1.2222753763198853, 1.2264585494995117, 1.220547080039978, 1.2226287126541138], 'val_accuracy': [0.5282805562019348, 0.5418552160263062, 0.529411792755127, 0.523755669593811, 0.5260180830955505, 0.523755669593811, 0.5282805562019348, 0.5328054428100586, 0.5350678563117981, 0.5350678563117981, 0.5328054428100586, 0.5395927429199219, 0.5328054428100586, 0.5395927429199219, 0.5384615659713745, 0.5395927429199219, 0.540723979473114, 0.5497737526893616, 0.5463801026344299, 0.5497737526893616, 0.5531674027442932, 0.5554298758506775, 0.5554298758506775, 0.5520362257957458, 0.5463801026344299, 0.5531674027442932, 0.5610859990119934, 0.5531674027442932, 0.557692289352417, 0.5509049892425537, 0.5633484125137329, 0.5531674027442932, 0.5565611124038696, 0.5531674027442932, 0.5520362257957458, 0.5531674027442932, 0.5554298758506775, 0.5531674027442932, 0.5509049892425537, 0.5497737526893616, 0.5520362257957458, 0.5520362257957458, 0.5520362257957458, 0.5463801026344299, 0.5542986392974854, 0.5497737526893616, 0.5520362257957458, 0.5475113391876221, 0.5542986392974854, 0.5554298758506775, 0.5633484125137329, 0.5622171759605408, 0.5633484125137329, 0.5667420625686646, 0.5554298758506775, 0.5599547624588013, 0.5678732991218567, 0.5588235259056091, 0.5633484125137329, 0.5542986392974854, 0.5554298758506775, 0.5588235259056091, 0.5599547624588013, 0.5554298758506775, 0.5633484125137329, 0.5588235259056091, 0.5622171759605408, 0.564479649066925, 0.5520362257957458, 0.564479649066925, 0.5599547624588013, 0.5554298758506775, 0.5622171759605408, 0.5554298758506775, 0.5497737526893616, 0.564479649066925, 0.5656108856201172, 0.5723981857299805, 0.570135772228241, 0.564479649066925, 0.5599547624588013, 0.5565611124038696, 0.5633484125137329, 0.564479649066925, 0.5622171759605408, 0.5542986392974854, 0.564479649066925, 0.5622171759605408, 0.5554298758506775, 0.5610859990119934, 0.5588235259056091, 0.5678732991218567, 0.5565611124038696, 0.5656108856201172, 0.5610859990119934, 0.5542986392974854, 0.5531674027442932, 0.5610859990119934, 0.5475113391876221, 0.564479649066925]}\n","45/45 [==============================] - 0s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 1.7704 - accuracy: 0.5044"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 6s 124ms/step - loss: 1.7704 - accuracy: 0.5044 - val_loss: 1.7658 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.7573 - accuracy: 0.5145 - val_loss: 1.7543 - val_accuracy: 0.5145\n","Epoch 3/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.7452 - accuracy: 0.5129 - val_loss: 1.7429 - val_accuracy: 0.5258\n","Epoch 4/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.7331 - accuracy: 0.5326 - val_loss: 1.7317 - val_accuracy: 0.5310\n","Epoch 5/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.7214 - accuracy: 0.5253 - val_loss: 1.7206 - val_accuracy: 0.5289\n","Epoch 6/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.7099 - accuracy: 0.5323 - val_loss: 1.7097 - val_accuracy: 0.5320\n","Epoch 7/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.6986 - accuracy: 0.5419 - val_loss: 1.6989 - val_accuracy: 0.5320\n","Epoch 8/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.6875 - accuracy: 0.5457 - val_loss: 1.6882 - val_accuracy: 0.5269\n","Epoch 9/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.6764 - accuracy: 0.5457 - val_loss: 1.6776 - val_accuracy: 0.5300\n","Epoch 10/100\n","31/31 [==============================] - 0s 9ms/step - loss: 1.6654 - accuracy: 0.5447 - val_loss: 1.6672 - val_accuracy: 0.5279\n","Epoch 11/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.6547 - accuracy: 0.5532 - val_loss: 1.6569 - val_accuracy: 0.5269\n","Epoch 12/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.6441 - accuracy: 0.5537 - val_loss: 1.6466 - val_accuracy: 0.5279\n","Epoch 13/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.6333 - accuracy: 0.5558 - val_loss: 1.6365 - val_accuracy: 0.5279\n","Epoch 14/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.6229 - accuracy: 0.5525 - val_loss: 1.6266 - val_accuracy: 0.5300\n","Epoch 15/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.6125 - accuracy: 0.5532 - val_loss: 1.6168 - val_accuracy: 0.5310\n","Epoch 16/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.6023 - accuracy: 0.5576 - val_loss: 1.6070 - val_accuracy: 0.5289\n","Epoch 17/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.5923 - accuracy: 0.5561 - val_loss: 1.5976 - val_accuracy: 0.5289\n","Epoch 18/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.5822 - accuracy: 0.5610 - val_loss: 1.5883 - val_accuracy: 0.5320\n","Epoch 19/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.5721 - accuracy: 0.5623 - val_loss: 1.5790 - val_accuracy: 0.5279\n","Epoch 20/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5622 - accuracy: 0.5646 - val_loss: 1.5705 - val_accuracy: 0.5382\n","Epoch 21/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.5529 - accuracy: 0.5651 - val_loss: 1.5607 - val_accuracy: 0.5165\n","Epoch 22/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.5439 - accuracy: 0.5721 - val_loss: 1.5530 - val_accuracy: 0.5403\n","Epoch 23/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.5336 - accuracy: 0.5713 - val_loss: 1.5446 - val_accuracy: 0.5393\n","Epoch 24/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.5246 - accuracy: 0.5649 - val_loss: 1.5377 - val_accuracy: 0.5310\n","Epoch 25/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.5154 - accuracy: 0.5649 - val_loss: 1.5281 - val_accuracy: 0.5403\n","Epoch 26/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.5058 - accuracy: 0.5700 - val_loss: 1.5211 - val_accuracy: 0.5362\n","Epoch 27/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4972 - accuracy: 0.5726 - val_loss: 1.5123 - val_accuracy: 0.5434\n","Epoch 28/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.4884 - accuracy: 0.5729 - val_loss: 1.5051 - val_accuracy: 0.5413\n","Epoch 29/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.4794 - accuracy: 0.5703 - val_loss: 1.4995 - val_accuracy: 0.5320\n","Epoch 30/100\n","31/31 [==============================] - 0s 9ms/step - loss: 1.4705 - accuracy: 0.5729 - val_loss: 1.4884 - val_accuracy: 0.5382\n","Epoch 31/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.4624 - accuracy: 0.5778 - val_loss: 1.4813 - val_accuracy: 0.5382\n","Epoch 32/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.4533 - accuracy: 0.5767 - val_loss: 1.4752 - val_accuracy: 0.5341\n","Epoch 33/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.4446 - accuracy: 0.5773 - val_loss: 1.4669 - val_accuracy: 0.5351\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.4368 - accuracy: 0.5770 - val_loss: 1.4593 - val_accuracy: 0.5341\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4279 - accuracy: 0.5837 - val_loss: 1.4571 - val_accuracy: 0.5351\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.4202 - accuracy: 0.5796 - val_loss: 1.4484 - val_accuracy: 0.5227\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.4121 - accuracy: 0.5822 - val_loss: 1.4397 - val_accuracy: 0.5248\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4040 - accuracy: 0.5855 - val_loss: 1.4352 - val_accuracy: 0.5279\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3963 - accuracy: 0.5796 - val_loss: 1.4261 - val_accuracy: 0.5269\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3881 - accuracy: 0.5824 - val_loss: 1.4195 - val_accuracy: 0.5279\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3803 - accuracy: 0.5855 - val_loss: 1.4177 - val_accuracy: 0.5269\n","Epoch 42/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3726 - accuracy: 0.5873 - val_loss: 1.4078 - val_accuracy: 0.5258\n","Epoch 43/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.3648 - accuracy: 0.5876 - val_loss: 1.4004 - val_accuracy: 0.5248\n","Epoch 44/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.3570 - accuracy: 0.5915 - val_loss: 1.3977 - val_accuracy: 0.5258\n","Epoch 45/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.3496 - accuracy: 0.5959 - val_loss: 1.3898 - val_accuracy: 0.5238\n","Epoch 46/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.3420 - accuracy: 0.5966 - val_loss: 1.3838 - val_accuracy: 0.5207\n","Epoch 47/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3345 - accuracy: 0.5984 - val_loss: 1.3763 - val_accuracy: 0.5176\n","Epoch 48/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.3270 - accuracy: 0.6044 - val_loss: 1.3729 - val_accuracy: 0.5217\n","Epoch 49/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.3200 - accuracy: 0.6034 - val_loss: 1.3651 - val_accuracy: 0.5155\n","Epoch 50/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.3124 - accuracy: 0.6031 - val_loss: 1.3637 - val_accuracy: 0.5227\n","Epoch 51/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.3054 - accuracy: 0.6057 - val_loss: 1.3566 - val_accuracy: 0.5165\n","Epoch 52/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2982 - accuracy: 0.6054 - val_loss: 1.3464 - val_accuracy: 0.5248\n","Epoch 53/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2926 - accuracy: 0.6039 - val_loss: 1.3410 - val_accuracy: 0.5310\n","Epoch 54/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2847 - accuracy: 0.6101 - val_loss: 1.3370 - val_accuracy: 0.5196\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2776 - accuracy: 0.6098 - val_loss: 1.3331 - val_accuracy: 0.5186\n","Epoch 56/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2701 - accuracy: 0.6116 - val_loss: 1.3305 - val_accuracy: 0.5196\n","Epoch 57/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2640 - accuracy: 0.6059 - val_loss: 1.3203 - val_accuracy: 0.5258\n","Epoch 58/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2568 - accuracy: 0.6145 - val_loss: 1.3193 - val_accuracy: 0.5238\n","Epoch 59/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2497 - accuracy: 0.6140 - val_loss: 1.3141 - val_accuracy: 0.5217\n","Epoch 60/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2441 - accuracy: 0.6121 - val_loss: 1.3103 - val_accuracy: 0.5186\n","Epoch 61/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2364 - accuracy: 0.6181 - val_loss: 1.3024 - val_accuracy: 0.5269\n","Epoch 62/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2300 - accuracy: 0.6150 - val_loss: 1.2957 - val_accuracy: 0.5269\n","Epoch 63/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2241 - accuracy: 0.6158 - val_loss: 1.3006 - val_accuracy: 0.5279\n","Epoch 64/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2168 - accuracy: 0.6207 - val_loss: 1.2883 - val_accuracy: 0.5310\n","Epoch 65/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2108 - accuracy: 0.6238 - val_loss: 1.2864 - val_accuracy: 0.5289\n","Epoch 66/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2058 - accuracy: 0.6225 - val_loss: 1.2833 - val_accuracy: 0.5279\n","Epoch 67/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1977 - accuracy: 0.6251 - val_loss: 1.2833 - val_accuracy: 0.5269\n","Epoch 68/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1916 - accuracy: 0.6258 - val_loss: 1.2874 - val_accuracy: 0.5248\n","Epoch 69/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1857 - accuracy: 0.6173 - val_loss: 1.2748 - val_accuracy: 0.5258\n","Epoch 70/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1790 - accuracy: 0.6251 - val_loss: 1.2662 - val_accuracy: 0.5320\n","Epoch 71/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1736 - accuracy: 0.6302 - val_loss: 1.2601 - val_accuracy: 0.5300\n","Epoch 72/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1679 - accuracy: 0.6295 - val_loss: 1.2625 - val_accuracy: 0.5341\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1613 - accuracy: 0.6328 - val_loss: 1.2536 - val_accuracy: 0.5310\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1555 - accuracy: 0.6282 - val_loss: 1.2502 - val_accuracy: 0.5320\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1505 - accuracy: 0.6362 - val_loss: 1.2424 - val_accuracy: 0.5320\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1440 - accuracy: 0.6302 - val_loss: 1.2485 - val_accuracy: 0.5341\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1376 - accuracy: 0.6362 - val_loss: 1.2407 - val_accuracy: 0.5310\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1329 - accuracy: 0.6351 - val_loss: 1.2390 - val_accuracy: 0.5362\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1268 - accuracy: 0.6370 - val_loss: 1.2343 - val_accuracy: 0.5269\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1204 - accuracy: 0.6395 - val_loss: 1.2368 - val_accuracy: 0.5372\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1157 - accuracy: 0.6421 - val_loss: 1.2396 - val_accuracy: 0.5434\n","Epoch 82/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1102 - accuracy: 0.6437 - val_loss: 1.2229 - val_accuracy: 0.5331\n","Epoch 83/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1042 - accuracy: 0.6468 - val_loss: 1.2176 - val_accuracy: 0.5413\n","Epoch 84/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0989 - accuracy: 0.6488 - val_loss: 1.2261 - val_accuracy: 0.5362\n","Epoch 85/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0949 - accuracy: 0.6419 - val_loss: 1.2280 - val_accuracy: 0.5351\n","Epoch 86/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0873 - accuracy: 0.6478 - val_loss: 1.2127 - val_accuracy: 0.5372\n","Epoch 87/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0837 - accuracy: 0.6463 - val_loss: 1.2060 - val_accuracy: 0.5382\n","Epoch 88/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0797 - accuracy: 0.6494 - val_loss: 1.2115 - val_accuracy: 0.5331\n","Epoch 89/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0731 - accuracy: 0.6519 - val_loss: 1.1993 - val_accuracy: 0.5331\n","Epoch 90/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0673 - accuracy: 0.6481 - val_loss: 1.2070 - val_accuracy: 0.5331\n","Epoch 91/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0632 - accuracy: 0.6553 - val_loss: 1.1907 - val_accuracy: 0.5217\n","Epoch 92/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0597 - accuracy: 0.6525 - val_loss: 1.2145 - val_accuracy: 0.5372\n","Epoch 93/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0540 - accuracy: 0.6499 - val_loss: 1.1860 - val_accuracy: 0.5300\n","Epoch 94/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0477 - accuracy: 0.6519 - val_loss: 1.1846 - val_accuracy: 0.5351\n","Epoch 95/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0418 - accuracy: 0.6587 - val_loss: 1.1853 - val_accuracy: 0.5320\n","Epoch 96/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0390 - accuracy: 0.6618 - val_loss: 1.1917 - val_accuracy: 0.5351\n","Epoch 97/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0326 - accuracy: 0.6610 - val_loss: 1.2034 - val_accuracy: 0.5300\n","Epoch 98/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0303 - accuracy: 0.6628 - val_loss: 1.1773 - val_accuracy: 0.5362\n","Epoch 99/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0269 - accuracy: 0.6584 - val_loss: 1.1776 - val_accuracy: 0.5341\n","Epoch 100/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0190 - accuracy: 0.6667 - val_loss: 1.1822 - val_accuracy: 0.5372\n","{'loss': [1.7704342603683472, 1.7572932243347168, 1.7451856136322021, 1.7330634593963623, 1.7214000225067139, 1.7099250555038452, 1.6985666751861572, 1.6874648332595825, 1.676410436630249, 1.6654497385025024, 1.6546727418899536, 1.6440768241882324, 1.6333200931549072, 1.6229243278503418, 1.6125338077545166, 1.602319359779358, 1.5922695398330688, 1.5822020769119263, 1.5721032619476318, 1.5621956586837769, 1.5528515577316284, 1.543917179107666, 1.533628225326538, 1.5246158838272095, 1.515430212020874, 1.505810022354126, 1.4972476959228516, 1.4884172677993774, 1.4793747663497925, 1.470471739768982, 1.462384581565857, 1.4532697200775146, 1.4445970058441162, 1.43684983253479, 1.4279173612594604, 1.420194387435913, 1.4120762348175049, 1.4039580821990967, 1.3963072299957275, 1.388100504875183, 1.380280613899231, 1.3725950717926025, 1.3648031949996948, 1.3569979667663574, 1.34962797164917, 1.34196138381958, 1.3344813585281372, 1.3270429372787476, 1.3200395107269287, 1.3124256134033203, 1.3053925037384033, 1.2982308864593506, 1.2926485538482666, 1.2846723794937134, 1.2775968313217163, 1.2701263427734375, 1.2639927864074707, 1.256828784942627, 1.2497446537017822, 1.244088888168335, 1.23638117313385, 1.2299799919128418, 1.2241052389144897, 1.2168079614639282, 1.2108469009399414, 1.2058260440826416, 1.1977359056472778, 1.191641926765442, 1.1857410669326782, 1.179032325744629, 1.1735851764678955, 1.1679463386535645, 1.1613011360168457, 1.155530333518982, 1.1505091190338135, 1.143964171409607, 1.1375856399536133, 1.1329323053359985, 1.1268062591552734, 1.1203867197036743, 1.1157432794570923, 1.1101605892181396, 1.1041667461395264, 1.0989151000976562, 1.0948922634124756, 1.0872931480407715, 1.083735466003418, 1.0796703100204468, 1.0731202363967896, 1.0673103332519531, 1.0631815195083618, 1.0597440004348755, 1.0540087223052979, 1.0477242469787598, 1.0418230295181274, 1.0389683246612549, 1.0326474905014038, 1.0302664041519165, 1.0268888473510742, 1.0190155506134033], 'accuracy': [0.5043927431106567, 0.5144702792167664, 0.5129199028015137, 0.5325581431388855, 0.5253229737281799, 0.5322997570037842, 0.5418604612350464, 0.5457364320755005, 0.5457364320755005, 0.5447028279304504, 0.5532299876213074, 0.55374675989151, 0.5558139681816101, 0.5524547696113586, 0.5532299876213074, 0.5576227307319641, 0.5560723543167114, 0.5609819293022156, 0.5622739195823669, 0.5645994544029236, 0.565116286277771, 0.5720930099487305, 0.5713178515434265, 0.5648579001426697, 0.5648579001426697, 0.5700258612632751, 0.5726098418235779, 0.5728682279586792, 0.5702842473983765, 0.5728682279586792, 0.5777778029441833, 0.5767441987991333, 0.5772609710693359, 0.5770025849342346, 0.5837209224700928, 0.5795865654945374, 0.5821705460548401, 0.5855297446250916, 0.5795865654945374, 0.5824289321899414, 0.5855297446250916, 0.5873385071754456, 0.5875968933105469, 0.591472864151001, 0.5958656072616577, 0.5966408252716064, 0.5984495878219604, 0.6043927669525146, 0.6033591628074646, 0.6031007766723633, 0.605684757232666, 0.6054263710975647, 0.603875994682312, 0.6100775003433228, 0.6098191142082214, 0.6116279363632202, 0.6059431433677673, 0.6144703030586243, 0.6139534711837769, 0.6121447086334229, 0.6180878281593323, 0.6149870753288269, 0.6157622933387756, 0.620671808719635, 0.6237726211547852, 0.6224806308746338, 0.6250646114349365, 0.6258397698402405, 0.6173126697540283, 0.6250646114349365, 0.630232572555542, 0.6294573545455933, 0.6328165531158447, 0.6281653642654419, 0.6361756920814514, 0.630232572555542, 0.6361756920814514, 0.6351421475410461, 0.6369509100914001, 0.6395348906517029, 0.6421188712120056, 0.6436692476272583, 0.6467700004577637, 0.6488372087478638, 0.6418604850769043, 0.6478036046028137, 0.646253228187561, 0.6493539810180664, 0.6519379615783691, 0.648061990737915, 0.6552971601486206, 0.6524547934532166, 0.6498708128929138, 0.6519379615783691, 0.6586563587188721, 0.6617571115493774, 0.6609818935394287, 0.6627907156944275, 0.658397912979126, 0.6666666865348816], 'val_loss': [1.7657504081726074, 1.7542636394500732, 1.7428994178771973, 1.731666922569275, 1.7206112146377563, 1.7096912860870361, 1.6988896131515503, 1.688216209411621, 1.6776323318481445, 1.667161226272583, 1.656850814819336, 1.6466435194015503, 1.6365413665771484, 1.6265848875045776, 1.6167539358139038, 1.6070213317871094, 1.5976232290267944, 1.588291883468628, 1.5790417194366455, 1.5704872608184814, 1.5607167482376099, 1.553014874458313, 1.5446254014968872, 1.5377280712127686, 1.528127670288086, 1.5211207866668701, 1.512329339981079, 1.505085825920105, 1.4994527101516724, 1.4884259700775146, 1.4813430309295654, 1.4751622676849365, 1.466934084892273, 1.4592851400375366, 1.4570707082748413, 1.448434829711914, 1.4396666288375854, 1.4352349042892456, 1.4260644912719727, 1.4195244312286377, 1.4177128076553345, 1.4078203439712524, 1.400367021560669, 1.3976728916168213, 1.3898189067840576, 1.3838013410568237, 1.37626314163208, 1.3729007244110107, 1.3651269674301147, 1.3637237548828125, 1.356605887413025, 1.34635329246521, 1.3410224914550781, 1.3369613885879517, 1.3331435918807983, 1.3305078744888306, 1.3203474283218384, 1.3192505836486816, 1.3140685558319092, 1.310295820236206, 1.302350640296936, 1.2957391738891602, 1.3006058931350708, 1.288286805152893, 1.286433219909668, 1.2833424806594849, 1.2833298444747925, 1.28738534450531, 1.2747540473937988, 1.2662379741668701, 1.2601159811019897, 1.2624797821044922, 1.253646731376648, 1.2501682043075562, 1.2423757314682007, 1.248523473739624, 1.240689754486084, 1.2389967441558838, 1.2342658042907715, 1.2368119955062866, 1.239569902420044, 1.2228909730911255, 1.2176381349563599, 1.22610342502594, 1.227960228919983, 1.212705135345459, 1.20600426197052, 1.2114524841308594, 1.1992956399917603, 1.2069640159606934, 1.1906510591506958, 1.2145347595214844, 1.1860474348068237, 1.1846339702606201, 1.1853156089782715, 1.1916731595993042, 1.2033618688583374, 1.1773121356964111, 1.17763090133667, 1.1821929216384888], 'val_accuracy': [0.48553720116615295, 0.5144628286361694, 0.5258264541625977, 0.5309917330741882, 0.5289255976676941, 0.5320248007774353, 0.5320248007774353, 0.5268595218658447, 0.5299586653709412, 0.5278925895690918, 0.5268595218658447, 0.5278925895690918, 0.5278925895690918, 0.5299586653709412, 0.5309917330741882, 0.5289255976676941, 0.5289255976676941, 0.5320248007774353, 0.5278925895690918, 0.538223147392273, 0.5165289044380188, 0.5402892827987671, 0.53925621509552, 0.5309917330741882, 0.5402892827987671, 0.5361570119857788, 0.5433884263038635, 0.5413222908973694, 0.5320248007774353, 0.538223147392273, 0.538223147392273, 0.5340909361839294, 0.5351239442825317, 0.5340909361839294, 0.5351239442825317, 0.5227272510528564, 0.5247933864593506, 0.5278925895690918, 0.5268595218658447, 0.5278925895690918, 0.5268595218658447, 0.5258264541625977, 0.5247933864593506, 0.5258264541625977, 0.5237603187561035, 0.5206611752510071, 0.5175619721412659, 0.5216942429542542, 0.5154958963394165, 0.5227272510528564, 0.5165289044380188, 0.5247933864593506, 0.5309917330741882, 0.51962810754776, 0.5185950398445129, 0.51962810754776, 0.5258264541625977, 0.5237603187561035, 0.5216942429542542, 0.5185950398445129, 0.5268595218658447, 0.5268595218658447, 0.5278925895690918, 0.5309917330741882, 0.5289255976676941, 0.5278925895690918, 0.5268595218658447, 0.5247933864593506, 0.5258264541625977, 0.5320248007774353, 0.5299586653709412, 0.5340909361839294, 0.5309917330741882, 0.5320248007774353, 0.5320248007774353, 0.5340909361839294, 0.5309917330741882, 0.5361570119857788, 0.5268595218658447, 0.5371900796890259, 0.5433884263038635, 0.5330578684806824, 0.5413222908973694, 0.5361570119857788, 0.5351239442825317, 0.5371900796890259, 0.538223147392273, 0.5330578684806824, 0.5330578684806824, 0.5330578684806824, 0.5216942429542542, 0.5371900796890259, 0.5299586653709412, 0.5351239442825317, 0.5320248007774353, 0.5351239442825317, 0.5299586653709412, 0.5361570119857788, 0.5340909361839294, 0.5371900796890259]}\n","32/32 [==============================] - 0s 8ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/29 [========================>.....] - ETA: 0s - loss: 1.0748 - accuracy: 0.6263"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 6s 99ms/step - loss: 1.0731 - accuracy: 0.6285 - val_loss: 1.1365 - val_accuracy: 0.5162\n","Epoch 2/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0638 - accuracy: 0.6393 - val_loss: 1.1325 - val_accuracy: 0.5172\n","Epoch 3/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0596 - accuracy: 0.6401 - val_loss: 1.1277 - val_accuracy: 0.5194\n","Epoch 4/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0553 - accuracy: 0.6398 - val_loss: 1.1231 - val_accuracy: 0.5259\n","Epoch 5/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0476 - accuracy: 0.6460 - val_loss: 1.1197 - val_accuracy: 0.5356\n","Epoch 6/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0433 - accuracy: 0.6519 - val_loss: 1.1151 - val_accuracy: 0.5399\n","Epoch 7/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0372 - accuracy: 0.6622 - val_loss: 1.1108 - val_accuracy: 0.5496\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0330 - accuracy: 0.6522 - val_loss: 1.1058 - val_accuracy: 0.5808\n","Epoch 9/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0283 - accuracy: 0.6557 - val_loss: 1.1023 - val_accuracy: 0.5625\n","Epoch 10/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0236 - accuracy: 0.6573 - val_loss: 1.0994 - val_accuracy: 0.5647\n","Epoch 11/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0182 - accuracy: 0.6622 - val_loss: 1.0940 - val_accuracy: 0.5905\n","Epoch 12/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0150 - accuracy: 0.6506 - val_loss: 1.0891 - val_accuracy: 0.5894\n","Epoch 13/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0104 - accuracy: 0.6541 - val_loss: 1.0855 - val_accuracy: 0.5787\n","Epoch 14/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0064 - accuracy: 0.6635 - val_loss: 1.0814 - val_accuracy: 0.5916\n","Epoch 15/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0023 - accuracy: 0.6592 - val_loss: 1.0752 - val_accuracy: 0.5905\n","Epoch 16/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9996 - accuracy: 0.6676 - val_loss: 1.0683 - val_accuracy: 0.5981\n","Epoch 17/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9961 - accuracy: 0.6581 - val_loss: 1.0736 - val_accuracy: 0.5927\n","Epoch 18/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9883 - accuracy: 0.6686 - val_loss: 1.0621 - val_accuracy: 0.6131\n","Epoch 19/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9897 - accuracy: 0.6560 - val_loss: 1.0785 - val_accuracy: 0.5938\n","Epoch 20/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9826 - accuracy: 0.6676 - val_loss: 1.0572 - val_accuracy: 0.6034\n","Epoch 21/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9788 - accuracy: 0.6649 - val_loss: 1.0622 - val_accuracy: 0.6045\n","Epoch 22/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9744 - accuracy: 0.6678 - val_loss: 1.0653 - val_accuracy: 0.5938\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9705 - accuracy: 0.6659 - val_loss: 1.0543 - val_accuracy: 0.5927\n","Epoch 24/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9658 - accuracy: 0.6724 - val_loss: 1.0557 - val_accuracy: 0.5959\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9605 - accuracy: 0.6789 - val_loss: 1.0717 - val_accuracy: 0.6078\n","Epoch 26/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9578 - accuracy: 0.6711 - val_loss: 1.0586 - val_accuracy: 0.5981\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9540 - accuracy: 0.6713 - val_loss: 1.0551 - val_accuracy: 0.5884\n","Epoch 28/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9486 - accuracy: 0.6748 - val_loss: 1.0566 - val_accuracy: 0.5797\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9453 - accuracy: 0.6824 - val_loss: 1.0561 - val_accuracy: 0.5991\n","Epoch 30/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9433 - accuracy: 0.6659 - val_loss: 1.0666 - val_accuracy: 0.6088\n","Epoch 31/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9416 - accuracy: 0.6805 - val_loss: 1.0554 - val_accuracy: 0.6002\n","Epoch 32/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9347 - accuracy: 0.6843 - val_loss: 1.0595 - val_accuracy: 0.5894\n","Epoch 33/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9342 - accuracy: 0.6783 - val_loss: 1.0678 - val_accuracy: 0.6034\n","Epoch 34/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9282 - accuracy: 0.6748 - val_loss: 1.0592 - val_accuracy: 0.5851\n","Epoch 35/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9230 - accuracy: 0.6837 - val_loss: 1.0818 - val_accuracy: 0.6034\n","Epoch 36/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9198 - accuracy: 0.6845 - val_loss: 1.0666 - val_accuracy: 0.5905\n","Epoch 37/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9172 - accuracy: 0.6853 - val_loss: 1.0779 - val_accuracy: 0.5991\n","Epoch 38/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9132 - accuracy: 0.6888 - val_loss: 1.0602 - val_accuracy: 0.6067\n","Epoch 39/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9094 - accuracy: 0.6899 - val_loss: 1.0628 - val_accuracy: 0.5970\n","Epoch 40/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9057 - accuracy: 0.6867 - val_loss: 1.0605 - val_accuracy: 0.5970\n","Epoch 41/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9019 - accuracy: 0.6967 - val_loss: 1.0541 - val_accuracy: 0.5938\n","Epoch 42/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8978 - accuracy: 0.6921 - val_loss: 1.0747 - val_accuracy: 0.6099\n","Epoch 43/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8975 - accuracy: 0.6875 - val_loss: 1.0515 - val_accuracy: 0.5884\n","Epoch 44/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8933 - accuracy: 0.6867 - val_loss: 1.0665 - val_accuracy: 0.6024\n","Epoch 45/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8870 - accuracy: 0.6977 - val_loss: 1.0633 - val_accuracy: 0.5959\n","Epoch 46/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8842 - accuracy: 0.7045 - val_loss: 1.0757 - val_accuracy: 0.5970\n","Epoch 47/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8819 - accuracy: 0.6983 - val_loss: 1.0626 - val_accuracy: 0.5830\n","Epoch 48/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8816 - accuracy: 0.6961 - val_loss: 1.0801 - val_accuracy: 0.6078\n","Epoch 49/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8744 - accuracy: 0.7055 - val_loss: 1.0566 - val_accuracy: 0.5797\n","Epoch 50/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8722 - accuracy: 0.7034 - val_loss: 1.0643 - val_accuracy: 0.5614\n","Epoch 51/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8724 - accuracy: 0.6940 - val_loss: 1.0692 - val_accuracy: 0.5959\n","Epoch 52/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8695 - accuracy: 0.7023 - val_loss: 1.0565 - val_accuracy: 0.6002\n","Epoch 53/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8642 - accuracy: 0.7020 - val_loss: 1.0769 - val_accuracy: 0.6034\n","Epoch 54/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8634 - accuracy: 0.7002 - val_loss: 1.0553 - val_accuracy: 0.6034\n","Epoch 55/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.8554 - accuracy: 0.7082 - val_loss: 1.0692 - val_accuracy: 0.6142\n","Epoch 56/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8511 - accuracy: 0.7072 - val_loss: 1.0586 - val_accuracy: 0.6088\n","Epoch 57/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8478 - accuracy: 0.7112 - val_loss: 1.0762 - val_accuracy: 0.6067\n","Epoch 58/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8448 - accuracy: 0.7104 - val_loss: 1.0831 - val_accuracy: 0.6056\n","Epoch 59/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8461 - accuracy: 0.7179 - val_loss: 1.0683 - val_accuracy: 0.6024\n","Epoch 60/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8409 - accuracy: 0.7179 - val_loss: 1.0735 - val_accuracy: 0.5938\n","Epoch 61/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8362 - accuracy: 0.7136 - val_loss: 1.0653 - val_accuracy: 0.6013\n","Epoch 62/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8338 - accuracy: 0.7169 - val_loss: 1.1024 - val_accuracy: 0.5927\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8307 - accuracy: 0.7142 - val_loss: 1.0571 - val_accuracy: 0.5981\n","Epoch 64/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8264 - accuracy: 0.7136 - val_loss: 1.0721 - val_accuracy: 0.6045\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8225 - accuracy: 0.7260 - val_loss: 1.0778 - val_accuracy: 0.6045\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8198 - accuracy: 0.7228 - val_loss: 1.0670 - val_accuracy: 0.5894\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8184 - accuracy: 0.7228 - val_loss: 1.0880 - val_accuracy: 0.5830\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8177 - accuracy: 0.7217 - val_loss: 1.0562 - val_accuracy: 0.6078\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8110 - accuracy: 0.7260 - val_loss: 1.0801 - val_accuracy: 0.6067\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8066 - accuracy: 0.7290 - val_loss: 1.0841 - val_accuracy: 0.5787\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8053 - accuracy: 0.7249 - val_loss: 1.0708 - val_accuracy: 0.5819\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8052 - accuracy: 0.7279 - val_loss: 1.0738 - val_accuracy: 0.5776\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7972 - accuracy: 0.7414 - val_loss: 1.0714 - val_accuracy: 0.6045\n","Epoch 74/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7967 - accuracy: 0.7293 - val_loss: 1.0789 - val_accuracy: 0.6056\n","Epoch 75/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7953 - accuracy: 0.7352 - val_loss: 1.1213 - val_accuracy: 0.5927\n","Epoch 76/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7978 - accuracy: 0.7298 - val_loss: 1.0900 - val_accuracy: 0.6045\n","Epoch 77/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7892 - accuracy: 0.7341 - val_loss: 1.0838 - val_accuracy: 0.6045\n","Epoch 78/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7857 - accuracy: 0.7384 - val_loss: 1.1108 - val_accuracy: 0.5981\n","Epoch 79/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7848 - accuracy: 0.7346 - val_loss: 1.1035 - val_accuracy: 0.5830\n","Epoch 80/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7794 - accuracy: 0.7379 - val_loss: 1.0960 - val_accuracy: 0.5862\n","Epoch 81/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7773 - accuracy: 0.7430 - val_loss: 1.0904 - val_accuracy: 0.5830\n","Epoch 82/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7726 - accuracy: 0.7457 - val_loss: 1.1166 - val_accuracy: 0.5884\n","Epoch 83/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7719 - accuracy: 0.7422 - val_loss: 1.1121 - val_accuracy: 0.5959\n","Epoch 84/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7694 - accuracy: 0.7511 - val_loss: 1.1127 - val_accuracy: 0.5884\n","Epoch 85/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7656 - accuracy: 0.7454 - val_loss: 1.1068 - val_accuracy: 0.6099\n","Epoch 86/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7608 - accuracy: 0.7548 - val_loss: 1.1019 - val_accuracy: 0.6056\n","Epoch 87/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7591 - accuracy: 0.7551 - val_loss: 1.1025 - val_accuracy: 0.5884\n","Epoch 88/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7574 - accuracy: 0.7540 - val_loss: 1.1486 - val_accuracy: 0.5797\n","Epoch 89/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7558 - accuracy: 0.7530 - val_loss: 1.1726 - val_accuracy: 0.5733\n","Epoch 90/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7675 - accuracy: 0.7435 - val_loss: 1.1428 - val_accuracy: 0.5765\n","Epoch 91/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7593 - accuracy: 0.7492 - val_loss: 1.1420 - val_accuracy: 0.6034\n","Epoch 92/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7485 - accuracy: 0.7559 - val_loss: 1.1271 - val_accuracy: 0.5981\n","Epoch 93/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7482 - accuracy: 0.7592 - val_loss: 1.1668 - val_accuracy: 0.5841\n","Epoch 94/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7455 - accuracy: 0.7538 - val_loss: 1.1277 - val_accuracy: 0.5905\n","Epoch 95/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7374 - accuracy: 0.7592 - val_loss: 1.1263 - val_accuracy: 0.6067\n","Epoch 96/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7391 - accuracy: 0.7567 - val_loss: 1.1490 - val_accuracy: 0.5927\n","Epoch 97/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7369 - accuracy: 0.7567 - val_loss: 1.1258 - val_accuracy: 0.6013\n","Epoch 98/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7345 - accuracy: 0.7551 - val_loss: 1.1259 - val_accuracy: 0.5797\n","Epoch 99/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7280 - accuracy: 0.7602 - val_loss: 1.1364 - val_accuracy: 0.6024\n","Epoch 100/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7306 - accuracy: 0.7651 - val_loss: 1.1460 - val_accuracy: 0.5873\n","{'loss': [1.0730687379837036, 1.0637733936309814, 1.0595648288726807, 1.0553295612335205, 1.0475505590438843, 1.0433074235916138, 1.0371826887130737, 1.033019781112671, 1.0283135175704956, 1.0235862731933594, 1.0182390213012695, 1.0150246620178223, 1.0104448795318604, 1.0064486265182495, 1.002321481704712, 0.9995669722557068, 0.9960746765136719, 0.9883045554161072, 0.9897494912147522, 0.9826183915138245, 0.9787765741348267, 0.9743538498878479, 0.9704970121383667, 0.9657639861106873, 0.9605344533920288, 0.9577925205230713, 0.9540015459060669, 0.9486193060874939, 0.9453338384628296, 0.943343460559845, 0.9415624737739563, 0.9346925616264343, 0.9341579079627991, 0.9282369017601013, 0.9230186343193054, 0.919772744178772, 0.9171797037124634, 0.9131919741630554, 0.9094232320785522, 0.9056501984596252, 0.9018955230712891, 0.8977983593940735, 0.8975261449813843, 0.8933103680610657, 0.8870255947113037, 0.8841978311538696, 0.8818594813346863, 0.8816105127334595, 0.8744112849235535, 0.8722304701805115, 0.872409999370575, 0.869500994682312, 0.8642364740371704, 0.8634287118911743, 0.855351984500885, 0.8510733842849731, 0.8477949500083923, 0.8448424935340881, 0.8460922837257385, 0.8409275412559509, 0.8361683487892151, 0.8337734937667847, 0.8307077884674072, 0.826388418674469, 0.8224866390228271, 0.8197705745697021, 0.8184363842010498, 0.8176887631416321, 0.8109681606292725, 0.8066009283065796, 0.8053377270698547, 0.8051977753639221, 0.7971948981285095, 0.7966520190238953, 0.7953266501426697, 0.7977803945541382, 0.7891978025436401, 0.7857144474983215, 0.7847822904586792, 0.7793799042701721, 0.77728271484375, 0.7726336121559143, 0.7718880772590637, 0.7693678736686707, 0.7655845284461975, 0.7607628107070923, 0.7590874433517456, 0.7573983669281006, 0.7557596564292908, 0.7675081491470337, 0.759261965751648, 0.7485460638999939, 0.748215913772583, 0.7454521059989929, 0.7374071478843689, 0.7391389012336731, 0.7369386553764343, 0.7345181107521057, 0.7279547452926636, 0.7306275367736816], 'accuracy': [0.6285021305084229, 0.639277994632721, 0.6400862336158752, 0.6398168206214905, 0.6460129022598267, 0.6519396305084229, 0.6621767282485962, 0.6522090435028076, 0.6557112336158752, 0.6573275923728943, 0.6621767282485962, 0.6505926847457886, 0.6540948152542114, 0.6635237336158752, 0.6592133641242981, 0.6675646305084229, 0.6581357717514038, 0.6686422228813171, 0.6559805870056152, 0.6675646305084229, 0.6648706793785095, 0.6678340435028076, 0.6659482717514038, 0.6724137663841248, 0.6788793206214905, 0.6710668206214905, 0.6713362336158752, 0.6748383641242981, 0.6823814511299133, 0.6659482717514038, 0.6804956793785095, 0.6842672228813171, 0.678340494632721, 0.6748383641242981, 0.6837284564971924, 0.6845366358757019, 0.6853448152542114, 0.688847005367279, 0.6899245977401733, 0.6866918206214905, 0.696659505367279, 0.6920797228813171, 0.6875, 0.6866918206214905, 0.6977370977401733, 0.704472005367279, 0.6982758641242981, 0.6961206793785095, 0.7055495977401733, 0.7033944129943848, 0.693965494632721, 0.7023168206214905, 0.7020474076271057, 0.7001616358757019, 0.7082435488700867, 0.7071659564971924, 0.7112069129943848, 0.7103987336158752, 0.7179418206214905, 0.7179418206214905, 0.7136314511299133, 0.7168642282485962, 0.7141702771186829, 0.7136314511299133, 0.7260237336158752, 0.7227909564971924, 0.7227909564971924, 0.7217133641242981, 0.7260237336158752, 0.7289870977401733, 0.724946141242981, 0.727909505367279, 0.7413793206214905, 0.7292564511299133, 0.7351831793785095, 0.7297952771186829, 0.7341055870056152, 0.7384159564971924, 0.7346444129943848, 0.7378771305084229, 0.7429956793785095, 0.7456896305084229, 0.7421875, 0.7510775923728943, 0.7454202771186829, 0.7548491358757019, 0.7551185488700867, 0.7540409564971924, 0.7529633641242981, 0.743534505367279, 0.7491918206214905, 0.7559267282485962, 0.759159505367279, 0.7537715435028076, 0.759159505367279, 0.7567349076271057, 0.7567349076271057, 0.7551185488700867, 0.7602370977401733, 0.7650862336158752], 'val_loss': [1.1364964246749878, 1.1325347423553467, 1.1276845932006836, 1.123115062713623, 1.1197013854980469, 1.115066409111023, 1.110795021057129, 1.1057955026626587, 1.1022584438323975, 1.0993709564208984, 1.0940182209014893, 1.0890915393829346, 1.0854698419570923, 1.08137047290802, 1.075209379196167, 1.0683166980743408, 1.0736263990402222, 1.0621367692947388, 1.078539252281189, 1.0571913719177246, 1.0621557235717773, 1.0653042793273926, 1.0543195009231567, 1.0556899309158325, 1.07167387008667, 1.0586488246917725, 1.0551283359527588, 1.056567668914795, 1.056053638458252, 1.0665665864944458, 1.0554414987564087, 1.05953049659729, 1.0677546262741089, 1.0592310428619385, 1.0818368196487427, 1.066630482673645, 1.077877163887024, 1.060180425643921, 1.0628308057785034, 1.0605469942092896, 1.05409574508667, 1.0747442245483398, 1.0515031814575195, 1.0665041208267212, 1.063265323638916, 1.075674057006836, 1.0626431703567505, 1.0800814628601074, 1.0566421747207642, 1.064342975616455, 1.0691874027252197, 1.0565310716629028, 1.0769104957580566, 1.0552853345870972, 1.0691930055618286, 1.058609127998352, 1.0762441158294678, 1.0830658674240112, 1.0682735443115234, 1.0735399723052979, 1.065321683883667, 1.1024210453033447, 1.0570740699768066, 1.0721267461776733, 1.0778310298919678, 1.066982388496399, 1.0880221128463745, 1.0562279224395752, 1.080094575881958, 1.0840702056884766, 1.0707769393920898, 1.0737552642822266, 1.0714349746704102, 1.0789321660995483, 1.121258020401001, 1.089990496635437, 1.083814263343811, 1.1107505559921265, 1.1035033464431763, 1.095950961112976, 1.090390682220459, 1.1166300773620605, 1.1121419668197632, 1.112667202949524, 1.1068259477615356, 1.101860761642456, 1.1025192737579346, 1.148637294769287, 1.1725977659225464, 1.1427924633026123, 1.1420458555221558, 1.1271456480026245, 1.1667577028274536, 1.1277127265930176, 1.126339077949524, 1.149044394493103, 1.1257669925689697, 1.1258890628814697, 1.1364494562149048, 1.1460270881652832], 'val_accuracy': [0.5161637663841248, 0.517241358757019, 0.5193965435028076, 0.5258620977401733, 0.5355603694915771, 0.5398706793785095, 0.5495689511299133, 0.5808189511299133, 0.5625, 0.5646551847457886, 0.5905172228813171, 0.5894396305084229, 0.5786637663841248, 0.5915948152542114, 0.5905172228813171, 0.5980603694915771, 0.5926724076271057, 0.6131465435028076, 0.59375, 0.6034482717514038, 0.6045258641242981, 0.59375, 0.5926724076271057, 0.5959051847457886, 0.607758641242981, 0.5980603694915771, 0.5883620977401733, 0.579741358757019, 0.5991379022598267, 0.6088362336158752, 0.600215494632721, 0.5894396305084229, 0.6034482717514038, 0.5851293206214905, 0.6034482717514038, 0.5905172228813171, 0.5991379022598267, 0.6066810488700867, 0.5969827771186829, 0.5969827771186829, 0.59375, 0.6099137663841248, 0.5883620977401733, 0.6023706793785095, 0.5959051847457886, 0.5969827771186829, 0.5829741358757019, 0.607758641242981, 0.579741358757019, 0.5614224076271057, 0.5959051847457886, 0.600215494632721, 0.6034482717514038, 0.6034482717514038, 0.6142241358757019, 0.6088362336158752, 0.6066810488700867, 0.6056034564971924, 0.6023706793785095, 0.59375, 0.6012930870056152, 0.5926724076271057, 0.5980603694915771, 0.6045258641242981, 0.6045258641242981, 0.5894396305084229, 0.5829741358757019, 0.607758641242981, 0.6066810488700867, 0.5786637663841248, 0.5818965435028076, 0.5775862336158752, 0.6045258641242981, 0.6056034564971924, 0.5926724076271057, 0.6045258641242981, 0.6045258641242981, 0.5980603694915771, 0.5829741358757019, 0.5862069129943848, 0.5829741358757019, 0.5883620977401733, 0.5959051847457886, 0.5883620977401733, 0.6099137663841248, 0.6056034564971924, 0.5883620977401733, 0.579741358757019, 0.5732758641242981, 0.576508641242981, 0.6034482717514038, 0.5980603694915771, 0.5840517282485962, 0.5905172228813171, 0.6066810488700867, 0.5926724076271057, 0.6012930870056152, 0.579741358757019, 0.6023706793785095, 0.587284505367279]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 5s 29ms/step - loss: 1.0711 - accuracy: 0.6344 - val_loss: 1.1383 - val_accuracy: 0.5057\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 1.0208 - accuracy: 0.6719"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 11ms/step - loss: 1.0615 - accuracy: 0.6406 - val_loss: 1.1348 - val_accuracy: 0.5057\n","Epoch 3/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0580 - accuracy: 0.6466 - val_loss: 1.1331 - val_accuracy: 0.5057\n","Epoch 4/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0527 - accuracy: 0.6477 - val_loss: 1.1253 - val_accuracy: 0.5102\n","Epoch 5/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0462 - accuracy: 0.6508 - val_loss: 1.1207 - val_accuracy: 0.5147\n","Epoch 6/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0418 - accuracy: 0.6582 - val_loss: 1.1174 - val_accuracy: 0.5170\n","Epoch 7/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0367 - accuracy: 0.6520 - val_loss: 1.1146 - val_accuracy: 0.5181\n","Epoch 8/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0322 - accuracy: 0.6534 - val_loss: 1.1076 - val_accuracy: 0.5317\n","Epoch 9/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0284 - accuracy: 0.6556 - val_loss: 1.1060 - val_accuracy: 0.5305\n","Epoch 10/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0210 - accuracy: 0.6616 - val_loss: 1.0993 - val_accuracy: 0.5362\n","Epoch 11/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0179 - accuracy: 0.6613 - val_loss: 1.0948 - val_accuracy: 0.5373\n","Epoch 12/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0134 - accuracy: 0.6559 - val_loss: 1.0905 - val_accuracy: 0.5419\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0106 - accuracy: 0.6511 - val_loss: 1.0838 - val_accuracy: 0.5622\n","Epoch 14/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0051 - accuracy: 0.6590 - val_loss: 1.0836 - val_accuracy: 0.5475\n","Epoch 15/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0015 - accuracy: 0.6604 - val_loss: 1.0753 - val_accuracy: 0.5588\n","Epoch 16/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9957 - accuracy: 0.6695 - val_loss: 1.0675 - val_accuracy: 0.5882\n","Epoch 17/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9961 - accuracy: 0.6602 - val_loss: 1.0681 - val_accuracy: 0.5656\n","Epoch 18/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9874 - accuracy: 0.6667 - val_loss: 1.0644 - val_accuracy: 0.5645\n","Epoch 19/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9839 - accuracy: 0.6718 - val_loss: 1.0581 - val_accuracy: 0.5894\n","Epoch 20/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9811 - accuracy: 0.6698 - val_loss: 1.0546 - val_accuracy: 0.5758\n","Epoch 21/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9796 - accuracy: 0.6706 - val_loss: 1.0490 - val_accuracy: 0.5995\n","Epoch 22/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9717 - accuracy: 0.6752 - val_loss: 1.0462 - val_accuracy: 0.5984\n","Epoch 23/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9668 - accuracy: 0.6771 - val_loss: 1.0452 - val_accuracy: 0.5939\n","Epoch 24/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9638 - accuracy: 0.6774 - val_loss: 1.0458 - val_accuracy: 0.5905\n","Epoch 25/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9628 - accuracy: 0.6737 - val_loss: 1.0444 - val_accuracy: 0.6063\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9567 - accuracy: 0.6836 - val_loss: 1.0445 - val_accuracy: 0.5973\n","Epoch 27/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9529 - accuracy: 0.6825 - val_loss: 1.0400 - val_accuracy: 0.5973\n","Epoch 28/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9508 - accuracy: 0.6817 - val_loss: 1.0446 - val_accuracy: 0.6075\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9447 - accuracy: 0.6740 - val_loss: 1.0507 - val_accuracy: 0.6007\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9437 - accuracy: 0.6808 - val_loss: 1.0418 - val_accuracy: 0.6041\n","Epoch 31/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9390 - accuracy: 0.6839 - val_loss: 1.0488 - val_accuracy: 0.6097\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9334 - accuracy: 0.6924 - val_loss: 1.0428 - val_accuracy: 0.6075\n","Epoch 33/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9291 - accuracy: 0.6919 - val_loss: 1.0430 - val_accuracy: 0.5962\n","Epoch 34/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9272 - accuracy: 0.6848 - val_loss: 1.0379 - val_accuracy: 0.6097\n","Epoch 35/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9219 - accuracy: 0.6848 - val_loss: 1.0429 - val_accuracy: 0.6007\n","Epoch 36/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9195 - accuracy: 0.6910 - val_loss: 1.0431 - val_accuracy: 0.6097\n","Epoch 37/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9147 - accuracy: 0.6938 - val_loss: 1.0384 - val_accuracy: 0.6041\n","Epoch 38/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9141 - accuracy: 0.6904 - val_loss: 1.0552 - val_accuracy: 0.5860\n","Epoch 39/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9117 - accuracy: 0.6930 - val_loss: 1.0468 - val_accuracy: 0.5995\n","Epoch 40/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9068 - accuracy: 0.6896 - val_loss: 1.0492 - val_accuracy: 0.5950\n","Epoch 41/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9027 - accuracy: 0.6967 - val_loss: 1.0564 - val_accuracy: 0.5848\n","Epoch 42/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8998 - accuracy: 0.6907 - val_loss: 1.0473 - val_accuracy: 0.5837\n","Epoch 43/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8927 - accuracy: 0.7012 - val_loss: 1.0380 - val_accuracy: 0.6029\n","Epoch 44/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8897 - accuracy: 0.7006 - val_loss: 1.0460 - val_accuracy: 0.5905\n","Epoch 45/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8920 - accuracy: 0.6967 - val_loss: 1.0440 - val_accuracy: 0.6109\n","Epoch 46/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8845 - accuracy: 0.7012 - val_loss: 1.0456 - val_accuracy: 0.5962\n","Epoch 47/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8798 - accuracy: 0.7029 - val_loss: 1.0401 - val_accuracy: 0.6029\n","Epoch 48/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8763 - accuracy: 0.7029 - val_loss: 1.0438 - val_accuracy: 0.5916\n","Epoch 49/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8748 - accuracy: 0.7015 - val_loss: 1.0486 - val_accuracy: 0.5984\n","Epoch 50/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8705 - accuracy: 0.7029 - val_loss: 1.0405 - val_accuracy: 0.5950\n","Epoch 51/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8655 - accuracy: 0.7051 - val_loss: 1.0477 - val_accuracy: 0.5984\n","Epoch 52/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8641 - accuracy: 0.7128 - val_loss: 1.0468 - val_accuracy: 0.5905\n","Epoch 53/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8617 - accuracy: 0.7100 - val_loss: 1.0462 - val_accuracy: 0.5928\n","Epoch 54/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8600 - accuracy: 0.7114 - val_loss: 1.0721 - val_accuracy: 0.5690\n","Epoch 55/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8586 - accuracy: 0.7063 - val_loss: 1.0623 - val_accuracy: 0.5894\n","Epoch 56/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8511 - accuracy: 0.7136 - val_loss: 1.0602 - val_accuracy: 0.5995\n","Epoch 57/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8475 - accuracy: 0.7170 - val_loss: 1.0480 - val_accuracy: 0.5995\n","Epoch 58/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8429 - accuracy: 0.7182 - val_loss: 1.0436 - val_accuracy: 0.5973\n","Epoch 59/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8421 - accuracy: 0.7207 - val_loss: 1.0576 - val_accuracy: 0.5871\n","Epoch 60/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8440 - accuracy: 0.7148 - val_loss: 1.0446 - val_accuracy: 0.5950\n","Epoch 61/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8365 - accuracy: 0.7196 - val_loss: 1.0792 - val_accuracy: 0.5962\n","Epoch 62/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8390 - accuracy: 0.7176 - val_loss: 1.0496 - val_accuracy: 0.5860\n","Epoch 63/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8361 - accuracy: 0.7122 - val_loss: 1.0487 - val_accuracy: 0.5973\n","Epoch 64/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8280 - accuracy: 0.7187 - val_loss: 1.0529 - val_accuracy: 0.6029\n","Epoch 65/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8267 - accuracy: 0.7269 - val_loss: 1.0621 - val_accuracy: 0.5860\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8226 - accuracy: 0.7250 - val_loss: 1.0559 - val_accuracy: 0.5916\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8168 - accuracy: 0.7337 - val_loss: 1.0851 - val_accuracy: 0.5860\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8202 - accuracy: 0.7301 - val_loss: 1.0592 - val_accuracy: 0.5781\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8182 - accuracy: 0.7261 - val_loss: 1.0855 - val_accuracy: 0.5792\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8103 - accuracy: 0.7312 - val_loss: 1.0556 - val_accuracy: 0.5984\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8094 - accuracy: 0.7284 - val_loss: 1.0907 - val_accuracy: 0.5735\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8043 - accuracy: 0.7281 - val_loss: 1.0668 - val_accuracy: 0.5950\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7990 - accuracy: 0.7400 - val_loss: 1.0741 - val_accuracy: 0.5860\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7987 - accuracy: 0.7394 - val_loss: 1.0863 - val_accuracy: 0.5905\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8000 - accuracy: 0.7284 - val_loss: 1.0707 - val_accuracy: 0.5916\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7937 - accuracy: 0.7284 - val_loss: 1.0836 - val_accuracy: 0.5701\n","Epoch 77/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7885 - accuracy: 0.7371 - val_loss: 1.0748 - val_accuracy: 0.5860\n","Epoch 78/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7884 - accuracy: 0.7385 - val_loss: 1.0692 - val_accuracy: 0.5758\n","Epoch 79/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7885 - accuracy: 0.7309 - val_loss: 1.1075 - val_accuracy: 0.5905\n","Epoch 80/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7859 - accuracy: 0.7417 - val_loss: 1.0794 - val_accuracy: 0.5939\n","Epoch 81/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7805 - accuracy: 0.7436 - val_loss: 1.0898 - val_accuracy: 0.5758\n","Epoch 82/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7788 - accuracy: 0.7411 - val_loss: 1.0846 - val_accuracy: 0.5882\n","Epoch 83/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7797 - accuracy: 0.7357 - val_loss: 1.0704 - val_accuracy: 0.5962\n","Epoch 84/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7713 - accuracy: 0.7518 - val_loss: 1.0937 - val_accuracy: 0.5860\n","Epoch 85/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7699 - accuracy: 0.7473 - val_loss: 1.1074 - val_accuracy: 0.5826\n","Epoch 86/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7647 - accuracy: 0.7566 - val_loss: 1.0910 - val_accuracy: 0.5871\n","Epoch 87/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7643 - accuracy: 0.7518 - val_loss: 1.0858 - val_accuracy: 0.5939\n","Epoch 88/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7636 - accuracy: 0.7538 - val_loss: 1.1311 - val_accuracy: 0.5905\n","Epoch 89/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7692 - accuracy: 0.7422 - val_loss: 1.1027 - val_accuracy: 0.5837\n","Epoch 90/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7558 - accuracy: 0.7578 - val_loss: 1.1098 - val_accuracy: 0.5667\n","Epoch 91/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7543 - accuracy: 0.7564 - val_loss: 1.1181 - val_accuracy: 0.5803\n","Epoch 92/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7541 - accuracy: 0.7569 - val_loss: 1.1204 - val_accuracy: 0.5792\n","Epoch 93/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7561 - accuracy: 0.7507 - val_loss: 1.1149 - val_accuracy: 0.5814\n","Epoch 94/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7529 - accuracy: 0.7544 - val_loss: 1.1535 - val_accuracy: 0.5758\n","Epoch 95/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7663 - accuracy: 0.7405 - val_loss: 1.1069 - val_accuracy: 0.5973\n","Epoch 96/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7407 - accuracy: 0.7615 - val_loss: 1.1084 - val_accuracy: 0.5871\n","Epoch 97/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7417 - accuracy: 0.7626 - val_loss: 1.1376 - val_accuracy: 0.5837\n","Epoch 98/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7439 - accuracy: 0.7592 - val_loss: 1.1160 - val_accuracy: 0.5860\n","Epoch 99/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7358 - accuracy: 0.7561 - val_loss: 1.1341 - val_accuracy: 0.5837\n","Epoch 100/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7316 - accuracy: 0.7606 - val_loss: 1.1245 - val_accuracy: 0.5928\n","{'loss': [1.0710985660552979, 1.0614556074142456, 1.058007001876831, 1.0527074337005615, 1.0462137460708618, 1.0417670011520386, 1.0366990566253662, 1.0321898460388184, 1.0283619165420532, 1.0209711790084839, 1.0179107189178467, 1.0134485960006714, 1.0106347799301147, 1.0050851106643677, 1.0014638900756836, 0.9957431554794312, 0.996097981929779, 0.9873810410499573, 0.9839013814926147, 0.9810693860054016, 0.9796164035797119, 0.9716659188270569, 0.9667932391166687, 0.9637953639030457, 0.9627823829650879, 0.9566540718078613, 0.952936589717865, 0.9508246183395386, 0.9446888566017151, 0.9436742663383484, 0.9389975666999817, 0.93344646692276, 0.9291428923606873, 0.9272487759590149, 0.9218907952308655, 0.9194595813751221, 0.9147422909736633, 0.9141441583633423, 0.911666214466095, 0.9068126082420349, 0.9027222394943237, 0.8997592926025391, 0.8927497863769531, 0.8897179365158081, 0.8920450806617737, 0.8844818472862244, 0.8797537684440613, 0.8763237595558167, 0.874794065952301, 0.8705054521560669, 0.8654562830924988, 0.864112377166748, 0.861736536026001, 0.8600324392318726, 0.8586423993110657, 0.8511337637901306, 0.8475416898727417, 0.8428546786308289, 0.8420565724372864, 0.8439525365829468, 0.836542546749115, 0.8390130400657654, 0.836050808429718, 0.8279864192008972, 0.826667070388794, 0.8226292133331299, 0.8168367147445679, 0.8201738595962524, 0.8181912302970886, 0.8103287816047668, 0.809390127658844, 0.8043089509010315, 0.799048662185669, 0.7987154722213745, 0.799955427646637, 0.793744683265686, 0.7885373830795288, 0.7884185910224915, 0.7884947061538696, 0.7858863472938538, 0.7805293202400208, 0.7787589430809021, 0.779701292514801, 0.7712809443473816, 0.7699471116065979, 0.7647082209587097, 0.7643038630485535, 0.7635537385940552, 0.7692463397979736, 0.7558417320251465, 0.7543428540229797, 0.754130482673645, 0.7561047673225403, 0.7528600096702576, 0.766347348690033, 0.7406635284423828, 0.7416735291481018, 0.7439465522766113, 0.7357532978057861, 0.7315601706504822], 'accuracy': [0.6344085931777954, 0.6406338214874268, 0.6465761065483093, 0.647707998752594, 0.6508206129074097, 0.6581776738166809, 0.6519524455070496, 0.653367280960083, 0.6556310057640076, 0.6615732908248901, 0.6612903475761414, 0.6559139490127563, 0.6511035561561584, 0.6590266227722168, 0.6604413986206055, 0.6694962978363037, 0.6601584553718567, 0.6666666865348816, 0.6717600226402283, 0.6697793006896973, 0.6706281900405884, 0.6751556396484375, 0.6771363615989685, 0.6774193644523621, 0.673740804195404, 0.6836445927619934, 0.6825127601623535, 0.6816638112068176, 0.6740237474441528, 0.6808149218559265, 0.6839275360107422, 0.6924165487289429, 0.6918506026268005, 0.6847764849662781, 0.6847764849662781, 0.6910017132759094, 0.6938313245773315, 0.6904357671737671, 0.6929824352264404, 0.689586877822876, 0.6966609954833984, 0.6907187104225159, 0.7011884450912476, 0.7006224989891052, 0.6966609954833984, 0.7011884450912476, 0.7028862237930298, 0.7028862237930298, 0.7014714479446411, 0.7028862237930298, 0.7051499485969543, 0.7127900123596191, 0.709960401058197, 0.7113752365112305, 0.706281840801239, 0.713638961315155, 0.7170345187187195, 0.7181664109230042, 0.7207130789756775, 0.7147707939147949, 0.7195811867713928, 0.7176004648208618, 0.7122241258621216, 0.7187322974205017, 0.7269383072853088, 0.7249575257301331, 0.7337294816970825, 0.7300509214401245, 0.7260894179344177, 0.7311828136444092, 0.7283531427383423, 0.7280701994895935, 0.7399547100067139, 0.7393888235092163, 0.7283531427383423, 0.7283531427383423, 0.7371250987052917, 0.7385398745536804, 0.7308998107910156, 0.7416524887084961, 0.7436332702636719, 0.7410866022109985, 0.7357102632522583, 0.751839280128479, 0.7473118305206299, 0.7566496729850769, 0.751839280128479, 0.7538200616836548, 0.7422184348106384, 0.7577815651893616, 0.7563667297363281, 0.7569326758384705, 0.7507073879241943, 0.7543859481811523, 0.7405206561088562, 0.7614601254463196, 0.7625919580459595, 0.759196400642395, 0.7560837864875793, 0.7606111764907837], 'val_loss': [1.1383135318756104, 1.1348382234573364, 1.133080244064331, 1.1252617835998535, 1.1207289695739746, 1.1173821687698364, 1.1145700216293335, 1.1076081991195679, 1.1060017347335815, 1.0992830991744995, 1.0948295593261719, 1.090450644493103, 1.0837903022766113, 1.0835883617401123, 1.075339674949646, 1.067488431930542, 1.068090796470642, 1.0643606185913086, 1.058093547821045, 1.0545846223831177, 1.0490405559539795, 1.0461866855621338, 1.0451669692993164, 1.045823097229004, 1.044388771057129, 1.044520616531372, 1.0399870872497559, 1.0445516109466553, 1.050701379776001, 1.0418213605880737, 1.0487627983093262, 1.0428215265274048, 1.0429964065551758, 1.0379347801208496, 1.042938232421875, 1.0431116819381714, 1.0383964776992798, 1.055163860321045, 1.0467894077301025, 1.0491889715194702, 1.0564199686050415, 1.047337293624878, 1.037998914718628, 1.0460469722747803, 1.044003963470459, 1.0455864667892456, 1.040108561515808, 1.0437697172164917, 1.0486364364624023, 1.0405206680297852, 1.047744870185852, 1.0467947721481323, 1.04619562625885, 1.0721089839935303, 1.062339425086975, 1.0602319240570068, 1.0480482578277588, 1.0435705184936523, 1.057560682296753, 1.0445629358291626, 1.0792354345321655, 1.0495765209197998, 1.048738956451416, 1.052943229675293, 1.0621012449264526, 1.0559264421463013, 1.0851318836212158, 1.0591989755630493, 1.0855118036270142, 1.05559241771698, 1.0906875133514404, 1.0668030977249146, 1.0740584135055542, 1.0863265991210938, 1.07069730758667, 1.0835964679718018, 1.074768304824829, 1.0691664218902588, 1.1075443029403687, 1.0793936252593994, 1.0898257493972778, 1.0845708847045898, 1.0703586339950562, 1.0937108993530273, 1.107360601425171, 1.091004490852356, 1.085770845413208, 1.131098985671997, 1.1026865243911743, 1.1097674369812012, 1.1180551052093506, 1.120389699935913, 1.114949345588684, 1.1535289287567139, 1.106888771057129, 1.1084164381027222, 1.1375510692596436, 1.1160094738006592, 1.1341196298599243, 1.1245001554489136], 'val_accuracy': [0.5056561231613159, 0.5056561231613159, 0.5056561231613159, 0.5101810097694397, 0.5147058963775635, 0.516968309879303, 0.5180995464324951, 0.5316742062568665, 0.5305429697036743, 0.5361990928649902, 0.5373303294181824, 0.5418552160263062, 0.5622171759605408, 0.5475113391876221, 0.5588235259056091, 0.5882353186607361, 0.5656108856201172, 0.564479649066925, 0.5893664956092834, 0.5757918357849121, 0.5995475053787231, 0.598416268825531, 0.5938913822174072, 0.5904977321624756, 0.6063348650932312, 0.5972850918769836, 0.5972850918769836, 0.6074660420417786, 0.6006787419319153, 0.6040723919868469, 0.6097285151481628, 0.6074660420417786, 0.5961538553237915, 0.6097285151481628, 0.6006787419319153, 0.6097285151481628, 0.6040723919868469, 0.5859728455543518, 0.5995475053787231, 0.5950226187705994, 0.5848416090011597, 0.5837104320526123, 0.6029411554336548, 0.5904977321624756, 0.610859751701355, 0.5961538553237915, 0.6029411554336548, 0.5916289687156677, 0.598416268825531, 0.5950226187705994, 0.598416268825531, 0.5904977321624756, 0.5927602052688599, 0.5690045356750488, 0.5893664956092834, 0.5995475053787231, 0.5995475053787231, 0.5972850918769836, 0.587104082107544, 0.5950226187705994, 0.5961538553237915, 0.5859728455543518, 0.5972850918769836, 0.6029411554336548, 0.5859728455543518, 0.5916289687156677, 0.5859728455543518, 0.5780543088912964, 0.5791855454444885, 0.598416268825531, 0.5735294222831726, 0.5950226187705994, 0.5859728455543518, 0.5904977321624756, 0.5916289687156677, 0.570135772228241, 0.5859728455543518, 0.5757918357849121, 0.5904977321624756, 0.5938913822174072, 0.5757918357849121, 0.5882353186607361, 0.5961538553237915, 0.5859728455543518, 0.5825791954994202, 0.587104082107544, 0.5938913822174072, 0.5904977321624756, 0.5837104320526123, 0.5667420625686646, 0.5803167223930359, 0.5791855454444885, 0.581447958946228, 0.5757918357849121, 0.5972850918769836, 0.587104082107544, 0.5837104320526123, 0.5859728455543518, 0.5837104320526123, 0.5927602052688599]}\n","45/45 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 5s 27ms/step - loss: 1.0755 - accuracy: 0.6279 - val_loss: 1.1367 - val_accuracy: 0.5145\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 1.0540 - accuracy: 0.6562"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 16ms/step - loss: 1.0661 - accuracy: 0.6323 - val_loss: 1.1326 - val_accuracy: 0.5165\n","Epoch 3/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0624 - accuracy: 0.6357 - val_loss: 1.1284 - val_accuracy: 0.5165\n","Epoch 4/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0542 - accuracy: 0.6447 - val_loss: 1.1239 - val_accuracy: 0.5207\n","Epoch 5/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0493 - accuracy: 0.6442 - val_loss: 1.1199 - val_accuracy: 0.5269\n","Epoch 6/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0461 - accuracy: 0.6442 - val_loss: 1.1159 - val_accuracy: 0.5269\n","Epoch 7/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0398 - accuracy: 0.6424 - val_loss: 1.1116 - val_accuracy: 0.5320\n","Epoch 8/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0352 - accuracy: 0.6455 - val_loss: 1.1086 - val_accuracy: 0.5362\n","Epoch 9/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0301 - accuracy: 0.6463 - val_loss: 1.1028 - val_accuracy: 0.5393\n","Epoch 10/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0271 - accuracy: 0.6473 - val_loss: 1.0988 - val_accuracy: 0.5403\n","Epoch 11/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0225 - accuracy: 0.6550 - val_loss: 1.0936 - val_accuracy: 0.5496\n","Epoch 12/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0155 - accuracy: 0.6543 - val_loss: 1.0895 - val_accuracy: 0.5475\n","Epoch 13/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0122 - accuracy: 0.6522 - val_loss: 1.0858 - val_accuracy: 0.5558\n","Epoch 14/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0070 - accuracy: 0.6527 - val_loss: 1.0810 - val_accuracy: 0.5517\n","Epoch 15/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0024 - accuracy: 0.6558 - val_loss: 1.0766 - val_accuracy: 0.5630\n","Epoch 16/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9990 - accuracy: 0.6571 - val_loss: 1.0743 - val_accuracy: 0.5671\n","Epoch 17/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9972 - accuracy: 0.6530 - val_loss: 1.0686 - val_accuracy: 0.5630\n","Epoch 18/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9938 - accuracy: 0.6512 - val_loss: 1.0648 - val_accuracy: 0.5723\n","Epoch 19/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9869 - accuracy: 0.6628 - val_loss: 1.0640 - val_accuracy: 0.5568\n","Epoch 20/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9840 - accuracy: 0.6574 - val_loss: 1.0683 - val_accuracy: 0.5775\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9784 - accuracy: 0.6556 - val_loss: 1.0582 - val_accuracy: 0.5682\n","Epoch 22/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9751 - accuracy: 0.6646 - val_loss: 1.0644 - val_accuracy: 0.5692\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9698 - accuracy: 0.6630 - val_loss: 1.0559 - val_accuracy: 0.5651\n","Epoch 24/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9717 - accuracy: 0.6571 - val_loss: 1.0723 - val_accuracy: 0.5775\n","Epoch 25/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9645 - accuracy: 0.6633 - val_loss: 1.0602 - val_accuracy: 0.5795\n","Epoch 26/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9579 - accuracy: 0.6705 - val_loss: 1.0638 - val_accuracy: 0.5837\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9558 - accuracy: 0.6718 - val_loss: 1.0619 - val_accuracy: 0.5702\n","Epoch 28/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9497 - accuracy: 0.6742 - val_loss: 1.0501 - val_accuracy: 0.5682\n","Epoch 29/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9473 - accuracy: 0.6773 - val_loss: 1.0577 - val_accuracy: 0.5785\n","Epoch 30/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9454 - accuracy: 0.6643 - val_loss: 1.0543 - val_accuracy: 0.5651\n","Epoch 31/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9414 - accuracy: 0.6680 - val_loss: 1.0560 - val_accuracy: 0.5661\n","Epoch 32/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9359 - accuracy: 0.6705 - val_loss: 1.0546 - val_accuracy: 0.5847\n","Epoch 33/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9316 - accuracy: 0.6780 - val_loss: 1.0500 - val_accuracy: 0.5764\n","Epoch 34/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9308 - accuracy: 0.6729 - val_loss: 1.0708 - val_accuracy: 0.5816\n","Epoch 35/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9261 - accuracy: 0.6767 - val_loss: 1.0713 - val_accuracy: 0.5692\n","Epoch 36/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9243 - accuracy: 0.6757 - val_loss: 1.0527 - val_accuracy: 0.5775\n","Epoch 37/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9186 - accuracy: 0.6786 - val_loss: 1.0485 - val_accuracy: 0.5671\n","Epoch 38/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9129 - accuracy: 0.6798 - val_loss: 1.0436 - val_accuracy: 0.5702\n","Epoch 39/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9104 - accuracy: 0.6783 - val_loss: 1.0469 - val_accuracy: 0.5733\n","Epoch 40/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9062 - accuracy: 0.6858 - val_loss: 1.0327 - val_accuracy: 0.5692\n","Epoch 41/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9048 - accuracy: 0.6829 - val_loss: 1.0351 - val_accuracy: 0.5640\n","Epoch 42/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9023 - accuracy: 0.6796 - val_loss: 1.0340 - val_accuracy: 0.5713\n","Epoch 43/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8977 - accuracy: 0.6876 - val_loss: 1.0346 - val_accuracy: 0.5651\n","Epoch 44/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8973 - accuracy: 0.6845 - val_loss: 1.0445 - val_accuracy: 0.5764\n","Epoch 45/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8898 - accuracy: 0.6933 - val_loss: 1.0378 - val_accuracy: 0.5744\n","Epoch 46/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8858 - accuracy: 0.6943 - val_loss: 1.0423 - val_accuracy: 0.5692\n","Epoch 47/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8816 - accuracy: 0.6879 - val_loss: 1.0706 - val_accuracy: 0.5620\n","Epoch 48/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8810 - accuracy: 0.6995 - val_loss: 1.0566 - val_accuracy: 0.5733\n","Epoch 49/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8772 - accuracy: 0.6953 - val_loss: 1.0525 - val_accuracy: 0.5651\n","Epoch 50/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8736 - accuracy: 0.6943 - val_loss: 1.0372 - val_accuracy: 0.5630\n","Epoch 51/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8783 - accuracy: 0.6987 - val_loss: 1.0533 - val_accuracy: 0.5579\n","Epoch 52/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8700 - accuracy: 0.7021 - val_loss: 1.0520 - val_accuracy: 0.5775\n","Epoch 53/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8646 - accuracy: 0.7023 - val_loss: 1.0277 - val_accuracy: 0.5702\n","Epoch 54/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8632 - accuracy: 0.6990 - val_loss: 1.0522 - val_accuracy: 0.5702\n","Epoch 55/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8568 - accuracy: 0.7036 - val_loss: 1.0181 - val_accuracy: 0.5661\n","Epoch 56/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8599 - accuracy: 0.6943 - val_loss: 1.0380 - val_accuracy: 0.5723\n","Epoch 57/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8548 - accuracy: 0.7016 - val_loss: 1.0159 - val_accuracy: 0.5589\n","Epoch 58/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8513 - accuracy: 0.6969 - val_loss: 1.0730 - val_accuracy: 0.5702\n","Epoch 59/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8453 - accuracy: 0.7059 - val_loss: 1.0432 - val_accuracy: 0.5661\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8472 - accuracy: 0.7016 - val_loss: 1.0242 - val_accuracy: 0.5610\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8429 - accuracy: 0.7065 - val_loss: 1.0152 - val_accuracy: 0.5599\n","Epoch 62/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8669 - accuracy: 0.6853 - val_loss: 1.1015 - val_accuracy: 0.5331\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8377 - accuracy: 0.7049 - val_loss: 1.0559 - val_accuracy: 0.5723\n","Epoch 64/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8328 - accuracy: 0.7121 - val_loss: 1.0340 - val_accuracy: 0.5713\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8296 - accuracy: 0.7129 - val_loss: 1.0491 - val_accuracy: 0.5640\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8281 - accuracy: 0.7194 - val_loss: 1.0415 - val_accuracy: 0.5640\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8245 - accuracy: 0.7109 - val_loss: 1.0451 - val_accuracy: 0.5486\n","Epoch 68/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8206 - accuracy: 0.7145 - val_loss: 1.0386 - val_accuracy: 0.5671\n","Epoch 69/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8191 - accuracy: 0.7209 - val_loss: 1.0123 - val_accuracy: 0.5630\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8190 - accuracy: 0.7209 - val_loss: 1.0434 - val_accuracy: 0.5579\n","Epoch 71/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8117 - accuracy: 0.7243 - val_loss: 1.0566 - val_accuracy: 0.5795\n","Epoch 72/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8140 - accuracy: 0.7173 - val_loss: 1.0202 - val_accuracy: 0.5568\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8084 - accuracy: 0.7173 - val_loss: 1.0240 - val_accuracy: 0.5537\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8021 - accuracy: 0.7313 - val_loss: 1.0319 - val_accuracy: 0.5702\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8025 - accuracy: 0.7310 - val_loss: 1.0488 - val_accuracy: 0.5537\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8061 - accuracy: 0.7183 - val_loss: 1.0156 - val_accuracy: 0.5568\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8035 - accuracy: 0.7212 - val_loss: 1.0380 - val_accuracy: 0.5702\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7967 - accuracy: 0.7264 - val_loss: 1.0118 - val_accuracy: 0.5620\n","Epoch 79/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7947 - accuracy: 0.7323 - val_loss: 1.0348 - val_accuracy: 0.5682\n","Epoch 80/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7888 - accuracy: 0.7269 - val_loss: 1.0280 - val_accuracy: 0.5465\n","Epoch 81/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7860 - accuracy: 0.7287 - val_loss: 1.0411 - val_accuracy: 0.5692\n","Epoch 82/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7843 - accuracy: 0.7243 - val_loss: 1.0425 - val_accuracy: 0.5455\n","Epoch 83/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7821 - accuracy: 0.7331 - val_loss: 1.0236 - val_accuracy: 0.5558\n","Epoch 84/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7848 - accuracy: 0.7227 - val_loss: 1.0356 - val_accuracy: 0.5640\n","Epoch 85/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7748 - accuracy: 0.7390 - val_loss: 1.0561 - val_accuracy: 0.5579\n","Epoch 86/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7728 - accuracy: 0.7395 - val_loss: 1.0117 - val_accuracy: 0.5682\n","Epoch 87/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7727 - accuracy: 0.7370 - val_loss: 1.0612 - val_accuracy: 0.5465\n","Epoch 88/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7714 - accuracy: 0.7434 - val_loss: 1.0513 - val_accuracy: 0.5671\n","Epoch 89/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7690 - accuracy: 0.7382 - val_loss: 1.0717 - val_accuracy: 0.5465\n","Epoch 90/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7680 - accuracy: 0.7362 - val_loss: 1.0590 - val_accuracy: 0.5713\n","Epoch 91/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7652 - accuracy: 0.7310 - val_loss: 1.0303 - val_accuracy: 0.5651\n","Epoch 92/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7614 - accuracy: 0.7382 - val_loss: 1.0587 - val_accuracy: 0.5413\n","Epoch 93/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7567 - accuracy: 0.7439 - val_loss: 1.0599 - val_accuracy: 0.5403\n","Epoch 94/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7571 - accuracy: 0.7468 - val_loss: 1.0277 - val_accuracy: 0.5568\n","Epoch 95/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7513 - accuracy: 0.7537 - val_loss: 1.0794 - val_accuracy: 0.5630\n","Epoch 96/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7512 - accuracy: 0.7450 - val_loss: 1.0410 - val_accuracy: 0.5610\n","Epoch 97/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7591 - accuracy: 0.7357 - val_loss: 1.0677 - val_accuracy: 0.5341\n","Epoch 98/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7460 - accuracy: 0.7532 - val_loss: 1.0688 - val_accuracy: 0.5651\n","Epoch 99/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7427 - accuracy: 0.7548 - val_loss: 1.0587 - val_accuracy: 0.5610\n","Epoch 100/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7430 - accuracy: 0.7522 - val_loss: 1.0800 - val_accuracy: 0.5300\n","{'loss': [1.075480341911316, 1.066088080406189, 1.0624089241027832, 1.0541521310806274, 1.049322247505188, 1.0461443662643433, 1.0397695302963257, 1.0351930856704712, 1.0300906896591187, 1.0270981788635254, 1.0225282907485962, 1.0154728889465332, 1.012184500694275, 1.0070295333862305, 1.0024452209472656, 0.9989816546440125, 0.9971814155578613, 0.9937711954116821, 0.9869108200073242, 0.9840458631515503, 0.9784358739852905, 0.9751131534576416, 0.9698010087013245, 0.9717346429824829, 0.9645293951034546, 0.9579087495803833, 0.9557679891586304, 0.9497336149215698, 0.9472997188568115, 0.9454293251037598, 0.9414191246032715, 0.9358570575714111, 0.9315828680992126, 0.9308348894119263, 0.9260650873184204, 0.9243285655975342, 0.9186439514160156, 0.9128673672676086, 0.9104432463645935, 0.906230092048645, 0.9047930240631104, 0.9022648930549622, 0.8976883888244629, 0.8973321914672852, 0.8897573351860046, 0.8858245611190796, 0.8816380500793457, 0.8809696435928345, 0.8771927356719971, 0.8736242055892944, 0.8783162832260132, 0.8700019121170044, 0.8645960688591003, 0.8632237911224365, 0.8567603826522827, 0.8598917722702026, 0.8547597527503967, 0.8513100743293762, 0.8453434109687805, 0.8472339510917664, 0.8428929448127747, 0.866901695728302, 0.8377042412757874, 0.8328273296356201, 0.8295565247535706, 0.8280831575393677, 0.8245176076889038, 0.8206479549407959, 0.819075882434845, 0.8190097212791443, 0.8117377758026123, 0.8139669299125671, 0.808434247970581, 0.8021225333213806, 0.8025429248809814, 0.8060846328735352, 0.8035380244255066, 0.7966633439064026, 0.7946661710739136, 0.7887994050979614, 0.7859971523284912, 0.78432697057724, 0.7821176648139954, 0.7848436832427979, 0.7748298048973083, 0.7728217244148254, 0.7726728916168213, 0.771358072757721, 0.769048273563385, 0.7680403590202332, 0.7652407288551331, 0.761437714099884, 0.7567288279533386, 0.7571314573287964, 0.7512953877449036, 0.7512300610542297, 0.7590818405151367, 0.7460463047027588, 0.7427224516868591, 0.7429665327072144], 'accuracy': [0.6279069781303406, 0.6322997212409973, 0.6356589198112488, 0.6447028517723083, 0.6441860198974609, 0.6441860198974609, 0.6423772573471069, 0.6454780101776123, 0.646253228187561, 0.6472868323326111, 0.6550387740135193, 0.6542635560035706, 0.6521964073181152, 0.6527131795883179, 0.6558139324188232, 0.6571059226989746, 0.6529715657234192, 0.6511628031730652, 0.6627907156944275, 0.6573643684387207, 0.6555555462837219, 0.6645994782447815, 0.6630491018295288, 0.6571059226989746, 0.6633074879646301, 0.6705426573753357, 0.6718346476554871, 0.6741601824760437, 0.6772609949111938, 0.6643410921096802, 0.667958676815033, 0.6705426573753357, 0.6780361533164978, 0.6728681921958923, 0.6767441630363464, 0.6757106184959412, 0.6785529851913452, 0.6798449754714966, 0.6782945990562439, 0.685788094997406, 0.682945728302002, 0.6795865893363953, 0.6875969171524048, 0.6844961047172546, 0.6932816505432129, 0.6943152546882629, 0.6878553032875061, 0.6994832158088684, 0.695348858833313, 0.6943152546882629, 0.6987079977989197, 0.7020671963691711, 0.7023255825042725, 0.698966383934021, 0.7036175727844238, 0.6943152546882629, 0.7015503644943237, 0.6968992352485657, 0.7059431672096252, 0.7015503644943237, 0.7064599394798279, 0.6852713227272034, 0.7049095630645752, 0.7121447324752808, 0.7129198908805847, 0.7193798422813416, 0.7108527421951294, 0.7144702672958374, 0.7209302186965942, 0.7209302186965942, 0.7242894172668457, 0.7173126339912415, 0.7173126339912415, 0.7312661409378052, 0.7310077548027039, 0.7183462381362915, 0.7211886048316956, 0.726356565952301, 0.7322997450828552, 0.7268733978271484, 0.7286821603775024, 0.7242894172668457, 0.733074963092804, 0.722739040851593, 0.7390180826187134, 0.739534854888916, 0.7369509339332581, 0.7434108257293701, 0.7382428646087646, 0.7361757159233093, 0.7310077548027039, 0.7382428646087646, 0.7439276576042175, 0.7467700242996216, 0.753746747970581, 0.7449612617492676, 0.7356589436531067, 0.7532299757003784, 0.7547803521156311, 0.7521963715553284], 'val_loss': [1.136744737625122, 1.1325684785842896, 1.1284065246582031, 1.1239421367645264, 1.119889736175537, 1.1158989667892456, 1.1116095781326294, 1.1086208820343018, 1.1027785539627075, 1.0988067388534546, 1.0936405658721924, 1.0895477533340454, 1.0858441591262817, 1.0809931755065918, 1.0766340494155884, 1.0742771625518799, 1.068604826927185, 1.0647704601287842, 1.0640493631362915, 1.0683457851409912, 1.0581961870193481, 1.0644205808639526, 1.0559067726135254, 1.0722815990447998, 1.0602494478225708, 1.063844084739685, 1.0618857145309448, 1.0501387119293213, 1.0576955080032349, 1.0543378591537476, 1.0560308694839478, 1.0545599460601807, 1.0500433444976807, 1.0707566738128662, 1.0712921619415283, 1.0526963472366333, 1.0484524965286255, 1.0436068773269653, 1.0469107627868652, 1.0327249765396118, 1.0351489782333374, 1.0340245962142944, 1.034577488899231, 1.044472575187683, 1.037806510925293, 1.0423243045806885, 1.0706335306167603, 1.056572437286377, 1.0524663925170898, 1.0371819734573364, 1.053349494934082, 1.0519877672195435, 1.02768874168396, 1.0522270202636719, 1.0180742740631104, 1.0380010604858398, 1.0159087181091309, 1.0730328559875488, 1.0432325601577759, 1.0241658687591553, 1.0151803493499756, 1.1014610528945923, 1.0558818578720093, 1.0339958667755127, 1.0490738153457642, 1.0414859056472778, 1.045119047164917, 1.0385664701461792, 1.0123478174209595, 1.0434356927871704, 1.0566320419311523, 1.020218014717102, 1.0240215063095093, 1.0319305658340454, 1.0488462448120117, 1.0155683755874634, 1.0379756689071655, 1.0118416547775269, 1.034789800643921, 1.0280423164367676, 1.041061520576477, 1.0424998998641968, 1.0235611200332642, 1.0355781316757202, 1.0560812950134277, 1.0116667747497559, 1.061225414276123, 1.051310658454895, 1.0717005729675293, 1.059048056602478, 1.0303326845169067, 1.058716058731079, 1.0598558187484741, 1.0277482271194458, 1.0793793201446533, 1.0410445928573608, 1.0676733255386353, 1.0688115358352661, 1.0586506128311157, 1.079966425895691], 'val_accuracy': [0.5144628286361694, 0.5165289044380188, 0.5165289044380188, 0.5206611752510071, 0.5268595218658447, 0.5268595218658447, 0.5320248007774353, 0.5361570119857788, 0.53925621509552, 0.5402892827987671, 0.5495867729187012, 0.547520637512207, 0.5557851195335388, 0.5516529083251953, 0.5630165338516235, 0.567148745059967, 0.5630165338516235, 0.5723140239715576, 0.5568181872367859, 0.577479362487793, 0.5681818127632141, 0.5692148804664612, 0.5650826692581177, 0.577479362487793, 0.5795454382896423, 0.5836777091026306, 0.5702479481697083, 0.5681818127632141, 0.5785123705863953, 0.5650826692581177, 0.56611567735672, 0.5847107172012329, 0.5764462947845459, 0.5816115736961365, 0.5692148804664612, 0.577479362487793, 0.567148745059967, 0.5702479481697083, 0.5733470916748047, 0.5692148804664612, 0.5640496015548706, 0.5712810158729553, 0.5650826692581177, 0.5764462947845459, 0.5743801593780518, 0.5692148804664612, 0.5619834661483765, 0.5733470916748047, 0.5650826692581177, 0.5630165338516235, 0.557851254940033, 0.577479362487793, 0.5702479481697083, 0.5702479481697083, 0.56611567735672, 0.5723140239715576, 0.55888432264328, 0.5702479481697083, 0.56611567735672, 0.5609503984451294, 0.5599173307418823, 0.5330578684806824, 0.5723140239715576, 0.5712810158729553, 0.5640496015548706, 0.5640496015548706, 0.5485537052154541, 0.567148745059967, 0.5630165338516235, 0.557851254940033, 0.5795454382896423, 0.5568181872367859, 0.5537189841270447, 0.5702479481697083, 0.5537189841270447, 0.5568181872367859, 0.5702479481697083, 0.5619834661483765, 0.5681818127632141, 0.5464876294136047, 0.5692148804664612, 0.5454545617103577, 0.5557851195335388, 0.5640496015548706, 0.557851254940033, 0.5681818127632141, 0.5464876294136047, 0.567148745059967, 0.5464876294136047, 0.5712810158729553, 0.5650826692581177, 0.5413222908973694, 0.5402892827987671, 0.5568181872367859, 0.5630165338516235, 0.5609503984451294, 0.5340909361839294, 0.5650826692581177, 0.5609503984451294, 0.5299586653709412]}\n","32/32 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 27ms/step - loss: 0.7886 - accuracy: 0.7139 - val_loss: 0.9497 - val_accuracy: 0.5399\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.7773 - accuracy: 0.7188"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 16ms/step - loss: 0.7853 - accuracy: 0.7139 - val_loss: 0.9513 - val_accuracy: 0.5776\n","Epoch 3/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7738 - accuracy: 0.7223 - val_loss: 0.9503 - val_accuracy: 0.5474\n","Epoch 4/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7697 - accuracy: 0.7320 - val_loss: 0.9478 - val_accuracy: 0.5226\n","Epoch 5/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7666 - accuracy: 0.7228 - val_loss: 0.9428 - val_accuracy: 0.5776\n","Epoch 6/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7617 - accuracy: 0.7425 - val_loss: 0.9435 - val_accuracy: 0.5927\n","Epoch 7/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7598 - accuracy: 0.7249 - val_loss: 0.9385 - val_accuracy: 0.5431\n","Epoch 8/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7566 - accuracy: 0.7279 - val_loss: 0.9331 - val_accuracy: 0.5894\n","Epoch 9/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7503 - accuracy: 0.7425 - val_loss: 0.9381 - val_accuracy: 0.5862\n","Epoch 10/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7502 - accuracy: 0.7322 - val_loss: 0.9353 - val_accuracy: 0.5690\n","Epoch 11/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7457 - accuracy: 0.7443 - val_loss: 0.9274 - val_accuracy: 0.5700\n","Epoch 12/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7487 - accuracy: 0.7414 - val_loss: 0.9342 - val_accuracy: 0.5420\n","Epoch 13/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7411 - accuracy: 0.7430 - val_loss: 0.9220 - val_accuracy: 0.5776\n","Epoch 14/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7415 - accuracy: 0.7390 - val_loss: 0.9163 - val_accuracy: 0.5765\n","Epoch 15/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7385 - accuracy: 0.7473 - val_loss: 0.9213 - val_accuracy: 0.5905\n","Epoch 16/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7347 - accuracy: 0.7495 - val_loss: 0.9282 - val_accuracy: 0.6250\n","Epoch 17/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7345 - accuracy: 0.7508 - val_loss: 0.9254 - val_accuracy: 0.5970\n","Epoch 18/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7270 - accuracy: 0.7578 - val_loss: 0.9084 - val_accuracy: 0.6218\n","Epoch 19/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7251 - accuracy: 0.7578 - val_loss: 0.9048 - val_accuracy: 0.6304\n","Epoch 20/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.7244 - accuracy: 0.7586 - val_loss: 0.8983 - val_accuracy: 0.6379\n","Epoch 21/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7248 - accuracy: 0.7573 - val_loss: 0.9182 - val_accuracy: 0.6390\n","Epoch 22/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7192 - accuracy: 0.7594 - val_loss: 0.9155 - val_accuracy: 0.6272\n","Epoch 23/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7178 - accuracy: 0.7627 - val_loss: 0.9191 - val_accuracy: 0.6401\n","Epoch 24/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7169 - accuracy: 0.7597 - val_loss: 0.9650 - val_accuracy: 0.6336\n","Epoch 25/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7178 - accuracy: 0.7559 - val_loss: 0.9741 - val_accuracy: 0.5981\n","Epoch 26/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7116 - accuracy: 0.7565 - val_loss: 0.9522 - val_accuracy: 0.6422\n","Epoch 27/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7082 - accuracy: 0.7694 - val_loss: 0.9914 - val_accuracy: 0.6261\n","Epoch 28/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7114 - accuracy: 0.7675 - val_loss: 0.9461 - val_accuracy: 0.6347\n","Epoch 29/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7100 - accuracy: 0.7608 - val_loss: 0.9674 - val_accuracy: 0.6487\n","Epoch 30/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6999 - accuracy: 0.7680 - val_loss: 0.9453 - val_accuracy: 0.6401\n","Epoch 31/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7006 - accuracy: 0.7637 - val_loss: 0.9654 - val_accuracy: 0.6390\n","Epoch 32/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6992 - accuracy: 0.7751 - val_loss: 0.9766 - val_accuracy: 0.6412\n","Epoch 33/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6972 - accuracy: 0.7670 - val_loss: 1.0239 - val_accuracy: 0.6433\n","Epoch 34/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7020 - accuracy: 0.7675 - val_loss: 1.0190 - val_accuracy: 0.6358\n","Epoch 35/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6925 - accuracy: 0.7702 - val_loss: 0.9802 - val_accuracy: 0.6466\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6929 - accuracy: 0.7775 - val_loss: 0.9821 - val_accuracy: 0.6498\n","Epoch 37/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6870 - accuracy: 0.7818 - val_loss: 0.9699 - val_accuracy: 0.6466\n","Epoch 38/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6875 - accuracy: 0.7775 - val_loss: 1.0124 - val_accuracy: 0.6422\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6824 - accuracy: 0.7761 - val_loss: 0.9824 - val_accuracy: 0.6390\n","Epoch 40/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6819 - accuracy: 0.7775 - val_loss: 0.9978 - val_accuracy: 0.6466\n","Epoch 41/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6939 - accuracy: 0.7734 - val_loss: 1.0051 - val_accuracy: 0.6498\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6963 - accuracy: 0.7648 - val_loss: 0.9851 - val_accuracy: 0.6530\n","Epoch 43/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6846 - accuracy: 0.7786 - val_loss: 1.0736 - val_accuracy: 0.6325\n","Epoch 44/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6896 - accuracy: 0.7745 - val_loss: 1.0643 - val_accuracy: 0.6078\n","Epoch 45/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6749 - accuracy: 0.7807 - val_loss: 0.9921 - val_accuracy: 0.6466\n","Epoch 46/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6691 - accuracy: 0.7880 - val_loss: 1.0086 - val_accuracy: 0.6379\n","Epoch 47/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6663 - accuracy: 0.7872 - val_loss: 1.0190 - val_accuracy: 0.6422\n","Epoch 48/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6653 - accuracy: 0.7899 - val_loss: 1.0266 - val_accuracy: 0.6401\n","Epoch 49/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6635 - accuracy: 0.7901 - val_loss: 1.0511 - val_accuracy: 0.6315\n","Epoch 50/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6688 - accuracy: 0.7858 - val_loss: 1.0093 - val_accuracy: 0.6455\n","Epoch 51/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6606 - accuracy: 0.7874 - val_loss: 1.0498 - val_accuracy: 0.6379\n","Epoch 52/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6608 - accuracy: 0.7883 - val_loss: 1.0280 - val_accuracy: 0.6347\n","Epoch 53/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6570 - accuracy: 0.7953 - val_loss: 1.0467 - val_accuracy: 0.6315\n","Epoch 54/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6520 - accuracy: 0.7977 - val_loss: 1.0433 - val_accuracy: 0.6207\n","Epoch 55/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6539 - accuracy: 0.7907 - val_loss: 1.0194 - val_accuracy: 0.6282\n","Epoch 56/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6544 - accuracy: 0.7864 - val_loss: 1.0264 - val_accuracy: 0.6315\n","Epoch 57/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6537 - accuracy: 0.7923 - val_loss: 1.0312 - val_accuracy: 0.6369\n","Epoch 58/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6486 - accuracy: 0.7969 - val_loss: 1.0501 - val_accuracy: 0.6261\n","Epoch 59/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6524 - accuracy: 0.7856 - val_loss: 1.0061 - val_accuracy: 0.6369\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6485 - accuracy: 0.7896 - val_loss: 1.0135 - val_accuracy: 0.6304\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6467 - accuracy: 0.7963 - val_loss: 1.0344 - val_accuracy: 0.6347\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6467 - accuracy: 0.7928 - val_loss: 1.0697 - val_accuracy: 0.6164\n","Epoch 63/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6366 - accuracy: 0.8020 - val_loss: 1.0686 - val_accuracy: 0.6401\n","Epoch 64/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6334 - accuracy: 0.8101 - val_loss: 1.0856 - val_accuracy: 0.5927\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6341 - accuracy: 0.8112 - val_loss: 1.0419 - val_accuracy: 0.6239\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6359 - accuracy: 0.8006 - val_loss: 1.0478 - val_accuracy: 0.6272\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6295 - accuracy: 0.8090 - val_loss: 1.0889 - val_accuracy: 0.6207\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6292 - accuracy: 0.8023 - val_loss: 1.0662 - val_accuracy: 0.6261\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6382 - accuracy: 0.7998 - val_loss: 1.0905 - val_accuracy: 0.6282\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6290 - accuracy: 0.8063 - val_loss: 1.0594 - val_accuracy: 0.6315\n","Epoch 71/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6268 - accuracy: 0.8044 - val_loss: 1.0668 - val_accuracy: 0.6282\n","Epoch 72/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6186 - accuracy: 0.8117 - val_loss: 1.0534 - val_accuracy: 0.6261\n","Epoch 73/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6203 - accuracy: 0.8128 - val_loss: 1.0929 - val_accuracy: 0.6401\n","Epoch 74/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6196 - accuracy: 0.8103 - val_loss: 1.1113 - val_accuracy: 0.6196\n","Epoch 75/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6159 - accuracy: 0.8060 - val_loss: 1.0650 - val_accuracy: 0.6250\n","Epoch 76/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6203 - accuracy: 0.8163 - val_loss: 1.1185 - val_accuracy: 0.6153\n","Epoch 77/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6216 - accuracy: 0.8133 - val_loss: 1.0966 - val_accuracy: 0.6228\n","Epoch 78/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6163 - accuracy: 0.8171 - val_loss: 1.1005 - val_accuracy: 0.6250\n","Epoch 79/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6104 - accuracy: 0.8222 - val_loss: 1.1490 - val_accuracy: 0.6088\n","Epoch 80/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6065 - accuracy: 0.8217 - val_loss: 1.1116 - val_accuracy: 0.6142\n","Epoch 81/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6067 - accuracy: 0.8171 - val_loss: 1.1477 - val_accuracy: 0.5916\n","Epoch 82/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6067 - accuracy: 0.8187 - val_loss: 1.0866 - val_accuracy: 0.6110\n","Epoch 83/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6134 - accuracy: 0.8112 - val_loss: 1.0832 - val_accuracy: 0.6218\n","Epoch 84/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6044 - accuracy: 0.8184 - val_loss: 1.1616 - val_accuracy: 0.6153\n","Epoch 85/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6062 - accuracy: 0.8203 - val_loss: 1.0953 - val_accuracy: 0.6293\n","Epoch 86/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6071 - accuracy: 0.8165 - val_loss: 1.1411 - val_accuracy: 0.6121\n","Epoch 87/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5915 - accuracy: 0.8349 - val_loss: 1.1010 - val_accuracy: 0.6175\n","Epoch 88/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5951 - accuracy: 0.8262 - val_loss: 1.0839 - val_accuracy: 0.6164\n","Epoch 89/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5985 - accuracy: 0.8241 - val_loss: 1.0808 - val_accuracy: 0.6304\n","Epoch 90/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5963 - accuracy: 0.8254 - val_loss: 1.1522 - val_accuracy: 0.6282\n","Epoch 91/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6025 - accuracy: 0.8152 - val_loss: 1.0944 - val_accuracy: 0.6153\n","Epoch 92/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5965 - accuracy: 0.8190 - val_loss: 1.1979 - val_accuracy: 0.6282\n","Epoch 93/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5994 - accuracy: 0.8268 - val_loss: 1.1427 - val_accuracy: 0.6131\n","Epoch 94/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5884 - accuracy: 0.8273 - val_loss: 1.1187 - val_accuracy: 0.6336\n","Epoch 95/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5811 - accuracy: 0.8384 - val_loss: 1.0977 - val_accuracy: 0.6153\n","Epoch 96/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5800 - accuracy: 0.8365 - val_loss: 1.0902 - val_accuracy: 0.6261\n","Epoch 97/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5826 - accuracy: 0.8297 - val_loss: 1.1561 - val_accuracy: 0.6002\n","Epoch 98/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5970 - accuracy: 0.8055 - val_loss: 1.1425 - val_accuracy: 0.6218\n","Epoch 99/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5808 - accuracy: 0.8332 - val_loss: 1.1096 - val_accuracy: 0.6304\n","Epoch 100/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5808 - accuracy: 0.8389 - val_loss: 1.1509 - val_accuracy: 0.6142\n","{'loss': [0.7886468768119812, 0.7853407859802246, 0.7738355994224548, 0.7697020769119263, 0.7665882110595703, 0.7617026567459106, 0.7598341107368469, 0.7566414475440979, 0.7503039836883545, 0.7502488493919373, 0.7457279562950134, 0.748669445514679, 0.7410871982574463, 0.7414889335632324, 0.738539457321167, 0.7346948981285095, 0.7345336675643921, 0.7270209789276123, 0.7250753045082092, 0.7244499921798706, 0.7247925400733948, 0.7192330956459045, 0.7178369760513306, 0.7169303894042969, 0.717814564704895, 0.7116305828094482, 0.7082221508026123, 0.7114494442939758, 0.7100352048873901, 0.699949324131012, 0.7005767226219177, 0.6991960406303406, 0.6971747279167175, 0.7020347714424133, 0.6925370693206787, 0.6929148435592651, 0.6870310306549072, 0.6875049471855164, 0.6824074387550354, 0.681900680065155, 0.6939456462860107, 0.6962563991546631, 0.6845797300338745, 0.6896373629570007, 0.6748502850532532, 0.6691297888755798, 0.6662530303001404, 0.665276288986206, 0.6634795665740967, 0.6688097715377808, 0.6606497168540955, 0.6608297824859619, 0.6570305824279785, 0.6519506573677063, 0.6538786292076111, 0.6544381380081177, 0.6537285447120667, 0.6485724449157715, 0.6523982286453247, 0.6484665274620056, 0.6466572880744934, 0.6467390656471252, 0.6366124153137207, 0.6333690285682678, 0.6341142058372498, 0.6358659267425537, 0.6294763684272766, 0.6291911602020264, 0.6382250785827637, 0.6290392279624939, 0.6268087029457092, 0.6185756921768188, 0.6202549934387207, 0.6196288466453552, 0.6158588528633118, 0.6202991008758545, 0.6216037273406982, 0.6163111925125122, 0.6103581786155701, 0.6064682602882385, 0.6067319512367249, 0.6067426800727844, 0.6134324073791504, 0.6043829321861267, 0.606243908405304, 0.6071317791938782, 0.5914954543113708, 0.5951194763183594, 0.5984573364257812, 0.5962854623794556, 0.6024603843688965, 0.5965127348899841, 0.599359393119812, 0.5883896946907043, 0.581107497215271, 0.5800018906593323, 0.5826136469841003, 0.596960723400116, 0.5808029174804688, 0.580845296382904], 'accuracy': [0.7139008641242981, 0.7139008641242981, 0.7222521305084229, 0.7319504022598267, 0.7227909564971924, 0.7424569129943848, 0.724946141242981, 0.727909505367279, 0.7424569129943848, 0.7322198152542114, 0.7443426847457886, 0.7413793206214905, 0.7429956793785095, 0.7389547228813171, 0.7473060488700867, 0.7494612336158752, 0.7508081793785095, 0.7578125, 0.7578125, 0.7586206793785095, 0.7572737336158752, 0.759428858757019, 0.7626616358757019, 0.7596982717514038, 0.7559267282485962, 0.756465494632721, 0.7693965435028076, 0.7675107717514038, 0.7607758641242981, 0.7680495977401733, 0.7637392282485962, 0.775053858757019, 0.766972005367279, 0.7675107717514038, 0.7702047228813171, 0.7774784564971924, 0.7817887663841248, 0.7774784564971924, 0.7761314511299133, 0.7774784564971924, 0.7734375, 0.7648168206214905, 0.7785560488700867, 0.7745150923728943, 0.7807112336158752, 0.7879849076271057, 0.7871767282485962, 0.7898706793785095, 0.7901400923728943, 0.7858297228813171, 0.787446141242981, 0.7882543206214905, 0.795258641242981, 0.7976831793785095, 0.790678858757019, 0.7863685488700867, 0.7922952771186829, 0.796875, 0.7855603694915771, 0.7896012663841248, 0.7963362336158752, 0.7928340435028076, 0.8019935488700867, 0.8100754022598267, 0.811152994632721, 0.8006465435028076, 0.8089978694915771, 0.8022629022598267, 0.7998383641242981, 0.806303858757019, 0.8044180870056152, 0.8116918206214905, 0.8127694129943848, 0.8103448152542114, 0.806034505367279, 0.8162715435028076, 0.8133081793785095, 0.8170797228813171, 0.8221982717514038, 0.821659505367279, 0.8170797228813171, 0.818696141242981, 0.811152994632721, 0.8184267282485962, 0.8203125, 0.8165409564971924, 0.8348599076271057, 0.8262392282485962, 0.8240840435028076, 0.8254310488700867, 0.8151939511299133, 0.818965494632721, 0.826777994632721, 0.8273168206214905, 0.8383620977401733, 0.8364762663841248, 0.829741358757019, 0.8054956793785095, 0.8332435488700867, 0.8389008641242981], 'val_loss': [0.9497352242469788, 0.9512665271759033, 0.9503225088119507, 0.947838306427002, 0.9428417086601257, 0.9434771537780762, 0.9384924173355103, 0.9331380724906921, 0.9381319284439087, 0.9352760314941406, 0.9274411201477051, 0.9342283010482788, 0.9220396280288696, 0.9163246750831604, 0.9213479161262512, 0.9282353520393372, 0.9254051446914673, 0.908420741558075, 0.9048341512680054, 0.8982881307601929, 0.918180525302887, 0.9155161380767822, 0.9191257357597351, 0.9650350213050842, 0.9741075038909912, 0.9522137641906738, 0.991427481174469, 0.9461305737495422, 0.9673912525177002, 0.9453475475311279, 0.9653688669204712, 0.9765913486480713, 1.0239408016204834, 1.0189813375473022, 0.9801695346832275, 0.9821376800537109, 0.969895601272583, 1.0124353170394897, 0.982390284538269, 0.9977790713310242, 1.0051400661468506, 0.9851071834564209, 1.0736281871795654, 1.0643393993377686, 0.9921464323997498, 1.008590579032898, 1.0190362930297852, 1.026577353477478, 1.0511243343353271, 1.0093046426773071, 1.049778699874878, 1.0280097723007202, 1.0467188358306885, 1.043291449546814, 1.0193735361099243, 1.0264458656311035, 1.0312230587005615, 1.0501189231872559, 1.006133794784546, 1.0134965181350708, 1.0343526601791382, 1.0697474479675293, 1.0685864686965942, 1.085632562637329, 1.0418696403503418, 1.0477594137191772, 1.0888630151748657, 1.066169261932373, 1.0904669761657715, 1.0593575239181519, 1.0667848587036133, 1.0534353256225586, 1.092862844467163, 1.111278772354126, 1.0650053024291992, 1.1184751987457275, 1.0966212749481201, 1.1004927158355713, 1.1489698886871338, 1.1115864515304565, 1.1476935148239136, 1.0866427421569824, 1.0832045078277588, 1.161560297012329, 1.0952564477920532, 1.141111135482788, 1.1010386943817139, 1.0839307308197021, 1.0807874202728271, 1.1522116661071777, 1.0944116115570068, 1.1979193687438965, 1.1426926851272583, 1.1186715364456177, 1.097700595855713, 1.0901652574539185, 1.1560518741607666, 1.1425278186798096, 1.1095958948135376, 1.1509122848510742], 'val_accuracy': [0.5398706793785095, 0.5775862336158752, 0.5474137663841248, 0.5226293206214905, 0.5775862336158752, 0.5926724076271057, 0.5431034564971924, 0.5894396305084229, 0.5862069129943848, 0.568965494632721, 0.5700430870056152, 0.5420258641242981, 0.5775862336158752, 0.576508641242981, 0.5905172228813171, 0.625, 0.5969827771186829, 0.6217672228813171, 0.6303879022598267, 0.6379310488700867, 0.639008641242981, 0.6271551847457886, 0.6400862336158752, 0.6336206793785095, 0.5980603694915771, 0.642241358757019, 0.6260775923728943, 0.6346982717514038, 0.6487069129943848, 0.6400862336158752, 0.639008641242981, 0.6411637663841248, 0.6433189511299133, 0.6357758641242981, 0.6465517282485962, 0.649784505367279, 0.6465517282485962, 0.642241358757019, 0.639008641242981, 0.6465517282485962, 0.649784505367279, 0.6530172228813171, 0.6325430870056152, 0.607758641242981, 0.6465517282485962, 0.6379310488700867, 0.642241358757019, 0.6400862336158752, 0.631465494632721, 0.6454741358757019, 0.6379310488700867, 0.6346982717514038, 0.631465494632721, 0.6206896305084229, 0.6282327771186829, 0.631465494632721, 0.6368534564971924, 0.6260775923728943, 0.6368534564971924, 0.6303879022598267, 0.6346982717514038, 0.6163793206214905, 0.6400862336158752, 0.5926724076271057, 0.6239224076271057, 0.6271551847457886, 0.6206896305084229, 0.6260775923728943, 0.6282327771186829, 0.631465494632721, 0.6282327771186829, 0.6260775923728943, 0.6400862336158752, 0.6196120977401733, 0.625, 0.6153017282485962, 0.6228448152542114, 0.625, 0.6088362336158752, 0.6142241358757019, 0.5915948152542114, 0.610991358757019, 0.6217672228813171, 0.6153017282485962, 0.6293103694915771, 0.6120689511299133, 0.6174569129943848, 0.6163793206214905, 0.6303879022598267, 0.6282327771186829, 0.6153017282485962, 0.6282327771186829, 0.6131465435028076, 0.6336206793785095, 0.6153017282485962, 0.6260775923728943, 0.600215494632721, 0.6217672228813171, 0.6303879022598267, 0.6142241358757019]}\n","38/38 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 3s 28ms/step - loss: 0.7871 - accuracy: 0.7153 - val_loss: 0.9511 - val_accuracy: 0.5339\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.8675 - accuracy: 0.6250"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 11ms/step - loss: 0.7707 - accuracy: 0.7289 - val_loss: 0.9565 - val_accuracy: 0.5136\n","Epoch 3/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7687 - accuracy: 0.7289 - val_loss: 0.9485 - val_accuracy: 0.5362\n","Epoch 4/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7658 - accuracy: 0.7394 - val_loss: 0.9456 - val_accuracy: 0.5611\n","Epoch 5/100\n","28/28 [==============================] - 1s 40ms/step - loss: 0.7604 - accuracy: 0.7346 - val_loss: 0.9422 - val_accuracy: 0.5622\n","Epoch 6/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7552 - accuracy: 0.7456 - val_loss: 0.9433 - val_accuracy: 0.5407\n","Epoch 7/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7553 - accuracy: 0.7357 - val_loss: 0.9361 - val_accuracy: 0.5543\n","Epoch 8/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7528 - accuracy: 0.7411 - val_loss: 0.9342 - val_accuracy: 0.5532\n","Epoch 9/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7499 - accuracy: 0.7411 - val_loss: 0.9292 - val_accuracy: 0.5995\n","Epoch 10/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7455 - accuracy: 0.7533 - val_loss: 0.9273 - val_accuracy: 0.6007\n","Epoch 11/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7381 - accuracy: 0.7507 - val_loss: 0.9224 - val_accuracy: 0.5701\n","Epoch 12/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7460 - accuracy: 0.7544 - val_loss: 0.9214 - val_accuracy: 0.5769\n","Epoch 13/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7417 - accuracy: 0.7507 - val_loss: 0.9209 - val_accuracy: 0.6007\n","Epoch 14/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7399 - accuracy: 0.7496 - val_loss: 0.9140 - val_accuracy: 0.5894\n","Epoch 15/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7371 - accuracy: 0.7589 - val_loss: 0.9052 - val_accuracy: 0.6210\n","Epoch 16/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7363 - accuracy: 0.7445 - val_loss: 0.9053 - val_accuracy: 0.6233\n","Epoch 17/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7273 - accuracy: 0.7632 - val_loss: 0.9021 - val_accuracy: 0.6143\n","Epoch 18/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7250 - accuracy: 0.7629 - val_loss: 0.9012 - val_accuracy: 0.6278\n","Epoch 19/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7316 - accuracy: 0.7499 - val_loss: 0.9034 - val_accuracy: 0.6256\n","Epoch 20/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7206 - accuracy: 0.7620 - val_loss: 0.9063 - val_accuracy: 0.6109\n","Epoch 21/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7283 - accuracy: 0.7493 - val_loss: 0.9053 - val_accuracy: 0.6176\n","Epoch 22/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7244 - accuracy: 0.7516 - val_loss: 0.9050 - val_accuracy: 0.6391\n","Epoch 23/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7151 - accuracy: 0.7595 - val_loss: 0.8978 - val_accuracy: 0.6346\n","Epoch 24/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7166 - accuracy: 0.7595 - val_loss: 0.9076 - val_accuracy: 0.6290\n","Epoch 25/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7119 - accuracy: 0.7663 - val_loss: 0.9095 - val_accuracy: 0.6369\n","Epoch 26/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7061 - accuracy: 0.7753 - val_loss: 0.9240 - val_accuracy: 0.6448\n","Epoch 27/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7179 - accuracy: 0.7657 - val_loss: 0.9307 - val_accuracy: 0.6403\n","Epoch 28/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7100 - accuracy: 0.7697 - val_loss: 0.9329 - val_accuracy: 0.6267\n","Epoch 29/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7031 - accuracy: 0.7716 - val_loss: 0.9377 - val_accuracy: 0.6346\n","Epoch 30/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6992 - accuracy: 0.7762 - val_loss: 0.9348 - val_accuracy: 0.6380\n","Epoch 31/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6962 - accuracy: 0.7796 - val_loss: 0.9391 - val_accuracy: 0.6527\n","Epoch 32/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6954 - accuracy: 0.7818 - val_loss: 0.9507 - val_accuracy: 0.6369\n","Epoch 33/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7027 - accuracy: 0.7654 - val_loss: 0.9644 - val_accuracy: 0.6346\n","Epoch 34/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7047 - accuracy: 0.7722 - val_loss: 0.9652 - val_accuracy: 0.6256\n","Epoch 35/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6954 - accuracy: 0.7824 - val_loss: 0.9568 - val_accuracy: 0.6437\n","Epoch 36/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6910 - accuracy: 0.7844 - val_loss: 0.9582 - val_accuracy: 0.6335\n","Epoch 37/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6910 - accuracy: 0.7796 - val_loss: 0.9584 - val_accuracy: 0.6380\n","Epoch 38/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6882 - accuracy: 0.7898 - val_loss: 0.9698 - val_accuracy: 0.6369\n","Epoch 39/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6856 - accuracy: 0.7813 - val_loss: 0.9640 - val_accuracy: 0.6403\n","Epoch 40/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6812 - accuracy: 0.7827 - val_loss: 0.9762 - val_accuracy: 0.6312\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6917 - accuracy: 0.7736 - val_loss: 0.9952 - val_accuracy: 0.6346\n","Epoch 42/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6783 - accuracy: 0.7861 - val_loss: 0.9729 - val_accuracy: 0.6346\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6797 - accuracy: 0.7787 - val_loss: 0.9928 - val_accuracy: 0.6267\n","Epoch 44/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6746 - accuracy: 0.7932 - val_loss: 0.9786 - val_accuracy: 0.6335\n","Epoch 45/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6724 - accuracy: 0.7957 - val_loss: 0.9624 - val_accuracy: 0.6324\n","Epoch 46/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6736 - accuracy: 0.7847 - val_loss: 0.9715 - val_accuracy: 0.6346\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6698 - accuracy: 0.7900 - val_loss: 0.9910 - val_accuracy: 0.6210\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6794 - accuracy: 0.7776 - val_loss: 0.9593 - val_accuracy: 0.6403\n","Epoch 49/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6713 - accuracy: 0.7864 - val_loss: 0.9961 - val_accuracy: 0.6335\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6626 - accuracy: 0.7963 - val_loss: 0.9791 - val_accuracy: 0.6290\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6577 - accuracy: 0.8005 - val_loss: 0.9962 - val_accuracy: 0.6278\n","Epoch 52/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6669 - accuracy: 0.7957 - val_loss: 0.9759 - val_accuracy: 0.6403\n","Epoch 53/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6582 - accuracy: 0.7957 - val_loss: 1.0108 - val_accuracy: 0.6278\n","Epoch 54/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6584 - accuracy: 0.8039 - val_loss: 0.9949 - val_accuracy: 0.6278\n","Epoch 55/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6576 - accuracy: 0.7872 - val_loss: 0.9972 - val_accuracy: 0.6290\n","Epoch 56/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6525 - accuracy: 0.7994 - val_loss: 1.0021 - val_accuracy: 0.6369\n","Epoch 57/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6542 - accuracy: 0.7940 - val_loss: 1.0120 - val_accuracy: 0.6278\n","Epoch 58/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6582 - accuracy: 0.7988 - val_loss: 1.0510 - val_accuracy: 0.6471\n","Epoch 59/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6531 - accuracy: 0.7940 - val_loss: 1.0183 - val_accuracy: 0.6222\n","Epoch 60/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6479 - accuracy: 0.7985 - val_loss: 1.0091 - val_accuracy: 0.6244\n","Epoch 61/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6425 - accuracy: 0.8090 - val_loss: 1.0027 - val_accuracy: 0.6346\n","Epoch 62/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6397 - accuracy: 0.8050 - val_loss: 1.0190 - val_accuracy: 0.6188\n","Epoch 63/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6393 - accuracy: 0.8067 - val_loss: 1.0077 - val_accuracy: 0.6290\n","Epoch 64/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6377 - accuracy: 0.8087 - val_loss: 1.0676 - val_accuracy: 0.6278\n","Epoch 65/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6427 - accuracy: 0.8045 - val_loss: 1.0444 - val_accuracy: 0.6290\n","Epoch 66/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6438 - accuracy: 0.7988 - val_loss: 1.1101 - val_accuracy: 0.6041\n","Epoch 67/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6487 - accuracy: 0.7946 - val_loss: 1.0615 - val_accuracy: 0.6324\n","Epoch 68/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6401 - accuracy: 0.8079 - val_loss: 1.0461 - val_accuracy: 0.6210\n","Epoch 69/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6359 - accuracy: 0.7999 - val_loss: 1.0841 - val_accuracy: 0.6131\n","Epoch 70/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6361 - accuracy: 0.8110 - val_loss: 1.0743 - val_accuracy: 0.6165\n","Epoch 71/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6341 - accuracy: 0.8019 - val_loss: 1.1052 - val_accuracy: 0.6267\n","Epoch 72/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6327 - accuracy: 0.8067 - val_loss: 1.0440 - val_accuracy: 0.6131\n","Epoch 73/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6425 - accuracy: 0.7977 - val_loss: 1.0395 - val_accuracy: 0.6357\n","Epoch 74/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6346 - accuracy: 0.7974 - val_loss: 1.1210 - val_accuracy: 0.6267\n","Epoch 75/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6385 - accuracy: 0.8028 - val_loss: 1.0960 - val_accuracy: 0.6222\n","Epoch 76/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6203 - accuracy: 0.8192 - val_loss: 1.0390 - val_accuracy: 0.6165\n","Epoch 77/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6220 - accuracy: 0.8130 - val_loss: 1.0462 - val_accuracy: 0.6222\n","Epoch 78/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6133 - accuracy: 0.8206 - val_loss: 1.0608 - val_accuracy: 0.6176\n","Epoch 79/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6122 - accuracy: 0.8192 - val_loss: 1.0517 - val_accuracy: 0.6222\n","Epoch 80/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6127 - accuracy: 0.8226 - val_loss: 1.0584 - val_accuracy: 0.6233\n","Epoch 81/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6139 - accuracy: 0.8217 - val_loss: 1.0700 - val_accuracy: 0.6301\n","Epoch 82/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6150 - accuracy: 0.8181 - val_loss: 1.0632 - val_accuracy: 0.6244\n","Epoch 83/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6065 - accuracy: 0.8240 - val_loss: 1.0700 - val_accuracy: 0.6278\n","Epoch 84/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6040 - accuracy: 0.8212 - val_loss: 1.0815 - val_accuracy: 0.6188\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6093 - accuracy: 0.8152 - val_loss: 1.1487 - val_accuracy: 0.6143\n","Epoch 86/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6141 - accuracy: 0.8178 - val_loss: 1.0789 - val_accuracy: 0.6109\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6191 - accuracy: 0.8113 - val_loss: 1.1249 - val_accuracy: 0.6165\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6069 - accuracy: 0.8192 - val_loss: 1.0804 - val_accuracy: 0.6346\n","Epoch 89/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5985 - accuracy: 0.8282 - val_loss: 1.0945 - val_accuracy: 0.6267\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6059 - accuracy: 0.8257 - val_loss: 1.1079 - val_accuracy: 0.6165\n","Epoch 91/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6016 - accuracy: 0.8379 - val_loss: 1.1107 - val_accuracy: 0.6199\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5924 - accuracy: 0.8328 - val_loss: 1.0898 - val_accuracy: 0.6131\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5903 - accuracy: 0.8280 - val_loss: 1.0980 - val_accuracy: 0.6131\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5900 - accuracy: 0.8268 - val_loss: 1.1037 - val_accuracy: 0.6188\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5925 - accuracy: 0.8260 - val_loss: 1.0982 - val_accuracy: 0.6165\n","Epoch 96/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5881 - accuracy: 0.8294 - val_loss: 1.1108 - val_accuracy: 0.6199\n","Epoch 97/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5890 - accuracy: 0.8339 - val_loss: 1.1619 - val_accuracy: 0.6210\n","Epoch 98/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5918 - accuracy: 0.8285 - val_loss: 1.1192 - val_accuracy: 0.6357\n","Epoch 99/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5817 - accuracy: 0.8339 - val_loss: 1.1537 - val_accuracy: 0.6256\n","Epoch 100/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5835 - accuracy: 0.8350 - val_loss: 1.1127 - val_accuracy: 0.6346\n","{'loss': [0.787129282951355, 0.7707415223121643, 0.7687154412269592, 0.7658297419548035, 0.7603634595870972, 0.7552320957183838, 0.7552641034126282, 0.7527933716773987, 0.7498704791069031, 0.7455077767372131, 0.7380945682525635, 0.7460424304008484, 0.7416873574256897, 0.7398611307144165, 0.7370506525039673, 0.7363221645355225, 0.7272562980651855, 0.7249699831008911, 0.7315582633018494, 0.7205731272697449, 0.7283492088317871, 0.7244498133659363, 0.7151015400886536, 0.7165856957435608, 0.7119438648223877, 0.7060891389846802, 0.7179309725761414, 0.710002064704895, 0.7030845880508423, 0.6991817355155945, 0.6961712837219238, 0.695357084274292, 0.7027471661567688, 0.7046747207641602, 0.6954138875007629, 0.6909716725349426, 0.6909996867179871, 0.6882155537605286, 0.6855694055557251, 0.6811984181404114, 0.6916578412055969, 0.6782760620117188, 0.6797173619270325, 0.674563467502594, 0.6723505258560181, 0.6736404299736023, 0.669814944267273, 0.6794072985649109, 0.6712689399719238, 0.6625889539718628, 0.6576709151268005, 0.6669069528579712, 0.6581584811210632, 0.6583646535873413, 0.6575984358787537, 0.652513861656189, 0.6542178988456726, 0.658202588558197, 0.6530895829200745, 0.6479402184486389, 0.6425482630729675, 0.6397278308868408, 0.6393100023269653, 0.6376607418060303, 0.642699658870697, 0.6437833309173584, 0.6486790180206299, 0.6400829553604126, 0.6359094977378845, 0.6360763907432556, 0.6340962052345276, 0.6326639652252197, 0.6425037384033203, 0.6346157193183899, 0.6384971141815186, 0.620252251625061, 0.6219813227653503, 0.613258957862854, 0.612160325050354, 0.6127004027366638, 0.6138914823532104, 0.6149707436561584, 0.6065425872802734, 0.6040100455284119, 0.6093493700027466, 0.6141257882118225, 0.6190723180770874, 0.6069172024726868, 0.5984682440757751, 0.6058788299560547, 0.6015665531158447, 0.5923806428909302, 0.5902997255325317, 0.5899767875671387, 0.5925419926643372, 0.5880951881408691, 0.5890335440635681, 0.5917695760726929, 0.5816749334335327, 0.5834726095199585], 'accuracy': [0.7153367400169373, 0.7289190888404846, 0.7289190888404846, 0.7393888235092163, 0.7345783710479736, 0.7456140518188477, 0.7357102632522583, 0.7410866022109985, 0.7410866022109985, 0.7532541155815125, 0.7507073879241943, 0.7543859481811523, 0.7507073879241943, 0.7495755553245544, 0.7589133977890015, 0.744482159614563, 0.7631579041481018, 0.7628749012947083, 0.7498584985733032, 0.7620260119438171, 0.7492926120758057, 0.7515563368797302, 0.7594793438911438, 0.7594793438911438, 0.7662705183029175, 0.7753254175186157, 0.7657045722007751, 0.7696660757064819, 0.7716468572616577, 0.7761743068695068, 0.7795698642730713, 0.7818335890769958, 0.7654216289520264, 0.7722128033638, 0.7823995351791382, 0.784380316734314, 0.7795698642730713, 0.7897566556930542, 0.7812677025794983, 0.7826825380325317, 0.7736276388168335, 0.7860780954360962, 0.7787209749221802, 0.7931522130966187, 0.7956989407539368, 0.7846632599830627, 0.790039598941803, 0.7775891423225403, 0.786361038684845, 0.7962648272514343, 0.8005093336105347, 0.7956989407539368, 0.7956989407539368, 0.8039049506187439, 0.7872099876403809, 0.7993775010108948, 0.7940011024475098, 0.7988115549087524, 0.7940011024475098, 0.7985285520553589, 0.8089982867240906, 0.8050367832183838, 0.806734561920166, 0.8087153434753418, 0.8044708371162415, 0.7988115549087524, 0.7945670485496521, 0.8078664541244507, 0.7999433875083923, 0.8109790682792664, 0.8019241690635681, 0.806734561920166, 0.7976796627044678, 0.797396719455719, 0.8027730584144592, 0.8191850781440735, 0.8129597902297974, 0.8205999135971069, 0.8191850781440735, 0.8225806355476379, 0.8217317461967468, 0.8180531859397888, 0.8239954710006714, 0.8211658000946045, 0.8152235150337219, 0.81777024269104, 0.8112620115280151, 0.8191850781440735, 0.8282399773597717, 0.8256932497024536, 0.8378607630729675, 0.8327674269676208, 0.8279569745063782, 0.8268251419067383, 0.8259762525558472, 0.8293718099594116, 0.8338992595672607, 0.8285229206085205, 0.8338992595672607, 0.8350311517715454], 'val_loss': [0.9510961174964905, 0.9565245509147644, 0.9485191106796265, 0.9455883502960205, 0.9422102570533752, 0.9433045387268066, 0.9360743165016174, 0.9341521859169006, 0.9291515350341797, 0.9272608757019043, 0.9223840236663818, 0.9214202761650085, 0.9208635687828064, 0.9140145182609558, 0.9051880836486816, 0.9053106307983398, 0.9021263718605042, 0.901203989982605, 0.903445303440094, 0.9062826633453369, 0.9053492546081543, 0.9049577713012695, 0.8977915048599243, 0.9075582027435303, 0.9095312356948853, 0.9239552617073059, 0.9306842684745789, 0.932858407497406, 0.9376708269119263, 0.9348375201225281, 0.9390809535980225, 0.9506579637527466, 0.9643811583518982, 0.9652208089828491, 0.9567961692810059, 0.9582359194755554, 0.9583518505096436, 0.9697664976119995, 0.9639686346054077, 0.9762235879898071, 0.995229184627533, 0.972857654094696, 0.9927824139595032, 0.97855544090271, 0.9624450206756592, 0.9714675545692444, 0.9910328984260559, 0.9593325257301331, 0.9961024522781372, 0.9791172742843628, 0.9961912631988525, 0.9759045839309692, 1.0108368396759033, 0.9948936104774475, 0.997166097164154, 1.0021239519119263, 1.0120186805725098, 1.0509898662567139, 1.0183483362197876, 1.0090625286102295, 1.00273859500885, 1.0189754962921143, 1.0077342987060547, 1.0675759315490723, 1.0443884134292603, 1.1101495027542114, 1.0615320205688477, 1.0461267232894897, 1.0841189622879028, 1.0742976665496826, 1.1052463054656982, 1.044014811515808, 1.039534091949463, 1.1209789514541626, 1.0959831476211548, 1.038955807685852, 1.0461596250534058, 1.0607584714889526, 1.0516564846038818, 1.0583765506744385, 1.0699936151504517, 1.0632426738739014, 1.0699611902236938, 1.0814896821975708, 1.1486538648605347, 1.0789299011230469, 1.1248717308044434, 1.0804173946380615, 1.0945125818252563, 1.1078615188598633, 1.110737919807434, 1.0897648334503174, 1.0980055332183838, 1.1036759614944458, 1.0982245206832886, 1.1107685565948486, 1.1619364023208618, 1.1192072629928589, 1.1536859273910522, 1.112654209136963], 'val_accuracy': [0.5339366793632507, 0.5135746598243713, 0.5361990928649902, 0.5610859990119934, 0.5622171759605408, 0.540723979473114, 0.5542986392974854, 0.5531674027442932, 0.5995475053787231, 0.6006787419319153, 0.570135772228241, 0.5769230723381042, 0.6006787419319153, 0.5893664956092834, 0.6210407018661499, 0.6233031749725342, 0.6142534017562866, 0.627828061580658, 0.6255655884742737, 0.610859751701355, 0.6176470518112183, 0.639140248298645, 0.6346153616905212, 0.6289592981338501, 0.6368778347969055, 0.6447963714599609, 0.6402714848518372, 0.6266968250274658, 0.6346153616905212, 0.6380090713500977, 0.6527149081230164, 0.6368778347969055, 0.6346153616905212, 0.6255655884742737, 0.6436651349067688, 0.6334841847419739, 0.6380090713500977, 0.6368778347969055, 0.6402714848518372, 0.6312217116355896, 0.6346153616905212, 0.6346153616905212, 0.6266968250274658, 0.6334841847419739, 0.6323529481887817, 0.6346153616905212, 0.6210407018661499, 0.6402714848518372, 0.6334841847419739, 0.6289592981338501, 0.627828061580658, 0.6402714848518372, 0.627828061580658, 0.627828061580658, 0.6289592981338501, 0.6368778347969055, 0.627828061580658, 0.6470588445663452, 0.622171938419342, 0.6244344115257263, 0.6346153616905212, 0.6187782883644104, 0.6289592981338501, 0.627828061580658, 0.6289592981338501, 0.6040723919868469, 0.6323529481887817, 0.6210407018661499, 0.6131221652030945, 0.6165158152580261, 0.6266968250274658, 0.6131221652030945, 0.6357465982437134, 0.6266968250274658, 0.622171938419342, 0.6165158152580261, 0.622171938419342, 0.6176470518112183, 0.622171938419342, 0.6233031749725342, 0.6300904750823975, 0.6244344115257263, 0.627828061580658, 0.6187782883644104, 0.6142534017562866, 0.610859751701355, 0.6165158152580261, 0.6346153616905212, 0.6266968250274658, 0.6165158152580261, 0.6199095249176025, 0.6131221652030945, 0.6131221652030945, 0.6187782883644104, 0.6165158152580261, 0.6199095249176025, 0.6210407018661499, 0.6357465982437134, 0.6255655884742737, 0.6346153616905212]}\n","45/45 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 3s 26ms/step - loss: 0.8000 - accuracy: 0.7078 - val_loss: 0.9521 - val_accuracy: 0.5331\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.7926 - accuracy: 0.6797"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 11ms/step - loss: 0.7891 - accuracy: 0.7116 - val_loss: 0.9556 - val_accuracy: 0.5186\n","Epoch 3/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7820 - accuracy: 0.7245 - val_loss: 0.9478 - val_accuracy: 0.5579\n","Epoch 4/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7750 - accuracy: 0.7271 - val_loss: 0.9448 - val_accuracy: 0.5661\n","Epoch 5/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7745 - accuracy: 0.7207 - val_loss: 0.9435 - val_accuracy: 0.5640\n","Epoch 6/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7677 - accuracy: 0.7276 - val_loss: 0.9400 - val_accuracy: 0.5527\n","Epoch 7/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7650 - accuracy: 0.7359 - val_loss: 0.9378 - val_accuracy: 0.5548\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7631 - accuracy: 0.7346 - val_loss: 0.9342 - val_accuracy: 0.5682\n","Epoch 9/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7618 - accuracy: 0.7295 - val_loss: 0.9305 - val_accuracy: 0.5630\n","Epoch 10/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7572 - accuracy: 0.7307 - val_loss: 0.9315 - val_accuracy: 0.5351\n","Epoch 11/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7573 - accuracy: 0.7359 - val_loss: 0.9242 - val_accuracy: 0.5661\n","Epoch 12/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7536 - accuracy: 0.7390 - val_loss: 0.9193 - val_accuracy: 0.5744\n","Epoch 13/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7487 - accuracy: 0.7344 - val_loss: 0.9293 - val_accuracy: 0.5434\n","Epoch 14/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7494 - accuracy: 0.7388 - val_loss: 0.9246 - val_accuracy: 0.5589\n","Epoch 15/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7499 - accuracy: 0.7395 - val_loss: 0.9143 - val_accuracy: 0.5610\n","Epoch 16/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7452 - accuracy: 0.7406 - val_loss: 0.9105 - val_accuracy: 0.5692\n","Epoch 17/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7426 - accuracy: 0.7432 - val_loss: 0.9059 - val_accuracy: 0.5940\n","Epoch 18/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7384 - accuracy: 0.7499 - val_loss: 0.9051 - val_accuracy: 0.5744\n","Epoch 19/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7386 - accuracy: 0.7465 - val_loss: 0.9043 - val_accuracy: 0.5909\n","Epoch 20/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7350 - accuracy: 0.7406 - val_loss: 0.9164 - val_accuracy: 0.5888\n","Epoch 21/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7396 - accuracy: 0.7473 - val_loss: 0.9197 - val_accuracy: 0.5816\n","Epoch 22/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7347 - accuracy: 0.7457 - val_loss: 0.9248 - val_accuracy: 0.5909\n","Epoch 23/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7324 - accuracy: 0.7488 - val_loss: 0.9767 - val_accuracy: 0.5764\n","Epoch 24/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7291 - accuracy: 0.7512 - val_loss: 0.9386 - val_accuracy: 0.5930\n","Epoch 25/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7238 - accuracy: 0.7563 - val_loss: 0.9475 - val_accuracy: 0.5806\n","Epoch 26/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7202 - accuracy: 0.7579 - val_loss: 0.9185 - val_accuracy: 0.5971\n","Epoch 27/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7248 - accuracy: 0.7496 - val_loss: 0.9817 - val_accuracy: 0.6043\n","Epoch 28/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7187 - accuracy: 0.7540 - val_loss: 0.9635 - val_accuracy: 0.6002\n","Epoch 29/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7179 - accuracy: 0.7566 - val_loss: 0.9570 - val_accuracy: 0.6105\n","Epoch 30/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7133 - accuracy: 0.7659 - val_loss: 0.9467 - val_accuracy: 0.6043\n","Epoch 31/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7126 - accuracy: 0.7649 - val_loss: 0.9493 - val_accuracy: 0.5950\n","Epoch 32/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7083 - accuracy: 0.7625 - val_loss: 0.9568 - val_accuracy: 0.5878\n","Epoch 33/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7090 - accuracy: 0.7638 - val_loss: 0.9745 - val_accuracy: 0.5775\n","Epoch 34/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7072 - accuracy: 0.7625 - val_loss: 0.9666 - val_accuracy: 0.5857\n","Epoch 35/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7013 - accuracy: 0.7636 - val_loss: 0.9758 - val_accuracy: 0.5868\n","Epoch 36/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7015 - accuracy: 0.7656 - val_loss: 0.9545 - val_accuracy: 0.5806\n","Epoch 37/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7225 - accuracy: 0.7411 - val_loss: 0.9531 - val_accuracy: 0.5930\n","Epoch 38/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7053 - accuracy: 0.7649 - val_loss: 0.9448 - val_accuracy: 0.6023\n","Epoch 39/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7003 - accuracy: 0.7649 - val_loss: 1.0367 - val_accuracy: 0.5909\n","Epoch 40/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6927 - accuracy: 0.7685 - val_loss: 0.9530 - val_accuracy: 0.5857\n","Epoch 41/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6949 - accuracy: 0.7724 - val_loss: 1.0086 - val_accuracy: 0.5795\n","Epoch 42/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6903 - accuracy: 0.7744 - val_loss: 1.0173 - val_accuracy: 0.5764\n","Epoch 43/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6859 - accuracy: 0.7780 - val_loss: 0.9671 - val_accuracy: 0.5847\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6864 - accuracy: 0.7749 - val_loss: 0.9677 - val_accuracy: 0.5868\n","Epoch 45/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6853 - accuracy: 0.7695 - val_loss: 0.9830 - val_accuracy: 0.5857\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6790 - accuracy: 0.7806 - val_loss: 1.0359 - val_accuracy: 0.6002\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6849 - accuracy: 0.7744 - val_loss: 0.9966 - val_accuracy: 0.6054\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6802 - accuracy: 0.7793 - val_loss: 1.0219 - val_accuracy: 0.5857\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6811 - accuracy: 0.7778 - val_loss: 0.9769 - val_accuracy: 0.5795\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6762 - accuracy: 0.7783 - val_loss: 0.9530 - val_accuracy: 0.5971\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6746 - accuracy: 0.7860 - val_loss: 1.0125 - val_accuracy: 0.5940\n","Epoch 52/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6712 - accuracy: 0.7850 - val_loss: 1.0259 - val_accuracy: 0.5816\n","Epoch 53/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6695 - accuracy: 0.7855 - val_loss: 0.9921 - val_accuracy: 0.5909\n","Epoch 54/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6677 - accuracy: 0.7749 - val_loss: 1.0392 - val_accuracy: 0.5971\n","Epoch 55/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6699 - accuracy: 0.7765 - val_loss: 0.9919 - val_accuracy: 0.6033\n","Epoch 56/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6696 - accuracy: 0.7819 - val_loss: 1.0023 - val_accuracy: 0.5950\n","Epoch 57/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6628 - accuracy: 0.7868 - val_loss: 0.9790 - val_accuracy: 0.5878\n","Epoch 58/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6642 - accuracy: 0.7879 - val_loss: 1.0783 - val_accuracy: 0.5795\n","Epoch 59/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6652 - accuracy: 0.7835 - val_loss: 1.0780 - val_accuracy: 0.5775\n","Epoch 60/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6564 - accuracy: 0.7974 - val_loss: 1.0324 - val_accuracy: 0.5971\n","Epoch 61/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6516 - accuracy: 0.7935 - val_loss: 0.9925 - val_accuracy: 0.5950\n","Epoch 62/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6541 - accuracy: 0.7915 - val_loss: 1.0163 - val_accuracy: 0.5992\n","Epoch 63/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6576 - accuracy: 0.7881 - val_loss: 0.9866 - val_accuracy: 0.5971\n","Epoch 64/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6568 - accuracy: 0.7933 - val_loss: 0.9752 - val_accuracy: 0.6002\n","Epoch 65/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6573 - accuracy: 0.7897 - val_loss: 0.9967 - val_accuracy: 0.5919\n","Epoch 66/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6482 - accuracy: 0.7959 - val_loss: 0.9871 - val_accuracy: 0.5816\n","Epoch 67/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6466 - accuracy: 0.7972 - val_loss: 1.0596 - val_accuracy: 0.5857\n","Epoch 68/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6688 - accuracy: 0.7698 - val_loss: 1.1213 - val_accuracy: 0.5775\n","Epoch 69/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6541 - accuracy: 0.7925 - val_loss: 1.0918 - val_accuracy: 0.5981\n","Epoch 70/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6450 - accuracy: 0.8013 - val_loss: 1.0053 - val_accuracy: 0.5971\n","Epoch 71/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6480 - accuracy: 0.7925 - val_loss: 0.9868 - val_accuracy: 0.5992\n","Epoch 72/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6390 - accuracy: 0.7951 - val_loss: 1.0607 - val_accuracy: 0.6012\n","Epoch 73/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6392 - accuracy: 0.7922 - val_loss: 1.0425 - val_accuracy: 0.5702\n","Epoch 74/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6388 - accuracy: 0.7943 - val_loss: 0.9966 - val_accuracy: 0.5919\n","Epoch 75/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6293 - accuracy: 0.8075 - val_loss: 1.0355 - val_accuracy: 0.5785\n","Epoch 76/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6272 - accuracy: 0.7979 - val_loss: 1.0606 - val_accuracy: 0.5806\n","Epoch 77/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6318 - accuracy: 0.8013 - val_loss: 1.0501 - val_accuracy: 0.5878\n","Epoch 78/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6278 - accuracy: 0.8078 - val_loss: 1.0714 - val_accuracy: 0.5795\n","Epoch 79/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6414 - accuracy: 0.7953 - val_loss: 1.1022 - val_accuracy: 0.5723\n","Epoch 80/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6497 - accuracy: 0.7995 - val_loss: 1.1508 - val_accuracy: 0.5899\n","Epoch 81/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6439 - accuracy: 0.7824 - val_loss: 1.1273 - val_accuracy: 0.5857\n","Epoch 82/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6251 - accuracy: 0.8059 - val_loss: 1.0096 - val_accuracy: 0.6002\n","Epoch 83/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6201 - accuracy: 0.8111 - val_loss: 1.0337 - val_accuracy: 0.5950\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6260 - accuracy: 0.8013 - val_loss: 1.0554 - val_accuracy: 0.5950\n","Epoch 85/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6253 - accuracy: 0.8116 - val_loss: 1.0666 - val_accuracy: 0.5806\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6217 - accuracy: 0.8080 - val_loss: 1.0100 - val_accuracy: 0.5930\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6304 - accuracy: 0.7997 - val_loss: 1.0651 - val_accuracy: 0.5919\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6276 - accuracy: 0.8031 - val_loss: 1.0357 - val_accuracy: 0.5857\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6202 - accuracy: 0.8031 - val_loss: 1.0964 - val_accuracy: 0.5764\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6047 - accuracy: 0.8176 - val_loss: 1.0307 - val_accuracy: 0.5919\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6154 - accuracy: 0.8176 - val_loss: 1.1412 - val_accuracy: 0.6012\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6095 - accuracy: 0.8090 - val_loss: 1.1089 - val_accuracy: 0.5899\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6073 - accuracy: 0.8150 - val_loss: 1.0755 - val_accuracy: 0.5930\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6075 - accuracy: 0.8134 - val_loss: 1.0948 - val_accuracy: 0.5919\n","Epoch 95/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6094 - accuracy: 0.8150 - val_loss: 1.0952 - val_accuracy: 0.5868\n","Epoch 96/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6206 - accuracy: 0.8047 - val_loss: 1.0639 - val_accuracy: 0.5754\n","Epoch 97/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6090 - accuracy: 0.8147 - val_loss: 1.1587 - val_accuracy: 0.5579\n","Epoch 98/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6120 - accuracy: 0.8238 - val_loss: 1.1958 - val_accuracy: 0.5950\n","Epoch 99/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6730 - accuracy: 0.7853 - val_loss: 1.1735 - val_accuracy: 0.5940\n","Epoch 100/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6091 - accuracy: 0.8111 - val_loss: 1.1692 - val_accuracy: 0.5899\n","{'loss': [0.8000090718269348, 0.7890682220458984, 0.7819549441337585, 0.7749837040901184, 0.7744637131690979, 0.767719566822052, 0.7650391459465027, 0.7631321549415588, 0.7618240118026733, 0.7571556568145752, 0.757318377494812, 0.7535650134086609, 0.7486518025398254, 0.7494103312492371, 0.7499237060546875, 0.745242178440094, 0.7426047921180725, 0.7383865118026733, 0.7385629415512085, 0.7349711656570435, 0.7395530939102173, 0.7347117066383362, 0.7323548793792725, 0.7291274666786194, 0.7238240838050842, 0.7201584577560425, 0.7248080372810364, 0.7186914682388306, 0.7178889513015747, 0.7133241295814514, 0.7125717401504517, 0.7083364129066467, 0.7089879512786865, 0.7072172164916992, 0.7013276219367981, 0.7014622092247009, 0.7225481271743774, 0.7052929997444153, 0.7003475427627563, 0.6926810145378113, 0.6948779821395874, 0.6903112530708313, 0.6858749985694885, 0.6863702535629272, 0.6852955222129822, 0.6789814829826355, 0.6849303841590881, 0.6801619529724121, 0.6811052560806274, 0.6761751174926758, 0.6746493577957153, 0.6711781024932861, 0.6694744825363159, 0.6677243113517761, 0.6698578000068665, 0.6696457266807556, 0.6628392934799194, 0.6642273664474487, 0.6651933193206787, 0.6563698053359985, 0.6516440510749817, 0.654132604598999, 0.6576389074325562, 0.6567912101745605, 0.6572933793067932, 0.6481720805168152, 0.6465914249420166, 0.6688097715377808, 0.6541493535041809, 0.6449625492095947, 0.6480003595352173, 0.6390157341957092, 0.6391902565956116, 0.6387534737586975, 0.6292988061904907, 0.6271874308586121, 0.6318431496620178, 0.6278415322303772, 0.6413958072662354, 0.6496661901473999, 0.6438634991645813, 0.6251229047775269, 0.6200942993164062, 0.6260107755661011, 0.6253356337547302, 0.6216946244239807, 0.6303567290306091, 0.6276242733001709, 0.6201651096343994, 0.604702353477478, 0.6153648495674133, 0.6094614267349243, 0.6073042154312134, 0.6075257062911987, 0.6094231605529785, 0.6206314563751221, 0.6090299487113953, 0.6120293140411377, 0.6729817986488342, 0.6091087460517883], 'accuracy': [0.7077519297599792, 0.7116279006004333, 0.724547803401947, 0.7271317839622498, 0.7206718325614929, 0.7276485562324524, 0.735917329788208, 0.7346253395080566, 0.7294573783874512, 0.7307493686676025, 0.735917329788208, 0.7390180826187134, 0.7343669533729553, 0.7387596964836121, 0.739534854888916, 0.7405684590339661, 0.7431524395942688, 0.749870777130127, 0.7465116381645203, 0.7405684590339661, 0.7472867965698242, 0.7457364201545715, 0.7488372325897217, 0.7511627674102783, 0.7563307285308838, 0.7578811645507812, 0.7496123909950256, 0.7540051937103271, 0.7565891742706299, 0.7658914923667908, 0.7648578882217407, 0.7625322937965393, 0.7638242840766907, 0.7625322937965393, 0.7635658979415894, 0.7656330466270447, 0.7410852909088135, 0.7648578882217407, 0.7648578882217407, 0.7684754729270935, 0.7723514437675476, 0.7744185924530029, 0.7780361771583557, 0.7749354243278503, 0.7695090174674988, 0.7806201577186584, 0.7744185924530029, 0.7793281674385071, 0.7777777910232544, 0.778294563293457, 0.7860465049743652, 0.7850129008293152, 0.7855297327041626, 0.7749354243278503, 0.776485800743103, 0.7819121479988098, 0.786821722984314, 0.7878552675247192, 0.7834625244140625, 0.7974160313606262, 0.7935400605201721, 0.791472852230072, 0.7881137132644653, 0.7932816743850708, 0.789664089679718, 0.7958656549453735, 0.7971576452255249, 0.7697674632072449, 0.7925064563751221, 0.8012920022010803, 0.7925064563751221, 0.7950904369354248, 0.7922480702400208, 0.7943152189254761, 0.8074935674667358, 0.7979328036308289, 0.8012920022010803, 0.8077519536018372, 0.7953488230705261, 0.7994831800460815, 0.7824289202690125, 0.8059431314468384, 0.8111110925674438, 0.8012920022010803, 0.8116279244422913, 0.8080103397369385, 0.7997416257858276, 0.8031007647514343, 0.8031007647514343, 0.8175710439682007, 0.8175710439682007, 0.8090439438819885, 0.814987063407898, 0.8134366869926453, 0.814987063407898, 0.804651141166687, 0.8147286772727966, 0.8237726092338562, 0.7852713465690613, 0.8111110925674438], 'val_loss': [0.9521321058273315, 0.9555624127388, 0.947844386100769, 0.9447785019874573, 0.9434739947319031, 0.939974844455719, 0.9377987384796143, 0.9342000484466553, 0.9305412769317627, 0.9314596652984619, 0.9241604804992676, 0.9193313717842102, 0.9293070435523987, 0.9245921969413757, 0.9143455028533936, 0.9105380177497864, 0.9058706760406494, 0.9051097631454468, 0.904254674911499, 0.9163869619369507, 0.919722855091095, 0.9248262643814087, 0.9767012000083923, 0.938605546951294, 0.9474726319313049, 0.9184934496879578, 0.9817435145378113, 0.9634988307952881, 0.9570363759994507, 0.9466770887374878, 0.9492663145065308, 0.9567672610282898, 0.97454833984375, 0.966550350189209, 0.9757578372955322, 0.9545202255249023, 0.953065812587738, 0.9447504281997681, 1.0367180109024048, 0.9529889822006226, 1.0086077451705933, 1.0172990560531616, 0.9670618176460266, 0.9676661491394043, 0.9830489158630371, 1.0358664989471436, 0.9965876340866089, 1.0218899250030518, 0.9768543243408203, 0.9530321359634399, 1.0125205516815186, 1.0259097814559937, 0.992063045501709, 1.039164662361145, 0.9918980598449707, 1.0022835731506348, 0.9790472388267517, 1.078295111656189, 1.0779674053192139, 1.03242027759552, 0.9925186634063721, 1.016322374343872, 0.986620306968689, 0.9751722812652588, 0.9967058300971985, 0.9870753288269043, 1.0596152544021606, 1.1213151216506958, 1.091813564300537, 1.0053203105926514, 0.9867695569992065, 1.0607277154922485, 1.042545199394226, 0.9965855479240417, 1.0355465412139893, 1.06056809425354, 1.0501073598861694, 1.0713748931884766, 1.1021887063980103, 1.1508251428604126, 1.1273014545440674, 1.0096410512924194, 1.0336825847625732, 1.0553728342056274, 1.0666214227676392, 1.010037899017334, 1.0650546550750732, 1.0357052087783813, 1.0963850021362305, 1.0306751728057861, 1.1412272453308105, 1.1088814735412598, 1.0754506587982178, 1.094800591468811, 1.0952309370040894, 1.063904047012329, 1.158717393875122, 1.1958343982696533, 1.1734646558761597, 1.1692323684692383], 'val_accuracy': [0.5330578684806824, 0.5185950398445129, 0.557851254940033, 0.56611567735672, 0.5640496015548706, 0.5526859760284424, 0.5547520518302917, 0.5681818127632141, 0.5630165338516235, 0.5351239442825317, 0.56611567735672, 0.5743801593780518, 0.5433884263038635, 0.55888432264328, 0.5609503984451294, 0.5692148804664612, 0.5940082669258118, 0.5743801593780518, 0.5909090638160706, 0.5888429880142212, 0.5816115736961365, 0.5909090638160706, 0.5764462947845459, 0.5929751992225647, 0.5805785059928894, 0.5971074104309082, 0.6043388247489929, 0.6002066135406494, 0.6105371713638306, 0.6043388247489929, 0.5950413346290588, 0.5878099203109741, 0.577479362487793, 0.58574378490448, 0.586776852607727, 0.5805785059928894, 0.5929751992225647, 0.6022727489471436, 0.5909090638160706, 0.58574378490448, 0.5795454382896423, 0.5764462947845459, 0.5847107172012329, 0.586776852607727, 0.58574378490448, 0.6002066135406494, 0.60537189245224, 0.58574378490448, 0.5795454382896423, 0.5971074104309082, 0.5940082669258118, 0.5816115736961365, 0.5909090638160706, 0.5971074104309082, 0.6033057570457458, 0.5950413346290588, 0.5878099203109741, 0.5795454382896423, 0.577479362487793, 0.5971074104309082, 0.5950413346290588, 0.5991735458374023, 0.5971074104309082, 0.6002066135406494, 0.5919421315193176, 0.5816115736961365, 0.58574378490448, 0.577479362487793, 0.5981404781341553, 0.5971074104309082, 0.5991735458374023, 0.6012396812438965, 0.5702479481697083, 0.5919421315193176, 0.5785123705863953, 0.5805785059928894, 0.5878099203109741, 0.5795454382896423, 0.5723140239715576, 0.5898760557174683, 0.58574378490448, 0.6002066135406494, 0.5950413346290588, 0.5950413346290588, 0.5805785059928894, 0.5929751992225647, 0.5919421315193176, 0.58574378490448, 0.5764462947845459, 0.5919421315193176, 0.6012396812438965, 0.5898760557174683, 0.5929751992225647, 0.5919421315193176, 0.586776852607727, 0.5754132270812988, 0.557851254940033, 0.5950413346290588, 0.5940082669258118, 0.5898760557174683]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 33ms/step - loss: 0.6514 - accuracy: 0.7839 - val_loss: 0.9144 - val_accuracy: 0.4989\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.6060 - accuracy: 0.7891"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 1s 21ms/step - loss: 0.6313 - accuracy: 0.7982 - val_loss: 0.9065 - val_accuracy: 0.5226\n","Epoch 3/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6269 - accuracy: 0.7971 - val_loss: 0.9054 - val_accuracy: 0.5593\n","Epoch 4/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6176 - accuracy: 0.8031 - val_loss: 0.9109 - val_accuracy: 0.5140\n","Epoch 5/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6177 - accuracy: 0.8093 - val_loss: 0.8959 - val_accuracy: 0.5442\n","Epoch 6/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6177 - accuracy: 0.8044 - val_loss: 0.9023 - val_accuracy: 0.5269\n","Epoch 7/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6231 - accuracy: 0.8041 - val_loss: 0.9338 - val_accuracy: 0.5065\n","Epoch 8/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6159 - accuracy: 0.8055 - val_loss: 0.9270 - val_accuracy: 0.5172\n","Epoch 9/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6047 - accuracy: 0.8200 - val_loss: 0.9153 - val_accuracy: 0.5345\n","Epoch 10/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6073 - accuracy: 0.8004 - val_loss: 0.9196 - val_accuracy: 0.5356\n","Epoch 11/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6018 - accuracy: 0.8136 - val_loss: 0.8993 - val_accuracy: 0.5539\n","Epoch 12/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6030 - accuracy: 0.8144 - val_loss: 0.8767 - val_accuracy: 0.5970\n","Epoch 13/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6122 - accuracy: 0.8133 - val_loss: 0.8997 - val_accuracy: 0.5614\n","Epoch 14/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6057 - accuracy: 0.8101 - val_loss: 0.9096 - val_accuracy: 0.5754\n","Epoch 15/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5913 - accuracy: 0.8217 - val_loss: 0.8843 - val_accuracy: 0.5894\n","Epoch 16/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5892 - accuracy: 0.8270 - val_loss: 0.8973 - val_accuracy: 0.6056\n","Epoch 17/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6018 - accuracy: 0.8206 - val_loss: 0.9050 - val_accuracy: 0.6444\n","Epoch 18/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5968 - accuracy: 0.8141 - val_loss: 0.8647 - val_accuracy: 0.6261\n","Epoch 19/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5878 - accuracy: 0.8270 - val_loss: 0.8729 - val_accuracy: 0.6552\n","Epoch 20/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5849 - accuracy: 0.8297 - val_loss: 0.8604 - val_accuracy: 0.6649\n","Epoch 21/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5900 - accuracy: 0.8155 - val_loss: 0.8664 - val_accuracy: 0.6659\n","Epoch 22/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5863 - accuracy: 0.8217 - val_loss: 0.8646 - val_accuracy: 0.6778\n","Epoch 23/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5828 - accuracy: 0.8289 - val_loss: 0.8673 - val_accuracy: 0.6821\n","Epoch 24/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5906 - accuracy: 0.8305 - val_loss: 0.9778 - val_accuracy: 0.6692\n","Epoch 25/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5922 - accuracy: 0.8279 - val_loss: 0.9371 - val_accuracy: 0.6627\n","Epoch 26/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5832 - accuracy: 0.8257 - val_loss: 0.8930 - val_accuracy: 0.6800\n","Epoch 27/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5822 - accuracy: 0.8254 - val_loss: 0.9340 - val_accuracy: 0.6864\n","Epoch 28/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5819 - accuracy: 0.8254 - val_loss: 1.0908 - val_accuracy: 0.6509\n","Epoch 29/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5852 - accuracy: 0.8257 - val_loss: 1.0096 - val_accuracy: 0.6433\n","Epoch 30/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5707 - accuracy: 0.8373 - val_loss: 0.9442 - val_accuracy: 0.6670\n","Epoch 31/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5726 - accuracy: 0.8381 - val_loss: 0.9207 - val_accuracy: 0.6843\n","Epoch 32/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5699 - accuracy: 0.8316 - val_loss: 0.9593 - val_accuracy: 0.6756\n","Epoch 33/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5732 - accuracy: 0.8365 - val_loss: 0.9372 - val_accuracy: 0.6735\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5678 - accuracy: 0.8338 - val_loss: 0.9672 - val_accuracy: 0.6875\n","Epoch 35/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5634 - accuracy: 0.8413 - val_loss: 0.9427 - val_accuracy: 0.6638\n","Epoch 36/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5630 - accuracy: 0.8389 - val_loss: 0.9466 - val_accuracy: 0.6713\n","Epoch 37/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5630 - accuracy: 0.8413 - val_loss: 1.0855 - val_accuracy: 0.6616\n","Epoch 38/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5714 - accuracy: 0.8281 - val_loss: 0.9419 - val_accuracy: 0.6746\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5628 - accuracy: 0.8349 - val_loss: 0.9464 - val_accuracy: 0.6703\n","Epoch 40/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5581 - accuracy: 0.8392 - val_loss: 0.9902 - val_accuracy: 0.6832\n","Epoch 41/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5554 - accuracy: 0.8370 - val_loss: 1.0221 - val_accuracy: 0.6638\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5591 - accuracy: 0.8459 - val_loss: 0.9809 - val_accuracy: 0.6692\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5519 - accuracy: 0.8494 - val_loss: 0.9849 - val_accuracy: 0.6552\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5515 - accuracy: 0.8534 - val_loss: 0.9876 - val_accuracy: 0.6756\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5532 - accuracy: 0.8384 - val_loss: 1.0977 - val_accuracy: 0.6649\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5493 - accuracy: 0.8411 - val_loss: 0.9734 - val_accuracy: 0.6638\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5496 - accuracy: 0.8470 - val_loss: 0.9576 - val_accuracy: 0.6713\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5431 - accuracy: 0.8545 - val_loss: 1.0739 - val_accuracy: 0.6703\n","Epoch 49/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5541 - accuracy: 0.8402 - val_loss: 1.0153 - val_accuracy: 0.6606\n","Epoch 50/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5544 - accuracy: 0.8402 - val_loss: 0.9980 - val_accuracy: 0.6466\n","Epoch 51/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5587 - accuracy: 0.8505 - val_loss: 1.0491 - val_accuracy: 0.6713\n","Epoch 52/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5542 - accuracy: 0.8343 - val_loss: 1.0615 - val_accuracy: 0.6369\n","Epoch 53/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5546 - accuracy: 0.8338 - val_loss: 1.0417 - val_accuracy: 0.6746\n","Epoch 54/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5439 - accuracy: 0.8510 - val_loss: 1.0431 - val_accuracy: 0.6800\n","Epoch 55/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5431 - accuracy: 0.8502 - val_loss: 0.9941 - val_accuracy: 0.6606\n","Epoch 56/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5374 - accuracy: 0.8583 - val_loss: 0.9997 - val_accuracy: 0.6735\n","Epoch 57/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5396 - accuracy: 0.8575 - val_loss: 1.0341 - val_accuracy: 0.6455\n","Epoch 58/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5333 - accuracy: 0.8570 - val_loss: 1.0022 - val_accuracy: 0.6606\n","Epoch 59/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5391 - accuracy: 0.8521 - val_loss: 1.0144 - val_accuracy: 0.6627\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5266 - accuracy: 0.8640 - val_loss: 1.0115 - val_accuracy: 0.6724\n","Epoch 61/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5260 - accuracy: 0.8580 - val_loss: 0.9961 - val_accuracy: 0.6541\n","Epoch 62/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5308 - accuracy: 0.8591 - val_loss: 1.0762 - val_accuracy: 0.6552\n","Epoch 63/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5241 - accuracy: 0.8631 - val_loss: 1.0989 - val_accuracy: 0.6519\n","Epoch 64/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5293 - accuracy: 0.8534 - val_loss: 1.0926 - val_accuracy: 0.6670\n","Epoch 65/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5509 - accuracy: 0.8397 - val_loss: 1.0474 - val_accuracy: 0.6670\n","Epoch 66/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5263 - accuracy: 0.8599 - val_loss: 1.1037 - val_accuracy: 0.6595\n","Epoch 67/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5302 - accuracy: 0.8599 - val_loss: 0.9900 - val_accuracy: 0.6692\n","Epoch 68/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5195 - accuracy: 0.8613 - val_loss: 1.0458 - val_accuracy: 0.6659\n","Epoch 69/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5232 - accuracy: 0.8567 - val_loss: 1.1017 - val_accuracy: 0.6498\n","Epoch 70/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5170 - accuracy: 0.8613 - val_loss: 1.0585 - val_accuracy: 0.6616\n","Epoch 71/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5179 - accuracy: 0.8613 - val_loss: 1.0225 - val_accuracy: 0.6616\n","Epoch 72/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5365 - accuracy: 0.8462 - val_loss: 1.0535 - val_accuracy: 0.6530\n","Epoch 73/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5354 - accuracy: 0.8570 - val_loss: 1.0988 - val_accuracy: 0.6498\n","Epoch 74/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5150 - accuracy: 0.8650 - val_loss: 1.1406 - val_accuracy: 0.6444\n","Epoch 75/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5196 - accuracy: 0.8572 - val_loss: 1.0284 - val_accuracy: 0.6746\n","Epoch 76/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5292 - accuracy: 0.8551 - val_loss: 1.1689 - val_accuracy: 0.6530\n","Epoch 77/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5068 - accuracy: 0.8715 - val_loss: 1.1151 - val_accuracy: 0.6681\n","Epoch 78/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5124 - accuracy: 0.8640 - val_loss: 1.1206 - val_accuracy: 0.6272\n","Epoch 79/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5199 - accuracy: 0.8594 - val_loss: 1.0947 - val_accuracy: 0.6369\n","Epoch 80/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5125 - accuracy: 0.8605 - val_loss: 1.1124 - val_accuracy: 0.6455\n","Epoch 81/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5050 - accuracy: 0.8737 - val_loss: 1.1555 - val_accuracy: 0.6703\n","Epoch 82/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5183 - accuracy: 0.8626 - val_loss: 1.0895 - val_accuracy: 0.6390\n","Epoch 83/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5211 - accuracy: 0.8540 - val_loss: 1.1225 - val_accuracy: 0.6433\n","Epoch 84/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5110 - accuracy: 0.8691 - val_loss: 1.1193 - val_accuracy: 0.6476\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4959 - accuracy: 0.8758 - val_loss: 1.1407 - val_accuracy: 0.6552\n","Epoch 86/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5011 - accuracy: 0.8723 - val_loss: 1.0980 - val_accuracy: 0.6746\n","Epoch 87/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5015 - accuracy: 0.8712 - val_loss: 1.1080 - val_accuracy: 0.6595\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5023 - accuracy: 0.8688 - val_loss: 1.1785 - val_accuracy: 0.6315\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4956 - accuracy: 0.8747 - val_loss: 1.0885 - val_accuracy: 0.6433\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4977 - accuracy: 0.8702 - val_loss: 1.1007 - val_accuracy: 0.6681\n","Epoch 91/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4989 - accuracy: 0.8804 - val_loss: 1.0423 - val_accuracy: 0.6616\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4956 - accuracy: 0.8710 - val_loss: 1.1806 - val_accuracy: 0.6498\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4970 - accuracy: 0.8688 - val_loss: 1.2359 - val_accuracy: 0.6196\n","Epoch 94/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4947 - accuracy: 0.8680 - val_loss: 1.2976 - val_accuracy: 0.6412\n","Epoch 95/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5067 - accuracy: 0.8707 - val_loss: 1.1980 - val_accuracy: 0.6509\n","Epoch 96/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5108 - accuracy: 0.8707 - val_loss: 1.0594 - val_accuracy: 0.6681\n","Epoch 97/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4849 - accuracy: 0.8793 - val_loss: 1.2127 - val_accuracy: 0.6196\n","Epoch 98/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4864 - accuracy: 0.8745 - val_loss: 1.1342 - val_accuracy: 0.6476\n","Epoch 99/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4946 - accuracy: 0.8747 - val_loss: 1.3354 - val_accuracy: 0.6013\n","Epoch 100/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4996 - accuracy: 0.8704 - val_loss: 1.3265 - val_accuracy: 0.6304\n","{'loss': [0.6514168977737427, 0.6312547326087952, 0.6268959641456604, 0.6175621747970581, 0.6177139282226562, 0.6176713109016418, 0.6230980157852173, 0.6158565282821655, 0.6046751737594604, 0.6072588562965393, 0.6017712950706482, 0.6030206084251404, 0.6121942400932312, 0.6056625843048096, 0.5912894010543823, 0.589176595211029, 0.6017817854881287, 0.5968191623687744, 0.5878220200538635, 0.5849255323410034, 0.5900185108184814, 0.5863315463066101, 0.5828088521957397, 0.5905545353889465, 0.5921584963798523, 0.5831539034843445, 0.5821781754493713, 0.5818527340888977, 0.5851601958274841, 0.5706861615180969, 0.5726207494735718, 0.5699167847633362, 0.5731919407844543, 0.5678086876869202, 0.5633907914161682, 0.5630466938018799, 0.5629526376724243, 0.5713760852813721, 0.5628116726875305, 0.5580523014068604, 0.5554375052452087, 0.5591443777084351, 0.551927924156189, 0.5515161752700806, 0.5531986355781555, 0.5493037700653076, 0.5495763421058655, 0.543071985244751, 0.554054856300354, 0.5544261932373047, 0.5587376356124878, 0.5541760921478271, 0.5546296238899231, 0.5438601970672607, 0.5430836081504822, 0.5374132394790649, 0.5395850539207458, 0.5332551002502441, 0.5390546321868896, 0.5266075730323792, 0.5260218977928162, 0.530839741230011, 0.5241137742996216, 0.5293448567390442, 0.5509370565414429, 0.5263055562973022, 0.5302172899246216, 0.5194515585899353, 0.52322918176651, 0.5170494318008423, 0.5179063677787781, 0.5365316271781921, 0.5354123711585999, 0.514970064163208, 0.5196426510810852, 0.5291537642478943, 0.5067666172981262, 0.5124109387397766, 0.519853413105011, 0.512519359588623, 0.5049810409545898, 0.5182893872261047, 0.5211122632026672, 0.5109766125679016, 0.4958939850330353, 0.5011308193206787, 0.501528799533844, 0.5022637844085693, 0.4956131875514984, 0.4976540207862854, 0.498855859041214, 0.4956419765949249, 0.496961772441864, 0.4946739375591278, 0.5067406296730042, 0.5107958316802979, 0.48490390181541443, 0.4863751530647278, 0.49464988708496094, 0.49962863326072693], 'accuracy': [0.7839439511299133, 0.798222005367279, 0.7971444129943848, 0.803071141242981, 0.8092672228813171, 0.8044180870056152, 0.8041487336158752, 0.8054956793785095, 0.8200430870056152, 0.8003771305084229, 0.8135775923728943, 0.8143857717514038, 0.8133081793785095, 0.8100754022598267, 0.821659505367279, 0.8270474076271057, 0.8205819129943848, 0.814116358757019, 0.8270474076271057, 0.829741358757019, 0.8154633641242981, 0.821659505367279, 0.8289331793785095, 0.8305495977401733, 0.8278555870056152, 0.8257004022598267, 0.8254310488700867, 0.8254310488700867, 0.8257004022598267, 0.837284505367279, 0.8380926847457886, 0.8316271305084229, 0.8364762663841248, 0.8337823152542114, 0.8413254022598267, 0.8389008641242981, 0.8413254022598267, 0.828125, 0.8348599076271057, 0.8391702771186829, 0.8370150923728943, 0.8459051847457886, 0.8494073152542114, 0.8534482717514038, 0.8383620977401733, 0.8410560488700867, 0.8469827771186829, 0.8545258641242981, 0.8402478694915771, 0.8402478694915771, 0.8504849076271057, 0.834321141242981, 0.8337823152542114, 0.8510237336158752, 0.850215494632721, 0.8582974076271057, 0.8574892282485962, 0.8569504022598267, 0.8521012663841248, 0.8639547228813171, 0.858027994632721, 0.8591055870056152, 0.8631465435028076, 0.8534482717514038, 0.8397090435028076, 0.8599137663841248, 0.8599137663841248, 0.8612607717514038, 0.8566810488700867, 0.8612607717514038, 0.8612607717514038, 0.8461745977401733, 0.8569504022598267, 0.8650323152542114, 0.8572198152542114, 0.8550646305084229, 0.8714978694915771, 0.8639547228813171, 0.859375, 0.8604525923728943, 0.873652994632721, 0.8626077771186829, 0.8539870977401733, 0.8690732717514038, 0.8758081793785095, 0.8723060488700867, 0.8712284564971924, 0.868803858757019, 0.8747305870056152, 0.8701508641242981, 0.8803879022598267, 0.8709590435028076, 0.868803858757019, 0.8679956793785095, 0.8706896305084229, 0.8706896305084229, 0.8793103694915771, 0.8744612336158752, 0.8747305870056152, 0.8704202771186829], 'val_loss': [0.9143876433372498, 0.9064981937408447, 0.9053782820701599, 0.9108532667160034, 0.8959311842918396, 0.9022554159164429, 0.9338195323944092, 0.9270398616790771, 0.9153339862823486, 0.9195978045463562, 0.8993002772331238, 0.8766778707504272, 0.8997478485107422, 0.909561038017273, 0.8842695355415344, 0.8972958922386169, 0.9049695134162903, 0.8647355437278748, 0.8728606700897217, 0.8604341745376587, 0.8664215207099915, 0.8646140694618225, 0.8673186898231506, 0.9777603149414062, 0.937056303024292, 0.8930464386940002, 0.9340031743049622, 1.090767502784729, 1.009597897529602, 0.9441694021224976, 0.920689046382904, 0.9593409299850464, 0.937211275100708, 0.9671788215637207, 0.9426599740982056, 0.9466391205787659, 1.0854911804199219, 0.94187992811203, 0.9464096426963806, 0.990176796913147, 1.0220997333526611, 0.980942964553833, 0.9849218726158142, 0.9876314401626587, 1.0977370738983154, 0.9733739495277405, 0.9576003551483154, 1.0738613605499268, 1.0153297185897827, 0.9979917407035828, 1.049052357673645, 1.0614893436431885, 1.0416887998580933, 1.0430865287780762, 0.9940915107727051, 0.9996739625930786, 1.0341309309005737, 1.0021570920944214, 1.0143953561782837, 1.0114986896514893, 0.9961493015289307, 1.0762474536895752, 1.0989466905593872, 1.0925709009170532, 1.0473871231079102, 1.103679895401001, 0.9899852871894836, 1.0458035469055176, 1.101728916168213, 1.058453917503357, 1.0224732160568237, 1.0535353422164917, 1.0987591743469238, 1.1406300067901611, 1.0284123420715332, 1.1688604354858398, 1.1150745153427124, 1.1206152439117432, 1.0946741104125977, 1.11244797706604, 1.1554999351501465, 1.0895273685455322, 1.1224836111068726, 1.119343876838684, 1.1407376527786255, 1.0980172157287598, 1.1080305576324463, 1.1784957647323608, 1.0884642601013184, 1.1006580591201782, 1.0422528982162476, 1.180628776550293, 1.2359037399291992, 1.2976495027542114, 1.1980403661727905, 1.0593737363815308, 1.2126933336257935, 1.1341770887374878, 1.3354259729385376, 1.32646644115448], 'val_accuracy': [0.4989224076271057, 0.5226293206214905, 0.5592672228813171, 0.514008641242981, 0.5441810488700867, 0.5269396305084229, 0.506465494632721, 0.517241358757019, 0.5344827771186829, 0.5355603694915771, 0.5538793206214905, 0.5969827771186829, 0.5614224076271057, 0.5754310488700867, 0.5894396305084229, 0.6056034564971924, 0.6443965435028076, 0.6260775923728943, 0.6551724076271057, 0.6648706793785095, 0.6659482717514038, 0.6778017282485962, 0.6821120977401733, 0.6691810488700867, 0.662715494632721, 0.6799569129943848, 0.6864224076271057, 0.6508620977401733, 0.6433189511299133, 0.6670258641242981, 0.6842672228813171, 0.6756465435028076, 0.673491358757019, 0.6875, 0.6637930870056152, 0.6713362336158752, 0.6616379022598267, 0.6745689511299133, 0.670258641242981, 0.6831896305084229, 0.6637930870056152, 0.6691810488700867, 0.6551724076271057, 0.6756465435028076, 0.6648706793785095, 0.6637930870056152, 0.6713362336158752, 0.670258641242981, 0.6605603694915771, 0.6465517282485962, 0.6713362336158752, 0.6368534564971924, 0.6745689511299133, 0.6799569129943848, 0.6605603694915771, 0.673491358757019, 0.6454741358757019, 0.6605603694915771, 0.662715494632721, 0.6724137663841248, 0.6540948152542114, 0.6551724076271057, 0.6519396305084229, 0.6670258641242981, 0.6670258641242981, 0.6594827771186829, 0.6691810488700867, 0.6659482717514038, 0.649784505367279, 0.6616379022598267, 0.6616379022598267, 0.6530172228813171, 0.649784505367279, 0.6443965435028076, 0.6745689511299133, 0.6530172228813171, 0.6681034564971924, 0.6271551847457886, 0.6368534564971924, 0.6454741358757019, 0.670258641242981, 0.639008641242981, 0.6433189511299133, 0.6476293206214905, 0.6551724076271057, 0.6745689511299133, 0.6594827771186829, 0.631465494632721, 0.6433189511299133, 0.6681034564971924, 0.6616379022598267, 0.649784505367279, 0.6196120977401733, 0.6411637663841248, 0.6508620977401733, 0.6681034564971924, 0.6196120977401733, 0.6476293206214905, 0.6012930870056152, 0.6303879022598267]}\n","38/38 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 3s 29ms/step - loss: 0.6435 - accuracy: 0.7864 - val_loss: 0.9061 - val_accuracy: 0.5238\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.6559 - accuracy: 0.7969"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 18ms/step - loss: 0.6317 - accuracy: 0.7937 - val_loss: 0.9043 - val_accuracy: 0.5441\n","Epoch 3/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6325 - accuracy: 0.7957 - val_loss: 0.9036 - val_accuracy: 0.5271\n","Epoch 4/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6269 - accuracy: 0.8076 - val_loss: 0.9034 - val_accuracy: 0.5283\n","Epoch 5/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6188 - accuracy: 0.8217 - val_loss: 0.9016 - val_accuracy: 0.5260\n","Epoch 6/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6128 - accuracy: 0.8124 - val_loss: 0.9008 - val_accuracy: 0.5283\n","Epoch 7/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6150 - accuracy: 0.8166 - val_loss: 0.8996 - val_accuracy: 0.5328\n","Epoch 8/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6066 - accuracy: 0.8209 - val_loss: 0.9068 - val_accuracy: 0.5362\n","Epoch 9/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6096 - accuracy: 0.8169 - val_loss: 0.8846 - val_accuracy: 0.5588\n","Epoch 10/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6074 - accuracy: 0.8231 - val_loss: 0.9016 - val_accuracy: 0.5532\n","Epoch 11/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6070 - accuracy: 0.8130 - val_loss: 0.9160 - val_accuracy: 0.5554\n","Epoch 12/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6040 - accuracy: 0.8203 - val_loss: 0.9024 - val_accuracy: 0.5667\n","Epoch 13/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6081 - accuracy: 0.8248 - val_loss: 0.8998 - val_accuracy: 0.5803\n","Epoch 14/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5953 - accuracy: 0.8277 - val_loss: 0.8668 - val_accuracy: 0.5928\n","Epoch 15/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6002 - accuracy: 0.8226 - val_loss: 0.8766 - val_accuracy: 0.5905\n","Epoch 16/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5952 - accuracy: 0.8246 - val_loss: 0.8545 - val_accuracy: 0.6210\n","Epoch 17/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5923 - accuracy: 0.8294 - val_loss: 0.8874 - val_accuracy: 0.6007\n","Epoch 18/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5890 - accuracy: 0.8280 - val_loss: 0.8450 - val_accuracy: 0.6403\n","Epoch 19/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5928 - accuracy: 0.8285 - val_loss: 0.8500 - val_accuracy: 0.6380\n","Epoch 20/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5893 - accuracy: 0.8297 - val_loss: 0.9026 - val_accuracy: 0.6244\n","Epoch 21/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5884 - accuracy: 0.8240 - val_loss: 0.8560 - val_accuracy: 0.6459\n","Epoch 22/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5977 - accuracy: 0.8220 - val_loss: 0.8713 - val_accuracy: 0.6618\n","Epoch 23/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5813 - accuracy: 0.8362 - val_loss: 0.8557 - val_accuracy: 0.6652\n","Epoch 24/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5979 - accuracy: 0.8246 - val_loss: 0.9105 - val_accuracy: 0.6538\n","Epoch 25/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5803 - accuracy: 0.8342 - val_loss: 0.8656 - val_accuracy: 0.6765\n","Epoch 26/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5797 - accuracy: 0.8314 - val_loss: 0.8676 - val_accuracy: 0.6686\n","Epoch 27/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5770 - accuracy: 0.8396 - val_loss: 0.8763 - val_accuracy: 0.6595\n","Epoch 28/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5750 - accuracy: 0.8418 - val_loss: 0.8894 - val_accuracy: 0.6731\n","Epoch 29/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5725 - accuracy: 0.8328 - val_loss: 0.9221 - val_accuracy: 0.6844\n","Epoch 30/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5730 - accuracy: 0.8319 - val_loss: 0.8865 - val_accuracy: 0.6753\n","Epoch 31/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5694 - accuracy: 0.8376 - val_loss: 0.8873 - val_accuracy: 0.6787\n","Epoch 32/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5651 - accuracy: 0.8438 - val_loss: 0.9158 - val_accuracy: 0.6731\n","Epoch 33/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5675 - accuracy: 0.8384 - val_loss: 0.9450 - val_accuracy: 0.6742\n","Epoch 34/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5686 - accuracy: 0.8447 - val_loss: 0.9225 - val_accuracy: 0.6640\n","Epoch 35/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5811 - accuracy: 0.8319 - val_loss: 0.9030 - val_accuracy: 0.6663\n","Epoch 36/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6080 - accuracy: 0.8192 - val_loss: 0.9818 - val_accuracy: 0.6686\n","Epoch 37/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5801 - accuracy: 0.8288 - val_loss: 0.9243 - val_accuracy: 0.6606\n","Epoch 38/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5664 - accuracy: 0.8384 - val_loss: 0.9143 - val_accuracy: 0.6663\n","Epoch 39/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5621 - accuracy: 0.8384 - val_loss: 0.9751 - val_accuracy: 0.6708\n","Epoch 40/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5719 - accuracy: 0.8356 - val_loss: 0.9229 - val_accuracy: 0.6697\n","Epoch 41/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5637 - accuracy: 0.8362 - val_loss: 0.9354 - val_accuracy: 0.6708\n","Epoch 42/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5573 - accuracy: 0.8466 - val_loss: 0.9335 - val_accuracy: 0.6686\n","Epoch 43/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5546 - accuracy: 0.8486 - val_loss: 0.9451 - val_accuracy: 0.6697\n","Epoch 44/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5575 - accuracy: 0.8398 - val_loss: 0.9109 - val_accuracy: 0.6686\n","Epoch 45/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5509 - accuracy: 0.8458 - val_loss: 0.9631 - val_accuracy: 0.6799\n","Epoch 46/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5474 - accuracy: 0.8560 - val_loss: 0.9155 - val_accuracy: 0.6731\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5518 - accuracy: 0.8503 - val_loss: 0.9273 - val_accuracy: 0.6663\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5458 - accuracy: 0.8492 - val_loss: 0.9665 - val_accuracy: 0.6708\n","Epoch 49/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5749 - accuracy: 0.8387 - val_loss: 0.9943 - val_accuracy: 0.6538\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5611 - accuracy: 0.8500 - val_loss: 0.9351 - val_accuracy: 0.6663\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5580 - accuracy: 0.8466 - val_loss: 0.9811 - val_accuracy: 0.6629\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5784 - accuracy: 0.8350 - val_loss: 1.0951 - val_accuracy: 0.6584\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5580 - accuracy: 0.8444 - val_loss: 0.9844 - val_accuracy: 0.6663\n","Epoch 54/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5418 - accuracy: 0.8557 - val_loss: 0.9785 - val_accuracy: 0.6629\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5354 - accuracy: 0.8639 - val_loss: 0.9891 - val_accuracy: 0.6731\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5398 - accuracy: 0.8526 - val_loss: 1.0051 - val_accuracy: 0.6708\n","Epoch 57/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5368 - accuracy: 0.8574 - val_loss: 0.9587 - val_accuracy: 0.6572\n","Epoch 58/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5346 - accuracy: 0.8571 - val_loss: 0.9617 - val_accuracy: 0.6584\n","Epoch 59/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5399 - accuracy: 0.8551 - val_loss: 0.9808 - val_accuracy: 0.6640\n","Epoch 60/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5355 - accuracy: 0.8554 - val_loss: 0.9645 - val_accuracy: 0.6697\n","Epoch 61/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5280 - accuracy: 0.8662 - val_loss: 0.9591 - val_accuracy: 0.6629\n","Epoch 62/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5374 - accuracy: 0.8520 - val_loss: 0.9826 - val_accuracy: 0.6561\n","Epoch 63/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5244 - accuracy: 0.8679 - val_loss: 0.9545 - val_accuracy: 0.6753\n","Epoch 64/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5318 - accuracy: 0.8537 - val_loss: 1.0027 - val_accuracy: 0.6640\n","Epoch 65/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5329 - accuracy: 0.8673 - val_loss: 1.0322 - val_accuracy: 0.6697\n","Epoch 66/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5416 - accuracy: 0.8571 - val_loss: 0.9696 - val_accuracy: 0.6572\n","Epoch 67/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5316 - accuracy: 0.8577 - val_loss: 1.0144 - val_accuracy: 0.6595\n","Epoch 68/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5362 - accuracy: 0.8585 - val_loss: 0.9663 - val_accuracy: 0.6595\n","Epoch 69/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5555 - accuracy: 0.8480 - val_loss: 1.0583 - val_accuracy: 0.6482\n","Epoch 70/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5356 - accuracy: 0.8537 - val_loss: 0.9977 - val_accuracy: 0.6572\n","Epoch 71/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5247 - accuracy: 0.8599 - val_loss: 1.0274 - val_accuracy: 0.6697\n","Epoch 72/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5190 - accuracy: 0.8676 - val_loss: 1.0044 - val_accuracy: 0.6719\n","Epoch 73/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5200 - accuracy: 0.8721 - val_loss: 1.0227 - val_accuracy: 0.6550\n","Epoch 74/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5124 - accuracy: 0.8710 - val_loss: 1.0378 - val_accuracy: 0.6640\n","Epoch 75/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5135 - accuracy: 0.8752 - val_loss: 1.0104 - val_accuracy: 0.6697\n","Epoch 76/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5103 - accuracy: 0.8718 - val_loss: 1.0446 - val_accuracy: 0.6686\n","Epoch 77/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5106 - accuracy: 0.8744 - val_loss: 1.0297 - val_accuracy: 0.6595\n","Epoch 78/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5130 - accuracy: 0.8693 - val_loss: 1.0295 - val_accuracy: 0.6538\n","Epoch 79/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5162 - accuracy: 0.8563 - val_loss: 1.0557 - val_accuracy: 0.6663\n","Epoch 80/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5148 - accuracy: 0.8628 - val_loss: 1.0610 - val_accuracy: 0.6561\n","Epoch 81/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5112 - accuracy: 0.8662 - val_loss: 1.0928 - val_accuracy: 0.6538\n","Epoch 82/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5199 - accuracy: 0.8608 - val_loss: 1.1035 - val_accuracy: 0.6765\n","Epoch 83/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5175 - accuracy: 0.8596 - val_loss: 1.0701 - val_accuracy: 0.6618\n","Epoch 84/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5055 - accuracy: 0.8687 - val_loss: 1.0661 - val_accuracy: 0.6584\n","Epoch 85/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5043 - accuracy: 0.8673 - val_loss: 1.0662 - val_accuracy: 0.6561\n","Epoch 86/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5012 - accuracy: 0.8681 - val_loss: 1.0719 - val_accuracy: 0.6629\n","Epoch 87/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5026 - accuracy: 0.8698 - val_loss: 1.0549 - val_accuracy: 0.6584\n","Epoch 88/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5054 - accuracy: 0.8670 - val_loss: 1.0641 - val_accuracy: 0.6516\n","Epoch 89/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5266 - accuracy: 0.8599 - val_loss: 1.1517 - val_accuracy: 0.6505\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5016 - accuracy: 0.8778 - val_loss: 1.0680 - val_accuracy: 0.6595\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5015 - accuracy: 0.8783 - val_loss: 1.0913 - val_accuracy: 0.6629\n","Epoch 92/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5197 - accuracy: 0.8613 - val_loss: 1.1518 - val_accuracy: 0.6414\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5047 - accuracy: 0.8727 - val_loss: 1.0900 - val_accuracy: 0.6584\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4932 - accuracy: 0.8783 - val_loss: 1.1826 - val_accuracy: 0.6527\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4982 - accuracy: 0.8758 - val_loss: 1.0859 - val_accuracy: 0.6584\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4929 - accuracy: 0.8735 - val_loss: 1.1405 - val_accuracy: 0.6629\n","Epoch 97/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5005 - accuracy: 0.8721 - val_loss: 1.1003 - val_accuracy: 0.6572\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5030 - accuracy: 0.8693 - val_loss: 1.0860 - val_accuracy: 0.6663\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4948 - accuracy: 0.8775 - val_loss: 1.1112 - val_accuracy: 0.6674\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4849 - accuracy: 0.8877 - val_loss: 1.1084 - val_accuracy: 0.6584\n","{'loss': [0.6434533596038818, 0.6317096948623657, 0.6324844360351562, 0.6269087791442871, 0.6188241243362427, 0.61279296875, 0.6149553656578064, 0.606596827507019, 0.6096043586730957, 0.6073994040489197, 0.6070379614830017, 0.6040448546409607, 0.6081495881080627, 0.5952585935592651, 0.6002137064933777, 0.5952104330062866, 0.5923017859458923, 0.5890184044837952, 0.5927504301071167, 0.5893076062202454, 0.5884135961532593, 0.5977227091789246, 0.5813259482383728, 0.5979406237602234, 0.5802609920501709, 0.5797292590141296, 0.5770017504692078, 0.5750377774238586, 0.5724812150001526, 0.5729650855064392, 0.5694401860237122, 0.5650969743728638, 0.5675052404403687, 0.5685601234436035, 0.5810573101043701, 0.6079572439193726, 0.580129861831665, 0.5664279460906982, 0.5620648264884949, 0.5718531608581543, 0.5636591911315918, 0.5572801828384399, 0.5545994639396667, 0.5575128197669983, 0.5509095788002014, 0.547386109828949, 0.5518267750740051, 0.5457704663276672, 0.5749112367630005, 0.5610724091529846, 0.5580138564109802, 0.57844078540802, 0.5580399632453918, 0.5418009757995605, 0.5353518724441528, 0.5398421287536621, 0.5367713570594788, 0.5345714688301086, 0.5398944616317749, 0.5354703664779663, 0.5280190110206604, 0.5373581647872925, 0.5244210362434387, 0.5318061709403992, 0.5328958034515381, 0.5416495203971863, 0.5315629243850708, 0.5362106561660767, 0.5555087924003601, 0.5356467962265015, 0.5246680378913879, 0.5189520120620728, 0.5199692845344543, 0.5123798251152039, 0.5135237574577332, 0.5102851390838623, 0.5106076598167419, 0.5130060911178589, 0.5161770582199097, 0.51479172706604, 0.5112464427947998, 0.5199140906333923, 0.517548143863678, 0.5054628849029541, 0.5043041706085205, 0.5012484788894653, 0.5026254653930664, 0.5053895115852356, 0.5266318321228027, 0.5016146898269653, 0.5014625191688538, 0.519661009311676, 0.5047351717948914, 0.4931644797325134, 0.4982166588306427, 0.4928959012031555, 0.5005181431770325, 0.5030136704444885, 0.49479204416275024, 0.48487722873687744], 'accuracy': [0.786361038684845, 0.793718159198761, 0.7956989407539368, 0.8075834512710571, 0.8217317461967468, 0.8123939037322998, 0.8166383504867554, 0.8208828568458557, 0.8169213533401489, 0.8231465816497803, 0.8129597902297974, 0.8203169107437134, 0.8248443603515625, 0.8276740312576294, 0.8225806355476379, 0.8245614171028137, 0.8293718099594116, 0.8279569745063782, 0.8285229206085205, 0.8296547532081604, 0.8239954710006714, 0.8220146894454956, 0.8361629843711853, 0.8245614171028137, 0.8341822028160095, 0.8313525915145874, 0.8395586013793945, 0.8418223261833191, 0.8327674269676208, 0.831918478012085, 0.8375778198242188, 0.8438030481338501, 0.8384267091751099, 0.8446519374847412, 0.831918478012085, 0.8191850781440735, 0.8288058638572693, 0.8384267091751099, 0.8384267091751099, 0.835597038269043, 0.8361629843711853, 0.846632719039917, 0.848613440990448, 0.8398415446281433, 0.8457838296890259, 0.855970561504364, 0.850311279296875, 0.8491793870925903, 0.8387096524238586, 0.8500282764434814, 0.846632719039917, 0.8350311517715454, 0.8443689942359924, 0.8556876182556152, 0.8638936281204224, 0.8525750041007996, 0.8573853969573975, 0.8571024537086487, 0.8551216721534729, 0.8554046154022217, 0.8661573529243469, 0.8520090579986572, 0.8678551316261292, 0.8537068367004395, 0.8672891855239868, 0.8571024537086487, 0.8576683402061462, 0.8585172891616821, 0.8480475544929504, 0.8537068367004395, 0.8599320650100708, 0.8675721287727356, 0.8720995783805847, 0.8709677457809448, 0.8752122521400452, 0.8718166351318359, 0.8743633031845093, 0.8692699670791626, 0.8562535643577576, 0.8627617359161377, 0.8661573529243469, 0.8607810139656067, 0.859649121761322, 0.8687040209770203, 0.8672891855239868, 0.8681380748748779, 0.8698358535766602, 0.867006242275238, 0.8599320650100708, 0.8777589201927185, 0.8783248662948608, 0.8613469004631042, 0.872665524482727, 0.8783248662948608, 0.8757781386375427, 0.8735144138336182, 0.8720995783805847, 0.8692699670791626, 0.8774759769439697, 0.8876627087593079], 'val_loss': [0.9060530066490173, 0.904296338558197, 0.9035522937774658, 0.903420627117157, 0.9016216993331909, 0.9008061289787292, 0.8996251225471497, 0.9068154692649841, 0.884590208530426, 0.9015649557113647, 0.9159955382347107, 0.9024402499198914, 0.8997573256492615, 0.8668058514595032, 0.8765771389007568, 0.8544992208480835, 0.8874495029449463, 0.8449956178665161, 0.850044846534729, 0.9026117920875549, 0.8560206890106201, 0.8713271021842957, 0.8557240962982178, 0.9104607105255127, 0.8655911087989807, 0.8675751090049744, 0.876298189163208, 0.8893617391586304, 0.9221423268318176, 0.8864650130271912, 0.8872906565666199, 0.9158463478088379, 0.9450329542160034, 0.9225162863731384, 0.9030372500419617, 0.9818293452262878, 0.9243457317352295, 0.9142655730247498, 0.9751001596450806, 0.9229481816291809, 0.9353775382041931, 0.9335441589355469, 0.9451236128807068, 0.910870373249054, 0.9630559682846069, 0.915489137172699, 0.9273369312286377, 0.9665147662162781, 0.9942905902862549, 0.935117781162262, 0.9811091423034668, 1.0950897932052612, 0.9843759536743164, 0.9784911870956421, 0.9891466498374939, 1.0050729513168335, 0.9587041735649109, 0.9616909027099609, 0.9807956218719482, 0.9644896388053894, 0.9590643048286438, 0.9826465845108032, 0.954501211643219, 1.0026586055755615, 1.0322225093841553, 0.9695674777030945, 1.0144325494766235, 0.9663097262382507, 1.058320164680481, 0.9977317452430725, 1.0274348258972168, 1.0043859481811523, 1.022712230682373, 1.0378271341323853, 1.0103684663772583, 1.0445737838745117, 1.0297431945800781, 1.0295108556747437, 1.0556930303573608, 1.0610451698303223, 1.0927836894989014, 1.1034526824951172, 1.0700758695602417, 1.0660535097122192, 1.0661829710006714, 1.0718536376953125, 1.0549073219299316, 1.0641264915466309, 1.1516673564910889, 1.0680134296417236, 1.0913290977478027, 1.1517770290374756, 1.090034008026123, 1.1825553178787231, 1.0859421491622925, 1.1404534578323364, 1.1003494262695312, 1.0859962701797485, 1.111171841621399, 1.1084176301956177], 'val_accuracy': [0.523755669593811, 0.5441176295280457, 0.5271493196487427, 0.5282805562019348, 0.5260180830955505, 0.5282805562019348, 0.5328054428100586, 0.5361990928649902, 0.5588235259056091, 0.5531674027442932, 0.5554298758506775, 0.5667420625686646, 0.5803167223930359, 0.5927602052688599, 0.5904977321624756, 0.6210407018661499, 0.6006787419319153, 0.6402714848518372, 0.6380090713500977, 0.6244344115257263, 0.6459276080131531, 0.6617646813392639, 0.6651583909988403, 0.6538461446762085, 0.6764705777168274, 0.668552041053772, 0.6595022678375244, 0.6730769276618958, 0.6843891143798828, 0.6753393411636353, 0.6787330508232117, 0.6730769276618958, 0.6742081642150879, 0.6640271544456482, 0.6662895679473877, 0.668552041053772, 0.6606335043907166, 0.6662895679473877, 0.6708144545555115, 0.6696832776069641, 0.6708144545555115, 0.668552041053772, 0.6696832776069641, 0.668552041053772, 0.679864227771759, 0.6730769276618958, 0.6662895679473877, 0.6708144545555115, 0.6538461446762085, 0.6662895679473877, 0.662895917892456, 0.6583710312843323, 0.6662895679473877, 0.662895917892456, 0.6730769276618958, 0.6708144545555115, 0.6572397947311401, 0.6583710312843323, 0.6640271544456482, 0.6696832776069641, 0.662895917892456, 0.6561086177825928, 0.6753393411636353, 0.6640271544456482, 0.6696832776069641, 0.6572397947311401, 0.6595022678375244, 0.6595022678375244, 0.6481900215148926, 0.6572397947311401, 0.6696832776069641, 0.6719456911087036, 0.6549773812294006, 0.6640271544456482, 0.6696832776069641, 0.668552041053772, 0.6595022678375244, 0.6538461446762085, 0.6662895679473877, 0.6561086177825928, 0.6538461446762085, 0.6764705777168274, 0.6617646813392639, 0.6583710312843323, 0.6561086177825928, 0.662895917892456, 0.6583710312843323, 0.651583731174469, 0.6504524946212769, 0.6595022678375244, 0.662895917892456, 0.6414027214050293, 0.6583710312843323, 0.6527149081230164, 0.6583710312843323, 0.662895917892456, 0.6572397947311401, 0.6662895679473877, 0.6674208045005798, 0.6583710312843323]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 4s 33ms/step - loss: 0.6741 - accuracy: 0.7718 - val_loss: 0.9035 - val_accuracy: 0.5733\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.7069 - accuracy: 0.8125"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 15ms/step - loss: 0.6612 - accuracy: 0.7713 - val_loss: 0.9033 - val_accuracy: 0.5372\n","Epoch 3/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6460 - accuracy: 0.7987 - val_loss: 0.9025 - val_accuracy: 0.5661\n","Epoch 4/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6441 - accuracy: 0.7894 - val_loss: 0.8986 - val_accuracy: 0.5682\n","Epoch 5/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6437 - accuracy: 0.7817 - val_loss: 0.8997 - val_accuracy: 0.5434\n","Epoch 6/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6447 - accuracy: 0.7891 - val_loss: 0.9134 - val_accuracy: 0.5196\n","Epoch 7/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6292 - accuracy: 0.8013 - val_loss: 0.9038 - val_accuracy: 0.5238\n","Epoch 8/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6354 - accuracy: 0.7990 - val_loss: 0.8987 - val_accuracy: 0.5289\n","Epoch 9/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6288 - accuracy: 0.7953 - val_loss: 0.8848 - val_accuracy: 0.5826\n","Epoch 10/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6283 - accuracy: 0.8028 - val_loss: 0.8888 - val_accuracy: 0.5486\n","Epoch 11/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6311 - accuracy: 0.8013 - val_loss: 0.8893 - val_accuracy: 0.5465\n","Epoch 12/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6256 - accuracy: 0.8034 - val_loss: 0.8884 - val_accuracy: 0.5527\n","Epoch 13/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6207 - accuracy: 0.7910 - val_loss: 0.8804 - val_accuracy: 0.5795\n","Epoch 14/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6246 - accuracy: 0.8008 - val_loss: 0.9188 - val_accuracy: 0.5455\n","Epoch 15/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6203 - accuracy: 0.8085 - val_loss: 0.8689 - val_accuracy: 0.5888\n","Epoch 16/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6194 - accuracy: 0.8039 - val_loss: 0.8586 - val_accuracy: 0.6116\n","Epoch 17/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6162 - accuracy: 0.8147 - val_loss: 0.8621 - val_accuracy: 0.6095\n","Epoch 18/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6138 - accuracy: 0.8116 - val_loss: 0.9032 - val_accuracy: 0.6023\n","Epoch 19/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6234 - accuracy: 0.8026 - val_loss: 0.8789 - val_accuracy: 0.6281\n","Epoch 20/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6103 - accuracy: 0.8065 - val_loss: 0.8588 - val_accuracy: 0.6322\n","Epoch 21/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6072 - accuracy: 0.8147 - val_loss: 0.9000 - val_accuracy: 0.6364\n","Epoch 22/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6135 - accuracy: 0.8088 - val_loss: 0.9447 - val_accuracy: 0.6374\n","Epoch 23/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6114 - accuracy: 0.8124 - val_loss: 0.8904 - val_accuracy: 0.6415\n","Epoch 24/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6028 - accuracy: 0.8142 - val_loss: 0.9014 - val_accuracy: 0.6477\n","Epoch 25/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5996 - accuracy: 0.8235 - val_loss: 0.8906 - val_accuracy: 0.6384\n","Epoch 26/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6121 - accuracy: 0.8013 - val_loss: 1.0323 - val_accuracy: 0.6405\n","Epoch 27/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6294 - accuracy: 0.7969 - val_loss: 0.9811 - val_accuracy: 0.6364\n","Epoch 28/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6199 - accuracy: 0.7990 - val_loss: 1.0015 - val_accuracy: 0.6436\n","Epoch 29/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6145 - accuracy: 0.8041 - val_loss: 0.9156 - val_accuracy: 0.6384\n","Epoch 30/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6082 - accuracy: 0.8096 - val_loss: 0.9214 - val_accuracy: 0.6436\n","Epoch 31/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5932 - accuracy: 0.8256 - val_loss: 0.9286 - val_accuracy: 0.6467\n","Epoch 32/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5890 - accuracy: 0.8248 - val_loss: 0.9171 - val_accuracy: 0.6498\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5936 - accuracy: 0.8214 - val_loss: 0.9472 - val_accuracy: 0.6291\n","Epoch 34/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5875 - accuracy: 0.8315 - val_loss: 0.9261 - val_accuracy: 0.6477\n","Epoch 35/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5938 - accuracy: 0.8240 - val_loss: 0.9799 - val_accuracy: 0.6302\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5872 - accuracy: 0.8204 - val_loss: 0.9978 - val_accuracy: 0.6281\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5949 - accuracy: 0.8176 - val_loss: 1.0950 - val_accuracy: 0.6426\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5894 - accuracy: 0.8258 - val_loss: 0.9860 - val_accuracy: 0.6364\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5917 - accuracy: 0.8225 - val_loss: 0.9932 - val_accuracy: 0.6312\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5737 - accuracy: 0.8323 - val_loss: 0.9830 - val_accuracy: 0.6240\n","Epoch 41/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5762 - accuracy: 0.8313 - val_loss: 1.0002 - val_accuracy: 0.6374\n","Epoch 42/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5980 - accuracy: 0.8137 - val_loss: 0.9459 - val_accuracy: 0.6353\n","Epoch 43/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5838 - accuracy: 0.8196 - val_loss: 0.9548 - val_accuracy: 0.6333\n","Epoch 44/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5769 - accuracy: 0.8305 - val_loss: 0.9216 - val_accuracy: 0.6446\n","Epoch 45/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5734 - accuracy: 0.8279 - val_loss: 0.9413 - val_accuracy: 0.6426\n","Epoch 46/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5704 - accuracy: 0.8359 - val_loss: 0.9679 - val_accuracy: 0.6291\n","Epoch 47/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5814 - accuracy: 0.8315 - val_loss: 1.0402 - val_accuracy: 0.6353\n","Epoch 48/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5778 - accuracy: 0.8256 - val_loss: 1.0223 - val_accuracy: 0.6415\n","Epoch 49/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5681 - accuracy: 0.8336 - val_loss: 0.9669 - val_accuracy: 0.6446\n","Epoch 50/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5695 - accuracy: 0.8302 - val_loss: 0.9620 - val_accuracy: 0.6343\n","Epoch 51/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5884 - accuracy: 0.8264 - val_loss: 1.0299 - val_accuracy: 0.6219\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5849 - accuracy: 0.8225 - val_loss: 0.9802 - val_accuracy: 0.6312\n","Epoch 53/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5687 - accuracy: 0.8362 - val_loss: 0.9710 - val_accuracy: 0.6374\n","Epoch 54/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5667 - accuracy: 0.8349 - val_loss: 0.9672 - val_accuracy: 0.6374\n","Epoch 55/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5684 - accuracy: 0.8367 - val_loss: 0.9757 - val_accuracy: 0.6312\n","Epoch 56/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5659 - accuracy: 0.8432 - val_loss: 0.9707 - val_accuracy: 0.6395\n","Epoch 57/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5581 - accuracy: 0.8406 - val_loss: 0.9863 - val_accuracy: 0.6271\n","Epoch 58/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5732 - accuracy: 0.8214 - val_loss: 1.0830 - val_accuracy: 0.6405\n","Epoch 59/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5588 - accuracy: 0.8406 - val_loss: 1.0020 - val_accuracy: 0.6229\n","Epoch 60/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5616 - accuracy: 0.8450 - val_loss: 1.0839 - val_accuracy: 0.6436\n","Epoch 61/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5624 - accuracy: 0.8442 - val_loss: 1.1177 - val_accuracy: 0.6312\n","Epoch 62/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5598 - accuracy: 0.8401 - val_loss: 0.9543 - val_accuracy: 0.6312\n","Epoch 63/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5587 - accuracy: 0.8323 - val_loss: 1.0128 - val_accuracy: 0.6374\n","Epoch 64/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5500 - accuracy: 0.8432 - val_loss: 1.0191 - val_accuracy: 0.6405\n","Epoch 65/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5550 - accuracy: 0.8364 - val_loss: 1.0088 - val_accuracy: 0.6322\n","Epoch 66/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5528 - accuracy: 0.8380 - val_loss: 1.0040 - val_accuracy: 0.6477\n","Epoch 67/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5628 - accuracy: 0.8395 - val_loss: 1.0039 - val_accuracy: 0.6333\n","Epoch 68/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5596 - accuracy: 0.8333 - val_loss: 1.0819 - val_accuracy: 0.6250\n","Epoch 69/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5479 - accuracy: 0.8419 - val_loss: 1.0111 - val_accuracy: 0.6415\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5467 - accuracy: 0.8447 - val_loss: 1.0147 - val_accuracy: 0.6322\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5438 - accuracy: 0.8432 - val_loss: 1.0046 - val_accuracy: 0.6260\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5407 - accuracy: 0.8468 - val_loss: 1.0362 - val_accuracy: 0.6229\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5402 - accuracy: 0.8486 - val_loss: 1.0427 - val_accuracy: 0.6415\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5397 - accuracy: 0.8553 - val_loss: 0.9895 - val_accuracy: 0.6343\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5392 - accuracy: 0.8450 - val_loss: 0.9905 - val_accuracy: 0.6426\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5480 - accuracy: 0.8473 - val_loss: 1.0125 - val_accuracy: 0.6291\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5332 - accuracy: 0.8537 - val_loss: 1.0558 - val_accuracy: 0.6343\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5323 - accuracy: 0.8561 - val_loss: 1.0165 - val_accuracy: 0.6240\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5297 - accuracy: 0.8589 - val_loss: 1.0701 - val_accuracy: 0.6281\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5323 - accuracy: 0.8525 - val_loss: 1.0522 - val_accuracy: 0.6291\n","Epoch 81/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5383 - accuracy: 0.8504 - val_loss: 1.0262 - val_accuracy: 0.6198\n","Epoch 82/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5347 - accuracy: 0.8457 - val_loss: 1.1660 - val_accuracy: 0.6085\n","Epoch 83/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5280 - accuracy: 0.8612 - val_loss: 1.1093 - val_accuracy: 0.6209\n","Epoch 84/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5408 - accuracy: 0.8419 - val_loss: 1.1254 - val_accuracy: 0.6322\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5504 - accuracy: 0.8491 - val_loss: 1.0755 - val_accuracy: 0.6467\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5289 - accuracy: 0.8535 - val_loss: 1.1500 - val_accuracy: 0.5961\n","Epoch 87/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5513 - accuracy: 0.8380 - val_loss: 1.3281 - val_accuracy: 0.6260\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5672 - accuracy: 0.8375 - val_loss: 1.0974 - val_accuracy: 0.6343\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5238 - accuracy: 0.8587 - val_loss: 1.1398 - val_accuracy: 0.6405\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5323 - accuracy: 0.8488 - val_loss: 1.0006 - val_accuracy: 0.6281\n","Epoch 91/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5351 - accuracy: 0.8452 - val_loss: 1.0677 - val_accuracy: 0.6260\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5331 - accuracy: 0.8602 - val_loss: 1.0711 - val_accuracy: 0.6281\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5160 - accuracy: 0.8646 - val_loss: 1.0466 - val_accuracy: 0.6353\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5191 - accuracy: 0.8584 - val_loss: 1.1444 - val_accuracy: 0.6178\n","Epoch 95/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5392 - accuracy: 0.8473 - val_loss: 1.2210 - val_accuracy: 0.6384\n","Epoch 96/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5638 - accuracy: 0.8248 - val_loss: 1.0463 - val_accuracy: 0.6291\n","Epoch 97/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5409 - accuracy: 0.8424 - val_loss: 1.0676 - val_accuracy: 0.6426\n","Epoch 98/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5179 - accuracy: 0.8556 - val_loss: 1.0240 - val_accuracy: 0.6322\n","Epoch 99/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5176 - accuracy: 0.8687 - val_loss: 1.1020 - val_accuracy: 0.6209\n","Epoch 100/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5348 - accuracy: 0.8599 - val_loss: 1.1184 - val_accuracy: 0.6240\n","{'loss': [0.6741282939910889, 0.6611889600753784, 0.6459591388702393, 0.6440640687942505, 0.6437297463417053, 0.6447300910949707, 0.6292290091514587, 0.6353828310966492, 0.6287793517112732, 0.6282686591148376, 0.6311128735542297, 0.6255658864974976, 0.6207451820373535, 0.6246303915977478, 0.6203261613845825, 0.6193870902061462, 0.6162068247795105, 0.613805890083313, 0.6234371662139893, 0.6102532148361206, 0.6072458028793335, 0.6134749054908752, 0.6113842725753784, 0.6027626395225525, 0.5995762944221497, 0.6120545268058777, 0.6293618083000183, 0.6199079155921936, 0.6144847273826599, 0.6082345843315125, 0.5931969285011292, 0.5890363454818726, 0.593576192855835, 0.5875110030174255, 0.5937662720680237, 0.5872182846069336, 0.5949339270591736, 0.5893844962120056, 0.5917260050773621, 0.5736923813819885, 0.5762282609939575, 0.5980274677276611, 0.5838010311126709, 0.5768691301345825, 0.5734429359436035, 0.5704147219657898, 0.5813556909561157, 0.577813446521759, 0.5680604577064514, 0.5694897770881653, 0.5883608460426331, 0.5849120020866394, 0.5687360167503357, 0.5666640400886536, 0.5684382319450378, 0.5659381151199341, 0.5581163763999939, 0.5732309818267822, 0.5587578415870667, 0.5615672469139099, 0.5624219179153442, 0.5597949624061584, 0.558733344078064, 0.5500380992889404, 0.5549828410148621, 0.5528261661529541, 0.5627828240394592, 0.5596027374267578, 0.5479347109794617, 0.5467119812965393, 0.5438259840011597, 0.5407094359397888, 0.5401925444602966, 0.5396671295166016, 0.5392214059829712, 0.5480315685272217, 0.5332416892051697, 0.5323445796966553, 0.529656171798706, 0.5323280096054077, 0.5383217930793762, 0.5347113609313965, 0.5280224084854126, 0.5408194065093994, 0.5504133105278015, 0.5289164185523987, 0.551278293132782, 0.5672140121459961, 0.5237950682640076, 0.5322620868682861, 0.5350624322891235, 0.533074676990509, 0.5159680247306824, 0.5190505981445312, 0.5391583442687988, 0.5638076066970825, 0.5409300923347473, 0.5178588032722473, 0.5176032185554504, 0.5348227620124817], 'accuracy': [0.7718346118927002, 0.7713178396224976, 0.7987080216407776, 0.7894057035446167, 0.7816537618637085, 0.7891472578048706, 0.8012920022010803, 0.7989664077758789, 0.7953488230705261, 0.802842378616333, 0.8012920022010803, 0.8033591508865356, 0.7909560799598694, 0.8007751703262329, 0.8085271120071411, 0.8038759827613831, 0.8147286772727966, 0.8116279244422913, 0.8025839924812317, 0.8064599633216858, 0.8147286772727966, 0.8087855577468872, 0.8124030828475952, 0.814211905002594, 0.8235142230987549, 0.8012920022010803, 0.7968991994857788, 0.7989664077758789, 0.8041343688964844, 0.8095607161521912, 0.8255813717842102, 0.8248062133789062, 0.8214470148086548, 0.8315245509147644, 0.8240309953689575, 0.8204134106636047, 0.8175710439682007, 0.8258398175239563, 0.8224806189537048, 0.8322997689247131, 0.8312661647796631, 0.8136950731277466, 0.8196382522583008, 0.8304909467697144, 0.8279069662094116, 0.8359172940254211, 0.8315245509147644, 0.8255813717842102, 0.8335917592048645, 0.830232560634613, 0.8263565897941589, 0.8224806189537048, 0.8361757397651672, 0.8348837494850159, 0.8366925120353699, 0.8431524634361267, 0.840568482875824, 0.8214470148086548, 0.840568482875824, 0.8449612259864807, 0.8441860675811768, 0.8400516510009766, 0.8322997689247131, 0.8431524634361267, 0.8364341259002686, 0.8379845023155212, 0.8395348787307739, 0.8333333134651184, 0.8418604731559753, 0.8447028398513794, 0.8431524634361267, 0.8467700481414795, 0.8485788106918335, 0.8552971482276917, 0.8449612259864807, 0.8472868204116821, 0.853746771812439, 0.8560723662376404, 0.8589147329330444, 0.8524547815322876, 0.8503875732421875, 0.8457364439964294, 0.8612403273582458, 0.8418604731559753, 0.8490955829620361, 0.8534883856773376, 0.8379845023155212, 0.8374677300453186, 0.8586563467979431, 0.8488371968269348, 0.845219612121582, 0.8602067232131958, 0.8645994663238525, 0.8583979606628418, 0.8472868204116821, 0.8248062133789062, 0.842377245426178, 0.855555534362793, 0.868733823299408, 0.8599483370780945], 'val_loss': [0.9035271406173706, 0.9032718539237976, 0.9025367498397827, 0.8985835313796997, 0.8997435569763184, 0.9134258031845093, 0.9037538766860962, 0.8987154960632324, 0.8847941160202026, 0.8888142704963684, 0.88925701379776, 0.888410210609436, 0.8804263472557068, 0.9187989830970764, 0.8689284920692444, 0.8586156368255615, 0.8620617389678955, 0.9032201766967773, 0.8788661360740662, 0.858774721622467, 0.8999984264373779, 0.9447445273399353, 0.8904162049293518, 0.9013837575912476, 0.8906205892562866, 1.032291293144226, 0.9810745120048523, 1.001489520072937, 0.9155921339988708, 0.9213804006576538, 0.9285843372344971, 0.9170628190040588, 0.9471655488014221, 0.9261024594306946, 0.9799473881721497, 0.9977543354034424, 1.0949970483779907, 0.9860076308250427, 0.9932337403297424, 0.9829923510551453, 1.0001955032348633, 0.9459139704704285, 0.954780638217926, 0.9215883016586304, 0.9413101673126221, 0.967854380607605, 1.040187120437622, 1.0223069190979004, 0.9668715000152588, 0.9620041251182556, 1.0299350023269653, 0.9801598787307739, 0.970986008644104, 0.9672251343727112, 0.975749135017395, 0.9707092046737671, 0.9862762093544006, 1.0829800367355347, 1.0020016431808472, 1.0838874578475952, 1.117701530456543, 0.9543347358703613, 1.0128083229064941, 1.0191056728363037, 1.0087928771972656, 1.0039840936660767, 1.0038858652114868, 1.0818777084350586, 1.0110597610473633, 1.0147427320480347, 1.0046088695526123, 1.0361582040786743, 1.0427039861679077, 0.9894679188728333, 0.9905157685279846, 1.0124602317810059, 1.055849552154541, 1.0165109634399414, 1.0700769424438477, 1.0522422790527344, 1.0262137651443481, 1.1659770011901855, 1.1092751026153564, 1.1254074573516846, 1.0754987001419067, 1.1500352621078491, 1.3281441926956177, 1.0973703861236572, 1.1398286819458008, 1.0005980730056763, 1.067667841911316, 1.071144938468933, 1.0465575456619263, 1.1444406509399414, 1.220967411994934, 1.046283483505249, 1.0675575733184814, 1.0240156650543213, 1.1020002365112305, 1.1184321641921997], 'val_accuracy': [0.5733470916748047, 0.5371900796890259, 0.56611567735672, 0.5681818127632141, 0.5433884263038635, 0.51962810754776, 0.5237603187561035, 0.5289255976676941, 0.5826446413993835, 0.5485537052154541, 0.5464876294136047, 0.5526859760284424, 0.5795454382896423, 0.5454545617103577, 0.5888429880142212, 0.6115702390670776, 0.6095041036605835, 0.6022727489471436, 0.6280992031097412, 0.6322314143180847, 0.6363636255264282, 0.6373966932296753, 0.6415289044380188, 0.6477272510528564, 0.6384297609329224, 0.6404958963394165, 0.6363636255264282, 0.6435950398445129, 0.6384297609329224, 0.6435950398445129, 0.6466942429542542, 0.6497933864593506, 0.6291322112083435, 0.6477272510528564, 0.6301652789115906, 0.6280992031097412, 0.6425619721412659, 0.6363636255264282, 0.6311983466148376, 0.6239669322967529, 0.6373966932296753, 0.6353305578231812, 0.6332644820213318, 0.64462810754776, 0.6425619721412659, 0.6291322112083435, 0.6353305578231812, 0.6415289044380188, 0.64462810754776, 0.6342975497245789, 0.6219007968902588, 0.6311983466148376, 0.6373966932296753, 0.6373966932296753, 0.6311983466148376, 0.6394628286361694, 0.6270661354064941, 0.6404958963394165, 0.6229338645935059, 0.6435950398445129, 0.6311983466148376, 0.6311983466148376, 0.6373966932296753, 0.6404958963394165, 0.6322314143180847, 0.6477272510528564, 0.6332644820213318, 0.625, 0.6415289044380188, 0.6322314143180847, 0.6260330677032471, 0.6229338645935059, 0.6415289044380188, 0.6342975497245789, 0.6425619721412659, 0.6291322112083435, 0.6342975497245789, 0.6239669322967529, 0.6280992031097412, 0.6291322112083435, 0.6198347210884094, 0.6084710955619812, 0.6208677887916565, 0.6322314143180847, 0.6466942429542542, 0.5960744023323059, 0.6260330677032471, 0.6342975497245789, 0.6404958963394165, 0.6280992031097412, 0.6260330677032471, 0.6280992031097412, 0.6353305578231812, 0.6177685856819153, 0.6384297609329224, 0.6291322112083435, 0.6425619721412659, 0.6322314143180847, 0.6208677887916565, 0.6239669322967529]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 4s 28ms/step - loss: 0.5550 - accuracy: 0.8341 - val_loss: 0.9006 - val_accuracy: 0.5022\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.5033 - accuracy: 0.8828"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 17ms/step - loss: 0.5302 - accuracy: 0.8618 - val_loss: 0.8936 - val_accuracy: 0.5108\n","Epoch 3/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5354 - accuracy: 0.8483 - val_loss: 0.8889 - val_accuracy: 0.5399\n","Epoch 4/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5278 - accuracy: 0.8553 - val_loss: 0.9091 - val_accuracy: 0.5075\n","Epoch 5/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5285 - accuracy: 0.8578 - val_loss: 0.9585 - val_accuracy: 0.5043\n","Epoch 6/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5180 - accuracy: 0.8607 - val_loss: 0.9216 - val_accuracy: 0.5140\n","Epoch 7/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5209 - accuracy: 0.8607 - val_loss: 0.8937 - val_accuracy: 0.5323\n","Epoch 8/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5297 - accuracy: 0.8537 - val_loss: 0.9170 - val_accuracy: 0.5226\n","Epoch 9/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5382 - accuracy: 0.8626 - val_loss: 0.9652 - val_accuracy: 0.5237\n","Epoch 10/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5253 - accuracy: 0.8594 - val_loss: 0.9903 - val_accuracy: 0.5226\n","Epoch 11/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5158 - accuracy: 0.8605 - val_loss: 0.9100 - val_accuracy: 0.5420\n","Epoch 12/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5288 - accuracy: 0.8486 - val_loss: 0.9413 - val_accuracy: 0.5388\n","Epoch 13/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5191 - accuracy: 0.8526 - val_loss: 0.8941 - val_accuracy: 0.5787\n","Epoch 14/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5161 - accuracy: 0.8615 - val_loss: 0.8722 - val_accuracy: 0.6078\n","Epoch 15/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5193 - accuracy: 0.8683 - val_loss: 0.8632 - val_accuracy: 0.6562\n","Epoch 16/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5152 - accuracy: 0.8642 - val_loss: 0.8995 - val_accuracy: 0.6056\n","Epoch 17/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5079 - accuracy: 0.8645 - val_loss: 0.9023 - val_accuracy: 0.6239\n","Epoch 18/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5072 - accuracy: 0.8621 - val_loss: 0.8751 - val_accuracy: 0.6315\n","Epoch 19/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5084 - accuracy: 0.8648 - val_loss: 0.8473 - val_accuracy: 0.6638\n","Epoch 20/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5027 - accuracy: 0.8653 - val_loss: 0.8598 - val_accuracy: 0.6584\n","Epoch 21/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5009 - accuracy: 0.8718 - val_loss: 0.8384 - val_accuracy: 0.7091\n","Epoch 22/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4922 - accuracy: 0.8742 - val_loss: 0.8632 - val_accuracy: 0.6767\n","Epoch 23/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4989 - accuracy: 0.8621 - val_loss: 0.8561 - val_accuracy: 0.6897\n","Epoch 24/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5008 - accuracy: 0.8575 - val_loss: 0.8955 - val_accuracy: 0.6961\n","Epoch 25/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5007 - accuracy: 0.8658 - val_loss: 0.9581 - val_accuracy: 0.6498\n","Epoch 26/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5070 - accuracy: 0.8570 - val_loss: 0.9660 - val_accuracy: 0.7091\n","Epoch 27/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5052 - accuracy: 0.8634 - val_loss: 0.9070 - val_accuracy: 0.6789\n","Epoch 28/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4861 - accuracy: 0.8836 - val_loss: 0.9168 - val_accuracy: 0.7015\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4845 - accuracy: 0.8809 - val_loss: 0.9224 - val_accuracy: 0.6983\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4887 - accuracy: 0.8769 - val_loss: 0.9338 - val_accuracy: 0.7091\n","Epoch 31/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4917 - accuracy: 0.8753 - val_loss: 0.9131 - val_accuracy: 0.7166\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4845 - accuracy: 0.8780 - val_loss: 0.9869 - val_accuracy: 0.7015\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4864 - accuracy: 0.8769 - val_loss: 0.9649 - val_accuracy: 0.7112\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4884 - accuracy: 0.8785 - val_loss: 0.9553 - val_accuracy: 0.7112\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4950 - accuracy: 0.8782 - val_loss: 1.0428 - val_accuracy: 0.7080\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4819 - accuracy: 0.8798 - val_loss: 1.1103 - val_accuracy: 0.6703\n","Epoch 37/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4980 - accuracy: 0.8618 - val_loss: 1.0942 - val_accuracy: 0.6509\n","Epoch 38/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5070 - accuracy: 0.8675 - val_loss: 0.9922 - val_accuracy: 0.6918\n","Epoch 39/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4771 - accuracy: 0.8801 - val_loss: 1.0297 - val_accuracy: 0.6918\n","Epoch 40/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4749 - accuracy: 0.8836 - val_loss: 0.9567 - val_accuracy: 0.6994\n","Epoch 41/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4735 - accuracy: 0.8912 - val_loss: 0.9835 - val_accuracy: 0.7144\n","Epoch 42/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4722 - accuracy: 0.8874 - val_loss: 1.0023 - val_accuracy: 0.7080\n","Epoch 43/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4838 - accuracy: 0.8758 - val_loss: 1.1096 - val_accuracy: 0.6638\n","Epoch 44/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4759 - accuracy: 0.8804 - val_loss: 1.1640 - val_accuracy: 0.6433\n","Epoch 45/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4749 - accuracy: 0.8863 - val_loss: 1.0972 - val_accuracy: 0.6670\n","Epoch 46/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4764 - accuracy: 0.8780 - val_loss: 1.0553 - val_accuracy: 0.6821\n","Epoch 47/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4870 - accuracy: 0.8780 - val_loss: 1.0420 - val_accuracy: 0.7134\n","Epoch 48/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4771 - accuracy: 0.8820 - val_loss: 1.0479 - val_accuracy: 0.6670\n","Epoch 49/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4701 - accuracy: 0.8839 - val_loss: 1.0573 - val_accuracy: 0.6649\n","Epoch 50/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4806 - accuracy: 0.8731 - val_loss: 1.1098 - val_accuracy: 0.6746\n","Epoch 51/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4856 - accuracy: 0.8745 - val_loss: 1.1282 - val_accuracy: 0.6940\n","Epoch 52/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4691 - accuracy: 0.8939 - val_loss: 1.2094 - val_accuracy: 0.6552\n","Epoch 53/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4849 - accuracy: 0.8715 - val_loss: 1.0793 - val_accuracy: 0.6681\n","Epoch 54/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4883 - accuracy: 0.8707 - val_loss: 1.0982 - val_accuracy: 0.6562\n","Epoch 55/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4793 - accuracy: 0.8766 - val_loss: 1.0112 - val_accuracy: 0.6800\n","Epoch 56/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4694 - accuracy: 0.8852 - val_loss: 1.1046 - val_accuracy: 0.7004\n","Epoch 57/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4596 - accuracy: 0.8909 - val_loss: 1.0532 - val_accuracy: 0.7058\n","Epoch 58/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4564 - accuracy: 0.8936 - val_loss: 1.0093 - val_accuracy: 0.6778\n","Epoch 59/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4588 - accuracy: 0.8947 - val_loss: 1.0797 - val_accuracy: 0.6509\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4636 - accuracy: 0.8852 - val_loss: 1.0571 - val_accuracy: 0.6940\n","Epoch 61/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4629 - accuracy: 0.8882 - val_loss: 0.9847 - val_accuracy: 0.7037\n","Epoch 62/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4555 - accuracy: 0.8925 - val_loss: 1.0125 - val_accuracy: 0.6703\n","Epoch 63/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4783 - accuracy: 0.8772 - val_loss: 1.0973 - val_accuracy: 0.6562\n","Epoch 64/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4568 - accuracy: 0.8895 - val_loss: 1.0380 - val_accuracy: 0.7015\n","Epoch 65/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4589 - accuracy: 0.8947 - val_loss: 0.9943 - val_accuracy: 0.6929\n","Epoch 66/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4577 - accuracy: 0.8877 - val_loss: 1.0361 - val_accuracy: 0.6616\n","Epoch 67/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4467 - accuracy: 0.8990 - val_loss: 1.1451 - val_accuracy: 0.6756\n","Epoch 68/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4535 - accuracy: 0.8979 - val_loss: 0.9994 - val_accuracy: 0.6994\n","Epoch 69/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4490 - accuracy: 0.8917 - val_loss: 1.0815 - val_accuracy: 0.6562\n","Epoch 70/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4547 - accuracy: 0.8874 - val_loss: 1.1451 - val_accuracy: 0.6509\n","Epoch 71/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4474 - accuracy: 0.8957 - val_loss: 1.0768 - val_accuracy: 0.6929\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4495 - accuracy: 0.8982 - val_loss: 1.2000 - val_accuracy: 0.6509\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4455 - accuracy: 0.9011 - val_loss: 1.1975 - val_accuracy: 0.6476\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4857 - accuracy: 0.8699 - val_loss: 1.1534 - val_accuracy: 0.6950\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4543 - accuracy: 0.8922 - val_loss: 1.1181 - val_accuracy: 0.6541\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4462 - accuracy: 0.8922 - val_loss: 1.2848 - val_accuracy: 0.6595\n","Epoch 77/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4656 - accuracy: 0.8901 - val_loss: 1.0684 - val_accuracy: 0.6724\n","Epoch 78/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4454 - accuracy: 0.9033 - val_loss: 1.1464 - val_accuracy: 0.6476\n","Epoch 79/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4397 - accuracy: 0.8971 - val_loss: 1.0436 - val_accuracy: 0.6929\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4471 - accuracy: 0.8992 - val_loss: 1.2104 - val_accuracy: 0.6659\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4618 - accuracy: 0.8912 - val_loss: 1.0629 - val_accuracy: 0.7004\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4451 - accuracy: 0.8957 - val_loss: 1.0982 - val_accuracy: 0.7004\n","Epoch 83/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4459 - accuracy: 0.8990 - val_loss: 1.0853 - val_accuracy: 0.6810\n","Epoch 84/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4416 - accuracy: 0.8952 - val_loss: 1.1356 - val_accuracy: 0.6950\n","Epoch 85/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4612 - accuracy: 0.8804 - val_loss: 1.2735 - val_accuracy: 0.6659\n","Epoch 86/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4438 - accuracy: 0.9001 - val_loss: 1.0543 - val_accuracy: 0.7037\n","Epoch 87/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4354 - accuracy: 0.8987 - val_loss: 1.0886 - val_accuracy: 0.6746\n","Epoch 88/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4310 - accuracy: 0.9046 - val_loss: 1.1064 - val_accuracy: 0.6778\n","Epoch 89/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4352 - accuracy: 0.8974 - val_loss: 1.1448 - val_accuracy: 0.6530\n","Epoch 90/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4330 - accuracy: 0.8968 - val_loss: 1.1422 - val_accuracy: 0.6606\n","Epoch 91/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4386 - accuracy: 0.8928 - val_loss: 1.1490 - val_accuracy: 0.6746\n","Epoch 92/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4318 - accuracy: 0.9006 - val_loss: 1.3118 - val_accuracy: 0.6509\n","Epoch 93/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4342 - accuracy: 0.8987 - val_loss: 1.1290 - val_accuracy: 0.6875\n","Epoch 94/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4257 - accuracy: 0.9073 - val_loss: 1.0569 - val_accuracy: 0.6853\n","Epoch 95/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4384 - accuracy: 0.8992 - val_loss: 1.1602 - val_accuracy: 0.6767\n","Epoch 96/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4575 - accuracy: 0.8992 - val_loss: 1.2788 - val_accuracy: 0.6875\n","Epoch 97/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4425 - accuracy: 0.8960 - val_loss: 1.2295 - val_accuracy: 0.6519\n","Epoch 98/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4507 - accuracy: 0.8901 - val_loss: 1.0746 - val_accuracy: 0.6994\n","Epoch 99/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4458 - accuracy: 0.8939 - val_loss: 1.4097 - val_accuracy: 0.6659\n","Epoch 100/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4413 - accuracy: 0.8871 - val_loss: 1.2340 - val_accuracy: 0.6670\n","{'loss': [0.5550186634063721, 0.5301647782325745, 0.5354112386703491, 0.5277992486953735, 0.5285153388977051, 0.5180427432060242, 0.5208749771118164, 0.529739260673523, 0.5382415056228638, 0.5252541899681091, 0.5158483982086182, 0.5288069248199463, 0.519111156463623, 0.5160939693450928, 0.5193029046058655, 0.5151975154876709, 0.507929265499115, 0.5071902871131897, 0.5084110498428345, 0.5027467608451843, 0.5008856058120728, 0.4921659827232361, 0.4988569915294647, 0.5008285641670227, 0.5007227659225464, 0.5070444345474243, 0.5052262544631958, 0.4860575795173645, 0.4845280945301056, 0.48874303698539734, 0.49165335297584534, 0.4845385253429413, 0.4864121377468109, 0.4883982837200165, 0.4949694275856018, 0.4819435775279999, 0.4979604184627533, 0.5070210695266724, 0.4771096110343933, 0.4749416410923004, 0.4734859764575958, 0.4722181558609009, 0.48376768827438354, 0.4758686423301697, 0.4749397337436676, 0.4763982892036438, 0.4869554042816162, 0.47709178924560547, 0.47014936804771423, 0.480648010969162, 0.4856395721435547, 0.469136506319046, 0.4848940372467041, 0.48825836181640625, 0.4792633652687073, 0.46941083669662476, 0.45957502722740173, 0.45643362402915955, 0.45881780982017517, 0.4636048972606659, 0.4629494249820709, 0.4554624855518341, 0.47828733921051025, 0.456773579120636, 0.4589431881904602, 0.4576599895954132, 0.4466874599456787, 0.4534813463687897, 0.4489591717720032, 0.454717755317688, 0.4473838806152344, 0.44951507449150085, 0.44554403424263, 0.485675573348999, 0.4542684853076935, 0.4462004601955414, 0.4656291902065277, 0.445355087518692, 0.4396940767765045, 0.44706636667251587, 0.4618406295776367, 0.44511300325393677, 0.4459352493286133, 0.4416162669658661, 0.4611627757549286, 0.4438188374042511, 0.4353558123111725, 0.4309539198875427, 0.4351780414581299, 0.4330175220966339, 0.4385910928249359, 0.43179312348365784, 0.4341653287410736, 0.42574343085289, 0.4384361207485199, 0.45745083689689636, 0.44247812032699585, 0.4506596624851227, 0.4457589089870453, 0.4413045644760132], 'accuracy': [0.8340517282485962, 0.8617995977401733, 0.8483297228813171, 0.8553340435028076, 0.857758641242981, 0.860722005367279, 0.860722005367279, 0.8537176847457886, 0.8626077771186829, 0.859375, 0.8604525923728943, 0.8485991358757019, 0.8526400923728943, 0.8615301847457886, 0.8682650923728943, 0.8642241358757019, 0.8644935488700867, 0.8620689511299133, 0.8647629022598267, 0.8653017282485962, 0.8717672228813171, 0.8741918206214905, 0.8620689511299133, 0.8574892282485962, 0.865840494632721, 0.8569504022598267, 0.8634159564971924, 0.8836206793785095, 0.8809267282485962, 0.8768857717514038, 0.8752694129943848, 0.8779633641242981, 0.8768857717514038, 0.8785021305084229, 0.8782327771186829, 0.8798491358757019, 0.8617995977401733, 0.8674569129943848, 0.8801185488700867, 0.8836206793785095, 0.8911637663841248, 0.8873922228813171, 0.8758081793785095, 0.8803879022598267, 0.8863146305084229, 0.8779633641242981, 0.8779633641242981, 0.8820043206214905, 0.8838900923728943, 0.8731142282485962, 0.8744612336158752, 0.8938577771186829, 0.8714978694915771, 0.8706896305084229, 0.876616358757019, 0.8852370977401733, 0.8908944129943848, 0.8935883641242981, 0.8946659564971924, 0.8852370977401733, 0.8882004022598267, 0.8925107717514038, 0.8771551847457886, 0.8895474076271057, 0.8946659564971924, 0.8876616358757019, 0.8989762663841248, 0.8978987336158752, 0.8917025923728943, 0.8873922228813171, 0.8957435488700867, 0.8981680870056152, 0.9011314511299133, 0.8698814511299133, 0.892241358757019, 0.892241358757019, 0.8900862336158752, 0.9032866358757019, 0.897090494632721, 0.8992456793785095, 0.8911637663841248, 0.8957435488700867, 0.8989762663841248, 0.8952047228813171, 0.8803879022598267, 0.900053858757019, 0.8987069129943848, 0.904633641242981, 0.8973599076271057, 0.896821141242981, 0.8927801847457886, 0.9005926847457886, 0.8987069129943848, 0.9073275923728943, 0.8992456793785095, 0.8992456793785095, 0.8960129022598267, 0.8900862336158752, 0.8938577771186829, 0.8871228694915771], 'val_loss': [0.9006389379501343, 0.8936260342597961, 0.8889102935791016, 0.9091110229492188, 0.9585382342338562, 0.9215704202651978, 0.893673300743103, 0.9170488119125366, 0.9652412533760071, 0.9903414249420166, 0.9100177884101868, 0.9413219094276428, 0.8941406011581421, 0.8722394108772278, 0.8631701469421387, 0.8994969129562378, 0.9023221135139465, 0.8750892877578735, 0.8473042249679565, 0.8597546815872192, 0.8383708000183105, 0.8632329702377319, 0.8560991883277893, 0.8955122828483582, 0.9580798149108887, 0.9659659266471863, 0.9069548845291138, 0.9168148040771484, 0.9223608374595642, 0.9338221549987793, 0.9130626320838928, 0.9868622422218323, 0.9648873805999756, 0.9553011655807495, 1.0428180694580078, 1.1103111505508423, 1.094156265258789, 0.992194652557373, 1.0297110080718994, 0.9566992521286011, 0.9834761619567871, 1.0023431777954102, 1.1096042394638062, 1.1639509201049805, 1.0972481966018677, 1.0553253889083862, 1.0420429706573486, 1.0479143857955933, 1.0573068857192993, 1.1097862720489502, 1.1282039880752563, 1.2094215154647827, 1.079318642616272, 1.0982242822647095, 1.0111771821975708, 1.104629635810852, 1.0532156229019165, 1.0093202590942383, 1.079676628112793, 1.0571136474609375, 0.984678328037262, 1.0125305652618408, 1.097337007522583, 1.038008451461792, 0.9942744970321655, 1.0361416339874268, 1.1450936794281006, 0.9994347095489502, 1.0815008878707886, 1.1450749635696411, 1.0767576694488525, 1.2000083923339844, 1.1975300312042236, 1.1534298658370972, 1.118144154548645, 1.2847819328308105, 1.0684486627578735, 1.1463593244552612, 1.0436129570007324, 1.2104312181472778, 1.062869906425476, 1.0982352495193481, 1.0852564573287964, 1.1356362104415894, 1.2734649181365967, 1.0543124675750732, 1.0885872840881348, 1.1063693761825562, 1.1448132991790771, 1.142236590385437, 1.1489521265029907, 1.3117601871490479, 1.129045009613037, 1.0569393634796143, 1.1601842641830444, 1.278762936592102, 1.2295007705688477, 1.0745818614959717, 1.4096919298171997, 1.2340086698532104], 'val_accuracy': [0.5021551847457886, 0.5107758641242981, 0.5398706793785095, 0.5075430870056152, 0.5043103694915771, 0.514008641242981, 0.5323275923728943, 0.5226293206214905, 0.5237069129943848, 0.5226293206214905, 0.5420258641242981, 0.5387930870056152, 0.5786637663841248, 0.607758641242981, 0.65625, 0.6056034564971924, 0.6239224076271057, 0.631465494632721, 0.6637930870056152, 0.6584051847457886, 0.7090517282485962, 0.6767241358757019, 0.6896551847457886, 0.6961206793785095, 0.649784505367279, 0.7090517282485962, 0.6788793206214905, 0.701508641242981, 0.6982758641242981, 0.7090517282485962, 0.7165948152542114, 0.701508641242981, 0.7112069129943848, 0.7112069129943848, 0.7079741358757019, 0.670258641242981, 0.6508620977401733, 0.6918103694915771, 0.6918103694915771, 0.6993534564971924, 0.7144396305084229, 0.7079741358757019, 0.6637930870056152, 0.6433189511299133, 0.6670258641242981, 0.6821120977401733, 0.7133620977401733, 0.6670258641242981, 0.6648706793785095, 0.6745689511299133, 0.693965494632721, 0.6551724076271057, 0.6681034564971924, 0.65625, 0.6799569129943848, 0.7004310488700867, 0.7058189511299133, 0.6778017282485962, 0.6508620977401733, 0.693965494632721, 0.7036637663841248, 0.670258641242981, 0.65625, 0.701508641242981, 0.6928879022598267, 0.6616379022598267, 0.6756465435028076, 0.6993534564971924, 0.65625, 0.6508620977401733, 0.6928879022598267, 0.6508620977401733, 0.6476293206214905, 0.6950430870056152, 0.6540948152542114, 0.6594827771186829, 0.6724137663841248, 0.6476293206214905, 0.6928879022598267, 0.6659482717514038, 0.7004310488700867, 0.7004310488700867, 0.681034505367279, 0.6950430870056152, 0.6659482717514038, 0.7036637663841248, 0.6745689511299133, 0.6778017282485962, 0.6530172228813171, 0.6605603694915771, 0.6745689511299133, 0.6508620977401733, 0.6875, 0.6853448152542114, 0.6767241358757019, 0.6875, 0.6519396305084229, 0.6993534564971924, 0.6659482717514038, 0.6670258641242981]}\n","38/38 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 3s 28ms/step - loss: 0.5619 - accuracy: 0.8271 - val_loss: 0.8917 - val_accuracy: 0.5611\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.5101 - accuracy: 0.8828"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 11ms/step - loss: 0.5546 - accuracy: 0.8401 - val_loss: 0.8925 - val_accuracy: 0.5238\n","Epoch 3/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5415 - accuracy: 0.8427 - val_loss: 0.9002 - val_accuracy: 0.5260\n","Epoch 4/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5349 - accuracy: 0.8580 - val_loss: 0.9046 - val_accuracy: 0.5260\n","Epoch 5/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5256 - accuracy: 0.8602 - val_loss: 0.9000 - val_accuracy: 0.5215\n","Epoch 6/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5164 - accuracy: 0.8568 - val_loss: 0.9101 - val_accuracy: 0.5385\n","Epoch 7/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5200 - accuracy: 0.8580 - val_loss: 0.8986 - val_accuracy: 0.5317\n","Epoch 8/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5172 - accuracy: 0.8690 - val_loss: 0.9172 - val_accuracy: 0.5464\n","Epoch 9/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5109 - accuracy: 0.8653 - val_loss: 0.9231 - val_accuracy: 0.5486\n","Epoch 10/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5181 - accuracy: 0.8650 - val_loss: 0.8730 - val_accuracy: 0.5679\n","Epoch 11/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5133 - accuracy: 0.8650 - val_loss: 0.8720 - val_accuracy: 0.5690\n","Epoch 12/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5146 - accuracy: 0.8653 - val_loss: 0.8947 - val_accuracy: 0.5645\n","Epoch 13/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5121 - accuracy: 0.8673 - val_loss: 0.8894 - val_accuracy: 0.5747\n","Epoch 14/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5070 - accuracy: 0.8715 - val_loss: 0.9117 - val_accuracy: 0.5735\n","Epoch 15/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5078 - accuracy: 0.8656 - val_loss: 0.8388 - val_accuracy: 0.6414\n","Epoch 16/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5188 - accuracy: 0.8546 - val_loss: 0.8842 - val_accuracy: 0.6109\n","Epoch 17/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5324 - accuracy: 0.8520 - val_loss: 0.9253 - val_accuracy: 0.6052\n","Epoch 18/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5612 - accuracy: 0.8347 - val_loss: 0.8519 - val_accuracy: 0.6765\n","Epoch 19/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5243 - accuracy: 0.8630 - val_loss: 0.8299 - val_accuracy: 0.6606\n","Epoch 20/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5075 - accuracy: 0.8679 - val_loss: 0.8502 - val_accuracy: 0.6629\n","Epoch 21/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5217 - accuracy: 0.8636 - val_loss: 0.8362 - val_accuracy: 0.6900\n","Epoch 22/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5141 - accuracy: 0.8701 - val_loss: 0.8418 - val_accuracy: 0.6946\n","Epoch 23/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5117 - accuracy: 0.8613 - val_loss: 0.8447 - val_accuracy: 0.7059\n","Epoch 24/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5051 - accuracy: 0.8707 - val_loss: 0.8252 - val_accuracy: 0.7002\n","Epoch 25/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4892 - accuracy: 0.8800 - val_loss: 0.8479 - val_accuracy: 0.7161\n","Epoch 26/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4875 - accuracy: 0.8795 - val_loss: 0.8603 - val_accuracy: 0.7206\n","Epoch 27/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5029 - accuracy: 0.8713 - val_loss: 0.8647 - val_accuracy: 0.7262\n","Epoch 28/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5142 - accuracy: 0.8727 - val_loss: 0.8307 - val_accuracy: 0.7161\n","Epoch 29/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4940 - accuracy: 0.8721 - val_loss: 0.9142 - val_accuracy: 0.7115\n","Epoch 30/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4970 - accuracy: 0.8752 - val_loss: 0.9134 - val_accuracy: 0.7014\n","Epoch 31/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4917 - accuracy: 0.8800 - val_loss: 0.9224 - val_accuracy: 0.7025\n","Epoch 32/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4960 - accuracy: 0.8840 - val_loss: 0.9141 - val_accuracy: 0.7115\n","Epoch 33/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4900 - accuracy: 0.8758 - val_loss: 0.8992 - val_accuracy: 0.7161\n","Epoch 34/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4823 - accuracy: 0.8803 - val_loss: 0.8812 - val_accuracy: 0.7183\n","Epoch 35/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4789 - accuracy: 0.8857 - val_loss: 0.9035 - val_accuracy: 0.7251\n","Epoch 36/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4799 - accuracy: 0.8843 - val_loss: 0.9197 - val_accuracy: 0.7195\n","Epoch 37/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4827 - accuracy: 0.8806 - val_loss: 0.8794 - val_accuracy: 0.7104\n","Epoch 38/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4869 - accuracy: 0.8693 - val_loss: 0.8940 - val_accuracy: 0.7217\n","Epoch 39/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4839 - accuracy: 0.8766 - val_loss: 0.9304 - val_accuracy: 0.7251\n","Epoch 40/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4799 - accuracy: 0.8826 - val_loss: 0.9039 - val_accuracy: 0.7115\n","Epoch 41/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4787 - accuracy: 0.8763 - val_loss: 0.9069 - val_accuracy: 0.7149\n","Epoch 42/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4861 - accuracy: 0.8817 - val_loss: 0.9607 - val_accuracy: 0.7183\n","Epoch 43/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5019 - accuracy: 0.8763 - val_loss: 0.9898 - val_accuracy: 0.6946\n","Epoch 44/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4839 - accuracy: 0.8749 - val_loss: 0.9761 - val_accuracy: 0.7195\n","Epoch 45/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4755 - accuracy: 0.8874 - val_loss: 0.9627 - val_accuracy: 0.7240\n","Epoch 46/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4787 - accuracy: 0.8851 - val_loss: 0.9899 - val_accuracy: 0.6934\n","Epoch 47/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4955 - accuracy: 0.8715 - val_loss: 0.9444 - val_accuracy: 0.6980\n","Epoch 48/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4898 - accuracy: 0.8673 - val_loss: 1.0390 - val_accuracy: 0.6844\n","Epoch 49/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4785 - accuracy: 0.8803 - val_loss: 0.9584 - val_accuracy: 0.7059\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4780 - accuracy: 0.8795 - val_loss: 0.9637 - val_accuracy: 0.7002\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4868 - accuracy: 0.8752 - val_loss: 0.9600 - val_accuracy: 0.7149\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4768 - accuracy: 0.8894 - val_loss: 1.0489 - val_accuracy: 0.7059\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4873 - accuracy: 0.8792 - val_loss: 0.9801 - val_accuracy: 0.6912\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4890 - accuracy: 0.8707 - val_loss: 0.9949 - val_accuracy: 0.6833\n","Epoch 55/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4670 - accuracy: 0.8846 - val_loss: 0.9467 - val_accuracy: 0.6991\n","Epoch 56/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4603 - accuracy: 0.8911 - val_loss: 0.9497 - val_accuracy: 0.7195\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4597 - accuracy: 0.8925 - val_loss: 0.9971 - val_accuracy: 0.7127\n","Epoch 58/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4691 - accuracy: 0.8862 - val_loss: 0.9656 - val_accuracy: 0.7059\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4599 - accuracy: 0.8874 - val_loss: 0.9576 - val_accuracy: 0.7093\n","Epoch 60/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4570 - accuracy: 0.8973 - val_loss: 0.9859 - val_accuracy: 0.7093\n","Epoch 61/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4612 - accuracy: 0.8953 - val_loss: 0.9517 - val_accuracy: 0.7048\n","Epoch 62/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4566 - accuracy: 0.8950 - val_loss: 0.9913 - val_accuracy: 0.7059\n","Epoch 63/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4570 - accuracy: 0.8916 - val_loss: 1.0550 - val_accuracy: 0.6799\n","Epoch 64/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4705 - accuracy: 0.8789 - val_loss: 0.9951 - val_accuracy: 0.7081\n","Epoch 65/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4608 - accuracy: 0.8905 - val_loss: 1.0658 - val_accuracy: 0.6900\n","Epoch 66/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4547 - accuracy: 0.8933 - val_loss: 0.9675 - val_accuracy: 0.6991\n","Epoch 67/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4534 - accuracy: 0.8913 - val_loss: 0.9898 - val_accuracy: 0.7002\n","Epoch 68/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4522 - accuracy: 0.8976 - val_loss: 1.0197 - val_accuracy: 0.7172\n","Epoch 69/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4553 - accuracy: 0.8922 - val_loss: 0.9819 - val_accuracy: 0.7036\n","Epoch 70/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4466 - accuracy: 0.8967 - val_loss: 0.9617 - val_accuracy: 0.7059\n","Epoch 71/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4508 - accuracy: 0.8981 - val_loss: 1.0321 - val_accuracy: 0.6946\n","Epoch 72/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4500 - accuracy: 0.8964 - val_loss: 0.9774 - val_accuracy: 0.7115\n","Epoch 73/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4719 - accuracy: 0.8939 - val_loss: 1.0485 - val_accuracy: 0.6946\n","Epoch 74/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4589 - accuracy: 0.8947 - val_loss: 1.0182 - val_accuracy: 0.7104\n","Epoch 75/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4583 - accuracy: 0.8908 - val_loss: 1.0202 - val_accuracy: 0.7036\n","Epoch 76/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4628 - accuracy: 0.8865 - val_loss: 1.0093 - val_accuracy: 0.7127\n","Epoch 77/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4604 - accuracy: 0.8928 - val_loss: 0.9968 - val_accuracy: 0.6934\n","Epoch 78/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4491 - accuracy: 0.8947 - val_loss: 1.0664 - val_accuracy: 0.7172\n","Epoch 79/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4455 - accuracy: 0.8984 - val_loss: 1.0464 - val_accuracy: 0.7115\n","Epoch 80/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4359 - accuracy: 0.9089 - val_loss: 1.0744 - val_accuracy: 0.6980\n","Epoch 81/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4395 - accuracy: 0.9032 - val_loss: 1.0220 - val_accuracy: 0.7025\n","Epoch 82/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4430 - accuracy: 0.8930 - val_loss: 1.0210 - val_accuracy: 0.6991\n","Epoch 83/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4387 - accuracy: 0.9015 - val_loss: 1.0547 - val_accuracy: 0.6991\n","Epoch 84/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4449 - accuracy: 0.8936 - val_loss: 1.0239 - val_accuracy: 0.6968\n","Epoch 85/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4457 - accuracy: 0.8964 - val_loss: 1.0405 - val_accuracy: 0.6912\n","Epoch 86/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4443 - accuracy: 0.8973 - val_loss: 1.0858 - val_accuracy: 0.7081\n","Epoch 87/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4413 - accuracy: 0.9044 - val_loss: 1.0537 - val_accuracy: 0.6980\n","Epoch 88/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4422 - accuracy: 0.8995 - val_loss: 1.0797 - val_accuracy: 0.6968\n","Epoch 89/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4487 - accuracy: 0.8981 - val_loss: 1.0761 - val_accuracy: 0.7081\n","Epoch 90/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4410 - accuracy: 0.8959 - val_loss: 1.0585 - val_accuracy: 0.6833\n","Epoch 91/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4515 - accuracy: 0.8877 - val_loss: 1.1713 - val_accuracy: 0.6776\n","Epoch 92/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4470 - accuracy: 0.8930 - val_loss: 1.2200 - val_accuracy: 0.6753\n","Epoch 93/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4397 - accuracy: 0.8995 - val_loss: 1.0520 - val_accuracy: 0.6934\n","Epoch 94/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4405 - accuracy: 0.8942 - val_loss: 1.0466 - val_accuracy: 0.6968\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4314 - accuracy: 0.9055 - val_loss: 1.0596 - val_accuracy: 0.6968\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4311 - accuracy: 0.9038 - val_loss: 1.0937 - val_accuracy: 0.6855\n","Epoch 97/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4246 - accuracy: 0.9080 - val_loss: 1.0662 - val_accuracy: 0.6900\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4282 - accuracy: 0.9080 - val_loss: 1.0666 - val_accuracy: 0.6968\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4223 - accuracy: 0.9089 - val_loss: 1.0712 - val_accuracy: 0.7081\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4239 - accuracy: 0.9106 - val_loss: 1.0661 - val_accuracy: 0.7115\n","{'loss': [0.5618858933448792, 0.5545653700828552, 0.5415346622467041, 0.5348626971244812, 0.5255725979804993, 0.5164394378662109, 0.5200383067131042, 0.5171741247177124, 0.5108566880226135, 0.5181325078010559, 0.5133270621299744, 0.5145822167396545, 0.5120985507965088, 0.5070416927337646, 0.5078439712524414, 0.5188498497009277, 0.5324339866638184, 0.5611672401428223, 0.5243277549743652, 0.5074573755264282, 0.521695613861084, 0.5140920281410217, 0.5116997361183167, 0.5051094889640808, 0.48923465609550476, 0.4874938428401947, 0.5029320120811462, 0.5142242908477783, 0.49403145909309387, 0.4970117211341858, 0.4917025566101074, 0.4959867000579834, 0.4900098443031311, 0.48226043581962585, 0.4788733720779419, 0.4798535406589508, 0.48268428444862366, 0.48690328001976013, 0.48392388224601746, 0.479939341545105, 0.47867655754089355, 0.48608121275901794, 0.5018832683563232, 0.4839416444301605, 0.4754681885242462, 0.4786817133426666, 0.49550753831863403, 0.4897650480270386, 0.47852060198783875, 0.47800907492637634, 0.4868021607398987, 0.4768069088459015, 0.4873405396938324, 0.4890337884426117, 0.46703290939331055, 0.46032842993736267, 0.45966190099716187, 0.4691303074359894, 0.45991644263267517, 0.457023948431015, 0.4611862003803253, 0.4565736651420593, 0.4569663405418396, 0.47051289677619934, 0.4608049690723419, 0.4547317326068878, 0.4534068703651428, 0.4522331953048706, 0.4553004801273346, 0.4465843737125397, 0.45082926750183105, 0.4499756693840027, 0.4718588888645172, 0.4589083194732666, 0.4582638144493103, 0.46277567744255066, 0.4604261517524719, 0.4490569531917572, 0.44553709030151367, 0.4359224736690521, 0.4394918382167816, 0.4430217444896698, 0.43868574500083923, 0.44494956731796265, 0.4456918239593506, 0.4443092346191406, 0.44127827882766724, 0.4421873688697815, 0.44868749380111694, 0.4409841299057007, 0.45146444439888, 0.4469705820083618, 0.43965423107147217, 0.440451979637146, 0.4314122498035431, 0.4311268627643585, 0.42463892698287964, 0.428181529045105, 0.42228543758392334, 0.4239408075809479], 'accuracy': [0.8271080851554871, 0.8401244878768921, 0.8426712155342102, 0.8579513430595398, 0.8602150678634644, 0.8568194508552551, 0.8579513430595398, 0.868986964225769, 0.865308403968811, 0.8650254607200623, 0.8650254607200623, 0.865308403968811, 0.8672891855239868, 0.8715336918830872, 0.8655914068222046, 0.8545557260513306, 0.8520090579986572, 0.8347481489181519, 0.8630446791648865, 0.8678551316261292, 0.8636106252670288, 0.8701188564300537, 0.8613469004631042, 0.870684802532196, 0.8800226449966431, 0.8794566988945007, 0.8712506890296936, 0.872665524482727, 0.8720995783805847, 0.8752122521400452, 0.8800226449966431, 0.8839841485023499, 0.8757781386375427, 0.8803055882453918, 0.8856819272041321, 0.8842670917510986, 0.8805885910987854, 0.8692699670791626, 0.8766270279884338, 0.8825693130493164, 0.8763440847396851, 0.8817204236984253, 0.8763440847396851, 0.8749292492866516, 0.8873797655105591, 0.8851160407066345, 0.8715336918830872, 0.8672891855239868, 0.8803055882453918, 0.8794566988945007, 0.8752122521400452, 0.8893604874610901, 0.879173755645752, 0.870684802532196, 0.8845500946044922, 0.8910582661628723, 0.8924731016159058, 0.8862478733062744, 0.8873797655105591, 0.8972835540771484, 0.8953027725219727, 0.8950198292732239, 0.8916242122650146, 0.8788907527923584, 0.8904923796653748, 0.8933219909667969, 0.8913412690162659, 0.8975664973258972, 0.892190158367157, 0.8967176079750061, 0.8981324434280396, 0.8964346647262573, 0.8938879370689392, 0.8947368264198303, 0.8907753229141235, 0.8865308165550232, 0.8927561044692993, 0.8947368264198303, 0.8984153866767883, 0.90888512134552, 0.9032257795333862, 0.8930390477180481, 0.901528000831604, 0.8936049938201904, 0.8964346647262573, 0.8972835540771484, 0.9043576717376709, 0.899547278881073, 0.8981324434280396, 0.895868718624115, 0.8876627087593079, 0.8930390477180481, 0.899547278881073, 0.8941709399223328, 0.9054895043373108, 0.9037917256355286, 0.9080362319946289, 0.9080362319946289, 0.90888512134552, 0.9105829000473022], 'val_loss': [0.891732931137085, 0.8924874067306519, 0.9001579880714417, 0.904610276222229, 0.8999656438827515, 0.9101365208625793, 0.8985962271690369, 0.917154848575592, 0.923115611076355, 0.8730307221412659, 0.872003972530365, 0.8946688771247864, 0.8894208073616028, 0.9117152690887451, 0.8388016223907471, 0.884243369102478, 0.9253326058387756, 0.8519043922424316, 0.8299175500869751, 0.8502451777458191, 0.8361785411834717, 0.8418352007865906, 0.8446841835975647, 0.8252094388008118, 0.8478972911834717, 0.8603471517562866, 0.8647064566612244, 0.8306571245193481, 0.9141574501991272, 0.9133792519569397, 0.922435998916626, 0.9140850305557251, 0.8992077112197876, 0.8812103271484375, 0.9035490155220032, 0.9197413921356201, 0.8793862462043762, 0.8940455913543701, 0.930375337600708, 0.9039459824562073, 0.9068936109542847, 0.9607205390930176, 0.989821195602417, 0.9760671257972717, 0.9626564383506775, 0.9898789525032043, 0.9443901181221008, 1.0389909744262695, 0.9583751559257507, 0.9636759757995605, 0.9600343108177185, 1.0489047765731812, 0.9801198840141296, 0.9948596358299255, 0.9466915726661682, 0.9496620297431946, 0.9971044063568115, 0.9655501842498779, 0.9575942158699036, 0.9858756065368652, 0.9517098069190979, 0.9912577271461487, 1.0549654960632324, 0.9951242804527283, 1.0657713413238525, 0.9675469994544983, 0.9898306131362915, 1.019736647605896, 0.9818711280822754, 0.9617448449134827, 1.032061219215393, 0.9774472117424011, 1.0485060214996338, 1.018180251121521, 1.0202171802520752, 1.0093374252319336, 0.9968297481536865, 1.0664429664611816, 1.0464458465576172, 1.0744059085845947, 1.0219542980194092, 1.0209534168243408, 1.0547337532043457, 1.0239211320877075, 1.0405070781707764, 1.0858323574066162, 1.0536545515060425, 1.079660415649414, 1.0760835409164429, 1.058547019958496, 1.1712642908096313, 1.219967246055603, 1.0519604682922363, 1.0465596914291382, 1.0596288442611694, 1.0937070846557617, 1.0662288665771484, 1.0666460990905762, 1.0712370872497559, 1.0661125183105469], 'val_accuracy': [0.5610859990119934, 0.523755669593811, 0.5260180830955505, 0.5260180830955505, 0.5214931964874268, 0.5384615659713745, 0.5316742062568665, 0.5463801026344299, 0.5486425161361694, 0.5678732991218567, 0.5690045356750488, 0.564479649066925, 0.5746606588363647, 0.5735294222831726, 0.6414027214050293, 0.610859751701355, 0.6052036285400391, 0.6764705777168274, 0.6606335043907166, 0.662895917892456, 0.6900452375411987, 0.6945701241493225, 0.7058823704719543, 0.7002262473106384, 0.7160633206367493, 0.720588207244873, 0.726244330406189, 0.7160633206367493, 0.7115384340286255, 0.7013574838638306, 0.7024886608123779, 0.7115384340286255, 0.7160633206367493, 0.7183257937431335, 0.7251130938529968, 0.7194570302963257, 0.7104072570800781, 0.7217194437980652, 0.7251130938529968, 0.7115384340286255, 0.7149321436882019, 0.7183257937431335, 0.6945701241493225, 0.7194570302963257, 0.7239819169044495, 0.6934388875961304, 0.6979637742042542, 0.6843891143798828, 0.7058823704719543, 0.7002262473106384, 0.7149321436882019, 0.7058823704719543, 0.6911764740943909, 0.6832579374313354, 0.6990950107574463, 0.7194570302963257, 0.7126696705818176, 0.7058823704719543, 0.709276020526886, 0.709276020526886, 0.7047511339187622, 0.7058823704719543, 0.679864227771759, 0.7081447839736938, 0.6900452375411987, 0.6990950107574463, 0.7002262473106384, 0.7171945571899414, 0.7036198973655701, 0.7058823704719543, 0.6945701241493225, 0.7115384340286255, 0.6945701241493225, 0.7104072570800781, 0.7036198973655701, 0.7126696705818176, 0.6934388875961304, 0.7171945571899414, 0.7115384340286255, 0.6979637742042542, 0.7024886608123779, 0.6990950107574463, 0.6990950107574463, 0.6968325972557068, 0.6911764740943909, 0.7081447839736938, 0.6979637742042542, 0.6968325972557068, 0.7081447839736938, 0.6832579374313354, 0.6776018142700195, 0.6753393411636353, 0.6934388875961304, 0.6968325972557068, 0.6968325972557068, 0.685520350933075, 0.6900452375411987, 0.6968325972557068, 0.7081447839736938, 0.7115384340286255]}\n","45/45 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 4s 34ms/step - loss: 0.5893 - accuracy: 0.8186 - val_loss: 0.8991 - val_accuracy: 0.5155\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.6461 - accuracy: 0.8672"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 1s 21ms/step - loss: 0.5543 - accuracy: 0.8406 - val_loss: 0.8881 - val_accuracy: 0.5713\n","Epoch 3/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5520 - accuracy: 0.8318 - val_loss: 0.8937 - val_accuracy: 0.5207\n","Epoch 4/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5605 - accuracy: 0.8411 - val_loss: 0.9113 - val_accuracy: 0.5196\n","Epoch 5/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5658 - accuracy: 0.8248 - val_loss: 0.8873 - val_accuracy: 0.5289\n","Epoch 6/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5541 - accuracy: 0.8382 - val_loss: 0.9179 - val_accuracy: 0.5176\n","Epoch 7/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5581 - accuracy: 0.8326 - val_loss: 0.8864 - val_accuracy: 0.5568\n","Epoch 8/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5572 - accuracy: 0.8336 - val_loss: 0.8823 - val_accuracy: 0.5723\n","Epoch 9/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5475 - accuracy: 0.8413 - val_loss: 0.9175 - val_accuracy: 0.5362\n","Epoch 10/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5462 - accuracy: 0.8470 - val_loss: 0.9213 - val_accuracy: 0.5372\n","Epoch 11/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5396 - accuracy: 0.8447 - val_loss: 0.8809 - val_accuracy: 0.5640\n","Epoch 12/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5266 - accuracy: 0.8540 - val_loss: 0.9204 - val_accuracy: 0.5527\n","Epoch 13/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5288 - accuracy: 0.8496 - val_loss: 0.9173 - val_accuracy: 0.5599\n","Epoch 14/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5399 - accuracy: 0.8483 - val_loss: 0.8962 - val_accuracy: 0.5806\n","Epoch 15/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5419 - accuracy: 0.8411 - val_loss: 0.8660 - val_accuracy: 0.6033\n","Epoch 16/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5383 - accuracy: 0.8413 - val_loss: 0.8463 - val_accuracy: 0.6364\n","Epoch 17/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5343 - accuracy: 0.8543 - val_loss: 0.8574 - val_accuracy: 0.6250\n","Epoch 18/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5315 - accuracy: 0.8488 - val_loss: 0.9182 - val_accuracy: 0.6167\n","Epoch 19/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5504 - accuracy: 0.8447 - val_loss: 0.8522 - val_accuracy: 0.6622\n","Epoch 20/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5291 - accuracy: 0.8496 - val_loss: 0.8627 - val_accuracy: 0.6570\n","Epoch 21/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5227 - accuracy: 0.8517 - val_loss: 0.8355 - val_accuracy: 0.6911\n","Epoch 22/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5159 - accuracy: 0.8581 - val_loss: 0.9517 - val_accuracy: 0.6405\n","Epoch 23/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5217 - accuracy: 0.8633 - val_loss: 0.9591 - val_accuracy: 0.6870\n","Epoch 24/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5322 - accuracy: 0.8499 - val_loss: 0.8588 - val_accuracy: 0.6746\n","Epoch 25/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5402 - accuracy: 0.8413 - val_loss: 1.1546 - val_accuracy: 0.6178\n","Epoch 26/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5486 - accuracy: 0.8269 - val_loss: 1.0196 - val_accuracy: 0.6684\n","Epoch 27/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5297 - accuracy: 0.8537 - val_loss: 0.9433 - val_accuracy: 0.6890\n","Epoch 28/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5119 - accuracy: 0.8625 - val_loss: 0.9117 - val_accuracy: 0.6767\n","Epoch 29/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5148 - accuracy: 0.8563 - val_loss: 0.9037 - val_accuracy: 0.6787\n","Epoch 30/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5407 - accuracy: 0.8432 - val_loss: 0.9454 - val_accuracy: 0.6632\n","Epoch 31/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5137 - accuracy: 0.8618 - val_loss: 0.9868 - val_accuracy: 0.6932\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5111 - accuracy: 0.8646 - val_loss: 0.9092 - val_accuracy: 0.6705\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5196 - accuracy: 0.8633 - val_loss: 0.9184 - val_accuracy: 0.6725\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5186 - accuracy: 0.8535 - val_loss: 0.9313 - val_accuracy: 0.6715\n","Epoch 35/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5198 - accuracy: 0.8561 - val_loss: 0.9618 - val_accuracy: 0.6612\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5059 - accuracy: 0.8638 - val_loss: 1.0131 - val_accuracy: 0.6674\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5130 - accuracy: 0.8630 - val_loss: 0.9456 - val_accuracy: 0.6880\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5031 - accuracy: 0.8708 - val_loss: 0.9374 - val_accuracy: 0.6798\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5070 - accuracy: 0.8633 - val_loss: 1.0293 - val_accuracy: 0.6736\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5107 - accuracy: 0.8638 - val_loss: 1.0343 - val_accuracy: 0.6880\n","Epoch 41/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5098 - accuracy: 0.8597 - val_loss: 0.9463 - val_accuracy: 0.6870\n","Epoch 42/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5026 - accuracy: 0.8703 - val_loss: 0.9887 - val_accuracy: 0.6457\n","Epoch 43/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5011 - accuracy: 0.8638 - val_loss: 1.1456 - val_accuracy: 0.6188\n","Epoch 44/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5047 - accuracy: 0.8602 - val_loss: 0.9819 - val_accuracy: 0.6663\n","Epoch 45/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4927 - accuracy: 0.8700 - val_loss: 0.9516 - val_accuracy: 0.6860\n","Epoch 46/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4989 - accuracy: 0.8721 - val_loss: 0.9296 - val_accuracy: 0.6849\n","Epoch 47/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4930 - accuracy: 0.8618 - val_loss: 1.0292 - val_accuracy: 0.6808\n","Epoch 48/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5074 - accuracy: 0.8581 - val_loss: 0.9572 - val_accuracy: 0.6849\n","Epoch 49/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5131 - accuracy: 0.8571 - val_loss: 1.0295 - val_accuracy: 0.6653\n","Epoch 50/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4969 - accuracy: 0.8672 - val_loss: 1.1136 - val_accuracy: 0.6736\n","Epoch 51/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4973 - accuracy: 0.8649 - val_loss: 0.9642 - val_accuracy: 0.6818\n","Epoch 52/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5006 - accuracy: 0.8680 - val_loss: 1.0530 - val_accuracy: 0.6860\n","Epoch 53/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5096 - accuracy: 0.8612 - val_loss: 1.1763 - val_accuracy: 0.6663\n","Epoch 54/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5173 - accuracy: 0.8589 - val_loss: 1.0745 - val_accuracy: 0.6529\n","Epoch 55/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4933 - accuracy: 0.8703 - val_loss: 1.1463 - val_accuracy: 0.6777\n","Epoch 56/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4946 - accuracy: 0.8724 - val_loss: 1.0036 - val_accuracy: 0.6808\n","Epoch 57/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4860 - accuracy: 0.8804 - val_loss: 0.9832 - val_accuracy: 0.6849\n","Epoch 58/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4824 - accuracy: 0.8765 - val_loss: 1.0273 - val_accuracy: 0.6622\n","Epoch 59/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4796 - accuracy: 0.8798 - val_loss: 1.1001 - val_accuracy: 0.6798\n","Epoch 60/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4840 - accuracy: 0.8786 - val_loss: 1.0304 - val_accuracy: 0.6777\n","Epoch 61/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4881 - accuracy: 0.8749 - val_loss: 0.9657 - val_accuracy: 0.6808\n","Epoch 62/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4976 - accuracy: 0.8687 - val_loss: 0.9871 - val_accuracy: 0.6705\n","Epoch 63/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4889 - accuracy: 0.8693 - val_loss: 1.1016 - val_accuracy: 0.6839\n","Epoch 64/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4738 - accuracy: 0.8822 - val_loss: 0.9579 - val_accuracy: 0.6921\n","Epoch 65/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5118 - accuracy: 0.8674 - val_loss: 1.2393 - val_accuracy: 0.6663\n","Epoch 66/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4768 - accuracy: 0.8765 - val_loss: 1.0188 - val_accuracy: 0.6663\n","Epoch 67/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5057 - accuracy: 0.8687 - val_loss: 1.2154 - val_accuracy: 0.6550\n","Epoch 68/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4987 - accuracy: 0.8659 - val_loss: 1.0636 - val_accuracy: 0.6488\n","Epoch 69/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4840 - accuracy: 0.8742 - val_loss: 0.9932 - val_accuracy: 0.6674\n","Epoch 70/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4776 - accuracy: 0.8747 - val_loss: 1.2284 - val_accuracy: 0.6622\n","Epoch 71/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5088 - accuracy: 0.8734 - val_loss: 0.9972 - val_accuracy: 0.6539\n","Epoch 72/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4923 - accuracy: 0.8749 - val_loss: 1.1007 - val_accuracy: 0.6643\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4847 - accuracy: 0.8703 - val_loss: 1.0782 - val_accuracy: 0.6529\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4796 - accuracy: 0.8729 - val_loss: 1.0448 - val_accuracy: 0.6384\n","Epoch 75/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4700 - accuracy: 0.8811 - val_loss: 1.0961 - val_accuracy: 0.6374\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4753 - accuracy: 0.8809 - val_loss: 1.0417 - val_accuracy: 0.6508\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4784 - accuracy: 0.8809 - val_loss: 1.0323 - val_accuracy: 0.6715\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4765 - accuracy: 0.8749 - val_loss: 1.1131 - val_accuracy: 0.6508\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4896 - accuracy: 0.8765 - val_loss: 1.1141 - val_accuracy: 0.6384\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4988 - accuracy: 0.8630 - val_loss: 1.1076 - val_accuracy: 0.6715\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4931 - accuracy: 0.8819 - val_loss: 1.0911 - val_accuracy: 0.6539\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4628 - accuracy: 0.8868 - val_loss: 1.0186 - val_accuracy: 0.6674\n","Epoch 83/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4750 - accuracy: 0.8809 - val_loss: 1.0520 - val_accuracy: 0.6736\n","Epoch 84/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4914 - accuracy: 0.8726 - val_loss: 0.9949 - val_accuracy: 0.6818\n","Epoch 85/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4634 - accuracy: 0.8845 - val_loss: 1.1029 - val_accuracy: 0.6550\n","Epoch 86/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4651 - accuracy: 0.8767 - val_loss: 1.0147 - val_accuracy: 0.6746\n","Epoch 87/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4720 - accuracy: 0.8718 - val_loss: 1.0991 - val_accuracy: 0.6684\n","Epoch 88/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4577 - accuracy: 0.8897 - val_loss: 1.0271 - val_accuracy: 0.6570\n","Epoch 89/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4580 - accuracy: 0.8873 - val_loss: 1.0404 - val_accuracy: 0.6653\n","Epoch 90/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4605 - accuracy: 0.8853 - val_loss: 1.0529 - val_accuracy: 0.6705\n","Epoch 91/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4571 - accuracy: 0.8894 - val_loss: 1.1396 - val_accuracy: 0.6364\n","Epoch 92/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4781 - accuracy: 0.8858 - val_loss: 1.0508 - val_accuracy: 0.6705\n","Epoch 93/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4553 - accuracy: 0.8935 - val_loss: 1.1134 - val_accuracy: 0.6405\n","Epoch 94/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4551 - accuracy: 0.8969 - val_loss: 1.0238 - val_accuracy: 0.6694\n","Epoch 95/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4988 - accuracy: 0.8690 - val_loss: 1.1629 - val_accuracy: 0.6426\n","Epoch 96/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4822 - accuracy: 0.8713 - val_loss: 1.1519 - val_accuracy: 0.6725\n","Epoch 97/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4889 - accuracy: 0.8824 - val_loss: 1.0757 - val_accuracy: 0.6839\n","Epoch 98/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4602 - accuracy: 0.8915 - val_loss: 1.0272 - val_accuracy: 0.6798\n","Epoch 99/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4719 - accuracy: 0.8822 - val_loss: 1.2432 - val_accuracy: 0.6725\n","Epoch 100/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4662 - accuracy: 0.8943 - val_loss: 1.0168 - val_accuracy: 0.6632\n","{'loss': [0.5892561078071594, 0.5543254017829895, 0.5519587397575378, 0.5605044364929199, 0.56578528881073, 0.5540542006492615, 0.5581041574478149, 0.5572304129600525, 0.5474629998207092, 0.5462116003036499, 0.5395618081092834, 0.5266136527061462, 0.5287551283836365, 0.5398927330970764, 0.5419111251831055, 0.5383087992668152, 0.5342973470687866, 0.5315414667129517, 0.5503993034362793, 0.5291278958320618, 0.5226798057556152, 0.5159410238265991, 0.5217177271842957, 0.5321961641311646, 0.5402334332466125, 0.548587441444397, 0.5296934247016907, 0.5119088888168335, 0.5148462653160095, 0.5406891107559204, 0.513713002204895, 0.5110675096511841, 0.5195595026016235, 0.5186444520950317, 0.5197701454162598, 0.505871593952179, 0.5129749774932861, 0.5031207203865051, 0.5069946050643921, 0.510655403137207, 0.5098199844360352, 0.5026004314422607, 0.5010514855384827, 0.5046634078025818, 0.4926590323448181, 0.49894577264785767, 0.49299201369285583, 0.5073539614677429, 0.513068675994873, 0.4969435930252075, 0.4972825348377228, 0.5006194710731506, 0.5096215009689331, 0.517314612865448, 0.4933100640773773, 0.4945639669895172, 0.48600587248802185, 0.482407808303833, 0.4796464443206787, 0.48402974009513855, 0.4880923628807068, 0.49760857224464417, 0.4889051914215088, 0.4737553894519806, 0.51183021068573, 0.47681838274002075, 0.5056698322296143, 0.4987350404262543, 0.4840439558029175, 0.4776061773300171, 0.5087576508522034, 0.49230024218559265, 0.4846974313259125, 0.47959059476852417, 0.4699999988079071, 0.4752550721168518, 0.4783916175365448, 0.4765070080757141, 0.489605188369751, 0.49879008531570435, 0.49311158061027527, 0.46284860372543335, 0.47499457001686096, 0.4913860857486725, 0.46336257457733154, 0.46510830521583557, 0.47203531861305237, 0.45768028497695923, 0.45800817012786865, 0.4605259597301483, 0.4571203291416168, 0.47810766100883484, 0.4553304612636566, 0.4551030695438385, 0.4988023638725281, 0.4821810722351074, 0.48885855078697205, 0.4602183699607849, 0.47186511754989624, 0.4661922752857208], 'accuracy': [0.8186046481132507, 0.840568482875824, 0.8317829370498657, 0.8410852551460266, 0.8248062133789062, 0.8382428884506226, 0.8325581550598145, 0.8335917592048645, 0.8413436412811279, 0.8470284342765808, 0.8447028398513794, 0.8540051579475403, 0.8496124148368835, 0.8483204245567322, 0.8410852551460266, 0.8413436412811279, 0.8542635440826416, 0.8488371968269348, 0.8447028398513794, 0.8496124148368835, 0.8516795635223389, 0.8581395149230957, 0.8633074760437012, 0.8498708009719849, 0.8413436412811279, 0.8268733620643616, 0.853746771812439, 0.8625323176383972, 0.8563307523727417, 0.8431524634361267, 0.8617570996284485, 0.8645994663238525, 0.8633074760437012, 0.8534883856773376, 0.8560723662376404, 0.8638243079185486, 0.8630490899085999, 0.8708010315895081, 0.8633074760437012, 0.8638243079185486, 0.8596899509429932, 0.8702842593193054, 0.8638243079185486, 0.8602067232131958, 0.8700258135795593, 0.8720930218696594, 0.8617570996284485, 0.8581395149230957, 0.8571059703826904, 0.8671834468841553, 0.8648578524589539, 0.867958664894104, 0.8612403273582458, 0.8589147329330444, 0.8702842593193054, 0.8723514080047607, 0.8803617358207703, 0.8764857649803162, 0.8798449635505676, 0.8785529732704163, 0.8749353885650635, 0.868733823299408, 0.8692506551742554, 0.882170557975769, 0.8674418330192566, 0.8764857649803162, 0.868733823299408, 0.8658914566040039, 0.8741602301597595, 0.8746770024299622, 0.8733850121498108, 0.8749353885650635, 0.8702842593193054, 0.8728682398796082, 0.881136953830719, 0.8808785676956177, 0.8808785676956177, 0.8749353885650635, 0.8764857649803162, 0.8630490899085999, 0.8819121718406677, 0.8868216872215271, 0.8808785676956177, 0.8726097941398621, 0.8844961524009705, 0.8767442107200623, 0.8718346357345581, 0.8896640539169312, 0.8873385190963745, 0.8852713108062744, 0.8894056677818298, 0.8857881426811218, 0.8935400247573853, 0.8968992233276367, 0.868992269039154, 0.8713178038597107, 0.8824289441108704, 0.8914728760719299, 0.882170557975769, 0.894315242767334], 'val_loss': [0.8990939259529114, 0.8881083130836487, 0.8937373757362366, 0.911300539970398, 0.8872501850128174, 0.9178709387779236, 0.8864158391952515, 0.8822566270828247, 0.9175094366073608, 0.9212689995765686, 0.8808925747871399, 0.920382559299469, 0.9173198342323303, 0.8962064981460571, 0.8660367727279663, 0.8463016748428345, 0.8574105501174927, 0.9182351231575012, 0.8521516919136047, 0.8627293705940247, 0.8355405330657959, 0.9517399668693542, 0.9591022729873657, 0.8587513566017151, 1.1545571088790894, 1.019577145576477, 0.9433397054672241, 0.9116974472999573, 0.9036906361579895, 0.9454162120819092, 0.9867532849311829, 0.9092293381690979, 0.918446958065033, 0.93131023645401, 0.9618182182312012, 1.013077974319458, 0.9456039071083069, 0.9373804926872253, 1.0293081998825073, 1.0343379974365234, 0.9463251233100891, 0.9887242317199707, 1.1455879211425781, 0.9818857312202454, 0.9515627026557922, 0.929571270942688, 1.0291799306869507, 0.9571840167045593, 1.0295206308364868, 1.1136223077774048, 0.9642042517662048, 1.0530041456222534, 1.1763331890106201, 1.074465274810791, 1.1462856531143188, 1.003606915473938, 0.9831988215446472, 1.0272653102874756, 1.1001189947128296, 1.0303840637207031, 0.9656991362571716, 0.9871426820755005, 1.1016265153884888, 0.9579291939735413, 1.239328384399414, 1.018763542175293, 1.2154182195663452, 1.0636428594589233, 0.9932140111923218, 1.2284444570541382, 0.99718177318573, 1.1006577014923096, 1.0782272815704346, 1.0447615385055542, 1.0960757732391357, 1.0417115688323975, 1.0322887897491455, 1.1131373643875122, 1.114097237586975, 1.1075860261917114, 1.0911219120025635, 1.0185842514038086, 1.0520293712615967, 0.9948521256446838, 1.102947473526001, 1.0147382020950317, 1.0990936756134033, 1.0270938873291016, 1.0403741598129272, 1.0529417991638184, 1.1396055221557617, 1.0508416891098022, 1.1134190559387207, 1.023810625076294, 1.1629245281219482, 1.1518863439559937, 1.075673222541809, 1.0271742343902588, 1.2431923151016235, 1.0167526006698608], 'val_accuracy': [0.5154958963394165, 0.5712810158729553, 0.5206611752510071, 0.51962810754776, 0.5289255976676941, 0.5175619721412659, 0.5568181872367859, 0.5723140239715576, 0.5361570119857788, 0.5371900796890259, 0.5640496015548706, 0.5526859760284424, 0.5599173307418823, 0.5805785059928894, 0.6033057570457458, 0.6363636255264282, 0.625, 0.6167355179786682, 0.6621900796890259, 0.6570248007774353, 0.69111567735672, 0.6404958963394165, 0.6869834661483765, 0.6745867729187012, 0.6177685856819153, 0.6683884263038635, 0.6890496015548706, 0.6766529083251953, 0.6787189841270447, 0.663223147392273, 0.6931818127632141, 0.6704545617103577, 0.672520637512207, 0.6714876294136047, 0.6611570119857788, 0.6673553586006165, 0.6880165338516235, 0.6797520518302917, 0.6735537052154541, 0.6880165338516235, 0.6869834661483765, 0.6456611752510071, 0.6188016533851624, 0.6663222908973694, 0.6859503984451294, 0.6849173307418823, 0.6807851195335388, 0.6849173307418823, 0.6652892827987671, 0.6735537052154541, 0.6818181872367859, 0.6859503984451294, 0.6663222908973694, 0.6528925895690918, 0.6776859760284424, 0.6807851195335388, 0.6849173307418823, 0.6621900796890259, 0.6797520518302917, 0.6776859760284424, 0.6807851195335388, 0.6704545617103577, 0.68388432264328, 0.692148745059967, 0.6663222908973694, 0.6663222908973694, 0.6549586653709412, 0.6487603187561035, 0.6673553586006165, 0.6621900796890259, 0.6539255976676941, 0.66425621509552, 0.6528925895690918, 0.6384297609329224, 0.6373966932296753, 0.6508264541625977, 0.6714876294136047, 0.6508264541625977, 0.6384297609329224, 0.6714876294136047, 0.6539255976676941, 0.6673553586006165, 0.6735537052154541, 0.6818181872367859, 0.6549586653709412, 0.6745867729187012, 0.6683884263038635, 0.6570248007774353, 0.6652892827987671, 0.6704545617103577, 0.6363636255264282, 0.6704545617103577, 0.6404958963394165, 0.6694214940071106, 0.6425619721412659, 0.672520637512207, 0.68388432264328, 0.6797520518302917, 0.672520637512207, 0.663223147392273]}\n","32/32 [==============================] - 0s 4ms/step\n"]}],"source":["global_model_CNN, metrics_df_CNN = federated_learning(Theta_data)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"id":"y3RXIk-qZ7ts","executionInfo":{"status":"ok","timestamp":1717436273453,"user_tz":-360,"elapsed":29,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}},"outputId":"cff6cb99-80f7-49d2-acdc-45d81fa2f020"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.556      0.567   0.474  0.516        0.474        0.638   \n","1        1     0.547      0.558   0.448  0.497        0.448        0.645   \n","2        2     0.535      0.550   0.386  0.453        0.386        0.685   \n","3        0     0.592      0.637   0.429  0.513        0.429        0.755   \n","4        1     0.562      0.546   0.733  0.626        0.733        0.391   \n","5        2     0.622      0.669   0.486  0.563        0.486        0.759   \n","6        0     0.627      0.699   0.447  0.545        0.447        0.807   \n","7        1     0.595      0.591   0.620  0.605        0.620        0.571   \n","8        2     0.650      0.713   0.500  0.588        0.500        0.799   \n","9        0     0.638      0.642   0.625  0.633        0.625        0.652   \n","10       1     0.607      0.576   0.814  0.674        0.814        0.401   \n","11       2     0.704      0.729   0.649  0.687        0.649        0.759   \n","12       0     0.683      0.676   0.702  0.689        0.702        0.663   \n","13       1     0.692      0.682   0.719  0.700        0.719        0.665   \n","14       2     0.736      0.753   0.703  0.727        0.703        0.769   \n","\n","    Kappa  \n","0   0.112  \n","1   0.093  \n","2   0.070  \n","3   0.184  \n","4   0.124  \n","5   0.245  \n","6   0.255  \n","7   0.191  \n","8   0.299  \n","9   0.276  \n","10  0.215  \n","11  0.408  \n","12  0.365  \n","13  0.384  \n","14  0.472  "],"text/html":["\n","  <div id=\"df-1a08091f-d7b0-4ce8-8332-7fb700cb90f5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.556</td>\n","      <td>0.567</td>\n","      <td>0.474</td>\n","      <td>0.516</td>\n","      <td>0.474</td>\n","      <td>0.638</td>\n","      <td>0.112</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.547</td>\n","      <td>0.558</td>\n","      <td>0.448</td>\n","      <td>0.497</td>\n","      <td>0.448</td>\n","      <td>0.645</td>\n","      <td>0.093</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.535</td>\n","      <td>0.550</td>\n","      <td>0.386</td>\n","      <td>0.453</td>\n","      <td>0.386</td>\n","      <td>0.685</td>\n","      <td>0.070</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.592</td>\n","      <td>0.637</td>\n","      <td>0.429</td>\n","      <td>0.513</td>\n","      <td>0.429</td>\n","      <td>0.755</td>\n","      <td>0.184</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.562</td>\n","      <td>0.546</td>\n","      <td>0.733</td>\n","      <td>0.626</td>\n","      <td>0.733</td>\n","      <td>0.391</td>\n","      <td>0.124</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.622</td>\n","      <td>0.669</td>\n","      <td>0.486</td>\n","      <td>0.563</td>\n","      <td>0.486</td>\n","      <td>0.759</td>\n","      <td>0.245</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.627</td>\n","      <td>0.699</td>\n","      <td>0.447</td>\n","      <td>0.545</td>\n","      <td>0.447</td>\n","      <td>0.807</td>\n","      <td>0.255</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.595</td>\n","      <td>0.591</td>\n","      <td>0.620</td>\n","      <td>0.605</td>\n","      <td>0.620</td>\n","      <td>0.571</td>\n","      <td>0.191</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.650</td>\n","      <td>0.713</td>\n","      <td>0.500</td>\n","      <td>0.588</td>\n","      <td>0.500</td>\n","      <td>0.799</td>\n","      <td>0.299</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.638</td>\n","      <td>0.642</td>\n","      <td>0.625</td>\n","      <td>0.633</td>\n","      <td>0.625</td>\n","      <td>0.652</td>\n","      <td>0.276</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.607</td>\n","      <td>0.576</td>\n","      <td>0.814</td>\n","      <td>0.674</td>\n","      <td>0.814</td>\n","      <td>0.401</td>\n","      <td>0.215</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.704</td>\n","      <td>0.729</td>\n","      <td>0.649</td>\n","      <td>0.687</td>\n","      <td>0.649</td>\n","      <td>0.759</td>\n","      <td>0.408</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.683</td>\n","      <td>0.676</td>\n","      <td>0.702</td>\n","      <td>0.689</td>\n","      <td>0.702</td>\n","      <td>0.663</td>\n","      <td>0.365</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.692</td>\n","      <td>0.682</td>\n","      <td>0.719</td>\n","      <td>0.700</td>\n","      <td>0.719</td>\n","      <td>0.665</td>\n","      <td>0.384</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.736</td>\n","      <td>0.753</td>\n","      <td>0.703</td>\n","      <td>0.727</td>\n","      <td>0.703</td>\n","      <td>0.769</td>\n","      <td>0.472</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a08091f-d7b0-4ce8-8332-7fb700cb90f5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1a08091f-d7b0-4ce8-8332-7fb700cb90f5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1a08091f-d7b0-4ce8-8332-7fb700cb90f5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-24badbc3-e143-4da3-aaa9-e7d7f815b0e2\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-24badbc3-e143-4da3-aaa9-e7d7f815b0e2')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-24badbc3-e143-4da3-aaa9-e7d7f815b0e2 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df_CNN\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06117476915324142,\n        \"min\": 0.535,\n        \"max\": 0.736,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.638,\n          0.704,\n          0.556\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0701480067937989,\n        \"min\": 0.546,\n        \"max\": 0.753,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.642,\n          0.729,\n          0.567\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1357059145287899,\n        \"min\": 0.386,\n        \"max\": 0.814,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.625,\n          0.649,\n          0.474\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08462055362167098,\n        \"min\": 0.453,\n        \"max\": 0.727,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.633,\n          0.687,\n          0.516\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1357059145287899,\n        \"min\": 0.386,\n        \"max\": 0.814,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.625,\n          0.649,\n          0.474\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1281742489552332,\n        \"min\": 0.391,\n        \"max\": 0.807,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.652,\n          0.663,\n          0.638\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12229075423525922,\n        \"min\": 0.07,\n        \"max\": 0.472,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.276,\n          0.408,\n          0.112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":13}],"source":["metrics_df_CNN.round(3)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"_iOLsKpkfzdG","executionInfo":{"status":"ok","timestamp":1717436274922,"user_tz":-360,"elapsed":1477,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}}},"outputs":[],"source":["metrics_df_CNN.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Frequency Domain/CNN/Delta_time_CNN.csv', index = False)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"ieXSN-9PI4Dx","executionInfo":{"status":"ok","timestamp":1717436274922,"user_tz":-360,"elapsed":9,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"sngKlH9A2eQj"},"source":["# Gru\n"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"Z5HrkVpf2ga8","executionInfo":{"status":"ok","timestamp":1717436274922,"user_tz":-360,"elapsed":7,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout, GRU\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model_gru(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(GRU(256, return_sequences=True))\n","    model.add(GRU(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning_gru(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model_gru(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model_gru(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Delta/CNN_GRU/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Delta/CNN_GRU/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PbdRuWk72ksq","executionInfo":{"status":"ok","timestamp":1717437331520,"user_tz":-360,"elapsed":1056604,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}},"outputId":"601db44e-1af3-4758-be67-2691a7912955"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 7s 47ms/step - loss: 1.4288 - accuracy: 0.5011 - val_loss: 1.4257 - val_accuracy: 0.4849\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 11ms/step - loss: 1.4224 - accuracy: 0.5040 - val_loss: 1.4195 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.4161 - accuracy: 0.5038 - val_loss: 1.4133 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.4098 - accuracy: 0.5038 - val_loss: 1.4072 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.4037 - accuracy: 0.5038 - val_loss: 1.4012 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3975 - accuracy: 0.5038 - val_loss: 1.3951 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.3914 - accuracy: 0.5038 - val_loss: 1.3891 - val_accuracy: 0.5065\n","Epoch 8/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.3854 - accuracy: 0.5038 - val_loss: 1.3832 - val_accuracy: 0.5442\n","Epoch 9/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.3794 - accuracy: 0.5097 - val_loss: 1.3773 - val_accuracy: 0.5603\n","Epoch 10/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.3734 - accuracy: 0.5005 - val_loss: 1.3714 - val_accuracy: 0.5593\n","Epoch 11/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3675 - accuracy: 0.5048 - val_loss: 1.3656 - val_accuracy: 0.5593\n","Epoch 12/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3618 - accuracy: 0.5132 - val_loss: 1.3598 - val_accuracy: 0.5582\n","Epoch 13/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3561 - accuracy: 0.5116 - val_loss: 1.3541 - val_accuracy: 0.5560\n","Epoch 14/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.3505 - accuracy: 0.5159 - val_loss: 1.3483 - val_accuracy: 0.5571\n","Epoch 15/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3444 - accuracy: 0.5129 - val_loss: 1.3426 - val_accuracy: 0.5603\n","Epoch 16/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3389 - accuracy: 0.5129 - val_loss: 1.3369 - val_accuracy: 0.5571\n","Epoch 17/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3334 - accuracy: 0.5202 - val_loss: 1.3313 - val_accuracy: 0.5593\n","Epoch 18/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3277 - accuracy: 0.5210 - val_loss: 1.3257 - val_accuracy: 0.5560\n","Epoch 19/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3222 - accuracy: 0.5218 - val_loss: 1.3201 - val_accuracy: 0.5496\n","Epoch 20/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.3166 - accuracy: 0.5218 - val_loss: 1.3145 - val_accuracy: 0.5345\n","Epoch 21/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3112 - accuracy: 0.5232 - val_loss: 1.3090 - val_accuracy: 0.5248\n","Epoch 22/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3056 - accuracy: 0.5296 - val_loss: 1.3035 - val_accuracy: 0.5237\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3003 - accuracy: 0.5242 - val_loss: 1.2981 - val_accuracy: 0.5216\n","Epoch 24/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2949 - accuracy: 0.5334 - val_loss: 1.2927 - val_accuracy: 0.5065\n","Epoch 25/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2894 - accuracy: 0.5353 - val_loss: 1.2873 - val_accuracy: 0.5108\n","Epoch 26/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2839 - accuracy: 0.5283 - val_loss: 1.2821 - val_accuracy: 0.5162\n","Epoch 27/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.2788 - accuracy: 0.5310 - val_loss: 1.2768 - val_accuracy: 0.5119\n","Epoch 28/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2734 - accuracy: 0.5385 - val_loss: 1.2718 - val_accuracy: 0.5032\n","Epoch 29/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2684 - accuracy: 0.5334 - val_loss: 1.2666 - val_accuracy: 0.5054\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2631 - accuracy: 0.5391 - val_loss: 1.2616 - val_accuracy: 0.5097\n","Epoch 31/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2583 - accuracy: 0.5412 - val_loss: 1.2567 - val_accuracy: 0.5054\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2531 - accuracy: 0.5388 - val_loss: 1.2519 - val_accuracy: 0.5129\n","Epoch 33/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2476 - accuracy: 0.5431 - val_loss: 1.2468 - val_accuracy: 0.5140\n","Epoch 34/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2425 - accuracy: 0.5391 - val_loss: 1.2418 - val_accuracy: 0.5172\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2375 - accuracy: 0.5480 - val_loss: 1.2372 - val_accuracy: 0.5162\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2325 - accuracy: 0.5401 - val_loss: 1.2323 - val_accuracy: 0.5194\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2272 - accuracy: 0.5517 - val_loss: 1.2275 - val_accuracy: 0.5151\n","Epoch 38/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2225 - accuracy: 0.5401 - val_loss: 1.2228 - val_accuracy: 0.5205\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2170 - accuracy: 0.5488 - val_loss: 1.2184 - val_accuracy: 0.5172\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2122 - accuracy: 0.5504 - val_loss: 1.2142 - val_accuracy: 0.5119\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2077 - accuracy: 0.5523 - val_loss: 1.2092 - val_accuracy: 0.5259\n","Epoch 42/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2025 - accuracy: 0.5512 - val_loss: 1.2046 - val_accuracy: 0.5151\n","Epoch 43/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1971 - accuracy: 0.5579 - val_loss: 1.2003 - val_accuracy: 0.5280\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1928 - accuracy: 0.5482 - val_loss: 1.1960 - val_accuracy: 0.5183\n","Epoch 45/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1869 - accuracy: 0.5620 - val_loss: 1.1918 - val_accuracy: 0.5183\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1816 - accuracy: 0.5563 - val_loss: 1.1875 - val_accuracy: 0.5280\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1780 - accuracy: 0.5644 - val_loss: 1.1832 - val_accuracy: 0.5237\n","Epoch 48/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1720 - accuracy: 0.5733 - val_loss: 1.1794 - val_accuracy: 0.5216\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1681 - accuracy: 0.5625 - val_loss: 1.1752 - val_accuracy: 0.5172\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1625 - accuracy: 0.5652 - val_loss: 1.1707 - val_accuracy: 0.5323\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1577 - accuracy: 0.5698 - val_loss: 1.1669 - val_accuracy: 0.5259\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1534 - accuracy: 0.5735 - val_loss: 1.1632 - val_accuracy: 0.5302\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1471 - accuracy: 0.5762 - val_loss: 1.1594 - val_accuracy: 0.5280\n","Epoch 54/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1437 - accuracy: 0.5744 - val_loss: 1.1551 - val_accuracy: 0.5420\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1391 - accuracy: 0.5779 - val_loss: 1.1528 - val_accuracy: 0.5269\n","Epoch 56/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1338 - accuracy: 0.5768 - val_loss: 1.1473 - val_accuracy: 0.5485\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1287 - accuracy: 0.5873 - val_loss: 1.1446 - val_accuracy: 0.5377\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1234 - accuracy: 0.5876 - val_loss: 1.1404 - val_accuracy: 0.5442\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1205 - accuracy: 0.5862 - val_loss: 1.1369 - val_accuracy: 0.5442\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1156 - accuracy: 0.5908 - val_loss: 1.1325 - val_accuracy: 0.5517\n","Epoch 61/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1096 - accuracy: 0.5876 - val_loss: 1.1301 - val_accuracy: 0.5506\n","Epoch 62/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1053 - accuracy: 0.5905 - val_loss: 1.1288 - val_accuracy: 0.5399\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1002 - accuracy: 0.5927 - val_loss: 1.1242 - val_accuracy: 0.5485\n","Epoch 64/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0949 - accuracy: 0.5997 - val_loss: 1.1219 - val_accuracy: 0.5517\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0895 - accuracy: 0.5997 - val_loss: 1.1180 - val_accuracy: 0.5463\n","Epoch 66/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0850 - accuracy: 0.6029 - val_loss: 1.1144 - val_accuracy: 0.5506\n","Epoch 67/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0814 - accuracy: 0.6040 - val_loss: 1.1145 - val_accuracy: 0.5463\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0747 - accuracy: 0.6061 - val_loss: 1.1094 - val_accuracy: 0.5528\n","Epoch 69/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0716 - accuracy: 0.6083 - val_loss: 1.1067 - val_accuracy: 0.5442\n","Epoch 70/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0680 - accuracy: 0.6018 - val_loss: 1.1046 - val_accuracy: 0.5453\n","Epoch 71/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0622 - accuracy: 0.6056 - val_loss: 1.1043 - val_accuracy: 0.5431\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0591 - accuracy: 0.6078 - val_loss: 1.1010 - val_accuracy: 0.5463\n","Epoch 73/100\n","29/29 [==============================] - 1s 40ms/step - loss: 1.0522 - accuracy: 0.6094 - val_loss: 1.0957 - val_accuracy: 0.5636\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0486 - accuracy: 0.6113 - val_loss: 1.0940 - val_accuracy: 0.5539\n","Epoch 75/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.0427 - accuracy: 0.6161 - val_loss: 1.0911 - val_accuracy: 0.5690\n","Epoch 76/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0368 - accuracy: 0.6204 - val_loss: 1.0927 - val_accuracy: 0.5453\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0350 - accuracy: 0.6228 - val_loss: 1.0922 - val_accuracy: 0.5388\n","Epoch 78/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0304 - accuracy: 0.6172 - val_loss: 1.0887 - val_accuracy: 0.5496\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0270 - accuracy: 0.6202 - val_loss: 1.0846 - val_accuracy: 0.5636\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0217 - accuracy: 0.6263 - val_loss: 1.0848 - val_accuracy: 0.5517\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0162 - accuracy: 0.6239 - val_loss: 1.0823 - val_accuracy: 0.5603\n","Epoch 82/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0156 - accuracy: 0.6218 - val_loss: 1.0813 - val_accuracy: 0.5453\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0093 - accuracy: 0.6282 - val_loss: 1.0819 - val_accuracy: 0.5366\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0054 - accuracy: 0.6215 - val_loss: 1.0784 - val_accuracy: 0.5550\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0021 - accuracy: 0.6239 - val_loss: 1.0796 - val_accuracy: 0.5453\n","Epoch 86/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9988 - accuracy: 0.6315 - val_loss: 1.0815 - val_accuracy: 0.5431\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9925 - accuracy: 0.6339 - val_loss: 1.0752 - val_accuracy: 0.5593\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9875 - accuracy: 0.6352 - val_loss: 1.0777 - val_accuracy: 0.5463\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9841 - accuracy: 0.6253 - val_loss: 1.0747 - val_accuracy: 0.5614\n","Epoch 90/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9806 - accuracy: 0.6304 - val_loss: 1.0748 - val_accuracy: 0.5603\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9784 - accuracy: 0.6350 - val_loss: 1.0728 - val_accuracy: 0.5657\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9717 - accuracy: 0.6347 - val_loss: 1.0682 - val_accuracy: 0.5614\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9702 - accuracy: 0.6366 - val_loss: 1.0663 - val_accuracy: 0.5560\n","Epoch 94/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9642 - accuracy: 0.6449 - val_loss: 1.0681 - val_accuracy: 0.5582\n","Epoch 95/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9620 - accuracy: 0.6374 - val_loss: 1.0656 - val_accuracy: 0.5636\n","Epoch 96/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9555 - accuracy: 0.6425 - val_loss: 1.0657 - val_accuracy: 0.5679\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9509 - accuracy: 0.6482 - val_loss: 1.0646 - val_accuracy: 0.5474\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9480 - accuracy: 0.6444 - val_loss: 1.0669 - val_accuracy: 0.5668\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9425 - accuracy: 0.6487 - val_loss: 1.0684 - val_accuracy: 0.5409\n","Epoch 100/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9419 - accuracy: 0.6460 - val_loss: 1.0658 - val_accuracy: 0.5668\n","{'loss': [1.4287546873092651, 1.4223607778549194, 1.4161385297775269, 1.409848928451538, 1.4036980867385864, 1.397460699081421, 1.3914090394973755, 1.385369062423706, 1.3794304132461548, 1.3734241724014282, 1.3675211668014526, 1.361810564994812, 1.3560787439346313, 1.350450038909912, 1.3444374799728394, 1.3388640880584717, 1.3333646059036255, 1.32765531539917, 1.322157859802246, 1.3166453838348389, 1.3111952543258667, 1.305607557296753, 1.300298810005188, 1.2949496507644653, 1.2894495725631714, 1.2839189767837524, 1.2788281440734863, 1.2733889818191528, 1.2683701515197754, 1.263092279434204, 1.2583096027374268, 1.2530826330184937, 1.2476409673690796, 1.2425475120544434, 1.2374893426895142, 1.2324718236923218, 1.2272123098373413, 1.222455620765686, 1.2170112133026123, 1.2121782302856445, 1.2076947689056396, 1.2024725675582886, 1.1971032619476318, 1.192833423614502, 1.1868702173233032, 1.181586742401123, 1.177955985069275, 1.172044038772583, 1.1681019067764282, 1.162514090538025, 1.1576769351959229, 1.1534383296966553, 1.1470913887023926, 1.1437205076217651, 1.139057993888855, 1.1338211297988892, 1.1287370920181274, 1.1233532428741455, 1.1205404996871948, 1.1155815124511719, 1.1095736026763916, 1.1053318977355957, 1.1002322435379028, 1.0949015617370605, 1.089455485343933, 1.0849945545196533, 1.0814063549041748, 1.074732780456543, 1.0716160535812378, 1.0679564476013184, 1.0622092485427856, 1.059122920036316, 1.0522072315216064, 1.048551082611084, 1.0426647663116455, 1.0368187427520752, 1.0350151062011719, 1.0304419994354248, 1.0269513130187988, 1.0217323303222656, 1.0162341594696045, 1.0156036615371704, 1.0093125104904175, 1.0053722858428955, 1.0020931959152222, 0.998769998550415, 0.9924731254577637, 0.9875236749649048, 0.9840694069862366, 0.9805572032928467, 0.9783971309661865, 0.9716773629188538, 0.9701859951019287, 0.9641748666763306, 0.9620132446289062, 0.9555180072784424, 0.9509359002113342, 0.9480011463165283, 0.9425007104873657, 0.9418655037879944], 'accuracy': [0.5010775923728943, 0.5040409564971924, 0.5037715435028076, 0.5037715435028076, 0.5037715435028076, 0.5037715435028076, 0.5037715435028076, 0.5037715435028076, 0.5096982717514038, 0.5005387663841248, 0.5048491358757019, 0.5132004022598267, 0.5115840435028076, 0.5158944129943848, 0.5129310488700867, 0.5129310488700867, 0.5202047228813171, 0.5210129022598267, 0.521821141242981, 0.521821141242981, 0.5231680870056152, 0.529633641242981, 0.5242456793785095, 0.5334051847457886, 0.5352909564971924, 0.5282866358757019, 0.5309805870056152, 0.5385237336158752, 0.5334051847457886, 0.5390625, 0.5412176847457886, 0.5387930870056152, 0.5431034564971924, 0.5390625, 0.5479525923728943, 0.5401400923728943, 0.5517241358757019, 0.5401400923728943, 0.5487607717514038, 0.5503771305084229, 0.5522629022598267, 0.5511853694915771, 0.5579202771186829, 0.548222005367279, 0.5619612336158752, 0.556303858757019, 0.5643857717514038, 0.5732758641242981, 0.5625, 0.5651939511299133, 0.5697737336158752, 0.5735452771186829, 0.5762392282485962, 0.5743534564971924, 0.5778555870056152, 0.576777994632721, 0.587284505367279, 0.587553858757019, 0.5862069129943848, 0.5907866358757019, 0.587553858757019, 0.5905172228813171, 0.5926724076271057, 0.5996767282485962, 0.5996767282485962, 0.602909505367279, 0.6039870977401733, 0.6061422228813171, 0.6082974076271057, 0.6018319129943848, 0.6056034564971924, 0.607758641242981, 0.609375, 0.6112607717514038, 0.6161099076271057, 0.6204202771186829, 0.6228448152542114, 0.6171875, 0.6201508641242981, 0.626347005367279, 0.6239224076271057, 0.6217672228813171, 0.6282327771186829, 0.6214978694915771, 0.6239224076271057, 0.631465494632721, 0.6338900923728943, 0.6352370977401733, 0.6252694129943848, 0.6303879022598267, 0.6349676847457886, 0.6346982717514038, 0.6365840435028076, 0.6449353694915771, 0.6373922228813171, 0.6425107717514038, 0.6481680870056152, 0.6443965435028076, 0.6487069129943848, 0.6460129022598267], 'val_loss': [1.4257051944732666, 1.419493556022644, 1.4133272171020508, 1.407225489616394, 1.401151418685913, 1.3951270580291748, 1.3891350030899048, 1.3831874132156372, 1.3772804737091064, 1.3714261054992676, 1.3656079769134521, 1.359805941581726, 1.3540737628936768, 1.348315954208374, 1.3426101207733154, 1.3369427919387817, 1.3312610387802124, 1.3256831169128418, 1.3200935125350952, 1.3144932985305786, 1.3089756965637207, 1.30345618724823, 1.2981233596801758, 1.2927018404006958, 1.287306785583496, 1.282092571258545, 1.2768476009368896, 1.271767497062683, 1.2666095495224, 1.2616325616836548, 1.2567154169082642, 1.2518796920776367, 1.2468376159667969, 1.2417576313018799, 1.2371630668640137, 1.2322726249694824, 1.2274553775787354, 1.2228257656097412, 1.2183550596237183, 1.2141625881195068, 1.209210991859436, 1.2045773267745972, 1.200255036354065, 1.1959584951400757, 1.1917731761932373, 1.1874672174453735, 1.1831793785095215, 1.1793899536132812, 1.1752266883850098, 1.170744776725769, 1.1668978929519653, 1.1631584167480469, 1.1593964099884033, 1.1551085710525513, 1.1527775526046753, 1.1472501754760742, 1.1446055173873901, 1.1403676271438599, 1.1369235515594482, 1.132534384727478, 1.130115270614624, 1.1288340091705322, 1.1242238283157349, 1.1218743324279785, 1.1179542541503906, 1.1144238710403442, 1.1145161390304565, 1.1093714237213135, 1.1067368984222412, 1.1045604944229126, 1.1042519807815552, 1.1010315418243408, 1.0957053899765015, 1.0939711332321167, 1.091126561164856, 1.092675805091858, 1.092219352722168, 1.088721752166748, 1.0846035480499268, 1.0847901105880737, 1.0823423862457275, 1.0812609195709229, 1.0819165706634521, 1.078383445739746, 1.0795581340789795, 1.0815308094024658, 1.075189471244812, 1.077696442604065, 1.0746959447860718, 1.0747616291046143, 1.0727900266647339, 1.068223476409912, 1.0663018226623535, 1.068109154701233, 1.065610408782959, 1.0657464265823364, 1.064632773399353, 1.0668588876724243, 1.0684431791305542, 1.0658382177352905], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.506465494632721, 0.5441810488700867, 0.5603448152542114, 0.5592672228813171, 0.5592672228813171, 0.5581896305084229, 0.556034505367279, 0.5571120977401733, 0.5603448152542114, 0.5571120977401733, 0.5592672228813171, 0.556034505367279, 0.5495689511299133, 0.5344827771186829, 0.524784505367279, 0.5237069129943848, 0.5215517282485962, 0.506465494632721, 0.5107758641242981, 0.5161637663841248, 0.5118534564971924, 0.5032327771186829, 0.5053879022598267, 0.5096982717514038, 0.5053879022598267, 0.5129310488700867, 0.514008641242981, 0.517241358757019, 0.5161637663841248, 0.5193965435028076, 0.5150862336158752, 0.5204741358757019, 0.517241358757019, 0.5118534564971924, 0.5258620977401733, 0.5150862336158752, 0.5280172228813171, 0.5183189511299133, 0.5183189511299133, 0.5280172228813171, 0.5237069129943848, 0.5215517282485962, 0.517241358757019, 0.5323275923728943, 0.5258620977401733, 0.5301724076271057, 0.5280172228813171, 0.5420258641242981, 0.5269396305084229, 0.548491358757019, 0.537715494632721, 0.5441810488700867, 0.5441810488700867, 0.5517241358757019, 0.5506465435028076, 0.5398706793785095, 0.548491358757019, 0.5517241358757019, 0.5463362336158752, 0.5506465435028076, 0.5463362336158752, 0.5528017282485962, 0.5441810488700867, 0.545258641242981, 0.5431034564971924, 0.5463362336158752, 0.5635775923728943, 0.5538793206214905, 0.568965494632721, 0.545258641242981, 0.5387930870056152, 0.5495689511299133, 0.5635775923728943, 0.5517241358757019, 0.5603448152542114, 0.545258641242981, 0.5366379022598267, 0.5549569129943848, 0.545258641242981, 0.5431034564971924, 0.5592672228813171, 0.5463362336158752, 0.5614224076271057, 0.5603448152542114, 0.5657327771186829, 0.5614224076271057, 0.556034505367279, 0.5581896305084229, 0.5635775923728943, 0.5678879022598267, 0.5474137663841248, 0.5668103694915771, 0.5409482717514038, 0.5668103694915771]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 8s 49ms/step - loss: 1.4288 - accuracy: 0.4992 - val_loss: 1.4259 - val_accuracy: 0.5215\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 14ms/step - loss: 1.4226 - accuracy: 0.5023 - val_loss: 1.4199 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.4165 - accuracy: 0.5034 - val_loss: 1.4140 - val_accuracy: 0.5385\n","Epoch 4/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4104 - accuracy: 0.4986 - val_loss: 1.4081 - val_accuracy: 0.5351\n","Epoch 5/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4044 - accuracy: 0.5000 - val_loss: 1.4022 - val_accuracy: 0.5294\n","Epoch 6/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3984 - accuracy: 0.5127 - val_loss: 1.3964 - val_accuracy: 0.5249\n","Epoch 7/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3924 - accuracy: 0.5127 - val_loss: 1.3907 - val_accuracy: 0.5215\n","Epoch 8/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3864 - accuracy: 0.5076 - val_loss: 1.3849 - val_accuracy: 0.5260\n","Epoch 9/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3807 - accuracy: 0.5116 - val_loss: 1.3792 - val_accuracy: 0.5249\n","Epoch 10/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3748 - accuracy: 0.5141 - val_loss: 1.3736 - val_accuracy: 0.5271\n","Epoch 11/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3691 - accuracy: 0.5173 - val_loss: 1.3680 - val_accuracy: 0.5238\n","Epoch 12/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3633 - accuracy: 0.5141 - val_loss: 1.3624 - val_accuracy: 0.5283\n","Epoch 13/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3577 - accuracy: 0.5192 - val_loss: 1.3569 - val_accuracy: 0.5283\n","Epoch 14/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3521 - accuracy: 0.5232 - val_loss: 1.3514 - val_accuracy: 0.5283\n","Epoch 15/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3465 - accuracy: 0.5224 - val_loss: 1.3459 - val_accuracy: 0.5317\n","Epoch 16/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3408 - accuracy: 0.5232 - val_loss: 1.3405 - val_accuracy: 0.5362\n","Epoch 17/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3357 - accuracy: 0.5297 - val_loss: 1.3352 - val_accuracy: 0.5385\n","Epoch 18/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3301 - accuracy: 0.5286 - val_loss: 1.3299 - val_accuracy: 0.5373\n","Epoch 19/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3244 - accuracy: 0.5374 - val_loss: 1.3247 - val_accuracy: 0.5385\n","Epoch 20/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3193 - accuracy: 0.5359 - val_loss: 1.3194 - val_accuracy: 0.5351\n","Epoch 21/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3134 - accuracy: 0.5374 - val_loss: 1.3143 - val_accuracy: 0.5351\n","Epoch 22/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.3083 - accuracy: 0.5331 - val_loss: 1.3093 - val_accuracy: 0.5396\n","Epoch 23/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.3029 - accuracy: 0.5368 - val_loss: 1.3044 - val_accuracy: 0.5407\n","Epoch 24/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.2977 - accuracy: 0.5405 - val_loss: 1.2994 - val_accuracy: 0.5452\n","Epoch 25/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2922 - accuracy: 0.5393 - val_loss: 1.2946 - val_accuracy: 0.5351\n","Epoch 26/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2869 - accuracy: 0.5388 - val_loss: 1.2899 - val_accuracy: 0.5362\n","Epoch 27/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2816 - accuracy: 0.5422 - val_loss: 1.2851 - val_accuracy: 0.5396\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2763 - accuracy: 0.5427 - val_loss: 1.2808 - val_accuracy: 0.5317\n","Epoch 29/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.2713 - accuracy: 0.5470 - val_loss: 1.2759 - val_accuracy: 0.5396\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2659 - accuracy: 0.5456 - val_loss: 1.2713 - val_accuracy: 0.5430\n","Epoch 31/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.2607 - accuracy: 0.5529 - val_loss: 1.2669 - val_accuracy: 0.5419\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2554 - accuracy: 0.5453 - val_loss: 1.2620 - val_accuracy: 0.5441\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2504 - accuracy: 0.5498 - val_loss: 1.2575 - val_accuracy: 0.5441\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2455 - accuracy: 0.5507 - val_loss: 1.2534 - val_accuracy: 0.5419\n","Epoch 35/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2407 - accuracy: 0.5470 - val_loss: 1.2476 - val_accuracy: 0.5464\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2357 - accuracy: 0.5555 - val_loss: 1.2433 - val_accuracy: 0.5441\n","Epoch 37/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.2305 - accuracy: 0.5538 - val_loss: 1.2392 - val_accuracy: 0.5396\n","Epoch 38/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.2256 - accuracy: 0.5529 - val_loss: 1.2341 - val_accuracy: 0.5475\n","Epoch 39/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.2208 - accuracy: 0.5685 - val_loss: 1.2301 - val_accuracy: 0.5486\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2157 - accuracy: 0.5560 - val_loss: 1.2249 - val_accuracy: 0.5486\n","Epoch 41/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.2104 - accuracy: 0.5608 - val_loss: 1.2202 - val_accuracy: 0.5520\n","Epoch 42/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.2051 - accuracy: 0.5637 - val_loss: 1.2153 - val_accuracy: 0.5554\n","Epoch 43/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.2010 - accuracy: 0.5603 - val_loss: 1.2106 - val_accuracy: 0.5566\n","Epoch 44/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1961 - accuracy: 0.5625 - val_loss: 1.2087 - val_accuracy: 0.5441\n","Epoch 45/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1907 - accuracy: 0.5623 - val_loss: 1.2016 - val_accuracy: 0.5532\n","Epoch 46/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1864 - accuracy: 0.5656 - val_loss: 1.1976 - val_accuracy: 0.5554\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1812 - accuracy: 0.5679 - val_loss: 1.1950 - val_accuracy: 0.5532\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1770 - accuracy: 0.5685 - val_loss: 1.1886 - val_accuracy: 0.5532\n","Epoch 49/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1716 - accuracy: 0.5736 - val_loss: 1.1878 - val_accuracy: 0.5509\n","Epoch 50/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1675 - accuracy: 0.5736 - val_loss: 1.1829 - val_accuracy: 0.5588\n","Epoch 51/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1621 - accuracy: 0.5767 - val_loss: 1.1777 - val_accuracy: 0.5441\n","Epoch 52/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1566 - accuracy: 0.5815 - val_loss: 1.1747 - val_accuracy: 0.5543\n","Epoch 53/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1537 - accuracy: 0.5787 - val_loss: 1.1689 - val_accuracy: 0.5498\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1482 - accuracy: 0.5804 - val_loss: 1.1652 - val_accuracy: 0.5520\n","Epoch 55/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1439 - accuracy: 0.5798 - val_loss: 1.1641 - val_accuracy: 0.5509\n","Epoch 56/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1391 - accuracy: 0.5829 - val_loss: 1.1624 - val_accuracy: 0.5498\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1346 - accuracy: 0.5866 - val_loss: 1.1572 - val_accuracy: 0.5543\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1302 - accuracy: 0.5815 - val_loss: 1.1577 - val_accuracy: 0.5566\n","Epoch 59/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1261 - accuracy: 0.5829 - val_loss: 1.1496 - val_accuracy: 0.5633\n","Epoch 60/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1200 - accuracy: 0.5852 - val_loss: 1.1480 - val_accuracy: 0.5554\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1167 - accuracy: 0.5838 - val_loss: 1.1462 - val_accuracy: 0.5600\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1113 - accuracy: 0.5925 - val_loss: 1.1406 - val_accuracy: 0.5566\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1071 - accuracy: 0.5905 - val_loss: 1.1376 - val_accuracy: 0.5600\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1038 - accuracy: 0.5897 - val_loss: 1.1365 - val_accuracy: 0.5611\n","Epoch 65/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0992 - accuracy: 0.5982 - val_loss: 1.1322 - val_accuracy: 0.5622\n","Epoch 66/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0945 - accuracy: 0.5962 - val_loss: 1.1296 - val_accuracy: 0.5622\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0919 - accuracy: 0.5948 - val_loss: 1.1270 - val_accuracy: 0.5622\n","Epoch 68/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0877 - accuracy: 0.5939 - val_loss: 1.1233 - val_accuracy: 0.5645\n","Epoch 69/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0838 - accuracy: 0.5993 - val_loss: 1.1239 - val_accuracy: 0.5588\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0779 - accuracy: 0.5985 - val_loss: 1.1222 - val_accuracy: 0.5554\n","Epoch 71/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0729 - accuracy: 0.6022 - val_loss: 1.1197 - val_accuracy: 0.5566\n","Epoch 72/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0689 - accuracy: 0.6058 - val_loss: 1.1146 - val_accuracy: 0.5645\n","Epoch 73/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0669 - accuracy: 0.5988 - val_loss: 1.1138 - val_accuracy: 0.5554\n","Epoch 74/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0606 - accuracy: 0.6078 - val_loss: 1.1088 - val_accuracy: 0.5577\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0577 - accuracy: 0.5956 - val_loss: 1.1125 - val_accuracy: 0.5577\n","Epoch 76/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0538 - accuracy: 0.6078 - val_loss: 1.1104 - val_accuracy: 0.5554\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0483 - accuracy: 0.6118 - val_loss: 1.1031 - val_accuracy: 0.5611\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0455 - accuracy: 0.6109 - val_loss: 1.1000 - val_accuracy: 0.5577\n","Epoch 79/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0411 - accuracy: 0.6115 - val_loss: 1.1007 - val_accuracy: 0.5611\n","Epoch 80/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0355 - accuracy: 0.6106 - val_loss: 1.1004 - val_accuracy: 0.5577\n","Epoch 81/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0336 - accuracy: 0.6095 - val_loss: 1.0949 - val_accuracy: 0.5690\n","Epoch 82/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.0302 - accuracy: 0.6211 - val_loss: 1.0955 - val_accuracy: 0.5701\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0243 - accuracy: 0.6302 - val_loss: 1.0925 - val_accuracy: 0.5577\n","Epoch 84/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0212 - accuracy: 0.6194 - val_loss: 1.0903 - val_accuracy: 0.5645\n","Epoch 85/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0190 - accuracy: 0.6273 - val_loss: 1.0935 - val_accuracy: 0.5611\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0118 - accuracy: 0.6316 - val_loss: 1.0851 - val_accuracy: 0.5645\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0092 - accuracy: 0.6191 - val_loss: 1.0832 - val_accuracy: 0.5600\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0070 - accuracy: 0.6287 - val_loss: 1.0875 - val_accuracy: 0.5701\n","Epoch 89/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9998 - accuracy: 0.6338 - val_loss: 1.0847 - val_accuracy: 0.5701\n","Epoch 90/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9995 - accuracy: 0.6256 - val_loss: 1.0893 - val_accuracy: 0.5577\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9955 - accuracy: 0.6290 - val_loss: 1.0809 - val_accuracy: 0.5600\n","Epoch 92/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9909 - accuracy: 0.6350 - val_loss: 1.0819 - val_accuracy: 0.5690\n","Epoch 93/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9860 - accuracy: 0.6375 - val_loss: 1.0778 - val_accuracy: 0.5611\n","Epoch 94/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9844 - accuracy: 0.6256 - val_loss: 1.0747 - val_accuracy: 0.5724\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9799 - accuracy: 0.6321 - val_loss: 1.0750 - val_accuracy: 0.5554\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9731 - accuracy: 0.6361 - val_loss: 1.0764 - val_accuracy: 0.5633\n","Epoch 97/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9713 - accuracy: 0.6404 - val_loss: 1.0712 - val_accuracy: 0.5656\n","Epoch 98/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9718 - accuracy: 0.6378 - val_loss: 1.0806 - val_accuracy: 0.5543\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9667 - accuracy: 0.6401 - val_loss: 1.0878 - val_accuracy: 0.5667\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9616 - accuracy: 0.6409 - val_loss: 1.0701 - val_accuracy: 0.5645\n","{'loss': [1.428797721862793, 1.4226372241973877, 1.4164631366729736, 1.4104405641555786, 1.40438711643219, 1.398404598236084, 1.3924118280410767, 1.3864198923110962, 1.3806531429290771, 1.3748295307159424, 1.3690564632415771, 1.3633487224578857, 1.357676386833191, 1.3520900011062622, 1.3465014696121216, 1.3408455848693848, 1.3357152938842773, 1.3300833702087402, 1.3244010210037231, 1.3193308115005493, 1.3134342432022095, 1.3082865476608276, 1.3029173612594604, 1.2976568937301636, 1.2922042608261108, 1.2869058847427368, 1.2815500497817993, 1.2763316631317139, 1.271262288093567, 1.26592218875885, 1.2606847286224365, 1.2554341554641724, 1.250351905822754, 1.2454673051834106, 1.2407077550888062, 1.2357121706008911, 1.230542540550232, 1.2255932092666626, 1.2208383083343506, 1.2157255411148071, 1.2104411125183105, 1.205140471458435, 1.200984001159668, 1.1960701942443848, 1.1906591653823853, 1.1864286661148071, 1.1812279224395752, 1.1770262718200684, 1.1716467142105103, 1.1675198078155518, 1.1621016263961792, 1.1565797328948975, 1.1537431478500366, 1.148229718208313, 1.143876075744629, 1.1390659809112549, 1.1346105337142944, 1.1302111148834229, 1.1261235475540161, 1.1199856996536255, 1.1166694164276123, 1.1113156080245972, 1.1071103811264038, 1.1038076877593994, 1.0992017984390259, 1.0944631099700928, 1.0919101238250732, 1.0876950025558472, 1.0837781429290771, 1.077905297279358, 1.0728837251663208, 1.0689481496810913, 1.0668604373931885, 1.0606119632720947, 1.0577187538146973, 1.0538356304168701, 1.0482642650604248, 1.0454826354980469, 1.0411083698272705, 1.0354691743850708, 1.0336376428604126, 1.030181884765625, 1.0242902040481567, 1.0211522579193115, 1.018985629081726, 1.011792778968811, 1.009191870689392, 1.007032871246338, 0.9998420476913452, 0.9995142221450806, 0.9954970479011536, 0.9909147620201111, 0.9860305786132812, 0.9843543171882629, 0.9799378514289856, 0.9731457829475403, 0.9712916612625122, 0.9717648029327393, 0.9666759371757507, 0.961555540561676], 'accuracy': [0.4991511106491089, 0.5022637248039246, 0.5033955574035645, 0.49858516454696655, 0.5, 0.5127334594726562, 0.5127334594726562, 0.5076400637626648, 0.5116015672683716, 0.5141482949256897, 0.5172609090805054, 0.5141482949256897, 0.5192416310310364, 0.5232031941413879, 0.522354245185852, 0.5232031941413879, 0.5297113656997681, 0.5285795331001282, 0.5373514294624329, 0.5359365940093994, 0.5373514294624329, 0.5331069827079773, 0.5367854833602905, 0.5404640436172485, 0.5393322110176086, 0.5387662649154663, 0.5421618819236755, 0.5427277684211731, 0.5469722747802734, 0.54555743932724, 0.552914559841156, 0.5452744960784912, 0.5498019456863403, 0.5506508350372314, 0.5469722747802734, 0.5554612278938293, 0.5537634491920471, 0.552914559841156, 0.5684776306152344, 0.5560271739959717, 0.5608375668525696, 0.5636672377586365, 0.5602716207504272, 0.5625353455543518, 0.562252402305603, 0.5656480193138123, 0.5679117441177368, 0.5684776306152344, 0.5735710263252258, 0.5735710263252258, 0.5766836404800415, 0.5814940333366394, 0.5786644220352173, 0.5803622007369995, 0.5797962546348572, 0.5829088687896729, 0.5865874290466309, 0.5814940333366394, 0.5829088687896729, 0.5851725935935974, 0.583757758140564, 0.5925297141075134, 0.5905489325523376, 0.5897000432014465, 0.5981889963150024, 0.5962082743644714, 0.594793438911438, 0.5939445495605469, 0.5993208885192871, 0.598471999168396, 0.602150559425354, 0.6058290600776672, 0.5987549424171448, 0.607809841632843, 0.5956423282623291, 0.607809841632843, 0.6117713451385498, 0.6109224557876587, 0.611488401889801, 0.6106395125389099, 0.6095076203346252, 0.6211092472076416, 0.6301641464233398, 0.6194114089012146, 0.627334475517273, 0.6315789222717285, 0.6191284656524658, 0.6287493109703064, 0.6338426470756531, 0.6256366968154907, 0.6290322542190552, 0.6349745392799377, 0.6375212073326111, 0.6256366968154907, 0.6321448683738708, 0.6361063718795776, 0.640350878238678, 0.6378042101860046, 0.6400679349899292, 0.6409168243408203], 'val_loss': [1.4259270429611206, 1.4199260473251343, 1.413976788520813, 1.4080678224563599, 1.4022120237350464, 1.3964207172393799, 1.390651822090149, 1.384911298751831, 1.3792427778244019, 1.3735986948013306, 1.3679834604263306, 1.3624091148376465, 1.3569012880325317, 1.3514256477355957, 1.345947027206421, 1.3405139446258545, 1.3352012634277344, 1.3298519849777222, 1.3246768712997437, 1.3194422721862793, 1.3143185377120972, 1.309320330619812, 1.3043948411941528, 1.2993862628936768, 1.2946391105651855, 1.289926290512085, 1.2851451635360718, 1.2807928323745728, 1.2758827209472656, 1.2713245153427124, 1.2669016122817993, 1.2619587182998657, 1.2574552297592163, 1.253383994102478, 1.2475732564926147, 1.2432835102081299, 1.2391691207885742, 1.23406183719635, 1.23008394241333, 1.2248659133911133, 1.220188856124878, 1.215263843536377, 1.2106472253799438, 1.2087299823760986, 1.2016332149505615, 1.1975501775741577, 1.1949645280838013, 1.188628911972046, 1.1878429651260376, 1.1829047203063965, 1.1777207851409912, 1.1746975183486938, 1.1689497232437134, 1.1652357578277588, 1.1640912294387817, 1.1623852252960205, 1.1572233438491821, 1.1576908826828003, 1.1495516300201416, 1.1480271816253662, 1.1462152004241943, 1.1406160593032837, 1.1375703811645508, 1.1364929676055908, 1.1321996450424194, 1.1295647621154785, 1.1269700527191162, 1.1233378648757935, 1.1238658428192139, 1.1222403049468994, 1.1197009086608887, 1.114611029624939, 1.1138250827789307, 1.1087778806686401, 1.1125260591506958, 1.1104168891906738, 1.1031101942062378, 1.0999654531478882, 1.1006815433502197, 1.1004363298416138, 1.0948847532272339, 1.0955246686935425, 1.0925403833389282, 1.0903067588806152, 1.0934962034225464, 1.085142731666565, 1.083245873451233, 1.0874810218811035, 1.0846651792526245, 1.0892525911331177, 1.080861210823059, 1.0819244384765625, 1.077797770500183, 1.0746591091156006, 1.0749760866165161, 1.076396107673645, 1.0711716413497925, 1.0805883407592773, 1.087774395942688, 1.070119023323059], 'val_accuracy': [0.5214931964874268, 0.4954751133918762, 0.5384615659713745, 0.5350678563117981, 0.529411792755127, 0.5248869061470032, 0.5214931964874268, 0.5260180830955505, 0.5248869061470032, 0.5271493196487427, 0.523755669593811, 0.5282805562019348, 0.5282805562019348, 0.5282805562019348, 0.5316742062568665, 0.5361990928649902, 0.5384615659713745, 0.5373303294181824, 0.5384615659713745, 0.5350678563117981, 0.5350678563117981, 0.5395927429199219, 0.540723979473114, 0.5452488660812378, 0.5350678563117981, 0.5361990928649902, 0.5395927429199219, 0.5316742062568665, 0.5395927429199219, 0.5429864525794983, 0.5418552160263062, 0.5441176295280457, 0.5441176295280457, 0.5418552160263062, 0.5463801026344299, 0.5441176295280457, 0.5395927429199219, 0.5475113391876221, 0.5486425161361694, 0.5486425161361694, 0.5520362257957458, 0.5554298758506775, 0.5565611124038696, 0.5441176295280457, 0.5531674027442932, 0.5554298758506775, 0.5531674027442932, 0.5531674027442932, 0.5509049892425537, 0.5588235259056091, 0.5441176295280457, 0.5542986392974854, 0.5497737526893616, 0.5520362257957458, 0.5509049892425537, 0.5497737526893616, 0.5542986392974854, 0.5565611124038696, 0.5633484125137329, 0.5554298758506775, 0.5599547624588013, 0.5565611124038696, 0.5599547624588013, 0.5610859990119934, 0.5622171759605408, 0.5622171759605408, 0.5622171759605408, 0.564479649066925, 0.5588235259056091, 0.5554298758506775, 0.5565611124038696, 0.564479649066925, 0.5554298758506775, 0.557692289352417, 0.557692289352417, 0.5554298758506775, 0.5610859990119934, 0.557692289352417, 0.5610859990119934, 0.557692289352417, 0.5690045356750488, 0.570135772228241, 0.557692289352417, 0.564479649066925, 0.5610859990119934, 0.564479649066925, 0.5599547624588013, 0.570135772228241, 0.570135772228241, 0.557692289352417, 0.5599547624588013, 0.5690045356750488, 0.5610859990119934, 0.5723981857299805, 0.5554298758506775, 0.5633484125137329, 0.5656108856201172, 0.5542986392974854, 0.5667420625686646, 0.564479649066925]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 1.4285 - accuracy: 0.5036"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 9s 80ms/step - loss: 1.4285 - accuracy: 0.5036 - val_loss: 1.4253 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 32ms/step - loss: 1.4215 - accuracy: 0.5023 - val_loss: 1.4187 - val_accuracy: 0.5289\n","Epoch 3/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4146 - accuracy: 0.5044 - val_loss: 1.4121 - val_accuracy: 0.5289\n","Epoch 4/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.4077 - accuracy: 0.5090 - val_loss: 1.4056 - val_accuracy: 0.5279\n","Epoch 5/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.4010 - accuracy: 0.5137 - val_loss: 1.3992 - val_accuracy: 0.5300\n","Epoch 6/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3941 - accuracy: 0.5173 - val_loss: 1.3929 - val_accuracy: 0.5300\n","Epoch 7/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3874 - accuracy: 0.5196 - val_loss: 1.3866 - val_accuracy: 0.5279\n","Epoch 8/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3809 - accuracy: 0.5165 - val_loss: 1.3803 - val_accuracy: 0.5300\n","Epoch 9/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3745 - accuracy: 0.5238 - val_loss: 1.3742 - val_accuracy: 0.5300\n","Epoch 10/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.3680 - accuracy: 0.5253 - val_loss: 1.3681 - val_accuracy: 0.5310\n","Epoch 11/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3618 - accuracy: 0.5230 - val_loss: 1.3620 - val_accuracy: 0.5269\n","Epoch 12/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3557 - accuracy: 0.5287 - val_loss: 1.3561 - val_accuracy: 0.5320\n","Epoch 13/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3493 - accuracy: 0.5269 - val_loss: 1.3502 - val_accuracy: 0.5248\n","Epoch 14/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3435 - accuracy: 0.5341 - val_loss: 1.3444 - val_accuracy: 0.5217\n","Epoch 15/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3374 - accuracy: 0.5328 - val_loss: 1.3386 - val_accuracy: 0.5269\n","Epoch 16/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3313 - accuracy: 0.5349 - val_loss: 1.3330 - val_accuracy: 0.5258\n","Epoch 17/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3253 - accuracy: 0.5323 - val_loss: 1.3274 - val_accuracy: 0.5258\n","Epoch 18/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.3195 - accuracy: 0.5375 - val_loss: 1.3220 - val_accuracy: 0.5362\n","Epoch 19/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.3140 - accuracy: 0.5411 - val_loss: 1.3165 - val_accuracy: 0.5372\n","Epoch 20/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3078 - accuracy: 0.5426 - val_loss: 1.3111 - val_accuracy: 0.5372\n","Epoch 21/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3021 - accuracy: 0.5395 - val_loss: 1.3060 - val_accuracy: 0.5289\n","Epoch 22/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.2961 - accuracy: 0.5437 - val_loss: 1.3010 - val_accuracy: 0.5258\n","Epoch 23/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2904 - accuracy: 0.5432 - val_loss: 1.2960 - val_accuracy: 0.5269\n","Epoch 24/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2849 - accuracy: 0.5372 - val_loss: 1.2911 - val_accuracy: 0.5269\n","Epoch 25/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.2791 - accuracy: 0.5444 - val_loss: 1.2860 - val_accuracy: 0.5279\n","Epoch 26/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2738 - accuracy: 0.5465 - val_loss: 1.2806 - val_accuracy: 0.5279\n","Epoch 27/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2682 - accuracy: 0.5478 - val_loss: 1.2758 - val_accuracy: 0.5289\n","Epoch 28/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.2630 - accuracy: 0.5408 - val_loss: 1.2716 - val_accuracy: 0.5269\n","Epoch 29/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2574 - accuracy: 0.5460 - val_loss: 1.2658 - val_accuracy: 0.5310\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2516 - accuracy: 0.5465 - val_loss: 1.2612 - val_accuracy: 0.5300\n","Epoch 31/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2464 - accuracy: 0.5509 - val_loss: 1.2561 - val_accuracy: 0.5248\n","Epoch 32/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2409 - accuracy: 0.5540 - val_loss: 1.2508 - val_accuracy: 0.5269\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2354 - accuracy: 0.5556 - val_loss: 1.2460 - val_accuracy: 0.5258\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2304 - accuracy: 0.5530 - val_loss: 1.2412 - val_accuracy: 0.5269\n","Epoch 35/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.2247 - accuracy: 0.5599 - val_loss: 1.2363 - val_accuracy: 0.5258\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2195 - accuracy: 0.5568 - val_loss: 1.2331 - val_accuracy: 0.5269\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2143 - accuracy: 0.5561 - val_loss: 1.2273 - val_accuracy: 0.5289\n","Epoch 38/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.2093 - accuracy: 0.5566 - val_loss: 1.2223 - val_accuracy: 0.5279\n","Epoch 39/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.2040 - accuracy: 0.5682 - val_loss: 1.2198 - val_accuracy: 0.5279\n","Epoch 40/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1986 - accuracy: 0.5633 - val_loss: 1.2139 - val_accuracy: 0.5269\n","Epoch 41/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1936 - accuracy: 0.5649 - val_loss: 1.2109 - val_accuracy: 0.5227\n","Epoch 42/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1886 - accuracy: 0.5672 - val_loss: 1.2051 - val_accuracy: 0.5227\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1837 - accuracy: 0.5641 - val_loss: 1.2002 - val_accuracy: 0.5269\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1785 - accuracy: 0.5638 - val_loss: 1.1976 - val_accuracy: 0.5279\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1732 - accuracy: 0.5695 - val_loss: 1.1926 - val_accuracy: 0.5289\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1685 - accuracy: 0.5654 - val_loss: 1.1861 - val_accuracy: 0.5279\n","Epoch 47/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1639 - accuracy: 0.5724 - val_loss: 1.1845 - val_accuracy: 0.5279\n","Epoch 48/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1587 - accuracy: 0.5721 - val_loss: 1.1819 - val_accuracy: 0.5279\n","Epoch 49/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1534 - accuracy: 0.5713 - val_loss: 1.1743 - val_accuracy: 0.5331\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1486 - accuracy: 0.5744 - val_loss: 1.1708 - val_accuracy: 0.5341\n","Epoch 51/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1437 - accuracy: 0.5716 - val_loss: 1.1710 - val_accuracy: 0.5289\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1390 - accuracy: 0.5778 - val_loss: 1.1672 - val_accuracy: 0.5310\n","Epoch 53/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1339 - accuracy: 0.5778 - val_loss: 1.1642 - val_accuracy: 0.5289\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1290 - accuracy: 0.5749 - val_loss: 1.1544 - val_accuracy: 0.5310\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1248 - accuracy: 0.5804 - val_loss: 1.1557 - val_accuracy: 0.5310\n","Epoch 56/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1194 - accuracy: 0.5804 - val_loss: 1.1479 - val_accuracy: 0.5269\n","Epoch 57/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1148 - accuracy: 0.5866 - val_loss: 1.1493 - val_accuracy: 0.5372\n","Epoch 58/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1098 - accuracy: 0.5848 - val_loss: 1.1382 - val_accuracy: 0.5238\n","Epoch 59/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.1050 - accuracy: 0.5863 - val_loss: 1.1368 - val_accuracy: 0.5289\n","Epoch 60/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1011 - accuracy: 0.5835 - val_loss: 1.1378 - val_accuracy: 0.5310\n","Epoch 61/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0957 - accuracy: 0.5933 - val_loss: 1.1392 - val_accuracy: 0.5331\n","Epoch 62/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0911 - accuracy: 0.5953 - val_loss: 1.1282 - val_accuracy: 0.5300\n","Epoch 63/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0870 - accuracy: 0.5904 - val_loss: 1.1262 - val_accuracy: 0.5258\n","Epoch 64/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0820 - accuracy: 0.5966 - val_loss: 1.1242 - val_accuracy: 0.5217\n","Epoch 65/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0767 - accuracy: 0.5938 - val_loss: 1.1197 - val_accuracy: 0.5258\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0722 - accuracy: 0.5974 - val_loss: 1.1221 - val_accuracy: 0.5238\n","Epoch 67/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0686 - accuracy: 0.6008 - val_loss: 1.1156 - val_accuracy: 0.5258\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0630 - accuracy: 0.6034 - val_loss: 1.1145 - val_accuracy: 0.5258\n","Epoch 69/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0592 - accuracy: 0.6003 - val_loss: 1.1163 - val_accuracy: 0.5207\n","Epoch 70/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0548 - accuracy: 0.5979 - val_loss: 1.1174 - val_accuracy: 0.5269\n","Epoch 71/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0490 - accuracy: 0.6039 - val_loss: 1.1076 - val_accuracy: 0.5238\n","Epoch 72/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0454 - accuracy: 0.6096 - val_loss: 1.1131 - val_accuracy: 0.5227\n","Epoch 73/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0403 - accuracy: 0.6065 - val_loss: 1.1107 - val_accuracy: 0.5248\n","Epoch 74/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0352 - accuracy: 0.6031 - val_loss: 1.1133 - val_accuracy: 0.5279\n","Epoch 75/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0321 - accuracy: 0.6109 - val_loss: 1.1064 - val_accuracy: 0.5248\n","Epoch 76/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0270 - accuracy: 0.6140 - val_loss: 1.1026 - val_accuracy: 0.5155\n","Epoch 77/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0254 - accuracy: 0.6109 - val_loss: 1.1149 - val_accuracy: 0.5269\n","Epoch 78/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0201 - accuracy: 0.6140 - val_loss: 1.0931 - val_accuracy: 0.5196\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0184 - accuracy: 0.6132 - val_loss: 1.0966 - val_accuracy: 0.5186\n","Epoch 80/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0099 - accuracy: 0.6183 - val_loss: 1.0896 - val_accuracy: 0.5196\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0086 - accuracy: 0.6163 - val_loss: 1.0901 - val_accuracy: 0.5155\n","Epoch 82/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0036 - accuracy: 0.6212 - val_loss: 1.0930 - val_accuracy: 0.5145\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9974 - accuracy: 0.6207 - val_loss: 1.0941 - val_accuracy: 0.5114\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9946 - accuracy: 0.6181 - val_loss: 1.0890 - val_accuracy: 0.5186\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9899 - accuracy: 0.6171 - val_loss: 1.0924 - val_accuracy: 0.5186\n","Epoch 86/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9845 - accuracy: 0.6209 - val_loss: 1.0920 - val_accuracy: 0.5196\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9816 - accuracy: 0.6253 - val_loss: 1.0974 - val_accuracy: 0.5134\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9775 - accuracy: 0.6253 - val_loss: 1.0827 - val_accuracy: 0.5227\n","Epoch 89/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9737 - accuracy: 0.6274 - val_loss: 1.0762 - val_accuracy: 0.5207\n","Epoch 90/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9722 - accuracy: 0.6220 - val_loss: 1.0919 - val_accuracy: 0.5134\n","Epoch 91/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9651 - accuracy: 0.6305 - val_loss: 1.0790 - val_accuracy: 0.5155\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9628 - accuracy: 0.6284 - val_loss: 1.0882 - val_accuracy: 0.5124\n","Epoch 93/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9577 - accuracy: 0.6305 - val_loss: 1.0879 - val_accuracy: 0.5248\n","Epoch 94/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9536 - accuracy: 0.6305 - val_loss: 1.0779 - val_accuracy: 0.5289\n","Epoch 95/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9515 - accuracy: 0.6364 - val_loss: 1.0709 - val_accuracy: 0.5227\n","Epoch 96/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9462 - accuracy: 0.6370 - val_loss: 1.0786 - val_accuracy: 0.5196\n","Epoch 97/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9433 - accuracy: 0.6385 - val_loss: 1.0889 - val_accuracy: 0.5165\n","Epoch 98/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9381 - accuracy: 0.6426 - val_loss: 1.0787 - val_accuracy: 0.5227\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9359 - accuracy: 0.6388 - val_loss: 1.0785 - val_accuracy: 0.5258\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9326 - accuracy: 0.6403 - val_loss: 1.0873 - val_accuracy: 0.5196\n","{'loss': [1.428513765335083, 1.4214985370635986, 1.4145855903625488, 1.4077342748641968, 1.4009509086608887, 1.3941336870193481, 1.3874480724334717, 1.3809106349945068, 1.3744710683822632, 1.3679553270339966, 1.3617979288101196, 1.3556866645812988, 1.349316954612732, 1.3434975147247314, 1.3373745679855347, 1.3312898874282837, 1.3253484964370728, 1.319473385810852, 1.3140015602111816, 1.3077913522720337, 1.302148461341858, 1.2961241006851196, 1.2903714179992676, 1.2849494218826294, 1.2790731191635132, 1.2737706899642944, 1.268194317817688, 1.2630349397659302, 1.257380485534668, 1.251607060432434, 1.2464141845703125, 1.240943193435669, 1.2354227304458618, 1.2304003238677979, 1.2247363328933716, 1.2194596529006958, 1.2142888307571411, 1.209327220916748, 1.2040051221847534, 1.1985735893249512, 1.1936399936676025, 1.1885669231414795, 1.183669090270996, 1.1785458326339722, 1.1731510162353516, 1.1685432195663452, 1.1638524532318115, 1.1587458848953247, 1.153370976448059, 1.1485859155654907, 1.1436878442764282, 1.138993740081787, 1.1338545083999634, 1.1289801597595215, 1.124784231185913, 1.119357943534851, 1.114835262298584, 1.1098220348358154, 1.1050071716308594, 1.1011452674865723, 1.0957263708114624, 1.091107726097107, 1.0869945287704468, 1.082002878189087, 1.0767096281051636, 1.0722155570983887, 1.0686172246932983, 1.0630003213882446, 1.0591802597045898, 1.0548267364501953, 1.049026370048523, 1.0454281568527222, 1.0403395891189575, 1.0351632833480835, 1.032064437866211, 1.0270286798477173, 1.025386095046997, 1.0201336145401, 1.01836359500885, 1.0098625421524048, 1.0085668563842773, 1.003570318222046, 0.9974254965782166, 0.9945999979972839, 0.9898815751075745, 0.9845222234725952, 0.9816384315490723, 0.9774821996688843, 0.9736824631690979, 0.9722109436988831, 0.9650654196739197, 0.9627642631530762, 0.9576643109321594, 0.95356285572052, 0.9514771699905396, 0.9461826086044312, 0.9433020949363708, 0.9380757212638855, 0.9359214305877686, 0.9325945377349854], 'accuracy': [0.5036175847053528, 0.5023255944252014, 0.5043927431106567, 0.5090439319610596, 0.5136950612068176, 0.5173126459121704, 0.5196382403373718, 0.5165374875068665, 0.5237725973129272, 0.5253229737281799, 0.5229974389076233, 0.5286821722984314, 0.5268734097480774, 0.5341085195541382, 0.5328165292739868, 0.5348837375640869, 0.5322997570037842, 0.5374677181243896, 0.5410852432250977, 0.5426356792449951, 0.539534866809845, 0.5436692237854004, 0.5431524515151978, 0.5372093319892883, 0.5444444417953491, 0.5465116500854492, 0.5478036403656006, 0.5408268570899963, 0.5459948182106018, 0.5465116500854492, 0.550904393196106, 0.5540051460266113, 0.5555555820465088, 0.552971601486206, 0.5599483251571655, 0.5568475723266602, 0.5560723543167114, 0.5565891265869141, 0.5682170391082764, 0.5633074641227722, 0.5648579001426697, 0.5671834349632263, 0.564082682132721, 0.5638242959976196, 0.5695090293884277, 0.5653746724128723, 0.5723513960838318, 0.5720930099487305, 0.5713178515434265, 0.5744186043739319, 0.5715762376785278, 0.5777778029441833, 0.5777778029441833, 0.5749353766441345, 0.5803617835044861, 0.5803617835044861, 0.5865632891654968, 0.5847545266151428, 0.5863049030303955, 0.5834625363349915, 0.593281626701355, 0.5953488349914551, 0.5904392600059509, 0.5966408252716064, 0.5937984585762024, 0.5974160432815552, 0.6007751822471619, 0.6033591628074646, 0.6002584099769592, 0.5979328155517578, 0.603875994682312, 0.6095607280731201, 0.6064599752426147, 0.6031007766723633, 0.6108527183532715, 0.6139534711837769, 0.6108527183532715, 0.6139534711837769, 0.6131783127784729, 0.6183462738990784, 0.6162790656089783, 0.6211886405944824, 0.620671808719635, 0.6180878281593323, 0.617054283618927, 0.6209302544593811, 0.6253229975700378, 0.6253229975700378, 0.6273902058601379, 0.6219637989997864, 0.6304909586906433, 0.6284237504005432, 0.6304909586906433, 0.6304909586906433, 0.6364341378211975, 0.6369509100914001, 0.6385012865066528, 0.6426356434822083, 0.6387596726417542, 0.6403100490570068], 'val_loss': [1.4252978563308716, 1.4186731576919556, 1.412117838859558, 1.4056349992752075, 1.3992177248001099, 1.3928598165512085, 1.3865621089935303, 1.380333423614502, 1.3741562366485596, 1.3680602312088013, 1.362033724784851, 1.3560653924942017, 1.3501591682434082, 1.344360113143921, 1.3385993242263794, 1.3329614400863647, 1.3273926973342896, 1.3220081329345703, 1.3165050745010376, 1.3111366033554077, 1.3060318231582642, 1.3010393381118774, 1.2960087060928345, 1.2911334037780762, 1.2859853506088257, 1.280606746673584, 1.275827169418335, 1.2715842723846436, 1.2658284902572632, 1.2612229585647583, 1.2560878992080688, 1.2507668733596802, 1.2459644079208374, 1.2411973476409912, 1.236348032951355, 1.2331165075302124, 1.227268099784851, 1.2222920656204224, 1.219832181930542, 1.2138950824737549, 1.210927128791809, 1.2051241397857666, 1.2001813650131226, 1.197586178779602, 1.1926075220108032, 1.1861026287078857, 1.1845422983169556, 1.1819089651107788, 1.1742748022079468, 1.1708459854125977, 1.1710106134414673, 1.1672114133834839, 1.1642173528671265, 1.1544435024261475, 1.1556990146636963, 1.1479376554489136, 1.149309515953064, 1.138177752494812, 1.136753797531128, 1.1378203630447388, 1.1392196416854858, 1.128178596496582, 1.126164197921753, 1.124184250831604, 1.119667410850525, 1.122148036956787, 1.1156320571899414, 1.1145259141921997, 1.116268277168274, 1.117431879043579, 1.1075966358184814, 1.113116979598999, 1.110656976699829, 1.1133432388305664, 1.1063863039016724, 1.1025500297546387, 1.1148531436920166, 1.0931354761123657, 1.096602201461792, 1.0895674228668213, 1.090137004852295, 1.093042016029358, 1.0941463708877563, 1.0890334844589233, 1.0924054384231567, 1.0919800996780396, 1.0973840951919556, 1.08268141746521, 1.0762488842010498, 1.091871738433838, 1.079014778137207, 1.0881717205047607, 1.0878585577011108, 1.077940583229065, 1.0708578824996948, 1.0785874128341675, 1.0888985395431519, 1.078679084777832, 1.0784592628479004, 1.0873163938522339], 'val_accuracy': [0.48553720116615295, 0.5289255976676941, 0.5289255976676941, 0.5278925895690918, 0.5299586653709412, 0.5299586653709412, 0.5278925895690918, 0.5299586653709412, 0.5299586653709412, 0.5309917330741882, 0.5268595218658447, 0.5320248007774353, 0.5247933864593506, 0.5216942429542542, 0.5268595218658447, 0.5258264541625977, 0.5258264541625977, 0.5361570119857788, 0.5371900796890259, 0.5371900796890259, 0.5289255976676941, 0.5258264541625977, 0.5268595218658447, 0.5268595218658447, 0.5278925895690918, 0.5278925895690918, 0.5289255976676941, 0.5268595218658447, 0.5309917330741882, 0.5299586653709412, 0.5247933864593506, 0.5268595218658447, 0.5258264541625977, 0.5268595218658447, 0.5258264541625977, 0.5268595218658447, 0.5289255976676941, 0.5278925895690918, 0.5278925895690918, 0.5268595218658447, 0.5227272510528564, 0.5227272510528564, 0.5268595218658447, 0.5278925895690918, 0.5289255976676941, 0.5278925895690918, 0.5278925895690918, 0.5278925895690918, 0.5330578684806824, 0.5340909361839294, 0.5289255976676941, 0.5309917330741882, 0.5289255976676941, 0.5309917330741882, 0.5309917330741882, 0.5268595218658447, 0.5371900796890259, 0.5237603187561035, 0.5289255976676941, 0.5309917330741882, 0.5330578684806824, 0.5299586653709412, 0.5258264541625977, 0.5216942429542542, 0.5258264541625977, 0.5237603187561035, 0.5258264541625977, 0.5258264541625977, 0.5206611752510071, 0.5268595218658447, 0.5237603187561035, 0.5227272510528564, 0.5247933864593506, 0.5278925895690918, 0.5247933864593506, 0.5154958963394165, 0.5268595218658447, 0.51962810754776, 0.5185950398445129, 0.51962810754776, 0.5154958963394165, 0.5144628286361694, 0.5113636255264282, 0.5185950398445129, 0.5185950398445129, 0.51962810754776, 0.5134297609329224, 0.5227272510528564, 0.5206611752510071, 0.5134297609329224, 0.5154958963394165, 0.5123966932296753, 0.5247933864593506, 0.5289255976676941, 0.5227272510528564, 0.51962810754776, 0.5165289044380188, 0.5227272510528564, 0.5258264541625977, 0.51962810754776]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 7s 50ms/step - loss: 0.9803 - accuracy: 0.6048 - val_loss: 1.0185 - val_accuracy: 0.5183\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 1.0047 - accuracy: 0.6406"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 13ms/step - loss: 0.9745 - accuracy: 0.6183 - val_loss: 1.0166 - val_accuracy: 0.5172\n","Epoch 3/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.9704 - accuracy: 0.6145 - val_loss: 1.0135 - val_accuracy: 0.5194\n","Epoch 4/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.9671 - accuracy: 0.6078 - val_loss: 1.0098 - val_accuracy: 0.5205\n","Epoch 5/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.9609 - accuracy: 0.6180 - val_loss: 1.0060 - val_accuracy: 0.5259\n","Epoch 6/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.9604 - accuracy: 0.6148 - val_loss: 1.0029 - val_accuracy: 0.5269\n","Epoch 7/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.9550 - accuracy: 0.6169 - val_loss: 1.0004 - val_accuracy: 0.5291\n","Epoch 8/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.9512 - accuracy: 0.6193 - val_loss: 0.9971 - val_accuracy: 0.5323\n","Epoch 9/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9462 - accuracy: 0.6296 - val_loss: 0.9935 - val_accuracy: 0.5420\n","Epoch 10/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.9418 - accuracy: 0.6258 - val_loss: 0.9899 - val_accuracy: 0.5496\n","Epoch 11/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9374 - accuracy: 0.6245 - val_loss: 0.9901 - val_accuracy: 0.5420\n","Epoch 12/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9367 - accuracy: 0.6239 - val_loss: 0.9858 - val_accuracy: 0.5560\n","Epoch 13/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9329 - accuracy: 0.6317 - val_loss: 0.9838 - val_accuracy: 0.5582\n","Epoch 14/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9281 - accuracy: 0.6266 - val_loss: 0.9785 - val_accuracy: 0.5679\n","Epoch 15/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9250 - accuracy: 0.6374 - val_loss: 0.9714 - val_accuracy: 0.5894\n","Epoch 16/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9199 - accuracy: 0.6331 - val_loss: 0.9705 - val_accuracy: 0.5884\n","Epoch 17/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9209 - accuracy: 0.6255 - val_loss: 0.9713 - val_accuracy: 0.5830\n","Epoch 18/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9130 - accuracy: 0.6404 - val_loss: 0.9717 - val_accuracy: 0.5808\n","Epoch 19/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9114 - accuracy: 0.6282 - val_loss: 0.9632 - val_accuracy: 0.5894\n","Epoch 20/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9074 - accuracy: 0.6342 - val_loss: 0.9609 - val_accuracy: 0.5938\n","Epoch 21/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9025 - accuracy: 0.6466 - val_loss: 0.9537 - val_accuracy: 0.5862\n","Epoch 22/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9026 - accuracy: 0.6323 - val_loss: 0.9536 - val_accuracy: 0.5873\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8967 - accuracy: 0.6390 - val_loss: 0.9512 - val_accuracy: 0.5787\n","Epoch 24/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8918 - accuracy: 0.6471 - val_loss: 0.9525 - val_accuracy: 0.5797\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8903 - accuracy: 0.6506 - val_loss: 0.9536 - val_accuracy: 0.5819\n","Epoch 26/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8849 - accuracy: 0.6377 - val_loss: 0.9512 - val_accuracy: 0.5830\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8830 - accuracy: 0.6433 - val_loss: 0.9544 - val_accuracy: 0.5830\n","Epoch 28/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8774 - accuracy: 0.6533 - val_loss: 0.9513 - val_accuracy: 0.5819\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8775 - accuracy: 0.6530 - val_loss: 0.9520 - val_accuracy: 0.5808\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8727 - accuracy: 0.6538 - val_loss: 0.9580 - val_accuracy: 0.5776\n","Epoch 31/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8784 - accuracy: 0.6398 - val_loss: 0.9496 - val_accuracy: 0.5808\n","Epoch 32/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8730 - accuracy: 0.6428 - val_loss: 0.9457 - val_accuracy: 0.5819\n","Epoch 33/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8620 - accuracy: 0.6598 - val_loss: 0.9483 - val_accuracy: 0.5776\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8604 - accuracy: 0.6492 - val_loss: 0.9494 - val_accuracy: 0.5862\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8579 - accuracy: 0.6511 - val_loss: 0.9418 - val_accuracy: 0.5819\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8559 - accuracy: 0.6460 - val_loss: 0.9416 - val_accuracy: 0.5862\n","Epoch 37/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8526 - accuracy: 0.6552 - val_loss: 0.9491 - val_accuracy: 0.5884\n","Epoch 38/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8466 - accuracy: 0.6616 - val_loss: 0.9469 - val_accuracy: 0.5765\n","Epoch 39/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8475 - accuracy: 0.6484 - val_loss: 0.9444 - val_accuracy: 0.5894\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8439 - accuracy: 0.6530 - val_loss: 0.9419 - val_accuracy: 0.5862\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8427 - accuracy: 0.6509 - val_loss: 0.9432 - val_accuracy: 0.5711\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8390 - accuracy: 0.6560 - val_loss: 0.9443 - val_accuracy: 0.5657\n","Epoch 43/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8348 - accuracy: 0.6630 - val_loss: 0.9493 - val_accuracy: 0.5797\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8322 - accuracy: 0.6630 - val_loss: 0.9476 - val_accuracy: 0.5776\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8311 - accuracy: 0.6595 - val_loss: 0.9441 - val_accuracy: 0.5916\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8275 - accuracy: 0.6608 - val_loss: 0.9420 - val_accuracy: 0.5776\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8196 - accuracy: 0.6684 - val_loss: 0.9420 - val_accuracy: 0.5776\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8208 - accuracy: 0.6646 - val_loss: 0.9408 - val_accuracy: 0.5797\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8172 - accuracy: 0.6611 - val_loss: 0.9417 - val_accuracy: 0.5862\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8155 - accuracy: 0.6721 - val_loss: 0.9373 - val_accuracy: 0.5754\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8112 - accuracy: 0.6716 - val_loss: 0.9382 - val_accuracy: 0.5819\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8082 - accuracy: 0.6724 - val_loss: 0.9297 - val_accuracy: 0.5765\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8049 - accuracy: 0.6770 - val_loss: 0.9314 - val_accuracy: 0.5851\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8020 - accuracy: 0.6708 - val_loss: 0.9393 - val_accuracy: 0.5862\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7979 - accuracy: 0.6837 - val_loss: 0.9331 - val_accuracy: 0.5862\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7961 - accuracy: 0.6762 - val_loss: 0.9406 - val_accuracy: 0.5711\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7932 - accuracy: 0.6783 - val_loss: 0.9446 - val_accuracy: 0.5808\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7873 - accuracy: 0.6862 - val_loss: 0.9331 - val_accuracy: 0.5851\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7911 - accuracy: 0.6813 - val_loss: 0.9321 - val_accuracy: 0.5819\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7887 - accuracy: 0.6778 - val_loss: 0.9438 - val_accuracy: 0.5884\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7825 - accuracy: 0.6856 - val_loss: 0.9419 - val_accuracy: 0.5787\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7803 - accuracy: 0.6923 - val_loss: 0.9422 - val_accuracy: 0.5873\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7778 - accuracy: 0.6837 - val_loss: 0.9366 - val_accuracy: 0.5765\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7751 - accuracy: 0.6886 - val_loss: 0.9424 - val_accuracy: 0.5873\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7692 - accuracy: 0.6848 - val_loss: 0.9337 - val_accuracy: 0.5873\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7676 - accuracy: 0.6897 - val_loss: 0.9398 - val_accuracy: 0.5862\n","Epoch 67/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7691 - accuracy: 0.6875 - val_loss: 0.9513 - val_accuracy: 0.5862\n","Epoch 68/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7724 - accuracy: 0.6789 - val_loss: 0.9378 - val_accuracy: 0.5851\n","Epoch 69/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7632 - accuracy: 0.6899 - val_loss: 0.9438 - val_accuracy: 0.5668\n","Epoch 70/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7629 - accuracy: 0.6856 - val_loss: 0.9449 - val_accuracy: 0.5830\n","Epoch 71/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7554 - accuracy: 0.6897 - val_loss: 0.9377 - val_accuracy: 0.5927\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7575 - accuracy: 0.6894 - val_loss: 0.9400 - val_accuracy: 0.5797\n","Epoch 73/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7497 - accuracy: 0.6967 - val_loss: 0.9518 - val_accuracy: 0.5700\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7463 - accuracy: 0.7058 - val_loss: 0.9467 - val_accuracy: 0.5851\n","Epoch 75/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7472 - accuracy: 0.6948 - val_loss: 0.9423 - val_accuracy: 0.5679\n","Epoch 76/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7415 - accuracy: 0.6937 - val_loss: 0.9462 - val_accuracy: 0.5841\n","Epoch 77/100\n","29/29 [==============================] - 1s 44ms/step - loss: 0.7382 - accuracy: 0.7031 - val_loss: 0.9415 - val_accuracy: 0.5948\n","Epoch 78/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7398 - accuracy: 0.6988 - val_loss: 0.9365 - val_accuracy: 0.5970\n","Epoch 79/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.7401 - accuracy: 0.6967 - val_loss: 0.9462 - val_accuracy: 0.6013\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7353 - accuracy: 0.6967 - val_loss: 0.9465 - val_accuracy: 0.5744\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7295 - accuracy: 0.7074 - val_loss: 0.9477 - val_accuracy: 0.5884\n","Epoch 82/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7286 - accuracy: 0.7101 - val_loss: 0.9441 - val_accuracy: 0.5905\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7223 - accuracy: 0.7109 - val_loss: 0.9437 - val_accuracy: 0.5927\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7186 - accuracy: 0.7196 - val_loss: 0.9431 - val_accuracy: 0.5927\n","Epoch 85/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7206 - accuracy: 0.7096 - val_loss: 0.9547 - val_accuracy: 0.5776\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7194 - accuracy: 0.7072 - val_loss: 0.9540 - val_accuracy: 0.5776\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7145 - accuracy: 0.7107 - val_loss: 0.9493 - val_accuracy: 0.5927\n","Epoch 88/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7111 - accuracy: 0.7136 - val_loss: 0.9537 - val_accuracy: 0.5787\n","Epoch 89/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7042 - accuracy: 0.7228 - val_loss: 0.9531 - val_accuracy: 0.6024\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7011 - accuracy: 0.7198 - val_loss: 0.9761 - val_accuracy: 0.5657\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7036 - accuracy: 0.7188 - val_loss: 0.9603 - val_accuracy: 0.5744\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7038 - accuracy: 0.7082 - val_loss: 0.9596 - val_accuracy: 0.5905\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6996 - accuracy: 0.7126 - val_loss: 0.9541 - val_accuracy: 0.5970\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6934 - accuracy: 0.7177 - val_loss: 0.9620 - val_accuracy: 0.5938\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7020 - accuracy: 0.7152 - val_loss: 0.9578 - val_accuracy: 0.5938\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6882 - accuracy: 0.7322 - val_loss: 0.9679 - val_accuracy: 0.5797\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6895 - accuracy: 0.7247 - val_loss: 0.9601 - val_accuracy: 0.5884\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6899 - accuracy: 0.7220 - val_loss: 0.9803 - val_accuracy: 0.5776\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6893 - accuracy: 0.7158 - val_loss: 0.9762 - val_accuracy: 0.5754\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6770 - accuracy: 0.7274 - val_loss: 0.9575 - val_accuracy: 0.5938\n","{'loss': [0.9802997708320618, 0.9744714498519897, 0.9704185724258423, 0.9671028256416321, 0.9608595371246338, 0.9604107141494751, 0.954958975315094, 0.9511595368385315, 0.9462077021598816, 0.941804826259613, 0.9373745322227478, 0.9366500377655029, 0.9328860640525818, 0.9281087517738342, 0.9250051975250244, 0.9198516607284546, 0.9208775162696838, 0.9130457639694214, 0.9114147424697876, 0.9073706865310669, 0.9024761915206909, 0.9026472568511963, 0.8966832756996155, 0.8918485045433044, 0.8903042078018188, 0.8848587274551392, 0.8830309510231018, 0.8773537278175354, 0.8775402307510376, 0.8727457523345947, 0.8783953189849854, 0.873026430606842, 0.862005352973938, 0.8604244589805603, 0.8579155206680298, 0.8558598756790161, 0.8525940179824829, 0.8466054201126099, 0.8474962115287781, 0.8439359068870544, 0.8426597118377686, 0.8389711976051331, 0.8348382115364075, 0.8321815133094788, 0.8310521841049194, 0.8275458812713623, 0.8196277618408203, 0.8208308815956116, 0.8172364830970764, 0.8155084252357483, 0.8112291693687439, 0.8082407116889954, 0.804870069026947, 0.8019904494285583, 0.797879159450531, 0.7961374521255493, 0.7932332754135132, 0.7872770428657532, 0.7911437749862671, 0.788680374622345, 0.7824545502662659, 0.7803381681442261, 0.7778000831604004, 0.775093138217926, 0.7691950798034668, 0.7676289677619934, 0.7691022157669067, 0.7723923325538635, 0.7631692290306091, 0.7628768682479858, 0.7553584575653076, 0.7574604153633118, 0.7497038245201111, 0.7462959289550781, 0.7471675872802734, 0.7414583563804626, 0.7381596565246582, 0.7397870421409607, 0.7400502562522888, 0.7353019118309021, 0.729540228843689, 0.728643000125885, 0.7222601771354675, 0.7186471223831177, 0.7206008434295654, 0.7194229364395142, 0.714529275894165, 0.7110952734947205, 0.7042005658149719, 0.7011329531669617, 0.7036049365997314, 0.7037551403045654, 0.6995795965194702, 0.6933525800704956, 0.7019728422164917, 0.6882133483886719, 0.6895210146903992, 0.6898772120475769, 0.6893197298049927, 0.6769556999206543], 'accuracy': [0.6047952771186829, 0.6182650923728943, 0.6144935488700867, 0.607758641242981, 0.6179956793785095, 0.6147629022598267, 0.6169180870056152, 0.6193426847457886, 0.6295797228813171, 0.6258081793785095, 0.6244612336158752, 0.6239224076271057, 0.6317349076271057, 0.626616358757019, 0.6373922228813171, 0.6330819129943848, 0.6255387663841248, 0.6403555870056152, 0.6282327771186829, 0.634159505367279, 0.6465517282485962, 0.6322737336158752, 0.639008641242981, 0.647090494632721, 0.6505926847457886, 0.6376616358757019, 0.6433189511299133, 0.6532866358757019, 0.6530172228813171, 0.6538254022598267, 0.6398168206214905, 0.6427801847457886, 0.6597521305084229, 0.6492456793785095, 0.6511314511299133, 0.6460129022598267, 0.6551724076271057, 0.6616379022598267, 0.6484375, 0.6530172228813171, 0.6508620977401733, 0.6559805870056152, 0.6629849076271057, 0.6629849076271057, 0.6594827771186829, 0.6608297228813171, 0.6683728694915771, 0.6646012663841248, 0.6610991358757019, 0.6721444129943848, 0.6716055870056152, 0.6724137663841248, 0.6769935488700867, 0.6707974076271057, 0.6837284564971924, 0.6761853694915771, 0.678340494632721, 0.686152994632721, 0.681303858757019, 0.6778017282485962, 0.6856142282485962, 0.6923491358757019, 0.6837284564971924, 0.6885775923728943, 0.6848060488700867, 0.6896551847457886, 0.6875, 0.6788793206214905, 0.6899245977401733, 0.6856142282485962, 0.6896551847457886, 0.6893857717514038, 0.696659505367279, 0.7058189511299133, 0.6947737336158752, 0.693696141242981, 0.703125, 0.6988146305084229, 0.696659505367279, 0.696659505367279, 0.7074353694915771, 0.7101293206214905, 0.7109375, 0.7195581793785095, 0.709590494632721, 0.7071659564971924, 0.7106680870056152, 0.7136314511299133, 0.7227909564971924, 0.7198275923728943, 0.71875, 0.7082435488700867, 0.712553858757019, 0.7176724076271057, 0.7152478694915771, 0.7322198152542114, 0.7246767282485962, 0.7219827771186829, 0.7157866358757019, 0.7273706793785095], 'val_loss': [1.0184931755065918, 1.0165690183639526, 1.0134698152542114, 1.0098460912704468, 1.0060436725616455, 1.0029301643371582, 1.0003995895385742, 0.9970972537994385, 0.9934951066970825, 0.989935040473938, 0.9900983572006226, 0.985849916934967, 0.9837601780891418, 0.9784597158432007, 0.9713953733444214, 0.9705204963684082, 0.9712548851966858, 0.9717392921447754, 0.9632146954536438, 0.9609317183494568, 0.9537486433982849, 0.9535664319992065, 0.9511845707893372, 0.9524835348129272, 0.953626811504364, 0.9512327909469604, 0.9544409513473511, 0.9512995481491089, 0.9519660472869873, 0.9579927921295166, 0.9496067762374878, 0.945651113986969, 0.9482859969139099, 0.9494460821151733, 0.9417809844017029, 0.9416099786758423, 0.9490795731544495, 0.9469136595726013, 0.9443891644477844, 0.9418877363204956, 0.9431633949279785, 0.9443117380142212, 0.9493128657341003, 0.9476351737976074, 0.9440732598304749, 0.942012369632721, 0.9420088529586792, 0.940808892250061, 0.9417189955711365, 0.9373179078102112, 0.9382068514823914, 0.9296606183052063, 0.931388258934021, 0.9393467307090759, 0.933111310005188, 0.94060879945755, 0.9445706009864807, 0.9330736398696899, 0.9320586919784546, 0.9438382387161255, 0.9419391751289368, 0.9422338008880615, 0.9365793466567993, 0.9424117803573608, 0.9336556196212769, 0.9397506713867188, 0.9513309001922607, 0.9377633333206177, 0.9438499808311462, 0.9448726773262024, 0.937712550163269, 0.9400323629379272, 0.9517534375190735, 0.9467307925224304, 0.942266047000885, 0.9461817145347595, 0.9415308237075806, 0.9365090131759644, 0.9462025165557861, 0.9464930295944214, 0.9476603269577026, 0.9441100358963013, 0.9436538219451904, 0.9430650472640991, 0.9546948075294495, 0.9540193676948547, 0.9493339657783508, 0.9536980986595154, 0.9531459212303162, 0.9761242866516113, 0.960326075553894, 0.9595585465431213, 0.9541002511978149, 0.9620117545127869, 0.9578056931495667, 0.9679144620895386, 0.9601136445999146, 0.9803162217140198, 0.9761943221092224, 0.9575455188751221], 'val_accuracy': [0.5183189511299133, 0.517241358757019, 0.5193965435028076, 0.5204741358757019, 0.5258620977401733, 0.5269396305084229, 0.5290948152542114, 0.5323275923728943, 0.5420258641242981, 0.5495689511299133, 0.5420258641242981, 0.556034505367279, 0.5581896305084229, 0.5678879022598267, 0.5894396305084229, 0.5883620977401733, 0.5829741358757019, 0.5808189511299133, 0.5894396305084229, 0.59375, 0.5862069129943848, 0.587284505367279, 0.5786637663841248, 0.579741358757019, 0.5818965435028076, 0.5829741358757019, 0.5829741358757019, 0.5818965435028076, 0.5808189511299133, 0.5775862336158752, 0.5808189511299133, 0.5818965435028076, 0.5775862336158752, 0.5862069129943848, 0.5818965435028076, 0.5862069129943848, 0.5883620977401733, 0.576508641242981, 0.5894396305084229, 0.5862069129943848, 0.5711206793785095, 0.5657327771186829, 0.579741358757019, 0.5775862336158752, 0.5915948152542114, 0.5775862336158752, 0.5775862336158752, 0.579741358757019, 0.5862069129943848, 0.5754310488700867, 0.5818965435028076, 0.576508641242981, 0.5851293206214905, 0.5862069129943848, 0.5862069129943848, 0.5711206793785095, 0.5808189511299133, 0.5851293206214905, 0.5818965435028076, 0.5883620977401733, 0.5786637663841248, 0.587284505367279, 0.576508641242981, 0.587284505367279, 0.587284505367279, 0.5862069129943848, 0.5862069129943848, 0.5851293206214905, 0.5668103694915771, 0.5829741358757019, 0.5926724076271057, 0.579741358757019, 0.5700430870056152, 0.5851293206214905, 0.5678879022598267, 0.5840517282485962, 0.5948275923728943, 0.5969827771186829, 0.6012930870056152, 0.5743534564971924, 0.5883620977401733, 0.5905172228813171, 0.5926724076271057, 0.5926724076271057, 0.5775862336158752, 0.5775862336158752, 0.5926724076271057, 0.5786637663841248, 0.6023706793785095, 0.5657327771186829, 0.5743534564971924, 0.5905172228813171, 0.5969827771186829, 0.59375, 0.59375, 0.579741358757019, 0.5883620977401733, 0.5775862336158752, 0.5754310488700867, 0.59375]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 6s 49ms/step - loss: 0.9777 - accuracy: 0.6115 - val_loss: 1.0203 - val_accuracy: 0.5057\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 14ms/step - loss: 0.9723 - accuracy: 0.6157 - val_loss: 1.0183 - val_accuracy: 0.5057\n","Epoch 3/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9683 - accuracy: 0.6126 - val_loss: 1.0151 - val_accuracy: 0.5068\n","Epoch 4/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.9614 - accuracy: 0.6092 - val_loss: 1.0123 - val_accuracy: 0.5079\n","Epoch 5/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9590 - accuracy: 0.6135 - val_loss: 1.0103 - val_accuracy: 0.5079\n","Epoch 6/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.9551 - accuracy: 0.6200 - val_loss: 1.0057 - val_accuracy: 0.5124\n","Epoch 7/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.9497 - accuracy: 0.6200 - val_loss: 1.0022 - val_accuracy: 0.5192\n","Epoch 8/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.9465 - accuracy: 0.6225 - val_loss: 0.9989 - val_accuracy: 0.5260\n","Epoch 9/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.9430 - accuracy: 0.6242 - val_loss: 0.9947 - val_accuracy: 0.5339\n","Epoch 10/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.9382 - accuracy: 0.6225 - val_loss: 0.9902 - val_accuracy: 0.5430\n","Epoch 11/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9381 - accuracy: 0.6276 - val_loss: 0.9882 - val_accuracy: 0.5407\n","Epoch 12/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9327 - accuracy: 0.6271 - val_loss: 0.9840 - val_accuracy: 0.5407\n","Epoch 13/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9299 - accuracy: 0.6217 - val_loss: 0.9788 - val_accuracy: 0.5509\n","Epoch 14/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9274 - accuracy: 0.6259 - val_loss: 0.9766 - val_accuracy: 0.5509\n","Epoch 15/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9229 - accuracy: 0.6316 - val_loss: 0.9681 - val_accuracy: 0.5509\n","Epoch 16/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9170 - accuracy: 0.6333 - val_loss: 0.9646 - val_accuracy: 0.5724\n","Epoch 17/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9179 - accuracy: 0.6304 - val_loss: 0.9629 - val_accuracy: 0.5724\n","Epoch 18/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9128 - accuracy: 0.6412 - val_loss: 0.9587 - val_accuracy: 0.5724\n","Epoch 19/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9094 - accuracy: 0.6316 - val_loss: 0.9535 - val_accuracy: 0.5826\n","Epoch 20/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9065 - accuracy: 0.6389 - val_loss: 0.9548 - val_accuracy: 0.5679\n","Epoch 21/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9024 - accuracy: 0.6367 - val_loss: 0.9491 - val_accuracy: 0.5837\n","Epoch 22/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8996 - accuracy: 0.6370 - val_loss: 0.9485 - val_accuracy: 0.5882\n","Epoch 23/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8970 - accuracy: 0.6463 - val_loss: 0.9432 - val_accuracy: 0.5950\n","Epoch 24/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8925 - accuracy: 0.6624 - val_loss: 0.9433 - val_accuracy: 0.5803\n","Epoch 25/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8874 - accuracy: 0.6404 - val_loss: 0.9429 - val_accuracy: 0.5792\n","Epoch 26/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8860 - accuracy: 0.6466 - val_loss: 0.9461 - val_accuracy: 0.5995\n","Epoch 27/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8852 - accuracy: 0.6387 - val_loss: 0.9385 - val_accuracy: 0.5995\n","Epoch 28/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8791 - accuracy: 0.6449 - val_loss: 0.9403 - val_accuracy: 0.5882\n","Epoch 29/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8769 - accuracy: 0.6474 - val_loss: 0.9466 - val_accuracy: 0.5984\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8742 - accuracy: 0.6474 - val_loss: 0.9456 - val_accuracy: 0.5848\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8713 - accuracy: 0.6460 - val_loss: 0.9409 - val_accuracy: 0.5803\n","Epoch 32/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8652 - accuracy: 0.6548 - val_loss: 0.9387 - val_accuracy: 0.5848\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8627 - accuracy: 0.6505 - val_loss: 0.9369 - val_accuracy: 0.5871\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8603 - accuracy: 0.6514 - val_loss: 0.9396 - val_accuracy: 0.5871\n","Epoch 35/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8578 - accuracy: 0.6545 - val_loss: 0.9328 - val_accuracy: 0.5781\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8587 - accuracy: 0.6503 - val_loss: 0.9348 - val_accuracy: 0.5860\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8561 - accuracy: 0.6556 - val_loss: 0.9338 - val_accuracy: 0.5848\n","Epoch 38/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8504 - accuracy: 0.6553 - val_loss: 0.9417 - val_accuracy: 0.5894\n","Epoch 39/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8452 - accuracy: 0.6655 - val_loss: 0.9444 - val_accuracy: 0.5848\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8438 - accuracy: 0.6636 - val_loss: 0.9289 - val_accuracy: 0.5803\n","Epoch 41/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8369 - accuracy: 0.6616 - val_loss: 0.9270 - val_accuracy: 0.5962\n","Epoch 42/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8355 - accuracy: 0.6701 - val_loss: 0.9359 - val_accuracy: 0.5871\n","Epoch 43/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8337 - accuracy: 0.6678 - val_loss: 0.9397 - val_accuracy: 0.5826\n","Epoch 44/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8310 - accuracy: 0.6596 - val_loss: 0.9559 - val_accuracy: 0.5781\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8316 - accuracy: 0.6590 - val_loss: 0.9291 - val_accuracy: 0.5882\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8289 - accuracy: 0.6650 - val_loss: 0.9526 - val_accuracy: 0.5848\n","Epoch 47/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8262 - accuracy: 0.6650 - val_loss: 0.9441 - val_accuracy: 0.5803\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8214 - accuracy: 0.6726 - val_loss: 0.9274 - val_accuracy: 0.5882\n","Epoch 49/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8201 - accuracy: 0.6675 - val_loss: 0.9400 - val_accuracy: 0.5747\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8131 - accuracy: 0.6613 - val_loss: 0.9420 - val_accuracy: 0.5826\n","Epoch 51/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8150 - accuracy: 0.6715 - val_loss: 0.9304 - val_accuracy: 0.5803\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8052 - accuracy: 0.6786 - val_loss: 0.9295 - val_accuracy: 0.5848\n","Epoch 53/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8034 - accuracy: 0.6814 - val_loss: 0.9173 - val_accuracy: 0.5939\n","Epoch 54/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8035 - accuracy: 0.6641 - val_loss: 0.9244 - val_accuracy: 0.5871\n","Epoch 55/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8000 - accuracy: 0.6695 - val_loss: 0.9264 - val_accuracy: 0.5792\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7932 - accuracy: 0.6766 - val_loss: 0.9353 - val_accuracy: 0.5792\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7944 - accuracy: 0.6819 - val_loss: 0.9655 - val_accuracy: 0.5826\n","Epoch 58/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7928 - accuracy: 0.6825 - val_loss: 0.9353 - val_accuracy: 0.5724\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7900 - accuracy: 0.6842 - val_loss: 0.9271 - val_accuracy: 0.5781\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7817 - accuracy: 0.6845 - val_loss: 0.9252 - val_accuracy: 0.5916\n","Epoch 61/100\n","28/28 [==============================] - 1s 40ms/step - loss: 0.7784 - accuracy: 0.6972 - val_loss: 0.9260 - val_accuracy: 0.6018\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7805 - accuracy: 0.6831 - val_loss: 0.9227 - val_accuracy: 0.5792\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7764 - accuracy: 0.6845 - val_loss: 0.9362 - val_accuracy: 0.5781\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7712 - accuracy: 0.6913 - val_loss: 0.9375 - val_accuracy: 0.5724\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7735 - accuracy: 0.6907 - val_loss: 0.9519 - val_accuracy: 0.5803\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7681 - accuracy: 0.6899 - val_loss: 0.9490 - val_accuracy: 0.5792\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7580 - accuracy: 0.6972 - val_loss: 0.9424 - val_accuracy: 0.5758\n","Epoch 68/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7602 - accuracy: 0.6904 - val_loss: 0.9315 - val_accuracy: 0.5905\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7598 - accuracy: 0.6933 - val_loss: 0.9393 - val_accuracy: 0.5871\n","Epoch 70/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7564 - accuracy: 0.7020 - val_loss: 0.9270 - val_accuracy: 0.5769\n","Epoch 71/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7537 - accuracy: 0.6902 - val_loss: 0.9350 - val_accuracy: 0.5792\n","Epoch 72/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7479 - accuracy: 0.6938 - val_loss: 0.9472 - val_accuracy: 0.5814\n","Epoch 73/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7519 - accuracy: 0.6969 - val_loss: 0.9391 - val_accuracy: 0.5769\n","Epoch 74/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7504 - accuracy: 0.6947 - val_loss: 0.9411 - val_accuracy: 0.5984\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7472 - accuracy: 0.7080 - val_loss: 0.9450 - val_accuracy: 0.5860\n","Epoch 76/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7471 - accuracy: 0.6995 - val_loss: 0.9352 - val_accuracy: 0.5916\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7439 - accuracy: 0.7026 - val_loss: 0.9511 - val_accuracy: 0.5724\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7364 - accuracy: 0.7066 - val_loss: 0.9616 - val_accuracy: 0.5724\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7389 - accuracy: 0.7080 - val_loss: 0.9650 - val_accuracy: 0.5633\n","Epoch 80/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7367 - accuracy: 0.6930 - val_loss: 0.9524 - val_accuracy: 0.5803\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7326 - accuracy: 0.7015 - val_loss: 0.9504 - val_accuracy: 0.5758\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7320 - accuracy: 0.7091 - val_loss: 0.9445 - val_accuracy: 0.5781\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7218 - accuracy: 0.7066 - val_loss: 0.9456 - val_accuracy: 0.5713\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7179 - accuracy: 0.7196 - val_loss: 0.9828 - val_accuracy: 0.5735\n","Epoch 85/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7260 - accuracy: 0.7097 - val_loss: 0.9561 - val_accuracy: 0.5588\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7177 - accuracy: 0.7111 - val_loss: 0.9661 - val_accuracy: 0.5939\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7166 - accuracy: 0.7117 - val_loss: 0.9638 - val_accuracy: 0.5814\n","Epoch 88/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7130 - accuracy: 0.7156 - val_loss: 0.9700 - val_accuracy: 0.5747\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7184 - accuracy: 0.7114 - val_loss: 0.9674 - val_accuracy: 0.5577\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7121 - accuracy: 0.7235 - val_loss: 0.9881 - val_accuracy: 0.5826\n","Epoch 91/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7021 - accuracy: 0.7218 - val_loss: 0.9734 - val_accuracy: 0.5600\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7052 - accuracy: 0.7199 - val_loss: 0.9636 - val_accuracy: 0.5747\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7047 - accuracy: 0.7170 - val_loss: 0.9643 - val_accuracy: 0.5758\n","Epoch 94/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7006 - accuracy: 0.7108 - val_loss: 0.9634 - val_accuracy: 0.5871\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6973 - accuracy: 0.7255 - val_loss: 0.9937 - val_accuracy: 0.5588\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7000 - accuracy: 0.7264 - val_loss: 0.9830 - val_accuracy: 0.5803\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6927 - accuracy: 0.7247 - val_loss: 0.9621 - val_accuracy: 0.5769\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6917 - accuracy: 0.7247 - val_loss: 0.9737 - val_accuracy: 0.5871\n","Epoch 99/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6880 - accuracy: 0.7289 - val_loss: 0.9979 - val_accuracy: 0.5826\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6893 - accuracy: 0.7235 - val_loss: 0.9800 - val_accuracy: 0.5566\n","{'loss': [0.9777137637138367, 0.9722690582275391, 0.9682577252388, 0.961401104927063, 0.9590173363685608, 0.9550676941871643, 0.9496847987174988, 0.9464538097381592, 0.9430482983589172, 0.9382219314575195, 0.9381095170974731, 0.9327023029327393, 0.9298893809318542, 0.9274309873580933, 0.9228700995445251, 0.9169992208480835, 0.9178556203842163, 0.9127702116966248, 0.9093515872955322, 0.9065068960189819, 0.9024257659912109, 0.8996161222457886, 0.8969582319259644, 0.8924723863601685, 0.8873665928840637, 0.8860113620758057, 0.8852413892745972, 0.8790754079818726, 0.8768529295921326, 0.8741756677627563, 0.8712692856788635, 0.8652246594429016, 0.8627087473869324, 0.8603121638298035, 0.8578302264213562, 0.8586670756340027, 0.8561338782310486, 0.8503736853599548, 0.8451981544494629, 0.843805193901062, 0.8368842005729675, 0.8354791402816772, 0.8337124586105347, 0.8310445547103882, 0.8316325545310974, 0.8288695216178894, 0.8262248039245605, 0.8214175701141357, 0.8200745582580566, 0.8130624294281006, 0.8150321841239929, 0.8051863312721252, 0.8034184575080872, 0.8035140037536621, 0.8000280261039734, 0.7932371497154236, 0.7943644523620605, 0.792776346206665, 0.7900364398956299, 0.7816872000694275, 0.7784038186073303, 0.780487060546875, 0.7763689756393433, 0.7712193727493286, 0.7735485434532166, 0.768075704574585, 0.757973849773407, 0.7602477669715881, 0.7598091959953308, 0.7563971281051636, 0.7536969780921936, 0.7479273676872253, 0.751916229724884, 0.7504332661628723, 0.7472081184387207, 0.7471217513084412, 0.7438627481460571, 0.7364410758018494, 0.7389322519302368, 0.7366788387298584, 0.7326046228408813, 0.7319822311401367, 0.7218249440193176, 0.7178915739059448, 0.725982129573822, 0.7177426218986511, 0.7166096568107605, 0.7129979133605957, 0.7183634638786316, 0.7120833992958069, 0.7020528316497803, 0.7052287459373474, 0.7047430276870728, 0.7006239891052246, 0.6973026394844055, 0.7000373601913452, 0.6926798224449158, 0.691685676574707, 0.6880193948745728, 0.6893041729927063], 'accuracy': [0.611488401889801, 0.6157329082489014, 0.6126202344894409, 0.6092246770858765, 0.6134691834449768, 0.6199773550033569, 0.6199773550033569, 0.6225240230560303, 0.6242218613624573, 0.6225240230560303, 0.6276174187660217, 0.6270514726638794, 0.6216751337051392, 0.6259196400642395, 0.6315789222717285, 0.6332767605781555, 0.6304470896720886, 0.6411997675895691, 0.6315789222717285, 0.6389360427856445, 0.63667231798172, 0.6369553208351135, 0.6462931632995605, 0.6624221801757812, 0.640350878238678, 0.6465761065483093, 0.6386530995368958, 0.6448783278465271, 0.6474249958992004, 0.6474249958992004, 0.646010160446167, 0.6547821164131165, 0.6505376100540161, 0.651386559009552, 0.6544991731643677, 0.6502546668052673, 0.6556310057640076, 0.6553480625152588, 0.6655347943305969, 0.6635540723800659, 0.6615732908248901, 0.670062243938446, 0.6677985191345215, 0.6595925092697144, 0.6590266227722168, 0.6649688482284546, 0.6649688482284546, 0.6726089119911194, 0.6675155758857727, 0.6612903475761414, 0.6714770793914795, 0.678551197052002, 0.6813808679580688, 0.6641199588775635, 0.6694962978363037, 0.676570475101471, 0.6819468140602112, 0.6825127601623535, 0.6842105388641357, 0.6844934821128845, 0.6972269415855408, 0.6830786466598511, 0.6844934821128845, 0.6912846565246582, 0.6907187104225159, 0.6898698210716248, 0.6972269415855408, 0.6904357671737671, 0.693265438079834, 0.7020373344421387, 0.6901528239250183, 0.6938313245773315, 0.696943998336792, 0.6946802735328674, 0.7079796195030212, 0.6994906663894653, 0.702603280544281, 0.7065647840499878, 0.7079796195030212, 0.6929824352264404, 0.7014714479446411, 0.7091115117073059, 0.7065647840499878, 0.7195811867713928, 0.7096773982048035, 0.7110922336578369, 0.7116581797599792, 0.715619683265686, 0.7113752365112305, 0.7235427498817444, 0.7218449115753174, 0.7198641896247864, 0.7170345187187195, 0.7108092904090881, 0.7255234718322754, 0.7263723611831665, 0.7246745824813843, 0.7246745824813843, 0.7289190888404846, 0.7235427498817444], 'val_loss': [1.0203324556350708, 1.0183122158050537, 1.0151257514953613, 1.012338399887085, 1.0103384256362915, 1.0056952238082886, 1.0022464990615845, 0.9989228844642639, 0.9946579337120056, 0.9901893734931946, 0.9882344603538513, 0.9839636087417603, 0.9788204431533813, 0.976619303226471, 0.9681397080421448, 0.9645979404449463, 0.962867796421051, 0.9586716890335083, 0.9535060524940491, 0.9548104405403137, 0.9490769505500793, 0.9484581351280212, 0.9432118535041809, 0.9433006644248962, 0.942895770072937, 0.9461499452590942, 0.938530445098877, 0.9403423070907593, 0.9465502500534058, 0.9455863237380981, 0.9409376978874207, 0.9386556148529053, 0.9368508458137512, 0.9396371245384216, 0.9327830076217651, 0.9347688555717468, 0.9337685704231262, 0.9416784644126892, 0.9443517923355103, 0.9288691282272339, 0.926985502243042, 0.9358708262443542, 0.9396686553955078, 0.9559003114700317, 0.9290997982025146, 0.9525739550590515, 0.9440872669219971, 0.9273791313171387, 0.9399631023406982, 0.9420201778411865, 0.9303815960884094, 0.9294546842575073, 0.9172858595848083, 0.9243546724319458, 0.9263723492622375, 0.9353141784667969, 0.965542197227478, 0.9353013038635254, 0.9270931482315063, 0.9251670837402344, 0.9259617924690247, 0.9226610660552979, 0.9362471103668213, 0.9375179409980774, 0.9518529176712036, 0.9489869475364685, 0.942379355430603, 0.9315170645713806, 0.9392732381820679, 0.9270433783531189, 0.9350037574768066, 0.9471983909606934, 0.9391173124313354, 0.9411190748214722, 0.9450242519378662, 0.9351886510848999, 0.9510684013366699, 0.961578905582428, 0.9649553298950195, 0.9523969292640686, 0.9503529667854309, 0.9445009827613831, 0.9455663561820984, 0.9828420281410217, 0.956077516078949, 0.966067373752594, 0.9637717604637146, 0.969964325428009, 0.9674155116081238, 0.9881015419960022, 0.9734349846839905, 0.9636275768280029, 0.9642869234085083, 0.9633610844612122, 0.9937179088592529, 0.9829834699630737, 0.9620816111564636, 0.9737038016319275, 0.9979231357574463, 0.9799650311470032], 'val_accuracy': [0.5056561231613159, 0.5056561231613159, 0.5067873597145081, 0.5079185366630554, 0.5079185366630554, 0.5124434232711792, 0.5192307829856873, 0.5260180830955505, 0.5339366793632507, 0.5429864525794983, 0.540723979473114, 0.540723979473114, 0.5509049892425537, 0.5509049892425537, 0.5509049892425537, 0.5723981857299805, 0.5723981857299805, 0.5723981857299805, 0.5825791954994202, 0.5678732991218567, 0.5837104320526123, 0.5882353186607361, 0.5950226187705994, 0.5803167223930359, 0.5791855454444885, 0.5995475053787231, 0.5995475053787231, 0.5882353186607361, 0.598416268825531, 0.5848416090011597, 0.5803167223930359, 0.5848416090011597, 0.587104082107544, 0.587104082107544, 0.5780543088912964, 0.5859728455543518, 0.5848416090011597, 0.5893664956092834, 0.5848416090011597, 0.5803167223930359, 0.5961538553237915, 0.587104082107544, 0.5825791954994202, 0.5780543088912964, 0.5882353186607361, 0.5848416090011597, 0.5803167223930359, 0.5882353186607361, 0.5746606588363647, 0.5825791954994202, 0.5803167223930359, 0.5848416090011597, 0.5938913822174072, 0.587104082107544, 0.5791855454444885, 0.5791855454444885, 0.5825791954994202, 0.5723981857299805, 0.5780543088912964, 0.5916289687156677, 0.6018099784851074, 0.5791855454444885, 0.5780543088912964, 0.5723981857299805, 0.5803167223930359, 0.5791855454444885, 0.5757918357849121, 0.5904977321624756, 0.587104082107544, 0.5769230723381042, 0.5791855454444885, 0.581447958946228, 0.5769230723381042, 0.598416268825531, 0.5859728455543518, 0.5916289687156677, 0.5723981857299805, 0.5723981857299805, 0.5633484125137329, 0.5803167223930359, 0.5757918357849121, 0.5780543088912964, 0.5712669491767883, 0.5735294222831726, 0.5588235259056091, 0.5938913822174072, 0.581447958946228, 0.5746606588363647, 0.557692289352417, 0.5825791954994202, 0.5599547624588013, 0.5746606588363647, 0.5757918357849121, 0.587104082107544, 0.5588235259056091, 0.5803167223930359, 0.5769230723381042, 0.587104082107544, 0.5825791954994202, 0.5565611124038696]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 7s 48ms/step - loss: 0.9805 - accuracy: 0.6052 - val_loss: 1.0196 - val_accuracy: 0.5145\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 1s 21ms/step - loss: 0.9762 - accuracy: 0.6041 - val_loss: 1.0162 - val_accuracy: 0.5176\n","Epoch 3/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9712 - accuracy: 0.6044 - val_loss: 1.0139 - val_accuracy: 0.5155\n","Epoch 4/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9678 - accuracy: 0.6044 - val_loss: 1.0101 - val_accuracy: 0.5165\n","Epoch 5/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9594 - accuracy: 0.6181 - val_loss: 1.0074 - val_accuracy: 0.5176\n","Epoch 6/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9581 - accuracy: 0.6072 - val_loss: 1.0040 - val_accuracy: 0.5238\n","Epoch 7/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9514 - accuracy: 0.6158 - val_loss: 1.0011 - val_accuracy: 0.5238\n","Epoch 8/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9485 - accuracy: 0.6181 - val_loss: 0.9973 - val_accuracy: 0.5310\n","Epoch 9/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9457 - accuracy: 0.6129 - val_loss: 0.9953 - val_accuracy: 0.5279\n","Epoch 10/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9420 - accuracy: 0.6124 - val_loss: 0.9932 - val_accuracy: 0.5269\n","Epoch 11/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9370 - accuracy: 0.6191 - val_loss: 0.9899 - val_accuracy: 0.5300\n","Epoch 12/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9352 - accuracy: 0.6152 - val_loss: 0.9861 - val_accuracy: 0.5372\n","Epoch 13/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9306 - accuracy: 0.6245 - val_loss: 0.9817 - val_accuracy: 0.5465\n","Epoch 14/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9246 - accuracy: 0.6302 - val_loss: 0.9790 - val_accuracy: 0.5434\n","Epoch 15/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.9224 - accuracy: 0.6274 - val_loss: 0.9767 - val_accuracy: 0.5486\n","Epoch 16/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9195 - accuracy: 0.6191 - val_loss: 0.9727 - val_accuracy: 0.5486\n","Epoch 17/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9171 - accuracy: 0.6171 - val_loss: 0.9725 - val_accuracy: 0.5506\n","Epoch 18/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9104 - accuracy: 0.6328 - val_loss: 0.9730 - val_accuracy: 0.5465\n","Epoch 19/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9096 - accuracy: 0.6276 - val_loss: 0.9690 - val_accuracy: 0.5465\n","Epoch 20/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9039 - accuracy: 0.6370 - val_loss: 0.9700 - val_accuracy: 0.5496\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8980 - accuracy: 0.6349 - val_loss: 0.9668 - val_accuracy: 0.5444\n","Epoch 22/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9004 - accuracy: 0.6318 - val_loss: 0.9770 - val_accuracy: 0.5486\n","Epoch 23/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8969 - accuracy: 0.6346 - val_loss: 0.9751 - val_accuracy: 0.5558\n","Epoch 24/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8936 - accuracy: 0.6297 - val_loss: 0.9751 - val_accuracy: 0.5527\n","Epoch 25/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8870 - accuracy: 0.6313 - val_loss: 0.9686 - val_accuracy: 0.5517\n","Epoch 26/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8841 - accuracy: 0.6408 - val_loss: 0.9762 - val_accuracy: 0.5548\n","Epoch 27/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8812 - accuracy: 0.6320 - val_loss: 0.9781 - val_accuracy: 0.5568\n","Epoch 28/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8819 - accuracy: 0.6354 - val_loss: 0.9715 - val_accuracy: 0.5465\n","Epoch 29/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8799 - accuracy: 0.6297 - val_loss: 0.9757 - val_accuracy: 0.5486\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8723 - accuracy: 0.6372 - val_loss: 0.9782 - val_accuracy: 0.5496\n","Epoch 31/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8711 - accuracy: 0.6393 - val_loss: 0.9809 - val_accuracy: 0.5506\n","Epoch 32/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8624 - accuracy: 0.6468 - val_loss: 0.9682 - val_accuracy: 0.5444\n","Epoch 33/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8634 - accuracy: 0.6442 - val_loss: 0.9990 - val_accuracy: 0.5506\n","Epoch 34/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8583 - accuracy: 0.6442 - val_loss: 0.9946 - val_accuracy: 0.5527\n","Epoch 35/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8552 - accuracy: 0.6548 - val_loss: 0.9753 - val_accuracy: 0.5517\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8533 - accuracy: 0.6494 - val_loss: 1.0054 - val_accuracy: 0.5465\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8522 - accuracy: 0.6537 - val_loss: 0.9671 - val_accuracy: 0.5558\n","Epoch 38/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8488 - accuracy: 0.6460 - val_loss: 0.9858 - val_accuracy: 0.5496\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8460 - accuracy: 0.6532 - val_loss: 0.9785 - val_accuracy: 0.5527\n","Epoch 40/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8437 - accuracy: 0.6486 - val_loss: 0.9760 - val_accuracy: 0.5599\n","Epoch 41/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8394 - accuracy: 0.6424 - val_loss: 0.9821 - val_accuracy: 0.5527\n","Epoch 42/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8365 - accuracy: 0.6398 - val_loss: 0.9806 - val_accuracy: 0.5589\n","Epoch 43/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8301 - accuracy: 0.6525 - val_loss: 0.9886 - val_accuracy: 0.5537\n","Epoch 44/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8282 - accuracy: 0.6579 - val_loss: 0.9854 - val_accuracy: 0.5548\n","Epoch 45/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8267 - accuracy: 0.6581 - val_loss: 0.9843 - val_accuracy: 0.5527\n","Epoch 46/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8230 - accuracy: 0.6532 - val_loss: 0.9818 - val_accuracy: 0.5506\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8190 - accuracy: 0.6685 - val_loss: 0.9822 - val_accuracy: 0.5496\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8174 - accuracy: 0.6630 - val_loss: 0.9937 - val_accuracy: 0.5548\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8172 - accuracy: 0.6620 - val_loss: 0.9805 - val_accuracy: 0.5517\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8160 - accuracy: 0.6602 - val_loss: 1.0192 - val_accuracy: 0.5537\n","Epoch 51/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8104 - accuracy: 0.6703 - val_loss: 0.9781 - val_accuracy: 0.5496\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8068 - accuracy: 0.6566 - val_loss: 0.9791 - val_accuracy: 0.5486\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7998 - accuracy: 0.6778 - val_loss: 0.9799 - val_accuracy: 0.5537\n","Epoch 54/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8038 - accuracy: 0.6612 - val_loss: 0.9775 - val_accuracy: 0.5558\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7993 - accuracy: 0.6623 - val_loss: 1.0134 - val_accuracy: 0.5465\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7961 - accuracy: 0.6713 - val_loss: 0.9917 - val_accuracy: 0.5537\n","Epoch 57/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7911 - accuracy: 0.6687 - val_loss: 0.9795 - val_accuracy: 0.5465\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7859 - accuracy: 0.6708 - val_loss: 0.9707 - val_accuracy: 0.5486\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7866 - accuracy: 0.6739 - val_loss: 0.9796 - val_accuracy: 0.5444\n","Epoch 60/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7769 - accuracy: 0.6775 - val_loss: 0.9729 - val_accuracy: 0.5517\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7830 - accuracy: 0.6801 - val_loss: 1.0274 - val_accuracy: 0.5455\n","Epoch 62/100\n","31/31 [==============================] - 1s 37ms/step - loss: 0.7779 - accuracy: 0.6760 - val_loss: 0.9792 - val_accuracy: 0.5630\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7717 - accuracy: 0.6827 - val_loss: 0.9846 - val_accuracy: 0.5599\n","Epoch 64/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7732 - accuracy: 0.6773 - val_loss: 0.9904 - val_accuracy: 0.5537\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7722 - accuracy: 0.6729 - val_loss: 0.9684 - val_accuracy: 0.5506\n","Epoch 66/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7690 - accuracy: 0.6747 - val_loss: 0.9827 - val_accuracy: 0.5527\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7669 - accuracy: 0.6827 - val_loss: 1.0232 - val_accuracy: 0.5486\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7610 - accuracy: 0.6840 - val_loss: 0.9898 - val_accuracy: 0.5413\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7609 - accuracy: 0.6855 - val_loss: 0.9994 - val_accuracy: 0.5413\n","Epoch 70/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7584 - accuracy: 0.6845 - val_loss: 0.9681 - val_accuracy: 0.5465\n","Epoch 71/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7565 - accuracy: 0.6879 - val_loss: 1.0269 - val_accuracy: 0.5486\n","Epoch 72/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7553 - accuracy: 0.6842 - val_loss: 0.9880 - val_accuracy: 0.5486\n","Epoch 73/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7486 - accuracy: 0.6964 - val_loss: 1.0060 - val_accuracy: 0.5558\n","Epoch 74/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7535 - accuracy: 0.6853 - val_loss: 1.0194 - val_accuracy: 0.5548\n","Epoch 75/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7445 - accuracy: 0.6910 - val_loss: 1.0085 - val_accuracy: 0.5527\n","Epoch 76/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7451 - accuracy: 0.6982 - val_loss: 0.9799 - val_accuracy: 0.5475\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7390 - accuracy: 0.6953 - val_loss: 1.0132 - val_accuracy: 0.5537\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7377 - accuracy: 0.6860 - val_loss: 0.9671 - val_accuracy: 0.5444\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7371 - accuracy: 0.6977 - val_loss: 1.0141 - val_accuracy: 0.5465\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7285 - accuracy: 0.6925 - val_loss: 0.9804 - val_accuracy: 0.5444\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7287 - accuracy: 0.6972 - val_loss: 0.9905 - val_accuracy: 0.5486\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7235 - accuracy: 0.7052 - val_loss: 0.9996 - val_accuracy: 0.5548\n","Epoch 83/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7239 - accuracy: 0.6974 - val_loss: 1.0052 - val_accuracy: 0.5455\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7198 - accuracy: 0.7070 - val_loss: 1.0196 - val_accuracy: 0.5424\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7120 - accuracy: 0.7041 - val_loss: 1.0403 - val_accuracy: 0.5537\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7192 - accuracy: 0.7034 - val_loss: 1.0001 - val_accuracy: 0.5465\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7090 - accuracy: 0.6990 - val_loss: 1.0256 - val_accuracy: 0.5506\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7119 - accuracy: 0.7103 - val_loss: 1.0166 - val_accuracy: 0.5517\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7043 - accuracy: 0.7119 - val_loss: 1.0201 - val_accuracy: 0.5475\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7095 - accuracy: 0.7010 - val_loss: 1.0352 - val_accuracy: 0.5537\n","Epoch 91/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7019 - accuracy: 0.7093 - val_loss: 1.0077 - val_accuracy: 0.5465\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7006 - accuracy: 0.7152 - val_loss: 1.0892 - val_accuracy: 0.5496\n","Epoch 93/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6988 - accuracy: 0.7098 - val_loss: 1.0292 - val_accuracy: 0.5403\n","Epoch 94/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7050 - accuracy: 0.7119 - val_loss: 1.0303 - val_accuracy: 0.5517\n","Epoch 95/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7028 - accuracy: 0.7008 - val_loss: 1.0470 - val_accuracy: 0.5537\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.7140 - val_loss: 1.0578 - val_accuracy: 0.5517\n","Epoch 97/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6946 - accuracy: 0.7106 - val_loss: 1.0023 - val_accuracy: 0.5496\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6956 - accuracy: 0.7098 - val_loss: 1.0037 - val_accuracy: 0.5486\n","Epoch 99/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6844 - accuracy: 0.7209 - val_loss: 1.0849 - val_accuracy: 0.5444\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6836 - accuracy: 0.7225 - val_loss: 1.0452 - val_accuracy: 0.5548\n","{'loss': [0.9804643392562866, 0.976233959197998, 0.9712324738502502, 0.9678285121917725, 0.9594460129737854, 0.9581366777420044, 0.951378583908081, 0.9485142827033997, 0.9456779956817627, 0.9420241117477417, 0.9370297789573669, 0.9352076649665833, 0.9306169748306274, 0.9245564341545105, 0.9223796129226685, 0.9194663763046265, 0.9170817732810974, 0.9104025959968567, 0.9096207618713379, 0.9039364457130432, 0.8979527354240417, 0.9004039168357849, 0.8968594074249268, 0.8935868144035339, 0.887021541595459, 0.8841100335121155, 0.8811900019645691, 0.8818530440330505, 0.879948079586029, 0.872282087802887, 0.8711151480674744, 0.8623619079589844, 0.8633875846862793, 0.8583386540412903, 0.8552213311195374, 0.8532645106315613, 0.852150559425354, 0.8487785458564758, 0.8459826707839966, 0.8437471985816956, 0.8394106030464172, 0.8365268707275391, 0.8300600647926331, 0.8281782269477844, 0.8266674876213074, 0.8229941129684448, 0.8190025091171265, 0.817395806312561, 0.817226767539978, 0.8159522414207458, 0.8104282021522522, 0.8068169355392456, 0.7997729778289795, 0.8037748336791992, 0.7993448376655579, 0.7960992455482483, 0.7910738587379456, 0.785934329032898, 0.7865883111953735, 0.776870846748352, 0.7830366492271423, 0.7778892517089844, 0.7716507315635681, 0.7731963992118835, 0.7721938490867615, 0.7690222263336182, 0.7668874263763428, 0.7610287070274353, 0.7609236240386963, 0.758366048336029, 0.756483793258667, 0.7552966475486755, 0.7486027479171753, 0.75349360704422, 0.7445305585861206, 0.7451443672180176, 0.7390037178993225, 0.7377303242683411, 0.7371177673339844, 0.7285270690917969, 0.7286591529846191, 0.7234947681427002, 0.7238653302192688, 0.7198087573051453, 0.7119611501693726, 0.7191665172576904, 0.7089832425117493, 0.711945116519928, 0.7043325901031494, 0.7094902396202087, 0.7018502354621887, 0.7005521655082703, 0.6987631916999817, 0.704980731010437, 0.702770471572876, 0.6931854486465454, 0.6945810317993164, 0.6956358551979065, 0.6844305992126465, 0.6836066246032715], 'accuracy': [0.6051679849624634, 0.6041343808174133, 0.6043927669525146, 0.6043927669525146, 0.6180878281593323, 0.6072351336479187, 0.6157622933387756, 0.6180878281593323, 0.6129198670387268, 0.6124030947685242, 0.6191214323043823, 0.6152454614639282, 0.6245477795600891, 0.630232572555542, 0.6273902058601379, 0.6191214323043823, 0.617054283618927, 0.6328165531158447, 0.6276485919952393, 0.6369509100914001, 0.6348837018013, 0.6317829489707947, 0.6346253156661987, 0.6297157406806946, 0.631266176700592, 0.6408268809318542, 0.632041335105896, 0.6354005336761475, 0.6297157406806946, 0.6372092962265015, 0.6392765045166016, 0.6467700004577637, 0.6441860198974609, 0.6441860198974609, 0.654780387878418, 0.6493539810180664, 0.6537467837333679, 0.6459948420524597, 0.6532299518585205, 0.6485788226127625, 0.6423772573471069, 0.6397932767868042, 0.6524547934532166, 0.6578811407089233, 0.6581395268440247, 0.6532299518585205, 0.6684754490852356, 0.6630491018295288, 0.6620154976844788, 0.6602067351341248, 0.6702842116355896, 0.656589150428772, 0.6777777671813965, 0.6612403392791748, 0.6622738838195801, 0.6713178157806396, 0.6687338352203369, 0.670801043510437, 0.6739017963409424, 0.6775193810462952, 0.6801033616065979, 0.6759690046310425, 0.6826873421669006, 0.6772609949111938, 0.6728681921958923, 0.6746770143508911, 0.6826873421669006, 0.683979332447052, 0.6855297088623047, 0.6844961047172546, 0.6878553032875061, 0.6842377185821533, 0.6963824033737183, 0.6852713227272034, 0.6909560561180115, 0.698191225528717, 0.695348858833313, 0.6860465407371521, 0.6976743936538696, 0.6925064325332642, 0.697157621383667, 0.7051679491996765, 0.6974160075187683, 0.7069767713546753, 0.7041343450546265, 0.7033591866493225, 0.698966383934021, 0.710335910320282, 0.7118862867355347, 0.7010335922241211, 0.7093023061752319, 0.7152454853057861, 0.7098191380500793, 0.7118862867355347, 0.7007752060890198, 0.7139534950256348, 0.7105942964553833, 0.7098191380500793, 0.7209302186965942, 0.7224805951118469], 'val_loss': [1.0195517539978027, 1.0161532163619995, 1.013893961906433, 1.0101149082183838, 1.007394790649414, 1.0039559602737427, 1.0010751485824585, 0.9972636699676514, 0.9953358769416809, 0.9932231903076172, 0.9899255633354187, 0.986091136932373, 0.9816541075706482, 0.9790371060371399, 0.976723849773407, 0.9727311730384827, 0.9725008606910706, 0.9730421900749207, 0.9690044522285461, 0.9700331091880798, 0.9667680263519287, 0.9770119190216064, 0.975121796131134, 0.9751061797142029, 0.9685670733451843, 0.9762129783630371, 0.9780876040458679, 0.9715486168861389, 0.9757047295570374, 0.9782484173774719, 0.9808655381202698, 0.9682040214538574, 0.999047040939331, 0.9945623278617859, 0.9753342270851135, 1.0053917169570923, 0.9671087861061096, 0.9857988953590393, 0.9784941077232361, 0.9760295748710632, 0.9821189045906067, 0.9805512428283691, 0.988560676574707, 0.9854113459587097, 0.98431795835495, 0.9818452596664429, 0.9822221994400024, 0.9937088489532471, 0.9804859161376953, 1.0192477703094482, 0.9780776500701904, 0.9791074395179749, 0.9798592925071716, 0.9775074124336243, 1.0133588314056396, 0.991731584072113, 0.9795154929161072, 0.9707384705543518, 0.9795971512794495, 0.9729276299476624, 1.0273784399032593, 0.9791577458381653, 0.9845815896987915, 0.9903669953346252, 0.9684182405471802, 0.9827309846878052, 1.0232256650924683, 0.9898346066474915, 0.9994083046913147, 0.9680525064468384, 1.0268579721450806, 0.9879710078239441, 1.0059590339660645, 1.019419550895691, 1.0084670782089233, 0.9798518419265747, 1.0132008790969849, 0.9671248197555542, 1.0140702724456787, 0.9803925156593323, 0.9905205965042114, 0.9996277093887329, 1.0052158832550049, 1.0195763111114502, 1.0402988195419312, 1.0001246929168701, 1.0255820751190186, 1.0166467428207397, 1.0201313495635986, 1.0351519584655762, 1.0077418088912964, 1.0891882181167603, 1.0291684865951538, 1.0302722454071045, 1.0469788312911987, 1.0577728748321533, 1.002305507659912, 1.0036898851394653, 1.084885835647583, 1.0451655387878418], 'val_accuracy': [0.5144628286361694, 0.5175619721412659, 0.5154958963394165, 0.5165289044380188, 0.5175619721412659, 0.5237603187561035, 0.5237603187561035, 0.5309917330741882, 0.5278925895690918, 0.5268595218658447, 0.5299586653709412, 0.5371900796890259, 0.5464876294136047, 0.5433884263038635, 0.5485537052154541, 0.5485537052154541, 0.5506198406219482, 0.5464876294136047, 0.5464876294136047, 0.5495867729187012, 0.5444214940071106, 0.5485537052154541, 0.5557851195335388, 0.5526859760284424, 0.5516529083251953, 0.5547520518302917, 0.5568181872367859, 0.5464876294136047, 0.5485537052154541, 0.5495867729187012, 0.5506198406219482, 0.5444214940071106, 0.5506198406219482, 0.5526859760284424, 0.5516529083251953, 0.5464876294136047, 0.5557851195335388, 0.5495867729187012, 0.5526859760284424, 0.5599173307418823, 0.5526859760284424, 0.55888432264328, 0.5537189841270447, 0.5547520518302917, 0.5526859760284424, 0.5506198406219482, 0.5495867729187012, 0.5547520518302917, 0.5516529083251953, 0.5537189841270447, 0.5495867729187012, 0.5485537052154541, 0.5537189841270447, 0.5557851195335388, 0.5464876294136047, 0.5537189841270447, 0.5464876294136047, 0.5485537052154541, 0.5444214940071106, 0.5516529083251953, 0.5454545617103577, 0.5630165338516235, 0.5599173307418823, 0.5537189841270447, 0.5506198406219482, 0.5526859760284424, 0.5485537052154541, 0.5413222908973694, 0.5413222908973694, 0.5464876294136047, 0.5485537052154541, 0.5485537052154541, 0.5557851195335388, 0.5547520518302917, 0.5526859760284424, 0.547520637512207, 0.5537189841270447, 0.5444214940071106, 0.5464876294136047, 0.5444214940071106, 0.5485537052154541, 0.5547520518302917, 0.5454545617103577, 0.5423553586006165, 0.5537189841270447, 0.5464876294136047, 0.5506198406219482, 0.5516529083251953, 0.547520637512207, 0.5537189841270447, 0.5464876294136047, 0.5495867729187012, 0.5402892827987671, 0.5516529083251953, 0.5537189841270447, 0.5516529083251953, 0.5495867729187012, 0.5485537052154541, 0.5444214940071106, 0.5547520518302917]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 8s 74ms/step - loss: 0.7328 - accuracy: 0.6902 - val_loss: 0.8601 - val_accuracy: 0.5312\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 16ms/step - loss: 0.7297 - accuracy: 0.6894 - val_loss: 0.8717 - val_accuracy: 0.5194\n","Epoch 3/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7211 - accuracy: 0.6853 - val_loss: 0.8642 - val_accuracy: 0.5269\n","Epoch 4/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7098 - accuracy: 0.7034 - val_loss: 0.8617 - val_accuracy: 0.5302\n","Epoch 5/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7105 - accuracy: 0.7031 - val_loss: 0.8560 - val_accuracy: 0.5345\n","Epoch 6/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7066 - accuracy: 0.7050 - val_loss: 0.8522 - val_accuracy: 0.5420\n","Epoch 7/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7023 - accuracy: 0.7031 - val_loss: 0.8502 - val_accuracy: 0.5442\n","Epoch 8/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6992 - accuracy: 0.7080 - val_loss: 0.8460 - val_accuracy: 0.5550\n","Epoch 9/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6969 - accuracy: 0.7142 - val_loss: 0.8408 - val_accuracy: 0.5765\n","Epoch 10/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6942 - accuracy: 0.7064 - val_loss: 0.8376 - val_accuracy: 0.5657\n","Epoch 11/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7016 - accuracy: 0.7069 - val_loss: 0.8349 - val_accuracy: 0.5722\n","Epoch 12/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6935 - accuracy: 0.7096 - val_loss: 0.8230 - val_accuracy: 0.6024\n","Epoch 13/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6882 - accuracy: 0.7112 - val_loss: 0.8248 - val_accuracy: 0.6078\n","Epoch 14/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6904 - accuracy: 0.7134 - val_loss: 0.8190 - val_accuracy: 0.6185\n","Epoch 15/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6877 - accuracy: 0.7088 - val_loss: 0.8291 - val_accuracy: 0.6067\n","Epoch 16/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.6915 - accuracy: 0.7166 - val_loss: 0.8275 - val_accuracy: 0.6282\n","Epoch 17/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6752 - accuracy: 0.7247 - val_loss: 0.8211 - val_accuracy: 0.6142\n","Epoch 18/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6751 - accuracy: 0.7193 - val_loss: 0.8218 - val_accuracy: 0.6369\n","Epoch 19/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6761 - accuracy: 0.7241 - val_loss: 0.8017 - val_accuracy: 0.6304\n","Epoch 20/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6752 - accuracy: 0.7201 - val_loss: 0.8170 - val_accuracy: 0.6541\n","Epoch 21/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6719 - accuracy: 0.7255 - val_loss: 0.7995 - val_accuracy: 0.6412\n","Epoch 22/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6708 - accuracy: 0.7182 - val_loss: 0.8264 - val_accuracy: 0.6455\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6661 - accuracy: 0.7268 - val_loss: 0.8348 - val_accuracy: 0.6207\n","Epoch 24/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6673 - accuracy: 0.7287 - val_loss: 0.8240 - val_accuracy: 0.6164\n","Epoch 25/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6662 - accuracy: 0.7244 - val_loss: 0.8142 - val_accuracy: 0.6412\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6580 - accuracy: 0.7303 - val_loss: 0.8210 - val_accuracy: 0.6272\n","Epoch 27/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6548 - accuracy: 0.7320 - val_loss: 0.8401 - val_accuracy: 0.6239\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6554 - accuracy: 0.7274 - val_loss: 0.8501 - val_accuracy: 0.6261\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6540 - accuracy: 0.7355 - val_loss: 0.8589 - val_accuracy: 0.6175\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6525 - accuracy: 0.7336 - val_loss: 0.8238 - val_accuracy: 0.6390\n","Epoch 31/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6480 - accuracy: 0.7363 - val_loss: 0.8624 - val_accuracy: 0.6228\n","Epoch 32/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6537 - accuracy: 0.7311 - val_loss: 0.8495 - val_accuracy: 0.6455\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6435 - accuracy: 0.7427 - val_loss: 0.8482 - val_accuracy: 0.6164\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6460 - accuracy: 0.7371 - val_loss: 0.8795 - val_accuracy: 0.6013\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6413 - accuracy: 0.7414 - val_loss: 0.8565 - val_accuracy: 0.6422\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6371 - accuracy: 0.7470 - val_loss: 0.8484 - val_accuracy: 0.6498\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6349 - accuracy: 0.7390 - val_loss: 0.8499 - val_accuracy: 0.6476\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6321 - accuracy: 0.7395 - val_loss: 0.8665 - val_accuracy: 0.6218\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6304 - accuracy: 0.7425 - val_loss: 0.8469 - val_accuracy: 0.6476\n","Epoch 40/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6378 - accuracy: 0.7427 - val_loss: 0.9019 - val_accuracy: 0.6056\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6274 - accuracy: 0.7513 - val_loss: 0.8790 - val_accuracy: 0.6185\n","Epoch 42/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6241 - accuracy: 0.7513 - val_loss: 0.8605 - val_accuracy: 0.6239\n","Epoch 43/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6246 - accuracy: 0.7540 - val_loss: 0.8835 - val_accuracy: 0.6175\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6239 - accuracy: 0.7594 - val_loss: 0.8628 - val_accuracy: 0.6228\n","Epoch 45/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6187 - accuracy: 0.7457 - val_loss: 0.8784 - val_accuracy: 0.6282\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6179 - accuracy: 0.7395 - val_loss: 0.8591 - val_accuracy: 0.6315\n","Epoch 47/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6157 - accuracy: 0.7465 - val_loss: 0.8752 - val_accuracy: 0.6261\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6172 - accuracy: 0.7573 - val_loss: 0.8635 - val_accuracy: 0.6466\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6158 - accuracy: 0.7513 - val_loss: 0.8835 - val_accuracy: 0.6476\n","Epoch 50/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6187 - accuracy: 0.7557 - val_loss: 0.8720 - val_accuracy: 0.6390\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6171 - accuracy: 0.7503 - val_loss: 0.8900 - val_accuracy: 0.6304\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6135 - accuracy: 0.7535 - val_loss: 0.8665 - val_accuracy: 0.6379\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6081 - accuracy: 0.7538 - val_loss: 0.8771 - val_accuracy: 0.6422\n","Epoch 54/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6086 - accuracy: 0.7578 - val_loss: 0.9055 - val_accuracy: 0.6185\n","Epoch 55/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6009 - accuracy: 0.7718 - val_loss: 0.8915 - val_accuracy: 0.6228\n","Epoch 56/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5994 - accuracy: 0.7573 - val_loss: 0.8981 - val_accuracy: 0.6164\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6006 - accuracy: 0.7557 - val_loss: 0.9127 - val_accuracy: 0.6121\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5939 - accuracy: 0.7613 - val_loss: 0.8871 - val_accuracy: 0.6282\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5964 - accuracy: 0.7651 - val_loss: 0.8908 - val_accuracy: 0.6455\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5933 - accuracy: 0.7578 - val_loss: 0.8793 - val_accuracy: 0.6325\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5975 - accuracy: 0.7635 - val_loss: 0.8962 - val_accuracy: 0.6476\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5944 - accuracy: 0.7694 - val_loss: 0.8707 - val_accuracy: 0.6347\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5853 - accuracy: 0.7716 - val_loss: 0.8849 - val_accuracy: 0.6347\n","Epoch 64/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5829 - accuracy: 0.7689 - val_loss: 0.8875 - val_accuracy: 0.6325\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5819 - accuracy: 0.7718 - val_loss: 0.8783 - val_accuracy: 0.6325\n","Epoch 66/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5744 - accuracy: 0.7769 - val_loss: 0.8894 - val_accuracy: 0.6207\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5810 - accuracy: 0.7686 - val_loss: 0.8995 - val_accuracy: 0.6433\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5774 - accuracy: 0.7734 - val_loss: 0.8878 - val_accuracy: 0.6379\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5764 - accuracy: 0.7713 - val_loss: 0.9231 - val_accuracy: 0.6401\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5732 - accuracy: 0.7686 - val_loss: 0.8961 - val_accuracy: 0.6304\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5695 - accuracy: 0.7772 - val_loss: 0.9404 - val_accuracy: 0.6261\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5698 - accuracy: 0.7753 - val_loss: 0.9124 - val_accuracy: 0.6347\n","Epoch 73/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5753 - accuracy: 0.7786 - val_loss: 0.9279 - val_accuracy: 0.6261\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5679 - accuracy: 0.7842 - val_loss: 0.9217 - val_accuracy: 0.6325\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5621 - accuracy: 0.7759 - val_loss: 0.9417 - val_accuracy: 0.6228\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5651 - accuracy: 0.7777 - val_loss: 0.9150 - val_accuracy: 0.6369\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5648 - accuracy: 0.7829 - val_loss: 0.9264 - val_accuracy: 0.6261\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5513 - accuracy: 0.7839 - val_loss: 0.9233 - val_accuracy: 0.6358\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5591 - accuracy: 0.7788 - val_loss: 0.9417 - val_accuracy: 0.6196\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5527 - accuracy: 0.7853 - val_loss: 0.9373 - val_accuracy: 0.6325\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5497 - accuracy: 0.7880 - val_loss: 0.9392 - val_accuracy: 0.6293\n","Epoch 82/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5582 - accuracy: 0.7783 - val_loss: 0.9231 - val_accuracy: 0.6401\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5523 - accuracy: 0.7850 - val_loss: 0.9684 - val_accuracy: 0.6110\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5411 - accuracy: 0.7969 - val_loss: 0.9329 - val_accuracy: 0.6304\n","Epoch 85/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5534 - accuracy: 0.7799 - val_loss: 0.9503 - val_accuracy: 0.6433\n","Epoch 86/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5388 - accuracy: 0.7888 - val_loss: 0.9424 - val_accuracy: 0.6422\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5481 - accuracy: 0.7842 - val_loss: 0.9702 - val_accuracy: 0.6272\n","Epoch 88/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5440 - accuracy: 0.7891 - val_loss: 0.9592 - val_accuracy: 0.6358\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5462 - accuracy: 0.7829 - val_loss: 0.9184 - val_accuracy: 0.6401\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5352 - accuracy: 0.7982 - val_loss: 0.9471 - val_accuracy: 0.6347\n","Epoch 91/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5337 - accuracy: 0.7928 - val_loss: 0.9499 - val_accuracy: 0.6196\n","Epoch 92/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5316 - accuracy: 0.7993 - val_loss: 0.9661 - val_accuracy: 0.6293\n","Epoch 93/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5318 - accuracy: 0.7893 - val_loss: 0.9268 - val_accuracy: 0.6239\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5498 - accuracy: 0.7837 - val_loss: 0.9598 - val_accuracy: 0.6175\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5325 - accuracy: 0.8004 - val_loss: 0.9557 - val_accuracy: 0.6401\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5255 - accuracy: 0.8060 - val_loss: 0.9408 - val_accuracy: 0.6315\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5228 - accuracy: 0.8058 - val_loss: 0.9901 - val_accuracy: 0.6272\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5340 - accuracy: 0.8031 - val_loss: 0.9519 - val_accuracy: 0.6261\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5274 - accuracy: 0.7888 - val_loss: 0.9830 - val_accuracy: 0.6336\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5230 - accuracy: 0.8047 - val_loss: 0.9698 - val_accuracy: 0.6455\n","{'loss': [0.7328014373779297, 0.7297027111053467, 0.7211242318153381, 0.7097763419151306, 0.7105227112770081, 0.7066258788108826, 0.7023237943649292, 0.699224054813385, 0.6968972682952881, 0.6942299604415894, 0.7015644311904907, 0.6935337781906128, 0.6882466673851013, 0.6903821229934692, 0.6877136826515198, 0.6915211081504822, 0.6751988530158997, 0.6751221418380737, 0.6761471033096313, 0.6751688122749329, 0.6719042062759399, 0.6707692742347717, 0.6661102771759033, 0.6672857403755188, 0.6661596894264221, 0.6579926013946533, 0.6547632813453674, 0.6553857326507568, 0.6539971828460693, 0.6524801850318909, 0.6480448246002197, 0.6536930799484253, 0.6434699296951294, 0.6460340023040771, 0.6412858366966248, 0.6370644569396973, 0.63493412733078, 0.6320698261260986, 0.6303850412368774, 0.6377595067024231, 0.6274298429489136, 0.6241142749786377, 0.6245683431625366, 0.623908281326294, 0.6187281608581543, 0.6178533434867859, 0.6157085299491882, 0.6172012090682983, 0.6157851815223694, 0.6186556816101074, 0.617074728012085, 0.6134980320930481, 0.6081366539001465, 0.6086034178733826, 0.6009008288383484, 0.5994442701339722, 0.6006096005439758, 0.5939155220985413, 0.5964489579200745, 0.5933085083961487, 0.5974870920181274, 0.5943798422813416, 0.5853326320648193, 0.5829374194145203, 0.5819308161735535, 0.5743940472602844, 0.5809835195541382, 0.5773985385894775, 0.5763916373252869, 0.5732144117355347, 0.5695032477378845, 0.5698077082633972, 0.5752962827682495, 0.567864716053009, 0.5620657205581665, 0.5650576949119568, 0.564762532711029, 0.5513351559638977, 0.5590593814849854, 0.5526957511901855, 0.549679696559906, 0.5581753849983215, 0.5523427724838257, 0.5410827994346619, 0.5533574819564819, 0.5387864708900452, 0.548136830329895, 0.5439556837081909, 0.5462443828582764, 0.5351895689964294, 0.5337093472480774, 0.5315560102462769, 0.5318066477775574, 0.5497875809669495, 0.532497763633728, 0.5255003571510315, 0.5227823257446289, 0.5340138077735901, 0.5273832082748413, 0.5230427980422974], 'accuracy': [0.6901939511299133, 0.6893857717514038, 0.6853448152542114, 0.7033944129943848, 0.703125, 0.7050107717514038, 0.703125, 0.7079741358757019, 0.7141702771186829, 0.7063577771186829, 0.7068965435028076, 0.709590494632721, 0.7112069129943848, 0.7133620977401733, 0.7087823152542114, 0.7165948152542114, 0.7246767282485962, 0.7192887663841248, 0.7241379022598267, 0.720097005367279, 0.7254849076271057, 0.7182112336158752, 0.7268319129943848, 0.7287176847457886, 0.7244073152542114, 0.7303340435028076, 0.7319504022598267, 0.7273706793785095, 0.7354525923728943, 0.7335668206214905, 0.7362607717514038, 0.7311422228813171, 0.7427262663841248, 0.7370689511299133, 0.7413793206214905, 0.7470366358757019, 0.7389547228813171, 0.7394935488700867, 0.7424569129943848, 0.7427262663841248, 0.751347005367279, 0.751347005367279, 0.7540409564971924, 0.759428858757019, 0.7456896305084229, 0.7394935488700867, 0.7464978694915771, 0.7572737336158752, 0.751347005367279, 0.7556573152542114, 0.7502694129943848, 0.7535021305084229, 0.7537715435028076, 0.7578125, 0.771821141242981, 0.7572737336158752, 0.7556573152542114, 0.7613146305084229, 0.7650862336158752, 0.7578125, 0.7634698152542114, 0.7693965435028076, 0.7715517282485962, 0.7688577771186829, 0.771821141242981, 0.7769396305084229, 0.7685883641242981, 0.7734375, 0.7712823152542114, 0.7685883641242981, 0.7772090435028076, 0.7753232717514038, 0.7785560488700867, 0.7842133641242981, 0.7758620977401733, 0.7777478694915771, 0.782866358757019, 0.7839439511299133, 0.7788254022598267, 0.7852909564971924, 0.7879849076271057, 0.7782866358757019, 0.7850215435028076, 0.796875, 0.779902994632721, 0.7887930870056152, 0.7842133641242981, 0.7890625, 0.782866358757019, 0.798222005367279, 0.7928340435028076, 0.7992995977401733, 0.7893319129943848, 0.7836745977401733, 0.8003771305084229, 0.806034505367279, 0.8057650923728943, 0.803071141242981, 0.7887930870056152, 0.8046875], 'val_loss': [0.8601186275482178, 0.8716899156570435, 0.8642383813858032, 0.8616718053817749, 0.855957567691803, 0.8522496819496155, 0.8501732349395752, 0.8460437059402466, 0.8408471941947937, 0.8375709652900696, 0.8349199891090393, 0.8230446577072144, 0.8248461484909058, 0.8190069794654846, 0.8291232585906982, 0.8274519443511963, 0.8211115002632141, 0.8218284249305725, 0.8016536235809326, 0.816974401473999, 0.7995033860206604, 0.8263927102088928, 0.83479905128479, 0.8240309357643127, 0.8141855001449585, 0.8209558129310608, 0.8400651812553406, 0.8500933051109314, 0.8589195609092712, 0.823814868927002, 0.8624106645584106, 0.8495091795921326, 0.8482031226158142, 0.8795085549354553, 0.8564860224723816, 0.8483834266662598, 0.8498952388763428, 0.8664749264717102, 0.8468949794769287, 0.901948094367981, 0.8790338635444641, 0.8604587912559509, 0.8835086822509766, 0.8628045916557312, 0.8783511519432068, 0.8590842485427856, 0.8751556873321533, 0.8635023832321167, 0.8835201263427734, 0.8720182180404663, 0.8899568319320679, 0.8664998412132263, 0.8771414756774902, 0.905501663684845, 0.8914812803268433, 0.8980839848518372, 0.9127465486526489, 0.8870691657066345, 0.8908224701881409, 0.8792517185211182, 0.8961690068244934, 0.8707479238510132, 0.8848941922187805, 0.8875319361686707, 0.8782685995101929, 0.8894380927085876, 0.8994638323783875, 0.8878129720687866, 0.9230790138244629, 0.8961024284362793, 0.9403673410415649, 0.9123607277870178, 0.9279087781906128, 0.9216982126235962, 0.9417171478271484, 0.9149661660194397, 0.9263919591903687, 0.9233426451683044, 0.941687822341919, 0.9372515082359314, 0.9392438530921936, 0.9231014847755432, 0.9684022068977356, 0.9329302310943604, 0.9502527117729187, 0.9423684477806091, 0.9701877236366272, 0.959211528301239, 0.9183577299118042, 0.9471492767333984, 0.9498608708381653, 0.9660560488700867, 0.9267513155937195, 0.9597613215446472, 0.9557033181190491, 0.940750002861023, 0.9900721907615662, 0.9518808126449585, 0.9829851984977722, 0.9698174595832825], 'val_accuracy': [0.53125, 0.5193965435028076, 0.5269396305084229, 0.5301724076271057, 0.5344827771186829, 0.5420258641242981, 0.5441810488700867, 0.5549569129943848, 0.576508641242981, 0.5657327771186829, 0.5721982717514038, 0.6023706793785095, 0.607758641242981, 0.618534505367279, 0.6066810488700867, 0.6282327771186829, 0.6142241358757019, 0.6368534564971924, 0.6303879022598267, 0.6540948152542114, 0.6411637663841248, 0.6454741358757019, 0.6206896305084229, 0.6163793206214905, 0.6411637663841248, 0.6271551847457886, 0.6239224076271057, 0.6260775923728943, 0.6174569129943848, 0.639008641242981, 0.6228448152542114, 0.6454741358757019, 0.6163793206214905, 0.6012930870056152, 0.642241358757019, 0.649784505367279, 0.6476293206214905, 0.6217672228813171, 0.6476293206214905, 0.6056034564971924, 0.618534505367279, 0.6239224076271057, 0.6174569129943848, 0.6228448152542114, 0.6282327771186829, 0.631465494632721, 0.6260775923728943, 0.6465517282485962, 0.6476293206214905, 0.639008641242981, 0.6303879022598267, 0.6379310488700867, 0.642241358757019, 0.618534505367279, 0.6228448152542114, 0.6163793206214905, 0.6120689511299133, 0.6282327771186829, 0.6454741358757019, 0.6325430870056152, 0.6476293206214905, 0.6346982717514038, 0.6346982717514038, 0.6325430870056152, 0.6325430870056152, 0.6206896305084229, 0.6433189511299133, 0.6379310488700867, 0.6400862336158752, 0.6303879022598267, 0.6260775923728943, 0.6346982717514038, 0.6260775923728943, 0.6325430870056152, 0.6228448152542114, 0.6368534564971924, 0.6260775923728943, 0.6357758641242981, 0.6196120977401733, 0.6325430870056152, 0.6293103694915771, 0.6400862336158752, 0.610991358757019, 0.6303879022598267, 0.6433189511299133, 0.642241358757019, 0.6271551847457886, 0.6357758641242981, 0.6400862336158752, 0.6346982717514038, 0.6196120977401733, 0.6293103694915771, 0.6239224076271057, 0.6174569129943848, 0.6400862336158752, 0.631465494632721, 0.6271551847457886, 0.6260775923728943, 0.6336206793785095, 0.6454741358757019]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 8s 49ms/step - loss: 0.7267 - accuracy: 0.6950 - val_loss: 0.8675 - val_accuracy: 0.5113\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 13ms/step - loss: 0.7250 - accuracy: 0.6873 - val_loss: 0.8738 - val_accuracy: 0.5090\n","Epoch 3/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7150 - accuracy: 0.7001 - val_loss: 0.8727 - val_accuracy: 0.5136\n","Epoch 4/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7189 - accuracy: 0.6930 - val_loss: 0.8691 - val_accuracy: 0.5147\n","Epoch 5/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7062 - accuracy: 0.7097 - val_loss: 0.8580 - val_accuracy: 0.5226\n","Epoch 6/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7009 - accuracy: 0.7074 - val_loss: 0.8526 - val_accuracy: 0.5294\n","Epoch 7/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7013 - accuracy: 0.7054 - val_loss: 0.8452 - val_accuracy: 0.5385\n","Epoch 8/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6983 - accuracy: 0.7100 - val_loss: 0.8527 - val_accuracy: 0.5362\n","Epoch 9/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6988 - accuracy: 0.7145 - val_loss: 0.8450 - val_accuracy: 0.5396\n","Epoch 10/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6931 - accuracy: 0.7145 - val_loss: 0.8446 - val_accuracy: 0.5419\n","Epoch 11/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6916 - accuracy: 0.7142 - val_loss: 0.8388 - val_accuracy: 0.5475\n","Epoch 12/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6946 - accuracy: 0.7170 - val_loss: 0.8548 - val_accuracy: 0.5419\n","Epoch 13/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6882 - accuracy: 0.7145 - val_loss: 0.8193 - val_accuracy: 0.5713\n","Epoch 14/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6966 - accuracy: 0.7020 - val_loss: 0.8151 - val_accuracy: 0.5724\n","Epoch 15/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6814 - accuracy: 0.7199 - val_loss: 0.8112 - val_accuracy: 0.5848\n","Epoch 16/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6861 - accuracy: 0.7148 - val_loss: 0.8198 - val_accuracy: 0.5735\n","Epoch 17/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6794 - accuracy: 0.7284 - val_loss: 0.8009 - val_accuracy: 0.6131\n","Epoch 18/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6750 - accuracy: 0.7264 - val_loss: 0.8047 - val_accuracy: 0.5984\n","Epoch 19/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6806 - accuracy: 0.7159 - val_loss: 0.7973 - val_accuracy: 0.6165\n","Epoch 20/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.6707 - accuracy: 0.7204 - val_loss: 0.7905 - val_accuracy: 0.6278\n","Epoch 21/100\n","28/28 [==============================] - 1s 17ms/step - loss: 0.6684 - accuracy: 0.7284 - val_loss: 0.7896 - val_accuracy: 0.6222\n","Epoch 22/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6730 - accuracy: 0.7303 - val_loss: 0.8005 - val_accuracy: 0.6154\n","Epoch 23/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6751 - accuracy: 0.7224 - val_loss: 0.7953 - val_accuracy: 0.6199\n","Epoch 24/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6712 - accuracy: 0.7295 - val_loss: 0.7986 - val_accuracy: 0.6210\n","Epoch 25/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6584 - accuracy: 0.7264 - val_loss: 0.8021 - val_accuracy: 0.6301\n","Epoch 26/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6647 - accuracy: 0.7289 - val_loss: 0.8117 - val_accuracy: 0.6290\n","Epoch 27/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6611 - accuracy: 0.7391 - val_loss: 0.8094 - val_accuracy: 0.6143\n","Epoch 28/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6516 - accuracy: 0.7351 - val_loss: 0.8088 - val_accuracy: 0.6109\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6509 - accuracy: 0.7354 - val_loss: 0.8166 - val_accuracy: 0.6188\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6541 - accuracy: 0.7329 - val_loss: 0.8168 - val_accuracy: 0.6244\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6481 - accuracy: 0.7371 - val_loss: 0.8300 - val_accuracy: 0.6267\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6608 - accuracy: 0.7301 - val_loss: 0.8125 - val_accuracy: 0.6120\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6498 - accuracy: 0.7422 - val_loss: 0.8528 - val_accuracy: 0.6165\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6501 - accuracy: 0.7340 - val_loss: 0.8165 - val_accuracy: 0.6176\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6505 - accuracy: 0.7317 - val_loss: 0.8214 - val_accuracy: 0.6267\n","Epoch 36/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6425 - accuracy: 0.7518 - val_loss: 0.8620 - val_accuracy: 0.6267\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6531 - accuracy: 0.7275 - val_loss: 0.8375 - val_accuracy: 0.6165\n","Epoch 38/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6468 - accuracy: 0.7357 - val_loss: 0.8341 - val_accuracy: 0.6301\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6329 - accuracy: 0.7499 - val_loss: 0.8680 - val_accuracy: 0.6097\n","Epoch 40/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6360 - accuracy: 0.7453 - val_loss: 0.8626 - val_accuracy: 0.6143\n","Epoch 41/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6349 - accuracy: 0.7425 - val_loss: 0.8417 - val_accuracy: 0.6199\n","Epoch 42/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6314 - accuracy: 0.7445 - val_loss: 0.8580 - val_accuracy: 0.6448\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6351 - accuracy: 0.7467 - val_loss: 0.8642 - val_accuracy: 0.6346\n","Epoch 44/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6373 - accuracy: 0.7439 - val_loss: 0.8511 - val_accuracy: 0.6210\n","Epoch 45/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6310 - accuracy: 0.7479 - val_loss: 0.8551 - val_accuracy: 0.6278\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6239 - accuracy: 0.7550 - val_loss: 0.8592 - val_accuracy: 0.6131\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6227 - accuracy: 0.7518 - val_loss: 0.8624 - val_accuracy: 0.6086\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6225 - accuracy: 0.7501 - val_loss: 0.8581 - val_accuracy: 0.6154\n","Epoch 49/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6186 - accuracy: 0.7578 - val_loss: 0.8830 - val_accuracy: 0.6210\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6201 - accuracy: 0.7544 - val_loss: 0.8868 - val_accuracy: 0.6075\n","Epoch 51/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6210 - accuracy: 0.7504 - val_loss: 0.8767 - val_accuracy: 0.6176\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6103 - accuracy: 0.7516 - val_loss: 0.8607 - val_accuracy: 0.6301\n","Epoch 53/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6140 - accuracy: 0.7521 - val_loss: 0.8561 - val_accuracy: 0.6097\n","Epoch 54/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6142 - accuracy: 0.7612 - val_loss: 0.8684 - val_accuracy: 0.6233\n","Epoch 55/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6111 - accuracy: 0.7569 - val_loss: 0.9119 - val_accuracy: 0.6029\n","Epoch 56/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6075 - accuracy: 0.7634 - val_loss: 0.9096 - val_accuracy: 0.6120\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6039 - accuracy: 0.7702 - val_loss: 0.8909 - val_accuracy: 0.6165\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6079 - accuracy: 0.7493 - val_loss: 0.8875 - val_accuracy: 0.6154\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6025 - accuracy: 0.7612 - val_loss: 0.9038 - val_accuracy: 0.6041\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6089 - accuracy: 0.7572 - val_loss: 0.8885 - val_accuracy: 0.6278\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6037 - accuracy: 0.7550 - val_loss: 0.9024 - val_accuracy: 0.6324\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5957 - accuracy: 0.7668 - val_loss: 0.8660 - val_accuracy: 0.6086\n","Epoch 63/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5998 - accuracy: 0.7595 - val_loss: 0.8767 - val_accuracy: 0.6357\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5954 - accuracy: 0.7600 - val_loss: 0.8738 - val_accuracy: 0.6278\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5938 - accuracy: 0.7598 - val_loss: 0.8902 - val_accuracy: 0.6403\n","Epoch 66/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5928 - accuracy: 0.7702 - val_loss: 0.8935 - val_accuracy: 0.6222\n","Epoch 67/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5911 - accuracy: 0.7668 - val_loss: 0.9283 - val_accuracy: 0.6312\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5878 - accuracy: 0.7668 - val_loss: 0.9021 - val_accuracy: 0.6256\n","Epoch 69/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5936 - accuracy: 0.7637 - val_loss: 0.9158 - val_accuracy: 0.6391\n","Epoch 70/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5845 - accuracy: 0.7685 - val_loss: 0.8864 - val_accuracy: 0.6222\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5832 - accuracy: 0.7663 - val_loss: 0.8782 - val_accuracy: 0.6143\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5778 - accuracy: 0.7716 - val_loss: 0.9353 - val_accuracy: 0.6007\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5792 - accuracy: 0.7796 - val_loss: 0.9602 - val_accuracy: 0.6357\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5899 - accuracy: 0.7705 - val_loss: 0.9022 - val_accuracy: 0.6120\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5843 - accuracy: 0.7742 - val_loss: 0.9303 - val_accuracy: 0.6041\n","Epoch 76/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5753 - accuracy: 0.7790 - val_loss: 0.8999 - val_accuracy: 0.6414\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5774 - accuracy: 0.7784 - val_loss: 0.8955 - val_accuracy: 0.6312\n","Epoch 78/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5715 - accuracy: 0.7813 - val_loss: 0.9086 - val_accuracy: 0.6210\n","Epoch 79/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5722 - accuracy: 0.7813 - val_loss: 0.9057 - val_accuracy: 0.6278\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5774 - accuracy: 0.7748 - val_loss: 0.9009 - val_accuracy: 0.6063\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5701 - accuracy: 0.7753 - val_loss: 0.9124 - val_accuracy: 0.6052\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5607 - accuracy: 0.7832 - val_loss: 0.9236 - val_accuracy: 0.6335\n","Epoch 83/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5600 - accuracy: 0.7813 - val_loss: 0.9470 - val_accuracy: 0.6244\n","Epoch 84/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5597 - accuracy: 0.7832 - val_loss: 0.9352 - val_accuracy: 0.6267\n","Epoch 85/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5576 - accuracy: 0.7852 - val_loss: 0.9405 - val_accuracy: 0.6233\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5647 - accuracy: 0.7943 - val_loss: 0.8996 - val_accuracy: 0.6391\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5579 - accuracy: 0.7886 - val_loss: 0.9345 - val_accuracy: 0.6244\n","Epoch 88/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5549 - accuracy: 0.7886 - val_loss: 0.9099 - val_accuracy: 0.6109\n","Epoch 89/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5517 - accuracy: 0.7889 - val_loss: 0.9020 - val_accuracy: 0.6120\n","Epoch 90/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5595 - accuracy: 0.7790 - val_loss: 0.9479 - val_accuracy: 0.6301\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5515 - accuracy: 0.7852 - val_loss: 0.9292 - val_accuracy: 0.6120\n","Epoch 92/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5457 - accuracy: 0.7878 - val_loss: 0.9443 - val_accuracy: 0.6267\n","Epoch 93/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5428 - accuracy: 0.7954 - val_loss: 0.9663 - val_accuracy: 0.6165\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5386 - accuracy: 0.7929 - val_loss: 0.9693 - val_accuracy: 0.6143\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5371 - accuracy: 0.7974 - val_loss: 0.9469 - val_accuracy: 0.6278\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5349 - accuracy: 0.7968 - val_loss: 0.9292 - val_accuracy: 0.6188\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5549 - accuracy: 0.7824 - val_loss: 0.9573 - val_accuracy: 0.6018\n","Epoch 98/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5612 - accuracy: 0.7844 - val_loss: 0.9644 - val_accuracy: 0.6222\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5401 - accuracy: 0.7968 - val_loss: 0.9649 - val_accuracy: 0.6210\n","Epoch 100/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5375 - accuracy: 0.7980 - val_loss: 0.9572 - val_accuracy: 0.6029\n","{'loss': [0.7266603708267212, 0.7250462174415588, 0.7150482535362244, 0.7189036011695862, 0.7062227129936218, 0.7009098529815674, 0.7013288140296936, 0.6982689499855042, 0.6988065242767334, 0.6930599212646484, 0.6916131973266602, 0.6945608854293823, 0.6881983876228333, 0.6966140866279602, 0.6814382672309875, 0.6860811114311218, 0.6794140934944153, 0.6749987006187439, 0.6806084513664246, 0.6707161664962769, 0.6683987379074097, 0.6730247139930725, 0.6751343011856079, 0.671164870262146, 0.6584057211875916, 0.6646840572357178, 0.6611393690109253, 0.6515686511993408, 0.6508573293685913, 0.6540585160255432, 0.6480928659439087, 0.660796046257019, 0.6498185992240906, 0.6500874161720276, 0.6504905819892883, 0.6424920558929443, 0.653144121170044, 0.6468368172645569, 0.6328878402709961, 0.6360418200492859, 0.6348744034767151, 0.6313967704772949, 0.6351374983787537, 0.6373103260993958, 0.6310392022132874, 0.6238603591918945, 0.6227376461029053, 0.6225312352180481, 0.6186468005180359, 0.6200945377349854, 0.6210404634475708, 0.610336184501648, 0.6139736771583557, 0.6142246723175049, 0.6111252903938293, 0.6074663400650024, 0.6039461493492126, 0.6078572869300842, 0.6025044918060303, 0.6089300513267517, 0.6037009954452515, 0.5956530570983887, 0.599844753742218, 0.5954025983810425, 0.5937974452972412, 0.5928072333335876, 0.5910792946815491, 0.5878278017044067, 0.5935888290405273, 0.5845410227775574, 0.5831876397132874, 0.577805757522583, 0.5791817903518677, 0.5899210572242737, 0.5842620730400085, 0.5753230452537537, 0.577427327632904, 0.5714637041091919, 0.5721539855003357, 0.5774358510971069, 0.5701316595077515, 0.5607306361198425, 0.5599510073661804, 0.5596804618835449, 0.5575665235519409, 0.5646822452545166, 0.5579196810722351, 0.5549089908599854, 0.5516805052757263, 0.5594872236251831, 0.5514567494392395, 0.5456526875495911, 0.5427554845809937, 0.5386156439781189, 0.5370988249778748, 0.5349385738372803, 0.5549297332763672, 0.5612024068832397, 0.5400593876838684, 0.5375252962112427], 'accuracy': [0.6949632167816162, 0.6873231530189514, 0.7000566124916077, 0.6929824352264404, 0.7096773982048035, 0.7074136734008789, 0.7054329514503479, 0.709960401058197, 0.7144878506660461, 0.7144878506660461, 0.7142048478126526, 0.7170345187187195, 0.7144878506660461, 0.7020373344421387, 0.7198641896247864, 0.7147707939147949, 0.7283531427383423, 0.7263723611831665, 0.7159026861190796, 0.7204301357269287, 0.7283531427383423, 0.7303339242935181, 0.7224108576774597, 0.7294849753379822, 0.7263723611831665, 0.7289190888404846, 0.7391058206558228, 0.735144317150116, 0.7354272603988647, 0.7328805923461914, 0.7371250987052917, 0.7300509214401245, 0.7422184348106384, 0.7340124249458313, 0.7317487001419067, 0.751839280128479, 0.7275042533874512, 0.7357102632522583, 0.7498584985733032, 0.7453310489654541, 0.742501437664032, 0.744482159614563, 0.7467458844184875, 0.7439162135124207, 0.7478777766227722, 0.7549518942832947, 0.751839280128479, 0.7501415014266968, 0.7577815651893616, 0.7543859481811523, 0.7504244446754456, 0.7515563368797302, 0.7521222233772278, 0.761177122592926, 0.7569326758384705, 0.7634408473968506, 0.7702320218086243, 0.7492926120758057, 0.761177122592926, 0.7572156190872192, 0.7549518942832947, 0.7668364644050598, 0.7594793438911438, 0.7600452899932861, 0.7597622871398926, 0.7702320218086243, 0.7668364644050598, 0.7668364644050598, 0.7637238502502441, 0.768534243106842, 0.7662705183029175, 0.7716468572616577, 0.7795698642730713, 0.7705150246620178, 0.774193525314331, 0.7790039777755737, 0.7784380316734314, 0.7812677025794983, 0.7812677025794983, 0.7747594714164734, 0.7753254175186157, 0.7832484245300293, 0.7812677025794983, 0.7832484245300293, 0.7852292060852051, 0.7942841053009033, 0.7886247634887695, 0.7886247634887695, 0.7889077663421631, 0.7790039777755737, 0.7852292060852051, 0.7877758741378784, 0.7954159379005432, 0.7928692698478699, 0.797396719455719, 0.7968307733535767, 0.7823995351791382, 0.784380316734314, 0.7968307733535767, 0.7979626655578613], 'val_loss': [0.8675104379653931, 0.8738085627555847, 0.872675359249115, 0.869052529335022, 0.8579546213150024, 0.8525854349136353, 0.8452214598655701, 0.8526998162269592, 0.8449589014053345, 0.8446097373962402, 0.8388415575027466, 0.8547853231430054, 0.8192523121833801, 0.8151488304138184, 0.8112230896949768, 0.8198158144950867, 0.8009229302406311, 0.8047478199005127, 0.7973122596740723, 0.7904897928237915, 0.7896395921707153, 0.8005145192146301, 0.7953410148620605, 0.7985773682594299, 0.8021252155303955, 0.8116847276687622, 0.8094316720962524, 0.8088294267654419, 0.8165601491928101, 0.8167620301246643, 0.8299909234046936, 0.8124933838844299, 0.8528113961219788, 0.8165146708488464, 0.8213817477226257, 0.8620234727859497, 0.8375025391578674, 0.8341335654258728, 0.8679683804512024, 0.8625627160072327, 0.8417471647262573, 0.8579820990562439, 0.8641767501831055, 0.8511318564414978, 0.8550524115562439, 0.8591858148574829, 0.8623788356781006, 0.8581494688987732, 0.8829762935638428, 0.886845052242279, 0.8767363429069519, 0.8606947660446167, 0.856059193611145, 0.8684026002883911, 0.9118640422821045, 0.909640371799469, 0.890935480594635, 0.8874831199645996, 0.9038400053977966, 0.8885484933853149, 0.902364194393158, 0.866014838218689, 0.8766661286354065, 0.8738486170768738, 0.890211284160614, 0.8934820294380188, 0.9282563924789429, 0.9020543098449707, 0.9158450961112976, 0.8863824605941772, 0.8781885504722595, 0.9352537989616394, 0.9602277874946594, 0.9021580815315247, 0.9303110837936401, 0.8998638391494751, 0.895470380783081, 0.9085671305656433, 0.9056689143180847, 0.9009258151054382, 0.9124446511268616, 0.9235554933547974, 0.9470043182373047, 0.9352238774299622, 0.940471887588501, 0.8996264338493347, 0.9345023036003113, 0.9098891615867615, 0.9019885659217834, 0.9479451775550842, 0.9291685223579407, 0.9443297386169434, 0.9662846922874451, 0.9692646265029907, 0.9468885660171509, 0.9292117953300476, 0.9572880864143372, 0.9643916487693787, 0.9649016261100769, 0.9571837782859802], 'val_accuracy': [0.5113122463226318, 0.5090497732162476, 0.5135746598243713, 0.5147058963775635, 0.5226244330406189, 0.529411792755127, 0.5384615659713745, 0.5361990928649902, 0.5395927429199219, 0.5418552160263062, 0.5475113391876221, 0.5418552160263062, 0.5712669491767883, 0.5723981857299805, 0.5848416090011597, 0.5735294222831726, 0.6131221652030945, 0.598416268825531, 0.6165158152580261, 0.627828061580658, 0.622171938419342, 0.6153846383094788, 0.6199095249176025, 0.6210407018661499, 0.6300904750823975, 0.6289592981338501, 0.6142534017562866, 0.610859751701355, 0.6187782883644104, 0.6244344115257263, 0.6266968250274658, 0.6119909286499023, 0.6165158152580261, 0.6176470518112183, 0.6266968250274658, 0.6266968250274658, 0.6165158152580261, 0.6300904750823975, 0.6097285151481628, 0.6142534017562866, 0.6199095249176025, 0.6447963714599609, 0.6346153616905212, 0.6210407018661499, 0.627828061580658, 0.6131221652030945, 0.6085972785949707, 0.6153846383094788, 0.6210407018661499, 0.6074660420417786, 0.6176470518112183, 0.6300904750823975, 0.6097285151481628, 0.6233031749725342, 0.6029411554336548, 0.6119909286499023, 0.6165158152580261, 0.6153846383094788, 0.6040723919868469, 0.627828061580658, 0.6323529481887817, 0.6085972785949707, 0.6357465982437134, 0.627828061580658, 0.6402714848518372, 0.622171938419342, 0.6312217116355896, 0.6255655884742737, 0.639140248298645, 0.622171938419342, 0.6142534017562866, 0.6006787419319153, 0.6357465982437134, 0.6119909286499023, 0.6040723919868469, 0.6414027214050293, 0.6312217116355896, 0.6210407018661499, 0.627828061580658, 0.6063348650932312, 0.6052036285400391, 0.6334841847419739, 0.6244344115257263, 0.6266968250274658, 0.6233031749725342, 0.639140248298645, 0.6244344115257263, 0.610859751701355, 0.6119909286499023, 0.6300904750823975, 0.6119909286499023, 0.6266968250274658, 0.6165158152580261, 0.6142534017562866, 0.627828061580658, 0.6187782883644104, 0.6018099784851074, 0.622171938419342, 0.6210407018661499, 0.6029411554336548]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.7406 - accuracy: 0.6816"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 62ms/step - loss: 0.7389 - accuracy: 0.6817 - val_loss: 0.8813 - val_accuracy: 0.5165\n","Epoch 2/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.7318 - accuracy: 0.6842 - val_loss: 0.8614 - val_accuracy: 0.5258\n","Epoch 3/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.7237 - accuracy: 0.6902 - val_loss: 0.8630 - val_accuracy: 0.5289\n","Epoch 4/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.7260 - accuracy: 0.6891 - val_loss: 0.8549 - val_accuracy: 0.5320\n","Epoch 5/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7148 - accuracy: 0.6902 - val_loss: 0.8548 - val_accuracy: 0.5310\n","Epoch 6/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7166 - accuracy: 0.6943 - val_loss: 0.8511 - val_accuracy: 0.5393\n","Epoch 7/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7165 - accuracy: 0.6946 - val_loss: 0.8484 - val_accuracy: 0.5320\n","Epoch 8/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7078 - accuracy: 0.6977 - val_loss: 0.8395 - val_accuracy: 0.5806\n","Epoch 9/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7156 - accuracy: 0.6974 - val_loss: 0.8385 - val_accuracy: 0.5579\n","Epoch 10/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7039 - accuracy: 0.6948 - val_loss: 0.8335 - val_accuracy: 0.5702\n","Epoch 11/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7057 - accuracy: 0.6987 - val_loss: 0.8338 - val_accuracy: 0.5589\n","Epoch 12/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7030 - accuracy: 0.7023 - val_loss: 0.8358 - val_accuracy: 0.5496\n","Epoch 13/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6989 - accuracy: 0.7010 - val_loss: 0.8293 - val_accuracy: 0.5671\n","Epoch 14/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6971 - accuracy: 0.7052 - val_loss: 0.8238 - val_accuracy: 0.5826\n","Epoch 15/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6937 - accuracy: 0.7047 - val_loss: 0.8174 - val_accuracy: 0.5961\n","Epoch 16/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6899 - accuracy: 0.7013 - val_loss: 0.8214 - val_accuracy: 0.5930\n","Epoch 17/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6848 - accuracy: 0.7101 - val_loss: 0.8233 - val_accuracy: 0.6012\n","Epoch 18/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6902 - accuracy: 0.7101 - val_loss: 0.8191 - val_accuracy: 0.6033\n","Epoch 19/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6850 - accuracy: 0.7062 - val_loss: 0.8357 - val_accuracy: 0.5919\n","Epoch 20/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6805 - accuracy: 0.7165 - val_loss: 0.8365 - val_accuracy: 0.5775\n","Epoch 21/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6779 - accuracy: 0.7116 - val_loss: 0.8630 - val_accuracy: 0.5764\n","Epoch 22/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6758 - accuracy: 0.7207 - val_loss: 0.8483 - val_accuracy: 0.5940\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6733 - accuracy: 0.7165 - val_loss: 0.8555 - val_accuracy: 0.5971\n","Epoch 24/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6777 - accuracy: 0.7199 - val_loss: 0.8551 - val_accuracy: 0.5961\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6770 - accuracy: 0.7083 - val_loss: 0.8850 - val_accuracy: 0.5950\n","Epoch 26/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6682 - accuracy: 0.7233 - val_loss: 0.8647 - val_accuracy: 0.5971\n","Epoch 27/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6685 - accuracy: 0.7238 - val_loss: 0.9019 - val_accuracy: 0.5733\n","Epoch 28/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6663 - accuracy: 0.7160 - val_loss: 0.9237 - val_accuracy: 0.5713\n","Epoch 29/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6700 - accuracy: 0.7256 - val_loss: 0.8894 - val_accuracy: 0.6095\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6661 - accuracy: 0.7233 - val_loss: 0.9601 - val_accuracy: 0.5764\n","Epoch 31/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6507 - accuracy: 0.7377 - val_loss: 0.9190 - val_accuracy: 0.5671\n","Epoch 32/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6572 - accuracy: 0.7243 - val_loss: 0.9327 - val_accuracy: 0.5702\n","Epoch 33/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6548 - accuracy: 0.7300 - val_loss: 0.9085 - val_accuracy: 0.5723\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6560 - accuracy: 0.7295 - val_loss: 0.9589 - val_accuracy: 0.5713\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6585 - accuracy: 0.7199 - val_loss: 0.9427 - val_accuracy: 0.5971\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6555 - accuracy: 0.7313 - val_loss: 0.9386 - val_accuracy: 0.5857\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6558 - accuracy: 0.7222 - val_loss: 0.9464 - val_accuracy: 0.5785\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6432 - accuracy: 0.7362 - val_loss: 0.9333 - val_accuracy: 0.5723\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6511 - accuracy: 0.7318 - val_loss: 0.9012 - val_accuracy: 0.6023\n","Epoch 40/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6549 - accuracy: 0.7230 - val_loss: 0.9574 - val_accuracy: 0.5671\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6409 - accuracy: 0.7315 - val_loss: 0.9264 - val_accuracy: 0.5775\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6372 - accuracy: 0.7457 - val_loss: 0.9451 - val_accuracy: 0.5857\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6334 - accuracy: 0.7434 - val_loss: 0.9334 - val_accuracy: 0.5899\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6365 - accuracy: 0.7395 - val_loss: 0.9952 - val_accuracy: 0.5640\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6403 - accuracy: 0.7411 - val_loss: 0.9246 - val_accuracy: 0.5847\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6306 - accuracy: 0.7499 - val_loss: 0.9296 - val_accuracy: 0.5981\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6323 - accuracy: 0.7331 - val_loss: 0.9202 - val_accuracy: 0.5795\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6339 - accuracy: 0.7375 - val_loss: 0.9804 - val_accuracy: 0.5806\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6287 - accuracy: 0.7447 - val_loss: 0.9343 - val_accuracy: 0.5826\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6282 - accuracy: 0.7401 - val_loss: 0.9455 - val_accuracy: 0.6033\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6387 - accuracy: 0.7318 - val_loss: 0.9142 - val_accuracy: 0.5919\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6270 - accuracy: 0.7380 - val_loss: 0.9650 - val_accuracy: 0.5806\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6244 - accuracy: 0.7468 - val_loss: 0.9826 - val_accuracy: 0.5702\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6120 - accuracy: 0.7561 - val_loss: 0.9410 - val_accuracy: 0.5826\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6214 - accuracy: 0.7447 - val_loss: 0.9492 - val_accuracy: 0.5775\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6167 - accuracy: 0.7424 - val_loss: 0.9882 - val_accuracy: 0.6002\n","Epoch 57/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6147 - accuracy: 0.7506 - val_loss: 0.9268 - val_accuracy: 0.5795\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6204 - accuracy: 0.7496 - val_loss: 0.9588 - val_accuracy: 0.5961\n","Epoch 59/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6222 - accuracy: 0.7452 - val_loss: 0.9962 - val_accuracy: 0.5692\n","Epoch 60/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6106 - accuracy: 0.7525 - val_loss: 0.9900 - val_accuracy: 0.5795\n","Epoch 61/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6112 - accuracy: 0.7537 - val_loss: 0.9677 - val_accuracy: 0.5981\n","Epoch 62/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6059 - accuracy: 0.7548 - val_loss: 0.9594 - val_accuracy: 0.6012\n","Epoch 63/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6080 - accuracy: 0.7522 - val_loss: 0.9476 - val_accuracy: 0.5981\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5984 - accuracy: 0.7641 - val_loss: 1.0229 - val_accuracy: 0.5702\n","Epoch 65/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6000 - accuracy: 0.7597 - val_loss: 0.9988 - val_accuracy: 0.5971\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6106 - accuracy: 0.7444 - val_loss: 0.9753 - val_accuracy: 0.5826\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6132 - accuracy: 0.7401 - val_loss: 1.0172 - val_accuracy: 0.5630\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5932 - accuracy: 0.7636 - val_loss: 1.0483 - val_accuracy: 0.5537\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6007 - accuracy: 0.7581 - val_loss: 0.9776 - val_accuracy: 0.5723\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5898 - accuracy: 0.7726 - val_loss: 0.9998 - val_accuracy: 0.5640\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5869 - accuracy: 0.7641 - val_loss: 0.9587 - val_accuracy: 0.6023\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5940 - accuracy: 0.7587 - val_loss: 0.9527 - val_accuracy: 0.6002\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5932 - accuracy: 0.7558 - val_loss: 0.9629 - val_accuracy: 0.5723\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5824 - accuracy: 0.7646 - val_loss: 1.0182 - val_accuracy: 0.5899\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5841 - accuracy: 0.7633 - val_loss: 1.0087 - val_accuracy: 0.5764\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5885 - accuracy: 0.7615 - val_loss: 1.0293 - val_accuracy: 0.5868\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5754 - accuracy: 0.7716 - val_loss: 0.9867 - val_accuracy: 0.5950\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5827 - accuracy: 0.7641 - val_loss: 1.0116 - val_accuracy: 0.5857\n","Epoch 79/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5703 - accuracy: 0.7747 - val_loss: 1.0271 - val_accuracy: 0.5950\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5789 - accuracy: 0.7729 - val_loss: 0.9722 - val_accuracy: 0.6085\n","Epoch 81/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5762 - accuracy: 0.7705 - val_loss: 0.9863 - val_accuracy: 0.5847\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5699 - accuracy: 0.7711 - val_loss: 1.0615 - val_accuracy: 0.5733\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5755 - accuracy: 0.7654 - val_loss: 1.0073 - val_accuracy: 0.5744\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5691 - accuracy: 0.7698 - val_loss: 0.9971 - val_accuracy: 0.6012\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5715 - accuracy: 0.7695 - val_loss: 1.0211 - val_accuracy: 0.5888\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5597 - accuracy: 0.7804 - val_loss: 1.0568 - val_accuracy: 0.5506\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5645 - accuracy: 0.7695 - val_loss: 1.0876 - val_accuracy: 0.5640\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5668 - accuracy: 0.7672 - val_loss: 1.0281 - val_accuracy: 0.5971\n","Epoch 89/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5669 - accuracy: 0.7698 - val_loss: 1.0062 - val_accuracy: 0.5847\n","Epoch 90/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5562 - accuracy: 0.7860 - val_loss: 1.0948 - val_accuracy: 0.5888\n","Epoch 91/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5671 - accuracy: 0.7729 - val_loss: 1.0364 - val_accuracy: 0.5971\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5504 - accuracy: 0.7809 - val_loss: 1.0428 - val_accuracy: 0.5806\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5709 - accuracy: 0.7749 - val_loss: 1.0146 - val_accuracy: 0.5971\n","Epoch 94/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5630 - accuracy: 0.7726 - val_loss: 1.0270 - val_accuracy: 0.5744\n","Epoch 95/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5531 - accuracy: 0.7902 - val_loss: 1.0553 - val_accuracy: 0.5950\n","Epoch 96/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5468 - accuracy: 0.7866 - val_loss: 1.0289 - val_accuracy: 0.5785\n","Epoch 97/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5521 - accuracy: 0.7824 - val_loss: 1.0264 - val_accuracy: 0.6074\n","Epoch 98/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5535 - accuracy: 0.7796 - val_loss: 1.0554 - val_accuracy: 0.5857\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5471 - accuracy: 0.7897 - val_loss: 1.0449 - val_accuracy: 0.6012\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5479 - accuracy: 0.7855 - val_loss: 1.0079 - val_accuracy: 0.5971\n","{'loss': [0.7389053702354431, 0.7318168878555298, 0.7237215638160706, 0.7259844541549683, 0.7148241400718689, 0.7165623903274536, 0.7164979577064514, 0.7078194618225098, 0.7155603170394897, 0.7038716077804565, 0.7056851983070374, 0.7030496001243591, 0.6988884210586548, 0.6971361041069031, 0.6936759352684021, 0.6899274587631226, 0.6847993731498718, 0.6902137398719788, 0.6849794387817383, 0.6805173754692078, 0.6779363751411438, 0.6757997274398804, 0.6733256578445435, 0.6776837706565857, 0.6769925951957703, 0.6681700944900513, 0.6684526801109314, 0.6662749648094177, 0.6699644923210144, 0.6661441922187805, 0.6507408618927002, 0.6571803689002991, 0.6548095345497131, 0.6559918522834778, 0.6584652662277222, 0.655484676361084, 0.6557683348655701, 0.6431582570075989, 0.6511091589927673, 0.6548858284950256, 0.6408745646476746, 0.6371546983718872, 0.6333618760108948, 0.6364763975143433, 0.6403326988220215, 0.6306426525115967, 0.6322592496871948, 0.6338978409767151, 0.6286828517913818, 0.6281806230545044, 0.638714611530304, 0.6269906163215637, 0.6243888735771179, 0.611989438533783, 0.621403157711029, 0.6167252063751221, 0.6147428750991821, 0.6204193830490112, 0.6222113966941833, 0.6105639934539795, 0.6111927032470703, 0.6058643460273743, 0.6079559922218323, 0.5983929634094238, 0.6000160574913025, 0.6106338500976562, 0.6131712794303894, 0.5931831002235413, 0.6006929874420166, 0.5897642374038696, 0.5869492888450623, 0.593961775302887, 0.5931643843650818, 0.5823671817779541, 0.5841442942619324, 0.5884684920310974, 0.5754187703132629, 0.5826653838157654, 0.570309579372406, 0.5789164900779724, 0.5761514902114868, 0.569891631603241, 0.57546067237854, 0.5691245198249817, 0.5715274810791016, 0.5597481727600098, 0.5645043849945068, 0.5667775869369507, 0.5669251084327698, 0.5562466979026794, 0.5670739412307739, 0.5503835678100586, 0.5708502531051636, 0.5629746317863464, 0.5531490445137024, 0.5467981100082397, 0.5520619750022888, 0.5535056591033936, 0.5470988750457764, 0.5478827357292175], 'accuracy': [0.6816537380218506, 0.6842377185821533, 0.6901808977127075, 0.6891472935676575, 0.6901808977127075, 0.6943152546882629, 0.6945736408233643, 0.6976743936538696, 0.6974160075187683, 0.6948320269584656, 0.6987079977989197, 0.7023255825042725, 0.7010335922241211, 0.7051679491996765, 0.7046511769294739, 0.7012919783592224, 0.7100775241851807, 0.7100775241851807, 0.7062015533447266, 0.7165374755859375, 0.7116279006004333, 0.7206718325614929, 0.7165374755859375, 0.7198966145515442, 0.7082687616348267, 0.7232558131217957, 0.7237725853919983, 0.7160206437110901, 0.7255814075469971, 0.7232558131217957, 0.737726092338562, 0.7242894172668457, 0.7299741506576538, 0.7294573783874512, 0.7198966145515442, 0.7312661409378052, 0.7222222089767456, 0.7361757159233093, 0.7317829728126526, 0.7229974269866943, 0.7315245270729065, 0.7457364201545715, 0.7434108257293701, 0.739534854888916, 0.7410852909088135, 0.749870777130127, 0.733074963092804, 0.7374677062034607, 0.7447028160095215, 0.7400516867637634, 0.7317829728126526, 0.7379844784736633, 0.7467700242996216, 0.7560723423957825, 0.7447028160095215, 0.7423772811889648, 0.7506459951400757, 0.7496123909950256, 0.7452196478843689, 0.7524547576904297, 0.753746747970581, 0.7547803521156311, 0.7521963715553284, 0.764082670211792, 0.7596899271011353, 0.7444444298744202, 0.7400516867637634, 0.7635658979415894, 0.7581395506858826, 0.7726098299026489, 0.764082670211792, 0.7586563229560852, 0.7558139562606812, 0.7645995020866394, 0.763307511806488, 0.7614986896514893, 0.7715762257575989, 0.764082670211792, 0.7746769785881042, 0.7728682160377502, 0.7705426216125488, 0.7710594534873962, 0.7653746604919434, 0.7697674632072449, 0.7695090174674988, 0.7803617715835571, 0.7695090174674988, 0.7671834826469421, 0.7697674632072449, 0.7860465049743652, 0.7728682160377502, 0.7808785438537598, 0.7749354243278503, 0.7726098299026489, 0.7901808619499207, 0.7865633368492126, 0.7824289202690125, 0.7795865535736084, 0.789664089679718, 0.7855297327041626], 'val_loss': [0.8812685608863831, 0.8614013195037842, 0.8629559874534607, 0.8549107313156128, 0.8547565340995789, 0.8511390089988708, 0.848353922367096, 0.8394773006439209, 0.8385250568389893, 0.8334650993347168, 0.8338302373886108, 0.8357526063919067, 0.8293187022209167, 0.8237513303756714, 0.8174299597740173, 0.8213983178138733, 0.8233083486557007, 0.819075882434845, 0.8356850743293762, 0.8365007638931274, 0.8629860281944275, 0.848334550857544, 0.8554980754852295, 0.85511314868927, 0.8849738240242004, 0.8646706938743591, 0.9019251465797424, 0.9236941933631897, 0.8894246816635132, 0.9600629210472107, 0.919022262096405, 0.9327486753463745, 0.9085148572921753, 0.9589035511016846, 0.9427188038825989, 0.9385772943496704, 0.9463842511177063, 0.9332751035690308, 0.9011576175689697, 0.9574101567268372, 0.926389753818512, 0.9450715184211731, 0.9333967566490173, 0.9952172636985779, 0.9245588183403015, 0.9295549392700195, 0.9202308058738708, 0.9804137945175171, 0.9342653751373291, 0.9455077052116394, 0.914190948009491, 0.964989960193634, 0.9825942516326904, 0.9410085678100586, 0.9492179155349731, 0.9882484674453735, 0.9267841577529907, 0.9588053226470947, 0.9961618185043335, 0.9899957776069641, 0.9676645994186401, 0.9594497680664062, 0.947643518447876, 1.022929072380066, 0.9987552165985107, 0.975328803062439, 1.0172044038772583, 1.0482646226882935, 0.977648138999939, 0.9998052716255188, 0.9586598873138428, 0.9527460932731628, 0.962853729724884, 1.0182054042816162, 1.0087157487869263, 1.0293303728103638, 0.9867398738861084, 1.0115641355514526, 1.0270873308181763, 0.9721678495407104, 0.9863213896751404, 1.0615075826644897, 1.0073496103286743, 0.9970867037773132, 1.0210829973220825, 1.0567532777786255, 1.0875964164733887, 1.0281085968017578, 1.0062121152877808, 1.0948282480239868, 1.0363768339157104, 1.0427637100219727, 1.014638900756836, 1.0269581079483032, 1.0553292036056519, 1.028861403465271, 1.026381492614746, 1.055356740951538, 1.0448825359344482, 1.007861852645874], 'val_accuracy': [0.5165289044380188, 0.5258264541625977, 0.5289255976676941, 0.5320248007774353, 0.5309917330741882, 0.53925621509552, 0.5320248007774353, 0.5805785059928894, 0.557851254940033, 0.5702479481697083, 0.55888432264328, 0.5495867729187012, 0.567148745059967, 0.5826446413993835, 0.5960744023323059, 0.5929751992225647, 0.6012396812438965, 0.6033057570457458, 0.5919421315193176, 0.577479362487793, 0.5764462947845459, 0.5940082669258118, 0.5971074104309082, 0.5960744023323059, 0.5950413346290588, 0.5971074104309082, 0.5733470916748047, 0.5712810158729553, 0.6095041036605835, 0.5764462947845459, 0.567148745059967, 0.5702479481697083, 0.5723140239715576, 0.5712810158729553, 0.5971074104309082, 0.58574378490448, 0.5785123705863953, 0.5723140239715576, 0.6022727489471436, 0.567148745059967, 0.577479362487793, 0.58574378490448, 0.5898760557174683, 0.5640496015548706, 0.5847107172012329, 0.5981404781341553, 0.5795454382896423, 0.5805785059928894, 0.5826446413993835, 0.6033057570457458, 0.5919421315193176, 0.5805785059928894, 0.5702479481697083, 0.5826446413993835, 0.577479362487793, 0.6002066135406494, 0.5795454382896423, 0.5960744023323059, 0.5692148804664612, 0.5795454382896423, 0.5981404781341553, 0.6012396812438965, 0.5981404781341553, 0.5702479481697083, 0.5971074104309082, 0.5826446413993835, 0.5630165338516235, 0.5537189841270447, 0.5723140239715576, 0.5640496015548706, 0.6022727489471436, 0.6002066135406494, 0.5723140239715576, 0.5898760557174683, 0.5764462947845459, 0.586776852607727, 0.5950413346290588, 0.58574378490448, 0.5950413346290588, 0.6084710955619812, 0.5847107172012329, 0.5733470916748047, 0.5743801593780518, 0.6012396812438965, 0.5888429880142212, 0.5506198406219482, 0.5640496015548706, 0.5971074104309082, 0.5847107172012329, 0.5888429880142212, 0.5971074104309082, 0.5805785059928894, 0.5971074104309082, 0.5743801593780518, 0.5950413346290588, 0.5785123705863953, 0.6074380278587341, 0.58574378490448, 0.6012396812438965, 0.5971074104309082]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 8s 51ms/step - loss: 0.5929 - accuracy: 0.7559 - val_loss: 0.8150 - val_accuracy: 0.5334\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 13ms/step - loss: 0.5689 - accuracy: 0.7780 - val_loss: 0.8148 - val_accuracy: 0.5334\n","Epoch 3/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5753 - accuracy: 0.7664 - val_loss: 0.8186 - val_accuracy: 0.5345\n","Epoch 4/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5629 - accuracy: 0.7729 - val_loss: 0.8159 - val_accuracy: 0.5409\n","Epoch 5/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5610 - accuracy: 0.7777 - val_loss: 0.8104 - val_accuracy: 0.5453\n","Epoch 6/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5594 - accuracy: 0.7745 - val_loss: 0.8150 - val_accuracy: 0.5453\n","Epoch 7/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5559 - accuracy: 0.7748 - val_loss: 0.8102 - val_accuracy: 0.5485\n","Epoch 8/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5604 - accuracy: 0.7772 - val_loss: 0.7841 - val_accuracy: 0.5894\n","Epoch 9/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5662 - accuracy: 0.7780 - val_loss: 0.8003 - val_accuracy: 0.5700\n","Epoch 10/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5560 - accuracy: 0.7699 - val_loss: 0.7956 - val_accuracy: 0.5884\n","Epoch 11/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5516 - accuracy: 0.7815 - val_loss: 0.7813 - val_accuracy: 0.6056\n","Epoch 12/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5506 - accuracy: 0.7761 - val_loss: 0.7730 - val_accuracy: 0.6164\n","Epoch 13/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5492 - accuracy: 0.7788 - val_loss: 0.7684 - val_accuracy: 0.6175\n","Epoch 14/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5464 - accuracy: 0.7829 - val_loss: 0.7868 - val_accuracy: 0.6272\n","Epoch 15/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5411 - accuracy: 0.7872 - val_loss: 0.7867 - val_accuracy: 0.6476\n","Epoch 16/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5363 - accuracy: 0.7888 - val_loss: 0.7720 - val_accuracy: 0.6347\n","Epoch 17/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5383 - accuracy: 0.7885 - val_loss: 0.7616 - val_accuracy: 0.6670\n","Epoch 18/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5428 - accuracy: 0.7823 - val_loss: 0.7946 - val_accuracy: 0.6562\n","Epoch 19/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5327 - accuracy: 0.7901 - val_loss: 0.7466 - val_accuracy: 0.6649\n","Epoch 20/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5429 - accuracy: 0.7823 - val_loss: 0.7911 - val_accuracy: 0.6659\n","Epoch 21/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5304 - accuracy: 0.7899 - val_loss: 0.7665 - val_accuracy: 0.6875\n","Epoch 22/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5392 - accuracy: 0.7883 - val_loss: 0.8417 - val_accuracy: 0.6325\n","Epoch 23/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5235 - accuracy: 0.7923 - val_loss: 0.7615 - val_accuracy: 0.6875\n","Epoch 24/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5347 - accuracy: 0.7909 - val_loss: 0.8588 - val_accuracy: 0.6401\n","Epoch 25/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5274 - accuracy: 0.7955 - val_loss: 0.7930 - val_accuracy: 0.6681\n","Epoch 26/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5241 - accuracy: 0.7980 - val_loss: 0.8190 - val_accuracy: 0.6886\n","Epoch 27/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5285 - accuracy: 0.7966 - val_loss: 0.8332 - val_accuracy: 0.6724\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5203 - accuracy: 0.7891 - val_loss: 0.8425 - val_accuracy: 0.6843\n","Epoch 29/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5233 - accuracy: 0.8041 - val_loss: 0.8421 - val_accuracy: 0.6476\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5384 - accuracy: 0.7861 - val_loss: 0.8514 - val_accuracy: 0.6853\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5244 - accuracy: 0.7947 - val_loss: 0.8252 - val_accuracy: 0.6670\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5175 - accuracy: 0.7931 - val_loss: 0.8626 - val_accuracy: 0.6498\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5093 - accuracy: 0.8006 - val_loss: 0.8183 - val_accuracy: 0.6800\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5068 - accuracy: 0.7974 - val_loss: 0.8635 - val_accuracy: 0.6670\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5212 - accuracy: 0.7982 - val_loss: 0.8813 - val_accuracy: 0.6552\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5047 - accuracy: 0.8033 - val_loss: 0.8307 - val_accuracy: 0.6810\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5026 - accuracy: 0.8141 - val_loss: 0.8461 - val_accuracy: 0.6843\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5045 - accuracy: 0.8015 - val_loss: 0.8592 - val_accuracy: 0.6670\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5018 - accuracy: 0.8087 - val_loss: 0.8359 - val_accuracy: 0.6832\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5027 - accuracy: 0.8101 - val_loss: 1.0282 - val_accuracy: 0.6099\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5089 - accuracy: 0.8004 - val_loss: 0.8664 - val_accuracy: 0.6778\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5005 - accuracy: 0.8068 - val_loss: 0.9219 - val_accuracy: 0.6433\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4988 - accuracy: 0.8128 - val_loss: 0.9306 - val_accuracy: 0.6466\n","Epoch 44/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5026 - accuracy: 0.8012 - val_loss: 0.8747 - val_accuracy: 0.6735\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4928 - accuracy: 0.8152 - val_loss: 0.8627 - val_accuracy: 0.6821\n","Epoch 46/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4895 - accuracy: 0.8141 - val_loss: 0.8830 - val_accuracy: 0.6681\n","Epoch 47/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4952 - accuracy: 0.8149 - val_loss: 0.8950 - val_accuracy: 0.6692\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4981 - accuracy: 0.8041 - val_loss: 0.9076 - val_accuracy: 0.6519\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4922 - accuracy: 0.8071 - val_loss: 0.9233 - val_accuracy: 0.6476\n","Epoch 50/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4861 - accuracy: 0.8163 - val_loss: 0.8635 - val_accuracy: 0.6907\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4895 - accuracy: 0.8165 - val_loss: 0.9055 - val_accuracy: 0.6767\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4984 - accuracy: 0.8171 - val_loss: 0.9570 - val_accuracy: 0.6455\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4916 - accuracy: 0.8101 - val_loss: 0.9414 - val_accuracy: 0.6756\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4915 - accuracy: 0.8055 - val_loss: 0.9181 - val_accuracy: 0.6455\n","Epoch 55/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4782 - accuracy: 0.8190 - val_loss: 0.9143 - val_accuracy: 0.6606\n","Epoch 56/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4737 - accuracy: 0.8182 - val_loss: 0.9592 - val_accuracy: 0.6369\n","Epoch 57/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4747 - accuracy: 0.8244 - val_loss: 0.8881 - val_accuracy: 0.6800\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4822 - accuracy: 0.8128 - val_loss: 0.9090 - val_accuracy: 0.6789\n","Epoch 59/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4823 - accuracy: 0.8195 - val_loss: 0.9090 - val_accuracy: 0.6638\n","Epoch 60/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4814 - accuracy: 0.8195 - val_loss: 0.9177 - val_accuracy: 0.6821\n","Epoch 61/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4798 - accuracy: 0.8141 - val_loss: 0.8681 - val_accuracy: 0.6886\n","Epoch 62/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4777 - accuracy: 0.8160 - val_loss: 0.9143 - val_accuracy: 0.6843\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4628 - accuracy: 0.8311 - val_loss: 0.9156 - val_accuracy: 0.6703\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4711 - accuracy: 0.8160 - val_loss: 0.8983 - val_accuracy: 0.6778\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4609 - accuracy: 0.8300 - val_loss: 0.9250 - val_accuracy: 0.6832\n","Epoch 66/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4651 - accuracy: 0.8268 - val_loss: 0.9885 - val_accuracy: 0.6379\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4599 - accuracy: 0.8260 - val_loss: 0.9017 - val_accuracy: 0.6681\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4646 - accuracy: 0.8200 - val_loss: 0.9286 - val_accuracy: 0.6681\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4814 - accuracy: 0.8190 - val_loss: 0.9386 - val_accuracy: 0.6659\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4654 - accuracy: 0.8233 - val_loss: 0.9908 - val_accuracy: 0.6487\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4608 - accuracy: 0.8319 - val_loss: 0.9958 - val_accuracy: 0.6476\n","Epoch 72/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4580 - accuracy: 0.8300 - val_loss: 0.9163 - val_accuracy: 0.6713\n","Epoch 73/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4515 - accuracy: 0.8378 - val_loss: 0.8931 - val_accuracy: 0.6864\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4545 - accuracy: 0.8300 - val_loss: 0.9741 - val_accuracy: 0.6476\n","Epoch 75/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4521 - accuracy: 0.8370 - val_loss: 0.9630 - val_accuracy: 0.6864\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4648 - accuracy: 0.8222 - val_loss: 0.9929 - val_accuracy: 0.6530\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4557 - accuracy: 0.8367 - val_loss: 1.0382 - val_accuracy: 0.6304\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4454 - accuracy: 0.8421 - val_loss: 0.9980 - val_accuracy: 0.6422\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4511 - accuracy: 0.8400 - val_loss: 0.9582 - val_accuracy: 0.6552\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4654 - accuracy: 0.8295 - val_loss: 0.9534 - val_accuracy: 0.6767\n","Epoch 81/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4494 - accuracy: 0.8394 - val_loss: 0.9735 - val_accuracy: 0.6616\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4511 - accuracy: 0.8376 - val_loss: 0.9471 - val_accuracy: 0.6724\n","Epoch 83/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4441 - accuracy: 0.8456 - val_loss: 0.9603 - val_accuracy: 0.6703\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4548 - accuracy: 0.8316 - val_loss: 0.9542 - val_accuracy: 0.6498\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4417 - accuracy: 0.8365 - val_loss: 0.9485 - val_accuracy: 0.6724\n","Epoch 86/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4357 - accuracy: 0.8421 - val_loss: 0.9490 - val_accuracy: 0.6800\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4358 - accuracy: 0.8475 - val_loss: 0.9846 - val_accuracy: 0.6638\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4383 - accuracy: 0.8373 - val_loss: 1.0068 - val_accuracy: 0.6756\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4377 - accuracy: 0.8435 - val_loss: 0.9608 - val_accuracy: 0.6789\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4294 - accuracy: 0.8489 - val_loss: 1.0054 - val_accuracy: 0.6487\n","Epoch 91/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4290 - accuracy: 0.8470 - val_loss: 1.0014 - val_accuracy: 0.6670\n","Epoch 92/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4280 - accuracy: 0.8486 - val_loss: 0.9532 - val_accuracy: 0.6692\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4367 - accuracy: 0.8421 - val_loss: 0.9626 - val_accuracy: 0.6767\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4470 - accuracy: 0.8421 - val_loss: 1.2215 - val_accuracy: 0.6034\n","Epoch 95/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4314 - accuracy: 0.8446 - val_loss: 1.0011 - val_accuracy: 0.6552\n","Epoch 96/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4283 - accuracy: 0.8473 - val_loss: 0.9704 - val_accuracy: 0.6832\n","Epoch 97/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4250 - accuracy: 0.8494 - val_loss: 0.9804 - val_accuracy: 0.6778\n","Epoch 98/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4265 - accuracy: 0.8478 - val_loss: 1.0335 - val_accuracy: 0.6455\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4322 - accuracy: 0.8416 - val_loss: 0.9735 - val_accuracy: 0.6864\n","Epoch 100/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4213 - accuracy: 0.8532 - val_loss: 0.9860 - val_accuracy: 0.6713\n","{'loss': [0.5929157733917236, 0.5688807368278503, 0.5753466486930847, 0.5629310607910156, 0.5609912872314453, 0.5593580007553101, 0.5558562278747559, 0.5603732466697693, 0.566239595413208, 0.556040346622467, 0.5515702962875366, 0.5505579113960266, 0.5492202639579773, 0.5463929176330566, 0.541072428226471, 0.5363445281982422, 0.5383460521697998, 0.5427625775337219, 0.5326571464538574, 0.5428860783576965, 0.5303899645805359, 0.5391556620597839, 0.523491621017456, 0.5346879363059998, 0.5273540616035461, 0.5241068601608276, 0.5284813046455383, 0.5203340649604797, 0.5232781767845154, 0.5384434461593628, 0.5244325399398804, 0.5174660682678223, 0.5092756152153015, 0.506767213344574, 0.5212088227272034, 0.5047327280044556, 0.5026096701622009, 0.5044899582862854, 0.5017585158348083, 0.5026721954345703, 0.5089364647865295, 0.5004779696464539, 0.4987860918045044, 0.5026084184646606, 0.492829293012619, 0.4895166754722595, 0.4952484369277954, 0.49808812141418457, 0.49222511053085327, 0.48611873388290405, 0.4894517958164215, 0.49842116236686707, 0.4915875196456909, 0.49145573377609253, 0.47818735241889954, 0.4736972749233246, 0.4747139513492584, 0.48223409056663513, 0.482285737991333, 0.4813539385795593, 0.47979170083999634, 0.4777202606201172, 0.4627964198589325, 0.47110429406166077, 0.4608653485774994, 0.46507924795150757, 0.45989754796028137, 0.4645923674106598, 0.4813954830169678, 0.4654126763343811, 0.4608113169670105, 0.45801034569740295, 0.4514569044113159, 0.4545223116874695, 0.4520893394947052, 0.4648459255695343, 0.4557136595249176, 0.44544199109077454, 0.45114821195602417, 0.4654167890548706, 0.44944220781326294, 0.4510999619960785, 0.4441218078136444, 0.45481228828430176, 0.44168561697006226, 0.4356769621372223, 0.4357627332210541, 0.43832528591156006, 0.4377311170101166, 0.42937684059143066, 0.429036021232605, 0.4279727339744568, 0.436739981174469, 0.44698160886764526, 0.4313790798187256, 0.4282774329185486, 0.4249839186668396, 0.42645108699798584, 0.4321969449520111, 0.42127081751823425], 'accuracy': [0.7559267282485962, 0.7780172228813171, 0.7664331793785095, 0.7728987336158752, 0.7777478694915771, 0.7745150923728943, 0.774784505367279, 0.7772090435028076, 0.7780172228813171, 0.7699353694915771, 0.7815194129943848, 0.7761314511299133, 0.7788254022598267, 0.782866358757019, 0.7871767282485962, 0.7887930870056152, 0.7885237336158752, 0.7823275923728943, 0.7901400923728943, 0.7823275923728943, 0.7898706793785095, 0.7882543206214905, 0.7922952771186829, 0.7909482717514038, 0.795527994632721, 0.7979525923728943, 0.7966055870056152, 0.7890625, 0.8041487336158752, 0.7860991358757019, 0.7947198152542114, 0.7931034564971924, 0.8006465435028076, 0.7974137663841248, 0.798222005367279, 0.803340494632721, 0.814116358757019, 0.8014547228813171, 0.8087284564971924, 0.8100754022598267, 0.8003771305084229, 0.8068426847457886, 0.8127694129943848, 0.8011853694915771, 0.8151939511299133, 0.814116358757019, 0.8149245977401733, 0.8041487336158752, 0.8071120977401733, 0.8162715435028076, 0.8165409564971924, 0.8170797228813171, 0.8100754022598267, 0.8054956793785095, 0.818965494632721, 0.8181573152542114, 0.8243534564971924, 0.8127694129943848, 0.8195043206214905, 0.8195043206214905, 0.814116358757019, 0.8160021305084229, 0.8310883641242981, 0.8160021305084229, 0.8300107717514038, 0.826777994632721, 0.8259698152542114, 0.8200430870056152, 0.818965494632721, 0.8232758641242981, 0.8318965435028076, 0.8300107717514038, 0.8378232717514038, 0.8300107717514038, 0.8370150923728943, 0.8221982717514038, 0.8367456793785095, 0.842133641242981, 0.8399784564971924, 0.829472005367279, 0.8394396305084229, 0.837553858757019, 0.8456357717514038, 0.8316271305084229, 0.8364762663841248, 0.842133641242981, 0.8475215435028076, 0.837284505367279, 0.8434805870056152, 0.8488685488700867, 0.8469827771186829, 0.8485991358757019, 0.842133641242981, 0.842133641242981, 0.8445581793785095, 0.8472521305084229, 0.8494073152542114, 0.8477909564971924, 0.8415948152542114, 0.853178858757019], 'val_loss': [0.814956545829773, 0.814758837223053, 0.8186229467391968, 0.8158605098724365, 0.8103815913200378, 0.8149709105491638, 0.8101932406425476, 0.7841314673423767, 0.8003093600273132, 0.7955504655838013, 0.7813206315040588, 0.7729719281196594, 0.7684438824653625, 0.7868233323097229, 0.7866582274436951, 0.7719948291778564, 0.7615790963172913, 0.7945778965950012, 0.7466070652008057, 0.7910980582237244, 0.7665162086486816, 0.8416698575019836, 0.761491596698761, 0.8588045239448547, 0.7930460572242737, 0.8189560174942017, 0.8331850171089172, 0.8425351977348328, 0.8421033024787903, 0.8514035940170288, 0.8252243995666504, 0.8625882863998413, 0.8183302283287048, 0.8634660840034485, 0.8812755942344666, 0.8306616544723511, 0.8461037874221802, 0.8591547608375549, 0.8359141945838928, 1.0281651020050049, 0.8664125204086304, 0.9219033718109131, 0.9306139945983887, 0.8747047185897827, 0.8626791834831238, 0.8829537034034729, 0.8950144648551941, 0.9076326489448547, 0.9232604503631592, 0.863539457321167, 0.9054502248764038, 0.9570392370223999, 0.9413595795631409, 0.9180508255958557, 0.9142975807189941, 0.9592223167419434, 0.8881409168243408, 0.9089609384536743, 0.9089726209640503, 0.9176501631736755, 0.8680674433708191, 0.9143115282058716, 0.9155570268630981, 0.8983299136161804, 0.9249715209007263, 0.988450288772583, 0.9017167091369629, 0.9286438226699829, 0.9385789632797241, 0.990783154964447, 0.9958329200744629, 0.9162733554840088, 0.8931312561035156, 0.9740536212921143, 0.963014543056488, 0.9928686022758484, 1.0381773710250854, 0.9980157613754272, 0.9582023620605469, 0.953436017036438, 0.9735428094863892, 0.9470910429954529, 0.9603018760681152, 0.9541928768157959, 0.9485355019569397, 0.9490456581115723, 0.9845998883247375, 1.0068169832229614, 0.9607983827590942, 1.0054367780685425, 1.0013751983642578, 0.953241765499115, 0.9626101851463318, 1.22145414352417, 1.0010932683944702, 0.9703914523124695, 0.9803946018218994, 1.0335086584091187, 0.9735181927680969, 0.9859833121299744], 'val_accuracy': [0.5334051847457886, 0.5334051847457886, 0.5344827771186829, 0.5409482717514038, 0.545258641242981, 0.545258641242981, 0.548491358757019, 0.5894396305084229, 0.5700430870056152, 0.5883620977401733, 0.6056034564971924, 0.6163793206214905, 0.6174569129943848, 0.6271551847457886, 0.6476293206214905, 0.6346982717514038, 0.6670258641242981, 0.65625, 0.6648706793785095, 0.6659482717514038, 0.6875, 0.6325430870056152, 0.6875, 0.6400862336158752, 0.6681034564971924, 0.6885775923728943, 0.6724137663841248, 0.6842672228813171, 0.6476293206214905, 0.6853448152542114, 0.6670258641242981, 0.649784505367279, 0.6799569129943848, 0.6670258641242981, 0.6551724076271057, 0.681034505367279, 0.6842672228813171, 0.6670258641242981, 0.6831896305084229, 0.6099137663841248, 0.6778017282485962, 0.6433189511299133, 0.6465517282485962, 0.673491358757019, 0.6821120977401733, 0.6681034564971924, 0.6691810488700867, 0.6519396305084229, 0.6476293206214905, 0.6907327771186829, 0.6767241358757019, 0.6454741358757019, 0.6756465435028076, 0.6454741358757019, 0.6605603694915771, 0.6368534564971924, 0.6799569129943848, 0.6788793206214905, 0.6637930870056152, 0.6821120977401733, 0.6885775923728943, 0.6842672228813171, 0.670258641242981, 0.6778017282485962, 0.6831896305084229, 0.6379310488700867, 0.6681034564971924, 0.6681034564971924, 0.6659482717514038, 0.6487069129943848, 0.6476293206214905, 0.6713362336158752, 0.6864224076271057, 0.6476293206214905, 0.6864224076271057, 0.6530172228813171, 0.6303879022598267, 0.642241358757019, 0.6551724076271057, 0.6767241358757019, 0.6616379022598267, 0.6724137663841248, 0.670258641242981, 0.649784505367279, 0.6724137663841248, 0.6799569129943848, 0.6637930870056152, 0.6756465435028076, 0.6788793206214905, 0.6487069129943848, 0.6670258641242981, 0.6691810488700867, 0.6767241358757019, 0.6034482717514038, 0.6551724076271057, 0.6831896305084229, 0.6778017282485962, 0.6454741358757019, 0.6864224076271057, 0.6713362336158752]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.5959 - accuracy: 0.7654"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 68ms/step - loss: 0.5959 - accuracy: 0.7654 - val_loss: 0.8421 - val_accuracy: 0.5238\n","Epoch 2/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.5811 - accuracy: 0.7646 - val_loss: 0.8265 - val_accuracy: 0.5317\n","Epoch 3/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5778 - accuracy: 0.7742 - val_loss: 0.8199 - val_accuracy: 0.5317\n","Epoch 4/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5748 - accuracy: 0.7683 - val_loss: 0.8162 - val_accuracy: 0.5339\n","Epoch 5/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5654 - accuracy: 0.7779 - val_loss: 0.8196 - val_accuracy: 0.5373\n","Epoch 6/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5709 - accuracy: 0.7765 - val_loss: 0.7975 - val_accuracy: 0.5486\n","Epoch 7/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5671 - accuracy: 0.7841 - val_loss: 0.8073 - val_accuracy: 0.5452\n","Epoch 8/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5658 - accuracy: 0.7725 - val_loss: 0.7863 - val_accuracy: 0.5520\n","Epoch 9/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5609 - accuracy: 0.7779 - val_loss: 0.7728 - val_accuracy: 0.5769\n","Epoch 10/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5577 - accuracy: 0.7782 - val_loss: 0.7576 - val_accuracy: 0.6380\n","Epoch 11/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5563 - accuracy: 0.7849 - val_loss: 0.7689 - val_accuracy: 0.5747\n","Epoch 12/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5579 - accuracy: 0.7858 - val_loss: 0.7621 - val_accuracy: 0.5882\n","Epoch 13/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5548 - accuracy: 0.7801 - val_loss: 0.7535 - val_accuracy: 0.5995\n","Epoch 14/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5566 - accuracy: 0.7816 - val_loss: 0.7425 - val_accuracy: 0.6290\n","Epoch 15/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5509 - accuracy: 0.7835 - val_loss: 0.7273 - val_accuracy: 0.6640\n","Epoch 16/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5451 - accuracy: 0.7872 - val_loss: 0.7196 - val_accuracy: 0.6618\n","Epoch 17/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5460 - accuracy: 0.7943 - val_loss: 0.7241 - val_accuracy: 0.6618\n","Epoch 18/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5431 - accuracy: 0.7923 - val_loss: 0.7240 - val_accuracy: 0.6572\n","Epoch 19/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5390 - accuracy: 0.7980 - val_loss: 0.7212 - val_accuracy: 0.6538\n","Epoch 20/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5415 - accuracy: 0.7903 - val_loss: 0.7094 - val_accuracy: 0.6708\n","Epoch 21/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5417 - accuracy: 0.7977 - val_loss: 0.7421 - val_accuracy: 0.6527\n","Epoch 22/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5375 - accuracy: 0.7932 - val_loss: 0.7176 - val_accuracy: 0.6821\n","Epoch 23/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5298 - accuracy: 0.7999 - val_loss: 0.7057 - val_accuracy: 0.6697\n","Epoch 24/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5333 - accuracy: 0.7982 - val_loss: 0.7238 - val_accuracy: 0.6821\n","Epoch 25/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5376 - accuracy: 0.7861 - val_loss: 0.7395 - val_accuracy: 0.6652\n","Epoch 26/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5296 - accuracy: 0.7997 - val_loss: 0.7408 - val_accuracy: 0.6606\n","Epoch 27/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5270 - accuracy: 0.7988 - val_loss: 0.7396 - val_accuracy: 0.6776\n","Epoch 28/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5272 - accuracy: 0.8070 - val_loss: 0.7749 - val_accuracy: 0.6742\n","Epoch 29/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5243 - accuracy: 0.7963 - val_loss: 0.7703 - val_accuracy: 0.6821\n","Epoch 30/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5234 - accuracy: 0.8059 - val_loss: 0.7997 - val_accuracy: 0.6629\n","Epoch 31/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5313 - accuracy: 0.8016 - val_loss: 0.8327 - val_accuracy: 0.6652\n","Epoch 32/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5210 - accuracy: 0.8016 - val_loss: 0.8176 - val_accuracy: 0.6550\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5185 - accuracy: 0.8036 - val_loss: 0.8122 - val_accuracy: 0.6719\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5150 - accuracy: 0.8039 - val_loss: 0.7848 - val_accuracy: 0.6799\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5147 - accuracy: 0.8039 - val_loss: 0.8932 - val_accuracy: 0.6414\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5215 - accuracy: 0.7988 - val_loss: 0.8144 - val_accuracy: 0.6765\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5174 - accuracy: 0.8107 - val_loss: 0.8069 - val_accuracy: 0.6674\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5129 - accuracy: 0.8079 - val_loss: 0.8151 - val_accuracy: 0.6595\n","Epoch 39/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5103 - accuracy: 0.8084 - val_loss: 0.7629 - val_accuracy: 0.6787\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5059 - accuracy: 0.8192 - val_loss: 0.7880 - val_accuracy: 0.6708\n","Epoch 41/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5157 - accuracy: 0.8081 - val_loss: 0.7866 - val_accuracy: 0.6900\n","Epoch 42/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5126 - accuracy: 0.8050 - val_loss: 0.8205 - val_accuracy: 0.6697\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5178 - accuracy: 0.8014 - val_loss: 0.8270 - val_accuracy: 0.6731\n","Epoch 44/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5126 - accuracy: 0.8033 - val_loss: 0.7784 - val_accuracy: 0.6686\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5044 - accuracy: 0.8121 - val_loss: 0.8143 - val_accuracy: 0.6471\n","Epoch 46/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5059 - accuracy: 0.8110 - val_loss: 0.8040 - val_accuracy: 0.6640\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4940 - accuracy: 0.8229 - val_loss: 0.8450 - val_accuracy: 0.6584\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4946 - accuracy: 0.8121 - val_loss: 0.8452 - val_accuracy: 0.6595\n","Epoch 49/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5055 - accuracy: 0.8115 - val_loss: 0.8314 - val_accuracy: 0.6708\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5029 - accuracy: 0.8093 - val_loss: 0.8174 - val_accuracy: 0.6640\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5183 - accuracy: 0.7968 - val_loss: 0.8532 - val_accuracy: 0.6618\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4930 - accuracy: 0.8181 - val_loss: 0.8231 - val_accuracy: 0.6787\n","Epoch 53/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4932 - accuracy: 0.8254 - val_loss: 0.8108 - val_accuracy: 0.6776\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4994 - accuracy: 0.8149 - val_loss: 0.8228 - val_accuracy: 0.6787\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4964 - accuracy: 0.8127 - val_loss: 0.8713 - val_accuracy: 0.6753\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5068 - accuracy: 0.8135 - val_loss: 0.8359 - val_accuracy: 0.6753\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4978 - accuracy: 0.8152 - val_loss: 0.8104 - val_accuracy: 0.6629\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4855 - accuracy: 0.8181 - val_loss: 0.8111 - val_accuracy: 0.6810\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4923 - accuracy: 0.8124 - val_loss: 0.8230 - val_accuracy: 0.6629\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4773 - accuracy: 0.8223 - val_loss: 0.8303 - val_accuracy: 0.6538\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4778 - accuracy: 0.8260 - val_loss: 0.8371 - val_accuracy: 0.6595\n","Epoch 62/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4769 - accuracy: 0.8282 - val_loss: 0.7833 - val_accuracy: 0.6719\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4783 - accuracy: 0.8195 - val_loss: 0.8025 - val_accuracy: 0.6821\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4811 - accuracy: 0.8280 - val_loss: 0.8202 - val_accuracy: 0.6742\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4769 - accuracy: 0.8248 - val_loss: 0.8164 - val_accuracy: 0.6833\n","Epoch 66/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4808 - accuracy: 0.8226 - val_loss: 0.8346 - val_accuracy: 0.6618\n","Epoch 67/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4920 - accuracy: 0.8141 - val_loss: 0.8579 - val_accuracy: 0.6652\n","Epoch 68/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4894 - accuracy: 0.8217 - val_loss: 0.8701 - val_accuracy: 0.6595\n","Epoch 69/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4815 - accuracy: 0.8231 - val_loss: 0.8145 - val_accuracy: 0.6821\n","Epoch 70/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4728 - accuracy: 0.8234 - val_loss: 0.8620 - val_accuracy: 0.6640\n","Epoch 71/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4666 - accuracy: 0.8331 - val_loss: 1.0067 - val_accuracy: 0.6278\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4699 - accuracy: 0.8299 - val_loss: 0.8489 - val_accuracy: 0.6697\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4711 - accuracy: 0.8345 - val_loss: 0.8853 - val_accuracy: 0.6674\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4573 - accuracy: 0.8396 - val_loss: 0.9109 - val_accuracy: 0.6561\n","Epoch 75/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4742 - accuracy: 0.8257 - val_loss: 0.9020 - val_accuracy: 0.6369\n","Epoch 76/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4728 - accuracy: 0.8217 - val_loss: 0.8543 - val_accuracy: 0.6357\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4637 - accuracy: 0.8302 - val_loss: 0.8620 - val_accuracy: 0.6482\n","Epoch 78/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4506 - accuracy: 0.8449 - val_loss: 0.8861 - val_accuracy: 0.6459\n","Epoch 79/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4588 - accuracy: 0.8336 - val_loss: 0.8658 - val_accuracy: 0.6663\n","Epoch 80/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4493 - accuracy: 0.8396 - val_loss: 0.8469 - val_accuracy: 0.6674\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4532 - accuracy: 0.8396 - val_loss: 0.9470 - val_accuracy: 0.6572\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4540 - accuracy: 0.8427 - val_loss: 0.9963 - val_accuracy: 0.6290\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4633 - accuracy: 0.8376 - val_loss: 0.9217 - val_accuracy: 0.6256\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4690 - accuracy: 0.8356 - val_loss: 0.8796 - val_accuracy: 0.6448\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4542 - accuracy: 0.8362 - val_loss: 0.8576 - val_accuracy: 0.6674\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4497 - accuracy: 0.8447 - val_loss: 0.8537 - val_accuracy: 0.6765\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4520 - accuracy: 0.8367 - val_loss: 0.9083 - val_accuracy: 0.6697\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4452 - accuracy: 0.8364 - val_loss: 0.9118 - val_accuracy: 0.6686\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4444 - accuracy: 0.8455 - val_loss: 0.9009 - val_accuracy: 0.6618\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4398 - accuracy: 0.8444 - val_loss: 0.8868 - val_accuracy: 0.6538\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4523 - accuracy: 0.8311 - val_loss: 0.9394 - val_accuracy: 0.6448\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4376 - accuracy: 0.8503 - val_loss: 1.0258 - val_accuracy: 0.6278\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4476 - accuracy: 0.8401 - val_loss: 0.9314 - val_accuracy: 0.6697\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4382 - accuracy: 0.8444 - val_loss: 0.9170 - val_accuracy: 0.6731\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4308 - accuracy: 0.8469 - val_loss: 0.9184 - val_accuracy: 0.6765\n","Epoch 96/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4395 - accuracy: 0.8455 - val_loss: 0.9373 - val_accuracy: 0.6595\n","Epoch 97/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4287 - accuracy: 0.8551 - val_loss: 0.9136 - val_accuracy: 0.6629\n","Epoch 98/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4258 - accuracy: 0.8551 - val_loss: 0.9011 - val_accuracy: 0.6674\n","Epoch 99/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4249 - accuracy: 0.8509 - val_loss: 0.9296 - val_accuracy: 0.6719\n","Epoch 100/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4360 - accuracy: 0.8475 - val_loss: 0.9298 - val_accuracy: 0.6731\n","{'loss': [0.5958794355392456, 0.5810693502426147, 0.5777754783630371, 0.5748205780982971, 0.5654035806655884, 0.5709201097488403, 0.567086398601532, 0.5657669305801392, 0.5608847737312317, 0.557713508605957, 0.5562888383865356, 0.5579491853713989, 0.5548072457313538, 0.5566001534461975, 0.5509094595909119, 0.5450694561004639, 0.5460382699966431, 0.5430926084518433, 0.5389999747276306, 0.5415073037147522, 0.5417470932006836, 0.5375121831893921, 0.5297548174858093, 0.5332677960395813, 0.5375917553901672, 0.5296119451522827, 0.5269683003425598, 0.527237057685852, 0.524280309677124, 0.5234021544456482, 0.5313344597816467, 0.5210469365119934, 0.5184783339500427, 0.5149757266044617, 0.5146755576133728, 0.5214560031890869, 0.5173686146736145, 0.5129256248474121, 0.5103170275688171, 0.5059080123901367, 0.5157381296157837, 0.5126169323921204, 0.5177867412567139, 0.5125583410263062, 0.5043546557426453, 0.5058966279029846, 0.4939820170402527, 0.4945829510688782, 0.5055469274520874, 0.5029467344284058, 0.5183194875717163, 0.4929928779602051, 0.49322548508644104, 0.4994390904903412, 0.4964464604854584, 0.506750762462616, 0.4977986216545105, 0.4855111837387085, 0.49225983023643494, 0.47725194692611694, 0.4777829945087433, 0.4768584072589874, 0.47825369238853455, 0.481052964925766, 0.4768643379211426, 0.48080581426620483, 0.4920404553413391, 0.48936617374420166, 0.4814753532409668, 0.47283226251602173, 0.46657422184944153, 0.4698579013347626, 0.47112587094306946, 0.4573311507701874, 0.47424688935279846, 0.4728171229362488, 0.46366360783576965, 0.45063647627830505, 0.45882129669189453, 0.44926363229751587, 0.45318588614463806, 0.4540095925331116, 0.46328338980674744, 0.46895524859428406, 0.45423418283462524, 0.4497419595718384, 0.4520379304885864, 0.44524192810058594, 0.4443519413471222, 0.4397689700126648, 0.45233863592147827, 0.4376274645328522, 0.4475517272949219, 0.4382360875606537, 0.43082791566848755, 0.4394735097885132, 0.4286872148513794, 0.4257526695728302, 0.4248993396759033, 0.43595898151397705], 'accuracy': [0.7654216289520264, 0.7645727396011353, 0.774193525314331, 0.7682512998580933, 0.7778720855712891, 0.7764572501182556, 0.7840973138809204, 0.7724957466125488, 0.7778720855712891, 0.7781550884246826, 0.7849462628364563, 0.7857951521873474, 0.7801358103752136, 0.7815506458282471, 0.7835314273834229, 0.7872099876403809, 0.7942841053009033, 0.7923033237457275, 0.7979626655578613, 0.7903226017951965, 0.7976796627044678, 0.7931522130966187, 0.7999433875083923, 0.7982456088066101, 0.7860780954360962, 0.7996604442596436, 0.7988115549087524, 0.8070175647735596, 0.7962648272514343, 0.8058856725692749, 0.8016412258148193, 0.8016412258148193, 0.8036219477653503, 0.8039049506187439, 0.8039049506187439, 0.7988115549087524, 0.8106960654258728, 0.8078664541244507, 0.808432400226593, 0.8191850781440735, 0.8081493973731995, 0.8050367832183838, 0.8013582229614258, 0.8033390045166016, 0.8121109008789062, 0.8109790682792664, 0.8228636384010315, 0.8121109008789062, 0.8115450143814087, 0.8092812895774841, 0.7968307733535767, 0.8180531859397888, 0.8254103064537048, 0.8149405717849731, 0.8126768469810486, 0.8135257363319397, 0.8152235150337219, 0.8180531859397888, 0.8123939037322998, 0.8222976922988892, 0.8259762525558472, 0.8282399773597717, 0.8194680213928223, 0.8279569745063782, 0.8248443603515625, 0.8225806355476379, 0.814091682434082, 0.8217317461967468, 0.8231465816497803, 0.823429524898529, 0.8330503702163696, 0.829937756061554, 0.8344652056694031, 0.8395586013793945, 0.8256932497024536, 0.8217317461967468, 0.8302206993103027, 0.8449349403381348, 0.833616316318512, 0.8395586013793945, 0.8395586013793945, 0.8426712155342102, 0.8375778198242188, 0.835597038269043, 0.8361629843711853, 0.8446519374847412, 0.8367289304733276, 0.8364459276199341, 0.8455008268356323, 0.8443689942359924, 0.8310695886611938, 0.850311279296875, 0.8401244878768921, 0.8443689942359924, 0.8469156622886658, 0.8455008268356323, 0.8551216721534729, 0.8551216721534729, 0.8508771657943726, 0.8474816083908081], 'val_loss': [0.8421350717544556, 0.8264849185943604, 0.8198918700218201, 0.8162133693695068, 0.8195521831512451, 0.7975224852561951, 0.8073119521141052, 0.7862634658813477, 0.7727840542793274, 0.7576407194137573, 0.7689024209976196, 0.762113630771637, 0.7535029053688049, 0.7425280213356018, 0.72725510597229, 0.7196106910705566, 0.7241017818450928, 0.723970353603363, 0.7211906313896179, 0.7094045877456665, 0.742090106010437, 0.7175860404968262, 0.7057042121887207, 0.7237701416015625, 0.7394576668739319, 0.7407898902893066, 0.7396227121353149, 0.7748955488204956, 0.7703030109405518, 0.7996972799301147, 0.8327456116676331, 0.8175821900367737, 0.8122498989105225, 0.7848372459411621, 0.8931733965873718, 0.8143515586853027, 0.8068759441375732, 0.8151347041130066, 0.7629356384277344, 0.7879648208618164, 0.7865517735481262, 0.8204699754714966, 0.8269530534744263, 0.7784132361412048, 0.8142839670181274, 0.8040404319763184, 0.8449755311012268, 0.8451616168022156, 0.8314223885536194, 0.8174421191215515, 0.8531716465950012, 0.8231491446495056, 0.8107934594154358, 0.8227945566177368, 0.8713167905807495, 0.8358911275863647, 0.8104150295257568, 0.811087429523468, 0.8230395913124084, 0.8302832841873169, 0.8370833992958069, 0.7833095788955688, 0.8025352954864502, 0.8202030658721924, 0.8164144158363342, 0.8345571160316467, 0.857926607131958, 0.870104968547821, 0.8144848346710205, 0.8619980812072754, 1.0067150592803955, 0.8488718271255493, 0.885280191898346, 0.9108847975730896, 0.9019984006881714, 0.8543268442153931, 0.8619806170463562, 0.8860856890678406, 0.8658311367034912, 0.8468763828277588, 0.9469656944274902, 0.9962873458862305, 0.9217307567596436, 0.8796018958091736, 0.857623279094696, 0.8536847233772278, 0.9083035588264465, 0.911756694316864, 0.9009283185005188, 0.8867839574813843, 0.9394296407699585, 1.0257821083068848, 0.9313935041427612, 0.917047917842865, 0.9184460043907166, 0.9373385906219482, 0.9136223196983337, 0.9010950922966003, 0.929633378982544, 0.9298282861709595], 'val_accuracy': [0.523755669593811, 0.5316742062568665, 0.5316742062568665, 0.5339366793632507, 0.5373303294181824, 0.5486425161361694, 0.5452488660812378, 0.5520362257957458, 0.5769230723381042, 0.6380090713500977, 0.5746606588363647, 0.5882353186607361, 0.5995475053787231, 0.6289592981338501, 0.6640271544456482, 0.6617646813392639, 0.6617646813392639, 0.6572397947311401, 0.6538461446762085, 0.6708144545555115, 0.6527149081230164, 0.6821267008781433, 0.6696832776069641, 0.6821267008781433, 0.6651583909988403, 0.6606335043907166, 0.6776018142700195, 0.6742081642150879, 0.6821267008781433, 0.662895917892456, 0.6651583909988403, 0.6549773812294006, 0.6719456911087036, 0.679864227771759, 0.6414027214050293, 0.6764705777168274, 0.6674208045005798, 0.6595022678375244, 0.6787330508232117, 0.6708144545555115, 0.6900452375411987, 0.6696832776069641, 0.6730769276618958, 0.668552041053772, 0.6470588445663452, 0.6640271544456482, 0.6583710312843323, 0.6595022678375244, 0.6708144545555115, 0.6640271544456482, 0.6617646813392639, 0.6787330508232117, 0.6776018142700195, 0.6787330508232117, 0.6753393411636353, 0.6753393411636353, 0.662895917892456, 0.6809954643249512, 0.662895917892456, 0.6538461446762085, 0.6595022678375244, 0.6719456911087036, 0.6821267008781433, 0.6742081642150879, 0.6832579374313354, 0.6617646813392639, 0.6651583909988403, 0.6595022678375244, 0.6821267008781433, 0.6640271544456482, 0.627828061580658, 0.6696832776069641, 0.6674208045005798, 0.6561086177825928, 0.6368778347969055, 0.6357465982437134, 0.6481900215148926, 0.6459276080131531, 0.6662895679473877, 0.6674208045005798, 0.6572397947311401, 0.6289592981338501, 0.6255655884742737, 0.6447963714599609, 0.6674208045005798, 0.6764705777168274, 0.6696832776069641, 0.668552041053772, 0.6617646813392639, 0.6538461446762085, 0.6447963714599609, 0.627828061580658, 0.6696832776069641, 0.6730769276618958, 0.6764705777168274, 0.6595022678375244, 0.662895917892456, 0.6674208045005798, 0.6719456911087036, 0.6730769276618958]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.5966 - accuracy: 0.7467"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 55ms/step - loss: 0.6015 - accuracy: 0.7463 - val_loss: 0.8174 - val_accuracy: 0.5341\n","Epoch 2/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5967 - accuracy: 0.7550 - val_loss: 0.8638 - val_accuracy: 0.5289\n","Epoch 3/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.5856 - accuracy: 0.7566 - val_loss: 0.8072 - val_accuracy: 0.5393\n","Epoch 4/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5877 - accuracy: 0.7641 - val_loss: 0.8183 - val_accuracy: 0.5382\n","Epoch 5/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5822 - accuracy: 0.7581 - val_loss: 0.7966 - val_accuracy: 0.5486\n","Epoch 6/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5804 - accuracy: 0.7623 - val_loss: 0.8038 - val_accuracy: 0.5455\n","Epoch 7/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5790 - accuracy: 0.7589 - val_loss: 0.7872 - val_accuracy: 0.5651\n","Epoch 8/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5747 - accuracy: 0.7643 - val_loss: 0.7805 - val_accuracy: 0.5816\n","Epoch 9/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5673 - accuracy: 0.7659 - val_loss: 0.7821 - val_accuracy: 0.5764\n","Epoch 10/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5663 - accuracy: 0.7718 - val_loss: 0.7758 - val_accuracy: 0.5878\n","Epoch 11/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5651 - accuracy: 0.7734 - val_loss: 0.7724 - val_accuracy: 0.5940\n","Epoch 12/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5798 - accuracy: 0.7548 - val_loss: 0.7951 - val_accuracy: 0.5630\n","Epoch 13/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5673 - accuracy: 0.7661 - val_loss: 0.7620 - val_accuracy: 0.6188\n","Epoch 14/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5755 - accuracy: 0.7556 - val_loss: 0.7606 - val_accuracy: 0.6374\n","Epoch 15/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5618 - accuracy: 0.7708 - val_loss: 0.7596 - val_accuracy: 0.6167\n","Epoch 16/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5604 - accuracy: 0.7778 - val_loss: 0.7662 - val_accuracy: 0.6229\n","Epoch 17/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5572 - accuracy: 0.7835 - val_loss: 0.7610 - val_accuracy: 0.6302\n","Epoch 18/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5582 - accuracy: 0.7726 - val_loss: 0.7638 - val_accuracy: 0.6240\n","Epoch 19/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5519 - accuracy: 0.7829 - val_loss: 0.8013 - val_accuracy: 0.6343\n","Epoch 20/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5654 - accuracy: 0.7713 - val_loss: 0.8446 - val_accuracy: 0.6322\n","Epoch 21/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5584 - accuracy: 0.7757 - val_loss: 0.8348 - val_accuracy: 0.6333\n","Epoch 22/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5496 - accuracy: 0.7760 - val_loss: 0.8284 - val_accuracy: 0.6322\n","Epoch 23/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5455 - accuracy: 0.7773 - val_loss: 0.8177 - val_accuracy: 0.6405\n","Epoch 24/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5447 - accuracy: 0.7829 - val_loss: 0.8060 - val_accuracy: 0.6508\n","Epoch 25/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5458 - accuracy: 0.7783 - val_loss: 0.8587 - val_accuracy: 0.6457\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5406 - accuracy: 0.7845 - val_loss: 0.8275 - val_accuracy: 0.6426\n","Epoch 27/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5445 - accuracy: 0.7809 - val_loss: 0.8595 - val_accuracy: 0.6384\n","Epoch 28/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5342 - accuracy: 0.7886 - val_loss: 0.8687 - val_accuracy: 0.6353\n","Epoch 29/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5389 - accuracy: 0.7866 - val_loss: 0.8830 - val_accuracy: 0.6467\n","Epoch 30/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5339 - accuracy: 0.7912 - val_loss: 0.8805 - val_accuracy: 0.6581\n","Epoch 31/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5332 - accuracy: 0.7876 - val_loss: 1.0863 - val_accuracy: 0.5754\n","Epoch 32/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5302 - accuracy: 0.7879 - val_loss: 0.8765 - val_accuracy: 0.6353\n","Epoch 33/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5325 - accuracy: 0.7873 - val_loss: 0.9061 - val_accuracy: 0.6477\n","Epoch 34/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5321 - accuracy: 0.7827 - val_loss: 0.8927 - val_accuracy: 0.6260\n","Epoch 35/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5360 - accuracy: 0.8003 - val_loss: 0.8466 - val_accuracy: 0.6519\n","Epoch 36/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5313 - accuracy: 0.7848 - val_loss: 0.8559 - val_accuracy: 0.6364\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5216 - accuracy: 0.7979 - val_loss: 0.9116 - val_accuracy: 0.6395\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5187 - accuracy: 0.7953 - val_loss: 0.9292 - val_accuracy: 0.6240\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5218 - accuracy: 0.7891 - val_loss: 1.0867 - val_accuracy: 0.5857\n","Epoch 40/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5231 - accuracy: 0.7953 - val_loss: 0.8905 - val_accuracy: 0.6395\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5228 - accuracy: 0.7943 - val_loss: 0.9324 - val_accuracy: 0.6281\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5235 - accuracy: 0.7935 - val_loss: 0.9872 - val_accuracy: 0.6364\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5187 - accuracy: 0.7941 - val_loss: 0.9570 - val_accuracy: 0.6395\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5173 - accuracy: 0.7990 - val_loss: 0.9089 - val_accuracy: 0.6477\n","Epoch 45/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5107 - accuracy: 0.8072 - val_loss: 0.9944 - val_accuracy: 0.6395\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5101 - accuracy: 0.8059 - val_loss: 0.9225 - val_accuracy: 0.6539\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5169 - accuracy: 0.8010 - val_loss: 0.9767 - val_accuracy: 0.6116\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5155 - accuracy: 0.8093 - val_loss: 0.9456 - val_accuracy: 0.6519\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5059 - accuracy: 0.7956 - val_loss: 0.9824 - val_accuracy: 0.6105\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5123 - accuracy: 0.8023 - val_loss: 1.0083 - val_accuracy: 0.6250\n","Epoch 51/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5154 - accuracy: 0.8059 - val_loss: 1.0060 - val_accuracy: 0.6064\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5240 - accuracy: 0.7959 - val_loss: 1.0383 - val_accuracy: 0.6116\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5074 - accuracy: 0.8013 - val_loss: 0.9614 - val_accuracy: 0.6384\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5082 - accuracy: 0.8049 - val_loss: 0.9638 - val_accuracy: 0.6333\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5083 - accuracy: 0.7972 - val_loss: 0.9529 - val_accuracy: 0.6498\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4968 - accuracy: 0.8080 - val_loss: 0.9474 - val_accuracy: 0.6426\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4977 - accuracy: 0.8093 - val_loss: 0.9365 - val_accuracy: 0.6291\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5142 - accuracy: 0.7930 - val_loss: 0.9558 - val_accuracy: 0.6229\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5041 - accuracy: 0.8109 - val_loss: 1.0090 - val_accuracy: 0.6250\n","Epoch 60/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4990 - accuracy: 0.8119 - val_loss: 0.9542 - val_accuracy: 0.6384\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5099 - accuracy: 0.8049 - val_loss: 0.9549 - val_accuracy: 0.6198\n","Epoch 62/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4963 - accuracy: 0.8124 - val_loss: 0.9243 - val_accuracy: 0.6188\n","Epoch 63/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4909 - accuracy: 0.8134 - val_loss: 0.9366 - val_accuracy: 0.6364\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4901 - accuracy: 0.8171 - val_loss: 1.1120 - val_accuracy: 0.5837\n","Epoch 65/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4956 - accuracy: 0.8121 - val_loss: 1.0432 - val_accuracy: 0.6095\n","Epoch 66/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4882 - accuracy: 0.8127 - val_loss: 1.0532 - val_accuracy: 0.6064\n","Epoch 67/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4915 - accuracy: 0.8023 - val_loss: 1.0778 - val_accuracy: 0.6529\n","Epoch 68/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4933 - accuracy: 0.8085 - val_loss: 1.1040 - val_accuracy: 0.6116\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4934 - accuracy: 0.8129 - val_loss: 0.9530 - val_accuracy: 0.6446\n","Epoch 70/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4767 - accuracy: 0.8217 - val_loss: 0.9514 - val_accuracy: 0.6271\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4906 - accuracy: 0.8147 - val_loss: 0.9576 - val_accuracy: 0.6364\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4755 - accuracy: 0.8269 - val_loss: 1.0144 - val_accuracy: 0.6157\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4864 - accuracy: 0.8207 - val_loss: 1.0208 - val_accuracy: 0.6229\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4695 - accuracy: 0.8297 - val_loss: 1.0594 - val_accuracy: 0.6508\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4865 - accuracy: 0.8127 - val_loss: 1.0654 - val_accuracy: 0.6395\n","Epoch 76/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4909 - accuracy: 0.8088 - val_loss: 1.0102 - val_accuracy: 0.6477\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4738 - accuracy: 0.8258 - val_loss: 1.0426 - val_accuracy: 0.6312\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4767 - accuracy: 0.8230 - val_loss: 1.0564 - val_accuracy: 0.6167\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4787 - accuracy: 0.8152 - val_loss: 1.0421 - val_accuracy: 0.6446\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4685 - accuracy: 0.8225 - val_loss: 1.0429 - val_accuracy: 0.6219\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4686 - accuracy: 0.8292 - val_loss: 0.9851 - val_accuracy: 0.6395\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4706 - accuracy: 0.8222 - val_loss: 1.0199 - val_accuracy: 0.6405\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4651 - accuracy: 0.8289 - val_loss: 1.0024 - val_accuracy: 0.6415\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4570 - accuracy: 0.8349 - val_loss: 1.0284 - val_accuracy: 0.6374\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4636 - accuracy: 0.8300 - val_loss: 1.0574 - val_accuracy: 0.6333\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4912 - accuracy: 0.8137 - val_loss: 1.0057 - val_accuracy: 0.6302\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4726 - accuracy: 0.8178 - val_loss: 0.9817 - val_accuracy: 0.6529\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4640 - accuracy: 0.8344 - val_loss: 1.0947 - val_accuracy: 0.6488\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4793 - accuracy: 0.8199 - val_loss: 1.0115 - val_accuracy: 0.6271\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4653 - accuracy: 0.8222 - val_loss: 1.0391 - val_accuracy: 0.6384\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4531 - accuracy: 0.8333 - val_loss: 1.0932 - val_accuracy: 0.6043\n","Epoch 92/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4616 - accuracy: 0.8225 - val_loss: 1.0415 - val_accuracy: 0.6395\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4520 - accuracy: 0.8351 - val_loss: 1.0575 - val_accuracy: 0.6477\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4669 - accuracy: 0.8292 - val_loss: 1.0675 - val_accuracy: 0.6260\n","Epoch 95/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4705 - accuracy: 0.8248 - val_loss: 1.1181 - val_accuracy: 0.6364\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4530 - accuracy: 0.8395 - val_loss: 1.0764 - val_accuracy: 0.6436\n","Epoch 97/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4437 - accuracy: 0.8370 - val_loss: 1.0753 - val_accuracy: 0.6353\n","Epoch 98/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4527 - accuracy: 0.8233 - val_loss: 1.0282 - val_accuracy: 0.6426\n","Epoch 99/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4548 - accuracy: 0.8274 - val_loss: 1.0608 - val_accuracy: 0.6271\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4487 - accuracy: 0.8385 - val_loss: 1.1954 - val_accuracy: 0.6043\n","{'loss': [0.6015258431434631, 0.5967031717300415, 0.5855957865715027, 0.5876586437225342, 0.582230806350708, 0.5803806781768799, 0.5790383219718933, 0.5746697187423706, 0.5673450827598572, 0.5663177371025085, 0.5650972127914429, 0.5798333287239075, 0.5673462748527527, 0.5755286812782288, 0.5618376731872559, 0.5603699684143066, 0.5572089552879333, 0.5581624507904053, 0.5519289970397949, 0.565359890460968, 0.558423638343811, 0.5496369004249573, 0.5455294847488403, 0.5447092652320862, 0.5458490252494812, 0.5406366586685181, 0.5444745421409607, 0.5342342853546143, 0.5388714671134949, 0.5339394211769104, 0.5331653952598572, 0.5302008390426636, 0.5325185060501099, 0.532121479511261, 0.5360280871391296, 0.5313320755958557, 0.5215807557106018, 0.518703281879425, 0.5218380093574524, 0.5231186747550964, 0.522787868976593, 0.5234927535057068, 0.5186622142791748, 0.5172881484031677, 0.510690450668335, 0.5100688338279724, 0.5169426202774048, 0.515521764755249, 0.5058586597442627, 0.5123167037963867, 0.5153520107269287, 0.5239856243133545, 0.5073747038841248, 0.5082289576530457, 0.5083063244819641, 0.4968241751194, 0.4976993501186371, 0.5142149925231934, 0.5040971636772156, 0.49898985028266907, 0.5098907351493835, 0.49626103043556213, 0.49087706208229065, 0.4901069402694702, 0.495581716299057, 0.48816192150115967, 0.4915139079093933, 0.4933112859725952, 0.4934045970439911, 0.47671589255332947, 0.490626722574234, 0.4755355417728424, 0.48638176918029785, 0.4695393443107605, 0.48653972148895264, 0.49088385701179504, 0.473777711391449, 0.4767303466796875, 0.47872886061668396, 0.46854937076568604, 0.46861663460731506, 0.4706469774246216, 0.46510422229766846, 0.45703625679016113, 0.46359655261039734, 0.4911879003047943, 0.4726243317127228, 0.46401700377464294, 0.4793315529823303, 0.46529269218444824, 0.45313477516174316, 0.46156471967697144, 0.451961874961853, 0.46687039732933044, 0.47052761912345886, 0.45301467180252075, 0.44365978240966797, 0.45272237062454224, 0.4547770917415619, 0.44866859912872314], 'accuracy': [0.746253252029419, 0.7550387382507324, 0.7565891742706299, 0.764082670211792, 0.7581395506858826, 0.762273907661438, 0.7589147090911865, 0.7643410563468933, 0.7658914923667908, 0.7718346118927002, 0.7733849883079529, 0.7547803521156311, 0.7661498785018921, 0.7555555701255798, 0.7708010077476501, 0.7777777910232544, 0.7834625244140625, 0.7726098299026489, 0.7829457521438599, 0.7713178396224976, 0.7757105827331543, 0.7759689688682556, 0.777260959148407, 0.7829457521438599, 0.778294563293457, 0.7844961285591125, 0.7808785438537598, 0.788630485534668, 0.7865633368492126, 0.7912144660949707, 0.7875968813896179, 0.7878552675247192, 0.7873384952545166, 0.7826873660087585, 0.8002583980560303, 0.7847545146942139, 0.7979328036308289, 0.7953488230705261, 0.7891472578048706, 0.7953488230705261, 0.7943152189254761, 0.7935400605201721, 0.7940568327903748, 0.7989664077758789, 0.8072351217269897, 0.8059431314468384, 0.801033616065979, 0.8093023300170898, 0.7956072092056274, 0.8023256063461304, 0.8059431314468384, 0.7958656549453735, 0.8012920022010803, 0.8049095869064331, 0.7971576452255249, 0.8080103397369385, 0.8093023300170898, 0.7930232286453247, 0.8108527064323425, 0.8118863105773926, 0.8049095869064331, 0.8124030828475952, 0.8134366869926453, 0.817054271697998, 0.8121446967124939, 0.8126614689826965, 0.8023256063461304, 0.8085271120071411, 0.8129199147224426, 0.8217054009437561, 0.8147286772727966, 0.8268733620643616, 0.8206718564033508, 0.8297157883644104, 0.8126614689826965, 0.8087855577468872, 0.8258398175239563, 0.8229973912239075, 0.8152454495429993, 0.8224806189537048, 0.829198956489563, 0.8222222328186035, 0.8289405703544617, 0.8348837494850159, 0.8299741744995117, 0.8136950731277466, 0.817829430103302, 0.8343669176101685, 0.8198966383934021, 0.8222222328186035, 0.8333333134651184, 0.8224806189537048, 0.8351421356201172, 0.829198956489563, 0.8248062133789062, 0.8395348787307739, 0.8369508981704712, 0.8232558369636536, 0.827390193939209, 0.8385012745857239], 'val_loss': [0.8173646926879883, 0.8637577891349792, 0.8071864247322083, 0.8183344006538391, 0.7966495156288147, 0.8038044571876526, 0.7872364521026611, 0.7805498242378235, 0.7821336388587952, 0.775797963142395, 0.7724448442459106, 0.7951149344444275, 0.761959433555603, 0.7605780363082886, 0.7595596313476562, 0.7662125825881958, 0.7609567642211914, 0.763785183429718, 0.8013486862182617, 0.844587504863739, 0.8347750306129456, 0.8283756971359253, 0.8177467584609985, 0.8059701323509216, 0.8587406873703003, 0.8275026082992554, 0.8594687581062317, 0.8686516880989075, 0.8830264806747437, 0.8804609775543213, 1.0862520933151245, 0.8765058517456055, 0.9061123132705688, 0.8927284479141235, 0.846593976020813, 0.8559157848358154, 0.9116299152374268, 0.9291560053825378, 1.0866575241088867, 0.8905491828918457, 0.9323617815971375, 0.987194836139679, 0.9569571614265442, 0.9088601469993591, 0.9944226145744324, 0.922493040561676, 0.9767186641693115, 0.9456360936164856, 0.9823883175849915, 1.0082827806472778, 1.005972146987915, 1.0383461713790894, 0.9614401459693909, 0.9637696743011475, 0.952907145023346, 0.9473716616630554, 0.9364724159240723, 0.9557774066925049, 1.0090311765670776, 0.9542484283447266, 0.9549119472503662, 0.9243173003196716, 0.9366267919540405, 1.1120349168777466, 1.0432196855545044, 1.0531522035598755, 1.0777842998504639, 1.104012370109558, 0.9530454277992249, 0.9513753056526184, 0.9576272964477539, 1.0143669843673706, 1.0208324193954468, 1.0593723058700562, 1.0654330253601074, 1.0102165937423706, 1.0426298379898071, 1.0564463138580322, 1.0420876741409302, 1.0429234504699707, 0.985085129737854, 1.0198615789413452, 1.0024083852767944, 1.0283658504486084, 1.0573773384094238, 1.0056591033935547, 0.9817070960998535, 1.0947465896606445, 1.011533498764038, 1.0391305685043335, 1.0932471752166748, 1.0415012836456299, 1.0575292110443115, 1.0674760341644287, 1.1180986166000366, 1.0764155387878418, 1.0753344297409058, 1.0282378196716309, 1.0608214139938354, 1.1954413652420044], 'val_accuracy': [0.5340909361839294, 0.5289255976676941, 0.53925621509552, 0.538223147392273, 0.5485537052154541, 0.5454545617103577, 0.5650826692581177, 0.5816115736961365, 0.5764462947845459, 0.5878099203109741, 0.5940082669258118, 0.5630165338516235, 0.6188016533851624, 0.6373966932296753, 0.6167355179786682, 0.6229338645935059, 0.6301652789115906, 0.6239669322967529, 0.6342975497245789, 0.6322314143180847, 0.6332644820213318, 0.6322314143180847, 0.6404958963394165, 0.6508264541625977, 0.6456611752510071, 0.6425619721412659, 0.6384297609329224, 0.6353305578231812, 0.6466942429542542, 0.6580578684806824, 0.5754132270812988, 0.6353305578231812, 0.6477272510528564, 0.6260330677032471, 0.6518595218658447, 0.6363636255264282, 0.6394628286361694, 0.6239669322967529, 0.58574378490448, 0.6394628286361694, 0.6280992031097412, 0.6363636255264282, 0.6394628286361694, 0.6477272510528564, 0.6394628286361694, 0.6539255976676941, 0.6115702390670776, 0.6518595218658447, 0.6105371713638306, 0.625, 0.6064049601554871, 0.6115702390670776, 0.6384297609329224, 0.6332644820213318, 0.6497933864593506, 0.6425619721412659, 0.6291322112083435, 0.6229338645935059, 0.625, 0.6384297609329224, 0.6198347210884094, 0.6188016533851624, 0.6363636255264282, 0.5836777091026306, 0.6095041036605835, 0.6064049601554871, 0.6528925895690918, 0.6115702390670776, 0.64462810754776, 0.6270661354064941, 0.6363636255264282, 0.6157024502754211, 0.6229338645935059, 0.6508264541625977, 0.6394628286361694, 0.6477272510528564, 0.6311983466148376, 0.6167355179786682, 0.64462810754776, 0.6219007968902588, 0.6394628286361694, 0.6404958963394165, 0.6415289044380188, 0.6373966932296753, 0.6332644820213318, 0.6301652789115906, 0.6528925895690918, 0.6487603187561035, 0.6270661354064941, 0.6384297609329224, 0.6043388247489929, 0.6394628286361694, 0.6477272510528564, 0.6260330677032471, 0.6363636255264282, 0.6435950398445129, 0.6353305578231812, 0.6425619721412659, 0.6270661354064941, 0.6043388247489929]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.4979 - accuracy: 0.8083"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 71ms/step - loss: 0.5008 - accuracy: 0.8087 - val_loss: 0.8434 - val_accuracy: 0.5291\n","Epoch 2/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.4850 - accuracy: 0.8163 - val_loss: 0.8445 - val_accuracy: 0.5334\n","Epoch 3/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.4713 - accuracy: 0.8233 - val_loss: 0.7864 - val_accuracy: 0.5647\n","Epoch 4/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4745 - accuracy: 0.8219 - val_loss: 0.8084 - val_accuracy: 0.5485\n","Epoch 5/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4662 - accuracy: 0.8244 - val_loss: 0.8060 - val_accuracy: 0.5506\n","Epoch 6/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4591 - accuracy: 0.8268 - val_loss: 0.7982 - val_accuracy: 0.5560\n","Epoch 7/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4648 - accuracy: 0.8179 - val_loss: 0.7882 - val_accuracy: 0.5776\n","Epoch 8/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4614 - accuracy: 0.8265 - val_loss: 0.7996 - val_accuracy: 0.5657\n","Epoch 9/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4523 - accuracy: 0.8357 - val_loss: 0.7712 - val_accuracy: 0.6024\n","Epoch 10/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4605 - accuracy: 0.8254 - val_loss: 0.7862 - val_accuracy: 0.5916\n","Epoch 11/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4619 - accuracy: 0.8295 - val_loss: 0.7530 - val_accuracy: 0.6401\n","Epoch 12/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4577 - accuracy: 0.8254 - val_loss: 0.7668 - val_accuracy: 0.6218\n","Epoch 13/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4475 - accuracy: 0.8354 - val_loss: 0.7505 - val_accuracy: 0.6778\n","Epoch 14/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4606 - accuracy: 0.8246 - val_loss: 0.7364 - val_accuracy: 0.6659\n","Epoch 15/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4479 - accuracy: 0.8381 - val_loss: 0.7486 - val_accuracy: 0.6670\n","Epoch 16/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4364 - accuracy: 0.8389 - val_loss: 0.7535 - val_accuracy: 0.6703\n","Epoch 17/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4449 - accuracy: 0.8319 - val_loss: 0.7390 - val_accuracy: 0.6950\n","Epoch 18/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4347 - accuracy: 0.8475 - val_loss: 0.7173 - val_accuracy: 0.7058\n","Epoch 19/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4348 - accuracy: 0.8359 - val_loss: 0.7367 - val_accuracy: 0.6950\n","Epoch 20/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4424 - accuracy: 0.8287 - val_loss: 0.7626 - val_accuracy: 0.6832\n","Epoch 21/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4353 - accuracy: 0.8408 - val_loss: 0.8123 - val_accuracy: 0.6703\n","Epoch 22/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4423 - accuracy: 0.8357 - val_loss: 0.7984 - val_accuracy: 0.6767\n","Epoch 23/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4341 - accuracy: 0.8394 - val_loss: 0.7577 - val_accuracy: 0.7284\n","Epoch 24/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4350 - accuracy: 0.8435 - val_loss: 0.8648 - val_accuracy: 0.6681\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4314 - accuracy: 0.8424 - val_loss: 0.8112 - val_accuracy: 0.6961\n","Epoch 26/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4380 - accuracy: 0.8416 - val_loss: 0.8180 - val_accuracy: 0.7134\n","Epoch 27/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4258 - accuracy: 0.8481 - val_loss: 0.8096 - val_accuracy: 0.6961\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4378 - accuracy: 0.8381 - val_loss: 0.9225 - val_accuracy: 0.6756\n","Epoch 29/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4225 - accuracy: 0.8545 - val_loss: 0.8514 - val_accuracy: 0.7112\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4170 - accuracy: 0.8543 - val_loss: 0.9847 - val_accuracy: 0.6584\n","Epoch 31/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4258 - accuracy: 0.8494 - val_loss: 0.8664 - val_accuracy: 0.7209\n","Epoch 32/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4252 - accuracy: 0.8494 - val_loss: 0.8901 - val_accuracy: 0.6897\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4206 - accuracy: 0.8510 - val_loss: 0.8740 - val_accuracy: 0.7058\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4208 - accuracy: 0.8438 - val_loss: 0.8567 - val_accuracy: 0.7274\n","Epoch 35/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4212 - accuracy: 0.8491 - val_loss: 0.8750 - val_accuracy: 0.6961\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4070 - accuracy: 0.8494 - val_loss: 0.9461 - val_accuracy: 0.6735\n","Epoch 37/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4133 - accuracy: 0.8578 - val_loss: 0.9701 - val_accuracy: 0.6541\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4208 - accuracy: 0.8489 - val_loss: 0.8707 - val_accuracy: 0.7263\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4132 - accuracy: 0.8526 - val_loss: 0.8956 - val_accuracy: 0.7047\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4154 - accuracy: 0.8537 - val_loss: 0.8729 - val_accuracy: 0.6983\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4054 - accuracy: 0.8605 - val_loss: 0.8743 - val_accuracy: 0.7144\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4092 - accuracy: 0.8553 - val_loss: 0.9611 - val_accuracy: 0.6853\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4172 - accuracy: 0.8478 - val_loss: 0.8766 - val_accuracy: 0.7144\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4044 - accuracy: 0.8540 - val_loss: 0.8578 - val_accuracy: 0.7188\n","Epoch 45/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4080 - accuracy: 0.8513 - val_loss: 0.9167 - val_accuracy: 0.6961\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4088 - accuracy: 0.8543 - val_loss: 0.9242 - val_accuracy: 0.6907\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4023 - accuracy: 0.8613 - val_loss: 0.8453 - val_accuracy: 0.7263\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3924 - accuracy: 0.8637 - val_loss: 0.9086 - val_accuracy: 0.7101\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3955 - accuracy: 0.8648 - val_loss: 0.9246 - val_accuracy: 0.6821\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4066 - accuracy: 0.8553 - val_loss: 0.9593 - val_accuracy: 0.6918\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3942 - accuracy: 0.8677 - val_loss: 0.9056 - val_accuracy: 0.7015\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4011 - accuracy: 0.8586 - val_loss: 1.0635 - val_accuracy: 0.6627\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4197 - accuracy: 0.8548 - val_loss: 0.9928 - val_accuracy: 0.6746\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4098 - accuracy: 0.8491 - val_loss: 0.9556 - val_accuracy: 0.6897\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3941 - accuracy: 0.8607 - val_loss: 0.9963 - val_accuracy: 0.6713\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3905 - accuracy: 0.8621 - val_loss: 1.0233 - val_accuracy: 0.6713\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3989 - accuracy: 0.8602 - val_loss: 0.9617 - val_accuracy: 0.7047\n","Epoch 58/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4008 - accuracy: 0.8543 - val_loss: 0.9821 - val_accuracy: 0.6918\n","Epoch 59/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3866 - accuracy: 0.8699 - val_loss: 0.9227 - val_accuracy: 0.7080\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3881 - accuracy: 0.8685 - val_loss: 0.9623 - val_accuracy: 0.6940\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3884 - accuracy: 0.8648 - val_loss: 0.9307 - val_accuracy: 0.7198\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3916 - accuracy: 0.8688 - val_loss: 0.9519 - val_accuracy: 0.7047\n","Epoch 63/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3891 - accuracy: 0.8653 - val_loss: 1.1483 - val_accuracy: 0.6336\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3860 - accuracy: 0.8677 - val_loss: 1.2106 - val_accuracy: 0.6325\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3831 - accuracy: 0.8691 - val_loss: 0.9623 - val_accuracy: 0.6940\n","Epoch 66/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3928 - accuracy: 0.8572 - val_loss: 1.0458 - val_accuracy: 0.6907\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3916 - accuracy: 0.8669 - val_loss: 0.9862 - val_accuracy: 0.6929\n","Epoch 68/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3811 - accuracy: 0.8699 - val_loss: 0.9715 - val_accuracy: 0.6983\n","Epoch 69/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3785 - accuracy: 0.8715 - val_loss: 1.0144 - val_accuracy: 0.6832\n","Epoch 70/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3913 - accuracy: 0.8702 - val_loss: 1.1253 - val_accuracy: 0.6724\n","Epoch 71/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4064 - accuracy: 0.8615 - val_loss: 1.0258 - val_accuracy: 0.6907\n","Epoch 72/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3784 - accuracy: 0.8747 - val_loss: 0.9787 - val_accuracy: 0.7069\n","Epoch 73/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3692 - accuracy: 0.8742 - val_loss: 0.9799 - val_accuracy: 0.7134\n","Epoch 74/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3701 - accuracy: 0.8739 - val_loss: 1.0156 - val_accuracy: 0.6950\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3782 - accuracy: 0.8728 - val_loss: 1.2417 - val_accuracy: 0.6293\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3694 - accuracy: 0.8755 - val_loss: 0.9955 - val_accuracy: 0.7015\n","Epoch 77/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3716 - accuracy: 0.8702 - val_loss: 0.9754 - val_accuracy: 0.7112\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3679 - accuracy: 0.8753 - val_loss: 1.0332 - val_accuracy: 0.6853\n","Epoch 79/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3678 - accuracy: 0.8780 - val_loss: 1.1218 - val_accuracy: 0.6616\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3706 - accuracy: 0.8761 - val_loss: 1.0104 - val_accuracy: 0.6950\n","Epoch 81/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3707 - accuracy: 0.8842 - val_loss: 0.9760 - val_accuracy: 0.7047\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3718 - accuracy: 0.8715 - val_loss: 1.0065 - val_accuracy: 0.6940\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3800 - accuracy: 0.8653 - val_loss: 0.9855 - val_accuracy: 0.6875\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3812 - accuracy: 0.8605 - val_loss: 1.0729 - val_accuracy: 0.6800\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3739 - accuracy: 0.8645 - val_loss: 1.0271 - val_accuracy: 0.7037\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3785 - accuracy: 0.8623 - val_loss: 1.1561 - val_accuracy: 0.6487\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3759 - accuracy: 0.8702 - val_loss: 1.4706 - val_accuracy: 0.5959\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3758 - accuracy: 0.8696 - val_loss: 1.1435 - val_accuracy: 0.6466\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3643 - accuracy: 0.8831 - val_loss: 1.0125 - val_accuracy: 0.7015\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3572 - accuracy: 0.8742 - val_loss: 1.0319 - val_accuracy: 0.6972\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3525 - accuracy: 0.8855 - val_loss: 1.1981 - val_accuracy: 0.6422\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3610 - accuracy: 0.8755 - val_loss: 1.2108 - val_accuracy: 0.6530\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3602 - accuracy: 0.8825 - val_loss: 1.0489 - val_accuracy: 0.6886\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3522 - accuracy: 0.8828 - val_loss: 1.0963 - val_accuracy: 0.6756\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3670 - accuracy: 0.8763 - val_loss: 1.0949 - val_accuracy: 0.6918\n","Epoch 96/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3560 - accuracy: 0.8815 - val_loss: 1.1013 - val_accuracy: 0.6800\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3586 - accuracy: 0.8847 - val_loss: 1.1323 - val_accuracy: 0.6573\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3554 - accuracy: 0.8761 - val_loss: 1.0407 - val_accuracy: 0.6864\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3564 - accuracy: 0.8812 - val_loss: 1.0856 - val_accuracy: 0.6756\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3543 - accuracy: 0.8798 - val_loss: 1.0365 - val_accuracy: 0.6961\n","{'loss': [0.5007941722869873, 0.4850101172924042, 0.4713381826877594, 0.47452157735824585, 0.4661901295185089, 0.45908600091934204, 0.46476656198501587, 0.46138617396354675, 0.45231887698173523, 0.4605275094509125, 0.4619400203227997, 0.4577063322067261, 0.44751495122909546, 0.46062585711479187, 0.44789692759513855, 0.436437726020813, 0.4448578357696533, 0.43466073274612427, 0.4347798824310303, 0.4423549175262451, 0.4352630078792572, 0.4423287808895111, 0.4340605139732361, 0.4350360333919525, 0.4313942790031433, 0.4380112588405609, 0.4258330464363098, 0.43775054812431335, 0.4224591851234436, 0.41702619194984436, 0.42579299211502075, 0.4252491295337677, 0.42064860463142395, 0.4208475351333618, 0.42118334770202637, 0.4070298969745636, 0.41325145959854126, 0.42082569003105164, 0.4132320284843445, 0.41543492674827576, 0.4054359793663025, 0.4092034697532654, 0.4172087609767914, 0.40436750650405884, 0.4080358147621155, 0.40879613161087036, 0.4022569954395294, 0.39237648248672485, 0.39547500014305115, 0.40657275915145874, 0.3942217528820038, 0.40114328265190125, 0.4196746349334717, 0.40982428193092346, 0.3940912187099457, 0.3905037045478821, 0.3988710045814514, 0.4008335769176483, 0.3866341710090637, 0.3880820572376251, 0.3884407579898834, 0.3916305899620056, 0.389110267162323, 0.38600125908851624, 0.3830708861351013, 0.39281752705574036, 0.3915698230266571, 0.3810831606388092, 0.3785228133201599, 0.3912689685821533, 0.40642374753952026, 0.3783682584762573, 0.3691740930080414, 0.3701380789279938, 0.3781692683696747, 0.36941179633140564, 0.37162306904792786, 0.367903470993042, 0.3678230345249176, 0.37055641412734985, 0.3707394301891327, 0.37178629636764526, 0.3800170123577118, 0.3812475800514221, 0.3738805949687958, 0.3784927427768707, 0.3758561909198761, 0.3758150637149811, 0.3643021881580353, 0.35723012685775757, 0.35253942012786865, 0.36095568537712097, 0.3601797819137573, 0.3522437512874603, 0.3669949471950531, 0.35600540041923523, 0.35856521129608154, 0.3554217517375946, 0.3564418852329254, 0.35430362820625305], 'accuracy': [0.8087284564971924, 0.8162715435028076, 0.8232758641242981, 0.821928858757019, 0.8243534564971924, 0.826777994632721, 0.8178879022598267, 0.826508641242981, 0.8356680870056152, 0.8254310488700867, 0.829472005367279, 0.8254310488700867, 0.8353987336158752, 0.8246228694915771, 0.8380926847457886, 0.8389008641242981, 0.8318965435028076, 0.8475215435028076, 0.8359375, 0.8286637663841248, 0.8407866358757019, 0.8356680870056152, 0.8394396305084229, 0.8434805870056152, 0.842402994632721, 0.8415948152542114, 0.8480603694915771, 0.8380926847457886, 0.8545258641242981, 0.8542564511299133, 0.8494073152542114, 0.8494073152542114, 0.8510237336158752, 0.84375, 0.8491379022598267, 0.8494073152542114, 0.857758641242981, 0.8488685488700867, 0.8526400923728943, 0.8537176847457886, 0.8604525923728943, 0.8553340435028076, 0.8477909564971924, 0.8539870977401733, 0.8512930870056152, 0.8542564511299133, 0.8612607717514038, 0.8636853694915771, 0.8647629022598267, 0.8553340435028076, 0.8677262663841248, 0.8585668206214905, 0.8547952771186829, 0.8491379022598267, 0.860722005367279, 0.8620689511299133, 0.8601831793785095, 0.8542564511299133, 0.8698814511299133, 0.868534505367279, 0.8647629022598267, 0.868803858757019, 0.8653017282485962, 0.8677262663841248, 0.8690732717514038, 0.8572198152542114, 0.8669180870056152, 0.8698814511299133, 0.8714978694915771, 0.8701508641242981, 0.8615301847457886, 0.8747305870056152, 0.8741918206214905, 0.8739224076271057, 0.8728448152542114, 0.8755387663841248, 0.8701508641242981, 0.8752694129943848, 0.8779633641242981, 0.8760775923728943, 0.884159505367279, 0.8714978694915771, 0.8653017282485962, 0.8604525923728943, 0.8644935488700867, 0.8623383641242981, 0.8701508641242981, 0.8696120977401733, 0.8830819129943848, 0.8741918206214905, 0.8855064511299133, 0.8755387663841248, 0.8825430870056152, 0.8828125, 0.876347005367279, 0.881465494632721, 0.8846982717514038, 0.8760775923728943, 0.881196141242981, 0.8798491358757019], 'val_loss': [0.8433734774589539, 0.8444932103157043, 0.7863665819168091, 0.8083829283714294, 0.8059648871421814, 0.7982157468795776, 0.7881985306739807, 0.7995843291282654, 0.771248996257782, 0.7861698269844055, 0.7530201077461243, 0.7667515873908997, 0.75053471326828, 0.7363693118095398, 0.7485976815223694, 0.7534961104393005, 0.7390339374542236, 0.7173342108726501, 0.7367361187934875, 0.7625584006309509, 0.8122831583023071, 0.7984086275100708, 0.7577491402626038, 0.8648488521575928, 0.811249315738678, 0.8179947137832642, 0.809551477432251, 0.9225469827651978, 0.8513520359992981, 0.9846689105033875, 0.8663856983184814, 0.8901234269142151, 0.8739770650863647, 0.8567405939102173, 0.8749514222145081, 0.9460682272911072, 0.9701063632965088, 0.8706943392753601, 0.8955847024917603, 0.8728944659233093, 0.8742820620536804, 0.9611254930496216, 0.8765561580657959, 0.8578373193740845, 0.9167030453681946, 0.924243688583374, 0.8453201651573181, 0.9085561037063599, 0.9246083498001099, 0.959347128868103, 0.9055744409561157, 1.0634732246398926, 0.9928112030029297, 0.9555731415748596, 0.9963093996047974, 1.0233476161956787, 0.961739718914032, 0.9820617437362671, 0.9226523041725159, 0.9622524380683899, 0.9306772947311401, 0.9518627524375916, 1.1482654809951782, 1.2105813026428223, 0.96230149269104, 1.0457755327224731, 0.9861786365509033, 0.9715010523796082, 1.0144095420837402, 1.125349521636963, 1.025838851928711, 0.9787347316741943, 0.979884684085846, 1.0155935287475586, 1.2416712045669556, 0.9954962730407715, 0.9753705263137817, 1.0331708192825317, 1.1218228340148926, 1.010361909866333, 0.9760148525238037, 1.0065311193466187, 0.9854960441589355, 1.0728553533554077, 1.0271387100219727, 1.1561119556427002, 1.470642328262329, 1.1435405015945435, 1.0125075578689575, 1.0319069623947144, 1.1981364488601685, 1.210814118385315, 1.0488759279251099, 1.0962876081466675, 1.0948762893676758, 1.1012771129608154, 1.1323269605636597, 1.0406895875930786, 1.0855906009674072, 1.0364667177200317], 'val_accuracy': [0.5290948152542114, 0.5334051847457886, 0.5646551847457886, 0.548491358757019, 0.5506465435028076, 0.556034505367279, 0.5775862336158752, 0.5657327771186829, 0.6023706793785095, 0.5915948152542114, 0.6400862336158752, 0.6217672228813171, 0.6778017282485962, 0.6659482717514038, 0.6670258641242981, 0.670258641242981, 0.6950430870056152, 0.7058189511299133, 0.6950430870056152, 0.6831896305084229, 0.670258641242981, 0.6767241358757019, 0.7284482717514038, 0.6681034564971924, 0.6961206793785095, 0.7133620977401733, 0.6961206793785095, 0.6756465435028076, 0.7112069129943848, 0.6584051847457886, 0.7209051847457886, 0.6896551847457886, 0.7058189511299133, 0.7273706793785095, 0.6961206793785095, 0.673491358757019, 0.6540948152542114, 0.7262930870056152, 0.704741358757019, 0.6982758641242981, 0.7144396305084229, 0.6853448152542114, 0.7144396305084229, 0.71875, 0.6961206793785095, 0.6907327771186829, 0.7262930870056152, 0.7101293206214905, 0.6821120977401733, 0.6918103694915771, 0.701508641242981, 0.662715494632721, 0.6745689511299133, 0.6896551847457886, 0.6713362336158752, 0.6713362336158752, 0.704741358757019, 0.6918103694915771, 0.7079741358757019, 0.693965494632721, 0.7198275923728943, 0.704741358757019, 0.6336206793785095, 0.6325430870056152, 0.693965494632721, 0.6907327771186829, 0.6928879022598267, 0.6982758641242981, 0.6831896305084229, 0.6724137663841248, 0.6907327771186829, 0.7068965435028076, 0.7133620977401733, 0.6950430870056152, 0.6293103694915771, 0.701508641242981, 0.7112069129943848, 0.6853448152542114, 0.6616379022598267, 0.6950430870056152, 0.704741358757019, 0.693965494632721, 0.6875, 0.6799569129943848, 0.7036637663841248, 0.6487069129943848, 0.5959051847457886, 0.6465517282485962, 0.701508641242981, 0.6971982717514038, 0.642241358757019, 0.6530172228813171, 0.6885775923728943, 0.6756465435028076, 0.6918103694915771, 0.6799569129943848, 0.6573275923728943, 0.6864224076271057, 0.6756465435028076, 0.6961206793785095]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","24/28 [========================>.....] - ETA: 0s - loss: 0.4951 - accuracy: 0.8148"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 7s 54ms/step - loss: 0.5056 - accuracy: 0.8090 - val_loss: 0.8372 - val_accuracy: 0.5271\n","Epoch 2/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4919 - accuracy: 0.8186 - val_loss: 0.8667 - val_accuracy: 0.5226\n","Epoch 3/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4813 - accuracy: 0.8254 - val_loss: 0.8339 - val_accuracy: 0.5351\n","Epoch 4/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4808 - accuracy: 0.8209 - val_loss: 0.8079 - val_accuracy: 0.5385\n","Epoch 5/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4758 - accuracy: 0.8277 - val_loss: 0.8373 - val_accuracy: 0.5407\n","Epoch 6/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4674 - accuracy: 0.8277 - val_loss: 0.8109 - val_accuracy: 0.5464\n","Epoch 7/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4649 - accuracy: 0.8316 - val_loss: 0.7719 - val_accuracy: 0.5667\n","Epoch 8/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4636 - accuracy: 0.8311 - val_loss: 0.7618 - val_accuracy: 0.5667\n","Epoch 9/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4605 - accuracy: 0.8345 - val_loss: 0.7534 - val_accuracy: 0.6018\n","Epoch 10/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.4667 - accuracy: 0.8285 - val_loss: 0.7276 - val_accuracy: 0.6278\n","Epoch 11/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4859 - accuracy: 0.8189 - val_loss: 0.7282 - val_accuracy: 0.6222\n","Epoch 12/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4530 - accuracy: 0.8379 - val_loss: 0.7124 - val_accuracy: 0.6618\n","Epoch 13/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4409 - accuracy: 0.8401 - val_loss: 0.6996 - val_accuracy: 0.6810\n","Epoch 14/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4544 - accuracy: 0.8390 - val_loss: 0.7016 - val_accuracy: 0.6787\n","Epoch 15/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4518 - accuracy: 0.8384 - val_loss: 0.6976 - val_accuracy: 0.6934\n","Epoch 16/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4437 - accuracy: 0.8381 - val_loss: 0.6843 - val_accuracy: 0.6799\n","Epoch 17/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4452 - accuracy: 0.8339 - val_loss: 0.6824 - val_accuracy: 0.7014\n","Epoch 18/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4496 - accuracy: 0.8410 - val_loss: 0.6739 - val_accuracy: 0.7048\n","Epoch 19/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4431 - accuracy: 0.8381 - val_loss: 0.6751 - val_accuracy: 0.6912\n","Epoch 20/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4425 - accuracy: 0.8424 - val_loss: 0.6723 - val_accuracy: 0.7002\n","Epoch 21/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4459 - accuracy: 0.8427 - val_loss: 0.7161 - val_accuracy: 0.6844\n","Epoch 22/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4416 - accuracy: 0.8466 - val_loss: 0.6794 - val_accuracy: 0.7059\n","Epoch 23/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4405 - accuracy: 0.8404 - val_loss: 0.6841 - val_accuracy: 0.7138\n","Epoch 24/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4382 - accuracy: 0.8480 - val_loss: 0.6796 - val_accuracy: 0.7183\n","Epoch 25/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4376 - accuracy: 0.8548 - val_loss: 0.7019 - val_accuracy: 0.7353\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4324 - accuracy: 0.8480 - val_loss: 0.7030 - val_accuracy: 0.7036\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4305 - accuracy: 0.8563 - val_loss: 0.7495 - val_accuracy: 0.7229\n","Epoch 28/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4372 - accuracy: 0.8407 - val_loss: 0.7235 - val_accuracy: 0.7240\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4295 - accuracy: 0.8529 - val_loss: 0.7395 - val_accuracy: 0.7330\n","Epoch 30/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4320 - accuracy: 0.8444 - val_loss: 0.7488 - val_accuracy: 0.7387\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4360 - accuracy: 0.8483 - val_loss: 0.7938 - val_accuracy: 0.7002\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4368 - accuracy: 0.8602 - val_loss: 0.7564 - val_accuracy: 0.7104\n","Epoch 33/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4350 - accuracy: 0.8438 - val_loss: 0.7383 - val_accuracy: 0.7262\n","Epoch 34/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4163 - accuracy: 0.8611 - val_loss: 0.7191 - val_accuracy: 0.7059\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4274 - accuracy: 0.8509 - val_loss: 0.7636 - val_accuracy: 0.7296\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4445 - accuracy: 0.8404 - val_loss: 0.8340 - val_accuracy: 0.6810\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4295 - accuracy: 0.8529 - val_loss: 0.7947 - val_accuracy: 0.7127\n","Epoch 38/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4211 - accuracy: 0.8565 - val_loss: 0.8490 - val_accuracy: 0.6968\n","Epoch 39/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4180 - accuracy: 0.8554 - val_loss: 0.7737 - val_accuracy: 0.7172\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4268 - accuracy: 0.8520 - val_loss: 0.7589 - val_accuracy: 0.7002\n","Epoch 41/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4273 - accuracy: 0.8517 - val_loss: 0.8408 - val_accuracy: 0.6991\n","Epoch 42/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4122 - accuracy: 0.8585 - val_loss: 0.8278 - val_accuracy: 0.6855\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4183 - accuracy: 0.8537 - val_loss: 0.7943 - val_accuracy: 0.6855\n","Epoch 44/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4058 - accuracy: 0.8605 - val_loss: 0.7609 - val_accuracy: 0.7240\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4022 - accuracy: 0.8687 - val_loss: 0.8030 - val_accuracy: 0.7229\n","Epoch 46/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4067 - accuracy: 0.8645 - val_loss: 0.8222 - val_accuracy: 0.7240\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4170 - accuracy: 0.8664 - val_loss: 0.8313 - val_accuracy: 0.7115\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4266 - accuracy: 0.8483 - val_loss: 0.8827 - val_accuracy: 0.7104\n","Epoch 49/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4167 - accuracy: 0.8543 - val_loss: 0.8543 - val_accuracy: 0.7036\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4071 - accuracy: 0.8698 - val_loss: 0.8932 - val_accuracy: 0.6946\n","Epoch 51/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3970 - accuracy: 0.8628 - val_loss: 0.8875 - val_accuracy: 0.6912\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4030 - accuracy: 0.8676 - val_loss: 0.7973 - val_accuracy: 0.7036\n","Epoch 53/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4199 - accuracy: 0.8540 - val_loss: 0.8043 - val_accuracy: 0.7195\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4040 - accuracy: 0.8577 - val_loss: 0.8878 - val_accuracy: 0.6957\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3978 - accuracy: 0.8738 - val_loss: 0.8342 - val_accuracy: 0.7149\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4009 - accuracy: 0.8659 - val_loss: 0.8103 - val_accuracy: 0.6900\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4120 - accuracy: 0.8585 - val_loss: 0.8005 - val_accuracy: 0.6980\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4054 - accuracy: 0.8588 - val_loss: 0.9564 - val_accuracy: 0.6652\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3936 - accuracy: 0.8727 - val_loss: 0.8195 - val_accuracy: 0.7070\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3918 - accuracy: 0.8775 - val_loss: 0.7840 - val_accuracy: 0.6946\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3916 - accuracy: 0.8724 - val_loss: 0.8223 - val_accuracy: 0.7002\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4020 - accuracy: 0.8681 - val_loss: 0.8651 - val_accuracy: 0.6991\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4169 - accuracy: 0.8633 - val_loss: 0.8696 - val_accuracy: 0.7127\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3949 - accuracy: 0.8679 - val_loss: 0.7936 - val_accuracy: 0.6968\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3950 - accuracy: 0.8707 - val_loss: 0.7850 - val_accuracy: 0.7149\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4099 - accuracy: 0.8608 - val_loss: 0.8920 - val_accuracy: 0.6980\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3963 - accuracy: 0.8636 - val_loss: 0.8518 - val_accuracy: 0.6923\n","Epoch 68/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3842 - accuracy: 0.8746 - val_loss: 0.8105 - val_accuracy: 0.7014\n","Epoch 69/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3853 - accuracy: 0.8679 - val_loss: 0.8571 - val_accuracy: 0.7104\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3945 - accuracy: 0.8701 - val_loss: 0.8302 - val_accuracy: 0.6991\n","Epoch 71/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3928 - accuracy: 0.8698 - val_loss: 0.8410 - val_accuracy: 0.7048\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3800 - accuracy: 0.8786 - val_loss: 0.8119 - val_accuracy: 0.7149\n","Epoch 73/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3824 - accuracy: 0.8761 - val_loss: 0.8252 - val_accuracy: 0.6957\n","Epoch 74/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3872 - accuracy: 0.8766 - val_loss: 0.8499 - val_accuracy: 0.6833\n","Epoch 75/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3782 - accuracy: 0.8763 - val_loss: 0.8546 - val_accuracy: 0.6991\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3815 - accuracy: 0.8786 - val_loss: 0.9564 - val_accuracy: 0.6708\n","Epoch 77/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3809 - accuracy: 0.8741 - val_loss: 0.8316 - val_accuracy: 0.7093\n","Epoch 78/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3632 - accuracy: 0.8826 - val_loss: 0.8475 - val_accuracy: 0.7048\n","Epoch 79/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3781 - accuracy: 0.8749 - val_loss: 0.8833 - val_accuracy: 0.6934\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3849 - accuracy: 0.8718 - val_loss: 0.8289 - val_accuracy: 0.7081\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3772 - accuracy: 0.8789 - val_loss: 0.9007 - val_accuracy: 0.6867\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3697 - accuracy: 0.8826 - val_loss: 0.8612 - val_accuracy: 0.7048\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3816 - accuracy: 0.8795 - val_loss: 1.0476 - val_accuracy: 0.6640\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3726 - accuracy: 0.8843 - val_loss: 0.8964 - val_accuracy: 0.6878\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3749 - accuracy: 0.8786 - val_loss: 0.8753 - val_accuracy: 0.7172\n","Epoch 86/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3686 - accuracy: 0.8837 - val_loss: 0.8592 - val_accuracy: 0.7070\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3720 - accuracy: 0.8800 - val_loss: 0.8690 - val_accuracy: 0.6968\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3802 - accuracy: 0.8755 - val_loss: 0.9309 - val_accuracy: 0.6923\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3752 - accuracy: 0.8744 - val_loss: 0.8582 - val_accuracy: 0.6833\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3581 - accuracy: 0.8857 - val_loss: 0.8577 - val_accuracy: 0.7048\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3708 - accuracy: 0.8780 - val_loss: 0.8343 - val_accuracy: 0.7115\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3646 - accuracy: 0.8846 - val_loss: 1.0002 - val_accuracy: 0.6686\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3704 - accuracy: 0.8868 - val_loss: 0.9131 - val_accuracy: 0.7138\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3708 - accuracy: 0.8831 - val_loss: 0.9344 - val_accuracy: 0.7081\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3693 - accuracy: 0.8792 - val_loss: 1.0068 - val_accuracy: 0.6674\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3675 - accuracy: 0.8851 - val_loss: 0.9712 - val_accuracy: 0.6810\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3633 - accuracy: 0.8843 - val_loss: 0.9134 - val_accuracy: 0.7115\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3443 - accuracy: 0.8987 - val_loss: 0.9176 - val_accuracy: 0.7138\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3670 - accuracy: 0.8846 - val_loss: 0.9287 - val_accuracy: 0.6968\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3612 - accuracy: 0.8829 - val_loss: 0.9622 - val_accuracy: 0.7070\n","{'loss': [0.5056231021881104, 0.4919191896915436, 0.4813475012779236, 0.48075857758522034, 0.4757542312145233, 0.46736589074134827, 0.4648503065109253, 0.4635660946369171, 0.4604593813419342, 0.4666997492313385, 0.4859442710876465, 0.4530366063117981, 0.4409114718437195, 0.45439237356185913, 0.4517735540866852, 0.44366583228111267, 0.44516319036483765, 0.44959014654159546, 0.44308748841285706, 0.44253024458885193, 0.4458919167518616, 0.4416215121746063, 0.4405081868171692, 0.43819573521614075, 0.4376186430454254, 0.4324154853820801, 0.4304867684841156, 0.4371728003025055, 0.42952781915664673, 0.43197765946388245, 0.4360354244709015, 0.43679279088974, 0.43503060936927795, 0.41626298427581787, 0.4274495244026184, 0.4445051848888397, 0.42952442169189453, 0.42106229066848755, 0.41802018880844116, 0.42681315541267395, 0.42734014987945557, 0.41216737031936646, 0.4183112382888794, 0.4057723581790924, 0.4021591544151306, 0.4066801071166992, 0.4169561564922333, 0.42657673358917236, 0.41671761870384216, 0.4070802330970764, 0.3970318138599396, 0.4029669165611267, 0.4198732376098633, 0.4040104150772095, 0.3977627158164978, 0.40086978673934937, 0.41199618577957153, 0.4053999185562134, 0.3936491906642914, 0.3918393850326538, 0.39161333441734314, 0.401996374130249, 0.4168841540813446, 0.3949415385723114, 0.3949880003929138, 0.4099411964416504, 0.39632001519203186, 0.3841750919818878, 0.38532790541648865, 0.39453038573265076, 0.3927667438983917, 0.38000553846359253, 0.38237619400024414, 0.38721519708633423, 0.3781644105911255, 0.3814839720726013, 0.38088324666023254, 0.3631550669670105, 0.3780902028083801, 0.3848755955696106, 0.37720489501953125, 0.36966001987457275, 0.38161855936050415, 0.37255018949508667, 0.37485960125923157, 0.3686237633228302, 0.3719896376132965, 0.38023537397384644, 0.3751998841762543, 0.3581125736236572, 0.3708212375640869, 0.364615261554718, 0.3704223334789276, 0.37077414989471436, 0.36929944157600403, 0.3674717843532562, 0.36333519220352173, 0.3443017303943634, 0.36704936623573303, 0.36120447516441345], 'accuracy': [0.8089982867240906, 0.8186191320419312, 0.8254103064537048, 0.8208828568458557, 0.8276740312576294, 0.8276740312576294, 0.8316355347633362, 0.8310695886611938, 0.8344652056694031, 0.8285229206085205, 0.8189020752906799, 0.8378607630729675, 0.8401244878768921, 0.8389926552772522, 0.8384267091751099, 0.8381437659263611, 0.8338992595672607, 0.8409733772277832, 0.8381437659263611, 0.8423882126808167, 0.8426712155342102, 0.846632719039917, 0.8404074907302856, 0.8480475544929504, 0.8548387289047241, 0.8480475544929504, 0.8562535643577576, 0.8406904339790344, 0.8528579473495483, 0.8443689942359924, 0.8483304977416992, 0.8602150678634644, 0.8438030481338501, 0.8610639572143555, 0.8508771657943726, 0.8404074907302856, 0.8528579473495483, 0.8565365076065063, 0.8554046154022217, 0.8520090579986572, 0.8517261147499084, 0.8585172891616821, 0.8537068367004395, 0.8604980111122131, 0.8687040209770203, 0.8644595146179199, 0.8664402961730957, 0.8483304977416992, 0.8542727828025818, 0.8698358535766602, 0.8627617359161377, 0.8675721287727356, 0.853989839553833, 0.8576683402061462, 0.8737974166870117, 0.8658743500709534, 0.8585172891616821, 0.8588002324104309, 0.872665524482727, 0.8774759769439697, 0.8723825812339783, 0.8681380748748779, 0.86332768201828, 0.8678551316261292, 0.870684802532196, 0.8607810139656067, 0.8636106252670288, 0.8746463060379028, 0.8678551316261292, 0.8701188564300537, 0.8698358535766602, 0.8786078095436096, 0.8760611414909363, 0.8766270279884338, 0.8763440847396851, 0.8786078095436096, 0.8740803599357605, 0.8825693130493164, 0.8749292492866516, 0.8718166351318359, 0.8788907527923584, 0.8825693130493164, 0.8794566988945007, 0.8842670917510986, 0.8786078095436096, 0.8837012052536011, 0.8800226449966431, 0.875495195388794, 0.8743633031845093, 0.8856819272041321, 0.8780418634414673, 0.8845500946044922, 0.8868138194084167, 0.8831352591514587, 0.879173755645752, 0.8851160407066345, 0.8842670917510986, 0.8986983299255371, 0.8845500946044922, 0.88285231590271], 'val_loss': [0.8372387290000916, 0.8666875958442688, 0.8339325785636902, 0.8079376816749573, 0.8373276591300964, 0.8109284043312073, 0.7718779444694519, 0.7617915868759155, 0.7534413933753967, 0.7275719046592712, 0.7282007336616516, 0.7124337553977966, 0.6995726227760315, 0.7016217708587646, 0.6975643038749695, 0.684334397315979, 0.6823974847793579, 0.6738935112953186, 0.6751142740249634, 0.6723416447639465, 0.7160946130752563, 0.6794444918632507, 0.684085488319397, 0.6796429753303528, 0.7019385695457458, 0.7030012607574463, 0.7495071887969971, 0.723524808883667, 0.7395205497741699, 0.7487801909446716, 0.7937943339347839, 0.7563852071762085, 0.7382981777191162, 0.7191084623336792, 0.763593316078186, 0.8339889049530029, 0.7947251796722412, 0.8489768505096436, 0.7737226486206055, 0.7589179277420044, 0.8407801389694214, 0.8278219699859619, 0.7943304181098938, 0.7608628869056702, 0.8029806017875671, 0.8222417235374451, 0.8313485980033875, 0.8827282190322876, 0.8542977571487427, 0.8931851387023926, 0.8874726891517639, 0.7973490357398987, 0.8043223023414612, 0.8877738118171692, 0.8342192769050598, 0.8103242516517639, 0.800457775592804, 0.9563850164413452, 0.8195033073425293, 0.7839609384536743, 0.8222936391830444, 0.8650888204574585, 0.8696229457855225, 0.7936170697212219, 0.7850409746170044, 0.8920336365699768, 0.8518251180648804, 0.8105440735816956, 0.8570534586906433, 0.83022540807724, 0.8409922122955322, 0.8119271993637085, 0.8251824975013733, 0.8499407172203064, 0.8545734286308289, 0.9564199447631836, 0.8316177725791931, 0.847504198551178, 0.8833255171775818, 0.8289234042167664, 0.9007135033607483, 0.8611834049224854, 1.0476319789886475, 0.8964307904243469, 0.8753296732902527, 0.8592323064804077, 0.868969738483429, 0.9309305548667908, 0.8582264184951782, 0.8577382564544678, 0.8343431353569031, 1.0002217292785645, 0.9131238460540771, 0.9344345927238464, 1.0067681074142456, 0.9712141752243042, 0.9134382009506226, 0.9176269173622131, 0.9287055730819702, 0.9622117877006531], 'val_accuracy': [0.5271493196487427, 0.5226244330406189, 0.5350678563117981, 0.5384615659713745, 0.540723979473114, 0.5463801026344299, 0.5667420625686646, 0.5667420625686646, 0.6018099784851074, 0.627828061580658, 0.622171938419342, 0.6617646813392639, 0.6809954643249512, 0.6787330508232117, 0.6934388875961304, 0.679864227771759, 0.7013574838638306, 0.7047511339187622, 0.6911764740943909, 0.7002262473106384, 0.6843891143798828, 0.7058823704719543, 0.7138009071350098, 0.7183257937431335, 0.7352941036224365, 0.7036198973655701, 0.7228506803512573, 0.7239819169044495, 0.733031690120697, 0.7386877536773682, 0.7002262473106384, 0.7104072570800781, 0.726244330406189, 0.7058823704719543, 0.7296379804611206, 0.6809954643249512, 0.7126696705818176, 0.6968325972557068, 0.7171945571899414, 0.7002262473106384, 0.6990950107574463, 0.685520350933075, 0.685520350933075, 0.7239819169044495, 0.7228506803512573, 0.7239819169044495, 0.7115384340286255, 0.7104072570800781, 0.7036198973655701, 0.6945701241493225, 0.6911764740943909, 0.7036198973655701, 0.7194570302963257, 0.6957013607025146, 0.7149321436882019, 0.6900452375411987, 0.6979637742042542, 0.6651583909988403, 0.7070135474205017, 0.6945701241493225, 0.7002262473106384, 0.6990950107574463, 0.7126696705818176, 0.6968325972557068, 0.7149321436882019, 0.6979637742042542, 0.692307710647583, 0.7013574838638306, 0.7104072570800781, 0.6990950107574463, 0.7047511339187622, 0.7149321436882019, 0.6957013607025146, 0.6832579374313354, 0.6990950107574463, 0.6708144545555115, 0.709276020526886, 0.7047511339187622, 0.6934388875961304, 0.7081447839736938, 0.6866515874862671, 0.7047511339187622, 0.6640271544456482, 0.6877828240394592, 0.7171945571899414, 0.7070135474205017, 0.6968325972557068, 0.692307710647583, 0.6832579374313354, 0.7047511339187622, 0.7115384340286255, 0.668552041053772, 0.7138009071350098, 0.7081447839736938, 0.6674208045005798, 0.6809954643249512, 0.7115384340286255, 0.7138009071350098, 0.6968325972557068, 0.7070135474205017]}\n","45/45 [==============================] - 2s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/31 [=========================>....] - ETA: 0s - loss: 0.5139 - accuracy: 0.7972"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 47ms/step - loss: 0.5185 - accuracy: 0.7961 - val_loss: 0.8245 - val_accuracy: 0.5362\n","Epoch 2/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5110 - accuracy: 0.7997 - val_loss: 0.8777 - val_accuracy: 0.5320\n","Epoch 3/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5007 - accuracy: 0.8101 - val_loss: 0.8301 - val_accuracy: 0.5362\n","Epoch 4/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4904 - accuracy: 0.8142 - val_loss: 0.8175 - val_accuracy: 0.5413\n","Epoch 5/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4929 - accuracy: 0.8090 - val_loss: 0.7712 - val_accuracy: 0.5723\n","Epoch 6/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4781 - accuracy: 0.8178 - val_loss: 0.7758 - val_accuracy: 0.5630\n","Epoch 7/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4804 - accuracy: 0.8209 - val_loss: 0.7638 - val_accuracy: 0.5899\n","Epoch 8/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4756 - accuracy: 0.8196 - val_loss: 0.7727 - val_accuracy: 0.5733\n","Epoch 9/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4881 - accuracy: 0.8171 - val_loss: 0.7738 - val_accuracy: 0.5764\n","Epoch 10/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4808 - accuracy: 0.8152 - val_loss: 0.7600 - val_accuracy: 0.5971\n","Epoch 11/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4828 - accuracy: 0.8147 - val_loss: 0.7447 - val_accuracy: 0.6281\n","Epoch 12/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4859 - accuracy: 0.8065 - val_loss: 0.7414 - val_accuracy: 0.6395\n","Epoch 13/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4860 - accuracy: 0.8101 - val_loss: 0.7432 - val_accuracy: 0.6498\n","Epoch 14/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4725 - accuracy: 0.8217 - val_loss: 0.7482 - val_accuracy: 0.6353\n","Epoch 15/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4656 - accuracy: 0.8279 - val_loss: 0.7461 - val_accuracy: 0.6395\n","Epoch 16/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4650 - accuracy: 0.8279 - val_loss: 0.7350 - val_accuracy: 0.6519\n","Epoch 17/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4687 - accuracy: 0.8313 - val_loss: 0.7423 - val_accuracy: 0.6591\n","Epoch 18/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4555 - accuracy: 0.8370 - val_loss: 0.7647 - val_accuracy: 0.6384\n","Epoch 19/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4706 - accuracy: 0.8253 - val_loss: 0.7887 - val_accuracy: 0.6395\n","Epoch 20/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4649 - accuracy: 0.8300 - val_loss: 0.7526 - val_accuracy: 0.6849\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4739 - accuracy: 0.8165 - val_loss: 0.8552 - val_accuracy: 0.6281\n","Epoch 22/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4687 - accuracy: 0.8222 - val_loss: 0.9398 - val_accuracy: 0.6095\n","Epoch 23/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4671 - accuracy: 0.8261 - val_loss: 0.8499 - val_accuracy: 0.6498\n","Epoch 24/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4595 - accuracy: 0.8253 - val_loss: 0.8841 - val_accuracy: 0.6364\n","Epoch 25/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4695 - accuracy: 0.8258 - val_loss: 0.8008 - val_accuracy: 0.6983\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4509 - accuracy: 0.8367 - val_loss: 0.8851 - val_accuracy: 0.6715\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4548 - accuracy: 0.8331 - val_loss: 0.8381 - val_accuracy: 0.6921\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4562 - accuracy: 0.8349 - val_loss: 0.9115 - val_accuracy: 0.6529\n","Epoch 29/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4535 - accuracy: 0.8320 - val_loss: 0.8189 - val_accuracy: 0.6798\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4471 - accuracy: 0.8315 - val_loss: 0.8547 - val_accuracy: 0.6725\n","Epoch 31/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4657 - accuracy: 0.8256 - val_loss: 0.8900 - val_accuracy: 0.6829\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4678 - accuracy: 0.8274 - val_loss: 0.8582 - val_accuracy: 0.6890\n","Epoch 33/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4504 - accuracy: 0.8349 - val_loss: 0.8806 - val_accuracy: 0.6839\n","Epoch 34/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4503 - accuracy: 0.8320 - val_loss: 0.9911 - val_accuracy: 0.6457\n","Epoch 35/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4449 - accuracy: 0.8359 - val_loss: 0.9821 - val_accuracy: 0.6415\n","Epoch 36/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4495 - accuracy: 0.8346 - val_loss: 0.9206 - val_accuracy: 0.6767\n","Epoch 37/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4468 - accuracy: 0.8359 - val_loss: 0.9276 - val_accuracy: 0.6839\n","Epoch 38/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4580 - accuracy: 0.8289 - val_loss: 1.1748 - val_accuracy: 0.6105\n","Epoch 39/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4588 - accuracy: 0.8271 - val_loss: 0.8757 - val_accuracy: 0.6787\n","Epoch 40/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4549 - accuracy: 0.8344 - val_loss: 0.8906 - val_accuracy: 0.6808\n","Epoch 41/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4375 - accuracy: 0.8444 - val_loss: 0.8869 - val_accuracy: 0.6870\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4394 - accuracy: 0.8463 - val_loss: 0.8886 - val_accuracy: 0.6870\n","Epoch 43/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4366 - accuracy: 0.8447 - val_loss: 1.0327 - val_accuracy: 0.6952\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4490 - accuracy: 0.8354 - val_loss: 0.9559 - val_accuracy: 0.6715\n","Epoch 45/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4413 - accuracy: 0.8421 - val_loss: 1.0044 - val_accuracy: 0.6880\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4415 - accuracy: 0.8372 - val_loss: 0.9664 - val_accuracy: 0.6787\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4344 - accuracy: 0.8447 - val_loss: 0.9892 - val_accuracy: 0.6395\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4288 - accuracy: 0.8486 - val_loss: 0.9616 - val_accuracy: 0.6694\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4247 - accuracy: 0.8527 - val_loss: 1.0163 - val_accuracy: 0.6890\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4399 - accuracy: 0.8424 - val_loss: 0.9648 - val_accuracy: 0.6829\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4243 - accuracy: 0.8522 - val_loss: 1.0165 - val_accuracy: 0.6839\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4271 - accuracy: 0.8434 - val_loss: 0.9255 - val_accuracy: 0.6725\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4284 - accuracy: 0.8475 - val_loss: 0.9084 - val_accuracy: 0.6870\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4257 - accuracy: 0.8491 - val_loss: 0.9374 - val_accuracy: 0.6798\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4261 - accuracy: 0.8470 - val_loss: 1.0234 - val_accuracy: 0.6818\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4254 - accuracy: 0.8419 - val_loss: 0.9881 - val_accuracy: 0.6632\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4242 - accuracy: 0.8494 - val_loss: 0.9659 - val_accuracy: 0.6715\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4186 - accuracy: 0.8537 - val_loss: 1.0909 - val_accuracy: 0.6374\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4183 - accuracy: 0.8486 - val_loss: 0.9687 - val_accuracy: 0.6767\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4128 - accuracy: 0.8514 - val_loss: 0.9824 - val_accuracy: 0.6694\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4253 - accuracy: 0.8486 - val_loss: 1.0121 - val_accuracy: 0.6539\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4263 - accuracy: 0.8530 - val_loss: 1.0327 - val_accuracy: 0.6694\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4131 - accuracy: 0.8584 - val_loss: 0.9450 - val_accuracy: 0.6705\n","Epoch 64/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4208 - accuracy: 0.8545 - val_loss: 1.1991 - val_accuracy: 0.6322\n","Epoch 65/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4348 - accuracy: 0.8447 - val_loss: 1.0929 - val_accuracy: 0.6477\n","Epoch 66/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4180 - accuracy: 0.8540 - val_loss: 1.1113 - val_accuracy: 0.6467\n","Epoch 67/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4220 - accuracy: 0.8504 - val_loss: 0.9041 - val_accuracy: 0.6767\n","Epoch 68/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4203 - accuracy: 0.8576 - val_loss: 0.9385 - val_accuracy: 0.6663\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4174 - accuracy: 0.8579 - val_loss: 1.0927 - val_accuracy: 0.6560\n","Epoch 70/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4051 - accuracy: 0.8618 - val_loss: 0.9718 - val_accuracy: 0.6767\n","Epoch 71/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4165 - accuracy: 0.8543 - val_loss: 1.1134 - val_accuracy: 0.6839\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4286 - accuracy: 0.8496 - val_loss: 1.0434 - val_accuracy: 0.6622\n","Epoch 73/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4126 - accuracy: 0.8556 - val_loss: 1.0903 - val_accuracy: 0.6467\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3981 - accuracy: 0.8587 - val_loss: 1.0376 - val_accuracy: 0.6777\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4054 - accuracy: 0.8594 - val_loss: 1.0061 - val_accuracy: 0.6808\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4000 - accuracy: 0.8602 - val_loss: 0.9992 - val_accuracy: 0.6715\n","Epoch 77/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3974 - accuracy: 0.8589 - val_loss: 0.9753 - val_accuracy: 0.6622\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4136 - accuracy: 0.8496 - val_loss: 1.0040 - val_accuracy: 0.6705\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4083 - accuracy: 0.8550 - val_loss: 1.1754 - val_accuracy: 0.6467\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4141 - accuracy: 0.8530 - val_loss: 1.3222 - val_accuracy: 0.5981\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4139 - accuracy: 0.8628 - val_loss: 1.0238 - val_accuracy: 0.6694\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4007 - accuracy: 0.8649 - val_loss: 1.0880 - val_accuracy: 0.6694\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3973 - accuracy: 0.8527 - val_loss: 1.1073 - val_accuracy: 0.6622\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4041 - accuracy: 0.8625 - val_loss: 0.9571 - val_accuracy: 0.6632\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3963 - accuracy: 0.8610 - val_loss: 1.1200 - val_accuracy: 0.6705\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3978 - accuracy: 0.8630 - val_loss: 1.0887 - val_accuracy: 0.6715\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3959 - accuracy: 0.8680 - val_loss: 1.1497 - val_accuracy: 0.6653\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3982 - accuracy: 0.8630 - val_loss: 0.9884 - val_accuracy: 0.6777\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3918 - accuracy: 0.8667 - val_loss: 1.0195 - val_accuracy: 0.6663\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4011 - accuracy: 0.8687 - val_loss: 1.1296 - val_accuracy: 0.6591\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3880 - accuracy: 0.8659 - val_loss: 1.2560 - val_accuracy: 0.6198\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3937 - accuracy: 0.8641 - val_loss: 1.0477 - val_accuracy: 0.6643\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3919 - accuracy: 0.8615 - val_loss: 1.0881 - val_accuracy: 0.6756\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3832 - accuracy: 0.8695 - val_loss: 0.9812 - val_accuracy: 0.6601\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4048 - accuracy: 0.8643 - val_loss: 1.0342 - val_accuracy: 0.6746\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4085 - accuracy: 0.8664 - val_loss: 1.0921 - val_accuracy: 0.6705\n","Epoch 97/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4009 - accuracy: 0.8654 - val_loss: 1.1478 - val_accuracy: 0.6539\n","Epoch 98/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4041 - accuracy: 0.8649 - val_loss: 1.0620 - val_accuracy: 0.6612\n","Epoch 99/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3798 - accuracy: 0.8656 - val_loss: 1.1215 - val_accuracy: 0.6705\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3790 - accuracy: 0.8755 - val_loss: 1.0667 - val_accuracy: 0.6622\n","{'loss': [0.5185090899467468, 0.510955274105072, 0.5007431507110596, 0.4903939664363861, 0.4928697943687439, 0.47813695669174194, 0.4803907573223114, 0.47559940814971924, 0.48813915252685547, 0.4807659089565277, 0.4827924966812134, 0.48587125539779663, 0.48597317934036255, 0.47253820300102234, 0.4656297564506531, 0.4649507999420166, 0.46872901916503906, 0.4555032551288605, 0.47055670619010925, 0.4649178087711334, 0.47394853830337524, 0.4686935842037201, 0.46708786487579346, 0.4595140814781189, 0.46946465969085693, 0.450927197933197, 0.45482251048088074, 0.4561885595321655, 0.4535296857357025, 0.4471382796764374, 0.46568724513053894, 0.46778228878974915, 0.4504361152648926, 0.45032721757888794, 0.44486990571022034, 0.4494999945163727, 0.44679614901542664, 0.4579640030860901, 0.4588121473789215, 0.45491936802864075, 0.43754786252975464, 0.4394002854824066, 0.43658435344696045, 0.4489786922931671, 0.4413171112537384, 0.4415152668952942, 0.4344283938407898, 0.4288233816623688, 0.4247474670410156, 0.4399307668209076, 0.424307644367218, 0.4270583391189575, 0.4284469783306122, 0.4256976544857025, 0.4261431097984314, 0.42543503642082214, 0.42419740557670593, 0.4185890257358551, 0.4182564318180084, 0.4128205180168152, 0.4253261685371399, 0.42633017897605896, 0.41307705640792847, 0.42076680064201355, 0.43480759859085083, 0.4179844260215759, 0.4220351278781891, 0.42033424973487854, 0.41738373041152954, 0.4051087200641632, 0.41650015115737915, 0.4286228120326996, 0.412553071975708, 0.3980930745601654, 0.4053924083709717, 0.39998722076416016, 0.3973826467990875, 0.4135730564594269, 0.40826699137687683, 0.4140627980232239, 0.41387853026390076, 0.40073126554489136, 0.397251158952713, 0.40406590700149536, 0.3962695896625519, 0.3977735638618469, 0.39587122201919556, 0.3981758654117584, 0.39175188541412354, 0.40107572078704834, 0.3879639208316803, 0.3937400281429291, 0.39189666509628296, 0.38323044776916504, 0.4047713577747345, 0.4085117280483246, 0.4008617103099823, 0.4040507972240448, 0.3797796070575714, 0.37902045249938965], 'accuracy': [0.7961240410804749, 0.7997416257858276, 0.8100775480270386, 0.814211905002594, 0.8090439438819885, 0.817829430103302, 0.8209302425384521, 0.8196382522583008, 0.817054271697998, 0.8152454495429993, 0.8147286772727966, 0.8064599633216858, 0.8100775480270386, 0.8217054009437561, 0.8279069662094116, 0.8279069662094116, 0.8312661647796631, 0.8369508981704712, 0.8253229856491089, 0.8299741744995117, 0.8165374398231506, 0.8222222328186035, 0.8260982036590576, 0.8253229856491089, 0.8258398175239563, 0.8366925120353699, 0.8330749273300171, 0.8348837494850159, 0.832041323184967, 0.8315245509147644, 0.8255813717842102, 0.827390193939209, 0.8348837494850159, 0.832041323184967, 0.8359172940254211, 0.8346253037452698, 0.8359172940254211, 0.8289405703544617, 0.8271318078041077, 0.8343669176101685, 0.8444444537162781, 0.8462532162666321, 0.8447028398513794, 0.8354005217552185, 0.8421188592910767, 0.8372092843055725, 0.8447028398513794, 0.8485788106918335, 0.8527131676673889, 0.842377245426178, 0.8521963953971863, 0.843410849571228, 0.8475452065467834, 0.8490955829620361, 0.8470284342765808, 0.8418604731559753, 0.8493540287017822, 0.853746771812439, 0.8485788106918335, 0.8514211773872375, 0.8485788106918335, 0.8529715538024902, 0.8583979606628418, 0.8545219898223877, 0.8447028398513794, 0.8540051579475403, 0.8503875732421875, 0.8576227426528931, 0.8578811287879944, 0.8617570996284485, 0.8542635440826416, 0.8496124148368835, 0.855555534362793, 0.8586563467979431, 0.8594315052032471, 0.8602067232131958, 0.8589147329330444, 0.8496124148368835, 0.8550387620925903, 0.8529715538024902, 0.8627907037734985, 0.8648578524589539, 0.8527131676673889, 0.8625323176383972, 0.8609819412231445, 0.8630490899085999, 0.867958664894104, 0.8630490899085999, 0.8666666746139526, 0.868733823299408, 0.8658914566040039, 0.8640826940536499, 0.8614987134933472, 0.8695090413093567, 0.8643410801887512, 0.8664082884788513, 0.8653746843338013, 0.8648578524589539, 0.8656330704689026, 0.8754522204399109], 'val_loss': [0.8245288729667664, 0.8777482509613037, 0.8300682902336121, 0.8175078630447388, 0.7711614966392517, 0.7758130431175232, 0.7638429999351501, 0.7726877331733704, 0.7737536430358887, 0.7600145936012268, 0.7447482943534851, 0.7413713335990906, 0.7431785464286804, 0.7481599450111389, 0.7461066246032715, 0.7350046038627625, 0.7423295378684998, 0.7646540999412537, 0.7887370586395264, 0.7526308298110962, 0.8552103042602539, 0.9397938847541809, 0.8498553037643433, 0.8841235041618347, 0.8008314967155457, 0.8850795030593872, 0.8380687832832336, 0.9115033745765686, 0.8188890218734741, 0.8546792268753052, 0.8900490403175354, 0.8582020998001099, 0.8805835843086243, 0.9911371469497681, 0.98210209608078, 0.9205775856971741, 0.9276013374328613, 1.1747987270355225, 0.8757141828536987, 0.8906311392784119, 0.8868802785873413, 0.8886404633522034, 1.0327461957931519, 0.955919086933136, 1.004446029663086, 0.9664105772972107, 0.9892336130142212, 0.9616408348083496, 1.0163270235061646, 0.9648182988166809, 1.01654851436615, 0.925471305847168, 0.9084402918815613, 0.9374169111251831, 1.0234310626983643, 0.9880513548851013, 0.9658870100975037, 1.0909007787704468, 0.9687075018882751, 0.9823911786079407, 1.0120823383331299, 1.032723307609558, 0.9449605345726013, 1.1991137266159058, 1.0928715467453003, 1.1113131046295166, 0.9040658473968506, 0.9385249018669128, 1.0926940441131592, 0.971761167049408, 1.1134042739868164, 1.043439269065857, 1.0903398990631104, 1.0376068353652954, 1.0060685873031616, 0.9991904497146606, 0.9752951264381409, 1.003995656967163, 1.1753778457641602, 1.3222249746322632, 1.0237611532211304, 1.087975025177002, 1.107291340827942, 0.9570918679237366, 1.1200227737426758, 1.088735580444336, 1.1496760845184326, 0.988359808921814, 1.0194510221481323, 1.129647970199585, 1.2560495138168335, 1.0477358102798462, 1.0881270170211792, 0.9811667203903198, 1.0342419147491455, 1.0921295881271362, 1.1477546691894531, 1.0619676113128662, 1.1215358972549438, 1.0666865110397339], 'val_accuracy': [0.5361570119857788, 0.5320248007774353, 0.5361570119857788, 0.5413222908973694, 0.5723140239715576, 0.5630165338516235, 0.5898760557174683, 0.5733470916748047, 0.5764462947845459, 0.5971074104309082, 0.6280992031097412, 0.6394628286361694, 0.6497933864593506, 0.6353305578231812, 0.6394628286361694, 0.6518595218658447, 0.6590909361839294, 0.6384297609329224, 0.6394628286361694, 0.6849173307418823, 0.6280992031097412, 0.6095041036605835, 0.6497933864593506, 0.6363636255264282, 0.6983470916748047, 0.6714876294136047, 0.692148745059967, 0.6528925895690918, 0.6797520518302917, 0.672520637512207, 0.682851254940033, 0.6890496015548706, 0.68388432264328, 0.6456611752510071, 0.6415289044380188, 0.6766529083251953, 0.68388432264328, 0.6105371713638306, 0.6787189841270447, 0.6807851195335388, 0.6869834661483765, 0.6869834661483765, 0.6952479481697083, 0.6714876294136047, 0.6880165338516235, 0.6787189841270447, 0.6394628286361694, 0.6694214940071106, 0.6890496015548706, 0.682851254940033, 0.68388432264328, 0.672520637512207, 0.6869834661483765, 0.6797520518302917, 0.6818181872367859, 0.663223147392273, 0.6714876294136047, 0.6373966932296753, 0.6766529083251953, 0.6694214940071106, 0.6539255976676941, 0.6694214940071106, 0.6704545617103577, 0.6322314143180847, 0.6477272510528564, 0.6466942429542542, 0.6766529083251953, 0.6663222908973694, 0.6559917330741882, 0.6766529083251953, 0.68388432264328, 0.6621900796890259, 0.6466942429542542, 0.6776859760284424, 0.6807851195335388, 0.6714876294136047, 0.6621900796890259, 0.6704545617103577, 0.6466942429542542, 0.5981404781341553, 0.6694214940071106, 0.6694214940071106, 0.6621900796890259, 0.663223147392273, 0.6704545617103577, 0.6714876294136047, 0.6652892827987671, 0.6776859760284424, 0.6663222908973694, 0.6590909361839294, 0.6198347210884094, 0.66425621509552, 0.6756198406219482, 0.6601239442825317, 0.6745867729187012, 0.6704545617103577, 0.6539255976676941, 0.6611570119857788, 0.6704545617103577, 0.6621900796890259]}\n","32/32 [==============================] - 1s 3ms/step\n"]}],"source":["global_model_gru, metrics_df_gru = federated_learning_gru(Theta_data)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"id":"FBEatZ972lN_","executionInfo":{"status":"ok","timestamp":1717437331521,"user_tz":-360,"elapsed":34,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}},"outputId":"abcba719-9882-4548-886b-9b755513d099"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision    Recall        F1  Sensitivity  Specificity  \\\n","0        0  0.549414   0.577023  0.370184  0.451020     0.370184     0.728643   \n","1        1  0.552260   0.580786  0.375706  0.456261     0.375706     0.728814   \n","2        2  0.540161   0.547847  0.459839  0.500000     0.459839     0.620482   \n","3        0  0.564489   0.581741  0.458961  0.513109     0.458961     0.670017   \n","4        1  0.560028   0.596811  0.370056  0.456844     0.370056     0.750000   \n","5        2  0.592369   0.621693  0.471888  0.536530     0.471888     0.712851   \n","6        0  0.596315   0.632184  0.460637  0.532946     0.460637     0.731993   \n","7        1  0.600989   0.676543  0.387006  0.492363     0.387006     0.814972   \n","8        2  0.646586   0.707386  0.500000  0.585882     0.500000     0.793173   \n","9        0  0.624791   0.620746  0.641541  0.630972     0.641541     0.608040   \n","10       1  0.646186   0.675127  0.563559  0.614319     0.563559     0.728814   \n","11       2  0.691767   0.706263  0.656627  0.680541     0.656627     0.726908   \n","12       0  0.665829   0.646884  0.730318  0.686074     0.730318     0.601340   \n","13       1  0.692797   0.746835  0.583333  0.655036     0.583333     0.802260   \n","14       2  0.716867   0.714286  0.722892  0.718563     0.722892     0.710843   \n","\n","       Kappa  \n","0   0.098827  \n","1   0.104520  \n","2   0.080321  \n","3   0.128978  \n","4   0.120056  \n","5   0.184739  \n","6   0.192630  \n","7   0.201977  \n","8   0.293173  \n","9   0.249581  \n","10  0.292373  \n","11  0.383534  \n","12  0.331658  \n","13  0.385593  \n","14  0.433735  "],"text/html":["\n","  <div id=\"df-0d47bb6f-f29f-4979-a5fe-43ad1ff3f239\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.549414</td>\n","      <td>0.577023</td>\n","      <td>0.370184</td>\n","      <td>0.451020</td>\n","      <td>0.370184</td>\n","      <td>0.728643</td>\n","      <td>0.098827</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.552260</td>\n","      <td>0.580786</td>\n","      <td>0.375706</td>\n","      <td>0.456261</td>\n","      <td>0.375706</td>\n","      <td>0.728814</td>\n","      <td>0.104520</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.540161</td>\n","      <td>0.547847</td>\n","      <td>0.459839</td>\n","      <td>0.500000</td>\n","      <td>0.459839</td>\n","      <td>0.620482</td>\n","      <td>0.080321</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.564489</td>\n","      <td>0.581741</td>\n","      <td>0.458961</td>\n","      <td>0.513109</td>\n","      <td>0.458961</td>\n","      <td>0.670017</td>\n","      <td>0.128978</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.560028</td>\n","      <td>0.596811</td>\n","      <td>0.370056</td>\n","      <td>0.456844</td>\n","      <td>0.370056</td>\n","      <td>0.750000</td>\n","      <td>0.120056</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.592369</td>\n","      <td>0.621693</td>\n","      <td>0.471888</td>\n","      <td>0.536530</td>\n","      <td>0.471888</td>\n","      <td>0.712851</td>\n","      <td>0.184739</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.596315</td>\n","      <td>0.632184</td>\n","      <td>0.460637</td>\n","      <td>0.532946</td>\n","      <td>0.460637</td>\n","      <td>0.731993</td>\n","      <td>0.192630</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.600989</td>\n","      <td>0.676543</td>\n","      <td>0.387006</td>\n","      <td>0.492363</td>\n","      <td>0.387006</td>\n","      <td>0.814972</td>\n","      <td>0.201977</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.646586</td>\n","      <td>0.707386</td>\n","      <td>0.500000</td>\n","      <td>0.585882</td>\n","      <td>0.500000</td>\n","      <td>0.793173</td>\n","      <td>0.293173</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.624791</td>\n","      <td>0.620746</td>\n","      <td>0.641541</td>\n","      <td>0.630972</td>\n","      <td>0.641541</td>\n","      <td>0.608040</td>\n","      <td>0.249581</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.646186</td>\n","      <td>0.675127</td>\n","      <td>0.563559</td>\n","      <td>0.614319</td>\n","      <td>0.563559</td>\n","      <td>0.728814</td>\n","      <td>0.292373</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.691767</td>\n","      <td>0.706263</td>\n","      <td>0.656627</td>\n","      <td>0.680541</td>\n","      <td>0.656627</td>\n","      <td>0.726908</td>\n","      <td>0.383534</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.665829</td>\n","      <td>0.646884</td>\n","      <td>0.730318</td>\n","      <td>0.686074</td>\n","      <td>0.730318</td>\n","      <td>0.601340</td>\n","      <td>0.331658</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.692797</td>\n","      <td>0.746835</td>\n","      <td>0.583333</td>\n","      <td>0.655036</td>\n","      <td>0.583333</td>\n","      <td>0.802260</td>\n","      <td>0.385593</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.716867</td>\n","      <td>0.714286</td>\n","      <td>0.722892</td>\n","      <td>0.718563</td>\n","      <td>0.722892</td>\n","      <td>0.710843</td>\n","      <td>0.433735</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d47bb6f-f29f-4979-a5fe-43ad1ff3f239')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0d47bb6f-f29f-4979-a5fe-43ad1ff3f239 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0d47bb6f-f29f-4979-a5fe-43ad1ff3f239');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b419788c-a972-41ab-9282-841ecf91442a\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b419788c-a972-41ab-9282-841ecf91442a')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b419788c-a972-41ab-9282-841ecf91442a button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_8feaf843-3cd8-43e2-b1e9-150bde881222\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('metrics_df_gru')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_8feaf843-3cd8-43e2-b1e9-150bde881222 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('metrics_df_gru');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"metrics_df_gru","summary":"{\n  \"name\": \"metrics_df_gru\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05820230958769734,\n        \"min\": 0.5401606425702812,\n        \"max\": 0.7168674698795181,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.6247906197654941,\n          0.6917670682730924,\n          0.5494137353433836\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.060001561065803205,\n        \"min\": 0.5478468899521531,\n        \"max\": 0.7468354430379747,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.6207455429497569,\n          0.7062634989200864,\n          0.577023498694517\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.125816202203669,\n        \"min\": 0.3700564971751412,\n        \"max\": 0.7303182579564489,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.6415410385259631,\n          0.6566265060240963,\n          0.37018425460636517\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09156524572094919,\n        \"min\": 0.4510204081632653,\n        \"max\": 0.718562874251497,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.6309719934102141,\n          0.6805411030176899,\n          0.4510204081632653\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.125816202203669,\n        \"min\": 0.3700564971751412,\n        \"max\": 0.7303182579564489,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.6415410385259631,\n          0.6566265060240963,\n          0.37018425460636517\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06615988759969443,\n        \"min\": 0.6013400335008375,\n        \"max\": 0.8149717514124294,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.6080402010050251,\n          0.6013400335008375,\n          0.7286432160804021\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11640461917539466,\n        \"min\": 0.08032128514056225,\n        \"max\": 0.4337349397590361,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.24958123953098832,\n          0.38353413654618473,\n          0.09882747068676712\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":17}],"source":["metrics_df_gru"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"JrpiIQ-42neY","executionInfo":{"status":"ok","timestamp":1717437331523,"user_tz":-360,"elapsed":16,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}}},"outputs":[],"source":["metrics_df_gru.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Frequency Domain/GRU/Delta_frequency_gru.csv', index = False)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"collapsed_sections":["6DhAYwXUSE9z","-JYOb1ECSWiK"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}