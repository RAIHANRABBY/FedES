{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Mbfw8uvdftFM"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"INiFJfLjgOkx"},"outputs":[],"source":["from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lYo2Uq77gQSH"},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import ExtraTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score, cross_val_predict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g66575_xgVzz"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPool1D, Flatten, Dropout,LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33476,"status":"ok","timestamp":1717399227050,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"},"user_tz":-360},"id":"MOCNWlamfr3v","outputId":"386f1dac-8300-40a0-cfe9-98a6e0132862"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iNy9eOGMf2qO"},"outputs":[],"source":["# Raw_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/only data/raw_data.npz'\n","\n","Theta_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/feature domain/frequency_domain_data.npz'\n","\n","\n","\n","# RAW = np.load(Raw_data, allow_pickle=True)  # Allow loading pickled object arrays\n","# X = RAW['X'].astype('float64')\n","# Y = RAW['Y'].astype('float64')\n","# group = RAW['Group'].astype('float64')"]},{"cell_type":"markdown","metadata":{"id":"PzeABzSyHgKg"},"source":["This is a good performing model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Os2jd5SO1jf"},"outputs":[],"source":["# %%capture\n","# !pip install wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tbr8rHq9PnM4"},"outputs":[],"source":["# import wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iwbCosHcPohF"},"outputs":[],"source":["# !wandb login"]},{"cell_type":"markdown","metadata":{"id":"6DhAYwXUSE9z"},"source":["# CNN-LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VvjC2xCQNHLP"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(LSTM(256, return_sequences=True))\n","    model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dense(32, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_callback = ModelCheckpoint(\n","                f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Total/best_model_{run_name}.h5',\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Total/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Evaluate client model\n","            y_pred = (client_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVURUnmYNNNg","outputId":"497fa23c-16d2-4bba-81ef-6838fa889a99","executionInfo":{"status":"ok","timestamp":1716751864182,"user_tz":-360,"elapsed":1200019,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.6929 - accuracy: 0.5751"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 15s 57ms/step - loss: 0.6929 - accuracy: 0.5859 - val_loss: 0.6931 - val_accuracy: 0.5172\n","Epoch 2/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6915 - accuracy: 0.7131 - val_loss: 0.6929 - val_accuracy: 0.5905\n","Epoch 3/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6880 - accuracy: 0.7206 - val_loss: 0.6924 - val_accuracy: 0.5916\n","Epoch 4/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6801 - accuracy: 0.7328 - val_loss: 0.6912 - val_accuracy: 0.6756\n","Epoch 5/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.6644 - accuracy: 0.7419 - val_loss: 0.6885 - val_accuracy: 0.7284\n","Epoch 6/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6347 - accuracy: 0.7390 - val_loss: 0.6826 - val_accuracy: 0.7446\n","Epoch 7/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5901 - accuracy: 0.7425 - val_loss: 0.6726 - val_accuracy: 0.7338\n","Epoch 8/100\n","29/29 [==============================] - 2s 53ms/step - loss: 0.5512 - accuracy: 0.7438 - val_loss: 0.6587 - val_accuracy: 0.7489\n","Epoch 9/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.5254 - accuracy: 0.7457 - val_loss: 0.6450 - val_accuracy: 0.7608\n","Epoch 10/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5155 - accuracy: 0.7530 - val_loss: 0.6332 - val_accuracy: 0.7629\n","Epoch 11/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5079 - accuracy: 0.7532 - val_loss: 0.6217 - val_accuracy: 0.7672\n","Epoch 12/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5046 - accuracy: 0.7532 - val_loss: 0.6091 - val_accuracy: 0.7662\n","Epoch 13/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4987 - accuracy: 0.7584 - val_loss: 0.5972 - val_accuracy: 0.7716\n","Epoch 14/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4953 - accuracy: 0.7645 - val_loss: 0.5831 - val_accuracy: 0.7780\n","Epoch 15/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4903 - accuracy: 0.7635 - val_loss: 0.5688 - val_accuracy: 0.7769\n","Epoch 16/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4883 - accuracy: 0.7651 - val_loss: 0.5560 - val_accuracy: 0.7769\n","Epoch 17/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4852 - accuracy: 0.7680 - val_loss: 0.5396 - val_accuracy: 0.7856\n","Epoch 18/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4848 - accuracy: 0.7694 - val_loss: 0.5255 - val_accuracy: 0.7866\n","Epoch 19/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.4795 - accuracy: 0.7775 - val_loss: 0.5100 - val_accuracy: 0.7899\n","Epoch 20/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4750 - accuracy: 0.7799 - val_loss: 0.4965 - val_accuracy: 0.7780\n","Epoch 21/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4708 - accuracy: 0.7826 - val_loss: 0.4830 - val_accuracy: 0.7802\n","Epoch 22/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.4713 - accuracy: 0.7807 - val_loss: 0.4764 - val_accuracy: 0.7877\n","Epoch 23/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4713 - accuracy: 0.7783 - val_loss: 0.4692 - val_accuracy: 0.7866\n","Epoch 24/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4623 - accuracy: 0.7904 - val_loss: 0.4659 - val_accuracy: 0.7974\n","Epoch 25/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4641 - accuracy: 0.7896 - val_loss: 0.4573 - val_accuracy: 0.7845\n","Epoch 26/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4614 - accuracy: 0.7899 - val_loss: 0.4558 - val_accuracy: 0.7942\n","Epoch 27/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4548 - accuracy: 0.7934 - val_loss: 0.4524 - val_accuracy: 0.7942\n","Epoch 28/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4534 - accuracy: 0.7953 - val_loss: 0.4558 - val_accuracy: 0.7974\n","Epoch 29/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4499 - accuracy: 0.8015 - val_loss: 0.4469 - val_accuracy: 0.7920\n","Epoch 30/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4482 - accuracy: 0.7996 - val_loss: 0.4445 - val_accuracy: 0.7942\n","Epoch 31/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4422 - accuracy: 0.7977 - val_loss: 0.4433 - val_accuracy: 0.7942\n","Epoch 32/100\n","29/29 [==============================] - 1s 44ms/step - loss: 0.4404 - accuracy: 0.8047 - val_loss: 0.4580 - val_accuracy: 0.7996\n","Epoch 33/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4364 - accuracy: 0.8023 - val_loss: 0.4402 - val_accuracy: 0.7942\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4291 - accuracy: 0.8098 - val_loss: 0.4397 - val_accuracy: 0.7931\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4334 - accuracy: 0.8101 - val_loss: 0.4371 - val_accuracy: 0.7931\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4255 - accuracy: 0.8101 - val_loss: 0.4365 - val_accuracy: 0.7974\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4247 - accuracy: 0.8101 - val_loss: 0.4373 - val_accuracy: 0.7963\n","Epoch 38/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4210 - accuracy: 0.8085 - val_loss: 0.4436 - val_accuracy: 0.8147\n","Epoch 39/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4144 - accuracy: 0.8168 - val_loss: 0.4324 - val_accuracy: 0.8039\n","Epoch 40/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4136 - accuracy: 0.8141 - val_loss: 0.4302 - val_accuracy: 0.8071\n","Epoch 41/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4066 - accuracy: 0.8200 - val_loss: 0.4288 - val_accuracy: 0.8071\n","Epoch 42/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4053 - accuracy: 0.8163 - val_loss: 0.4301 - val_accuracy: 0.8050\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4006 - accuracy: 0.8222 - val_loss: 0.4290 - val_accuracy: 0.8103\n","Epoch 44/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3977 - accuracy: 0.8192 - val_loss: 0.4281 - val_accuracy: 0.8114\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3925 - accuracy: 0.8273 - val_loss: 0.4277 - val_accuracy: 0.8125\n","Epoch 46/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3891 - accuracy: 0.8305 - val_loss: 0.4285 - val_accuracy: 0.8114\n","Epoch 47/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3877 - accuracy: 0.8316 - val_loss: 0.4268 - val_accuracy: 0.8147\n","Epoch 48/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3825 - accuracy: 0.8300 - val_loss: 0.4301 - val_accuracy: 0.8093\n","Epoch 49/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.3811 - accuracy: 0.8316 - val_loss: 0.4275 - val_accuracy: 0.8179\n","Epoch 50/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.3792 - accuracy: 0.8338 - val_loss: 0.4284 - val_accuracy: 0.8200\n","Epoch 51/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3764 - accuracy: 0.8367 - val_loss: 0.4285 - val_accuracy: 0.8168\n","Epoch 52/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3738 - accuracy: 0.8389 - val_loss: 0.4310 - val_accuracy: 0.8190\n","Epoch 53/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3641 - accuracy: 0.8411 - val_loss: 0.4285 - val_accuracy: 0.8179\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3652 - accuracy: 0.8408 - val_loss: 0.4265 - val_accuracy: 0.8157\n","Epoch 55/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3567 - accuracy: 0.8462 - val_loss: 0.4299 - val_accuracy: 0.8254\n","Epoch 56/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3587 - accuracy: 0.8470 - val_loss: 0.4453 - val_accuracy: 0.8028\n","Epoch 57/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3565 - accuracy: 0.8473 - val_loss: 0.4365 - val_accuracy: 0.8254\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3561 - accuracy: 0.8481 - val_loss: 0.4281 - val_accuracy: 0.8222\n","Epoch 59/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3469 - accuracy: 0.8540 - val_loss: 0.4329 - val_accuracy: 0.8276\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3504 - accuracy: 0.8481 - val_loss: 0.4287 - val_accuracy: 0.8254\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3457 - accuracy: 0.8556 - val_loss: 0.4294 - val_accuracy: 0.8190\n","Epoch 62/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3408 - accuracy: 0.8548 - val_loss: 0.4327 - val_accuracy: 0.8319\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3364 - accuracy: 0.8594 - val_loss: 0.4322 - val_accuracy: 0.8200\n","Epoch 64/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3352 - accuracy: 0.8559 - val_loss: 0.4316 - val_accuracy: 0.8254\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3316 - accuracy: 0.8583 - val_loss: 0.4333 - val_accuracy: 0.8297\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3309 - accuracy: 0.8570 - val_loss: 0.4483 - val_accuracy: 0.8200\n","Epoch 67/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3259 - accuracy: 0.8613 - val_loss: 0.4324 - val_accuracy: 0.8211\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3211 - accuracy: 0.8650 - val_loss: 0.4341 - val_accuracy: 0.8200\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3206 - accuracy: 0.8645 - val_loss: 0.4374 - val_accuracy: 0.8308\n","Epoch 70/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3184 - accuracy: 0.8734 - val_loss: 0.4365 - val_accuracy: 0.8190\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3131 - accuracy: 0.8685 - val_loss: 0.4334 - val_accuracy: 0.8276\n","Epoch 72/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3116 - accuracy: 0.8656 - val_loss: 0.4372 - val_accuracy: 0.8308\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3074 - accuracy: 0.8777 - val_loss: 0.4476 - val_accuracy: 0.8244\n","Epoch 74/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3024 - accuracy: 0.8788 - val_loss: 0.4380 - val_accuracy: 0.8276\n","Epoch 75/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2999 - accuracy: 0.8782 - val_loss: 0.4389 - val_accuracy: 0.8297\n","Epoch 76/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2984 - accuracy: 0.8774 - val_loss: 0.4470 - val_accuracy: 0.8244\n","Epoch 77/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2938 - accuracy: 0.8793 - val_loss: 0.4449 - val_accuracy: 0.8244\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2896 - accuracy: 0.8844 - val_loss: 0.4427 - val_accuracy: 0.8308\n","Epoch 79/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2866 - accuracy: 0.8871 - val_loss: 0.4445 - val_accuracy: 0.8297\n","Epoch 80/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.2836 - accuracy: 0.8874 - val_loss: 0.4555 - val_accuracy: 0.8082\n","Epoch 81/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.2813 - accuracy: 0.8912 - val_loss: 0.4482 - val_accuracy: 0.8287\n","Epoch 82/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2750 - accuracy: 0.8914 - val_loss: 0.4484 - val_accuracy: 0.8297\n","Epoch 83/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.2786 - accuracy: 0.8914 - val_loss: 0.4552 - val_accuracy: 0.8168\n","Epoch 84/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.2781 - accuracy: 0.8901 - val_loss: 0.4527 - val_accuracy: 0.8147\n","Epoch 85/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2749 - accuracy: 0.8979 - val_loss: 0.4500 - val_accuracy: 0.8265\n","Epoch 86/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2689 - accuracy: 0.8955 - val_loss: 0.4499 - val_accuracy: 0.8244\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2584 - accuracy: 0.9046 - val_loss: 0.4500 - val_accuracy: 0.8265\n","Epoch 88/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2561 - accuracy: 0.8995 - val_loss: 0.4563 - val_accuracy: 0.8222\n","Epoch 89/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2528 - accuracy: 0.8990 - val_loss: 0.4546 - val_accuracy: 0.8244\n","Epoch 90/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2511 - accuracy: 0.9038 - val_loss: 0.4601 - val_accuracy: 0.8200\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2512 - accuracy: 0.9030 - val_loss: 0.4706 - val_accuracy: 0.8114\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2466 - accuracy: 0.9057 - val_loss: 0.4622 - val_accuracy: 0.8265\n","Epoch 93/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2444 - accuracy: 0.9068 - val_loss: 0.4641 - val_accuracy: 0.8233\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2468 - accuracy: 0.9049 - val_loss: 0.4663 - val_accuracy: 0.8190\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2438 - accuracy: 0.9106 - val_loss: 0.4641 - val_accuracy: 0.8244\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2332 - accuracy: 0.9141 - val_loss: 0.4651 - val_accuracy: 0.8244\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2326 - accuracy: 0.9108 - val_loss: 0.4789 - val_accuracy: 0.8136\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2318 - accuracy: 0.9092 - val_loss: 0.4669 - val_accuracy: 0.8233\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2252 - accuracy: 0.9151 - val_loss: 0.4711 - val_accuracy: 0.8233\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2254 - accuracy: 0.9192 - val_loss: 0.4728 - val_accuracy: 0.8222\n","{'loss': [0.6928755044937134, 0.6914501190185547, 0.6880160570144653, 0.6801234483718872, 0.6643990874290466, 0.6346668004989624, 0.5901094675064087, 0.5511631369590759, 0.5254483819007874, 0.5154847502708435, 0.5078964829444885, 0.5045534372329712, 0.49865809082984924, 0.4953172504901886, 0.49026983976364136, 0.4882929027080536, 0.48520204424858093, 0.48484814167022705, 0.4794906973838806, 0.4750320613384247, 0.47082436084747314, 0.47132688760757446, 0.4713270366191864, 0.4622578024864197, 0.46412572264671326, 0.4614182710647583, 0.45482006669044495, 0.45343631505966187, 0.4498840272426605, 0.4481928050518036, 0.4422168433666229, 0.440350204706192, 0.4364473223686218, 0.42907702922821045, 0.43341222405433655, 0.4255276322364807, 0.424729585647583, 0.4210466742515564, 0.41435927152633667, 0.41362082958221436, 0.4065554738044739, 0.4052741527557373, 0.4005848169326782, 0.39771977066993713, 0.39250683784484863, 0.38914668560028076, 0.38772302865982056, 0.38254520297050476, 0.3810911476612091, 0.3791694641113281, 0.3763832151889801, 0.37382832169532776, 0.36408668756484985, 0.36517372727394104, 0.35669809579849243, 0.35872355103492737, 0.3564918339252472, 0.3560740053653717, 0.34692928194999695, 0.3504352867603302, 0.3456610441207886, 0.3407861590385437, 0.33644136786460876, 0.3352437913417816, 0.33157721161842346, 0.33085930347442627, 0.32586973905563354, 0.32106858491897583, 0.32058659195899963, 0.31839802861213684, 0.3130907118320465, 0.31164538860321045, 0.3073580265045166, 0.3023832142353058, 0.2998630404472351, 0.29843178391456604, 0.2938336431980133, 0.2895592749118805, 0.28656005859375, 0.28362593054771423, 0.28133219480514526, 0.2749571204185486, 0.27859407663345337, 0.2780749201774597, 0.2749498188495636, 0.26886171102523804, 0.25844019651412964, 0.2561226189136505, 0.2528426945209503, 0.25108444690704346, 0.2512480914592743, 0.2466474026441574, 0.2444046586751938, 0.24682128429412842, 0.24375976622104645, 0.233171746134758, 0.2325870245695114, 0.23181511461734772, 0.2252291738986969, 0.22538349032402039], 'accuracy': [0.5859375, 0.7130926847457886, 0.7206357717514038, 0.732758641242981, 0.7419180870056152, 0.7389547228813171, 0.7424569129943848, 0.743803858757019, 0.7456896305084229, 0.7529633641242981, 0.7532327771186829, 0.7532327771186829, 0.7583512663841248, 0.7645474076271057, 0.7634698152542114, 0.7650862336158752, 0.7680495977401733, 0.7693965435028076, 0.7774784564971924, 0.779902994632721, 0.782597005367279, 0.7807112336158752, 0.7782866358757019, 0.790409505367279, 0.7896012663841248, 0.7898706793785095, 0.7933728694915771, 0.795258641242981, 0.8014547228813171, 0.7995689511299133, 0.7976831793785095, 0.8046875, 0.8022629022598267, 0.8098060488700867, 0.8100754022598267, 0.8100754022598267, 0.8100754022598267, 0.8084590435028076, 0.8168103694915771, 0.814116358757019, 0.8200430870056152, 0.8162715435028076, 0.8221982717514038, 0.8192349076271057, 0.8273168206214905, 0.8305495977401733, 0.8316271305084229, 0.8300107717514038, 0.8316271305084229, 0.8337823152542114, 0.8367456793785095, 0.8389008641242981, 0.8410560488700867, 0.8407866358757019, 0.8461745977401733, 0.8469827771186829, 0.8472521305084229, 0.8480603694915771, 0.8539870977401733, 0.8480603694915771, 0.8556034564971924, 0.8547952771186829, 0.859375, 0.8558728694915771, 0.8582974076271057, 0.8569504022598267, 0.8612607717514038, 0.8650323152542114, 0.8644935488700867, 0.873383641242981, 0.868534505367279, 0.865571141242981, 0.8776939511299133, 0.8787715435028076, 0.8782327771186829, 0.8774245977401733, 0.8793103694915771, 0.884428858757019, 0.8871228694915771, 0.8873922228813171, 0.8911637663841248, 0.8914331793785095, 0.8914331793785095, 0.8900862336158752, 0.8978987336158752, 0.8954741358757019, 0.904633641242981, 0.8995150923728943, 0.8989762663841248, 0.9038254022598267, 0.9030172228813171, 0.9057112336158752, 0.9067887663841248, 0.904902994632721, 0.9105603694915771, 0.9140625, 0.9108297228813171, 0.9092133641242981, 0.9151400923728943, 0.9191810488700867], 'val_loss': [0.693083643913269, 0.692855954170227, 0.6923717856407166, 0.691199779510498, 0.6884571313858032, 0.6825871467590332, 0.6726288199424744, 0.6587188243865967, 0.6449823975563049, 0.6332458853721619, 0.6216727495193481, 0.6090637445449829, 0.5971863269805908, 0.5830798149108887, 0.5688430070877075, 0.5559868216514587, 0.5395662784576416, 0.5255445241928101, 0.5099863409996033, 0.49653998017311096, 0.48298752307891846, 0.47636616230010986, 0.4691731929779053, 0.4658687114715576, 0.45734700560569763, 0.45581933856010437, 0.45237600803375244, 0.4557729661464691, 0.4469383955001831, 0.44450142979621887, 0.4432907700538635, 0.4580302834510803, 0.440186083316803, 0.4396646320819855, 0.43712538480758667, 0.4365091323852539, 0.4372515380382538, 0.44360581040382385, 0.4324077069759369, 0.4302079379558563, 0.4288424849510193, 0.4301382005214691, 0.4290276765823364, 0.42813625931739807, 0.42771732807159424, 0.4284534156322479, 0.42675262689590454, 0.4300982654094696, 0.4274637699127197, 0.4284386932849884, 0.4285440742969513, 0.43102410435676575, 0.42850133776664734, 0.4265173077583313, 0.4299355447292328, 0.4453169107437134, 0.4365367293357849, 0.42812052369117737, 0.4329011142253876, 0.4287402629852295, 0.4293939769268036, 0.432745099067688, 0.43223631381988525, 0.4315650463104248, 0.43332916498184204, 0.44831883907318115, 0.43239134550094604, 0.43407294154167175, 0.4374408721923828, 0.43647199869155884, 0.4334021806716919, 0.4372348487377167, 0.4475732445716858, 0.43803870677948, 0.4388572871685028, 0.44702595472335815, 0.4448959529399872, 0.4426652789115906, 0.4445498585700989, 0.4555343687534332, 0.44820472598075867, 0.44844263792037964, 0.4551921784877777, 0.4526519477367401, 0.4500356912612915, 0.4499259889125824, 0.4500156044960022, 0.4562841057777405, 0.45459485054016113, 0.4601134955883026, 0.4705756902694702, 0.4622209072113037, 0.4641076922416687, 0.46628066897392273, 0.46410080790519714, 0.46507105231285095, 0.47888028621673584, 0.4669119417667389, 0.4711042642593384, 0.47280871868133545], 'val_accuracy': [0.517241358757019, 0.5905172228813171, 0.5915948152542114, 0.6756465435028076, 0.7284482717514038, 0.7446120977401733, 0.7338362336158752, 0.7489224076271057, 0.7607758641242981, 0.7629310488700867, 0.767241358757019, 0.7661637663841248, 0.7715517282485962, 0.7780172228813171, 0.7769396305084229, 0.7769396305084229, 0.7855603694915771, 0.7866379022598267, 0.7898706793785095, 0.7780172228813171, 0.7801724076271057, 0.787715494632721, 0.7866379022598267, 0.7974137663841248, 0.7844827771186829, 0.7941810488700867, 0.7941810488700867, 0.7974137663841248, 0.7920258641242981, 0.7941810488700867, 0.7941810488700867, 0.7995689511299133, 0.7941810488700867, 0.7931034564971924, 0.7931034564971924, 0.7974137663841248, 0.7963362336158752, 0.8146551847457886, 0.8038793206214905, 0.8071120977401733, 0.8071120977401733, 0.8049569129943848, 0.8103448152542114, 0.8114224076271057, 0.8125, 0.8114224076271057, 0.8146551847457886, 0.8092672228813171, 0.8178879022598267, 0.8200430870056152, 0.8168103694915771, 0.818965494632721, 0.8178879022598267, 0.8157327771186829, 0.8254310488700867, 0.8028017282485962, 0.8254310488700867, 0.8221982717514038, 0.8275862336158752, 0.8254310488700867, 0.818965494632721, 0.8318965435028076, 0.8200430870056152, 0.8254310488700867, 0.829741358757019, 0.8200430870056152, 0.8211206793785095, 0.8200430870056152, 0.8308189511299133, 0.818965494632721, 0.8275862336158752, 0.8308189511299133, 0.8243534564971924, 0.8275862336158752, 0.829741358757019, 0.8243534564971924, 0.8243534564971924, 0.8308189511299133, 0.829741358757019, 0.8081896305084229, 0.8286637663841248, 0.829741358757019, 0.8168103694915771, 0.8146551847457886, 0.826508641242981, 0.8243534564971924, 0.826508641242981, 0.8221982717514038, 0.8243534564971924, 0.8200430870056152, 0.8114224076271057, 0.826508641242981, 0.8232758641242981, 0.818965494632721, 0.8243534564971924, 0.8243534564971924, 0.8135775923728943, 0.8232758641242981, 0.8232758641242981, 0.8221982717514038]}\n","38/38 [==============================] - 2s 11ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.6929 - accuracy: 0.5453"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 79ms/step - loss: 0.6929 - accuracy: 0.5453 - val_loss: 0.6931 - val_accuracy: 0.5045\n","Epoch 2/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6918 - accuracy: 0.6811 - val_loss: 0.6930 - val_accuracy: 0.5057\n","Epoch 3/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6893 - accuracy: 0.7139 - val_loss: 0.6927 - val_accuracy: 0.5136\n","Epoch 4/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6842 - accuracy: 0.7122 - val_loss: 0.6920 - val_accuracy: 0.5781\n","Epoch 5/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6740 - accuracy: 0.7207 - val_loss: 0.6903 - val_accuracy: 0.6652\n","Epoch 6/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6541 - accuracy: 0.7244 - val_loss: 0.6871 - val_accuracy: 0.6923\n","Epoch 7/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6225 - accuracy: 0.7250 - val_loss: 0.6806 - val_accuracy: 0.7093\n","Epoch 8/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.5873 - accuracy: 0.7252 - val_loss: 0.6710 - val_accuracy: 0.7115\n","Epoch 9/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.5596 - accuracy: 0.7275 - val_loss: 0.6608 - val_accuracy: 0.7172\n","Epoch 10/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.5459 - accuracy: 0.7312 - val_loss: 0.6505 - val_accuracy: 0.7195\n","Epoch 11/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5354 - accuracy: 0.7317 - val_loss: 0.6412 - val_accuracy: 0.7195\n","Epoch 12/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5315 - accuracy: 0.7377 - val_loss: 0.6320 - val_accuracy: 0.7285\n","Epoch 13/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.5285 - accuracy: 0.7368 - val_loss: 0.6214 - val_accuracy: 0.7319\n","Epoch 14/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5250 - accuracy: 0.7377 - val_loss: 0.6102 - val_accuracy: 0.7274\n","Epoch 15/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5192 - accuracy: 0.7442 - val_loss: 0.5997 - val_accuracy: 0.7296\n","Epoch 16/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5196 - accuracy: 0.7487 - val_loss: 0.5869 - val_accuracy: 0.7364\n","Epoch 17/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5153 - accuracy: 0.7470 - val_loss: 0.5752 - val_accuracy: 0.7319\n","Epoch 18/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5106 - accuracy: 0.7504 - val_loss: 0.5633 - val_accuracy: 0.7387\n","Epoch 19/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5088 - accuracy: 0.7513 - val_loss: 0.5508 - val_accuracy: 0.7432\n","Epoch 20/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5046 - accuracy: 0.7550 - val_loss: 0.5415 - val_accuracy: 0.7410\n","Epoch 21/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5023 - accuracy: 0.7555 - val_loss: 0.5304 - val_accuracy: 0.7500\n","Epoch 22/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4980 - accuracy: 0.7581 - val_loss: 0.5196 - val_accuracy: 0.7568\n","Epoch 23/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4933 - accuracy: 0.7651 - val_loss: 0.5121 - val_accuracy: 0.7602\n","Epoch 24/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4914 - accuracy: 0.7651 - val_loss: 0.5047 - val_accuracy: 0.7613\n","Epoch 25/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4858 - accuracy: 0.7711 - val_loss: 0.5020 - val_accuracy: 0.7579\n","Epoch 26/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4832 - accuracy: 0.7719 - val_loss: 0.4945 - val_accuracy: 0.7636\n","Epoch 27/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4779 - accuracy: 0.7725 - val_loss: 0.4903 - val_accuracy: 0.7670\n","Epoch 28/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4761 - accuracy: 0.7779 - val_loss: 0.4876 - val_accuracy: 0.7658\n","Epoch 29/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4732 - accuracy: 0.7784 - val_loss: 0.4866 - val_accuracy: 0.7658\n","Epoch 30/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4671 - accuracy: 0.7784 - val_loss: 0.4805 - val_accuracy: 0.7681\n","Epoch 31/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.4610 - accuracy: 0.7838 - val_loss: 0.4793 - val_accuracy: 0.7704\n","Epoch 32/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.4598 - accuracy: 0.7869 - val_loss: 0.4759 - val_accuracy: 0.7726\n","Epoch 33/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.4551 - accuracy: 0.7886 - val_loss: 0.4742 - val_accuracy: 0.7805\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4535 - accuracy: 0.7881 - val_loss: 0.4735 - val_accuracy: 0.7794\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4501 - accuracy: 0.7915 - val_loss: 0.4712 - val_accuracy: 0.7760\n","Epoch 36/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4433 - accuracy: 0.7957 - val_loss: 0.4728 - val_accuracy: 0.7760\n","Epoch 37/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4436 - accuracy: 0.7999 - val_loss: 0.4661 - val_accuracy: 0.7828\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4373 - accuracy: 0.8005 - val_loss: 0.4677 - val_accuracy: 0.7794\n","Epoch 39/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4388 - accuracy: 0.7965 - val_loss: 0.4639 - val_accuracy: 0.7885\n","Epoch 40/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4294 - accuracy: 0.8056 - val_loss: 0.4666 - val_accuracy: 0.7794\n","Epoch 41/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4259 - accuracy: 0.8059 - val_loss: 0.4614 - val_accuracy: 0.7873\n","Epoch 42/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4248 - accuracy: 0.8059 - val_loss: 0.4716 - val_accuracy: 0.7726\n","Epoch 43/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4249 - accuracy: 0.8008 - val_loss: 0.4613 - val_accuracy: 0.7873\n","Epoch 44/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4190 - accuracy: 0.8079 - val_loss: 0.4571 - val_accuracy: 0.7907\n","Epoch 45/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4120 - accuracy: 0.8130 - val_loss: 0.4598 - val_accuracy: 0.7907\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4080 - accuracy: 0.8175 - val_loss: 0.4718 - val_accuracy: 0.7805\n","Epoch 47/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4070 - accuracy: 0.8181 - val_loss: 0.4584 - val_accuracy: 0.7941\n","Epoch 48/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4040 - accuracy: 0.8195 - val_loss: 0.4569 - val_accuracy: 0.7952\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4007 - accuracy: 0.8192 - val_loss: 0.4562 - val_accuracy: 0.7941\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3960 - accuracy: 0.8200 - val_loss: 0.4678 - val_accuracy: 0.7873\n","Epoch 51/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3972 - accuracy: 0.8248 - val_loss: 0.4570 - val_accuracy: 0.7986\n","Epoch 52/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3918 - accuracy: 0.8265 - val_loss: 0.4601 - val_accuracy: 0.8032\n","Epoch 53/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3880 - accuracy: 0.8280 - val_loss: 0.4554 - val_accuracy: 0.8009\n","Epoch 54/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3862 - accuracy: 0.8288 - val_loss: 0.4551 - val_accuracy: 0.8009\n","Epoch 55/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3801 - accuracy: 0.8288 - val_loss: 0.4551 - val_accuracy: 0.8020\n","Epoch 56/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3796 - accuracy: 0.8370 - val_loss: 0.4540 - val_accuracy: 0.8020\n","Epoch 57/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3774 - accuracy: 0.8316 - val_loss: 0.4523 - val_accuracy: 0.8009\n","Epoch 58/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.3710 - accuracy: 0.8381 - val_loss: 0.4535 - val_accuracy: 0.8088\n","Epoch 59/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3719 - accuracy: 0.8367 - val_loss: 0.4620 - val_accuracy: 0.7919\n","Epoch 60/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.3689 - accuracy: 0.8393 - val_loss: 0.4531 - val_accuracy: 0.8100\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3646 - accuracy: 0.8427 - val_loss: 0.4547 - val_accuracy: 0.7986\n","Epoch 62/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.3584 - accuracy: 0.8404 - val_loss: 0.4559 - val_accuracy: 0.8145\n","Epoch 63/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3604 - accuracy: 0.8407 - val_loss: 0.4527 - val_accuracy: 0.8088\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3555 - accuracy: 0.8444 - val_loss: 0.4596 - val_accuracy: 0.7964\n","Epoch 65/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3550 - accuracy: 0.8430 - val_loss: 0.4685 - val_accuracy: 0.7919\n","Epoch 66/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3512 - accuracy: 0.8500 - val_loss: 0.4519 - val_accuracy: 0.8190\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3427 - accuracy: 0.8509 - val_loss: 0.4589 - val_accuracy: 0.7975\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3376 - accuracy: 0.8534 - val_loss: 0.4547 - val_accuracy: 0.8111\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3380 - accuracy: 0.8509 - val_loss: 0.4544 - val_accuracy: 0.8111\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3357 - accuracy: 0.8540 - val_loss: 0.4596 - val_accuracy: 0.7986\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3357 - accuracy: 0.8540 - val_loss: 0.4532 - val_accuracy: 0.8145\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3318 - accuracy: 0.8563 - val_loss: 0.4555 - val_accuracy: 0.8088\n","Epoch 73/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3257 - accuracy: 0.8605 - val_loss: 0.4552 - val_accuracy: 0.8156\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3225 - accuracy: 0.8613 - val_loss: 0.4558 - val_accuracy: 0.8100\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3186 - accuracy: 0.8650 - val_loss: 0.4695 - val_accuracy: 0.7998\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3207 - accuracy: 0.8596 - val_loss: 0.4613 - val_accuracy: 0.8122\n","Epoch 77/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3128 - accuracy: 0.8636 - val_loss: 0.4548 - val_accuracy: 0.8156\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3086 - accuracy: 0.8696 - val_loss: 0.4687 - val_accuracy: 0.8111\n","Epoch 79/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3035 - accuracy: 0.8704 - val_loss: 0.4613 - val_accuracy: 0.8122\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3056 - accuracy: 0.8670 - val_loss: 0.4679 - val_accuracy: 0.8190\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2983 - accuracy: 0.8727 - val_loss: 0.4610 - val_accuracy: 0.8133\n","Epoch 82/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2982 - accuracy: 0.8752 - val_loss: 0.4620 - val_accuracy: 0.8122\n","Epoch 83/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.2945 - accuracy: 0.8795 - val_loss: 0.4649 - val_accuracy: 0.8281\n","Epoch 84/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2912 - accuracy: 0.8761 - val_loss: 0.4624 - val_accuracy: 0.8156\n","Epoch 85/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2826 - accuracy: 0.8857 - val_loss: 0.4661 - val_accuracy: 0.8133\n","Epoch 86/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2759 - accuracy: 0.8902 - val_loss: 0.4672 - val_accuracy: 0.8145\n","Epoch 87/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2806 - accuracy: 0.8823 - val_loss: 0.4694 - val_accuracy: 0.8167\n","Epoch 88/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2736 - accuracy: 0.8851 - val_loss: 0.4668 - val_accuracy: 0.8213\n","Epoch 89/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2703 - accuracy: 0.8879 - val_loss: 0.4752 - val_accuracy: 0.8156\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2679 - accuracy: 0.8865 - val_loss: 0.4949 - val_accuracy: 0.8100\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2649 - accuracy: 0.8922 - val_loss: 0.4694 - val_accuracy: 0.8190\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2546 - accuracy: 0.9018 - val_loss: 0.4903 - val_accuracy: 0.8100\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2634 - accuracy: 0.8953 - val_loss: 0.4715 - val_accuracy: 0.8167\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2554 - accuracy: 0.8987 - val_loss: 0.4721 - val_accuracy: 0.8235\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2464 - accuracy: 0.9018 - val_loss: 0.4720 - val_accuracy: 0.8247\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2380 - accuracy: 0.9095 - val_loss: 0.5208 - val_accuracy: 0.8111\n","Epoch 97/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2515 - accuracy: 0.8978 - val_loss: 0.4780 - val_accuracy: 0.8179\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2452 - accuracy: 0.9041 - val_loss: 0.4821 - val_accuracy: 0.8179\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2312 - accuracy: 0.9092 - val_loss: 0.4927 - val_accuracy: 0.8156\n","Epoch 100/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2395 - accuracy: 0.9029 - val_loss: 0.5239 - val_accuracy: 0.7998\n","{'loss': [0.6929243803024292, 0.6918338537216187, 0.6892794370651245, 0.6842235922813416, 0.674013614654541, 0.6541370749473572, 0.6225295066833496, 0.5873066186904907, 0.5596199631690979, 0.5459298491477966, 0.5354410409927368, 0.5315226316452026, 0.5285159349441528, 0.5249760150909424, 0.5192330479621887, 0.5196006894111633, 0.5152826905250549, 0.5106005072593689, 0.5088310837745667, 0.5045759677886963, 0.5022994875907898, 0.49800968170166016, 0.49334341287612915, 0.49141091108322144, 0.48583534359931946, 0.483224481344223, 0.47792044281959534, 0.4761050343513489, 0.4732385575771332, 0.4671042263507843, 0.46104171872138977, 0.45978349447250366, 0.45507094264030457, 0.4535202383995056, 0.4500681757926941, 0.44334402680397034, 0.4435597062110901, 0.43726372718811035, 0.4387580156326294, 0.42942559719085693, 0.42588168382644653, 0.4247789978981018, 0.4248952269554138, 0.4189887046813965, 0.4120190739631653, 0.40800780057907104, 0.40696054697036743, 0.4039740264415741, 0.40067195892333984, 0.3960201144218445, 0.3971561789512634, 0.39176318049430847, 0.38796165585517883, 0.3862428665161133, 0.38010695576667786, 0.37957215309143066, 0.37740272283554077, 0.3710183799266815, 0.3718729615211487, 0.3688666522502899, 0.36464667320251465, 0.35842934250831604, 0.3604263663291931, 0.3555085361003876, 0.35499700903892517, 0.3512192666530609, 0.3426673114299774, 0.33756574988365173, 0.3380139470100403, 0.3357144594192505, 0.3357034921646118, 0.33177685737609863, 0.32568657398223877, 0.3224668502807617, 0.31863081455230713, 0.3206638991832733, 0.3128303289413452, 0.30862560868263245, 0.3035125732421875, 0.3055509328842163, 0.29831135272979736, 0.2982034981250763, 0.29447126388549805, 0.291218638420105, 0.28258195519447327, 0.2758619487285614, 0.2805534303188324, 0.2735642194747925, 0.27031171321868896, 0.2679172456264496, 0.26492416858673096, 0.2545962929725647, 0.26341068744659424, 0.2553988993167877, 0.24644134938716888, 0.2380259484052658, 0.2515392005443573, 0.24523033201694489, 0.23123160004615784, 0.23946283757686615], 'accuracy': [0.5452744960784912, 0.6810979247093201, 0.7139219045639038, 0.7122241258621216, 0.7207130789756775, 0.7243916392326355, 0.7249575257301331, 0.7252405285835266, 0.7275042533874512, 0.7311828136444092, 0.7317487001419067, 0.7376909852027893, 0.7368420958518982, 0.7376909852027893, 0.7441992163658142, 0.7487266659736633, 0.7470288872718811, 0.7504244446754456, 0.7512733340263367, 0.7549518942832947, 0.755517840385437, 0.7580645084381104, 0.7651386260986328, 0.7651386260986328, 0.7710809111595154, 0.7719298005104065, 0.7724957466125488, 0.7778720855712891, 0.7784380316734314, 0.7784380316734314, 0.7838143706321716, 0.7869269847869873, 0.7886247634887695, 0.788058876991272, 0.7914544343948364, 0.7956989407539368, 0.7999433875083923, 0.8005093336105347, 0.7965478301048279, 0.8056027293205261, 0.8058856725692749, 0.8058856725692749, 0.8007922768592834, 0.8078664541244507, 0.8129597902297974, 0.8174872398376465, 0.8180531859397888, 0.8194680213928223, 0.8191850781440735, 0.8200339674949646, 0.8248443603515625, 0.8265421390533447, 0.8279569745063782, 0.8288058638572693, 0.8288058638572693, 0.8370118737220764, 0.8316355347633362, 0.8381437659263611, 0.8367289304733276, 0.839275598526001, 0.8426712155342102, 0.8404074907302856, 0.8406904339790344, 0.8443689942359924, 0.842954158782959, 0.8500282764434814, 0.8508771657943726, 0.8534238934516907, 0.8508771657943726, 0.853989839553833, 0.853989839553833, 0.8562535643577576, 0.8604980111122131, 0.8613469004631042, 0.8650254607200623, 0.859649121761322, 0.8636106252670288, 0.8695529103279114, 0.8704017996788025, 0.867006242275238, 0.872665524482727, 0.8752122521400452, 0.8794566988945007, 0.8760611414909363, 0.8856819272041321, 0.8902093768119812, 0.8822863698005676, 0.8851160407066345, 0.8879456520080566, 0.8865308165550232, 0.892190158367157, 0.9018110036849976, 0.8953027725219727, 0.8986983299255371, 0.9018110036849976, 0.9094510674476624, 0.897849440574646, 0.9040747284889221, 0.9091680645942688, 0.9029428362846375], 'val_loss': [0.6930863857269287, 0.6929628252983093, 0.6926612257957458, 0.6919643878936768, 0.6903303861618042, 0.6870604157447815, 0.6806338429450989, 0.6710079312324524, 0.6607878804206848, 0.6505492329597473, 0.6411730051040649, 0.6320476531982422, 0.6214154958724976, 0.6101562976837158, 0.599713921546936, 0.5869459509849548, 0.5752471089363098, 0.5632954835891724, 0.5507850646972656, 0.5414991974830627, 0.5304297804832458, 0.5196272730827332, 0.5121008157730103, 0.5047021508216858, 0.5019503235816956, 0.4944804906845093, 0.49034035205841064, 0.4876348674297333, 0.4865540862083435, 0.48053112626075745, 0.4792822599411011, 0.475896954536438, 0.4741564691066742, 0.4735415279865265, 0.47122853994369507, 0.4728052616119385, 0.4661037027835846, 0.46769022941589355, 0.46390995383262634, 0.46664848923683167, 0.4613904356956482, 0.47159767150878906, 0.46133333444595337, 0.45710843801498413, 0.4598311483860016, 0.471820205450058, 0.4584464430809021, 0.4569079279899597, 0.456215500831604, 0.4677989184856415, 0.4570428133010864, 0.4600827395915985, 0.45537039637565613, 0.4550742208957672, 0.45506903529167175, 0.45404380559921265, 0.4523126482963562, 0.453498899936676, 0.46203291416168213, 0.4530619978904724, 0.45470288395881653, 0.455859899520874, 0.4527406692504883, 0.45964089035987854, 0.4685479402542114, 0.45190533995628357, 0.45894768834114075, 0.45470237731933594, 0.45437106490135193, 0.45960113406181335, 0.4532412588596344, 0.45546698570251465, 0.4552389681339264, 0.45579177141189575, 0.469531774520874, 0.46133774518966675, 0.4548450708389282, 0.468735009431839, 0.46125850081443787, 0.46785759925842285, 0.46098068356513977, 0.4620300233364105, 0.46489936113357544, 0.46242398023605347, 0.466105580329895, 0.46723270416259766, 0.46936923265457153, 0.4668329358100891, 0.4751613140106201, 0.4949125051498413, 0.46941420435905457, 0.4903198778629303, 0.47147172689437866, 0.47210752964019775, 0.4719506800174713, 0.5207599401473999, 0.47795119881629944, 0.48213034868240356, 0.4926983714103699, 0.5238974094390869], 'val_accuracy': [0.5045248866081238, 0.5056561231613159, 0.5135746598243713, 0.5780543088912964, 0.6651583909988403, 0.692307710647583, 0.709276020526886, 0.7115384340286255, 0.7171945571899414, 0.7194570302963257, 0.7194570302963257, 0.7285068035125732, 0.7319004535675049, 0.7273755669593811, 0.7296379804611206, 0.7364253401756287, 0.7319004535675049, 0.7386877536773682, 0.7432126402854919, 0.7409502267837524, 0.75, 0.7567873597145081, 0.7601810097694397, 0.7613122463226318, 0.7579185366630554, 0.7635746598243713, 0.766968309879303, 0.7658371329307556, 0.7658371329307556, 0.7680995464324951, 0.7703620195388794, 0.7726244330406189, 0.7805429697036743, 0.779411792755127, 0.7760180830955505, 0.7760180830955505, 0.7828054428100586, 0.779411792755127, 0.7884615659713745, 0.779411792755127, 0.7873303294181824, 0.7726244330406189, 0.7873303294181824, 0.790723979473114, 0.790723979473114, 0.7805429697036743, 0.7941176295280457, 0.7952488660812378, 0.7941176295280457, 0.7873303294181824, 0.7986425161361694, 0.8031674027442932, 0.8009049892425537, 0.8009049892425537, 0.8020362257957458, 0.8020362257957458, 0.8009049892425537, 0.8088235259056091, 0.7918552160263062, 0.8099547624588013, 0.7986425161361694, 0.814479649066925, 0.8088235259056091, 0.7963801026344299, 0.7918552160263062, 0.8190045356750488, 0.7975113391876221, 0.8110859990119934, 0.8110859990119934, 0.7986425161361694, 0.814479649066925, 0.8088235259056091, 0.8156108856201172, 0.8099547624588013, 0.7997737526893616, 0.8122171759605408, 0.8156108856201172, 0.8110859990119934, 0.8122171759605408, 0.8190045356750488, 0.8133484125137329, 0.8122171759605408, 0.8280543088912964, 0.8156108856201172, 0.8133484125137329, 0.814479649066925, 0.8167420625686646, 0.8212669491767883, 0.8156108856201172, 0.8099547624588013, 0.8190045356750488, 0.8099547624588013, 0.8167420625686646, 0.8235294222831726, 0.8246606588363647, 0.8110859990119934, 0.8178732991218567, 0.8178732991218567, 0.8156108856201172, 0.7997737526893616]}\n","45/45 [==============================] - 1s 8ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.6929 - accuracy: 0.5602"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 9s 88ms/step - loss: 0.6929 - accuracy: 0.5602 - val_loss: 0.6931 - val_accuracy: 0.5434\n","Epoch 2/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6914 - accuracy: 0.7036 - val_loss: 0.6929 - val_accuracy: 0.5165\n","Epoch 3/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6879 - accuracy: 0.7212 - val_loss: 0.6924 - val_accuracy: 0.5455\n","Epoch 4/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6800 - accuracy: 0.7271 - val_loss: 0.6911 - val_accuracy: 0.6550\n","Epoch 5/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6632 - accuracy: 0.7266 - val_loss: 0.6882 - val_accuracy: 0.7004\n","Epoch 6/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6312 - accuracy: 0.7351 - val_loss: 0.6819 - val_accuracy: 0.7397\n","Epoch 7/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5878 - accuracy: 0.7333 - val_loss: 0.6711 - val_accuracy: 0.7469\n","Epoch 8/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5529 - accuracy: 0.7395 - val_loss: 0.6579 - val_accuracy: 0.7500\n","Epoch 9/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5341 - accuracy: 0.7395 - val_loss: 0.6467 - val_accuracy: 0.7510\n","Epoch 10/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.5288 - accuracy: 0.7401 - val_loss: 0.6363 - val_accuracy: 0.7541\n","Epoch 11/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5216 - accuracy: 0.7403 - val_loss: 0.6251 - val_accuracy: 0.7572\n","Epoch 12/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5134 - accuracy: 0.7421 - val_loss: 0.6137 - val_accuracy: 0.7510\n","Epoch 13/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5087 - accuracy: 0.7506 - val_loss: 0.6002 - val_accuracy: 0.7562\n","Epoch 14/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5021 - accuracy: 0.7548 - val_loss: 0.5848 - val_accuracy: 0.7603\n","Epoch 15/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4982 - accuracy: 0.7537 - val_loss: 0.5716 - val_accuracy: 0.7634\n","Epoch 16/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4935 - accuracy: 0.7623 - val_loss: 0.5522 - val_accuracy: 0.7696\n","Epoch 17/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4883 - accuracy: 0.7669 - val_loss: 0.5389 - val_accuracy: 0.7645\n","Epoch 18/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4821 - accuracy: 0.7695 - val_loss: 0.5202 - val_accuracy: 0.7707\n","Epoch 19/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4744 - accuracy: 0.7780 - val_loss: 0.5072 - val_accuracy: 0.7758\n","Epoch 20/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4703 - accuracy: 0.7809 - val_loss: 0.4934 - val_accuracy: 0.7779\n","Epoch 21/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4682 - accuracy: 0.7809 - val_loss: 0.4868 - val_accuracy: 0.7738\n","Epoch 22/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4611 - accuracy: 0.7855 - val_loss: 0.4879 - val_accuracy: 0.7665\n","Epoch 23/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4554 - accuracy: 0.7904 - val_loss: 0.4700 - val_accuracy: 0.7779\n","Epoch 24/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4580 - accuracy: 0.7938 - val_loss: 0.4740 - val_accuracy: 0.7810\n","Epoch 25/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4488 - accuracy: 0.7961 - val_loss: 0.4642 - val_accuracy: 0.7831\n","Epoch 26/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4426 - accuracy: 0.8008 - val_loss: 0.4627 - val_accuracy: 0.7872\n","Epoch 27/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4358 - accuracy: 0.8005 - val_loss: 0.4612 - val_accuracy: 0.7872\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4358 - accuracy: 0.8013 - val_loss: 0.4644 - val_accuracy: 0.7841\n","Epoch 29/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4346 - accuracy: 0.8021 - val_loss: 0.4614 - val_accuracy: 0.7851\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4279 - accuracy: 0.8078 - val_loss: 0.4610 - val_accuracy: 0.7862\n","Epoch 31/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.4255 - accuracy: 0.8075 - val_loss: 0.4575 - val_accuracy: 0.7913\n","Epoch 32/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4216 - accuracy: 0.8129 - val_loss: 0.4621 - val_accuracy: 0.7872\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4160 - accuracy: 0.8158 - val_loss: 0.4565 - val_accuracy: 0.7913\n","Epoch 34/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4122 - accuracy: 0.8158 - val_loss: 0.4590 - val_accuracy: 0.7903\n","Epoch 35/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4092 - accuracy: 0.8186 - val_loss: 0.4591 - val_accuracy: 0.7862\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4055 - accuracy: 0.8171 - val_loss: 0.4564 - val_accuracy: 0.7893\n","Epoch 37/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4130 - accuracy: 0.8150 - val_loss: 0.4543 - val_accuracy: 0.7944\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4042 - accuracy: 0.8217 - val_loss: 0.4522 - val_accuracy: 0.7924\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3981 - accuracy: 0.8276 - val_loss: 0.4524 - val_accuracy: 0.7893\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3981 - accuracy: 0.8222 - val_loss: 0.4564 - val_accuracy: 0.7913\n","Epoch 41/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3949 - accuracy: 0.8274 - val_loss: 0.4493 - val_accuracy: 0.7975\n","Epoch 42/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3922 - accuracy: 0.8261 - val_loss: 0.4510 - val_accuracy: 0.8006\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3875 - accuracy: 0.8339 - val_loss: 0.4529 - val_accuracy: 0.7955\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3822 - accuracy: 0.8320 - val_loss: 0.4471 - val_accuracy: 0.7986\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3804 - accuracy: 0.8315 - val_loss: 0.4509 - val_accuracy: 0.7934\n","Epoch 46/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3820 - accuracy: 0.8333 - val_loss: 0.4484 - val_accuracy: 0.8006\n","Epoch 47/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3774 - accuracy: 0.8367 - val_loss: 0.4459 - val_accuracy: 0.8006\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3747 - accuracy: 0.8333 - val_loss: 0.4620 - val_accuracy: 0.7851\n","Epoch 49/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3772 - accuracy: 0.8339 - val_loss: 0.4442 - val_accuracy: 0.7965\n","Epoch 50/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3722 - accuracy: 0.8390 - val_loss: 0.4441 - val_accuracy: 0.8027\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3669 - accuracy: 0.8380 - val_loss: 0.4499 - val_accuracy: 0.7975\n","Epoch 52/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3588 - accuracy: 0.8452 - val_loss: 0.4452 - val_accuracy: 0.8089\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3597 - accuracy: 0.8496 - val_loss: 0.4479 - val_accuracy: 0.8068\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3623 - accuracy: 0.8470 - val_loss: 0.4502 - val_accuracy: 0.7996\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3569 - accuracy: 0.8478 - val_loss: 0.4425 - val_accuracy: 0.8058\n","Epoch 56/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3539 - accuracy: 0.8499 - val_loss: 0.4441 - val_accuracy: 0.8058\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3473 - accuracy: 0.8530 - val_loss: 0.4535 - val_accuracy: 0.7913\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3491 - accuracy: 0.8483 - val_loss: 0.4432 - val_accuracy: 0.8079\n","Epoch 59/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3420 - accuracy: 0.8535 - val_loss: 0.4437 - val_accuracy: 0.8120\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3377 - accuracy: 0.8568 - val_loss: 0.4556 - val_accuracy: 0.7955\n","Epoch 61/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3359 - accuracy: 0.8592 - val_loss: 0.4439 - val_accuracy: 0.8099\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3341 - accuracy: 0.8618 - val_loss: 0.4438 - val_accuracy: 0.8099\n","Epoch 63/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3390 - accuracy: 0.8579 - val_loss: 0.4424 - val_accuracy: 0.8140\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3302 - accuracy: 0.8592 - val_loss: 0.4576 - val_accuracy: 0.7965\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3264 - accuracy: 0.8667 - val_loss: 0.4670 - val_accuracy: 0.7913\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3304 - accuracy: 0.8636 - val_loss: 0.4424 - val_accuracy: 0.8089\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3216 - accuracy: 0.8618 - val_loss: 0.4429 - val_accuracy: 0.8130\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3192 - accuracy: 0.8659 - val_loss: 0.4429 - val_accuracy: 0.8110\n","Epoch 69/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3114 - accuracy: 0.8693 - val_loss: 0.4445 - val_accuracy: 0.8182\n","Epoch 70/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3171 - accuracy: 0.8693 - val_loss: 0.4446 - val_accuracy: 0.8120\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3104 - accuracy: 0.8739 - val_loss: 0.4520 - val_accuracy: 0.8058\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3110 - accuracy: 0.8693 - val_loss: 0.4432 - val_accuracy: 0.8151\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2997 - accuracy: 0.8739 - val_loss: 0.4601 - val_accuracy: 0.7986\n","Epoch 74/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3021 - accuracy: 0.8749 - val_loss: 0.4471 - val_accuracy: 0.8151\n","Epoch 75/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2999 - accuracy: 0.8775 - val_loss: 0.4517 - val_accuracy: 0.8089\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2942 - accuracy: 0.8798 - val_loss: 0.4456 - val_accuracy: 0.8182\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2925 - accuracy: 0.8767 - val_loss: 0.4464 - val_accuracy: 0.8171\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2889 - accuracy: 0.8824 - val_loss: 0.4560 - val_accuracy: 0.8058\n","Epoch 79/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2875 - accuracy: 0.8804 - val_loss: 0.4485 - val_accuracy: 0.8192\n","Epoch 80/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2860 - accuracy: 0.8840 - val_loss: 0.4480 - val_accuracy: 0.8151\n","Epoch 81/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2829 - accuracy: 0.8848 - val_loss: 0.4485 - val_accuracy: 0.8161\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2714 - accuracy: 0.8910 - val_loss: 0.4586 - val_accuracy: 0.8171\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2752 - accuracy: 0.8819 - val_loss: 0.4752 - val_accuracy: 0.8017\n","Epoch 84/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2796 - accuracy: 0.8850 - val_loss: 0.4599 - val_accuracy: 0.8140\n","Epoch 85/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2679 - accuracy: 0.8912 - val_loss: 0.4689 - val_accuracy: 0.8089\n","Epoch 86/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2713 - accuracy: 0.8904 - val_loss: 0.4568 - val_accuracy: 0.8213\n","Epoch 87/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.2709 - accuracy: 0.8910 - val_loss: 0.4518 - val_accuracy: 0.8233\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2563 - accuracy: 0.8972 - val_loss: 0.4543 - val_accuracy: 0.8161\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2567 - accuracy: 0.8984 - val_loss: 0.4570 - val_accuracy: 0.8223\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2524 - accuracy: 0.9016 - val_loss: 0.4573 - val_accuracy: 0.8213\n","Epoch 91/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2556 - accuracy: 0.8961 - val_loss: 0.4862 - val_accuracy: 0.8048\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2499 - accuracy: 0.9008 - val_loss: 0.4606 - val_accuracy: 0.8233\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2433 - accuracy: 0.9036 - val_loss: 0.4741 - val_accuracy: 0.8161\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2428 - accuracy: 0.9062 - val_loss: 0.4624 - val_accuracy: 0.8233\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2320 - accuracy: 0.9142 - val_loss: 0.4647 - val_accuracy: 0.8182\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2397 - accuracy: 0.9052 - val_loss: 0.4659 - val_accuracy: 0.8213\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2287 - accuracy: 0.9119 - val_loss: 0.4699 - val_accuracy: 0.8213\n","Epoch 98/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2330 - accuracy: 0.9106 - val_loss: 0.4747 - val_accuracy: 0.8213\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2209 - accuracy: 0.9165 - val_loss: 0.4994 - val_accuracy: 0.8089\n","Epoch 100/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.2202 - accuracy: 0.9127 - val_loss: 0.4772 - val_accuracy: 0.8182\n","{'loss': [0.6929129362106323, 0.6914346218109131, 0.6879460215568542, 0.6799713969230652, 0.6632208228111267, 0.6312387585639954, 0.5877758264541626, 0.5528968572616577, 0.5341182947158813, 0.5287678837776184, 0.5216225981712341, 0.5134087800979614, 0.5087370872497559, 0.5021417737007141, 0.49818897247314453, 0.49350738525390625, 0.4883117079734802, 0.4820508062839508, 0.4743829369544983, 0.4703257083892822, 0.46819379925727844, 0.4610871970653534, 0.4554491341114044, 0.4579622447490692, 0.4488467574119568, 0.4426290988922119, 0.4358489513397217, 0.43575841188430786, 0.434596985578537, 0.42790132761001587, 0.42547908425331116, 0.42160287499427795, 0.416006863117218, 0.412209153175354, 0.40924713015556335, 0.4054740369319916, 0.4129665791988373, 0.40416237711906433, 0.3981301188468933, 0.3981424868106842, 0.39493754506111145, 0.39222660660743713, 0.3875482380390167, 0.3822479546070099, 0.3804171681404114, 0.3819776773452759, 0.37743616104125977, 0.37473395466804504, 0.37718623876571655, 0.37215515971183777, 0.36693286895751953, 0.35878828167915344, 0.35967832803726196, 0.36231914162635803, 0.3568984270095825, 0.3539353609085083, 0.3472882807254791, 0.3490745723247528, 0.3419521450996399, 0.33767735958099365, 0.335863322019577, 0.33414846658706665, 0.3389967679977417, 0.3301650285720825, 0.3264318108558655, 0.3303857743740082, 0.3216470181941986, 0.31922096014022827, 0.3113722801208496, 0.3170878291130066, 0.31039372086524963, 0.31098315119743347, 0.2996754050254822, 0.3021054267883301, 0.2998569905757904, 0.2942489981651306, 0.2925075888633728, 0.288897305727005, 0.2874986231327057, 0.28603824973106384, 0.28286221623420715, 0.2714492678642273, 0.2751912474632263, 0.279606431722641, 0.2679494321346283, 0.27134209871292114, 0.2708807587623596, 0.2563260495662689, 0.25668665766716003, 0.25243109464645386, 0.2556019723415375, 0.24985119700431824, 0.24326418340206146, 0.2428378164768219, 0.23199543356895447, 0.2397225946187973, 0.22869336605072021, 0.232997864484787, 0.22085648775100708, 0.22024080157279968], 'accuracy': [0.5602067112922668, 0.7036175727844238, 0.7211886048316956, 0.7271317839622498, 0.7266150116920471, 0.7351421117782593, 0.7333333492279053, 0.739534854888916, 0.739534854888916, 0.7400516867637634, 0.7403100728988647, 0.7421188354492188, 0.7506459951400757, 0.7547803521156311, 0.753746747970581, 0.762273907661438, 0.766925036907196, 0.7695090174674988, 0.7780361771583557, 0.7808785438537598, 0.7808785438537598, 0.7855297327041626, 0.790439248085022, 0.7937984466552734, 0.7961240410804749, 0.8007751703262329, 0.8005167841911316, 0.8012920022010803, 0.8020671606063843, 0.8077519536018372, 0.8074935674667358, 0.8129199147224426, 0.8157622814178467, 0.8157622814178467, 0.8186046481132507, 0.817054271697998, 0.814987063407898, 0.8217054009437561, 0.8276485800743103, 0.8222222328186035, 0.827390193939209, 0.8260982036590576, 0.8338501453399658, 0.832041323184967, 0.8315245509147644, 0.8333333134651184, 0.8366925120353699, 0.8333333134651184, 0.8338501453399658, 0.8390181064605713, 0.8379845023155212, 0.845219612121582, 0.8496124148368835, 0.8470284342765808, 0.8478035926818848, 0.8498708009719849, 0.8529715538024902, 0.8483204245567322, 0.8534883856773376, 0.8568475246429443, 0.8591731190681458, 0.8617570996284485, 0.8578811287879944, 0.8591731190681458, 0.8666666746139526, 0.8635658621788025, 0.8617570996284485, 0.8658914566040039, 0.8692506551742554, 0.8692506551742554, 0.8739017844200134, 0.8692506551742554, 0.8739017844200134, 0.8749353885650635, 0.8775193691253662, 0.8798449635505676, 0.8767442107200623, 0.8824289441108704, 0.8803617358207703, 0.883979320526123, 0.8847545385360718, 0.8909560441970825, 0.8819121718406677, 0.8850129246711731, 0.8912144899368286, 0.8904392719268799, 0.8909560441970825, 0.897157609462738, 0.8984495997428894, 0.9015504121780396, 0.896124005317688, 0.9007751941680908, 0.9036175608634949, 0.9062015414237976, 0.9142118692398071, 0.9051679372787476, 0.9118863344192505, 0.9105943441390991, 0.9165374636650085, 0.9126614928245544], 'val_loss': [0.6930633187294006, 0.6928533315658569, 0.692392110824585, 0.6910762190818787, 0.6881640553474426, 0.6818692684173584, 0.6711231470108032, 0.6579097509384155, 0.6466534733772278, 0.6362937688827515, 0.6250607967376709, 0.6137436628341675, 0.6002230048179626, 0.5848498344421387, 0.5716269612312317, 0.552181601524353, 0.538935661315918, 0.5202478170394897, 0.5071988105773926, 0.4934164881706238, 0.4868216812610626, 0.4878624677658081, 0.47000548243522644, 0.47403547167778015, 0.4641552269458771, 0.4627048075199127, 0.46116745471954346, 0.4644007682800293, 0.4614482522010803, 0.46097779273986816, 0.4575147032737732, 0.4620586037635803, 0.4564780592918396, 0.45898476243019104, 0.459099143743515, 0.4564319849014282, 0.454266756772995, 0.4522387981414795, 0.4524208903312683, 0.4563750922679901, 0.4492977559566498, 0.4510146379470825, 0.4528881907463074, 0.4471486210823059, 0.45093584060668945, 0.44841238856315613, 0.4459245800971985, 0.46204766631126404, 0.4442240595817566, 0.4441239535808563, 0.4498804211616516, 0.4452054798603058, 0.44794961810112, 0.45020556449890137, 0.44245070219039917, 0.44408655166625977, 0.45354145765304565, 0.4431963860988617, 0.44372907280921936, 0.45556965470314026, 0.44389069080352783, 0.44383949041366577, 0.4424283504486084, 0.45762091875076294, 0.4670490026473999, 0.44237059354782104, 0.44286924600601196, 0.4428815543651581, 0.4445306360721588, 0.4445810317993164, 0.4519655108451843, 0.44317635893821716, 0.46009430289268494, 0.4471360743045807, 0.45174795389175415, 0.4456425905227661, 0.4464440643787384, 0.45596224069595337, 0.44847360253334045, 0.44804874062538147, 0.4485362470149994, 0.4586062729358673, 0.4752195477485657, 0.4598895311355591, 0.46887853741645813, 0.4567541778087616, 0.45183202624320984, 0.4542977213859558, 0.4570356011390686, 0.45725753903388977, 0.4862000644207001, 0.4606229364871979, 0.47413939237594604, 0.4624043107032776, 0.4647439420223236, 0.46592292189598083, 0.46990272402763367, 0.47469332814216614, 0.49941766262054443, 0.4772118330001831], 'val_accuracy': [0.5433884263038635, 0.5165289044380188, 0.5454545617103577, 0.6549586653709412, 0.7004132270812988, 0.7396694421768188, 0.7469007968902588, 0.75, 0.7510330677032471, 0.7541322112083435, 0.7572314143180847, 0.7510330677032471, 0.7561983466148376, 0.7603305578231812, 0.7634297609329224, 0.76962810754776, 0.7644628286361694, 0.7706611752510071, 0.7758264541625977, 0.7778925895690918, 0.7737603187561035, 0.7665289044380188, 0.7778925895690918, 0.7809917330741882, 0.7830578684806824, 0.7871900796890259, 0.7871900796890259, 0.7840909361839294, 0.7851239442825317, 0.7861570119857788, 0.7913222908973694, 0.7871900796890259, 0.7913222908973694, 0.7902892827987671, 0.7861570119857788, 0.78925621509552, 0.7944214940071106, 0.7923553586006165, 0.78925621509552, 0.7913222908973694, 0.797520637512207, 0.8006198406219482, 0.7954545617103577, 0.7985537052154541, 0.7933884263038635, 0.8006198406219482, 0.8006198406219482, 0.7851239442825317, 0.7964876294136047, 0.8026859760284424, 0.797520637512207, 0.80888432264328, 0.8068181872367859, 0.7995867729187012, 0.8057851195335388, 0.8057851195335388, 0.7913222908973694, 0.807851254940033, 0.8119834661483765, 0.7954545617103577, 0.8099173307418823, 0.8099173307418823, 0.8140496015548706, 0.7964876294136047, 0.7913222908973694, 0.80888432264328, 0.8130165338516235, 0.8109503984451294, 0.8181818127632141, 0.8119834661483765, 0.8057851195335388, 0.8150826692581177, 0.7985537052154541, 0.8150826692581177, 0.80888432264328, 0.8181818127632141, 0.817148745059967, 0.8057851195335388, 0.8192148804664612, 0.8150826692581177, 0.81611567735672, 0.817148745059967, 0.8016529083251953, 0.8140496015548706, 0.80888432264328, 0.8212810158729553, 0.8233470916748047, 0.81611567735672, 0.8223140239715576, 0.8212810158729553, 0.8047520518302917, 0.8233470916748047, 0.81611567735672, 0.8233470916748047, 0.8181818127632141, 0.8212810158729553, 0.8212810158729553, 0.8212810158729553, 0.80888432264328, 0.8181818127632141]}\n","32/32 [==============================] - 1s 9ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.3094 - accuracy: 0.8693"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 58ms/step - loss: 0.3076 - accuracy: 0.8707 - val_loss: 0.6772 - val_accuracy: 0.4871\n","Epoch 2/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2937 - accuracy: 0.8793 - val_loss: 0.6746 - val_accuracy: 0.4871\n","Epoch 3/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2934 - accuracy: 0.8839 - val_loss: 0.6688 - val_accuracy: 0.4968\n","Epoch 4/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.2816 - accuracy: 0.8860 - val_loss: 0.6628 - val_accuracy: 0.5140\n","Epoch 5/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2817 - accuracy: 0.8850 - val_loss: 0.6561 - val_accuracy: 0.5409\n","Epoch 6/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2765 - accuracy: 0.8925 - val_loss: 0.6471 - val_accuracy: 0.5938\n","Epoch 7/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2739 - accuracy: 0.8885 - val_loss: 0.6385 - val_accuracy: 0.6422\n","Epoch 8/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2698 - accuracy: 0.8952 - val_loss: 0.6289 - val_accuracy: 0.6950\n","Epoch 9/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.2596 - accuracy: 0.8955 - val_loss: 0.6128 - val_accuracy: 0.7759\n","Epoch 10/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.2608 - accuracy: 0.8990 - val_loss: 0.5966 - val_accuracy: 0.8190\n","Epoch 11/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.2586 - accuracy: 0.8949 - val_loss: 0.5792 - val_accuracy: 0.8341\n","Epoch 12/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2495 - accuracy: 0.9014 - val_loss: 0.5622 - val_accuracy: 0.8330\n","Epoch 13/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.2519 - accuracy: 0.9046 - val_loss: 0.5372 - val_accuracy: 0.8481\n","Epoch 14/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2517 - accuracy: 0.9014 - val_loss: 0.5135 - val_accuracy: 0.8534\n","Epoch 15/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2369 - accuracy: 0.9076 - val_loss: 0.4925 - val_accuracy: 0.8502\n","Epoch 16/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2386 - accuracy: 0.9073 - val_loss: 0.4714 - val_accuracy: 0.8438\n","Epoch 17/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2381 - accuracy: 0.9030 - val_loss: 0.4456 - val_accuracy: 0.8481\n","Epoch 18/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2323 - accuracy: 0.9103 - val_loss: 0.4066 - val_accuracy: 0.8567\n","Epoch 19/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2250 - accuracy: 0.9135 - val_loss: 0.4010 - val_accuracy: 0.8448\n","Epoch 20/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2218 - accuracy: 0.9195 - val_loss: 0.3869 - val_accuracy: 0.8470\n","Epoch 21/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2285 - accuracy: 0.9122 - val_loss: 0.3559 - val_accuracy: 0.8556\n","Epoch 22/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2150 - accuracy: 0.9186 - val_loss: 0.3499 - val_accuracy: 0.8556\n","Epoch 23/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2157 - accuracy: 0.9235 - val_loss: 0.3378 - val_accuracy: 0.8545\n","Epoch 24/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.2135 - accuracy: 0.9159 - val_loss: 0.3362 - val_accuracy: 0.8578\n","Epoch 25/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2116 - accuracy: 0.9208 - val_loss: 0.3659 - val_accuracy: 0.8491\n","Epoch 26/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2073 - accuracy: 0.9248 - val_loss: 0.3394 - val_accuracy: 0.8556\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2032 - accuracy: 0.9243 - val_loss: 0.3437 - val_accuracy: 0.8534\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1914 - accuracy: 0.9291 - val_loss: 0.3498 - val_accuracy: 0.8545\n","Epoch 29/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2016 - accuracy: 0.9227 - val_loss: 0.3753 - val_accuracy: 0.8502\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1901 - accuracy: 0.9324 - val_loss: 0.3590 - val_accuracy: 0.8502\n","Epoch 31/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1926 - accuracy: 0.9313 - val_loss: 0.3652 - val_accuracy: 0.8534\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1886 - accuracy: 0.9302 - val_loss: 0.3656 - val_accuracy: 0.8545\n","Epoch 33/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1783 - accuracy: 0.9359 - val_loss: 0.3782 - val_accuracy: 0.8534\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1839 - accuracy: 0.9364 - val_loss: 0.3957 - val_accuracy: 0.8481\n","Epoch 35/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1734 - accuracy: 0.9359 - val_loss: 0.3736 - val_accuracy: 0.8545\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1779 - accuracy: 0.9351 - val_loss: 0.3842 - val_accuracy: 0.8524\n","Epoch 37/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1763 - accuracy: 0.9378 - val_loss: 0.3761 - val_accuracy: 0.8470\n","Epoch 38/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.1643 - accuracy: 0.9418 - val_loss: 0.3774 - val_accuracy: 0.8524\n","Epoch 39/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1694 - accuracy: 0.9375 - val_loss: 0.4209 - val_accuracy: 0.8448\n","Epoch 40/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1632 - accuracy: 0.9448 - val_loss: 0.3821 - val_accuracy: 0.8524\n","Epoch 41/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1536 - accuracy: 0.9450 - val_loss: 0.3933 - val_accuracy: 0.8502\n","Epoch 42/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1547 - accuracy: 0.9461 - val_loss: 0.3900 - val_accuracy: 0.8545\n","Epoch 43/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1532 - accuracy: 0.9464 - val_loss: 0.4042 - val_accuracy: 0.8502\n","Epoch 44/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1556 - accuracy: 0.9429 - val_loss: 0.3937 - val_accuracy: 0.8491\n","Epoch 45/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1517 - accuracy: 0.9445 - val_loss: 0.4112 - val_accuracy: 0.8481\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1445 - accuracy: 0.9520 - val_loss: 0.4081 - val_accuracy: 0.8491\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1574 - accuracy: 0.9453 - val_loss: 0.4153 - val_accuracy: 0.8524\n","Epoch 48/100\n","29/29 [==============================] - 1s 48ms/step - loss: 0.1452 - accuracy: 0.9520 - val_loss: 0.3967 - val_accuracy: 0.8610\n","Epoch 49/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1419 - accuracy: 0.9558 - val_loss: 0.4032 - val_accuracy: 0.8578\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1336 - accuracy: 0.9553 - val_loss: 0.4044 - val_accuracy: 0.8524\n","Epoch 51/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1384 - accuracy: 0.9515 - val_loss: 0.4098 - val_accuracy: 0.8556\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1287 - accuracy: 0.9580 - val_loss: 0.4111 - val_accuracy: 0.8513\n","Epoch 53/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1328 - accuracy: 0.9585 - val_loss: 0.4602 - val_accuracy: 0.8384\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1296 - accuracy: 0.9580 - val_loss: 0.4348 - val_accuracy: 0.8438\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1214 - accuracy: 0.9628 - val_loss: 0.4154 - val_accuracy: 0.8545\n","Epoch 56/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1168 - accuracy: 0.9631 - val_loss: 0.4225 - val_accuracy: 0.8588\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1275 - accuracy: 0.9585 - val_loss: 0.4494 - val_accuracy: 0.8394\n","Epoch 58/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1267 - accuracy: 0.9612 - val_loss: 0.4241 - val_accuracy: 0.8621\n","Epoch 59/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1167 - accuracy: 0.9639 - val_loss: 0.4701 - val_accuracy: 0.8341\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1176 - accuracy: 0.9634 - val_loss: 0.4259 - val_accuracy: 0.8524\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1232 - accuracy: 0.9591 - val_loss: 0.4346 - val_accuracy: 0.8524\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1038 - accuracy: 0.9685 - val_loss: 0.4426 - val_accuracy: 0.8416\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1068 - accuracy: 0.9682 - val_loss: 0.4576 - val_accuracy: 0.8502\n","Epoch 64/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1073 - accuracy: 0.9688 - val_loss: 0.4460 - val_accuracy: 0.8491\n","Epoch 65/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1033 - accuracy: 0.9674 - val_loss: 0.4509 - val_accuracy: 0.8491\n","Epoch 66/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1002 - accuracy: 0.9704 - val_loss: 0.4505 - val_accuracy: 0.8470\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1026 - accuracy: 0.9671 - val_loss: 0.4861 - val_accuracy: 0.8394\n","Epoch 68/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1040 - accuracy: 0.9720 - val_loss: 0.4515 - val_accuracy: 0.8556\n","Epoch 69/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0984 - accuracy: 0.9690 - val_loss: 0.4601 - val_accuracy: 0.8470\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0908 - accuracy: 0.9755 - val_loss: 0.4982 - val_accuracy: 0.8384\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0947 - accuracy: 0.9696 - val_loss: 0.4587 - val_accuracy: 0.8545\n","Epoch 72/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0944 - accuracy: 0.9731 - val_loss: 0.4637 - val_accuracy: 0.8438\n","Epoch 73/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0918 - accuracy: 0.9720 - val_loss: 0.4642 - val_accuracy: 0.8534\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0958 - accuracy: 0.9714 - val_loss: 0.4703 - val_accuracy: 0.8481\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0890 - accuracy: 0.9744 - val_loss: 0.4903 - val_accuracy: 0.8373\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0778 - accuracy: 0.9801 - val_loss: 0.4672 - val_accuracy: 0.8470\n","Epoch 77/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0881 - accuracy: 0.9744 - val_loss: 0.4721 - val_accuracy: 0.8513\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0856 - accuracy: 0.9752 - val_loss: 0.5198 - val_accuracy: 0.8394\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0819 - accuracy: 0.9760 - val_loss: 0.4742 - val_accuracy: 0.8556\n","Epoch 80/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0784 - accuracy: 0.9793 - val_loss: 0.4963 - val_accuracy: 0.8448\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0717 - accuracy: 0.9790 - val_loss: 0.4849 - val_accuracy: 0.8481\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0768 - accuracy: 0.9782 - val_loss: 0.4928 - val_accuracy: 0.8459\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0813 - accuracy: 0.9763 - val_loss: 0.5051 - val_accuracy: 0.8427\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0805 - accuracy: 0.9760 - val_loss: 0.4896 - val_accuracy: 0.8491\n","Epoch 85/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0805 - accuracy: 0.9731 - val_loss: 0.5198 - val_accuracy: 0.8405\n","Epoch 86/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0726 - accuracy: 0.9803 - val_loss: 0.4948 - val_accuracy: 0.8438\n","Epoch 87/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0686 - accuracy: 0.9803 - val_loss: 0.5327 - val_accuracy: 0.8330\n","Epoch 88/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0666 - accuracy: 0.9828 - val_loss: 0.5083 - val_accuracy: 0.8427\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0685 - accuracy: 0.9822 - val_loss: 0.5188 - val_accuracy: 0.8427\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0588 - accuracy: 0.9852 - val_loss: 0.5093 - val_accuracy: 0.8470\n","Epoch 91/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0615 - accuracy: 0.9836 - val_loss: 0.5600 - val_accuracy: 0.8373\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0630 - accuracy: 0.9833 - val_loss: 0.5208 - val_accuracy: 0.8481\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0648 - accuracy: 0.9798 - val_loss: 0.5193 - val_accuracy: 0.8427\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0660 - accuracy: 0.9811 - val_loss: 0.5442 - val_accuracy: 0.8394\n","Epoch 95/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0601 - accuracy: 0.9838 - val_loss: 0.5582 - val_accuracy: 0.8341\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0607 - accuracy: 0.9820 - val_loss: 0.5240 - val_accuracy: 0.8438\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0610 - accuracy: 0.9822 - val_loss: 0.5440 - val_accuracy: 0.8405\n","Epoch 98/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0542 - accuracy: 0.9863 - val_loss: 0.5296 - val_accuracy: 0.8491\n","Epoch 99/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0525 - accuracy: 0.9876 - val_loss: 0.5344 - val_accuracy: 0.8513\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0527 - accuracy: 0.9868 - val_loss: 0.5341 - val_accuracy: 0.8459\n","{'loss': [0.30760693550109863, 0.2937398850917816, 0.2934090793132782, 0.2816063165664673, 0.2817149758338928, 0.2764670252799988, 0.27386191487312317, 0.2698220908641815, 0.2596133351325989, 0.2608220875263214, 0.2586420476436615, 0.24950818717479706, 0.25190481543540955, 0.2517475187778473, 0.23691974580287933, 0.2385953664779663, 0.2380998581647873, 0.23225994408130646, 0.2250393182039261, 0.22180061042308807, 0.22846657037734985, 0.21496924757957458, 0.21565274894237518, 0.21345943212509155, 0.2116103321313858, 0.20729050040245056, 0.20323656499385834, 0.19144244492053986, 0.20158466696739197, 0.19006535410881042, 0.19259873032569885, 0.1886196732521057, 0.17833633720874786, 0.1838729828596115, 0.17338770627975464, 0.17787402868270874, 0.17628411948680878, 0.16431552171707153, 0.1694048047065735, 0.16319827735424042, 0.15361040830612183, 0.1547144204378128, 0.15323816239833832, 0.15555666387081146, 0.1516958624124527, 0.1444895714521408, 0.1574295312166214, 0.14516238868236542, 0.14189444482326508, 0.13357838988304138, 0.13844408094882965, 0.1286916583776474, 0.1327558010816574, 0.12956254184246063, 0.12144340574741364, 0.11684239655733109, 0.12751397490501404, 0.12673620879650116, 0.11668986082077026, 0.1175556629896164, 0.12317681312561035, 0.1038382276892662, 0.10682983696460724, 0.10726660490036011, 0.10330281406641006, 0.10024593025445938, 0.10259667783975601, 0.1040261834859848, 0.09841904044151306, 0.09080752730369568, 0.09466807544231415, 0.0943833440542221, 0.09180796891450882, 0.09581567347049713, 0.08896803855895996, 0.07781977206468582, 0.08807723224163055, 0.08557271212339401, 0.08187331259250641, 0.07843422889709473, 0.07170470058917999, 0.07677377015352249, 0.08126985281705856, 0.08052882552146912, 0.08050352334976196, 0.07259735465049744, 0.0685858428478241, 0.06664042919874191, 0.0684966892004013, 0.05880313739180565, 0.061463046818971634, 0.06303270906209946, 0.06482288241386414, 0.06602061539888382, 0.06013187766075134, 0.06068791076540947, 0.06099161133170128, 0.054157573729753494, 0.05252377316355705, 0.052714306861162186], 'accuracy': [0.8706896305084229, 0.8793103694915771, 0.8838900923728943, 0.8860452771186829, 0.8849676847457886, 0.8925107717514038, 0.8884698152542114, 0.8952047228813171, 0.8954741358757019, 0.8989762663841248, 0.8949353694915771, 0.9014008641242981, 0.904633641242981, 0.9014008641242981, 0.907597005367279, 0.9073275923728943, 0.9030172228813171, 0.9102909564971924, 0.9135237336158752, 0.9194504022598267, 0.9121767282485962, 0.9186422228813171, 0.923491358757019, 0.9159482717514038, 0.9207974076271057, 0.9248383641242981, 0.9242995977401733, 0.9291487336158752, 0.9226831793785095, 0.9323814511299133, 0.931303858757019, 0.9302262663841248, 0.935883641242981, 0.9364224076271057, 0.935883641242981, 0.9350754022598267, 0.9377694129943848, 0.9418103694915771, 0.9375, 0.9447737336158752, 0.9450430870056152, 0.9461206793785095, 0.9463900923728943, 0.9428879022598267, 0.9445043206214905, 0.9520474076271057, 0.9453125, 0.9520474076271057, 0.9558189511299133, 0.9552801847457886, 0.951508641242981, 0.9579741358757019, 0.9585129022598267, 0.9579741358757019, 0.9628232717514038, 0.9630926847457886, 0.9585129022598267, 0.9612069129943848, 0.9639008641242981, 0.9633620977401733, 0.9590517282485962, 0.9684805870056152, 0.9682112336158752, 0.96875, 0.967402994632721, 0.970366358757019, 0.967133641242981, 0.9719827771186829, 0.9690194129943848, 0.9754849076271057, 0.9695581793785095, 0.9730603694915771, 0.9719827771186829, 0.9714439511299133, 0.9744073152542114, 0.9800646305084229, 0.9744073152542114, 0.975215494632721, 0.9760237336158752, 0.9792564511299133, 0.9789870977401733, 0.978178858757019, 0.9762930870056152, 0.9760237336158752, 0.9730603694915771, 0.9803340435028076, 0.9803340435028076, 0.982758641242981, 0.9822198152542114, 0.9851831793785095, 0.9835668206214905, 0.9832974076271057, 0.9797952771186829, 0.9811422228813171, 0.9838362336158752, 0.9819504022598267, 0.9822198152542114, 0.9862607717514038, 0.9876077771186829, 0.9867995977401733], 'val_loss': [0.677178144454956, 0.6746478080749512, 0.6687926650047302, 0.6627783179283142, 0.6561445593833923, 0.647085428237915, 0.6384825706481934, 0.6289373636245728, 0.6127592325210571, 0.596589982509613, 0.5791772603988647, 0.5621819496154785, 0.5371941328048706, 0.513507068157196, 0.49247047305107117, 0.4713604748249054, 0.4455854892730713, 0.40664684772491455, 0.4010147452354431, 0.3868643343448639, 0.35589906573295593, 0.34987786412239075, 0.33781906962394714, 0.33616647124290466, 0.3659246265888214, 0.33936864137649536, 0.3437156677246094, 0.3498338758945465, 0.37534573674201965, 0.35897427797317505, 0.36521270871162415, 0.36559686064720154, 0.3781881332397461, 0.3957207500934601, 0.37358975410461426, 0.3842477798461914, 0.3760760724544525, 0.3773820102214813, 0.42092856764793396, 0.38213759660720825, 0.39332252740859985, 0.389960378408432, 0.4042278230190277, 0.3937498927116394, 0.41120412945747375, 0.40812069177627563, 0.41529518365859985, 0.3967413008213043, 0.4032193124294281, 0.40435707569122314, 0.4098176956176758, 0.4111438989639282, 0.46019163727760315, 0.4347842335700989, 0.41544362902641296, 0.4224967956542969, 0.4494327902793884, 0.42411378026008606, 0.47008222341537476, 0.4259144961833954, 0.4346106946468353, 0.44260555505752563, 0.4575958251953125, 0.4459766447544098, 0.45093950629234314, 0.4505178928375244, 0.48609238862991333, 0.45146629214286804, 0.4601263403892517, 0.49823465943336487, 0.45870548486709595, 0.46370092034339905, 0.46424365043640137, 0.4702848196029663, 0.4902738630771637, 0.4671817123889923, 0.4720505475997925, 0.5198096036911011, 0.47418156266212463, 0.49629804491996765, 0.4848659038543701, 0.49283766746520996, 0.5050675868988037, 0.4896128475666046, 0.5197799801826477, 0.49484822154045105, 0.5327017307281494, 0.5083440542221069, 0.5188418626785278, 0.5093498826026917, 0.5600043535232544, 0.5208472609519958, 0.5192873477935791, 0.544164776802063, 0.5582204461097717, 0.5240292549133301, 0.5440384745597839, 0.5295863747596741, 0.534363329410553, 0.5340796709060669], 'val_accuracy': [0.48706895112991333, 0.48706895112991333, 0.4967672526836395, 0.514008641242981, 0.5409482717514038, 0.59375, 0.642241358757019, 0.6950430870056152, 0.7758620977401733, 0.818965494632721, 0.8340517282485962, 0.8329741358757019, 0.8480603694915771, 0.8534482717514038, 0.850215494632721, 0.84375, 0.8480603694915771, 0.8566810488700867, 0.8448275923728943, 0.8469827771186829, 0.8556034564971924, 0.8556034564971924, 0.8545258641242981, 0.857758641242981, 0.8491379022598267, 0.8556034564971924, 0.8534482717514038, 0.8545258641242981, 0.850215494632721, 0.850215494632721, 0.8534482717514038, 0.8545258641242981, 0.8534482717514038, 0.8480603694915771, 0.8545258641242981, 0.8523706793785095, 0.8469827771186829, 0.8523706793785095, 0.8448275923728943, 0.8523706793785095, 0.850215494632721, 0.8545258641242981, 0.850215494632721, 0.8491379022598267, 0.8480603694915771, 0.8491379022598267, 0.8523706793785095, 0.860991358757019, 0.857758641242981, 0.8523706793785095, 0.8556034564971924, 0.8512930870056152, 0.8383620977401733, 0.84375, 0.8545258641242981, 0.8588362336158752, 0.8394396305084229, 0.8620689511299133, 0.8340517282485962, 0.8523706793785095, 0.8523706793785095, 0.8415948152542114, 0.850215494632721, 0.8491379022598267, 0.8491379022598267, 0.8469827771186829, 0.8394396305084229, 0.8556034564971924, 0.8469827771186829, 0.8383620977401733, 0.8545258641242981, 0.84375, 0.8534482717514038, 0.8480603694915771, 0.837284505367279, 0.8469827771186829, 0.8512930870056152, 0.8394396305084229, 0.8556034564971924, 0.8448275923728943, 0.8480603694915771, 0.8459051847457886, 0.8426724076271057, 0.8491379022598267, 0.8405172228813171, 0.84375, 0.8329741358757019, 0.8426724076271057, 0.8426724076271057, 0.8469827771186829, 0.837284505367279, 0.8480603694915771, 0.8426724076271057, 0.8394396305084229, 0.8340517282485962, 0.84375, 0.8405172228813171, 0.8491379022598267, 0.8512930870056152, 0.8459051847457886]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.3286 - accuracy: 0.8552"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 7s 58ms/step - loss: 0.3267 - accuracy: 0.8571 - val_loss: 0.6776 - val_accuracy: 0.4966\n","Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3197 - accuracy: 0.8585 - val_loss: 0.6739 - val_accuracy: 0.5000\n","Epoch 3/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3128 - accuracy: 0.8664 - val_loss: 0.6681 - val_accuracy: 0.5181\n","Epoch 4/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3030 - accuracy: 0.8761 - val_loss: 0.6651 - val_accuracy: 0.5147\n","Epoch 5/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.2978 - accuracy: 0.8738 - val_loss: 0.6563 - val_accuracy: 0.6063\n","Epoch 6/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3002 - accuracy: 0.8744 - val_loss: 0.6513 - val_accuracy: 0.6029\n","Epoch 7/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2903 - accuracy: 0.8803 - val_loss: 0.6439 - val_accuracy: 0.6222\n","Epoch 8/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.2841 - accuracy: 0.8851 - val_loss: 0.6347 - val_accuracy: 0.6900\n","Epoch 9/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.2849 - accuracy: 0.8789 - val_loss: 0.6230 - val_accuracy: 0.7477\n","Epoch 10/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.2800 - accuracy: 0.8860 - val_loss: 0.6113 - val_accuracy: 0.7647\n","Epoch 11/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.2717 - accuracy: 0.8865 - val_loss: 0.5986 - val_accuracy: 0.7828\n","Epoch 12/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.2800 - accuracy: 0.8803 - val_loss: 0.5782 - val_accuracy: 0.8281\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2713 - accuracy: 0.8865 - val_loss: 0.5642 - val_accuracy: 0.8167\n","Epoch 14/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2607 - accuracy: 0.8913 - val_loss: 0.5368 - val_accuracy: 0.8529\n","Epoch 15/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2595 - accuracy: 0.8950 - val_loss: 0.5123 - val_accuracy: 0.8541\n","Epoch 16/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2557 - accuracy: 0.8962 - val_loss: 0.4885 - val_accuracy: 0.8575\n","Epoch 17/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2546 - accuracy: 0.8953 - val_loss: 0.4699 - val_accuracy: 0.8529\n","Epoch 18/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2560 - accuracy: 0.8993 - val_loss: 0.4389 - val_accuracy: 0.8541\n","Epoch 19/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2427 - accuracy: 0.9027 - val_loss: 0.4199 - val_accuracy: 0.8586\n","Epoch 20/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2370 - accuracy: 0.9055 - val_loss: 0.3944 - val_accuracy: 0.8450\n","Epoch 21/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2436 - accuracy: 0.9018 - val_loss: 0.3747 - val_accuracy: 0.8484\n","Epoch 22/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2323 - accuracy: 0.9046 - val_loss: 0.3696 - val_accuracy: 0.8552\n","Epoch 23/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2340 - accuracy: 0.9069 - val_loss: 0.3553 - val_accuracy: 0.8575\n","Epoch 24/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2279 - accuracy: 0.9075 - val_loss: 0.3587 - val_accuracy: 0.8552\n","Epoch 25/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2191 - accuracy: 0.9145 - val_loss: 0.3514 - val_accuracy: 0.8575\n","Epoch 26/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2221 - accuracy: 0.9123 - val_loss: 0.3511 - val_accuracy: 0.8507\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2158 - accuracy: 0.9151 - val_loss: 0.3521 - val_accuracy: 0.8563\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2174 - accuracy: 0.9120 - val_loss: 0.3628 - val_accuracy: 0.8507\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2079 - accuracy: 0.9199 - val_loss: 0.3608 - val_accuracy: 0.8586\n","Epoch 30/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2057 - accuracy: 0.9168 - val_loss: 0.3632 - val_accuracy: 0.8609\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2032 - accuracy: 0.9211 - val_loss: 0.3681 - val_accuracy: 0.8586\n","Epoch 32/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2015 - accuracy: 0.9199 - val_loss: 0.3691 - val_accuracy: 0.8597\n","Epoch 33/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.1927 - accuracy: 0.9298 - val_loss: 0.3754 - val_accuracy: 0.8620\n","Epoch 34/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1984 - accuracy: 0.9165 - val_loss: 0.3767 - val_accuracy: 0.8597\n","Epoch 35/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.1863 - accuracy: 0.9278 - val_loss: 0.3750 - val_accuracy: 0.8631\n","Epoch 36/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1920 - accuracy: 0.9219 - val_loss: 0.3802 - val_accuracy: 0.8609\n","Epoch 37/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1810 - accuracy: 0.9284 - val_loss: 0.3827 - val_accuracy: 0.8597\n","Epoch 38/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.1894 - accuracy: 0.9244 - val_loss: 0.3855 - val_accuracy: 0.8597\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1826 - accuracy: 0.9281 - val_loss: 0.3871 - val_accuracy: 0.8586\n","Epoch 40/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1757 - accuracy: 0.9341 - val_loss: 0.4025 - val_accuracy: 0.8541\n","Epoch 41/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1712 - accuracy: 0.9335 - val_loss: 0.3889 - val_accuracy: 0.8586\n","Epoch 42/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1761 - accuracy: 0.9301 - val_loss: 0.3876 - val_accuracy: 0.8631\n","Epoch 43/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1634 - accuracy: 0.9423 - val_loss: 0.3910 - val_accuracy: 0.8654\n","Epoch 44/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1674 - accuracy: 0.9366 - val_loss: 0.3949 - val_accuracy: 0.8620\n","Epoch 45/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1601 - accuracy: 0.9400 - val_loss: 0.3977 - val_accuracy: 0.8586\n","Epoch 46/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1495 - accuracy: 0.9443 - val_loss: 0.4048 - val_accuracy: 0.8552\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1555 - accuracy: 0.9448 - val_loss: 0.4057 - val_accuracy: 0.8575\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1515 - accuracy: 0.9448 - val_loss: 0.4075 - val_accuracy: 0.8609\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1428 - accuracy: 0.9451 - val_loss: 0.4043 - val_accuracy: 0.8643\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1436 - accuracy: 0.9457 - val_loss: 0.4119 - val_accuracy: 0.8609\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1429 - accuracy: 0.9462 - val_loss: 0.4086 - val_accuracy: 0.8597\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1443 - accuracy: 0.9448 - val_loss: 0.4124 - val_accuracy: 0.8597\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1375 - accuracy: 0.9491 - val_loss: 0.4213 - val_accuracy: 0.8609\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1321 - accuracy: 0.9530 - val_loss: 0.4197 - val_accuracy: 0.8586\n","Epoch 55/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1388 - accuracy: 0.9491 - val_loss: 0.4235 - val_accuracy: 0.8643\n","Epoch 56/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.1309 - accuracy: 0.9525 - val_loss: 0.4170 - val_accuracy: 0.8643\n","Epoch 57/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.1260 - accuracy: 0.9564 - val_loss: 0.4190 - val_accuracy: 0.8676\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1228 - accuracy: 0.9570 - val_loss: 0.4236 - val_accuracy: 0.8609\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1182 - accuracy: 0.9612 - val_loss: 0.4266 - val_accuracy: 0.8563\n","Epoch 60/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.1152 - accuracy: 0.9604 - val_loss: 0.4278 - val_accuracy: 0.8586\n","Epoch 61/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1130 - accuracy: 0.9615 - val_loss: 0.4427 - val_accuracy: 0.8597\n","Epoch 62/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1134 - accuracy: 0.9601 - val_loss: 0.4488 - val_accuracy: 0.8541\n","Epoch 63/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1162 - accuracy: 0.9561 - val_loss: 0.4423 - val_accuracy: 0.8552\n","Epoch 64/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1194 - accuracy: 0.9598 - val_loss: 0.4406 - val_accuracy: 0.8631\n","Epoch 65/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1074 - accuracy: 0.9638 - val_loss: 0.4448 - val_accuracy: 0.8563\n","Epoch 66/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1031 - accuracy: 0.9649 - val_loss: 0.4433 - val_accuracy: 0.8676\n","Epoch 67/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0974 - accuracy: 0.9709 - val_loss: 0.4440 - val_accuracy: 0.8631\n","Epoch 68/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0984 - accuracy: 0.9672 - val_loss: 0.4547 - val_accuracy: 0.8507\n","Epoch 69/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1051 - accuracy: 0.9632 - val_loss: 0.4587 - val_accuracy: 0.8586\n","Epoch 70/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0950 - accuracy: 0.9697 - val_loss: 0.4582 - val_accuracy: 0.8609\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0975 - accuracy: 0.9646 - val_loss: 0.4709 - val_accuracy: 0.8484\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0965 - accuracy: 0.9683 - val_loss: 0.4710 - val_accuracy: 0.8620\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0900 - accuracy: 0.9714 - val_loss: 0.4658 - val_accuracy: 0.8597\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0880 - accuracy: 0.9709 - val_loss: 0.4836 - val_accuracy: 0.8643\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0822 - accuracy: 0.9743 - val_loss: 0.4722 - val_accuracy: 0.8676\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0806 - accuracy: 0.9745 - val_loss: 0.4936 - val_accuracy: 0.8575\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0860 - accuracy: 0.9700 - val_loss: 0.4919 - val_accuracy: 0.8552\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0834 - accuracy: 0.9740 - val_loss: 0.4728 - val_accuracy: 0.8609\n","Epoch 79/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0745 - accuracy: 0.9782 - val_loss: 0.5254 - val_accuracy: 0.8586\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0779 - accuracy: 0.9743 - val_loss: 0.4842 - val_accuracy: 0.8586\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0708 - accuracy: 0.9799 - val_loss: 0.4937 - val_accuracy: 0.8643\n","Epoch 82/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0731 - accuracy: 0.9799 - val_loss: 0.4938 - val_accuracy: 0.8586\n","Epoch 83/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0688 - accuracy: 0.9802 - val_loss: 0.5003 - val_accuracy: 0.8609\n","Epoch 84/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0683 - accuracy: 0.9791 - val_loss: 0.4997 - val_accuracy: 0.8563\n","Epoch 85/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0660 - accuracy: 0.9830 - val_loss: 0.5138 - val_accuracy: 0.8563\n","Epoch 86/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0710 - accuracy: 0.9779 - val_loss: 0.5170 - val_accuracy: 0.8620\n","Epoch 87/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0692 - accuracy: 0.9785 - val_loss: 0.5133 - val_accuracy: 0.8552\n","Epoch 88/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0865 - accuracy: 0.9703 - val_loss: 0.5574 - val_accuracy: 0.8416\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0754 - accuracy: 0.9765 - val_loss: 0.5223 - val_accuracy: 0.8631\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0654 - accuracy: 0.9810 - val_loss: 0.5346 - val_accuracy: 0.8665\n","Epoch 91/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0584 - accuracy: 0.9859 - val_loss: 0.5768 - val_accuracy: 0.8552\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0748 - accuracy: 0.9737 - val_loss: 0.5188 - val_accuracy: 0.8541\n","Epoch 93/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0561 - accuracy: 0.9844 - val_loss: 0.5315 - val_accuracy: 0.8575\n","Epoch 94/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0603 - accuracy: 0.9827 - val_loss: 0.5333 - val_accuracy: 0.8529\n","Epoch 95/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0553 - accuracy: 0.9844 - val_loss: 0.5476 - val_accuracy: 0.8631\n","Epoch 96/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0548 - accuracy: 0.9833 - val_loss: 0.5382 - val_accuracy: 0.8586\n","Epoch 97/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0505 - accuracy: 0.9881 - val_loss: 0.5355 - val_accuracy: 0.8631\n","Epoch 98/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0501 - accuracy: 0.9884 - val_loss: 0.5435 - val_accuracy: 0.8609\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0532 - accuracy: 0.9830 - val_loss: 0.5777 - val_accuracy: 0.8620\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0521 - accuracy: 0.9853 - val_loss: 0.5614 - val_accuracy: 0.8609\n","{'loss': [0.3266569674015045, 0.3197253346443176, 0.3128262758255005, 0.3030255138874054, 0.2977901101112366, 0.3001593053340912, 0.29029956459999084, 0.28406864404678345, 0.28494879603385925, 0.2799719274044037, 0.2717357575893402, 0.2800195515155792, 0.27128732204437256, 0.2606965899467468, 0.2594512104988098, 0.25570836663246155, 0.2546393871307373, 0.2560066878795624, 0.24270294606685638, 0.2369803935289383, 0.24361121654510498, 0.23233650624752045, 0.23397527635097504, 0.22791887819766998, 0.21908874809741974, 0.2221139669418335, 0.21576406061649323, 0.2174481898546219, 0.20785318315029144, 0.20570357143878937, 0.2032008320093155, 0.20145893096923828, 0.1927112638950348, 0.19844461977481842, 0.18631617724895477, 0.1920497566461563, 0.1810024529695511, 0.1893821805715561, 0.1826256811618805, 0.17565466463565826, 0.1711754947900772, 0.17613907158374786, 0.1634189784526825, 0.16740728914737701, 0.16011135280132294, 0.1495446115732193, 0.15550543367862701, 0.1515151709318161, 0.14279477298259735, 0.14362719655036926, 0.1428809016942978, 0.14428050816059113, 0.13752302527427673, 0.13210569322109222, 0.13875985145568848, 0.1308959722518921, 0.1259554624557495, 0.12282273173332214, 0.11817148327827454, 0.11517352610826492, 0.11297331005334854, 0.11336885392665863, 0.11616096645593643, 0.11944562941789627, 0.10742960125207901, 0.10311274230480194, 0.09737946838140488, 0.09840131551027298, 0.10508223623037338, 0.09497781842947006, 0.09749919921159744, 0.09646937251091003, 0.09000420570373535, 0.08802377432584763, 0.08217400312423706, 0.08061543107032776, 0.08604642748832703, 0.08341440558433533, 0.07451535016298294, 0.07785425335168839, 0.07076253741979599, 0.07309862226247787, 0.0687936320900917, 0.06829450279474258, 0.06601924449205399, 0.07101289927959442, 0.06921494007110596, 0.08647848665714264, 0.07538247108459473, 0.06536808609962463, 0.058444343507289886, 0.07482168078422546, 0.056109823286533356, 0.06028736010193825, 0.055274397134780884, 0.05481712147593498, 0.05051085352897644, 0.05007820576429367, 0.05319854989647865, 0.05207626149058342], 'accuracy': [0.8571024537086487, 0.8585172891616821, 0.8664402961730957, 0.8760611414909363, 0.8737974166870117, 0.8743633031845093, 0.8803055882453918, 0.8851160407066345, 0.8788907527923584, 0.8859649300575256, 0.8865308165550232, 0.8803055882453918, 0.8865308165550232, 0.8913412690162659, 0.8950198292732239, 0.8961516618728638, 0.8953027725219727, 0.8992642760276794, 0.9026598930358887, 0.9054895043373108, 0.9018110036849976, 0.9046406149864197, 0.9069043397903442, 0.9074702858924866, 0.914544403553009, 0.9122806787490845, 0.9151103496551514, 0.9119977355003357, 0.9199207425117493, 0.9168081283569336, 0.9210526347160339, 0.9199207425117493, 0.9298245906829834, 0.9165251851081848, 0.9278438091278076, 0.921901524066925, 0.92840975522995, 0.9244481921195984, 0.9281267523765564, 0.934069037437439, 0.9335030913352966, 0.9301075339317322, 0.9422750473022461, 0.9366157054901123, 0.9400113224983215, 0.9442558288574219, 0.9448217153549194, 0.9448217153549194, 0.945104718208313, 0.9456706047058105, 0.9462365508079529, 0.9448217153549194, 0.9490662217140198, 0.9530277252197266, 0.9490662217140198, 0.9524617791175842, 0.9564233422279358, 0.9569892287254333, 0.9612337350845337, 0.9603848457336426, 0.9615166783332825, 0.960101842880249, 0.9561403393745422, 0.9598188996315002, 0.963780403137207, 0.9649122953414917, 0.9708545804023743, 0.9671760201454163, 0.9632145166397095, 0.9697226881980896, 0.9646292924880981, 0.9683078527450562, 0.9714204668998718, 0.9708545804023743, 0.9742501378059387, 0.9745330810546875, 0.9700056314468384, 0.9739671945571899, 0.9782116413116455, 0.9742501378059387, 0.9799094796180725, 0.9799094796180725, 0.9801924228668213, 0.9790605306625366, 0.9830220937728882, 0.9779286980628967, 0.9784946441650391, 0.9702886343002319, 0.9765138626098633, 0.9810413122177124, 0.9858517050743103, 0.9736841917037964, 0.9844368696212769, 0.9827390909194946, 0.9844368696212769, 0.983305037021637, 0.9881154298782349, 0.9883984327316284, 0.9830220937728882, 0.9852858185768127], 'val_loss': [0.6775735020637512, 0.6738964915275574, 0.668055534362793, 0.6650726199150085, 0.656272828578949, 0.6512543559074402, 0.643879771232605, 0.6346650719642639, 0.6229640245437622, 0.6112566590309143, 0.598629891872406, 0.5781530737876892, 0.5642033219337463, 0.5367610454559326, 0.5123218297958374, 0.48854854702949524, 0.4699339270591736, 0.4388989508152008, 0.41989874839782715, 0.3944159746170044, 0.3747178912162781, 0.3695829510688782, 0.3553027808666229, 0.35873866081237793, 0.3513563275337219, 0.3511458933353424, 0.3521271049976349, 0.3627645969390869, 0.3608221709728241, 0.3632296323776245, 0.368094801902771, 0.3691266179084778, 0.3753657937049866, 0.3767205774784088, 0.3749518394470215, 0.38018572330474854, 0.3826526701450348, 0.38545486330986023, 0.3870827257633209, 0.4024510085582733, 0.3889129161834717, 0.3876497149467468, 0.39100757241249084, 0.3949327766895294, 0.3977157771587372, 0.4047534167766571, 0.40566936135292053, 0.4075402617454529, 0.4043186604976654, 0.4118715226650238, 0.40860143303871155, 0.4123840630054474, 0.4212789535522461, 0.41973382234573364, 0.423542320728302, 0.4170464277267456, 0.4189869463443756, 0.4235956072807312, 0.4265710115432739, 0.4278497099876404, 0.4427233934402466, 0.4488177001476288, 0.4423424303531647, 0.4406425654888153, 0.44481000304222107, 0.44332391023635864, 0.4440290927886963, 0.45471060276031494, 0.4587034583091736, 0.4582013189792633, 0.4709455668926239, 0.4709568917751312, 0.4657610058784485, 0.48364830017089844, 0.47215989232063293, 0.49363619089126587, 0.4919472932815552, 0.47284066677093506, 0.5254210233688354, 0.48424339294433594, 0.4936635196208954, 0.4938466548919678, 0.5003159046173096, 0.49966269731521606, 0.5138450264930725, 0.5170249938964844, 0.5132520794868469, 0.5574173331260681, 0.5223040580749512, 0.5346351861953735, 0.5768471360206604, 0.5188105702400208, 0.5315244793891907, 0.5333312153816223, 0.5476264953613281, 0.5381906628608704, 0.535455048084259, 0.5434765219688416, 0.5776804685592651, 0.5613560676574707], 'val_accuracy': [0.49660632014274597, 0.5, 0.5180995464324951, 0.5147058963775635, 0.6063348650932312, 0.6029411554336548, 0.622171938419342, 0.6900452375411987, 0.7477375268936157, 0.7647058963775635, 0.7828054428100586, 0.8280543088912964, 0.8167420625686646, 0.8529411554336548, 0.8540723919868469, 0.8574660420417786, 0.8529411554336548, 0.8540723919868469, 0.8585972785949707, 0.8450226187705994, 0.848416268825531, 0.8552036285400391, 0.8574660420417786, 0.8552036285400391, 0.8574660420417786, 0.8506787419319153, 0.8563348650932312, 0.8506787419319153, 0.8585972785949707, 0.860859751701355, 0.8585972785949707, 0.8597285151481628, 0.8619909286499023, 0.8597285151481628, 0.8631221652030945, 0.860859751701355, 0.8597285151481628, 0.8597285151481628, 0.8585972785949707, 0.8540723919868469, 0.8585972785949707, 0.8631221652030945, 0.8653846383094788, 0.8619909286499023, 0.8585972785949707, 0.8552036285400391, 0.8574660420417786, 0.860859751701355, 0.8642534017562866, 0.860859751701355, 0.8597285151481628, 0.8597285151481628, 0.860859751701355, 0.8585972785949707, 0.8642534017562866, 0.8642534017562866, 0.8676470518112183, 0.860859751701355, 0.8563348650932312, 0.8585972785949707, 0.8597285151481628, 0.8540723919868469, 0.8552036285400391, 0.8631221652030945, 0.8563348650932312, 0.8676470518112183, 0.8631221652030945, 0.8506787419319153, 0.8585972785949707, 0.860859751701355, 0.848416268825531, 0.8619909286499023, 0.8597285151481628, 0.8642534017562866, 0.8676470518112183, 0.8574660420417786, 0.8552036285400391, 0.860859751701355, 0.8585972785949707, 0.8585972785949707, 0.8642534017562866, 0.8585972785949707, 0.860859751701355, 0.8563348650932312, 0.8563348650932312, 0.8619909286499023, 0.8552036285400391, 0.8416289687156677, 0.8631221652030945, 0.8665158152580261, 0.8552036285400391, 0.8540723919868469, 0.8574660420417786, 0.8529411554336548, 0.8631221652030945, 0.8585972785949707, 0.8631221652030945, 0.860859751701355, 0.8619909286499023, 0.860859751701355]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.3069 - accuracy: 0.8698"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 74ms/step - loss: 0.3066 - accuracy: 0.8703 - val_loss: 0.6783 - val_accuracy: 0.4866\n","Epoch 2/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.2990 - accuracy: 0.8783 - val_loss: 0.6727 - val_accuracy: 0.4948\n","Epoch 3/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2933 - accuracy: 0.8791 - val_loss: 0.6678 - val_accuracy: 0.5000\n","Epoch 4/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2839 - accuracy: 0.8848 - val_loss: 0.6619 - val_accuracy: 0.5351\n","Epoch 5/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2860 - accuracy: 0.8791 - val_loss: 0.6554 - val_accuracy: 0.5568\n","Epoch 6/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.2814 - accuracy: 0.8842 - val_loss: 0.6475 - val_accuracy: 0.6043\n","Epoch 7/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2834 - accuracy: 0.8819 - val_loss: 0.6369 - val_accuracy: 0.6477\n","Epoch 8/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2718 - accuracy: 0.8894 - val_loss: 0.6244 - val_accuracy: 0.7490\n","Epoch 9/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2674 - accuracy: 0.8915 - val_loss: 0.6100 - val_accuracy: 0.7800\n","Epoch 10/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2687 - accuracy: 0.8912 - val_loss: 0.5931 - val_accuracy: 0.8182\n","Epoch 11/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2597 - accuracy: 0.8946 - val_loss: 0.5798 - val_accuracy: 0.7913\n","Epoch 12/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2608 - accuracy: 0.8953 - val_loss: 0.5549 - val_accuracy: 0.8337\n","Epoch 13/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2519 - accuracy: 0.8995 - val_loss: 0.5330 - val_accuracy: 0.8337\n","Epoch 14/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2513 - accuracy: 0.9000 - val_loss: 0.5056 - val_accuracy: 0.8388\n","Epoch 15/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2465 - accuracy: 0.9072 - val_loss: 0.4696 - val_accuracy: 0.8564\n","Epoch 16/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2437 - accuracy: 0.9003 - val_loss: 0.4466 - val_accuracy: 0.8543\n","Epoch 17/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2434 - accuracy: 0.9083 - val_loss: 0.4315 - val_accuracy: 0.8450\n","Epoch 18/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2360 - accuracy: 0.9052 - val_loss: 0.3893 - val_accuracy: 0.8461\n","Epoch 19/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2386 - accuracy: 0.9052 - val_loss: 0.3727 - val_accuracy: 0.8543\n","Epoch 20/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2313 - accuracy: 0.9098 - val_loss: 0.3597 - val_accuracy: 0.8512\n","Epoch 21/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2304 - accuracy: 0.9098 - val_loss: 0.3515 - val_accuracy: 0.8554\n","Epoch 22/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2256 - accuracy: 0.9101 - val_loss: 0.3576 - val_accuracy: 0.8357\n","Epoch 23/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2378 - accuracy: 0.9021 - val_loss: 0.3428 - val_accuracy: 0.8543\n","Epoch 24/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2335 - accuracy: 0.9080 - val_loss: 0.3463 - val_accuracy: 0.8502\n","Epoch 25/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2141 - accuracy: 0.9173 - val_loss: 0.3462 - val_accuracy: 0.8502\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2149 - accuracy: 0.9129 - val_loss: 0.3556 - val_accuracy: 0.8564\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2108 - accuracy: 0.9150 - val_loss: 0.3634 - val_accuracy: 0.8523\n","Epoch 28/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2067 - accuracy: 0.9251 - val_loss: 0.3610 - val_accuracy: 0.8502\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2073 - accuracy: 0.9194 - val_loss: 0.3654 - val_accuracy: 0.8512\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2075 - accuracy: 0.9186 - val_loss: 0.3799 - val_accuracy: 0.8512\n","Epoch 31/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2034 - accuracy: 0.9207 - val_loss: 0.3717 - val_accuracy: 0.8512\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1964 - accuracy: 0.9214 - val_loss: 0.3734 - val_accuracy: 0.8492\n","Epoch 33/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.1955 - accuracy: 0.9233 - val_loss: 0.3796 - val_accuracy: 0.8502\n","Epoch 34/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2046 - accuracy: 0.9191 - val_loss: 0.3952 - val_accuracy: 0.8481\n","Epoch 35/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1877 - accuracy: 0.9310 - val_loss: 0.3780 - val_accuracy: 0.8492\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1861 - accuracy: 0.9276 - val_loss: 0.3814 - val_accuracy: 0.8512\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1796 - accuracy: 0.9326 - val_loss: 0.3810 - val_accuracy: 0.8481\n","Epoch 38/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1790 - accuracy: 0.9341 - val_loss: 0.3871 - val_accuracy: 0.8502\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1758 - accuracy: 0.9339 - val_loss: 0.3958 - val_accuracy: 0.8471\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1740 - accuracy: 0.9333 - val_loss: 0.3901 - val_accuracy: 0.8440\n","Epoch 41/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1709 - accuracy: 0.9370 - val_loss: 0.3894 - val_accuracy: 0.8481\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1630 - accuracy: 0.9434 - val_loss: 0.3929 - val_accuracy: 0.8523\n","Epoch 43/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1694 - accuracy: 0.9359 - val_loss: 0.3997 - val_accuracy: 0.8471\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1615 - accuracy: 0.9419 - val_loss: 0.3991 - val_accuracy: 0.8440\n","Epoch 45/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1608 - accuracy: 0.9388 - val_loss: 0.4047 - val_accuracy: 0.8512\n","Epoch 46/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1603 - accuracy: 0.9395 - val_loss: 0.4154 - val_accuracy: 0.8461\n","Epoch 47/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1579 - accuracy: 0.9403 - val_loss: 0.4131 - val_accuracy: 0.8512\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1499 - accuracy: 0.9468 - val_loss: 0.4056 - val_accuracy: 0.8419\n","Epoch 49/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1564 - accuracy: 0.9429 - val_loss: 0.4164 - val_accuracy: 0.8492\n","Epoch 50/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1458 - accuracy: 0.9450 - val_loss: 0.4365 - val_accuracy: 0.8533\n","Epoch 51/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1464 - accuracy: 0.9475 - val_loss: 0.4191 - val_accuracy: 0.8440\n","Epoch 52/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1435 - accuracy: 0.9452 - val_loss: 0.4302 - val_accuracy: 0.8471\n","Epoch 53/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1403 - accuracy: 0.9494 - val_loss: 0.4427 - val_accuracy: 0.8409\n","Epoch 54/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1388 - accuracy: 0.9481 - val_loss: 0.4218 - val_accuracy: 0.8419\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1368 - accuracy: 0.9514 - val_loss: 0.4254 - val_accuracy: 0.8430\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1323 - accuracy: 0.9506 - val_loss: 0.4431 - val_accuracy: 0.8399\n","Epoch 57/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.1310 - accuracy: 0.9543 - val_loss: 0.4346 - val_accuracy: 0.8399\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1254 - accuracy: 0.9537 - val_loss: 0.4443 - val_accuracy: 0.8461\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1277 - accuracy: 0.9561 - val_loss: 0.4419 - val_accuracy: 0.8409\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1213 - accuracy: 0.9592 - val_loss: 0.4508 - val_accuracy: 0.8461\n","Epoch 61/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1176 - accuracy: 0.9579 - val_loss: 0.4612 - val_accuracy: 0.8409\n","Epoch 62/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1245 - accuracy: 0.9522 - val_loss: 0.4571 - val_accuracy: 0.8378\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1198 - accuracy: 0.9556 - val_loss: 0.4543 - val_accuracy: 0.8388\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1176 - accuracy: 0.9553 - val_loss: 0.4644 - val_accuracy: 0.8399\n","Epoch 65/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1081 - accuracy: 0.9625 - val_loss: 0.4674 - val_accuracy: 0.8368\n","Epoch 66/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1235 - accuracy: 0.9548 - val_loss: 0.4577 - val_accuracy: 0.8492\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1009 - accuracy: 0.9643 - val_loss: 0.4680 - val_accuracy: 0.8523\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1075 - accuracy: 0.9641 - val_loss: 0.4629 - val_accuracy: 0.8461\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1128 - accuracy: 0.9620 - val_loss: 0.4636 - val_accuracy: 0.8450\n","Epoch 70/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0961 - accuracy: 0.9690 - val_loss: 0.4729 - val_accuracy: 0.8430\n","Epoch 71/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.1064 - accuracy: 0.9615 - val_loss: 0.4709 - val_accuracy: 0.8440\n","Epoch 72/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0965 - accuracy: 0.9698 - val_loss: 0.4776 - val_accuracy: 0.8419\n","Epoch 73/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0978 - accuracy: 0.9656 - val_loss: 0.5020 - val_accuracy: 0.8419\n","Epoch 74/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0920 - accuracy: 0.9700 - val_loss: 0.4915 - val_accuracy: 0.8471\n","Epoch 75/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0871 - accuracy: 0.9721 - val_loss: 0.5014 - val_accuracy: 0.8409\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0908 - accuracy: 0.9695 - val_loss: 0.4998 - val_accuracy: 0.8430\n","Epoch 77/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0911 - accuracy: 0.9729 - val_loss: 0.5013 - val_accuracy: 0.8388\n","Epoch 78/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0779 - accuracy: 0.9762 - val_loss: 0.5091 - val_accuracy: 0.8440\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0801 - accuracy: 0.9739 - val_loss: 0.5124 - val_accuracy: 0.8419\n","Epoch 80/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0814 - accuracy: 0.9711 - val_loss: 0.5071 - val_accuracy: 0.8450\n","Epoch 81/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0789 - accuracy: 0.9726 - val_loss: 0.5128 - val_accuracy: 0.8440\n","Epoch 82/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0788 - accuracy: 0.9742 - val_loss: 0.5200 - val_accuracy: 0.8440\n","Epoch 83/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0756 - accuracy: 0.9760 - val_loss: 0.5224 - val_accuracy: 0.8409\n","Epoch 84/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0842 - accuracy: 0.9718 - val_loss: 0.5514 - val_accuracy: 0.8347\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0764 - accuracy: 0.9762 - val_loss: 0.5363 - val_accuracy: 0.8388\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0781 - accuracy: 0.9731 - val_loss: 0.5364 - val_accuracy: 0.8430\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0756 - accuracy: 0.9755 - val_loss: 0.5322 - val_accuracy: 0.8368\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0877 - accuracy: 0.9687 - val_loss: 0.5966 - val_accuracy: 0.8450\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0721 - accuracy: 0.9773 - val_loss: 0.5265 - val_accuracy: 0.8430\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0696 - accuracy: 0.9786 - val_loss: 0.5378 - val_accuracy: 0.8399\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0668 - accuracy: 0.9804 - val_loss: 0.5529 - val_accuracy: 0.8440\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0654 - accuracy: 0.9819 - val_loss: 0.5554 - val_accuracy: 0.8368\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0644 - accuracy: 0.9809 - val_loss: 0.5551 - val_accuracy: 0.8388\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0585 - accuracy: 0.9835 - val_loss: 0.5610 - val_accuracy: 0.8430\n","Epoch 95/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0636 - accuracy: 0.9814 - val_loss: 0.5646 - val_accuracy: 0.8388\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0703 - accuracy: 0.9749 - val_loss: 0.5605 - val_accuracy: 0.8430\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0612 - accuracy: 0.9809 - val_loss: 0.5672 - val_accuracy: 0.8347\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0580 - accuracy: 0.9835 - val_loss: 0.5753 - val_accuracy: 0.8368\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0609 - accuracy: 0.9814 - val_loss: 0.5892 - val_accuracy: 0.8347\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0592 - accuracy: 0.9819 - val_loss: 0.5923 - val_accuracy: 0.8295\n","{'loss': [0.30664825439453125, 0.2989518940448761, 0.29332855343818665, 0.28394466638565063, 0.28600215911865234, 0.2813817262649536, 0.2834182679653168, 0.27180248498916626, 0.2674084007740021, 0.2686628997325897, 0.25973838567733765, 0.2607633173465729, 0.2519342303276062, 0.2513059079647064, 0.24646589159965515, 0.24370843172073364, 0.24343350529670715, 0.23598511517047882, 0.23862633109092712, 0.23126628994941711, 0.23039674758911133, 0.22555525600910187, 0.23777812719345093, 0.2335435301065445, 0.21413472294807434, 0.21494117379188538, 0.21075661480426788, 0.20667721331119537, 0.20728744566440582, 0.20752663910388947, 0.20340675115585327, 0.19637636840343475, 0.19552990794181824, 0.2045922428369522, 0.18765991926193237, 0.18606577813625336, 0.1796354204416275, 0.17903196811676025, 0.1757620871067047, 0.1739850491285324, 0.1708926409482956, 0.16301052272319794, 0.1694449782371521, 0.1615302711725235, 0.1608469933271408, 0.16034859418869019, 0.15791228413581848, 0.14992474019527435, 0.15636199712753296, 0.14578184485435486, 0.14636296033859253, 0.14353768527507782, 0.14025314152240753, 0.1388368457555771, 0.13683433830738068, 0.13232693076133728, 0.1309632956981659, 0.12539003789424896, 0.12771397829055786, 0.1212782934308052, 0.11757952719926834, 0.12445863336324692, 0.11980624496936798, 0.11756914108991623, 0.10808505862951279, 0.12346574664115906, 0.10089116543531418, 0.10746782273054123, 0.11279813200235367, 0.09609581530094147, 0.10636772960424423, 0.096542127430439, 0.09781648963689804, 0.09197285771369934, 0.08712322264909744, 0.09076539427042007, 0.09113761782646179, 0.0778999850153923, 0.08014772832393646, 0.08136142045259476, 0.07886304706335068, 0.07877138257026672, 0.07558619230985641, 0.08421213179826736, 0.07637149095535278, 0.07806113362312317, 0.07563900947570801, 0.08774411678314209, 0.07212119549512863, 0.06964945793151855, 0.06676510721445084, 0.06540578603744507, 0.06442052125930786, 0.05853710696101189, 0.06364384293556213, 0.07029508799314499, 0.06117995083332062, 0.05800725147128105, 0.060866571962833405, 0.059171803295612335], 'accuracy': [0.8702842593193054, 0.8782945871353149, 0.8790697455406189, 0.8847545385360718, 0.8790697455406189, 0.8842377066612244, 0.8819121718406677, 0.8894056677818298, 0.8914728760719299, 0.8912144899368286, 0.8945736289024353, 0.895348846912384, 0.8994832038879395, 0.8999999761581421, 0.9072351455688477, 0.9002584218978882, 0.9082687497138977, 0.9051679372787476, 0.9051679372787476, 0.9098191261291504, 0.9098191261291504, 0.9100775122642517, 0.9020671844482422, 0.9080103635787964, 0.9173126816749573, 0.9129198789596558, 0.9149870872497559, 0.9250646233558655, 0.9193798303604126, 0.9186046719551086, 0.920671820640564, 0.9214470386505127, 0.9232558012008667, 0.9191214442253113, 0.9310077428817749, 0.9276486039161682, 0.9325581192970276, 0.934108555316925, 0.933850109577179, 0.9333333373069763, 0.9369509220123291, 0.9434108734130859, 0.935917317867279, 0.9418604373931885, 0.9387596845626831, 0.9395349025726318, 0.9403100609779358, 0.9467700123786926, 0.9428940415382385, 0.9449612498283386, 0.9475452303886414, 0.9452196359634399, 0.9493539929389954, 0.948062002658844, 0.9514212012290955, 0.9506459832191467, 0.9542635679244995, 0.9537467956542969, 0.9560723304748535, 0.9591731429100037, 0.9578811526298523, 0.9521963596343994, 0.9555555582046509, 0.9552971720695496, 0.9625322818756104, 0.9547803401947021, 0.9643411040306091, 0.964082658290863, 0.9620155096054077, 0.9689922332763672, 0.9614987373352051, 0.9697674512863159, 0.9656330943107605, 0.9700258374214172, 0.9720930457115173, 0.9695090651512146, 0.9728682041168213, 0.9762274026870728, 0.9739018082618713, 0.9710594415664673, 0.97260981798172, 0.9741601943969727, 0.9759690165519714, 0.9718345999717712, 0.9762274026870728, 0.9731265902519226, 0.975452184677124, 0.9687338471412659, 0.9772610068321228, 0.9785529971122742, 0.9803617596626282, 0.9819121360778809, 0.9808785319328308, 0.9834625124931335, 0.9813953638076782, 0.9749354124069214, 0.9808785319328308, 0.9834625124931335, 0.9813953638076782, 0.9819121360778809], 'val_loss': [0.6782552003860474, 0.672659695148468, 0.6677715182304382, 0.6619031429290771, 0.6553614139556885, 0.647537112236023, 0.6369129419326782, 0.6243908405303955, 0.6099703907966614, 0.5930980443954468, 0.5798397660255432, 0.554946780204773, 0.5330462455749512, 0.5056149959564209, 0.4695660173892975, 0.4466340243816376, 0.4315023422241211, 0.3892710208892822, 0.3727216422557831, 0.3597385883331299, 0.35147109627723694, 0.35757139325141907, 0.3427940011024475, 0.3462912142276764, 0.34619805216789246, 0.35562583804130554, 0.36341631412506104, 0.36098602414131165, 0.365416944026947, 0.37993115186691284, 0.3716580271720886, 0.3733651638031006, 0.37960538268089294, 0.39524102210998535, 0.3779841363430023, 0.38136500120162964, 0.38100743293762207, 0.38706955313682556, 0.3957616090774536, 0.3901388943195343, 0.3893812596797943, 0.3928850293159485, 0.39972636103630066, 0.3991250991821289, 0.40473106503486633, 0.4154268205165863, 0.41314584016799927, 0.4056163728237152, 0.416390597820282, 0.43649616837501526, 0.41912776231765747, 0.43019258975982666, 0.4426797330379486, 0.42177316546440125, 0.42538440227508545, 0.44312623143196106, 0.43456748127937317, 0.44429975748062134, 0.44185489416122437, 0.45081639289855957, 0.46122077107429504, 0.45714709162712097, 0.45427829027175903, 0.4644075632095337, 0.46743863821029663, 0.4576975405216217, 0.4679725468158722, 0.4629373848438263, 0.46355295181274414, 0.4728530943393707, 0.4708804786205292, 0.4775722026824951, 0.5020314455032349, 0.49147191643714905, 0.5014331340789795, 0.4997602701187134, 0.501303493976593, 0.5090993642807007, 0.5123940110206604, 0.5071379542350769, 0.5127840042114258, 0.5199531316757202, 0.5223540663719177, 0.5513789057731628, 0.5362591743469238, 0.5363600254058838, 0.5321738719940186, 0.5965948104858398, 0.526471734046936, 0.5378496050834656, 0.5529065728187561, 0.5554034113883972, 0.5550951361656189, 0.5610369443893433, 0.5646490454673767, 0.560513973236084, 0.5671712160110474, 0.5752687454223633, 0.5891991853713989, 0.5923030972480774], 'val_accuracy': [0.48657023906707764, 0.4948347210884094, 0.5, 0.5351239442825317, 0.5568181872367859, 0.6043388247489929, 0.6477272510528564, 0.7489669322967529, 0.7799586653709412, 0.8181818127632141, 0.7913222908973694, 0.8336777091026306, 0.8336777091026306, 0.8388429880142212, 0.8564049601554871, 0.8543388247489929, 0.8450413346290588, 0.8460744023323059, 0.8543388247489929, 0.8512396812438965, 0.85537189245224, 0.83574378490448, 0.8543388247489929, 0.8502066135406494, 0.8502066135406494, 0.8564049601554871, 0.8522727489471436, 0.8502066135406494, 0.8512396812438965, 0.8512396812438965, 0.8512396812438965, 0.8491735458374023, 0.8502066135406494, 0.8481404781341553, 0.8491735458374023, 0.8512396812438965, 0.8481404781341553, 0.8502066135406494, 0.8471074104309082, 0.8440082669258118, 0.8481404781341553, 0.8522727489471436, 0.8471074104309082, 0.8440082669258118, 0.8512396812438965, 0.8460744023323059, 0.8512396812438965, 0.8419421315193176, 0.8491735458374023, 0.8533057570457458, 0.8440082669258118, 0.8471074104309082, 0.8409090638160706, 0.8419421315193176, 0.8429751992225647, 0.8398760557174683, 0.8398760557174683, 0.8460744023323059, 0.8409090638160706, 0.8460744023323059, 0.8409090638160706, 0.8378099203109741, 0.8388429880142212, 0.8398760557174683, 0.836776852607727, 0.8491735458374023, 0.8522727489471436, 0.8460744023323059, 0.8450413346290588, 0.8429751992225647, 0.8440082669258118, 0.8419421315193176, 0.8419421315193176, 0.8471074104309082, 0.8409090638160706, 0.8429751992225647, 0.8388429880142212, 0.8440082669258118, 0.8419421315193176, 0.8450413346290588, 0.8440082669258118, 0.8440082669258118, 0.8409090638160706, 0.8347107172012329, 0.8388429880142212, 0.8429751992225647, 0.836776852607727, 0.8450413346290588, 0.8429751992225647, 0.8398760557174683, 0.8440082669258118, 0.836776852607727, 0.8388429880142212, 0.8429751992225647, 0.8388429880142212, 0.8429751992225647, 0.8347107172012329, 0.836776852607727, 0.8347107172012329, 0.8295454382896423]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.1294 - accuracy: 0.9573"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 56ms/step - loss: 0.1296 - accuracy: 0.9569 - val_loss: 0.6644 - val_accuracy: 0.4946\n","Epoch 2/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.1220 - accuracy: 0.9572 - val_loss: 0.6597 - val_accuracy: 0.4989\n","Epoch 3/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.1136 - accuracy: 0.9593 - val_loss: 0.6465 - val_accuracy: 0.5496\n","Epoch 4/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1005 - accuracy: 0.9674 - val_loss: 0.6359 - val_accuracy: 0.6067\n","Epoch 5/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0906 - accuracy: 0.9698 - val_loss: 0.6235 - val_accuracy: 0.6573\n","Epoch 6/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0992 - accuracy: 0.9685 - val_loss: 0.6136 - val_accuracy: 0.6724\n","Epoch 7/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0941 - accuracy: 0.9685 - val_loss: 0.5893 - val_accuracy: 0.7856\n","Epoch 8/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0858 - accuracy: 0.9698 - val_loss: 0.5743 - val_accuracy: 0.7877\n","Epoch 9/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0887 - accuracy: 0.9698 - val_loss: 0.5661 - val_accuracy: 0.7317\n","Epoch 10/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.0851 - accuracy: 0.9728 - val_loss: 0.5230 - val_accuracy: 0.8793\n","Epoch 11/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.0815 - accuracy: 0.9747 - val_loss: 0.4989 - val_accuracy: 0.8836\n","Epoch 12/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0750 - accuracy: 0.9752 - val_loss: 0.4734 - val_accuracy: 0.8739\n","Epoch 13/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0785 - accuracy: 0.9752 - val_loss: 0.4438 - val_accuracy: 0.8782\n","Epoch 14/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0759 - accuracy: 0.9774 - val_loss: 0.4132 - val_accuracy: 0.8847\n","Epoch 15/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0746 - accuracy: 0.9768 - val_loss: 0.3655 - val_accuracy: 0.9062\n","Epoch 16/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0742 - accuracy: 0.9758 - val_loss: 0.3506 - val_accuracy: 0.8858\n","Epoch 17/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0713 - accuracy: 0.9798 - val_loss: 0.3162 - val_accuracy: 0.8998\n","Epoch 18/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0674 - accuracy: 0.9814 - val_loss: 0.2751 - val_accuracy: 0.8998\n","Epoch 19/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0664 - accuracy: 0.9801 - val_loss: 0.2686 - val_accuracy: 0.9019\n","Epoch 20/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0665 - accuracy: 0.9787 - val_loss: 0.2461 - val_accuracy: 0.9062\n","Epoch 21/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0668 - accuracy: 0.9806 - val_loss: 0.2389 - val_accuracy: 0.9084\n","Epoch 22/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0715 - accuracy: 0.9798 - val_loss: 0.2616 - val_accuracy: 0.8955\n","Epoch 23/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0627 - accuracy: 0.9817 - val_loss: 0.2388 - val_accuracy: 0.9095\n","Epoch 24/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0572 - accuracy: 0.9852 - val_loss: 0.2483 - val_accuracy: 0.9062\n","Epoch 25/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0625 - accuracy: 0.9822 - val_loss: 0.2632 - val_accuracy: 0.9030\n","Epoch 26/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0518 - accuracy: 0.9846 - val_loss: 0.2579 - val_accuracy: 0.9116\n","Epoch 27/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0645 - accuracy: 0.9795 - val_loss: 0.2743 - val_accuracy: 0.9095\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0592 - accuracy: 0.9828 - val_loss: 0.2823 - val_accuracy: 0.9062\n","Epoch 29/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0515 - accuracy: 0.9863 - val_loss: 0.2781 - val_accuracy: 0.9138\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0511 - accuracy: 0.9871 - val_loss: 0.2944 - val_accuracy: 0.9062\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0557 - accuracy: 0.9855 - val_loss: 0.3661 - val_accuracy: 0.8847\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0482 - accuracy: 0.9884 - val_loss: 0.2972 - val_accuracy: 0.9052\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0496 - accuracy: 0.9857 - val_loss: 0.3070 - val_accuracy: 0.9062\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0462 - accuracy: 0.9879 - val_loss: 0.3166 - val_accuracy: 0.9084\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0430 - accuracy: 0.9895 - val_loss: 0.3067 - val_accuracy: 0.9106\n","Epoch 36/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0445 - accuracy: 0.9884 - val_loss: 0.3082 - val_accuracy: 0.9073\n","Epoch 37/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0428 - accuracy: 0.9881 - val_loss: 0.3185 - val_accuracy: 0.9116\n","Epoch 38/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0406 - accuracy: 0.9900 - val_loss: 0.4057 - val_accuracy: 0.8772\n","Epoch 39/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0543 - accuracy: 0.9814 - val_loss: 0.3274 - val_accuracy: 0.9106\n","Epoch 40/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0426 - accuracy: 0.9895 - val_loss: 0.3335 - val_accuracy: 0.9009\n","Epoch 41/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0417 - accuracy: 0.9890 - val_loss: 0.3432 - val_accuracy: 0.9062\n","Epoch 42/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0400 - accuracy: 0.9890 - val_loss: 0.3364 - val_accuracy: 0.9041\n","Epoch 43/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0373 - accuracy: 0.9927 - val_loss: 0.3438 - val_accuracy: 0.8998\n","Epoch 44/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0464 - accuracy: 0.9876 - val_loss: 0.3654 - val_accuracy: 0.8901\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0385 - accuracy: 0.9898 - val_loss: 0.3397 - val_accuracy: 0.9041\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0398 - accuracy: 0.9892 - val_loss: 0.3473 - val_accuracy: 0.9030\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0436 - accuracy: 0.9881 - val_loss: 0.3690 - val_accuracy: 0.9009\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0385 - accuracy: 0.9898 - val_loss: 0.3489 - val_accuracy: 0.9019\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0327 - accuracy: 0.9938 - val_loss: 0.3561 - val_accuracy: 0.8987\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0351 - accuracy: 0.9900 - val_loss: 0.3706 - val_accuracy: 0.9009\n","Epoch 51/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0353 - accuracy: 0.9906 - val_loss: 0.3903 - val_accuracy: 0.8944\n","Epoch 52/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0320 - accuracy: 0.9935 - val_loss: 0.3705 - val_accuracy: 0.8998\n","Epoch 53/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0360 - accuracy: 0.9900 - val_loss: 0.3567 - val_accuracy: 0.8955\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0432 - accuracy: 0.9887 - val_loss: 0.3936 - val_accuracy: 0.8933\n","Epoch 55/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0366 - accuracy: 0.9906 - val_loss: 0.3814 - val_accuracy: 0.8976\n","Epoch 56/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0308 - accuracy: 0.9916 - val_loss: 0.3878 - val_accuracy: 0.8955\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0299 - accuracy: 0.9933 - val_loss: 0.3853 - val_accuracy: 0.8955\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0299 - accuracy: 0.9930 - val_loss: 0.3916 - val_accuracy: 0.8966\n","Epoch 59/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0303 - accuracy: 0.9925 - val_loss: 0.3788 - val_accuracy: 0.8976\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0258 - accuracy: 0.9938 - val_loss: 0.3937 - val_accuracy: 0.8944\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0292 - accuracy: 0.9933 - val_loss: 0.3754 - val_accuracy: 0.9041\n","Epoch 62/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0285 - accuracy: 0.9927 - val_loss: 0.3804 - val_accuracy: 0.9019\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0244 - accuracy: 0.9949 - val_loss: 0.3786 - val_accuracy: 0.9062\n","Epoch 64/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0236 - accuracy: 0.9957 - val_loss: 0.3932 - val_accuracy: 0.8944\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0224 - accuracy: 0.9954 - val_loss: 0.4126 - val_accuracy: 0.8890\n","Epoch 66/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0314 - accuracy: 0.9908 - val_loss: 0.3894 - val_accuracy: 0.8976\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0223 - accuracy: 0.9949 - val_loss: 0.4026 - val_accuracy: 0.8998\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0205 - accuracy: 0.9954 - val_loss: 0.3987 - val_accuracy: 0.8955\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0218 - accuracy: 0.9949 - val_loss: 0.3978 - val_accuracy: 0.8955\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0279 - accuracy: 0.9903 - val_loss: 0.4405 - val_accuracy: 0.8933\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0478 - accuracy: 0.9833 - val_loss: 0.3978 - val_accuracy: 0.9030\n","Epoch 72/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0236 - accuracy: 0.9943 - val_loss: 0.3932 - val_accuracy: 0.9062\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0232 - accuracy: 0.9946 - val_loss: 0.4852 - val_accuracy: 0.8728\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0241 - accuracy: 0.9925 - val_loss: 0.4024 - val_accuracy: 0.9041\n","Epoch 75/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0199 - accuracy: 0.9952 - val_loss: 0.4220 - val_accuracy: 0.8976\n","Epoch 76/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0198 - accuracy: 0.9962 - val_loss: 0.4442 - val_accuracy: 0.8912\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0198 - accuracy: 0.9957 - val_loss: 0.4120 - val_accuracy: 0.8944\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0190 - accuracy: 0.9957 - val_loss: 0.4134 - val_accuracy: 0.9073\n","Epoch 79/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0192 - accuracy: 0.9946 - val_loss: 0.4296 - val_accuracy: 0.9009\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0211 - accuracy: 0.9938 - val_loss: 0.4339 - val_accuracy: 0.8976\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0196 - accuracy: 0.9946 - val_loss: 0.4679 - val_accuracy: 0.8976\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0207 - accuracy: 0.9949 - val_loss: 0.4210 - val_accuracy: 0.9019\n","Epoch 83/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0186 - accuracy: 0.9968 - val_loss: 0.4167 - val_accuracy: 0.9030\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0135 - accuracy: 0.9973 - val_loss: 0.4108 - val_accuracy: 0.9030\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0243 - accuracy: 0.9914 - val_loss: 0.4243 - val_accuracy: 0.9009\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0183 - accuracy: 0.9954 - val_loss: 0.4337 - val_accuracy: 0.9019\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0377 - accuracy: 0.9868 - val_loss: 0.5105 - val_accuracy: 0.8696\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0240 - accuracy: 0.9925 - val_loss: 0.4138 - val_accuracy: 0.8987\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0151 - accuracy: 0.9970 - val_loss: 0.4240 - val_accuracy: 0.8987\n","Epoch 90/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0156 - accuracy: 0.9970 - val_loss: 0.4489 - val_accuracy: 0.8944\n","Epoch 91/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0148 - accuracy: 0.9960 - val_loss: 0.4846 - val_accuracy: 0.8847\n","Epoch 92/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0145 - accuracy: 0.9965 - val_loss: 0.4462 - val_accuracy: 0.8998\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0162 - accuracy: 0.9968 - val_loss: 0.5165 - val_accuracy: 0.8836\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0151 - accuracy: 0.9968 - val_loss: 0.4373 - val_accuracy: 0.8987\n","Epoch 95/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0208 - accuracy: 0.9930 - val_loss: 0.4570 - val_accuracy: 0.8987\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.4778 - val_accuracy: 0.8847\n","Epoch 97/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0189 - accuracy: 0.9935 - val_loss: 0.4381 - val_accuracy: 0.8987\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 0.4397 - val_accuracy: 0.9052\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0109 - accuracy: 0.9978 - val_loss: 0.4453 - val_accuracy: 0.9041\n","Epoch 100/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0128 - accuracy: 0.9973 - val_loss: 0.4642 - val_accuracy: 0.8987\n","{'loss': [0.12959693372249603, 0.12199155986309052, 0.11357447504997253, 0.1005401685833931, 0.09062737226486206, 0.09923877567052841, 0.09412974864244461, 0.08579111844301224, 0.08869259059429169, 0.08507264405488968, 0.0815470814704895, 0.07498810440301895, 0.07849334180355072, 0.07591083645820618, 0.07460182905197144, 0.07418303936719894, 0.07134462893009186, 0.06736668944358826, 0.06642960011959076, 0.06647110730409622, 0.06678491830825806, 0.07146891951560974, 0.06272875517606735, 0.05715562030673027, 0.06250631809234619, 0.051801085472106934, 0.06451194733381271, 0.05917249619960785, 0.05151853337883949, 0.05111202225089073, 0.055709440261125565, 0.04820246249437332, 0.04961320012807846, 0.04624349623918533, 0.04299074783921242, 0.044458676129579544, 0.042767442762851715, 0.04059072956442833, 0.05434895679354668, 0.04262181371450424, 0.041686106473207474, 0.040044594556093216, 0.03734284266829491, 0.046439047902822495, 0.03848492354154587, 0.03975818306207657, 0.04363309219479561, 0.038518451154232025, 0.03269236534833908, 0.03505658730864525, 0.035262834280729294, 0.03201834112405777, 0.03598475828766823, 0.04316991940140724, 0.03660601004958153, 0.030827149748802185, 0.029947366565465927, 0.02992522157728672, 0.030265673995018005, 0.025848563760519028, 0.029211778193712234, 0.028464986011385918, 0.024409282952547073, 0.023625751957297325, 0.02239023894071579, 0.031388457864522934, 0.022261878475546837, 0.020540785044431686, 0.02177758514881134, 0.02786693535745144, 0.04778266325592995, 0.023605994880199432, 0.023244276642799377, 0.02407814748585224, 0.01993205025792122, 0.019781839102506638, 0.019843406975269318, 0.01902391016483307, 0.019229888916015625, 0.021090269088745117, 0.01962883397936821, 0.020709991455078125, 0.018555302172899246, 0.01352533046156168, 0.024339431896805763, 0.018306411802768707, 0.03769563511013985, 0.024023063480854034, 0.01513813529163599, 0.015570934861898422, 0.014849387109279633, 0.014450721442699432, 0.0162384994328022, 0.015062040649354458, 0.02082310989499092, 0.018330078572034836, 0.018870016559958458, 0.012942628003656864, 0.010916142724454403, 0.012791315093636513], 'accuracy': [0.9568965435028076, 0.9571659564971924, 0.959321141242981, 0.967402994632721, 0.9698275923728943, 0.9684805870056152, 0.9684805870056152, 0.9698275923728943, 0.9698275923728943, 0.9727909564971924, 0.9746767282485962, 0.975215494632721, 0.975215494632721, 0.9773706793785095, 0.9768319129943848, 0.9757543206214905, 0.9797952771186829, 0.9814116358757019, 0.9800646305084229, 0.9787176847457886, 0.9806034564971924, 0.9797952771186829, 0.9816810488700867, 0.9851831793785095, 0.9822198152542114, 0.9846444129943848, 0.9795258641242981, 0.982758641242981, 0.9862607717514038, 0.9870689511299133, 0.9854525923728943, 0.9884159564971924, 0.985722005367279, 0.9878771305084229, 0.9894935488700867, 0.9884159564971924, 0.9881465435028076, 0.9900323152542114, 0.9814116358757019, 0.9894935488700867, 0.9889547228813171, 0.9889547228813171, 0.9927262663841248, 0.9876077771186829, 0.9897629022598267, 0.9892241358757019, 0.9881465435028076, 0.9897629022598267, 0.993803858757019, 0.9900323152542114, 0.990571141242981, 0.993534505367279, 0.9900323152542114, 0.9886853694915771, 0.990571141242981, 0.9916487336158752, 0.9932650923728943, 0.9929956793785095, 0.9924569129943848, 0.993803858757019, 0.9932650923728943, 0.9927262663841248, 0.9948814511299133, 0.9956896305084229, 0.9954202771186829, 0.990840494632721, 0.9948814511299133, 0.9954202771186829, 0.9948814511299133, 0.9903017282485962, 0.9832974076271057, 0.9943426847457886, 0.9946120977401733, 0.9924569129943848, 0.9951508641242981, 0.9962284564971924, 0.9956896305084229, 0.9956896305084229, 0.9946120977401733, 0.993803858757019, 0.9946120977401733, 0.9948814511299133, 0.9967672228813171, 0.9973060488700867, 0.9913793206214905, 0.9954202771186829, 0.9867995977401733, 0.9924569129943848, 0.9970366358757019, 0.9970366358757019, 0.9959590435028076, 0.9964978694915771, 0.9967672228813171, 0.9967672228813171, 0.9929956793785095, 0.9943426847457886, 0.993534505367279, 0.9970366358757019, 0.9978448152542114, 0.9973060488700867], 'val_loss': [0.6643620729446411, 0.6597216129302979, 0.646490752696991, 0.635887086391449, 0.623494565486908, 0.6136146187782288, 0.5892917513847351, 0.5742579698562622, 0.5660969018936157, 0.5229842066764832, 0.49886244535446167, 0.47337740659713745, 0.4438360333442688, 0.41319939494132996, 0.3655066192150116, 0.35056358575820923, 0.3161790668964386, 0.27510955929756165, 0.26857584714889526, 0.24609015882015228, 0.23887032270431519, 0.2616373896598816, 0.2387731969356537, 0.24834653735160828, 0.2631901502609253, 0.2578814625740051, 0.2742650806903839, 0.28228792548179626, 0.27808666229248047, 0.2944449186325073, 0.36609581112861633, 0.2971629500389099, 0.3070140480995178, 0.3165518641471863, 0.30669423937797546, 0.30819109082221985, 0.31848710775375366, 0.405696839094162, 0.327435165643692, 0.3335336446762085, 0.3432293236255646, 0.3363996148109436, 0.34379446506500244, 0.36535757780075073, 0.3396691381931305, 0.3472822904586792, 0.3689856231212616, 0.34890103340148926, 0.3560853898525238, 0.3706430494785309, 0.3902689516544342, 0.37049147486686707, 0.3566665053367615, 0.3935984969139099, 0.3813515305519104, 0.3877633512020111, 0.38529786467552185, 0.39156636595726013, 0.37883323431015015, 0.3937157988548279, 0.3753814101219177, 0.38036271929740906, 0.3786255121231079, 0.3932313024997711, 0.4126339852809906, 0.389440655708313, 0.4026435315608978, 0.39872634410858154, 0.39781302213668823, 0.4404934048652649, 0.397771418094635, 0.3931770324707031, 0.48521918058395386, 0.4024149179458618, 0.42199522256851196, 0.4441870450973511, 0.4119764268398285, 0.4133889973163605, 0.429583340883255, 0.4338912069797516, 0.4679325819015503, 0.4209875762462616, 0.416729211807251, 0.4108084440231323, 0.42433956265449524, 0.43368762731552124, 0.5105041861534119, 0.41382884979248047, 0.4240052103996277, 0.44891947507858276, 0.48464176058769226, 0.44616764783859253, 0.5165059566497803, 0.43734288215637207, 0.4569731652736664, 0.47778668999671936, 0.4380626678466797, 0.4396679401397705, 0.4453263580799103, 0.46423253417015076], 'val_accuracy': [0.49461206793785095, 0.4989224076271057, 0.5495689511299133, 0.6066810488700867, 0.6573275923728943, 0.6724137663841248, 0.7855603694915771, 0.787715494632721, 0.7316810488700867, 0.8793103694915771, 0.8836206793785095, 0.8739224076271057, 0.8782327771186829, 0.8846982717514038, 0.90625, 0.8857758641242981, 0.899784505367279, 0.899784505367279, 0.9019396305084229, 0.90625, 0.9084051847457886, 0.8954741358757019, 0.9094827771186829, 0.90625, 0.9030172228813171, 0.9116379022598267, 0.9094827771186829, 0.90625, 0.9137930870056152, 0.90625, 0.8846982717514038, 0.9051724076271057, 0.90625, 0.9084051847457886, 0.9105603694915771, 0.9073275923728943, 0.9116379022598267, 0.8771551847457886, 0.9105603694915771, 0.9008620977401733, 0.90625, 0.9040948152542114, 0.899784505367279, 0.8900862336158752, 0.9040948152542114, 0.9030172228813171, 0.9008620977401733, 0.9019396305084229, 0.8987069129943848, 0.9008620977401733, 0.8943965435028076, 0.899784505367279, 0.8954741358757019, 0.8933189511299133, 0.8976293206214905, 0.8954741358757019, 0.8954741358757019, 0.8965517282485962, 0.8976293206214905, 0.8943965435028076, 0.9040948152542114, 0.9019396305084229, 0.90625, 0.8943965435028076, 0.889008641242981, 0.8976293206214905, 0.899784505367279, 0.8954741358757019, 0.8954741358757019, 0.8933189511299133, 0.9030172228813171, 0.90625, 0.8728448152542114, 0.9040948152542114, 0.8976293206214905, 0.8911637663841248, 0.8943965435028076, 0.9073275923728943, 0.9008620977401733, 0.8976293206214905, 0.8976293206214905, 0.9019396305084229, 0.9030172228813171, 0.9030172228813171, 0.9008620977401733, 0.9019396305084229, 0.8696120977401733, 0.8987069129943848, 0.8987069129943848, 0.8943965435028076, 0.8846982717514038, 0.899784505367279, 0.8836206793785095, 0.8987069129943848, 0.8987069129943848, 0.8846982717514038, 0.8987069129943848, 0.9051724076271057, 0.9040948152542114, 0.8987069129943848]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 8s 58ms/step - loss: 0.1317 - accuracy: 0.9496 - val_loss: 0.6615 - val_accuracy: 0.5204\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 1s 22ms/step - loss: 0.1126 - accuracy: 0.9593 - val_loss: 0.6560 - val_accuracy: 0.5328\n","Epoch 3/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1064 - accuracy: 0.9621 - val_loss: 0.6461 - val_accuracy: 0.5781\n","Epoch 4/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.1019 - accuracy: 0.9635 - val_loss: 0.6388 - val_accuracy: 0.5860\n","Epoch 5/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1042 - accuracy: 0.9593 - val_loss: 0.6235 - val_accuracy: 0.6719\n","Epoch 6/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0943 - accuracy: 0.9652 - val_loss: 0.6129 - val_accuracy: 0.6957\n","Epoch 7/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0946 - accuracy: 0.9672 - val_loss: 0.6001 - val_accuracy: 0.7330\n","Epoch 8/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0892 - accuracy: 0.9686 - val_loss: 0.5750 - val_accuracy: 0.8348\n","Epoch 9/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0889 - accuracy: 0.9692 - val_loss: 0.5593 - val_accuracy: 0.8303\n","Epoch 10/100\n","28/28 [==============================] - 1s 38ms/step - loss: 0.0827 - accuracy: 0.9726 - val_loss: 0.5382 - val_accuracy: 0.8473\n","Epoch 11/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.0827 - accuracy: 0.9740 - val_loss: 0.5079 - val_accuracy: 0.8880\n","Epoch 12/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.0832 - accuracy: 0.9737 - val_loss: 0.4772 - val_accuracy: 0.8993\n","Epoch 13/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0906 - accuracy: 0.9672 - val_loss: 0.4422 - val_accuracy: 0.8971\n","Epoch 14/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0805 - accuracy: 0.9740 - val_loss: 0.4270 - val_accuracy: 0.8914\n","Epoch 15/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0742 - accuracy: 0.9759 - val_loss: 0.3878 - val_accuracy: 0.9027\n","Epoch 16/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0711 - accuracy: 0.9788 - val_loss: 0.3567 - val_accuracy: 0.9061\n","Epoch 17/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0674 - accuracy: 0.9810 - val_loss: 0.3261 - val_accuracy: 0.9050\n","Epoch 18/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0691 - accuracy: 0.9808 - val_loss: 0.3016 - val_accuracy: 0.9027\n","Epoch 19/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0670 - accuracy: 0.9802 - val_loss: 0.2806 - val_accuracy: 0.9050\n","Epoch 20/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0610 - accuracy: 0.9830 - val_loss: 0.2660 - val_accuracy: 0.9050\n","Epoch 21/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0625 - accuracy: 0.9813 - val_loss: 0.2531 - val_accuracy: 0.9072\n","Epoch 22/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0739 - accuracy: 0.9762 - val_loss: 0.2595 - val_accuracy: 0.8948\n","Epoch 23/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0638 - accuracy: 0.9810 - val_loss: 0.2560 - val_accuracy: 0.9050\n","Epoch 24/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0695 - accuracy: 0.9776 - val_loss: 0.2665 - val_accuracy: 0.9061\n","Epoch 25/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0605 - accuracy: 0.9830 - val_loss: 0.2705 - val_accuracy: 0.9072\n","Epoch 26/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0616 - accuracy: 0.9819 - val_loss: 0.2864 - val_accuracy: 0.9050\n","Epoch 27/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0565 - accuracy: 0.9856 - val_loss: 0.2935 - val_accuracy: 0.9095\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0577 - accuracy: 0.9864 - val_loss: 0.3276 - val_accuracy: 0.8971\n","Epoch 29/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0610 - accuracy: 0.9793 - val_loss: 0.3142 - val_accuracy: 0.8982\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0531 - accuracy: 0.9833 - val_loss: 0.3339 - val_accuracy: 0.8891\n","Epoch 31/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0531 - accuracy: 0.9833 - val_loss: 0.3259 - val_accuracy: 0.9027\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0530 - accuracy: 0.9830 - val_loss: 0.3313 - val_accuracy: 0.9061\n","Epoch 33/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0466 - accuracy: 0.9875 - val_loss: 0.3539 - val_accuracy: 0.9084\n","Epoch 34/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0497 - accuracy: 0.9833 - val_loss: 0.3416 - val_accuracy: 0.8993\n","Epoch 35/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0473 - accuracy: 0.9878 - val_loss: 0.3653 - val_accuracy: 0.9072\n","Epoch 36/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0502 - accuracy: 0.9842 - val_loss: 0.3766 - val_accuracy: 0.8982\n","Epoch 37/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0468 - accuracy: 0.9856 - val_loss: 0.3699 - val_accuracy: 0.9061\n","Epoch 38/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0446 - accuracy: 0.9878 - val_loss: 0.3775 - val_accuracy: 0.8993\n","Epoch 39/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0425 - accuracy: 0.9895 - val_loss: 0.3672 - val_accuracy: 0.9050\n","Epoch 40/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0398 - accuracy: 0.9915 - val_loss: 0.3707 - val_accuracy: 0.8982\n","Epoch 41/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0369 - accuracy: 0.9904 - val_loss: 0.3665 - val_accuracy: 0.9005\n","Epoch 42/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0405 - accuracy: 0.9895 - val_loss: 0.3747 - val_accuracy: 0.8982\n","Epoch 43/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0363 - accuracy: 0.9918 - val_loss: 0.3723 - val_accuracy: 0.9038\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0423 - accuracy: 0.9887 - val_loss: 0.3823 - val_accuracy: 0.9072\n","Epoch 45/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0368 - accuracy: 0.9892 - val_loss: 0.3826 - val_accuracy: 0.9038\n","Epoch 46/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0384 - accuracy: 0.9895 - val_loss: 0.3852 - val_accuracy: 0.9038\n","Epoch 47/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0298 - accuracy: 0.9938 - val_loss: 0.3783 - val_accuracy: 0.9061\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0348 - accuracy: 0.9898 - val_loss: 0.3838 - val_accuracy: 0.8982\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0384 - accuracy: 0.9867 - val_loss: 0.4402 - val_accuracy: 0.8971\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0318 - accuracy: 0.9918 - val_loss: 0.4089 - val_accuracy: 0.9027\n","Epoch 51/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0336 - accuracy: 0.9907 - val_loss: 0.3972 - val_accuracy: 0.8903\n","Epoch 52/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0306 - accuracy: 0.9909 - val_loss: 0.4197 - val_accuracy: 0.9005\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0363 - accuracy: 0.9878 - val_loss: 0.4118 - val_accuracy: 0.8982\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0294 - accuracy: 0.9926 - val_loss: 0.4658 - val_accuracy: 0.8914\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0290 - accuracy: 0.9929 - val_loss: 0.4212 - val_accuracy: 0.8880\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0274 - accuracy: 0.9918 - val_loss: 0.4232 - val_accuracy: 0.8993\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0266 - accuracy: 0.9938 - val_loss: 0.4097 - val_accuracy: 0.8959\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0309 - accuracy: 0.9912 - val_loss: 0.4174 - val_accuracy: 0.9095\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0255 - accuracy: 0.9943 - val_loss: 0.4455 - val_accuracy: 0.9027\n","Epoch 60/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0257 - accuracy: 0.9943 - val_loss: 0.4262 - val_accuracy: 0.8937\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0229 - accuracy: 0.9943 - val_loss: 0.4286 - val_accuracy: 0.9027\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0307 - accuracy: 0.9904 - val_loss: 0.4417 - val_accuracy: 0.8914\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0227 - accuracy: 0.9932 - val_loss: 0.4394 - val_accuracy: 0.8846\n","Epoch 64/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0223 - accuracy: 0.9943 - val_loss: 0.4272 - val_accuracy: 0.8937\n","Epoch 65/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0364 - accuracy: 0.9878 - val_loss: 0.4314 - val_accuracy: 0.8914\n","Epoch 66/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0281 - accuracy: 0.9909 - val_loss: 0.5012 - val_accuracy: 0.8801\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0404 - accuracy: 0.9867 - val_loss: 0.4281 - val_accuracy: 0.8993\n","Epoch 68/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0216 - accuracy: 0.9949 - val_loss: 0.4294 - val_accuracy: 0.8903\n","Epoch 69/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0217 - accuracy: 0.9941 - val_loss: 0.4261 - val_accuracy: 0.8937\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0196 - accuracy: 0.9952 - val_loss: 0.4350 - val_accuracy: 0.8948\n","Epoch 71/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0156 - accuracy: 0.9977 - val_loss: 0.4470 - val_accuracy: 0.8937\n","Epoch 72/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0223 - accuracy: 0.9943 - val_loss: 0.4643 - val_accuracy: 0.8857\n","Epoch 73/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0190 - accuracy: 0.9955 - val_loss: 0.4383 - val_accuracy: 0.8982\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0176 - accuracy: 0.9960 - val_loss: 0.4403 - val_accuracy: 0.8846\n","Epoch 75/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.4576 - val_accuracy: 0.8948\n","Epoch 76/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0136 - accuracy: 0.9975 - val_loss: 0.4804 - val_accuracy: 0.9005\n","Epoch 77/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0149 - accuracy: 0.9972 - val_loss: 0.4658 - val_accuracy: 0.8971\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0166 - accuracy: 0.9963 - val_loss: 0.4717 - val_accuracy: 0.8982\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0167 - accuracy: 0.9960 - val_loss: 0.4756 - val_accuracy: 0.8914\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0155 - accuracy: 0.9975 - val_loss: 0.4776 - val_accuracy: 0.8903\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0160 - accuracy: 0.9963 - val_loss: 0.5018 - val_accuracy: 0.9016\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0208 - accuracy: 0.9943 - val_loss: 0.4906 - val_accuracy: 0.8925\n","Epoch 83/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0161 - accuracy: 0.9969 - val_loss: 0.4823 - val_accuracy: 0.8914\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0157 - accuracy: 0.9960 - val_loss: 0.4765 - val_accuracy: 0.9027\n","Epoch 85/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.4729 - val_accuracy: 0.9005\n","Epoch 86/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0171 - accuracy: 0.9960 - val_loss: 0.4842 - val_accuracy: 0.9005\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.4917 - val_accuracy: 0.9050\n","Epoch 88/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0122 - accuracy: 0.9972 - val_loss: 0.4923 - val_accuracy: 0.8880\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0123 - accuracy: 0.9966 - val_loss: 0.4991 - val_accuracy: 0.8959\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.4875 - val_accuracy: 0.8903\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0198 - accuracy: 0.9949 - val_loss: 0.4895 - val_accuracy: 0.8925\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0129 - accuracy: 0.9966 - val_loss: 0.5056 - val_accuracy: 0.8959\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0115 - accuracy: 0.9972 - val_loss: 0.5004 - val_accuracy: 0.8993\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.5142 - val_accuracy: 0.8993\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0126 - accuracy: 0.9955 - val_loss: 0.5174 - val_accuracy: 0.8914\n","Epoch 96/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0128 - accuracy: 0.9977 - val_loss: 0.5003 - val_accuracy: 0.8948\n","Epoch 97/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 0.5123 - val_accuracy: 0.8937\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0155 - accuracy: 0.9938 - val_loss: 0.5000 - val_accuracy: 0.8971\n","Epoch 99/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.5168 - val_accuracy: 0.8937\n","Epoch 100/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.5181 - val_accuracy: 0.8959\n","{'loss': [0.131658136844635, 0.11264542490243912, 0.10639281570911407, 0.1018596738576889, 0.10418622940778732, 0.09429279714822769, 0.09455902129411697, 0.08919675648212433, 0.08888927847146988, 0.08267592638731003, 0.08274462074041367, 0.08320260047912598, 0.09063730388879776, 0.08048027008771896, 0.07417862117290497, 0.07113388925790787, 0.06736134737730026, 0.0691249892115593, 0.06704283505678177, 0.06100086867809296, 0.0625060424208641, 0.07389172911643982, 0.06377940624952316, 0.06946424394845963, 0.06049305200576782, 0.061590828001499176, 0.056504327803850174, 0.05772009864449501, 0.060965362936258316, 0.0530959777534008, 0.05313479155302048, 0.05300597473978996, 0.04655260965228081, 0.04967273026704788, 0.047305114567279816, 0.05017890781164169, 0.04681822285056114, 0.04464174807071686, 0.042549341917037964, 0.03980419784784317, 0.03685746714472771, 0.04049708694219589, 0.036250703036785126, 0.04228514805436134, 0.03682970255613327, 0.03838549926877022, 0.029811374843120575, 0.034840792417526245, 0.038353513926267624, 0.031803783029317856, 0.033561959862709045, 0.0306194219738245, 0.03630596026778221, 0.029350707307457924, 0.028958113864064217, 0.02735981158912182, 0.026617450639605522, 0.03086690418422222, 0.02549600601196289, 0.02571551688015461, 0.022884748876094818, 0.030730661004781723, 0.022729048505425453, 0.022271983325481415, 0.036386843770742416, 0.028101587668061256, 0.04037492349743843, 0.021594539284706116, 0.02169889584183693, 0.01963226869702339, 0.015618547797203064, 0.022277643904089928, 0.018985873088240623, 0.017623484134674072, 0.016498718410730362, 0.013634891249239445, 0.014874841086566448, 0.016633694991469383, 0.016737716272473335, 0.015483287163078785, 0.01602226495742798, 0.02078939788043499, 0.016093026846647263, 0.015699272975325584, 0.01552945002913475, 0.017114052549004555, 0.012916258536279202, 0.012194085866212845, 0.012258252128958702, 0.015131319873034954, 0.01984505169093609, 0.012866639532148838, 0.011515267193317413, 0.011960228905081749, 0.012598578818142414, 0.012772609479725361, 0.01585824228823185, 0.015535873360931873, 0.01020329911261797, 0.009719033725559711], 'accuracy': [0.9496321678161621, 0.9592529535293579, 0.9620826244354248, 0.9634974598884583, 0.9592529535293579, 0.9651952385902405, 0.9671760201454163, 0.9685908555984497, 0.9691567420959473, 0.9725523591041565, 0.9739671945571899, 0.9736841917037964, 0.9671760201454163, 0.9739671945571899, 0.975947916507721, 0.9787775874137878, 0.9810413122177124, 0.9807583689689636, 0.9801924228668213, 0.9830220937728882, 0.9813242554664612, 0.9762309193611145, 0.9810413122177124, 0.977645754814148, 0.9830220937728882, 0.9818902015686035, 0.9855687618255615, 0.9864176511764526, 0.9793435335159302, 0.983305037021637, 0.983305037021637, 0.9830220937728882, 0.9875495433807373, 0.983305037021637, 0.9878324866294861, 0.9841539263725281, 0.9855687618255615, 0.9878324866294861, 0.9895302653312683, 0.9915110468864441, 0.9903791546821594, 0.9895302653312683, 0.9917939901351929, 0.9886813759803772, 0.9892473220825195, 0.9895302653312683, 0.9937747716903687, 0.9898132681846619, 0.9867005944252014, 0.9917939901351929, 0.990662157535553, 0.9909451007843018, 0.9878324866294861, 0.992642879486084, 0.9929258823394775, 0.9917939901351929, 0.9937747716903687, 0.9912280440330505, 0.994340717792511, 0.994340717792511, 0.994340717792511, 0.9903791546821594, 0.9932088255882263, 0.994340717792511, 0.9878324866294861, 0.9909451007843018, 0.9867005944252014, 0.9949066042900085, 0.9940577149391174, 0.9951896071434021, 0.9977362751960754, 0.994340717792511, 0.9954725503921509, 0.9960384964942932, 0.9951896071434021, 0.9974533319473267, 0.9971703290939331, 0.996321439743042, 0.9960384964942932, 0.9974533319473267, 0.996321439743042, 0.994340717792511, 0.9968873858451843, 0.9960384964942932, 0.9957554936408997, 0.9960384964942932, 0.9968873858451843, 0.9971703290939331, 0.9966044425964355, 0.9954725503921509, 0.9949066042900085, 0.9966044425964355, 0.9971703290939331, 0.9968873858451843, 0.9954725503921509, 0.9977362751960754, 0.9946236610412598, 0.9937747716903687, 0.9968873858451843, 0.9974533319473267], 'val_loss': [0.6615103483200073, 0.6560131907463074, 0.6460955739021301, 0.6388034820556641, 0.6234592199325562, 0.6128985285758972, 0.6001451015472412, 0.5750267505645752, 0.5593117475509644, 0.5382000207901001, 0.5078698992729187, 0.47715041041374207, 0.4422299861907959, 0.4269556701183319, 0.3878234028816223, 0.356733500957489, 0.32605573534965515, 0.30158883333206177, 0.28059259057044983, 0.2660069167613983, 0.2530701160430908, 0.25945940613746643, 0.2559964060783386, 0.26652321219444275, 0.2704775035381317, 0.28639549016952515, 0.2935495972633362, 0.32764390110969543, 0.31420809030532837, 0.33393415808677673, 0.3259378969669342, 0.3312790095806122, 0.35386282205581665, 0.34160399436950684, 0.3653058707714081, 0.3766241669654846, 0.36991286277770996, 0.3774862587451935, 0.3672323226928711, 0.37072113156318665, 0.36653241515159607, 0.3747011721134186, 0.37227508425712585, 0.3822953999042511, 0.3826025128364563, 0.38524216413497925, 0.3782736361026764, 0.38380345702171326, 0.44017571210861206, 0.4089239835739136, 0.3971681296825409, 0.4196808338165283, 0.4117960035800934, 0.46582692861557007, 0.4211704134941101, 0.42315396666526794, 0.4097181558609009, 0.4174163043498993, 0.44554969668388367, 0.426152765750885, 0.42859867215156555, 0.44168293476104736, 0.4393519163131714, 0.4271848797798157, 0.4314196705818176, 0.501178503036499, 0.4280672073364258, 0.42941612005233765, 0.426142156124115, 0.4350125193595886, 0.4469839036464691, 0.4642939269542694, 0.43831127882003784, 0.4402519464492798, 0.45760098099708557, 0.4803764820098877, 0.46578672528266907, 0.47166383266448975, 0.4756351411342621, 0.47757813334465027, 0.5018243789672852, 0.49056240916252136, 0.4822586476802826, 0.4764645993709564, 0.4728982448577881, 0.484208881855011, 0.49169155955314636, 0.49230027198791504, 0.4990612864494324, 0.4874778389930725, 0.48954400420188904, 0.5055825710296631, 0.5003823041915894, 0.5141600370407104, 0.517391562461853, 0.500302255153656, 0.5122731328010559, 0.49997323751449585, 0.5168027281761169, 0.5181251764297485], 'val_accuracy': [0.5203620195388794, 0.5328054428100586, 0.5780543088912964, 0.5859728455543518, 0.6719456911087036, 0.6957013607025146, 0.733031690120697, 0.8348416090011597, 0.8303167223930359, 0.8472850918769836, 0.8880090713500977, 0.8993212580680847, 0.8970588445663452, 0.8914027214050293, 0.9027149081230164, 0.9061086177825928, 0.9049773812294006, 0.9027149081230164, 0.9049773812294006, 0.9049773812294006, 0.9072397947311401, 0.8947963714599609, 0.9049773812294006, 0.9061086177825928, 0.9072397947311401, 0.9049773812294006, 0.9095022678375244, 0.8970588445663452, 0.8981900215148926, 0.889140248298645, 0.9027149081230164, 0.9061086177825928, 0.9083710312843323, 0.8993212580680847, 0.9072397947311401, 0.8981900215148926, 0.9061086177825928, 0.8993212580680847, 0.9049773812294006, 0.8981900215148926, 0.9004524946212769, 0.8981900215148926, 0.9038461446762085, 0.9072397947311401, 0.9038461446762085, 0.9038461446762085, 0.9061086177825928, 0.8981900215148926, 0.8970588445663452, 0.9027149081230164, 0.8902714848518372, 0.9004524946212769, 0.8981900215148926, 0.8914027214050293, 0.8880090713500977, 0.8993212580680847, 0.8959276080131531, 0.9095022678375244, 0.9027149081230164, 0.8936651349067688, 0.9027149081230164, 0.8914027214050293, 0.8846153616905212, 0.8936651349067688, 0.8914027214050293, 0.8800904750823975, 0.8993212580680847, 0.8902714848518372, 0.8936651349067688, 0.8947963714599609, 0.8936651349067688, 0.8857465982437134, 0.8981900215148926, 0.8846153616905212, 0.8947963714599609, 0.9004524946212769, 0.8970588445663452, 0.8981900215148926, 0.8914027214050293, 0.8902714848518372, 0.901583731174469, 0.8925339579582214, 0.8914027214050293, 0.9027149081230164, 0.9004524946212769, 0.9004524946212769, 0.9049773812294006, 0.8880090713500977, 0.8959276080131531, 0.8902714848518372, 0.8925339579582214, 0.8959276080131531, 0.8993212580680847, 0.8993212580680847, 0.8914027214050293, 0.8947963714599609, 0.8936651349067688, 0.8970588445663452, 0.8936651349067688, 0.8959276080131531]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.1286 - accuracy: 0.9531"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 70ms/step - loss: 0.1293 - accuracy: 0.9537 - val_loss: 0.6645 - val_accuracy: 0.4979\n","Epoch 2/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.1221 - accuracy: 0.9561 - val_loss: 0.6531 - val_accuracy: 0.5455\n","Epoch 3/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1259 - accuracy: 0.9566 - val_loss: 0.6484 - val_accuracy: 0.5424\n","Epoch 4/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1075 - accuracy: 0.9651 - val_loss: 0.6369 - val_accuracy: 0.5992\n","Epoch 5/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.1031 - accuracy: 0.9612 - val_loss: 0.6245 - val_accuracy: 0.6353\n","Epoch 6/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1028 - accuracy: 0.9641 - val_loss: 0.6019 - val_accuracy: 0.7810\n","Epoch 7/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0990 - accuracy: 0.9636 - val_loss: 0.5901 - val_accuracy: 0.7583\n","Epoch 8/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0922 - accuracy: 0.9695 - val_loss: 0.5605 - val_accuracy: 0.8667\n","Epoch 9/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0980 - accuracy: 0.9664 - val_loss: 0.5445 - val_accuracy: 0.8419\n","Epoch 10/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0916 - accuracy: 0.9674 - val_loss: 0.5153 - val_accuracy: 0.8688\n","Epoch 11/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0938 - accuracy: 0.9695 - val_loss: 0.4903 - val_accuracy: 0.8657\n","Epoch 12/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0862 - accuracy: 0.9693 - val_loss: 0.4540 - val_accuracy: 0.8719\n","Epoch 13/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0839 - accuracy: 0.9716 - val_loss: 0.4380 - val_accuracy: 0.8585\n","Epoch 14/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0866 - accuracy: 0.9729 - val_loss: 0.3891 - val_accuracy: 0.8781\n","Epoch 15/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0800 - accuracy: 0.9721 - val_loss: 0.3565 - val_accuracy: 0.8833\n","Epoch 16/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0910 - accuracy: 0.9674 - val_loss: 0.3236 - val_accuracy: 0.8822\n","Epoch 17/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0815 - accuracy: 0.9718 - val_loss: 0.2960 - val_accuracy: 0.8915\n","Epoch 18/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0709 - accuracy: 0.9778 - val_loss: 0.2799 - val_accuracy: 0.8926\n","Epoch 19/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0781 - accuracy: 0.9708 - val_loss: 0.3041 - val_accuracy: 0.8688\n","Epoch 20/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0672 - accuracy: 0.9793 - val_loss: 0.2617 - val_accuracy: 0.8884\n","Epoch 21/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0753 - accuracy: 0.9747 - val_loss: 0.2650 - val_accuracy: 0.8905\n","Epoch 22/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0732 - accuracy: 0.9755 - val_loss: 0.2812 - val_accuracy: 0.8874\n","Epoch 23/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0644 - accuracy: 0.9814 - val_loss: 0.2834 - val_accuracy: 0.8926\n","Epoch 24/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0617 - accuracy: 0.9829 - val_loss: 0.2920 - val_accuracy: 0.8905\n","Epoch 25/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0652 - accuracy: 0.9788 - val_loss: 0.3057 - val_accuracy: 0.8915\n","Epoch 26/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0612 - accuracy: 0.9809 - val_loss: 0.3189 - val_accuracy: 0.8884\n","Epoch 27/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0663 - accuracy: 0.9775 - val_loss: 0.3222 - val_accuracy: 0.8874\n","Epoch 28/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0580 - accuracy: 0.9811 - val_loss: 0.3343 - val_accuracy: 0.8895\n","Epoch 29/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0658 - accuracy: 0.9749 - val_loss: 0.3677 - val_accuracy: 0.8781\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0597 - accuracy: 0.9811 - val_loss: 0.3501 - val_accuracy: 0.8853\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0552 - accuracy: 0.9835 - val_loss: 0.3510 - val_accuracy: 0.8822\n","Epoch 32/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0526 - accuracy: 0.9855 - val_loss: 0.3560 - val_accuracy: 0.8864\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0515 - accuracy: 0.9850 - val_loss: 0.3653 - val_accuracy: 0.8874\n","Epoch 34/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0630 - accuracy: 0.9757 - val_loss: 0.3745 - val_accuracy: 0.8853\n","Epoch 35/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0506 - accuracy: 0.9837 - val_loss: 0.3725 - val_accuracy: 0.8812\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0479 - accuracy: 0.9868 - val_loss: 0.3805 - val_accuracy: 0.8822\n","Epoch 37/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0446 - accuracy: 0.9891 - val_loss: 0.3969 - val_accuracy: 0.8750\n","Epoch 38/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0447 - accuracy: 0.9881 - val_loss: 0.3977 - val_accuracy: 0.8802\n","Epoch 39/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0477 - accuracy: 0.9837 - val_loss: 0.3840 - val_accuracy: 0.8833\n","Epoch 40/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0458 - accuracy: 0.9871 - val_loss: 0.3823 - val_accuracy: 0.8853\n","Epoch 41/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0439 - accuracy: 0.9879 - val_loss: 0.3844 - val_accuracy: 0.8843\n","Epoch 42/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0457 - accuracy: 0.9871 - val_loss: 0.3915 - val_accuracy: 0.8802\n","Epoch 43/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0431 - accuracy: 0.9863 - val_loss: 0.3972 - val_accuracy: 0.8760\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0429 - accuracy: 0.9858 - val_loss: 0.4078 - val_accuracy: 0.8791\n","Epoch 45/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0440 - accuracy: 0.9850 - val_loss: 0.4020 - val_accuracy: 0.8791\n","Epoch 46/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0502 - accuracy: 0.9837 - val_loss: 0.4329 - val_accuracy: 0.8812\n","Epoch 47/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0372 - accuracy: 0.9881 - val_loss: 0.4047 - val_accuracy: 0.8760\n","Epoch 48/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0425 - accuracy: 0.9866 - val_loss: 0.4047 - val_accuracy: 0.8791\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0358 - accuracy: 0.9904 - val_loss: 0.4056 - val_accuracy: 0.8781\n","Epoch 50/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0362 - accuracy: 0.9907 - val_loss: 0.4042 - val_accuracy: 0.8802\n","Epoch 51/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0345 - accuracy: 0.9897 - val_loss: 0.4084 - val_accuracy: 0.8812\n","Epoch 52/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0389 - accuracy: 0.9889 - val_loss: 0.4138 - val_accuracy: 0.8843\n","Epoch 53/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0366 - accuracy: 0.9899 - val_loss: 0.4199 - val_accuracy: 0.8750\n","Epoch 54/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0353 - accuracy: 0.9907 - val_loss: 0.4244 - val_accuracy: 0.8853\n","Epoch 55/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0334 - accuracy: 0.9889 - val_loss: 0.4353 - val_accuracy: 0.8884\n","Epoch 56/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0336 - accuracy: 0.9886 - val_loss: 0.4190 - val_accuracy: 0.8760\n","Epoch 57/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0374 - accuracy: 0.9884 - val_loss: 0.4428 - val_accuracy: 0.8843\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0325 - accuracy: 0.9912 - val_loss: 0.4335 - val_accuracy: 0.8750\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0322 - accuracy: 0.9897 - val_loss: 0.4401 - val_accuracy: 0.8750\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0395 - accuracy: 0.9855 - val_loss: 0.4926 - val_accuracy: 0.8843\n","Epoch 61/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0350 - accuracy: 0.9873 - val_loss: 0.4363 - val_accuracy: 0.8750\n","Epoch 62/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0276 - accuracy: 0.9915 - val_loss: 0.4389 - val_accuracy: 0.8791\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 0.4521 - val_accuracy: 0.8750\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0275 - accuracy: 0.9925 - val_loss: 0.4531 - val_accuracy: 0.8729\n","Epoch 65/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 0.4594 - val_accuracy: 0.8874\n","Epoch 66/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0288 - accuracy: 0.9925 - val_loss: 0.4511 - val_accuracy: 0.8791\n","Epoch 67/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0245 - accuracy: 0.9938 - val_loss: 0.4596 - val_accuracy: 0.8812\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0331 - accuracy: 0.9902 - val_loss: 0.4596 - val_accuracy: 0.8874\n","Epoch 69/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.4497 - val_accuracy: 0.8833\n","Epoch 70/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0268 - accuracy: 0.9922 - val_loss: 0.4669 - val_accuracy: 0.8833\n","Epoch 71/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0304 - accuracy: 0.9902 - val_loss: 0.4557 - val_accuracy: 0.8812\n","Epoch 72/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0279 - accuracy: 0.9904 - val_loss: 0.4852 - val_accuracy: 0.8864\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0311 - accuracy: 0.9915 - val_loss: 0.4742 - val_accuracy: 0.8864\n","Epoch 74/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0271 - accuracy: 0.9917 - val_loss: 0.4683 - val_accuracy: 0.8740\n","Epoch 75/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0288 - accuracy: 0.9915 - val_loss: 0.5007 - val_accuracy: 0.8874\n","Epoch 76/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0228 - accuracy: 0.9941 - val_loss: 0.4662 - val_accuracy: 0.8822\n","Epoch 77/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0208 - accuracy: 0.9948 - val_loss: 0.4779 - val_accuracy: 0.8822\n","Epoch 78/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0260 - accuracy: 0.9930 - val_loss: 0.4824 - val_accuracy: 0.8812\n","Epoch 79/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0254 - accuracy: 0.9920 - val_loss: 0.4687 - val_accuracy: 0.8822\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0206 - accuracy: 0.9943 - val_loss: 0.4872 - val_accuracy: 0.8812\n","Epoch 81/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0182 - accuracy: 0.9956 - val_loss: 0.4832 - val_accuracy: 0.8791\n","Epoch 82/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0222 - accuracy: 0.9935 - val_loss: 0.4918 - val_accuracy: 0.8864\n","Epoch 83/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0222 - accuracy: 0.9948 - val_loss: 0.4782 - val_accuracy: 0.8843\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0174 - accuracy: 0.9956 - val_loss: 0.4803 - val_accuracy: 0.8802\n","Epoch 85/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0185 - accuracy: 0.9948 - val_loss: 0.5039 - val_accuracy: 0.8864\n","Epoch 86/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0272 - accuracy: 0.9920 - val_loss: 0.4883 - val_accuracy: 0.8740\n","Epoch 87/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0315 - accuracy: 0.9873 - val_loss: 0.4944 - val_accuracy: 0.8719\n","Epoch 88/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0220 - accuracy: 0.9938 - val_loss: 0.4762 - val_accuracy: 0.8781\n","Epoch 89/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0287 - accuracy: 0.9904 - val_loss: 0.5449 - val_accuracy: 0.8833\n","Epoch 90/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0223 - accuracy: 0.9943 - val_loss: 0.5183 - val_accuracy: 0.8729\n","Epoch 91/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0187 - accuracy: 0.9951 - val_loss: 0.5202 - val_accuracy: 0.8833\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.5326 - val_accuracy: 0.8843\n","Epoch 93/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 0.5214 - val_accuracy: 0.8853\n","Epoch 94/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.5142 - val_accuracy: 0.8740\n","Epoch 95/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0141 - accuracy: 0.9966 - val_loss: 0.5199 - val_accuracy: 0.8719\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 0.5263 - val_accuracy: 0.8750\n","Epoch 97/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0192 - accuracy: 0.9956 - val_loss: 0.5352 - val_accuracy: 0.8822\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0161 - accuracy: 0.9948 - val_loss: 0.5279 - val_accuracy: 0.8709\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0141 - accuracy: 0.9964 - val_loss: 0.5254 - val_accuracy: 0.8771\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0119 - accuracy: 0.9972 - val_loss: 0.5409 - val_accuracy: 0.8771\n","{'loss': [0.12932926416397095, 0.12210671603679657, 0.12589186429977417, 0.10747799277305603, 0.10313934087753296, 0.10278824716806412, 0.09899819642305374, 0.09218018501996994, 0.09802557528018951, 0.09161104261875153, 0.09384482353925705, 0.08617819100618362, 0.08386997878551483, 0.0865640640258789, 0.08001112192869186, 0.09098197519779205, 0.08145322650671005, 0.07089994847774506, 0.07812649756669998, 0.0671716257929802, 0.07528078556060791, 0.07319004833698273, 0.06439313292503357, 0.061655882745981216, 0.06523310393095016, 0.061204440891742706, 0.06633240729570389, 0.058032430708408356, 0.06581737846136093, 0.05974053218960762, 0.05516289919614792, 0.052594393491744995, 0.051450926810503006, 0.0630146712064743, 0.050559837371110916, 0.04791540652513504, 0.04464362561702728, 0.04470013827085495, 0.04771599546074867, 0.04576176404953003, 0.04394768550992012, 0.04566531628370285, 0.04305804893374443, 0.04285772517323494, 0.044023945927619934, 0.05015761777758598, 0.037232257425785065, 0.04249146208167076, 0.03581162169575691, 0.036226850003004074, 0.03446892648935318, 0.03888959437608719, 0.036625150591135025, 0.035318512469530106, 0.033426620066165924, 0.033636849373579025, 0.03741426765918732, 0.032488949596881866, 0.032231178134679794, 0.039474401623010635, 0.034982115030288696, 0.027559353038668633, 0.028350234031677246, 0.02753099426627159, 0.02519170194864273, 0.02879009023308754, 0.02450052835047245, 0.03308749198913574, 0.02615528181195259, 0.026783496141433716, 0.030447525903582573, 0.027925966307520866, 0.031096473336219788, 0.027142450213432312, 0.028807716444134712, 0.02277141995728016, 0.020783476531505585, 0.025990664958953857, 0.025366703048348427, 0.02059066668152809, 0.01817481406033039, 0.02217053435742855, 0.022195030003786087, 0.017435571178793907, 0.01850568875670433, 0.027211088687181473, 0.031498536467552185, 0.022017506882548332, 0.02865174598991871, 0.022286364808678627, 0.01866820827126503, 0.016251636669039726, 0.015467079356312752, 0.0150758046656847, 0.014072724618017673, 0.015560874715447426, 0.019170381128787994, 0.016102027148008347, 0.014143154956400394, 0.011949966661632061], 'accuracy': [0.9537467956542969, 0.9560723304748535, 0.9565891623497009, 0.9651162624359131, 0.961240291595459, 0.964082658290863, 0.9635658860206604, 0.9695090651512146, 0.9664082527160645, 0.9674418568611145, 0.9695090651512146, 0.9692506194114685, 0.9715762138366699, 0.9728682041168213, 0.9720930457115173, 0.9674418568611145, 0.9718345999717712, 0.9777777791023254, 0.970801055431366, 0.9793281555175781, 0.9746770262718201, 0.975452184677124, 0.9813953638076782, 0.9829457402229309, 0.9788113832473755, 0.9808785319328308, 0.9775193929672241, 0.9811369776725769, 0.9749354124069214, 0.9811369776725769, 0.9834625124931335, 0.9855297207832336, 0.985012948513031, 0.9757105708122253, 0.9837209582328796, 0.986821711063385, 0.9891473054885864, 0.9881137013435364, 0.9837209582328796, 0.9870800971984863, 0.9878553152084351, 0.9870800971984863, 0.9863049387931824, 0.985788106918335, 0.985012948513031, 0.9837209582328796, 0.9881137013435364, 0.9865633249282837, 0.9904392957687378, 0.9906976819038391, 0.9896640777587891, 0.9888888597488403, 0.9899224638938904, 0.9906976819038391, 0.9888888597488403, 0.988630473613739, 0.9883720874786377, 0.9912144541740417, 0.9896640777587891, 0.9855297207832336, 0.9873384833335876, 0.9914728403091431, 0.9912144541740417, 0.9925064444541931, 0.9932816624641418, 0.9925064444541931, 0.9937984347343445, 0.9901808500289917, 0.9914728403091431, 0.9922480583190918, 0.9901808500289917, 0.9904392957687378, 0.9914728403091431, 0.9917312860488892, 0.9914728403091431, 0.9940568208694458, 0.9948320388793945, 0.9930232763290405, 0.9919896721839905, 0.9943152666091919, 0.9956072568893433, 0.9935400485992432, 0.9948320388793945, 0.9956072568893433, 0.9948320388793945, 0.9919896721839905, 0.9873384833335876, 0.9937984347343445, 0.9904392957687378, 0.9943152666091919, 0.9950904250144958, 0.9968992471694946, 0.9958656430244446, 0.9968992471694946, 0.9966408014297485, 0.9956072568893433, 0.9956072568893433, 0.9948320388793945, 0.9963824152946472, 0.997157633304596], 'val_loss': [0.6645301580429077, 0.6530683040618896, 0.6484359502792358, 0.636858344078064, 0.6245153546333313, 0.601884663105011, 0.5901011228561401, 0.5604572892189026, 0.5445383191108704, 0.51528000831604, 0.49030357599258423, 0.45395177602767944, 0.43797123432159424, 0.3891485333442688, 0.3565429449081421, 0.323576956987381, 0.2960270643234253, 0.2798931896686554, 0.30410563945770264, 0.26167696714401245, 0.265048623085022, 0.2811931073665619, 0.2833845615386963, 0.2920319437980652, 0.30571961402893066, 0.3188912570476532, 0.32224375009536743, 0.33430880308151245, 0.36768049001693726, 0.35006991028785706, 0.3509737253189087, 0.35599634051322937, 0.36534833908081055, 0.3744730055332184, 0.37246474623680115, 0.3805469572544098, 0.3968924582004547, 0.39768731594085693, 0.38395074009895325, 0.38229259848594666, 0.38440975546836853, 0.3914720118045807, 0.39718425273895264, 0.4077512323856354, 0.4020468592643738, 0.4329254627227783, 0.4047054350376129, 0.4046749770641327, 0.40558865666389465, 0.40416571497917175, 0.4084261357784271, 0.4137749969959259, 0.4199260473251343, 0.42443183064460754, 0.43531253933906555, 0.41904306411743164, 0.442767858505249, 0.4335365891456604, 0.4400938153266907, 0.49263787269592285, 0.4362850785255432, 0.43891018629074097, 0.45213329792022705, 0.45314735174179077, 0.459395170211792, 0.45110535621643066, 0.4596247673034668, 0.4595566689968109, 0.4497348666191101, 0.46685996651649475, 0.4557201564311981, 0.4852198660373688, 0.4741658866405487, 0.46829482913017273, 0.5006890296936035, 0.4662034511566162, 0.47794827818870544, 0.48239102959632874, 0.4687452018260956, 0.4872264564037323, 0.48317623138427734, 0.49177587032318115, 0.478198379278183, 0.48033633828163147, 0.5038548111915588, 0.48827800154685974, 0.49441036581993103, 0.47624245285987854, 0.5449265837669373, 0.5183231830596924, 0.5201857089996338, 0.5326076745986938, 0.5214437246322632, 0.5142470002174377, 0.5198923945426941, 0.5262762904167175, 0.535165548324585, 0.5279083251953125, 0.5254426598548889, 0.5408876538276672], 'val_accuracy': [0.49793389439582825, 0.5454545617103577, 0.5423553586006165, 0.5991735458374023, 0.6353305578231812, 0.7809917330741882, 0.7582644820213318, 0.8667355179786682, 0.8419421315193176, 0.8688016533851624, 0.8657024502754211, 0.8719007968902588, 0.8584710955619812, 0.8780992031097412, 0.8832644820213318, 0.8822314143180847, 0.8915289044380188, 0.8925619721412659, 0.8688016533851624, 0.8884297609329224, 0.8904958963394165, 0.8873966932296753, 0.8925619721412659, 0.8904958963394165, 0.8915289044380188, 0.8884297609329224, 0.8873966932296753, 0.8894628286361694, 0.8780992031097412, 0.8853305578231812, 0.8822314143180847, 0.8863636255264282, 0.8873966932296753, 0.8853305578231812, 0.8811983466148376, 0.8822314143180847, 0.875, 0.8801652789115906, 0.8832644820213318, 0.8853305578231812, 0.8842975497245789, 0.8801652789115906, 0.8760330677032471, 0.8791322112083435, 0.8791322112083435, 0.8811983466148376, 0.8760330677032471, 0.8791322112083435, 0.8780992031097412, 0.8801652789115906, 0.8811983466148376, 0.8842975497245789, 0.875, 0.8853305578231812, 0.8884297609329224, 0.8760330677032471, 0.8842975497245789, 0.875, 0.875, 0.8842975497245789, 0.875, 0.8791322112083435, 0.875, 0.8729338645935059, 0.8873966932296753, 0.8791322112083435, 0.8811983466148376, 0.8873966932296753, 0.8832644820213318, 0.8832644820213318, 0.8811983466148376, 0.8863636255264282, 0.8863636255264282, 0.8739669322967529, 0.8873966932296753, 0.8822314143180847, 0.8822314143180847, 0.8811983466148376, 0.8822314143180847, 0.8811983466148376, 0.8791322112083435, 0.8863636255264282, 0.8842975497245789, 0.8801652789115906, 0.8863636255264282, 0.8739669322967529, 0.8719007968902588, 0.8780992031097412, 0.8832644820213318, 0.8729338645935059, 0.8832644820213318, 0.8842975497245789, 0.8853305578231812, 0.8739669322967529, 0.8719007968902588, 0.875, 0.8822314143180847, 0.8708677887916565, 0.8770661354064941, 0.8770661354064941]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.0593 - accuracy: 0.9814"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 54ms/step - loss: 0.0606 - accuracy: 0.9809 - val_loss: 0.6659 - val_accuracy: 0.4925\n","Epoch 2/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0535 - accuracy: 0.9836 - val_loss: 0.6637 - val_accuracy: 0.4957\n","Epoch 3/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0516 - accuracy: 0.9836 - val_loss: 0.6447 - val_accuracy: 0.5172\n","Epoch 4/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0358 - accuracy: 0.9895 - val_loss: 0.6350 - val_accuracy: 0.5356\n","Epoch 5/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0341 - accuracy: 0.9900 - val_loss: 0.6075 - val_accuracy: 0.6261\n","Epoch 6/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0328 - accuracy: 0.9908 - val_loss: 0.5911 - val_accuracy: 0.6584\n","Epoch 7/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0364 - accuracy: 0.9906 - val_loss: 0.5789 - val_accuracy: 0.6713\n","Epoch 8/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0311 - accuracy: 0.9906 - val_loss: 0.5472 - val_accuracy: 0.7220\n","Epoch 9/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.0300 - accuracy: 0.9919 - val_loss: 0.5161 - val_accuracy: 0.7845\n","Epoch 10/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0456 - accuracy: 0.9846 - val_loss: 0.4737 - val_accuracy: 0.8599\n","Epoch 11/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 0.4489 - val_accuracy: 0.8599\n","Epoch 12/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.0272 - accuracy: 0.9925 - val_loss: 0.4103 - val_accuracy: 0.8782\n","Epoch 13/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.0239 - accuracy: 0.9935 - val_loss: 0.3639 - val_accuracy: 0.9127\n","Epoch 14/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0213 - accuracy: 0.9943 - val_loss: 0.3277 - val_accuracy: 0.9181\n","Epoch 15/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0248 - accuracy: 0.9930 - val_loss: 0.2966 - val_accuracy: 0.9246\n","Epoch 16/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0236 - accuracy: 0.9938 - val_loss: 0.2909 - val_accuracy: 0.8944\n","Epoch 17/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0261 - accuracy: 0.9938 - val_loss: 0.2328 - val_accuracy: 0.9332\n","Epoch 18/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0217 - accuracy: 0.9946 - val_loss: 0.2349 - val_accuracy: 0.9116\n","Epoch 19/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0191 - accuracy: 0.9962 - val_loss: 0.1952 - val_accuracy: 0.9310\n","Epoch 20/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0286 - accuracy: 0.9908 - val_loss: 0.1895 - val_accuracy: 0.9353\n","Epoch 21/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.1929 - val_accuracy: 0.9332\n","Epoch 22/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0188 - accuracy: 0.9943 - val_loss: 0.1962 - val_accuracy: 0.9321\n","Epoch 23/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0186 - accuracy: 0.9957 - val_loss: 0.1849 - val_accuracy: 0.9364\n","Epoch 24/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0151 - accuracy: 0.9962 - val_loss: 0.1981 - val_accuracy: 0.9364\n","Epoch 25/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.2142 - val_accuracy: 0.9343\n","Epoch 26/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.2653 - val_accuracy: 0.9278\n","Epoch 27/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 0.2397 - val_accuracy: 0.9364\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.2605 - val_accuracy: 0.9300\n","Epoch 29/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0181 - accuracy: 0.9930 - val_loss: 0.2555 - val_accuracy: 0.9407\n","Epoch 30/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0151 - accuracy: 0.9946 - val_loss: 0.2552 - val_accuracy: 0.9353\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 0.3032 - val_accuracy: 0.9192\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.2791 - val_accuracy: 0.9332\n","Epoch 33/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0193 - accuracy: 0.9943 - val_loss: 0.2814 - val_accuracy: 0.9332\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0173 - accuracy: 0.9949 - val_loss: 0.2917 - val_accuracy: 0.9289\n","Epoch 35/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 0.2919 - val_accuracy: 0.9353\n","Epoch 36/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 0.2897 - val_accuracy: 0.9364\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.2951 - val_accuracy: 0.9343\n","Epoch 38/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0123 - accuracy: 0.9965 - val_loss: 0.3160 - val_accuracy: 0.9310\n","Epoch 39/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0195 - accuracy: 0.9922 - val_loss: 0.2932 - val_accuracy: 0.9300\n","Epoch 40/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0223 - accuracy: 0.9919 - val_loss: 0.3692 - val_accuracy: 0.9116\n","Epoch 41/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0234 - accuracy: 0.9919 - val_loss: 0.3046 - val_accuracy: 0.9310\n","Epoch 42/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.2939 - val_accuracy: 0.9353\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.3070 - val_accuracy: 0.9267\n","Epoch 44/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0207 - accuracy: 0.9906 - val_loss: 0.3190 - val_accuracy: 0.9300\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.2972 - val_accuracy: 0.9332\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.3132 - val_accuracy: 0.9386\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.3195 - val_accuracy: 0.9300\n","Epoch 48/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.2989 - val_accuracy: 0.9343\n","Epoch 49/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.2983 - val_accuracy: 0.9278\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.3058 - val_accuracy: 0.9353\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0107 - accuracy: 0.9981 - val_loss: 0.3285 - val_accuracy: 0.9332\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.3145 - val_accuracy: 0.9332\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.3152 - val_accuracy: 0.9246\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0092 - accuracy: 0.9981 - val_loss: 0.3346 - val_accuracy: 0.9278\n","Epoch 55/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.3009 - val_accuracy: 0.9310\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 0.2937 - val_accuracy: 0.9332\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.3278 - val_accuracy: 0.9332\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.3163 - val_accuracy: 0.9310\n","Epoch 59/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.3227 - val_accuracy: 0.9289\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.3062 - val_accuracy: 0.9310\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.3706 - val_accuracy: 0.9203\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.3159 - val_accuracy: 0.9310\n","Epoch 63/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.3309 - val_accuracy: 0.9267\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.3213 - val_accuracy: 0.9267\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.3088 - val_accuracy: 0.9321\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.3260 - val_accuracy: 0.9300\n","Epoch 67/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.3277 - val_accuracy: 0.9278\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.3451 - val_accuracy: 0.9300\n","Epoch 69/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.3579 - val_accuracy: 0.9224\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.3195 - val_accuracy: 0.9321\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.3339 - val_accuracy: 0.9278\n","Epoch 72/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.3682 - val_accuracy: 0.9181\n","Epoch 73/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.3215 - val_accuracy: 0.9246\n","Epoch 74/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0147 - accuracy: 0.9943 - val_loss: 0.3957 - val_accuracy: 0.9213\n","Epoch 75/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.3699 - val_accuracy: 0.9267\n","Epoch 76/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.3643 - val_accuracy: 0.9256\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.3440 - val_accuracy: 0.9332\n","Epoch 78/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.3763 - val_accuracy: 0.9278\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0170 - accuracy: 0.9938 - val_loss: 0.3778 - val_accuracy: 0.9289\n","Epoch 80/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 0.4055 - val_accuracy: 0.9052\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 0.3611 - val_accuracy: 0.9278\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.3489 - val_accuracy: 0.9267\n","Epoch 83/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0100 - accuracy: 0.9962 - val_loss: 0.3497 - val_accuracy: 0.9256\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.3428 - val_accuracy: 0.9256\n","Epoch 85/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 0.9965 - val_loss: 0.3855 - val_accuracy: 0.9159\n","Epoch 86/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.3687 - val_accuracy: 0.9300\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0148 - accuracy: 0.9933 - val_loss: 0.3483 - val_accuracy: 0.9321\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.4011 - val_accuracy: 0.9192\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.3643 - val_accuracy: 0.9267\n","Epoch 90/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.3824 - val_accuracy: 0.9224\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.3779 - val_accuracy: 0.9213\n","Epoch 92/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.5329 - val_accuracy: 0.8944\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0105 - accuracy: 0.9973 - val_loss: 0.3745 - val_accuracy: 0.9256\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.4123 - val_accuracy: 0.9138\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.3895 - val_accuracy: 0.9213\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.3840 - val_accuracy: 0.9235\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.3974 - val_accuracy: 0.9224\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.3910 - val_accuracy: 0.9278\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0080 - accuracy: 0.9965 - val_loss: 0.4034 - val_accuracy: 0.9267\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.4321 - val_accuracy: 0.9138\n","{'loss': [0.06063767895102501, 0.05349045619368553, 0.05162109434604645, 0.03580911085009575, 0.03410116955637932, 0.032757051289081573, 0.03636429086327553, 0.031134668737649918, 0.02998260036110878, 0.04560888186097145, 0.024132894352078438, 0.027215395122766495, 0.023856833577156067, 0.021312646567821503, 0.024849317967891693, 0.023571880534291267, 0.026083603501319885, 0.021737072616815567, 0.01905830018222332, 0.028594598174095154, 0.017851632088422775, 0.018832143396139145, 0.018597643822431564, 0.015099583193659782, 0.015205655246973038, 0.01710711047053337, 0.016510745510458946, 0.017379922792315483, 0.018053120002150536, 0.015054725110530853, 0.012868649326264858, 0.011811954900622368, 0.01930971071124077, 0.01725929230451584, 0.011766410432755947, 0.011807585135102272, 0.012053195387125015, 0.012250789441168308, 0.01952291652560234, 0.022322293370962143, 0.023438725620508194, 0.014655322767794132, 0.014365378767251968, 0.020668787881731987, 0.01313716173171997, 0.009169538505375385, 0.010468401946127415, 0.013047671876847744, 0.011943522840738297, 0.008601122535765171, 0.010669725015759468, 0.009767267853021622, 0.008221144787967205, 0.009195088408887386, 0.00957629643380642, 0.007902809418737888, 0.006214257795363665, 0.0072402055375278, 0.007659086957573891, 0.010838675312697887, 0.006735885515809059, 0.00642783660441637, 0.009553120471537113, 0.006877026055008173, 0.005861438345164061, 0.007340345531702042, 0.00499724643304944, 0.006114966701716185, 0.011075128801167011, 0.005957047455012798, 0.009204354137182236, 0.009181338362395763, 0.009516616351902485, 0.01467728242278099, 0.005464824847877026, 0.006663228385150433, 0.00586773082613945, 0.0075882538221776485, 0.017030049115419388, 0.015834270045161247, 0.007603232283145189, 0.0052964771166443825, 0.009968637488782406, 0.006737695541232824, 0.008349132724106312, 0.007202791981399059, 0.01482471078634262, 0.004530200269073248, 0.008001217618584633, 0.005412171129137278, 0.0067456383258104324, 0.009654127061367035, 0.010450438596308231, 0.0049847448244690895, 0.004751751199364662, 0.004220407921820879, 0.003983750939369202, 0.005196620710194111, 0.008005018346011639, 0.00593958655372262], 'accuracy': [0.9808728694915771, 0.9835668206214905, 0.9835668206214905, 0.9894935488700867, 0.9900323152542114, 0.990840494632721, 0.990571141242981, 0.990571141242981, 0.9919180870056152, 0.9846444129943848, 0.9932650923728943, 0.9924569129943848, 0.993534505367279, 0.9943426847457886, 0.9929956793785095, 0.993803858757019, 0.993803858757019, 0.9946120977401733, 0.9962284564971924, 0.990840494632721, 0.9940732717514038, 0.9943426847457886, 0.9956896305084229, 0.9962284564971924, 0.9956896305084229, 0.9943426847457886, 0.9946120977401733, 0.9943426847457886, 0.9929956793785095, 0.9946120977401733, 0.9970366358757019, 0.9964978694915771, 0.9943426847457886, 0.9948814511299133, 0.9973060488700867, 0.9973060488700867, 0.9962284564971924, 0.9964978694915771, 0.9921875, 0.9919180870056152, 0.9919180870056152, 0.9951508641242981, 0.9956896305084229, 0.990571141242981, 0.9970366358757019, 0.9973060488700867, 0.9967672228813171, 0.9956896305084229, 0.9967672228813171, 0.9967672228813171, 0.9981142282485962, 0.9970366358757019, 0.9970366358757019, 0.9981142282485962, 0.9975754022598267, 0.9981142282485962, 0.9989224076271057, 0.9975754022598267, 0.9981142282485962, 0.9970366358757019, 0.9981142282485962, 0.998383641242981, 0.9967672228813171, 0.9978448152542114, 0.9989224076271057, 0.9981142282485962, 0.9989224076271057, 0.998383641242981, 0.9962284564971924, 0.998383641242981, 0.9967672228813171, 0.9970366358757019, 0.9967672228813171, 0.9943426847457886, 0.9981142282485962, 0.9978448152542114, 0.9975754022598267, 0.9975754022598267, 0.993803858757019, 0.9946120977401733, 0.9981142282485962, 0.998383641242981, 0.9962284564971924, 0.998383641242981, 0.9964978694915771, 0.998383641242981, 0.9932650923728943, 0.9991918206214905, 0.9978448152542114, 0.998652994632721, 0.9978448152542114, 0.9970366358757019, 0.9973060488700867, 0.998652994632721, 0.998383641242981, 0.998652994632721, 0.9989224076271057, 0.9989224076271057, 0.9964978694915771, 0.998652994632721], 'val_loss': [0.6659361720085144, 0.6636670827865601, 0.6446964144706726, 0.6350110769271851, 0.607515275478363, 0.5910677909851074, 0.5788582563400269, 0.5471553206443787, 0.5160919427871704, 0.4737255871295929, 0.4488544166088104, 0.4102979898452759, 0.3638872802257538, 0.3277077376842499, 0.29655084013938904, 0.29090964794158936, 0.2328222244977951, 0.23494471609592438, 0.1952192336320877, 0.18947453796863556, 0.19291910529136658, 0.19624017179012299, 0.18489685654640198, 0.19809122383594513, 0.21417336165905, 0.2652508616447449, 0.23974287509918213, 0.2604720890522003, 0.25550606846809387, 0.255227655172348, 0.30317288637161255, 0.27911657094955444, 0.281406432390213, 0.29169633984565735, 0.2918523848056793, 0.28969883918762207, 0.2951238453388214, 0.31598562002182007, 0.2931528687477112, 0.3691829442977905, 0.3046296536922455, 0.29387137293815613, 0.30699795484542847, 0.3190009593963623, 0.2971893548965454, 0.3131953477859497, 0.3194780647754669, 0.2988966703414917, 0.2982930839061737, 0.30578193068504333, 0.32846927642822266, 0.31453534960746765, 0.3151875138282776, 0.3346026539802551, 0.30085182189941406, 0.2936546802520752, 0.32784023880958557, 0.3162628412246704, 0.3227277100086212, 0.3062190115451813, 0.37061822414398193, 0.31594318151474, 0.3309175670146942, 0.321252703666687, 0.3087932765483856, 0.3259686827659607, 0.32766789197921753, 0.3450790345668793, 0.3578796088695526, 0.3194997310638428, 0.33386853337287903, 0.3682057857513428, 0.3215000033378601, 0.39568495750427246, 0.3699396252632141, 0.3643149137496948, 0.34400880336761475, 0.37629976868629456, 0.37776991724967957, 0.40549078583717346, 0.36114224791526794, 0.348920077085495, 0.3496662676334381, 0.3427930176258087, 0.38552576303482056, 0.3686695396900177, 0.34832707047462463, 0.4011387228965759, 0.3643476366996765, 0.3823922872543335, 0.3779444992542267, 0.5329080820083618, 0.3744508624076843, 0.41233813762664795, 0.3894749879837036, 0.38403791189193726, 0.39737656712532043, 0.3909589946269989, 0.4033917188644409, 0.4321179986000061], 'val_accuracy': [0.4924568831920624, 0.49568966031074524, 0.517241358757019, 0.5355603694915771, 0.6260775923728943, 0.6584051847457886, 0.6713362336158752, 0.7219827771186829, 0.7844827771186829, 0.8599137663841248, 0.8599137663841248, 0.8782327771186829, 0.912715494632721, 0.9181034564971924, 0.9245689511299133, 0.8943965435028076, 0.9331896305084229, 0.9116379022598267, 0.931034505367279, 0.9353448152542114, 0.9331896305084229, 0.9321120977401733, 0.9364224076271057, 0.9364224076271057, 0.9342672228813171, 0.9278017282485962, 0.9364224076271057, 0.9299569129943848, 0.9407327771186829, 0.9353448152542114, 0.9191810488700867, 0.9331896305084229, 0.9331896305084229, 0.9288793206214905, 0.9353448152542114, 0.9364224076271057, 0.9342672228813171, 0.931034505367279, 0.9299569129943848, 0.9116379022598267, 0.931034505367279, 0.9353448152542114, 0.9267241358757019, 0.9299569129943848, 0.9331896305084229, 0.9385775923728943, 0.9299569129943848, 0.9342672228813171, 0.9278017282485962, 0.9353448152542114, 0.9331896305084229, 0.9331896305084229, 0.9245689511299133, 0.9278017282485962, 0.931034505367279, 0.9331896305084229, 0.9331896305084229, 0.931034505367279, 0.9288793206214905, 0.931034505367279, 0.920258641242981, 0.931034505367279, 0.9267241358757019, 0.9267241358757019, 0.9321120977401733, 0.9299569129943848, 0.9278017282485962, 0.9299569129943848, 0.9224137663841248, 0.9321120977401733, 0.9278017282485962, 0.9181034564971924, 0.9245689511299133, 0.9213362336158752, 0.9267241358757019, 0.9256465435028076, 0.9331896305084229, 0.9278017282485962, 0.9288793206214905, 0.9051724076271057, 0.9278017282485962, 0.9267241358757019, 0.9256465435028076, 0.9256465435028076, 0.9159482717514038, 0.9299569129943848, 0.9321120977401733, 0.9191810488700867, 0.9267241358757019, 0.9224137663841248, 0.9213362336158752, 0.8943965435028076, 0.9256465435028076, 0.9137930870056152, 0.9213362336158752, 0.923491358757019, 0.9224137663841248, 0.9278017282485962, 0.9267241358757019, 0.9137930870056152]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.0619 - accuracy: 0.9780"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 76ms/step - loss: 0.0612 - accuracy: 0.9782 - val_loss: 0.6724 - val_accuracy: 0.5034\n","Epoch 2/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.0529 - accuracy: 0.9788 - val_loss: 0.6477 - val_accuracy: 0.5328\n","Epoch 3/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0530 - accuracy: 0.9793 - val_loss: 0.6395 - val_accuracy: 0.5430\n","Epoch 4/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0397 - accuracy: 0.9873 - val_loss: 0.6318 - val_accuracy: 0.5600\n","Epoch 5/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0337 - accuracy: 0.9887 - val_loss: 0.6050 - val_accuracy: 0.6403\n","Epoch 6/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0373 - accuracy: 0.9887 - val_loss: 0.5744 - val_accuracy: 0.7907\n","Epoch 7/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0370 - accuracy: 0.9887 - val_loss: 0.5695 - val_accuracy: 0.7183\n","Epoch 8/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0277 - accuracy: 0.9904 - val_loss: 0.5377 - val_accuracy: 0.7998\n","Epoch 9/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0259 - accuracy: 0.9924 - val_loss: 0.5100 - val_accuracy: 0.8495\n","Epoch 10/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0227 - accuracy: 0.9941 - val_loss: 0.4756 - val_accuracy: 0.8937\n","Epoch 11/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0259 - accuracy: 0.9915 - val_loss: 0.4483 - val_accuracy: 0.8925\n","Epoch 12/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0282 - accuracy: 0.9895 - val_loss: 0.4141 - val_accuracy: 0.9016\n","Epoch 13/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0247 - accuracy: 0.9941 - val_loss: 0.3836 - val_accuracy: 0.9061\n","Epoch 14/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0194 - accuracy: 0.9949 - val_loss: 0.3454 - val_accuracy: 0.9208\n","Epoch 15/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 0.2973 - val_accuracy: 0.9253\n","Epoch 16/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0220 - accuracy: 0.9938 - val_loss: 0.2691 - val_accuracy: 0.9276\n","Epoch 17/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0203 - accuracy: 0.9943 - val_loss: 0.2430 - val_accuracy: 0.9344\n","Epoch 18/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0284 - accuracy: 0.9909 - val_loss: 0.2214 - val_accuracy: 0.9321\n","Epoch 19/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0227 - accuracy: 0.9941 - val_loss: 0.2069 - val_accuracy: 0.9299\n","Epoch 20/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0216 - accuracy: 0.9938 - val_loss: 0.1978 - val_accuracy: 0.9310\n","Epoch 21/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0188 - accuracy: 0.9949 - val_loss: 0.1989 - val_accuracy: 0.9321\n","Epoch 22/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0202 - accuracy: 0.9938 - val_loss: 0.2011 - val_accuracy: 0.9310\n","Epoch 23/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0203 - accuracy: 0.9924 - val_loss: 0.2115 - val_accuracy: 0.9310\n","Epoch 24/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0289 - accuracy: 0.9895 - val_loss: 0.2603 - val_accuracy: 0.9197\n","Epoch 25/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0195 - accuracy: 0.9935 - val_loss: 0.2352 - val_accuracy: 0.9276\n","Epoch 26/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.2599 - val_accuracy: 0.9219\n","Epoch 27/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0193 - accuracy: 0.9941 - val_loss: 0.2530 - val_accuracy: 0.9310\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0174 - accuracy: 0.9949 - val_loss: 0.2941 - val_accuracy: 0.9287\n","Epoch 29/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0166 - accuracy: 0.9943 - val_loss: 0.3117 - val_accuracy: 0.9152\n","Epoch 30/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0239 - accuracy: 0.9901 - val_loss: 0.3595 - val_accuracy: 0.9186\n","Epoch 31/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.2987 - val_accuracy: 0.9197\n","Epoch 32/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0192 - accuracy: 0.9929 - val_loss: 0.2923 - val_accuracy: 0.9310\n","Epoch 33/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0149 - accuracy: 0.9960 - val_loss: 0.3502 - val_accuracy: 0.9242\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.3536 - val_accuracy: 0.9242\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0166 - accuracy: 0.9943 - val_loss: 0.3140 - val_accuracy: 0.9287\n","Epoch 36/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.3296 - val_accuracy: 0.9299\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0115 - accuracy: 0.9975 - val_loss: 0.3228 - val_accuracy: 0.9299\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0081 - accuracy: 0.9989 - val_loss: 0.3467 - val_accuracy: 0.9276\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.3188 - val_accuracy: 0.9242\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.3147 - val_accuracy: 0.9310\n","Epoch 41/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0117 - accuracy: 0.9980 - val_loss: 0.3149 - val_accuracy: 0.9287\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.3226 - val_accuracy: 0.9276\n","Epoch 43/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0106 - accuracy: 0.9972 - val_loss: 0.3392 - val_accuracy: 0.9152\n","Epoch 44/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0087 - accuracy: 0.9989 - val_loss: 0.3395 - val_accuracy: 0.9231\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.3255 - val_accuracy: 0.9299\n","Epoch 46/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0156 - accuracy: 0.9941 - val_loss: 0.3773 - val_accuracy: 0.9276\n","Epoch 47/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.3512 - val_accuracy: 0.9208\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0085 - accuracy: 0.9986 - val_loss: 0.3387 - val_accuracy: 0.9287\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.3577 - val_accuracy: 0.9287\n","Epoch 50/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0101 - accuracy: 0.9972 - val_loss: 0.4011 - val_accuracy: 0.9253\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0263 - accuracy: 0.9901 - val_loss: 0.3582 - val_accuracy: 0.9208\n","Epoch 52/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0177 - accuracy: 0.9932 - val_loss: 0.4570 - val_accuracy: 0.9174\n","Epoch 53/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.3551 - val_accuracy: 0.9197\n","Epoch 54/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.3529 - val_accuracy: 0.9299\n","Epoch 55/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.3375 - val_accuracy: 0.9287\n","Epoch 56/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0059 - accuracy: 0.9992 - val_loss: 0.3495 - val_accuracy: 0.9174\n","Epoch 57/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0096 - accuracy: 0.9980 - val_loss: 0.3504 - val_accuracy: 0.9276\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.3515 - val_accuracy: 0.9253\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.3518 - val_accuracy: 0.9253\n","Epoch 60/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.3645 - val_accuracy: 0.9174\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.3550 - val_accuracy: 0.9208\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.3731 - val_accuracy: 0.9197\n","Epoch 63/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.3673 - val_accuracy: 0.9299\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0151 - accuracy: 0.9943 - val_loss: 0.3786 - val_accuracy: 0.9310\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 0.9986 - val_loss: 0.3827 - val_accuracy: 0.9242\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.3625 - val_accuracy: 0.9276\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.3641 - val_accuracy: 0.9265\n","Epoch 68/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.4222 - val_accuracy: 0.9231\n","Epoch 69/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0046 - accuracy: 0.9997 - val_loss: 0.3768 - val_accuracy: 0.9287\n","Epoch 70/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.3732 - val_accuracy: 0.9163\n","Epoch 71/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0063 - accuracy: 0.9975 - val_loss: 0.3840 - val_accuracy: 0.9231\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.3959 - val_accuracy: 0.9231\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.4449 - val_accuracy: 0.9197\n","Epoch 74/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.3774 - val_accuracy: 0.9186\n","Epoch 75/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.4439 - val_accuracy: 0.9061\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.4704 - val_accuracy: 0.9208\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.3816 - val_accuracy: 0.9231\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.3908 - val_accuracy: 0.9208\n","Epoch 79/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.4200 - val_accuracy: 0.9265\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.4297 - val_accuracy: 0.9253\n","Epoch 81/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.4057 - val_accuracy: 0.9231\n","Epoch 82/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.4151 - val_accuracy: 0.9186\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.4190 - val_accuracy: 0.9219\n","Epoch 84/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.4453 - val_accuracy: 0.9253\n","Epoch 85/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.4618 - val_accuracy: 0.9242\n","Epoch 86/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.4611 - val_accuracy: 0.9208\n","Epoch 87/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.4041 - val_accuracy: 0.9242\n","Epoch 88/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.4195 - val_accuracy: 0.9129\n","Epoch 89/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.4210 - val_accuracy: 0.9265\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0214 - accuracy: 0.9912 - val_loss: 0.4070 - val_accuracy: 0.9208\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.4057 - val_accuracy: 0.9265\n","Epoch 92/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0091 - accuracy: 0.9960 - val_loss: 0.4456 - val_accuracy: 0.9208\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.4172 - val_accuracy: 0.9208\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.4226 - val_accuracy: 0.9265\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.5026 - val_accuracy: 0.9140\n","Epoch 96/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.4768 - val_accuracy: 0.9186\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.4784 - val_accuracy: 0.9106\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0089 - accuracy: 0.9966 - val_loss: 0.4440 - val_accuracy: 0.9242\n","Epoch 99/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0082 - accuracy: 0.9963 - val_loss: 0.4464 - val_accuracy: 0.9197\n","Epoch 100/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.4868 - val_accuracy: 0.9197\n","{'loss': [0.061213113367557526, 0.05285490304231644, 0.05301393195986748, 0.039732374250888824, 0.033707279711961746, 0.0373363122344017, 0.037020113319158554, 0.02772267907857895, 0.02592170052230358, 0.022656690329313278, 0.025870587676763535, 0.028246145695447922, 0.024692006409168243, 0.019352082163095474, 0.026537204161286354, 0.021952642127871513, 0.02026197500526905, 0.028397144749760628, 0.022718802094459534, 0.021636003628373146, 0.018846342340111732, 0.020183643326163292, 0.02027294971048832, 0.02888554334640503, 0.01952619105577469, 0.013780947774648666, 0.019331062212586403, 0.017432421445846558, 0.01662175916135311, 0.023926598951220512, 0.019696902483701706, 0.01916932873427868, 0.014936795458197594, 0.014753122813999653, 0.01663576066493988, 0.011768593452870846, 0.011525686830282211, 0.00806412659585476, 0.010737193748354912, 0.012594795785844326, 0.011747749522328377, 0.012650703079998493, 0.01064511202275753, 0.008702416904270649, 0.012250297702848911, 0.015561683103442192, 0.008716369047760963, 0.00847904197871685, 0.008639673702418804, 0.010089771822094917, 0.026274019852280617, 0.017692184075713158, 0.013020006939768791, 0.011351886205375195, 0.013330460526049137, 0.005870745051652193, 0.009561729617416859, 0.007897320203483105, 0.007576006930321455, 0.0074290931224823, 0.008802318945527077, 0.008703088387846947, 0.014293995685875416, 0.015064040198922157, 0.008327451534569263, 0.010963688604533672, 0.0064852554351091385, 0.005767444148659706, 0.004619457293301821, 0.0055533843114972115, 0.006306053139269352, 0.004069274291396141, 0.006603536196053028, 0.006801306735724211, 0.007796043995767832, 0.012837664224207401, 0.005415233783423901, 0.0047951568849384785, 0.00621100002899766, 0.0066591170616447926, 0.00450735492631793, 0.008392193354666233, 0.007684545591473579, 0.0077596986666321754, 0.0056421407498419285, 0.005830920767039061, 0.004957045428454876, 0.006786747369915247, 0.009619816206395626, 0.021377019584178925, 0.007326482329517603, 0.009121011011302471, 0.005444822832942009, 0.006189845502376556, 0.003995068371295929, 0.005929004866629839, 0.003813317744061351, 0.008852023631334305, 0.008203559555113316, 0.007323161233216524], 'accuracy': [0.9782116413116455, 0.9787775874137878, 0.9793435335159302, 0.9872665405273438, 0.9886813759803772, 0.9886813759803772, 0.9886813759803772, 0.9903791546821594, 0.9923599362373352, 0.9940577149391174, 0.9915110468864441, 0.9895302653312683, 0.9940577149391174, 0.9949066042900085, 0.9920769929885864, 0.9937747716903687, 0.994340717792511, 0.9909451007843018, 0.9940577149391174, 0.9937747716903687, 0.9949066042900085, 0.9937747716903687, 0.9923599362373352, 0.9895302653312683, 0.9934917688369751, 0.996321439743042, 0.9940577149391174, 0.9949066042900085, 0.994340717792511, 0.9900962114334106, 0.9937747716903687, 0.9929258823394775, 0.9960384964942932, 0.9951896071434021, 0.994340717792511, 0.9966044425964355, 0.9974533319473267, 0.9988681674003601, 0.9966044425964355, 0.9957554936408997, 0.9980192184448242, 0.9968873858451843, 0.9971703290939331, 0.9988681674003601, 0.996321439743042, 0.9940577149391174, 0.9974533319473267, 0.9985851645469666, 0.9971703290939331, 0.9971703290939331, 0.9900962114334106, 0.9932088255882263, 0.9957554936408997, 0.9968873858451843, 0.9957554936408997, 0.9991511106491089, 0.9980192184448242, 0.9980192184448242, 0.9974533319473267, 0.9974533319473267, 0.9971703290939331, 0.9977362751960754, 0.9957554936408997, 0.994340717792511, 0.9985851645469666, 0.9968873858451843, 0.9985851645469666, 0.9985851645469666, 0.9997170567512512, 0.9988681674003601, 0.9974533319473267, 0.9991511106491089, 0.9980192184448242, 0.9988681674003601, 0.9980192184448242, 0.9960384964942932, 0.9988681674003601, 0.9994340538978577, 0.9985851645469666, 0.9980192184448242, 0.9988681674003601, 0.9968873858451843, 0.9974533319473267, 0.9974533319473267, 0.9983022212982178, 0.9983022212982178, 0.9988681674003601, 0.9980192184448242, 0.9968873858451843, 0.9912280440330505, 0.9983022212982178, 0.9960384964942932, 0.9983022212982178, 0.9980192184448242, 0.9991511106491089, 0.9985851645469666, 0.9994340538978577, 0.9966044425964355, 0.996321439743042, 0.9983022212982178], 'val_loss': [0.6723997592926025, 0.6477226614952087, 0.6395164728164673, 0.6317505836486816, 0.6050066947937012, 0.5744134187698364, 0.569473147392273, 0.5376696586608887, 0.5100100636482239, 0.4756317138671875, 0.4483156204223633, 0.41413840651512146, 0.383556991815567, 0.3454343378543854, 0.2973361611366272, 0.26914000511169434, 0.24302062392234802, 0.22141791880130768, 0.2068997323513031, 0.19783800840377808, 0.1989070624113083, 0.20112624764442444, 0.21146705746650696, 0.260310560464859, 0.2351989597082138, 0.2598980963230133, 0.2529686987400055, 0.2940966784954071, 0.31170564889907837, 0.359454870223999, 0.2986825108528137, 0.2923409044742584, 0.35020995140075684, 0.3535503149032593, 0.3140237331390381, 0.32958105206489563, 0.322823166847229, 0.34672802686691284, 0.31875079870224, 0.3147185444831848, 0.31492742896080017, 0.32259538769721985, 0.3391795754432678, 0.33945077657699585, 0.32553204894065857, 0.37729963660240173, 0.3512473404407501, 0.3387448489665985, 0.35765954852104187, 0.4011416435241699, 0.3582285940647125, 0.4569805860519409, 0.3551044464111328, 0.35292160511016846, 0.3375229239463806, 0.34948569536209106, 0.35038673877716064, 0.3515092432498932, 0.3518277704715729, 0.36451372504234314, 0.3550316095352173, 0.37313976883888245, 0.3673499524593353, 0.37859052419662476, 0.3827258348464966, 0.3625147342681885, 0.36412283778190613, 0.42216718196868896, 0.3768135607242584, 0.3731803297996521, 0.38404548168182373, 0.3958657383918762, 0.44487500190734863, 0.37740081548690796, 0.44385379552841187, 0.47037434577941895, 0.38162335753440857, 0.39079681038856506, 0.42000827193260193, 0.4296843111515045, 0.4057031571865082, 0.4151175916194916, 0.41897228360176086, 0.44533291459083557, 0.4618317186832428, 0.46112075448036194, 0.4040527939796448, 0.4195046126842499, 0.4210366904735565, 0.4070076644420624, 0.40567949414253235, 0.44563549757003784, 0.4172349274158478, 0.422589510679245, 0.50257408618927, 0.4768209755420685, 0.4783930480480194, 0.44402334094047546, 0.4464367926120758, 0.4867608845233917], 'val_accuracy': [0.5033936500549316, 0.5328054428100586, 0.5429864525794983, 0.5599547624588013, 0.6402714848518372, 0.790723979473114, 0.7183257937431335, 0.7997737526893616, 0.8495475053787231, 0.8936651349067688, 0.8925339579582214, 0.901583731174469, 0.9061086177825928, 0.9208144545555115, 0.9253393411636353, 0.9276018142700195, 0.9343891143798828, 0.9321267008781433, 0.929864227771759, 0.9309954643249512, 0.9321267008781433, 0.9309954643249512, 0.9309954643249512, 0.9196832776069641, 0.9276018142700195, 0.9219456911087036, 0.9309954643249512, 0.9287330508232117, 0.9151583909988403, 0.918552041053772, 0.9196832776069641, 0.9309954643249512, 0.9242081642150879, 0.9242081642150879, 0.9287330508232117, 0.929864227771759, 0.929864227771759, 0.9276018142700195, 0.9242081642150879, 0.9309954643249512, 0.9287330508232117, 0.9276018142700195, 0.9151583909988403, 0.9230769276618958, 0.929864227771759, 0.9276018142700195, 0.9208144545555115, 0.9287330508232117, 0.9287330508232117, 0.9253393411636353, 0.9208144545555115, 0.9174208045005798, 0.9196832776069641, 0.929864227771759, 0.9287330508232117, 0.9174208045005798, 0.9276018142700195, 0.9253393411636353, 0.9253393411636353, 0.9174208045005798, 0.9208144545555115, 0.9196832776069641, 0.929864227771759, 0.9309954643249512, 0.9242081642150879, 0.9276018142700195, 0.9264705777168274, 0.9230769276618958, 0.9287330508232117, 0.9162895679473877, 0.9230769276618958, 0.9230769276618958, 0.9196832776069641, 0.918552041053772, 0.9061086177825928, 0.9208144545555115, 0.9230769276618958, 0.9208144545555115, 0.9264705777168274, 0.9253393411636353, 0.9230769276618958, 0.918552041053772, 0.9219456911087036, 0.9253393411636353, 0.9242081642150879, 0.9208144545555115, 0.9242081642150879, 0.912895917892456, 0.9264705777168274, 0.9208144545555115, 0.9264705777168274, 0.9208144545555115, 0.9208144545555115, 0.9264705777168274, 0.9140271544456482, 0.918552041053772, 0.9106335043907166, 0.9242081642150879, 0.9196832776069641, 0.9196832776069641]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9749"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 9s 57ms/step - loss: 0.0832 - accuracy: 0.9749 - val_loss: 0.6703 - val_accuracy: 0.4928\n","Epoch 2/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0556 - accuracy: 0.9822 - val_loss: 0.6524 - val_accuracy: 0.5165\n","Epoch 3/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0574 - accuracy: 0.9801 - val_loss: 0.6522 - val_accuracy: 0.5186\n","Epoch 4/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0512 - accuracy: 0.9824 - val_loss: 0.6254 - val_accuracy: 0.5744\n","Epoch 5/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0394 - accuracy: 0.9853 - val_loss: 0.6061 - val_accuracy: 0.6188\n","Epoch 6/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0361 - accuracy: 0.9860 - val_loss: 0.5869 - val_accuracy: 0.6539\n","Epoch 7/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0381 - accuracy: 0.9876 - val_loss: 0.5556 - val_accuracy: 0.7417\n","Epoch 8/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0340 - accuracy: 0.9886 - val_loss: 0.5402 - val_accuracy: 0.7293\n","Epoch 9/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0333 - accuracy: 0.9902 - val_loss: 0.4938 - val_accuracy: 0.8419\n","Epoch 10/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0322 - accuracy: 0.9886 - val_loss: 0.4707 - val_accuracy: 0.8326\n","Epoch 11/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.0317 - accuracy: 0.9889 - val_loss: 0.4161 - val_accuracy: 0.9019\n","Epoch 12/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0317 - accuracy: 0.9879 - val_loss: 0.3815 - val_accuracy: 0.9101\n","Epoch 13/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0322 - accuracy: 0.9889 - val_loss: 0.3494 - val_accuracy: 0.9101\n","Epoch 14/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0267 - accuracy: 0.9922 - val_loss: 0.3058 - val_accuracy: 0.9174\n","Epoch 15/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.0283 - accuracy: 0.9922 - val_loss: 0.2674 - val_accuracy: 0.9205\n","Epoch 16/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0314 - accuracy: 0.9899 - val_loss: 0.2456 - val_accuracy: 0.9174\n","Epoch 17/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0265 - accuracy: 0.9910 - val_loss: 0.2569 - val_accuracy: 0.8957\n","Epoch 18/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0347 - accuracy: 0.9873 - val_loss: 0.2114 - val_accuracy: 0.9194\n","Epoch 19/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0220 - accuracy: 0.9938 - val_loss: 0.2083 - val_accuracy: 0.9215\n","Epoch 20/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.2118 - val_accuracy: 0.9205\n","Epoch 21/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0211 - accuracy: 0.9946 - val_loss: 0.2207 - val_accuracy: 0.9256\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0244 - accuracy: 0.9910 - val_loss: 0.2596 - val_accuracy: 0.9091\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0230 - accuracy: 0.9920 - val_loss: 0.2519 - val_accuracy: 0.9112\n","Epoch 24/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0201 - accuracy: 0.9943 - val_loss: 0.2877 - val_accuracy: 0.9070\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0286 - accuracy: 0.9910 - val_loss: 0.2786 - val_accuracy: 0.9184\n","Epoch 26/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0240 - accuracy: 0.9930 - val_loss: 0.3126 - val_accuracy: 0.9060\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 0.2988 - val_accuracy: 0.9184\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0269 - accuracy: 0.9920 - val_loss: 0.3015 - val_accuracy: 0.9153\n","Epoch 29/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0249 - accuracy: 0.9928 - val_loss: 0.3067 - val_accuracy: 0.9205\n","Epoch 30/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0203 - accuracy: 0.9951 - val_loss: 0.3155 - val_accuracy: 0.9184\n","Epoch 31/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0199 - accuracy: 0.9946 - val_loss: 0.3042 - val_accuracy: 0.9215\n","Epoch 32/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.3254 - val_accuracy: 0.9236\n","Epoch 33/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0145 - accuracy: 0.9953 - val_loss: 0.3211 - val_accuracy: 0.9246\n","Epoch 34/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0175 - accuracy: 0.9935 - val_loss: 0.3314 - val_accuracy: 0.9236\n","Epoch 35/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0179 - accuracy: 0.9935 - val_loss: 0.3222 - val_accuracy: 0.9246\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0166 - accuracy: 0.9941 - val_loss: 0.3673 - val_accuracy: 0.9112\n","Epoch 37/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0355 - accuracy: 0.9848 - val_loss: 0.3230 - val_accuracy: 0.9205\n","Epoch 38/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0287 - accuracy: 0.9891 - val_loss: 0.3482 - val_accuracy: 0.9101\n","Epoch 39/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0227 - accuracy: 0.9915 - val_loss: 0.4031 - val_accuracy: 0.8988\n","Epoch 40/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.3347 - val_accuracy: 0.9205\n","Epoch 41/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0216 - accuracy: 0.9930 - val_loss: 0.3334 - val_accuracy: 0.9184\n","Epoch 42/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0132 - accuracy: 0.9969 - val_loss: 0.3376 - val_accuracy: 0.9153\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.3396 - val_accuracy: 0.9143\n","Epoch 44/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0111 - accuracy: 0.9972 - val_loss: 0.3489 - val_accuracy: 0.9194\n","Epoch 45/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0138 - accuracy: 0.9948 - val_loss: 0.3429 - val_accuracy: 0.9225\n","Epoch 46/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0114 - accuracy: 0.9972 - val_loss: 0.3402 - val_accuracy: 0.9205\n","Epoch 47/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.3536 - val_accuracy: 0.9184\n","Epoch 48/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0267 - accuracy: 0.9912 - val_loss: 0.5431 - val_accuracy: 0.8905\n","Epoch 49/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0403 - accuracy: 0.9845 - val_loss: 0.3409 - val_accuracy: 0.9246\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0256 - accuracy: 0.9907 - val_loss: 0.3776 - val_accuracy: 0.9091\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.3498 - val_accuracy: 0.9163\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0123 - accuracy: 0.9982 - val_loss: 0.3667 - val_accuracy: 0.9101\n","Epoch 53/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.3540 - val_accuracy: 0.9205\n","Epoch 54/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.4033 - val_accuracy: 0.9070\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.3687 - val_accuracy: 0.9205\n","Epoch 56/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.3649 - val_accuracy: 0.9143\n","Epoch 57/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.3752 - val_accuracy: 0.9091\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.3735 - val_accuracy: 0.9163\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.3816 - val_accuracy: 0.9143\n","Epoch 60/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.3621 - val_accuracy: 0.9184\n","Epoch 61/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.3718 - val_accuracy: 0.9215\n","Epoch 62/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.3845 - val_accuracy: 0.9122\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.3825 - val_accuracy: 0.9091\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0101 - accuracy: 0.9972 - val_loss: 0.4023 - val_accuracy: 0.9132\n","Epoch 65/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.4012 - val_accuracy: 0.9174\n","Epoch 66/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0132 - accuracy: 0.9966 - val_loss: 0.4099 - val_accuracy: 0.9081\n","Epoch 67/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.3709 - val_accuracy: 0.9112\n","Epoch 68/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.4255 - val_accuracy: 0.9163\n","Epoch 69/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.4034 - val_accuracy: 0.9153\n","Epoch 70/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.3945 - val_accuracy: 0.9194\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.3940 - val_accuracy: 0.9163\n","Epoch 72/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.3870 - val_accuracy: 0.9091\n","Epoch 73/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.3842 - val_accuracy: 0.9122\n","Epoch 74/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0118 - accuracy: 0.9951 - val_loss: 0.4478 - val_accuracy: 0.9091\n","Epoch 75/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.4115 - val_accuracy: 0.9153\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.4145 - val_accuracy: 0.9174\n","Epoch 77/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.4306 - val_accuracy: 0.9091\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 0.9966 - val_loss: 0.4030 - val_accuracy: 0.9163\n","Epoch 79/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.3983 - val_accuracy: 0.9101\n","Epoch 80/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.4011 - val_accuracy: 0.9153\n","Epoch 81/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.4152 - val_accuracy: 0.9143\n","Epoch 82/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.4886 - val_accuracy: 0.9050\n","Epoch 83/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.4176 - val_accuracy: 0.9070\n","Epoch 84/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.4610 - val_accuracy: 0.9019\n","Epoch 85/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.4183 - val_accuracy: 0.9101\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0091 - accuracy: 0.9966 - val_loss: 0.4207 - val_accuracy: 0.9070\n","Epoch 87/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 0.9992 - val_loss: 0.4057 - val_accuracy: 0.9153\n","Epoch 88/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.4473 - val_accuracy: 0.9101\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.4231 - val_accuracy: 0.9132\n","Epoch 90/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.4270 - val_accuracy: 0.9112\n","Epoch 91/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.4248 - val_accuracy: 0.9132\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 0.4339 - val_accuracy: 0.9081\n","Epoch 93/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 0.4469 - val_accuracy: 0.9091\n","Epoch 94/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.4083 - val_accuracy: 0.9153\n","Epoch 95/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.4927 - val_accuracy: 0.9060\n","Epoch 96/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.4972 - val_accuracy: 0.8946\n","Epoch 97/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.4141 - val_accuracy: 0.9122\n","Epoch 98/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 0.6087 - val_accuracy: 0.8874\n","Epoch 99/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0167 - accuracy: 0.9922 - val_loss: 0.4337 - val_accuracy: 0.8957\n","Epoch 100/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.4234 - val_accuracy: 0.9060\n","{'loss': [0.08315558731555939, 0.0556204728782177, 0.05740658938884735, 0.05121983215212822, 0.03944846987724304, 0.03605719655752182, 0.038096219301223755, 0.03404153510928154, 0.033349741250276566, 0.032226819545030594, 0.0317072793841362, 0.03170154616236687, 0.032190170139074326, 0.02671842835843563, 0.02825646474957466, 0.031446438282728195, 0.026488661766052246, 0.03474639728665352, 0.021994974464178085, 0.02188108116388321, 0.021074414253234863, 0.024402137845754623, 0.02298852615058422, 0.020097414031624794, 0.028623463585972786, 0.023989951238036156, 0.027846386656165123, 0.02688090316951275, 0.024855326861143112, 0.020270943641662598, 0.01987966150045395, 0.014839496463537216, 0.01445576548576355, 0.017513230443000793, 0.017922647297382355, 0.016569901257753372, 0.03546403720974922, 0.02867138758301735, 0.022685643285512924, 0.01487899199128151, 0.02158132940530777, 0.013210806995630264, 0.015053678303956985, 0.011083293706178665, 0.013794909231364727, 0.011365439742803574, 0.01368339080363512, 0.026662928983569145, 0.04032238572835922, 0.025576848536729813, 0.014920156449079514, 0.012264187447726727, 0.009820105507969856, 0.009724198840558529, 0.010412006638944149, 0.013501450419425964, 0.00833627488464117, 0.009203227236866951, 0.010502185672521591, 0.00845433585345745, 0.009510581381618977, 0.010375558398663998, 0.01615225337445736, 0.010090070776641369, 0.009943665936589241, 0.013238620012998581, 0.010432207956910133, 0.012649769894778728, 0.01020929217338562, 0.00749101722612977, 0.007136393338441849, 0.0065041715279221535, 0.008619594387710094, 0.011779622174799442, 0.009040954522788525, 0.009234749712049961, 0.00843428447842598, 0.0082028117030859, 0.005831236485391855, 0.005261341575533152, 0.007801251020282507, 0.008812191896140575, 0.01161207165569067, 0.00599793391302228, 0.005585205741226673, 0.009056959301233292, 0.00585695868358016, 0.013501602225005627, 0.008842583745718002, 0.00546031491830945, 0.00891941599547863, 0.015086885541677475, 0.013155410997569561, 0.009157413616776466, 0.009795045480132103, 0.014825701713562012, 0.02394605427980423, 0.01419417466968298, 0.01668405532836914, 0.007983237504959106], 'accuracy': [0.9749354124069214, 0.9821705222129822, 0.9801033735275269, 0.9824289679527283, 0.9852713346481323, 0.9860464930534363, 0.987596869468689, 0.988630473613739, 0.9901808500289917, 0.988630473613739, 0.9888888597488403, 0.9878553152084351, 0.9888888597488403, 0.9922480583190918, 0.9922480583190918, 0.9899224638938904, 0.9909560680389404, 0.9873384833335876, 0.9937984347343445, 0.9932816624641418, 0.9945736527442932, 0.9909560680389404, 0.9919896721839905, 0.9943152666091919, 0.9909560680389404, 0.9930232763290405, 0.9912144541740417, 0.9919896721839905, 0.9927648305892944, 0.9950904250144958, 0.9945736527442932, 0.9956072568893433, 0.9953488111495972, 0.9935400485992432, 0.9935400485992432, 0.9940568208694458, 0.9847545027732849, 0.9891473054885864, 0.9914728403091431, 0.9950904250144958, 0.9930232763290405, 0.9968992471694946, 0.9950904250144958, 0.997157633304596, 0.9948320388793945, 0.997157633304596, 0.9950904250144958, 0.9912144541740417, 0.9844961166381836, 0.9906976819038391, 0.9953488111495972, 0.998191237449646, 0.9979327917098999, 0.9979327917098999, 0.9966408014297485, 0.9956072568893433, 0.998191237449646, 0.9974160194396973, 0.9966408014297485, 0.998191237449646, 0.997157633304596, 0.9974160194396973, 0.9948320388793945, 0.997157633304596, 0.9979327917098999, 0.9966408014297485, 0.9968992471694946, 0.9958656430244446, 0.9966408014297485, 0.997157633304596, 0.998191237449646, 0.9984496235847473, 0.9979327917098999, 0.9950904250144958, 0.9968992471694946, 0.9976744055747986, 0.9974160194396973, 0.9966408014297485, 0.9987080097198486, 0.9992247819900513, 0.998191237449646, 0.9968992471694946, 0.9958656430244446, 0.9987080097198486, 0.9987080097198486, 0.9966408014297485, 0.9992247819900513, 0.9958656430244446, 0.9974160194396973, 0.9987080097198486, 0.9976744055747986, 0.9956072568893433, 0.9961240291595459, 0.9974160194396973, 0.9968992471694946, 0.9956072568893433, 0.9917312860488892, 0.9953488111495972, 0.9922480583190918, 0.9979327917098999], 'val_loss': [0.6703418493270874, 0.6524137258529663, 0.6522036194801331, 0.6253955960273743, 0.606076717376709, 0.5869192481040955, 0.5556333065032959, 0.5402072668075562, 0.49382302165031433, 0.4707495868206024, 0.4160829782485962, 0.3814792037010193, 0.3494237959384918, 0.30576378107070923, 0.26738157868385315, 0.2455844134092331, 0.2569376230239868, 0.21136988699436188, 0.20833581686019897, 0.21175585687160492, 0.22069403529167175, 0.25959163904190063, 0.2519264817237854, 0.2877373993396759, 0.2785876393318176, 0.31257331371307373, 0.2987888753414154, 0.30154478549957275, 0.30669254064559937, 0.3155267834663391, 0.3041655123233795, 0.32536715269088745, 0.3211289346218109, 0.33136555552482605, 0.32223543524742126, 0.36733177304267883, 0.3230385482311249, 0.34815967082977295, 0.40307891368865967, 0.33473628759384155, 0.3333609104156494, 0.337575763463974, 0.3396422266960144, 0.34885767102241516, 0.34294039011001587, 0.34022676944732666, 0.3535934090614319, 0.5430715680122375, 0.34091028571128845, 0.3776177763938904, 0.3498077392578125, 0.36667948961257935, 0.3540140986442566, 0.4033075273036957, 0.3686982989311218, 0.364879310131073, 0.3751830756664276, 0.37347957491874695, 0.38159021735191345, 0.36207056045532227, 0.3718236982822418, 0.38448837399482727, 0.3824949264526367, 0.4023247957229614, 0.4011731743812561, 0.40987062454223633, 0.3709292709827423, 0.42553386092185974, 0.4033631682395935, 0.39449524879455566, 0.39397117495536804, 0.3869868516921997, 0.3841642141342163, 0.4477875232696533, 0.41153478622436523, 0.4145355224609375, 0.430580198764801, 0.402976930141449, 0.3982764184474945, 0.40106022357940674, 0.41519811749458313, 0.4885837435722351, 0.4176182448863983, 0.4609869420528412, 0.4182947278022766, 0.42074039578437805, 0.4057481288909912, 0.4472579061985016, 0.42314741015434265, 0.4269520044326782, 0.42479923367500305, 0.4338536858558655, 0.44690951704978943, 0.4083084762096405, 0.4926643669605255, 0.49717214703559875, 0.4141261875629425, 0.6086982488632202, 0.433666467666626, 0.42341744899749756], 'val_accuracy': [0.4927685856819153, 0.5165289044380188, 0.5185950398445129, 0.5743801593780518, 0.6188016533851624, 0.6539255976676941, 0.7417355179786682, 0.7293388247489929, 0.8419421315193176, 0.8326446413993835, 0.9018595218658447, 0.9101239442825317, 0.9101239442825317, 0.9173553586006165, 0.9204545617103577, 0.9173553586006165, 0.8956611752510071, 0.9194214940071106, 0.9214876294136047, 0.9204545617103577, 0.9256198406219482, 0.9090909361839294, 0.9111570119857788, 0.9070248007774353, 0.9183884263038635, 0.9059917330741882, 0.9183884263038635, 0.9152892827987671, 0.9204545617103577, 0.9183884263038635, 0.9214876294136047, 0.9235537052154541, 0.9245867729187012, 0.9235537052154541, 0.9245867729187012, 0.9111570119857788, 0.9204545617103577, 0.9101239442825317, 0.8987603187561035, 0.9204545617103577, 0.9183884263038635, 0.9152892827987671, 0.91425621509552, 0.9194214940071106, 0.922520637512207, 0.9204545617103577, 0.9183884263038635, 0.8904958963394165, 0.9245867729187012, 0.9090909361839294, 0.9163222908973694, 0.9101239442825317, 0.9204545617103577, 0.9070248007774353, 0.9204545617103577, 0.91425621509552, 0.9090909361839294, 0.9163222908973694, 0.91425621509552, 0.9183884263038635, 0.9214876294136047, 0.9121900796890259, 0.9090909361839294, 0.913223147392273, 0.9173553586006165, 0.9080578684806824, 0.9111570119857788, 0.9163222908973694, 0.9152892827987671, 0.9194214940071106, 0.9163222908973694, 0.9090909361839294, 0.9121900796890259, 0.9090909361839294, 0.9152892827987671, 0.9173553586006165, 0.9090909361839294, 0.9163222908973694, 0.9101239442825317, 0.9152892827987671, 0.91425621509552, 0.9049586653709412, 0.9070248007774353, 0.9018595218658447, 0.9101239442825317, 0.9070248007774353, 0.9152892827987671, 0.9101239442825317, 0.913223147392273, 0.9111570119857788, 0.913223147392273, 0.9080578684806824, 0.9090909361839294, 0.9152892827987671, 0.9059917330741882, 0.89462810754776, 0.9121900796890259, 0.8873966932296753, 0.8956611752510071, 0.9059917330741882]}\n","32/32 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 7s 52ms/step - loss: 0.0338 - accuracy: 0.9903 - val_loss: 0.6867 - val_accuracy: 0.4881\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0260 - accuracy: 0.9941 - val_loss: 0.6734 - val_accuracy: 0.4903\n","Epoch 3/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0265 - accuracy: 0.9919 - val_loss: 0.6549 - val_accuracy: 0.5043\n","Epoch 4/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0174 - accuracy: 0.9919 - val_loss: 0.6456 - val_accuracy: 0.5119\n","Epoch 5/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.5976 - val_accuracy: 0.5981\n","Epoch 6/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0164 - accuracy: 0.9941 - val_loss: 0.5929 - val_accuracy: 0.5927\n","Epoch 7/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0155 - accuracy: 0.9957 - val_loss: 0.5395 - val_accuracy: 0.7037\n","Epoch 8/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.0167 - accuracy: 0.9952 - val_loss: 0.5090 - val_accuracy: 0.7532\n","Epoch 9/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0170 - accuracy: 0.9941 - val_loss: 0.5021 - val_accuracy: 0.7198\n","Epoch 10/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 0.4884 - val_accuracy: 0.7220\n","Epoch 11/100\n","29/29 [==============================] - 1s 43ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.4181 - val_accuracy: 0.8394\n","Epoch 12/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.3786 - val_accuracy: 0.8556\n","Epoch 13/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.3456 - val_accuracy: 0.8653\n","Epoch 14/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0070 - accuracy: 0.9989 - val_loss: 0.2979 - val_accuracy: 0.9041\n","Epoch 15/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.2341 - val_accuracy: 0.9418\n","Epoch 16/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.2269 - val_accuracy: 0.9224\n","Epoch 17/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.1851 - val_accuracy: 0.9429\n","Epoch 18/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0101 - accuracy: 0.9973 - val_loss: 0.1530 - val_accuracy: 0.9494\n","Epoch 19/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.1544 - val_accuracy: 0.9537\n","Epoch 20/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0121 - accuracy: 0.9968 - val_loss: 0.1489 - val_accuracy: 0.9494\n","Epoch 21/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.1870 - val_accuracy: 0.9321\n","Epoch 22/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.1625 - val_accuracy: 0.9483\n","Epoch 23/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.1635 - val_accuracy: 0.9558\n","Epoch 24/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.1767 - val_accuracy: 0.9537\n","Epoch 25/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.2118 - val_accuracy: 0.9418\n","Epoch 26/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.2189 - val_accuracy: 0.9450\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.1868 - val_accuracy: 0.9558\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.2386 - val_accuracy: 0.9375\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.2031 - val_accuracy: 0.9547\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0127 - accuracy: 0.9949 - val_loss: 0.2271 - val_accuracy: 0.9494\n","Epoch 31/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.2176 - val_accuracy: 0.9526\n","Epoch 32/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.2293 - val_accuracy: 0.9483\n","Epoch 33/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.2402 - val_accuracy: 0.9483\n","Epoch 34/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.2364 - val_accuracy: 0.9526\n","Epoch 35/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.2339 - val_accuracy: 0.9569\n","Epoch 36/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.2262 - val_accuracy: 0.9537\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.2351 - val_accuracy: 0.9494\n","Epoch 38/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.2730 - val_accuracy: 0.9461\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.2400 - val_accuracy: 0.9515\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.2416 - val_accuracy: 0.9537\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.2658 - val_accuracy: 0.9461\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.2807 - val_accuracy: 0.9386\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.2529 - val_accuracy: 0.9461\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.2351 - val_accuracy: 0.9558\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.2715 - val_accuracy: 0.9515\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0098 - accuracy: 0.9960 - val_loss: 0.3042 - val_accuracy: 0.9289\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 0.2487 - val_accuracy: 0.9537\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.2547 - val_accuracy: 0.9504\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.2968 - val_accuracy: 0.9418\n","Epoch 50/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0231 - accuracy: 0.9900 - val_loss: 0.2547 - val_accuracy: 0.9472\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0098 - accuracy: 0.9954 - val_loss: 0.2538 - val_accuracy: 0.9429\n","Epoch 52/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.2498 - val_accuracy: 0.9418\n","Epoch 53/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.2583 - val_accuracy: 0.9450\n","Epoch 54/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.3474 - val_accuracy: 0.9343\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 0.2508 - val_accuracy: 0.9494\n","Epoch 56/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.2838 - val_accuracy: 0.9386\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.2596 - val_accuracy: 0.9472\n","Epoch 58/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 0.3175 - val_accuracy: 0.9397\n","Epoch 59/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.2656 - val_accuracy: 0.9429\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.3665 - val_accuracy: 0.9203\n","Epoch 61/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.3719 - val_accuracy: 0.9203\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0124 - accuracy: 0.9952 - val_loss: 0.2663 - val_accuracy: 0.9429\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.2818 - val_accuracy: 0.9407\n","Epoch 64/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.3000 - val_accuracy: 0.9343\n","Epoch 65/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.4151 - val_accuracy: 0.9138\n","Epoch 66/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0158 - accuracy: 0.9933 - val_loss: 0.3953 - val_accuracy: 0.9310\n","Epoch 67/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.2875 - val_accuracy: 0.9343\n","Epoch 68/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.2650 - val_accuracy: 0.9483\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.2687 - val_accuracy: 0.9472\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.3864 - val_accuracy: 0.9149\n","Epoch 71/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.2666 - val_accuracy: 0.9472\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.2586 - val_accuracy: 0.9483\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.3474 - val_accuracy: 0.9256\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0074 - accuracy: 0.9968 - val_loss: 0.2521 - val_accuracy: 0.9494\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.2677 - val_accuracy: 0.9472\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.2604 - val_accuracy: 0.9429\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.2642 - val_accuracy: 0.9418\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.2570 - val_accuracy: 0.9483\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.2692 - val_accuracy: 0.9429\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0043 - accuracy: 0.9981 - val_loss: 0.2627 - val_accuracy: 0.9440\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.2638 - val_accuracy: 0.9472\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.2855 - val_accuracy: 0.9407\n","Epoch 83/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.2674 - val_accuracy: 0.9450\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.2672 - val_accuracy: 0.9461\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.2733 - val_accuracy: 0.9483\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.3729 - val_accuracy: 0.9267\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.2747 - val_accuracy: 0.9472\n","Epoch 88/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.2859 - val_accuracy: 0.9440\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.2851 - val_accuracy: 0.9494\n","Epoch 90/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.2760 - val_accuracy: 0.9429\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.3884 - val_accuracy: 0.9289\n","Epoch 92/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0145 - accuracy: 0.9946 - val_loss: 0.3001 - val_accuracy: 0.9397\n","Epoch 93/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0055 - accuracy: 0.9978 - val_loss: 0.3028 - val_accuracy: 0.9386\n","Epoch 94/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.3193 - val_accuracy: 0.9429\n","Epoch 95/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.2765 - val_accuracy: 0.9375\n","Epoch 96/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.2661 - val_accuracy: 0.9440\n","Epoch 97/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.2994 - val_accuracy: 0.9375\n","Epoch 98/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.2949 - val_accuracy: 0.9418\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.2914 - val_accuracy: 0.9397\n","Epoch 100/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.2888 - val_accuracy: 0.9440\n","{'loss': [0.03381572663784027, 0.026020610705018044, 0.02645270898938179, 0.017371956259012222, 0.020465834066271782, 0.016444316133856773, 0.01548680942505598, 0.016651296988129616, 0.017041414976119995, 0.018006373196840286, 0.014242958277463913, 0.008679485879838467, 0.008813159540295601, 0.006953396834433079, 0.009679599665105343, 0.006864681374281645, 0.005376178305596113, 0.010129858739674091, 0.008845505304634571, 0.012115650810301304, 0.010624784976243973, 0.01288100890815258, 0.00625101150944829, 0.007219439372420311, 0.008668053895235062, 0.011835458688437939, 0.01864432729780674, 0.010824201628565788, 0.01325787790119648, 0.012650346383452415, 0.005778586026281118, 0.0069211325608193874, 0.006708814296871424, 0.004808914382010698, 0.003677906934171915, 0.006376350298523903, 0.0033870949409902096, 0.0030847308225929737, 0.00275134458206594, 0.0036231817211955786, 0.0051124198362231255, 0.0034063851926475763, 0.0032605049200356007, 0.002093184506520629, 0.004749820102006197, 0.00981828197836876, 0.0051550655625760555, 0.002857363782823086, 0.0038231136277318, 0.023128265514969826, 0.009822548367083073, 0.005898121278733015, 0.007160288281738758, 0.006854369305074215, 0.011985096149146557, 0.008209900930523872, 0.007785698864609003, 0.00837823934853077, 0.0072499830275774, 0.0074460175819695, 0.006149435881525278, 0.012363533489406109, 0.005263877101242542, 0.004960114136338234, 0.008746101520955563, 0.01581037975847721, 0.00858820416033268, 0.0027494681999087334, 0.0023760569747537374, 0.004066908732056618, 0.004240158013999462, 0.0025515351444482803, 0.004670551046729088, 0.0074182008393108845, 0.002931286348029971, 0.004365092143416405, 0.001851631561294198, 0.002297939732670784, 0.001607447862625122, 0.004303355701267719, 0.0034915837459266186, 0.005913666915148497, 0.001856766757555306, 0.003192812204360962, 0.005782559514045715, 0.00743109779432416, 0.008182240650057793, 0.0029443225357681513, 0.0039879498071968555, 0.0035449638962745667, 0.0016818211879581213, 0.01445587258785963, 0.005539626348763704, 0.003289165673777461, 0.00358183472417295, 0.0029684538021683693, 0.0016702115535736084, 0.0024926632177084684, 0.00265663955360651, 0.0025074374862015247], 'accuracy': [0.9903017282485962, 0.9940732717514038, 0.9919180870056152, 0.9919180870056152, 0.993534505367279, 0.9940732717514038, 0.9956896305084229, 0.9951508641242981, 0.9940732717514038, 0.9943426847457886, 0.9956896305084229, 0.9973060488700867, 0.9975754022598267, 0.9989224076271057, 0.9975754022598267, 0.9981142282485962, 0.9989224076271057, 0.9973060488700867, 0.9975754022598267, 0.9967672228813171, 0.9964978694915771, 0.9954202771186829, 0.998383641242981, 0.9978448152542114, 0.9970366358757019, 0.9954202771186829, 0.9940732717514038, 0.9970366358757019, 0.9959590435028076, 0.9948814511299133, 0.998652994632721, 0.9981142282485962, 0.998383641242981, 0.998383641242981, 0.9989224076271057, 0.9978448152542114, 0.9991918206214905, 0.9994612336158752, 0.9997305870056152, 0.9989224076271057, 0.998652994632721, 0.9994612336158752, 0.9989224076271057, 0.9997305870056152, 0.998652994632721, 0.9959590435028076, 0.9981142282485962, 0.9997305870056152, 0.9989224076271057, 0.9900323152542114, 0.9954202771186829, 0.9989224076271057, 0.9978448152542114, 0.9975754022598267, 0.9956896305084229, 0.9970366358757019, 0.9970366358757019, 0.9981142282485962, 0.9978448152542114, 0.9978448152542114, 0.9981142282485962, 0.9951508641242981, 0.998383641242981, 0.9989224076271057, 0.9973060488700867, 0.9932650923728943, 0.9970366358757019, 0.9994612336158752, 0.9994612336158752, 0.998652994632721, 0.9989224076271057, 0.9991918206214905, 0.998383641242981, 0.9967672228813171, 0.9989224076271057, 0.9989224076271057, 0.9994612336158752, 0.9994612336158752, 0.9997305870056152, 0.9981142282485962, 0.9991918206214905, 0.998383641242981, 0.9997305870056152, 0.9989224076271057, 0.9975754022598267, 0.9975754022598267, 0.9970366358757019, 0.9989224076271057, 0.9991918206214905, 0.9991918206214905, 0.9997305870056152, 0.9946120977401733, 0.9978448152542114, 0.9989224076271057, 0.9991918206214905, 0.9991918206214905, 0.9997305870056152, 0.9994612336158752, 0.9989224076271057, 0.9991918206214905], 'val_loss': [0.6866578459739685, 0.6733502745628357, 0.6549137830734253, 0.6456398963928223, 0.5975951552391052, 0.5928504467010498, 0.5394734144210815, 0.509044885635376, 0.5021134614944458, 0.4884389638900757, 0.41811949014663696, 0.3785686790943146, 0.34564876556396484, 0.297860324382782, 0.2340744137763977, 0.22688689827919006, 0.18508432805538177, 0.1530253291130066, 0.15441596508026123, 0.14888907968997955, 0.18698197603225708, 0.1625099778175354, 0.16353322565555573, 0.17670534551143646, 0.21177184581756592, 0.21890351176261902, 0.18678312003612518, 0.23859983682632446, 0.2031070739030838, 0.22710783779621124, 0.21758121252059937, 0.22927920520305634, 0.24017450213432312, 0.23642094433307648, 0.23386259377002716, 0.22617779672145844, 0.23505865037441254, 0.27300575375556946, 0.24004417657852173, 0.24160410463809967, 0.2657739520072937, 0.28070706129074097, 0.2528662085533142, 0.2350587695837021, 0.2714521586894989, 0.3041759133338928, 0.2486800104379654, 0.2546735107898712, 0.29681044816970825, 0.2547336518764496, 0.25375092029571533, 0.24983403086662292, 0.25834569334983826, 0.34737688302993774, 0.25084176659584045, 0.28380781412124634, 0.25961780548095703, 0.31750956177711487, 0.26561155915260315, 0.3664689362049103, 0.37193483114242554, 0.26628944277763367, 0.2817972004413605, 0.30001145601272583, 0.41511109471321106, 0.395292192697525, 0.2874860167503357, 0.26496443152427673, 0.26874056458473206, 0.3864228129386902, 0.2665989100933075, 0.2585861086845398, 0.34739458560943604, 0.2520679831504822, 0.2677452862262726, 0.26039770245552063, 0.26421836018562317, 0.2570051848888397, 0.2692427933216095, 0.262704461812973, 0.26380735635757446, 0.2854681611061096, 0.2674340605735779, 0.26720738410949707, 0.27332568168640137, 0.3729032874107361, 0.2746850550174713, 0.28588277101516724, 0.285148024559021, 0.2760011553764343, 0.38844138383865356, 0.3000921905040741, 0.302754282951355, 0.31929078698158264, 0.2764776051044464, 0.26605424284935, 0.29935595393180847, 0.2949449419975281, 0.29142120480537415, 0.288788765668869], 'val_accuracy': [0.4881465435028076, 0.4903017282485962, 0.5043103694915771, 0.5118534564971924, 0.5980603694915771, 0.5926724076271057, 0.7036637663841248, 0.7532327771186829, 0.7198275923728943, 0.7219827771186829, 0.8394396305084229, 0.8556034564971924, 0.8653017282485962, 0.9040948152542114, 0.9418103694915771, 0.9224137663841248, 0.9428879022598267, 0.9493534564971924, 0.9536637663841248, 0.9493534564971924, 0.9321120977401733, 0.9482758641242981, 0.9558189511299133, 0.9536637663841248, 0.9418103694915771, 0.9450430870056152, 0.9558189511299133, 0.9375, 0.954741358757019, 0.9493534564971924, 0.9525862336158752, 0.9482758641242981, 0.9482758641242981, 0.9525862336158752, 0.9568965435028076, 0.9536637663841248, 0.9493534564971924, 0.9461206793785095, 0.951508641242981, 0.9536637663841248, 0.9461206793785095, 0.9385775923728943, 0.9461206793785095, 0.9558189511299133, 0.951508641242981, 0.9288793206214905, 0.9536637663841248, 0.9504310488700867, 0.9418103694915771, 0.9471982717514038, 0.9428879022598267, 0.9418103694915771, 0.9450430870056152, 0.9342672228813171, 0.9493534564971924, 0.9385775923728943, 0.9471982717514038, 0.9396551847457886, 0.9428879022598267, 0.920258641242981, 0.920258641242981, 0.9428879022598267, 0.9407327771186829, 0.9342672228813171, 0.9137930870056152, 0.931034505367279, 0.9342672228813171, 0.9482758641242981, 0.9471982717514038, 0.9148706793785095, 0.9471982717514038, 0.9482758641242981, 0.9256465435028076, 0.9493534564971924, 0.9471982717514038, 0.9428879022598267, 0.9418103694915771, 0.9482758641242981, 0.9428879022598267, 0.943965494632721, 0.9471982717514038, 0.9407327771186829, 0.9450430870056152, 0.9461206793785095, 0.9482758641242981, 0.9267241358757019, 0.9471982717514038, 0.943965494632721, 0.9493534564971924, 0.9428879022598267, 0.9288793206214905, 0.9396551847457886, 0.9385775923728943, 0.9428879022598267, 0.9375, 0.943965494632721, 0.9375, 0.9418103694915771, 0.9396551847457886, 0.943965494632721]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.0374 - accuracy: 0.9878"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 7s 56ms/step - loss: 0.0366 - accuracy: 0.9884 - val_loss: 0.6745 - val_accuracy: 0.5045\n","Epoch 2/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0216 - accuracy: 0.9935 - val_loss: 0.6652 - val_accuracy: 0.5113\n","Epoch 3/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0329 - accuracy: 0.9892 - val_loss: 0.6226 - val_accuracy: 0.5633\n","Epoch 4/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0267 - accuracy: 0.9898 - val_loss: 0.6123 - val_accuracy: 0.5871\n","Epoch 5/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.0197 - accuracy: 0.9949 - val_loss: 0.5977 - val_accuracy: 0.6052\n","Epoch 6/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.0156 - accuracy: 0.9943 - val_loss: 0.5845 - val_accuracy: 0.6210\n","Epoch 7/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.0154 - accuracy: 0.9955 - val_loss: 0.5612 - val_accuracy: 0.6516\n","Epoch 8/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 0.5192 - val_accuracy: 0.7443\n","Epoch 9/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0161 - accuracy: 0.9943 - val_loss: 0.5103 - val_accuracy: 0.7195\n","Epoch 10/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0327 - accuracy: 0.9861 - val_loss: 0.4457 - val_accuracy: 0.8597\n","Epoch 11/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0163 - accuracy: 0.9943 - val_loss: 0.4267 - val_accuracy: 0.8529\n","Epoch 12/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.3703 - val_accuracy: 0.9265\n","Epoch 13/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 0.3355 - val_accuracy: 0.9299\n","Epoch 14/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.3094 - val_accuracy: 0.9129\n","Epoch 15/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0074 - accuracy: 0.9966 - val_loss: 0.2647 - val_accuracy: 0.9367\n","Epoch 16/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0080 - accuracy: 0.9969 - val_loss: 0.2208 - val_accuracy: 0.9480\n","Epoch 17/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.2102 - val_accuracy: 0.9468\n","Epoch 18/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.1923 - val_accuracy: 0.9446\n","Epoch 19/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.1858 - val_accuracy: 0.9389\n","Epoch 20/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0140 - accuracy: 0.9946 - val_loss: 0.1599 - val_accuracy: 0.9514\n","Epoch 21/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.1540 - val_accuracy: 0.9480\n","Epoch 22/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.1605 - val_accuracy: 0.9502\n","Epoch 23/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.1760 - val_accuracy: 0.9480\n","Epoch 24/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.1934 - val_accuracy: 0.9412\n","Epoch 25/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.1856 - val_accuracy: 0.9502\n","Epoch 26/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.1982 - val_accuracy: 0.9514\n","Epoch 27/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0156 - accuracy: 0.9963 - val_loss: 0.2273 - val_accuracy: 0.9468\n","Epoch 28/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.2596 - val_accuracy: 0.9389\n","Epoch 29/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0094 - accuracy: 0.9960 - val_loss: 0.2412 - val_accuracy: 0.9446\n","Epoch 30/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.2467 - val_accuracy: 0.9468\n","Epoch 31/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.2762 - val_accuracy: 0.9400\n","Epoch 32/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0089 - accuracy: 0.9966 - val_loss: 0.2657 - val_accuracy: 0.9355\n","Epoch 33/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.2708 - val_accuracy: 0.9457\n","Epoch 34/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0090 - accuracy: 0.9975 - val_loss: 0.2702 - val_accuracy: 0.9446\n","Epoch 35/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.2867 - val_accuracy: 0.9434\n","Epoch 36/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.2906 - val_accuracy: 0.9400\n","Epoch 37/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0063 - accuracy: 0.9992 - val_loss: 0.2925 - val_accuracy: 0.9423\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0148 - accuracy: 0.9955 - val_loss: 0.3308 - val_accuracy: 0.9400\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0247 - accuracy: 0.9901 - val_loss: 0.2853 - val_accuracy: 0.9412\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0502 - accuracy: 0.9844 - val_loss: 0.3314 - val_accuracy: 0.9287\n","Epoch 41/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.2658 - val_accuracy: 0.9434\n","Epoch 42/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0069 - accuracy: 0.9975 - val_loss: 0.2581 - val_accuracy: 0.9446\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.2735 - val_accuracy: 0.9446\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.3157 - val_accuracy: 0.9355\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0036 - accuracy: 0.9997 - val_loss: 0.2699 - val_accuracy: 0.9446\n","Epoch 46/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 0.2864 - val_accuracy: 0.9400\n","Epoch 47/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2712 - val_accuracy: 0.9457\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.3122 - val_accuracy: 0.9389\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.2673 - val_accuracy: 0.9468\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 0.2637 - val_accuracy: 0.9491\n","Epoch 51/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.2657 - val_accuracy: 0.9468\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.2766 - val_accuracy: 0.9423\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.3184 - val_accuracy: 0.9400\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.2960 - val_accuracy: 0.9367\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.3028 - val_accuracy: 0.9468\n","Epoch 56/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0058 - accuracy: 0.9972 - val_loss: 0.2865 - val_accuracy: 0.9468\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.3178 - val_accuracy: 0.9378\n","Epoch 58/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.2841 - val_accuracy: 0.9446\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.2959 - val_accuracy: 0.9457\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.2877 - val_accuracy: 0.9468\n","Epoch 61/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.3545 - val_accuracy: 0.9355\n","Epoch 62/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.3209 - val_accuracy: 0.9434\n","Epoch 63/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.3161 - val_accuracy: 0.9434\n","Epoch 64/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.2863 - val_accuracy: 0.9446\n","Epoch 65/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.3013 - val_accuracy: 0.9378\n","Epoch 66/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.3524 - val_accuracy: 0.9378\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.3414 - val_accuracy: 0.9412\n","Epoch 68/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.2940 - val_accuracy: 0.9480\n","Epoch 69/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0060 - accuracy: 0.9975 - val_loss: 0.3128 - val_accuracy: 0.9423\n","Epoch 70/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.3094 - val_accuracy: 0.9468\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3965 - val_accuracy: 0.9287\n","Epoch 72/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.3026 - val_accuracy: 0.9457\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.2942 - val_accuracy: 0.9468\n","Epoch 74/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.2991 - val_accuracy: 0.9480\n","Epoch 75/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.3150 - val_accuracy: 0.9446\n","Epoch 76/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 0.2978 - val_accuracy: 0.9491\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.3584 - val_accuracy: 0.9378\n","Epoch 78/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.4936 - val_accuracy: 0.9140\n","Epoch 79/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0051 - accuracy: 0.9972 - val_loss: 0.3009 - val_accuracy: 0.9457\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.3185 - val_accuracy: 0.9446\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.3138 - val_accuracy: 0.9389\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.3083 - val_accuracy: 0.9400\n","Epoch 83/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.3653 - val_accuracy: 0.9310\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.3067 - val_accuracy: 0.9423\n","Epoch 85/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.4462 - val_accuracy: 0.9106\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.3511 - val_accuracy: 0.9333\n","Epoch 87/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.3953 - val_accuracy: 0.9321\n","Epoch 88/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.3364 - val_accuracy: 0.9412\n","Epoch 89/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.3340 - val_accuracy: 0.9434\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.4954 - val_accuracy: 0.9084\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0119 - accuracy: 0.9952 - val_loss: 0.3497 - val_accuracy: 0.9321\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.3339 - val_accuracy: 0.9423\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.7350 - val_accuracy: 0.8801\n","Epoch 94/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.4543 - val_accuracy: 0.9231\n","Epoch 95/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.3201 - val_accuracy: 0.9434\n","Epoch 96/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.3815 - val_accuracy: 0.9355\n","Epoch 97/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.3287 - val_accuracy: 0.9446\n","Epoch 98/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.3445 - val_accuracy: 0.9434\n","Epoch 99/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3260 - val_accuracy: 0.9378\n","Epoch 100/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3474 - val_accuracy: 0.9400\n","{'loss': [0.03658335655927658, 0.02155672200024128, 0.03293149918317795, 0.026661548763513565, 0.0197383314371109, 0.01560997311025858, 0.015418577007949352, 0.015835026279091835, 0.016085762530565262, 0.03271881490945816, 0.016253642737865448, 0.011874038726091385, 0.007431903854012489, 0.009387398138642311, 0.007403988856822252, 0.007977332919836044, 0.008163344115018845, 0.007088488899171352, 0.006931016221642494, 0.01404782384634018, 0.0075718411244452, 0.006556712556630373, 0.007005119230598211, 0.005785905756056309, 0.005412927828729153, 0.006625662092119455, 0.015563013963401318, 0.008742168545722961, 0.009380458854138851, 0.008453656919300556, 0.01006204355508089, 0.008931782096624374, 0.017477691173553467, 0.009016655385494232, 0.00807232316583395, 0.007475408725440502, 0.006336837075650692, 0.01481526717543602, 0.024697354063391685, 0.05015881732106209, 0.012511582113802433, 0.006863159593194723, 0.005612058565020561, 0.0037679823581129313, 0.00361019279807806, 0.004384223837405443, 0.0028339303098618984, 0.004257110878825188, 0.0031561399810016155, 0.00772214587777853, 0.005430490244179964, 0.0023631840012967587, 0.00407905550673604, 0.0038739866577088833, 0.004411378409713507, 0.005817518103867769, 0.0027810835745185614, 0.0025450086686760187, 0.0037885643541812897, 0.0037148369010537863, 0.002171039581298828, 0.004296777304261923, 0.003193748416379094, 0.0022743355948477983, 0.00524904066696763, 0.004737060982733965, 0.0032875854521989822, 0.0025147509295493364, 0.005989967379719019, 0.004750236868858337, 0.0022995315957814455, 0.0037000086158514023, 0.0030935294926166534, 0.0030747868586331606, 0.002361617051064968, 0.0034990923013538122, 0.0038473904132843018, 0.008374973200261593, 0.00512689771130681, 0.004869469907134771, 0.00751454895362258, 0.005929769016802311, 0.006826077587902546, 0.003002905985340476, 0.005020464304834604, 0.008669912815093994, 0.00783059373497963, 0.003400595625862479, 0.0049369363114237785, 0.004516572691500187, 0.01191556453704834, 0.009211644530296326, 0.009427632205188274, 0.012870155274868011, 0.006249132566154003, 0.00403162045404315, 0.00331040658056736, 0.0039035987574607134, 0.002170479390770197, 0.0012921519810333848], 'accuracy': [0.9883984327316284, 0.9934917688369751, 0.9892473220825195, 0.9898132681846619, 0.9949066042900085, 0.994340717792511, 0.9954725503921509, 0.9946236610412598, 0.994340717792511, 0.9861347079277039, 0.994340717792511, 0.9966044425964355, 0.9985851645469666, 0.9968873858451843, 0.9966044425964355, 0.9968873858451843, 0.9971703290939331, 0.9983022212982178, 0.9985851645469666, 0.9946236610412598, 0.9974533319473267, 0.9977362751960754, 0.9985851645469666, 0.9980192184448242, 0.9991511106491089, 0.9983022212982178, 0.996321439743042, 0.9977362751960754, 0.9960384964942932, 0.9968873858451843, 0.996321439743042, 0.9966044425964355, 0.994340717792511, 0.9974533319473267, 0.9977362751960754, 0.9977362751960754, 0.9991511106491089, 0.9954725503921509, 0.9900962114334106, 0.9844368696212769, 0.996321439743042, 0.9974533319473267, 0.9983022212982178, 0.9991511106491089, 0.9997170567512512, 0.9983022212982178, 1.0, 0.9988681674003601, 0.9994340538978577, 0.9980192184448242, 0.9980192184448242, 0.9997170567512512, 0.9991511106491089, 0.9991511106491089, 0.9985851645469666, 0.9971703290939331, 0.9994340538978577, 0.9997170567512512, 0.9988681674003601, 0.9988681674003601, 0.9997170567512512, 0.9985851645469666, 0.9997170567512512, 0.9997170567512512, 0.9983022212982178, 0.9985851645469666, 0.9991511106491089, 0.9991511106491089, 0.9974533319473267, 0.9988681674003601, 1.0, 0.9988681674003601, 0.9988681674003601, 0.9988681674003601, 0.9994340538978577, 0.9985851645469666, 0.9994340538978577, 0.9974533319473267, 0.9971703290939331, 0.9988681674003601, 0.9974533319473267, 0.9988681674003601, 0.9983022212982178, 0.9997170567512512, 0.9985851645469666, 0.9971703290939331, 0.9974533319473267, 0.9994340538978577, 0.9985851645469666, 0.9985851645469666, 0.9951896071434021, 0.9968873858451843, 0.9971703290939331, 0.996321439743042, 0.9983022212982178, 0.9985851645469666, 0.9988681674003601, 0.9988681674003601, 1.0, 1.0], 'val_loss': [0.6745455861091614, 0.6652413606643677, 0.6225529313087463, 0.6122790575027466, 0.5976915955543518, 0.5844890475273132, 0.5612093806266785, 0.5191830396652222, 0.5103153586387634, 0.4456871449947357, 0.42670196294784546, 0.3702697157859802, 0.3355017602443695, 0.3094461262226105, 0.26472511887550354, 0.22083896398544312, 0.2102051079273224, 0.1923469752073288, 0.18577180802822113, 0.15989598631858826, 0.15395505726337433, 0.1605464667081833, 0.17604827880859375, 0.19343741238117218, 0.18563036620616913, 0.19818954169750214, 0.22727583348751068, 0.25959959626197815, 0.24121864140033722, 0.2466629296541214, 0.27623450756073, 0.2656826078891754, 0.2707922160625458, 0.2701539099216461, 0.2867319881916046, 0.2905966341495514, 0.2924525737762451, 0.3307506740093231, 0.28532832860946655, 0.3314134478569031, 0.2658388614654541, 0.2581475079059601, 0.2734910845756531, 0.3157283067703247, 0.2699461579322815, 0.2863962650299072, 0.2711620032787323, 0.3121516704559326, 0.26733100414276123, 0.2637283205986023, 0.2657342851161957, 0.27655139565467834, 0.31843632459640503, 0.2959500253200531, 0.3027722239494324, 0.2865021228790283, 0.3178330957889557, 0.2840528190135956, 0.29585954546928406, 0.28768444061279297, 0.3544532358646393, 0.3208852708339691, 0.3161257207393646, 0.2862945795059204, 0.3013460338115692, 0.35241565108299255, 0.3414101004600525, 0.2940281331539154, 0.31281861662864685, 0.3093552887439728, 0.396484375, 0.3025625944137573, 0.29424411058425903, 0.29907000064849854, 0.3150146007537842, 0.2978173494338989, 0.358422189950943, 0.4936027228832245, 0.3008521497249603, 0.318461537361145, 0.3138170838356018, 0.3082874119281769, 0.365286648273468, 0.3067017197608948, 0.44620636105537415, 0.35111120343208313, 0.39526981115341187, 0.3363652527332306, 0.3339734971523285, 0.49537792801856995, 0.3496897220611572, 0.3338935375213623, 0.7349743247032166, 0.4543375074863434, 0.3200557231903076, 0.381535142660141, 0.3286921977996826, 0.3445322811603546, 0.32595568895339966, 0.3474191427230835], 'val_accuracy': [0.5045248866081238, 0.5113122463226318, 0.5633484125137329, 0.587104082107544, 0.6052036285400391, 0.6210407018661499, 0.651583731174469, 0.7443438768386841, 0.7194570302963257, 0.8597285151481628, 0.8529411554336548, 0.9264705777168274, 0.929864227771759, 0.912895917892456, 0.9366515874862671, 0.9479637742042542, 0.9468325972557068, 0.9445701241493225, 0.9389140009880066, 0.9513574838638306, 0.9479637742042542, 0.9502262473106384, 0.9479637742042542, 0.9411764740943909, 0.9502262473106384, 0.9513574838638306, 0.9468325972557068, 0.9389140009880066, 0.9445701241493225, 0.9468325972557068, 0.9400452375411987, 0.935520350933075, 0.9457013607025146, 0.9445701241493225, 0.9434388875961304, 0.9400452375411987, 0.942307710647583, 0.9400452375411987, 0.9411764740943909, 0.9287330508232117, 0.9434388875961304, 0.9445701241493225, 0.9445701241493225, 0.935520350933075, 0.9445701241493225, 0.9400452375411987, 0.9457013607025146, 0.9389140009880066, 0.9468325972557068, 0.9490950107574463, 0.9468325972557068, 0.942307710647583, 0.9400452375411987, 0.9366515874862671, 0.9468325972557068, 0.9468325972557068, 0.9377828240394592, 0.9445701241493225, 0.9457013607025146, 0.9468325972557068, 0.935520350933075, 0.9434388875961304, 0.9434388875961304, 0.9445701241493225, 0.9377828240394592, 0.9377828240394592, 0.9411764740943909, 0.9479637742042542, 0.942307710647583, 0.9468325972557068, 0.9287330508232117, 0.9457013607025146, 0.9468325972557068, 0.9479637742042542, 0.9445701241493225, 0.9490950107574463, 0.9377828240394592, 0.9140271544456482, 0.9457013607025146, 0.9445701241493225, 0.9389140009880066, 0.9400452375411987, 0.9309954643249512, 0.942307710647583, 0.9106335043907166, 0.9332579374313354, 0.9321267008781433, 0.9411764740943909, 0.9434388875961304, 0.9083710312843323, 0.9321267008781433, 0.942307710647583, 0.8800904750823975, 0.9230769276618958, 0.9434388875961304, 0.935520350933075, 0.9445701241493225, 0.9434388875961304, 0.9377828240394592, 0.9400452375411987]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.0533 - accuracy: 0.9841"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 74ms/step - loss: 0.0526 - accuracy: 0.9845 - val_loss: 0.6888 - val_accuracy: 0.4866\n","Epoch 2/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.0262 - accuracy: 0.9917 - val_loss: 0.6673 - val_accuracy: 0.5021\n","Epoch 3/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0310 - accuracy: 0.9894 - val_loss: 0.6425 - val_accuracy: 0.5227\n","Epoch 4/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0244 - accuracy: 0.9899 - val_loss: 0.6352 - val_accuracy: 0.5331\n","Epoch 5/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.5972 - val_accuracy: 0.5950\n","Epoch 6/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0234 - accuracy: 0.9928 - val_loss: 0.5597 - val_accuracy: 0.6798\n","Epoch 7/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0161 - accuracy: 0.9941 - val_loss: 0.5343 - val_accuracy: 0.7159\n","Epoch 8/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.5037 - val_accuracy: 0.7624\n","Epoch 9/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0204 - accuracy: 0.9925 - val_loss: 0.4662 - val_accuracy: 0.8140\n","Epoch 10/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.4213 - val_accuracy: 0.8574\n","Epoch 11/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0157 - accuracy: 0.9946 - val_loss: 0.3873 - val_accuracy: 0.8719\n","Epoch 12/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.3384 - val_accuracy: 0.9091\n","Epoch 13/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 0.3003 - val_accuracy: 0.9132\n","Epoch 14/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.2708 - val_accuracy: 0.9101\n","Epoch 15/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.2283 - val_accuracy: 0.9298\n","Epoch 16/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.2129 - val_accuracy: 0.9256\n","Epoch 17/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.1791 - val_accuracy: 0.9308\n","Epoch 18/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0165 - accuracy: 0.9941 - val_loss: 0.2050 - val_accuracy: 0.9153\n","Epoch 19/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.1721 - val_accuracy: 0.9421\n","Epoch 20/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.1846 - val_accuracy: 0.9370\n","Epoch 21/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.2123 - val_accuracy: 0.9339\n","Epoch 22/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.2168 - val_accuracy: 0.9390\n","Epoch 23/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0204 - accuracy: 0.9920 - val_loss: 0.2109 - val_accuracy: 0.9370\n","Epoch 24/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0087 - accuracy: 0.9964 - val_loss: 0.2283 - val_accuracy: 0.9370\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0157 - accuracy: 0.9943 - val_loss: 0.2470 - val_accuracy: 0.9360\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.2441 - val_accuracy: 0.9411\n","Epoch 27/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.2518 - val_accuracy: 0.9432\n","Epoch 28/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.2743 - val_accuracy: 0.9349\n","Epoch 29/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.2971 - val_accuracy: 0.9360\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.2992 - val_accuracy: 0.9370\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.3377 - val_accuracy: 0.9298\n","Epoch 32/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0077 - accuracy: 0.9990 - val_loss: 0.2849 - val_accuracy: 0.9380\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0063 - accuracy: 0.9992 - val_loss: 0.2982 - val_accuracy: 0.9370\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.3363 - val_accuracy: 0.9298\n","Epoch 35/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0091 - accuracy: 0.9964 - val_loss: 0.2973 - val_accuracy: 0.9329\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.3139 - val_accuracy: 0.9349\n","Epoch 37/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.3108 - val_accuracy: 0.9339\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.3261 - val_accuracy: 0.9277\n","Epoch 39/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.3190 - val_accuracy: 0.9360\n","Epoch 40/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.3164 - val_accuracy: 0.9298\n","Epoch 41/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0192 - accuracy: 0.9941 - val_loss: 0.3780 - val_accuracy: 0.9298\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.3132 - val_accuracy: 0.9380\n","Epoch 43/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.3146 - val_accuracy: 0.9370\n","Epoch 44/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.3316 - val_accuracy: 0.9349\n","Epoch 45/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.3265 - val_accuracy: 0.9339\n","Epoch 46/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.3262 - val_accuracy: 0.9360\n","Epoch 47/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0100 - accuracy: 0.9959 - val_loss: 0.3508 - val_accuracy: 0.9390\n","Epoch 48/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.3359 - val_accuracy: 0.9318\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.3397 - val_accuracy: 0.9349\n","Epoch 50/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.3265 - val_accuracy: 0.9360\n","Epoch 51/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.3298 - val_accuracy: 0.9318\n","Epoch 52/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.3401 - val_accuracy: 0.9256\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0067 - accuracy: 0.9966 - val_loss: 0.3430 - val_accuracy: 0.9287\n","Epoch 54/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.3464 - val_accuracy: 0.9349\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.3439 - val_accuracy: 0.9318\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.3596 - val_accuracy: 0.9298\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.3468 - val_accuracy: 0.9349\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.3624 - val_accuracy: 0.9308\n","Epoch 59/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.3354 - val_accuracy: 0.9380\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 0.3476 - val_accuracy: 0.9349\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.3357 - val_accuracy: 0.9318\n","Epoch 62/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.3468 - val_accuracy: 0.9308\n","Epoch 63/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.4126 - val_accuracy: 0.9174\n","Epoch 64/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.3526 - val_accuracy: 0.9318\n","Epoch 65/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.3970 - val_accuracy: 0.9277\n","Epoch 66/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.3580 - val_accuracy: 0.9287\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.3672 - val_accuracy: 0.9329\n","Epoch 68/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.3538 - val_accuracy: 0.9287\n","Epoch 69/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.3914 - val_accuracy: 0.9236\n","Epoch 70/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.3539 - val_accuracy: 0.9287\n","Epoch 71/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.3548 - val_accuracy: 0.9360\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0103 - accuracy: 0.9961 - val_loss: 0.3475 - val_accuracy: 0.9349\n","Epoch 73/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0286 - accuracy: 0.9902 - val_loss: 0.4014 - val_accuracy: 0.9298\n","Epoch 74/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 0.3615 - val_accuracy: 0.9318\n","Epoch 75/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.3643 - val_accuracy: 0.9318\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.3684 - val_accuracy: 0.9298\n","Epoch 77/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 0.3710 - val_accuracy: 0.9298\n","Epoch 78/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.3674 - val_accuracy: 0.9298\n","Epoch 79/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.3633 - val_accuracy: 0.9308\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.3815 - val_accuracy: 0.9298\n","Epoch 81/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.3779 - val_accuracy: 0.9349\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.4076 - val_accuracy: 0.9246\n","Epoch 83/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.3771 - val_accuracy: 0.9308\n","Epoch 84/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.3818 - val_accuracy: 0.9318\n","Epoch 85/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.4006 - val_accuracy: 0.9225\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.3794 - val_accuracy: 0.9298\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.3811 - val_accuracy: 0.9298\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.3711 - val_accuracy: 0.9277\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.3891 - val_accuracy: 0.9277\n","Epoch 90/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.3890 - val_accuracy: 0.9256\n","Epoch 91/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.3544 - val_accuracy: 0.9329\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.3613 - val_accuracy: 0.9318\n","Epoch 93/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.3991 - val_accuracy: 0.9256\n","Epoch 94/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.3700 - val_accuracy: 0.9329\n","Epoch 95/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.3963 - val_accuracy: 0.9236\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0106 - accuracy: 0.9953 - val_loss: 0.3842 - val_accuracy: 0.9360\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.3626 - val_accuracy: 0.9298\n","Epoch 98/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.3713 - val_accuracy: 0.9287\n","Epoch 99/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.3643 - val_accuracy: 0.9329\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0094 - accuracy: 0.9959 - val_loss: 0.4145 - val_accuracy: 0.9246\n","{'loss': [0.05261360853910446, 0.026178613305091858, 0.031031131744384766, 0.024418620392680168, 0.01750100590288639, 0.02339733950793743, 0.01605728268623352, 0.014589681290090084, 0.020410330966114998, 0.012085704132914543, 0.015744416043162346, 0.012564065866172314, 0.01297403872013092, 0.009899389930069447, 0.01160286646336317, 0.006726078223437071, 0.01413124892860651, 0.01650630123913288, 0.0173279270529747, 0.013640140183269978, 0.008631056174635887, 0.012026173062622547, 0.020423471927642822, 0.008650844916701317, 0.015727559104561806, 0.008665643632411957, 0.009183051995933056, 0.0071332878433167934, 0.006981497630476952, 0.008325326256453991, 0.015379385091364384, 0.0077245901338756084, 0.006302550435066223, 0.008577565662562847, 0.009116290137171745, 0.007276811171323061, 0.006755133159458637, 0.008278843946754932, 0.007436585146933794, 0.006750868167728186, 0.019179893657565117, 0.013357591815292835, 0.010457375086843967, 0.005909114610403776, 0.0063901362009346485, 0.00641546119004488, 0.010040069930255413, 0.010561193339526653, 0.01682617887854576, 0.005246803164482117, 0.006296446546912193, 0.004522617906332016, 0.006728953216224909, 0.008534807711839676, 0.0034778343979269266, 0.006857721600681543, 0.013141469098627567, 0.006450155284255743, 0.004600174259394407, 0.005100838840007782, 0.005748807452619076, 0.004580744542181492, 0.00594636844471097, 0.006184571422636509, 0.006368005182594061, 0.004117245320230722, 0.00411520479246974, 0.007351547479629517, 0.006659578066319227, 0.012053883634507656, 0.005595081020146608, 0.010256779380142689, 0.02855265699326992, 0.010117018595337868, 0.006484586279839277, 0.003937233705073595, 0.0033389537129551172, 0.004214595537632704, 0.0038808733224868774, 0.0037165479734539986, 0.004338597413152456, 0.00553151685744524, 0.003767261980101466, 0.004990250337868929, 0.0049117631278932095, 0.010430029593408108, 0.003188032191246748, 0.005428193137049675, 0.003741363063454628, 0.005898206494748592, 0.004875705111771822, 0.004310960415750742, 0.007408419158309698, 0.005308280233293772, 0.00382816675119102, 0.010587847791612148, 0.005376334302127361, 0.004251117818057537, 0.010491946712136269, 0.009352135471999645], 'accuracy': [0.9844961166381836, 0.9917312860488892, 0.9894056916236877, 0.9899224638938904, 0.9943152666091919, 0.9927648305892944, 0.9940568208694458, 0.9953488111495972, 0.9925064444541931, 0.9963824152946472, 0.9945736527442932, 0.9956072568893433, 0.9961240291595459, 0.9966408014297485, 0.9966408014297485, 0.9979327917098999, 0.9956072568893433, 0.9940568208694458, 0.9943152666091919, 0.9956072568893433, 0.998191237449646, 0.9963824152946472, 0.9919896721839905, 0.9963824152946472, 0.9943152666091919, 0.9976744055747986, 0.9968992471694946, 0.9979327917098999, 0.9984496235847473, 0.9979327917098999, 0.9953488111495972, 0.99896639585495, 0.9992247819900513, 0.997157633304596, 0.9963824152946472, 0.9976744055747986, 0.9984496235847473, 0.9976744055747986, 0.998191237449646, 0.9979327917098999, 0.9940568208694458, 0.9958656430244446, 0.9974160194396973, 0.9987080097198486, 0.9984496235847473, 0.9987080097198486, 0.9958656430244446, 0.9968992471694946, 0.9950904250144958, 0.99896639585495, 0.9979327917098999, 0.99896639585495, 0.9966408014297485, 0.997157633304596, 0.9994832277297974, 0.9974160194396973, 0.9956072568893433, 0.9984496235847473, 0.9987080097198486, 0.9994832277297974, 0.9984496235847473, 0.9994832277297974, 0.9987080097198486, 0.9979327917098999, 0.9979327917098999, 0.99896639585495, 0.9994832277297974, 0.9974160194396973, 0.9979327917098999, 0.9958656430244446, 0.99896639585495, 0.9961240291595459, 0.9901808500289917, 0.9963824152946472, 0.9987080097198486, 0.9992247819900513, 0.9984496235847473, 0.9987080097198486, 0.9987080097198486, 0.99896639585495, 0.99896639585495, 0.998191237449646, 0.99896639585495, 0.9987080097198486, 0.9984496235847473, 0.9966408014297485, 0.9997416138648987, 0.9979327917098999, 0.9992247819900513, 0.998191237449646, 0.9987080097198486, 0.99896639585495, 0.9976744055747986, 0.998191237449646, 0.9992247819900513, 0.9953488111495972, 0.9987080097198486, 0.9987080097198486, 0.9966408014297485, 0.9958656430244446], 'val_loss': [0.6888211369514465, 0.6673353910446167, 0.6424579620361328, 0.6351895928382874, 0.5972089171409607, 0.5596786737442017, 0.5342690944671631, 0.5036527514457703, 0.46617311239242554, 0.42127394676208496, 0.3872640132904053, 0.3384492099285126, 0.300342321395874, 0.27076396346092224, 0.22829575836658478, 0.21286025643348694, 0.17906835675239563, 0.20496031641960144, 0.17212660610675812, 0.18464188277721405, 0.2123267650604248, 0.21683913469314575, 0.21089956164360046, 0.22832739353179932, 0.24702174961566925, 0.24413900077342987, 0.2517603933811188, 0.2743209898471832, 0.29706713557243347, 0.2991577684879303, 0.337688148021698, 0.2849474549293518, 0.2981618344783783, 0.33628156781196594, 0.2973228096961975, 0.31390830874443054, 0.31080061197280884, 0.3260592818260193, 0.3189854323863983, 0.31638282537460327, 0.37798982858657837, 0.3132290840148926, 0.3146406412124634, 0.3315848112106323, 0.32648056745529175, 0.3261568546295166, 0.35081490874290466, 0.33588188886642456, 0.3397132158279419, 0.326480895280838, 0.32978764176368713, 0.34011366963386536, 0.3430325984954834, 0.3464356064796448, 0.3438756465911865, 0.35959044098854065, 0.346832811832428, 0.3623844087123871, 0.33544495701789856, 0.3476354479789734, 0.33571508526802063, 0.3467560410499573, 0.4125555455684662, 0.3526013493537903, 0.39703482389450073, 0.3579779863357544, 0.36719489097595215, 0.3538419306278229, 0.3913736939430237, 0.35394784808158875, 0.3547893166542053, 0.34747448563575745, 0.4013981223106384, 0.3614773750305176, 0.3642626106739044, 0.3683822751045227, 0.37097886204719543, 0.36742642521858215, 0.3633134961128235, 0.3814924359321594, 0.3779233694076538, 0.40763407945632935, 0.37712836265563965, 0.3818172514438629, 0.40064939856529236, 0.3793998956680298, 0.38111597299575806, 0.3710702657699585, 0.38906994462013245, 0.38898995518684387, 0.3543846011161804, 0.36132365465164185, 0.399077445268631, 0.3699986934661865, 0.39630600810050964, 0.38422515988349915, 0.3625843822956085, 0.3712675869464874, 0.3642853796482086, 0.4144990146160126], 'val_accuracy': [0.48657023906707764, 0.5020661354064941, 0.5227272510528564, 0.5330578684806824, 0.5950413346290588, 0.6797520518302917, 0.7159090638160706, 0.7623966932296753, 0.8140496015548706, 0.8574380278587341, 0.8719007968902588, 0.9090909361839294, 0.913223147392273, 0.9101239442825317, 0.9297520518302917, 0.9256198406219482, 0.9307851195335388, 0.9152892827987671, 0.942148745059967, 0.9369834661483765, 0.93388432264328, 0.9390496015548706, 0.9369834661483765, 0.9369834661483765, 0.9359503984451294, 0.94111567735672, 0.9431818127632141, 0.9349173307418823, 0.9359503984451294, 0.9369834661483765, 0.9297520518302917, 0.9380165338516235, 0.9369834661483765, 0.9297520518302917, 0.932851254940033, 0.9349173307418823, 0.93388432264328, 0.9276859760284424, 0.9359503984451294, 0.9297520518302917, 0.9297520518302917, 0.9380165338516235, 0.9369834661483765, 0.9349173307418823, 0.93388432264328, 0.9359503984451294, 0.9390496015548706, 0.9318181872367859, 0.9349173307418823, 0.9359503984451294, 0.9318181872367859, 0.9256198406219482, 0.9287189841270447, 0.9349173307418823, 0.9318181872367859, 0.9297520518302917, 0.9349173307418823, 0.9307851195335388, 0.9380165338516235, 0.9349173307418823, 0.9318181872367859, 0.9307851195335388, 0.9173553586006165, 0.9318181872367859, 0.9276859760284424, 0.9287189841270447, 0.932851254940033, 0.9287189841270447, 0.9235537052154541, 0.9287189841270447, 0.9359503984451294, 0.9349173307418823, 0.9297520518302917, 0.9318181872367859, 0.9318181872367859, 0.9297520518302917, 0.9297520518302917, 0.9297520518302917, 0.9307851195335388, 0.9297520518302917, 0.9349173307418823, 0.9245867729187012, 0.9307851195335388, 0.9318181872367859, 0.922520637512207, 0.9297520518302917, 0.9297520518302917, 0.9276859760284424, 0.9276859760284424, 0.9256198406219482, 0.932851254940033, 0.9318181872367859, 0.9256198406219482, 0.932851254940033, 0.9235537052154541, 0.9359503984451294, 0.9297520518302917, 0.9287189841270447, 0.932851254940033, 0.9245867729187012]}\n","32/32 [==============================] - 1s 4ms/step\n"]}],"source":["global_model, metrics_df = federated_learning(Theta_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ik5JoVP2NPvY","colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"status":"ok","timestamp":1716751864184,"user_tz":-360,"elapsed":14,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"a92b8cb5-56ac-4d1a-f597-3887a7b5675b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.770      0.776   0.759  0.767        0.759        0.781   \n","1        1     0.763      0.706   0.904  0.793        0.904        0.623   \n","2        2     0.739      0.708   0.813  0.757        0.813        0.665   \n","3        0     0.807      0.793   0.832  0.812        0.832        0.782   \n","4        1     0.838      0.835   0.843  0.839        0.843        0.833   \n","5        2     0.795      0.754   0.876  0.810        0.876        0.715   \n","6        0     0.835      0.812   0.871  0.841        0.871        0.799   \n","7        1     0.881      0.871   0.894  0.882        0.894        0.867   \n","8        2     0.861      0.836   0.900  0.867        0.900        0.823   \n","9        0     0.853      0.806   0.930  0.863        0.930        0.776   \n","10       1     0.905      0.918   0.890  0.904        0.890        0.921   \n","11       2     0.888      0.850   0.942  0.893        0.942        0.833   \n","12       0     0.878      0.845   0.925  0.883        0.925        0.831   \n","13       1     0.919      0.921   0.918  0.919        0.918        0.921   \n","14       2     0.918      0.913   0.924  0.918        0.924        0.912   \n","\n","    Kappa  \n","0   0.539  \n","1   0.527  \n","2   0.478  \n","3   0.615  \n","4   0.677  \n","5   0.590  \n","6   0.670  \n","7   0.761  \n","8   0.723  \n","9   0.705  \n","10  0.811  \n","11  0.775  \n","12  0.755  \n","13  0.839  \n","14  0.835  "],"text/html":["\n","  <div id=\"df-3a16b386-c79a-4487-8419-50de2ec1cec5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.770</td>\n","      <td>0.776</td>\n","      <td>0.759</td>\n","      <td>0.767</td>\n","      <td>0.759</td>\n","      <td>0.781</td>\n","      <td>0.539</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.763</td>\n","      <td>0.706</td>\n","      <td>0.904</td>\n","      <td>0.793</td>\n","      <td>0.904</td>\n","      <td>0.623</td>\n","      <td>0.527</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.739</td>\n","      <td>0.708</td>\n","      <td>0.813</td>\n","      <td>0.757</td>\n","      <td>0.813</td>\n","      <td>0.665</td>\n","      <td>0.478</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.807</td>\n","      <td>0.793</td>\n","      <td>0.832</td>\n","      <td>0.812</td>\n","      <td>0.832</td>\n","      <td>0.782</td>\n","      <td>0.615</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.838</td>\n","      <td>0.835</td>\n","      <td>0.843</td>\n","      <td>0.839</td>\n","      <td>0.843</td>\n","      <td>0.833</td>\n","      <td>0.677</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.795</td>\n","      <td>0.754</td>\n","      <td>0.876</td>\n","      <td>0.810</td>\n","      <td>0.876</td>\n","      <td>0.715</td>\n","      <td>0.590</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.835</td>\n","      <td>0.812</td>\n","      <td>0.871</td>\n","      <td>0.841</td>\n","      <td>0.871</td>\n","      <td>0.799</td>\n","      <td>0.670</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.881</td>\n","      <td>0.871</td>\n","      <td>0.894</td>\n","      <td>0.882</td>\n","      <td>0.894</td>\n","      <td>0.867</td>\n","      <td>0.761</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.861</td>\n","      <td>0.836</td>\n","      <td>0.900</td>\n","      <td>0.867</td>\n","      <td>0.900</td>\n","      <td>0.823</td>\n","      <td>0.723</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.853</td>\n","      <td>0.806</td>\n","      <td>0.930</td>\n","      <td>0.863</td>\n","      <td>0.930</td>\n","      <td>0.776</td>\n","      <td>0.705</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.905</td>\n","      <td>0.918</td>\n","      <td>0.890</td>\n","      <td>0.904</td>\n","      <td>0.890</td>\n","      <td>0.921</td>\n","      <td>0.811</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.888</td>\n","      <td>0.850</td>\n","      <td>0.942</td>\n","      <td>0.893</td>\n","      <td>0.942</td>\n","      <td>0.833</td>\n","      <td>0.775</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.878</td>\n","      <td>0.845</td>\n","      <td>0.925</td>\n","      <td>0.883</td>\n","      <td>0.925</td>\n","      <td>0.831</td>\n","      <td>0.755</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.919</td>\n","      <td>0.921</td>\n","      <td>0.918</td>\n","      <td>0.919</td>\n","      <td>0.918</td>\n","      <td>0.921</td>\n","      <td>0.839</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.918</td>\n","      <td>0.913</td>\n","      <td>0.924</td>\n","      <td>0.918</td>\n","      <td>0.924</td>\n","      <td>0.912</td>\n","      <td>0.835</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a16b386-c79a-4487-8419-50de2ec1cec5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3a16b386-c79a-4487-8419-50de2ec1cec5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3a16b386-c79a-4487-8419-50de2ec1cec5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-71c2ecc1-f4c9-4d00-aca9-1332689e65d7\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-71c2ecc1-f4c9-4d00-aca9-1332689e65d7')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-71c2ecc1-f4c9-4d00-aca9-1332689e65d7 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.057690883987317226,\n        \"min\": 0.739,\n        \"max\": 0.919,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.853,\n          0.888,\n          0.77\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.068532022407325,\n        \"min\": 0.706,\n        \"max\": 0.921,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.806,\n          0.85,\n          0.776\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05063285212473929,\n        \"min\": 0.759,\n        \"max\": 0.942,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.93,\n          0.942,\n          0.759\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05261296237167994,\n        \"min\": 0.757,\n        \"max\": 0.919,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.863,\n          0.893,\n          0.767\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05063285212473929,\n        \"min\": 0.759,\n        \"max\": 0.942,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.93,\n          0.942,\n          0.759\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08765831935635632,\n        \"min\": 0.623,\n        \"max\": 0.921,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.831,\n          0.776,\n          0.781\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11526780412008666,\n        \"min\": 0.478,\n        \"max\": 0.839,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.705,\n          0.775,\n          0.539\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":9}],"source":["\n","metrics_df.round(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ncf_cMAQF6g4"},"outputs":[],"source":["metrics_df.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Frequency Domain/frequency_domain_CNN_LSTM.csv', index = False)"]},{"cell_type":"markdown","source":["#Draw CNN_LSTM"],"metadata":{"id":"VNy6-RxAKjH8"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import re\n","import os\n","\n","# Function to read CSV logs and extract accuracy and validation accuracy\n","def read_logs(log_dir, num_clients, local_epochs):\n","    dataframes = []\n","    for epoch in range(local_epochs):\n","        for client in range(num_clients):\n","            log_file = os.path.join(log_dir, f'training_log_epoch_{epoch}_client_{client}.csv')\n","            if os.path.exists(log_file):\n","                df = pd.read_csv(log_file, sep=';')\n","                df['epoch_number'] = epoch\n","                df['client_number'] = client\n","                dataframes.append(df)\n","            else:\n","                print(f\"Log file not found: {log_file}\")\n","\n","    return pd.concat(dataframes) if dataframes else pd.DataFrame()\n","\n","# Function to plot the training and validation accuracy\n","def plot_accuracy(all_metrics_df, unique_epochs, output_dir):\n","    # Set the Seaborn style\n","    sns.set(style=\"whitegrid\")\n","\n","    # Create subplots for each epoch\n","    fig, axes = plt.subplots(2, len(unique_epochs), figsize=(len(unique_epochs) * 3, 4.5), sharex=True)\n","\n","    # Set the color palette\n","    palette = sns.color_palette(\"Set1\", n_colors=all_metrics_df['client_number'].nunique())\n","\n","    # Store the lines and labels for the legend\n","    lines = []\n","    labels = []\n","\n","    # Iterate through each epoch and plot the training and validation accuracy\n","    for i, epoch in enumerate(unique_epochs):\n","        epoch_df = all_metrics_df[all_metrics_df['epoch_number'] == epoch]\n","        for j, client in enumerate(epoch_df['client_number'].unique()):\n","            client_df = epoch_df[epoch_df['client_number'] == client].dropna(subset=['accuracy', 'val_accuracy'])\n","            if not client_df.empty:\n","                line, = axes[0, i].plot(client_df.index, client_df['accuracy'], label=f'Client {client}', alpha=0.6, color=palette[j], linewidth=2.0)\n","                axes[1, i].plot(client_df.index, client_df['val_accuracy'], label=f'Client {client}', alpha=0.6, color=palette[j], linewidth=2.0)\n","\n","                if i == 0:\n","                    lines.append(line)\n","                    labels.append(f'Client {client}')\n","\n","        axes[0, i].set_title(f'Epoch {epoch}', fontsize=12, fontweight='bold')\n","        axes[0, i].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","        axes[1, i].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","        axes[1, i].set_xlabel('Steps', fontsize=10, fontweight='bold')\n","        axes[0, i].grid(True)\n","        axes[1, i].grid(True)\n","        axes[0, i].tick_params(axis='both', which='major', labelsize=10)\n","        axes[1, i].tick_params(axis='both', which='major', labelsize=10)\n","\n","    # Add a single legend for the entire figure\n","    fig.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, 1.0), ncol=len(labels), fontsize=10, frameon=True)\n","\n","    # Add row labels\n","    fig.text(0.04, 0.75, 'Training Accuracy', ha='center', va='center', rotation='vertical', fontsize=12, fontweight='bold')\n","    fig.text(0.04, 0.25, 'Validation Accuracy', ha='center', va='center', rotation='vertical', fontsize=12, fontweight='bold')\n","\n","    plt.tight_layout(rect=[0.05, 0, 1, 0.95])\n","    plt.subplots_adjust(hspace=0.2, top=0.88)  # Add some space between the rows and reduce space between the legend and plot\n","\n","    # Save the figure in high DPI PNG and PDF\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    fig.savefig(os.path.join(output_dir, 'accuracy_plot.png'), dpi=300, format='png')\n","    fig.savefig(os.path.join(output_dir, 'accuracy_plot.pdf'), dpi=300, format='pdf')\n","\n","    plt.show()\n","\n","# Directory where CSV logs are saved\n","log_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Total'\n","\n","# Output directory for saving plots\n","output_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Total/plots'\n","\n","# Number of clients and local epochs\n","num_clients = 3\n","local_epochs = 5\n","\n","# Read logs and generate the dataframe\n","all_metrics_df = read_logs(log_dir, num_clients, local_epochs)\n","\n","# Get unique epochs from the dataframe\n","unique_epochs = sorted(all_metrics_df['epoch_number'].unique())\n","\n","# Plot the accuracy\n","plot_accuracy(all_metrics_df, unique_epochs, output_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"e-S2thS6KnXT","executionInfo":{"status":"ok","timestamp":1716752271557,"user_tz":-360,"elapsed":5773,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"3941d26a-915f-4d07-fa63-4b562bbd151a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x450 with 10 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import re\n","import os\n","\n","# Function to read CSV logs and extract accuracy and validation accuracy\n","def read_logs(log_dir, num_clients, local_epochs):\n","    dataframes = []\n","    for epoch in range(local_epochs):\n","        for client in range(num_clients):\n","            log_file = os.path.join(log_dir, f'training_log_epoch_{epoch}_client_{client}.csv')\n","            if os.path.exists(log_file):\n","                df = pd.read_csv(log_file, sep=';')\n","                df['epoch_number'] = epoch\n","                df['client_number'] = client\n","                dataframes.append(df)\n","            else:\n","                print(f\"Log file not found: {log_file}\")\n","\n","    return pd.concat(dataframes) if dataframes else pd.DataFrame()\n","\n","# Function to plot the training and validation accuracy for the final epoch\n","def plot_final_epoch_accuracy(all_metrics_df, output_dir):\n","    # Set the Seaborn style\n","    sns.set(style=\"whitegrid\")\n","\n","    # Get the final epoch number\n","    final_epoch = all_metrics_df['epoch_number'].max()\n","\n","    # Filter the data for the final epoch\n","    final_epoch_df = all_metrics_df[all_metrics_df['epoch_number'] == final_epoch]\n","\n","    # Calculate the average training and validation accuracy for the final epoch\n","    avg_train_accuracy = final_epoch_df['accuracy'].mean()\n","    avg_val_accuracy = final_epoch_df['val_accuracy'].mean()\n","\n","    print(f\"Final Epoch: {final_epoch}\")\n","    print(f\"Average Training Accuracy: {avg_train_accuracy:.4f}\")\n","    print(f\"Average Validation Accuracy: {avg_val_accuracy:.4f}\")\n","\n","    # Create subplots for the final epoch\n","    fig, axes = plt.subplots(1, 2, figsize=(12, 4.5), sharex=True)\n","\n","    # Set the color palette\n","    palette = sns.color_palette(\"Set1\", n_colors=final_epoch_df['client_number'].nunique())\n","\n","    # Store the lines and labels for the legend\n","    lines = []\n","    labels = []\n","\n","    # Plot the training and validation accuracy for the final epoch\n","    for client in final_epoch_df['client_number'].unique():\n","        client_df = final_epoch_df[final_epoch_df['client_number'] == client].dropna(subset=['accuracy', 'val_accuracy'])\n","        if not client_df.empty:\n","            line, = axes[0].plot(client_df.index, client_df['accuracy'], label=f'Client {client}', alpha=0.6, color=palette[client], linewidth=2.0)\n","            axes[1].plot(client_df.index, client_df['val_accuracy'], label=f'Client {client}', alpha=0.6, color=palette[client], linewidth=2.0)\n","\n","            if len(lines) < final_epoch_df['client_number'].nunique():\n","                lines.append(line)\n","                labels.append(f'Client {client}')\n","\n","    axes[0].set_title(f'Training Accuracy (Epoch {final_epoch})', fontsize=12, fontweight='bold')\n","    axes[0].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","\n","    axes[1].set_title(f'Validation Accuracy (Epoch {final_epoch})', fontsize=12, fontweight='bold')\n","\n","\n","    for ax in axes:\n","        ax.set_xlabel('Steps', fontsize=10, fontweight='bold')\n","        ax.grid(True)\n","        ax.tick_params(axis='both', which='major', labelsize=10)\n","\n","    # Add a single legend for the entire figure\n","    fig.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, 1.05), ncol=len(labels), fontsize=10, frameon=True)\n","\n","    plt.tight_layout(rect=[0.05, 0.05, 1, 0.95])\n","    plt.subplots_adjust(hspace=0.2, top=0.85)  # Add some space between the rows and reduce space between the legend and plot\n","\n","    # Save the figure in high DPI PNG and PDF\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    fig.savefig(os.path.join(output_dir, 'final_epoch_accuracy_plot.png'), dpi=300, format='png')\n","    fig.savefig(os.path.join(output_dir, 'final_epoch_accuracy_plot.pdf'), dpi=300, format='pdf')\n","\n","    plt.show()\n","\n","# Directory where CSV logs are saved\n","log_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Total'\n","\n","# Output directory for saving plots\n","output_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Total/plots'\n","\n","# Number of clients and local epochs\n","num_clients = 3\n","local_epochs = 5\n","\n","# Read logs and generate the dataframe\n","all_metrics_df = read_logs(log_dir, num_clients, local_epochs)\n","\n","# Plot the accuracy for the final epoch\n","plot_final_epoch_accuracy(all_metrics_df, output_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NlC1cJDfRFjG","executionInfo":{"status":"ok","timestamp":1716752281801,"user_tz":-360,"elapsed":2941,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"b6781ded-06c4-4d66-98a9-0057144fec5f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Final Epoch: 4\n","Average Training Accuracy: 0.9972\n","Average Validation Accuracy: 0.9058\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x450 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"QUuWzfMHSNmi"},"source":["# CNN"]},{"cell_type":"code","source":["%%capture\n","!pip install tensorflow_addons"],"metadata":{"id":"hLngWbjM-HAu"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8xrx_fxBSWGd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717399244500,"user_tz":-360,"elapsed":483,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}},"outputId":"408386f1-c4b1-4c1e-e801-ffa0adb35e2d"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    # model.add(Dropout(0.5))\n","    # model.add(LSTM(256, return_sequences=True))\n","    # model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Total/CNN/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Total/CNN/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":797941,"status":"ok","timestamp":1717400048470,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"},"user_tz":-360},"id":"H1TaNdIbSfkq","outputId":"a5260cb6-b7b2-4003-a2c2-ed87f929bc46"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 12s 32ms/step - loss: 1.7497 - accuracy: 0.5994 - val_loss: 1.7661 - val_accuracy: 0.6918\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 1.7126 - accuracy: 0.7344"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 16ms/step - loss: 1.6939 - accuracy: 0.7128 - val_loss: 1.7536 - val_accuracy: 0.7478\n","Epoch 3/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.6361 - accuracy: 0.7379 - val_loss: 1.7387 - val_accuracy: 0.7597\n","Epoch 4/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.5866 - accuracy: 0.7481 - val_loss: 1.7225 - val_accuracy: 0.7597\n","Epoch 5/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.5585 - accuracy: 0.7487 - val_loss: 1.7063 - val_accuracy: 0.7597\n","Epoch 6/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5402 - accuracy: 0.7516 - val_loss: 1.6915 - val_accuracy: 0.7662\n","Epoch 7/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5250 - accuracy: 0.7575 - val_loss: 1.6772 - val_accuracy: 0.7694\n","Epoch 8/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.5114 - accuracy: 0.7597 - val_loss: 1.6625 - val_accuracy: 0.7694\n","Epoch 9/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.4977 - accuracy: 0.7645 - val_loss: 1.6470 - val_accuracy: 0.7726\n","Epoch 10/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.4860 - accuracy: 0.7683 - val_loss: 1.6298 - val_accuracy: 0.7823\n","Epoch 11/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.4717 - accuracy: 0.7729 - val_loss: 1.6136 - val_accuracy: 0.7812\n","Epoch 12/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.4621 - accuracy: 0.7756 - val_loss: 1.5939 - val_accuracy: 0.7834\n","Epoch 13/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4453 - accuracy: 0.7823 - val_loss: 1.5750 - val_accuracy: 0.7877\n","Epoch 14/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.4315 - accuracy: 0.7858 - val_loss: 1.5535 - val_accuracy: 0.7823\n","Epoch 15/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.4188 - accuracy: 0.7891 - val_loss: 1.5337 - val_accuracy: 0.7931\n","Epoch 16/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.4054 - accuracy: 0.7909 - val_loss: 1.5113 - val_accuracy: 0.7909\n","Epoch 17/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.3947 - accuracy: 0.7947 - val_loss: 1.4834 - val_accuracy: 0.7802\n","Epoch 18/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.3810 - accuracy: 0.7947 - val_loss: 1.4630 - val_accuracy: 0.7866\n","Epoch 19/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.3676 - accuracy: 0.8015 - val_loss: 1.4432 - val_accuracy: 0.7931\n","Epoch 20/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.3584 - accuracy: 0.8050 - val_loss: 1.4218 - val_accuracy: 0.7931\n","Epoch 21/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.3440 - accuracy: 0.8044 - val_loss: 1.4016 - val_accuracy: 0.7909\n","Epoch 22/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.3300 - accuracy: 0.8109 - val_loss: 1.3792 - val_accuracy: 0.7888\n","Epoch 23/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.3194 - accuracy: 0.8144 - val_loss: 1.3686 - val_accuracy: 0.8028\n","Epoch 24/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3061 - accuracy: 0.8184 - val_loss: 1.3513 - val_accuracy: 0.7974\n","Epoch 25/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.2949 - accuracy: 0.8203 - val_loss: 1.3362 - val_accuracy: 0.7974\n","Epoch 26/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.2829 - accuracy: 0.8254 - val_loss: 1.3241 - val_accuracy: 0.7974\n","Epoch 27/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.2723 - accuracy: 0.8265 - val_loss: 1.3142 - val_accuracy: 0.7942\n","Epoch 28/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2603 - accuracy: 0.8346 - val_loss: 1.3079 - val_accuracy: 0.8071\n","Epoch 29/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.2534 - accuracy: 0.8314 - val_loss: 1.3055 - val_accuracy: 0.8103\n","Epoch 30/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2413 - accuracy: 0.8327 - val_loss: 1.2904 - val_accuracy: 0.8125\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2273 - accuracy: 0.8411 - val_loss: 1.2806 - val_accuracy: 0.8006\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2178 - accuracy: 0.8427 - val_loss: 1.2727 - val_accuracy: 0.8114\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2064 - accuracy: 0.8475 - val_loss: 1.2654 - val_accuracy: 0.8093\n","Epoch 34/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1966 - accuracy: 0.8454 - val_loss: 1.2624 - val_accuracy: 0.8168\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1857 - accuracy: 0.8524 - val_loss: 1.2582 - val_accuracy: 0.7974\n","Epoch 36/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1782 - accuracy: 0.8524 - val_loss: 1.2459 - val_accuracy: 0.8050\n","Epoch 37/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1669 - accuracy: 0.8529 - val_loss: 1.2395 - val_accuracy: 0.8136\n","Epoch 38/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1573 - accuracy: 0.8583 - val_loss: 1.2335 - val_accuracy: 0.8179\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1450 - accuracy: 0.8615 - val_loss: 1.2264 - val_accuracy: 0.8168\n","Epoch 40/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1364 - accuracy: 0.8621 - val_loss: 1.2208 - val_accuracy: 0.8190\n","Epoch 41/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1253 - accuracy: 0.8650 - val_loss: 1.2155 - val_accuracy: 0.8168\n","Epoch 42/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1164 - accuracy: 0.8656 - val_loss: 1.2204 - val_accuracy: 0.8200\n","Epoch 43/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1077 - accuracy: 0.8715 - val_loss: 1.2038 - val_accuracy: 0.8211\n","Epoch 44/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0963 - accuracy: 0.8707 - val_loss: 1.1995 - val_accuracy: 0.8147\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0910 - accuracy: 0.8696 - val_loss: 1.1928 - val_accuracy: 0.8265\n","Epoch 46/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0787 - accuracy: 0.8777 - val_loss: 1.1880 - val_accuracy: 0.8211\n","Epoch 47/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0712 - accuracy: 0.8758 - val_loss: 1.1907 - val_accuracy: 0.8233\n","Epoch 48/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0595 - accuracy: 0.8836 - val_loss: 1.1783 - val_accuracy: 0.8265\n","Epoch 49/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0547 - accuracy: 0.8785 - val_loss: 1.1764 - val_accuracy: 0.8147\n","Epoch 50/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0417 - accuracy: 0.8860 - val_loss: 1.1714 - val_accuracy: 0.8125\n","Epoch 51/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0382 - accuracy: 0.8852 - val_loss: 1.1718 - val_accuracy: 0.8254\n","Epoch 52/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0234 - accuracy: 0.8917 - val_loss: 1.1608 - val_accuracy: 0.8179\n","Epoch 53/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0122 - accuracy: 0.8963 - val_loss: 1.1550 - val_accuracy: 0.8233\n","Epoch 54/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0032 - accuracy: 0.8982 - val_loss: 1.1503 - val_accuracy: 0.8244\n","Epoch 55/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9940 - accuracy: 0.8963 - val_loss: 1.1624 - val_accuracy: 0.8222\n","Epoch 56/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9864 - accuracy: 0.9003 - val_loss: 1.1424 - val_accuracy: 0.8319\n","Epoch 57/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9777 - accuracy: 0.9073 - val_loss: 1.1387 - val_accuracy: 0.8265\n","Epoch 58/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9690 - accuracy: 0.9038 - val_loss: 1.1383 - val_accuracy: 0.8276\n","Epoch 59/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9584 - accuracy: 0.9143 - val_loss: 1.1307 - val_accuracy: 0.8244\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9490 - accuracy: 0.9138 - val_loss: 1.1266 - val_accuracy: 0.8265\n","Epoch 61/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9412 - accuracy: 0.9151 - val_loss: 1.1271 - val_accuracy: 0.8157\n","Epoch 62/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9339 - accuracy: 0.9124 - val_loss: 1.1279 - val_accuracy: 0.8254\n","Epoch 63/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9251 - accuracy: 0.9216 - val_loss: 1.1181 - val_accuracy: 0.8190\n","Epoch 64/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9173 - accuracy: 0.9178 - val_loss: 1.1149 - val_accuracy: 0.8254\n","Epoch 65/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9069 - accuracy: 0.9227 - val_loss: 1.1101 - val_accuracy: 0.8265\n","Epoch 66/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8970 - accuracy: 0.9294 - val_loss: 1.1080 - val_accuracy: 0.8265\n","Epoch 67/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8902 - accuracy: 0.9286 - val_loss: 1.1054 - val_accuracy: 0.8233\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8802 - accuracy: 0.9340 - val_loss: 1.1031 - val_accuracy: 0.8297\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8707 - accuracy: 0.9356 - val_loss: 1.1044 - val_accuracy: 0.8200\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8663 - accuracy: 0.9335 - val_loss: 1.0989 - val_accuracy: 0.8190\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8642 - accuracy: 0.9324 - val_loss: 1.1054 - val_accuracy: 0.8093\n","Epoch 72/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8513 - accuracy: 0.9356 - val_loss: 1.0979 - val_accuracy: 0.8147\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8406 - accuracy: 0.9440 - val_loss: 1.1036 - val_accuracy: 0.8308\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8357 - accuracy: 0.9448 - val_loss: 1.0898 - val_accuracy: 0.8200\n","Epoch 75/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8236 - accuracy: 0.9496 - val_loss: 1.0859 - val_accuracy: 0.8276\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8188 - accuracy: 0.9477 - val_loss: 1.0839 - val_accuracy: 0.8265\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8174 - accuracy: 0.9423 - val_loss: 1.0816 - val_accuracy: 0.8200\n","Epoch 78/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8022 - accuracy: 0.9518 - val_loss: 1.0788 - val_accuracy: 0.8233\n","Epoch 79/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8022 - accuracy: 0.9453 - val_loss: 1.0941 - val_accuracy: 0.8125\n","Epoch 80/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7924 - accuracy: 0.9512 - val_loss: 1.0746 - val_accuracy: 0.8244\n","Epoch 81/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7803 - accuracy: 0.9577 - val_loss: 1.0799 - val_accuracy: 0.8222\n","Epoch 82/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7748 - accuracy: 0.9593 - val_loss: 1.0718 - val_accuracy: 0.8265\n","Epoch 83/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7702 - accuracy: 0.9569 - val_loss: 1.0777 - val_accuracy: 0.8168\n","Epoch 84/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7602 - accuracy: 0.9617 - val_loss: 1.0706 - val_accuracy: 0.8200\n","Epoch 85/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7541 - accuracy: 0.9612 - val_loss: 1.0731 - val_accuracy: 0.8200\n","Epoch 86/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7479 - accuracy: 0.9609 - val_loss: 1.0651 - val_accuracy: 0.8244\n","Epoch 87/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7438 - accuracy: 0.9607 - val_loss: 1.0638 - val_accuracy: 0.8287\n","Epoch 88/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7369 - accuracy: 0.9652 - val_loss: 1.0646 - val_accuracy: 0.8244\n","Epoch 89/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7283 - accuracy: 0.9666 - val_loss: 1.0641 - val_accuracy: 0.8233\n","Epoch 90/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7214 - accuracy: 0.9688 - val_loss: 1.0623 - val_accuracy: 0.8233\n","Epoch 91/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7141 - accuracy: 0.9714 - val_loss: 1.0617 - val_accuracy: 0.8233\n","Epoch 92/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7085 - accuracy: 0.9698 - val_loss: 1.0602 - val_accuracy: 0.8200\n","Epoch 93/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7026 - accuracy: 0.9709 - val_loss: 1.0618 - val_accuracy: 0.8233\n","Epoch 94/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6976 - accuracy: 0.9717 - val_loss: 1.0575 - val_accuracy: 0.8254\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6964 - accuracy: 0.9704 - val_loss: 1.0642 - val_accuracy: 0.8233\n","Epoch 96/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.9733 - val_loss: 1.0583 - val_accuracy: 0.8211\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6803 - accuracy: 0.9728 - val_loss: 1.0625 - val_accuracy: 0.8211\n","Epoch 98/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6747 - accuracy: 0.9755 - val_loss: 1.0583 - val_accuracy: 0.8190\n","Epoch 99/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6673 - accuracy: 0.9790 - val_loss: 1.0650 - val_accuracy: 0.8233\n","Epoch 100/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6637 - accuracy: 0.9782 - val_loss: 1.0730 - val_accuracy: 0.8254\n","{'loss': [1.7497249841690063, 1.6939425468444824, 1.636121153831482, 1.5865732431411743, 1.5585421323776245, 1.5402233600616455, 1.5250247716903687, 1.511388897895813, 1.4977493286132812, 1.485957145690918, 1.4716812372207642, 1.4621046781539917, 1.4453400373458862, 1.4314838647842407, 1.4187532663345337, 1.4053958654403687, 1.3946963548660278, 1.3810150623321533, 1.3676369190216064, 1.3584389686584473, 1.3440046310424805, 1.3300082683563232, 1.3194236755371094, 1.3061366081237793, 1.2949392795562744, 1.2828638553619385, 1.2723045349121094, 1.2602603435516357, 1.2533553838729858, 1.2412716150283813, 1.227300763130188, 1.2178431749343872, 1.206356406211853, 1.1965570449829102, 1.1856752634048462, 1.1782442331314087, 1.1668686866760254, 1.1572829484939575, 1.144992709159851, 1.136379361152649, 1.1253212690353394, 1.1163685321807861, 1.1077388525009155, 1.0963349342346191, 1.0909537076950073, 1.078729271888733, 1.0711625814437866, 1.0594854354858398, 1.0547369718551636, 1.0417439937591553, 1.0381815433502197, 1.023377537727356, 1.012192964553833, 1.0031554698944092, 0.9939954280853271, 0.9863953590393066, 0.9776621460914612, 0.968957245349884, 0.9584356546401978, 0.9489815831184387, 0.9411625266075134, 0.9338657855987549, 0.9251283407211304, 0.9173181056976318, 0.9069161415100098, 0.8970096111297607, 0.8901920914649963, 0.8802267909049988, 0.8707454800605774, 0.8662846684455872, 0.8641905188560486, 0.8512905836105347, 0.8405698537826538, 0.8357235193252563, 0.8236405849456787, 0.8187776803970337, 0.8173744082450867, 0.8022439479827881, 0.802176296710968, 0.7924370765686035, 0.7802518010139465, 0.7748430371284485, 0.7701535224914551, 0.76015704870224, 0.7540558576583862, 0.7479081749916077, 0.743830144405365, 0.7369004487991333, 0.7283085584640503, 0.7214359641075134, 0.7141146063804626, 0.7085056900978088, 0.7025595903396606, 0.6976285576820374, 0.6964434385299683, 0.6894439458847046, 0.6802791953086853, 0.6746789216995239, 0.6672608852386475, 0.6636961698532104], 'accuracy': [0.5994073152542114, 0.7128232717514038, 0.7378771305084229, 0.7481142282485962, 0.748652994632721, 0.751616358757019, 0.7575430870056152, 0.7596982717514038, 0.7645474076271057, 0.7683189511299133, 0.7728987336158752, 0.7755926847457886, 0.7823275923728943, 0.7858297228813171, 0.7890625, 0.7909482717514038, 0.7947198152542114, 0.7947198152542114, 0.8014547228813171, 0.8049569129943848, 0.8044180870056152, 0.810883641242981, 0.8143857717514038, 0.8184267282485962, 0.8203125, 0.8254310488700867, 0.826508641242981, 0.834590494632721, 0.8313577771186829, 0.8327047228813171, 0.8410560488700867, 0.8426724076271057, 0.8475215435028076, 0.845366358757019, 0.8523706793785095, 0.8523706793785095, 0.852909505367279, 0.8582974076271057, 0.8615301847457886, 0.8620689511299133, 0.8650323152542114, 0.865571141242981, 0.8714978694915771, 0.8706896305084229, 0.8696120977401733, 0.8776939511299133, 0.8758081793785095, 0.8836206793785095, 0.8785021305084229, 0.8860452771186829, 0.8852370977401733, 0.8917025923728943, 0.8962823152542114, 0.8981680870056152, 0.8962823152542114, 0.9003232717514038, 0.9073275923728943, 0.9038254022598267, 0.9143319129943848, 0.9137930870056152, 0.9151400923728943, 0.912446141242981, 0.9216055870056152, 0.9178340435028076, 0.9226831793785095, 0.9294180870056152, 0.9286099076271057, 0.9339978694915771, 0.9356142282485962, 0.9334590435028076, 0.9323814511299133, 0.9356142282485962, 0.943965494632721, 0.9447737336158752, 0.9496228694915771, 0.9477370977401733, 0.9423491358757019, 0.951777994632721, 0.9453125, 0.9512392282485962, 0.9577047228813171, 0.959321141242981, 0.9568965435028076, 0.9617456793785095, 0.9612069129943848, 0.9609375, 0.9606680870056152, 0.9652478694915771, 0.9665948152542114, 0.96875, 0.9714439511299133, 0.9698275923728943, 0.9709051847457886, 0.9717133641242981, 0.970366358757019, 0.9733297228813171, 0.9727909564971924, 0.9754849076271057, 0.9789870977401733, 0.978178858757019], 'val_loss': [1.7660653591156006, 1.7536197900772095, 1.7387349605560303, 1.7224668264389038, 1.706329584121704, 1.6914576292037964, 1.6771904230117798, 1.6625362634658813, 1.6470261812210083, 1.6297526359558105, 1.613623857498169, 1.5939322710037231, 1.57502281665802, 1.5534851551055908, 1.5337214469909668, 1.5113428831100464, 1.4833953380584717, 1.462984561920166, 1.4432135820388794, 1.4218016862869263, 1.401599407196045, 1.3792051076889038, 1.368610143661499, 1.3513054847717285, 1.3362312316894531, 1.3241431713104248, 1.3142082691192627, 1.3079432249069214, 1.3054524660110474, 1.2904316186904907, 1.280605435371399, 1.2727093696594238, 1.2653846740722656, 1.2624163627624512, 1.2581528425216675, 1.245881199836731, 1.2394814491271973, 1.233535647392273, 1.2264164686203003, 1.2207913398742676, 1.215499758720398, 1.2203543186187744, 1.2038384675979614, 1.199486494064331, 1.192834496498108, 1.187995195388794, 1.190685749053955, 1.1783331632614136, 1.1763542890548706, 1.1713922023773193, 1.1717740297317505, 1.1607656478881836, 1.1550302505493164, 1.1503361463546753, 1.1623777151107788, 1.1424471139907837, 1.1387263536453247, 1.1382653713226318, 1.1306551694869995, 1.1265922784805298, 1.1270607709884644, 1.1278630495071411, 1.1181001663208008, 1.1149024963378906, 1.1100897789001465, 1.1079638004302979, 1.105411171913147, 1.103122591972351, 1.104411244392395, 1.0988903045654297, 1.1054424047470093, 1.097902536392212, 1.1036429405212402, 1.0898451805114746, 1.0859485864639282, 1.083871603012085, 1.081605076789856, 1.0787676572799683, 1.0940806865692139, 1.0746430158615112, 1.0799052715301514, 1.0717926025390625, 1.0776816606521606, 1.070584774017334, 1.0730847120285034, 1.0651240348815918, 1.063828945159912, 1.0645729303359985, 1.0641100406646729, 1.062312364578247, 1.0616990327835083, 1.0601996183395386, 1.0618066787719727, 1.0575395822525024, 1.0641722679138184, 1.058301568031311, 1.0624842643737793, 1.058264136314392, 1.0650407075881958, 1.0730241537094116], 'val_accuracy': [0.6918103694915771, 0.7478448152542114, 0.7596982717514038, 0.7596982717514038, 0.7596982717514038, 0.7661637663841248, 0.7693965435028076, 0.7693965435028076, 0.7726293206214905, 0.7823275923728943, 0.78125, 0.7834051847457886, 0.787715494632721, 0.7823275923728943, 0.7931034564971924, 0.7909482717514038, 0.7801724076271057, 0.7866379022598267, 0.7931034564971924, 0.7931034564971924, 0.7909482717514038, 0.7887930870056152, 0.8028017282485962, 0.7974137663841248, 0.7974137663841248, 0.7974137663841248, 0.7941810488700867, 0.8071120977401733, 0.8103448152542114, 0.8125, 0.8006465435028076, 0.8114224076271057, 0.8092672228813171, 0.8168103694915771, 0.7974137663841248, 0.8049569129943848, 0.8135775923728943, 0.8178879022598267, 0.8168103694915771, 0.818965494632721, 0.8168103694915771, 0.8200430870056152, 0.8211206793785095, 0.8146551847457886, 0.826508641242981, 0.8211206793785095, 0.8232758641242981, 0.826508641242981, 0.8146551847457886, 0.8125, 0.8254310488700867, 0.8178879022598267, 0.8232758641242981, 0.8243534564971924, 0.8221982717514038, 0.8318965435028076, 0.826508641242981, 0.8275862336158752, 0.8243534564971924, 0.826508641242981, 0.8157327771186829, 0.8254310488700867, 0.818965494632721, 0.8254310488700867, 0.826508641242981, 0.826508641242981, 0.8232758641242981, 0.829741358757019, 0.8200430870056152, 0.818965494632721, 0.8092672228813171, 0.8146551847457886, 0.8308189511299133, 0.8200430870056152, 0.8275862336158752, 0.826508641242981, 0.8200430870056152, 0.8232758641242981, 0.8125, 0.8243534564971924, 0.8221982717514038, 0.826508641242981, 0.8168103694915771, 0.8200430870056152, 0.8200430870056152, 0.8243534564971924, 0.8286637663841248, 0.8243534564971924, 0.8232758641242981, 0.8232758641242981, 0.8232758641242981, 0.8200430870056152, 0.8232758641242981, 0.8254310488700867, 0.8232758641242981, 0.8211206793785095, 0.8211206793785095, 0.818965494632721, 0.8232758641242981, 0.8254310488700867]}\n","38/38 [==============================] - 0s 8ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 1.7557 - accuracy: 0.5806"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 7s 74ms/step - loss: 1.7557 - accuracy: 0.5806 - val_loss: 1.7668 - val_accuracy: 0.6414\n","Epoch 2/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.7077 - accuracy: 0.6876 - val_loss: 1.7555 - val_accuracy: 0.7081\n","Epoch 3/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6562 - accuracy: 0.7159 - val_loss: 1.7424 - val_accuracy: 0.6980\n","Epoch 4/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6126 - accuracy: 0.7244 - val_loss: 1.7285 - val_accuracy: 0.7070\n","Epoch 5/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.5862 - accuracy: 0.7298 - val_loss: 1.7141 - val_accuracy: 0.7104\n","Epoch 6/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5669 - accuracy: 0.7332 - val_loss: 1.7008 - val_accuracy: 0.7183\n","Epoch 7/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5530 - accuracy: 0.7368 - val_loss: 1.6877 - val_accuracy: 0.7240\n","Epoch 8/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.5412 - accuracy: 0.7366 - val_loss: 1.6749 - val_accuracy: 0.7330\n","Epoch 9/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5261 - accuracy: 0.7408 - val_loss: 1.6609 - val_accuracy: 0.7285\n","Epoch 10/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5129 - accuracy: 0.7467 - val_loss: 1.6464 - val_accuracy: 0.7262\n","Epoch 11/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5005 - accuracy: 0.7518 - val_loss: 1.6313 - val_accuracy: 0.7308\n","Epoch 12/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4873 - accuracy: 0.7555 - val_loss: 1.6150 - val_accuracy: 0.7353\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4733 - accuracy: 0.7592 - val_loss: 1.5988 - val_accuracy: 0.7421\n","Epoch 14/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4609 - accuracy: 0.7606 - val_loss: 1.5795 - val_accuracy: 0.7511\n","Epoch 15/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4486 - accuracy: 0.7697 - val_loss: 1.5637 - val_accuracy: 0.7545\n","Epoch 16/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4375 - accuracy: 0.7685 - val_loss: 1.5412 - val_accuracy: 0.7557\n","Epoch 17/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4229 - accuracy: 0.7736 - val_loss: 1.5204 - val_accuracy: 0.7590\n","Epoch 18/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4108 - accuracy: 0.7770 - val_loss: 1.5000 - val_accuracy: 0.7523\n","Epoch 19/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.3961 - accuracy: 0.7849 - val_loss: 1.4794 - val_accuracy: 0.7545\n","Epoch 20/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.3832 - accuracy: 0.7886 - val_loss: 1.4621 - val_accuracy: 0.7670\n","Epoch 21/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.3709 - accuracy: 0.7946 - val_loss: 1.4490 - val_accuracy: 0.7771\n","Epoch 22/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3633 - accuracy: 0.7957 - val_loss: 1.4223 - val_accuracy: 0.7636\n","Epoch 23/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3485 - accuracy: 0.8019 - val_loss: 1.4054 - val_accuracy: 0.7681\n","Epoch 24/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3384 - accuracy: 0.8014 - val_loss: 1.3926 - val_accuracy: 0.7715\n","Epoch 25/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3251 - accuracy: 0.8093 - val_loss: 1.3795 - val_accuracy: 0.7715\n","Epoch 26/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3145 - accuracy: 0.8115 - val_loss: 1.3687 - val_accuracy: 0.7749\n","Epoch 27/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.3042 - accuracy: 0.8130 - val_loss: 1.3593 - val_accuracy: 0.7817\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2933 - accuracy: 0.8183 - val_loss: 1.3478 - val_accuracy: 0.7783\n","Epoch 29/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2826 - accuracy: 0.8175 - val_loss: 1.3420 - val_accuracy: 0.7715\n","Epoch 30/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2713 - accuracy: 0.8212 - val_loss: 1.3321 - val_accuracy: 0.7817\n","Epoch 31/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2597 - accuracy: 0.8231 - val_loss: 1.3242 - val_accuracy: 0.7805\n","Epoch 32/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2506 - accuracy: 0.8246 - val_loss: 1.3183 - val_accuracy: 0.7896\n","Epoch 33/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2394 - accuracy: 0.8277 - val_loss: 1.3136 - val_accuracy: 0.7930\n","Epoch 34/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2286 - accuracy: 0.8311 - val_loss: 1.3042 - val_accuracy: 0.7794\n","Epoch 35/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2189 - accuracy: 0.8339 - val_loss: 1.2965 - val_accuracy: 0.7885\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2094 - accuracy: 0.8379 - val_loss: 1.2921 - val_accuracy: 0.7952\n","Epoch 37/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1991 - accuracy: 0.8401 - val_loss: 1.2840 - val_accuracy: 0.7952\n","Epoch 38/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1890 - accuracy: 0.8415 - val_loss: 1.2843 - val_accuracy: 0.7817\n","Epoch 39/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1791 - accuracy: 0.8410 - val_loss: 1.2732 - val_accuracy: 0.8054\n","Epoch 40/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1766 - accuracy: 0.8449 - val_loss: 1.2680 - val_accuracy: 0.7998\n","Epoch 41/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1611 - accuracy: 0.8514 - val_loss: 1.2612 - val_accuracy: 0.7862\n","Epoch 42/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1506 - accuracy: 0.8554 - val_loss: 1.2668 - val_accuracy: 0.7794\n","Epoch 43/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1460 - accuracy: 0.8489 - val_loss: 1.2567 - val_accuracy: 0.7862\n","Epoch 44/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1313 - accuracy: 0.8548 - val_loss: 1.2429 - val_accuracy: 0.7896\n","Epoch 45/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1208 - accuracy: 0.8611 - val_loss: 1.2392 - val_accuracy: 0.7885\n","Epoch 46/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1112 - accuracy: 0.8616 - val_loss: 1.2409 - val_accuracy: 0.7919\n","Epoch 47/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1056 - accuracy: 0.8602 - val_loss: 1.2349 - val_accuracy: 0.7907\n","Epoch 48/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0944 - accuracy: 0.8656 - val_loss: 1.2207 - val_accuracy: 0.7964\n","Epoch 49/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0828 - accuracy: 0.8735 - val_loss: 1.2182 - val_accuracy: 0.7952\n","Epoch 50/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0757 - accuracy: 0.8701 - val_loss: 1.2116 - val_accuracy: 0.7986\n","Epoch 51/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0659 - accuracy: 0.8763 - val_loss: 1.2133 - val_accuracy: 0.7952\n","Epoch 52/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0580 - accuracy: 0.8749 - val_loss: 1.2014 - val_accuracy: 0.7975\n","Epoch 53/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0479 - accuracy: 0.8812 - val_loss: 1.1976 - val_accuracy: 0.7998\n","Epoch 54/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0408 - accuracy: 0.8786 - val_loss: 1.1913 - val_accuracy: 0.8100\n","Epoch 55/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0316 - accuracy: 0.8860 - val_loss: 1.1872 - val_accuracy: 0.8066\n","Epoch 56/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0234 - accuracy: 0.8851 - val_loss: 1.1831 - val_accuracy: 0.8066\n","Epoch 57/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0117 - accuracy: 0.8913 - val_loss: 1.1810 - val_accuracy: 0.8100\n","Epoch 58/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0039 - accuracy: 0.8916 - val_loss: 1.1731 - val_accuracy: 0.8066\n","Epoch 59/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9937 - accuracy: 0.8973 - val_loss: 1.1700 - val_accuracy: 0.8054\n","Epoch 60/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9832 - accuracy: 0.9007 - val_loss: 1.1702 - val_accuracy: 0.8088\n","Epoch 61/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9774 - accuracy: 0.9018 - val_loss: 1.1742 - val_accuracy: 0.8133\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9671 - accuracy: 0.9032 - val_loss: 1.1626 - val_accuracy: 0.8100\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9623 - accuracy: 0.9021 - val_loss: 1.1666 - val_accuracy: 0.8122\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9489 - accuracy: 0.9128 - val_loss: 1.1503 - val_accuracy: 0.8054\n","Epoch 65/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9428 - accuracy: 0.9117 - val_loss: 1.1462 - val_accuracy: 0.8088\n","Epoch 66/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9326 - accuracy: 0.9177 - val_loss: 1.1447 - val_accuracy: 0.8077\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9230 - accuracy: 0.9182 - val_loss: 1.1395 - val_accuracy: 0.8032\n","Epoch 68/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9138 - accuracy: 0.9171 - val_loss: 1.1506 - val_accuracy: 0.8156\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9069 - accuracy: 0.9205 - val_loss: 1.1414 - val_accuracy: 0.8111\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9032 - accuracy: 0.9168 - val_loss: 1.1329 - val_accuracy: 0.8179\n","Epoch 71/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8894 - accuracy: 0.9261 - val_loss: 1.1261 - val_accuracy: 0.8077\n","Epoch 72/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8851 - accuracy: 0.9256 - val_loss: 1.1240 - val_accuracy: 0.8077\n","Epoch 73/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8734 - accuracy: 0.9307 - val_loss: 1.1209 - val_accuracy: 0.8077\n","Epoch 74/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8685 - accuracy: 0.9310 - val_loss: 1.1213 - val_accuracy: 0.8156\n","Epoch 75/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8577 - accuracy: 0.9363 - val_loss: 1.1221 - val_accuracy: 0.8201\n","Epoch 76/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8563 - accuracy: 0.9290 - val_loss: 1.1103 - val_accuracy: 0.8179\n","Epoch 77/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8450 - accuracy: 0.9344 - val_loss: 1.1067 - val_accuracy: 0.8145\n","Epoch 78/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8406 - accuracy: 0.9346 - val_loss: 1.1176 - val_accuracy: 0.8077\n","Epoch 79/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8357 - accuracy: 0.9380 - val_loss: 1.1065 - val_accuracy: 0.8167\n","Epoch 80/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8218 - accuracy: 0.9460 - val_loss: 1.0983 - val_accuracy: 0.8179\n","Epoch 81/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8097 - accuracy: 0.9530 - val_loss: 1.0980 - val_accuracy: 0.8122\n","Epoch 82/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8077 - accuracy: 0.9471 - val_loss: 1.0973 - val_accuracy: 0.8167\n","Epoch 83/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7973 - accuracy: 0.9510 - val_loss: 1.0954 - val_accuracy: 0.8156\n","Epoch 84/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7920 - accuracy: 0.9542 - val_loss: 1.0916 - val_accuracy: 0.8190\n","Epoch 85/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7829 - accuracy: 0.9513 - val_loss: 1.0876 - val_accuracy: 0.8190\n","Epoch 86/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7759 - accuracy: 0.9570 - val_loss: 1.0883 - val_accuracy: 0.8190\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7674 - accuracy: 0.9595 - val_loss: 1.0997 - val_accuracy: 0.8247\n","Epoch 88/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7657 - accuracy: 0.9564 - val_loss: 1.0881 - val_accuracy: 0.8190\n","Epoch 89/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7558 - accuracy: 0.9635 - val_loss: 1.0814 - val_accuracy: 0.8156\n","Epoch 90/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7516 - accuracy: 0.9598 - val_loss: 1.0864 - val_accuracy: 0.8213\n","Epoch 91/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7458 - accuracy: 0.9655 - val_loss: 1.0782 - val_accuracy: 0.8167\n","Epoch 92/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7425 - accuracy: 0.9621 - val_loss: 1.1013 - val_accuracy: 0.8213\n","Epoch 93/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7338 - accuracy: 0.9649 - val_loss: 1.0761 - val_accuracy: 0.8167\n","Epoch 94/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7224 - accuracy: 0.9711 - val_loss: 1.0724 - val_accuracy: 0.8133\n","Epoch 95/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7242 - accuracy: 0.9663 - val_loss: 1.0801 - val_accuracy: 0.8190\n","Epoch 96/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7151 - accuracy: 0.9700 - val_loss: 1.0724 - val_accuracy: 0.8156\n","Epoch 97/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7044 - accuracy: 0.9731 - val_loss: 1.0710 - val_accuracy: 0.8156\n","Epoch 98/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7006 - accuracy: 0.9745 - val_loss: 1.0857 - val_accuracy: 0.8269\n","Epoch 99/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7001 - accuracy: 0.9737 - val_loss: 1.0700 - val_accuracy: 0.8201\n","Epoch 100/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6886 - accuracy: 0.9785 - val_loss: 1.0666 - val_accuracy: 0.8167\n","{'loss': [1.7557135820388794, 1.707655906677246, 1.6562186479568481, 1.6126171350479126, 1.586188793182373, 1.5668963193893433, 1.5530271530151367, 1.5412123203277588, 1.5260897874832153, 1.5129104852676392, 1.5004894733428955, 1.4873231649398804, 1.4732722043991089, 1.4608566761016846, 1.4486485719680786, 1.4374687671661377, 1.4229485988616943, 1.410772442817688, 1.396092176437378, 1.3831690549850464, 1.3709498643875122, 1.3632689714431763, 1.3485114574432373, 1.3384069204330444, 1.3251357078552246, 1.3145002126693726, 1.304247260093689, 1.293252944946289, 1.2826108932495117, 1.2713366746902466, 1.2597044706344604, 1.2506201267242432, 1.239445447921753, 1.2286343574523926, 1.2188782691955566, 1.2093960046768188, 1.1991397142410278, 1.1890169382095337, 1.1790999174118042, 1.1766371726989746, 1.1611113548278809, 1.150558352470398, 1.1459558010101318, 1.13125479221344, 1.1207916736602783, 1.111231803894043, 1.105647087097168, 1.0944041013717651, 1.0827964544296265, 1.075701117515564, 1.0659420490264893, 1.0579818487167358, 1.0478894710540771, 1.0408298969268799, 1.0316201448440552, 1.0234215259552002, 1.0116660594940186, 1.003868818283081, 0.9937145113945007, 0.9831911325454712, 0.977412760257721, 0.9670975804328918, 0.9622650742530823, 0.9488981366157532, 0.9428066611289978, 0.9326279163360596, 0.9230397939682007, 0.9137922525405884, 0.9069449305534363, 0.903249979019165, 0.8893990516662598, 0.8850690126419067, 0.8734204769134521, 0.868467390537262, 0.8576617240905762, 0.8562986254692078, 0.8449702262878418, 0.8405703902244568, 0.8357207179069519, 0.821750283241272, 0.8096995949745178, 0.8077253699302673, 0.7972517609596252, 0.7919664978981018, 0.7829176783561707, 0.7759444713592529, 0.767419159412384, 0.7657408714294434, 0.7557863593101501, 0.751611590385437, 0.7457601428031921, 0.7424977421760559, 0.7338133454322815, 0.7224215865135193, 0.7242370843887329, 0.7150852680206299, 0.7044496536254883, 0.700639009475708, 0.7000664472579956, 0.6886256337165833], 'accuracy': [0.5806451439857483, 0.6876060962677002, 0.7159026861190796, 0.7243916392326355, 0.7297679781913757, 0.7331635355949402, 0.7368420958518982, 0.7365591526031494, 0.740803599357605, 0.7467458844184875, 0.751839280128479, 0.755517840385437, 0.759196400642395, 0.7606111764907837, 0.7696660757064819, 0.768534243106842, 0.7736276388168335, 0.777023196220398, 0.7849462628364563, 0.7886247634887695, 0.7945670485496521, 0.7956989407539368, 0.8019241690635681, 0.8013582229614258, 0.8092812895774841, 0.8115450143814087, 0.8129597902297974, 0.8183361887931824, 0.8174872398376465, 0.8211658000946045, 0.8231465816497803, 0.8245614171028137, 0.8276740312576294, 0.8310695886611938, 0.8338992595672607, 0.8378607630729675, 0.8401244878768921, 0.8415393233299255, 0.8409733772277832, 0.8449349403381348, 0.8514431118965149, 0.8554046154022217, 0.8488964438438416, 0.8548387289047241, 0.8610639572143555, 0.8616299033164978, 0.8602150678634644, 0.8655914068222046, 0.8735144138336182, 0.8701188564300537, 0.8763440847396851, 0.8749292492866516, 0.881154477596283, 0.8786078095436096, 0.8859649300575256, 0.8851160407066345, 0.8913412690162659, 0.8916242122650146, 0.8972835540771484, 0.9006791114807129, 0.9018110036849976, 0.9032257795333862, 0.9020939469337463, 0.9128466248512268, 0.9117147922515869, 0.9176570177078247, 0.918222963809967, 0.9170911312103271, 0.9204866886138916, 0.9168081283569336, 0.9261460304260254, 0.9255800843238831, 0.9306734800338745, 0.9309564232826233, 0.9363327622413635, 0.9289756417274475, 0.9343519806861877, 0.9346349835395813, 0.9380305409431458, 0.9459536075592041, 0.9530277252197266, 0.947085440158844, 0.9510469436645508, 0.9541596174240112, 0.9513299465179443, 0.9569892287254333, 0.9595359563827515, 0.9564233422279358, 0.9634974598884583, 0.9598188996315002, 0.965478241443634, 0.9620826244354248, 0.9649122953414917, 0.971137523651123, 0.9663271307945251, 0.9700056314468384, 0.9731183052062988, 0.9745330810546875, 0.9736841917037964, 0.9784946441650391], 'val_loss': [1.7667852640151978, 1.7554863691329956, 1.742393970489502, 1.7285408973693848, 1.7141252756118774, 1.7008202075958252, 1.6877415180206299, 1.6748842000961304, 1.6609467267990112, 1.6464370489120483, 1.6312910318374634, 1.6150140762329102, 1.5988103151321411, 1.5795321464538574, 1.5636889934539795, 1.5411746501922607, 1.5203708410263062, 1.5000264644622803, 1.4793928861618042, 1.4621068239212036, 1.4490368366241455, 1.422349452972412, 1.4054393768310547, 1.392625331878662, 1.3794949054718018, 1.3686633110046387, 1.3592849969863892, 1.3478081226348877, 1.3419585227966309, 1.3320753574371338, 1.3241735696792603, 1.318347692489624, 1.313550591468811, 1.3041796684265137, 1.296451210975647, 1.2921288013458252, 1.2840332984924316, 1.284277319908142, 1.2731506824493408, 1.2680087089538574, 1.2612395286560059, 1.2667961120605469, 1.2566554546356201, 1.2428829669952393, 1.2391724586486816, 1.240899920463562, 1.2349367141723633, 1.2206780910491943, 1.2182117700576782, 1.211582899093628, 1.2133193016052246, 1.201427936553955, 1.1975526809692383, 1.1913173198699951, 1.1872409582138062, 1.18306565284729, 1.1810272932052612, 1.1731436252593994, 1.169956922531128, 1.1701651811599731, 1.174167513847351, 1.162575602531433, 1.166568636894226, 1.1502934694290161, 1.146226167678833, 1.1447328329086304, 1.139541506767273, 1.1506314277648926, 1.1413511037826538, 1.1328964233398438, 1.1261221170425415, 1.1240088939666748, 1.120914340019226, 1.1212910413742065, 1.1220719814300537, 1.1103053092956543, 1.1066758632659912, 1.1176040172576904, 1.1064609289169312, 1.0982732772827148, 1.097960114479065, 1.097285509109497, 1.0954279899597168, 1.091592788696289, 1.0876294374465942, 1.0882710218429565, 1.099692463874817, 1.0880928039550781, 1.081396222114563, 1.0864108800888062, 1.0781623125076294, 1.1013153791427612, 1.076095700263977, 1.0724477767944336, 1.080065369606018, 1.0724374055862427, 1.0709683895111084, 1.0856602191925049, 1.069959282875061, 1.0665743350982666], 'val_accuracy': [0.6414027214050293, 0.7081447839736938, 0.6979637742042542, 0.7070135474205017, 0.7104072570800781, 0.7183257937431335, 0.7239819169044495, 0.733031690120697, 0.7285068035125732, 0.726244330406189, 0.7307692170143127, 0.7352941036224365, 0.7420814633369446, 0.7511312365531921, 0.7545248866081238, 0.7556561231613159, 0.7590497732162476, 0.7522624731063843, 0.7545248866081238, 0.766968309879303, 0.7771493196487427, 0.7635746598243713, 0.7680995464324951, 0.7714931964874268, 0.7714931964874268, 0.7748869061470032, 0.7816742062568665, 0.7782805562019348, 0.7714931964874268, 0.7816742062568665, 0.7805429697036743, 0.7895927429199219, 0.7929864525794983, 0.779411792755127, 0.7884615659713745, 0.7952488660812378, 0.7952488660812378, 0.7816742062568665, 0.8054298758506775, 0.7997737526893616, 0.7861990928649902, 0.779411792755127, 0.7861990928649902, 0.7895927429199219, 0.7884615659713745, 0.7918552160263062, 0.790723979473114, 0.7963801026344299, 0.7952488660812378, 0.7986425161361694, 0.7952488660812378, 0.7975113391876221, 0.7997737526893616, 0.8099547624588013, 0.8065611124038696, 0.8065611124038696, 0.8099547624588013, 0.8065611124038696, 0.8054298758506775, 0.8088235259056091, 0.8133484125137329, 0.8099547624588013, 0.8122171759605408, 0.8054298758506775, 0.8088235259056091, 0.807692289352417, 0.8031674027442932, 0.8156108856201172, 0.8110859990119934, 0.8178732991218567, 0.807692289352417, 0.807692289352417, 0.807692289352417, 0.8156108856201172, 0.820135772228241, 0.8178732991218567, 0.814479649066925, 0.807692289352417, 0.8167420625686646, 0.8178732991218567, 0.8122171759605408, 0.8167420625686646, 0.8156108856201172, 0.8190045356750488, 0.8190045356750488, 0.8190045356750488, 0.8246606588363647, 0.8190045356750488, 0.8156108856201172, 0.8212669491767883, 0.8167420625686646, 0.8212669491767883, 0.8167420625686646, 0.8133484125137329, 0.8190045356750488, 0.8156108856201172, 0.8156108856201172, 0.8269230723381042, 0.820135772228241, 0.8167420625686646]}\n","45/45 [==============================] - 0s 6ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 5s 45ms/step - loss: 1.7481 - accuracy: 0.6202 - val_loss: 1.7653 - val_accuracy: 0.6674\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 1.7136 - accuracy: 0.6719"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 1s 19ms/step - loss: 1.6914 - accuracy: 0.7070 - val_loss: 1.7521 - val_accuracy: 0.7314\n","Epoch 3/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.6345 - accuracy: 0.7253 - val_loss: 1.7372 - val_accuracy: 0.7397\n","Epoch 4/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5923 - accuracy: 0.7372 - val_loss: 1.7205 - val_accuracy: 0.7521\n","Epoch 5/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.5666 - accuracy: 0.7364 - val_loss: 1.7048 - val_accuracy: 0.7376\n","Epoch 6/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.5485 - accuracy: 0.7421 - val_loss: 1.6899 - val_accuracy: 0.7438\n","Epoch 7/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.5300 - accuracy: 0.7460 - val_loss: 1.6752 - val_accuracy: 0.7541\n","Epoch 8/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.5140 - accuracy: 0.7501 - val_loss: 1.6597 - val_accuracy: 0.7583\n","Epoch 9/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.4980 - accuracy: 0.7594 - val_loss: 1.6435 - val_accuracy: 0.7521\n","Epoch 10/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.4837 - accuracy: 0.7597 - val_loss: 1.6259 - val_accuracy: 0.7624\n","Epoch 11/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.4672 - accuracy: 0.7646 - val_loss: 1.6050 - val_accuracy: 0.7738\n","Epoch 12/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.4524 - accuracy: 0.7721 - val_loss: 1.5849 - val_accuracy: 0.7727\n","Epoch 13/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.4366 - accuracy: 0.7762 - val_loss: 1.5652 - val_accuracy: 0.7727\n","Epoch 14/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4245 - accuracy: 0.7811 - val_loss: 1.5394 - val_accuracy: 0.7800\n","Epoch 15/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.4072 - accuracy: 0.7904 - val_loss: 1.5190 - val_accuracy: 0.7769\n","Epoch 16/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.3950 - accuracy: 0.7959 - val_loss: 1.4958 - val_accuracy: 0.7779\n","Epoch 17/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.3798 - accuracy: 0.7982 - val_loss: 1.4700 - val_accuracy: 0.7800\n","Epoch 18/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3662 - accuracy: 0.8041 - val_loss: 1.4464 - val_accuracy: 0.7820\n","Epoch 19/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3533 - accuracy: 0.8065 - val_loss: 1.4243 - val_accuracy: 0.7779\n","Epoch 20/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.3461 - accuracy: 0.8052 - val_loss: 1.4049 - val_accuracy: 0.7831\n","Epoch 21/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.3294 - accuracy: 0.8114 - val_loss: 1.3908 - val_accuracy: 0.7893\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3162 - accuracy: 0.8186 - val_loss: 1.3706 - val_accuracy: 0.7882\n","Epoch 23/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3039 - accuracy: 0.8196 - val_loss: 1.3578 - val_accuracy: 0.7882\n","Epoch 24/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2914 - accuracy: 0.8274 - val_loss: 1.3464 - val_accuracy: 0.7913\n","Epoch 25/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2845 - accuracy: 0.8274 - val_loss: 1.3374 - val_accuracy: 0.7882\n","Epoch 26/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2783 - accuracy: 0.8276 - val_loss: 1.3232 - val_accuracy: 0.7924\n","Epoch 27/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.2609 - accuracy: 0.8307 - val_loss: 1.3168 - val_accuracy: 0.7965\n","Epoch 28/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2476 - accuracy: 0.8364 - val_loss: 1.3055 - val_accuracy: 0.7975\n","Epoch 29/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2373 - accuracy: 0.8377 - val_loss: 1.2975 - val_accuracy: 0.7975\n","Epoch 30/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2254 - accuracy: 0.8421 - val_loss: 1.2891 - val_accuracy: 0.7975\n","Epoch 31/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2168 - accuracy: 0.8408 - val_loss: 1.2862 - val_accuracy: 0.7986\n","Epoch 32/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.2089 - accuracy: 0.8452 - val_loss: 1.2751 - val_accuracy: 0.8068\n","Epoch 33/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1963 - accuracy: 0.8473 - val_loss: 1.2734 - val_accuracy: 0.7955\n","Epoch 34/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1847 - accuracy: 0.8499 - val_loss: 1.2616 - val_accuracy: 0.7996\n","Epoch 35/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.1735 - accuracy: 0.8509 - val_loss: 1.2538 - val_accuracy: 0.8099\n","Epoch 36/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1665 - accuracy: 0.8527 - val_loss: 1.2518 - val_accuracy: 0.8048\n","Epoch 37/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1561 - accuracy: 0.8550 - val_loss: 1.2420 - val_accuracy: 0.8017\n","Epoch 38/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1440 - accuracy: 0.8568 - val_loss: 1.2457 - val_accuracy: 0.8058\n","Epoch 39/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1407 - accuracy: 0.8574 - val_loss: 1.2284 - val_accuracy: 0.8120\n","Epoch 40/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1251 - accuracy: 0.8630 - val_loss: 1.2245 - val_accuracy: 0.8099\n","Epoch 41/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1189 - accuracy: 0.8630 - val_loss: 1.2248 - val_accuracy: 0.8110\n","Epoch 42/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1094 - accuracy: 0.8646 - val_loss: 1.2121 - val_accuracy: 0.8068\n","Epoch 43/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0983 - accuracy: 0.8693 - val_loss: 1.2042 - val_accuracy: 0.8140\n","Epoch 44/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0927 - accuracy: 0.8672 - val_loss: 1.2003 - val_accuracy: 0.8110\n","Epoch 45/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0787 - accuracy: 0.8711 - val_loss: 1.2014 - val_accuracy: 0.8099\n","Epoch 46/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0720 - accuracy: 0.8749 - val_loss: 1.1865 - val_accuracy: 0.8171\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0604 - accuracy: 0.8783 - val_loss: 1.1806 - val_accuracy: 0.8171\n","Epoch 48/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0515 - accuracy: 0.8755 - val_loss: 1.1796 - val_accuracy: 0.8130\n","Epoch 49/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0451 - accuracy: 0.8780 - val_loss: 1.1705 - val_accuracy: 0.8171\n","Epoch 50/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0315 - accuracy: 0.8817 - val_loss: 1.1688 - val_accuracy: 0.8151\n","Epoch 51/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0231 - accuracy: 0.8827 - val_loss: 1.1599 - val_accuracy: 0.8182\n","Epoch 52/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0143 - accuracy: 0.8912 - val_loss: 1.1547 - val_accuracy: 0.8171\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0045 - accuracy: 0.8912 - val_loss: 1.1496 - val_accuracy: 0.8161\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9951 - accuracy: 0.8910 - val_loss: 1.1446 - val_accuracy: 0.8202\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9858 - accuracy: 0.8935 - val_loss: 1.1420 - val_accuracy: 0.8213\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9802 - accuracy: 0.8969 - val_loss: 1.1365 - val_accuracy: 0.8213\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9788 - accuracy: 0.8902 - val_loss: 1.1434 - val_accuracy: 0.7996\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9618 - accuracy: 0.8984 - val_loss: 1.1275 - val_accuracy: 0.8151\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9532 - accuracy: 0.9021 - val_loss: 1.1240 - val_accuracy: 0.8182\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9466 - accuracy: 0.9021 - val_loss: 1.1238 - val_accuracy: 0.8202\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9398 - accuracy: 0.9047 - val_loss: 1.1253 - val_accuracy: 0.8068\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9278 - accuracy: 0.9080 - val_loss: 1.1189 - val_accuracy: 0.8037\n","Epoch 63/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9261 - accuracy: 0.9059 - val_loss: 1.1071 - val_accuracy: 0.8110\n","Epoch 64/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9138 - accuracy: 0.9098 - val_loss: 1.1026 - val_accuracy: 0.8099\n","Epoch 65/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9046 - accuracy: 0.9114 - val_loss: 1.0966 - val_accuracy: 0.8161\n","Epoch 66/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8952 - accuracy: 0.9160 - val_loss: 1.0973 - val_accuracy: 0.8140\n","Epoch 67/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8903 - accuracy: 0.9173 - val_loss: 1.0965 - val_accuracy: 0.8089\n","Epoch 68/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8846 - accuracy: 0.9173 - val_loss: 1.0879 - val_accuracy: 0.8151\n","Epoch 69/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8737 - accuracy: 0.9202 - val_loss: 1.0824 - val_accuracy: 0.8140\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8632 - accuracy: 0.9266 - val_loss: 1.0800 - val_accuracy: 0.8110\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8533 - accuracy: 0.9266 - val_loss: 1.0821 - val_accuracy: 0.8068\n","Epoch 72/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8522 - accuracy: 0.9258 - val_loss: 1.0836 - val_accuracy: 0.8079\n","Epoch 73/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8452 - accuracy: 0.9243 - val_loss: 1.0692 - val_accuracy: 0.8110\n","Epoch 74/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8348 - accuracy: 0.9313 - val_loss: 1.0847 - val_accuracy: 0.8006\n","Epoch 75/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8310 - accuracy: 0.9289 - val_loss: 1.0713 - val_accuracy: 0.8089\n","Epoch 76/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8298 - accuracy: 0.9276 - val_loss: 1.0681 - val_accuracy: 0.8099\n","Epoch 77/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8254 - accuracy: 0.9274 - val_loss: 1.0626 - val_accuracy: 0.8089\n","Epoch 78/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8057 - accuracy: 0.9351 - val_loss: 1.0545 - val_accuracy: 0.8089\n","Epoch 79/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7963 - accuracy: 0.9411 - val_loss: 1.0549 - val_accuracy: 0.8161\n","Epoch 80/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8146 - accuracy: 0.9220 - val_loss: 1.0583 - val_accuracy: 0.8089\n","Epoch 81/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7868 - accuracy: 0.9401 - val_loss: 1.0466 - val_accuracy: 0.8130\n","Epoch 82/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7777 - accuracy: 0.9429 - val_loss: 1.0478 - val_accuracy: 0.8151\n","Epoch 83/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7704 - accuracy: 0.9481 - val_loss: 1.0440 - val_accuracy: 0.8089\n","Epoch 84/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7658 - accuracy: 0.9465 - val_loss: 1.0398 - val_accuracy: 0.8171\n","Epoch 85/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7585 - accuracy: 0.9475 - val_loss: 1.0427 - val_accuracy: 0.8099\n","Epoch 86/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7542 - accuracy: 0.9514 - val_loss: 1.0346 - val_accuracy: 0.8171\n","Epoch 87/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7445 - accuracy: 0.9535 - val_loss: 1.0380 - val_accuracy: 0.8140\n","Epoch 88/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7369 - accuracy: 0.9550 - val_loss: 1.0385 - val_accuracy: 0.8048\n","Epoch 89/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7331 - accuracy: 0.9543 - val_loss: 1.0361 - val_accuracy: 0.8130\n","Epoch 90/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7289 - accuracy: 0.9517 - val_loss: 1.0316 - val_accuracy: 0.8058\n","Epoch 91/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7201 - accuracy: 0.9576 - val_loss: 1.0378 - val_accuracy: 0.8182\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7128 - accuracy: 0.9592 - val_loss: 1.0357 - val_accuracy: 0.8048\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7145 - accuracy: 0.9594 - val_loss: 1.0242 - val_accuracy: 0.8140\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7061 - accuracy: 0.9581 - val_loss: 1.0226 - val_accuracy: 0.8140\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6965 - accuracy: 0.9656 - val_loss: 1.0229 - val_accuracy: 0.8202\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6892 - accuracy: 0.9654 - val_loss: 1.0273 - val_accuracy: 0.8130\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6869 - accuracy: 0.9636 - val_loss: 1.0206 - val_accuracy: 0.8099\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6800 - accuracy: 0.9664 - val_loss: 1.0213 - val_accuracy: 0.8017\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6739 - accuracy: 0.9672 - val_loss: 1.0313 - val_accuracy: 0.8140\n","Epoch 100/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6739 - accuracy: 0.9623 - val_loss: 1.0161 - val_accuracy: 0.8089\n","{'loss': [1.7480745315551758, 1.691359281539917, 1.6344852447509766, 1.5923256874084473, 1.5665874481201172, 1.5484641790390015, 1.5300413370132446, 1.5139997005462646, 1.497973918914795, 1.4836804866790771, 1.4672049283981323, 1.4523591995239258, 1.4365894794464111, 1.4245082139968872, 1.4072457551956177, 1.395044207572937, 1.3798149824142456, 1.3661893606185913, 1.3532761335372925, 1.346082091331482, 1.3294296264648438, 1.3162226676940918, 1.3039189577102661, 1.2913507223129272, 1.2844865322113037, 1.2782641649246216, 1.2609410285949707, 1.2475813627243042, 1.237296223640442, 1.2254153490066528, 1.216768503189087, 1.208915114402771, 1.1963368654251099, 1.1846965551376343, 1.17353355884552, 1.1665196418762207, 1.1560529470443726, 1.1440439224243164, 1.1406937837600708, 1.1250988245010376, 1.118888020515442, 1.1093966960906982, 1.0982906818389893, 1.0926871299743652, 1.0787407159805298, 1.0720460414886475, 1.0604360103607178, 1.05152428150177, 1.0450962781906128, 1.0315083265304565, 1.0230927467346191, 1.0143051147460938, 1.0045427083969116, 0.9951260685920715, 0.9857513308525085, 0.9801941514015198, 0.9788487553596497, 0.9618139863014221, 0.9532405734062195, 0.9466437697410583, 0.9397920370101929, 0.9278115630149841, 0.9261321425437927, 0.9137676954269409, 0.9046475291252136, 0.8951646089553833, 0.8902695775032043, 0.8846064805984497, 0.8737326264381409, 0.8632297515869141, 0.8532589077949524, 0.8522170186042786, 0.8451986312866211, 0.834760308265686, 0.8310009837150574, 0.8297726511955261, 0.8254393935203552, 0.805687427520752, 0.7963024973869324, 0.8146370053291321, 0.7868196368217468, 0.7777427434921265, 0.7704348564147949, 0.7657720446586609, 0.7585161924362183, 0.7542160749435425, 0.7444892525672913, 0.7369449734687805, 0.7331457138061523, 0.7289454340934753, 0.7201295495033264, 0.7128087282180786, 0.7145494818687439, 0.706057608127594, 0.6964916586875916, 0.689244270324707, 0.686942458152771, 0.6800357699394226, 0.6738814115524292, 0.6739020347595215], 'accuracy': [0.6201550364494324, 0.7069767713546753, 0.7253230214118958, 0.7372093200683594, 0.7364341020584106, 0.7421188354492188, 0.7459948062896729, 0.750129222869873, 0.7594315409660339, 0.7596899271011353, 0.7645995020866394, 0.7720929980278015, 0.7762274146080017, 0.7811369299888611, 0.790439248085022, 0.7958656549453735, 0.7981911897659302, 0.8041343688964844, 0.8064599633216858, 0.8051679730415344, 0.8113695383071899, 0.8186046481132507, 0.8196382522583008, 0.827390193939209, 0.827390193939209, 0.8276485800743103, 0.8307493329048157, 0.8364341259002686, 0.8377261161804199, 0.8421188592910767, 0.8408268690109253, 0.845219612121582, 0.8472868204116821, 0.8498708009719849, 0.8509044051170349, 0.8527131676673889, 0.8550387620925903, 0.8568475246429443, 0.8573643565177917, 0.8630490899085999, 0.8630490899085999, 0.8645994663238525, 0.8692506551742554, 0.8671834468841553, 0.8710594177246094, 0.8749353885650635, 0.8782945871353149, 0.8754522204399109, 0.8780362010002136, 0.8816537261009216, 0.8826873302459717, 0.8912144899368286, 0.8912144899368286, 0.8909560441970825, 0.8935400247573853, 0.8968992233276367, 0.8901808857917786, 0.8984495997428894, 0.9020671844482422, 0.9020671844482422, 0.9046511650085449, 0.9080103635787964, 0.9059431552886963, 0.9098191261291504, 0.9113695025444031, 0.9160206913948059, 0.9173126816749573, 0.9173126816749573, 0.9201550483703613, 0.9266149997711182, 0.9266149997711182, 0.9258397817611694, 0.9242894053459167, 0.9312661290168762, 0.9289405941963196, 0.9276486039161682, 0.9273901581764221, 0.9351420998573303, 0.9410852789878845, 0.9219638109207153, 0.9400516748428345, 0.9428940415382385, 0.948062002658844, 0.9465116262435913, 0.9475452303886414, 0.9514212012290955, 0.9534883499145508, 0.9550387859344482, 0.9542635679244995, 0.9516795873641968, 0.957622766494751, 0.9591731429100037, 0.959431529045105, 0.9581395387649536, 0.9656330943107605, 0.9653746485710144, 0.9635658860206604, 0.9664082527160645, 0.9671834707260132, 0.962273895740509], 'val_loss': [1.765312910079956, 1.7521318197250366, 1.7372448444366455, 1.7205328941345215, 1.7048324346542358, 1.6899453401565552, 1.6752142906188965, 1.6596620082855225, 1.6434673070907593, 1.6258689165115356, 1.6049983501434326, 1.5848678350448608, 1.5652004480361938, 1.5394316911697388, 1.5189839601516724, 1.4958455562591553, 1.4699615240097046, 1.4463725090026855, 1.4242839813232422, 1.4048529863357544, 1.3908343315124512, 1.3706469535827637, 1.357823133468628, 1.3463921546936035, 1.3374300003051758, 1.323158860206604, 1.316799521446228, 1.3055241107940674, 1.2974900007247925, 1.2891167402267456, 1.286218285560608, 1.275133728981018, 1.2733603715896606, 1.2615634202957153, 1.253825306892395, 1.2517999410629272, 1.2419935464859009, 1.2456940412521362, 1.2284398078918457, 1.2245286703109741, 1.2248224020004272, 1.2121332883834839, 1.204179286956787, 1.2002729177474976, 1.2013893127441406, 1.1865205764770508, 1.180609941482544, 1.1795990467071533, 1.1705198287963867, 1.168782353401184, 1.1599183082580566, 1.1547387838363647, 1.1496117115020752, 1.144622802734375, 1.1420221328735352, 1.1364734172821045, 1.1434459686279297, 1.1274704933166504, 1.1240308284759521, 1.1238367557525635, 1.1253094673156738, 1.1189121007919312, 1.1070810556411743, 1.102644443511963, 1.0965898036956787, 1.0972648859024048, 1.0964882373809814, 1.0878854990005493, 1.0823966264724731, 1.0800162553787231, 1.0821245908737183, 1.0835843086242676, 1.069221019744873, 1.084742546081543, 1.0712833404541016, 1.06814444065094, 1.0625807046890259, 1.05451500415802, 1.0549088716506958, 1.0582610368728638, 1.0466252565383911, 1.047790288925171, 1.0440030097961426, 1.0397820472717285, 1.0426541566848755, 1.0345555543899536, 1.0379916429519653, 1.0384976863861084, 1.036064624786377, 1.0315513610839844, 1.0378131866455078, 1.0356862545013428, 1.0242186784744263, 1.0225532054901123, 1.0229331254959106, 1.0273020267486572, 1.0205968618392944, 1.0212939977645874, 1.0312503576278687, 1.0161420106887817], 'val_accuracy': [0.6673553586006165, 0.7314049601554871, 0.7396694421768188, 0.7520661354064941, 0.7376033067703247, 0.7438016533851624, 0.7541322112083435, 0.7582644820213318, 0.7520661354064941, 0.7623966932296753, 0.7737603187561035, 0.7727272510528564, 0.7727272510528564, 0.7799586653709412, 0.7768595218658447, 0.7778925895690918, 0.7799586653709412, 0.7820248007774353, 0.7778925895690918, 0.7830578684806824, 0.78925621509552, 0.788223147392273, 0.788223147392273, 0.7913222908973694, 0.788223147392273, 0.7923553586006165, 0.7964876294136047, 0.797520637512207, 0.797520637512207, 0.797520637512207, 0.7985537052154541, 0.8068181872367859, 0.7954545617103577, 0.7995867729187012, 0.8099173307418823, 0.8047520518302917, 0.8016529083251953, 0.8057851195335388, 0.8119834661483765, 0.8099173307418823, 0.8109503984451294, 0.8068181872367859, 0.8140496015548706, 0.8109503984451294, 0.8099173307418823, 0.817148745059967, 0.817148745059967, 0.8130165338516235, 0.817148745059967, 0.8150826692581177, 0.8181818127632141, 0.817148745059967, 0.81611567735672, 0.8202479481697083, 0.8212810158729553, 0.8212810158729553, 0.7995867729187012, 0.8150826692581177, 0.8181818127632141, 0.8202479481697083, 0.8068181872367859, 0.8037189841270447, 0.8109503984451294, 0.8099173307418823, 0.81611567735672, 0.8140496015548706, 0.80888432264328, 0.8150826692581177, 0.8140496015548706, 0.8109503984451294, 0.8068181872367859, 0.807851254940033, 0.8109503984451294, 0.8006198406219482, 0.80888432264328, 0.8099173307418823, 0.80888432264328, 0.80888432264328, 0.81611567735672, 0.80888432264328, 0.8130165338516235, 0.8150826692581177, 0.80888432264328, 0.817148745059967, 0.8099173307418823, 0.817148745059967, 0.8140496015548706, 0.8047520518302917, 0.8130165338516235, 0.8057851195335388, 0.8181818127632141, 0.8047520518302917, 0.8140496015548706, 0.8140496015548706, 0.8202479481697083, 0.8130165338516235, 0.8099173307418823, 0.8016529083251953, 0.8140496015548706, 0.80888432264328]}\n","32/32 [==============================] - 0s 8ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 27ms/step - loss: 0.7817 - accuracy: 0.9133 - val_loss: 1.2432 - val_accuracy: 0.4871\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.7730 - accuracy: 0.9062"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 15ms/step - loss: 0.7595 - accuracy: 0.9305 - val_loss: 1.2314 - val_accuracy: 0.4914\n","Epoch 3/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7476 - accuracy: 0.9340 - val_loss: 1.2168 - val_accuracy: 0.5065\n","Epoch 4/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7382 - accuracy: 0.9351 - val_loss: 1.2103 - val_accuracy: 0.5032\n","Epoch 5/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.7266 - accuracy: 0.9461 - val_loss: 1.1955 - val_accuracy: 0.5216\n","Epoch 6/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7172 - accuracy: 0.9464 - val_loss: 1.1694 - val_accuracy: 0.5700\n","Epoch 7/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7096 - accuracy: 0.9480 - val_loss: 1.1427 - val_accuracy: 0.6595\n","Epoch 8/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7057 - accuracy: 0.9485 - val_loss: 1.1193 - val_accuracy: 0.7144\n","Epoch 9/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6990 - accuracy: 0.9494 - val_loss: 1.1113 - val_accuracy: 0.6821\n","Epoch 10/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6901 - accuracy: 0.9553 - val_loss: 1.0791 - val_accuracy: 0.7500\n","Epoch 11/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6785 - accuracy: 0.9585 - val_loss: 1.0436 - val_accuracy: 0.8168\n","Epoch 12/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6758 - accuracy: 0.9572 - val_loss: 1.0438 - val_accuracy: 0.7457\n","Epoch 13/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6672 - accuracy: 0.9634 - val_loss: 1.0139 - val_accuracy: 0.7920\n","Epoch 14/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6616 - accuracy: 0.9599 - val_loss: 0.9618 - val_accuracy: 0.8534\n","Epoch 15/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6540 - accuracy: 0.9617 - val_loss: 0.9379 - val_accuracy: 0.8556\n","Epoch 16/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6445 - accuracy: 0.9679 - val_loss: 0.9145 - val_accuracy: 0.8556\n","Epoch 17/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6422 - accuracy: 0.9663 - val_loss: 0.9223 - val_accuracy: 0.8341\n","Epoch 18/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6338 - accuracy: 0.9709 - val_loss: 0.8593 - val_accuracy: 0.8772\n","Epoch 19/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6291 - accuracy: 0.9690 - val_loss: 0.8392 - val_accuracy: 0.8772\n","Epoch 20/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6239 - accuracy: 0.9723 - val_loss: 0.8393 - val_accuracy: 0.8718\n","Epoch 21/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6177 - accuracy: 0.9744 - val_loss: 0.8170 - val_accuracy: 0.8772\n","Epoch 22/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6132 - accuracy: 0.9744 - val_loss: 0.8288 - val_accuracy: 0.8739\n","Epoch 23/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6080 - accuracy: 0.9728 - val_loss: 0.8249 - val_accuracy: 0.8631\n","Epoch 24/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6052 - accuracy: 0.9736 - val_loss: 0.8405 - val_accuracy: 0.8588\n","Epoch 25/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6004 - accuracy: 0.9784 - val_loss: 0.8058 - val_accuracy: 0.8739\n","Epoch 26/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5945 - accuracy: 0.9758 - val_loss: 0.8068 - val_accuracy: 0.8739\n","Epoch 27/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5867 - accuracy: 0.9801 - val_loss: 0.8229 - val_accuracy: 0.8728\n","Epoch 28/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5828 - accuracy: 0.9809 - val_loss: 0.8103 - val_accuracy: 0.8750\n","Epoch 29/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5764 - accuracy: 0.9838 - val_loss: 0.8084 - val_accuracy: 0.8782\n","Epoch 30/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5717 - accuracy: 0.9825 - val_loss: 0.8411 - val_accuracy: 0.8621\n","Epoch 31/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5674 - accuracy: 0.9849 - val_loss: 0.8021 - val_accuracy: 0.8739\n","Epoch 32/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5630 - accuracy: 0.9849 - val_loss: 0.8348 - val_accuracy: 0.8642\n","Epoch 33/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5602 - accuracy: 0.9846 - val_loss: 0.8067 - val_accuracy: 0.8772\n","Epoch 34/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5541 - accuracy: 0.9871 - val_loss: 0.8030 - val_accuracy: 0.8815\n","Epoch 35/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5484 - accuracy: 0.9860 - val_loss: 0.8029 - val_accuracy: 0.8750\n","Epoch 36/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5454 - accuracy: 0.9890 - val_loss: 0.8019 - val_accuracy: 0.8793\n","Epoch 37/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5427 - accuracy: 0.9884 - val_loss: 0.8324 - val_accuracy: 0.8696\n","Epoch 38/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5379 - accuracy: 0.9911 - val_loss: 0.8059 - val_accuracy: 0.8761\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5328 - accuracy: 0.9916 - val_loss: 0.8039 - val_accuracy: 0.8772\n","Epoch 40/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5302 - accuracy: 0.9916 - val_loss: 0.8048 - val_accuracy: 0.8793\n","Epoch 41/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5253 - accuracy: 0.9919 - val_loss: 0.8126 - val_accuracy: 0.8739\n","Epoch 42/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5224 - accuracy: 0.9919 - val_loss: 0.8098 - val_accuracy: 0.8739\n","Epoch 43/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5202 - accuracy: 0.9903 - val_loss: 0.8139 - val_accuracy: 0.8750\n","Epoch 44/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5128 - accuracy: 0.9941 - val_loss: 0.8014 - val_accuracy: 0.8793\n","Epoch 45/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5112 - accuracy: 0.9925 - val_loss: 0.8073 - val_accuracy: 0.8761\n","Epoch 46/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5075 - accuracy: 0.9933 - val_loss: 0.8045 - val_accuracy: 0.8761\n","Epoch 47/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5070 - accuracy: 0.9927 - val_loss: 0.8101 - val_accuracy: 0.8728\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4993 - accuracy: 0.9952 - val_loss: 0.8036 - val_accuracy: 0.8761\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4976 - accuracy: 0.9949 - val_loss: 0.8047 - val_accuracy: 0.8772\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4938 - accuracy: 0.9949 - val_loss: 0.8045 - val_accuracy: 0.8772\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4911 - accuracy: 0.9960 - val_loss: 0.8046 - val_accuracy: 0.8728\n","Epoch 52/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4906 - accuracy: 0.9949 - val_loss: 0.8028 - val_accuracy: 0.8793\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4864 - accuracy: 0.9954 - val_loss: 0.8052 - val_accuracy: 0.8815\n","Epoch 54/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4826 - accuracy: 0.9952 - val_loss: 0.8051 - val_accuracy: 0.8718\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4804 - accuracy: 0.9954 - val_loss: 0.8017 - val_accuracy: 0.8750\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4765 - accuracy: 0.9968 - val_loss: 0.8124 - val_accuracy: 0.8718\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4742 - accuracy: 0.9960 - val_loss: 0.8083 - val_accuracy: 0.8772\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4708 - accuracy: 0.9970 - val_loss: 0.8104 - val_accuracy: 0.8782\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4683 - accuracy: 0.9970 - val_loss: 0.8029 - val_accuracy: 0.8761\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4655 - accuracy: 0.9970 - val_loss: 0.8037 - val_accuracy: 0.8739\n","Epoch 61/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4623 - accuracy: 0.9976 - val_loss: 0.8060 - val_accuracy: 0.8772\n","Epoch 62/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4609 - accuracy: 0.9968 - val_loss: 0.8059 - val_accuracy: 0.8728\n","Epoch 63/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4579 - accuracy: 0.9978 - val_loss: 0.8025 - val_accuracy: 0.8739\n","Epoch 64/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4553 - accuracy: 0.9981 - val_loss: 0.8082 - val_accuracy: 0.8804\n","Epoch 65/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4532 - accuracy: 0.9976 - val_loss: 0.8048 - val_accuracy: 0.8793\n","Epoch 66/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4531 - accuracy: 0.9970 - val_loss: 0.8124 - val_accuracy: 0.8739\n","Epoch 67/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4521 - accuracy: 0.9968 - val_loss: 0.8091 - val_accuracy: 0.8782\n","Epoch 68/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4518 - accuracy: 0.9962 - val_loss: 0.8090 - val_accuracy: 0.8772\n","Epoch 69/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4461 - accuracy: 0.9970 - val_loss: 0.8048 - val_accuracy: 0.8804\n","Epoch 70/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4417 - accuracy: 0.9981 - val_loss: 0.8067 - val_accuracy: 0.8793\n","Epoch 71/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4394 - accuracy: 0.9970 - val_loss: 0.8060 - val_accuracy: 0.8761\n","Epoch 72/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4370 - accuracy: 0.9981 - val_loss: 0.8176 - val_accuracy: 0.8761\n","Epoch 73/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4390 - accuracy: 0.9976 - val_loss: 0.8062 - val_accuracy: 0.8750\n","Epoch 74/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4331 - accuracy: 0.9978 - val_loss: 0.8133 - val_accuracy: 0.8685\n","Epoch 75/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4314 - accuracy: 0.9978 - val_loss: 0.8131 - val_accuracy: 0.8739\n","Epoch 76/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4291 - accuracy: 0.9981 - val_loss: 0.8156 - val_accuracy: 0.8728\n","Epoch 77/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4266 - accuracy: 0.9981 - val_loss: 0.8070 - val_accuracy: 0.8707\n","Epoch 78/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4235 - accuracy: 0.9981 - val_loss: 0.8052 - val_accuracy: 0.8718\n","Epoch 79/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4227 - accuracy: 0.9984 - val_loss: 0.8193 - val_accuracy: 0.8675\n","Epoch 80/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4212 - accuracy: 0.9981 - val_loss: 0.8287 - val_accuracy: 0.8664\n","Epoch 81/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4186 - accuracy: 0.9981 - val_loss: 0.8112 - val_accuracy: 0.8707\n","Epoch 82/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4189 - accuracy: 0.9973 - val_loss: 0.8061 - val_accuracy: 0.8739\n","Epoch 83/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4160 - accuracy: 0.9978 - val_loss: 0.8090 - val_accuracy: 0.8793\n","Epoch 84/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4125 - accuracy: 0.9989 - val_loss: 0.8078 - val_accuracy: 0.8728\n","Epoch 85/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4106 - accuracy: 0.9984 - val_loss: 0.8085 - val_accuracy: 0.8793\n","Epoch 86/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4089 - accuracy: 0.9978 - val_loss: 0.8085 - val_accuracy: 0.8739\n","Epoch 87/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4054 - accuracy: 0.9989 - val_loss: 0.8105 - val_accuracy: 0.8804\n","Epoch 88/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4050 - accuracy: 0.9987 - val_loss: 0.8187 - val_accuracy: 0.8739\n","Epoch 89/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4022 - accuracy: 0.9987 - val_loss: 0.8098 - val_accuracy: 0.8739\n","Epoch 90/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4011 - accuracy: 0.9989 - val_loss: 0.8148 - val_accuracy: 0.8739\n","Epoch 91/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3990 - accuracy: 0.9989 - val_loss: 0.8147 - val_accuracy: 0.8782\n","Epoch 92/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3976 - accuracy: 0.9989 - val_loss: 0.8113 - val_accuracy: 0.8804\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3953 - accuracy: 0.9989 - val_loss: 0.8244 - val_accuracy: 0.8664\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3938 - accuracy: 0.9989 - val_loss: 0.8346 - val_accuracy: 0.8653\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3931 - accuracy: 0.9992 - val_loss: 0.8204 - val_accuracy: 0.8739\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3905 - accuracy: 0.9992 - val_loss: 0.8217 - val_accuracy: 0.8707\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3884 - accuracy: 0.9992 - val_loss: 0.8183 - val_accuracy: 0.8696\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3872 - accuracy: 0.9992 - val_loss: 0.8154 - val_accuracy: 0.8750\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3885 - accuracy: 0.9984 - val_loss: 0.8184 - val_accuracy: 0.8728\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3853 - accuracy: 0.9984 - val_loss: 0.8363 - val_accuracy: 0.8631\n","{'loss': [0.7817376852035522, 0.7594563961029053, 0.7476317882537842, 0.7381805181503296, 0.7266109585762024, 0.7171645164489746, 0.7096346020698547, 0.705704391002655, 0.6990459561347961, 0.6900571584701538, 0.678516149520874, 0.6757781505584717, 0.6671542525291443, 0.6616351008415222, 0.6540085077285767, 0.6444997191429138, 0.6421700119972229, 0.6337600350379944, 0.6291439533233643, 0.6239439845085144, 0.617670476436615, 0.6132049560546875, 0.6080414056777954, 0.605209469795227, 0.6003839373588562, 0.5945144891738892, 0.5867381691932678, 0.5828233957290649, 0.5764278769493103, 0.5717337131500244, 0.567355215549469, 0.562957763671875, 0.5602287650108337, 0.5540589094161987, 0.548358678817749, 0.5454062223434448, 0.5427004098892212, 0.5378558039665222, 0.5327852964401245, 0.5302033424377441, 0.525276780128479, 0.5224031805992126, 0.5202339887619019, 0.5127604603767395, 0.511193573474884, 0.5074959397315979, 0.5070095658302307, 0.49934083223342896, 0.49761804938316345, 0.4938300549983978, 0.49113890528678894, 0.4905624985694885, 0.48636114597320557, 0.482557088136673, 0.4803730845451355, 0.4765486419200897, 0.47417932748794556, 0.4708043336868286, 0.4682754874229431, 0.465526819229126, 0.46227097511291504, 0.4608653485774994, 0.4579073190689087, 0.45526349544525146, 0.4532487988471985, 0.45307913422584534, 0.452134370803833, 0.45176103711128235, 0.4461483359336853, 0.44165918231010437, 0.4393777549266815, 0.43698468804359436, 0.4389796853065491, 0.4331040680408478, 0.4313732981681824, 0.4291217625141144, 0.42661234736442566, 0.4235038161277771, 0.42268961668014526, 0.4211786091327667, 0.4186117351055145, 0.418885737657547, 0.4159509837627411, 0.4124651551246643, 0.410569965839386, 0.4088645875453949, 0.405380517244339, 0.4050397276878357, 0.4022355377674103, 0.40107911825180054, 0.39903533458709717, 0.3975779116153717, 0.3953017294406891, 0.3938288986682892, 0.3930688202381134, 0.39048218727111816, 0.38843977451324463, 0.38722312450408936, 0.3885490596294403, 0.3852597177028656], 'accuracy': [0.9132543206214905, 0.9304956793785095, 0.9339978694915771, 0.9350754022598267, 0.9461206793785095, 0.9463900923728943, 0.9480064511299133, 0.9485452771186829, 0.9493534564971924, 0.9552801847457886, 0.9585129022598267, 0.9571659564971924, 0.9633620977401733, 0.9598599076271057, 0.9617456793785095, 0.9679418206214905, 0.9663254022598267, 0.9709051847457886, 0.9690194129943848, 0.9722521305084229, 0.9744073152542114, 0.9744073152542114, 0.9727909564971924, 0.9735991358757019, 0.9784482717514038, 0.9757543206214905, 0.9800646305084229, 0.9808728694915771, 0.9838362336158752, 0.9824892282485962, 0.9849137663841248, 0.9849137663841248, 0.9846444129943848, 0.9870689511299133, 0.985991358757019, 0.9889547228813171, 0.9884159564971924, 0.9911099076271057, 0.9916487336158752, 0.9916487336158752, 0.9919180870056152, 0.9919180870056152, 0.9903017282485962, 0.9940732717514038, 0.9924569129943848, 0.9932650923728943, 0.9927262663841248, 0.9951508641242981, 0.9948814511299133, 0.9948814511299133, 0.9959590435028076, 0.9948814511299133, 0.9954202771186829, 0.9951508641242981, 0.9954202771186829, 0.9967672228813171, 0.9959590435028076, 0.9970366358757019, 0.9970366358757019, 0.9970366358757019, 0.9975754022598267, 0.9967672228813171, 0.9978448152542114, 0.9981142282485962, 0.9975754022598267, 0.9970366358757019, 0.9967672228813171, 0.9962284564971924, 0.9970366358757019, 0.9981142282485962, 0.9970366358757019, 0.9981142282485962, 0.9975754022598267, 0.9978448152542114, 0.9978448152542114, 0.9981142282485962, 0.9981142282485962, 0.9981142282485962, 0.998383641242981, 0.9981142282485962, 0.9981142282485962, 0.9973060488700867, 0.9978448152542114, 0.9989224076271057, 0.998383641242981, 0.9978448152542114, 0.9989224076271057, 0.998652994632721, 0.998652994632721, 0.9989224076271057, 0.9989224076271057, 0.9989224076271057, 0.9989224076271057, 0.9989224076271057, 0.9991918206214905, 0.9991918206214905, 0.9991918206214905, 0.9991918206214905, 0.998383641242981, 0.998383641242981], 'val_loss': [1.2432000637054443, 1.2313860654830933, 1.216793179512024, 1.2103495597839355, 1.1954505443572998, 1.1693847179412842, 1.1426981687545776, 1.1193279027938843, 1.1113135814666748, 1.0791423320770264, 1.0435712337493896, 1.043811559677124, 1.0139214992523193, 0.961784839630127, 0.9378939270973206, 0.9145376086235046, 0.9223020076751709, 0.8592702746391296, 0.8391736149787903, 0.8392521142959595, 0.8170267343521118, 0.8288194537162781, 0.8248586058616638, 0.8404729962348938, 0.8057522177696228, 0.806791365146637, 0.8228774666786194, 0.8103210926055908, 0.8083850145339966, 0.8411034345626831, 0.8021270036697388, 0.8348318338394165, 0.8067472577095032, 0.8030413389205933, 0.8029047846794128, 0.8018693327903748, 0.8323965668678284, 0.8058674335479736, 0.8038918972015381, 0.8047928810119629, 0.8125860691070557, 0.8097589612007141, 0.8138792514801025, 0.8014339804649353, 0.8073495626449585, 0.8045324683189392, 0.8100985884666443, 0.8036338090896606, 0.8046919107437134, 0.8045202493667603, 0.8045863509178162, 0.8028209209442139, 0.80521160364151, 0.805124819278717, 0.8016931414604187, 0.812357485294342, 0.8083293437957764, 0.8104304075241089, 0.8029412627220154, 0.8037026524543762, 0.8059912919998169, 0.805939793586731, 0.8025011420249939, 0.8082202672958374, 0.8047508597373962, 0.812404990196228, 0.8091416954994202, 0.8089525103569031, 0.804804265499115, 0.8067398071289062, 0.8060451745986938, 0.8176484107971191, 0.8062126636505127, 0.8132849335670471, 0.8130660653114319, 0.815583348274231, 0.8070160150527954, 0.8051654696464539, 0.8193332552909851, 0.8286836743354797, 0.8111535906791687, 0.8060773611068726, 0.8090366721153259, 0.8078036308288574, 0.8084892630577087, 0.8085079193115234, 0.8105056285858154, 0.8187173008918762, 0.8097711205482483, 0.8148385882377625, 0.8146684765815735, 0.8112727999687195, 0.824370265007019, 0.8345789313316345, 0.8203595876693726, 0.821662187576294, 0.8182525038719177, 0.8153650760650635, 0.8183842301368713, 0.8362958431243896], 'val_accuracy': [0.48706895112991333, 0.4913793206214905, 0.506465494632721, 0.5032327771186829, 0.5215517282485962, 0.5700430870056152, 0.6594827771186829, 0.7144396305084229, 0.6821120977401733, 0.75, 0.8168103694915771, 0.7456896305084229, 0.7920258641242981, 0.8534482717514038, 0.8556034564971924, 0.8556034564971924, 0.8340517282485962, 0.8771551847457886, 0.8771551847457886, 0.8717672228813171, 0.8771551847457886, 0.8739224076271057, 0.8631465435028076, 0.8588362336158752, 0.8739224076271057, 0.8739224076271057, 0.8728448152542114, 0.875, 0.8782327771186829, 0.8620689511299133, 0.8739224076271057, 0.8642241358757019, 0.8771551847457886, 0.881465494632721, 0.875, 0.8793103694915771, 0.8696120977401733, 0.8760775923728943, 0.8771551847457886, 0.8793103694915771, 0.8739224076271057, 0.8739224076271057, 0.875, 0.8793103694915771, 0.8760775923728943, 0.8760775923728943, 0.8728448152542114, 0.8760775923728943, 0.8771551847457886, 0.8771551847457886, 0.8728448152542114, 0.8793103694915771, 0.881465494632721, 0.8717672228813171, 0.875, 0.8717672228813171, 0.8771551847457886, 0.8782327771186829, 0.8760775923728943, 0.8739224076271057, 0.8771551847457886, 0.8728448152542114, 0.8739224076271057, 0.8803879022598267, 0.8793103694915771, 0.8739224076271057, 0.8782327771186829, 0.8771551847457886, 0.8803879022598267, 0.8793103694915771, 0.8760775923728943, 0.8760775923728943, 0.875, 0.868534505367279, 0.8739224076271057, 0.8728448152542114, 0.8706896305084229, 0.8717672228813171, 0.8674569129943848, 0.8663793206214905, 0.8706896305084229, 0.8739224076271057, 0.8793103694915771, 0.8728448152542114, 0.8793103694915771, 0.8739224076271057, 0.8803879022598267, 0.8739224076271057, 0.8739224076271057, 0.8739224076271057, 0.8782327771186829, 0.8803879022598267, 0.8663793206214905, 0.8653017282485962, 0.8739224076271057, 0.8706896305084229, 0.8696120977401733, 0.875, 0.8728448152542114, 0.8631465435028076]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 27ms/step - loss: 0.8009 - accuracy: 0.9061 - val_loss: 1.2405 - val_accuracy: 0.4966\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.8097 - accuracy: 0.8828"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 17ms/step - loss: 0.7790 - accuracy: 0.9162 - val_loss: 1.2266 - val_accuracy: 0.5034\n","Epoch 3/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7680 - accuracy: 0.9196 - val_loss: 1.2180 - val_accuracy: 0.5079\n","Epoch 4/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7575 - accuracy: 0.9267 - val_loss: 1.1997 - val_accuracy: 0.5385\n","Epoch 5/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7459 - accuracy: 0.9363 - val_loss: 1.1954 - val_accuracy: 0.5283\n","Epoch 6/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7393 - accuracy: 0.9366 - val_loss: 1.1702 - val_accuracy: 0.6041\n","Epoch 7/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7284 - accuracy: 0.9394 - val_loss: 1.1527 - val_accuracy: 0.6391\n","Epoch 8/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7216 - accuracy: 0.9434 - val_loss: 1.1317 - val_accuracy: 0.6821\n","Epoch 9/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.7116 - accuracy: 0.9462 - val_loss: 1.1132 - val_accuracy: 0.7104\n","Epoch 10/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7037 - accuracy: 0.9513 - val_loss: 1.0870 - val_accuracy: 0.7579\n","Epoch 11/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.6969 - accuracy: 0.9519 - val_loss: 1.0610 - val_accuracy: 0.7896\n","Epoch 12/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6889 - accuracy: 0.9576 - val_loss: 1.0331 - val_accuracy: 0.8156\n","Epoch 13/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6834 - accuracy: 0.9542 - val_loss: 0.9996 - val_accuracy: 0.8518\n","Epoch 14/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6780 - accuracy: 0.9587 - val_loss: 0.9829 - val_accuracy: 0.8450\n","Epoch 15/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6725 - accuracy: 0.9570 - val_loss: 0.9595 - val_accuracy: 0.8439\n","Epoch 16/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6661 - accuracy: 0.9590 - val_loss: 0.9318 - val_accuracy: 0.8518\n","Epoch 17/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6562 - accuracy: 0.9638 - val_loss: 0.9012 - val_accuracy: 0.8665\n","Epoch 18/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6501 - accuracy: 0.9663 - val_loss: 0.8830 - val_accuracy: 0.8597\n","Epoch 19/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6481 - accuracy: 0.9663 - val_loss: 0.8628 - val_accuracy: 0.8756\n","Epoch 20/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6504 - accuracy: 0.9564 - val_loss: 0.8699 - val_accuracy: 0.8428\n","Epoch 21/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6366 - accuracy: 0.9658 - val_loss: 0.8382 - val_accuracy: 0.8620\n","Epoch 22/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6268 - accuracy: 0.9717 - val_loss: 0.8249 - val_accuracy: 0.8722\n","Epoch 23/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6256 - accuracy: 0.9683 - val_loss: 0.8182 - val_accuracy: 0.8733\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6190 - accuracy: 0.9723 - val_loss: 0.8150 - val_accuracy: 0.8767\n","Epoch 25/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6130 - accuracy: 0.9731 - val_loss: 0.8132 - val_accuracy: 0.8778\n","Epoch 26/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6090 - accuracy: 0.9745 - val_loss: 0.8101 - val_accuracy: 0.8733\n","Epoch 27/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6029 - accuracy: 0.9751 - val_loss: 0.8165 - val_accuracy: 0.8790\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5954 - accuracy: 0.9813 - val_loss: 0.8157 - val_accuracy: 0.8767\n","Epoch 29/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5903 - accuracy: 0.9813 - val_loss: 0.8102 - val_accuracy: 0.8767\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5877 - accuracy: 0.9793 - val_loss: 0.8266 - val_accuracy: 0.8733\n","Epoch 31/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5835 - accuracy: 0.9822 - val_loss: 0.8077 - val_accuracy: 0.8744\n","Epoch 32/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5753 - accuracy: 0.9859 - val_loss: 0.8125 - val_accuracy: 0.8778\n","Epoch 33/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5716 - accuracy: 0.9847 - val_loss: 0.8170 - val_accuracy: 0.8756\n","Epoch 34/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5679 - accuracy: 0.9853 - val_loss: 0.8221 - val_accuracy: 0.8756\n","Epoch 35/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5627 - accuracy: 0.9870 - val_loss: 0.8097 - val_accuracy: 0.8733\n","Epoch 36/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5612 - accuracy: 0.9873 - val_loss: 0.8132 - val_accuracy: 0.8609\n","Epoch 37/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5547 - accuracy: 0.9873 - val_loss: 0.8142 - val_accuracy: 0.8756\n","Epoch 38/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5503 - accuracy: 0.9870 - val_loss: 0.8095 - val_accuracy: 0.8654\n","Epoch 39/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5457 - accuracy: 0.9898 - val_loss: 0.8099 - val_accuracy: 0.8756\n","Epoch 40/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5433 - accuracy: 0.9890 - val_loss: 0.8105 - val_accuracy: 0.8756\n","Epoch 41/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5403 - accuracy: 0.9881 - val_loss: 0.8433 - val_accuracy: 0.8778\n","Epoch 42/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5339 - accuracy: 0.9904 - val_loss: 0.8084 - val_accuracy: 0.8620\n","Epoch 43/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5296 - accuracy: 0.9918 - val_loss: 0.8065 - val_accuracy: 0.8676\n","Epoch 44/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5252 - accuracy: 0.9924 - val_loss: 0.8069 - val_accuracy: 0.8631\n","Epoch 45/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5257 - accuracy: 0.9892 - val_loss: 0.8058 - val_accuracy: 0.8699\n","Epoch 46/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5185 - accuracy: 0.9941 - val_loss: 0.8070 - val_accuracy: 0.8665\n","Epoch 47/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5161 - accuracy: 0.9929 - val_loss: 0.8071 - val_accuracy: 0.8688\n","Epoch 48/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5118 - accuracy: 0.9943 - val_loss: 0.8076 - val_accuracy: 0.8710\n","Epoch 49/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5079 - accuracy: 0.9935 - val_loss: 0.8086 - val_accuracy: 0.8676\n","Epoch 50/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5044 - accuracy: 0.9949 - val_loss: 0.8170 - val_accuracy: 0.8767\n","Epoch 51/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5035 - accuracy: 0.9943 - val_loss: 0.8155 - val_accuracy: 0.8767\n","Epoch 52/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4990 - accuracy: 0.9943 - val_loss: 0.8142 - val_accuracy: 0.8710\n","Epoch 53/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4969 - accuracy: 0.9946 - val_loss: 0.8152 - val_accuracy: 0.8733\n","Epoch 54/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4916 - accuracy: 0.9952 - val_loss: 0.8235 - val_accuracy: 0.8756\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4876 - accuracy: 0.9966 - val_loss: 0.8079 - val_accuracy: 0.8665\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4852 - accuracy: 0.9958 - val_loss: 0.8089 - val_accuracy: 0.8676\n","Epoch 57/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4833 - accuracy: 0.9955 - val_loss: 0.8222 - val_accuracy: 0.8710\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4794 - accuracy: 0.9972 - val_loss: 0.8174 - val_accuracy: 0.8699\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4767 - accuracy: 0.9977 - val_loss: 0.8137 - val_accuracy: 0.8654\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4751 - accuracy: 0.9972 - val_loss: 0.8181 - val_accuracy: 0.8710\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4723 - accuracy: 0.9972 - val_loss: 0.8262 - val_accuracy: 0.8722\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4689 - accuracy: 0.9980 - val_loss: 0.8087 - val_accuracy: 0.8654\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4674 - accuracy: 0.9977 - val_loss: 0.8126 - val_accuracy: 0.8586\n","Epoch 64/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4645 - accuracy: 0.9966 - val_loss: 0.8369 - val_accuracy: 0.8710\n","Epoch 65/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4630 - accuracy: 0.9977 - val_loss: 0.8304 - val_accuracy: 0.8744\n","Epoch 66/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4581 - accuracy: 0.9977 - val_loss: 0.8137 - val_accuracy: 0.8688\n","Epoch 67/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4564 - accuracy: 0.9977 - val_loss: 0.8165 - val_accuracy: 0.8710\n","Epoch 68/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4554 - accuracy: 0.9983 - val_loss: 0.8199 - val_accuracy: 0.8699\n","Epoch 69/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4508 - accuracy: 0.9983 - val_loss: 0.8273 - val_accuracy: 0.8733\n","Epoch 70/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4495 - accuracy: 0.9980 - val_loss: 0.8128 - val_accuracy: 0.8609\n","Epoch 71/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4466 - accuracy: 0.9983 - val_loss: 0.8498 - val_accuracy: 0.8699\n","Epoch 72/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4471 - accuracy: 0.9983 - val_loss: 0.8237 - val_accuracy: 0.8688\n","Epoch 73/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4433 - accuracy: 0.9980 - val_loss: 0.8151 - val_accuracy: 0.8631\n","Epoch 74/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4402 - accuracy: 0.9989 - val_loss: 0.8378 - val_accuracy: 0.8744\n","Epoch 75/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4380 - accuracy: 0.9989 - val_loss: 0.8198 - val_accuracy: 0.8710\n","Epoch 76/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4368 - accuracy: 0.9989 - val_loss: 0.8254 - val_accuracy: 0.8699\n","Epoch 77/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4335 - accuracy: 0.9989 - val_loss: 0.8192 - val_accuracy: 0.8620\n","Epoch 78/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4338 - accuracy: 0.9983 - val_loss: 0.8213 - val_accuracy: 0.8688\n","Epoch 79/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4304 - accuracy: 0.9989 - val_loss: 0.8337 - val_accuracy: 0.8688\n","Epoch 80/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4277 - accuracy: 0.9989 - val_loss: 0.8147 - val_accuracy: 0.8620\n","Epoch 81/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4255 - accuracy: 0.9989 - val_loss: 0.8313 - val_accuracy: 0.8699\n","Epoch 82/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4241 - accuracy: 0.9986 - val_loss: 0.8253 - val_accuracy: 0.8710\n","Epoch 83/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4216 - accuracy: 0.9989 - val_loss: 0.8367 - val_accuracy: 0.8722\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4192 - accuracy: 0.9994 - val_loss: 0.8238 - val_accuracy: 0.8688\n","Epoch 85/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4170 - accuracy: 0.9992 - val_loss: 0.8474 - val_accuracy: 0.8744\n","Epoch 86/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4154 - accuracy: 0.9997 - val_loss: 0.8477 - val_accuracy: 0.8722\n","Epoch 87/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4141 - accuracy: 0.9992 - val_loss: 0.8364 - val_accuracy: 0.8699\n","Epoch 88/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4130 - accuracy: 0.9992 - val_loss: 0.8360 - val_accuracy: 0.8484\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4122 - accuracy: 0.9992 - val_loss: 0.8356 - val_accuracy: 0.8699\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4069 - accuracy: 0.9997 - val_loss: 0.8327 - val_accuracy: 0.8676\n","Epoch 91/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4054 - accuracy: 0.9994 - val_loss: 0.8438 - val_accuracy: 0.8710\n","Epoch 92/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4044 - accuracy: 0.9997 - val_loss: 0.8385 - val_accuracy: 0.8699\n","Epoch 93/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4032 - accuracy: 0.9997 - val_loss: 0.8334 - val_accuracy: 0.8688\n","Epoch 94/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4001 - accuracy: 0.9994 - val_loss: 0.8275 - val_accuracy: 0.8710\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3985 - accuracy: 0.9997 - val_loss: 0.8500 - val_accuracy: 0.8699\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3970 - accuracy: 0.9997 - val_loss: 0.8342 - val_accuracy: 0.8699\n","Epoch 97/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3954 - accuracy: 0.9997 - val_loss: 0.8246 - val_accuracy: 0.8609\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3937 - accuracy: 0.9997 - val_loss: 0.8308 - val_accuracy: 0.8710\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3919 - accuracy: 0.9997 - val_loss: 0.8354 - val_accuracy: 0.8699\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3903 - accuracy: 0.9997 - val_loss: 0.8296 - val_accuracy: 0.8654\n","{'loss': [0.8009400963783264, 0.778998851776123, 0.7679892182350159, 0.7574653029441833, 0.7458829283714294, 0.7392581701278687, 0.7283883690834045, 0.7215855121612549, 0.711576521396637, 0.7037497758865356, 0.6969493627548218, 0.6889038681983948, 0.6833681464195251, 0.6779511570930481, 0.6725008487701416, 0.6661273241043091, 0.6561748385429382, 0.650112509727478, 0.6481090784072876, 0.6503581404685974, 0.6365506649017334, 0.6268137097358704, 0.6256290078163147, 0.6189850568771362, 0.6130141019821167, 0.6090002059936523, 0.602896511554718, 0.5954164862632751, 0.590321958065033, 0.5876913070678711, 0.583547830581665, 0.5752866268157959, 0.5716240406036377, 0.5678855776786804, 0.5627138018608093, 0.5612108111381531, 0.5547139048576355, 0.5502753853797913, 0.5456863641738892, 0.5433189272880554, 0.540256142616272, 0.5338526368141174, 0.5295534133911133, 0.5251898169517517, 0.5257319211959839, 0.5185278654098511, 0.516063928604126, 0.5117788910865784, 0.5079254508018494, 0.5043625831604004, 0.5034979581832886, 0.4989633560180664, 0.49690350890159607, 0.491630494594574, 0.48760825395584106, 0.4851759672164917, 0.48326200246810913, 0.4793511927127838, 0.4767124652862549, 0.4750504493713379, 0.4722703993320465, 0.468904584646225, 0.46735379099845886, 0.46448665857315063, 0.46297529339790344, 0.458054780960083, 0.456418514251709, 0.4553505480289459, 0.4508098065853119, 0.44947463274002075, 0.44664624333381653, 0.4471406638622284, 0.44325295090675354, 0.44024935364723206, 0.43800148367881775, 0.436769038438797, 0.43347328901290894, 0.433795303106308, 0.43041282892227173, 0.42770445346832275, 0.4255281686782837, 0.4241240918636322, 0.4215950667858124, 0.41922369599342346, 0.4170289635658264, 0.4153928756713867, 0.41406649351119995, 0.4130449593067169, 0.4122089147567749, 0.40694165229797363, 0.4054473340511322, 0.40442341566085815, 0.4032144844532013, 0.4000546336174011, 0.39848172664642334, 0.39703255891799927, 0.395440012216568, 0.39373067021369934, 0.39193129539489746, 0.3903484046459198], 'accuracy': [0.9060554504394531, 0.916242241859436, 0.9196377992630005, 0.926711916923523, 0.9363327622413635, 0.9366157054901123, 0.9394453763961792, 0.943406879901886, 0.9462365508079529, 0.9513299465179443, 0.9518958926200867, 0.9575551748275757, 0.9541596174240112, 0.9586870670318604, 0.9569892287254333, 0.9589700102806091, 0.963780403137207, 0.9663271307945251, 0.9663271307945251, 0.9564233422279358, 0.9657611846923828, 0.9717034697532654, 0.9683078527450562, 0.9722693562507629, 0.9731183052062988, 0.9745330810546875, 0.9750990271568298, 0.9813242554664612, 0.9813242554664612, 0.9793435335159302, 0.9821732044219971, 0.9858517050743103, 0.9847198724746704, 0.9852858185768127, 0.986983597278595, 0.9872665405273438, 0.9872665405273438, 0.986983597278595, 0.9898132681846619, 0.988964319229126, 0.9881154298782349, 0.9903791546821594, 0.9917939901351929, 0.9923599362373352, 0.9892473220825195, 0.9940577149391174, 0.9929258823394775, 0.994340717792511, 0.9934917688369751, 0.9949066042900085, 0.994340717792511, 0.994340717792511, 0.9946236610412598, 0.9951896071434021, 0.9966044425964355, 0.9957554936408997, 0.9954725503921509, 0.9971703290939331, 0.9977362751960754, 0.9971703290939331, 0.9971703290939331, 0.9980192184448242, 0.9977362751960754, 0.9966044425964355, 0.9977362751960754, 0.9977362751960754, 0.9977362751960754, 0.9983022212982178, 0.9983022212982178, 0.9980192184448242, 0.9983022212982178, 0.9983022212982178, 0.9980192184448242, 0.9988681674003601, 0.9988681674003601, 0.9988681674003601, 0.9988681674003601, 0.9983022212982178, 0.9988681674003601, 0.9988681674003601, 0.9988681674003601, 0.9985851645469666, 0.9988681674003601, 0.9994340538978577, 0.9991511106491089, 0.9997170567512512, 0.9991511106491089, 0.9991511106491089, 0.9991511106491089, 0.9997170567512512, 0.9994340538978577, 0.9997170567512512, 0.9997170567512512, 0.9994340538978577, 0.9997170567512512, 0.9997170567512512, 0.9997170567512512, 0.9997170567512512, 0.9997170567512512, 0.9997170567512512], 'val_loss': [1.240519642829895, 1.2265887260437012, 1.2179688215255737, 1.1996501684188843, 1.1954481601715088, 1.170179843902588, 1.1526895761489868, 1.1317460536956787, 1.1132060289382935, 1.0870267152786255, 1.060980200767517, 1.0330791473388672, 0.9996165037155151, 0.9828776121139526, 0.9594626426696777, 0.9317665696144104, 0.901223361492157, 0.8829900026321411, 0.862772524356842, 0.8699418306350708, 0.8381625413894653, 0.82492995262146, 0.818196713924408, 0.8149955868721008, 0.813153862953186, 0.8101390600204468, 0.8165133595466614, 0.8157257437705994, 0.8102123737335205, 0.8265597224235535, 0.8076629042625427, 0.8124879598617554, 0.8169578909873962, 0.822085976600647, 0.8097107410430908, 0.8132423162460327, 0.8142003417015076, 0.8095477223396301, 0.8098999857902527, 0.8105225563049316, 0.8432618379592896, 0.8083534836769104, 0.806535005569458, 0.8068907856941223, 0.8057578206062317, 0.8070455193519592, 0.8070638179779053, 0.8075920343399048, 0.8085958361625671, 0.8169852495193481, 0.8155385851860046, 0.8141877055168152, 0.8152275085449219, 0.8235388994216919, 0.8079181909561157, 0.8089286684989929, 0.822166919708252, 0.817436695098877, 0.8137196898460388, 0.8181388974189758, 0.8262253999710083, 0.8086962103843689, 0.8125686049461365, 0.8369489908218384, 0.8304028511047363, 0.8136611580848694, 0.8164653778076172, 0.8199196457862854, 0.8272616267204285, 0.8128273487091064, 0.8497868776321411, 0.8236655592918396, 0.8151323795318604, 0.8378096222877502, 0.8197979927062988, 0.8253944516181946, 0.8191638588905334, 0.8212882876396179, 0.8337104320526123, 0.8147329092025757, 0.831251859664917, 0.8252503871917725, 0.8367034792900085, 0.8238106369972229, 0.8473930358886719, 0.847652018070221, 0.8364235758781433, 0.8360238671302795, 0.8355695605278015, 0.8327429294586182, 0.8437740802764893, 0.8385472893714905, 0.8334472179412842, 0.8274692296981812, 0.8500123023986816, 0.8342232704162598, 0.8246064186096191, 0.8308397531509399, 0.835414707660675, 0.8295977115631104], 'val_accuracy': [0.49660632014274597, 0.5033936500549316, 0.5079185366630554, 0.5384615659713745, 0.5282805562019348, 0.6040723919868469, 0.639140248298645, 0.6821267008781433, 0.7104072570800781, 0.7579185366630554, 0.7895927429199219, 0.8156108856201172, 0.8518099784851074, 0.8450226187705994, 0.8438913822174072, 0.8518099784851074, 0.8665158152580261, 0.8597285151481628, 0.8755655884742737, 0.8427602052688599, 0.8619909286499023, 0.872171938419342, 0.8733031749725342, 0.8766968250274658, 0.877828061580658, 0.8733031749725342, 0.8789592981338501, 0.8766968250274658, 0.8766968250274658, 0.8733031749725342, 0.8744344115257263, 0.877828061580658, 0.8755655884742737, 0.8755655884742737, 0.8733031749725342, 0.860859751701355, 0.8755655884742737, 0.8653846383094788, 0.8755655884742737, 0.8755655884742737, 0.877828061580658, 0.8619909286499023, 0.8676470518112183, 0.8631221652030945, 0.8699095249176025, 0.8665158152580261, 0.8687782883644104, 0.8710407018661499, 0.8676470518112183, 0.8766968250274658, 0.8766968250274658, 0.8710407018661499, 0.8733031749725342, 0.8755655884742737, 0.8665158152580261, 0.8676470518112183, 0.8710407018661499, 0.8699095249176025, 0.8653846383094788, 0.8710407018661499, 0.872171938419342, 0.8653846383094788, 0.8585972785949707, 0.8710407018661499, 0.8744344115257263, 0.8687782883644104, 0.8710407018661499, 0.8699095249176025, 0.8733031749725342, 0.860859751701355, 0.8699095249176025, 0.8687782883644104, 0.8631221652030945, 0.8744344115257263, 0.8710407018661499, 0.8699095249176025, 0.8619909286499023, 0.8687782883644104, 0.8687782883644104, 0.8619909286499023, 0.8699095249176025, 0.8710407018661499, 0.872171938419342, 0.8687782883644104, 0.8744344115257263, 0.872171938419342, 0.8699095249176025, 0.848416268825531, 0.8699095249176025, 0.8676470518112183, 0.8710407018661499, 0.8699095249176025, 0.8687782883644104, 0.8710407018661499, 0.8699095249176025, 0.8699095249176025, 0.860859751701355, 0.8710407018661499, 0.8699095249176025, 0.8653846383094788]}\n","45/45 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 3s 26ms/step - loss: 0.7955 - accuracy: 0.9070 - val_loss: 1.2434 - val_accuracy: 0.4866\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.7902 - accuracy: 0.9141"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 1s 16ms/step - loss: 0.7703 - accuracy: 0.9199 - val_loss: 1.2356 - val_accuracy: 0.4876\n","Epoch 3/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7662 - accuracy: 0.9204 - val_loss: 1.2183 - val_accuracy: 0.5041\n","Epoch 4/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7534 - accuracy: 0.9243 - val_loss: 1.2015 - val_accuracy: 0.5165\n","Epoch 5/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7424 - accuracy: 0.9300 - val_loss: 1.1935 - val_accuracy: 0.5196\n","Epoch 6/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7333 - accuracy: 0.9323 - val_loss: 1.1602 - val_accuracy: 0.6209\n","Epoch 7/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7302 - accuracy: 0.9328 - val_loss: 1.1373 - val_accuracy: 0.6798\n","Epoch 8/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7226 - accuracy: 0.9331 - val_loss: 1.1331 - val_accuracy: 0.6384\n","Epoch 9/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7089 - accuracy: 0.9403 - val_loss: 1.1137 - val_accuracy: 0.6663\n","Epoch 10/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7043 - accuracy: 0.9411 - val_loss: 1.0759 - val_accuracy: 0.7500\n","Epoch 11/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6955 - accuracy: 0.9470 - val_loss: 1.0391 - val_accuracy: 0.8233\n","Epoch 12/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6912 - accuracy: 0.9468 - val_loss: 1.0135 - val_accuracy: 0.8254\n","Epoch 13/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6811 - accuracy: 0.9509 - val_loss: 0.9910 - val_accuracy: 0.8275\n","Epoch 14/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6794 - accuracy: 0.9491 - val_loss: 0.9439 - val_accuracy: 0.8657\n","Epoch 15/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6686 - accuracy: 0.9550 - val_loss: 0.9141 - val_accuracy: 0.8626\n","Epoch 16/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6634 - accuracy: 0.9563 - val_loss: 0.8872 - val_accuracy: 0.8688\n","Epoch 17/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6599 - accuracy: 0.9568 - val_loss: 0.8720 - val_accuracy: 0.8657\n","Epoch 18/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6507 - accuracy: 0.9576 - val_loss: 0.8515 - val_accuracy: 0.8647\n","Epoch 19/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6462 - accuracy: 0.9607 - val_loss: 0.8357 - val_accuracy: 0.8667\n","Epoch 20/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6404 - accuracy: 0.9597 - val_loss: 0.8612 - val_accuracy: 0.8388\n","Epoch 21/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6359 - accuracy: 0.9612 - val_loss: 0.8135 - val_accuracy: 0.8667\n","Epoch 22/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6277 - accuracy: 0.9649 - val_loss: 0.8063 - val_accuracy: 0.8719\n","Epoch 23/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6220 - accuracy: 0.9685 - val_loss: 0.8051 - val_accuracy: 0.8678\n","Epoch 24/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6162 - accuracy: 0.9721 - val_loss: 0.8009 - val_accuracy: 0.8678\n","Epoch 25/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6117 - accuracy: 0.9685 - val_loss: 0.8089 - val_accuracy: 0.8678\n","Epoch 26/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6043 - accuracy: 0.9718 - val_loss: 0.7989 - val_accuracy: 0.8729\n","Epoch 27/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6015 - accuracy: 0.9713 - val_loss: 0.8031 - val_accuracy: 0.8678\n","Epoch 28/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5992 - accuracy: 0.9736 - val_loss: 0.8315 - val_accuracy: 0.8595\n","Epoch 29/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5973 - accuracy: 0.9705 - val_loss: 0.7990 - val_accuracy: 0.8729\n","Epoch 30/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5883 - accuracy: 0.9693 - val_loss: 0.8448 - val_accuracy: 0.8440\n","Epoch 31/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5900 - accuracy: 0.9705 - val_loss: 0.8002 - val_accuracy: 0.8709\n","Epoch 32/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5779 - accuracy: 0.9783 - val_loss: 0.8121 - val_accuracy: 0.8657\n","Epoch 33/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5741 - accuracy: 0.9765 - val_loss: 0.7974 - val_accuracy: 0.8616\n","Epoch 34/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5671 - accuracy: 0.9811 - val_loss: 0.7985 - val_accuracy: 0.8667\n","Epoch 35/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5664 - accuracy: 0.9798 - val_loss: 0.7914 - val_accuracy: 0.8709\n","Epoch 36/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5617 - accuracy: 0.9780 - val_loss: 0.7944 - val_accuracy: 0.8678\n","Epoch 37/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5528 - accuracy: 0.9822 - val_loss: 0.7920 - val_accuracy: 0.8636\n","Epoch 38/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5527 - accuracy: 0.9804 - val_loss: 0.8119 - val_accuracy: 0.8533\n","Epoch 39/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5460 - accuracy: 0.9840 - val_loss: 0.7992 - val_accuracy: 0.8709\n","Epoch 40/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5438 - accuracy: 0.9845 - val_loss: 0.7897 - val_accuracy: 0.8729\n","Epoch 41/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5372 - accuracy: 0.9848 - val_loss: 0.7912 - val_accuracy: 0.8688\n","Epoch 42/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5335 - accuracy: 0.9863 - val_loss: 0.8005 - val_accuracy: 0.8554\n","Epoch 43/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5339 - accuracy: 0.9835 - val_loss: 0.7883 - val_accuracy: 0.8667\n","Epoch 44/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5247 - accuracy: 0.9876 - val_loss: 0.7880 - val_accuracy: 0.8636\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5263 - accuracy: 0.9868 - val_loss: 0.8139 - val_accuracy: 0.8523\n","Epoch 46/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5226 - accuracy: 0.9863 - val_loss: 0.7898 - val_accuracy: 0.8626\n","Epoch 47/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5143 - accuracy: 0.9884 - val_loss: 0.7883 - val_accuracy: 0.8636\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5100 - accuracy: 0.9912 - val_loss: 0.7896 - val_accuracy: 0.8678\n","Epoch 49/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5068 - accuracy: 0.9904 - val_loss: 0.8110 - val_accuracy: 0.8667\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5059 - accuracy: 0.9899 - val_loss: 0.7913 - val_accuracy: 0.8636\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5026 - accuracy: 0.9917 - val_loss: 0.7860 - val_accuracy: 0.8667\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4983 - accuracy: 0.9920 - val_loss: 0.8040 - val_accuracy: 0.8688\n","Epoch 53/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4938 - accuracy: 0.9912 - val_loss: 0.7946 - val_accuracy: 0.8574\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4954 - accuracy: 0.9884 - val_loss: 0.7858 - val_accuracy: 0.8647\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4900 - accuracy: 0.9912 - val_loss: 0.7851 - val_accuracy: 0.8585\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4859 - accuracy: 0.9922 - val_loss: 0.8008 - val_accuracy: 0.8709\n","Epoch 57/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4876 - accuracy: 0.9899 - val_loss: 0.7873 - val_accuracy: 0.8616\n","Epoch 58/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4782 - accuracy: 0.9925 - val_loss: 0.7887 - val_accuracy: 0.8688\n","Epoch 59/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4771 - accuracy: 0.9935 - val_loss: 0.7872 - val_accuracy: 0.8595\n","Epoch 60/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4733 - accuracy: 0.9941 - val_loss: 0.8005 - val_accuracy: 0.8585\n","Epoch 61/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4718 - accuracy: 0.9925 - val_loss: 0.7988 - val_accuracy: 0.8523\n","Epoch 62/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4706 - accuracy: 0.9928 - val_loss: 0.7898 - val_accuracy: 0.8657\n","Epoch 63/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4665 - accuracy: 0.9938 - val_loss: 0.7884 - val_accuracy: 0.8605\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4662 - accuracy: 0.9941 - val_loss: 0.7960 - val_accuracy: 0.8740\n","Epoch 65/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4595 - accuracy: 0.9948 - val_loss: 0.8010 - val_accuracy: 0.8781\n","Epoch 66/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4619 - accuracy: 0.9935 - val_loss: 0.7969 - val_accuracy: 0.8740\n","Epoch 67/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4561 - accuracy: 0.9946 - val_loss: 0.7912 - val_accuracy: 0.8667\n","Epoch 68/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4524 - accuracy: 0.9961 - val_loss: 0.7901 - val_accuracy: 0.8585\n","Epoch 69/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4503 - accuracy: 0.9959 - val_loss: 0.7988 - val_accuracy: 0.8667\n","Epoch 70/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4482 - accuracy: 0.9959 - val_loss: 0.8051 - val_accuracy: 0.8481\n","Epoch 71/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4450 - accuracy: 0.9959 - val_loss: 0.7982 - val_accuracy: 0.8492\n","Epoch 72/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4435 - accuracy: 0.9972 - val_loss: 0.7960 - val_accuracy: 0.8605\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4399 - accuracy: 0.9972 - val_loss: 0.7960 - val_accuracy: 0.8605\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4404 - accuracy: 0.9959 - val_loss: 0.8424 - val_accuracy: 0.8471\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4376 - accuracy: 0.9964 - val_loss: 0.7988 - val_accuracy: 0.8678\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4332 - accuracy: 0.9972 - val_loss: 0.7960 - val_accuracy: 0.8688\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4324 - accuracy: 0.9966 - val_loss: 0.8038 - val_accuracy: 0.8492\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4313 - accuracy: 0.9966 - val_loss: 0.7969 - val_accuracy: 0.8595\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4267 - accuracy: 0.9974 - val_loss: 0.8057 - val_accuracy: 0.8502\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4252 - accuracy: 0.9982 - val_loss: 0.8008 - val_accuracy: 0.8719\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4231 - accuracy: 0.9979 - val_loss: 0.8097 - val_accuracy: 0.8512\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4206 - accuracy: 0.9979 - val_loss: 0.8037 - val_accuracy: 0.8605\n","Epoch 83/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4192 - accuracy: 0.9984 - val_loss: 0.8094 - val_accuracy: 0.8719\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4176 - accuracy: 0.9984 - val_loss: 0.8168 - val_accuracy: 0.8709\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4147 - accuracy: 0.9984 - val_loss: 0.8078 - val_accuracy: 0.8719\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4133 - accuracy: 0.9982 - val_loss: 0.8072 - val_accuracy: 0.8719\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4115 - accuracy: 0.9987 - val_loss: 0.8102 - val_accuracy: 0.8729\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4105 - accuracy: 0.9984 - val_loss: 0.8115 - val_accuracy: 0.8698\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4076 - accuracy: 0.9987 - val_loss: 0.8102 - val_accuracy: 0.8471\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4048 - accuracy: 0.9990 - val_loss: 0.8211 - val_accuracy: 0.8450\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4026 - accuracy: 0.9990 - val_loss: 0.8067 - val_accuracy: 0.8616\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4009 - accuracy: 0.9990 - val_loss: 0.8170 - val_accuracy: 0.8409\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4025 - accuracy: 0.9987 - val_loss: 0.8102 - val_accuracy: 0.8574\n","Epoch 94/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3987 - accuracy: 0.9990 - val_loss: 0.8100 - val_accuracy: 0.8636\n","Epoch 95/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3950 - accuracy: 0.9995 - val_loss: 0.8132 - val_accuracy: 0.8492\n","Epoch 96/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3935 - accuracy: 0.9995 - val_loss: 0.8100 - val_accuracy: 0.8595\n","Epoch 97/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3917 - accuracy: 0.9995 - val_loss: 0.8098 - val_accuracy: 0.8585\n","Epoch 98/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3905 - accuracy: 0.9990 - val_loss: 0.8125 - val_accuracy: 0.8616\n","Epoch 99/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3887 - accuracy: 0.9992 - val_loss: 0.8151 - val_accuracy: 0.8647\n","Epoch 100/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3869 - accuracy: 0.9992 - val_loss: 0.8163 - val_accuracy: 0.8595\n","{'loss': [0.7955433130264282, 0.7703073620796204, 0.7661789059638977, 0.7533799409866333, 0.7423761487007141, 0.7332878708839417, 0.7302404642105103, 0.7226372361183167, 0.7088746428489685, 0.7043216228485107, 0.6954801082611084, 0.6911615133285522, 0.6810970902442932, 0.6794126629829407, 0.6686368584632874, 0.6634407639503479, 0.6599311828613281, 0.6507169008255005, 0.646165668964386, 0.6403861045837402, 0.6358879208564758, 0.6277374029159546, 0.6220022439956665, 0.6162279844284058, 0.6116600036621094, 0.6043256521224976, 0.6015465259552002, 0.5991606712341309, 0.5973042249679565, 0.5882698893547058, 0.5899510383605957, 0.5778710842132568, 0.5740605592727661, 0.567127525806427, 0.566372811794281, 0.5616641640663147, 0.5527903437614441, 0.552746057510376, 0.5459786653518677, 0.5438023805618286, 0.5371791124343872, 0.5335283875465393, 0.5339019298553467, 0.5247113108634949, 0.526343584060669, 0.5226048231124878, 0.5143141746520996, 0.5099863409996033, 0.506813108921051, 0.5058549642562866, 0.5026441216468811, 0.498332142829895, 0.49377134442329407, 0.4953891932964325, 0.49004536867141724, 0.485933780670166, 0.48757728934288025, 0.4782329499721527, 0.4771467447280884, 0.47333240509033203, 0.47177404165267944, 0.4705767035484314, 0.46652957797050476, 0.4662066400051117, 0.45949941873550415, 0.4618946313858032, 0.4561445116996765, 0.4523594379425049, 0.4502815008163452, 0.44823727011680603, 0.44503054022789, 0.44350311160087585, 0.43994003534317017, 0.4404188394546509, 0.43762221932411194, 0.43318885564804077, 0.43237173557281494, 0.431323766708374, 0.4267171025276184, 0.4252206087112427, 0.4230547845363617, 0.4205837845802307, 0.41924378275871277, 0.41762375831604004, 0.41467154026031494, 0.4133087694644928, 0.4115472137928009, 0.4105086028575897, 0.40756934881210327, 0.4048306941986084, 0.4025733470916748, 0.4009055197238922, 0.40245407819747925, 0.39872440695762634, 0.39503049850463867, 0.39353683590888977, 0.3917240798473358, 0.39049965143203735, 0.38873523473739624, 0.38691362738609314], 'accuracy': [0.9069767594337463, 0.91989666223526, 0.9204134345054626, 0.9242894053459167, 0.9299741387367249, 0.9322997331619263, 0.9328165650367737, 0.933074951171875, 0.9403100609779358, 0.9410852789878845, 0.947028398513794, 0.9467700123786926, 0.950904369354248, 0.949095606803894, 0.9550387859344482, 0.9563307762145996, 0.9568475484848022, 0.957622766494751, 0.9607235193252563, 0.9596899151802063, 0.961240291595459, 0.9648578763008118, 0.9684754610061646, 0.9720930457115173, 0.9684754610061646, 0.9718345999717712, 0.9713178277015686, 0.97364342212677, 0.9705426096916199, 0.9692506194114685, 0.9705426096916199, 0.9782945513725281, 0.9764857888221741, 0.9811369776725769, 0.9798449873924255, 0.9780361652374268, 0.9821705222129822, 0.9803617596626282, 0.983979344367981, 0.9844961166381836, 0.9847545027732849, 0.9863049387931824, 0.9834625124931335, 0.987596869468689, 0.986821711063385, 0.9863049387931824, 0.9883720874786377, 0.9912144541740417, 0.9904392957687378, 0.9899224638938904, 0.9917312860488892, 0.9919896721839905, 0.9912144541740417, 0.9883720874786377, 0.9912144541740417, 0.9922480583190918, 0.9899224638938904, 0.9925064444541931, 0.9935400485992432, 0.9940568208694458, 0.9925064444541931, 0.9927648305892944, 0.9937984347343445, 0.9940568208694458, 0.9948320388793945, 0.9935400485992432, 0.9945736527442932, 0.9961240291595459, 0.9958656430244446, 0.9958656430244446, 0.9958656430244446, 0.997157633304596, 0.997157633304596, 0.9958656430244446, 0.9963824152946472, 0.997157633304596, 0.9966408014297485, 0.9966408014297485, 0.9974160194396973, 0.998191237449646, 0.9979327917098999, 0.9979327917098999, 0.9984496235847473, 0.9984496235847473, 0.9984496235847473, 0.998191237449646, 0.9987080097198486, 0.9984496235847473, 0.9987080097198486, 0.99896639585495, 0.99896639585495, 0.99896639585495, 0.9987080097198486, 0.99896639585495, 0.9994832277297974, 0.9994832277297974, 0.9994832277297974, 0.99896639585495, 0.9992247819900513, 0.9992247819900513], 'val_loss': [1.2433534860610962, 1.2356070280075073, 1.218320369720459, 1.2015321254730225, 1.1935393810272217, 1.1601840257644653, 1.13731050491333, 1.133082389831543, 1.1137423515319824, 1.0758986473083496, 1.0390714406967163, 1.013497233390808, 0.9910048842430115, 0.9439241886138916, 0.9140961170196533, 0.8872366547584534, 0.8719525933265686, 0.8514515161514282, 0.8356501460075378, 0.861243486404419, 0.8134515285491943, 0.8063108921051025, 0.8051296472549438, 0.800947368144989, 0.808866024017334, 0.7988666892051697, 0.8030960559844971, 0.8314633965492249, 0.7990164160728455, 0.8448050022125244, 0.8001545667648315, 0.8120976090431213, 0.7973760962486267, 0.798535943031311, 0.7914143204689026, 0.7943897247314453, 0.7920076847076416, 0.81190425157547, 0.7992078065872192, 0.7896612882614136, 0.7912055253982544, 0.8005088567733765, 0.7883013486862183, 0.7880420684814453, 0.8139166831970215, 0.7898351550102234, 0.7883114218711853, 0.7895826697349548, 0.8110358119010925, 0.7912824749946594, 0.7860345840454102, 0.8040016293525696, 0.7945739030838013, 0.7857841849327087, 0.785086989402771, 0.8007972836494446, 0.7873400449752808, 0.7887254953384399, 0.7872309684753418, 0.8005444407463074, 0.7988278865814209, 0.7898299098014832, 0.7884054780006409, 0.795996904373169, 0.8009624481201172, 0.7968747019767761, 0.7911730408668518, 0.7900660634040833, 0.7987688779830933, 0.8050689697265625, 0.7982326149940491, 0.7959672212600708, 0.7959575653076172, 0.8424239754676819, 0.7988108992576599, 0.7960081696510315, 0.8037912249565125, 0.796886146068573, 0.8056877851486206, 0.8007980585098267, 0.8096945881843567, 0.8037165999412537, 0.8094105124473572, 0.8168091773986816, 0.8078271746635437, 0.8072075843811035, 0.8101599216461182, 0.8115188479423523, 0.8102229237556458, 0.821069598197937, 0.8066975474357605, 0.8170062899589539, 0.8101901412010193, 0.8100230097770691, 0.8132094144821167, 0.8100260496139526, 0.8097647428512573, 0.8125306367874146, 0.8150652647018433, 0.8163209557533264], 'val_accuracy': [0.48657023906707764, 0.4876033067703247, 0.5041322112083435, 0.5165289044380188, 0.51962810754776, 0.6208677887916565, 0.6797520518302917, 0.6384297609329224, 0.6663222908973694, 0.75, 0.8233470916748047, 0.8254132270812988, 0.827479362487793, 0.8657024502754211, 0.8626033067703247, 0.8688016533851624, 0.8657024502754211, 0.8646694421768188, 0.8667355179786682, 0.8388429880142212, 0.8667355179786682, 0.8719007968902588, 0.8677685856819153, 0.8677685856819153, 0.8677685856819153, 0.8729338645935059, 0.8677685856819153, 0.8595041036605835, 0.8729338645935059, 0.8440082669258118, 0.8708677887916565, 0.8657024502754211, 0.8615702390670776, 0.8667355179786682, 0.8708677887916565, 0.8677685856819153, 0.8636363744735718, 0.8533057570457458, 0.8708677887916565, 0.8729338645935059, 0.8688016533851624, 0.85537189245224, 0.8667355179786682, 0.8636363744735718, 0.8522727489471436, 0.8626033067703247, 0.8636363744735718, 0.8677685856819153, 0.8667355179786682, 0.8636363744735718, 0.8667355179786682, 0.8688016533851624, 0.8574380278587341, 0.8646694421768188, 0.8584710955619812, 0.8708677887916565, 0.8615702390670776, 0.8688016533851624, 0.8595041036605835, 0.8584710955619812, 0.8522727489471436, 0.8657024502754211, 0.8605371713638306, 0.8739669322967529, 0.8780992031097412, 0.8739669322967529, 0.8667355179786682, 0.8584710955619812, 0.8667355179786682, 0.8481404781341553, 0.8491735458374023, 0.8605371713638306, 0.8605371713638306, 0.8471074104309082, 0.8677685856819153, 0.8688016533851624, 0.8491735458374023, 0.8595041036605835, 0.8502066135406494, 0.8719007968902588, 0.8512396812438965, 0.8605371713638306, 0.8719007968902588, 0.8708677887916565, 0.8719007968902588, 0.8719007968902588, 0.8729338645935059, 0.8698347210884094, 0.8471074104309082, 0.8450413346290588, 0.8615702390670776, 0.8409090638160706, 0.8574380278587341, 0.8636363744735718, 0.8491735458374023, 0.8595041036605835, 0.8584710955619812, 0.8615702390670776, 0.8646694421768188, 0.8595041036605835]}\n","32/32 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 28ms/step - loss: 0.4282 - accuracy: 0.9833 - val_loss: 1.0794 - val_accuracy: 0.4849\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.4012 - accuracy: 0.9922"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 15ms/step - loss: 0.4150 - accuracy: 0.9890 - val_loss: 1.0754 - val_accuracy: 0.4860\n","Epoch 3/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4072 - accuracy: 0.9941 - val_loss: 1.0712 - val_accuracy: 0.4903\n","Epoch 4/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4072 - accuracy: 0.9935 - val_loss: 1.0485 - val_accuracy: 0.4957\n","Epoch 5/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3991 - accuracy: 0.9960 - val_loss: 1.0211 - val_accuracy: 0.5216\n","Epoch 6/100\n","29/29 [==============================] - 1s 35ms/step - loss: 0.4006 - accuracy: 0.9943 - val_loss: 0.9985 - val_accuracy: 0.5463\n","Epoch 7/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3943 - accuracy: 0.9973 - val_loss: 0.9806 - val_accuracy: 0.5733\n","Epoch 8/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3911 - accuracy: 0.9968 - val_loss: 0.9161 - val_accuracy: 0.6552\n","Epoch 9/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3924 - accuracy: 0.9954 - val_loss: 0.8729 - val_accuracy: 0.7091\n","Epoch 10/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3872 - accuracy: 0.9978 - val_loss: 0.8643 - val_accuracy: 0.7047\n","Epoch 11/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3862 - accuracy: 0.9973 - val_loss: 0.8199 - val_accuracy: 0.7457\n","Epoch 12/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3855 - accuracy: 0.9976 - val_loss: 0.8002 - val_accuracy: 0.7608\n","Epoch 13/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3808 - accuracy: 0.9978 - val_loss: 0.7589 - val_accuracy: 0.8006\n","Epoch 14/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3788 - accuracy: 0.9989 - val_loss: 0.6923 - val_accuracy: 0.8728\n","Epoch 15/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3756 - accuracy: 0.9987 - val_loss: 0.6791 - val_accuracy: 0.8739\n","Epoch 16/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3745 - accuracy: 0.9987 - val_loss: 0.6370 - val_accuracy: 0.8998\n","Epoch 17/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3747 - accuracy: 0.9989 - val_loss: 0.6398 - val_accuracy: 0.8879\n","Epoch 18/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3709 - accuracy: 0.9984 - val_loss: 0.5964 - val_accuracy: 0.9127\n","Epoch 19/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3696 - accuracy: 0.9981 - val_loss: 0.5890 - val_accuracy: 0.9213\n","Epoch 20/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3676 - accuracy: 0.9989 - val_loss: 0.6020 - val_accuracy: 0.9030\n","Epoch 21/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3667 - accuracy: 0.9992 - val_loss: 0.5859 - val_accuracy: 0.9159\n","Epoch 22/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3647 - accuracy: 0.9984 - val_loss: 0.5722 - val_accuracy: 0.9213\n","Epoch 23/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3635 - accuracy: 0.9987 - val_loss: 0.5769 - val_accuracy: 0.9224\n","Epoch 24/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3617 - accuracy: 0.9995 - val_loss: 0.5770 - val_accuracy: 0.9213\n","Epoch 25/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3596 - accuracy: 0.9995 - val_loss: 0.5815 - val_accuracy: 0.9224\n","Epoch 26/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3587 - accuracy: 0.9995 - val_loss: 0.5842 - val_accuracy: 0.9213\n","Epoch 27/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3567 - accuracy: 0.9992 - val_loss: 0.5942 - val_accuracy: 0.9181\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3567 - accuracy: 0.9995 - val_loss: 0.5994 - val_accuracy: 0.9235\n","Epoch 29/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3547 - accuracy: 0.9992 - val_loss: 0.5986 - val_accuracy: 0.9224\n","Epoch 30/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3530 - accuracy: 0.9995 - val_loss: 0.6108 - val_accuracy: 0.9149\n","Epoch 31/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3517 - accuracy: 0.9992 - val_loss: 0.5974 - val_accuracy: 0.9203\n","Epoch 32/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3509 - accuracy: 0.9992 - val_loss: 0.6105 - val_accuracy: 0.9170\n","Epoch 33/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3490 - accuracy: 0.9995 - val_loss: 0.6071 - val_accuracy: 0.9235\n","Epoch 34/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3473 - accuracy: 0.9992 - val_loss: 0.6036 - val_accuracy: 0.9192\n","Epoch 35/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3480 - accuracy: 0.9995 - val_loss: 0.6904 - val_accuracy: 0.8804\n","Epoch 36/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3467 - accuracy: 0.9995 - val_loss: 0.6044 - val_accuracy: 0.9203\n","Epoch 37/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3442 - accuracy: 0.9997 - val_loss: 0.6185 - val_accuracy: 0.9170\n","Epoch 38/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3426 - accuracy: 0.9997 - val_loss: 0.6053 - val_accuracy: 0.9213\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3416 - accuracy: 0.9992 - val_loss: 0.6505 - val_accuracy: 0.9019\n","Epoch 40/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3418 - accuracy: 0.9995 - val_loss: 0.6284 - val_accuracy: 0.9181\n","Epoch 41/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3392 - accuracy: 0.9995 - val_loss: 0.6140 - val_accuracy: 0.9192\n","Epoch 42/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3370 - accuracy: 0.9997 - val_loss: 0.6107 - val_accuracy: 0.9224\n","Epoch 43/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3354 - accuracy: 0.9995 - val_loss: 0.6151 - val_accuracy: 0.9192\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3346 - accuracy: 0.9997 - val_loss: 0.6096 - val_accuracy: 0.9224\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3332 - accuracy: 0.9997 - val_loss: 0.6105 - val_accuracy: 0.9213\n","Epoch 46/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3324 - accuracy: 0.9995 - val_loss: 0.6125 - val_accuracy: 0.9203\n","Epoch 47/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3316 - accuracy: 0.9997 - val_loss: 0.6186 - val_accuracy: 0.9138\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3303 - accuracy: 0.9997 - val_loss: 0.6106 - val_accuracy: 0.9235\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3294 - accuracy: 0.9992 - val_loss: 0.6123 - val_accuracy: 0.9213\n","Epoch 50/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3276 - accuracy: 0.9997 - val_loss: 0.6133 - val_accuracy: 0.9181\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3258 - accuracy: 1.0000 - val_loss: 0.6102 - val_accuracy: 0.9203\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3254 - accuracy: 0.9997 - val_loss: 0.6106 - val_accuracy: 0.9192\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3237 - accuracy: 0.9997 - val_loss: 0.6217 - val_accuracy: 0.9138\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3227 - accuracy: 1.0000 - val_loss: 0.6196 - val_accuracy: 0.9181\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3226 - accuracy: 0.9995 - val_loss: 0.6184 - val_accuracy: 0.9192\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3200 - accuracy: 0.9997 - val_loss: 0.6084 - val_accuracy: 0.9181\n","Epoch 57/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3193 - accuracy: 0.9997 - val_loss: 0.6126 - val_accuracy: 0.9213\n","Epoch 58/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3182 - accuracy: 0.9997 - val_loss: 0.6156 - val_accuracy: 0.9170\n","Epoch 59/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3171 - accuracy: 0.9997 - val_loss: 0.6127 - val_accuracy: 0.9246\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3163 - accuracy: 0.9995 - val_loss: 0.6072 - val_accuracy: 0.9203\n","Epoch 61/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3144 - accuracy: 1.0000 - val_loss: 0.6142 - val_accuracy: 0.9149\n","Epoch 62/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3133 - accuracy: 1.0000 - val_loss: 0.6093 - val_accuracy: 0.9192\n","Epoch 63/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3119 - accuracy: 0.9997 - val_loss: 0.6120 - val_accuracy: 0.9170\n","Epoch 64/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3110 - accuracy: 1.0000 - val_loss: 0.6104 - val_accuracy: 0.9213\n","Epoch 65/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3097 - accuracy: 1.0000 - val_loss: 0.6103 - val_accuracy: 0.9192\n","Epoch 66/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3085 - accuracy: 0.9997 - val_loss: 0.6082 - val_accuracy: 0.9192\n","Epoch 67/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3075 - accuracy: 1.0000 - val_loss: 0.6094 - val_accuracy: 0.9170\n","Epoch 68/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3064 - accuracy: 1.0000 - val_loss: 0.6166 - val_accuracy: 0.9159\n","Epoch 69/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3048 - accuracy: 1.0000 - val_loss: 0.6068 - val_accuracy: 0.9149\n","Epoch 70/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3041 - accuracy: 1.0000 - val_loss: 0.6101 - val_accuracy: 0.9181\n","Epoch 71/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3027 - accuracy: 1.0000 - val_loss: 0.6194 - val_accuracy: 0.9116\n","Epoch 72/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3015 - accuracy: 1.0000 - val_loss: 0.6084 - val_accuracy: 0.9192\n","Epoch 73/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3007 - accuracy: 1.0000 - val_loss: 0.6143 - val_accuracy: 0.9159\n","Epoch 74/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2999 - accuracy: 0.9997 - val_loss: 0.6124 - val_accuracy: 0.9149\n","Epoch 75/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2985 - accuracy: 1.0000 - val_loss: 0.6096 - val_accuracy: 0.9159\n","Epoch 76/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2972 - accuracy: 0.9997 - val_loss: 0.6120 - val_accuracy: 0.9170\n","Epoch 77/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2959 - accuracy: 1.0000 - val_loss: 0.6064 - val_accuracy: 0.9170\n","Epoch 78/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2945 - accuracy: 1.0000 - val_loss: 0.6089 - val_accuracy: 0.9149\n","Epoch 79/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2932 - accuracy: 1.0000 - val_loss: 0.6066 - val_accuracy: 0.9192\n","Epoch 80/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2927 - accuracy: 1.0000 - val_loss: 0.6161 - val_accuracy: 0.9149\n","Epoch 81/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2912 - accuracy: 1.0000 - val_loss: 0.6097 - val_accuracy: 0.9127\n","Epoch 82/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2898 - accuracy: 1.0000 - val_loss: 0.6055 - val_accuracy: 0.9170\n","Epoch 83/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2887 - accuracy: 1.0000 - val_loss: 0.6155 - val_accuracy: 0.9149\n","Epoch 84/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2880 - accuracy: 1.0000 - val_loss: 0.6035 - val_accuracy: 0.9159\n","Epoch 85/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2864 - accuracy: 1.0000 - val_loss: 0.6035 - val_accuracy: 0.9149\n","Epoch 86/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2851 - accuracy: 1.0000 - val_loss: 0.6050 - val_accuracy: 0.9170\n","Epoch 87/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2841 - accuracy: 1.0000 - val_loss: 0.6182 - val_accuracy: 0.9127\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2829 - accuracy: 1.0000 - val_loss: 0.6065 - val_accuracy: 0.9159\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2818 - accuracy: 1.0000 - val_loss: 0.6192 - val_accuracy: 0.9149\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2816 - accuracy: 1.0000 - val_loss: 0.6199 - val_accuracy: 0.9127\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2798 - accuracy: 1.0000 - val_loss: 0.6065 - val_accuracy: 0.9138\n","Epoch 92/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2783 - accuracy: 1.0000 - val_loss: 0.5979 - val_accuracy: 0.9149\n","Epoch 93/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2773 - accuracy: 1.0000 - val_loss: 0.6029 - val_accuracy: 0.9149\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2758 - accuracy: 1.0000 - val_loss: 0.6026 - val_accuracy: 0.9127\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2747 - accuracy: 1.0000 - val_loss: 0.6010 - val_accuracy: 0.9149\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2736 - accuracy: 1.0000 - val_loss: 0.6203 - val_accuracy: 0.9084\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2726 - accuracy: 1.0000 - val_loss: 0.5989 - val_accuracy: 0.9127\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2712 - accuracy: 1.0000 - val_loss: 0.5996 - val_accuracy: 0.9149\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2701 - accuracy: 1.0000 - val_loss: 0.5980 - val_accuracy: 0.9138\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2692 - accuracy: 1.0000 - val_loss: 0.5981 - val_accuracy: 0.9149\n","{'loss': [0.42823731899261475, 0.4150077700614929, 0.407236784696579, 0.40716248750686646, 0.3991048038005829, 0.40062159299850464, 0.39431214332580566, 0.39110907912254333, 0.3924397826194763, 0.38722294569015503, 0.38622215390205383, 0.3854908049106598, 0.3808489739894867, 0.37882474064826965, 0.3755570650100708, 0.3745422959327698, 0.3746934235095978, 0.3709084093570709, 0.36962470412254333, 0.36757609248161316, 0.3666589856147766, 0.36472147703170776, 0.36350885033607483, 0.36168697476387024, 0.3596310019493103, 0.35867244005203247, 0.3567412793636322, 0.3566795289516449, 0.3547206521034241, 0.353042870759964, 0.35174521803855896, 0.35087108612060547, 0.34900209307670593, 0.3472939729690552, 0.347975492477417, 0.3467422425746918, 0.34424203634262085, 0.34260237216949463, 0.3415847420692444, 0.34183433651924133, 0.33919984102249146, 0.33702683448791504, 0.33541685342788696, 0.3345986604690552, 0.33322975039482117, 0.3323618769645691, 0.3315826952457428, 0.3303060233592987, 0.3293948769569397, 0.32764774560928345, 0.3258421719074249, 0.3253960907459259, 0.3236841857433319, 0.3226785957813263, 0.32264432311058044, 0.3199951648712158, 0.3193393349647522, 0.31822192668914795, 0.3171289563179016, 0.31632038950920105, 0.3143698573112488, 0.3133217394351959, 0.31185340881347656, 0.31098946928977966, 0.30965346097946167, 0.30852043628692627, 0.30754542350769043, 0.3063551187515259, 0.3048308193683624, 0.304146945476532, 0.30269041657447815, 0.3015083074569702, 0.3007262349128723, 0.2998906970024109, 0.29851478338241577, 0.29716208577156067, 0.2959006428718567, 0.2945215404033661, 0.2931680977344513, 0.2926536798477173, 0.2912335991859436, 0.2897668778896332, 0.2887023389339447, 0.2879529893398285, 0.2863616347312927, 0.2850903272628784, 0.28413668274879456, 0.28288471698760986, 0.28176456689834595, 0.28157857060432434, 0.27981826663017273, 0.27825677394866943, 0.2773110568523407, 0.2758321762084961, 0.2746503949165344, 0.2735691964626312, 0.2725948095321655, 0.27119576930999756, 0.270137757062912, 0.2692127227783203], 'accuracy': [0.9832974076271057, 0.9889547228813171, 0.9940732717514038, 0.993534505367279, 0.9959590435028076, 0.9943426847457886, 0.9973060488700867, 0.9967672228813171, 0.9954202771186829, 0.9978448152542114, 0.9973060488700867, 0.9975754022598267, 0.9978448152542114, 0.9989224076271057, 0.998652994632721, 0.998652994632721, 0.9989224076271057, 0.998383641242981, 0.9981142282485962, 0.9989224076271057, 0.9991918206214905, 0.998383641242981, 0.998652994632721, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9991918206214905, 0.9994612336158752, 0.9991918206214905, 0.9994612336158752, 0.9991918206214905, 0.9991918206214905, 0.9994612336158752, 0.9991918206214905, 0.9994612336158752, 0.9994612336158752, 0.9997305870056152, 0.9997305870056152, 0.9991918206214905, 0.9994612336158752, 0.9994612336158752, 0.9997305870056152, 0.9994612336158752, 0.9997305870056152, 0.9997305870056152, 0.9994612336158752, 0.9997305870056152, 0.9997305870056152, 0.9991918206214905, 0.9997305870056152, 1.0, 0.9997305870056152, 0.9997305870056152, 1.0, 0.9994612336158752, 0.9997305870056152, 0.9997305870056152, 0.9997305870056152, 0.9997305870056152, 0.9994612336158752, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997305870056152, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [1.079399585723877, 1.0753668546676636, 1.0711708068847656, 1.048533320426941, 1.0210981369018555, 0.9985442757606506, 0.9806024432182312, 0.9160832762718201, 0.872922956943512, 0.8643242120742798, 0.8198627829551697, 0.8001631498336792, 0.7588942050933838, 0.6922785639762878, 0.6790841221809387, 0.6369653344154358, 0.6398206353187561, 0.5964053869247437, 0.5890321135520935, 0.6020007133483887, 0.585878849029541, 0.5722154378890991, 0.5769157409667969, 0.5770363211631775, 0.5815376043319702, 0.5841525793075562, 0.5942240357398987, 0.5993859767913818, 0.5986033082008362, 0.6108250617980957, 0.5973883271217346, 0.6105396151542664, 0.6071165800094604, 0.6036447882652283, 0.6903915405273438, 0.6043709516525269, 0.618539035320282, 0.6053059101104736, 0.6504836082458496, 0.628440797328949, 0.6139642000198364, 0.6106937527656555, 0.6150622963905334, 0.6096354126930237, 0.610536515712738, 0.6125155687332153, 0.6185898780822754, 0.6106204390525818, 0.6123045682907104, 0.6132761240005493, 0.6101516485214233, 0.6106439232826233, 0.621740460395813, 0.6195517182350159, 0.6184243559837341, 0.6084001660346985, 0.612558901309967, 0.6155502796173096, 0.6127303838729858, 0.6072290539741516, 0.6141544580459595, 0.6092521548271179, 0.6120160222053528, 0.6103742122650146, 0.610326886177063, 0.6082028150558472, 0.60944002866745, 0.6166038513183594, 0.6067988872528076, 0.6100824475288391, 0.6193811297416687, 0.6084389686584473, 0.6142755746841431, 0.6123901605606079, 0.6095517873764038, 0.6119885444641113, 0.6063792109489441, 0.6089164018630981, 0.6066233515739441, 0.6161348223686218, 0.6096876263618469, 0.6054710149765015, 0.6155399680137634, 0.6034724712371826, 0.603454053401947, 0.6049728393554688, 0.6182147264480591, 0.6064810156822205, 0.619199275970459, 0.619892954826355, 0.6065056920051575, 0.5979098677635193, 0.6028758883476257, 0.6026170253753662, 0.6009870171546936, 0.6203110218048096, 0.5988887548446655, 0.599645733833313, 0.5979532599449158, 0.598146378993988], 'val_accuracy': [0.48491379618644714, 0.48599138855934143, 0.4903017282485962, 0.49568966031074524, 0.5215517282485962, 0.5463362336158752, 0.5732758641242981, 0.6551724076271057, 0.7090517282485962, 0.704741358757019, 0.7456896305084229, 0.7607758641242981, 0.8006465435028076, 0.8728448152542114, 0.8739224076271057, 0.899784505367279, 0.8879310488700867, 0.912715494632721, 0.9213362336158752, 0.9030172228813171, 0.9159482717514038, 0.9213362336158752, 0.9224137663841248, 0.9213362336158752, 0.9224137663841248, 0.9213362336158752, 0.9181034564971924, 0.923491358757019, 0.9224137663841248, 0.9148706793785095, 0.920258641242981, 0.9170258641242981, 0.923491358757019, 0.9191810488700867, 0.8803879022598267, 0.920258641242981, 0.9170258641242981, 0.9213362336158752, 0.9019396305084229, 0.9181034564971924, 0.9191810488700867, 0.9224137663841248, 0.9191810488700867, 0.9224137663841248, 0.9213362336158752, 0.920258641242981, 0.9137930870056152, 0.923491358757019, 0.9213362336158752, 0.9181034564971924, 0.920258641242981, 0.9191810488700867, 0.9137930870056152, 0.9181034564971924, 0.9191810488700867, 0.9181034564971924, 0.9213362336158752, 0.9170258641242981, 0.9245689511299133, 0.920258641242981, 0.9148706793785095, 0.9191810488700867, 0.9170258641242981, 0.9213362336158752, 0.9191810488700867, 0.9191810488700867, 0.9170258641242981, 0.9159482717514038, 0.9148706793785095, 0.9181034564971924, 0.9116379022598267, 0.9191810488700867, 0.9159482717514038, 0.9148706793785095, 0.9159482717514038, 0.9170258641242981, 0.9170258641242981, 0.9148706793785095, 0.9191810488700867, 0.9148706793785095, 0.912715494632721, 0.9170258641242981, 0.9148706793785095, 0.9159482717514038, 0.9148706793785095, 0.9170258641242981, 0.912715494632721, 0.9159482717514038, 0.9148706793785095, 0.912715494632721, 0.9137930870056152, 0.9148706793785095, 0.9148706793785095, 0.912715494632721, 0.9148706793785095, 0.9084051847457886, 0.912715494632721, 0.9148706793785095, 0.9137930870056152, 0.9148706793785095]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 3s 30ms/step - loss: 0.4483 - accuracy: 0.9782 - val_loss: 1.0735 - val_accuracy: 0.4977\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.4396 - accuracy: 0.9766"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 18ms/step - loss: 0.4268 - accuracy: 0.9861 - val_loss: 1.0712 - val_accuracy: 0.4989\n","Epoch 3/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4237 - accuracy: 0.9859 - val_loss: 1.0485 - val_accuracy: 0.5057\n","Epoch 4/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4219 - accuracy: 0.9847 - val_loss: 1.0401 - val_accuracy: 0.5147\n","Epoch 5/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4088 - accuracy: 0.9918 - val_loss: 1.0189 - val_accuracy: 0.5317\n","Epoch 6/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4067 - accuracy: 0.9926 - val_loss: 0.9945 - val_accuracy: 0.5645\n","Epoch 7/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4023 - accuracy: 0.9935 - val_loss: 0.9825 - val_accuracy: 0.5758\n","Epoch 8/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3987 - accuracy: 0.9946 - val_loss: 0.9235 - val_accuracy: 0.6391\n","Epoch 9/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3985 - accuracy: 0.9958 - val_loss: 0.8804 - val_accuracy: 0.7081\n","Epoch 10/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3943 - accuracy: 0.9952 - val_loss: 0.8818 - val_accuracy: 0.6787\n","Epoch 11/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3905 - accuracy: 0.9980 - val_loss: 0.7991 - val_accuracy: 0.8156\n","Epoch 12/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3901 - accuracy: 0.9975 - val_loss: 0.7870 - val_accuracy: 0.8054\n","Epoch 13/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3869 - accuracy: 0.9983 - val_loss: 0.7398 - val_accuracy: 0.8484\n","Epoch 14/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3858 - accuracy: 0.9986 - val_loss: 0.6930 - val_accuracy: 0.8937\n","Epoch 15/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3826 - accuracy: 0.9980 - val_loss: 0.6842 - val_accuracy: 0.8722\n","Epoch 16/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3795 - accuracy: 0.9994 - val_loss: 0.6455 - val_accuracy: 0.8982\n","Epoch 17/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3783 - accuracy: 0.9994 - val_loss: 0.6278 - val_accuracy: 0.9005\n","Epoch 18/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3772 - accuracy: 0.9992 - val_loss: 0.5971 - val_accuracy: 0.9106\n","Epoch 19/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3750 - accuracy: 0.9992 - val_loss: 0.5863 - val_accuracy: 0.9061\n","Epoch 20/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3728 - accuracy: 0.9992 - val_loss: 0.5762 - val_accuracy: 0.9106\n","Epoch 21/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3717 - accuracy: 0.9992 - val_loss: 0.5723 - val_accuracy: 0.9061\n","Epoch 22/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3698 - accuracy: 0.9994 - val_loss: 0.5684 - val_accuracy: 0.9072\n","Epoch 23/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3683 - accuracy: 0.9994 - val_loss: 0.5684 - val_accuracy: 0.9095\n","Epoch 24/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3672 - accuracy: 0.9992 - val_loss: 0.5693 - val_accuracy: 0.9095\n","Epoch 25/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3653 - accuracy: 0.9997 - val_loss: 0.5729 - val_accuracy: 0.9118\n","Epoch 26/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3639 - accuracy: 0.9994 - val_loss: 0.5769 - val_accuracy: 0.9095\n","Epoch 27/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3630 - accuracy: 0.9994 - val_loss: 0.5946 - val_accuracy: 0.9061\n","Epoch 28/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3620 - accuracy: 0.9994 - val_loss: 0.5929 - val_accuracy: 0.9072\n","Epoch 29/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3594 - accuracy: 0.9997 - val_loss: 0.5892 - val_accuracy: 0.9118\n","Epoch 30/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3585 - accuracy: 0.9997 - val_loss: 0.5956 - val_accuracy: 0.9084\n","Epoch 31/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3566 - accuracy: 0.9997 - val_loss: 0.5988 - val_accuracy: 0.9084\n","Epoch 32/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3572 - accuracy: 0.9992 - val_loss: 0.6123 - val_accuracy: 0.9084\n","Epoch 33/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3545 - accuracy: 0.9997 - val_loss: 0.5999 - val_accuracy: 0.9084\n","Epoch 34/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3532 - accuracy: 0.9997 - val_loss: 0.6474 - val_accuracy: 0.9005\n","Epoch 35/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3521 - accuracy: 0.9997 - val_loss: 0.6038 - val_accuracy: 0.9072\n","Epoch 36/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3500 - accuracy: 0.9997 - val_loss: 0.6029 - val_accuracy: 0.9072\n","Epoch 37/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3491 - accuracy: 0.9997 - val_loss: 0.6020 - val_accuracy: 0.9050\n","Epoch 38/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3480 - accuracy: 0.9994 - val_loss: 0.6277 - val_accuracy: 0.9050\n","Epoch 39/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3470 - accuracy: 0.9997 - val_loss: 0.6060 - val_accuracy: 0.9061\n","Epoch 40/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3453 - accuracy: 0.9997 - val_loss: 0.6065 - val_accuracy: 0.9084\n","Epoch 41/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3445 - accuracy: 0.9994 - val_loss: 0.6188 - val_accuracy: 0.9016\n","Epoch 42/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3426 - accuracy: 0.9997 - val_loss: 0.6146 - val_accuracy: 0.9050\n","Epoch 43/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3413 - accuracy: 1.0000 - val_loss: 0.6183 - val_accuracy: 0.9084\n","Epoch 44/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3406 - accuracy: 0.9997 - val_loss: 0.6107 - val_accuracy: 0.9038\n","Epoch 45/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3401 - accuracy: 0.9994 - val_loss: 0.6082 - val_accuracy: 0.9038\n","Epoch 46/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3378 - accuracy: 0.9997 - val_loss: 0.6073 - val_accuracy: 0.9038\n","Epoch 47/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3365 - accuracy: 0.9997 - val_loss: 0.6104 - val_accuracy: 0.9038\n","Epoch 48/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3352 - accuracy: 1.0000 - val_loss: 0.6126 - val_accuracy: 0.9072\n","Epoch 49/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3339 - accuracy: 0.9997 - val_loss: 0.6053 - val_accuracy: 0.9038\n","Epoch 50/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3331 - accuracy: 1.0000 - val_loss: 0.6234 - val_accuracy: 0.9061\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3318 - accuracy: 0.9997 - val_loss: 0.6206 - val_accuracy: 0.9050\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3306 - accuracy: 1.0000 - val_loss: 0.6174 - val_accuracy: 0.9061\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3293 - accuracy: 0.9997 - val_loss: 0.6255 - val_accuracy: 0.9050\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3285 - accuracy: 1.0000 - val_loss: 0.6091 - val_accuracy: 0.9005\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3271 - accuracy: 1.0000 - val_loss: 0.6243 - val_accuracy: 0.9050\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3256 - accuracy: 0.9997 - val_loss: 0.6195 - val_accuracy: 0.9061\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3254 - accuracy: 0.9997 - val_loss: 0.6212 - val_accuracy: 0.9084\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3239 - accuracy: 1.0000 - val_loss: 0.6244 - val_accuracy: 0.9061\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3231 - accuracy: 0.9997 - val_loss: 0.6113 - val_accuracy: 0.9038\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3213 - accuracy: 1.0000 - val_loss: 0.6108 - val_accuracy: 0.9016\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3210 - accuracy: 1.0000 - val_loss: 0.6113 - val_accuracy: 0.9038\n","Epoch 62/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3197 - accuracy: 1.0000 - val_loss: 0.6392 - val_accuracy: 0.9050\n","Epoch 63/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3181 - accuracy: 1.0000 - val_loss: 0.6081 - val_accuracy: 0.9005\n","Epoch 64/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3171 - accuracy: 1.0000 - val_loss: 0.6346 - val_accuracy: 0.9027\n","Epoch 65/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3155 - accuracy: 1.0000 - val_loss: 0.6121 - val_accuracy: 0.9027\n","Epoch 66/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3141 - accuracy: 1.0000 - val_loss: 0.6141 - val_accuracy: 0.9038\n","Epoch 67/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3131 - accuracy: 1.0000 - val_loss: 0.6285 - val_accuracy: 0.9027\n","Epoch 68/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3124 - accuracy: 0.9997 - val_loss: 0.6124 - val_accuracy: 0.9050\n","Epoch 69/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3108 - accuracy: 1.0000 - val_loss: 0.6195 - val_accuracy: 0.9027\n","Epoch 70/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3109 - accuracy: 1.0000 - val_loss: 0.6133 - val_accuracy: 0.9038\n","Epoch 71/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3088 - accuracy: 1.0000 - val_loss: 0.6127 - val_accuracy: 0.9016\n","Epoch 72/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3074 - accuracy: 1.0000 - val_loss: 0.6076 - val_accuracy: 0.8971\n","Epoch 73/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3064 - accuracy: 1.0000 - val_loss: 0.6306 - val_accuracy: 0.9072\n","Epoch 74/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3054 - accuracy: 1.0000 - val_loss: 0.6207 - val_accuracy: 0.9050\n","Epoch 75/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3041 - accuracy: 1.0000 - val_loss: 0.6282 - val_accuracy: 0.9027\n","Epoch 76/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3030 - accuracy: 1.0000 - val_loss: 0.6134 - val_accuracy: 0.9038\n","Epoch 77/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3022 - accuracy: 1.0000 - val_loss: 0.6218 - val_accuracy: 0.9027\n","Epoch 78/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3007 - accuracy: 1.0000 - val_loss: 0.6095 - val_accuracy: 0.9027\n","Epoch 79/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2995 - accuracy: 1.0000 - val_loss: 0.6045 - val_accuracy: 0.9027\n","Epoch 80/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2988 - accuracy: 1.0000 - val_loss: 0.6265 - val_accuracy: 0.9027\n","Epoch 81/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2978 - accuracy: 1.0000 - val_loss: 0.6116 - val_accuracy: 0.9005\n","Epoch 82/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2961 - accuracy: 1.0000 - val_loss: 0.6179 - val_accuracy: 0.9027\n","Epoch 83/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2949 - accuracy: 1.0000 - val_loss: 0.6170 - val_accuracy: 0.9027\n","Epoch 84/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2938 - accuracy: 1.0000 - val_loss: 0.6125 - val_accuracy: 0.9005\n","Epoch 85/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2929 - accuracy: 1.0000 - val_loss: 0.6100 - val_accuracy: 0.9016\n","Epoch 86/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2920 - accuracy: 1.0000 - val_loss: 0.6037 - val_accuracy: 0.9038\n","Epoch 87/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2915 - accuracy: 1.0000 - val_loss: 0.6040 - val_accuracy: 0.9016\n","Epoch 88/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2896 - accuracy: 1.0000 - val_loss: 0.6066 - val_accuracy: 0.9016\n","Epoch 89/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2881 - accuracy: 1.0000 - val_loss: 0.6085 - val_accuracy: 0.9027\n","Epoch 90/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2869 - accuracy: 1.0000 - val_loss: 0.6180 - val_accuracy: 0.9016\n","Epoch 91/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2859 - accuracy: 1.0000 - val_loss: 0.6055 - val_accuracy: 0.9027\n","Epoch 92/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2849 - accuracy: 1.0000 - val_loss: 0.6115 - val_accuracy: 0.9016\n","Epoch 93/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2841 - accuracy: 1.0000 - val_loss: 0.5993 - val_accuracy: 0.9005\n","Epoch 94/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2829 - accuracy: 1.0000 - val_loss: 0.6255 - val_accuracy: 0.9016\n","Epoch 95/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2813 - accuracy: 1.0000 - val_loss: 0.5953 - val_accuracy: 0.9005\n","Epoch 96/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2802 - accuracy: 1.0000 - val_loss: 0.6019 - val_accuracy: 0.9016\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2793 - accuracy: 1.0000 - val_loss: 0.6009 - val_accuracy: 0.9038\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2786 - accuracy: 1.0000 - val_loss: 0.6016 - val_accuracy: 0.8993\n","Epoch 99/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2770 - accuracy: 1.0000 - val_loss: 0.5967 - val_accuracy: 0.8971\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2763 - accuracy: 1.0000 - val_loss: 0.6635 - val_accuracy: 0.8948\n","{'loss': [0.4482608735561371, 0.4268313944339752, 0.42373421788215637, 0.4218948185443878, 0.4087609052658081, 0.40671506524086, 0.4023027718067169, 0.3987252116203308, 0.39846882224082947, 0.3943481743335724, 0.3904869854450226, 0.3900839686393738, 0.38688746094703674, 0.38577261567115784, 0.38264596462249756, 0.37945353984832764, 0.37830281257629395, 0.3772437572479248, 0.3750024437904358, 0.37283897399902344, 0.3716675937175751, 0.36984798312187195, 0.3682864010334015, 0.36724036931991577, 0.3652569055557251, 0.36390504240989685, 0.3629820942878723, 0.3619890809059143, 0.35935574769973755, 0.3584517240524292, 0.3566407561302185, 0.35718750953674316, 0.35448914766311646, 0.35324913263320923, 0.3521294593811035, 0.35003623366355896, 0.3490876853466034, 0.34803834557533264, 0.3469652831554413, 0.34529998898506165, 0.3444584608078003, 0.3426034450531006, 0.34133994579315186, 0.3405698835849762, 0.34007498621940613, 0.33776232600212097, 0.33646461367607117, 0.3351787030696869, 0.3338828682899475, 0.3331489562988281, 0.33182963728904724, 0.33059537410736084, 0.3293220102787018, 0.3284503221511841, 0.3270737826824188, 0.32564711570739746, 0.3254351019859314, 0.32393044233322144, 0.3230612576007843, 0.32126444578170776, 0.32100096344947815, 0.3197358548641205, 0.3181280791759491, 0.3171474039554596, 0.31550806760787964, 0.3141353726387024, 0.3130977153778076, 0.3124469518661499, 0.31083351373672485, 0.3109041750431061, 0.30879727005958557, 0.3073877990245819, 0.30636635422706604, 0.30535197257995605, 0.30406564474105835, 0.3030284345149994, 0.30218008160591125, 0.30068713426589966, 0.29946690797805786, 0.298763632774353, 0.29784417152404785, 0.29614880681037903, 0.2948663532733917, 0.2938145399093628, 0.29292556643486023, 0.2919582426548004, 0.2915040850639343, 0.2896430194377899, 0.28811654448509216, 0.28689002990722656, 0.2859470844268799, 0.28494739532470703, 0.2841161787509918, 0.28290197253227234, 0.28134384751319885, 0.2801821231842041, 0.27932626008987427, 0.2786269187927246, 0.27699291706085205, 0.2762661278247833], 'accuracy': [0.9782116413116455, 0.9861347079277039, 0.9858517050743103, 0.9847198724746704, 0.9917939901351929, 0.992642879486084, 0.9934917688369751, 0.9946236610412598, 0.9957554936408997, 0.9951896071434021, 0.9980192184448242, 0.9974533319473267, 0.9983022212982178, 0.9985851645469666, 0.9980192184448242, 0.9994340538978577, 0.9994340538978577, 0.9991511106491089, 0.9991511106491089, 0.9991511106491089, 0.9991511106491089, 0.9994340538978577, 0.9994340538978577, 0.9991511106491089, 0.9997170567512512, 0.9994340538978577, 0.9994340538978577, 0.9994340538978577, 0.9997170567512512, 0.9997170567512512, 0.9997170567512512, 0.9991511106491089, 0.9997170567512512, 0.9997170567512512, 0.9997170567512512, 0.9997170567512512, 0.9997170567512512, 0.9994340538978577, 0.9997170567512512, 0.9997170567512512, 0.9994340538978577, 0.9997170567512512, 1.0, 0.9997170567512512, 0.9994340538978577, 0.9997170567512512, 0.9997170567512512, 1.0, 0.9997170567512512, 1.0, 0.9997170567512512, 1.0, 0.9997170567512512, 1.0, 1.0, 0.9997170567512512, 0.9997170567512512, 1.0, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [1.0734691619873047, 1.071220874786377, 1.0485371351242065, 1.0401191711425781, 1.018916368484497, 0.9944629073143005, 0.9824753403663635, 0.9235461354255676, 0.8803750872612, 0.881841778755188, 0.7991330027580261, 0.7869803309440613, 0.7398340702056885, 0.6929989457130432, 0.6842095851898193, 0.6455475687980652, 0.6278291344642639, 0.5970781445503235, 0.5862936973571777, 0.5761573314666748, 0.5723342299461365, 0.5684358477592468, 0.5683785080909729, 0.5693321824073792, 0.5728625059127808, 0.5769492387771606, 0.594558596611023, 0.5928775072097778, 0.5892278552055359, 0.5955638885498047, 0.5987579822540283, 0.6123218536376953, 0.5999462604522705, 0.6474264860153198, 0.6038036346435547, 0.6029195785522461, 0.6019830703735352, 0.6277284026145935, 0.6060189008712769, 0.6064954996109009, 0.6188362836837769, 0.6145782470703125, 0.6183409690856934, 0.610663890838623, 0.6082048416137695, 0.6072787046432495, 0.6103624105453491, 0.612644612789154, 0.6053000688552856, 0.6234357357025146, 0.620643138885498, 0.6174487471580505, 0.6254558563232422, 0.6090928912162781, 0.6243258118629456, 0.6194912791252136, 0.621205747127533, 0.6244438290596008, 0.611326277256012, 0.6108089089393616, 0.6113471984863281, 0.6392368674278259, 0.6080968379974365, 0.6345634460449219, 0.6120684146881104, 0.6140729188919067, 0.628548800945282, 0.6123615503311157, 0.6195496916770935, 0.6132867336273193, 0.6126997470855713, 0.6076115965843201, 0.6305870413780212, 0.6206542253494263, 0.6282331347465515, 0.6133706569671631, 0.6218300461769104, 0.6094984412193298, 0.6045214533805847, 0.6264848709106445, 0.6115536093711853, 0.6179197430610657, 0.6169822216033936, 0.6124783158302307, 0.6100127100944519, 0.603708803653717, 0.6039808392524719, 0.6065929532051086, 0.6085323691368103, 0.6180087327957153, 0.6055451035499573, 0.6114710569381714, 0.5993019938468933, 0.6255100965499878, 0.5953108668327332, 0.6019384860992432, 0.6009342074394226, 0.601610004901886, 0.5966818332672119, 0.6634681224822998], 'val_accuracy': [0.4977375566959381, 0.49886876344680786, 0.5056561231613159, 0.5147058963775635, 0.5316742062568665, 0.564479649066925, 0.5757918357849121, 0.639140248298645, 0.7081447839736938, 0.6787330508232117, 0.8156108856201172, 0.8054298758506775, 0.848416268825531, 0.8936651349067688, 0.872171938419342, 0.8981900215148926, 0.9004524946212769, 0.9106335043907166, 0.9061086177825928, 0.9106335043907166, 0.9061086177825928, 0.9072397947311401, 0.9095022678375244, 0.9095022678375244, 0.9117646813392639, 0.9095022678375244, 0.9061086177825928, 0.9072397947311401, 0.9117646813392639, 0.9083710312843323, 0.9083710312843323, 0.9083710312843323, 0.9083710312843323, 0.9004524946212769, 0.9072397947311401, 0.9072397947311401, 0.9049773812294006, 0.9049773812294006, 0.9061086177825928, 0.9083710312843323, 0.901583731174469, 0.9049773812294006, 0.9083710312843323, 0.9038461446762085, 0.9038461446762085, 0.9038461446762085, 0.9038461446762085, 0.9072397947311401, 0.9038461446762085, 0.9061086177825928, 0.9049773812294006, 0.9061086177825928, 0.9049773812294006, 0.9004524946212769, 0.9049773812294006, 0.9061086177825928, 0.9083710312843323, 0.9061086177825928, 0.9038461446762085, 0.901583731174469, 0.9038461446762085, 0.9049773812294006, 0.9004524946212769, 0.9027149081230164, 0.9027149081230164, 0.9038461446762085, 0.9027149081230164, 0.9049773812294006, 0.9027149081230164, 0.9038461446762085, 0.901583731174469, 0.8970588445663452, 0.9072397947311401, 0.9049773812294006, 0.9027149081230164, 0.9038461446762085, 0.9027149081230164, 0.9027149081230164, 0.9027149081230164, 0.9027149081230164, 0.9004524946212769, 0.9027149081230164, 0.9027149081230164, 0.9004524946212769, 0.901583731174469, 0.9038461446762085, 0.901583731174469, 0.901583731174469, 0.9027149081230164, 0.901583731174469, 0.9027149081230164, 0.901583731174469, 0.9004524946212769, 0.901583731174469, 0.9004524946212769, 0.901583731174469, 0.9038461446762085, 0.8993212580680847, 0.8970588445663452, 0.8947963714599609]}\n","45/45 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 3s 29ms/step - loss: 0.4553 - accuracy: 0.9698 - val_loss: 1.0764 - val_accuracy: 0.4866\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 13ms/step - loss: 0.4355 - accuracy: 0.9806 - val_loss: 1.0836 - val_accuracy: 0.4866\n","Epoch 3/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4371 - accuracy: 0.9809 - val_loss: 1.0591 - val_accuracy: 0.4969\n","Epoch 4/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4211 - accuracy: 0.9871 - val_loss: 1.0656 - val_accuracy: 0.4959\n","Epoch 5/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4174 - accuracy: 0.9868 - val_loss: 1.0226 - val_accuracy: 0.5196\n","Epoch 6/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4109 - accuracy: 0.9907 - val_loss: 1.0033 - val_accuracy: 0.5362\n","Epoch 7/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4065 - accuracy: 0.9902 - val_loss: 0.9513 - val_accuracy: 0.6085\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4053 - accuracy: 0.9907 - val_loss: 0.9363 - val_accuracy: 0.6271\n","Epoch 9/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4009 - accuracy: 0.9943 - val_loss: 0.9217 - val_accuracy: 0.6405\n","Epoch 10/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3970 - accuracy: 0.9953 - val_loss: 0.8288 - val_accuracy: 0.7707\n","Epoch 11/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3945 - accuracy: 0.9959 - val_loss: 0.8030 - val_accuracy: 0.7862\n","Epoch 12/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3921 - accuracy: 0.9972 - val_loss: 0.7576 - val_accuracy: 0.8275\n","Epoch 13/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3910 - accuracy: 0.9961 - val_loss: 0.7215 - val_accuracy: 0.8523\n","Epoch 14/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3912 - accuracy: 0.9961 - val_loss: 0.7113 - val_accuracy: 0.8378\n","Epoch 15/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3866 - accuracy: 0.9974 - val_loss: 0.6720 - val_accuracy: 0.8719\n","Epoch 16/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3842 - accuracy: 0.9982 - val_loss: 0.6795 - val_accuracy: 0.8461\n","Epoch 17/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3847 - accuracy: 0.9972 - val_loss: 0.6141 - val_accuracy: 0.8967\n","Epoch 18/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3802 - accuracy: 0.9987 - val_loss: 0.6179 - val_accuracy: 0.8926\n","Epoch 19/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3792 - accuracy: 0.9984 - val_loss: 0.5940 - val_accuracy: 0.9060\n","Epoch 20/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3761 - accuracy: 0.9990 - val_loss: 0.5937 - val_accuracy: 0.9050\n","Epoch 21/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3758 - accuracy: 0.9990 - val_loss: 0.5867 - val_accuracy: 0.9081\n","Epoch 22/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3735 - accuracy: 0.9987 - val_loss: 0.6019 - val_accuracy: 0.9070\n","Epoch 23/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3708 - accuracy: 0.9987 - val_loss: 0.5900 - val_accuracy: 0.9122\n","Epoch 24/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3701 - accuracy: 0.9990 - val_loss: 0.6246 - val_accuracy: 0.9008\n","Epoch 25/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3706 - accuracy: 0.9990 - val_loss: 0.6033 - val_accuracy: 0.9153\n","Epoch 26/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3665 - accuracy: 0.9982 - val_loss: 0.6011 - val_accuracy: 0.9122\n","Epoch 27/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3656 - accuracy: 0.9992 - val_loss: 0.6066 - val_accuracy: 0.9184\n","Epoch 28/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3629 - accuracy: 0.9992 - val_loss: 0.6278 - val_accuracy: 0.9081\n","Epoch 29/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3640 - accuracy: 0.9990 - val_loss: 0.6097 - val_accuracy: 0.9101\n","Epoch 30/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3602 - accuracy: 0.9997 - val_loss: 0.6172 - val_accuracy: 0.9091\n","Epoch 31/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3589 - accuracy: 0.9992 - val_loss: 0.6143 - val_accuracy: 0.9132\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3578 - accuracy: 0.9992 - val_loss: 0.6189 - val_accuracy: 0.9122\n","Epoch 33/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3571 - accuracy: 0.9990 - val_loss: 0.6172 - val_accuracy: 0.9132\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3579 - accuracy: 0.9992 - val_loss: 0.6238 - val_accuracy: 0.9060\n","Epoch 35/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3546 - accuracy: 0.9992 - val_loss: 0.6403 - val_accuracy: 0.8988\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3542 - accuracy: 0.9995 - val_loss: 0.6234 - val_accuracy: 0.9081\n","Epoch 37/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3528 - accuracy: 0.9990 - val_loss: 0.6205 - val_accuracy: 0.9101\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3503 - accuracy: 0.9997 - val_loss: 0.6541 - val_accuracy: 0.9029\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3561 - accuracy: 0.9966 - val_loss: 0.6288 - val_accuracy: 0.9091\n","Epoch 40/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3511 - accuracy: 0.9990 - val_loss: 0.6272 - val_accuracy: 0.9029\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3476 - accuracy: 0.9995 - val_loss: 0.6299 - val_accuracy: 0.9039\n","Epoch 42/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3466 - accuracy: 0.9990 - val_loss: 0.6319 - val_accuracy: 0.9019\n","Epoch 43/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3439 - accuracy: 0.9997 - val_loss: 0.6280 - val_accuracy: 0.9122\n","Epoch 44/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3430 - accuracy: 0.9997 - val_loss: 0.6323 - val_accuracy: 0.9039\n","Epoch 45/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3426 - accuracy: 0.9995 - val_loss: 0.6282 - val_accuracy: 0.9060\n","Epoch 46/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3421 - accuracy: 0.9997 - val_loss: 0.6236 - val_accuracy: 0.9101\n","Epoch 47/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3393 - accuracy: 0.9997 - val_loss: 0.6242 - val_accuracy: 0.9132\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3386 - accuracy: 0.9995 - val_loss: 0.6276 - val_accuracy: 0.9060\n","Epoch 49/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3373 - accuracy: 0.9997 - val_loss: 0.6309 - val_accuracy: 0.9132\n","Epoch 50/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3373 - accuracy: 0.9990 - val_loss: 0.6368 - val_accuracy: 0.8998\n","Epoch 51/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3346 - accuracy: 1.0000 - val_loss: 0.6323 - val_accuracy: 0.9019\n","Epoch 52/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3342 - accuracy: 1.0000 - val_loss: 0.6342 - val_accuracy: 0.9019\n","Epoch 53/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3330 - accuracy: 0.9997 - val_loss: 0.6323 - val_accuracy: 0.9019\n","Epoch 54/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3329 - accuracy: 1.0000 - val_loss: 0.6552 - val_accuracy: 0.8988\n","Epoch 55/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3305 - accuracy: 0.9997 - val_loss: 0.6296 - val_accuracy: 0.9039\n","Epoch 56/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3293 - accuracy: 0.9997 - val_loss: 0.6365 - val_accuracy: 0.9008\n","Epoch 57/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3289 - accuracy: 1.0000 - val_loss: 0.6292 - val_accuracy: 0.9081\n","Epoch 58/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3274 - accuracy: 0.9997 - val_loss: 0.6348 - val_accuracy: 0.8998\n","Epoch 59/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3261 - accuracy: 0.9995 - val_loss: 0.6326 - val_accuracy: 0.9091\n","Epoch 60/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3257 - accuracy: 1.0000 - val_loss: 0.6527 - val_accuracy: 0.8998\n","Epoch 61/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3253 - accuracy: 0.9995 - val_loss: 0.6318 - val_accuracy: 0.9039\n","Epoch 62/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3230 - accuracy: 1.0000 - val_loss: 0.6378 - val_accuracy: 0.9091\n","Epoch 63/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3221 - accuracy: 0.9997 - val_loss: 0.6349 - val_accuracy: 0.9019\n","Epoch 64/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3231 - accuracy: 0.9997 - val_loss: 0.6286 - val_accuracy: 0.9081\n","Epoch 65/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3200 - accuracy: 0.9997 - val_loss: 0.6323 - val_accuracy: 0.9029\n","Epoch 66/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3189 - accuracy: 1.0000 - val_loss: 0.6338 - val_accuracy: 0.9008\n","Epoch 67/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3181 - accuracy: 0.9997 - val_loss: 0.6355 - val_accuracy: 0.9008\n","Epoch 68/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3171 - accuracy: 1.0000 - val_loss: 0.6315 - val_accuracy: 0.9060\n","Epoch 69/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3162 - accuracy: 1.0000 - val_loss: 0.6291 - val_accuracy: 0.9050\n","Epoch 70/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3151 - accuracy: 1.0000 - val_loss: 0.6297 - val_accuracy: 0.9039\n","Epoch 71/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3138 - accuracy: 1.0000 - val_loss: 0.6287 - val_accuracy: 0.9050\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3127 - accuracy: 0.9997 - val_loss: 0.6293 - val_accuracy: 0.9039\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3115 - accuracy: 1.0000 - val_loss: 0.6346 - val_accuracy: 0.8998\n","Epoch 74/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3105 - accuracy: 1.0000 - val_loss: 0.6318 - val_accuracy: 0.9019\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3096 - accuracy: 1.0000 - val_loss: 0.6832 - val_accuracy: 0.8864\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3104 - accuracy: 1.0000 - val_loss: 0.6300 - val_accuracy: 0.9050\n","Epoch 77/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3077 - accuracy: 0.9997 - val_loss: 0.6251 - val_accuracy: 0.9060\n","Epoch 78/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3064 - accuracy: 1.0000 - val_loss: 0.6313 - val_accuracy: 0.9008\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3056 - accuracy: 1.0000 - val_loss: 0.6365 - val_accuracy: 0.9029\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3045 - accuracy: 1.0000 - val_loss: 0.6361 - val_accuracy: 0.8977\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3036 - accuracy: 0.9997 - val_loss: 0.6330 - val_accuracy: 0.8977\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3028 - accuracy: 1.0000 - val_loss: 0.6337 - val_accuracy: 0.9039\n","Epoch 83/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3014 - accuracy: 1.0000 - val_loss: 0.6323 - val_accuracy: 0.9050\n","Epoch 84/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3008 - accuracy: 1.0000 - val_loss: 0.6503 - val_accuracy: 0.9008\n","Epoch 85/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3000 - accuracy: 1.0000 - val_loss: 0.6349 - val_accuracy: 0.8998\n","Epoch 86/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2984 - accuracy: 1.0000 - val_loss: 0.6308 - val_accuracy: 0.9019\n","Epoch 87/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2968 - accuracy: 1.0000 - val_loss: 0.6322 - val_accuracy: 0.9029\n","Epoch 88/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2962 - accuracy: 0.9997 - val_loss: 0.6314 - val_accuracy: 0.9029\n","Epoch 89/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2949 - accuracy: 1.0000 - val_loss: 0.6345 - val_accuracy: 0.8967\n","Epoch 90/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2940 - accuracy: 1.0000 - val_loss: 0.6463 - val_accuracy: 0.8998\n","Epoch 91/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2931 - accuracy: 0.9997 - val_loss: 0.6368 - val_accuracy: 0.9019\n","Epoch 92/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2925 - accuracy: 0.9997 - val_loss: 0.6418 - val_accuracy: 0.8977\n","Epoch 93/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2916 - accuracy: 1.0000 - val_loss: 0.6420 - val_accuracy: 0.9039\n","Epoch 94/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2900 - accuracy: 1.0000 - val_loss: 0.6652 - val_accuracy: 0.8895\n","Epoch 95/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2888 - accuracy: 1.0000 - val_loss: 0.6333 - val_accuracy: 0.8988\n","Epoch 96/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2879 - accuracy: 1.0000 - val_loss: 0.6281 - val_accuracy: 0.9039\n","Epoch 97/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2864 - accuracy: 1.0000 - val_loss: 0.6317 - val_accuracy: 0.8988\n","Epoch 98/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2855 - accuracy: 1.0000 - val_loss: 0.6325 - val_accuracy: 0.9008\n","Epoch 99/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2848 - accuracy: 1.0000 - val_loss: 0.6371 - val_accuracy: 0.8988\n","Epoch 100/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2839 - accuracy: 1.0000 - val_loss: 0.6320 - val_accuracy: 0.9019\n","{'loss': [0.4553110897541046, 0.4355432689189911, 0.43711718916893005, 0.42106881737709045, 0.41740095615386963, 0.4108692407608032, 0.40651267766952515, 0.4053492844104767, 0.4009450376033783, 0.3970167934894562, 0.39447692036628723, 0.39206185936927795, 0.3910311162471771, 0.3912349343299866, 0.3865658938884735, 0.3841691017150879, 0.38467374444007874, 0.3801775276660919, 0.3791835606098175, 0.376054048538208, 0.3757515549659729, 0.3734537959098816, 0.3707781434059143, 0.3700506389141083, 0.3706052601337433, 0.36647292971611023, 0.36558419466018677, 0.3629407584667206, 0.3640332520008087, 0.3602016270160675, 0.3589491844177246, 0.3577994108200073, 0.3571292459964752, 0.35794806480407715, 0.3545728921890259, 0.354177862405777, 0.35278934240341187, 0.350349485874176, 0.35609471797943115, 0.3510565161705017, 0.34763360023498535, 0.3465760350227356, 0.34387829899787903, 0.3429633378982544, 0.3425838053226471, 0.3421075642108917, 0.3392830193042755, 0.3385637104511261, 0.33726438879966736, 0.3372785449028015, 0.3346158564090729, 0.3341645300388336, 0.3330177664756775, 0.3329194188117981, 0.33047032356262207, 0.3293326497077942, 0.3289191424846649, 0.3273727297782898, 0.3260841369628906, 0.3256998658180237, 0.32533344626426697, 0.3230227828025818, 0.32205730676651, 0.32308855652809143, 0.3200342357158661, 0.31889018416404724, 0.31809455156326294, 0.31714725494384766, 0.3161959946155548, 0.31513944268226624, 0.3137916028499603, 0.3126557469367981, 0.3114846348762512, 0.31053608655929565, 0.3095603883266449, 0.31043219566345215, 0.30774831771850586, 0.3063884973526001, 0.305576354265213, 0.3045378625392914, 0.30363935232162476, 0.3027566969394684, 0.30142825841903687, 0.3008405268192291, 0.30002373456954956, 0.2983769178390503, 0.2968316674232483, 0.2961764335632324, 0.294911652803421, 0.2939578890800476, 0.2930583953857422, 0.2924560606479645, 0.2915627658367157, 0.2899726629257202, 0.2887929379940033, 0.287906289100647, 0.2864406108856201, 0.2854854166507721, 0.2848236858844757, 0.2838793992996216], 'accuracy': [0.9697674512863159, 0.9806201457977295, 0.9808785319328308, 0.9870800971984863, 0.986821711063385, 0.9906976819038391, 0.9901808500289917, 0.9906976819038391, 0.9943152666091919, 0.9953488111495972, 0.9958656430244446, 0.997157633304596, 0.9961240291595459, 0.9961240291595459, 0.9974160194396973, 0.998191237449646, 0.997157633304596, 0.9987080097198486, 0.9984496235847473, 0.99896639585495, 0.99896639585495, 0.9987080097198486, 0.9987080097198486, 0.99896639585495, 0.99896639585495, 0.998191237449646, 0.9992247819900513, 0.9992247819900513, 0.99896639585495, 0.9997416138648987, 0.9992247819900513, 0.9992247819900513, 0.99896639585495, 0.9992247819900513, 0.9992247819900513, 0.9994832277297974, 0.99896639585495, 0.9997416138648987, 0.9966408014297485, 0.99896639585495, 0.9994832277297974, 0.99896639585495, 0.9997416138648987, 0.9997416138648987, 0.9994832277297974, 0.9997416138648987, 0.9997416138648987, 0.9994832277297974, 0.9997416138648987, 0.99896639585495, 1.0, 1.0, 0.9997416138648987, 1.0, 0.9997416138648987, 0.9997416138648987, 1.0, 0.9997416138648987, 0.9994832277297974, 1.0, 0.9994832277297974, 1.0, 0.9997416138648987, 0.9997416138648987, 0.9997416138648987, 1.0, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 0.9997416138648987, 1.0, 1.0, 1.0, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997416138648987, 1.0, 1.0, 0.9997416138648987, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [1.0763628482818604, 1.0836328268051147, 1.0590806007385254, 1.0655957460403442, 1.0225579738616943, 1.0032823085784912, 0.9512536525726318, 0.9362627863883972, 0.9217057824134827, 0.828798770904541, 0.8030364513397217, 0.7575857639312744, 0.7215152382850647, 0.711301326751709, 0.6719837188720703, 0.6794883012771606, 0.614100992679596, 0.6178673505783081, 0.5940057635307312, 0.5936717391014099, 0.5867468118667603, 0.6019183993339539, 0.5900086164474487, 0.6246427893638611, 0.6032670736312866, 0.6011008620262146, 0.6066418290138245, 0.6278076171875, 0.6097400188446045, 0.6172431111335754, 0.6143184304237366, 0.618858277797699, 0.6171579957008362, 0.6237508654594421, 0.6402824521064758, 0.623442530632019, 0.6205422878265381, 0.654100239276886, 0.6288155913352966, 0.6272110939025879, 0.6298786401748657, 0.6319100856781006, 0.627984344959259, 0.6322728395462036, 0.6282263994216919, 0.6236327886581421, 0.6242194175720215, 0.6276360750198364, 0.6309050917625427, 0.6367612481117249, 0.6323395371437073, 0.6342359781265259, 0.6323075890541077, 0.6551858186721802, 0.6295588612556458, 0.636455774307251, 0.6292129158973694, 0.634830892086029, 0.6326162815093994, 0.6527363061904907, 0.6317670345306396, 0.6377508640289307, 0.6349077224731445, 0.6285840272903442, 0.6323451399803162, 0.6338365077972412, 0.6354602575302124, 0.6315216422080994, 0.6290839314460754, 0.6297125816345215, 0.6287083625793457, 0.6293375492095947, 0.6345787644386292, 0.6317611932754517, 0.6831766963005066, 0.6300491094589233, 0.6250807046890259, 0.6313055753707886, 0.636451244354248, 0.6360741853713989, 0.6330170631408691, 0.6337061524391174, 0.6323279738426208, 0.6502520442008972, 0.6348899602890015, 0.6308194994926453, 0.6321855783462524, 0.6314253211021423, 0.6345095038414001, 0.646289050579071, 0.6367859244346619, 0.6417972445487976, 0.6419991254806519, 0.6652124524116516, 0.6332801580429077, 0.6280889511108398, 0.6317157745361328, 0.6325189471244812, 0.6371196508407593, 0.6320385932922363], 'val_accuracy': [0.48657023906707764, 0.48657023906707764, 0.4969008266925812, 0.4958677589893341, 0.51962810754776, 0.5361570119857788, 0.6084710955619812, 0.6270661354064941, 0.6404958963394165, 0.7706611752510071, 0.7861570119857788, 0.827479362487793, 0.8522727489471436, 0.8378099203109741, 0.8719007968902588, 0.8460744023323059, 0.8966942429542542, 0.8925619721412659, 0.9059917330741882, 0.9049586653709412, 0.9080578684806824, 0.9070248007774353, 0.9121900796890259, 0.9008264541625977, 0.9152892827987671, 0.9121900796890259, 0.9183884263038635, 0.9080578684806824, 0.9101239442825317, 0.9090909361839294, 0.913223147392273, 0.9121900796890259, 0.913223147392273, 0.9059917330741882, 0.8987603187561035, 0.9080578684806824, 0.9101239442825317, 0.9028925895690918, 0.9090909361839294, 0.9028925895690918, 0.9039255976676941, 0.9018595218658447, 0.9121900796890259, 0.9039255976676941, 0.9059917330741882, 0.9101239442825317, 0.913223147392273, 0.9059917330741882, 0.913223147392273, 0.8997933864593506, 0.9018595218658447, 0.9018595218658447, 0.9018595218658447, 0.8987603187561035, 0.9039255976676941, 0.9008264541625977, 0.9080578684806824, 0.8997933864593506, 0.9090909361839294, 0.8997933864593506, 0.9039255976676941, 0.9090909361839294, 0.9018595218658447, 0.9080578684806824, 0.9028925895690918, 0.9008264541625977, 0.9008264541625977, 0.9059917330741882, 0.9049586653709412, 0.9039255976676941, 0.9049586653709412, 0.9039255976676941, 0.8997933864593506, 0.9018595218658447, 0.8863636255264282, 0.9049586653709412, 0.9059917330741882, 0.9008264541625977, 0.9028925895690918, 0.8977272510528564, 0.8977272510528564, 0.9039255976676941, 0.9049586653709412, 0.9008264541625977, 0.8997933864593506, 0.9018595218658447, 0.9028925895690918, 0.9028925895690918, 0.8966942429542542, 0.8997933864593506, 0.9018595218658447, 0.8977272510528564, 0.9039255976676941, 0.8894628286361694, 0.8987603187561035, 0.9039255976676941, 0.8987603187561035, 0.9008264541625977, 0.8987603187561035, 0.9018595218658447]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 5s 34ms/step - loss: 0.3062 - accuracy: 0.9895 - val_loss: 1.0027 - val_accuracy: 0.4849\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.2961 - accuracy: 0.9922"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 17ms/step - loss: 0.2930 - accuracy: 0.9949 - val_loss: 1.0059 - val_accuracy: 0.4860\n","Epoch 3/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2856 - accuracy: 0.9970 - val_loss: 0.9988 - val_accuracy: 0.4892\n","Epoch 4/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2838 - accuracy: 0.9989 - val_loss: 0.9826 - val_accuracy: 0.4957\n","Epoch 5/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2811 - accuracy: 0.9995 - val_loss: 0.9683 - val_accuracy: 0.5011\n","Epoch 6/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2819 - accuracy: 0.9992 - val_loss: 0.9508 - val_accuracy: 0.5129\n","Epoch 7/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2796 - accuracy: 0.9995 - val_loss: 0.8967 - val_accuracy: 0.5700\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2781 - accuracy: 0.9995 - val_loss: 0.8678 - val_accuracy: 0.6013\n","Epoch 9/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2772 - accuracy: 0.9995 - val_loss: 0.8049 - val_accuracy: 0.6595\n","Epoch 10/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2766 - accuracy: 0.9992 - val_loss: 0.7466 - val_accuracy: 0.7069\n","Epoch 11/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2758 - accuracy: 0.9995 - val_loss: 0.7287 - val_accuracy: 0.7209\n","Epoch 12/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2746 - accuracy: 0.9995 - val_loss: 0.6587 - val_accuracy: 0.8028\n","Epoch 13/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2738 - accuracy: 0.9995 - val_loss: 0.6050 - val_accuracy: 0.8578\n","Epoch 14/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2732 - accuracy: 0.9997 - val_loss: 0.5745 - val_accuracy: 0.8772\n","Epoch 15/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2725 - accuracy: 0.9997 - val_loss: 0.5304 - val_accuracy: 0.9041\n","Epoch 16/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2716 - accuracy: 0.9997 - val_loss: 0.4951 - val_accuracy: 0.9246\n","Epoch 17/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2711 - accuracy: 0.9995 - val_loss: 0.4592 - val_accuracy: 0.9353\n","Epoch 18/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2716 - accuracy: 0.9995 - val_loss: 0.5030 - val_accuracy: 0.9084\n","Epoch 19/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2724 - accuracy: 0.9995 - val_loss: 0.4370 - val_accuracy: 0.9375\n","Epoch 20/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2712 - accuracy: 0.9992 - val_loss: 0.4317 - val_accuracy: 0.9386\n","Epoch 21/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2677 - accuracy: 0.9997 - val_loss: 0.4417 - val_accuracy: 0.9364\n","Epoch 22/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2668 - accuracy: 1.0000 - val_loss: 0.4405 - val_accuracy: 0.9332\n","Epoch 23/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2660 - accuracy: 0.9997 - val_loss: 0.4348 - val_accuracy: 0.9397\n","Epoch 24/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2660 - accuracy: 0.9997 - val_loss: 0.4405 - val_accuracy: 0.9407\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2648 - accuracy: 0.9997 - val_loss: 0.4423 - val_accuracy: 0.9397\n","Epoch 26/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2637 - accuracy: 1.0000 - val_loss: 0.4421 - val_accuracy: 0.9418\n","Epoch 27/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2629 - accuracy: 0.9997 - val_loss: 0.4436 - val_accuracy: 0.9407\n","Epoch 28/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2622 - accuracy: 1.0000 - val_loss: 0.4487 - val_accuracy: 0.9429\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2617 - accuracy: 0.9997 - val_loss: 0.4595 - val_accuracy: 0.9407\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2609 - accuracy: 1.0000 - val_loss: 0.4515 - val_accuracy: 0.9429\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2598 - accuracy: 1.0000 - val_loss: 0.4537 - val_accuracy: 0.9429\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2590 - accuracy: 1.0000 - val_loss: 0.4815 - val_accuracy: 0.9300\n","Epoch 33/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2590 - accuracy: 1.0000 - val_loss: 0.4599 - val_accuracy: 0.9440\n","Epoch 34/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2574 - accuracy: 1.0000 - val_loss: 0.4623 - val_accuracy: 0.9386\n","Epoch 35/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2572 - accuracy: 0.9997 - val_loss: 0.4612 - val_accuracy: 0.9429\n","Epoch 36/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2558 - accuracy: 1.0000 - val_loss: 0.4600 - val_accuracy: 0.9397\n","Epoch 37/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2547 - accuracy: 1.0000 - val_loss: 0.4595 - val_accuracy: 0.9397\n","Epoch 38/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2541 - accuracy: 1.0000 - val_loss: 0.4649 - val_accuracy: 0.9386\n","Epoch 39/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2532 - accuracy: 1.0000 - val_loss: 0.4612 - val_accuracy: 0.9407\n","Epoch 40/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2524 - accuracy: 1.0000 - val_loss: 0.4648 - val_accuracy: 0.9375\n","Epoch 41/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2516 - accuracy: 1.0000 - val_loss: 0.4621 - val_accuracy: 0.9407\n","Epoch 42/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2507 - accuracy: 1.0000 - val_loss: 0.4613 - val_accuracy: 0.9375\n","Epoch 43/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2499 - accuracy: 1.0000 - val_loss: 0.4678 - val_accuracy: 0.9386\n","Epoch 44/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2493 - accuracy: 1.0000 - val_loss: 0.4692 - val_accuracy: 0.9364\n","Epoch 45/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2491 - accuracy: 0.9997 - val_loss: 0.4669 - val_accuracy: 0.9397\n","Epoch 46/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2475 - accuracy: 1.0000 - val_loss: 0.4606 - val_accuracy: 0.9386\n","Epoch 47/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2467 - accuracy: 1.0000 - val_loss: 0.4599 - val_accuracy: 0.9397\n","Epoch 48/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2460 - accuracy: 1.0000 - val_loss: 0.4614 - val_accuracy: 0.9397\n","Epoch 49/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2447 - accuracy: 1.0000 - val_loss: 0.4597 - val_accuracy: 0.9364\n","Epoch 50/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2446 - accuracy: 0.9997 - val_loss: 0.4740 - val_accuracy: 0.9321\n","Epoch 51/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2433 - accuracy: 1.0000 - val_loss: 0.4617 - val_accuracy: 0.9418\n","Epoch 52/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2422 - accuracy: 1.0000 - val_loss: 0.4615 - val_accuracy: 0.9375\n","Epoch 53/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2414 - accuracy: 1.0000 - val_loss: 0.4618 - val_accuracy: 0.9418\n","Epoch 54/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2403 - accuracy: 1.0000 - val_loss: 0.4624 - val_accuracy: 0.9375\n","Epoch 55/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2397 - accuracy: 1.0000 - val_loss: 0.4787 - val_accuracy: 0.9267\n","Epoch 56/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2389 - accuracy: 1.0000 - val_loss: 0.4647 - val_accuracy: 0.9332\n","Epoch 57/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2378 - accuracy: 1.0000 - val_loss: 0.4652 - val_accuracy: 0.9364\n","Epoch 58/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2372 - accuracy: 1.0000 - val_loss: 0.4615 - val_accuracy: 0.9386\n","Epoch 59/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2359 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.9364\n","Epoch 60/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2351 - accuracy: 1.0000 - val_loss: 0.4638 - val_accuracy: 0.9375\n","Epoch 61/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2344 - accuracy: 1.0000 - val_loss: 0.4643 - val_accuracy: 0.9353\n","Epoch 62/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2335 - accuracy: 1.0000 - val_loss: 0.4599 - val_accuracy: 0.9386\n","Epoch 63/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.2324 - accuracy: 1.0000 - val_loss: 0.4573 - val_accuracy: 0.9353\n","Epoch 64/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2315 - accuracy: 1.0000 - val_loss: 0.4831 - val_accuracy: 0.9289\n","Epoch 65/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2308 - accuracy: 1.0000 - val_loss: 0.4660 - val_accuracy: 0.9375\n","Epoch 66/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2297 - accuracy: 1.0000 - val_loss: 0.4610 - val_accuracy: 0.9386\n","Epoch 67/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2286 - accuracy: 1.0000 - val_loss: 0.4577 - val_accuracy: 0.9364\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2274 - accuracy: 1.0000 - val_loss: 0.4560 - val_accuracy: 0.9343\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2270 - accuracy: 1.0000 - val_loss: 0.4604 - val_accuracy: 0.9375\n","Epoch 70/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2262 - accuracy: 1.0000 - val_loss: 0.4923 - val_accuracy: 0.9203\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2254 - accuracy: 1.0000 - val_loss: 0.4559 - val_accuracy: 0.9332\n","Epoch 72/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2239 - accuracy: 1.0000 - val_loss: 0.4593 - val_accuracy: 0.9353\n","Epoch 73/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2230 - accuracy: 1.0000 - val_loss: 0.4647 - val_accuracy: 0.9321\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2220 - accuracy: 1.0000 - val_loss: 0.4566 - val_accuracy: 0.9364\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2208 - accuracy: 1.0000 - val_loss: 0.4596 - val_accuracy: 0.9353\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2201 - accuracy: 1.0000 - val_loss: 0.4550 - val_accuracy: 0.9364\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2198 - accuracy: 1.0000 - val_loss: 0.4669 - val_accuracy: 0.9321\n","Epoch 78/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2186 - accuracy: 1.0000 - val_loss: 0.4754 - val_accuracy: 0.9246\n","Epoch 79/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.4523 - val_accuracy: 0.9353\n","Epoch 80/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2163 - accuracy: 1.0000 - val_loss: 0.4536 - val_accuracy: 0.9364\n","Epoch 81/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2154 - accuracy: 1.0000 - val_loss: 0.4596 - val_accuracy: 0.9310\n","Epoch 82/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2143 - accuracy: 1.0000 - val_loss: 0.4584 - val_accuracy: 0.9332\n","Epoch 83/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.4518 - val_accuracy: 0.9353\n","Epoch 84/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.4533 - val_accuracy: 0.9364\n","Epoch 85/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.4557 - val_accuracy: 0.9321\n","Epoch 86/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2108 - accuracy: 1.0000 - val_loss: 0.4516 - val_accuracy: 0.9343\n","Epoch 87/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2099 - accuracy: 1.0000 - val_loss: 0.4464 - val_accuracy: 0.9343\n","Epoch 88/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2092 - accuracy: 1.0000 - val_loss: 0.4540 - val_accuracy: 0.9321\n","Epoch 89/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2078 - accuracy: 1.0000 - val_loss: 0.4542 - val_accuracy: 0.9321\n","Epoch 90/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2067 - accuracy: 1.0000 - val_loss: 0.4504 - val_accuracy: 0.9332\n","Epoch 91/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2058 - accuracy: 1.0000 - val_loss: 0.4491 - val_accuracy: 0.9364\n","Epoch 92/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2048 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.9343\n","Epoch 93/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2038 - accuracy: 1.0000 - val_loss: 0.4485 - val_accuracy: 0.9321\n","Epoch 94/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2032 - accuracy: 1.0000 - val_loss: 0.4457 - val_accuracy: 0.9321\n","Epoch 95/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2023 - accuracy: 1.0000 - val_loss: 0.4465 - val_accuracy: 0.9343\n","Epoch 96/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.2011 - accuracy: 1.0000 - val_loss: 0.4481 - val_accuracy: 0.9321\n","Epoch 97/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2000 - accuracy: 1.0000 - val_loss: 0.4476 - val_accuracy: 0.9343\n","Epoch 98/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1991 - accuracy: 1.0000 - val_loss: 0.4468 - val_accuracy: 0.9343\n","Epoch 99/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1981 - accuracy: 1.0000 - val_loss: 0.4474 - val_accuracy: 0.9278\n","Epoch 100/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1973 - accuracy: 1.0000 - val_loss: 0.4437 - val_accuracy: 0.9321\n","{'loss': [0.3062293231487274, 0.29299837350845337, 0.28562262654304504, 0.2838192582130432, 0.28113988041877747, 0.28185054659843445, 0.2796051502227783, 0.278140664100647, 0.2772063612937927, 0.2766241431236267, 0.2757662534713745, 0.2745622396469116, 0.27383288741111755, 0.27322447299957275, 0.2724784016609192, 0.2716129422187805, 0.27114158868789673, 0.2715948522090912, 0.27240806818008423, 0.2711727023124695, 0.26767048239707947, 0.26683804392814636, 0.2659769058227539, 0.2660004496574402, 0.26483720541000366, 0.2636864483356476, 0.2628932297229767, 0.26217710971832275, 0.26170194149017334, 0.2608514130115509, 0.25980573892593384, 0.2590288519859314, 0.25895607471466064, 0.2574031949043274, 0.2571968734264374, 0.25582197308540344, 0.25473061203956604, 0.25414538383483887, 0.25323742628097534, 0.2524334192276001, 0.25161516666412354, 0.25069817900657654, 0.24991607666015625, 0.24928008019924164, 0.24911771714687347, 0.24750016629695892, 0.2466598004102707, 0.24595513939857483, 0.2447102963924408, 0.2445620447397232, 0.24329790472984314, 0.2422194480895996, 0.24140816926956177, 0.24029703438282013, 0.23972617089748383, 0.2389354556798935, 0.2377980649471283, 0.23718178272247314, 0.23585103452205658, 0.235057070851326, 0.23439551889896393, 0.23347343504428864, 0.23244193196296692, 0.23151887953281403, 0.23082269728183746, 0.229702427983284, 0.2285567969083786, 0.22744183242321014, 0.2269657999277115, 0.22617487609386444, 0.22541238367557526, 0.22391004860401154, 0.22300072014331818, 0.22196686267852783, 0.22083619236946106, 0.22006209194660187, 0.2197856307029724, 0.21856199204921722, 0.21736088395118713, 0.2163175493478775, 0.21542327105998993, 0.21434354782104492, 0.21335533261299133, 0.21260425448417664, 0.21152259409427643, 0.21076756715774536, 0.2098790407180786, 0.2092285007238388, 0.20776021480560303, 0.20673544704914093, 0.20579300820827484, 0.20477642118930817, 0.20379580557346344, 0.20322175323963165, 0.20226149260997772, 0.20105454325675964, 0.19995376467704773, 0.19911226630210876, 0.19809360802173615, 0.19727325439453125], 'accuracy': [0.9894935488700867, 0.9948814511299133, 0.9970366358757019, 0.9989224076271057, 0.9994612336158752, 0.9991918206214905, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9991918206214905, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9997305870056152, 0.9997305870056152, 0.9997305870056152, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9991918206214905, 0.9997305870056152, 1.0, 0.9997305870056152, 0.9997305870056152, 0.9997305870056152, 1.0, 0.9997305870056152, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [1.0027005672454834, 1.0059422254562378, 0.9988348484039307, 0.9825688004493713, 0.9683176279067993, 0.9508267641067505, 0.8966847658157349, 0.8677572011947632, 0.8048912286758423, 0.7466362118721008, 0.7286875247955322, 0.6587033271789551, 0.6049917340278625, 0.5745095610618591, 0.5303568840026855, 0.4950544536113739, 0.4591923654079437, 0.5029814839363098, 0.43698838353157043, 0.43170347809791565, 0.441682904958725, 0.44052654504776, 0.43482664227485657, 0.44051292538642883, 0.4423378109931946, 0.4420571029186249, 0.4435949921607971, 0.4487108290195465, 0.45953091979026794, 0.4515082836151123, 0.45374172925949097, 0.4815162420272827, 0.4599205553531647, 0.4622746706008911, 0.461249440908432, 0.45996353030204773, 0.459460973739624, 0.4648969769477844, 0.4612359404563904, 0.46481600403785706, 0.46208369731903076, 0.4613231420516968, 0.46777522563934326, 0.4691924452781677, 0.4669158458709717, 0.46061334013938904, 0.45990651845932007, 0.4614495038986206, 0.4597160518169403, 0.4739692807197571, 0.46173498034477234, 0.4615306258201599, 0.4617863893508911, 0.4624376595020294, 0.4786880314350128, 0.4646608531475067, 0.46522876620292664, 0.4615384340286255, 0.45780637860298157, 0.46378713846206665, 0.4642846882343292, 0.4599025845527649, 0.45725560188293457, 0.48314258456230164, 0.4659944772720337, 0.4610118865966797, 0.4576554596424103, 0.4559935927391052, 0.460408478975296, 0.49225398898124695, 0.4559358060359955, 0.45925503969192505, 0.4646725356578827, 0.4565788805484772, 0.45961645245552063, 0.45498669147491455, 0.46694692969322205, 0.475405752658844, 0.4523223340511322, 0.45364147424697876, 0.4595917761325836, 0.4583817422389984, 0.4517745077610016, 0.4532826244831085, 0.4557425379753113, 0.45163053274154663, 0.44636332988739014, 0.4539666771888733, 0.4542407989501953, 0.4503644108772278, 0.44910091161727905, 0.44992560148239136, 0.4485381543636322, 0.445700466632843, 0.44651105999946594, 0.4481421113014221, 0.44758832454681396, 0.44676122069358826, 0.44744130969047546, 0.44365784525871277], 'val_accuracy': [0.48491379618644714, 0.48599138855934143, 0.4892241358757019, 0.49568966031074524, 0.5010775923728943, 0.5129310488700867, 0.5700430870056152, 0.6012930870056152, 0.6594827771186829, 0.7068965435028076, 0.7209051847457886, 0.8028017282485962, 0.857758641242981, 0.8771551847457886, 0.9040948152542114, 0.9245689511299133, 0.9353448152542114, 0.9084051847457886, 0.9375, 0.9385775923728943, 0.9364224076271057, 0.9331896305084229, 0.9396551847457886, 0.9407327771186829, 0.9396551847457886, 0.9418103694915771, 0.9407327771186829, 0.9428879022598267, 0.9407327771186829, 0.9428879022598267, 0.9428879022598267, 0.9299569129943848, 0.943965494632721, 0.9385775923728943, 0.9428879022598267, 0.9396551847457886, 0.9396551847457886, 0.9385775923728943, 0.9407327771186829, 0.9375, 0.9407327771186829, 0.9375, 0.9385775923728943, 0.9364224076271057, 0.9396551847457886, 0.9385775923728943, 0.9396551847457886, 0.9396551847457886, 0.9364224076271057, 0.9321120977401733, 0.9418103694915771, 0.9375, 0.9418103694915771, 0.9375, 0.9267241358757019, 0.9331896305084229, 0.9364224076271057, 0.9385775923728943, 0.9364224076271057, 0.9375, 0.9353448152542114, 0.9385775923728943, 0.9353448152542114, 0.9288793206214905, 0.9375, 0.9385775923728943, 0.9364224076271057, 0.9342672228813171, 0.9375, 0.920258641242981, 0.9331896305084229, 0.9353448152542114, 0.9321120977401733, 0.9364224076271057, 0.9353448152542114, 0.9364224076271057, 0.9321120977401733, 0.9245689511299133, 0.9353448152542114, 0.9364224076271057, 0.931034505367279, 0.9331896305084229, 0.9353448152542114, 0.9364224076271057, 0.9321120977401733, 0.9342672228813171, 0.9342672228813171, 0.9321120977401733, 0.9321120977401733, 0.9331896305084229, 0.9364224076271057, 0.9342672228813171, 0.9321120977401733, 0.9321120977401733, 0.9342672228813171, 0.9321120977401733, 0.9342672228813171, 0.9342672228813171, 0.9278017282485962, 0.9321120977401733]}\n","38/38 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.3063 - accuracy: 0.9902"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 4s 38ms/step - loss: 0.3058 - accuracy: 0.9904 - val_loss: 0.9936 - val_accuracy: 0.4977\n","Epoch 2/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2931 - accuracy: 0.9958 - val_loss: 0.9926 - val_accuracy: 0.4977\n","Epoch 3/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2879 - accuracy: 0.9975 - val_loss: 0.9883 - val_accuracy: 0.4989\n","Epoch 4/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2840 - accuracy: 0.9992 - val_loss: 0.9730 - val_accuracy: 0.5045\n","Epoch 5/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2827 - accuracy: 0.9989 - val_loss: 0.9494 - val_accuracy: 0.5158\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2816 - accuracy: 0.9989 - val_loss: 0.9314 - val_accuracy: 0.5294\n","Epoch 7/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2795 - accuracy: 0.9997 - val_loss: 0.8905 - val_accuracy: 0.5724\n","Epoch 8/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2777 - accuracy: 1.0000 - val_loss: 0.8720 - val_accuracy: 0.5871\n","Epoch 9/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2781 - accuracy: 0.9997 - val_loss: 0.7805 - val_accuracy: 0.6708\n","Epoch 10/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2768 - accuracy: 1.0000 - val_loss: 0.7670 - val_accuracy: 0.6844\n","Epoch 11/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2749 - accuracy: 1.0000 - val_loss: 0.6992 - val_accuracy: 0.7749\n","Epoch 12/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2740 - accuracy: 1.0000 - val_loss: 0.6533 - val_accuracy: 0.8213\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2733 - accuracy: 0.9997 - val_loss: 0.5865 - val_accuracy: 0.8790\n","Epoch 14/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2727 - accuracy: 1.0000 - val_loss: 0.5668 - val_accuracy: 0.8801\n","Epoch 15/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2725 - accuracy: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.9265\n","Epoch 16/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2710 - accuracy: 1.0000 - val_loss: 0.4897 - val_accuracy: 0.9276\n","Epoch 17/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2701 - accuracy: 1.0000 - val_loss: 0.4812 - val_accuracy: 0.9197\n","Epoch 18/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2694 - accuracy: 0.9997 - val_loss: 0.4555 - val_accuracy: 0.9287\n","Epoch 19/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2682 - accuracy: 1.0000 - val_loss: 0.4445 - val_accuracy: 0.9287\n","Epoch 20/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2673 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.9321\n","Epoch 21/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2665 - accuracy: 1.0000 - val_loss: 0.4254 - val_accuracy: 0.9321\n","Epoch 22/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2660 - accuracy: 1.0000 - val_loss: 0.4236 - val_accuracy: 0.9344\n","Epoch 23/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2650 - accuracy: 1.0000 - val_loss: 0.4234 - val_accuracy: 0.9321\n","Epoch 24/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2642 - accuracy: 1.0000 - val_loss: 0.4257 - val_accuracy: 0.9321\n","Epoch 25/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2634 - accuracy: 1.0000 - val_loss: 0.4282 - val_accuracy: 0.9333\n","Epoch 26/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2623 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.9321\n","Epoch 27/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2614 - accuracy: 1.0000 - val_loss: 0.4319 - val_accuracy: 0.9333\n","Epoch 28/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2606 - accuracy: 1.0000 - val_loss: 0.4404 - val_accuracy: 0.9321\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2597 - accuracy: 1.0000 - val_loss: 0.4444 - val_accuracy: 0.9344\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2592 - accuracy: 1.0000 - val_loss: 0.4484 - val_accuracy: 0.9253\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2583 - accuracy: 1.0000 - val_loss: 0.4428 - val_accuracy: 0.9333\n","Epoch 32/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2569 - accuracy: 1.0000 - val_loss: 0.4464 - val_accuracy: 0.9310\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2560 - accuracy: 1.0000 - val_loss: 0.4432 - val_accuracy: 0.9333\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2555 - accuracy: 1.0000 - val_loss: 0.4689 - val_accuracy: 0.9276\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2546 - accuracy: 1.0000 - val_loss: 0.4573 - val_accuracy: 0.9310\n","Epoch 36/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2540 - accuracy: 1.0000 - val_loss: 0.4467 - val_accuracy: 0.9321\n","Epoch 37/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2527 - accuracy: 1.0000 - val_loss: 0.4631 - val_accuracy: 0.9299\n","Epoch 38/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2519 - accuracy: 1.0000 - val_loss: 0.4489 - val_accuracy: 0.9287\n","Epoch 39/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2515 - accuracy: 1.0000 - val_loss: 0.4519 - val_accuracy: 0.9287\n","Epoch 40/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2507 - accuracy: 1.0000 - val_loss: 0.4583 - val_accuracy: 0.9310\n","Epoch 41/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2491 - accuracy: 1.0000 - val_loss: 0.4514 - val_accuracy: 0.9310\n","Epoch 42/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2481 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.9321\n","Epoch 43/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2475 - accuracy: 1.0000 - val_loss: 0.4546 - val_accuracy: 0.9231\n","Epoch 44/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2465 - accuracy: 1.0000 - val_loss: 0.4613 - val_accuracy: 0.9287\n","Epoch 45/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2453 - accuracy: 1.0000 - val_loss: 0.4522 - val_accuracy: 0.9287\n","Epoch 46/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2445 - accuracy: 1.0000 - val_loss: 0.4536 - val_accuracy: 0.9253\n","Epoch 47/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2434 - accuracy: 1.0000 - val_loss: 0.4678 - val_accuracy: 0.9287\n","Epoch 48/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2425 - accuracy: 1.0000 - val_loss: 0.4474 - val_accuracy: 0.9299\n","Epoch 49/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2419 - accuracy: 1.0000 - val_loss: 0.4798 - val_accuracy: 0.9208\n","Epoch 50/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2407 - accuracy: 1.0000 - val_loss: 0.4489 - val_accuracy: 0.9287\n","Epoch 51/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2398 - accuracy: 1.0000 - val_loss: 0.4506 - val_accuracy: 0.9253\n","Epoch 52/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2388 - accuracy: 1.0000 - val_loss: 0.4493 - val_accuracy: 0.9321\n","Epoch 53/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2388 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.9265\n","Epoch 54/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2374 - accuracy: 1.0000 - val_loss: 0.4526 - val_accuracy: 0.9253\n","Epoch 55/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2359 - accuracy: 1.0000 - val_loss: 0.4538 - val_accuracy: 0.9242\n","Epoch 56/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2348 - accuracy: 1.0000 - val_loss: 0.4638 - val_accuracy: 0.9276\n","Epoch 57/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2340 - accuracy: 1.0000 - val_loss: 0.4587 - val_accuracy: 0.9265\n","Epoch 58/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2332 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.9265\n","Epoch 59/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2320 - accuracy: 1.0000 - val_loss: 0.4494 - val_accuracy: 0.9242\n","Epoch 60/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2310 - accuracy: 1.0000 - val_loss: 0.4511 - val_accuracy: 0.9265\n","Epoch 61/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2300 - accuracy: 1.0000 - val_loss: 0.4636 - val_accuracy: 0.9253\n","Epoch 62/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2292 - accuracy: 1.0000 - val_loss: 0.4477 - val_accuracy: 0.9253\n","Epoch 63/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2281 - accuracy: 1.0000 - val_loss: 0.4516 - val_accuracy: 0.9253\n","Epoch 64/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2272 - accuracy: 1.0000 - val_loss: 0.4511 - val_accuracy: 0.9242\n","Epoch 65/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2263 - accuracy: 1.0000 - val_loss: 0.4566 - val_accuracy: 0.9265\n","Epoch 66/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2253 - accuracy: 1.0000 - val_loss: 0.4546 - val_accuracy: 0.9265\n","Epoch 67/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2244 - accuracy: 1.0000 - val_loss: 0.4574 - val_accuracy: 0.9253\n","Epoch 68/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2235 - accuracy: 1.0000 - val_loss: 0.4478 - val_accuracy: 0.9242\n","Epoch 69/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2223 - accuracy: 1.0000 - val_loss: 0.4714 - val_accuracy: 0.9219\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2213 - accuracy: 1.0000 - val_loss: 0.4446 - val_accuracy: 0.9253\n","Epoch 71/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2203 - accuracy: 1.0000 - val_loss: 0.4413 - val_accuracy: 0.9253\n","Epoch 72/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2195 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.9287\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2187 - accuracy: 1.0000 - val_loss: 0.4515 - val_accuracy: 0.9242\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.4778 - val_accuracy: 0.9219\n","Epoch 75/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2166 - accuracy: 1.0000 - val_loss: 0.4388 - val_accuracy: 0.9321\n","Epoch 76/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2154 - accuracy: 1.0000 - val_loss: 0.4562 - val_accuracy: 0.9231\n","Epoch 77/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2142 - accuracy: 1.0000 - val_loss: 0.4383 - val_accuracy: 0.9231\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.4475 - val_accuracy: 0.9276\n","Epoch 79/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.4418 - val_accuracy: 0.9242\n","Epoch 80/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.4370 - val_accuracy: 0.9253\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2108 - accuracy: 1.0000 - val_loss: 0.4556 - val_accuracy: 0.9231\n","Epoch 82/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.4294 - val_accuracy: 0.9231\n","Epoch 83/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.4550 - val_accuracy: 0.9219\n","Epoch 84/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2074 - accuracy: 1.0000 - val_loss: 0.4490 - val_accuracy: 0.9219\n","Epoch 85/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2063 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.9186\n","Epoch 86/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2054 - accuracy: 1.0000 - val_loss: 0.4489 - val_accuracy: 0.9231\n","Epoch 87/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2043 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.9253\n","Epoch 88/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2034 - accuracy: 1.0000 - val_loss: 0.4417 - val_accuracy: 0.9231\n","Epoch 89/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2027 - accuracy: 1.0000 - val_loss: 0.4329 - val_accuracy: 0.9231\n","Epoch 90/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.2014 - accuracy: 1.0000 - val_loss: 0.4358 - val_accuracy: 0.9231\n","Epoch 91/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2003 - accuracy: 1.0000 - val_loss: 0.4428 - val_accuracy: 0.9219\n","Epoch 92/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1994 - accuracy: 1.0000 - val_loss: 0.4409 - val_accuracy: 0.9242\n","Epoch 93/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1984 - accuracy: 1.0000 - val_loss: 0.4334 - val_accuracy: 0.9242\n","Epoch 94/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.1972 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.9208\n","Epoch 95/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1964 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.9197\n","Epoch 96/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1953 - accuracy: 1.0000 - val_loss: 0.4268 - val_accuracy: 0.9231\n","Epoch 97/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.1945 - accuracy: 1.0000 - val_loss: 0.4420 - val_accuracy: 0.9208\n","Epoch 98/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1934 - accuracy: 1.0000 - val_loss: 0.4245 - val_accuracy: 0.9219\n","Epoch 99/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1924 - accuracy: 1.0000 - val_loss: 0.4252 - val_accuracy: 0.9231\n","Epoch 100/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1913 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 0.9242\n","{'loss': [0.3057950437068939, 0.2930634021759033, 0.2879348397254944, 0.2839922606945038, 0.28271183371543884, 0.28159597516059875, 0.2795152962207794, 0.2777293622493744, 0.2781430184841156, 0.2767537236213684, 0.2749025225639343, 0.27396872639656067, 0.2733103036880493, 0.27273860573768616, 0.2725277245044708, 0.271017849445343, 0.27013272047042847, 0.2693822979927063, 0.26818975806236267, 0.2673119604587555, 0.2665089964866638, 0.26604512333869934, 0.26501959562301636, 0.2641957998275757, 0.26339516043663025, 0.2623056471347809, 0.2613845467567444, 0.26062944531440735, 0.25965651869773865, 0.2592427730560303, 0.25827261805534363, 0.2569222152233124, 0.2560370862483978, 0.25551095604896545, 0.2545801103115082, 0.2539847791194916, 0.2527085840702057, 0.2518722116947174, 0.2514883875846863, 0.2506817877292633, 0.2491036206483841, 0.24814099073410034, 0.2474929541349411, 0.24648913741111755, 0.24529358744621277, 0.24447442591190338, 0.24341252446174622, 0.2425379902124405, 0.2418517768383026, 0.24068580567836761, 0.23975026607513428, 0.2388075441122055, 0.23881930112838745, 0.2374277114868164, 0.23589979112148285, 0.2348182052373886, 0.23403720557689667, 0.2331812083721161, 0.23202162981033325, 0.2309778928756714, 0.23002593219280243, 0.2291913479566574, 0.22814995050430298, 0.22715474665164948, 0.22628186643123627, 0.22534041106700897, 0.22440508008003235, 0.2234990894794464, 0.22231896221637726, 0.22127214074134827, 0.22032147645950317, 0.21948811411857605, 0.21874591708183289, 0.21745947003364563, 0.2166110724210739, 0.21536675095558167, 0.2142472118139267, 0.2137944996356964, 0.2123139351606369, 0.21145175397396088, 0.21079765260219574, 0.2094576507806778, 0.20829646289348602, 0.2073899358510971, 0.20634818077087402, 0.20544810593128204, 0.20434601604938507, 0.20337015390396118, 0.20269577205181122, 0.2014474719762802, 0.20027194917201996, 0.19936127960681915, 0.19836458563804626, 0.19721639156341553, 0.19638486206531525, 0.1953321397304535, 0.194534033536911, 0.19336967170238495, 0.19236111640930176, 0.19127975404262543], 'accuracy': [0.9903791546821594, 0.9957554936408997, 0.9974533319473267, 0.9991511106491089, 0.9988681674003601, 0.9988681674003601, 0.9997170567512512, 1.0, 0.9997170567512512, 1.0, 1.0, 1.0, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.9935676455497742, 0.9925536513328552, 0.9883404970169067, 0.9730214476585388, 0.9493796229362488, 0.9313527941703796, 0.8905286192893982, 0.8720487952232361, 0.780548095703125, 0.7670455574989319, 0.6992442011833191, 0.653323769569397, 0.5865108966827393, 0.5668338537216187, 0.5080379843711853, 0.4896807074546814, 0.4812339246273041, 0.45551612973213196, 0.44452136754989624, 0.42887404561042786, 0.42537713050842285, 0.42361980676651, 0.42335864901542664, 0.4256689250469208, 0.42819175124168396, 0.4285588264465332, 0.4318974018096924, 0.44040247797966003, 0.4444294273853302, 0.4483889639377594, 0.44280922412872314, 0.44635552167892456, 0.4432145655155182, 0.46887803077697754, 0.4573373794555664, 0.44674378633499146, 0.4631200134754181, 0.4488867521286011, 0.4518960118293762, 0.45829111337661743, 0.45139753818511963, 0.45781102776527405, 0.45458462834358215, 0.4612690508365631, 0.4521523416042328, 0.4535989761352539, 0.4677995443344116, 0.4474015533924103, 0.4797985255718231, 0.44887691736221313, 0.4505629241466522, 0.4492781162261963, 0.4492439031600952, 0.45264285802841187, 0.4537840187549591, 0.4638032913208008, 0.4587317705154419, 0.44917458295822144, 0.44942182302474976, 0.4511220455169678, 0.4635508358478546, 0.44772499799728394, 0.4516182541847229, 0.45113399624824524, 0.4565778076648712, 0.45464959740638733, 0.4574284851551056, 0.4478289783000946, 0.4714445173740387, 0.4445672929286957, 0.4413369297981262, 0.439913809299469, 0.4515403211116791, 0.47777292132377625, 0.4387650191783905, 0.4562213718891144, 0.4382655620574951, 0.4475083649158478, 0.4417997896671295, 0.43698033690452576, 0.4555682837963104, 0.4294392764568329, 0.4549582600593567, 0.44899338483810425, 0.4348326027393341, 0.44891101121902466, 0.43425196409225464, 0.4416954219341278, 0.43289628624916077, 0.4357844591140747, 0.44277000427246094, 0.4409123659133911, 0.4333518445491791, 0.43691739439964294, 0.43140122294425964, 0.4268122613430023, 0.44196051359176636, 0.42445409297943115, 0.42523154616355896, 0.42283937335014343], 'val_accuracy': [0.4977375566959381, 0.4977375566959381, 0.49886876344680786, 0.5045248866081238, 0.5158371329307556, 0.529411792755127, 0.5723981857299805, 0.587104082107544, 0.6708144545555115, 0.6843891143798828, 0.7748869061470032, 0.8212669491767883, 0.8789592981338501, 0.8800904750823975, 0.9264705777168274, 0.9276018142700195, 0.9196832776069641, 0.9287330508232117, 0.9287330508232117, 0.9321267008781433, 0.9321267008781433, 0.9343891143798828, 0.9321267008781433, 0.9321267008781433, 0.9332579374313354, 0.9321267008781433, 0.9332579374313354, 0.9321267008781433, 0.9343891143798828, 0.9253393411636353, 0.9332579374313354, 0.9309954643249512, 0.9332579374313354, 0.9276018142700195, 0.9309954643249512, 0.9321267008781433, 0.929864227771759, 0.9287330508232117, 0.9287330508232117, 0.9309954643249512, 0.9309954643249512, 0.9321267008781433, 0.9230769276618958, 0.9287330508232117, 0.9287330508232117, 0.9253393411636353, 0.9287330508232117, 0.929864227771759, 0.9208144545555115, 0.9287330508232117, 0.9253393411636353, 0.9321267008781433, 0.9264705777168274, 0.9253393411636353, 0.9242081642150879, 0.9276018142700195, 0.9264705777168274, 0.9264705777168274, 0.9242081642150879, 0.9264705777168274, 0.9253393411636353, 0.9253393411636353, 0.9253393411636353, 0.9242081642150879, 0.9264705777168274, 0.9264705777168274, 0.9253393411636353, 0.9242081642150879, 0.9219456911087036, 0.9253393411636353, 0.9253393411636353, 0.9287330508232117, 0.9242081642150879, 0.9219456911087036, 0.9321267008781433, 0.9230769276618958, 0.9230769276618958, 0.9276018142700195, 0.9242081642150879, 0.9253393411636353, 0.9230769276618958, 0.9230769276618958, 0.9219456911087036, 0.9219456911087036, 0.918552041053772, 0.9230769276618958, 0.9253393411636353, 0.9230769276618958, 0.9230769276618958, 0.9230769276618958, 0.9219456911087036, 0.9242081642150879, 0.9242081642150879, 0.9208144545555115, 0.9196832776069641, 0.9230769276618958, 0.9208144545555115, 0.9219456911087036, 0.9230769276618958, 0.9242081642150879]}\n","45/45 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 5s 34ms/step - loss: 0.3153 - accuracy: 0.9858 - val_loss: 1.0167 - val_accuracy: 0.4855\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.2952 - accuracy: 0.9922"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 11ms/step - loss: 0.2977 - accuracy: 0.9925 - val_loss: 1.0139 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2916 - accuracy: 0.9972 - val_loss: 1.0092 - val_accuracy: 0.4866\n","Epoch 4/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2867 - accuracy: 0.9977 - val_loss: 0.9929 - val_accuracy: 0.4948\n","Epoch 5/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2855 - accuracy: 0.9979 - val_loss: 0.9943 - val_accuracy: 0.4969\n","Epoch 6/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2853 - accuracy: 0.9984 - val_loss: 0.9479 - val_accuracy: 0.5186\n","Epoch 7/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2816 - accuracy: 0.9990 - val_loss: 0.9164 - val_accuracy: 0.5444\n","Epoch 8/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2809 - accuracy: 1.0000 - val_loss: 0.8584 - val_accuracy: 0.5992\n","Epoch 9/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2790 - accuracy: 1.0000 - val_loss: 0.8085 - val_accuracy: 0.6612\n","Epoch 10/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2780 - accuracy: 1.0000 - val_loss: 0.7395 - val_accuracy: 0.7252\n","Epoch 11/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2768 - accuracy: 1.0000 - val_loss: 0.6964 - val_accuracy: 0.7707\n","Epoch 12/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2762 - accuracy: 1.0000 - val_loss: 0.6549 - val_accuracy: 0.8110\n","Epoch 13/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2764 - accuracy: 1.0000 - val_loss: 0.5691 - val_accuracy: 0.8833\n","Epoch 14/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2751 - accuracy: 0.9997 - val_loss: 0.5228 - val_accuracy: 0.9143\n","Epoch 15/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2742 - accuracy: 1.0000 - val_loss: 0.5283 - val_accuracy: 0.8936\n","Epoch 16/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2727 - accuracy: 1.0000 - val_loss: 0.5195 - val_accuracy: 0.8915\n","Epoch 17/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2722 - accuracy: 1.0000 - val_loss: 0.4677 - val_accuracy: 0.9246\n","Epoch 18/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2716 - accuracy: 1.0000 - val_loss: 0.5059 - val_accuracy: 0.8988\n","Epoch 19/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2725 - accuracy: 0.9995 - val_loss: 0.4703 - val_accuracy: 0.9256\n","Epoch 20/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2693 - accuracy: 1.0000 - val_loss: 0.4561 - val_accuracy: 0.9349\n","Epoch 21/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2691 - accuracy: 1.0000 - val_loss: 0.4528 - val_accuracy: 0.9298\n","Epoch 22/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2695 - accuracy: 1.0000 - val_loss: 0.4584 - val_accuracy: 0.9339\n","Epoch 23/100\n","31/31 [==============================] - 1s 36ms/step - loss: 0.2679 - accuracy: 1.0000 - val_loss: 0.4583 - val_accuracy: 0.9390\n","Epoch 24/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2675 - accuracy: 1.0000 - val_loss: 0.4758 - val_accuracy: 0.9277\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2666 - accuracy: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.9256\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2663 - accuracy: 0.9997 - val_loss: 0.4882 - val_accuracy: 0.9277\n","Epoch 27/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2652 - accuracy: 0.9997 - val_loss: 0.4932 - val_accuracy: 0.9308\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2635 - accuracy: 0.9997 - val_loss: 0.4876 - val_accuracy: 0.9298\n","Epoch 29/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2628 - accuracy: 1.0000 - val_loss: 0.4882 - val_accuracy: 0.9277\n","Epoch 30/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2631 - accuracy: 1.0000 - val_loss: 0.4895 - val_accuracy: 0.9329\n","Epoch 31/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2616 - accuracy: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.9308\n","Epoch 32/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2600 - accuracy: 1.0000 - val_loss: 0.4988 - val_accuracy: 0.9225\n","Epoch 33/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2605 - accuracy: 1.0000 - val_loss: 0.5075 - val_accuracy: 0.9225\n","Epoch 34/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2592 - accuracy: 1.0000 - val_loss: 0.4883 - val_accuracy: 0.9339\n","Epoch 35/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2576 - accuracy: 1.0000 - val_loss: 0.4863 - val_accuracy: 0.9329\n","Epoch 36/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2570 - accuracy: 1.0000 - val_loss: 0.4909 - val_accuracy: 0.9329\n","Epoch 37/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2560 - accuracy: 1.0000 - val_loss: 0.4893 - val_accuracy: 0.9360\n","Epoch 38/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2551 - accuracy: 1.0000 - val_loss: 0.5001 - val_accuracy: 0.9267\n","Epoch 39/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2555 - accuracy: 1.0000 - val_loss: 0.5021 - val_accuracy: 0.9256\n","Epoch 40/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2539 - accuracy: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.9225\n","Epoch 41/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2548 - accuracy: 0.9997 - val_loss: 0.5092 - val_accuracy: 0.9287\n","Epoch 42/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2523 - accuracy: 1.0000 - val_loss: 0.4883 - val_accuracy: 0.9308\n","Epoch 43/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2515 - accuracy: 1.0000 - val_loss: 0.4892 - val_accuracy: 0.9370\n","Epoch 44/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2504 - accuracy: 1.0000 - val_loss: 0.4863 - val_accuracy: 0.9360\n","Epoch 45/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2496 - accuracy: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.9277\n","Epoch 46/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2487 - accuracy: 1.0000 - val_loss: 0.4907 - val_accuracy: 0.9308\n","Epoch 47/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2487 - accuracy: 1.0000 - val_loss: 0.4947 - val_accuracy: 0.9277\n","Epoch 48/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2471 - accuracy: 1.0000 - val_loss: 0.4933 - val_accuracy: 0.9318\n","Epoch 49/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2462 - accuracy: 1.0000 - val_loss: 0.4899 - val_accuracy: 0.9349\n","Epoch 50/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2455 - accuracy: 1.0000 - val_loss: 0.5009 - val_accuracy: 0.9287\n","Epoch 51/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2446 - accuracy: 1.0000 - val_loss: 0.4872 - val_accuracy: 0.9318\n","Epoch 52/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2436 - accuracy: 1.0000 - val_loss: 0.4870 - val_accuracy: 0.9318\n","Epoch 53/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2446 - accuracy: 1.0000 - val_loss: 0.5204 - val_accuracy: 0.9153\n","Epoch 54/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2437 - accuracy: 1.0000 - val_loss: 0.5051 - val_accuracy: 0.9205\n","Epoch 55/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2416 - accuracy: 1.0000 - val_loss: 0.4895 - val_accuracy: 0.9298\n","Epoch 56/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2405 - accuracy: 1.0000 - val_loss: 0.4971 - val_accuracy: 0.9236\n","Epoch 57/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2398 - accuracy: 1.0000 - val_loss: 0.4863 - val_accuracy: 0.9318\n","Epoch 58/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2387 - accuracy: 1.0000 - val_loss: 0.4902 - val_accuracy: 0.9277\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2380 - accuracy: 1.0000 - val_loss: 0.4863 - val_accuracy: 0.9318\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2372 - accuracy: 1.0000 - val_loss: 0.4881 - val_accuracy: 0.9308\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2364 - accuracy: 1.0000 - val_loss: 0.4981 - val_accuracy: 0.9236\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2358 - accuracy: 1.0000 - val_loss: 0.4827 - val_accuracy: 0.9329\n","Epoch 63/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2343 - accuracy: 1.0000 - val_loss: 0.4904 - val_accuracy: 0.9287\n","Epoch 64/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2339 - accuracy: 1.0000 - val_loss: 0.4932 - val_accuracy: 0.9318\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2331 - accuracy: 1.0000 - val_loss: 0.4891 - val_accuracy: 0.9318\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2326 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.9267\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2338 - accuracy: 0.9997 - val_loss: 0.4962 - val_accuracy: 0.9246\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2303 - accuracy: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.9308\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2293 - accuracy: 1.0000 - val_loss: 0.4857 - val_accuracy: 0.9318\n","Epoch 70/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2284 - accuracy: 1.0000 - val_loss: 0.4849 - val_accuracy: 0.9298\n","Epoch 71/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2275 - accuracy: 1.0000 - val_loss: 0.4885 - val_accuracy: 0.9277\n","Epoch 72/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2266 - accuracy: 1.0000 - val_loss: 0.4864 - val_accuracy: 0.9308\n","Epoch 73/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2259 - accuracy: 1.0000 - val_loss: 0.4905 - val_accuracy: 0.9256\n","Epoch 74/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2269 - accuracy: 1.0000 - val_loss: 0.5107 - val_accuracy: 0.9184\n","Epoch 75/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2249 - accuracy: 1.0000 - val_loss: 0.4782 - val_accuracy: 0.9308\n","Epoch 76/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2232 - accuracy: 1.0000 - val_loss: 0.4830 - val_accuracy: 0.9246\n","Epoch 77/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2222 - accuracy: 1.0000 - val_loss: 0.4812 - val_accuracy: 0.9298\n","Epoch 78/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2217 - accuracy: 1.0000 - val_loss: 0.4867 - val_accuracy: 0.9277\n","Epoch 79/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2213 - accuracy: 1.0000 - val_loss: 0.4842 - val_accuracy: 0.9277\n","Epoch 80/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2198 - accuracy: 1.0000 - val_loss: 0.4802 - val_accuracy: 0.9277\n","Epoch 81/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2191 - accuracy: 1.0000 - val_loss: 0.4810 - val_accuracy: 0.9236\n","Epoch 82/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2183 - accuracy: 1.0000 - val_loss: 0.4845 - val_accuracy: 0.9267\n","Epoch 83/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2171 - accuracy: 1.0000 - val_loss: 0.4929 - val_accuracy: 0.9153\n","Epoch 84/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2163 - accuracy: 1.0000 - val_loss: 0.4773 - val_accuracy: 0.9308\n","Epoch 85/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2152 - accuracy: 1.0000 - val_loss: 0.4829 - val_accuracy: 0.9287\n","Epoch 86/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2145 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.9287\n","Epoch 87/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2137 - accuracy: 1.0000 - val_loss: 0.4780 - val_accuracy: 0.9298\n","Epoch 88/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.4754 - val_accuracy: 0.9287\n","Epoch 89/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.4869 - val_accuracy: 0.9225\n","Epoch 90/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2108 - accuracy: 1.0000 - val_loss: 0.4758 - val_accuracy: 0.9277\n","Epoch 91/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2098 - accuracy: 1.0000 - val_loss: 0.4859 - val_accuracy: 0.9215\n","Epoch 92/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2091 - accuracy: 1.0000 - val_loss: 0.4865 - val_accuracy: 0.9174\n","Epoch 93/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.4869 - val_accuracy: 0.9194\n","Epoch 94/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2079 - accuracy: 1.0000 - val_loss: 0.4893 - val_accuracy: 0.9132\n","Epoch 95/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.2064 - accuracy: 1.0000 - val_loss: 0.4774 - val_accuracy: 0.9267\n","Epoch 96/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2055 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.9277\n","Epoch 97/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.2048 - accuracy: 1.0000 - val_loss: 0.4724 - val_accuracy: 0.9256\n","Epoch 98/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.2035 - accuracy: 1.0000 - val_loss: 0.4879 - val_accuracy: 0.9153\n","Epoch 99/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2026 - accuracy: 1.0000 - val_loss: 0.4721 - val_accuracy: 0.9277\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2017 - accuracy: 1.0000 - val_loss: 0.4771 - val_accuracy: 0.9225\n","{'loss': [0.31533083319664, 0.29766881465911865, 0.29155993461608887, 0.286726176738739, 0.2855091691017151, 0.28525787591934204, 0.2816118597984314, 0.28093379735946655, 0.2789837121963501, 0.2780490517616272, 0.2768232226371765, 0.2761871814727783, 0.27643653750419617, 0.2751445472240448, 0.27417320013046265, 0.27274090051651, 0.27220287919044495, 0.2715897560119629, 0.2724834680557251, 0.2693275213241577, 0.2691270411014557, 0.2694530785083771, 0.26793375611305237, 0.2674883008003235, 0.26657363772392273, 0.2662718892097473, 0.26520001888275146, 0.26352596282958984, 0.26278403401374817, 0.2631010413169861, 0.2616300880908966, 0.26003655791282654, 0.2605460286140442, 0.25917956233024597, 0.2575654685497284, 0.2569634020328522, 0.25599557161331177, 0.2550605535507202, 0.2554921507835388, 0.2539054751396179, 0.2547833323478699, 0.25227415561676025, 0.2515414357185364, 0.2503850758075714, 0.2496095597743988, 0.24867193400859833, 0.24873322248458862, 0.247139111161232, 0.24618901312351227, 0.24547487497329712, 0.24460582435131073, 0.24359847605228424, 0.24462935328483582, 0.24366332590579987, 0.2416456639766693, 0.2404838502407074, 0.2397630512714386, 0.23870986700057983, 0.23802167177200317, 0.23719534277915955, 0.23639027774333954, 0.23576852679252625, 0.2343296855688095, 0.23391789197921753, 0.2331172227859497, 0.23256444931030273, 0.233775794506073, 0.2302878350019455, 0.229261115193367, 0.22837984561920166, 0.22749096155166626, 0.2265937626361847, 0.2259175181388855, 0.22692705690860748, 0.22494745254516602, 0.2231767773628235, 0.22223716974258423, 0.22170193493366241, 0.22126884758472443, 0.21980784833431244, 0.21905741095542908, 0.21832334995269775, 0.21709023416042328, 0.2162562757730484, 0.21523669362068176, 0.21452102065086365, 0.2136569619178772, 0.2126307189464569, 0.21213988959789276, 0.2108469158411026, 0.20983178913593292, 0.20906656980514526, 0.20826923847198486, 0.20791466534137726, 0.20639972388744354, 0.20548592507839203, 0.2047683745622635, 0.20354633033275604, 0.20260784029960632, 0.20171327888965607], 'accuracy': [0.985788106918335, 0.9925064444541931, 0.997157633304596, 0.9976744055747986, 0.9979327917098999, 0.9984496235847473, 0.99896639585495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 0.9994832277297974, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997416138648987, 0.9997416138648987, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [1.0166682004928589, 1.0139248371124268, 1.0091755390167236, 0.9929489493370056, 0.9943126440048218, 0.9479393362998962, 0.9164333343505859, 0.8584374785423279, 0.8084525465965271, 0.7394568920135498, 0.6964030861854553, 0.6548529267311096, 0.5690712332725525, 0.5228019952774048, 0.5282980799674988, 0.5194931626319885, 0.46772879362106323, 0.5059311389923096, 0.47030237317085266, 0.456104576587677, 0.4527667164802551, 0.45840752124786377, 0.4583320915699005, 0.47576904296875, 0.49609991908073425, 0.48823416233062744, 0.4932210445404053, 0.48760783672332764, 0.4881640374660492, 0.4894806146621704, 0.4876320958137512, 0.4987829625606537, 0.5074633359909058, 0.4883061349391937, 0.4862574338912964, 0.4909074008464813, 0.48925623297691345, 0.5000535249710083, 0.5020503401756287, 0.5072017312049866, 0.5092277526855469, 0.4882601797580719, 0.48922818899154663, 0.48631933331489563, 0.49202778935432434, 0.4907021224498749, 0.49473440647125244, 0.49331459403038025, 0.4899104833602905, 0.5009303092956543, 0.4871721565723419, 0.48701950907707214, 0.5204490423202515, 0.5051466822624207, 0.4895252287387848, 0.4971190392971039, 0.4863111972808838, 0.4902324080467224, 0.48630964756011963, 0.4881476163864136, 0.49812665581703186, 0.4826555550098419, 0.49036699533462524, 0.493216872215271, 0.48912307620048523, 0.48660439252853394, 0.49618151783943176, 0.48750588297843933, 0.4857279360294342, 0.4848783612251282, 0.48853030800819397, 0.4864378273487091, 0.49052345752716064, 0.5107252597808838, 0.478207528591156, 0.4829704165458679, 0.48119837045669556, 0.48674479126930237, 0.48423895239830017, 0.4801558256149292, 0.4809982478618622, 0.48449236154556274, 0.49290844798088074, 0.47727805376052856, 0.4828996956348419, 0.47489839792251587, 0.47797515988349915, 0.4754166305065155, 0.48693132400512695, 0.4758025109767914, 0.48589470982551575, 0.48649993538856506, 0.48694053292274475, 0.48930826783180237, 0.4774392545223236, 0.4748741686344147, 0.4723508656024933, 0.4878510534763336, 0.4720662534236908, 0.4771353006362915], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.4948347210884094, 0.4969008266925812, 0.5185950398445129, 0.5444214940071106, 0.5991735458374023, 0.6611570119857788, 0.7252066135406494, 0.7706611752510071, 0.8109503984451294, 0.8832644820213318, 0.91425621509552, 0.8935950398445129, 0.8915289044380188, 0.9245867729187012, 0.8987603187561035, 0.9256198406219482, 0.9349173307418823, 0.9297520518302917, 0.93388432264328, 0.9390496015548706, 0.9276859760284424, 0.9256198406219482, 0.9276859760284424, 0.9307851195335388, 0.9297520518302917, 0.9276859760284424, 0.932851254940033, 0.9307851195335388, 0.922520637512207, 0.922520637512207, 0.93388432264328, 0.932851254940033, 0.932851254940033, 0.9359503984451294, 0.9266529083251953, 0.9256198406219482, 0.922520637512207, 0.9287189841270447, 0.9307851195335388, 0.9369834661483765, 0.9359503984451294, 0.9276859760284424, 0.9307851195335388, 0.9276859760284424, 0.9318181872367859, 0.9349173307418823, 0.9287189841270447, 0.9318181872367859, 0.9318181872367859, 0.9152892827987671, 0.9204545617103577, 0.9297520518302917, 0.9235537052154541, 0.9318181872367859, 0.9276859760284424, 0.9318181872367859, 0.9307851195335388, 0.9235537052154541, 0.932851254940033, 0.9287189841270447, 0.9318181872367859, 0.9318181872367859, 0.9266529083251953, 0.9245867729187012, 0.9307851195335388, 0.9318181872367859, 0.9297520518302917, 0.9276859760284424, 0.9307851195335388, 0.9256198406219482, 0.9183884263038635, 0.9307851195335388, 0.9245867729187012, 0.9297520518302917, 0.9276859760284424, 0.9276859760284424, 0.9276859760284424, 0.9235537052154541, 0.9266529083251953, 0.9152892827987671, 0.9307851195335388, 0.9287189841270447, 0.9287189841270447, 0.9297520518302917, 0.9287189841270447, 0.922520637512207, 0.9276859760284424, 0.9214876294136047, 0.9173553586006165, 0.9194214940071106, 0.913223147392273, 0.9266529083251953, 0.9276859760284424, 0.9256198406219482, 0.9152892827987671, 0.9276859760284424, 0.922520637512207]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 4s 34ms/step - loss: 0.2168 - accuracy: 0.9930 - val_loss: 0.9486 - val_accuracy: 0.4849\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.2028 - accuracy: 1.0000"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 1s 22ms/step - loss: 0.2041 - accuracy: 0.9981 - val_loss: 0.9378 - val_accuracy: 0.4871\n","Epoch 3/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2021 - accuracy: 0.9989 - val_loss: 0.9308 - val_accuracy: 0.4892\n","Epoch 4/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2027 - accuracy: 0.9992 - val_loss: 0.9155 - val_accuracy: 0.4935\n","Epoch 5/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2005 - accuracy: 0.9995 - val_loss: 0.8928 - val_accuracy: 0.5032\n","Epoch 6/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1997 - accuracy: 0.9997 - val_loss: 0.8647 - val_accuracy: 0.5226\n","Epoch 7/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1989 - accuracy: 0.9995 - val_loss: 0.8458 - val_accuracy: 0.5463\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1987 - accuracy: 0.9995 - val_loss: 0.7878 - val_accuracy: 0.5981\n","Epoch 9/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1977 - accuracy: 0.9997 - val_loss: 0.7269 - val_accuracy: 0.6530\n","Epoch 10/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1966 - accuracy: 1.0000 - val_loss: 0.7194 - val_accuracy: 0.6616\n","Epoch 11/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.1968 - accuracy: 0.9997 - val_loss: 0.6197 - val_accuracy: 0.7489\n","Epoch 12/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1962 - accuracy: 1.0000 - val_loss: 0.5940 - val_accuracy: 0.7651\n","Epoch 13/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1955 - accuracy: 0.9997 - val_loss: 0.5017 - val_accuracy: 0.8879\n","Epoch 14/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1950 - accuracy: 1.0000 - val_loss: 0.4929 - val_accuracy: 0.8761\n","Epoch 15/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1943 - accuracy: 0.9997 - val_loss: 0.4451 - val_accuracy: 0.9116\n","Epoch 16/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1942 - accuracy: 1.0000 - val_loss: 0.3928 - val_accuracy: 0.9343\n","Epoch 17/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1934 - accuracy: 1.0000 - val_loss: 0.4021 - val_accuracy: 0.9300\n","Epoch 18/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1931 - accuracy: 1.0000 - val_loss: 0.3588 - val_accuracy: 0.9429\n","Epoch 19/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1928 - accuracy: 1.0000 - val_loss: 0.3366 - val_accuracy: 0.9472\n","Epoch 20/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1920 - accuracy: 0.9997 - val_loss: 0.3479 - val_accuracy: 0.9461\n","Epoch 21/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1916 - accuracy: 1.0000 - val_loss: 0.3267 - val_accuracy: 0.9494\n","Epoch 22/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1908 - accuracy: 1.0000 - val_loss: 0.3415 - val_accuracy: 0.9483\n","Epoch 23/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1910 - accuracy: 1.0000 - val_loss: 0.3262 - val_accuracy: 0.9526\n","Epoch 24/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.1898 - accuracy: 1.0000 - val_loss: 0.3276 - val_accuracy: 0.9515\n","Epoch 25/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.1894 - accuracy: 0.9997 - val_loss: 0.3310 - val_accuracy: 0.9494\n","Epoch 26/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1889 - accuracy: 1.0000 - val_loss: 0.3301 - val_accuracy: 0.9526\n","Epoch 27/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1883 - accuracy: 1.0000 - val_loss: 0.3382 - val_accuracy: 0.9515\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1889 - accuracy: 0.9997 - val_loss: 0.3360 - val_accuracy: 0.9537\n","Epoch 29/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1874 - accuracy: 1.0000 - val_loss: 0.3369 - val_accuracy: 0.9580\n","Epoch 30/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1867 - accuracy: 1.0000 - val_loss: 0.3398 - val_accuracy: 0.9504\n","Epoch 31/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1859 - accuracy: 1.0000 - val_loss: 0.3403 - val_accuracy: 0.9515\n","Epoch 32/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1852 - accuracy: 1.0000 - val_loss: 0.3413 - val_accuracy: 0.9504\n","Epoch 33/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1847 - accuracy: 1.0000 - val_loss: 0.3425 - val_accuracy: 0.9526\n","Epoch 34/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1841 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.9526\n","Epoch 35/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.1840 - accuracy: 1.0000 - val_loss: 0.3468 - val_accuracy: 0.9515\n","Epoch 36/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.1830 - accuracy: 1.0000 - val_loss: 0.3444 - val_accuracy: 0.9526\n","Epoch 37/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1824 - accuracy: 1.0000 - val_loss: 0.3503 - val_accuracy: 0.9526\n","Epoch 38/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1817 - accuracy: 1.0000 - val_loss: 0.3475 - val_accuracy: 0.9515\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1817 - accuracy: 0.9997 - val_loss: 0.3439 - val_accuracy: 0.9515\n","Epoch 40/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1805 - accuracy: 1.0000 - val_loss: 0.3485 - val_accuracy: 0.9526\n","Epoch 41/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.1798 - accuracy: 1.0000 - val_loss: 0.3499 - val_accuracy: 0.9504\n","Epoch 42/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1793 - accuracy: 1.0000 - val_loss: 0.3466 - val_accuracy: 0.9515\n","Epoch 43/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1786 - accuracy: 1.0000 - val_loss: 0.3509 - val_accuracy: 0.9504\n","Epoch 44/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.1783 - accuracy: 1.0000 - val_loss: 0.3465 - val_accuracy: 0.9515\n","Epoch 45/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.1777 - accuracy: 1.0000 - val_loss: 0.3532 - val_accuracy: 0.9526\n","Epoch 46/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1770 - accuracy: 1.0000 - val_loss: 0.3513 - val_accuracy: 0.9515\n","Epoch 47/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1764 - accuracy: 1.0000 - val_loss: 0.3464 - val_accuracy: 0.9494\n","Epoch 48/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.1756 - accuracy: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.9504\n","Epoch 49/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.1748 - accuracy: 1.0000 - val_loss: 0.3451 - val_accuracy: 0.9504\n","Epoch 50/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.1743 - accuracy: 1.0000 - val_loss: 0.3444 - val_accuracy: 0.9494\n","Epoch 51/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1735 - accuracy: 1.0000 - val_loss: 0.3465 - val_accuracy: 0.9483\n","Epoch 52/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1729 - accuracy: 1.0000 - val_loss: 0.3453 - val_accuracy: 0.9494\n","Epoch 53/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1723 - accuracy: 1.0000 - val_loss: 0.3492 - val_accuracy: 0.9494\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1718 - accuracy: 1.0000 - val_loss: 0.3462 - val_accuracy: 0.9504\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1709 - accuracy: 1.0000 - val_loss: 0.3450 - val_accuracy: 0.9472\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1702 - accuracy: 1.0000 - val_loss: 0.3482 - val_accuracy: 0.9494\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1695 - accuracy: 1.0000 - val_loss: 0.3455 - val_accuracy: 0.9461\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1689 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.9504\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1680 - accuracy: 1.0000 - val_loss: 0.3466 - val_accuracy: 0.9483\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1673 - accuracy: 1.0000 - val_loss: 0.3466 - val_accuracy: 0.9494\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1666 - accuracy: 1.0000 - val_loss: 0.3444 - val_accuracy: 0.9504\n","Epoch 62/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1660 - accuracy: 1.0000 - val_loss: 0.3457 - val_accuracy: 0.9494\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1652 - accuracy: 1.0000 - val_loss: 0.3443 - val_accuracy: 0.9450\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1647 - accuracy: 1.0000 - val_loss: 0.3432 - val_accuracy: 0.9483\n","Epoch 65/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1638 - accuracy: 1.0000 - val_loss: 0.3433 - val_accuracy: 0.9483\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1632 - accuracy: 1.0000 - val_loss: 0.3490 - val_accuracy: 0.9483\n","Epoch 67/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.1624 - accuracy: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.9494\n","Epoch 68/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1617 - accuracy: 1.0000 - val_loss: 0.3433 - val_accuracy: 0.9450\n","Epoch 69/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1611 - accuracy: 1.0000 - val_loss: 0.3412 - val_accuracy: 0.9461\n","Epoch 70/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.1605 - accuracy: 1.0000 - val_loss: 0.3446 - val_accuracy: 0.9440\n","Epoch 71/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.1595 - accuracy: 1.0000 - val_loss: 0.3416 - val_accuracy: 0.9450\n","Epoch 72/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1588 - accuracy: 1.0000 - val_loss: 0.3446 - val_accuracy: 0.9494\n","Epoch 73/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1582 - accuracy: 1.0000 - val_loss: 0.3443 - val_accuracy: 0.9440\n","Epoch 74/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1574 - accuracy: 1.0000 - val_loss: 0.3414 - val_accuracy: 0.9440\n","Epoch 75/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.1565 - accuracy: 1.0000 - val_loss: 0.3407 - val_accuracy: 0.9440\n","Epoch 76/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.1559 - accuracy: 1.0000 - val_loss: 0.3441 - val_accuracy: 0.9418\n","Epoch 77/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1552 - accuracy: 1.0000 - val_loss: 0.3406 - val_accuracy: 0.9429\n","Epoch 78/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.1545 - accuracy: 1.0000 - val_loss: 0.3603 - val_accuracy: 0.9375\n","Epoch 79/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1540 - accuracy: 1.0000 - val_loss: 0.3443 - val_accuracy: 0.9450\n","Epoch 80/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1530 - accuracy: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.9472\n","Epoch 81/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1522 - accuracy: 1.0000 - val_loss: 0.3414 - val_accuracy: 0.9450\n","Epoch 82/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1514 - accuracy: 1.0000 - val_loss: 0.3411 - val_accuracy: 0.9440\n","Epoch 83/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1507 - accuracy: 1.0000 - val_loss: 0.3401 - val_accuracy: 0.9418\n","Epoch 84/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1501 - accuracy: 1.0000 - val_loss: 0.3466 - val_accuracy: 0.9418\n","Epoch 85/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.1494 - accuracy: 1.0000 - val_loss: 0.3416 - val_accuracy: 0.9429\n","Epoch 86/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1485 - accuracy: 1.0000 - val_loss: 0.3404 - val_accuracy: 0.9429\n","Epoch 87/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.1477 - accuracy: 1.0000 - val_loss: 0.3413 - val_accuracy: 0.9440\n","Epoch 88/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1470 - accuracy: 1.0000 - val_loss: 0.3412 - val_accuracy: 0.9483\n","Epoch 89/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1462 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.9407\n","Epoch 90/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1456 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 0.9461\n","Epoch 91/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1447 - accuracy: 1.0000 - val_loss: 0.3397 - val_accuracy: 0.9440\n","Epoch 92/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1440 - accuracy: 1.0000 - val_loss: 0.3395 - val_accuracy: 0.9440\n","Epoch 93/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1433 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.9418\n","Epoch 94/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1428 - accuracy: 1.0000 - val_loss: 0.3404 - val_accuracy: 0.9429\n","Epoch 95/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1419 - accuracy: 1.0000 - val_loss: 0.3451 - val_accuracy: 0.9450\n","Epoch 96/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1412 - accuracy: 1.0000 - val_loss: 0.3438 - val_accuracy: 0.9397\n","Epoch 97/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.1404 - accuracy: 1.0000 - val_loss: 0.3440 - val_accuracy: 0.9429\n","Epoch 98/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1395 - accuracy: 1.0000 - val_loss: 0.3412 - val_accuracy: 0.9450\n","Epoch 99/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.1388 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.9440\n","Epoch 100/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1382 - accuracy: 1.0000 - val_loss: 0.3422 - val_accuracy: 0.9418\n","{'loss': [0.21675707399845123, 0.2040509581565857, 0.20211319625377655, 0.20269140601158142, 0.20053480565547943, 0.1996677666902542, 0.1988905817270279, 0.19869297742843628, 0.197727233171463, 0.19659467041492462, 0.1968129426240921, 0.1961948573589325, 0.19546765089035034, 0.19499552249908447, 0.19433297216892242, 0.1942419409751892, 0.19344376027584076, 0.19307774305343628, 0.19283948838710785, 0.1920100450515747, 0.1916474997997284, 0.1908184438943863, 0.19095012545585632, 0.18975865840911865, 0.1894175410270691, 0.18886259198188782, 0.18833181262016296, 0.1889466941356659, 0.1873847395181656, 0.1866716742515564, 0.18585343658924103, 0.18522605299949646, 0.18468396365642548, 0.18412457406520844, 0.18396806716918945, 0.18297742307186127, 0.1824183315038681, 0.18167288601398468, 0.18172340095043182, 0.1804608702659607, 0.1798078566789627, 0.17928001284599304, 0.17859481275081635, 0.1782936453819275, 0.17773756384849548, 0.17696313560009003, 0.1763882339000702, 0.17555490136146545, 0.1747773438692093, 0.1743127405643463, 0.17347829043865204, 0.17286935448646545, 0.1722797155380249, 0.17177920043468475, 0.1708804965019226, 0.17018063366413116, 0.16949614882469177, 0.16894038021564484, 0.16803014278411865, 0.16727350652217865, 0.16662417352199554, 0.16603516042232513, 0.16523435711860657, 0.16471411287784576, 0.1638135015964508, 0.16315612196922302, 0.1623842567205429, 0.16168129444122314, 0.16112712025642395, 0.1605442315340042, 0.15947069227695465, 0.15883973240852356, 0.15815778076648712, 0.15738385915756226, 0.15654520690441132, 0.15593479573726654, 0.15516984462738037, 0.15449528396129608, 0.1540435254573822, 0.15303131937980652, 0.1522088199853897, 0.15141478180885315, 0.15068350732326508, 0.15006130933761597, 0.1494014710187912, 0.14847694337368011, 0.1476982980966568, 0.14699164032936096, 0.14624017477035522, 0.14558584988117218, 0.14472344517707825, 0.1439981311559677, 0.14330387115478516, 0.14283296465873718, 0.14190474152565002, 0.14116841554641724, 0.14037032425403595, 0.13953492045402527, 0.13877615332603455, 0.13822582364082336], 'accuracy': [0.9929956793785095, 0.9981142282485962, 0.9989224076271057, 0.9991918206214905, 0.9994612336158752, 0.9997305870056152, 0.9994612336158752, 0.9994612336158752, 0.9997305870056152, 1.0, 0.9997305870056152, 1.0, 0.9997305870056152, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.9485892057418823, 0.9377985596656799, 0.9307723045349121, 0.9155324697494507, 0.8928000926971436, 0.8646973967552185, 0.8457993865013123, 0.7877932190895081, 0.7268524169921875, 0.7194413542747498, 0.619736909866333, 0.5939768552780151, 0.5017479062080383, 0.49285757541656494, 0.4450536370277405, 0.39279401302337646, 0.40210461616516113, 0.3588235676288605, 0.3365577161312103, 0.34793561697006226, 0.3267005383968353, 0.3415301740169525, 0.3262166380882263, 0.3276415169239044, 0.3310467302799225, 0.33006006479263306, 0.3382033705711365, 0.3359890282154083, 0.33694037795066833, 0.33978569507598877, 0.34026581048965454, 0.34129104018211365, 0.34247133135795593, 0.35071155428886414, 0.34677693247795105, 0.34443211555480957, 0.35032323002815247, 0.3475121557712555, 0.34388524293899536, 0.3485116958618164, 0.34991106390953064, 0.3465532660484314, 0.3509250283241272, 0.3465120196342468, 0.3531516194343567, 0.35131362080574036, 0.34644410014152527, 0.3473421633243561, 0.34509751200675964, 0.34439027309417725, 0.34645912051200867, 0.34528374671936035, 0.3491567075252533, 0.34615233540534973, 0.34500133991241455, 0.3481716811656952, 0.3455047011375427, 0.3436092734336853, 0.34659430384635925, 0.3466435372829437, 0.34443843364715576, 0.3456583321094513, 0.3443385064601898, 0.34316641092300415, 0.343315064907074, 0.3490135073661804, 0.3472588062286377, 0.34333062171936035, 0.3411894738674164, 0.34457331895828247, 0.34164848923683167, 0.34464287757873535, 0.3443152904510498, 0.3414199948310852, 0.34071603417396545, 0.34411337971687317, 0.34055519104003906, 0.36033132672309875, 0.3442847728729248, 0.34387481212615967, 0.34142789244651794, 0.34107527136802673, 0.3400523066520691, 0.3465605080127716, 0.3416215181350708, 0.3403923213481903, 0.3413444459438324, 0.34120267629623413, 0.34265390038490295, 0.3395821154117584, 0.339669793844223, 0.33947911858558655, 0.3420388996601105, 0.3403584063053131, 0.3451286852359772, 0.3438176214694977, 0.343987375497818, 0.34116795659065247, 0.34269753098487854, 0.34218883514404297], 'val_accuracy': [0.48491379618644714, 0.48706895112991333, 0.4892241358757019, 0.49353447556495667, 0.5032327771186829, 0.5226293206214905, 0.5463362336158752, 0.5980603694915771, 0.6530172228813171, 0.6616379022598267, 0.7489224076271057, 0.7650862336158752, 0.8879310488700867, 0.8760775923728943, 0.9116379022598267, 0.9342672228813171, 0.9299569129943848, 0.9428879022598267, 0.9471982717514038, 0.9461206793785095, 0.9493534564971924, 0.9482758641242981, 0.9525862336158752, 0.951508641242981, 0.9493534564971924, 0.9525862336158752, 0.951508641242981, 0.9536637663841248, 0.9579741358757019, 0.9504310488700867, 0.951508641242981, 0.9504310488700867, 0.9525862336158752, 0.9525862336158752, 0.951508641242981, 0.9525862336158752, 0.9525862336158752, 0.951508641242981, 0.951508641242981, 0.9525862336158752, 0.9504310488700867, 0.951508641242981, 0.9504310488700867, 0.951508641242981, 0.9525862336158752, 0.951508641242981, 0.9493534564971924, 0.9504310488700867, 0.9504310488700867, 0.9493534564971924, 0.9482758641242981, 0.9493534564971924, 0.9493534564971924, 0.9504310488700867, 0.9471982717514038, 0.9493534564971924, 0.9461206793785095, 0.9504310488700867, 0.9482758641242981, 0.9493534564971924, 0.9504310488700867, 0.9493534564971924, 0.9450430870056152, 0.9482758641242981, 0.9482758641242981, 0.9482758641242981, 0.9493534564971924, 0.9450430870056152, 0.9461206793785095, 0.943965494632721, 0.9450430870056152, 0.9493534564971924, 0.943965494632721, 0.943965494632721, 0.943965494632721, 0.9418103694915771, 0.9428879022598267, 0.9375, 0.9450430870056152, 0.9471982717514038, 0.9450430870056152, 0.943965494632721, 0.9418103694915771, 0.9418103694915771, 0.9428879022598267, 0.9428879022598267, 0.943965494632721, 0.9482758641242981, 0.9407327771186829, 0.9461206793785095, 0.943965494632721, 0.943965494632721, 0.9418103694915771, 0.9428879022598267, 0.9450430870056152, 0.9396551847457886, 0.9428879022598267, 0.9450430870056152, 0.943965494632721, 0.9418103694915771]}\n","38/38 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 3s 29ms/step - loss: 0.2219 - accuracy: 0.9915 - val_loss: 0.9313 - val_accuracy: 0.4966\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.2087 - accuracy: 1.0000"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 16ms/step - loss: 0.2054 - accuracy: 0.9980 - val_loss: 0.9306 - val_accuracy: 0.4977\n","Epoch 3/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2020 - accuracy: 0.9994 - val_loss: 0.9268 - val_accuracy: 0.4989\n","Epoch 4/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2012 - accuracy: 0.9997 - val_loss: 0.9117 - val_accuracy: 0.5034\n","Epoch 5/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2003 - accuracy: 0.9997 - val_loss: 0.8760 - val_accuracy: 0.5158\n","Epoch 6/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1999 - accuracy: 0.9997 - val_loss: 0.8610 - val_accuracy: 0.5362\n","Epoch 7/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1989 - accuracy: 1.0000 - val_loss: 0.8254 - val_accuracy: 0.5611\n","Epoch 8/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1983 - accuracy: 1.0000 - val_loss: 0.7810 - val_accuracy: 0.6018\n","Epoch 9/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1976 - accuracy: 1.0000 - val_loss: 0.7317 - val_accuracy: 0.6301\n","Epoch 10/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1970 - accuracy: 1.0000 - val_loss: 0.6854 - val_accuracy: 0.6799\n","Epoch 11/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.1966 - accuracy: 1.0000 - val_loss: 0.6083 - val_accuracy: 0.7862\n","Epoch 12/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.1962 - accuracy: 1.0000 - val_loss: 0.5701 - val_accuracy: 0.8224\n","Epoch 13/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1956 - accuracy: 1.0000 - val_loss: 0.5293 - val_accuracy: 0.8484\n","Epoch 14/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.1953 - accuracy: 1.0000 - val_loss: 0.4630 - val_accuracy: 0.9095\n","Epoch 15/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1949 - accuracy: 1.0000 - val_loss: 0.4404 - val_accuracy: 0.9152\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1943 - accuracy: 1.0000 - val_loss: 0.4054 - val_accuracy: 0.9310\n","Epoch 17/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1937 - accuracy: 1.0000 - val_loss: 0.3847 - val_accuracy: 0.9355\n","Epoch 18/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1933 - accuracy: 1.0000 - val_loss: 0.3461 - val_accuracy: 0.9457\n","Epoch 19/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.1930 - accuracy: 1.0000 - val_loss: 0.3486 - val_accuracy: 0.9434\n","Epoch 20/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1925 - accuracy: 1.0000 - val_loss: 0.3286 - val_accuracy: 0.9457\n","Epoch 21/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.1919 - accuracy: 1.0000 - val_loss: 0.3266 - val_accuracy: 0.9434\n","Epoch 22/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1916 - accuracy: 1.0000 - val_loss: 0.3252 - val_accuracy: 0.9457\n","Epoch 23/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1907 - accuracy: 1.0000 - val_loss: 0.3175 - val_accuracy: 0.9457\n","Epoch 24/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.1901 - accuracy: 1.0000 - val_loss: 0.3154 - val_accuracy: 0.9446\n","Epoch 25/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1896 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.9457\n","Epoch 26/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1893 - accuracy: 1.0000 - val_loss: 0.3241 - val_accuracy: 0.9468\n","Epoch 27/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.1884 - accuracy: 1.0000 - val_loss: 0.3171 - val_accuracy: 0.9446\n","Epoch 28/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1881 - accuracy: 1.0000 - val_loss: 0.3192 - val_accuracy: 0.9457\n","Epoch 29/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1874 - accuracy: 1.0000 - val_loss: 0.3224 - val_accuracy: 0.9514\n","Epoch 30/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.1870 - accuracy: 1.0000 - val_loss: 0.3208 - val_accuracy: 0.9480\n","Epoch 31/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1864 - accuracy: 1.0000 - val_loss: 0.3250 - val_accuracy: 0.9491\n","Epoch 32/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1861 - accuracy: 1.0000 - val_loss: 0.3257 - val_accuracy: 0.9434\n","Epoch 33/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1856 - accuracy: 1.0000 - val_loss: 0.3251 - val_accuracy: 0.9457\n","Epoch 34/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.1845 - accuracy: 1.0000 - val_loss: 0.3277 - val_accuracy: 0.9468\n","Epoch 35/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.1839 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.9502\n","Epoch 36/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1834 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9502\n","Epoch 37/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.1826 - accuracy: 1.0000 - val_loss: 0.3379 - val_accuracy: 0.9491\n","Epoch 38/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1821 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.9468\n","Epoch 39/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1815 - accuracy: 1.0000 - val_loss: 0.3333 - val_accuracy: 0.9502\n","Epoch 40/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.1810 - accuracy: 1.0000 - val_loss: 0.3337 - val_accuracy: 0.9502\n","Epoch 41/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1803 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9502\n","Epoch 42/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1796 - accuracy: 1.0000 - val_loss: 0.3309 - val_accuracy: 0.9480\n","Epoch 43/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1791 - accuracy: 1.0000 - val_loss: 0.3281 - val_accuracy: 0.9457\n","Epoch 44/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1784 - accuracy: 1.0000 - val_loss: 0.3308 - val_accuracy: 0.9502\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1777 - accuracy: 1.0000 - val_loss: 0.3456 - val_accuracy: 0.9457\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1771 - accuracy: 1.0000 - val_loss: 0.3295 - val_accuracy: 0.9491\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1764 - accuracy: 1.0000 - val_loss: 0.3313 - val_accuracy: 0.9446\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1757 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.9480\n","Epoch 49/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1752 - accuracy: 1.0000 - val_loss: 0.3291 - val_accuracy: 0.9468\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1744 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.9468\n","Epoch 51/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.1738 - accuracy: 1.0000 - val_loss: 0.3317 - val_accuracy: 0.9457\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1733 - accuracy: 1.0000 - val_loss: 0.3332 - val_accuracy: 0.9480\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1723 - accuracy: 1.0000 - val_loss: 0.3428 - val_accuracy: 0.9434\n","Epoch 54/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.1717 - accuracy: 1.0000 - val_loss: 0.3459 - val_accuracy: 0.9446\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1711 - accuracy: 1.0000 - val_loss: 0.3386 - val_accuracy: 0.9412\n","Epoch 56/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.1707 - accuracy: 1.0000 - val_loss: 0.3260 - val_accuracy: 0.9412\n","Epoch 57/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1697 - accuracy: 1.0000 - val_loss: 0.3310 - val_accuracy: 0.9457\n","Epoch 58/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1690 - accuracy: 1.0000 - val_loss: 0.3314 - val_accuracy: 0.9457\n","Epoch 59/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1684 - accuracy: 1.0000 - val_loss: 0.3255 - val_accuracy: 0.9412\n","Epoch 60/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1676 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9457\n","Epoch 61/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.1670 - accuracy: 1.0000 - val_loss: 0.3690 - val_accuracy: 0.9367\n","Epoch 62/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1679 - accuracy: 1.0000 - val_loss: 0.3597 - val_accuracy: 0.9389\n","Epoch 63/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1661 - accuracy: 1.0000 - val_loss: 0.3505 - val_accuracy: 0.9434\n","Epoch 64/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1649 - accuracy: 1.0000 - val_loss: 0.3319 - val_accuracy: 0.9457\n","Epoch 65/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1642 - accuracy: 1.0000 - val_loss: 0.3263 - val_accuracy: 0.9412\n","Epoch 66/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1635 - accuracy: 1.0000 - val_loss: 0.3321 - val_accuracy: 0.9434\n","Epoch 67/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1627 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.9446\n","Epoch 68/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1619 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.9434\n","Epoch 69/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1615 - accuracy: 1.0000 - val_loss: 0.3273 - val_accuracy: 0.9389\n","Epoch 70/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1607 - accuracy: 1.0000 - val_loss: 0.3247 - val_accuracy: 0.9389\n","Epoch 71/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1600 - accuracy: 1.0000 - val_loss: 0.3451 - val_accuracy: 0.9412\n","Epoch 72/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.1593 - accuracy: 1.0000 - val_loss: 0.3249 - val_accuracy: 0.9423\n","Epoch 73/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.1587 - accuracy: 1.0000 - val_loss: 0.3318 - val_accuracy: 0.9400\n","Epoch 74/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1580 - accuracy: 1.0000 - val_loss: 0.3333 - val_accuracy: 0.9389\n","Epoch 75/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1573 - accuracy: 1.0000 - val_loss: 0.3398 - val_accuracy: 0.9434\n","Epoch 76/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1565 - accuracy: 1.0000 - val_loss: 0.3208 - val_accuracy: 0.9389\n","Epoch 77/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1558 - accuracy: 1.0000 - val_loss: 0.3245 - val_accuracy: 0.9400\n","Epoch 78/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1550 - accuracy: 1.0000 - val_loss: 0.3419 - val_accuracy: 0.9400\n","Epoch 79/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1543 - accuracy: 1.0000 - val_loss: 0.3208 - val_accuracy: 0.9367\n","Epoch 80/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1539 - accuracy: 1.0000 - val_loss: 0.3273 - val_accuracy: 0.9389\n","Epoch 81/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1529 - accuracy: 1.0000 - val_loss: 0.3240 - val_accuracy: 0.9400\n","Epoch 82/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.1522 - accuracy: 1.0000 - val_loss: 0.3210 - val_accuracy: 0.9400\n","Epoch 83/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.1514 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.9389\n","Epoch 84/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.1507 - accuracy: 1.0000 - val_loss: 0.3240 - val_accuracy: 0.9412\n","Epoch 85/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1501 - accuracy: 1.0000 - val_loss: 0.3359 - val_accuracy: 0.9400\n","Epoch 86/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1495 - accuracy: 1.0000 - val_loss: 0.3167 - val_accuracy: 0.9389\n","Epoch 87/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.1486 - accuracy: 1.0000 - val_loss: 0.3307 - val_accuracy: 0.9389\n","Epoch 88/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.1478 - accuracy: 1.0000 - val_loss: 0.3524 - val_accuracy: 0.9344\n","Epoch 89/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.1473 - accuracy: 1.0000 - val_loss: 0.3402 - val_accuracy: 0.9355\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1465 - accuracy: 1.0000 - val_loss: 0.3423 - val_accuracy: 0.9367\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1459 - accuracy: 1.0000 - val_loss: 0.3245 - val_accuracy: 0.9412\n","Epoch 92/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.1452 - accuracy: 1.0000 - val_loss: 0.3317 - val_accuracy: 0.9389\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1443 - accuracy: 1.0000 - val_loss: 0.3184 - val_accuracy: 0.9389\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1437 - accuracy: 1.0000 - val_loss: 0.3368 - val_accuracy: 0.9367\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1428 - accuracy: 1.0000 - val_loss: 0.3158 - val_accuracy: 0.9378\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1422 - accuracy: 1.0000 - val_loss: 0.3192 - val_accuracy: 0.9400\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1414 - accuracy: 1.0000 - val_loss: 0.3156 - val_accuracy: 0.9367\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1408 - accuracy: 1.0000 - val_loss: 0.3177 - val_accuracy: 0.9378\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1400 - accuracy: 1.0000 - val_loss: 0.3478 - val_accuracy: 0.9367\n","Epoch 100/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.1392 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9355\n","{'loss': [0.2219236046075821, 0.20541782677173615, 0.2020111232995987, 0.2012028694152832, 0.20034348964691162, 0.19988946616649628, 0.198868528008461, 0.19834797084331512, 0.1975698173046112, 0.1970343142747879, 0.19659213721752167, 0.19622313976287842, 0.19564402103424072, 0.19530613720417023, 0.1948980689048767, 0.194292351603508, 0.19366931915283203, 0.19330279529094696, 0.192995086312294, 0.19247722625732422, 0.19192396104335785, 0.191573828458786, 0.19065222144126892, 0.19010032713413239, 0.18957093358039856, 0.18934236466884613, 0.18839579820632935, 0.18814966082572937, 0.18740446865558624, 0.18695533275604248, 0.18639540672302246, 0.18609046936035156, 0.1856239140033722, 0.18448559939861298, 0.183942511677742, 0.18339276313781738, 0.1826123148202896, 0.18210692703723907, 0.18152888119220734, 0.1809607744216919, 0.18031194806098938, 0.17962397634983063, 0.17910407483577728, 0.17835280299186707, 0.17774905264377594, 0.17712430655956268, 0.17638257145881653, 0.17574161291122437, 0.17518216371536255, 0.17442207038402557, 0.17382898926734924, 0.17332634329795837, 0.172305628657341, 0.1716945916414261, 0.17105823755264282, 0.1706990748643875, 0.16965851187705994, 0.1689956933259964, 0.16841067373752594, 0.16755695641040802, 0.1670098900794983, 0.16786056756973267, 0.1661401242017746, 0.16490958631038666, 0.16421698033809662, 0.163467139005661, 0.16270777583122253, 0.16194723546504974, 0.1615118831396103, 0.16066335141658783, 0.15997716784477234, 0.15933898091316223, 0.1586565226316452, 0.1579543799161911, 0.1572612076997757, 0.15649747848510742, 0.15578949451446533, 0.1550425887107849, 0.1543188989162445, 0.15390029549598694, 0.1528802365064621, 0.1521565169095993, 0.1514461636543274, 0.15074367821216583, 0.15007469058036804, 0.14949414134025574, 0.14860786497592926, 0.147764191031456, 0.14725647866725922, 0.14649346470832825, 0.14592626690864563, 0.14515137672424316, 0.1442752480506897, 0.1436566263437271, 0.14282828569412231, 0.14222893118858337, 0.14139710366725922, 0.14078116416931152, 0.13995103538036346, 0.1392206996679306], 'accuracy': [0.9915110468864441, 0.9980192184448242, 0.9994340538978577, 0.9997170567512512, 0.9997170567512512, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.931284487247467, 0.9305621981620789, 0.9267710447311401, 0.9117039442062378, 0.8759554624557495, 0.8610369563102722, 0.8253862857818604, 0.7809686660766602, 0.7317484021186829, 0.6854326128959656, 0.6082515120506287, 0.5701232552528381, 0.5293325185775757, 0.46295464038848877, 0.4403895139694214, 0.40538522601127625, 0.3846604824066162, 0.3461332321166992, 0.34861359000205994, 0.3286178708076477, 0.3266465961933136, 0.3252454400062561, 0.31749552488327026, 0.3153538405895233, 0.3159116804599762, 0.32407623529434204, 0.31709569692611694, 0.31923171877861023, 0.3224499821662903, 0.3208264708518982, 0.32500022649765015, 0.3257104456424713, 0.32506299018859863, 0.32765501737594604, 0.33427101373672485, 0.3340553045272827, 0.33794137835502625, 0.35069942474365234, 0.33331620693206787, 0.33373236656188965, 0.3347327709197998, 0.33090776205062866, 0.32806962728500366, 0.33076080679893494, 0.34564968943595886, 0.32947981357574463, 0.3313174843788147, 0.33286088705062866, 0.32908764481544495, 0.33288848400115967, 0.3316502273082733, 0.3332093060016632, 0.3427838385105133, 0.3459225594997406, 0.33858320116996765, 0.3260425329208374, 0.3310319781303406, 0.3313619792461395, 0.32546889781951904, 0.3344345688819885, 0.36898544430732727, 0.3597235381603241, 0.35046470165252686, 0.33192679286003113, 0.3263470530509949, 0.3321153521537781, 0.33352434635162354, 0.33560484647750854, 0.32731303572654724, 0.3246849477291107, 0.3451167941093445, 0.3249422311782837, 0.3317912518978119, 0.33332133293151855, 0.3398011028766632, 0.32082733511924744, 0.32451343536376953, 0.3418576717376709, 0.32082074880599976, 0.3273078501224518, 0.32402491569519043, 0.3210201561450958, 0.327849417924881, 0.3239508271217346, 0.33592480421066284, 0.31669241189956665, 0.33069369196891785, 0.3523663878440857, 0.3402325510978699, 0.3422906696796417, 0.32454293966293335, 0.3317321836948395, 0.3184033930301666, 0.33682772517204285, 0.3158375322818756, 0.3191770911216736, 0.3156049847602844, 0.3176528513431549, 0.3477502763271332, 0.334177702665329], 'val_accuracy': [0.49660632014274597, 0.4977375566959381, 0.49886876344680786, 0.5033936500549316, 0.5158371329307556, 0.5361990928649902, 0.5610859990119934, 0.6018099784851074, 0.6300904750823975, 0.679864227771759, 0.7861990928649902, 0.8223981857299805, 0.848416268825531, 0.9095022678375244, 0.9151583909988403, 0.9309954643249512, 0.935520350933075, 0.9457013607025146, 0.9434388875961304, 0.9457013607025146, 0.9434388875961304, 0.9457013607025146, 0.9457013607025146, 0.9445701241493225, 0.9457013607025146, 0.9468325972557068, 0.9445701241493225, 0.9457013607025146, 0.9513574838638306, 0.9479637742042542, 0.9490950107574463, 0.9434388875961304, 0.9457013607025146, 0.9468325972557068, 0.9502262473106384, 0.9502262473106384, 0.9490950107574463, 0.9468325972557068, 0.9502262473106384, 0.9502262473106384, 0.9502262473106384, 0.9479637742042542, 0.9457013607025146, 0.9502262473106384, 0.9457013607025146, 0.9490950107574463, 0.9445701241493225, 0.9479637742042542, 0.9468325972557068, 0.9468325972557068, 0.9457013607025146, 0.9479637742042542, 0.9434388875961304, 0.9445701241493225, 0.9411764740943909, 0.9411764740943909, 0.9457013607025146, 0.9457013607025146, 0.9411764740943909, 0.9457013607025146, 0.9366515874862671, 0.9389140009880066, 0.9434388875961304, 0.9457013607025146, 0.9411764740943909, 0.9434388875961304, 0.9445701241493225, 0.9434388875961304, 0.9389140009880066, 0.9389140009880066, 0.9411764740943909, 0.942307710647583, 0.9400452375411987, 0.9389140009880066, 0.9434388875961304, 0.9389140009880066, 0.9400452375411987, 0.9400452375411987, 0.9366515874862671, 0.9389140009880066, 0.9400452375411987, 0.9400452375411987, 0.9389140009880066, 0.9411764740943909, 0.9400452375411987, 0.9389140009880066, 0.9389140009880066, 0.9343891143798828, 0.935520350933075, 0.9366515874862671, 0.9411764740943909, 0.9389140009880066, 0.9389140009880066, 0.9366515874862671, 0.9377828240394592, 0.9400452375411987, 0.9366515874862671, 0.9377828240394592, 0.9366515874862671, 0.935520350933075]}\n","45/45 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 3s 27ms/step - loss: 0.2253 - accuracy: 0.9886 - val_loss: 0.9528 - val_accuracy: 0.4855\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.2033 - accuracy: 1.0000"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 13ms/step - loss: 0.2074 - accuracy: 0.9982 - val_loss: 0.9517 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2039 - accuracy: 0.9995 - val_loss: 0.9416 - val_accuracy: 0.4886\n","Epoch 4/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2027 - accuracy: 0.9995 - val_loss: 0.9337 - val_accuracy: 0.4928\n","Epoch 5/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2015 - accuracy: 0.9997 - val_loss: 0.9259 - val_accuracy: 0.4979\n","Epoch 6/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2006 - accuracy: 1.0000 - val_loss: 0.8947 - val_accuracy: 0.5103\n","Epoch 7/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2006 - accuracy: 1.0000 - val_loss: 0.8444 - val_accuracy: 0.5444\n","Epoch 8/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2005 - accuracy: 1.0000 - val_loss: 0.7814 - val_accuracy: 0.5961\n","Epoch 9/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1990 - accuracy: 0.9997 - val_loss: 0.7395 - val_accuracy: 0.6477\n","Epoch 10/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1980 - accuracy: 1.0000 - val_loss: 0.7190 - val_accuracy: 0.6705\n","Epoch 11/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1994 - accuracy: 1.0000 - val_loss: 0.5823 - val_accuracy: 0.8099\n","Epoch 12/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1973 - accuracy: 1.0000 - val_loss: 0.5765 - val_accuracy: 0.7986\n","Epoch 13/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1965 - accuracy: 1.0000 - val_loss: 0.4954 - val_accuracy: 0.8678\n","Epoch 14/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1962 - accuracy: 1.0000 - val_loss: 0.4484 - val_accuracy: 0.9101\n","Epoch 15/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1958 - accuracy: 1.0000 - val_loss: 0.4398 - val_accuracy: 0.8998\n","Epoch 16/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1947 - accuracy: 1.0000 - val_loss: 0.3856 - val_accuracy: 0.9401\n","Epoch 17/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1954 - accuracy: 1.0000 - val_loss: 0.3767 - val_accuracy: 0.9421\n","Epoch 18/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.1937 - accuracy: 1.0000 - val_loss: 0.3722 - val_accuracy: 0.9390\n","Epoch 19/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1936 - accuracy: 1.0000 - val_loss: 0.3539 - val_accuracy: 0.9432\n","Epoch 20/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1930 - accuracy: 1.0000 - val_loss: 0.3505 - val_accuracy: 0.9442\n","Epoch 21/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.1926 - accuracy: 1.0000 - val_loss: 0.3538 - val_accuracy: 0.9442\n","Epoch 22/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.1917 - accuracy: 1.0000 - val_loss: 0.3536 - val_accuracy: 0.9442\n","Epoch 23/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1911 - accuracy: 1.0000 - val_loss: 0.3556 - val_accuracy: 0.9442\n","Epoch 24/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1906 - accuracy: 1.0000 - val_loss: 0.3604 - val_accuracy: 0.9432\n","Epoch 25/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.1900 - accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.9421\n","Epoch 26/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1896 - accuracy: 1.0000 - val_loss: 0.3661 - val_accuracy: 0.9452\n","Epoch 27/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.1890 - accuracy: 1.0000 - val_loss: 0.3750 - val_accuracy: 0.9432\n","Epoch 28/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.1887 - accuracy: 1.0000 - val_loss: 0.3756 - val_accuracy: 0.9421\n","Epoch 29/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1880 - accuracy: 1.0000 - val_loss: 0.3743 - val_accuracy: 0.9432\n","Epoch 30/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1874 - accuracy: 1.0000 - val_loss: 0.3703 - val_accuracy: 0.9452\n","Epoch 31/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.1868 - accuracy: 1.0000 - val_loss: 0.3804 - val_accuracy: 0.9421\n","Epoch 32/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.1870 - accuracy: 1.0000 - val_loss: 0.3766 - val_accuracy: 0.9442\n","Epoch 33/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.1864 - accuracy: 1.0000 - val_loss: 0.3817 - val_accuracy: 0.9421\n","Epoch 34/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.1856 - accuracy: 1.0000 - val_loss: 0.3798 - val_accuracy: 0.9452\n","Epoch 35/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.1846 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9432\n","Epoch 36/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.1838 - accuracy: 1.0000 - val_loss: 0.3795 - val_accuracy: 0.9432\n","Epoch 37/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1832 - accuracy: 1.0000 - val_loss: 0.3795 - val_accuracy: 0.9421\n","Epoch 38/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1832 - accuracy: 1.0000 - val_loss: 0.3761 - val_accuracy: 0.9432\n","Epoch 39/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.1825 - accuracy: 1.0000 - val_loss: 0.3786 - val_accuracy: 0.9432\n","Epoch 40/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1815 - accuracy: 1.0000 - val_loss: 0.3741 - val_accuracy: 0.9463\n","Epoch 41/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.1809 - accuracy: 1.0000 - val_loss: 0.3807 - val_accuracy: 0.9432\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1803 - accuracy: 1.0000 - val_loss: 0.3775 - val_accuracy: 0.9421\n","Epoch 43/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.1797 - accuracy: 1.0000 - val_loss: 0.3775 - val_accuracy: 0.9421\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1791 - accuracy: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.9432\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1784 - accuracy: 1.0000 - val_loss: 0.3763 - val_accuracy: 0.9411\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1778 - accuracy: 1.0000 - val_loss: 0.4118 - val_accuracy: 0.9287\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1792 - accuracy: 1.0000 - val_loss: 0.3746 - val_accuracy: 0.9452\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1769 - accuracy: 1.0000 - val_loss: 0.3935 - val_accuracy: 0.9390\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1760 - accuracy: 1.0000 - val_loss: 0.3798 - val_accuracy: 0.9442\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1754 - accuracy: 1.0000 - val_loss: 0.3791 - val_accuracy: 0.9401\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1750 - accuracy: 1.0000 - val_loss: 0.3791 - val_accuracy: 0.9411\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1739 - accuracy: 1.0000 - val_loss: 0.3867 - val_accuracy: 0.9432\n","Epoch 53/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.1737 - accuracy: 1.0000 - val_loss: 0.3786 - val_accuracy: 0.9421\n","Epoch 54/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.1733 - accuracy: 1.0000 - val_loss: 0.3768 - val_accuracy: 0.9401\n","Epoch 55/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1720 - accuracy: 1.0000 - val_loss: 0.3826 - val_accuracy: 0.9401\n","Epoch 56/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1714 - accuracy: 1.0000 - val_loss: 0.3792 - val_accuracy: 0.9411\n","Epoch 57/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.1707 - accuracy: 1.0000 - val_loss: 0.3830 - val_accuracy: 0.9390\n","Epoch 58/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.1700 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9411\n","Epoch 59/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.1695 - accuracy: 1.0000 - val_loss: 0.3860 - val_accuracy: 0.9411\n","Epoch 60/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.1687 - accuracy: 1.0000 - val_loss: 0.3818 - val_accuracy: 0.9380\n","Epoch 61/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1682 - accuracy: 1.0000 - val_loss: 0.3827 - val_accuracy: 0.9370\n","Epoch 62/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1675 - accuracy: 1.0000 - val_loss: 0.3951 - val_accuracy: 0.9411\n","Epoch 63/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1669 - accuracy: 1.0000 - val_loss: 0.3898 - val_accuracy: 0.9380\n","Epoch 64/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1665 - accuracy: 1.0000 - val_loss: 0.3752 - val_accuracy: 0.9380\n","Epoch 65/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1660 - accuracy: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.9411\n","Epoch 66/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.1648 - accuracy: 1.0000 - val_loss: 0.3758 - val_accuracy: 0.9401\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1641 - accuracy: 1.0000 - val_loss: 0.3801 - val_accuracy: 0.9380\n","Epoch 68/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.1634 - accuracy: 1.0000 - val_loss: 0.3808 - val_accuracy: 0.9390\n","Epoch 69/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1628 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.9370\n","Epoch 70/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1622 - accuracy: 1.0000 - val_loss: 0.3855 - val_accuracy: 0.9339\n","Epoch 71/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.1616 - accuracy: 1.0000 - val_loss: 0.3857 - val_accuracy: 0.9349\n","Epoch 72/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1608 - accuracy: 1.0000 - val_loss: 0.3750 - val_accuracy: 0.9401\n","Epoch 73/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1606 - accuracy: 1.0000 - val_loss: 0.3827 - val_accuracy: 0.9360\n","Epoch 74/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.1597 - accuracy: 1.0000 - val_loss: 0.3886 - val_accuracy: 0.9360\n","Epoch 75/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.1594 - accuracy: 1.0000 - val_loss: 0.3792 - val_accuracy: 0.9370\n","Epoch 76/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1580 - accuracy: 1.0000 - val_loss: 0.3838 - val_accuracy: 0.9329\n","Epoch 77/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.1575 - accuracy: 1.0000 - val_loss: 0.3791 - val_accuracy: 0.9360\n","Epoch 78/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.1565 - accuracy: 1.0000 - val_loss: 0.3749 - val_accuracy: 0.9380\n","Epoch 79/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.1558 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.9360\n","Epoch 80/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1553 - accuracy: 1.0000 - val_loss: 0.3771 - val_accuracy: 0.9390\n","Epoch 81/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.1546 - accuracy: 1.0000 - val_loss: 0.3742 - val_accuracy: 0.9370\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1542 - accuracy: 1.0000 - val_loss: 0.3748 - val_accuracy: 0.9360\n","Epoch 83/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.1531 - accuracy: 1.0000 - val_loss: 0.3728 - val_accuracy: 0.9370\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1524 - accuracy: 1.0000 - val_loss: 0.3778 - val_accuracy: 0.9360\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1519 - accuracy: 1.0000 - val_loss: 0.3736 - val_accuracy: 0.9380\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1513 - accuracy: 1.0000 - val_loss: 0.3773 - val_accuracy: 0.9339\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1505 - accuracy: 1.0000 - val_loss: 0.3700 - val_accuracy: 0.9370\n","Epoch 88/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.1500 - accuracy: 1.0000 - val_loss: 0.3963 - val_accuracy: 0.9329\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1493 - accuracy: 1.0000 - val_loss: 0.3701 - val_accuracy: 0.9370\n","Epoch 90/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.1483 - accuracy: 1.0000 - val_loss: 0.3761 - val_accuracy: 0.9329\n","Epoch 91/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.1476 - accuracy: 1.0000 - val_loss: 0.3929 - val_accuracy: 0.9298\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1469 - accuracy: 1.0000 - val_loss: 0.3703 - val_accuracy: 0.9380\n","Epoch 93/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.1469 - accuracy: 1.0000 - val_loss: 0.3658 - val_accuracy: 0.9380\n","Epoch 94/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1458 - accuracy: 1.0000 - val_loss: 0.3724 - val_accuracy: 0.9360\n","Epoch 95/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1449 - accuracy: 1.0000 - val_loss: 0.3741 - val_accuracy: 0.9360\n","Epoch 96/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1443 - accuracy: 1.0000 - val_loss: 0.3707 - val_accuracy: 0.9370\n","Epoch 97/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.1435 - accuracy: 1.0000 - val_loss: 0.3698 - val_accuracy: 0.9339\n","Epoch 98/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1427 - accuracy: 1.0000 - val_loss: 0.3784 - val_accuracy: 0.9339\n","Epoch 99/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.1424 - accuracy: 1.0000 - val_loss: 0.3662 - val_accuracy: 0.9370\n","Epoch 100/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.1414 - accuracy: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.9370\n","{'loss': [0.22530731558799744, 0.20742054283618927, 0.20391960442066193, 0.20267833769321442, 0.20150761306285858, 0.20062926411628723, 0.20064696669578552, 0.2004878669977188, 0.1990436464548111, 0.19802094995975494, 0.19942456483840942, 0.1972835659980774, 0.19646891951560974, 0.196180060505867, 0.19580063223838806, 0.1946839988231659, 0.19541959464550018, 0.19369812309741974, 0.19361114501953125, 0.19298337399959564, 0.19256514310836792, 0.1916600465774536, 0.19108471274375916, 0.1906026005744934, 0.19003009796142578, 0.1896154284477234, 0.18895961344242096, 0.1887260526418686, 0.18797288835048676, 0.1874343603849411, 0.186814546585083, 0.18700018525123596, 0.18638743460178375, 0.18560589849948883, 0.1846112608909607, 0.1837867945432663, 0.18315865099430084, 0.18316368758678436, 0.18251430988311768, 0.18150879442691803, 0.18093936145305634, 0.18032778799533844, 0.17971715331077576, 0.17913949489593506, 0.17841632664203644, 0.17778432369232178, 0.17915400862693787, 0.176935613155365, 0.17604276537895203, 0.17542584240436554, 0.17499381303787231, 0.17394402623176575, 0.17371560633182526, 0.17330065369606018, 0.17200931906700134, 0.1713746041059494, 0.1707482933998108, 0.17003342509269714, 0.1694590002298355, 0.16869404911994934, 0.16816911101341248, 0.16753236949443817, 0.16693159937858582, 0.16645804047584534, 0.16596587002277374, 0.16478295624256134, 0.16407981514930725, 0.1634453982114792, 0.16279259324073792, 0.16220314800739288, 0.1616162210702896, 0.16077882051467896, 0.1605927050113678, 0.15967801213264465, 0.1593969762325287, 0.15800079703330994, 0.15749917924404144, 0.15653875470161438, 0.1557905375957489, 0.15533439815044403, 0.15459094941616058, 0.1541714072227478, 0.15314941108226776, 0.1524433195590973, 0.15187692642211914, 0.15134172141551971, 0.15052901208400726, 0.1500340849161148, 0.1492941677570343, 0.14825516939163208, 0.14762996137142181, 0.1468886435031891, 0.14694415032863617, 0.1458130031824112, 0.1448979675769806, 0.14434325695037842, 0.14354704320430756, 0.14273998141288757, 0.14238105714321136, 0.14139705896377563], 'accuracy': [0.988630473613739, 0.998191237449646, 0.9994832277297974, 0.9994832277297974, 0.9997416138648987, 1.0, 1.0, 1.0, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.9527907967567444, 0.9516871571540833, 0.9415989518165588, 0.9336627125740051, 0.9259006381034851, 0.8947442173957825, 0.8444483876228333, 0.781423807144165, 0.7395070791244507, 0.7190417051315308, 0.5823037624359131, 0.5764619708061218, 0.4954220652580261, 0.4483630061149597, 0.43976035714149475, 0.3855907917022705, 0.37673288583755493, 0.3721969723701477, 0.3539436459541321, 0.3504771888256073, 0.3538361191749573, 0.3536109924316406, 0.35561230778694153, 0.3603906035423279, 0.36228910088539124, 0.3661283254623413, 0.37504899501800537, 0.37557804584503174, 0.3743251860141754, 0.3703446090221405, 0.380424439907074, 0.37657061219215393, 0.3817490339279175, 0.37981468439102173, 0.37933841347694397, 0.3794683516025543, 0.3794986605644226, 0.3761465847492218, 0.37856608629226685, 0.3740844130516052, 0.38067659735679626, 0.3774985074996948, 0.37747517228126526, 0.37380093336105347, 0.37632566690444946, 0.4118375778198242, 0.3746225833892822, 0.39346522092819214, 0.3798017203807831, 0.3790833652019501, 0.3791378438472748, 0.3866560757160187, 0.3785753548145294, 0.37675410509109497, 0.38257208466529846, 0.37919366359710693, 0.38300463557243347, 0.37925663590431213, 0.3860376477241516, 0.381798654794693, 0.3827432692050934, 0.39505767822265625, 0.3897848427295685, 0.37520650029182434, 0.3730134963989258, 0.375848650932312, 0.3801177740097046, 0.380808025598526, 0.38187772035598755, 0.3854978084564209, 0.3856675326824188, 0.37501031160354614, 0.3826940357685089, 0.3886284828186035, 0.37917691469192505, 0.38382163643836975, 0.379116028547287, 0.3749410808086395, 0.37565937638282776, 0.3771106004714966, 0.37421914935112, 0.3748033046722412, 0.37282249331474304, 0.37780579924583435, 0.37362611293792725, 0.3773263096809387, 0.36997950077056885, 0.3962518870830536, 0.3700594902038574, 0.3761301040649414, 0.3929211497306824, 0.3703490197658539, 0.3657970726490021, 0.3723617196083069, 0.3740612268447876, 0.3706986606121063, 0.3697702884674072, 0.3783988654613495, 0.3661916255950928, 0.36738547682762146], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.4886363744735718, 0.4927685856819153, 0.49793389439582825, 0.5103305578231812, 0.5444214940071106, 0.5960744023323059, 0.6477272510528564, 0.6704545617103577, 0.8099173307418823, 0.7985537052154541, 0.8677685856819153, 0.9101239442825317, 0.8997933864593506, 0.9400826692581177, 0.942148745059967, 0.9390496015548706, 0.9431818127632141, 0.9442148804664612, 0.9442148804664612, 0.9442148804664612, 0.9442148804664612, 0.9431818127632141, 0.942148745059967, 0.9452479481697083, 0.9431818127632141, 0.942148745059967, 0.9431818127632141, 0.9452479481697083, 0.942148745059967, 0.9442148804664612, 0.942148745059967, 0.9452479481697083, 0.9431818127632141, 0.9431818127632141, 0.942148745059967, 0.9431818127632141, 0.9431818127632141, 0.9462810158729553, 0.9431818127632141, 0.942148745059967, 0.942148745059967, 0.9431818127632141, 0.94111567735672, 0.9287189841270447, 0.9452479481697083, 0.9390496015548706, 0.9442148804664612, 0.9400826692581177, 0.94111567735672, 0.9431818127632141, 0.942148745059967, 0.9400826692581177, 0.9400826692581177, 0.94111567735672, 0.9390496015548706, 0.94111567735672, 0.94111567735672, 0.9380165338516235, 0.9369834661483765, 0.94111567735672, 0.9380165338516235, 0.9380165338516235, 0.94111567735672, 0.9400826692581177, 0.9380165338516235, 0.9390496015548706, 0.9369834661483765, 0.93388432264328, 0.9349173307418823, 0.9400826692581177, 0.9359503984451294, 0.9359503984451294, 0.9369834661483765, 0.932851254940033, 0.9359503984451294, 0.9380165338516235, 0.9359503984451294, 0.9390496015548706, 0.9369834661483765, 0.9359503984451294, 0.9369834661483765, 0.9359503984451294, 0.9380165338516235, 0.93388432264328, 0.9369834661483765, 0.932851254940033, 0.9369834661483765, 0.932851254940033, 0.9297520518302917, 0.9380165338516235, 0.9380165338516235, 0.9359503984451294, 0.9359503984451294, 0.9369834661483765, 0.93388432264328, 0.93388432264328, 0.9369834661483765, 0.9369834661483765]}\n","32/32 [==============================] - 0s 2ms/step\n"]}],"source":["global_model_CNN, metrics_df_CNN = federated_learning(Theta_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"elapsed":40,"status":"ok","timestamp":1717400048471,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"},"user_tz":-360},"id":"y3RXIk-qZ7ts","outputId":"d2a98ce3-bc5c-411f-d91a-3ec8dd3c29e6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.747      0.747   0.747  0.747        0.747        0.747   \n","1        1     0.792      0.805   0.771  0.788        0.771        0.814   \n","2        2     0.736      0.709   0.799  0.752        0.799        0.673   \n","3        0     0.798      0.791   0.811  0.801        0.811        0.786   \n","4        1     0.849      0.853   0.843  0.848        0.843        0.855   \n","5        2     0.806      0.806   0.807  0.806        0.807        0.805   \n","6        0     0.838      0.817   0.869  0.843        0.869        0.806   \n","7        1     0.886      0.859   0.922  0.890        0.922        0.849   \n","8        2     0.863      0.824   0.924  0.871        0.924        0.803   \n","9        0     0.874      0.854   0.901  0.877        0.901        0.846   \n","10       1     0.902      0.877   0.935  0.905        0.935        0.869   \n","11       2     0.889      0.851   0.942  0.894        0.942        0.835   \n","12       0     0.891      0.868   0.923  0.894        0.923        0.859   \n","13       1     0.917      0.903   0.935  0.919        0.935        0.900   \n","14       2     0.903      0.871   0.946  0.907        0.946        0.859   \n","\n","    Kappa  \n","0   0.494  \n","1   0.585  \n","2   0.472  \n","3   0.596  \n","4   0.698  \n","5   0.612  \n","6   0.675  \n","7   0.771  \n","8   0.727  \n","9   0.747  \n","10  0.804  \n","11  0.777  \n","12  0.782  \n","13  0.835  \n","14  0.805  "],"text/html":["\n","  <div id=\"df-82c8544d-2838-47ea-869a-1b88f78bd015\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.747</td>\n","      <td>0.747</td>\n","      <td>0.747</td>\n","      <td>0.747</td>\n","      <td>0.747</td>\n","      <td>0.747</td>\n","      <td>0.494</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.792</td>\n","      <td>0.805</td>\n","      <td>0.771</td>\n","      <td>0.788</td>\n","      <td>0.771</td>\n","      <td>0.814</td>\n","      <td>0.585</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.736</td>\n","      <td>0.709</td>\n","      <td>0.799</td>\n","      <td>0.752</td>\n","      <td>0.799</td>\n","      <td>0.673</td>\n","      <td>0.472</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.798</td>\n","      <td>0.791</td>\n","      <td>0.811</td>\n","      <td>0.801</td>\n","      <td>0.811</td>\n","      <td>0.786</td>\n","      <td>0.596</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.849</td>\n","      <td>0.853</td>\n","      <td>0.843</td>\n","      <td>0.848</td>\n","      <td>0.843</td>\n","      <td>0.855</td>\n","      <td>0.698</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.806</td>\n","      <td>0.806</td>\n","      <td>0.807</td>\n","      <td>0.806</td>\n","      <td>0.807</td>\n","      <td>0.805</td>\n","      <td>0.612</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.838</td>\n","      <td>0.817</td>\n","      <td>0.869</td>\n","      <td>0.843</td>\n","      <td>0.869</td>\n","      <td>0.806</td>\n","      <td>0.675</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.886</td>\n","      <td>0.859</td>\n","      <td>0.922</td>\n","      <td>0.890</td>\n","      <td>0.922</td>\n","      <td>0.849</td>\n","      <td>0.771</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.863</td>\n","      <td>0.824</td>\n","      <td>0.924</td>\n","      <td>0.871</td>\n","      <td>0.924</td>\n","      <td>0.803</td>\n","      <td>0.727</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.874</td>\n","      <td>0.854</td>\n","      <td>0.901</td>\n","      <td>0.877</td>\n","      <td>0.901</td>\n","      <td>0.846</td>\n","      <td>0.747</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.902</td>\n","      <td>0.877</td>\n","      <td>0.935</td>\n","      <td>0.905</td>\n","      <td>0.935</td>\n","      <td>0.869</td>\n","      <td>0.804</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.889</td>\n","      <td>0.851</td>\n","      <td>0.942</td>\n","      <td>0.894</td>\n","      <td>0.942</td>\n","      <td>0.835</td>\n","      <td>0.777</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.891</td>\n","      <td>0.868</td>\n","      <td>0.923</td>\n","      <td>0.894</td>\n","      <td>0.923</td>\n","      <td>0.859</td>\n","      <td>0.782</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.917</td>\n","      <td>0.903</td>\n","      <td>0.935</td>\n","      <td>0.919</td>\n","      <td>0.935</td>\n","      <td>0.900</td>\n","      <td>0.835</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.903</td>\n","      <td>0.871</td>\n","      <td>0.946</td>\n","      <td>0.907</td>\n","      <td>0.946</td>\n","      <td>0.859</td>\n","      <td>0.805</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82c8544d-2838-47ea-869a-1b88f78bd015')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-82c8544d-2838-47ea-869a-1b88f78bd015 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-82c8544d-2838-47ea-869a-1b88f78bd015');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b6aadf15-0670-4845-979f-0a3a1b834745\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b6aadf15-0670-4845-979f-0a3a1b834745')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b6aadf15-0670-4845-979f-0a3a1b834745 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df_CNN\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0577970175536354,\n        \"min\": 0.736,\n        \"max\": 0.917,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.874,\n          0.889,\n          0.747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.051749396131742446,\n        \"min\": 0.709,\n        \"max\": 0.903,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.854,\n          0.851,\n          0.747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06913203378491113,\n        \"min\": 0.747,\n        \"max\": 0.946,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.901,\n          0.942,\n          0.747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05739570251043772,\n        \"min\": 0.747,\n        \"max\": 0.919,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.877,\n          0.894,\n          0.747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06913203378491113,\n        \"min\": 0.747,\n        \"max\": 0.946,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.901,\n          0.942,\n          0.747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05583624015176625,\n        \"min\": 0.673,\n        \"max\": 0.9,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.846,\n          0.835,\n          0.747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11544077021820077,\n        \"min\": 0.472,\n        \"max\": 0.835,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.747,\n          0.777,\n          0.494\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":10}],"source":["metrics_df_CNN.round(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_iOLsKpkfzdG"},"outputs":[],"source":["metrics_df_CNN.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Frequency Domain/CNN/frequency_CNN.csv', index = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ieXSN-9PI4Dx"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# GRU"],"metadata":{"id":"R82ujKis8rsa"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout, GRU\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model_gru(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(GRU(256, return_sequences=True))\n","    model.add(GRU(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning_gru(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model_gru(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model_gru(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Total/CNN_GRU/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Total/CNN_GRU/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"c5pv0lgH8tLw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["global_model_gru, metrics_df_gru = federated_learning_gru(Theta_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tpZ3MIfb9MJ6","executionInfo":{"status":"ok","timestamp":1717401201217,"user_tz":-360,"elapsed":1152143,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}},"outputId":"98b5197e-15dc-4058-de71-1600e47c7556"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 1.4309 - accuracy: 0.5619"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 53ms/step - loss: 1.4305 - accuracy: 0.5625 - val_loss: 1.4295 - val_accuracy: 0.5776\n","Epoch 2/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.4191 - accuracy: 0.6342 - val_loss: 1.4232 - val_accuracy: 0.7241\n","Epoch 3/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.4030 - accuracy: 0.6794 - val_loss: 1.4165 - val_accuracy: 0.7371\n","Epoch 4/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.3776 - accuracy: 0.7031 - val_loss: 1.4085 - val_accuracy: 0.7511\n","Epoch 5/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3401 - accuracy: 0.7223 - val_loss: 1.3976 - val_accuracy: 0.7489\n","Epoch 6/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.2963 - accuracy: 0.7373 - val_loss: 1.3835 - val_accuracy: 0.7554\n","Epoch 7/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2558 - accuracy: 0.7395 - val_loss: 1.3661 - val_accuracy: 0.7478\n","Epoch 8/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.2331 - accuracy: 0.7441 - val_loss: 1.3502 - val_accuracy: 0.7608\n","Epoch 9/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2207 - accuracy: 0.7465 - val_loss: 1.3344 - val_accuracy: 0.7597\n","Epoch 10/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2106 - accuracy: 0.7503 - val_loss: 1.3196 - val_accuracy: 0.7554\n","Epoch 11/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.2028 - accuracy: 0.7500 - val_loss: 1.3051 - val_accuracy: 0.7640\n","Epoch 12/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.1921 - accuracy: 0.7573 - val_loss: 1.2893 - val_accuracy: 0.7683\n","Epoch 13/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.1848 - accuracy: 0.7629 - val_loss: 1.2729 - val_accuracy: 0.7683\n","Epoch 14/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.1770 - accuracy: 0.7629 - val_loss: 1.2571 - val_accuracy: 0.7716\n","Epoch 15/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.1699 - accuracy: 0.7667 - val_loss: 1.2398 - val_accuracy: 0.7769\n","Epoch 16/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1622 - accuracy: 0.7640 - val_loss: 1.2201 - val_accuracy: 0.7759\n","Epoch 17/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1536 - accuracy: 0.7680 - val_loss: 1.2049 - val_accuracy: 0.7856\n","Epoch 18/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1469 - accuracy: 0.7705 - val_loss: 1.1864 - val_accuracy: 0.7877\n","Epoch 19/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1386 - accuracy: 0.7726 - val_loss: 1.1692 - val_accuracy: 0.7856\n","Epoch 20/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1315 - accuracy: 0.7769 - val_loss: 1.1557 - val_accuracy: 0.7823\n","Epoch 21/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1230 - accuracy: 0.7807 - val_loss: 1.1404 - val_accuracy: 0.7834\n","Epoch 22/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1177 - accuracy: 0.7839 - val_loss: 1.1282 - val_accuracy: 0.7931\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1090 - accuracy: 0.7845 - val_loss: 1.1202 - val_accuracy: 0.7899\n","Epoch 24/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1036 - accuracy: 0.7883 - val_loss: 1.1084 - val_accuracy: 0.7909\n","Epoch 25/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.0971 - accuracy: 0.7896 - val_loss: 1.0999 - val_accuracy: 0.7942\n","Epoch 26/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0877 - accuracy: 0.7923 - val_loss: 1.0885 - val_accuracy: 0.7877\n","Epoch 27/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0787 - accuracy: 0.7934 - val_loss: 1.0806 - val_accuracy: 0.7931\n","Epoch 28/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0721 - accuracy: 0.7988 - val_loss: 1.0766 - val_accuracy: 0.8006\n","Epoch 29/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.0656 - accuracy: 0.8039 - val_loss: 1.0684 - val_accuracy: 0.8017\n","Epoch 30/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0582 - accuracy: 0.8015 - val_loss: 1.0703 - val_accuracy: 0.7985\n","Epoch 31/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0522 - accuracy: 0.7988 - val_loss: 1.0614 - val_accuracy: 0.8017\n","Epoch 32/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0408 - accuracy: 0.8090 - val_loss: 1.0489 - val_accuracy: 0.7963\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0337 - accuracy: 0.8103 - val_loss: 1.0426 - val_accuracy: 0.7963\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0235 - accuracy: 0.8103 - val_loss: 1.0374 - val_accuracy: 0.7996\n","Epoch 35/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0138 - accuracy: 0.8184 - val_loss: 1.0333 - val_accuracy: 0.8082\n","Epoch 36/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.0089 - accuracy: 0.8252 - val_loss: 1.0282 - val_accuracy: 0.8136\n","Epoch 37/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.0049 - accuracy: 0.8225 - val_loss: 1.0244 - val_accuracy: 0.8147\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9989 - accuracy: 0.8171 - val_loss: 1.0220 - val_accuracy: 0.7985\n","Epoch 39/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.9898 - accuracy: 0.8249 - val_loss: 1.0159 - val_accuracy: 0.8168\n","Epoch 40/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9791 - accuracy: 0.8295 - val_loss: 1.0101 - val_accuracy: 0.8039\n","Epoch 41/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.9710 - accuracy: 0.8305 - val_loss: 1.0059 - val_accuracy: 0.8179\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9688 - accuracy: 0.8308 - val_loss: 1.0019 - val_accuracy: 0.8039\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9578 - accuracy: 0.8314 - val_loss: 0.9964 - val_accuracy: 0.8093\n","Epoch 44/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9553 - accuracy: 0.8343 - val_loss: 0.9929 - val_accuracy: 0.8125\n","Epoch 45/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9470 - accuracy: 0.8378 - val_loss: 0.9975 - val_accuracy: 0.8222\n","Epoch 46/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9428 - accuracy: 0.8376 - val_loss: 0.9855 - val_accuracy: 0.8157\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9333 - accuracy: 0.8416 - val_loss: 0.9813 - val_accuracy: 0.8190\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9284 - accuracy: 0.8435 - val_loss: 0.9981 - val_accuracy: 0.7985\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9203 - accuracy: 0.8443 - val_loss: 0.9741 - val_accuracy: 0.8136\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9168 - accuracy: 0.8421 - val_loss: 0.9723 - val_accuracy: 0.8157\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9038 - accuracy: 0.8497 - val_loss: 0.9683 - val_accuracy: 0.8093\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8958 - accuracy: 0.8526 - val_loss: 0.9654 - val_accuracy: 0.8147\n","Epoch 53/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8911 - accuracy: 0.8556 - val_loss: 0.9633 - val_accuracy: 0.8103\n","Epoch 54/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8830 - accuracy: 0.8572 - val_loss: 0.9624 - val_accuracy: 0.8254\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8802 - accuracy: 0.8567 - val_loss: 0.9568 - val_accuracy: 0.8136\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8702 - accuracy: 0.8653 - val_loss: 0.9547 - val_accuracy: 0.8125\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8690 - accuracy: 0.8607 - val_loss: 0.9606 - val_accuracy: 0.8211\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8563 - accuracy: 0.8618 - val_loss: 0.9527 - val_accuracy: 0.8147\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8526 - accuracy: 0.8675 - val_loss: 0.9497 - val_accuracy: 0.8168\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8568 - accuracy: 0.8602 - val_loss: 0.9437 - val_accuracy: 0.8179\n","Epoch 61/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8435 - accuracy: 0.8739 - val_loss: 0.9402 - val_accuracy: 0.8222\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8359 - accuracy: 0.8745 - val_loss: 0.9360 - val_accuracy: 0.8222\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8234 - accuracy: 0.8817 - val_loss: 0.9486 - val_accuracy: 0.8114\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8244 - accuracy: 0.8763 - val_loss: 0.9468 - val_accuracy: 0.8190\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8190 - accuracy: 0.8807 - val_loss: 0.9295 - val_accuracy: 0.8244\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8068 - accuracy: 0.8796 - val_loss: 0.9296 - val_accuracy: 0.8211\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8034 - accuracy: 0.8817 - val_loss: 0.9253 - val_accuracy: 0.8222\n","Epoch 68/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8032 - accuracy: 0.8823 - val_loss: 0.9342 - val_accuracy: 0.8147\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7954 - accuracy: 0.8815 - val_loss: 0.9371 - val_accuracy: 0.8114\n","Epoch 70/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7852 - accuracy: 0.8863 - val_loss: 0.9184 - val_accuracy: 0.8200\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7728 - accuracy: 0.8882 - val_loss: 0.9248 - val_accuracy: 0.8200\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7722 - accuracy: 0.8901 - val_loss: 0.9180 - val_accuracy: 0.8190\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7658 - accuracy: 0.8906 - val_loss: 0.9181 - val_accuracy: 0.8244\n","Epoch 74/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7629 - accuracy: 0.8912 - val_loss: 0.9184 - val_accuracy: 0.8200\n","Epoch 75/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7511 - accuracy: 0.8987 - val_loss: 0.9130 - val_accuracy: 0.8233\n","Epoch 76/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7458 - accuracy: 0.8966 - val_loss: 0.9084 - val_accuracy: 0.8211\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7377 - accuracy: 0.9022 - val_loss: 0.9126 - val_accuracy: 0.8222\n","Epoch 78/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7365 - accuracy: 0.8990 - val_loss: 0.9218 - val_accuracy: 0.8114\n","Epoch 79/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7297 - accuracy: 0.9030 - val_loss: 0.9068 - val_accuracy: 0.8222\n","Epoch 80/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7179 - accuracy: 0.9049 - val_loss: 0.9095 - val_accuracy: 0.8136\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7192 - accuracy: 0.9049 - val_loss: 0.9069 - val_accuracy: 0.8200\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7091 - accuracy: 0.9057 - val_loss: 0.9461 - val_accuracy: 0.8093\n","Epoch 83/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7092 - accuracy: 0.9100 - val_loss: 0.9041 - val_accuracy: 0.8179\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6979 - accuracy: 0.9122 - val_loss: 0.9050 - val_accuracy: 0.8179\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6892 - accuracy: 0.9119 - val_loss: 0.9051 - val_accuracy: 0.8168\n","Epoch 86/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6864 - accuracy: 0.9124 - val_loss: 0.9031 - val_accuracy: 0.8200\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6773 - accuracy: 0.9184 - val_loss: 0.9020 - val_accuracy: 0.8179\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6632 - accuracy: 0.9278 - val_loss: 0.9015 - val_accuracy: 0.8168\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6688 - accuracy: 0.9208 - val_loss: 0.9017 - val_accuracy: 0.8168\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6635 - accuracy: 0.9232 - val_loss: 0.9173 - val_accuracy: 0.8222\n","Epoch 91/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6533 - accuracy: 0.9267 - val_loss: 0.9025 - val_accuracy: 0.8211\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6429 - accuracy: 0.9297 - val_loss: 0.9083 - val_accuracy: 0.8211\n","Epoch 93/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6429 - accuracy: 0.9238 - val_loss: 0.9035 - val_accuracy: 0.8168\n","Epoch 94/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6372 - accuracy: 0.9305 - val_loss: 0.9033 - val_accuracy: 0.8147\n","Epoch 95/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6350 - accuracy: 0.9291 - val_loss: 0.9012 - val_accuracy: 0.8179\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6220 - accuracy: 0.9345 - val_loss: 0.9025 - val_accuracy: 0.8125\n","Epoch 97/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6198 - accuracy: 0.9343 - val_loss: 0.9023 - val_accuracy: 0.8179\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6105 - accuracy: 0.9370 - val_loss: 0.9076 - val_accuracy: 0.8222\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6040 - accuracy: 0.9402 - val_loss: 0.9123 - val_accuracy: 0.8211\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6046 - accuracy: 0.9351 - val_loss: 0.9322 - val_accuracy: 0.8200\n","{'loss': [1.4304836988449097, 1.4191340208053589, 1.4029977321624756, 1.3776142597198486, 1.3401038646697998, 1.2962942123413086, 1.2557629346847534, 1.2330825328826904, 1.220658540725708, 1.2105886936187744, 1.2028008699417114, 1.1921391487121582, 1.1847825050354004, 1.1770374774932861, 1.1699446439743042, 1.1622248888015747, 1.153649926185608, 1.1468747854232788, 1.1386332511901855, 1.1315126419067383, 1.122989535331726, 1.1177088022232056, 1.1090384721755981, 1.1036102771759033, 1.0970873832702637, 1.087738037109375, 1.078698992729187, 1.072077989578247, 1.0656119585037231, 1.0581567287445068, 1.0522429943084717, 1.0408085584640503, 1.033715844154358, 1.0235204696655273, 1.0138232707977295, 1.008887767791748, 1.0049140453338623, 0.9988962411880493, 0.989824652671814, 0.9791293740272522, 0.9709776639938354, 0.9687968492507935, 0.9577503204345703, 0.9552696943283081, 0.9470176696777344, 0.9427684545516968, 0.9333458542823792, 0.9283563494682312, 0.9203082323074341, 0.9168326258659363, 0.9037892818450928, 0.8957647085189819, 0.8910616636276245, 0.8829651474952698, 0.8801608085632324, 0.870210587978363, 0.8690186142921448, 0.8563380241394043, 0.8525999188423157, 0.8567992448806763, 0.8434872031211853, 0.8358955979347229, 0.8233572840690613, 0.8243921399116516, 0.8190271854400635, 0.8068326115608215, 0.8033651113510132, 0.8031907081604004, 0.7953988313674927, 0.7852053642272949, 0.7728435397148132, 0.7722381353378296, 0.7658006548881531, 0.762923002243042, 0.7510890364646912, 0.7458109259605408, 0.7377318143844604, 0.7365232706069946, 0.7296881079673767, 0.7179028987884521, 0.7191645503044128, 0.7090871930122375, 0.7091653347015381, 0.6979350447654724, 0.68924480676651, 0.6864249110221863, 0.6773315072059631, 0.6632154583930969, 0.6688429713249207, 0.6635385751724243, 0.6532925963401794, 0.642938494682312, 0.6428921818733215, 0.6372178792953491, 0.6350045800209045, 0.6219635009765625, 0.6197981834411621, 0.6105145812034607, 0.603950560092926, 0.6046435236930847], 'accuracy': [0.5625, 0.634159505367279, 0.6794180870056152, 0.703125, 0.7222521305084229, 0.7373383641242981, 0.7394935488700867, 0.7440732717514038, 0.7464978694915771, 0.7502694129943848, 0.75, 0.7572737336158752, 0.7629310488700867, 0.7629310488700867, 0.7667025923728943, 0.764008641242981, 0.7680495977401733, 0.7704741358757019, 0.7726293206214905, 0.7769396305084229, 0.7807112336158752, 0.7839439511299133, 0.7844827771186829, 0.7882543206214905, 0.7896012663841248, 0.7922952771186829, 0.7933728694915771, 0.7987607717514038, 0.8038793206214905, 0.8014547228813171, 0.7987607717514038, 0.8089978694915771, 0.8103448152542114, 0.8103448152542114, 0.8184267282485962, 0.8251616358757019, 0.8224676847457886, 0.8170797228813171, 0.8248922228813171, 0.829472005367279, 0.8305495977401733, 0.8308189511299133, 0.8313577771186829, 0.834321141242981, 0.8378232717514038, 0.837553858757019, 0.8415948152542114, 0.8434805870056152, 0.8442887663841248, 0.842133641242981, 0.8496767282485962, 0.8526400923728943, 0.8556034564971924, 0.8572198152542114, 0.8566810488700867, 0.8653017282485962, 0.860722005367279, 0.8617995977401733, 0.8674569129943848, 0.8601831793785095, 0.8739224076271057, 0.8744612336158752, 0.8817349076271057, 0.876347005367279, 0.8806573152542114, 0.8795797228813171, 0.8817349076271057, 0.8822737336158752, 0.881465494632721, 0.8863146305084229, 0.8882004022598267, 0.8900862336158752, 0.890625, 0.8911637663841248, 0.8987069129943848, 0.8965517282485962, 0.9022090435028076, 0.8989762663841248, 0.9030172228813171, 0.904902994632721, 0.904902994632721, 0.9057112336158752, 0.9100215435028076, 0.9121767282485962, 0.9119073152542114, 0.912446141242981, 0.9183728694915771, 0.9278017282485962, 0.9207974076271057, 0.923222005367279, 0.9267241358757019, 0.9296875, 0.9237607717514038, 0.9304956793785095, 0.9291487336158752, 0.9345366358757019, 0.9342672228813171, 0.9369612336158752, 0.9401939511299133, 0.9350754022598267], 'val_loss': [1.4295121431350708, 1.423222541809082, 1.4165136814117432, 1.4085322618484497, 1.3976280689239502, 1.3834567070007324, 1.3660860061645508, 1.3502423763275146, 1.334449291229248, 1.3195608854293823, 1.3050625324249268, 1.289259433746338, 1.272854208946228, 1.257086157798767, 1.23978853225708, 1.2201255559921265, 1.204904317855835, 1.1863646507263184, 1.1691772937774658, 1.1557013988494873, 1.1403889656066895, 1.128195881843567, 1.1201742887496948, 1.1084210872650146, 1.0998828411102295, 1.0884846448898315, 1.0806468725204468, 1.0765929222106934, 1.068406105041504, 1.0702781677246094, 1.061355710029602, 1.048883080482483, 1.0426063537597656, 1.0373543500900269, 1.0333441495895386, 1.0282431840896606, 1.0243775844573975, 1.022034764289856, 1.0159122943878174, 1.0101196765899658, 1.005936622619629, 1.0019267797470093, 0.9963824152946472, 0.9929351210594177, 0.9974843263626099, 0.9855173826217651, 0.9812884330749512, 0.998113214969635, 0.9740558862686157, 0.9723191261291504, 0.9683042168617249, 0.9653780460357666, 0.9632624387741089, 0.9624139666557312, 0.9567616581916809, 0.9547159075737, 0.9605638384819031, 0.9526903629302979, 0.9496766328811646, 0.9436557292938232, 0.9402114152908325, 0.9359771609306335, 0.948607325553894, 0.9467666745185852, 0.9294648170471191, 0.9296203851699829, 0.9253089427947998, 0.9342146515846252, 0.9370748996734619, 0.918398916721344, 0.924761176109314, 0.9179530739784241, 0.9180801510810852, 0.9184235334396362, 0.9130443930625916, 0.9084219932556152, 0.9125654101371765, 0.9217528104782104, 0.9068039059638977, 0.9094878435134888, 0.9069415330886841, 0.9461460709571838, 0.9041290283203125, 0.905042827129364, 0.9050721526145935, 0.9031324982643127, 0.9019644260406494, 0.9014586806297302, 0.9016838073730469, 0.9172630310058594, 0.9025379419326782, 0.9082631468772888, 0.9034565687179565, 0.9033216238021851, 0.9011508822441101, 0.902508020401001, 0.9023475646972656, 0.9075649976730347, 0.9122770428657532, 0.932174026966095], 'val_accuracy': [0.5775862336158752, 0.7241379022598267, 0.7370689511299133, 0.7510775923728943, 0.7489224076271057, 0.7553879022598267, 0.7478448152542114, 0.7607758641242981, 0.7596982717514038, 0.7553879022598267, 0.764008641242981, 0.7683189511299133, 0.7683189511299133, 0.7715517282485962, 0.7769396305084229, 0.7758620977401733, 0.7855603694915771, 0.787715494632721, 0.7855603694915771, 0.7823275923728943, 0.7834051847457886, 0.7931034564971924, 0.7898706793785095, 0.7909482717514038, 0.7941810488700867, 0.787715494632721, 0.7931034564971924, 0.8006465435028076, 0.8017241358757019, 0.798491358757019, 0.8017241358757019, 0.7963362336158752, 0.7963362336158752, 0.7995689511299133, 0.8081896305084229, 0.8135775923728943, 0.8146551847457886, 0.798491358757019, 0.8168103694915771, 0.8038793206214905, 0.8178879022598267, 0.8038793206214905, 0.8092672228813171, 0.8125, 0.8221982717514038, 0.8157327771186829, 0.818965494632721, 0.798491358757019, 0.8135775923728943, 0.8157327771186829, 0.8092672228813171, 0.8146551847457886, 0.8103448152542114, 0.8254310488700867, 0.8135775923728943, 0.8125, 0.8211206793785095, 0.8146551847457886, 0.8168103694915771, 0.8178879022598267, 0.8221982717514038, 0.8221982717514038, 0.8114224076271057, 0.818965494632721, 0.8243534564971924, 0.8211206793785095, 0.8221982717514038, 0.8146551847457886, 0.8114224076271057, 0.8200430870056152, 0.8200430870056152, 0.818965494632721, 0.8243534564971924, 0.8200430870056152, 0.8232758641242981, 0.8211206793785095, 0.8221982717514038, 0.8114224076271057, 0.8221982717514038, 0.8135775923728943, 0.8200430870056152, 0.8092672228813171, 0.8178879022598267, 0.8178879022598267, 0.8168103694915771, 0.8200430870056152, 0.8178879022598267, 0.8168103694915771, 0.8168103694915771, 0.8221982717514038, 0.8211206793785095, 0.8211206793785095, 0.8168103694915771, 0.8146551847457886, 0.8178879022598267, 0.8125, 0.8178879022598267, 0.8221982717514038, 0.8211206793785095, 0.8200430870056152]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 8s 50ms/step - loss: 1.4314 - accuracy: 0.5903 - val_loss: 1.4297 - val_accuracy: 0.6629\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.4218 - accuracy: 0.6024 - val_loss: 1.4238 - val_accuracy: 0.6991\n","Epoch 3/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.4085 - accuracy: 0.6579 - val_loss: 1.4177 - val_accuracy: 0.6934\n","Epoch 4/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3893 - accuracy: 0.6839 - val_loss: 1.4107 - val_accuracy: 0.6934\n","Epoch 5/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.3595 - accuracy: 0.7046 - val_loss: 1.4022 - val_accuracy: 0.7036\n","Epoch 6/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.3228 - accuracy: 0.7131 - val_loss: 1.3918 - val_accuracy: 0.7104\n","Epoch 7/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2873 - accuracy: 0.7221 - val_loss: 1.3777 - val_accuracy: 0.7036\n","Epoch 8/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2590 - accuracy: 0.7298 - val_loss: 1.3635 - val_accuracy: 0.7149\n","Epoch 9/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2429 - accuracy: 0.7320 - val_loss: 1.3498 - val_accuracy: 0.7127\n","Epoch 10/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.2328 - accuracy: 0.7332 - val_loss: 1.3369 - val_accuracy: 0.7172\n","Epoch 11/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.2277 - accuracy: 0.7312 - val_loss: 1.3250 - val_accuracy: 0.7195\n","Epoch 12/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.2188 - accuracy: 0.7334 - val_loss: 1.3119 - val_accuracy: 0.7262\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2109 - accuracy: 0.7320 - val_loss: 1.2978 - val_accuracy: 0.7251\n","Epoch 14/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.2071 - accuracy: 0.7383 - val_loss: 1.2844 - val_accuracy: 0.7296\n","Epoch 15/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1979 - accuracy: 0.7391 - val_loss: 1.2712 - val_accuracy: 0.7206\n","Epoch 16/100\n","28/28 [==============================] - 1s 30ms/step - loss: 1.1905 - accuracy: 0.7439 - val_loss: 1.2563 - val_accuracy: 0.7319\n","Epoch 17/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.1826 - accuracy: 0.7490 - val_loss: 1.2409 - val_accuracy: 0.7330\n","Epoch 18/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1757 - accuracy: 0.7484 - val_loss: 1.2265 - val_accuracy: 0.7387\n","Epoch 19/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1742 - accuracy: 0.7470 - val_loss: 1.2175 - val_accuracy: 0.7274\n","Epoch 20/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1674 - accuracy: 0.7467 - val_loss: 1.1990 - val_accuracy: 0.7421\n","Epoch 21/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.1545 - accuracy: 0.7533 - val_loss: 1.1848 - val_accuracy: 0.7477\n","Epoch 22/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1473 - accuracy: 0.7595 - val_loss: 1.1760 - val_accuracy: 0.7387\n","Epoch 23/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1402 - accuracy: 0.7626 - val_loss: 1.1637 - val_accuracy: 0.7477\n","Epoch 24/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1307 - accuracy: 0.7666 - val_loss: 1.1514 - val_accuracy: 0.7523\n","Epoch 25/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1222 - accuracy: 0.7685 - val_loss: 1.1413 - val_accuracy: 0.7534\n","Epoch 26/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1154 - accuracy: 0.7728 - val_loss: 1.1329 - val_accuracy: 0.7704\n","Epoch 27/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.1071 - accuracy: 0.7776 - val_loss: 1.1236 - val_accuracy: 0.7738\n","Epoch 28/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0980 - accuracy: 0.7776 - val_loss: 1.1150 - val_accuracy: 0.7726\n","Epoch 29/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0907 - accuracy: 0.7835 - val_loss: 1.1086 - val_accuracy: 0.7771\n","Epoch 30/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0826 - accuracy: 0.7830 - val_loss: 1.0995 - val_accuracy: 0.7760\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0745 - accuracy: 0.7883 - val_loss: 1.0931 - val_accuracy: 0.7738\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0645 - accuracy: 0.7946 - val_loss: 1.0863 - val_accuracy: 0.7760\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0568 - accuracy: 0.7943 - val_loss: 1.0858 - val_accuracy: 0.7749\n","Epoch 34/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0499 - accuracy: 0.7963 - val_loss: 1.0807 - val_accuracy: 0.7794\n","Epoch 35/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.0477 - accuracy: 0.8016 - val_loss: 1.0708 - val_accuracy: 0.7805\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0327 - accuracy: 0.8056 - val_loss: 1.0676 - val_accuracy: 0.7783\n","Epoch 37/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.0239 - accuracy: 0.8093 - val_loss: 1.0605 - val_accuracy: 0.7851\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0181 - accuracy: 0.8059 - val_loss: 1.0620 - val_accuracy: 0.7805\n","Epoch 39/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0137 - accuracy: 0.8104 - val_loss: 1.0550 - val_accuracy: 0.7839\n","Epoch 40/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.0038 - accuracy: 0.8132 - val_loss: 1.0528 - val_accuracy: 0.7873\n","Epoch 41/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.0010 - accuracy: 0.8104 - val_loss: 1.0429 - val_accuracy: 0.7930\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9929 - accuracy: 0.8093 - val_loss: 1.0447 - val_accuracy: 0.7885\n","Epoch 43/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.9876 - accuracy: 0.8141 - val_loss: 1.0352 - val_accuracy: 0.7964\n","Epoch 44/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9775 - accuracy: 0.8268 - val_loss: 1.0335 - val_accuracy: 0.7851\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9706 - accuracy: 0.8246 - val_loss: 1.0266 - val_accuracy: 0.7952\n","Epoch 46/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9647 - accuracy: 0.8223 - val_loss: 1.0245 - val_accuracy: 0.8077\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9572 - accuracy: 0.8291 - val_loss: 1.0190 - val_accuracy: 0.7941\n","Epoch 48/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9510 - accuracy: 0.8231 - val_loss: 1.0171 - val_accuracy: 0.8100\n","Epoch 49/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9500 - accuracy: 0.8288 - val_loss: 1.0124 - val_accuracy: 0.7941\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9392 - accuracy: 0.8342 - val_loss: 1.0061 - val_accuracy: 0.8032\n","Epoch 51/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9328 - accuracy: 0.8342 - val_loss: 1.0045 - val_accuracy: 0.7986\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9246 - accuracy: 0.8407 - val_loss: 1.0052 - val_accuracy: 0.7941\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9183 - accuracy: 0.8373 - val_loss: 0.9977 - val_accuracy: 0.8020\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9117 - accuracy: 0.8396 - val_loss: 1.0058 - val_accuracy: 0.7941\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9060 - accuracy: 0.8393 - val_loss: 0.9917 - val_accuracy: 0.8077\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9056 - accuracy: 0.8376 - val_loss: 1.0079 - val_accuracy: 0.7919\n","Epoch 57/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8925 - accuracy: 0.8466 - val_loss: 0.9888 - val_accuracy: 0.8213\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8943 - accuracy: 0.8447 - val_loss: 0.9813 - val_accuracy: 0.8066\n","Epoch 59/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8751 - accuracy: 0.8543 - val_loss: 0.9808 - val_accuracy: 0.8054\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8702 - accuracy: 0.8540 - val_loss: 0.9795 - val_accuracy: 0.8066\n","Epoch 61/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8619 - accuracy: 0.8571 - val_loss: 0.9753 - val_accuracy: 0.8111\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8661 - accuracy: 0.8526 - val_loss: 0.9724 - val_accuracy: 0.8133\n","Epoch 63/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8500 - accuracy: 0.8560 - val_loss: 0.9684 - val_accuracy: 0.8201\n","Epoch 64/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8448 - accuracy: 0.8642 - val_loss: 0.9774 - val_accuracy: 0.8201\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8380 - accuracy: 0.8667 - val_loss: 0.9681 - val_accuracy: 0.8100\n","Epoch 66/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8321 - accuracy: 0.8619 - val_loss: 0.9660 - val_accuracy: 0.8190\n","Epoch 67/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8259 - accuracy: 0.8653 - val_loss: 0.9598 - val_accuracy: 0.8190\n","Epoch 68/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8221 - accuracy: 0.8687 - val_loss: 0.9582 - val_accuracy: 0.8190\n","Epoch 69/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8098 - accuracy: 0.8729 - val_loss: 0.9589 - val_accuracy: 0.8111\n","Epoch 70/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8088 - accuracy: 0.8715 - val_loss: 0.9524 - val_accuracy: 0.8190\n","Epoch 71/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8006 - accuracy: 0.8778 - val_loss: 0.9501 - val_accuracy: 0.8201\n","Epoch 72/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7937 - accuracy: 0.8778 - val_loss: 0.9499 - val_accuracy: 0.8179\n","Epoch 73/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.7871 - accuracy: 0.8803 - val_loss: 0.9530 - val_accuracy: 0.8111\n","Epoch 74/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7783 - accuracy: 0.8803 - val_loss: 0.9549 - val_accuracy: 0.8066\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7708 - accuracy: 0.8820 - val_loss: 0.9510 - val_accuracy: 0.8145\n","Epoch 76/100\n","28/28 [==============================] - 1s 46ms/step - loss: 0.7761 - accuracy: 0.8814 - val_loss: 0.9413 - val_accuracy: 0.8258\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7552 - accuracy: 0.8922 - val_loss: 0.9377 - val_accuracy: 0.8247\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7586 - accuracy: 0.8860 - val_loss: 0.9398 - val_accuracy: 0.8247\n","Epoch 79/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7509 - accuracy: 0.8928 - val_loss: 0.9380 - val_accuracy: 0.8190\n","Epoch 80/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7361 - accuracy: 0.8981 - val_loss: 0.9466 - val_accuracy: 0.8122\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7346 - accuracy: 0.8925 - val_loss: 0.9451 - val_accuracy: 0.8145\n","Epoch 82/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7218 - accuracy: 0.9041 - val_loss: 0.9311 - val_accuracy: 0.8303\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7206 - accuracy: 0.8998 - val_loss: 0.9304 - val_accuracy: 0.8303\n","Epoch 84/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7180 - accuracy: 0.9027 - val_loss: 0.9316 - val_accuracy: 0.8201\n","Epoch 85/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.7109 - accuracy: 0.9012 - val_loss: 0.9281 - val_accuracy: 0.8314\n","Epoch 86/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7005 - accuracy: 0.9083 - val_loss: 0.9250 - val_accuracy: 0.8247\n","Epoch 87/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6977 - accuracy: 0.9049 - val_loss: 0.9328 - val_accuracy: 0.8224\n","Epoch 88/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6973 - accuracy: 0.9066 - val_loss: 0.9237 - val_accuracy: 0.8292\n","Epoch 89/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6828 - accuracy: 0.9128 - val_loss: 0.9305 - val_accuracy: 0.8201\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6709 - accuracy: 0.9208 - val_loss: 0.9238 - val_accuracy: 0.8303\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6729 - accuracy: 0.9194 - val_loss: 0.9326 - val_accuracy: 0.8190\n","Epoch 92/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6609 - accuracy: 0.9250 - val_loss: 0.9237 - val_accuracy: 0.8314\n","Epoch 93/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6551 - accuracy: 0.9219 - val_loss: 0.9239 - val_accuracy: 0.8326\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6536 - accuracy: 0.9213 - val_loss: 0.9238 - val_accuracy: 0.8292\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6481 - accuracy: 0.9256 - val_loss: 0.9205 - val_accuracy: 0.8326\n","Epoch 96/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6390 - accuracy: 0.9293 - val_loss: 0.9265 - val_accuracy: 0.8247\n","Epoch 97/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6362 - accuracy: 0.9267 - val_loss: 0.9312 - val_accuracy: 0.8224\n","Epoch 98/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6318 - accuracy: 0.9301 - val_loss: 0.9199 - val_accuracy: 0.8314\n","Epoch 99/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6207 - accuracy: 0.9363 - val_loss: 0.9315 - val_accuracy: 0.8235\n","Epoch 100/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6130 - accuracy: 0.9377 - val_loss: 0.9264 - val_accuracy: 0.8269\n","{'loss': [1.4313992261886597, 1.4218159914016724, 1.4085122346878052, 1.3893485069274902, 1.3595463037490845, 1.3227747678756714, 1.2872629165649414, 1.2590124607086182, 1.242879033088684, 1.232838749885559, 1.2277069091796875, 1.2187951803207397, 1.210854411125183, 1.2071257829666138, 1.1979087591171265, 1.19054114818573, 1.1825979948043823, 1.1757341623306274, 1.1742123365402222, 1.1673799753189087, 1.1544963121414185, 1.1473079919815063, 1.1402194499969482, 1.1307494640350342, 1.1222026348114014, 1.1153703927993774, 1.10712468624115, 1.0980416536331177, 1.090666651725769, 1.082588791847229, 1.0744640827178955, 1.0644917488098145, 1.0568456649780273, 1.0498600006103516, 1.0477302074432373, 1.032679796218872, 1.0238879919052124, 1.018145203590393, 1.0136674642562866, 1.003791332244873, 1.0009663105010986, 0.9928672313690186, 0.9875996708869934, 0.9775052666664124, 0.9706323742866516, 0.9646503329277039, 0.9572280049324036, 0.9510054588317871, 0.9500240683555603, 0.9391517043113708, 0.9327518939971924, 0.9246161580085754, 0.9182904958724976, 0.9116550087928772, 0.906013548374176, 0.9056054949760437, 0.892510175704956, 0.8942667245864868, 0.8750537633895874, 0.8701897859573364, 0.8618510365486145, 0.8660950660705566, 0.8500076532363892, 0.8448215126991272, 0.8380324244499207, 0.8320541381835938, 0.8259419202804565, 0.8220974802970886, 0.809799075126648, 0.8088432550430298, 0.8005775809288025, 0.793677031993866, 0.7870529890060425, 0.7783257961273193, 0.7707957625389099, 0.7760584354400635, 0.7551954388618469, 0.7585994005203247, 0.7509366273880005, 0.7360601425170898, 0.7346122860908508, 0.721759021282196, 0.7206230759620667, 0.718044638633728, 0.7109499573707581, 0.7005193829536438, 0.6977077126502991, 0.6972581148147583, 0.6827929615974426, 0.6708876490592957, 0.6729487776756287, 0.6608551144599915, 0.6550836563110352, 0.6535897850990295, 0.6481443643569946, 0.6389695405960083, 0.6362247467041016, 0.6317838430404663, 0.6207202076911926, 0.6130111217498779], 'accuracy': [0.5902659893035889, 0.6024335026741028, 0.6578947305679321, 0.6839275360107422, 0.7045840620994568, 0.7130730152130127, 0.7221279144287109, 0.7297679781913757, 0.7320317029953003, 0.7331635355949402, 0.7311828136444092, 0.7334465384483337, 0.7320317029953003, 0.7382569313049316, 0.7391058206558228, 0.7439162135124207, 0.7490096092224121, 0.7484436631202698, 0.7470288872718811, 0.7467458844184875, 0.7532541155815125, 0.7594793438911438, 0.7625919580459595, 0.7665534615516663, 0.768534243106842, 0.7727787494659424, 0.7775891423225403, 0.7775891423225403, 0.7835314273834229, 0.7829654812812805, 0.7883418202400208, 0.7945670485496521, 0.7942841053009033, 0.7962648272514343, 0.8016412258148193, 0.8056027293205261, 0.8092812895774841, 0.8058856725692749, 0.810413122177124, 0.8132427930831909, 0.810413122177124, 0.8092812895774841, 0.814091682434082, 0.8268251419067383, 0.8245614171028137, 0.8222976922988892, 0.8290888667106628, 0.8231465816497803, 0.8288058638572693, 0.8341822028160095, 0.8341822028160095, 0.8406904339790344, 0.83729487657547, 0.8395586013793945, 0.839275598526001, 0.8375778198242188, 0.846632719039917, 0.8446519374847412, 0.8542727828025818, 0.853989839553833, 0.8571024537086487, 0.8525750041007996, 0.855970561504364, 0.8641765713691711, 0.8667232394218445, 0.8619128465652466, 0.865308403968811, 0.8687040209770203, 0.8729485273361206, 0.8715336918830872, 0.8777589201927185, 0.8777589201927185, 0.8803055882453918, 0.8803055882453918, 0.8820033669471741, 0.8814374804496765, 0.892190158367157, 0.8859649300575256, 0.8927561044692993, 0.8981324434280396, 0.8924731016159058, 0.9040747284889221, 0.8998302221298218, 0.9026598930358887, 0.9012450575828552, 0.9083191752433777, 0.9049236178398132, 0.9066213965415955, 0.9128466248512268, 0.9207696914672852, 0.9193548560142517, 0.9250141382217407, 0.921901524066925, 0.9213355779647827, 0.9255800843238831, 0.9292586445808411, 0.926711916923523, 0.9301075339317322, 0.9363327622413635, 0.937747597694397], 'val_loss': [1.4297192096710205, 1.4238371849060059, 1.4176619052886963, 1.4107327461242676, 1.402180552482605, 1.3918018341064453, 1.3776723146438599, 1.3634675741195679, 1.3498185873031616, 1.3369170427322388, 1.3249739408493042, 1.3119386434555054, 1.297752857208252, 1.2843869924545288, 1.2711904048919678, 1.2562819719314575, 1.2409147024154663, 1.2265006303787231, 1.217485785484314, 1.199041724205017, 1.1848214864730835, 1.1760282516479492, 1.1637022495269775, 1.1513622999191284, 1.1413490772247314, 1.1329338550567627, 1.1235839128494263, 1.1149866580963135, 1.1085563898086548, 1.0994597673416138, 1.0931473970413208, 1.0863295793533325, 1.0858030319213867, 1.0806559324264526, 1.0708385705947876, 1.0676298141479492, 1.060503363609314, 1.0620113611221313, 1.0549758672714233, 1.052849531173706, 1.042861819267273, 1.0446574687957764, 1.0352181196212769, 1.0335450172424316, 1.0265898704528809, 1.0245286226272583, 1.0189586877822876, 1.0170921087265015, 1.012424349784851, 1.0060968399047852, 1.0045301914215088, 1.005172848701477, 0.9977438449859619, 1.0058118104934692, 0.9916892647743225, 1.0078895092010498, 0.9888115525245667, 0.9813336133956909, 0.980797290802002, 0.9794691205024719, 0.9752625823020935, 0.9724317789077759, 0.9683560132980347, 0.9774414896965027, 0.9680737257003784, 0.9660038948059082, 0.9598278403282166, 0.9581964612007141, 0.9588803648948669, 0.9523746967315674, 0.9501301050186157, 0.9498817324638367, 0.9529685974121094, 0.9548735022544861, 0.9509947299957275, 0.941297173500061, 0.9376777410507202, 0.9397830963134766, 0.9379578828811646, 0.9466034173965454, 0.9451298713684082, 0.9311241507530212, 0.9303677678108215, 0.931614875793457, 0.928061842918396, 0.9250461459159851, 0.9327566623687744, 0.923733651638031, 0.9304569959640503, 0.9237775206565857, 0.9326061010360718, 0.9237260222434998, 0.9238694906234741, 0.9238079190254211, 0.9205021858215332, 0.9264818429946899, 0.931236743927002, 0.9199305176734924, 0.9315398931503296, 0.9263513684272766], 'val_accuracy': [0.662895917892456, 0.6990950107574463, 0.6934388875961304, 0.6934388875961304, 0.7036198973655701, 0.7104072570800781, 0.7036198973655701, 0.7149321436882019, 0.7126696705818176, 0.7171945571899414, 0.7194570302963257, 0.726244330406189, 0.7251130938529968, 0.7296379804611206, 0.720588207244873, 0.7319004535675049, 0.733031690120697, 0.7386877536773682, 0.7273755669593811, 0.7420814633369446, 0.7477375268936157, 0.7386877536773682, 0.7477375268936157, 0.7522624731063843, 0.7533936500549316, 0.7703620195388794, 0.773755669593811, 0.7726244330406189, 0.7771493196487427, 0.7760180830955505, 0.773755669593811, 0.7760180830955505, 0.7748869061470032, 0.779411792755127, 0.7805429697036743, 0.7782805562019348, 0.7850678563117981, 0.7805429697036743, 0.7839366793632507, 0.7873303294181824, 0.7929864525794983, 0.7884615659713745, 0.7963801026344299, 0.7850678563117981, 0.7952488660812378, 0.807692289352417, 0.7941176295280457, 0.8099547624588013, 0.7941176295280457, 0.8031674027442932, 0.7986425161361694, 0.7941176295280457, 0.8020362257957458, 0.7941176295280457, 0.807692289352417, 0.7918552160263062, 0.8212669491767883, 0.8065611124038696, 0.8054298758506775, 0.8065611124038696, 0.8110859990119934, 0.8133484125137329, 0.820135772228241, 0.820135772228241, 0.8099547624588013, 0.8190045356750488, 0.8190045356750488, 0.8190045356750488, 0.8110859990119934, 0.8190045356750488, 0.820135772228241, 0.8178732991218567, 0.8110859990119934, 0.8065611124038696, 0.814479649066925, 0.8257918357849121, 0.8246606588363647, 0.8246606588363647, 0.8190045356750488, 0.8122171759605408, 0.814479649066925, 0.8303167223930359, 0.8303167223930359, 0.820135772228241, 0.831447958946228, 0.8246606588363647, 0.8223981857299805, 0.8291855454444885, 0.820135772228241, 0.8303167223930359, 0.8190045356750488, 0.831447958946228, 0.8325791954994202, 0.8291855454444885, 0.8325791954994202, 0.8246606588363647, 0.8223981857299805, 0.831447958946228, 0.8235294222831726, 0.8269230723381042]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 8s 51ms/step - loss: 1.4306 - accuracy: 0.5646 - val_loss: 1.4291 - val_accuracy: 0.5868\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4189 - accuracy: 0.6124 - val_loss: 1.4226 - val_accuracy: 0.6890\n","Epoch 3/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.4022 - accuracy: 0.6535 - val_loss: 1.4155 - val_accuracy: 0.7231\n","Epoch 4/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.3753 - accuracy: 0.7000 - val_loss: 1.4069 - val_accuracy: 0.7428\n","Epoch 5/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.3384 - accuracy: 0.7140 - val_loss: 1.3957 - val_accuracy: 0.7438\n","Epoch 6/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2934 - accuracy: 0.7276 - val_loss: 1.3815 - val_accuracy: 0.7376\n","Epoch 7/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2588 - accuracy: 0.7370 - val_loss: 1.3642 - val_accuracy: 0.7490\n","Epoch 8/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2369 - accuracy: 0.7362 - val_loss: 1.3481 - val_accuracy: 0.7490\n","Epoch 9/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2264 - accuracy: 0.7364 - val_loss: 1.3335 - val_accuracy: 0.7531\n","Epoch 10/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.2187 - accuracy: 0.7421 - val_loss: 1.3193 - val_accuracy: 0.7541\n","Epoch 11/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2066 - accuracy: 0.7439 - val_loss: 1.3043 - val_accuracy: 0.7572\n","Epoch 12/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1972 - accuracy: 0.7447 - val_loss: 1.2887 - val_accuracy: 0.7572\n","Epoch 13/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1892 - accuracy: 0.7522 - val_loss: 1.2726 - val_accuracy: 0.7428\n","Epoch 14/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.1797 - accuracy: 0.7532 - val_loss: 1.2555 - val_accuracy: 0.7521\n","Epoch 15/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.1683 - accuracy: 0.7641 - val_loss: 1.2366 - val_accuracy: 0.7614\n","Epoch 16/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1581 - accuracy: 0.7615 - val_loss: 1.2188 - val_accuracy: 0.7562\n","Epoch 17/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1498 - accuracy: 0.7685 - val_loss: 1.2083 - val_accuracy: 0.7500\n","Epoch 18/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.1423 - accuracy: 0.7713 - val_loss: 1.1814 - val_accuracy: 0.7655\n","Epoch 19/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.1297 - accuracy: 0.7760 - val_loss: 1.1655 - val_accuracy: 0.7686\n","Epoch 20/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.1195 - accuracy: 0.7793 - val_loss: 1.1483 - val_accuracy: 0.7758\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1115 - accuracy: 0.7835 - val_loss: 1.1418 - val_accuracy: 0.7758\n","Epoch 22/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.1005 - accuracy: 0.7894 - val_loss: 1.1207 - val_accuracy: 0.7851\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0894 - accuracy: 0.7904 - val_loss: 1.1119 - val_accuracy: 0.7800\n","Epoch 24/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0784 - accuracy: 0.8044 - val_loss: 1.1013 - val_accuracy: 0.7903\n","Epoch 25/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0705 - accuracy: 0.7990 - val_loss: 1.0949 - val_accuracy: 0.7913\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0646 - accuracy: 0.8018 - val_loss: 1.0880 - val_accuracy: 0.7893\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0527 - accuracy: 0.8062 - val_loss: 1.0828 - val_accuracy: 0.7882\n","Epoch 28/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0470 - accuracy: 0.8083 - val_loss: 1.0735 - val_accuracy: 0.7872\n","Epoch 29/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0381 - accuracy: 0.8129 - val_loss: 1.0675 - val_accuracy: 0.7903\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0317 - accuracy: 0.8173 - val_loss: 1.0632 - val_accuracy: 0.7903\n","Epoch 31/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0195 - accuracy: 0.8243 - val_loss: 1.0647 - val_accuracy: 0.7924\n","Epoch 32/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0182 - accuracy: 0.8158 - val_loss: 1.0534 - val_accuracy: 0.7955\n","Epoch 33/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0114 - accuracy: 0.8214 - val_loss: 1.0488 - val_accuracy: 0.7944\n","Epoch 34/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0036 - accuracy: 0.8186 - val_loss: 1.0450 - val_accuracy: 0.7986\n","Epoch 35/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9961 - accuracy: 0.8235 - val_loss: 1.0441 - val_accuracy: 0.7986\n","Epoch 36/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9872 - accuracy: 0.8287 - val_loss: 1.0351 - val_accuracy: 0.8017\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9829 - accuracy: 0.8300 - val_loss: 1.0333 - val_accuracy: 0.8006\n","Epoch 38/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9750 - accuracy: 0.8326 - val_loss: 1.0264 - val_accuracy: 0.8027\n","Epoch 39/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9676 - accuracy: 0.8364 - val_loss: 1.0231 - val_accuracy: 0.7996\n","Epoch 40/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9568 - accuracy: 0.8359 - val_loss: 1.0198 - val_accuracy: 0.8048\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9543 - accuracy: 0.8395 - val_loss: 1.0147 - val_accuracy: 0.8037\n","Epoch 42/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9489 - accuracy: 0.8434 - val_loss: 1.0105 - val_accuracy: 0.8079\n","Epoch 43/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9374 - accuracy: 0.8444 - val_loss: 1.0073 - val_accuracy: 0.8110\n","Epoch 44/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9301 - accuracy: 0.8439 - val_loss: 1.0033 - val_accuracy: 0.8099\n","Epoch 45/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9308 - accuracy: 0.8421 - val_loss: 1.0013 - val_accuracy: 0.8089\n","Epoch 46/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9257 - accuracy: 0.8426 - val_loss: 0.9958 - val_accuracy: 0.8120\n","Epoch 47/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9192 - accuracy: 0.8535 - val_loss: 0.9908 - val_accuracy: 0.8151\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9067 - accuracy: 0.8537 - val_loss: 0.9875 - val_accuracy: 0.8110\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9033 - accuracy: 0.8522 - val_loss: 0.9832 - val_accuracy: 0.8151\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8939 - accuracy: 0.8558 - val_loss: 0.9810 - val_accuracy: 0.8151\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8861 - accuracy: 0.8589 - val_loss: 0.9791 - val_accuracy: 0.8130\n","Epoch 52/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8793 - accuracy: 0.8589 - val_loss: 0.9770 - val_accuracy: 0.8120\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8732 - accuracy: 0.8599 - val_loss: 0.9721 - val_accuracy: 0.8151\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8717 - accuracy: 0.8574 - val_loss: 0.9703 - val_accuracy: 0.8058\n","Epoch 55/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8636 - accuracy: 0.8618 - val_loss: 0.9672 - val_accuracy: 0.8130\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8584 - accuracy: 0.8646 - val_loss: 0.9614 - val_accuracy: 0.8151\n","Epoch 57/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8519 - accuracy: 0.8669 - val_loss: 0.9591 - val_accuracy: 0.8130\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8488 - accuracy: 0.8667 - val_loss: 0.9602 - val_accuracy: 0.8048\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8391 - accuracy: 0.8669 - val_loss: 0.9622 - val_accuracy: 0.8110\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8330 - accuracy: 0.8690 - val_loss: 0.9502 - val_accuracy: 0.8140\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8220 - accuracy: 0.8739 - val_loss: 0.9581 - val_accuracy: 0.8110\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8239 - accuracy: 0.8718 - val_loss: 0.9451 - val_accuracy: 0.8130\n","Epoch 63/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8088 - accuracy: 0.8804 - val_loss: 0.9406 - val_accuracy: 0.8161\n","Epoch 64/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8034 - accuracy: 0.8788 - val_loss: 0.9411 - val_accuracy: 0.8151\n","Epoch 65/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7975 - accuracy: 0.8850 - val_loss: 0.9402 - val_accuracy: 0.8171\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7991 - accuracy: 0.8832 - val_loss: 0.9373 - val_accuracy: 0.8151\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7884 - accuracy: 0.8814 - val_loss: 0.9364 - val_accuracy: 0.8089\n","Epoch 68/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7844 - accuracy: 0.8868 - val_loss: 0.9419 - val_accuracy: 0.8048\n","Epoch 69/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.7786 - accuracy: 0.8853 - val_loss: 0.9289 - val_accuracy: 0.8182\n","Epoch 70/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7713 - accuracy: 0.8866 - val_loss: 0.9266 - val_accuracy: 0.8161\n","Epoch 71/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7652 - accuracy: 0.8863 - val_loss: 0.9254 - val_accuracy: 0.8182\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7640 - accuracy: 0.8840 - val_loss: 0.9321 - val_accuracy: 0.8079\n","Epoch 73/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7527 - accuracy: 0.8922 - val_loss: 0.9354 - val_accuracy: 0.8068\n","Epoch 74/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7491 - accuracy: 0.8928 - val_loss: 0.9176 - val_accuracy: 0.8171\n","Epoch 75/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7405 - accuracy: 0.8948 - val_loss: 0.9192 - val_accuracy: 0.8120\n","Epoch 76/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7323 - accuracy: 0.9016 - val_loss: 0.9180 - val_accuracy: 0.8140\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7281 - accuracy: 0.8997 - val_loss: 0.9288 - val_accuracy: 0.8079\n","Epoch 78/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7250 - accuracy: 0.9005 - val_loss: 0.9218 - val_accuracy: 0.8099\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7156 - accuracy: 0.8997 - val_loss: 0.9128 - val_accuracy: 0.8099\n","Epoch 80/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7111 - accuracy: 0.9049 - val_loss: 0.9170 - val_accuracy: 0.8089\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7035 - accuracy: 0.9062 - val_loss: 0.9159 - val_accuracy: 0.8151\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7044 - accuracy: 0.9067 - val_loss: 0.9223 - val_accuracy: 0.8089\n","Epoch 83/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6935 - accuracy: 0.9103 - val_loss: 0.9120 - val_accuracy: 0.8110\n","Epoch 84/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6854 - accuracy: 0.9165 - val_loss: 0.9077 - val_accuracy: 0.8089\n","Epoch 85/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6785 - accuracy: 0.9158 - val_loss: 0.9120 - val_accuracy: 0.8140\n","Epoch 86/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6690 - accuracy: 0.9178 - val_loss: 0.9054 - val_accuracy: 0.8192\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6655 - accuracy: 0.9191 - val_loss: 0.9048 - val_accuracy: 0.8192\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6595 - accuracy: 0.9158 - val_loss: 0.9071 - val_accuracy: 0.8110\n","Epoch 89/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6557 - accuracy: 0.9207 - val_loss: 0.9105 - val_accuracy: 0.8223\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6522 - accuracy: 0.9207 - val_loss: 0.9208 - val_accuracy: 0.8068\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6495 - accuracy: 0.9212 - val_loss: 0.9046 - val_accuracy: 0.8192\n","Epoch 92/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6435 - accuracy: 0.9214 - val_loss: 0.9093 - val_accuracy: 0.8140\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6415 - accuracy: 0.9220 - val_loss: 0.9087 - val_accuracy: 0.8151\n","Epoch 94/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6404 - accuracy: 0.9199 - val_loss: 0.9064 - val_accuracy: 0.8192\n","Epoch 95/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6252 - accuracy: 0.9256 - val_loss: 0.9134 - val_accuracy: 0.8058\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6184 - accuracy: 0.9320 - val_loss: 0.9015 - val_accuracy: 0.8182\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6069 - accuracy: 0.9357 - val_loss: 0.9044 - val_accuracy: 0.8202\n","Epoch 98/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6026 - accuracy: 0.9364 - val_loss: 0.9053 - val_accuracy: 0.8202\n","Epoch 99/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6001 - accuracy: 0.9357 - val_loss: 0.9060 - val_accuracy: 0.8202\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5946 - accuracy: 0.9333 - val_loss: 0.9072 - val_accuracy: 0.8223\n","{'loss': [1.430635929107666, 1.418900489807129, 1.402172327041626, 1.3753376007080078, 1.3384348154067993, 1.2933835983276367, 1.2588121891021729, 1.2369463443756104, 1.2263896465301514, 1.2186720371246338, 1.2065569162368774, 1.1971704959869385, 1.1891745328903198, 1.1796973943710327, 1.1683183908462524, 1.1580755710601807, 1.1498373746871948, 1.1423165798187256, 1.1296697854995728, 1.1195282936096191, 1.1115386486053467, 1.1004647016525269, 1.0894070863723755, 1.0783753395080566, 1.0705249309539795, 1.0646100044250488, 1.0527468919754028, 1.0469505786895752, 1.0381184816360474, 1.0317202806472778, 1.019489049911499, 1.0181618928909302, 1.0113760232925415, 1.003637671470642, 0.9961298704147339, 0.9872335195541382, 0.9828915596008301, 0.9749736189842224, 0.9675647616386414, 0.9567916393280029, 0.9542623162269592, 0.9489051103591919, 0.9373983144760132, 0.9300532341003418, 0.9308342933654785, 0.9256898760795593, 0.9191518425941467, 0.90665602684021, 0.9032573103904724, 0.8938660025596619, 0.8860541582107544, 0.8792508840560913, 0.8731914758682251, 0.8716719150543213, 0.8635571599006653, 0.8583803772926331, 0.8518577814102173, 0.8487935662269592, 0.8390741348266602, 0.8330164551734924, 0.8219982981681824, 0.8238627314567566, 0.8087524175643921, 0.8034120202064514, 0.7975095510482788, 0.7991455793380737, 0.7883629202842712, 0.7843828201293945, 0.7786197662353516, 0.7712810039520264, 0.7651650905609131, 0.7640421390533447, 0.7527258992195129, 0.7491339445114136, 0.7405498027801514, 0.7322885394096375, 0.7280800938606262, 0.7249580025672913, 0.7156141996383667, 0.7110821604728699, 0.7035135626792908, 0.7043646574020386, 0.6935153007507324, 0.6853969693183899, 0.6785194277763367, 0.6690473556518555, 0.6655394434928894, 0.6595367789268494, 0.6557413935661316, 0.6522003412246704, 0.6494574546813965, 0.6434568762779236, 0.6414693593978882, 0.6403527855873108, 0.6251991391181946, 0.6183508634567261, 0.6068959832191467, 0.6026350259780884, 0.6001174449920654, 0.5946107506752014], 'accuracy': [0.5645994544029236, 0.6124030947685242, 0.6534883975982666, 0.699999988079071, 0.7139534950256348, 0.7276485562324524, 0.7369509339332581, 0.7361757159233093, 0.7364341020584106, 0.7421188354492188, 0.7439276576042175, 0.7447028160095215, 0.7521963715553284, 0.7532299757003784, 0.764082670211792, 0.7614986896514893, 0.7684754729270935, 0.7713178396224976, 0.7759689688682556, 0.7793281674385071, 0.7834625244140625, 0.7894057035446167, 0.790439248085022, 0.8043927550315857, 0.7989664077758789, 0.801808774471283, 0.8062015771865845, 0.8082687258720398, 0.8129199147224426, 0.8173126578330994, 0.8242893815040588, 0.8157622814178467, 0.8214470148086548, 0.8186046481132507, 0.8235142230987549, 0.8286821842193604, 0.8299741744995117, 0.8325581550598145, 0.8364341259002686, 0.8359172940254211, 0.8395348787307739, 0.843410849571228, 0.8444444537162781, 0.8439276218414307, 0.8421188592910767, 0.8426356315612793, 0.8534883856773376, 0.853746771812439, 0.8521963953971863, 0.8558139801025391, 0.8589147329330444, 0.8589147329330444, 0.8599483370780945, 0.8573643565177917, 0.8617570996284485, 0.8645994663238525, 0.866925060749054, 0.8666666746139526, 0.866925060749054, 0.868992269039154, 0.8739017844200134, 0.8718346357345581, 0.8803617358207703, 0.8788113594055176, 0.8850129246711731, 0.8832041621208191, 0.8813953399658203, 0.8868216872215271, 0.8852713108062744, 0.8865633010864258, 0.8863049149513245, 0.883979320526123, 0.8922480344772339, 0.8927648663520813, 0.8948320150375366, 0.9015504121780396, 0.8997415900230408, 0.9005168080329895, 0.8997415900230408, 0.9049095511436462, 0.9062015414237976, 0.906718373298645, 0.910335898399353, 0.9165374636650085, 0.9157622456550598, 0.9178294539451599, 0.9191214442253113, 0.9157622456550598, 0.920671820640564, 0.920671820640564, 0.9211886525154114, 0.9214470386505127, 0.9219638109207153, 0.91989666223526, 0.9255813956260681, 0.932041347026825, 0.9356589317321777, 0.9364340901374817, 0.9356589317321777, 0.9333333373069763], 'val_loss': [1.4290962219238281, 1.4225614070892334, 1.4154572486877441, 1.4069108963012695, 1.3957405090332031, 1.3814541101455688, 1.364190697669983, 1.3480662107467651, 1.3334509134292603, 1.319300651550293, 1.3043062686920166, 1.288711667060852, 1.2726134061813354, 1.2555348873138428, 1.2365713119506836, 1.2188118696212769, 1.2082891464233398, 1.181381344795227, 1.1654733419418335, 1.1483376026153564, 1.1417889595031738, 1.1206531524658203, 1.1119107007980347, 1.101265788078308, 1.0948784351348877, 1.0880119800567627, 1.0828489065170288, 1.0734548568725586, 1.0675301551818848, 1.0632297992706299, 1.0647246837615967, 1.0533896684646606, 1.048843502998352, 1.0449578762054443, 1.044114112854004, 1.0350773334503174, 1.0333316326141357, 1.026388168334961, 1.0231126546859741, 1.019797682762146, 1.0146576166152954, 1.010485053062439, 1.0073305368423462, 1.0033183097839355, 1.0012547969818115, 0.9957797527313232, 0.9907832741737366, 0.9874938726425171, 0.9832115769386292, 0.9810181856155396, 0.9791464805603027, 0.9769546985626221, 0.9720683097839355, 0.9703012704849243, 0.9671841263771057, 0.9613950252532959, 0.9591366648674011, 0.9601607918739319, 0.9622330069541931, 0.9502409100532532, 0.9581393599510193, 0.9450515508651733, 0.9405974745750427, 0.9411300420761108, 0.9401780962944031, 0.9372560977935791, 0.9363512992858887, 0.9419122338294983, 0.9288577437400818, 0.926633894443512, 0.9253566861152649, 0.9321074485778809, 0.935375452041626, 0.9175902605056763, 0.9191597104072571, 0.918004035949707, 0.92877596616745, 0.9217533469200134, 0.912782609462738, 0.9169525504112244, 0.9158718585968018, 0.9223071932792664, 0.9119865894317627, 0.9076655507087708, 0.9119570255279541, 0.9053956866264343, 0.9048346281051636, 0.907102108001709, 0.9105448722839355, 0.9207771420478821, 0.9046111702919006, 0.9093428254127502, 0.908689022064209, 0.906370222568512, 0.913419246673584, 0.9015499949455261, 0.9043508768081665, 0.9053289294242859, 0.9059635400772095, 0.9071662425994873], 'val_accuracy': [0.586776852607727, 0.6890496015548706, 0.7231404781341553, 0.7427685856819153, 0.7438016533851624, 0.7376033067703247, 0.7489669322967529, 0.7489669322967529, 0.7530992031097412, 0.7541322112083435, 0.7572314143180847, 0.7572314143180847, 0.7427685856819153, 0.7520661354064941, 0.7613636255264282, 0.7561983466148376, 0.75, 0.7654958963394165, 0.7685950398445129, 0.7758264541625977, 0.7758264541625977, 0.7851239442825317, 0.7799586653709412, 0.7902892827987671, 0.7913222908973694, 0.78925621509552, 0.788223147392273, 0.7871900796890259, 0.7902892827987671, 0.7902892827987671, 0.7923553586006165, 0.7954545617103577, 0.7944214940071106, 0.7985537052154541, 0.7985537052154541, 0.8016529083251953, 0.8006198406219482, 0.8026859760284424, 0.7995867729187012, 0.8047520518302917, 0.8037189841270447, 0.807851254940033, 0.8109503984451294, 0.8099173307418823, 0.80888432264328, 0.8119834661483765, 0.8150826692581177, 0.8109503984451294, 0.8150826692581177, 0.8150826692581177, 0.8130165338516235, 0.8119834661483765, 0.8150826692581177, 0.8057851195335388, 0.8130165338516235, 0.8150826692581177, 0.8130165338516235, 0.8047520518302917, 0.8109503984451294, 0.8140496015548706, 0.8109503984451294, 0.8130165338516235, 0.81611567735672, 0.8150826692581177, 0.817148745059967, 0.8150826692581177, 0.80888432264328, 0.8047520518302917, 0.8181818127632141, 0.81611567735672, 0.8181818127632141, 0.807851254940033, 0.8068181872367859, 0.817148745059967, 0.8119834661483765, 0.8140496015548706, 0.807851254940033, 0.8099173307418823, 0.8099173307418823, 0.80888432264328, 0.8150826692581177, 0.80888432264328, 0.8109503984451294, 0.80888432264328, 0.8140496015548706, 0.8192148804664612, 0.8192148804664612, 0.8109503984451294, 0.8223140239715576, 0.8068181872367859, 0.8192148804664612, 0.8140496015548706, 0.8150826692581177, 0.8192148804664612, 0.8057851195335388, 0.8181818127632141, 0.8202479481697083, 0.8202479481697083, 0.8202479481697083, 0.8223140239715576]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.7067 - accuracy: 0.8848"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 47ms/step - loss: 0.7094 - accuracy: 0.8839 - val_loss: 1.1219 - val_accuracy: 0.4860\n","Epoch 2/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6870 - accuracy: 0.8930 - val_loss: 1.1197 - val_accuracy: 0.4860\n","Epoch 3/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6850 - accuracy: 0.8960 - val_loss: 1.1111 - val_accuracy: 0.4871\n","Epoch 4/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6691 - accuracy: 0.9030 - val_loss: 1.1059 - val_accuracy: 0.4871\n","Epoch 5/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6687 - accuracy: 0.9025 - val_loss: 1.0934 - val_accuracy: 0.4892\n","Epoch 6/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6574 - accuracy: 0.9065 - val_loss: 1.0745 - val_accuracy: 0.5022\n","Epoch 7/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6538 - accuracy: 0.9049 - val_loss: 1.0651 - val_accuracy: 0.5097\n","Epoch 8/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6398 - accuracy: 0.9149 - val_loss: 1.0402 - val_accuracy: 0.5528\n","Epoch 9/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6385 - accuracy: 0.9089 - val_loss: 1.0228 - val_accuracy: 0.5830\n","Epoch 10/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6228 - accuracy: 0.9189 - val_loss: 1.0040 - val_accuracy: 0.6121\n","Epoch 11/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6235 - accuracy: 0.9176 - val_loss: 0.9807 - val_accuracy: 0.6595\n","Epoch 12/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6164 - accuracy: 0.9224 - val_loss: 0.9347 - val_accuracy: 0.7899\n","Epoch 13/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6145 - accuracy: 0.9189 - val_loss: 0.9263 - val_accuracy: 0.7403\n","Epoch 14/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5995 - accuracy: 0.9238 - val_loss: 0.8941 - val_accuracy: 0.7963\n","Epoch 15/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6008 - accuracy: 0.9259 - val_loss: 0.8675 - val_accuracy: 0.8082\n","Epoch 16/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5916 - accuracy: 0.9259 - val_loss: 0.8217 - val_accuracy: 0.8578\n","Epoch 17/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5856 - accuracy: 0.9302 - val_loss: 0.7983 - val_accuracy: 0.8578\n","Epoch 18/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.5809 - accuracy: 0.9300 - val_loss: 0.7715 - val_accuracy: 0.8621\n","Epoch 19/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5736 - accuracy: 0.9321 - val_loss: 0.7481 - val_accuracy: 0.8664\n","Epoch 20/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5681 - accuracy: 0.9337 - val_loss: 0.7405 - val_accuracy: 0.8631\n","Epoch 21/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5622 - accuracy: 0.9345 - val_loss: 0.7289 - val_accuracy: 0.8696\n","Epoch 22/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5605 - accuracy: 0.9370 - val_loss: 0.7087 - val_accuracy: 0.8631\n","Epoch 23/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5511 - accuracy: 0.9432 - val_loss: 0.7278 - val_accuracy: 0.8578\n","Epoch 24/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5523 - accuracy: 0.9367 - val_loss: 0.7001 - val_accuracy: 0.8642\n","Epoch 25/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5443 - accuracy: 0.9399 - val_loss: 0.7017 - val_accuracy: 0.8653\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5317 - accuracy: 0.9499 - val_loss: 0.6991 - val_accuracy: 0.8610\n","Epoch 27/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5386 - accuracy: 0.9407 - val_loss: 0.7004 - val_accuracy: 0.8621\n","Epoch 28/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5298 - accuracy: 0.9413 - val_loss: 0.7386 - val_accuracy: 0.8578\n","Epoch 29/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5139 - accuracy: 0.9512 - val_loss: 0.7068 - val_accuracy: 0.8610\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5157 - accuracy: 0.9496 - val_loss: 0.7078 - val_accuracy: 0.8578\n","Epoch 31/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5139 - accuracy: 0.9494 - val_loss: 0.7152 - val_accuracy: 0.8664\n","Epoch 32/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5057 - accuracy: 0.9539 - val_loss: 0.7103 - val_accuracy: 0.8567\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5003 - accuracy: 0.9545 - val_loss: 0.7359 - val_accuracy: 0.8653\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5038 - accuracy: 0.9529 - val_loss: 0.7141 - val_accuracy: 0.8621\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4953 - accuracy: 0.9555 - val_loss: 0.7163 - val_accuracy: 0.8578\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4883 - accuracy: 0.9574 - val_loss: 0.7174 - val_accuracy: 0.8631\n","Epoch 37/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4823 - accuracy: 0.9588 - val_loss: 0.7183 - val_accuracy: 0.8578\n","Epoch 38/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4763 - accuracy: 0.9604 - val_loss: 0.7189 - val_accuracy: 0.8588\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4741 - accuracy: 0.9604 - val_loss: 0.7259 - val_accuracy: 0.8588\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4736 - accuracy: 0.9617 - val_loss: 0.7266 - val_accuracy: 0.8524\n","Epoch 41/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4720 - accuracy: 0.9607 - val_loss: 0.7317 - val_accuracy: 0.8621\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4644 - accuracy: 0.9593 - val_loss: 0.7269 - val_accuracy: 0.8578\n","Epoch 43/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4568 - accuracy: 0.9652 - val_loss: 0.7239 - val_accuracy: 0.8556\n","Epoch 44/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4635 - accuracy: 0.9644 - val_loss: 0.7435 - val_accuracy: 0.8556\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4568 - accuracy: 0.9663 - val_loss: 0.7219 - val_accuracy: 0.8588\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4491 - accuracy: 0.9663 - val_loss: 0.7261 - val_accuracy: 0.8578\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4413 - accuracy: 0.9701 - val_loss: 0.7225 - val_accuracy: 0.8567\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4384 - accuracy: 0.9696 - val_loss: 0.7262 - val_accuracy: 0.8599\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4410 - accuracy: 0.9655 - val_loss: 0.7309 - val_accuracy: 0.8534\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4332 - accuracy: 0.9712 - val_loss: 0.7350 - val_accuracy: 0.8545\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4298 - accuracy: 0.9714 - val_loss: 0.7465 - val_accuracy: 0.8545\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4220 - accuracy: 0.9747 - val_loss: 0.7425 - val_accuracy: 0.8578\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4240 - accuracy: 0.9709 - val_loss: 0.7649 - val_accuracy: 0.8502\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4240 - accuracy: 0.9731 - val_loss: 0.7382 - val_accuracy: 0.8524\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4103 - accuracy: 0.9776 - val_loss: 0.7382 - val_accuracy: 0.8524\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4110 - accuracy: 0.9776 - val_loss: 0.7407 - val_accuracy: 0.8556\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4005 - accuracy: 0.9822 - val_loss: 0.7722 - val_accuracy: 0.8502\n","Epoch 58/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4028 - accuracy: 0.9820 - val_loss: 0.7552 - val_accuracy: 0.8556\n","Epoch 59/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4007 - accuracy: 0.9784 - val_loss: 0.7787 - val_accuracy: 0.8459\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3998 - accuracy: 0.9811 - val_loss: 0.7637 - val_accuracy: 0.8578\n","Epoch 61/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3915 - accuracy: 0.9825 - val_loss: 0.7610 - val_accuracy: 0.8438\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3910 - accuracy: 0.9822 - val_loss: 0.7666 - val_accuracy: 0.8545\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3932 - accuracy: 0.9803 - val_loss: 0.7799 - val_accuracy: 0.8524\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3872 - accuracy: 0.9841 - val_loss: 0.7619 - val_accuracy: 0.8513\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3845 - accuracy: 0.9820 - val_loss: 0.7783 - val_accuracy: 0.8459\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3830 - accuracy: 0.9825 - val_loss: 0.7753 - val_accuracy: 0.8448\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3776 - accuracy: 0.9830 - val_loss: 0.7645 - val_accuracy: 0.8524\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3739 - accuracy: 0.9852 - val_loss: 0.7810 - val_accuracy: 0.8524\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3725 - accuracy: 0.9852 - val_loss: 0.7744 - val_accuracy: 0.8491\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3679 - accuracy: 0.9846 - val_loss: 0.7766 - val_accuracy: 0.8405\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3720 - accuracy: 0.9860 - val_loss: 0.8025 - val_accuracy: 0.8513\n","Epoch 72/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3678 - accuracy: 0.9868 - val_loss: 0.7826 - val_accuracy: 0.8470\n","Epoch 73/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3700 - accuracy: 0.9852 - val_loss: 0.7861 - val_accuracy: 0.8448\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3614 - accuracy: 0.9876 - val_loss: 0.7835 - val_accuracy: 0.8459\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3566 - accuracy: 0.9890 - val_loss: 0.7873 - val_accuracy: 0.8438\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3554 - accuracy: 0.9887 - val_loss: 0.7874 - val_accuracy: 0.8448\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3577 - accuracy: 0.9868 - val_loss: 0.8037 - val_accuracy: 0.8394\n","Epoch 78/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3502 - accuracy: 0.9863 - val_loss: 0.7916 - val_accuracy: 0.8438\n","Epoch 79/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3482 - accuracy: 0.9892 - val_loss: 0.7965 - val_accuracy: 0.8545\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3476 - accuracy: 0.9895 - val_loss: 0.7963 - val_accuracy: 0.8513\n","Epoch 81/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3429 - accuracy: 0.9908 - val_loss: 0.7998 - val_accuracy: 0.8513\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3402 - accuracy: 0.9908 - val_loss: 0.8039 - val_accuracy: 0.8416\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3372 - accuracy: 0.9914 - val_loss: 0.8108 - val_accuracy: 0.8470\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3383 - accuracy: 0.9895 - val_loss: 0.8080 - val_accuracy: 0.8438\n","Epoch 85/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3337 - accuracy: 0.9925 - val_loss: 0.8255 - val_accuracy: 0.8513\n","Epoch 86/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3362 - accuracy: 0.9890 - val_loss: 0.8085 - val_accuracy: 0.8470\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3322 - accuracy: 0.9900 - val_loss: 0.8084 - val_accuracy: 0.8459\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3310 - accuracy: 0.9916 - val_loss: 0.8318 - val_accuracy: 0.8491\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3274 - accuracy: 0.9919 - val_loss: 0.8165 - val_accuracy: 0.8427\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3259 - accuracy: 0.9914 - val_loss: 0.8189 - val_accuracy: 0.8427\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3236 - accuracy: 0.9911 - val_loss: 0.8282 - val_accuracy: 0.8427\n","Epoch 92/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3226 - accuracy: 0.9916 - val_loss: 0.8213 - val_accuracy: 0.8502\n","Epoch 93/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3219 - accuracy: 0.9916 - val_loss: 0.8181 - val_accuracy: 0.8394\n","Epoch 94/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3177 - accuracy: 0.9938 - val_loss: 0.8208 - val_accuracy: 0.8405\n","Epoch 95/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3161 - accuracy: 0.9938 - val_loss: 0.8217 - val_accuracy: 0.8491\n","Epoch 96/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3225 - accuracy: 0.9908 - val_loss: 0.8473 - val_accuracy: 0.8427\n","Epoch 97/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3154 - accuracy: 0.9927 - val_loss: 0.8230 - val_accuracy: 0.8459\n","Epoch 98/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3104 - accuracy: 0.9949 - val_loss: 0.8319 - val_accuracy: 0.8491\n","Epoch 99/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3140 - accuracy: 0.9941 - val_loss: 0.8302 - val_accuracy: 0.8470\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3067 - accuracy: 0.9949 - val_loss: 0.8421 - val_accuracy: 0.8448\n","{'loss': [0.7093778848648071, 0.6870085000991821, 0.6849524974822998, 0.6691322922706604, 0.6687357425689697, 0.6573901772499084, 0.6538344621658325, 0.6398065686225891, 0.638466477394104, 0.6227524280548096, 0.6234917640686035, 0.6164065003395081, 0.6145166754722595, 0.599513590335846, 0.600757360458374, 0.5915915966033936, 0.5855874419212341, 0.580935537815094, 0.5736222267150879, 0.5681300163269043, 0.5622076392173767, 0.5604588985443115, 0.5510631799697876, 0.5522853136062622, 0.5442532300949097, 0.5316817760467529, 0.5385735034942627, 0.5298494696617126, 0.5138963460922241, 0.5157335996627808, 0.513908863067627, 0.5057262778282166, 0.5002986192703247, 0.5037586688995361, 0.49528083205223083, 0.4883163273334503, 0.48232129216194153, 0.47628095746040344, 0.4740849733352661, 0.473550021648407, 0.47196027636528015, 0.46443936228752136, 0.4568197727203369, 0.4635268449783325, 0.45676952600479126, 0.4491128921508789, 0.44126302003860474, 0.4383554458618164, 0.4409884810447693, 0.43322989344596863, 0.4297632575035095, 0.4220421314239502, 0.42403292655944824, 0.42403799295425415, 0.4102728068828583, 0.4110200107097626, 0.40048590302467346, 0.40276455879211426, 0.4006735384464264, 0.3998011350631714, 0.3914864659309387, 0.3909984827041626, 0.3932400643825531, 0.3872344195842743, 0.38452988862991333, 0.3830077648162842, 0.3775961101055145, 0.37393248081207275, 0.37248411774635315, 0.36788037419319153, 0.3720179498195648, 0.367840439081192, 0.36995798349380493, 0.36142727732658386, 0.3565547466278076, 0.355403333902359, 0.35773181915283203, 0.35017406940460205, 0.34816044569015503, 0.3475654423236847, 0.34291788935661316, 0.3401612639427185, 0.3372459411621094, 0.3382731080055237, 0.33365580439567566, 0.3362070918083191, 0.3321719765663147, 0.3309575915336609, 0.3273875117301941, 0.32590821385383606, 0.32364365458488464, 0.32257989048957825, 0.32193973660469055, 0.3177426755428314, 0.31607481837272644, 0.32253795862197876, 0.31539350748062134, 0.3104071319103241, 0.31401917338371277, 0.30674439668655396], 'accuracy': [0.8838900923728943, 0.8930495977401733, 0.8960129022598267, 0.9030172228813171, 0.9024784564971924, 0.9065194129943848, 0.904902994632721, 0.9148706793785095, 0.9089439511299133, 0.9189116358757019, 0.9175646305084229, 0.9224137663841248, 0.9189116358757019, 0.9237607717514038, 0.9259159564971924, 0.9259159564971924, 0.9302262663841248, 0.9299569129943848, 0.9321120977401733, 0.9337284564971924, 0.9345366358757019, 0.9369612336158752, 0.9431573152542114, 0.9366918206214905, 0.9399245977401733, 0.9498922228813171, 0.9407327771186829, 0.9412715435028076, 0.9512392282485962, 0.9496228694915771, 0.9493534564971924, 0.9539331793785095, 0.954472005367279, 0.9528555870056152, 0.9555495977401733, 0.9574353694915771, 0.9587823152542114, 0.9603987336158752, 0.9603987336158752, 0.9617456793785095, 0.9606680870056152, 0.959321141242981, 0.9652478694915771, 0.9644396305084229, 0.9663254022598267, 0.9663254022598267, 0.970097005367279, 0.9695581793785095, 0.9655172228813171, 0.9711745977401733, 0.9714439511299133, 0.9746767282485962, 0.9709051847457886, 0.9730603694915771, 0.9776400923728943, 0.9776400923728943, 0.9822198152542114, 0.9819504022598267, 0.9784482717514038, 0.9811422228813171, 0.9824892282485962, 0.9822198152542114, 0.9803340435028076, 0.9841055870056152, 0.9819504022598267, 0.9824892282485962, 0.983027994632721, 0.9851831793785095, 0.9851831793785095, 0.9846444129943848, 0.985991358757019, 0.9867995977401733, 0.9851831793785095, 0.9876077771186829, 0.9889547228813171, 0.9886853694915771, 0.9867995977401733, 0.9862607717514038, 0.9892241358757019, 0.9894935488700867, 0.990840494632721, 0.990840494632721, 0.9913793206214905, 0.9894935488700867, 0.9924569129943848, 0.9889547228813171, 0.9900323152542114, 0.9916487336158752, 0.9919180870056152, 0.9913793206214905, 0.9911099076271057, 0.9916487336158752, 0.9916487336158752, 0.993803858757019, 0.993803858757019, 0.990840494632721, 0.9927262663841248, 0.9948814511299133, 0.9940732717514038, 0.9948814511299133], 'val_loss': [1.1218868494033813, 1.1197247505187988, 1.1110804080963135, 1.1058605909347534, 1.0933775901794434, 1.0744662284851074, 1.0651085376739502, 1.0401978492736816, 1.022790551185608, 1.0039623975753784, 0.9807072877883911, 0.9346957802772522, 0.9262974858283997, 0.8941285610198975, 0.8675111532211304, 0.8217333555221558, 0.7983403205871582, 0.7714711427688599, 0.7480717301368713, 0.7404563426971436, 0.7289018034934998, 0.7086827754974365, 0.7278385162353516, 0.7001060247421265, 0.7016538381576538, 0.6991068124771118, 0.7003867626190186, 0.738633930683136, 0.7068044543266296, 0.7077640295028687, 0.7152231335639954, 0.7102687954902649, 0.7358778715133667, 0.7141444087028503, 0.7163161635398865, 0.7174184918403625, 0.7182871103286743, 0.718916654586792, 0.7259264588356018, 0.7265982627868652, 0.7316644787788391, 0.7269029021263123, 0.7239267826080322, 0.7434921264648438, 0.721925675868988, 0.7261096835136414, 0.7225077152252197, 0.7262024879455566, 0.7309128046035767, 0.7349836230278015, 0.7464773058891296, 0.7424899339675903, 0.764861524105072, 0.7381824851036072, 0.7381570935249329, 0.7406979203224182, 0.7721666097640991, 0.7552285194396973, 0.7787430286407471, 0.7636902928352356, 0.7610132098197937, 0.7666414380073547, 0.7799364328384399, 0.7618793845176697, 0.7782756686210632, 0.7753074765205383, 0.7645062804222107, 0.7810086011886597, 0.7744306921958923, 0.7766063809394836, 0.8024927973747253, 0.782637894153595, 0.7860787510871887, 0.7834912538528442, 0.7872647643089294, 0.787362813949585, 0.8037047386169434, 0.7916111946105957, 0.7965000867843628, 0.7962902784347534, 0.799837589263916, 0.8038923740386963, 0.8107605576515198, 0.8080416917800903, 0.8255146741867065, 0.8085091710090637, 0.8083812594413757, 0.8318386673927307, 0.8165489435195923, 0.8189042210578918, 0.8282491564750671, 0.8212500810623169, 0.818114697933197, 0.8207893967628479, 0.8216855525970459, 0.8473453521728516, 0.8229643106460571, 0.831920862197876, 0.8301502466201782, 0.8421438932418823], 'val_accuracy': [0.48599138855934143, 0.48599138855934143, 0.48706895112991333, 0.48706895112991333, 0.4892241358757019, 0.5021551847457886, 0.5096982717514038, 0.5528017282485962, 0.5829741358757019, 0.6120689511299133, 0.6594827771186829, 0.7898706793785095, 0.7403017282485962, 0.7963362336158752, 0.8081896305084229, 0.857758641242981, 0.857758641242981, 0.8620689511299133, 0.8663793206214905, 0.8631465435028076, 0.8696120977401733, 0.8631465435028076, 0.857758641242981, 0.8642241358757019, 0.8653017282485962, 0.860991358757019, 0.8620689511299133, 0.857758641242981, 0.860991358757019, 0.857758641242981, 0.8663793206214905, 0.8566810488700867, 0.8653017282485962, 0.8620689511299133, 0.857758641242981, 0.8631465435028076, 0.857758641242981, 0.8588362336158752, 0.8588362336158752, 0.8523706793785095, 0.8620689511299133, 0.857758641242981, 0.8556034564971924, 0.8556034564971924, 0.8588362336158752, 0.857758641242981, 0.8566810488700867, 0.8599137663841248, 0.8534482717514038, 0.8545258641242981, 0.8545258641242981, 0.857758641242981, 0.850215494632721, 0.8523706793785095, 0.8523706793785095, 0.8556034564971924, 0.850215494632721, 0.8556034564971924, 0.8459051847457886, 0.857758641242981, 0.84375, 0.8545258641242981, 0.8523706793785095, 0.8512930870056152, 0.8459051847457886, 0.8448275923728943, 0.8523706793785095, 0.8523706793785095, 0.8491379022598267, 0.8405172228813171, 0.8512930870056152, 0.8469827771186829, 0.8448275923728943, 0.8459051847457886, 0.84375, 0.8448275923728943, 0.8394396305084229, 0.84375, 0.8545258641242981, 0.8512930870056152, 0.8512930870056152, 0.8415948152542114, 0.8469827771186829, 0.84375, 0.8512930870056152, 0.8469827771186829, 0.8459051847457886, 0.8491379022598267, 0.8426724076271057, 0.8426724076271057, 0.8426724076271057, 0.850215494632721, 0.8394396305084229, 0.8405172228813171, 0.8491379022598267, 0.8426724076271057, 0.8459051847457886, 0.8491379022598267, 0.8469827771186829, 0.8448275923728943]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.7186 - accuracy: 0.8759"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 72ms/step - loss: 0.7189 - accuracy: 0.8752 - val_loss: 1.1226 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6969 - accuracy: 0.8871 - val_loss: 1.1166 - val_accuracy: 0.4966\n","Epoch 3/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6928 - accuracy: 0.8899 - val_loss: 1.1035 - val_accuracy: 0.4977\n","Epoch 4/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6915 - accuracy: 0.8879 - val_loss: 1.0973 - val_accuracy: 0.4977\n","Epoch 5/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6792 - accuracy: 0.8933 - val_loss: 1.0876 - val_accuracy: 0.5011\n","Epoch 6/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6703 - accuracy: 0.8964 - val_loss: 1.0767 - val_accuracy: 0.5079\n","Epoch 7/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6657 - accuracy: 0.9007 - val_loss: 1.0603 - val_accuracy: 0.5283\n","Epoch 8/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6502 - accuracy: 0.9041 - val_loss: 1.0426 - val_accuracy: 0.5509\n","Epoch 9/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6442 - accuracy: 0.9083 - val_loss: 1.0235 - val_accuracy: 0.5973\n","Epoch 10/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6431 - accuracy: 0.9069 - val_loss: 1.0150 - val_accuracy: 0.5928\n","Epoch 11/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6389 - accuracy: 0.9038 - val_loss: 0.9784 - val_accuracy: 0.6968\n","Epoch 12/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6308 - accuracy: 0.9075 - val_loss: 0.9583 - val_accuracy: 0.7172\n","Epoch 13/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6248 - accuracy: 0.9171 - val_loss: 0.9361 - val_accuracy: 0.7398\n","Epoch 14/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6181 - accuracy: 0.9154 - val_loss: 0.9117 - val_accuracy: 0.7715\n","Epoch 15/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6134 - accuracy: 0.9145 - val_loss: 0.8859 - val_accuracy: 0.7907\n","Epoch 16/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6029 - accuracy: 0.9236 - val_loss: 0.8595 - val_accuracy: 0.8088\n","Epoch 17/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6062 - accuracy: 0.9185 - val_loss: 0.8124 - val_accuracy: 0.8541\n","Epoch 18/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6026 - accuracy: 0.9165 - val_loss: 0.7862 - val_accuracy: 0.8586\n","Epoch 19/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5929 - accuracy: 0.9188 - val_loss: 0.7878 - val_accuracy: 0.8462\n","Epoch 20/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5887 - accuracy: 0.9171 - val_loss: 0.7536 - val_accuracy: 0.8541\n","Epoch 21/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5791 - accuracy: 0.9290 - val_loss: 0.7367 - val_accuracy: 0.8575\n","Epoch 22/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5742 - accuracy: 0.9270 - val_loss: 0.7215 - val_accuracy: 0.8631\n","Epoch 23/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5627 - accuracy: 0.9372 - val_loss: 0.7187 - val_accuracy: 0.8631\n","Epoch 24/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5659 - accuracy: 0.9301 - val_loss: 0.7087 - val_accuracy: 0.8643\n","Epoch 25/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.5604 - accuracy: 0.9329 - val_loss: 0.7088 - val_accuracy: 0.8654\n","Epoch 26/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5529 - accuracy: 0.9372 - val_loss: 0.7088 - val_accuracy: 0.8643\n","Epoch 27/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5461 - accuracy: 0.9383 - val_loss: 0.7109 - val_accuracy: 0.8699\n","Epoch 28/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5420 - accuracy: 0.9394 - val_loss: 0.7105 - val_accuracy: 0.8654\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5326 - accuracy: 0.9440 - val_loss: 0.7186 - val_accuracy: 0.8665\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5330 - accuracy: 0.9403 - val_loss: 0.7140 - val_accuracy: 0.8643\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5238 - accuracy: 0.9454 - val_loss: 0.7298 - val_accuracy: 0.8597\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5178 - accuracy: 0.9502 - val_loss: 0.7208 - val_accuracy: 0.8688\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5170 - accuracy: 0.9460 - val_loss: 0.7214 - val_accuracy: 0.8654\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5179 - accuracy: 0.9454 - val_loss: 0.7272 - val_accuracy: 0.8631\n","Epoch 35/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5019 - accuracy: 0.9542 - val_loss: 0.7260 - val_accuracy: 0.8643\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4947 - accuracy: 0.9576 - val_loss: 0.7273 - val_accuracy: 0.8665\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4923 - accuracy: 0.9584 - val_loss: 0.7268 - val_accuracy: 0.8688\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4857 - accuracy: 0.9578 - val_loss: 0.7450 - val_accuracy: 0.8665\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4876 - accuracy: 0.9590 - val_loss: 0.7290 - val_accuracy: 0.8688\n","Epoch 40/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4822 - accuracy: 0.9601 - val_loss: 0.7332 - val_accuracy: 0.8609\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4793 - accuracy: 0.9561 - val_loss: 0.7358 - val_accuracy: 0.8654\n","Epoch 42/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4679 - accuracy: 0.9652 - val_loss: 0.7358 - val_accuracy: 0.8620\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4682 - accuracy: 0.9641 - val_loss: 0.7491 - val_accuracy: 0.8609\n","Epoch 44/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4653 - accuracy: 0.9629 - val_loss: 0.7383 - val_accuracy: 0.8688\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4602 - accuracy: 0.9643 - val_loss: 0.7350 - val_accuracy: 0.8665\n","Epoch 46/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4582 - accuracy: 0.9683 - val_loss: 0.7368 - val_accuracy: 0.8586\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4510 - accuracy: 0.9658 - val_loss: 0.7478 - val_accuracy: 0.8597\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4478 - accuracy: 0.9660 - val_loss: 0.7452 - val_accuracy: 0.8586\n","Epoch 49/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4403 - accuracy: 0.9731 - val_loss: 0.7426 - val_accuracy: 0.8665\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4409 - accuracy: 0.9686 - val_loss: 0.7528 - val_accuracy: 0.8586\n","Epoch 51/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4353 - accuracy: 0.9728 - val_loss: 0.7510 - val_accuracy: 0.8676\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4311 - accuracy: 0.9754 - val_loss: 0.7441 - val_accuracy: 0.8676\n","Epoch 53/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4275 - accuracy: 0.9731 - val_loss: 0.7734 - val_accuracy: 0.8563\n","Epoch 54/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4344 - accuracy: 0.9692 - val_loss: 0.7608 - val_accuracy: 0.8597\n","Epoch 55/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4266 - accuracy: 0.9709 - val_loss: 0.7496 - val_accuracy: 0.8609\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4190 - accuracy: 0.9754 - val_loss: 0.7469 - val_accuracy: 0.8654\n","Epoch 57/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4196 - accuracy: 0.9745 - val_loss: 0.7595 - val_accuracy: 0.8563\n","Epoch 58/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4123 - accuracy: 0.9791 - val_loss: 0.7533 - val_accuracy: 0.8665\n","Epoch 59/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4048 - accuracy: 0.9819 - val_loss: 0.7566 - val_accuracy: 0.8665\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4051 - accuracy: 0.9802 - val_loss: 0.7585 - val_accuracy: 0.8654\n","Epoch 61/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4058 - accuracy: 0.9810 - val_loss: 0.8020 - val_accuracy: 0.8575\n","Epoch 62/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4050 - accuracy: 0.9785 - val_loss: 0.7674 - val_accuracy: 0.8665\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4028 - accuracy: 0.9793 - val_loss: 0.7624 - val_accuracy: 0.8609\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3975 - accuracy: 0.9808 - val_loss: 0.7612 - val_accuracy: 0.8688\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3923 - accuracy: 0.9836 - val_loss: 0.7587 - val_accuracy: 0.8631\n","Epoch 66/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3901 - accuracy: 0.9847 - val_loss: 0.7661 - val_accuracy: 0.8597\n","Epoch 67/100\n","28/28 [==============================] - 1s 42ms/step - loss: 0.3825 - accuracy: 0.9853 - val_loss: 0.7618 - val_accuracy: 0.8722\n","Epoch 68/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3834 - accuracy: 0.9836 - val_loss: 0.7598 - val_accuracy: 0.8710\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3759 - accuracy: 0.9890 - val_loss: 0.7653 - val_accuracy: 0.8688\n","Epoch 70/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3764 - accuracy: 0.9873 - val_loss: 0.8174 - val_accuracy: 0.8518\n","Epoch 71/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3783 - accuracy: 0.9847 - val_loss: 0.7998 - val_accuracy: 0.8620\n","Epoch 72/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3802 - accuracy: 0.9844 - val_loss: 0.7747 - val_accuracy: 0.8699\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3689 - accuracy: 0.9878 - val_loss: 0.7722 - val_accuracy: 0.8665\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3696 - accuracy: 0.9859 - val_loss: 0.7844 - val_accuracy: 0.8631\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3692 - accuracy: 0.9867 - val_loss: 0.7716 - val_accuracy: 0.8688\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3667 - accuracy: 0.9878 - val_loss: 0.7807 - val_accuracy: 0.8631\n","Epoch 77/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3696 - accuracy: 0.9847 - val_loss: 0.7878 - val_accuracy: 0.8620\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3636 - accuracy: 0.9884 - val_loss: 0.8048 - val_accuracy: 0.8575\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3579 - accuracy: 0.9892 - val_loss: 0.7857 - val_accuracy: 0.8699\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3664 - accuracy: 0.9827 - val_loss: 0.8051 - val_accuracy: 0.8586\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3544 - accuracy: 0.9898 - val_loss: 0.7831 - val_accuracy: 0.8631\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3505 - accuracy: 0.9918 - val_loss: 0.7863 - val_accuracy: 0.8665\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3522 - accuracy: 0.9892 - val_loss: 0.7829 - val_accuracy: 0.8620\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3454 - accuracy: 0.9909 - val_loss: 0.7862 - val_accuracy: 0.8643\n","Epoch 85/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3445 - accuracy: 0.9904 - val_loss: 0.8019 - val_accuracy: 0.8609\n","Epoch 86/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3446 - accuracy: 0.9901 - val_loss: 0.8000 - val_accuracy: 0.8597\n","Epoch 87/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3391 - accuracy: 0.9926 - val_loss: 0.7881 - val_accuracy: 0.8676\n","Epoch 88/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3402 - accuracy: 0.9932 - val_loss: 0.7918 - val_accuracy: 0.8631\n","Epoch 89/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3406 - accuracy: 0.9907 - val_loss: 0.7960 - val_accuracy: 0.8676\n","Epoch 90/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3355 - accuracy: 0.9912 - val_loss: 0.7877 - val_accuracy: 0.8654\n","Epoch 91/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3314 - accuracy: 0.9932 - val_loss: 0.8282 - val_accuracy: 0.8575\n","Epoch 92/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3340 - accuracy: 0.9909 - val_loss: 0.8035 - val_accuracy: 0.8643\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3316 - accuracy: 0.9924 - val_loss: 0.8089 - val_accuracy: 0.8631\n","Epoch 94/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3282 - accuracy: 0.9921 - val_loss: 0.7942 - val_accuracy: 0.8631\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3247 - accuracy: 0.9946 - val_loss: 0.8043 - val_accuracy: 0.8597\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3232 - accuracy: 0.9924 - val_loss: 0.7987 - val_accuracy: 0.8609\n","Epoch 97/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3231 - accuracy: 0.9924 - val_loss: 0.8092 - val_accuracy: 0.8575\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3200 - accuracy: 0.9941 - val_loss: 0.7981 - val_accuracy: 0.8597\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3213 - accuracy: 0.9938 - val_loss: 0.8105 - val_accuracy: 0.8563\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3162 - accuracy: 0.9949 - val_loss: 0.8031 - val_accuracy: 0.8654\n","{'loss': [0.718853771686554, 0.6969241499900818, 0.6927632093429565, 0.6915425062179565, 0.6792325973510742, 0.6703465580940247, 0.6656992435455322, 0.6502437591552734, 0.644243061542511, 0.6430880427360535, 0.6389393210411072, 0.6307983994483948, 0.6248113512992859, 0.6181079745292664, 0.6133838891983032, 0.602910578250885, 0.6061990857124329, 0.6025649905204773, 0.5929155945777893, 0.5886818766593933, 0.5791254043579102, 0.5742416381835938, 0.5627206563949585, 0.5658640265464783, 0.5603978037834167, 0.5529153347015381, 0.5461481809616089, 0.5419979691505432, 0.5325779318809509, 0.5330157279968262, 0.5237525105476379, 0.5177958011627197, 0.5169845819473267, 0.5178794264793396, 0.5018671751022339, 0.4946821630001068, 0.49228647351264954, 0.4857196807861328, 0.4876030683517456, 0.48215508460998535, 0.47927406430244446, 0.46793612837791443, 0.4682334065437317, 0.46529725193977356, 0.4601624608039856, 0.4582168161869049, 0.45103442668914795, 0.4478098750114441, 0.4402802884578705, 0.44088953733444214, 0.43529483675956726, 0.43106111884117126, 0.42754292488098145, 0.4343913495540619, 0.42655134201049805, 0.4189544916152954, 0.41963255405426025, 0.4122675061225891, 0.4048269987106323, 0.40508005023002625, 0.405788391828537, 0.4049954116344452, 0.4028002619743347, 0.39745184779167175, 0.3922969102859497, 0.390094131231308, 0.38251572847366333, 0.38335946202278137, 0.3758516013622284, 0.3764055669307709, 0.37828269600868225, 0.38023948669433594, 0.3689262866973877, 0.36962059140205383, 0.3691616654396057, 0.36668816208839417, 0.3696306645870209, 0.36360689997673035, 0.3578779697418213, 0.3664119839668274, 0.3543774485588074, 0.3505370318889618, 0.3521893620491028, 0.34535813331604004, 0.3445263206958771, 0.3445656895637512, 0.3390941917896271, 0.34015172719955444, 0.34060215950012207, 0.3354892432689667, 0.3313998281955719, 0.3339616060256958, 0.3316481411457062, 0.3281751573085785, 0.3246961534023285, 0.3232230544090271, 0.3230733573436737, 0.3199605643749237, 0.3212643563747406, 0.3162379860877991], 'accuracy': [0.8752122521400452, 0.8870967626571655, 0.8899264335632324, 0.8879456520080566, 0.8933219909667969, 0.8964346647262573, 0.9006791114807129, 0.9040747284889221, 0.9083191752433777, 0.9069043397903442, 0.9037917256355286, 0.9074702858924866, 0.9170911312103271, 0.9153932929039001, 0.914544403553009, 0.9235993027687073, 0.9185059666633606, 0.9165251851081848, 0.9187889099121094, 0.9170911312103271, 0.9289756417274475, 0.9269949197769165, 0.9371816515922546, 0.9301075339317322, 0.9329372048377991, 0.9371816515922546, 0.9383135437965393, 0.9394453763961792, 0.9439728260040283, 0.9402942657470703, 0.9453876614570618, 0.9501980543136597, 0.9459536075592041, 0.9453876614570618, 0.9541596174240112, 0.9575551748275757, 0.9584040641784668, 0.9578381180763245, 0.9589700102806091, 0.960101842880249, 0.9561403393745422, 0.9651952385902405, 0.9640634059906006, 0.9629315137863159, 0.9643463492393494, 0.9683078527450562, 0.9657611846923828, 0.9660441279411316, 0.9731183052062988, 0.9685908555984497, 0.9728353023529053, 0.9753820300102234, 0.9731183052062988, 0.9691567420959473, 0.9708545804023743, 0.9753820300102234, 0.9745330810546875, 0.9790605306625366, 0.9818902015686035, 0.9801924228668213, 0.9810413122177124, 0.9784946441650391, 0.9793435335159302, 0.9807583689689636, 0.9835879802703857, 0.9847198724746704, 0.9852858185768127, 0.9835879802703857, 0.988964319229126, 0.9872665405273438, 0.9847198724746704, 0.9844368696212769, 0.9878324866294861, 0.9858517050743103, 0.9867005944252014, 0.9878324866294861, 0.9847198724746704, 0.9883984327316284, 0.9892473220825195, 0.9827390909194946, 0.9898132681846619, 0.9917939901351929, 0.9892473220825195, 0.9909451007843018, 0.9903791546821594, 0.9900962114334106, 0.992642879486084, 0.9932088255882263, 0.990662157535553, 0.9912280440330505, 0.9932088255882263, 0.9909451007843018, 0.9923599362373352, 0.9920769929885864, 0.9946236610412598, 0.9923599362373352, 0.9923599362373352, 0.9940577149391174, 0.9937747716903687, 0.9949066042900085], 'val_loss': [1.122585415840149, 1.1165986061096191, 1.1034564971923828, 1.0972522497177124, 1.087583065032959, 1.0767009258270264, 1.0603106021881104, 1.042567253112793, 1.0234845876693726, 1.0149528980255127, 0.9784480333328247, 0.958336591720581, 0.9361009001731873, 0.9117106199264526, 0.8858826160430908, 0.8594825863838196, 0.8123849630355835, 0.7861983776092529, 0.7878271341323853, 0.7535623908042908, 0.7366696000099182, 0.7214509844779968, 0.718743622303009, 0.7087273001670837, 0.7088016271591187, 0.7087819576263428, 0.710949182510376, 0.7105399370193481, 0.7186040282249451, 0.7139657735824585, 0.7297632694244385, 0.7207663655281067, 0.7214201092720032, 0.7272475361824036, 0.7259555459022522, 0.727345883846283, 0.7268263101577759, 0.7450138330459595, 0.7289910912513733, 0.7332466244697571, 0.7358277440071106, 0.7357710003852844, 0.7490649223327637, 0.7382521033287048, 0.7349889278411865, 0.7367867827415466, 0.7478453516960144, 0.7451914548873901, 0.7426202297210693, 0.7528288960456848, 0.7510228753089905, 0.744087815284729, 0.7733901143074036, 0.7607696652412415, 0.7495957612991333, 0.746870219707489, 0.7595428228378296, 0.7532504796981812, 0.756592333316803, 0.7585086226463318, 0.8019734621047974, 0.767390787601471, 0.7623817324638367, 0.7612380385398865, 0.7587065100669861, 0.7661421895027161, 0.7618139386177063, 0.7598300576210022, 0.7653481960296631, 0.8173676133155823, 0.799795925617218, 0.7747231125831604, 0.7722082138061523, 0.7844095826148987, 0.7716358304023743, 0.7807183861732483, 0.7877576947212219, 0.8048297166824341, 0.7857391238212585, 0.8051470518112183, 0.7831010818481445, 0.7862610816955566, 0.7829364538192749, 0.7862090468406677, 0.8019459843635559, 0.8000438809394836, 0.7880914211273193, 0.791813850402832, 0.7960270643234253, 0.7877146601676941, 0.8282438516616821, 0.8034685254096985, 0.8088972568511963, 0.7942165732383728, 0.8043485879898071, 0.7987172603607178, 0.8092395663261414, 0.7980743050575256, 0.810547411441803, 0.8031432032585144], 'val_accuracy': [0.4954751133918762, 0.49660632014274597, 0.4977375566959381, 0.4977375566959381, 0.5011312365531921, 0.5079185366630554, 0.5282805562019348, 0.5509049892425537, 0.5972850918769836, 0.5927602052688599, 0.6968325972557068, 0.7171945571899414, 0.7398189902305603, 0.7714931964874268, 0.790723979473114, 0.8088235259056091, 0.8540723919868469, 0.8585972785949707, 0.8461538553237915, 0.8540723919868469, 0.8574660420417786, 0.8631221652030945, 0.8631221652030945, 0.8642534017562866, 0.8653846383094788, 0.8642534017562866, 0.8699095249176025, 0.8653846383094788, 0.8665158152580261, 0.8642534017562866, 0.8597285151481628, 0.8687782883644104, 0.8653846383094788, 0.8631221652030945, 0.8642534017562866, 0.8665158152580261, 0.8687782883644104, 0.8665158152580261, 0.8687782883644104, 0.860859751701355, 0.8653846383094788, 0.8619909286499023, 0.860859751701355, 0.8687782883644104, 0.8665158152580261, 0.8585972785949707, 0.8597285151481628, 0.8585972785949707, 0.8665158152580261, 0.8585972785949707, 0.8676470518112183, 0.8676470518112183, 0.8563348650932312, 0.8597285151481628, 0.860859751701355, 0.8653846383094788, 0.8563348650932312, 0.8665158152580261, 0.8665158152580261, 0.8653846383094788, 0.8574660420417786, 0.8665158152580261, 0.860859751701355, 0.8687782883644104, 0.8631221652030945, 0.8597285151481628, 0.872171938419342, 0.8710407018661499, 0.8687782883644104, 0.8518099784851074, 0.8619909286499023, 0.8699095249176025, 0.8665158152580261, 0.8631221652030945, 0.8687782883644104, 0.8631221652030945, 0.8619909286499023, 0.8574660420417786, 0.8699095249176025, 0.8585972785949707, 0.8631221652030945, 0.8665158152580261, 0.8619909286499023, 0.8642534017562866, 0.860859751701355, 0.8597285151481628, 0.8676470518112183, 0.8631221652030945, 0.8676470518112183, 0.8653846383094788, 0.8574660420417786, 0.8642534017562866, 0.8631221652030945, 0.8631221652030945, 0.8597285151481628, 0.860859751701355, 0.8574660420417786, 0.8597285151481628, 0.8563348650932312, 0.8653846383094788]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 8s 49ms/step - loss: 0.7160 - accuracy: 0.8860 - val_loss: 1.1250 - val_accuracy: 0.4855\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6935 - accuracy: 0.8935 - val_loss: 1.1181 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.6807 - accuracy: 0.8972 - val_loss: 1.1070 - val_accuracy: 0.4876\n","Epoch 4/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6761 - accuracy: 0.8987 - val_loss: 1.0960 - val_accuracy: 0.4907\n","Epoch 5/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6624 - accuracy: 0.9080 - val_loss: 1.0875 - val_accuracy: 0.4938\n","Epoch 6/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6584 - accuracy: 0.9052 - val_loss: 1.0721 - val_accuracy: 0.5062\n","Epoch 7/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6568 - accuracy: 0.9010 - val_loss: 1.0623 - val_accuracy: 0.5103\n","Epoch 8/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6495 - accuracy: 0.9072 - val_loss: 1.0444 - val_accuracy: 0.5475\n","Epoch 9/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6395 - accuracy: 0.9096 - val_loss: 1.0165 - val_accuracy: 0.6023\n","Epoch 10/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6461 - accuracy: 0.9005 - val_loss: 1.0138 - val_accuracy: 0.5816\n","Epoch 11/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6291 - accuracy: 0.9106 - val_loss: 0.9603 - val_accuracy: 0.7221\n","Epoch 12/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6264 - accuracy: 0.9140 - val_loss: 0.9397 - val_accuracy: 0.7376\n","Epoch 13/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6165 - accuracy: 0.9152 - val_loss: 0.8860 - val_accuracy: 0.8337\n","Epoch 14/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6127 - accuracy: 0.9202 - val_loss: 0.8695 - val_accuracy: 0.8275\n","Epoch 15/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6066 - accuracy: 0.9199 - val_loss: 0.8423 - val_accuracy: 0.8264\n","Epoch 16/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5966 - accuracy: 0.9261 - val_loss: 0.8046 - val_accuracy: 0.8450\n","Epoch 17/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5979 - accuracy: 0.9196 - val_loss: 0.8103 - val_accuracy: 0.8233\n","Epoch 18/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5940 - accuracy: 0.9207 - val_loss: 0.7675 - val_accuracy: 0.8533\n","Epoch 19/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5795 - accuracy: 0.9271 - val_loss: 0.7557 - val_accuracy: 0.8492\n","Epoch 20/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5791 - accuracy: 0.9295 - val_loss: 0.7360 - val_accuracy: 0.8502\n","Epoch 21/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5774 - accuracy: 0.9276 - val_loss: 0.7449 - val_accuracy: 0.8461\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5688 - accuracy: 0.9305 - val_loss: 0.7161 - val_accuracy: 0.8523\n","Epoch 23/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5598 - accuracy: 0.9354 - val_loss: 0.7085 - val_accuracy: 0.8574\n","Epoch 24/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5526 - accuracy: 0.9395 - val_loss: 0.7148 - val_accuracy: 0.8481\n","Epoch 25/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5524 - accuracy: 0.9346 - val_loss: 0.7116 - val_accuracy: 0.8595\n","Epoch 26/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5424 - accuracy: 0.9364 - val_loss: 0.7145 - val_accuracy: 0.8502\n","Epoch 27/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5394 - accuracy: 0.9413 - val_loss: 0.7215 - val_accuracy: 0.8533\n","Epoch 28/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5388 - accuracy: 0.9393 - val_loss: 0.7159 - val_accuracy: 0.8585\n","Epoch 29/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5300 - accuracy: 0.9406 - val_loss: 0.7194 - val_accuracy: 0.8564\n","Epoch 30/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5225 - accuracy: 0.9450 - val_loss: 0.7228 - val_accuracy: 0.8523\n","Epoch 31/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5214 - accuracy: 0.9465 - val_loss: 0.7272 - val_accuracy: 0.8585\n","Epoch 32/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5139 - accuracy: 0.9473 - val_loss: 0.7269 - val_accuracy: 0.8512\n","Epoch 33/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.5127 - accuracy: 0.9499 - val_loss: 0.7228 - val_accuracy: 0.8605\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5140 - accuracy: 0.9439 - val_loss: 0.7662 - val_accuracy: 0.8388\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5042 - accuracy: 0.9496 - val_loss: 0.7249 - val_accuracy: 0.8533\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4993 - accuracy: 0.9481 - val_loss: 0.7239 - val_accuracy: 0.8512\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4872 - accuracy: 0.9566 - val_loss: 0.7253 - val_accuracy: 0.8533\n","Epoch 38/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4839 - accuracy: 0.9522 - val_loss: 0.7333 - val_accuracy: 0.8564\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4799 - accuracy: 0.9571 - val_loss: 0.7299 - val_accuracy: 0.8481\n","Epoch 40/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4762 - accuracy: 0.9581 - val_loss: 0.7418 - val_accuracy: 0.8523\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4803 - accuracy: 0.9545 - val_loss: 0.7316 - val_accuracy: 0.8554\n","Epoch 42/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4767 - accuracy: 0.9532 - val_loss: 0.7257 - val_accuracy: 0.8585\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4654 - accuracy: 0.9615 - val_loss: 0.7371 - val_accuracy: 0.8512\n","Epoch 44/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4591 - accuracy: 0.9620 - val_loss: 0.7269 - val_accuracy: 0.8574\n","Epoch 45/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4558 - accuracy: 0.9605 - val_loss: 0.7290 - val_accuracy: 0.8543\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4559 - accuracy: 0.9612 - val_loss: 0.7342 - val_accuracy: 0.8564\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4552 - accuracy: 0.9610 - val_loss: 0.7330 - val_accuracy: 0.8533\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4489 - accuracy: 0.9641 - val_loss: 0.7384 - val_accuracy: 0.8543\n","Epoch 49/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4462 - accuracy: 0.9615 - val_loss: 0.7712 - val_accuracy: 0.8461\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4480 - accuracy: 0.9605 - val_loss: 0.7447 - val_accuracy: 0.8564\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4367 - accuracy: 0.9682 - val_loss: 0.7324 - val_accuracy: 0.8554\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4320 - accuracy: 0.9664 - val_loss: 0.7296 - val_accuracy: 0.8595\n","Epoch 53/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4260 - accuracy: 0.9705 - val_loss: 0.7314 - val_accuracy: 0.8605\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4195 - accuracy: 0.9731 - val_loss: 0.7449 - val_accuracy: 0.8523\n","Epoch 55/100\n","31/31 [==============================] - 1s 39ms/step - loss: 0.4229 - accuracy: 0.9705 - val_loss: 0.7447 - val_accuracy: 0.8626\n","Epoch 56/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4210 - accuracy: 0.9711 - val_loss: 0.7383 - val_accuracy: 0.8523\n","Epoch 57/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4058 - accuracy: 0.9770 - val_loss: 0.7485 - val_accuracy: 0.8523\n","Epoch 58/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4119 - accuracy: 0.9749 - val_loss: 0.7575 - val_accuracy: 0.8585\n","Epoch 59/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4097 - accuracy: 0.9742 - val_loss: 0.7750 - val_accuracy: 0.8543\n","Epoch 60/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4067 - accuracy: 0.9734 - val_loss: 0.7412 - val_accuracy: 0.8585\n","Epoch 61/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3994 - accuracy: 0.9793 - val_loss: 0.7517 - val_accuracy: 0.8554\n","Epoch 62/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3971 - accuracy: 0.9775 - val_loss: 0.7523 - val_accuracy: 0.8585\n","Epoch 63/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3954 - accuracy: 0.9783 - val_loss: 0.7679 - val_accuracy: 0.8440\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3929 - accuracy: 0.9793 - val_loss: 0.7544 - val_accuracy: 0.8605\n","Epoch 65/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3981 - accuracy: 0.9731 - val_loss: 0.7510 - val_accuracy: 0.8554\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3854 - accuracy: 0.9798 - val_loss: 0.7596 - val_accuracy: 0.8616\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3896 - accuracy: 0.9767 - val_loss: 0.7581 - val_accuracy: 0.8605\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3850 - accuracy: 0.9786 - val_loss: 0.7583 - val_accuracy: 0.8492\n","Epoch 69/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3746 - accuracy: 0.9832 - val_loss: 0.7652 - val_accuracy: 0.8471\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3764 - accuracy: 0.9791 - val_loss: 0.7511 - val_accuracy: 0.8585\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3748 - accuracy: 0.9804 - val_loss: 0.7655 - val_accuracy: 0.8554\n","Epoch 72/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3730 - accuracy: 0.9801 - val_loss: 0.7583 - val_accuracy: 0.8564\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3684 - accuracy: 0.9860 - val_loss: 0.7648 - val_accuracy: 0.8512\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3634 - accuracy: 0.9845 - val_loss: 0.7734 - val_accuracy: 0.8492\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3640 - accuracy: 0.9845 - val_loss: 0.7650 - val_accuracy: 0.8595\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3678 - accuracy: 0.9809 - val_loss: 0.7684 - val_accuracy: 0.8574\n","Epoch 77/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3574 - accuracy: 0.9866 - val_loss: 0.7706 - val_accuracy: 0.8512\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3594 - accuracy: 0.9840 - val_loss: 0.7693 - val_accuracy: 0.8502\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3550 - accuracy: 0.9835 - val_loss: 0.7831 - val_accuracy: 0.8430\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3515 - accuracy: 0.9863 - val_loss: 0.7700 - val_accuracy: 0.8595\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3517 - accuracy: 0.9879 - val_loss: 0.7759 - val_accuracy: 0.8512\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3454 - accuracy: 0.9889 - val_loss: 0.7744 - val_accuracy: 0.8564\n","Epoch 83/100\n","31/31 [==============================] - 1s 36ms/step - loss: 0.3437 - accuracy: 0.9881 - val_loss: 0.7768 - val_accuracy: 0.8647\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3392 - accuracy: 0.9899 - val_loss: 0.7752 - val_accuracy: 0.8523\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3410 - accuracy: 0.9886 - val_loss: 0.7863 - val_accuracy: 0.8564\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3354 - accuracy: 0.9904 - val_loss: 0.7840 - val_accuracy: 0.8543\n","Epoch 87/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3350 - accuracy: 0.9912 - val_loss: 0.7899 - val_accuracy: 0.8502\n","Epoch 88/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3361 - accuracy: 0.9871 - val_loss: 0.7937 - val_accuracy: 0.8512\n","Epoch 89/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3320 - accuracy: 0.9897 - val_loss: 0.7881 - val_accuracy: 0.8523\n","Epoch 90/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3293 - accuracy: 0.9904 - val_loss: 0.7819 - val_accuracy: 0.8564\n","Epoch 91/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3306 - accuracy: 0.9879 - val_loss: 0.7804 - val_accuracy: 0.8585\n","Epoch 92/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3252 - accuracy: 0.9920 - val_loss: 0.7900 - val_accuracy: 0.8502\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3329 - accuracy: 0.9855 - val_loss: 0.7809 - val_accuracy: 0.8554\n","Epoch 94/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3250 - accuracy: 0.9902 - val_loss: 0.7751 - val_accuracy: 0.8585\n","Epoch 95/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3203 - accuracy: 0.9922 - val_loss: 0.7828 - val_accuracy: 0.8543\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3154 - accuracy: 0.9930 - val_loss: 0.7944 - val_accuracy: 0.8512\n","Epoch 97/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3173 - accuracy: 0.9907 - val_loss: 0.8014 - val_accuracy: 0.8512\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3171 - accuracy: 0.9912 - val_loss: 0.7956 - val_accuracy: 0.8636\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3172 - accuracy: 0.9886 - val_loss: 0.8231 - val_accuracy: 0.8388\n","Epoch 100/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3126 - accuracy: 0.9912 - val_loss: 0.8003 - val_accuracy: 0.8585\n","{'loss': [0.715967059135437, 0.6934854984283447, 0.6807080507278442, 0.6761013269424438, 0.6623700857162476, 0.6584282517433167, 0.6567888855934143, 0.649451494216919, 0.6395400762557983, 0.6460986137390137, 0.6291331648826599, 0.6264366507530212, 0.6164553761482239, 0.6126592755317688, 0.6066065430641174, 0.5965583324432373, 0.5978872179985046, 0.594028115272522, 0.5795372724533081, 0.5791040062904358, 0.5773549675941467, 0.568835973739624, 0.5598262548446655, 0.5526330471038818, 0.552440881729126, 0.5424119830131531, 0.5393805503845215, 0.5388066172599792, 0.529986560344696, 0.5224807262420654, 0.5213812589645386, 0.5139146447181702, 0.5127257704734802, 0.5139874815940857, 0.5042439699172974, 0.4993332326412201, 0.4872404634952545, 0.4839249849319458, 0.4799124002456665, 0.4761659502983093, 0.4803045988082886, 0.4767494201660156, 0.46542850136756897, 0.4590810537338257, 0.4557720124721527, 0.45586517453193665, 0.4552140533924103, 0.4489041864871979, 0.44624483585357666, 0.4480075538158417, 0.4366721212863922, 0.4320083558559418, 0.4259943664073944, 0.41952669620513916, 0.4229484796524048, 0.42097681760787964, 0.40582892298698425, 0.41194671392440796, 0.4096813201904297, 0.4066878855228424, 0.3994113504886627, 0.39710479974746704, 0.3953614830970764, 0.3928830921649933, 0.39806488156318665, 0.38540390133857727, 0.38964423537254333, 0.38496488332748413, 0.37457939982414246, 0.37642794847488403, 0.3747609555721283, 0.37298715114593506, 0.3683948516845703, 0.3633786141872406, 0.3639935851097107, 0.3677881062030792, 0.3573744297027588, 0.359378844499588, 0.3549968898296356, 0.3515393137931824, 0.35169702768325806, 0.3453846275806427, 0.34366264939308167, 0.3391939401626587, 0.3410162925720215, 0.33539578318595886, 0.3349571228027344, 0.33606866002082825, 0.33197885751724243, 0.3292657732963562, 0.3305804431438446, 0.32518792152404785, 0.3328966796398163, 0.32503804564476013, 0.32027867436408997, 0.31543800234794617, 0.3172873258590698, 0.31714388728141785, 0.317179411649704, 0.31258848309516907], 'accuracy': [0.8860465288162231, 0.8935400247573853, 0.897157609462738, 0.8987079858779907, 0.9080103635787964, 0.9051679372787476, 0.9010335803031921, 0.9072351455688477, 0.9095607399940491, 0.9005168080329895, 0.9105943441390991, 0.9139534831047058, 0.9152454733848572, 0.9201550483703613, 0.91989666223526, 0.9260981678962708, 0.9196382164955139, 0.920671820640564, 0.9271317720413208, 0.9294573664665222, 0.9276486039161682, 0.9304909706115723, 0.9354005455970764, 0.9395349025726318, 0.9346253275871277, 0.9364340901374817, 0.9413436651229858, 0.9392764568328857, 0.9405684471130371, 0.9449612498283386, 0.9465116262435913, 0.94728684425354, 0.9498708248138428, 0.9439276456832886, 0.9496123790740967, 0.948062002658844, 0.9565891623497009, 0.9521963596343994, 0.9571059346199036, 0.9581395387649536, 0.9545219540596008, 0.9532299637794495, 0.9614987373352051, 0.9620155096054077, 0.960465133190155, 0.961240291595459, 0.9609819054603577, 0.964082658290863, 0.9614987373352051, 0.960465133190155, 0.9682170748710632, 0.9664082527160645, 0.9705426096916199, 0.9731265902519226, 0.9705426096916199, 0.9710594415664673, 0.9770025610923767, 0.9749354124069214, 0.9741601943969727, 0.9733850359916687, 0.9793281555175781, 0.9775193929672241, 0.9782945513725281, 0.9793281555175781, 0.9731265902519226, 0.9798449873924255, 0.9767441749572754, 0.9785529971122742, 0.9832041263580322, 0.9790697693824768, 0.9803617596626282, 0.9801033735275269, 0.9860464930534363, 0.9844961166381836, 0.9844961166381836, 0.9808785319328308, 0.9865633249282837, 0.983979344367981, 0.9834625124931335, 0.9863049387931824, 0.9878553152084351, 0.9888888597488403, 0.9881137013435364, 0.9899224638938904, 0.988630473613739, 0.9904392957687378, 0.9912144541740417, 0.9870800971984863, 0.9896640777587891, 0.9904392957687378, 0.9878553152084351, 0.9919896721839905, 0.9855297207832336, 0.9901808500289917, 0.9922480583190918, 0.9930232763290405, 0.9906976819038391, 0.9912144541740417, 0.988630473613739, 0.9912144541740417], 'val_loss': [1.1250436305999756, 1.118106484413147, 1.1070376634597778, 1.0959937572479248, 1.0875060558319092, 1.0721025466918945, 1.0622631311416626, 1.0444095134735107, 1.0165050029754639, 1.0137627124786377, 0.960321843624115, 0.9396746754646301, 0.8860004544258118, 0.8694673776626587, 0.8423364758491516, 0.8046396374702454, 0.8103268146514893, 0.7674659490585327, 0.7556893825531006, 0.7360444068908691, 0.744867205619812, 0.7160966396331787, 0.7084594964981079, 0.7147639393806458, 0.7115994095802307, 0.714495837688446, 0.7214503884315491, 0.7158554792404175, 0.7194140553474426, 0.722821831703186, 0.727212131023407, 0.7269076704978943, 0.7228097319602966, 0.7662150263786316, 0.7249311804771423, 0.7238505482673645, 0.7253254055976868, 0.7333185076713562, 0.7298738956451416, 0.7418175935745239, 0.731585681438446, 0.7256700396537781, 0.7370747327804565, 0.7268805503845215, 0.7290402054786682, 0.7342336177825928, 0.7329728603363037, 0.7384443879127502, 0.7711607217788696, 0.744723379611969, 0.7324488759040833, 0.7295751571655273, 0.7314398288726807, 0.7449192404747009, 0.7446597814559937, 0.7382706999778748, 0.7484644055366516, 0.7575138807296753, 0.7750265598297119, 0.7411878705024719, 0.7517075538635254, 0.7522952556610107, 0.7678900361061096, 0.7544470429420471, 0.7510421276092529, 0.7596293687820435, 0.7580715417861938, 0.7582636475563049, 0.7652289867401123, 0.7511261105537415, 0.7654889822006226, 0.7582595944404602, 0.7648339867591858, 0.773440957069397, 0.7650212049484253, 0.7683731317520142, 0.7705701589584351, 0.7693157196044922, 0.7831112146377563, 0.7700389623641968, 0.7759323120117188, 0.7743636965751648, 0.7768344283103943, 0.775187075138092, 0.786273717880249, 0.7840330600738525, 0.7898693680763245, 0.7937391400337219, 0.7881085276603699, 0.7819424271583557, 0.7804244756698608, 0.7899906635284424, 0.7808747887611389, 0.7750970721244812, 0.7828218936920166, 0.7944192290306091, 0.801383376121521, 0.7955614328384399, 0.823111891746521, 0.8002743124961853], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.4876033067703247, 0.49070248007774353, 0.49380165338516235, 0.5061983466148376, 0.5103305578231812, 0.547520637512207, 0.6022727489471436, 0.5816115736961365, 0.7221074104309082, 0.7376033067703247, 0.8336777091026306, 0.827479362487793, 0.8264462947845459, 0.8450413346290588, 0.8233470916748047, 0.8533057570457458, 0.8491735458374023, 0.8502066135406494, 0.8460744023323059, 0.8522727489471436, 0.8574380278587341, 0.8481404781341553, 0.8595041036605835, 0.8502066135406494, 0.8533057570457458, 0.8584710955619812, 0.8564049601554871, 0.8522727489471436, 0.8584710955619812, 0.8512396812438965, 0.8605371713638306, 0.8388429880142212, 0.8533057570457458, 0.8512396812438965, 0.8533057570457458, 0.8564049601554871, 0.8481404781341553, 0.8522727489471436, 0.85537189245224, 0.8584710955619812, 0.8512396812438965, 0.8574380278587341, 0.8543388247489929, 0.8564049601554871, 0.8533057570457458, 0.8543388247489929, 0.8460744023323059, 0.8564049601554871, 0.85537189245224, 0.8595041036605835, 0.8605371713638306, 0.8522727489471436, 0.8626033067703247, 0.8522727489471436, 0.8522727489471436, 0.8584710955619812, 0.8543388247489929, 0.8584710955619812, 0.85537189245224, 0.8584710955619812, 0.8440082669258118, 0.8605371713638306, 0.85537189245224, 0.8615702390670776, 0.8605371713638306, 0.8491735458374023, 0.8471074104309082, 0.8584710955619812, 0.85537189245224, 0.8564049601554871, 0.8512396812438965, 0.8491735458374023, 0.8595041036605835, 0.8574380278587341, 0.8512396812438965, 0.8502066135406494, 0.8429751992225647, 0.8595041036605835, 0.8512396812438965, 0.8564049601554871, 0.8646694421768188, 0.8522727489471436, 0.8564049601554871, 0.8543388247489929, 0.8502066135406494, 0.8512396812438965, 0.8522727489471436, 0.8564049601554871, 0.8584710955619812, 0.8502066135406494, 0.85537189245224, 0.8584710955619812, 0.8543388247489929, 0.8512396812438965, 0.8512396812438965, 0.8636363744735718, 0.8388429880142212, 0.8584710955619812]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.3888 - accuracy: 0.9626"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 48ms/step - loss: 0.3880 - accuracy: 0.9631 - val_loss: 0.9925 - val_accuracy: 0.4860\n","Epoch 2/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3734 - accuracy: 0.9690 - val_loss: 0.9880 - val_accuracy: 0.4860\n","Epoch 3/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3557 - accuracy: 0.9752 - val_loss: 0.9848 - val_accuracy: 0.4860\n","Epoch 4/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3503 - accuracy: 0.9768 - val_loss: 0.9777 - val_accuracy: 0.4871\n","Epoch 5/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3460 - accuracy: 0.9766 - val_loss: 0.9628 - val_accuracy: 0.4978\n","Epoch 6/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3476 - accuracy: 0.9766 - val_loss: 0.9455 - val_accuracy: 0.5032\n","Epoch 7/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3490 - accuracy: 0.9736 - val_loss: 0.9421 - val_accuracy: 0.5097\n","Epoch 8/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3394 - accuracy: 0.9801 - val_loss: 0.9009 - val_accuracy: 0.5485\n","Epoch 9/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3355 - accuracy: 0.9817 - val_loss: 0.8425 - val_accuracy: 0.6336\n","Epoch 10/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3289 - accuracy: 0.9817 - val_loss: 0.8485 - val_accuracy: 0.6121\n","Epoch 11/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3268 - accuracy: 0.9838 - val_loss: 0.7750 - val_accuracy: 0.7069\n","Epoch 12/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3264 - accuracy: 0.9833 - val_loss: 0.7264 - val_accuracy: 0.7716\n","Epoch 13/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3217 - accuracy: 0.9820 - val_loss: 0.7046 - val_accuracy: 0.7791\n","Epoch 14/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3208 - accuracy: 0.9852 - val_loss: 0.7083 - val_accuracy: 0.7597\n","Epoch 15/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3195 - accuracy: 0.9855 - val_loss: 0.6277 - val_accuracy: 0.8448\n","Epoch 16/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3138 - accuracy: 0.9871 - val_loss: 0.6005 - val_accuracy: 0.8610\n","Epoch 17/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3100 - accuracy: 0.9868 - val_loss: 0.5431 - val_accuracy: 0.8976\n","Epoch 18/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3126 - accuracy: 0.9855 - val_loss: 0.5817 - val_accuracy: 0.8610\n","Epoch 19/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3041 - accuracy: 0.9895 - val_loss: 0.5217 - val_accuracy: 0.8912\n","Epoch 20/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3020 - accuracy: 0.9914 - val_loss: 0.4969 - val_accuracy: 0.9009\n","Epoch 21/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2997 - accuracy: 0.9898 - val_loss: 0.4843 - val_accuracy: 0.9041\n","Epoch 22/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2997 - accuracy: 0.9887 - val_loss: 0.5275 - val_accuracy: 0.8912\n","Epoch 23/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3117 - accuracy: 0.9825 - val_loss: 0.4942 - val_accuracy: 0.8998\n","Epoch 24/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2966 - accuracy: 0.9890 - val_loss: 0.5215 - val_accuracy: 0.8966\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2929 - accuracy: 0.9925 - val_loss: 0.4965 - val_accuracy: 0.9030\n","Epoch 26/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2935 - accuracy: 0.9887 - val_loss: 0.5032 - val_accuracy: 0.9052\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2906 - accuracy: 0.9906 - val_loss: 0.5361 - val_accuracy: 0.8933\n","Epoch 28/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2889 - accuracy: 0.9900 - val_loss: 0.5220 - val_accuracy: 0.9138\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2882 - accuracy: 0.9925 - val_loss: 0.5335 - val_accuracy: 0.8966\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2868 - accuracy: 0.9919 - val_loss: 0.5348 - val_accuracy: 0.9073\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2857 - accuracy: 0.9925 - val_loss: 0.5295 - val_accuracy: 0.9019\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2870 - accuracy: 0.9906 - val_loss: 0.5386 - val_accuracy: 0.9106\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2860 - accuracy: 0.9900 - val_loss: 0.5309 - val_accuracy: 0.8998\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2813 - accuracy: 0.9908 - val_loss: 0.5457 - val_accuracy: 0.9009\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2774 - accuracy: 0.9938 - val_loss: 0.5637 - val_accuracy: 0.9041\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2768 - accuracy: 0.9938 - val_loss: 0.5562 - val_accuracy: 0.9052\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2756 - accuracy: 0.9938 - val_loss: 0.5411 - val_accuracy: 0.9062\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2724 - accuracy: 0.9952 - val_loss: 0.5462 - val_accuracy: 0.8998\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2768 - accuracy: 0.9908 - val_loss: 0.6000 - val_accuracy: 0.8987\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2776 - accuracy: 0.9911 - val_loss: 0.5516 - val_accuracy: 0.8966\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2702 - accuracy: 0.9957 - val_loss: 0.5368 - val_accuracy: 0.9030\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2685 - accuracy: 0.9938 - val_loss: 0.5479 - val_accuracy: 0.9106\n","Epoch 43/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2696 - accuracy: 0.9930 - val_loss: 0.5476 - val_accuracy: 0.9030\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2685 - accuracy: 0.9933 - val_loss: 0.5547 - val_accuracy: 0.9052\n","Epoch 45/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2668 - accuracy: 0.9938 - val_loss: 0.5680 - val_accuracy: 0.9052\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2674 - accuracy: 0.9922 - val_loss: 0.5572 - val_accuracy: 0.9052\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2601 - accuracy: 0.9965 - val_loss: 0.5511 - val_accuracy: 0.8998\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2586 - accuracy: 0.9960 - val_loss: 0.5576 - val_accuracy: 0.8998\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2594 - accuracy: 0.9949 - val_loss: 0.5533 - val_accuracy: 0.9019\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2581 - accuracy: 0.9954 - val_loss: 0.5485 - val_accuracy: 0.9084\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2545 - accuracy: 0.9962 - val_loss: 0.5514 - val_accuracy: 0.9019\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2578 - accuracy: 0.9935 - val_loss: 0.5860 - val_accuracy: 0.8933\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2564 - accuracy: 0.9954 - val_loss: 0.5659 - val_accuracy: 0.9052\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2614 - accuracy: 0.9922 - val_loss: 0.5751 - val_accuracy: 0.8987\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2531 - accuracy: 0.9954 - val_loss: 0.5926 - val_accuracy: 0.8933\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2573 - accuracy: 0.9933 - val_loss: 0.5988 - val_accuracy: 0.8955\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2506 - accuracy: 0.9952 - val_loss: 0.5735 - val_accuracy: 0.9019\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2484 - accuracy: 0.9965 - val_loss: 0.5694 - val_accuracy: 0.9030\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2461 - accuracy: 0.9973 - val_loss: 0.5597 - val_accuracy: 0.9052\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.2478 - accuracy: 0.9960 - val_loss: 0.5537 - val_accuracy: 0.9041\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2470 - accuracy: 0.9960 - val_loss: 0.5739 - val_accuracy: 0.8955\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2459 - accuracy: 0.9962 - val_loss: 0.5693 - val_accuracy: 0.8966\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2449 - accuracy: 0.9968 - val_loss: 0.5633 - val_accuracy: 0.8998\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2544 - accuracy: 0.9927 - val_loss: 0.6171 - val_accuracy: 0.8901\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2431 - accuracy: 0.9957 - val_loss: 0.5671 - val_accuracy: 0.8998\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2416 - accuracy: 0.9968 - val_loss: 0.5872 - val_accuracy: 0.8987\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2390 - accuracy: 0.9978 - val_loss: 0.5610 - val_accuracy: 0.8976\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2377 - accuracy: 0.9973 - val_loss: 0.5681 - val_accuracy: 0.8944\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2374 - accuracy: 0.9973 - val_loss: 0.5665 - val_accuracy: 0.9019\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2357 - accuracy: 0.9968 - val_loss: 0.5788 - val_accuracy: 0.8987\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2347 - accuracy: 0.9973 - val_loss: 0.5682 - val_accuracy: 0.8998\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2348 - accuracy: 0.9962 - val_loss: 0.5785 - val_accuracy: 0.8976\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2361 - accuracy: 0.9943 - val_loss: 0.5842 - val_accuracy: 0.8944\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2312 - accuracy: 0.9984 - val_loss: 0.5834 - val_accuracy: 0.8998\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2293 - accuracy: 0.9987 - val_loss: 0.5798 - val_accuracy: 0.9041\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2298 - accuracy: 0.9976 - val_loss: 0.5807 - val_accuracy: 0.9062\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2283 - accuracy: 0.9981 - val_loss: 0.5768 - val_accuracy: 0.8976\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2287 - accuracy: 0.9968 - val_loss: 0.5828 - val_accuracy: 0.8976\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2249 - accuracy: 0.9984 - val_loss: 0.5804 - val_accuracy: 0.8987\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2245 - accuracy: 0.9987 - val_loss: 0.5699 - val_accuracy: 0.9041\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2250 - accuracy: 0.9978 - val_loss: 0.5898 - val_accuracy: 0.9030\n","Epoch 82/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2254 - accuracy: 0.9978 - val_loss: 0.6567 - val_accuracy: 0.8793\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2256 - accuracy: 0.9960 - val_loss: 0.6079 - val_accuracy: 0.9041\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2241 - accuracy: 0.9976 - val_loss: 0.6078 - val_accuracy: 0.8966\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2216 - accuracy: 0.9981 - val_loss: 0.5793 - val_accuracy: 0.8987\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2202 - accuracy: 0.9981 - val_loss: 0.5806 - val_accuracy: 0.8976\n","Epoch 87/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2191 - accuracy: 0.9992 - val_loss: 0.5778 - val_accuracy: 0.8976\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2178 - accuracy: 0.9984 - val_loss: 0.5960 - val_accuracy: 0.8933\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2179 - accuracy: 0.9978 - val_loss: 0.5889 - val_accuracy: 0.8998\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2212 - accuracy: 0.9965 - val_loss: 0.6101 - val_accuracy: 0.8998\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2175 - accuracy: 0.9978 - val_loss: 0.6074 - val_accuracy: 0.8976\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2143 - accuracy: 0.9995 - val_loss: 0.5956 - val_accuracy: 0.8976\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2160 - accuracy: 0.9978 - val_loss: 0.5966 - val_accuracy: 0.8987\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2140 - accuracy: 0.9984 - val_loss: 0.6020 - val_accuracy: 0.8998\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2129 - accuracy: 0.9987 - val_loss: 0.6190 - val_accuracy: 0.8858\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2119 - accuracy: 0.9984 - val_loss: 0.6049 - val_accuracy: 0.8901\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2141 - accuracy: 0.9978 - val_loss: 0.6159 - val_accuracy: 0.8944\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2116 - accuracy: 0.9989 - val_loss: 0.5929 - val_accuracy: 0.8966\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2125 - accuracy: 0.9981 - val_loss: 0.5845 - val_accuracy: 0.8966\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2085 - accuracy: 0.9984 - val_loss: 0.5844 - val_accuracy: 0.8998\n","{'loss': [0.38801512122154236, 0.37336528301239014, 0.35569947957992554, 0.35030150413513184, 0.3460410535335541, 0.3476085960865021, 0.34902340173721313, 0.3394069969654083, 0.3355262577533722, 0.32887375354766846, 0.32684868574142456, 0.32638925313949585, 0.32167884707450867, 0.3207775056362152, 0.31946733593940735, 0.31380563974380493, 0.3099936842918396, 0.31255170702934265, 0.30414074659347534, 0.30203482508659363, 0.2997487783432007, 0.29974934458732605, 0.3116636276245117, 0.29655206203460693, 0.29289892315864563, 0.29349687695503235, 0.2906380891799927, 0.28886693716049194, 0.28822603821754456, 0.286800742149353, 0.28569912910461426, 0.2870279550552368, 0.28598177433013916, 0.28125229477882385, 0.277389258146286, 0.27683353424072266, 0.27556389570236206, 0.27241408824920654, 0.2768419086933136, 0.2776181399822235, 0.27023375034332275, 0.2684682607650757, 0.26957300305366516, 0.2684973180294037, 0.266834557056427, 0.26736241579055786, 0.26014742255210876, 0.25861382484436035, 0.2594006359577179, 0.25813350081443787, 0.2545275092124939, 0.2577509582042694, 0.25641441345214844, 0.2613688111305237, 0.25311338901519775, 0.2573097050189972, 0.2505521774291992, 0.24844014644622803, 0.24613824486732483, 0.2477811723947525, 0.24695615470409393, 0.2459101378917694, 0.2449120581150055, 0.2544010281562805, 0.24311688542366028, 0.2415735274553299, 0.23898974061012268, 0.23769289255142212, 0.23741886019706726, 0.23569875955581665, 0.2346586138010025, 0.23481960594654083, 0.23609822988510132, 0.2312058061361313, 0.2292565256357193, 0.22975946962833405, 0.2282629907131195, 0.2286813110113144, 0.22485840320587158, 0.22452875971794128, 0.22500677406787872, 0.2254379838705063, 0.22557201981544495, 0.22413919866085052, 0.22160528600215912, 0.2201949805021286, 0.2191230207681656, 0.2178497314453125, 0.21789628267288208, 0.22120235860347748, 0.21752741932868958, 0.21434468030929565, 0.21597996354103088, 0.2139730155467987, 0.2128535658121109, 0.2118663787841797, 0.21408414840698242, 0.2115587741136551, 0.21245643496513367, 0.2084641307592392], 'accuracy': [0.9630926847457886, 0.9690194129943848, 0.975215494632721, 0.9768319129943848, 0.9765625, 0.9765625, 0.9735991358757019, 0.9800646305084229, 0.9816810488700867, 0.9816810488700867, 0.9838362336158752, 0.9832974076271057, 0.9819504022598267, 0.9851831793785095, 0.9854525923728943, 0.9870689511299133, 0.9867995977401733, 0.9854525923728943, 0.9894935488700867, 0.9913793206214905, 0.9897629022598267, 0.9886853694915771, 0.9824892282485962, 0.9889547228813171, 0.9924569129943848, 0.9886853694915771, 0.990571141242981, 0.9900323152542114, 0.9924569129943848, 0.9919180870056152, 0.9924569129943848, 0.990571141242981, 0.9900323152542114, 0.990840494632721, 0.993803858757019, 0.993803858757019, 0.993803858757019, 0.9951508641242981, 0.990840494632721, 0.9911099076271057, 0.9956896305084229, 0.993803858757019, 0.9929956793785095, 0.9932650923728943, 0.993803858757019, 0.9921875, 0.9964978694915771, 0.9959590435028076, 0.9948814511299133, 0.9954202771186829, 0.9962284564971924, 0.993534505367279, 0.9954202771186829, 0.9921875, 0.9954202771186829, 0.9932650923728943, 0.9951508641242981, 0.9964978694915771, 0.9973060488700867, 0.9959590435028076, 0.9959590435028076, 0.9962284564971924, 0.9967672228813171, 0.9927262663841248, 0.9956896305084229, 0.9967672228813171, 0.9978448152542114, 0.9973060488700867, 0.9973060488700867, 0.9967672228813171, 0.9973060488700867, 0.9962284564971924, 0.9943426847457886, 0.998383641242981, 0.998652994632721, 0.9975754022598267, 0.9981142282485962, 0.9967672228813171, 0.998383641242981, 0.998652994632721, 0.9978448152542114, 0.9978448152542114, 0.9959590435028076, 0.9975754022598267, 0.9981142282485962, 0.9981142282485962, 0.9991918206214905, 0.998383641242981, 0.9978448152542114, 0.9964978694915771, 0.9978448152542114, 0.9994612336158752, 0.9978448152542114, 0.998383641242981, 0.998652994632721, 0.998383641242981, 0.9978448152542114, 0.9989224076271057, 0.9981142282485962, 0.998383641242981], 'val_loss': [0.9924601316452026, 0.988016664981842, 0.9848366975784302, 0.9776508212089539, 0.9628340005874634, 0.9455066919326782, 0.9420533776283264, 0.9009115099906921, 0.8425351977348328, 0.8484544157981873, 0.7749772667884827, 0.7263689637184143, 0.7046151757240295, 0.7083032131195068, 0.6277278661727905, 0.6004729866981506, 0.5430718064308167, 0.5816575288772583, 0.5216912627220154, 0.4968966245651245, 0.48433512449264526, 0.5275432467460632, 0.4941870868206024, 0.5215471386909485, 0.4964570701122284, 0.503237247467041, 0.5361374616622925, 0.5219642519950867, 0.5334903001785278, 0.5348438024520874, 0.5295284390449524, 0.5386474132537842, 0.530933141708374, 0.5456762313842773, 0.5636724233627319, 0.5561509728431702, 0.5411072373390198, 0.5461507439613342, 0.599997341632843, 0.5515992045402527, 0.5367756485939026, 0.5478646755218506, 0.5475677251815796, 0.5546879768371582, 0.5679965615272522, 0.5572143793106079, 0.5510948300361633, 0.5576481223106384, 0.5533389449119568, 0.5484728813171387, 0.551393449306488, 0.585950493812561, 0.5658804178237915, 0.5751290917396545, 0.5926024317741394, 0.5987579226493835, 0.5734818577766418, 0.5694386959075928, 0.5597211718559265, 0.5537371635437012, 0.5738589763641357, 0.5692925453186035, 0.5632548928260803, 0.6170560121536255, 0.5671459436416626, 0.5872490406036377, 0.5610082745552063, 0.5680686831474304, 0.5665029883384705, 0.578813374042511, 0.5681555271148682, 0.5785306692123413, 0.5842151045799255, 0.5834463238716125, 0.5797668099403381, 0.5807146430015564, 0.5768405199050903, 0.58278888463974, 0.5804165005683899, 0.5698984265327454, 0.5897718667984009, 0.6566685438156128, 0.6078587770462036, 0.6078489422798157, 0.5792838335037231, 0.5805943012237549, 0.5778409838676453, 0.595967710018158, 0.5889391303062439, 0.6100913286209106, 0.6073861718177795, 0.5955974459648132, 0.5965517163276672, 0.6019914746284485, 0.6190160512924194, 0.6049105525016785, 0.6158794164657593, 0.592879593372345, 0.5844622254371643, 0.5843688249588013], 'val_accuracy': [0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48706895112991333, 0.4978448152542114, 0.5032327771186829, 0.5096982717514038, 0.548491358757019, 0.6336206793785095, 0.6120689511299133, 0.7068965435028076, 0.7715517282485962, 0.7790948152542114, 0.7596982717514038, 0.8448275923728943, 0.860991358757019, 0.8976293206214905, 0.860991358757019, 0.8911637663841248, 0.9008620977401733, 0.9040948152542114, 0.8911637663841248, 0.899784505367279, 0.8965517282485962, 0.9030172228813171, 0.9051724076271057, 0.8933189511299133, 0.9137930870056152, 0.8965517282485962, 0.9073275923728943, 0.9019396305084229, 0.9105603694915771, 0.899784505367279, 0.9008620977401733, 0.9040948152542114, 0.9051724076271057, 0.90625, 0.899784505367279, 0.8987069129943848, 0.8965517282485962, 0.9030172228813171, 0.9105603694915771, 0.9030172228813171, 0.9051724076271057, 0.9051724076271057, 0.9051724076271057, 0.899784505367279, 0.899784505367279, 0.9019396305084229, 0.9084051847457886, 0.9019396305084229, 0.8933189511299133, 0.9051724076271057, 0.8987069129943848, 0.8933189511299133, 0.8954741358757019, 0.9019396305084229, 0.9030172228813171, 0.9051724076271057, 0.9040948152542114, 0.8954741358757019, 0.8965517282485962, 0.899784505367279, 0.8900862336158752, 0.899784505367279, 0.8987069129943848, 0.8976293206214905, 0.8943965435028076, 0.9019396305084229, 0.8987069129943848, 0.899784505367279, 0.8976293206214905, 0.8943965435028076, 0.899784505367279, 0.9040948152542114, 0.90625, 0.8976293206214905, 0.8976293206214905, 0.8987069129943848, 0.9040948152542114, 0.9030172228813171, 0.8793103694915771, 0.9040948152542114, 0.8965517282485962, 0.8987069129943848, 0.8976293206214905, 0.8976293206214905, 0.8933189511299133, 0.899784505367279, 0.899784505367279, 0.8976293206214905, 0.8976293206214905, 0.8987069129943848, 0.899784505367279, 0.8857758641242981, 0.8900862336158752, 0.8943965435028076, 0.8965517282485962, 0.8965517282485962, 0.899784505367279]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.3932 - accuracy: 0.9589"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 51ms/step - loss: 0.3930 - accuracy: 0.9587 - val_loss: 0.9907 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3699 - accuracy: 0.9689 - val_loss: 0.9857 - val_accuracy: 0.4966\n","Epoch 3/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3599 - accuracy: 0.9731 - val_loss: 0.9792 - val_accuracy: 0.4989\n","Epoch 4/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3538 - accuracy: 0.9745 - val_loss: 0.9725 - val_accuracy: 0.5023\n","Epoch 5/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3575 - accuracy: 0.9720 - val_loss: 0.9597 - val_accuracy: 0.5023\n","Epoch 6/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3527 - accuracy: 0.9731 - val_loss: 0.9564 - val_accuracy: 0.5079\n","Epoch 7/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3444 - accuracy: 0.9771 - val_loss: 0.9323 - val_accuracy: 0.5271\n","Epoch 8/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3392 - accuracy: 0.9788 - val_loss: 0.9061 - val_accuracy: 0.5498\n","Epoch 9/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3355 - accuracy: 0.9805 - val_loss: 0.8559 - val_accuracy: 0.6097\n","Epoch 10/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3367 - accuracy: 0.9768 - val_loss: 0.8372 - val_accuracy: 0.6346\n","Epoch 11/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.3290 - accuracy: 0.9847 - val_loss: 0.7931 - val_accuracy: 0.6900\n","Epoch 12/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3266 - accuracy: 0.9856 - val_loss: 0.7665 - val_accuracy: 0.7195\n","Epoch 13/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3272 - accuracy: 0.9873 - val_loss: 0.7281 - val_accuracy: 0.7545\n","Epoch 14/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3211 - accuracy: 0.9878 - val_loss: 0.6584 - val_accuracy: 0.8348\n","Epoch 15/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3234 - accuracy: 0.9842 - val_loss: 0.6779 - val_accuracy: 0.7885\n","Epoch 16/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3193 - accuracy: 0.9873 - val_loss: 0.6630 - val_accuracy: 0.7930\n","Epoch 17/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3185 - accuracy: 0.9850 - val_loss: 0.5652 - val_accuracy: 0.8869\n","Epoch 18/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3177 - accuracy: 0.9844 - val_loss: 0.5427 - val_accuracy: 0.8982\n","Epoch 19/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3095 - accuracy: 0.9878 - val_loss: 0.5246 - val_accuracy: 0.8993\n","Epoch 20/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3053 - accuracy: 0.9921 - val_loss: 0.4990 - val_accuracy: 0.9016\n","Epoch 21/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3039 - accuracy: 0.9924 - val_loss: 0.4984 - val_accuracy: 0.9061\n","Epoch 22/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3042 - accuracy: 0.9901 - val_loss: 0.5027 - val_accuracy: 0.8993\n","Epoch 23/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3019 - accuracy: 0.9912 - val_loss: 0.4970 - val_accuracy: 0.9061\n","Epoch 24/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3001 - accuracy: 0.9909 - val_loss: 0.5196 - val_accuracy: 0.8959\n","Epoch 25/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2967 - accuracy: 0.9915 - val_loss: 0.5144 - val_accuracy: 0.9016\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3017 - accuracy: 0.9878 - val_loss: 0.5116 - val_accuracy: 0.9050\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2930 - accuracy: 0.9946 - val_loss: 0.5177 - val_accuracy: 0.9027\n","Epoch 28/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2954 - accuracy: 0.9912 - val_loss: 0.5233 - val_accuracy: 0.9061\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2907 - accuracy: 0.9935 - val_loss: 0.5496 - val_accuracy: 0.9005\n","Epoch 30/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2976 - accuracy: 0.9890 - val_loss: 0.5492 - val_accuracy: 0.9095\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2874 - accuracy: 0.9929 - val_loss: 0.5435 - val_accuracy: 0.9050\n","Epoch 32/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2889 - accuracy: 0.9918 - val_loss: 0.5836 - val_accuracy: 0.9129\n","Epoch 33/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2953 - accuracy: 0.9887 - val_loss: 0.5563 - val_accuracy: 0.9038\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2838 - accuracy: 0.9932 - val_loss: 0.5702 - val_accuracy: 0.9084\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2816 - accuracy: 0.9938 - val_loss: 0.5629 - val_accuracy: 0.9084\n","Epoch 36/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2825 - accuracy: 0.9935 - val_loss: 0.5678 - val_accuracy: 0.9072\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2829 - accuracy: 0.9926 - val_loss: 0.5759 - val_accuracy: 0.9072\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2814 - accuracy: 0.9943 - val_loss: 0.5643 - val_accuracy: 0.9005\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2781 - accuracy: 0.9935 - val_loss: 0.5640 - val_accuracy: 0.9050\n","Epoch 40/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2720 - accuracy: 0.9963 - val_loss: 0.5632 - val_accuracy: 0.9061\n","Epoch 41/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2779 - accuracy: 0.9929 - val_loss: 0.5945 - val_accuracy: 0.9072\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2715 - accuracy: 0.9958 - val_loss: 0.5692 - val_accuracy: 0.9038\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2736 - accuracy: 0.9952 - val_loss: 0.6042 - val_accuracy: 0.9050\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2695 - accuracy: 0.9943 - val_loss: 0.5774 - val_accuracy: 0.9016\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2676 - accuracy: 0.9946 - val_loss: 0.5729 - val_accuracy: 0.8993\n","Epoch 46/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2689 - accuracy: 0.9929 - val_loss: 0.5935 - val_accuracy: 0.8891\n","Epoch 47/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2690 - accuracy: 0.9943 - val_loss: 0.5781 - val_accuracy: 0.8993\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2678 - accuracy: 0.9949 - val_loss: 0.5809 - val_accuracy: 0.8993\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2623 - accuracy: 0.9960 - val_loss: 0.5645 - val_accuracy: 0.9061\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2607 - accuracy: 0.9966 - val_loss: 0.6035 - val_accuracy: 0.9050\n","Epoch 51/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2576 - accuracy: 0.9949 - val_loss: 0.5780 - val_accuracy: 0.9050\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2636 - accuracy: 0.9935 - val_loss: 0.5785 - val_accuracy: 0.8971\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2618 - accuracy: 0.9924 - val_loss: 0.5796 - val_accuracy: 0.8959\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2561 - accuracy: 0.9946 - val_loss: 0.5851 - val_accuracy: 0.8993\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2536 - accuracy: 0.9963 - val_loss: 0.5812 - val_accuracy: 0.8914\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2516 - accuracy: 0.9966 - val_loss: 0.5813 - val_accuracy: 0.8982\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2534 - accuracy: 0.9946 - val_loss: 0.5844 - val_accuracy: 0.9027\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2503 - accuracy: 0.9966 - val_loss: 0.6028 - val_accuracy: 0.8948\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2507 - accuracy: 0.9955 - val_loss: 0.6422 - val_accuracy: 0.8948\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2527 - accuracy: 0.9932 - val_loss: 0.5824 - val_accuracy: 0.8971\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2440 - accuracy: 0.9983 - val_loss: 0.5812 - val_accuracy: 0.9038\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2479 - accuracy: 0.9955 - val_loss: 0.6180 - val_accuracy: 0.9005\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2475 - accuracy: 0.9960 - val_loss: 0.6112 - val_accuracy: 0.9027\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2436 - accuracy: 0.9963 - val_loss: 0.5979 - val_accuracy: 0.9038\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2420 - accuracy: 0.9969 - val_loss: 0.5946 - val_accuracy: 0.9027\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2396 - accuracy: 0.9969 - val_loss: 0.5996 - val_accuracy: 0.8937\n","Epoch 67/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2403 - accuracy: 0.9972 - val_loss: 0.6054 - val_accuracy: 0.8937\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2386 - accuracy: 0.9975 - val_loss: 0.6002 - val_accuracy: 0.8959\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2387 - accuracy: 0.9960 - val_loss: 0.6353 - val_accuracy: 0.8993\n","Epoch 70/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2354 - accuracy: 0.9986 - val_loss: 0.6058 - val_accuracy: 0.8914\n","Epoch 71/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2352 - accuracy: 0.9972 - val_loss: 0.6123 - val_accuracy: 0.8982\n","Epoch 72/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2430 - accuracy: 0.9929 - val_loss: 0.6008 - val_accuracy: 0.9016\n","Epoch 73/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2375 - accuracy: 0.9963 - val_loss: 0.5965 - val_accuracy: 0.8993\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2334 - accuracy: 0.9977 - val_loss: 0.5926 - val_accuracy: 0.8959\n","Epoch 75/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2347 - accuracy: 0.9963 - val_loss: 0.6035 - val_accuracy: 0.8937\n","Epoch 76/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2318 - accuracy: 0.9960 - val_loss: 0.6101 - val_accuracy: 0.8880\n","Epoch 77/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2297 - accuracy: 0.9977 - val_loss: 0.6316 - val_accuracy: 0.8993\n","Epoch 78/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2293 - accuracy: 0.9980 - val_loss: 0.6039 - val_accuracy: 0.8914\n","Epoch 79/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2278 - accuracy: 0.9983 - val_loss: 0.6124 - val_accuracy: 0.8971\n","Epoch 80/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2251 - accuracy: 0.9989 - val_loss: 0.6261 - val_accuracy: 0.8959\n","Epoch 81/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2260 - accuracy: 0.9983 - val_loss: 0.6156 - val_accuracy: 0.8925\n","Epoch 82/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2260 - accuracy: 0.9975 - val_loss: 0.6142 - val_accuracy: 0.8937\n","Epoch 83/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2233 - accuracy: 0.9986 - val_loss: 0.6356 - val_accuracy: 0.8971\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2219 - accuracy: 0.9986 - val_loss: 0.6166 - val_accuracy: 0.8914\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2248 - accuracy: 0.9966 - val_loss: 0.6483 - val_accuracy: 0.8925\n","Epoch 86/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2210 - accuracy: 0.9992 - val_loss: 0.6177 - val_accuracy: 0.8971\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2223 - accuracy: 0.9977 - val_loss: 0.6339 - val_accuracy: 0.8948\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2250 - accuracy: 0.9960 - val_loss: 0.6535 - val_accuracy: 0.8925\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2200 - accuracy: 0.9986 - val_loss: 0.6719 - val_accuracy: 0.8937\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2214 - accuracy: 0.9975 - val_loss: 0.6712 - val_accuracy: 0.8937\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2203 - accuracy: 0.9966 - val_loss: 0.6135 - val_accuracy: 0.8925\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2174 - accuracy: 0.9977 - val_loss: 0.6194 - val_accuracy: 0.8959\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2165 - accuracy: 0.9983 - val_loss: 0.6182 - val_accuracy: 0.8993\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2155 - accuracy: 0.9986 - val_loss: 0.6476 - val_accuracy: 0.8971\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2138 - accuracy: 0.9980 - val_loss: 0.6297 - val_accuracy: 0.8982\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2120 - accuracy: 0.9992 - val_loss: 0.6267 - val_accuracy: 0.8971\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2135 - accuracy: 0.9980 - val_loss: 0.6756 - val_accuracy: 0.8959\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2143 - accuracy: 0.9977 - val_loss: 0.6514 - val_accuracy: 0.8937\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2096 - accuracy: 0.9994 - val_loss: 0.6252 - val_accuracy: 0.8993\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2084 - accuracy: 0.9992 - val_loss: 0.6225 - val_accuracy: 0.9016\n","{'loss': [0.39303866028785706, 0.36986473202705383, 0.3599186837673187, 0.35383516550064087, 0.3575361967086792, 0.35274770855903625, 0.34436386823654175, 0.3391580581665039, 0.3354700207710266, 0.33667129278182983, 0.32904723286628723, 0.3266000747680664, 0.32723096013069153, 0.3211267292499542, 0.323445200920105, 0.31926682591438293, 0.3184676766395569, 0.3176930546760559, 0.3094942569732666, 0.3052770793437958, 0.30388933420181274, 0.3041502833366394, 0.3019259572029114, 0.3000548183917999, 0.2967424690723419, 0.30172666907310486, 0.2929910719394684, 0.2953696846961975, 0.29069554805755615, 0.2976139783859253, 0.28740060329437256, 0.2888913154602051, 0.29528921842575073, 0.28376486897468567, 0.2816436290740967, 0.2824501395225525, 0.282929927110672, 0.2813739776611328, 0.2780746519565582, 0.27195408940315247, 0.27792438864707947, 0.27149471640586853, 0.2735726833343506, 0.26950255036354065, 0.2676321864128113, 0.26892805099487305, 0.2690081298351288, 0.26780515909194946, 0.2623095214366913, 0.2607058584690094, 0.2575557231903076, 0.26364001631736755, 0.2617708444595337, 0.2560752034187317, 0.25364288687705994, 0.2515791356563568, 0.25336477160453796, 0.25027766823768616, 0.25067970156669617, 0.25271129608154297, 0.24398736655712128, 0.24790026247501373, 0.24750404059886932, 0.2435738444328308, 0.24195054173469543, 0.2396346777677536, 0.24028858542442322, 0.23861917853355408, 0.23870187997817993, 0.23535017669200897, 0.2351796180009842, 0.24303407967090607, 0.23754002153873444, 0.23344819247722626, 0.2347351759672165, 0.23183317482471466, 0.22969050705432892, 0.2292667180299759, 0.22776955366134644, 0.22506989538669586, 0.2260006070137024, 0.22603574395179749, 0.22333337366580963, 0.22191902995109558, 0.22482764720916748, 0.2209545224905014, 0.22232168912887573, 0.2249860018491745, 0.21996788680553436, 0.2214290350675583, 0.22025428712368011, 0.21737265586853027, 0.21649663150310516, 0.21553054451942444, 0.2138071209192276, 0.21197161078453064, 0.2134690284729004, 0.2143462598323822, 0.2096184641122818, 0.2083560824394226], 'accuracy': [0.9586870670318604, 0.9688737988471985, 0.9731183052062988, 0.9745330810546875, 0.9719864130020142, 0.9731183052062988, 0.9770798087120056, 0.9787775874137878, 0.9804753661155701, 0.9767968058586121, 0.9847198724746704, 0.9855687618255615, 0.9872665405273438, 0.9878324866294861, 0.9841539263725281, 0.9872665405273438, 0.9850028157234192, 0.9844368696212769, 0.9878324866294861, 0.9920769929885864, 0.9923599362373352, 0.9900962114334106, 0.9912280440330505, 0.9909451007843018, 0.9915110468864441, 0.9878324866294861, 0.9946236610412598, 0.9912280440330505, 0.9934917688369751, 0.988964319229126, 0.9929258823394775, 0.9917939901351929, 0.9886813759803772, 0.9932088255882263, 0.9937747716903687, 0.9934917688369751, 0.992642879486084, 0.994340717792511, 0.9934917688369751, 0.996321439743042, 0.9929258823394775, 0.9957554936408997, 0.9951896071434021, 0.994340717792511, 0.9946236610412598, 0.9929258823394775, 0.994340717792511, 0.9949066042900085, 0.9960384964942932, 0.9966044425964355, 0.9949066042900085, 0.9934917688369751, 0.9923599362373352, 0.9946236610412598, 0.996321439743042, 0.9966044425964355, 0.9946236610412598, 0.9966044425964355, 0.9954725503921509, 0.9932088255882263, 0.9983022212982178, 0.9954725503921509, 0.9960384964942932, 0.996321439743042, 0.9968873858451843, 0.9968873858451843, 0.9971703290939331, 0.9974533319473267, 0.9960384964942932, 0.9985851645469666, 0.9971703290939331, 0.9929258823394775, 0.996321439743042, 0.9977362751960754, 0.996321439743042, 0.9960384964942932, 0.9977362751960754, 0.9980192184448242, 0.9983022212982178, 0.9988681674003601, 0.9983022212982178, 0.9974533319473267, 0.9985851645469666, 0.9985851645469666, 0.9966044425964355, 0.9991511106491089, 0.9977362751960754, 0.9960384964942932, 0.9985851645469666, 0.9974533319473267, 0.9966044425964355, 0.9977362751960754, 0.9983022212982178, 0.9985851645469666, 0.9980192184448242, 0.9991511106491089, 0.9980192184448242, 0.9977362751960754, 0.9994340538978577, 0.9991511106491089], 'val_loss': [0.990729033946991, 0.9856542348861694, 0.9791582822799683, 0.9724616408348083, 0.9597495198249817, 0.9563870429992676, 0.932302713394165, 0.9060776233673096, 0.8558830618858337, 0.8372149467468262, 0.793083906173706, 0.766533374786377, 0.7281123399734497, 0.6584087610244751, 0.6778555512428284, 0.6629616618156433, 0.5651994943618774, 0.542691707611084, 0.5245688557624817, 0.49898195266723633, 0.49839726090431213, 0.5027434229850769, 0.49699515104293823, 0.5195896029472351, 0.5144376158714294, 0.5115931034088135, 0.5177098512649536, 0.5233275890350342, 0.5495745539665222, 0.5492099523544312, 0.5434682965278625, 0.5835633873939514, 0.5562923550605774, 0.5701524615287781, 0.5628910064697266, 0.5678046941757202, 0.575872004032135, 0.5643177628517151, 0.5640418529510498, 0.563226580619812, 0.5945180654525757, 0.5691775679588318, 0.6042090654373169, 0.5774274468421936, 0.5729054808616638, 0.5935413241386414, 0.5780630707740784, 0.5808529257774353, 0.5645107626914978, 0.6034965515136719, 0.5780339241027832, 0.5784658193588257, 0.5795606374740601, 0.585123598575592, 0.581242561340332, 0.5812896490097046, 0.5844302177429199, 0.6027858853340149, 0.6421819925308228, 0.5823631286621094, 0.5811646580696106, 0.6180256009101868, 0.6111522912979126, 0.5978690981864929, 0.5946015119552612, 0.5995753407478333, 0.6053640246391296, 0.6001743078231812, 0.6353397965431213, 0.6058127284049988, 0.6123260259628296, 0.6007816791534424, 0.5965102314949036, 0.5925743579864502, 0.6035115718841553, 0.6101384162902832, 0.6316065192222595, 0.6038713455200195, 0.6123815774917603, 0.6260753870010376, 0.6155952215194702, 0.6141635775566101, 0.6355913281440735, 0.6165662407875061, 0.6482950448989868, 0.6176687479019165, 0.6338589191436768, 0.6534634828567505, 0.6718828082084656, 0.6711621880531311, 0.6135172247886658, 0.6194208264350891, 0.6181509494781494, 0.6475673317909241, 0.6297017931938171, 0.6266688108444214, 0.6755598783493042, 0.6513879895210266, 0.6252268552780151, 0.622527539730072], 'val_accuracy': [0.4954751133918762, 0.49660632014274597, 0.49886876344680786, 0.5022624731063843, 0.5022624731063843, 0.5079185366630554, 0.5271493196487427, 0.5497737526893616, 0.6097285151481628, 0.6346153616905212, 0.6900452375411987, 0.7194570302963257, 0.7545248866081238, 0.8348416090011597, 0.7884615659713745, 0.7929864525794983, 0.8868778347969055, 0.8981900215148926, 0.8993212580680847, 0.901583731174469, 0.9061086177825928, 0.8993212580680847, 0.9061086177825928, 0.8959276080131531, 0.901583731174469, 0.9049773812294006, 0.9027149081230164, 0.9061086177825928, 0.9004524946212769, 0.9095022678375244, 0.9049773812294006, 0.912895917892456, 0.9038461446762085, 0.9083710312843323, 0.9083710312843323, 0.9072397947311401, 0.9072397947311401, 0.9004524946212769, 0.9049773812294006, 0.9061086177825928, 0.9072397947311401, 0.9038461446762085, 0.9049773812294006, 0.901583731174469, 0.8993212580680847, 0.889140248298645, 0.8993212580680847, 0.8993212580680847, 0.9061086177825928, 0.9049773812294006, 0.9049773812294006, 0.8970588445663452, 0.8959276080131531, 0.8993212580680847, 0.8914027214050293, 0.8981900215148926, 0.9027149081230164, 0.8947963714599609, 0.8947963714599609, 0.8970588445663452, 0.9038461446762085, 0.9004524946212769, 0.9027149081230164, 0.9038461446762085, 0.9027149081230164, 0.8936651349067688, 0.8936651349067688, 0.8959276080131531, 0.8993212580680847, 0.8914027214050293, 0.8981900215148926, 0.901583731174469, 0.8993212580680847, 0.8959276080131531, 0.8936651349067688, 0.8880090713500977, 0.8993212580680847, 0.8914027214050293, 0.8970588445663452, 0.8959276080131531, 0.8925339579582214, 0.8936651349067688, 0.8970588445663452, 0.8914027214050293, 0.8925339579582214, 0.8970588445663452, 0.8947963714599609, 0.8925339579582214, 0.8936651349067688, 0.8936651349067688, 0.8925339579582214, 0.8959276080131531, 0.8993212580680847, 0.8970588445663452, 0.8981900215148926, 0.8970588445663452, 0.8959276080131531, 0.8936651349067688, 0.8993212580680847, 0.901583731174469]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.3911 - accuracy: 0.9612"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 11s 151ms/step - loss: 0.3911 - accuracy: 0.9612 - val_loss: 0.9924 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3804 - accuracy: 0.9615 - val_loss: 0.9902 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.3595 - accuracy: 0.9713 - val_loss: 0.9856 - val_accuracy: 0.4866\n","Epoch 4/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.3544 - accuracy: 0.9742 - val_loss: 0.9774 - val_accuracy: 0.4897\n","Epoch 5/100\n","31/31 [==============================] - 1s 40ms/step - loss: 0.3529 - accuracy: 0.9726 - val_loss: 0.9731 - val_accuracy: 0.4959\n","Epoch 6/100\n","31/31 [==============================] - 1s 39ms/step - loss: 0.3543 - accuracy: 0.9721 - val_loss: 0.9350 - val_accuracy: 0.5186\n","Epoch 7/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3455 - accuracy: 0.9762 - val_loss: 0.9344 - val_accuracy: 0.5196\n","Epoch 8/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3448 - accuracy: 0.9773 - val_loss: 0.8851 - val_accuracy: 0.5713\n","Epoch 9/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3448 - accuracy: 0.9791 - val_loss: 0.8430 - val_accuracy: 0.6291\n","Epoch 10/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3383 - accuracy: 0.9798 - val_loss: 0.8541 - val_accuracy: 0.6147\n","Epoch 11/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3425 - accuracy: 0.9770 - val_loss: 0.7566 - val_accuracy: 0.7469\n","Epoch 12/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3326 - accuracy: 0.9788 - val_loss: 0.7500 - val_accuracy: 0.7407\n","Epoch 13/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3253 - accuracy: 0.9842 - val_loss: 0.6898 - val_accuracy: 0.7996\n","Epoch 14/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.3304 - accuracy: 0.9814 - val_loss: 0.6422 - val_accuracy: 0.8275\n","Epoch 15/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.3228 - accuracy: 0.9840 - val_loss: 0.6137 - val_accuracy: 0.8481\n","Epoch 16/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.3201 - accuracy: 0.9848 - val_loss: 0.5480 - val_accuracy: 0.8946\n","Epoch 17/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3147 - accuracy: 0.9845 - val_loss: 0.5467 - val_accuracy: 0.8884\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3134 - accuracy: 0.9860 - val_loss: 0.5540 - val_accuracy: 0.8760\n","Epoch 19/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3224 - accuracy: 0.9814 - val_loss: 0.5171 - val_accuracy: 0.8946\n","Epoch 20/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3089 - accuracy: 0.9848 - val_loss: 0.5018 - val_accuracy: 0.8998\n","Epoch 21/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3074 - accuracy: 0.9879 - val_loss: 0.5443 - val_accuracy: 0.8843\n","Epoch 22/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3073 - accuracy: 0.9881 - val_loss: 0.5153 - val_accuracy: 0.9019\n","Epoch 23/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3052 - accuracy: 0.9886 - val_loss: 0.5131 - val_accuracy: 0.9050\n","Epoch 24/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3015 - accuracy: 0.9899 - val_loss: 0.5175 - val_accuracy: 0.9060\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2983 - accuracy: 0.9904 - val_loss: 0.5347 - val_accuracy: 0.9019\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2976 - accuracy: 0.9891 - val_loss: 0.5344 - val_accuracy: 0.8998\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2963 - accuracy: 0.9902 - val_loss: 0.5472 - val_accuracy: 0.8967\n","Epoch 28/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2930 - accuracy: 0.9907 - val_loss: 0.5541 - val_accuracy: 0.9008\n","Epoch 29/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2937 - accuracy: 0.9902 - val_loss: 0.5742 - val_accuracy: 0.8926\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2942 - accuracy: 0.9881 - val_loss: 0.5793 - val_accuracy: 0.8915\n","Epoch 31/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2929 - accuracy: 0.9891 - val_loss: 0.5601 - val_accuracy: 0.9008\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3011 - accuracy: 0.9855 - val_loss: 0.5667 - val_accuracy: 0.8967\n","Epoch 33/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2937 - accuracy: 0.9853 - val_loss: 0.5627 - val_accuracy: 0.8967\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2850 - accuracy: 0.9928 - val_loss: 0.6002 - val_accuracy: 0.8915\n","Epoch 35/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2887 - accuracy: 0.9897 - val_loss: 0.5811 - val_accuracy: 0.8895\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2873 - accuracy: 0.9884 - val_loss: 0.5695 - val_accuracy: 0.9008\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2822 - accuracy: 0.9917 - val_loss: 0.5630 - val_accuracy: 0.9008\n","Epoch 38/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2810 - accuracy: 0.9917 - val_loss: 0.5704 - val_accuracy: 0.8988\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2789 - accuracy: 0.9904 - val_loss: 0.5757 - val_accuracy: 0.9019\n","Epoch 40/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2885 - accuracy: 0.9873 - val_loss: 0.6595 - val_accuracy: 0.8750\n","Epoch 41/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2876 - accuracy: 0.9871 - val_loss: 0.5894 - val_accuracy: 0.9019\n","Epoch 42/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2753 - accuracy: 0.9922 - val_loss: 0.5653 - val_accuracy: 0.8988\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2733 - accuracy: 0.9930 - val_loss: 0.5720 - val_accuracy: 0.8977\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2709 - accuracy: 0.9943 - val_loss: 0.5702 - val_accuracy: 0.8977\n","Epoch 45/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2676 - accuracy: 0.9935 - val_loss: 0.5774 - val_accuracy: 0.8988\n","Epoch 46/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2687 - accuracy: 0.9943 - val_loss: 0.5940 - val_accuracy: 0.8998\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2683 - accuracy: 0.9922 - val_loss: 0.5894 - val_accuracy: 0.8905\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2675 - accuracy: 0.9925 - val_loss: 0.5857 - val_accuracy: 0.8988\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2639 - accuracy: 0.9928 - val_loss: 0.5778 - val_accuracy: 0.8988\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2598 - accuracy: 0.9956 - val_loss: 0.5900 - val_accuracy: 0.8946\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2628 - accuracy: 0.9941 - val_loss: 0.5808 - val_accuracy: 0.8967\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2709 - accuracy: 0.9899 - val_loss: 0.6117 - val_accuracy: 0.8853\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2632 - accuracy: 0.9915 - val_loss: 0.5905 - val_accuracy: 0.8957\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2569 - accuracy: 0.9943 - val_loss: 0.5812 - val_accuracy: 0.9008\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2559 - accuracy: 0.9946 - val_loss: 0.5828 - val_accuracy: 0.8977\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2585 - accuracy: 0.9933 - val_loss: 0.5959 - val_accuracy: 0.9029\n","Epoch 57/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2542 - accuracy: 0.9941 - val_loss: 0.5887 - val_accuracy: 0.8957\n","Epoch 58/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2533 - accuracy: 0.9948 - val_loss: 0.5827 - val_accuracy: 0.8936\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2506 - accuracy: 0.9948 - val_loss: 0.6115 - val_accuracy: 0.8884\n","Epoch 60/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2508 - accuracy: 0.9943 - val_loss: 0.6023 - val_accuracy: 0.8884\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2469 - accuracy: 0.9956 - val_loss: 0.5913 - val_accuracy: 0.8988\n","Epoch 62/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2471 - accuracy: 0.9964 - val_loss: 0.5920 - val_accuracy: 0.8895\n","Epoch 63/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2460 - accuracy: 0.9953 - val_loss: 0.6238 - val_accuracy: 0.8874\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2594 - accuracy: 0.9891 - val_loss: 0.6350 - val_accuracy: 0.8895\n","Epoch 65/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2527 - accuracy: 0.9897 - val_loss: 0.6182 - val_accuracy: 0.8977\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2536 - accuracy: 0.9902 - val_loss: 0.6870 - val_accuracy: 0.8750\n","Epoch 67/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2491 - accuracy: 0.9928 - val_loss: 0.5938 - val_accuracy: 0.8946\n","Epoch 68/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2450 - accuracy: 0.9935 - val_loss: 0.6142 - val_accuracy: 0.8874\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2444 - accuracy: 0.9946 - val_loss: 0.6160 - val_accuracy: 0.8864\n","Epoch 70/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2366 - accuracy: 0.9964 - val_loss: 0.6107 - val_accuracy: 0.8864\n","Epoch 71/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2387 - accuracy: 0.9959 - val_loss: 0.5962 - val_accuracy: 0.8946\n","Epoch 72/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2404 - accuracy: 0.9943 - val_loss: 0.6328 - val_accuracy: 0.8977\n","Epoch 73/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2454 - accuracy: 0.9912 - val_loss: 0.6099 - val_accuracy: 0.8884\n","Epoch 74/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2410 - accuracy: 0.9930 - val_loss: 0.6032 - val_accuracy: 0.8977\n","Epoch 75/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2347 - accuracy: 0.9961 - val_loss: 0.6250 - val_accuracy: 0.8843\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2324 - accuracy: 0.9969 - val_loss: 0.6076 - val_accuracy: 0.8926\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2324 - accuracy: 0.9961 - val_loss: 0.6064 - val_accuracy: 0.8926\n","Epoch 78/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2307 - accuracy: 0.9966 - val_loss: 0.6193 - val_accuracy: 0.8915\n","Epoch 79/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2321 - accuracy: 0.9951 - val_loss: 0.6140 - val_accuracy: 0.8936\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2301 - accuracy: 0.9972 - val_loss: 0.6072 - val_accuracy: 0.8977\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2329 - accuracy: 0.9941 - val_loss: 0.6177 - val_accuracy: 0.8884\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2296 - accuracy: 0.9961 - val_loss: 0.6187 - val_accuracy: 0.8926\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2262 - accuracy: 0.9977 - val_loss: 0.6046 - val_accuracy: 0.8946\n","Epoch 84/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2241 - accuracy: 0.9974 - val_loss: 0.6136 - val_accuracy: 0.8915\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2262 - accuracy: 0.9969 - val_loss: 0.6383 - val_accuracy: 0.8843\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2285 - accuracy: 0.9951 - val_loss: 0.6249 - val_accuracy: 0.8936\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2228 - accuracy: 0.9969 - val_loss: 0.6124 - val_accuracy: 0.8957\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2216 - accuracy: 0.9974 - val_loss: 0.6215 - val_accuracy: 0.8946\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2209 - accuracy: 0.9979 - val_loss: 0.6223 - val_accuracy: 0.8936\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2229 - accuracy: 0.9951 - val_loss: 0.6320 - val_accuracy: 0.8895\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2176 - accuracy: 0.9987 - val_loss: 0.6131 - val_accuracy: 0.8915\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2178 - accuracy: 0.9977 - val_loss: 0.6409 - val_accuracy: 0.8895\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2165 - accuracy: 0.9982 - val_loss: 0.6395 - val_accuracy: 0.8853\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2167 - accuracy: 0.9966 - val_loss: 0.6251 - val_accuracy: 0.8895\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2153 - accuracy: 0.9984 - val_loss: 0.6299 - val_accuracy: 0.8884\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2169 - accuracy: 0.9972 - val_loss: 0.6448 - val_accuracy: 0.8895\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2156 - accuracy: 0.9966 - val_loss: 0.6451 - val_accuracy: 0.8915\n","Epoch 98/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2156 - accuracy: 0.9972 - val_loss: 0.6350 - val_accuracy: 0.8915\n","Epoch 99/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2146 - accuracy: 0.9972 - val_loss: 0.6230 - val_accuracy: 0.8895\n","Epoch 100/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2123 - accuracy: 0.9987 - val_loss: 0.6264 - val_accuracy: 0.8936\n","{'loss': [0.3911314308643341, 0.3804093897342682, 0.3594891130924225, 0.35437971353530884, 0.3528934121131897, 0.3542528450489044, 0.3454805314540863, 0.3447526693344116, 0.3447806239128113, 0.3383486568927765, 0.3424915373325348, 0.3326380252838135, 0.32530221343040466, 0.3304173946380615, 0.3227521479129791, 0.32011178135871887, 0.3146999776363373, 0.3133801221847534, 0.3223772346973419, 0.30890342593193054, 0.30742111802101135, 0.30730584263801575, 0.3051559627056122, 0.3014623522758484, 0.2982873320579529, 0.2976415157318115, 0.2963067591190338, 0.2929704189300537, 0.2936655879020691, 0.29423820972442627, 0.2929200828075409, 0.301071435213089, 0.29374808073043823, 0.2849513590335846, 0.2886749804019928, 0.287276953458786, 0.2822295129299164, 0.28095945715904236, 0.27894073724746704, 0.28851428627967834, 0.2876094877719879, 0.2752607464790344, 0.2733406126499176, 0.27088871598243713, 0.26756927371025085, 0.2686610221862793, 0.2682889699935913, 0.2674671709537506, 0.2638859152793884, 0.2598329484462738, 0.26281076669692993, 0.27090713381767273, 0.2631607949733734, 0.2569311261177063, 0.2559308409690857, 0.25847211480140686, 0.2542271018028259, 0.2532891631126404, 0.25062453746795654, 0.2508307993412018, 0.24693895876407623, 0.2470940500497818, 0.2460092306137085, 0.2594297230243683, 0.2527408003807068, 0.2535872757434845, 0.24905727803707123, 0.2450271099805832, 0.24438397586345673, 0.23655003309249878, 0.23874907195568085, 0.2403702437877655, 0.24541063606739044, 0.24102725088596344, 0.23468363285064697, 0.23241305351257324, 0.23235444724559784, 0.230684295296669, 0.23209300637245178, 0.2301272749900818, 0.23287492990493774, 0.22956877946853638, 0.2262301743030548, 0.22410915791988373, 0.22622190415859222, 0.22846494615077972, 0.2228175550699234, 0.22164738178253174, 0.22093725204467773, 0.22294506430625916, 0.21758195757865906, 0.21780043840408325, 0.2164594531059265, 0.21666021645069122, 0.21526335179805756, 0.21689480543136597, 0.215592160820961, 0.21557487547397614, 0.2145717591047287, 0.2122722715139389], 'accuracy': [0.961240291595459, 0.9614987373352051, 0.9713178277015686, 0.9741601943969727, 0.97260981798172, 0.9720930457115173, 0.9762274026870728, 0.9772610068321228, 0.9790697693824768, 0.9798449873924255, 0.9770025610923767, 0.9788113832473755, 0.9842377305030823, 0.9813953638076782, 0.983979344367981, 0.9847545027732849, 0.9844961166381836, 0.9860464930534363, 0.9813953638076782, 0.9847545027732849, 0.9878553152084351, 0.9881137013435364, 0.988630473613739, 0.9899224638938904, 0.9904392957687378, 0.9891473054885864, 0.9901808500289917, 0.9906976819038391, 0.9901808500289917, 0.9881137013435364, 0.9891473054885864, 0.9855297207832336, 0.9852713346481323, 0.9927648305892944, 0.9896640777587891, 0.9883720874786377, 0.9917312860488892, 0.9917312860488892, 0.9904392957687378, 0.9873384833335876, 0.9870800971984863, 0.9922480583190918, 0.9930232763290405, 0.9943152666091919, 0.9935400485992432, 0.9943152666091919, 0.9922480583190918, 0.9925064444541931, 0.9927648305892944, 0.9956072568893433, 0.9940568208694458, 0.9899224638938904, 0.9914728403091431, 0.9943152666091919, 0.9945736527442932, 0.9932816624641418, 0.9940568208694458, 0.9948320388793945, 0.9948320388793945, 0.9943152666091919, 0.9956072568893433, 0.9963824152946472, 0.9953488111495972, 0.9891473054885864, 0.9896640777587891, 0.9901808500289917, 0.9927648305892944, 0.9935400485992432, 0.9945736527442932, 0.9963824152946472, 0.9958656430244446, 0.9943152666091919, 0.9912144541740417, 0.9930232763290405, 0.9961240291595459, 0.9968992471694946, 0.9961240291595459, 0.9966408014297485, 0.9950904250144958, 0.997157633304596, 0.9940568208694458, 0.9961240291595459, 0.9976744055747986, 0.9974160194396973, 0.9968992471694946, 0.9950904250144958, 0.9968992471694946, 0.9974160194396973, 0.9979327917098999, 0.9950904250144958, 0.9987080097198486, 0.9976744055747986, 0.998191237449646, 0.9966408014297485, 0.9984496235847473, 0.997157633304596, 0.9966408014297485, 0.997157633304596, 0.997157633304596, 0.9987080097198486], 'val_loss': [0.9923781752586365, 0.990159809589386, 0.9856246709823608, 0.9773665070533752, 0.9731284976005554, 0.9349761009216309, 0.934440553188324, 0.88507080078125, 0.8430161476135254, 0.8540911674499512, 0.7565982341766357, 0.7500268816947937, 0.6897702813148499, 0.642179012298584, 0.6137206554412842, 0.5480361580848694, 0.5467199683189392, 0.5540277361869812, 0.51705002784729, 0.5017662644386292, 0.5443326830863953, 0.5153099298477173, 0.5131309032440186, 0.517467200756073, 0.5347343683242798, 0.5344107747077942, 0.5471943020820618, 0.5541015863418579, 0.5742431282997131, 0.5793099403381348, 0.5601251125335693, 0.5666933059692383, 0.5627351999282837, 0.6002230644226074, 0.581071674823761, 0.5695154666900635, 0.5629728436470032, 0.5703830122947693, 0.5756517648696899, 0.6595320701599121, 0.5893574953079224, 0.565269410610199, 0.5719584226608276, 0.5702401399612427, 0.5773950219154358, 0.5939726233482361, 0.5894091725349426, 0.5857130885124207, 0.5777984857559204, 0.5900061726570129, 0.5807623863220215, 0.6117077469825745, 0.5905249714851379, 0.5811766386032104, 0.5828099250793457, 0.5958531498908997, 0.5887193083763123, 0.5827122926712036, 0.6114831566810608, 0.6023381948471069, 0.5912923216819763, 0.5920022130012512, 0.6238229870796204, 0.6350031495094299, 0.6182145476341248, 0.6870295405387878, 0.5937700271606445, 0.6142465472221375, 0.6160009503364563, 0.6106889843940735, 0.5962002277374268, 0.6327822208404541, 0.6099026203155518, 0.60318922996521, 0.6250154972076416, 0.6075710654258728, 0.6063977479934692, 0.6192975044250488, 0.6139901280403137, 0.6071930527687073, 0.6177070140838623, 0.6186875700950623, 0.6046452522277832, 0.6135944128036499, 0.6383329033851624, 0.6248940825462341, 0.6124393343925476, 0.6214580535888672, 0.6222760677337646, 0.631996750831604, 0.6130896210670471, 0.6408663392066956, 0.6394531726837158, 0.6251159906387329, 0.6298927068710327, 0.6447919607162476, 0.6450828313827515, 0.6350263953208923, 0.6230249404907227, 0.6264374852180481], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.48966941237449646, 0.4958677589893341, 0.5185950398445129, 0.51962810754776, 0.5712810158729553, 0.6291322112083435, 0.6146694421768188, 0.7469007968902588, 0.7407024502754211, 0.7995867729187012, 0.827479362487793, 0.8481404781341553, 0.89462810754776, 0.8884297609329224, 0.8760330677032471, 0.89462810754776, 0.8997933864593506, 0.8842975497245789, 0.9018595218658447, 0.9049586653709412, 0.9059917330741882, 0.9018595218658447, 0.8997933864593506, 0.8966942429542542, 0.9008264541625977, 0.8925619721412659, 0.8915289044380188, 0.9008264541625977, 0.8966942429542542, 0.8966942429542542, 0.8915289044380188, 0.8894628286361694, 0.9008264541625977, 0.9008264541625977, 0.8987603187561035, 0.9018595218658447, 0.875, 0.9018595218658447, 0.8987603187561035, 0.8977272510528564, 0.8977272510528564, 0.8987603187561035, 0.8997933864593506, 0.8904958963394165, 0.8987603187561035, 0.8987603187561035, 0.89462810754776, 0.8966942429542542, 0.8853305578231812, 0.8956611752510071, 0.9008264541625977, 0.8977272510528564, 0.9028925895690918, 0.8956611752510071, 0.8935950398445129, 0.8884297609329224, 0.8884297609329224, 0.8987603187561035, 0.8894628286361694, 0.8873966932296753, 0.8894628286361694, 0.8977272510528564, 0.875, 0.89462810754776, 0.8873966932296753, 0.8863636255264282, 0.8863636255264282, 0.89462810754776, 0.8977272510528564, 0.8884297609329224, 0.8977272510528564, 0.8842975497245789, 0.8925619721412659, 0.8925619721412659, 0.8915289044380188, 0.8935950398445129, 0.8977272510528564, 0.8884297609329224, 0.8925619721412659, 0.89462810754776, 0.8915289044380188, 0.8842975497245789, 0.8935950398445129, 0.8956611752510071, 0.89462810754776, 0.8935950398445129, 0.8894628286361694, 0.8915289044380188, 0.8894628286361694, 0.8853305578231812, 0.8894628286361694, 0.8884297609329224, 0.8894628286361694, 0.8915289044380188, 0.8915289044380188, 0.8894628286361694, 0.8935950398445129]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.2477 - accuracy: 0.9844"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 6s 55ms/step - loss: 0.2477 - accuracy: 0.9844 - val_loss: 0.9320 - val_accuracy: 0.4860\n","Epoch 2/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2424 - accuracy: 0.9863 - val_loss: 0.9282 - val_accuracy: 0.4860\n","Epoch 3/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2443 - accuracy: 0.9849 - val_loss: 0.9217 - val_accuracy: 0.4881\n","Epoch 4/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.2247 - accuracy: 0.9919 - val_loss: 0.9167 - val_accuracy: 0.4903\n","Epoch 5/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.2247 - accuracy: 0.9930 - val_loss: 0.9135 - val_accuracy: 0.4957\n","Epoch 6/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.2217 - accuracy: 0.9943 - val_loss: 0.8766 - val_accuracy: 0.5075\n","Epoch 7/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.2213 - accuracy: 0.9930 - val_loss: 0.8573 - val_accuracy: 0.5291\n","Epoch 8/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2170 - accuracy: 0.9941 - val_loss: 0.8438 - val_accuracy: 0.5409\n","Epoch 9/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.2170 - accuracy: 0.9946 - val_loss: 0.8130 - val_accuracy: 0.5690\n","Epoch 10/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.2131 - accuracy: 0.9952 - val_loss: 0.7571 - val_accuracy: 0.6444\n","Epoch 11/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2114 - accuracy: 0.9976 - val_loss: 0.7273 - val_accuracy: 0.6713\n","Epoch 12/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.2133 - accuracy: 0.9960 - val_loss: 0.6506 - val_accuracy: 0.7263\n","Epoch 13/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2139 - accuracy: 0.9949 - val_loss: 0.5610 - val_accuracy: 0.8276\n","Epoch 14/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2161 - accuracy: 0.9930 - val_loss: 0.5149 - val_accuracy: 0.8718\n","Epoch 15/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2100 - accuracy: 0.9960 - val_loss: 0.5033 - val_accuracy: 0.8578\n","Epoch 16/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2115 - accuracy: 0.9946 - val_loss: 0.4495 - val_accuracy: 0.8933\n","Epoch 17/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2093 - accuracy: 0.9954 - val_loss: 0.4229 - val_accuracy: 0.9106\n","Epoch 18/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2079 - accuracy: 0.9952 - val_loss: 0.4192 - val_accuracy: 0.9095\n","Epoch 19/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2101 - accuracy: 0.9943 - val_loss: 0.3804 - val_accuracy: 0.9332\n","Epoch 20/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2057 - accuracy: 0.9976 - val_loss: 0.3620 - val_accuracy: 0.9397\n","Epoch 21/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2067 - accuracy: 0.9960 - val_loss: 0.4018 - val_accuracy: 0.9170\n","Epoch 22/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2050 - accuracy: 0.9962 - val_loss: 0.3660 - val_accuracy: 0.9397\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2053 - accuracy: 0.9970 - val_loss: 0.3724 - val_accuracy: 0.9332\n","Epoch 24/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2017 - accuracy: 0.9976 - val_loss: 0.3733 - val_accuracy: 0.9397\n","Epoch 25/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2003 - accuracy: 0.9978 - val_loss: 0.3777 - val_accuracy: 0.9407\n","Epoch 26/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.2008 - accuracy: 0.9970 - val_loss: 0.3892 - val_accuracy: 0.9418\n","Epoch 27/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2024 - accuracy: 0.9962 - val_loss: 0.4091 - val_accuracy: 0.9386\n","Epoch 28/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1993 - accuracy: 0.9976 - val_loss: 0.4011 - val_accuracy: 0.9364\n","Epoch 29/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1989 - accuracy: 0.9987 - val_loss: 0.4068 - val_accuracy: 0.9353\n","Epoch 30/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1962 - accuracy: 0.9981 - val_loss: 0.4072 - val_accuracy: 0.9418\n","Epoch 31/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1994 - accuracy: 0.9965 - val_loss: 0.4145 - val_accuracy: 0.9386\n","Epoch 32/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.1991 - accuracy: 0.9962 - val_loss: 0.4185 - val_accuracy: 0.9429\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1975 - accuracy: 0.9965 - val_loss: 0.4192 - val_accuracy: 0.9418\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1935 - accuracy: 0.9992 - val_loss: 0.4282 - val_accuracy: 0.9375\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1956 - accuracy: 0.9978 - val_loss: 0.4366 - val_accuracy: 0.9407\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1927 - accuracy: 0.9978 - val_loss: 0.4222 - val_accuracy: 0.9386\n","Epoch 37/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1914 - accuracy: 0.9989 - val_loss: 0.4276 - val_accuracy: 0.9321\n","Epoch 38/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1915 - accuracy: 0.9981 - val_loss: 0.4269 - val_accuracy: 0.9375\n","Epoch 39/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1946 - accuracy: 0.9965 - val_loss: 0.4247 - val_accuracy: 0.9364\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1892 - accuracy: 0.9989 - val_loss: 0.4206 - val_accuracy: 0.9375\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1903 - accuracy: 0.9973 - val_loss: 0.4353 - val_accuracy: 0.9353\n","Epoch 42/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1887 - accuracy: 0.9987 - val_loss: 0.4266 - val_accuracy: 0.9343\n","Epoch 43/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1875 - accuracy: 0.9992 - val_loss: 0.4254 - val_accuracy: 0.9407\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1893 - accuracy: 0.9976 - val_loss: 0.4238 - val_accuracy: 0.9407\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1927 - accuracy: 0.9943 - val_loss: 0.4305 - val_accuracy: 0.9407\n","Epoch 46/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1886 - accuracy: 0.9970 - val_loss: 0.4313 - val_accuracy: 0.9364\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1914 - accuracy: 0.9957 - val_loss: 0.4469 - val_accuracy: 0.9256\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1855 - accuracy: 0.9981 - val_loss: 0.4204 - val_accuracy: 0.9397\n","Epoch 49/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1854 - accuracy: 0.9978 - val_loss: 0.4312 - val_accuracy: 0.9407\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1843 - accuracy: 0.9989 - val_loss: 0.4254 - val_accuracy: 0.9364\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1840 - accuracy: 0.9978 - val_loss: 0.4824 - val_accuracy: 0.9267\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1882 - accuracy: 0.9952 - val_loss: 0.4428 - val_accuracy: 0.9332\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1822 - accuracy: 0.9984 - val_loss: 0.4415 - val_accuracy: 0.9321\n","Epoch 54/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1822 - accuracy: 0.9978 - val_loss: 0.4382 - val_accuracy: 0.9343\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1802 - accuracy: 0.9992 - val_loss: 0.4335 - val_accuracy: 0.9418\n","Epoch 56/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1783 - accuracy: 0.9995 - val_loss: 0.4300 - val_accuracy: 0.9343\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1780 - accuracy: 0.9995 - val_loss: 0.4359 - val_accuracy: 0.9343\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1788 - accuracy: 0.9984 - val_loss: 0.4311 - val_accuracy: 0.9300\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1830 - accuracy: 0.9954 - val_loss: 0.5623 - val_accuracy: 0.9095\n","Epoch 60/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1808 - accuracy: 0.9973 - val_loss: 0.4436 - val_accuracy: 0.9278\n","Epoch 61/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1819 - accuracy: 0.9968 - val_loss: 0.4687 - val_accuracy: 0.9289\n","Epoch 62/100\n","29/29 [==============================] - 1s 40ms/step - loss: 0.1808 - accuracy: 0.9968 - val_loss: 0.4439 - val_accuracy: 0.9364\n","Epoch 63/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1767 - accuracy: 0.9987 - val_loss: 0.4392 - val_accuracy: 0.9343\n","Epoch 64/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.1761 - accuracy: 0.9989 - val_loss: 0.4440 - val_accuracy: 0.9364\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1762 - accuracy: 0.9981 - val_loss: 0.4561 - val_accuracy: 0.9332\n","Epoch 66/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1766 - accuracy: 0.9981 - val_loss: 0.4521 - val_accuracy: 0.9278\n","Epoch 67/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1735 - accuracy: 0.9995 - val_loss: 0.4516 - val_accuracy: 0.9256\n","Epoch 68/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1716 - accuracy: 0.9995 - val_loss: 0.4371 - val_accuracy: 0.9343\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1708 - accuracy: 0.9992 - val_loss: 0.4451 - val_accuracy: 0.9300\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1717 - accuracy: 0.9989 - val_loss: 0.4662 - val_accuracy: 0.9300\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1711 - accuracy: 0.9992 - val_loss: 0.4526 - val_accuracy: 0.9300\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1692 - accuracy: 0.9997 - val_loss: 0.4591 - val_accuracy: 0.9278\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1691 - accuracy: 0.9992 - val_loss: 0.4537 - val_accuracy: 0.9332\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1678 - accuracy: 0.9997 - val_loss: 0.4389 - val_accuracy: 0.9343\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1674 - accuracy: 0.9995 - val_loss: 0.4442 - val_accuracy: 0.9397\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1665 - accuracy: 0.9997 - val_loss: 0.4339 - val_accuracy: 0.9418\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1659 - accuracy: 0.9997 - val_loss: 0.4424 - val_accuracy: 0.9300\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1690 - accuracy: 0.9984 - val_loss: 0.4911 - val_accuracy: 0.9170\n","Epoch 79/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1743 - accuracy: 0.9962 - val_loss: 0.4660 - val_accuracy: 0.9343\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1657 - accuracy: 0.9995 - val_loss: 0.4448 - val_accuracy: 0.9300\n","Epoch 81/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1643 - accuracy: 0.9992 - val_loss: 0.4616 - val_accuracy: 0.9310\n","Epoch 82/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1636 - accuracy: 0.9989 - val_loss: 0.4461 - val_accuracy: 0.9353\n","Epoch 83/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1626 - accuracy: 1.0000 - val_loss: 0.4447 - val_accuracy: 0.9364\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1701 - accuracy: 0.9960 - val_loss: 0.6230 - val_accuracy: 0.8847\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1691 - accuracy: 0.9973 - val_loss: 0.4655 - val_accuracy: 0.9235\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1613 - accuracy: 0.9997 - val_loss: 0.4411 - val_accuracy: 0.9321\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1653 - accuracy: 0.9984 - val_loss: 0.4591 - val_accuracy: 0.9300\n","Epoch 88/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1637 - accuracy: 0.9984 - val_loss: 0.4471 - val_accuracy: 0.9321\n","Epoch 89/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1594 - accuracy: 0.9997 - val_loss: 0.4435 - val_accuracy: 0.9300\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1593 - accuracy: 0.9995 - val_loss: 0.4500 - val_accuracy: 0.9343\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1591 - accuracy: 0.9995 - val_loss: 0.4323 - val_accuracy: 0.9343\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1596 - accuracy: 0.9989 - val_loss: 0.4385 - val_accuracy: 0.9278\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1582 - accuracy: 0.9997 - val_loss: 0.4326 - val_accuracy: 0.9321\n","Epoch 94/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1582 - accuracy: 0.9989 - val_loss: 0.4398 - val_accuracy: 0.9300\n","Epoch 95/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1580 - accuracy: 0.9995 - val_loss: 0.4389 - val_accuracy: 0.9278\n","Epoch 96/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1598 - accuracy: 0.9978 - val_loss: 0.4852 - val_accuracy: 0.9159\n","Epoch 97/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1586 - accuracy: 0.9984 - val_loss: 0.4286 - val_accuracy: 0.9289\n","Epoch 98/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1564 - accuracy: 0.9995 - val_loss: 0.4373 - val_accuracy: 0.9256\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1557 - accuracy: 0.9989 - val_loss: 0.4348 - val_accuracy: 0.9300\n","Epoch 100/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1541 - accuracy: 0.9992 - val_loss: 0.4291 - val_accuracy: 0.9321\n","{'loss': [0.24770234525203705, 0.2423519641160965, 0.24429284036159515, 0.22470687329769135, 0.22471983730793, 0.22173552215099335, 0.22129838168621063, 0.21701417863368988, 0.21696171164512634, 0.21314257383346558, 0.21137861907482147, 0.21334637701511383, 0.21386420726776123, 0.2161005735397339, 0.21000847220420837, 0.21145491302013397, 0.20928069949150085, 0.20787736773490906, 0.21007223427295685, 0.20568303763866425, 0.2067236602306366, 0.20495590567588806, 0.20532192289829254, 0.20172105729579926, 0.20027360320091248, 0.20083847641944885, 0.20235376060009003, 0.19929015636444092, 0.19887101650238037, 0.1962154507637024, 0.19940170645713806, 0.1991191953420639, 0.19745875895023346, 0.19349515438079834, 0.19555217027664185, 0.19265137612819672, 0.19139085710048676, 0.191453754901886, 0.19459275901317596, 0.18920376896858215, 0.19029764831066132, 0.18866723775863647, 0.18748261034488678, 0.18933416903018951, 0.1927434206008911, 0.18860706686973572, 0.19140900671482086, 0.1854647994041443, 0.18543478846549988, 0.18425579369068146, 0.18395647406578064, 0.18820445239543915, 0.18218426406383514, 0.18223540484905243, 0.1802358776330948, 0.17834408581256866, 0.17802104353904724, 0.17876607179641724, 0.1829947978258133, 0.18076291680335999, 0.181932732462883, 0.18076029419898987, 0.17671051621437073, 0.17605452239513397, 0.17624309659004211, 0.176597461104393, 0.17348714172840118, 0.17155860364437103, 0.17084626853466034, 0.17173196375370026, 0.17113374173641205, 0.16921517252922058, 0.16911818087100983, 0.16782225668430328, 0.16741758584976196, 0.16650564968585968, 0.16587187349796295, 0.16895586252212524, 0.17428776621818542, 0.16567368805408478, 0.1643032431602478, 0.16362476348876953, 0.1626119762659073, 0.17008699476718903, 0.1691363900899887, 0.1612957864999771, 0.1652502864599228, 0.16371670365333557, 0.15943767130374908, 0.15928804874420166, 0.15909479558467865, 0.1596430093050003, 0.15822964906692505, 0.15823812782764435, 0.15797851979732513, 0.15981575846672058, 0.15862531960010529, 0.15644517540931702, 0.15569256246089935, 0.15414412319660187], 'accuracy': [0.984375, 0.9862607717514038, 0.9849137663841248, 0.9919180870056152, 0.9929956793785095, 0.9943426847457886, 0.9929956793785095, 0.9940732717514038, 0.9946120977401733, 0.9951508641242981, 0.9975754022598267, 0.9959590435028076, 0.9948814511299133, 0.9929956793785095, 0.9959590435028076, 0.9946120977401733, 0.9954202771186829, 0.9951508641242981, 0.9943426847457886, 0.9975754022598267, 0.9959590435028076, 0.9962284564971924, 0.9970366358757019, 0.9975754022598267, 0.9978448152542114, 0.9970366358757019, 0.9962284564971924, 0.9975754022598267, 0.998652994632721, 0.9981142282485962, 0.9964978694915771, 0.9962284564971924, 0.9964978694915771, 0.9991918206214905, 0.9978448152542114, 0.9978448152542114, 0.9989224076271057, 0.9981142282485962, 0.9964978694915771, 0.9989224076271057, 0.9973060488700867, 0.998652994632721, 0.9991918206214905, 0.9975754022598267, 0.9943426847457886, 0.9970366358757019, 0.9956896305084229, 0.9981142282485962, 0.9978448152542114, 0.9989224076271057, 0.9978448152542114, 0.9951508641242981, 0.998383641242981, 0.9978448152542114, 0.9991918206214905, 0.9994612336158752, 0.9994612336158752, 0.998383641242981, 0.9954202771186829, 0.9973060488700867, 0.9967672228813171, 0.9967672228813171, 0.998652994632721, 0.9989224076271057, 0.9981142282485962, 0.9981142282485962, 0.9994612336158752, 0.9994612336158752, 0.9991918206214905, 0.9989224076271057, 0.9991918206214905, 0.9997305870056152, 0.9991918206214905, 0.9997305870056152, 0.9994612336158752, 0.9997305870056152, 0.9997305870056152, 0.998383641242981, 0.9962284564971924, 0.9994612336158752, 0.9991918206214905, 0.9989224076271057, 1.0, 0.9959590435028076, 0.9973060488700867, 0.9997305870056152, 0.998383641242981, 0.998383641242981, 0.9997305870056152, 0.9994612336158752, 0.9994612336158752, 0.9989224076271057, 0.9997305870056152, 0.9989224076271057, 0.9994612336158752, 0.9978448152542114, 0.998383641242981, 0.9994612336158752, 0.9989224076271057, 0.9991918206214905], 'val_loss': [0.9320358633995056, 0.9281988739967346, 0.9216894507408142, 0.9166796207427979, 0.9135393500328064, 0.8765900135040283, 0.8572936654090881, 0.8437836170196533, 0.8129744529724121, 0.7571281790733337, 0.7273282408714294, 0.6506198644638062, 0.5610442757606506, 0.5149127840995789, 0.5033019185066223, 0.44947072863578796, 0.4228678345680237, 0.4192450940608978, 0.38041427731513977, 0.36201292276382446, 0.4018383324146271, 0.3660467863082886, 0.3724015951156616, 0.37330958247184753, 0.3776642680168152, 0.38918009400367737, 0.40911322832107544, 0.40107572078704834, 0.4067841172218323, 0.4072059392929077, 0.41446104645729065, 0.418497771024704, 0.41921067237854004, 0.4281558692455292, 0.4365611970424652, 0.4222065508365631, 0.42758262157440186, 0.4269317388534546, 0.4246869385242462, 0.42059093713760376, 0.43529072403907776, 0.42657098174095154, 0.42541661858558655, 0.4238181412220001, 0.4305025637149811, 0.43132147192955017, 0.4468948245048523, 0.4203715920448303, 0.4312317371368408, 0.4253520667552948, 0.4823690950870514, 0.4427882134914398, 0.4415329694747925, 0.4381909668445587, 0.4335349202156067, 0.42995303869247437, 0.4359145760536194, 0.43111005425453186, 0.5622969269752502, 0.443560928106308, 0.4686982035636902, 0.44392767548561096, 0.43916258215904236, 0.4440156817436218, 0.45606353878974915, 0.45206230878829956, 0.4516107738018036, 0.43710872530937195, 0.44514819979667664, 0.4661971926689148, 0.4526449739933014, 0.459075003862381, 0.45367395877838135, 0.43886733055114746, 0.44420185685157776, 0.43385446071624756, 0.44236379861831665, 0.49110063910484314, 0.4659932851791382, 0.44479337334632874, 0.46155092120170593, 0.44614654779434204, 0.4446635842323303, 0.6229715943336487, 0.46552199125289917, 0.441089928150177, 0.45907506346702576, 0.44710665941238403, 0.44349202513694763, 0.4500410556793213, 0.4322965741157532, 0.43852531909942627, 0.43264493346214294, 0.43975070118904114, 0.4388829171657562, 0.48516297340393066, 0.42860716581344604, 0.43731021881103516, 0.43483778834342957, 0.4291142523288727], 'val_accuracy': [0.48599138855934143, 0.48599138855934143, 0.4881465435028076, 0.4903017282485962, 0.49568966031074524, 0.5075430870056152, 0.5290948152542114, 0.5409482717514038, 0.568965494632721, 0.6443965435028076, 0.6713362336158752, 0.7262930870056152, 0.8275862336158752, 0.8717672228813171, 0.857758641242981, 0.8933189511299133, 0.9105603694915771, 0.9094827771186829, 0.9331896305084229, 0.9396551847457886, 0.9170258641242981, 0.9396551847457886, 0.9331896305084229, 0.9396551847457886, 0.9407327771186829, 0.9418103694915771, 0.9385775923728943, 0.9364224076271057, 0.9353448152542114, 0.9418103694915771, 0.9385775923728943, 0.9428879022598267, 0.9418103694915771, 0.9375, 0.9407327771186829, 0.9385775923728943, 0.9321120977401733, 0.9375, 0.9364224076271057, 0.9375, 0.9353448152542114, 0.9342672228813171, 0.9407327771186829, 0.9407327771186829, 0.9407327771186829, 0.9364224076271057, 0.9256465435028076, 0.9396551847457886, 0.9407327771186829, 0.9364224076271057, 0.9267241358757019, 0.9331896305084229, 0.9321120977401733, 0.9342672228813171, 0.9418103694915771, 0.9342672228813171, 0.9342672228813171, 0.9299569129943848, 0.9094827771186829, 0.9278017282485962, 0.9288793206214905, 0.9364224076271057, 0.9342672228813171, 0.9364224076271057, 0.9331896305084229, 0.9278017282485962, 0.9256465435028076, 0.9342672228813171, 0.9299569129943848, 0.9299569129943848, 0.9299569129943848, 0.9278017282485962, 0.9331896305084229, 0.9342672228813171, 0.9396551847457886, 0.9418103694915771, 0.9299569129943848, 0.9170258641242981, 0.9342672228813171, 0.9299569129943848, 0.931034505367279, 0.9353448152542114, 0.9364224076271057, 0.8846982717514038, 0.923491358757019, 0.9321120977401733, 0.9299569129943848, 0.9321120977401733, 0.9299569129943848, 0.9342672228813171, 0.9342672228813171, 0.9278017282485962, 0.9321120977401733, 0.9299569129943848, 0.9278017282485962, 0.9159482717514038, 0.9288793206214905, 0.9256465435028076, 0.9299569129943848, 0.9321120977401733]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.2622 - accuracy: 0.9791"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 10s 51ms/step - loss: 0.2622 - accuracy: 0.9791 - val_loss: 0.9242 - val_accuracy: 0.4966\n","Epoch 2/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2403 - accuracy: 0.9875 - val_loss: 0.9228 - val_accuracy: 0.4989\n","Epoch 3/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2288 - accuracy: 0.9921 - val_loss: 0.9190 - val_accuracy: 0.4989\n","Epoch 4/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2359 - accuracy: 0.9884 - val_loss: 0.9089 - val_accuracy: 0.5011\n","Epoch 5/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2307 - accuracy: 0.9918 - val_loss: 0.8915 - val_accuracy: 0.5079\n","Epoch 6/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2278 - accuracy: 0.9924 - val_loss: 0.8732 - val_accuracy: 0.5226\n","Epoch 7/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2228 - accuracy: 0.9938 - val_loss: 0.8744 - val_accuracy: 0.5249\n","Epoch 8/100\n","28/28 [==============================] - 1s 38ms/step - loss: 0.2214 - accuracy: 0.9949 - val_loss: 0.8472 - val_accuracy: 0.5486\n","Epoch 9/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.2232 - accuracy: 0.9912 - val_loss: 0.7838 - val_accuracy: 0.6029\n","Epoch 10/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.2219 - accuracy: 0.9941 - val_loss: 0.7098 - val_accuracy: 0.6912\n","Epoch 11/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.2219 - accuracy: 0.9938 - val_loss: 0.6750 - val_accuracy: 0.7274\n","Epoch 12/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2162 - accuracy: 0.9958 - val_loss: 0.6832 - val_accuracy: 0.7104\n","Epoch 13/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2166 - accuracy: 0.9958 - val_loss: 0.6312 - val_accuracy: 0.7511\n","Epoch 14/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2145 - accuracy: 0.9960 - val_loss: 0.5932 - val_accuracy: 0.7851\n","Epoch 15/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2134 - accuracy: 0.9966 - val_loss: 0.5169 - val_accuracy: 0.8575\n","Epoch 16/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2106 - accuracy: 0.9972 - val_loss: 0.5002 - val_accuracy: 0.8575\n","Epoch 17/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2188 - accuracy: 0.9929 - val_loss: 0.4739 - val_accuracy: 0.8846\n","Epoch 18/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2204 - accuracy: 0.9921 - val_loss: 0.3894 - val_accuracy: 0.9355\n","Epoch 19/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2172 - accuracy: 0.9929 - val_loss: 0.4401 - val_accuracy: 0.8993\n","Epoch 20/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2089 - accuracy: 0.9969 - val_loss: 0.3889 - val_accuracy: 0.9197\n","Epoch 21/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2144 - accuracy: 0.9943 - val_loss: 0.3924 - val_accuracy: 0.9174\n","Epoch 22/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2044 - accuracy: 0.9977 - val_loss: 0.3903 - val_accuracy: 0.9163\n","Epoch 23/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2059 - accuracy: 0.9960 - val_loss: 0.3891 - val_accuracy: 0.9253\n","Epoch 24/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2034 - accuracy: 0.9966 - val_loss: 0.3911 - val_accuracy: 0.9321\n","Epoch 25/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2011 - accuracy: 0.9994 - val_loss: 0.4103 - val_accuracy: 0.9174\n","Epoch 26/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2006 - accuracy: 0.9986 - val_loss: 0.4092 - val_accuracy: 0.9310\n","Epoch 27/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2004 - accuracy: 0.9989 - val_loss: 0.4154 - val_accuracy: 0.9321\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1990 - accuracy: 0.9992 - val_loss: 0.4264 - val_accuracy: 0.9321\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1977 - accuracy: 0.9989 - val_loss: 0.4230 - val_accuracy: 0.9310\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1969 - accuracy: 0.9989 - val_loss: 0.4368 - val_accuracy: 0.9333\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1974 - accuracy: 0.9980 - val_loss: 0.4485 - val_accuracy: 0.9299\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1979 - accuracy: 0.9980 - val_loss: 0.4434 - val_accuracy: 0.9333\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1976 - accuracy: 0.9972 - val_loss: 0.4802 - val_accuracy: 0.9242\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2001 - accuracy: 0.9975 - val_loss: 0.4469 - val_accuracy: 0.9276\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1959 - accuracy: 0.9977 - val_loss: 0.4428 - val_accuracy: 0.9310\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1954 - accuracy: 0.9975 - val_loss: 0.4460 - val_accuracy: 0.9310\n","Epoch 37/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1970 - accuracy: 0.9972 - val_loss: 0.4536 - val_accuracy: 0.9242\n","Epoch 38/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1954 - accuracy: 0.9972 - val_loss: 0.4625 - val_accuracy: 0.9265\n","Epoch 39/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1906 - accuracy: 0.9992 - val_loss: 0.5012 - val_accuracy: 0.9208\n","Epoch 40/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.1966 - accuracy: 0.9955 - val_loss: 0.4785 - val_accuracy: 0.9118\n","Epoch 41/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1937 - accuracy: 0.9986 - val_loss: 0.4700 - val_accuracy: 0.9287\n","Epoch 42/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.1926 - accuracy: 0.9980 - val_loss: 0.4615 - val_accuracy: 0.9276\n","Epoch 43/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.1911 - accuracy: 0.9980 - val_loss: 0.4678 - val_accuracy: 0.9299\n","Epoch 44/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.1906 - accuracy: 0.9980 - val_loss: 0.4671 - val_accuracy: 0.9253\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1882 - accuracy: 0.9992 - val_loss: 0.4585 - val_accuracy: 0.9287\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1904 - accuracy: 0.9969 - val_loss: 0.4985 - val_accuracy: 0.9208\n","Epoch 47/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1928 - accuracy: 0.9966 - val_loss: 0.4886 - val_accuracy: 0.9152\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1888 - accuracy: 0.9983 - val_loss: 0.4910 - val_accuracy: 0.9197\n","Epoch 49/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1854 - accuracy: 0.9992 - val_loss: 0.4849 - val_accuracy: 0.9231\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1860 - accuracy: 0.9989 - val_loss: 0.4976 - val_accuracy: 0.9174\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1888 - accuracy: 0.9977 - val_loss: 0.4620 - val_accuracy: 0.9253\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1865 - accuracy: 0.9980 - val_loss: 0.4556 - val_accuracy: 0.9321\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1834 - accuracy: 0.9992 - val_loss: 0.4476 - val_accuracy: 0.9276\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1835 - accuracy: 0.9989 - val_loss: 0.4717 - val_accuracy: 0.9140\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1854 - accuracy: 0.9989 - val_loss: 0.4752 - val_accuracy: 0.9163\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1850 - accuracy: 0.9977 - val_loss: 0.4733 - val_accuracy: 0.9276\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1808 - accuracy: 0.9992 - val_loss: 0.4818 - val_accuracy: 0.9253\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1821 - accuracy: 0.9980 - val_loss: 0.5580 - val_accuracy: 0.9118\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1814 - accuracy: 0.9992 - val_loss: 0.4965 - val_accuracy: 0.9186\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1827 - accuracy: 0.9975 - val_loss: 0.5718 - val_accuracy: 0.9118\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1816 - accuracy: 0.9983 - val_loss: 0.4798 - val_accuracy: 0.9219\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1778 - accuracy: 0.9994 - val_loss: 0.4694 - val_accuracy: 0.9242\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1785 - accuracy: 0.9986 - val_loss: 0.4779 - val_accuracy: 0.9265\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1776 - accuracy: 0.9989 - val_loss: 0.4862 - val_accuracy: 0.9219\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1753 - accuracy: 0.9997 - val_loss: 0.4960 - val_accuracy: 0.9219\n","Epoch 66/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1779 - accuracy: 0.9986 - val_loss: 0.4680 - val_accuracy: 0.9219\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1757 - accuracy: 0.9994 - val_loss: 0.4754 - val_accuracy: 0.9197\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1744 - accuracy: 0.9994 - val_loss: 0.5013 - val_accuracy: 0.9163\n","Epoch 69/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1819 - accuracy: 0.9960 - val_loss: 0.5278 - val_accuracy: 0.9174\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1804 - accuracy: 0.9969 - val_loss: 0.5110 - val_accuracy: 0.9186\n","Epoch 71/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1807 - accuracy: 0.9958 - val_loss: 0.4837 - val_accuracy: 0.9231\n","Epoch 72/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.1767 - accuracy: 0.9986 - val_loss: 0.4722 - val_accuracy: 0.9208\n","Epoch 73/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1739 - accuracy: 0.9980 - val_loss: 0.4664 - val_accuracy: 0.9231\n","Epoch 74/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1724 - accuracy: 0.9992 - val_loss: 0.5022 - val_accuracy: 0.9186\n","Epoch 75/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1730 - accuracy: 0.9989 - val_loss: 0.5317 - val_accuracy: 0.9163\n","Epoch 76/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1723 - accuracy: 0.9989 - val_loss: 0.5161 - val_accuracy: 0.9186\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1702 - accuracy: 0.9997 - val_loss: 0.4784 - val_accuracy: 0.9197\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1684 - accuracy: 0.9997 - val_loss: 0.4845 - val_accuracy: 0.9231\n","Epoch 79/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1684 - accuracy: 0.9994 - val_loss: 0.4878 - val_accuracy: 0.9253\n","Epoch 80/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1681 - accuracy: 0.9992 - val_loss: 0.4918 - val_accuracy: 0.9231\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1670 - accuracy: 1.0000 - val_loss: 0.5114 - val_accuracy: 0.9208\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1681 - accuracy: 0.9992 - val_loss: 0.4836 - val_accuracy: 0.9186\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1664 - accuracy: 0.9994 - val_loss: 0.4927 - val_accuracy: 0.9242\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1663 - accuracy: 0.9992 - val_loss: 0.4888 - val_accuracy: 0.9231\n","Epoch 85/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1664 - accuracy: 0.9994 - val_loss: 0.4745 - val_accuracy: 0.9208\n","Epoch 86/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1647 - accuracy: 0.9997 - val_loss: 0.5063 - val_accuracy: 0.9242\n","Epoch 87/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1651 - accuracy: 0.9992 - val_loss: 0.4783 - val_accuracy: 0.9265\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1646 - accuracy: 0.9992 - val_loss: 0.4989 - val_accuracy: 0.9197\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1630 - accuracy: 0.9997 - val_loss: 0.4887 - val_accuracy: 0.9174\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1625 - accuracy: 0.9997 - val_loss: 0.5054 - val_accuracy: 0.9174\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1617 - accuracy: 0.9994 - val_loss: 0.4801 - val_accuracy: 0.9219\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1642 - accuracy: 0.9977 - val_loss: 0.5160 - val_accuracy: 0.9197\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1666 - accuracy: 0.9966 - val_loss: 0.4804 - val_accuracy: 0.9152\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1613 - accuracy: 0.9997 - val_loss: 0.4986 - val_accuracy: 0.9186\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1606 - accuracy: 0.9994 - val_loss: 0.4839 - val_accuracy: 0.9219\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1591 - accuracy: 0.9997 - val_loss: 0.4802 - val_accuracy: 0.9231\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1599 - accuracy: 0.9994 - val_loss: 0.5273 - val_accuracy: 0.9163\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1584 - accuracy: 0.9994 - val_loss: 0.4754 - val_accuracy: 0.9208\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1577 - accuracy: 0.9997 - val_loss: 0.4780 - val_accuracy: 0.9174\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1567 - accuracy: 1.0000 - val_loss: 0.5375 - val_accuracy: 0.9140\n","{'loss': [0.2621617913246155, 0.24026866257190704, 0.22878345847129822, 0.2359485924243927, 0.2306518852710724, 0.2277735322713852, 0.22281017899513245, 0.22144055366516113, 0.22320087254047394, 0.22185388207435608, 0.22191552817821503, 0.21622993052005768, 0.21660055220127106, 0.21452268958091736, 0.21337676048278809, 0.2105749398469925, 0.2188224196434021, 0.2203526347875595, 0.21717733144760132, 0.20887283980846405, 0.21437953412532806, 0.2043912261724472, 0.20591677725315094, 0.2034418135881424, 0.20106090605258942, 0.2006227970123291, 0.20040082931518555, 0.1990399956703186, 0.1976683884859085, 0.19685479998588562, 0.19741220772266388, 0.19794012606143951, 0.1975897252559662, 0.2001386135816574, 0.19593726098537445, 0.19542737305164337, 0.19704121351242065, 0.19542236626148224, 0.19055449962615967, 0.19658949971199036, 0.19370129704475403, 0.19260285794734955, 0.19109897315502167, 0.19061659276485443, 0.18818399310112, 0.1904219090938568, 0.19279304146766663, 0.1888185739517212, 0.1854342669248581, 0.18597003817558289, 0.18881194293498993, 0.1865045428276062, 0.18342776596546173, 0.1835009753704071, 0.1854431927204132, 0.18502014875411987, 0.18079814314842224, 0.18211981654167175, 0.18140536546707153, 0.182660311460495, 0.1816253811120987, 0.17782112956047058, 0.1784939020872116, 0.17756032943725586, 0.17530488967895508, 0.1778971552848816, 0.17565050721168518, 0.17435041069984436, 0.18187911808490753, 0.1804376244544983, 0.1806897073984146, 0.1767028570175171, 0.1739068478345871, 0.17236635088920593, 0.17304086685180664, 0.17229673266410828, 0.17021626234054565, 0.16841471195220947, 0.1684339940547943, 0.1681029498577118, 0.1670139878988266, 0.16810059547424316, 0.16639098525047302, 0.166294664144516, 0.16639846563339233, 0.16467620432376862, 0.16505426168441772, 0.1646387130022049, 0.16298800706863403, 0.16253264248371124, 0.16169887781143188, 0.16417910158634186, 0.1665566861629486, 0.16134613752365112, 0.16057275235652924, 0.1591164916753769, 0.15985773503780365, 0.15840978920459747, 0.15774255990982056, 0.1566549837589264], 'accuracy': [0.9790605306625366, 0.9875495433807373, 0.9920769929885864, 0.9883984327316284, 0.9917939901351929, 0.9923599362373352, 0.9937747716903687, 0.9949066042900085, 0.9912280440330505, 0.9940577149391174, 0.9937747716903687, 0.9957554936408997, 0.9957554936408997, 0.9960384964942932, 0.9966044425964355, 0.9971703290939331, 0.9929258823394775, 0.9920769929885864, 0.9929258823394775, 0.9968873858451843, 0.994340717792511, 0.9977362751960754, 0.9960384964942932, 0.9966044425964355, 0.9994340538978577, 0.9985851645469666, 0.9988681674003601, 0.9991511106491089, 0.9988681674003601, 0.9988681674003601, 0.9980192184448242, 0.9980192184448242, 0.9971703290939331, 0.9974533319473267, 0.9977362751960754, 0.9974533319473267, 0.9971703290939331, 0.9971703290939331, 0.9991511106491089, 0.9954725503921509, 0.9985851645469666, 0.9980192184448242, 0.9980192184448242, 0.9980192184448242, 0.9991511106491089, 0.9968873858451843, 0.9966044425964355, 0.9983022212982178, 0.9991511106491089, 0.9988681674003601, 0.9977362751960754, 0.9980192184448242, 0.9991511106491089, 0.9988681674003601, 0.9988681674003601, 0.9977362751960754, 0.9991511106491089, 0.9980192184448242, 0.9991511106491089, 0.9974533319473267, 0.9983022212982178, 0.9994340538978577, 0.9985851645469666, 0.9988681674003601, 0.9997170567512512, 0.9985851645469666, 0.9994340538978577, 0.9994340538978577, 0.9960384964942932, 0.9968873858451843, 0.9957554936408997, 0.9985851645469666, 0.9980192184448242, 0.9991511106491089, 0.9988681674003601, 0.9988681674003601, 0.9997170567512512, 0.9997170567512512, 0.9994340538978577, 0.9991511106491089, 1.0, 0.9991511106491089, 0.9994340538978577, 0.9991511106491089, 0.9994340538978577, 0.9997170567512512, 0.9991511106491089, 0.9991511106491089, 0.9997170567512512, 0.9997170567512512, 0.9994340538978577, 0.9977362751960754, 0.9966044425964355, 0.9997170567512512, 0.9994340538978577, 0.9997170567512512, 0.9994340538978577, 0.9994340538978577, 0.9997170567512512, 1.0], 'val_loss': [0.9242063760757446, 0.9227591156959534, 0.9189749956130981, 0.9089493155479431, 0.8915203213691711, 0.8731533288955688, 0.8744258880615234, 0.8472319841384888, 0.7838255167007446, 0.7098023295402527, 0.6749894618988037, 0.6831743121147156, 0.6312032341957092, 0.5932345390319824, 0.5168564915657043, 0.5001692771911621, 0.4738782048225403, 0.3893502652645111, 0.44011926651000977, 0.3888500928878784, 0.3923892676830292, 0.39032047986984253, 0.38911616802215576, 0.39110347628593445, 0.4103371500968933, 0.4091600477695465, 0.41541245579719543, 0.4264388978481293, 0.42300945520401, 0.4368073344230652, 0.4484632611274719, 0.4434121549129486, 0.48016971349716187, 0.4468921720981598, 0.4427567422389984, 0.445966511964798, 0.4535934627056122, 0.4624658524990082, 0.501246988773346, 0.47850301861763, 0.47002583742141724, 0.4615456163883209, 0.4678191542625427, 0.4671136736869812, 0.45847252011299133, 0.49847325682640076, 0.4886152446269989, 0.49104931950569153, 0.48487502336502075, 0.49762099981307983, 0.46202102303504944, 0.4556450843811035, 0.4476250112056732, 0.4717347025871277, 0.4751793444156647, 0.47328296303749084, 0.48178577423095703, 0.5579756498336792, 0.4965002238750458, 0.5717855095863342, 0.4797515571117401, 0.4693998396396637, 0.47794002294540405, 0.48624303936958313, 0.4959591031074524, 0.46801555156707764, 0.47535285353660583, 0.5013454556465149, 0.527777373790741, 0.510967493057251, 0.48372459411621094, 0.4722002446651459, 0.4664331376552582, 0.5022290349006653, 0.5316956043243408, 0.5160955786705017, 0.4784029722213745, 0.48452818393707275, 0.4877753257751465, 0.49183791875839233, 0.5114315152168274, 0.483583003282547, 0.4927128553390503, 0.48877325654029846, 0.47450804710388184, 0.5062939524650574, 0.47826698422431946, 0.498928964138031, 0.4886736273765564, 0.5053657293319702, 0.4800770580768585, 0.5160287618637085, 0.4804432690143585, 0.49856048822402954, 0.48392078280448914, 0.4802272319793701, 0.5273496508598328, 0.47540074586868286, 0.47798046469688416, 0.5374723076820374], 'val_accuracy': [0.49660632014274597, 0.49886876344680786, 0.49886876344680786, 0.5011312365531921, 0.5079185366630554, 0.5226244330406189, 0.5248869061470032, 0.5486425161361694, 0.6029411554336548, 0.6911764740943909, 0.7273755669593811, 0.7104072570800781, 0.7511312365531921, 0.7850678563117981, 0.8574660420417786, 0.8574660420417786, 0.8846153616905212, 0.935520350933075, 0.8993212580680847, 0.9196832776069641, 0.9174208045005798, 0.9162895679473877, 0.9253393411636353, 0.9321267008781433, 0.9174208045005798, 0.9309954643249512, 0.9321267008781433, 0.9321267008781433, 0.9309954643249512, 0.9332579374313354, 0.929864227771759, 0.9332579374313354, 0.9242081642150879, 0.9276018142700195, 0.9309954643249512, 0.9309954643249512, 0.9242081642150879, 0.9264705777168274, 0.9208144545555115, 0.9117646813392639, 0.9287330508232117, 0.9276018142700195, 0.929864227771759, 0.9253393411636353, 0.9287330508232117, 0.9208144545555115, 0.9151583909988403, 0.9196832776069641, 0.9230769276618958, 0.9174208045005798, 0.9253393411636353, 0.9321267008781433, 0.9276018142700195, 0.9140271544456482, 0.9162895679473877, 0.9276018142700195, 0.9253393411636353, 0.9117646813392639, 0.918552041053772, 0.9117646813392639, 0.9219456911087036, 0.9242081642150879, 0.9264705777168274, 0.9219456911087036, 0.9219456911087036, 0.9219456911087036, 0.9196832776069641, 0.9162895679473877, 0.9174208045005798, 0.918552041053772, 0.9230769276618958, 0.9208144545555115, 0.9230769276618958, 0.918552041053772, 0.9162895679473877, 0.918552041053772, 0.9196832776069641, 0.9230769276618958, 0.9253393411636353, 0.9230769276618958, 0.9208144545555115, 0.918552041053772, 0.9242081642150879, 0.9230769276618958, 0.9208144545555115, 0.9242081642150879, 0.9264705777168274, 0.9196832776069641, 0.9174208045005798, 0.9174208045005798, 0.9219456911087036, 0.9196832776069641, 0.9151583909988403, 0.918552041053772, 0.9219456911087036, 0.9230769276618958, 0.9162895679473877, 0.9208144545555115, 0.9174208045005798, 0.9140271544456482]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 7s 47ms/step - loss: 0.2539 - accuracy: 0.9832 - val_loss: 0.9323 - val_accuracy: 0.4855\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2475 - accuracy: 0.9822 - val_loss: 0.9333 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2371 - accuracy: 0.9876 - val_loss: 0.9235 - val_accuracy: 0.4886\n","Epoch 4/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2289 - accuracy: 0.9897 - val_loss: 0.9230 - val_accuracy: 0.4907\n","Epoch 5/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.2319 - accuracy: 0.9881 - val_loss: 0.9103 - val_accuracy: 0.4990\n","Epoch 6/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.2236 - accuracy: 0.9930 - val_loss: 0.8896 - val_accuracy: 0.5103\n","Epoch 7/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.2230 - accuracy: 0.9935 - val_loss: 0.8764 - val_accuracy: 0.5207\n","Epoch 8/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.2257 - accuracy: 0.9891 - val_loss: 0.8146 - val_accuracy: 0.5795\n","Epoch 9/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.2256 - accuracy: 0.9915 - val_loss: 0.7725 - val_accuracy: 0.6240\n","Epoch 10/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2237 - accuracy: 0.9933 - val_loss: 0.7340 - val_accuracy: 0.6436\n","Epoch 11/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2177 - accuracy: 0.9953 - val_loss: 0.6692 - val_accuracy: 0.7273\n","Epoch 12/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2200 - accuracy: 0.9930 - val_loss: 0.6270 - val_accuracy: 0.7665\n","Epoch 13/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2170 - accuracy: 0.9933 - val_loss: 0.5816 - val_accuracy: 0.8110\n","Epoch 14/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2185 - accuracy: 0.9928 - val_loss: 0.5646 - val_accuracy: 0.8120\n","Epoch 15/100\n","31/31 [==============================] - 1s 36ms/step - loss: 0.2184 - accuracy: 0.9928 - val_loss: 0.4947 - val_accuracy: 0.8709\n","Epoch 16/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2125 - accuracy: 0.9961 - val_loss: 0.4156 - val_accuracy: 0.9153\n","Epoch 17/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2203 - accuracy: 0.9902 - val_loss: 0.4637 - val_accuracy: 0.8802\n","Epoch 18/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2093 - accuracy: 0.9959 - val_loss: 0.4006 - val_accuracy: 0.9132\n","Epoch 19/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2093 - accuracy: 0.9953 - val_loss: 0.4016 - val_accuracy: 0.9122\n","Epoch 20/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2092 - accuracy: 0.9951 - val_loss: 0.3939 - val_accuracy: 0.9184\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2043 - accuracy: 0.9977 - val_loss: 0.4169 - val_accuracy: 0.9143\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2076 - accuracy: 0.9953 - val_loss: 0.4197 - val_accuracy: 0.9184\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2090 - accuracy: 0.9946 - val_loss: 0.4237 - val_accuracy: 0.9122\n","Epoch 24/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2053 - accuracy: 0.9959 - val_loss: 0.4238 - val_accuracy: 0.9225\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2046 - accuracy: 0.9966 - val_loss: 0.4388 - val_accuracy: 0.9132\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2037 - accuracy: 0.9972 - val_loss: 0.4347 - val_accuracy: 0.9205\n","Epoch 27/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2038 - accuracy: 0.9966 - val_loss: 0.4622 - val_accuracy: 0.9194\n","Epoch 28/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2002 - accuracy: 0.9984 - val_loss: 0.4572 - val_accuracy: 0.9163\n","Epoch 29/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1989 - accuracy: 0.9977 - val_loss: 0.4616 - val_accuracy: 0.9153\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2030 - accuracy: 0.9959 - val_loss: 0.4713 - val_accuracy: 0.9225\n","Epoch 31/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.1991 - accuracy: 0.9977 - val_loss: 0.4587 - val_accuracy: 0.9236\n","Epoch 32/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1984 - accuracy: 0.9977 - val_loss: 0.4906 - val_accuracy: 0.9153\n","Epoch 33/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1972 - accuracy: 0.9966 - val_loss: 0.4663 - val_accuracy: 0.9215\n","Epoch 34/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1955 - accuracy: 0.9977 - val_loss: 0.5047 - val_accuracy: 0.9091\n","Epoch 35/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2005 - accuracy: 0.9956 - val_loss: 0.4753 - val_accuracy: 0.9215\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1991 - accuracy: 0.9961 - val_loss: 0.4784 - val_accuracy: 0.9194\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1962 - accuracy: 0.9977 - val_loss: 0.4710 - val_accuracy: 0.9184\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1979 - accuracy: 0.9946 - val_loss: 0.4751 - val_accuracy: 0.9215\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2040 - accuracy: 0.9928 - val_loss: 0.4745 - val_accuracy: 0.9205\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1972 - accuracy: 0.9969 - val_loss: 0.4711 - val_accuracy: 0.9215\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1969 - accuracy: 0.9956 - val_loss: 0.5251 - val_accuracy: 0.9039\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1978 - accuracy: 0.9959 - val_loss: 0.4749 - val_accuracy: 0.9205\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1923 - accuracy: 0.9972 - val_loss: 0.5192 - val_accuracy: 0.9174\n","Epoch 44/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1928 - accuracy: 0.9966 - val_loss: 0.4808 - val_accuracy: 0.9132\n","Epoch 45/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1894 - accuracy: 0.9984 - val_loss: 0.5348 - val_accuracy: 0.9184\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1915 - accuracy: 0.9974 - val_loss: 0.5073 - val_accuracy: 0.9081\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1884 - accuracy: 0.9984 - val_loss: 0.4890 - val_accuracy: 0.9163\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1917 - accuracy: 0.9956 - val_loss: 0.4909 - val_accuracy: 0.9132\n","Epoch 49/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1863 - accuracy: 0.9984 - val_loss: 0.4897 - val_accuracy: 0.9163\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1857 - accuracy: 0.9990 - val_loss: 0.4978 - val_accuracy: 0.9174\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1842 - accuracy: 0.9992 - val_loss: 0.4924 - val_accuracy: 0.9174\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1852 - accuracy: 0.9990 - val_loss: 0.4835 - val_accuracy: 0.9153\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1861 - accuracy: 0.9982 - val_loss: 0.5174 - val_accuracy: 0.9174\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1835 - accuracy: 0.9987 - val_loss: 0.4938 - val_accuracy: 0.9194\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1842 - accuracy: 0.9977 - val_loss: 0.5106 - val_accuracy: 0.9060\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1826 - accuracy: 0.9990 - val_loss: 0.4907 - val_accuracy: 0.9163\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1819 - accuracy: 0.9977 - val_loss: 0.4840 - val_accuracy: 0.9143\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1804 - accuracy: 0.9990 - val_loss: 0.5046 - val_accuracy: 0.9225\n","Epoch 59/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1896 - accuracy: 0.9951 - val_loss: 0.5068 - val_accuracy: 0.9225\n","Epoch 60/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1888 - accuracy: 0.9951 - val_loss: 0.5068 - val_accuracy: 0.9184\n","Epoch 61/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.1841 - accuracy: 0.9979 - val_loss: 0.5052 - val_accuracy: 0.9174\n","Epoch 62/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1863 - accuracy: 0.9953 - val_loss: 0.4972 - val_accuracy: 0.9163\n","Epoch 63/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.1814 - accuracy: 0.9977 - val_loss: 0.5190 - val_accuracy: 0.9050\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1849 - accuracy: 0.9964 - val_loss: 0.5749 - val_accuracy: 0.9008\n","Epoch 65/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1807 - accuracy: 0.9977 - val_loss: 0.4834 - val_accuracy: 0.9153\n","Epoch 66/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1794 - accuracy: 0.9977 - val_loss: 0.4973 - val_accuracy: 0.9163\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1759 - accuracy: 0.9992 - val_loss: 0.5004 - val_accuracy: 0.9143\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1751 - accuracy: 0.9990 - val_loss: 0.5065 - val_accuracy: 0.9153\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1754 - accuracy: 0.9987 - val_loss: 0.5006 - val_accuracy: 0.9163\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1737 - accuracy: 1.0000 - val_loss: 0.5063 - val_accuracy: 0.9174\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1762 - accuracy: 0.9977 - val_loss: 0.5288 - val_accuracy: 0.9070\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1745 - accuracy: 0.9990 - val_loss: 0.5048 - val_accuracy: 0.9143\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1731 - accuracy: 0.9987 - val_loss: 0.5014 - val_accuracy: 0.9163\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1733 - accuracy: 0.9982 - val_loss: 0.5009 - val_accuracy: 0.9163\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1721 - accuracy: 0.9987 - val_loss: 0.5009 - val_accuracy: 0.9132\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1720 - accuracy: 0.9990 - val_loss: 0.5102 - val_accuracy: 0.9153\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1761 - accuracy: 0.9966 - val_loss: 0.5137 - val_accuracy: 0.9029\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1792 - accuracy: 0.9948 - val_loss: 0.5643 - val_accuracy: 0.9029\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1750 - accuracy: 0.9972 - val_loss: 0.4917 - val_accuracy: 0.9132\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1676 - accuracy: 1.0000 - val_loss: 0.5111 - val_accuracy: 0.9081\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1694 - accuracy: 0.9992 - val_loss: 0.5162 - val_accuracy: 0.9132\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1678 - accuracy: 0.9992 - val_loss: 0.5140 - val_accuracy: 0.9112\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1697 - accuracy: 0.9984 - val_loss: 0.4947 - val_accuracy: 0.9081\n","Epoch 84/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1677 - accuracy: 0.9984 - val_loss: 0.5161 - val_accuracy: 0.9081\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1662 - accuracy: 0.9992 - val_loss: 0.5068 - val_accuracy: 0.9163\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1656 - accuracy: 0.9995 - val_loss: 0.4918 - val_accuracy: 0.9194\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1637 - accuracy: 0.9997 - val_loss: 0.4993 - val_accuracy: 0.9184\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1635 - accuracy: 0.9995 - val_loss: 0.5118 - val_accuracy: 0.9101\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1629 - accuracy: 0.9997 - val_loss: 0.5113 - val_accuracy: 0.9112\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1630 - accuracy: 0.9997 - val_loss: 0.5051 - val_accuracy: 0.9122\n","Epoch 91/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1639 - accuracy: 0.9990 - val_loss: 0.5178 - val_accuracy: 0.9122\n","Epoch 92/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1668 - accuracy: 0.9969 - val_loss: 0.5227 - val_accuracy: 0.9101\n","Epoch 93/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.1624 - accuracy: 0.9992 - val_loss: 0.5123 - val_accuracy: 0.9143\n","Epoch 94/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1616 - accuracy: 0.9995 - val_loss: 0.4981 - val_accuracy: 0.9132\n","Epoch 95/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1636 - accuracy: 0.9984 - val_loss: 0.5610 - val_accuracy: 0.8988\n","Epoch 96/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1636 - accuracy: 0.9977 - val_loss: 0.5097 - val_accuracy: 0.9143\n","Epoch 97/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1618 - accuracy: 0.9984 - val_loss: 0.4954 - val_accuracy: 0.9122\n","Epoch 98/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1641 - accuracy: 0.9969 - val_loss: 0.5142 - val_accuracy: 0.9122\n","Epoch 99/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1614 - accuracy: 0.9984 - val_loss: 0.5177 - val_accuracy: 0.9122\n","Epoch 100/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1590 - accuracy: 0.9997 - val_loss: 0.5577 - val_accuracy: 0.9101\n","{'loss': [0.2538786828517914, 0.24746595323085785, 0.23711350560188293, 0.22885635495185852, 0.23191680014133453, 0.22362783551216125, 0.22299973666667938, 0.22571556270122528, 0.22559943795204163, 0.22369299829006195, 0.21770791709423065, 0.2199781984090805, 0.21695224940776825, 0.2184637486934662, 0.21840809285640717, 0.21248896420001984, 0.22033792734146118, 0.2092898041009903, 0.20931482315063477, 0.20921356976032257, 0.20425930619239807, 0.2075757533311844, 0.2089879810810089, 0.20525047183036804, 0.20461153984069824, 0.20365415513515472, 0.20379778742790222, 0.20016460120677948, 0.19887983798980713, 0.20299196243286133, 0.1991472989320755, 0.19844619929790497, 0.1971753090620041, 0.1954892873764038, 0.2005172222852707, 0.19912123680114746, 0.1962042599916458, 0.19791404902935028, 0.20398354530334473, 0.197163388133049, 0.19685372710227966, 0.19776920974254608, 0.1923089176416397, 0.1928083747625351, 0.18943902850151062, 0.19152095913887024, 0.1883959174156189, 0.19168931245803833, 0.18627281486988068, 0.1856795996427536, 0.1841728836297989, 0.1852179318666458, 0.18606434762477875, 0.18349944055080414, 0.1842481940984726, 0.18262352049350739, 0.1819320172071457, 0.18044854700565338, 0.18959373235702515, 0.1887955367565155, 0.18410438299179077, 0.18627633154392242, 0.18141642212867737, 0.18494513630867004, 0.18074816465377808, 0.17936481535434723, 0.17589113116264343, 0.17510700225830078, 0.17538736760616302, 0.17365767061710358, 0.17624789476394653, 0.1744730919599533, 0.17305095493793488, 0.17327727377414703, 0.1720808893442154, 0.17198149859905243, 0.17610366642475128, 0.17921267449855804, 0.17499901354312897, 0.16755793988704681, 0.16938209533691406, 0.167777419090271, 0.1696593463420868, 0.16765429079532623, 0.16621413826942444, 0.1656159907579422, 0.16369138658046722, 0.16353021562099457, 0.1628529578447342, 0.16300731897354126, 0.1638580709695816, 0.16680675745010376, 0.16235250234603882, 0.16158999502658844, 0.16357043385505676, 0.16359259188175201, 0.1618405133485794, 0.16407473385334015, 0.16135716438293457, 0.15903793275356293], 'accuracy': [0.9832041263580322, 0.9821705222129822, 0.987596869468689, 0.9896640777587891, 0.9881137013435364, 0.9930232763290405, 0.9935400485992432, 0.9891473054885864, 0.9914728403091431, 0.9932816624641418, 0.9953488111495972, 0.9930232763290405, 0.9932816624641418, 0.9927648305892944, 0.9927648305892944, 0.9961240291595459, 0.9901808500289917, 0.9958656430244446, 0.9953488111495972, 0.9950904250144958, 0.9976744055747986, 0.9953488111495972, 0.9945736527442932, 0.9958656430244446, 0.9966408014297485, 0.997157633304596, 0.9966408014297485, 0.9984496235847473, 0.9976744055747986, 0.9958656430244446, 0.9976744055747986, 0.9976744055747986, 0.9966408014297485, 0.9976744055747986, 0.9956072568893433, 0.9961240291595459, 0.9976744055747986, 0.9945736527442932, 0.9927648305892944, 0.9968992471694946, 0.9956072568893433, 0.9958656430244446, 0.997157633304596, 0.9966408014297485, 0.9984496235847473, 0.9974160194396973, 0.9984496235847473, 0.9956072568893433, 0.9984496235847473, 0.99896639585495, 0.9992247819900513, 0.99896639585495, 0.998191237449646, 0.9987080097198486, 0.9976744055747986, 0.99896639585495, 0.9976744055747986, 0.99896639585495, 0.9950904250144958, 0.9950904250144958, 0.9979327917098999, 0.9953488111495972, 0.9976744055747986, 0.9963824152946472, 0.9976744055747986, 0.9976744055747986, 0.9992247819900513, 0.99896639585495, 0.9987080097198486, 1.0, 0.9976744055747986, 0.99896639585495, 0.9987080097198486, 0.998191237449646, 0.9987080097198486, 0.99896639585495, 0.9966408014297485, 0.9948320388793945, 0.997157633304596, 1.0, 0.9992247819900513, 0.9992247819900513, 0.9984496235847473, 0.9984496235847473, 0.9992247819900513, 0.9994832277297974, 0.9997416138648987, 0.9994832277297974, 0.9997416138648987, 0.9997416138648987, 0.99896639585495, 0.9968992471694946, 0.9992247819900513, 0.9994832277297974, 0.9984496235847473, 0.9976744055747986, 0.9984496235847473, 0.9968992471694946, 0.9984496235847473, 0.9997416138648987], 'val_loss': [0.932316780090332, 0.9332507252693176, 0.9235424399375916, 0.9229723215103149, 0.9103051424026489, 0.8895531296730042, 0.8763808012008667, 0.8145748972892761, 0.7725356817245483, 0.7340326309204102, 0.6692440509796143, 0.6269751191139221, 0.5815766453742981, 0.5645995140075684, 0.494693785905838, 0.4155859053134918, 0.4637129306793213, 0.40057554841041565, 0.4016371965408325, 0.3938910663127899, 0.41691163182258606, 0.4197057783603668, 0.4236640930175781, 0.4238013029098511, 0.4387560486793518, 0.43469303846359253, 0.46221527457237244, 0.4571678638458252, 0.46155837178230286, 0.4712670147418976, 0.4587065577507019, 0.4905826151371002, 0.4663158655166626, 0.5047008395195007, 0.47529882192611694, 0.47842881083488464, 0.47101765871047974, 0.47506916522979736, 0.4744834005832672, 0.4710744321346283, 0.5251453518867493, 0.47486841678619385, 0.5192123055458069, 0.480821430683136, 0.5348395705223083, 0.5072596073150635, 0.4889841675758362, 0.49087437987327576, 0.4897210896015167, 0.49779054522514343, 0.49235036969184875, 0.48348695039749146, 0.5173594355583191, 0.4937780201435089, 0.5106034278869629, 0.4906730353832245, 0.48400425910949707, 0.5046412348747253, 0.5067634582519531, 0.5068015456199646, 0.5051610469818115, 0.4972485899925232, 0.5190421342849731, 0.5749058723449707, 0.4834367632865906, 0.49732089042663574, 0.5003732442855835, 0.506463348865509, 0.5006244778633118, 0.5062976479530334, 0.5287801027297974, 0.5047512650489807, 0.5013663172721863, 0.500904381275177, 0.5008706450462341, 0.5102072954177856, 0.5136934518814087, 0.5643018484115601, 0.49170270562171936, 0.5110602974891663, 0.516165018081665, 0.5139654874801636, 0.4947173595428467, 0.5160918235778809, 0.5067780613899231, 0.491800993680954, 0.4993234872817993, 0.5117952227592468, 0.5112752914428711, 0.505091667175293, 0.5178000926971436, 0.5227111577987671, 0.5122684240341187, 0.4981227517127991, 0.5610279440879822, 0.5097118616104126, 0.49538958072662354, 0.5141516923904419, 0.517719030380249, 0.5577396154403687], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.4886363744735718, 0.49070248007774353, 0.49896693229675293, 0.5103305578231812, 0.5206611752510071, 0.5795454382896423, 0.6239669322967529, 0.6435950398445129, 0.7272727489471436, 0.7665289044380188, 0.8109503984451294, 0.8119834661483765, 0.8708677887916565, 0.9152892827987671, 0.8801652789115906, 0.913223147392273, 0.9121900796890259, 0.9183884263038635, 0.91425621509552, 0.9183884263038635, 0.9121900796890259, 0.922520637512207, 0.913223147392273, 0.9204545617103577, 0.9194214940071106, 0.9163222908973694, 0.9152892827987671, 0.922520637512207, 0.9235537052154541, 0.9152892827987671, 0.9214876294136047, 0.9090909361839294, 0.9214876294136047, 0.9194214940071106, 0.9183884263038635, 0.9214876294136047, 0.9204545617103577, 0.9214876294136047, 0.9039255976676941, 0.9204545617103577, 0.9173553586006165, 0.913223147392273, 0.9183884263038635, 0.9080578684806824, 0.9163222908973694, 0.913223147392273, 0.9163222908973694, 0.9173553586006165, 0.9173553586006165, 0.9152892827987671, 0.9173553586006165, 0.9194214940071106, 0.9059917330741882, 0.9163222908973694, 0.91425621509552, 0.922520637512207, 0.922520637512207, 0.9183884263038635, 0.9173553586006165, 0.9163222908973694, 0.9049586653709412, 0.9008264541625977, 0.9152892827987671, 0.9163222908973694, 0.91425621509552, 0.9152892827987671, 0.9163222908973694, 0.9173553586006165, 0.9070248007774353, 0.91425621509552, 0.9163222908973694, 0.9163222908973694, 0.913223147392273, 0.9152892827987671, 0.9028925895690918, 0.9028925895690918, 0.913223147392273, 0.9080578684806824, 0.913223147392273, 0.9111570119857788, 0.9080578684806824, 0.9080578684806824, 0.9163222908973694, 0.9194214940071106, 0.9183884263038635, 0.9101239442825317, 0.9111570119857788, 0.9121900796890259, 0.9121900796890259, 0.9101239442825317, 0.91425621509552, 0.913223147392273, 0.8987603187561035, 0.91425621509552, 0.9121900796890259, 0.9121900796890259, 0.9121900796890259, 0.9101239442825317]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.1805 - accuracy: 0.9919"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 49ms/step - loss: 0.1827 - accuracy: 0.9914 - val_loss: 0.8998 - val_accuracy: 0.4860\n","Epoch 2/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1732 - accuracy: 0.9922 - val_loss: 0.8925 - val_accuracy: 0.4860\n","Epoch 3/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1658 - accuracy: 0.9965 - val_loss: 0.8919 - val_accuracy: 0.4860\n","Epoch 4/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1625 - accuracy: 0.9978 - val_loss: 0.8872 - val_accuracy: 0.4914\n","Epoch 5/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1625 - accuracy: 0.9981 - val_loss: 0.8771 - val_accuracy: 0.4989\n","Epoch 6/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1642 - accuracy: 0.9946 - val_loss: 0.8592 - val_accuracy: 0.5011\n","Epoch 7/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1616 - accuracy: 0.9968 - val_loss: 0.8201 - val_accuracy: 0.5205\n","Epoch 8/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.1580 - accuracy: 0.9987 - val_loss: 0.8082 - val_accuracy: 0.5377\n","Epoch 9/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1576 - accuracy: 0.9987 - val_loss: 0.7325 - val_accuracy: 0.5959\n","Epoch 10/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1579 - accuracy: 0.9978 - val_loss: 0.7389 - val_accuracy: 0.6002\n","Epoch 11/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1555 - accuracy: 0.9995 - val_loss: 0.6969 - val_accuracy: 0.6573\n","Epoch 12/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.1616 - accuracy: 0.9952 - val_loss: 0.5364 - val_accuracy: 0.7899\n","Epoch 13/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.1565 - accuracy: 0.9978 - val_loss: 0.4947 - val_accuracy: 0.8254\n","Epoch 14/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1605 - accuracy: 0.9968 - val_loss: 0.5441 - val_accuracy: 0.7651\n","Epoch 15/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.1624 - accuracy: 0.9962 - val_loss: 0.4049 - val_accuracy: 0.9019\n","Epoch 16/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.1559 - accuracy: 0.9978 - val_loss: 0.3761 - val_accuracy: 0.9213\n","Epoch 17/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.1543 - accuracy: 0.9987 - val_loss: 0.3282 - val_accuracy: 0.9418\n","Epoch 18/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1529 - accuracy: 0.9989 - val_loss: 0.3304 - val_accuracy: 0.9310\n","Epoch 19/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.1519 - accuracy: 0.9992 - val_loss: 0.3093 - val_accuracy: 0.9440\n","Epoch 20/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.1526 - accuracy: 0.9981 - val_loss: 0.2812 - val_accuracy: 0.9558\n","Epoch 21/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1558 - accuracy: 0.9981 - val_loss: 0.2883 - val_accuracy: 0.9515\n","Epoch 22/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1539 - accuracy: 0.9981 - val_loss: 0.3299 - val_accuracy: 0.9375\n","Epoch 23/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1524 - accuracy: 0.9981 - val_loss: 0.3461 - val_accuracy: 0.9353\n","Epoch 24/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1509 - accuracy: 0.9992 - val_loss: 0.3246 - val_accuracy: 0.9450\n","Epoch 25/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1487 - accuracy: 0.9997 - val_loss: 0.3024 - val_accuracy: 0.9580\n","Epoch 26/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1500 - accuracy: 0.9992 - val_loss: 0.3135 - val_accuracy: 0.9580\n","Epoch 27/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1517 - accuracy: 0.9973 - val_loss: 0.3291 - val_accuracy: 0.9537\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1481 - accuracy: 0.9984 - val_loss: 0.3204 - val_accuracy: 0.9537\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1458 - accuracy: 1.0000 - val_loss: 0.3267 - val_accuracy: 0.9537\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1470 - accuracy: 0.9987 - val_loss: 0.3309 - val_accuracy: 0.9580\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1470 - accuracy: 0.9989 - val_loss: 0.3349 - val_accuracy: 0.9558\n","Epoch 32/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.1450 - accuracy: 0.9997 - val_loss: 0.3308 - val_accuracy: 0.9601\n","Epoch 33/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1453 - accuracy: 0.9995 - val_loss: 0.3553 - val_accuracy: 0.9504\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1462 - accuracy: 0.9992 - val_loss: 0.3292 - val_accuracy: 0.9504\n","Epoch 35/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1487 - accuracy: 0.9973 - val_loss: 0.3384 - val_accuracy: 0.9515\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1452 - accuracy: 0.9981 - val_loss: 0.3239 - val_accuracy: 0.9580\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1447 - accuracy: 0.9995 - val_loss: 0.3574 - val_accuracy: 0.9450\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1458 - accuracy: 0.9981 - val_loss: 0.3408 - val_accuracy: 0.9526\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1427 - accuracy: 0.9992 - val_loss: 0.3239 - val_accuracy: 0.9547\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1417 - accuracy: 0.9995 - val_loss: 0.3230 - val_accuracy: 0.9580\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1429 - accuracy: 0.9984 - val_loss: 0.3369 - val_accuracy: 0.9537\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1465 - accuracy: 0.9970 - val_loss: 0.3408 - val_accuracy: 0.9580\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1408 - accuracy: 0.9995 - val_loss: 0.3327 - val_accuracy: 0.9580\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1398 - accuracy: 0.9997 - val_loss: 0.3359 - val_accuracy: 0.9569\n","Epoch 45/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1423 - accuracy: 0.9989 - val_loss: 0.3427 - val_accuracy: 0.9461\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1404 - accuracy: 0.9992 - val_loss: 0.3372 - val_accuracy: 0.9558\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1394 - accuracy: 0.9992 - val_loss: 0.3450 - val_accuracy: 0.9494\n","Epoch 48/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1379 - accuracy: 1.0000 - val_loss: 0.3419 - val_accuracy: 0.9547\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1384 - accuracy: 0.9997 - val_loss: 0.3474 - val_accuracy: 0.9472\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1371 - accuracy: 0.9997 - val_loss: 0.3393 - val_accuracy: 0.9591\n","Epoch 51/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.1364 - accuracy: 0.9997 - val_loss: 0.3371 - val_accuracy: 0.9569\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1358 - accuracy: 0.9997 - val_loss: 0.3358 - val_accuracy: 0.9537\n","Epoch 53/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1356 - accuracy: 0.9997 - val_loss: 0.3401 - val_accuracy: 0.9483\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1370 - accuracy: 0.9989 - val_loss: 0.3533 - val_accuracy: 0.9494\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1370 - accuracy: 0.9995 - val_loss: 0.3540 - val_accuracy: 0.9504\n","Epoch 56/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1348 - accuracy: 0.9992 - val_loss: 0.3427 - val_accuracy: 0.9537\n","Epoch 57/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1341 - accuracy: 0.9995 - val_loss: 0.3454 - val_accuracy: 0.9558\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1331 - accuracy: 0.9997 - val_loss: 0.3408 - val_accuracy: 0.9504\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1339 - accuracy: 0.9992 - val_loss: 0.3387 - val_accuracy: 0.9504\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1331 - accuracy: 0.9997 - val_loss: 0.3488 - val_accuracy: 0.9526\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1330 - accuracy: 0.9992 - val_loss: 0.3823 - val_accuracy: 0.9386\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1343 - accuracy: 0.9989 - val_loss: 0.3415 - val_accuracy: 0.9569\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1310 - accuracy: 1.0000 - val_loss: 0.3589 - val_accuracy: 0.9526\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1321 - accuracy: 0.9992 - val_loss: 0.3705 - val_accuracy: 0.9461\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1346 - accuracy: 0.9978 - val_loss: 0.3361 - val_accuracy: 0.9429\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1318 - accuracy: 0.9992 - val_loss: 0.3319 - val_accuracy: 0.9547\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1359 - accuracy: 0.9965 - val_loss: 0.3531 - val_accuracy: 0.9429\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1299 - accuracy: 0.9995 - val_loss: 0.3738 - val_accuracy: 0.9386\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1293 - accuracy: 0.9995 - val_loss: 0.3412 - val_accuracy: 0.9494\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1313 - accuracy: 0.9987 - val_loss: 0.3630 - val_accuracy: 0.9440\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1290 - accuracy: 0.9992 - val_loss: 0.3600 - val_accuracy: 0.9450\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1307 - accuracy: 0.9987 - val_loss: 0.3378 - val_accuracy: 0.9569\n","Epoch 73/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1276 - accuracy: 0.9995 - val_loss: 0.3402 - val_accuracy: 0.9429\n","Epoch 74/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1277 - accuracy: 0.9992 - val_loss: 0.3498 - val_accuracy: 0.9526\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1279 - accuracy: 0.9984 - val_loss: 0.3566 - val_accuracy: 0.9450\n","Epoch 76/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1285 - accuracy: 0.9984 - val_loss: 0.3889 - val_accuracy: 0.9321\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1267 - accuracy: 0.9992 - val_loss: 0.3428 - val_accuracy: 0.9515\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1252 - accuracy: 0.9995 - val_loss: 0.3385 - val_accuracy: 0.9494\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1243 - accuracy: 0.9997 - val_loss: 0.3344 - val_accuracy: 0.9494\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1239 - accuracy: 1.0000 - val_loss: 0.3389 - val_accuracy: 0.9450\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1245 - accuracy: 0.9992 - val_loss: 0.4226 - val_accuracy: 0.9149\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1244 - accuracy: 0.9992 - val_loss: 0.3616 - val_accuracy: 0.9450\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1245 - accuracy: 0.9992 - val_loss: 0.4554 - val_accuracy: 0.9106\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1259 - accuracy: 0.9989 - val_loss: 0.3792 - val_accuracy: 0.9407\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1221 - accuracy: 0.9995 - val_loss: 0.3523 - val_accuracy: 0.9483\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1214 - accuracy: 0.9995 - val_loss: 0.3548 - val_accuracy: 0.9461\n","Epoch 87/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1207 - accuracy: 0.9997 - val_loss: 0.3371 - val_accuracy: 0.9526\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1220 - accuracy: 0.9995 - val_loss: 0.3528 - val_accuracy: 0.9429\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1196 - accuracy: 1.0000 - val_loss: 0.3535 - val_accuracy: 0.9483\n","Epoch 90/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1200 - accuracy: 0.9997 - val_loss: 0.3514 - val_accuracy: 0.9461\n","Epoch 91/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1209 - accuracy: 0.9992 - val_loss: 0.3691 - val_accuracy: 0.9429\n","Epoch 92/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1222 - accuracy: 0.9984 - val_loss: 0.3448 - val_accuracy: 0.9483\n","Epoch 93/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1187 - accuracy: 0.9997 - val_loss: 0.3514 - val_accuracy: 0.9494\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1173 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 0.9472\n","Epoch 95/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1169 - accuracy: 1.0000 - val_loss: 0.3553 - val_accuracy: 0.9418\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1164 - accuracy: 1.0000 - val_loss: 0.3602 - val_accuracy: 0.9440\n","Epoch 97/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.1163 - accuracy: 0.9997 - val_loss: 0.3475 - val_accuracy: 0.9450\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1161 - accuracy: 0.9997 - val_loss: 0.3402 - val_accuracy: 0.9504\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1156 - accuracy: 1.0000 - val_loss: 0.3935 - val_accuracy: 0.9310\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1149 - accuracy: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.9483\n","{'loss': [0.18271642923355103, 0.1732209324836731, 0.1658010631799698, 0.16246354579925537, 0.16252751648426056, 0.16423951089382172, 0.16159094870090485, 0.15803669393062592, 0.1575540155172348, 0.15792588889598846, 0.15550632774829865, 0.16157284379005432, 0.15646706521511078, 0.1605110764503479, 0.16238605976104736, 0.15585097670555115, 0.15434876084327698, 0.15289922058582306, 0.1519029289484024, 0.15262311697006226, 0.15578201413154602, 0.15391573309898376, 0.1524190753698349, 0.15093395113945007, 0.14869152009487152, 0.15000778436660767, 0.15168698132038116, 0.14814116060733795, 0.14583387970924377, 0.14699731767177582, 0.14701443910598755, 0.1450178027153015, 0.14525113999843597, 0.14623156189918518, 0.14873537421226501, 0.14521285891532898, 0.14473965764045715, 0.1458033323287964, 0.1427353024482727, 0.14170005917549133, 0.14293549954891205, 0.14653845131397247, 0.14080269634723663, 0.1398112177848816, 0.14231067895889282, 0.14042186737060547, 0.13941754400730133, 0.13786521553993225, 0.13839660584926605, 0.13710641860961914, 0.13636434078216553, 0.13578718900680542, 0.13563372194766998, 0.13698077201843262, 0.13697706162929535, 0.13476699590682983, 0.13406780362129211, 0.13310730457305908, 0.13393019139766693, 0.1331096738576889, 0.13298065960407257, 0.13427650928497314, 0.13096210360527039, 0.13212507963180542, 0.13462160527706146, 0.13179482519626617, 0.1359434574842453, 0.12992994487285614, 0.12932978570461273, 0.1313101053237915, 0.1289672553539276, 0.13069729506969452, 0.1275622695684433, 0.12771862745285034, 0.1279023289680481, 0.12847448885440826, 0.12673982977867126, 0.12518934905529022, 0.12427565455436707, 0.12394852936267853, 0.12449366599321365, 0.1243983656167984, 0.12449876964092255, 0.1258731335401535, 0.12213166803121567, 0.12135233730077744, 0.1207418292760849, 0.12202651798725128, 0.11958694458007812, 0.12003916501998901, 0.12091176211833954, 0.12218929082155228, 0.11866392195224762, 0.11731407046318054, 0.11690370738506317, 0.11643011122941971, 0.11633807420730591, 0.11609048396348953, 0.11555638164281845, 0.11493724584579468], 'accuracy': [0.9913793206214905, 0.9921875, 0.9964978694915771, 0.9978448152542114, 0.9981142282485962, 0.9946120977401733, 0.9967672228813171, 0.998652994632721, 0.998652994632721, 0.9978448152542114, 0.9994612336158752, 0.9951508641242981, 0.9978448152542114, 0.9967672228813171, 0.9962284564971924, 0.9978448152542114, 0.998652994632721, 0.9989224076271057, 0.9991918206214905, 0.9981142282485962, 0.9981142282485962, 0.9981142282485962, 0.9981142282485962, 0.9991918206214905, 0.9997305870056152, 0.9991918206214905, 0.9973060488700867, 0.998383641242981, 1.0, 0.998652994632721, 0.9989224076271057, 0.9997305870056152, 0.9994612336158752, 0.9991918206214905, 0.9973060488700867, 0.9981142282485962, 0.9994612336158752, 0.9981142282485962, 0.9991918206214905, 0.9994612336158752, 0.998383641242981, 0.9970366358757019, 0.9994612336158752, 0.9997305870056152, 0.9989224076271057, 0.9991918206214905, 0.9991918206214905, 1.0, 0.9997305870056152, 0.9997305870056152, 0.9997305870056152, 0.9997305870056152, 0.9997305870056152, 0.9989224076271057, 0.9994612336158752, 0.9991918206214905, 0.9994612336158752, 0.9997305870056152, 0.9991918206214905, 0.9997305870056152, 0.9991918206214905, 0.9989224076271057, 1.0, 0.9991918206214905, 0.9978448152542114, 0.9991918206214905, 0.9964978694915771, 0.9994612336158752, 0.9994612336158752, 0.998652994632721, 0.9991918206214905, 0.998652994632721, 0.9994612336158752, 0.9991918206214905, 0.998383641242981, 0.998383641242981, 0.9991918206214905, 0.9994612336158752, 0.9997305870056152, 1.0, 0.9991918206214905, 0.9991918206214905, 0.9991918206214905, 0.9989224076271057, 0.9994612336158752, 0.9994612336158752, 0.9997305870056152, 0.9994612336158752, 1.0, 0.9997305870056152, 0.9991918206214905, 0.998383641242981, 0.9997305870056152, 1.0, 1.0, 1.0, 0.9997305870056152, 0.9997305870056152, 1.0, 1.0], 'val_loss': [0.8997731804847717, 0.8924597501754761, 0.8919395804405212, 0.8871658444404602, 0.8770578503608704, 0.8591898083686829, 0.820056140422821, 0.8081924319267273, 0.7324522733688354, 0.738914430141449, 0.6968664526939392, 0.5364162921905518, 0.494742214679718, 0.5441212058067322, 0.40488171577453613, 0.37606242299079895, 0.32820871472358704, 0.3304433822631836, 0.30930712819099426, 0.2811743915081024, 0.2883288264274597, 0.32985082268714905, 0.34605440497398376, 0.3245919346809387, 0.30244800448417664, 0.3135491609573364, 0.32908791303634644, 0.3204382061958313, 0.32673418521881104, 0.33093389868736267, 0.33492887020111084, 0.3307752013206482, 0.35529181361198425, 0.32921460270881653, 0.33837631344795227, 0.32394009828567505, 0.3574492931365967, 0.34077227115631104, 0.32391318678855896, 0.3229590356349945, 0.33685770630836487, 0.3408074975013733, 0.33265945315361023, 0.3358971178531647, 0.34272003173828125, 0.33717748522758484, 0.34498313069343567, 0.3418782949447632, 0.34735870361328125, 0.3393372595310211, 0.33706411719322205, 0.33584022521972656, 0.34006625413894653, 0.35334205627441406, 0.3539797067642212, 0.34270453453063965, 0.3453711271286011, 0.34083282947540283, 0.3387259244918823, 0.3487703204154968, 0.38229963183403015, 0.341508686542511, 0.35885390639305115, 0.3704823851585388, 0.33606213331222534, 0.3318558633327484, 0.3530963063240051, 0.3737725019454956, 0.3412399888038635, 0.36304253339767456, 0.35999172925949097, 0.3377794027328491, 0.34021344780921936, 0.3498096764087677, 0.3566468358039856, 0.38885822892189026, 0.34278520941734314, 0.33848536014556885, 0.33444535732269287, 0.33891966938972473, 0.42261284589767456, 0.3615947961807251, 0.4554159939289093, 0.37920138239860535, 0.35234442353248596, 0.35478097200393677, 0.3371332883834839, 0.3527906537055969, 0.35349878668785095, 0.3513853847980499, 0.36909782886505127, 0.3448330760002136, 0.3514194190502167, 0.3487454354763031, 0.35527971386909485, 0.36017271876335144, 0.3475395441055298, 0.34018993377685547, 0.3935275673866272, 0.3517068028450012], 'val_accuracy': [0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.4913793206214905, 0.4989224076271057, 0.5010775923728943, 0.5204741358757019, 0.537715494632721, 0.5959051847457886, 0.600215494632721, 0.6573275923728943, 0.7898706793785095, 0.8254310488700867, 0.7650862336158752, 0.9019396305084229, 0.9213362336158752, 0.9418103694915771, 0.931034505367279, 0.943965494632721, 0.9558189511299133, 0.951508641242981, 0.9375, 0.9353448152542114, 0.9450430870056152, 0.9579741358757019, 0.9579741358757019, 0.9536637663841248, 0.9536637663841248, 0.9536637663841248, 0.9579741358757019, 0.9558189511299133, 0.9601293206214905, 0.9504310488700867, 0.9504310488700867, 0.951508641242981, 0.9579741358757019, 0.9450430870056152, 0.9525862336158752, 0.954741358757019, 0.9579741358757019, 0.9536637663841248, 0.9579741358757019, 0.9579741358757019, 0.9568965435028076, 0.9461206793785095, 0.9558189511299133, 0.9493534564971924, 0.954741358757019, 0.9471982717514038, 0.9590517282485962, 0.9568965435028076, 0.9536637663841248, 0.9482758641242981, 0.9493534564971924, 0.9504310488700867, 0.9536637663841248, 0.9558189511299133, 0.9504310488700867, 0.9504310488700867, 0.9525862336158752, 0.9385775923728943, 0.9568965435028076, 0.9525862336158752, 0.9461206793785095, 0.9428879022598267, 0.954741358757019, 0.9428879022598267, 0.9385775923728943, 0.9493534564971924, 0.943965494632721, 0.9450430870056152, 0.9568965435028076, 0.9428879022598267, 0.9525862336158752, 0.9450430870056152, 0.9321120977401733, 0.951508641242981, 0.9493534564971924, 0.9493534564971924, 0.9450430870056152, 0.9148706793785095, 0.9450430870056152, 0.9105603694915771, 0.9407327771186829, 0.9482758641242981, 0.9461206793785095, 0.9525862336158752, 0.9428879022598267, 0.9482758641242981, 0.9461206793785095, 0.9428879022598267, 0.9482758641242981, 0.9493534564971924, 0.9471982717514038, 0.9418103694915771, 0.943965494632721, 0.9450430870056152, 0.9504310488700867, 0.931034505367279, 0.9482758641242981]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.1920 - accuracy: 0.9875"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 7s 74ms/step - loss: 0.1920 - accuracy: 0.9875 - val_loss: 0.8937 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.1791 - accuracy: 0.9912 - val_loss: 0.8836 - val_accuracy: 0.4977\n","Epoch 3/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.1715 - accuracy: 0.9958 - val_loss: 0.8809 - val_accuracy: 0.4989\n","Epoch 4/100\n","28/28 [==============================] - 1s 41ms/step - loss: 0.1666 - accuracy: 0.9963 - val_loss: 0.8714 - val_accuracy: 0.5023\n","Epoch 5/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1656 - accuracy: 0.9969 - val_loss: 0.8569 - val_accuracy: 0.5090\n","Epoch 6/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1627 - accuracy: 0.9975 - val_loss: 0.8300 - val_accuracy: 0.5215\n","Epoch 7/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1629 - accuracy: 0.9977 - val_loss: 0.8121 - val_accuracy: 0.5407\n","Epoch 8/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.1625 - accuracy: 0.9969 - val_loss: 0.7779 - val_accuracy: 0.5588\n","Epoch 9/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1625 - accuracy: 0.9972 - val_loss: 0.7129 - val_accuracy: 0.6143\n","Epoch 10/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.1597 - accuracy: 0.9983 - val_loss: 0.6583 - val_accuracy: 0.6810\n","Epoch 11/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.1582 - accuracy: 0.9986 - val_loss: 0.6071 - val_accuracy: 0.7296\n","Epoch 12/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.1584 - accuracy: 0.9983 - val_loss: 0.5739 - val_accuracy: 0.7590\n","Epoch 13/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1557 - accuracy: 0.9986 - val_loss: 0.5384 - val_accuracy: 0.7760\n","Epoch 14/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1579 - accuracy: 0.9986 - val_loss: 0.4513 - val_accuracy: 0.8790\n","Epoch 15/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1556 - accuracy: 0.9989 - val_loss: 0.4486 - val_accuracy: 0.8597\n","Epoch 16/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.1593 - accuracy: 0.9977 - val_loss: 0.4062 - val_accuracy: 0.8993\n","Epoch 17/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1556 - accuracy: 0.9989 - val_loss: 0.3766 - val_accuracy: 0.9106\n","Epoch 18/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1556 - accuracy: 0.9975 - val_loss: 0.3813 - val_accuracy: 0.9050\n","Epoch 19/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1576 - accuracy: 0.9972 - val_loss: 0.3095 - val_accuracy: 0.9367\n","Epoch 20/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1528 - accuracy: 0.9994 - val_loss: 0.2969 - val_accuracy: 0.9446\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1516 - accuracy: 0.9997 - val_loss: 0.3005 - val_accuracy: 0.9446\n","Epoch 22/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.1513 - accuracy: 0.9997 - val_loss: 0.2898 - val_accuracy: 0.9457\n","Epoch 23/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.1518 - accuracy: 0.9994 - val_loss: 0.2986 - val_accuracy: 0.9480\n","Epoch 24/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.1525 - accuracy: 0.9983 - val_loss: 0.3078 - val_accuracy: 0.9446\n","Epoch 25/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1537 - accuracy: 0.9980 - val_loss: 0.3146 - val_accuracy: 0.9446\n","Epoch 26/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1509 - accuracy: 0.9989 - val_loss: 0.3410 - val_accuracy: 0.9412\n","Epoch 27/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.1518 - accuracy: 0.9986 - val_loss: 0.3276 - val_accuracy: 0.9525\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1508 - accuracy: 0.9980 - val_loss: 0.3249 - val_accuracy: 0.9446\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1490 - accuracy: 0.9989 - val_loss: 0.3316 - val_accuracy: 0.9457\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1507 - accuracy: 0.9980 - val_loss: 0.3347 - val_accuracy: 0.9502\n","Epoch 31/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.1501 - accuracy: 0.9975 - val_loss: 0.3546 - val_accuracy: 0.9378\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1500 - accuracy: 0.9983 - val_loss: 0.3556 - val_accuracy: 0.9400\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1481 - accuracy: 0.9989 - val_loss: 0.3549 - val_accuracy: 0.9468\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1475 - accuracy: 0.9992 - val_loss: 0.3642 - val_accuracy: 0.9446\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1450 - accuracy: 0.9992 - val_loss: 0.3597 - val_accuracy: 0.9434\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1461 - accuracy: 0.9989 - val_loss: 0.3657 - val_accuracy: 0.9412\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1477 - accuracy: 0.9980 - val_loss: 0.3679 - val_accuracy: 0.9491\n","Epoch 38/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.1434 - accuracy: 0.9997 - val_loss: 0.3615 - val_accuracy: 0.9502\n","Epoch 39/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1446 - accuracy: 0.9992 - val_loss: 0.3593 - val_accuracy: 0.9468\n","Epoch 40/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1435 - accuracy: 0.9994 - val_loss: 0.3634 - val_accuracy: 0.9446\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1442 - accuracy: 0.9989 - val_loss: 0.3702 - val_accuracy: 0.9446\n","Epoch 42/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1434 - accuracy: 0.9997 - val_loss: 0.3863 - val_accuracy: 0.9400\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1419 - accuracy: 0.9994 - val_loss: 0.3623 - val_accuracy: 0.9367\n","Epoch 44/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1440 - accuracy: 0.9986 - val_loss: 0.3538 - val_accuracy: 0.9446\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1414 - accuracy: 0.9997 - val_loss: 0.3656 - val_accuracy: 0.9457\n","Epoch 46/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1419 - accuracy: 0.9994 - val_loss: 0.3905 - val_accuracy: 0.9367\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1455 - accuracy: 0.9977 - val_loss: 0.3815 - val_accuracy: 0.9400\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1417 - accuracy: 0.9989 - val_loss: 0.3796 - val_accuracy: 0.9344\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1435 - accuracy: 0.9977 - val_loss: 0.3705 - val_accuracy: 0.9333\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1439 - accuracy: 0.9977 - val_loss: 0.4526 - val_accuracy: 0.9253\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1451 - accuracy: 0.9963 - val_loss: 0.4226 - val_accuracy: 0.9186\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1392 - accuracy: 0.9997 - val_loss: 0.3734 - val_accuracy: 0.9423\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1364 - accuracy: 1.0000 - val_loss: 0.3664 - val_accuracy: 0.9423\n","Epoch 54/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.1373 - accuracy: 0.9997 - val_loss: 0.3913 - val_accuracy: 0.9367\n","Epoch 55/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1367 - accuracy: 0.9992 - val_loss: 0.3760 - val_accuracy: 0.9412\n","Epoch 56/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1359 - accuracy: 0.9997 - val_loss: 0.3651 - val_accuracy: 0.9412\n","Epoch 57/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1348 - accuracy: 0.9997 - val_loss: 0.3606 - val_accuracy: 0.9423\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1350 - accuracy: 0.9994 - val_loss: 0.3949 - val_accuracy: 0.9344\n","Epoch 59/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1344 - accuracy: 1.0000 - val_loss: 0.3664 - val_accuracy: 0.9412\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1337 - accuracy: 0.9997 - val_loss: 0.3646 - val_accuracy: 0.9412\n","Epoch 61/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1339 - accuracy: 0.9997 - val_loss: 0.3761 - val_accuracy: 0.9344\n","Epoch 62/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1338 - accuracy: 0.9994 - val_loss: 0.3756 - val_accuracy: 0.9367\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1342 - accuracy: 0.9994 - val_loss: 0.3753 - val_accuracy: 0.9434\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1334 - accuracy: 0.9994 - val_loss: 0.3619 - val_accuracy: 0.9412\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1342 - accuracy: 0.9989 - val_loss: 0.3682 - val_accuracy: 0.9434\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1308 - accuracy: 1.0000 - val_loss: 0.3848 - val_accuracy: 0.9367\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1317 - accuracy: 0.9992 - val_loss: 0.3641 - val_accuracy: 0.9321\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1301 - accuracy: 1.0000 - val_loss: 0.3693 - val_accuracy: 0.9367\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1306 - accuracy: 0.9994 - val_loss: 0.3920 - val_accuracy: 0.9333\n","Epoch 70/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1301 - accuracy: 0.9997 - val_loss: 0.4006 - val_accuracy: 0.9378\n","Epoch 71/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1306 - accuracy: 0.9992 - val_loss: 0.3717 - val_accuracy: 0.9389\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1292 - accuracy: 0.9994 - val_loss: 0.3714 - val_accuracy: 0.9423\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1278 - accuracy: 1.0000 - val_loss: 0.3718 - val_accuracy: 0.9434\n","Epoch 74/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1278 - accuracy: 1.0000 - val_loss: 0.3998 - val_accuracy: 0.9344\n","Epoch 75/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1273 - accuracy: 0.9994 - val_loss: 0.3599 - val_accuracy: 0.9355\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1273 - accuracy: 0.9997 - val_loss: 0.3692 - val_accuracy: 0.9389\n","Epoch 77/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1261 - accuracy: 1.0000 - val_loss: 0.3696 - val_accuracy: 0.9400\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1259 - accuracy: 1.0000 - val_loss: 0.3777 - val_accuracy: 0.9389\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1246 - accuracy: 1.0000 - val_loss: 0.3731 - val_accuracy: 0.9423\n","Epoch 80/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1249 - accuracy: 1.0000 - val_loss: 0.3928 - val_accuracy: 0.9367\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1244 - accuracy: 1.0000 - val_loss: 0.3745 - val_accuracy: 0.9389\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1242 - accuracy: 0.9994 - val_loss: 0.3850 - val_accuracy: 0.9344\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1242 - accuracy: 0.9997 - val_loss: 0.3788 - val_accuracy: 0.9378\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1256 - accuracy: 0.9989 - val_loss: 0.3822 - val_accuracy: 0.9333\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1239 - accuracy: 0.9992 - val_loss: 0.3804 - val_accuracy: 0.9378\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1233 - accuracy: 0.9997 - val_loss: 0.3826 - val_accuracy: 0.9378\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1220 - accuracy: 1.0000 - val_loss: 0.3755 - val_accuracy: 0.9400\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1207 - accuracy: 1.0000 - val_loss: 0.3748 - val_accuracy: 0.9378\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1210 - accuracy: 1.0000 - val_loss: 0.3954 - val_accuracy: 0.9355\n","Epoch 90/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1214 - accuracy: 0.9997 - val_loss: 0.3962 - val_accuracy: 0.9378\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1223 - accuracy: 0.9994 - val_loss: 0.3862 - val_accuracy: 0.9333\n","Epoch 92/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1196 - accuracy: 1.0000 - val_loss: 0.3856 - val_accuracy: 0.9276\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1188 - accuracy: 1.0000 - val_loss: 0.3878 - val_accuracy: 0.9321\n","Epoch 94/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1186 - accuracy: 1.0000 - val_loss: 0.3817 - val_accuracy: 0.9344\n","Epoch 95/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1183 - accuracy: 1.0000 - val_loss: 0.4504 - val_accuracy: 0.9242\n","Epoch 96/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1183 - accuracy: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.9321\n","Epoch 97/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1167 - accuracy: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.9321\n","Epoch 98/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1165 - accuracy: 0.9997 - val_loss: 0.3884 - val_accuracy: 0.9367\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1172 - accuracy: 0.9997 - val_loss: 0.3946 - val_accuracy: 0.9287\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1173 - accuracy: 0.9994 - val_loss: 0.3948 - val_accuracy: 0.9265\n","{'loss': [0.19204095005989075, 0.17913855612277985, 0.1714971959590912, 0.1666226089000702, 0.1655898243188858, 0.16266335546970367, 0.16288353502750397, 0.16250622272491455, 0.16254737973213196, 0.15967299044132233, 0.15817292034626007, 0.15842801332473755, 0.155711367726326, 0.1578623205423355, 0.1556219905614853, 0.15933921933174133, 0.15555620193481445, 0.15556879341602325, 0.15755385160446167, 0.15284965932369232, 0.1516265720129013, 0.15126538276672363, 0.1518038958311081, 0.15248048305511475, 0.15373986959457397, 0.15087513625621796, 0.15180644392967224, 0.15083137154579163, 0.14903709292411804, 0.1507103443145752, 0.15014216303825378, 0.1499905288219452, 0.14814038574695587, 0.14754442870616913, 0.14498452842235565, 0.14608706533908844, 0.14765310287475586, 0.14342451095581055, 0.1446254402399063, 0.14351221919059753, 0.144212543964386, 0.14338529109954834, 0.14194150269031525, 0.14402031898498535, 0.14138764142990112, 0.1418558806180954, 0.14549188315868378, 0.14166130125522614, 0.14350007474422455, 0.14391840994358063, 0.14507785439491272, 0.13920968770980835, 0.13641977310180664, 0.1373416781425476, 0.13665951788425446, 0.1359100490808487, 0.13483886420726776, 0.1350223422050476, 0.1343756467103958, 0.1336791068315506, 0.13389797508716583, 0.13378040492534637, 0.1342308074235916, 0.13341906666755676, 0.13420750200748444, 0.13075938820838928, 0.13171976804733276, 0.1300622820854187, 0.13060419261455536, 0.13009747862815857, 0.13056975603103638, 0.12920178472995758, 0.12782837450504303, 0.12782399356365204, 0.12727126479148865, 0.12734003365039825, 0.12611429393291473, 0.1259428858757019, 0.12459085136651993, 0.12488452345132828, 0.1243758574128151, 0.12424743920564651, 0.1241632029414177, 0.1255512535572052, 0.12385716289281845, 0.12325117737054825, 0.12197614461183548, 0.12070929259061813, 0.12103966623544693, 0.12142937630414963, 0.12230222672224045, 0.11958612501621246, 0.11884267628192902, 0.11856167018413544, 0.11825092881917953, 0.11834678053855896, 0.11672435700893402, 0.11654029786586761, 0.11721126735210419, 0.11727483570575714], 'accuracy': [0.9875495433807373, 0.9912280440330505, 0.9957554936408997, 0.996321439743042, 0.9968873858451843, 0.9974533319473267, 0.9977362751960754, 0.9968873858451843, 0.9971703290939331, 0.9983022212982178, 0.9985851645469666, 0.9983022212982178, 0.9985851645469666, 0.9985851645469666, 0.9988681674003601, 0.9977362751960754, 0.9988681674003601, 0.9974533319473267, 0.9971703290939331, 0.9994340538978577, 0.9997170567512512, 0.9997170567512512, 0.9994340538978577, 0.9983022212982178, 0.9980192184448242, 0.9988681674003601, 0.9985851645469666, 0.9980192184448242, 0.9988681674003601, 0.9980192184448242, 0.9974533319473267, 0.9983022212982178, 0.9988681674003601, 0.9991511106491089, 0.9991511106491089, 0.9988681674003601, 0.9980192184448242, 0.9997170567512512, 0.9991511106491089, 0.9994340538978577, 0.9988681674003601, 0.9997170567512512, 0.9994340538978577, 0.9985851645469666, 0.9997170567512512, 0.9994340538978577, 0.9977362751960754, 0.9988681674003601, 0.9977362751960754, 0.9977362751960754, 0.996321439743042, 0.9997170567512512, 1.0, 0.9997170567512512, 0.9991511106491089, 0.9997170567512512, 0.9997170567512512, 0.9994340538978577, 1.0, 0.9997170567512512, 0.9997170567512512, 0.9994340538978577, 0.9994340538978577, 0.9994340538978577, 0.9988681674003601, 1.0, 0.9991511106491089, 1.0, 0.9994340538978577, 0.9997170567512512, 0.9991511106491089, 0.9994340538978577, 1.0, 1.0, 0.9994340538978577, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9994340538978577, 0.9997170567512512, 0.9988681674003601, 0.9991511106491089, 0.9997170567512512, 1.0, 1.0, 1.0, 0.9997170567512512, 0.9994340538978577, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997170567512512, 0.9997170567512512, 0.9994340538978577], 'val_loss': [0.8937294483184814, 0.883626401424408, 0.8809019327163696, 0.8714106678962708, 0.8569085597991943, 0.8299617767333984, 0.8120520114898682, 0.7779468297958374, 0.7128815054893494, 0.6583051681518555, 0.6070569753646851, 0.5738696455955505, 0.5383628606796265, 0.45131731033325195, 0.44864243268966675, 0.406201034784317, 0.37660157680511475, 0.38128218054771423, 0.30954137444496155, 0.2968836724758148, 0.30049678683280945, 0.28980696201324463, 0.29861292243003845, 0.30775243043899536, 0.3146434426307678, 0.34100762009620667, 0.3276367783546448, 0.3248502016067505, 0.3316228985786438, 0.33473068475723267, 0.3546237647533417, 0.3556479811668396, 0.3548565208911896, 0.3642053008079529, 0.35969069600105286, 0.36573857069015503, 0.36787495017051697, 0.3614879250526428, 0.35929667949676514, 0.36337223649024963, 0.3701893389225006, 0.38634318113327026, 0.36228108406066895, 0.35377612709999084, 0.3656381666660309, 0.3905163109302521, 0.3815288245677948, 0.3796461224555969, 0.3705463707447052, 0.4525763988494873, 0.42256736755371094, 0.37342795729637146, 0.36640992760658264, 0.39125025272369385, 0.37602800130844116, 0.3650768995285034, 0.36056607961654663, 0.3948577642440796, 0.3663601279258728, 0.36460620164871216, 0.3760813772678375, 0.3755591809749603, 0.37530553340911865, 0.36188507080078125, 0.3682042360305786, 0.3848048150539398, 0.36409446597099304, 0.3692759871482849, 0.39199352264404297, 0.40062248706817627, 0.3717210292816162, 0.371420294046402, 0.37179869413375854, 0.39981165528297424, 0.3599376976490021, 0.3691607415676117, 0.3696482479572296, 0.37767165899276733, 0.37311360239982605, 0.39284583926200867, 0.374532014131546, 0.38498854637145996, 0.3787907660007477, 0.38222837448120117, 0.3803838789463043, 0.38262248039245605, 0.3754712641239166, 0.37478992342948914, 0.39536619186401367, 0.3962262272834778, 0.3862045407295227, 0.3856218159198761, 0.38781675696372986, 0.38171008229255676, 0.450437992811203, 0.3820331394672394, 0.3820497691631317, 0.3884444534778595, 0.39464902877807617, 0.3948419392108917], 'val_accuracy': [0.4954751133918762, 0.4977375566959381, 0.49886876344680786, 0.5022624731063843, 0.5090497732162476, 0.5214931964874268, 0.540723979473114, 0.5588235259056091, 0.6142534017562866, 0.6809954643249512, 0.7296379804611206, 0.7590497732162476, 0.7760180830955505, 0.8789592981338501, 0.8597285151481628, 0.8993212580680847, 0.9106335043907166, 0.9049773812294006, 0.9366515874862671, 0.9445701241493225, 0.9445701241493225, 0.9457013607025146, 0.9479637742042542, 0.9445701241493225, 0.9445701241493225, 0.9411764740943909, 0.9524886608123779, 0.9445701241493225, 0.9457013607025146, 0.9502262473106384, 0.9377828240394592, 0.9400452375411987, 0.9468325972557068, 0.9445701241493225, 0.9434388875961304, 0.9411764740943909, 0.9490950107574463, 0.9502262473106384, 0.9468325972557068, 0.9445701241493225, 0.9445701241493225, 0.9400452375411987, 0.9366515874862671, 0.9445701241493225, 0.9457013607025146, 0.9366515874862671, 0.9400452375411987, 0.9343891143798828, 0.9332579374313354, 0.9253393411636353, 0.918552041053772, 0.942307710647583, 0.942307710647583, 0.9366515874862671, 0.9411764740943909, 0.9411764740943909, 0.942307710647583, 0.9343891143798828, 0.9411764740943909, 0.9411764740943909, 0.9343891143798828, 0.9366515874862671, 0.9434388875961304, 0.9411764740943909, 0.9434388875961304, 0.9366515874862671, 0.9321267008781433, 0.9366515874862671, 0.9332579374313354, 0.9377828240394592, 0.9389140009880066, 0.942307710647583, 0.9434388875961304, 0.9343891143798828, 0.935520350933075, 0.9389140009880066, 0.9400452375411987, 0.9389140009880066, 0.942307710647583, 0.9366515874862671, 0.9389140009880066, 0.9343891143798828, 0.9377828240394592, 0.9332579374313354, 0.9377828240394592, 0.9377828240394592, 0.9400452375411987, 0.9377828240394592, 0.935520350933075, 0.9377828240394592, 0.9332579374313354, 0.9276018142700195, 0.9321267008781433, 0.9343891143798828, 0.9242081642150879, 0.9321267008781433, 0.9321267008781433, 0.9366515874862671, 0.9287330508232117, 0.9264705777168274]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 9s 58ms/step - loss: 0.1856 - accuracy: 0.9899 - val_loss: 0.9001 - val_accuracy: 0.4855\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1704 - accuracy: 0.9951 - val_loss: 0.8964 - val_accuracy: 0.4876\n","Epoch 3/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1713 - accuracy: 0.9938 - val_loss: 0.8982 - val_accuracy: 0.4886\n","Epoch 4/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1777 - accuracy: 0.9897 - val_loss: 0.8699 - val_accuracy: 0.4959\n","Epoch 5/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1762 - accuracy: 0.9925 - val_loss: 0.8881 - val_accuracy: 0.4959\n","Epoch 6/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1664 - accuracy: 0.9956 - val_loss: 0.8458 - val_accuracy: 0.5145\n","Epoch 7/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1641 - accuracy: 0.9974 - val_loss: 0.8006 - val_accuracy: 0.5393\n","Epoch 8/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1653 - accuracy: 0.9961 - val_loss: 0.8098 - val_accuracy: 0.5424\n","Epoch 9/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1643 - accuracy: 0.9948 - val_loss: 0.7320 - val_accuracy: 0.6085\n","Epoch 10/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1612 - accuracy: 0.9974 - val_loss: 0.6602 - val_accuracy: 0.6715\n","Epoch 11/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1615 - accuracy: 0.9974 - val_loss: 0.6385 - val_accuracy: 0.6994\n","Epoch 12/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1619 - accuracy: 0.9966 - val_loss: 0.6048 - val_accuracy: 0.7314\n","Epoch 13/100\n","31/31 [==============================] - 1s 37ms/step - loss: 0.1595 - accuracy: 0.9979 - val_loss: 0.5099 - val_accuracy: 0.8161\n","Epoch 14/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1589 - accuracy: 0.9987 - val_loss: 0.4467 - val_accuracy: 0.8688\n","Epoch 15/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1568 - accuracy: 0.9984 - val_loss: 0.4238 - val_accuracy: 0.8853\n","Epoch 16/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.1612 - accuracy: 0.9956 - val_loss: 0.3318 - val_accuracy: 0.9318\n","Epoch 17/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1601 - accuracy: 0.9972 - val_loss: 0.3399 - val_accuracy: 0.9246\n","Epoch 18/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1589 - accuracy: 0.9977 - val_loss: 0.3599 - val_accuracy: 0.9194\n","Epoch 19/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1579 - accuracy: 0.9977 - val_loss: 0.3492 - val_accuracy: 0.9194\n","Epoch 20/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1568 - accuracy: 0.9974 - val_loss: 0.3528 - val_accuracy: 0.9287\n","Epoch 21/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.1558 - accuracy: 0.9982 - val_loss: 0.3332 - val_accuracy: 0.9360\n","Epoch 22/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1548 - accuracy: 0.9987 - val_loss: 0.3504 - val_accuracy: 0.9308\n","Epoch 23/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.1644 - accuracy: 0.9943 - val_loss: 0.3347 - val_accuracy: 0.9411\n","Epoch 24/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1550 - accuracy: 0.9982 - val_loss: 0.3591 - val_accuracy: 0.9349\n","Epoch 25/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1511 - accuracy: 0.9995 - val_loss: 0.3569 - val_accuracy: 0.9329\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1554 - accuracy: 0.9966 - val_loss: 0.3810 - val_accuracy: 0.9349\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1551 - accuracy: 0.9969 - val_loss: 0.3708 - val_accuracy: 0.9370\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1499 - accuracy: 0.9997 - val_loss: 0.3745 - val_accuracy: 0.9360\n","Epoch 29/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.1518 - accuracy: 0.9987 - val_loss: 0.3925 - val_accuracy: 0.9370\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1511 - accuracy: 0.9984 - val_loss: 0.3941 - val_accuracy: 0.9329\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1512 - accuracy: 0.9990 - val_loss: 0.3804 - val_accuracy: 0.9390\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1483 - accuracy: 0.9997 - val_loss: 0.3913 - val_accuracy: 0.9339\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1493 - accuracy: 0.9979 - val_loss: 0.3868 - val_accuracy: 0.9370\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1560 - accuracy: 0.9961 - val_loss: 0.4397 - val_accuracy: 0.9225\n","Epoch 35/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.1504 - accuracy: 0.9990 - val_loss: 0.3986 - val_accuracy: 0.9339\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1507 - accuracy: 0.9982 - val_loss: 0.4104 - val_accuracy: 0.9349\n","Epoch 37/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.1506 - accuracy: 0.9979 - val_loss: 0.4411 - val_accuracy: 0.9184\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1523 - accuracy: 0.9964 - val_loss: 0.4446 - val_accuracy: 0.9267\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1507 - accuracy: 0.9969 - val_loss: 0.4024 - val_accuracy: 0.9318\n","Epoch 40/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1512 - accuracy: 0.9972 - val_loss: 0.3970 - val_accuracy: 0.9421\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1468 - accuracy: 0.9979 - val_loss: 0.3875 - val_accuracy: 0.9360\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1485 - accuracy: 0.9977 - val_loss: 0.3797 - val_accuracy: 0.9390\n","Epoch 43/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.1462 - accuracy: 0.9990 - val_loss: 0.3855 - val_accuracy: 0.9349\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1444 - accuracy: 0.9990 - val_loss: 0.3998 - val_accuracy: 0.9360\n","Epoch 45/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1436 - accuracy: 0.9995 - val_loss: 0.4135 - val_accuracy: 0.9349\n","Epoch 46/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1476 - accuracy: 0.9982 - val_loss: 0.3915 - val_accuracy: 0.9298\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1481 - accuracy: 0.9966 - val_loss: 0.3962 - val_accuracy: 0.9360\n","Epoch 48/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1424 - accuracy: 0.9997 - val_loss: 0.3932 - val_accuracy: 0.9329\n","Epoch 49/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.1425 - accuracy: 0.9997 - val_loss: 0.3951 - val_accuracy: 0.9360\n","Epoch 50/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1408 - accuracy: 0.9995 - val_loss: 0.3910 - val_accuracy: 0.9349\n","Epoch 51/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1410 - accuracy: 0.9997 - val_loss: 0.3873 - val_accuracy: 0.9370\n","Epoch 52/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1439 - accuracy: 0.9982 - val_loss: 0.4128 - val_accuracy: 0.9298\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1413 - accuracy: 0.9992 - val_loss: 0.4352 - val_accuracy: 0.9267\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1414 - accuracy: 0.9990 - val_loss: 0.3888 - val_accuracy: 0.9318\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1419 - accuracy: 0.9979 - val_loss: 0.4055 - val_accuracy: 0.9318\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1396 - accuracy: 0.9990 - val_loss: 0.4331 - val_accuracy: 0.9205\n","Epoch 57/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1662 - accuracy: 0.9886 - val_loss: 0.4051 - val_accuracy: 0.9308\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1417 - accuracy: 0.9979 - val_loss: 0.4078 - val_accuracy: 0.9287\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1393 - accuracy: 0.9995 - val_loss: 0.3973 - val_accuracy: 0.9256\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1376 - accuracy: 0.9997 - val_loss: 0.4092 - val_accuracy: 0.9256\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1396 - accuracy: 0.9992 - val_loss: 0.4020 - val_accuracy: 0.9298\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1380 - accuracy: 0.9995 - val_loss: 0.4011 - val_accuracy: 0.9349\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1421 - accuracy: 0.9972 - val_loss: 0.4551 - val_accuracy: 0.9112\n","Epoch 64/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1419 - accuracy: 0.9972 - val_loss: 0.3941 - val_accuracy: 0.9277\n","Epoch 65/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.1352 - accuracy: 1.0000 - val_loss: 0.4066 - val_accuracy: 0.9298\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1357 - accuracy: 1.0000 - val_loss: 0.4189 - val_accuracy: 0.9298\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1350 - accuracy: 0.9995 - val_loss: 0.4001 - val_accuracy: 0.9277\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1341 - accuracy: 1.0000 - val_loss: 0.3964 - val_accuracy: 0.9277\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1357 - accuracy: 0.9984 - val_loss: 0.3993 - val_accuracy: 0.9287\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1338 - accuracy: 0.9997 - val_loss: 0.4236 - val_accuracy: 0.9360\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1350 - accuracy: 0.9987 - val_loss: 0.4195 - val_accuracy: 0.9329\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1344 - accuracy: 0.9990 - val_loss: 0.4069 - val_accuracy: 0.9256\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1342 - accuracy: 0.9992 - val_loss: 0.4100 - val_accuracy: 0.9318\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1329 - accuracy: 0.9990 - val_loss: 0.3956 - val_accuracy: 0.9318\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1315 - accuracy: 1.0000 - val_loss: 0.4106 - val_accuracy: 0.9308\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1318 - accuracy: 0.9995 - val_loss: 0.3985 - val_accuracy: 0.9298\n","Epoch 77/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1307 - accuracy: 1.0000 - val_loss: 0.4029 - val_accuracy: 0.9287\n","Epoch 78/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1301 - accuracy: 1.0000 - val_loss: 0.4071 - val_accuracy: 0.9308\n","Epoch 79/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1302 - accuracy: 0.9997 - val_loss: 0.4057 - val_accuracy: 0.9298\n","Epoch 80/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1302 - accuracy: 0.9997 - val_loss: 0.4065 - val_accuracy: 0.9267\n","Epoch 81/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1300 - accuracy: 0.9992 - val_loss: 0.4299 - val_accuracy: 0.9277\n","Epoch 82/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.1314 - accuracy: 0.9990 - val_loss: 0.4058 - val_accuracy: 0.9287\n","Epoch 83/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1298 - accuracy: 0.9997 - val_loss: 0.4321 - val_accuracy: 0.9267\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1296 - accuracy: 0.9984 - val_loss: 0.4737 - val_accuracy: 0.9256\n","Epoch 85/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1383 - accuracy: 0.9948 - val_loss: 0.4325 - val_accuracy: 0.9101\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1297 - accuracy: 0.9992 - val_loss: 0.3869 - val_accuracy: 0.9318\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1283 - accuracy: 0.9992 - val_loss: 0.4081 - val_accuracy: 0.9329\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1273 - accuracy: 0.9995 - val_loss: 0.4009 - val_accuracy: 0.9298\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1269 - accuracy: 0.9997 - val_loss: 0.4094 - val_accuracy: 0.9329\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1267 - accuracy: 0.9992 - val_loss: 0.4212 - val_accuracy: 0.9267\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1295 - accuracy: 0.9979 - val_loss: 0.4020 - val_accuracy: 0.9318\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1292 - accuracy: 0.9990 - val_loss: 0.4065 - val_accuracy: 0.9287\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1269 - accuracy: 0.9997 - val_loss: 0.4177 - val_accuracy: 0.9236\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1248 - accuracy: 0.9995 - val_loss: 0.4206 - val_accuracy: 0.9236\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1263 - accuracy: 0.9990 - val_loss: 0.4110 - val_accuracy: 0.9256\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1252 - accuracy: 0.9995 - val_loss: 0.4263 - val_accuracy: 0.9184\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1236 - accuracy: 0.9997 - val_loss: 0.4242 - val_accuracy: 0.9318\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1262 - accuracy: 0.9987 - val_loss: 0.4054 - val_accuracy: 0.9256\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1238 - accuracy: 0.9997 - val_loss: 0.3973 - val_accuracy: 0.9246\n","Epoch 100/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.1227 - accuracy: 0.9997 - val_loss: 0.4049 - val_accuracy: 0.9287\n","{'loss': [0.18558357656002045, 0.17035432159900665, 0.17132721841335297, 0.1776529848575592, 0.17622531950473785, 0.16644150018692017, 0.16408762335777283, 0.16532132029533386, 0.16427211463451385, 0.16120928525924683, 0.16150733828544617, 0.16189351677894592, 0.15952332317829132, 0.15886543691158295, 0.156789630651474, 0.1612427830696106, 0.1601269245147705, 0.1589004099369049, 0.15794770419597626, 0.1568322628736496, 0.15579353272914886, 0.15481774508953094, 0.16437646746635437, 0.1549830138683319, 0.15109653770923615, 0.15542671084403992, 0.15507884323596954, 0.14985014498233795, 0.15176816284656525, 0.15109378099441528, 0.15117132663726807, 0.14831919968128204, 0.14927637577056885, 0.15595267713069916, 0.1504167765378952, 0.15065719187259674, 0.15059009194374084, 0.15230922400951385, 0.15070168673992157, 0.15116403996944427, 0.14676152169704437, 0.14852173626422882, 0.14622777700424194, 0.14435671269893646, 0.14360164105892181, 0.14755602180957794, 0.14809361100196838, 0.1424422264099121, 0.14246083796024323, 0.14075510203838348, 0.14098289608955383, 0.1438852846622467, 0.14132210612297058, 0.14142416417598724, 0.14185401797294617, 0.13956230878829956, 0.16616611182689667, 0.14168083667755127, 0.1392522156238556, 0.1375914067029953, 0.13963304460048676, 0.1379806250333786, 0.142123281955719, 0.14185263216495514, 0.13516472280025482, 0.13567282259464264, 0.13501669466495514, 0.13405582308769226, 0.1356615275144577, 0.1337781846523285, 0.13504405319690704, 0.13444802165031433, 0.13423843681812286, 0.13291150331497192, 0.13146133720874786, 0.13176561892032623, 0.13067743182182312, 0.13014067709445953, 0.1302441954612732, 0.13018585741519928, 0.12996701896190643, 0.131398543715477, 0.1297965943813324, 0.12961892783641815, 0.13833272457122803, 0.12965695559978485, 0.12829901278018951, 0.12731020152568817, 0.1269182562828064, 0.12666670978069305, 0.12945906817913055, 0.12922711670398712, 0.1269126832485199, 0.12483079731464386, 0.12632650136947632, 0.12524636089801788, 0.12363234162330627, 0.12620480358600616, 0.12383817136287689, 0.12268608808517456], 'accuracy': [0.9899224638938904, 0.9950904250144958, 0.9937984347343445, 0.9896640777587891, 0.9925064444541931, 0.9956072568893433, 0.9974160194396973, 0.9961240291595459, 0.9948320388793945, 0.9974160194396973, 0.9974160194396973, 0.9966408014297485, 0.9979327917098999, 0.9987080097198486, 0.9984496235847473, 0.9956072568893433, 0.997157633304596, 0.9976744055747986, 0.9976744055747986, 0.9974160194396973, 0.998191237449646, 0.9987080097198486, 0.9943152666091919, 0.998191237449646, 0.9994832277297974, 0.9966408014297485, 0.9968992471694946, 0.9997416138648987, 0.9987080097198486, 0.9984496235847473, 0.99896639585495, 0.9997416138648987, 0.9979327917098999, 0.9961240291595459, 0.99896639585495, 0.998191237449646, 0.9979327917098999, 0.9963824152946472, 0.9968992471694946, 0.997157633304596, 0.9979327917098999, 0.9976744055747986, 0.99896639585495, 0.99896639585495, 0.9994832277297974, 0.998191237449646, 0.9966408014297485, 0.9997416138648987, 0.9997416138648987, 0.9994832277297974, 0.9997416138648987, 0.998191237449646, 0.9992247819900513, 0.99896639585495, 0.9979327917098999, 0.99896639585495, 0.988630473613739, 0.9979327917098999, 0.9994832277297974, 0.9997416138648987, 0.9992247819900513, 0.9994832277297974, 0.997157633304596, 0.997157633304596, 1.0, 1.0, 0.9994832277297974, 1.0, 0.9984496235847473, 0.9997416138648987, 0.9987080097198486, 0.99896639585495, 0.9992247819900513, 0.99896639585495, 1.0, 0.9994832277297974, 1.0, 1.0, 0.9997416138648987, 0.9997416138648987, 0.9992247819900513, 0.99896639585495, 0.9997416138648987, 0.9984496235847473, 0.9948320388793945, 0.9992247819900513, 0.9992247819900513, 0.9994832277297974, 0.9997416138648987, 0.9992247819900513, 0.9979327917098999, 0.99896639585495, 0.9997416138648987, 0.9994832277297974, 0.99896639585495, 0.9994832277297974, 0.9997416138648987, 0.9987080097198486, 0.9997416138648987, 0.9997416138648987], 'val_loss': [0.9000720381736755, 0.8964102864265442, 0.8981853723526001, 0.8699265122413635, 0.888146698474884, 0.8458201885223389, 0.800561785697937, 0.8097603917121887, 0.7320208549499512, 0.6602457165718079, 0.638485848903656, 0.6048046350479126, 0.5099155306816101, 0.44665688276290894, 0.42378297448158264, 0.33176279067993164, 0.3398841619491577, 0.3598519265651703, 0.34921538829803467, 0.3528444766998291, 0.3331696391105652, 0.3503819704055786, 0.3346883952617645, 0.3591005206108093, 0.3568647503852844, 0.38103991746902466, 0.3708449602127075, 0.37446215748786926, 0.39253026247024536, 0.3941033184528351, 0.3804033696651459, 0.39127662777900696, 0.3868313729763031, 0.43973758816719055, 0.39860931038856506, 0.4104021489620209, 0.44106316566467285, 0.444640576839447, 0.40237879753112793, 0.3970038890838623, 0.3874692916870117, 0.37967002391815186, 0.3855215013027191, 0.3997921943664551, 0.4135076403617859, 0.39151108264923096, 0.39620688557624817, 0.39315739274024963, 0.39505735039711, 0.3909684717655182, 0.3872935175895691, 0.41284075379371643, 0.43519046902656555, 0.38878294825553894, 0.4055437445640564, 0.4331141412258148, 0.40513235330581665, 0.40784215927124023, 0.3973224461078644, 0.40920349955558777, 0.40199726819992065, 0.4011228680610657, 0.45510557293891907, 0.3941463530063629, 0.40655097365379333, 0.41893380880355835, 0.4001094698905945, 0.39639633893966675, 0.39931464195251465, 0.4235955774784088, 0.4194699823856354, 0.4068507254123688, 0.40995121002197266, 0.3955759108066559, 0.4106355905532837, 0.39853957295417786, 0.40292516350746155, 0.40707674622535706, 0.4056992828845978, 0.40650179982185364, 0.42992791533470154, 0.4058479368686676, 0.43212950229644775, 0.4737372100353241, 0.43254798650741577, 0.38694828748703003, 0.40809911489486694, 0.40089237689971924, 0.4093768298625946, 0.4212082624435425, 0.4020357131958008, 0.4065321087837219, 0.4177083969116211, 0.4205630421638489, 0.41099250316619873, 0.4262884557247162, 0.4242390990257263, 0.4054480195045471, 0.397306352853775, 0.40492957830429077], 'val_accuracy': [0.48553720116615295, 0.4876033067703247, 0.4886363744735718, 0.4958677589893341, 0.4958677589893341, 0.5144628286361694, 0.53925621509552, 0.5423553586006165, 0.6084710955619812, 0.6714876294136047, 0.6993801593780518, 0.7314049601554871, 0.81611567735672, 0.8688016533851624, 0.8853305578231812, 0.9318181872367859, 0.9245867729187012, 0.9194214940071106, 0.9194214940071106, 0.9287189841270447, 0.9359503984451294, 0.9307851195335388, 0.94111567735672, 0.9349173307418823, 0.932851254940033, 0.9349173307418823, 0.9369834661483765, 0.9359503984451294, 0.9369834661483765, 0.932851254940033, 0.9390496015548706, 0.93388432264328, 0.9369834661483765, 0.922520637512207, 0.93388432264328, 0.9349173307418823, 0.9183884263038635, 0.9266529083251953, 0.9318181872367859, 0.942148745059967, 0.9359503984451294, 0.9390496015548706, 0.9349173307418823, 0.9359503984451294, 0.9349173307418823, 0.9297520518302917, 0.9359503984451294, 0.932851254940033, 0.9359503984451294, 0.9349173307418823, 0.9369834661483765, 0.9297520518302917, 0.9266529083251953, 0.9318181872367859, 0.9318181872367859, 0.9204545617103577, 0.9307851195335388, 0.9287189841270447, 0.9256198406219482, 0.9256198406219482, 0.9297520518302917, 0.9349173307418823, 0.9111570119857788, 0.9276859760284424, 0.9297520518302917, 0.9297520518302917, 0.9276859760284424, 0.9276859760284424, 0.9287189841270447, 0.9359503984451294, 0.932851254940033, 0.9256198406219482, 0.9318181872367859, 0.9318181872367859, 0.9307851195335388, 0.9297520518302917, 0.9287189841270447, 0.9307851195335388, 0.9297520518302917, 0.9266529083251953, 0.9276859760284424, 0.9287189841270447, 0.9266529083251953, 0.9256198406219482, 0.9101239442825317, 0.9318181872367859, 0.932851254940033, 0.9297520518302917, 0.932851254940033, 0.9266529083251953, 0.9318181872367859, 0.9287189841270447, 0.9235537052154541, 0.9235537052154541, 0.9256198406219482, 0.9183884263038635, 0.9318181872367859, 0.9256198406219482, 0.9245867729187012, 0.9287189841270447]}\n","32/32 [==============================] - 1s 4ms/step\n"]}]},{"cell_type":"code","source":["metrics_df_gru"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"id":"3971cOiW9Sjj","executionInfo":{"status":"ok","timestamp":1717401201226,"user_tz":-360,"elapsed":47,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}},"outputId":"c5418ff1-806a-4bd5-c7d3-4d9c00a52e42"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision    Recall        F1  Sensitivity  Specificity  \\\n","0        0  0.764657   0.759868  0.773869  0.766805     0.773869     0.755444   \n","1        1  0.805085   0.793478  0.824859  0.808864     0.824859     0.785311   \n","2        2  0.736948   0.733202  0.744980  0.739044     0.744980     0.728916   \n","3        0  0.813233   0.773392  0.886097  0.825917     0.886097     0.740369   \n","4        1  0.831215   0.798726  0.885593  0.839920     0.885593     0.776836   \n","5        2  0.816265   0.798861  0.845382  0.821463     0.845382     0.787149   \n","6        0  0.866834   0.852090  0.887772  0.869565     0.887772     0.845896   \n","7        1  0.888418   0.900875  0.872881  0.886657     0.872881     0.903955   \n","8        2  0.869478   0.845865  0.903614  0.873786     0.903614     0.835341   \n","9        0  0.892797   0.866980  0.927973  0.896440     0.927973     0.857621   \n","10       1  0.906780   0.876963  0.946328  0.910326     0.946328     0.867232   \n","11       2  0.902610   0.880455  0.931727  0.905366     0.931727     0.873494   \n","12       0  0.902848   0.874028  0.941374  0.906452     0.941374     0.864322   \n","13       1  0.930085   0.908725  0.956215  0.931865     0.956215     0.903955   \n","14       2  0.917671   0.904669  0.933735  0.918972     0.933735     0.901606   \n","\n","       Kappa  \n","0   0.529313  \n","1   0.610169  \n","2   0.473896  \n","3   0.626466  \n","4   0.662429  \n","5   0.632530  \n","6   0.733668  \n","7   0.776836  \n","8   0.738956  \n","9   0.785595  \n","10  0.813559  \n","11  0.805221  \n","12  0.805695  \n","13  0.860169  \n","14  0.835341  "],"text/html":["\n","  <div id=\"df-cf63c711-8adc-4914-9110-35505f9c6bd1\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.764657</td>\n","      <td>0.759868</td>\n","      <td>0.773869</td>\n","      <td>0.766805</td>\n","      <td>0.773869</td>\n","      <td>0.755444</td>\n","      <td>0.529313</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.805085</td>\n","      <td>0.793478</td>\n","      <td>0.824859</td>\n","      <td>0.808864</td>\n","      <td>0.824859</td>\n","      <td>0.785311</td>\n","      <td>0.610169</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.736948</td>\n","      <td>0.733202</td>\n","      <td>0.744980</td>\n","      <td>0.739044</td>\n","      <td>0.744980</td>\n","      <td>0.728916</td>\n","      <td>0.473896</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.813233</td>\n","      <td>0.773392</td>\n","      <td>0.886097</td>\n","      <td>0.825917</td>\n","      <td>0.886097</td>\n","      <td>0.740369</td>\n","      <td>0.626466</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.831215</td>\n","      <td>0.798726</td>\n","      <td>0.885593</td>\n","      <td>0.839920</td>\n","      <td>0.885593</td>\n","      <td>0.776836</td>\n","      <td>0.662429</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.816265</td>\n","      <td>0.798861</td>\n","      <td>0.845382</td>\n","      <td>0.821463</td>\n","      <td>0.845382</td>\n","      <td>0.787149</td>\n","      <td>0.632530</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.866834</td>\n","      <td>0.852090</td>\n","      <td>0.887772</td>\n","      <td>0.869565</td>\n","      <td>0.887772</td>\n","      <td>0.845896</td>\n","      <td>0.733668</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.888418</td>\n","      <td>0.900875</td>\n","      <td>0.872881</td>\n","      <td>0.886657</td>\n","      <td>0.872881</td>\n","      <td>0.903955</td>\n","      <td>0.776836</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.869478</td>\n","      <td>0.845865</td>\n","      <td>0.903614</td>\n","      <td>0.873786</td>\n","      <td>0.903614</td>\n","      <td>0.835341</td>\n","      <td>0.738956</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.892797</td>\n","      <td>0.866980</td>\n","      <td>0.927973</td>\n","      <td>0.896440</td>\n","      <td>0.927973</td>\n","      <td>0.857621</td>\n","      <td>0.785595</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.906780</td>\n","      <td>0.876963</td>\n","      <td>0.946328</td>\n","      <td>0.910326</td>\n","      <td>0.946328</td>\n","      <td>0.867232</td>\n","      <td>0.813559</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.902610</td>\n","      <td>0.880455</td>\n","      <td>0.931727</td>\n","      <td>0.905366</td>\n","      <td>0.931727</td>\n","      <td>0.873494</td>\n","      <td>0.805221</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.902848</td>\n","      <td>0.874028</td>\n","      <td>0.941374</td>\n","      <td>0.906452</td>\n","      <td>0.941374</td>\n","      <td>0.864322</td>\n","      <td>0.805695</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.930085</td>\n","      <td>0.908725</td>\n","      <td>0.956215</td>\n","      <td>0.931865</td>\n","      <td>0.956215</td>\n","      <td>0.903955</td>\n","      <td>0.860169</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.917671</td>\n","      <td>0.904669</td>\n","      <td>0.933735</td>\n","      <td>0.918972</td>\n","      <td>0.933735</td>\n","      <td>0.901606</td>\n","      <td>0.835341</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf63c711-8adc-4914-9110-35505f9c6bd1')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-cf63c711-8adc-4914-9110-35505f9c6bd1 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-cf63c711-8adc-4914-9110-35505f9c6bd1');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-cca758a9-5cf0-4d7d-a6e5-5383eb89190c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cca758a9-5cf0-4d7d-a6e5-5383eb89190c')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-cca758a9-5cf0-4d7d-a6e5-5383eb89190c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"metrics_df_gru","summary":"{\n  \"name\": \"metrics_df_gru\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05859767829583839,\n        \"min\": 0.7369477911646586,\n        \"max\": 0.9300847457627118,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.8927973199329984,\n          0.9026104417670683,\n          0.7646566164154104\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05696899582797963,\n        \"min\": 0.733201581027668,\n        \"max\": 0.9087248322147651,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.86697965571205,\n          0.8804554079696395,\n          0.7598684210526315\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06327380309246154,\n        \"min\": 0.7449799196787149,\n        \"max\": 0.9562146892655368,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.9279731993299832,\n          0.9317269076305221,\n          0.7738693467336684\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05775023583076327,\n        \"min\": 0.7390438247011953,\n        \"max\": 0.9318651066758431,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.8964401294498382,\n          0.9053658536585367,\n          0.7668049792531121\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06327380309246154,\n        \"min\": 0.7449799196787149,\n        \"max\": 0.9562146892655368,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.9279731993299832,\n          0.9317269076305221,\n          0.7738693467336684\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06094639161222956,\n        \"min\": 0.7289156626506024,\n        \"max\": 0.903954802259887,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.8576214405360134,\n          0.8734939759036144,\n          0.7554438860971524\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11719535659167676,\n        \"min\": 0.4738955823293173,\n        \"max\": 0.8601694915254238,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7855946398659966,\n          0.8052208835341366,\n          0.5293132328308208\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["metrics_df_gru.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Frequency Domain/GRU/frequency_gru.csv', index = False)"],"metadata":{"id":"hCzdCYtQ9WNN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BqrJXveF-S1q"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}