{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Mbfw8uvdftFM","executionInfo":{"status":"ok","timestamp":1717431125103,"user_tz":-360,"elapsed":1796,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sb"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"INiFJfLjgOkx","executionInfo":{"status":"ok","timestamp":1717431125957,"user_tz":-360,"elapsed":861,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"outputs":[],"source":["from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"lYo2Uq77gQSH","executionInfo":{"status":"ok","timestamp":1717431129554,"user_tz":-360,"elapsed":3601,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import ExtraTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score, cross_val_predict"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"g66575_xgVzz","executionInfo":{"status":"ok","timestamp":1717431133544,"user_tz":-360,"elapsed":3999,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPool1D, Flatten, Dropout,LSTM"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27800,"status":"ok","timestamp":1717431161337,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"},"user_tz":-360},"id":"MOCNWlamfr3v","outputId":"c3613b77-a274-45d1-814e-97f0a838ccca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"iNy9eOGMf2qO","executionInfo":{"status":"ok","timestamp":1717431161338,"user_tz":-360,"elapsed":8,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"outputs":[],"source":["# Raw_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/only data/raw_data.npz'\n","\n","Theta_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/feature domain/Theta_frequency.npz'\n","\n","\n","\n","# RAW = np.load(Raw_data, allow_pickle=True)  # Allow loading pickled object arrays\n","# X = RAW['X'].astype('float64')\n","# Y = RAW['Y'].astype('float64')\n","# group = RAW['Group'].astype('float64')"]},{"cell_type":"markdown","metadata":{"id":"PzeABzSyHgKg"},"source":["This is a good performing model"]},{"cell_type":"markdown","metadata":{"id":"6DhAYwXUSE9z"},"source":["# CNN-LSTM"]},{"cell_type":"code","source":["%%capture\n","!pip install tensorflow_addons"],"metadata":{"id":"Gr-BOSTD4lPe","executionInfo":{"status":"ok","timestamp":1717431339040,"user_tz":-360,"elapsed":10839,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"id":"VvjC2xCQNHLP","executionInfo":{"status":"ok","timestamp":1717431339859,"user_tz":-360,"elapsed":830,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bcfe90dc-3563-4bf0-ff5d-9b73fb9fa955"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(LSTM(256, return_sequences=True))\n","    model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dense(32, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_callback = ModelCheckpoint(\n","                f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Theta/CNN_LSTM/best_model_{run_name}.h5',\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Theta/CNN_LSTM/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Evaluate client model\n","            y_pred = (client_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVURUnmYNNNg","outputId":"e1e73115-3ab4-457a-87ff-d81f99a53220","executionInfo":{"status":"ok","timestamp":1717432519473,"user_tz":-360,"elapsed":1179621,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5036"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 26s 110ms/step - loss: 0.6932 - accuracy: 0.5092 - val_loss: 0.6931 - val_accuracy: 0.5151\n","Epoch 2/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.6930 - accuracy: 0.5781 - val_loss: 0.6931 - val_accuracy: 0.5172\n","Epoch 3/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.6927 - accuracy: 0.5717 - val_loss: 0.6931 - val_accuracy: 0.5216\n","Epoch 4/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6923 - accuracy: 0.5792 - val_loss: 0.6930 - val_accuracy: 0.5216\n","Epoch 5/100\n","29/29 [==============================] - 1s 36ms/step - loss: 0.6916 - accuracy: 0.5768 - val_loss: 0.6929 - val_accuracy: 0.5302\n","Epoch 6/100\n","29/29 [==============================] - 1s 49ms/step - loss: 0.6906 - accuracy: 0.5752 - val_loss: 0.6927 - val_accuracy: 0.5420\n","Epoch 7/100\n","29/29 [==============================] - 2s 57ms/step - loss: 0.6890 - accuracy: 0.5738 - val_loss: 0.6923 - val_accuracy: 0.5571\n","Epoch 8/100\n","29/29 [==============================] - 1s 51ms/step - loss: 0.6869 - accuracy: 0.5757 - val_loss: 0.6917 - val_accuracy: 0.5647\n","Epoch 9/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.6847 - accuracy: 0.5752 - val_loss: 0.6909 - val_accuracy: 0.5625\n","Epoch 10/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.6831 - accuracy: 0.5741 - val_loss: 0.6900 - val_accuracy: 0.5668\n","Epoch 11/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.6819 - accuracy: 0.5770 - val_loss: 0.6891 - val_accuracy: 0.5690\n","Epoch 12/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6812 - accuracy: 0.5770 - val_loss: 0.6882 - val_accuracy: 0.5679\n","Epoch 13/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6802 - accuracy: 0.5827 - val_loss: 0.6874 - val_accuracy: 0.5700\n","Epoch 14/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6795 - accuracy: 0.5795 - val_loss: 0.6865 - val_accuracy: 0.5744\n","Epoch 15/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6783 - accuracy: 0.5865 - val_loss: 0.6852 - val_accuracy: 0.5722\n","Epoch 16/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6779 - accuracy: 0.5889 - val_loss: 0.6838 - val_accuracy: 0.5722\n","Epoch 17/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6762 - accuracy: 0.5884 - val_loss: 0.6824 - val_accuracy: 0.5733\n","Epoch 18/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6747 - accuracy: 0.5940 - val_loss: 0.6809 - val_accuracy: 0.5744\n","Epoch 19/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6731 - accuracy: 0.6005 - val_loss: 0.6794 - val_accuracy: 0.5711\n","Epoch 20/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6710 - accuracy: 0.6032 - val_loss: 0.6768 - val_accuracy: 0.5668\n","Epoch 21/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6692 - accuracy: 0.6005 - val_loss: 0.6752 - val_accuracy: 0.5722\n","Epoch 22/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6659 - accuracy: 0.6067 - val_loss: 0.6726 - val_accuracy: 0.5819\n","Epoch 23/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6633 - accuracy: 0.6107 - val_loss: 0.6706 - val_accuracy: 0.5862\n","Epoch 24/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6608 - accuracy: 0.6131 - val_loss: 0.6686 - val_accuracy: 0.5938\n","Epoch 25/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6581 - accuracy: 0.6142 - val_loss: 0.6668 - val_accuracy: 0.5991\n","Epoch 26/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6562 - accuracy: 0.6148 - val_loss: 0.6680 - val_accuracy: 0.5819\n","Epoch 27/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6559 - accuracy: 0.6158 - val_loss: 0.6650 - val_accuracy: 0.5894\n","Epoch 28/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6547 - accuracy: 0.6175 - val_loss: 0.6648 - val_accuracy: 0.5873\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6533 - accuracy: 0.6258 - val_loss: 0.6650 - val_accuracy: 0.5873\n","Epoch 30/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6517 - accuracy: 0.6255 - val_loss: 0.6641 - val_accuracy: 0.5884\n","Epoch 31/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6511 - accuracy: 0.6258 - val_loss: 0.6628 - val_accuracy: 0.5927\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6503 - accuracy: 0.6261 - val_loss: 0.6643 - val_accuracy: 0.5884\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6474 - accuracy: 0.6269 - val_loss: 0.6638 - val_accuracy: 0.5927\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6481 - accuracy: 0.6298 - val_loss: 0.6670 - val_accuracy: 0.5959\n","Epoch 35/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6466 - accuracy: 0.6261 - val_loss: 0.6619 - val_accuracy: 0.6002\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6454 - accuracy: 0.6304 - val_loss: 0.6643 - val_accuracy: 0.5959\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6459 - accuracy: 0.6293 - val_loss: 0.6638 - val_accuracy: 0.5970\n","Epoch 38/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6448 - accuracy: 0.6290 - val_loss: 0.6628 - val_accuracy: 0.5991\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6447 - accuracy: 0.6328 - val_loss: 0.6623 - val_accuracy: 0.5970\n","Epoch 40/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6433 - accuracy: 0.6320 - val_loss: 0.6646 - val_accuracy: 0.6002\n","Epoch 41/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6441 - accuracy: 0.6395 - val_loss: 0.6624 - val_accuracy: 0.6034\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6416 - accuracy: 0.6347 - val_loss: 0.6638 - val_accuracy: 0.5991\n","Epoch 43/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6404 - accuracy: 0.6390 - val_loss: 0.6615 - val_accuracy: 0.6056\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6409 - accuracy: 0.6363 - val_loss: 0.6619 - val_accuracy: 0.6056\n","Epoch 45/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6403 - accuracy: 0.6390 - val_loss: 0.6616 - val_accuracy: 0.6067\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6403 - accuracy: 0.6385 - val_loss: 0.6648 - val_accuracy: 0.6024\n","Epoch 47/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6391 - accuracy: 0.6417 - val_loss: 0.6615 - val_accuracy: 0.6088\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6377 - accuracy: 0.6398 - val_loss: 0.6637 - val_accuracy: 0.6013\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6372 - accuracy: 0.6420 - val_loss: 0.6623 - val_accuracy: 0.6078\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6361 - accuracy: 0.6452 - val_loss: 0.6615 - val_accuracy: 0.6067\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6363 - accuracy: 0.6371 - val_loss: 0.6627 - val_accuracy: 0.5981\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6346 - accuracy: 0.6436 - val_loss: 0.6613 - val_accuracy: 0.6045\n","Epoch 53/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6353 - accuracy: 0.6404 - val_loss: 0.6620 - val_accuracy: 0.6099\n","Epoch 54/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6333 - accuracy: 0.6466 - val_loss: 0.6598 - val_accuracy: 0.6142\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6337 - accuracy: 0.6441 - val_loss: 0.6620 - val_accuracy: 0.6088\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6313 - accuracy: 0.6479 - val_loss: 0.6615 - val_accuracy: 0.6142\n","Epoch 57/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6322 - accuracy: 0.6457 - val_loss: 0.6618 - val_accuracy: 0.6110\n","Epoch 58/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6317 - accuracy: 0.6463 - val_loss: 0.6598 - val_accuracy: 0.6142\n","Epoch 59/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6317 - accuracy: 0.6492 - val_loss: 0.6597 - val_accuracy: 0.6121\n","Epoch 60/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6302 - accuracy: 0.6471 - val_loss: 0.6633 - val_accuracy: 0.6121\n","Epoch 61/100\n","29/29 [==============================] - 2s 54ms/step - loss: 0.6290 - accuracy: 0.6474 - val_loss: 0.6603 - val_accuracy: 0.6153\n","Epoch 62/100\n","29/29 [==============================] - 2s 61ms/step - loss: 0.6285 - accuracy: 0.6498 - val_loss: 0.6613 - val_accuracy: 0.6175\n","Epoch 63/100\n","29/29 [==============================] - 1s 39ms/step - loss: 0.6271 - accuracy: 0.6495 - val_loss: 0.6598 - val_accuracy: 0.6175\n","Epoch 64/100\n","29/29 [==============================] - 2s 67ms/step - loss: 0.6270 - accuracy: 0.6544 - val_loss: 0.6615 - val_accuracy: 0.6185\n","Epoch 65/100\n","29/29 [==============================] - 1s 37ms/step - loss: 0.6258 - accuracy: 0.6530 - val_loss: 0.6609 - val_accuracy: 0.6153\n","Epoch 66/100\n","29/29 [==============================] - 2s 64ms/step - loss: 0.6257 - accuracy: 0.6487 - val_loss: 0.6615 - val_accuracy: 0.6196\n","Epoch 67/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6240 - accuracy: 0.6562 - val_loss: 0.6599 - val_accuracy: 0.6153\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6234 - accuracy: 0.6538 - val_loss: 0.6616 - val_accuracy: 0.6196\n","Epoch 69/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6239 - accuracy: 0.6560 - val_loss: 0.6607 - val_accuracy: 0.6196\n","Epoch 70/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6226 - accuracy: 0.6573 - val_loss: 0.6638 - val_accuracy: 0.6185\n","Epoch 71/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6200 - accuracy: 0.6589 - val_loss: 0.6623 - val_accuracy: 0.6185\n","Epoch 72/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.6206 - accuracy: 0.6576 - val_loss: 0.6601 - val_accuracy: 0.6218\n","Epoch 73/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6189 - accuracy: 0.6541 - val_loss: 0.6615 - val_accuracy: 0.6175\n","Epoch 74/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6162 - accuracy: 0.6622 - val_loss: 0.6627 - val_accuracy: 0.6131\n","Epoch 75/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6165 - accuracy: 0.6635 - val_loss: 0.6606 - val_accuracy: 0.6142\n","Epoch 76/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6159 - accuracy: 0.6646 - val_loss: 0.6612 - val_accuracy: 0.6142\n","Epoch 77/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6127 - accuracy: 0.6681 - val_loss: 0.6604 - val_accuracy: 0.6207\n","Epoch 78/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6149 - accuracy: 0.6659 - val_loss: 0.6601 - val_accuracy: 0.6185\n","Epoch 79/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6126 - accuracy: 0.6649 - val_loss: 0.6617 - val_accuracy: 0.6131\n","Epoch 80/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6106 - accuracy: 0.6721 - val_loss: 0.6646 - val_accuracy: 0.6142\n","Epoch 81/100\n","29/29 [==============================] - 1s 51ms/step - loss: 0.6085 - accuracy: 0.6719 - val_loss: 0.6618 - val_accuracy: 0.6142\n","Epoch 82/100\n","29/29 [==============================] - 1s 42ms/step - loss: 0.6089 - accuracy: 0.6711 - val_loss: 0.6607 - val_accuracy: 0.6164\n","Epoch 83/100\n","29/29 [==============================] - 1s 47ms/step - loss: 0.6071 - accuracy: 0.6721 - val_loss: 0.6645 - val_accuracy: 0.6088\n","Epoch 84/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.6069 - accuracy: 0.6727 - val_loss: 0.6659 - val_accuracy: 0.6121\n","Epoch 85/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.6038 - accuracy: 0.6708 - val_loss: 0.6649 - val_accuracy: 0.6175\n","Epoch 86/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6015 - accuracy: 0.6767 - val_loss: 0.6640 - val_accuracy: 0.6110\n","Epoch 87/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5978 - accuracy: 0.6888 - val_loss: 0.6632 - val_accuracy: 0.6164\n","Epoch 88/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5964 - accuracy: 0.6802 - val_loss: 0.6641 - val_accuracy: 0.6121\n","Epoch 89/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5957 - accuracy: 0.6851 - val_loss: 0.6640 - val_accuracy: 0.6067\n","Epoch 90/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5946 - accuracy: 0.6843 - val_loss: 0.6638 - val_accuracy: 0.6142\n","Epoch 91/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5928 - accuracy: 0.6862 - val_loss: 0.6644 - val_accuracy: 0.6045\n","Epoch 92/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5924 - accuracy: 0.6878 - val_loss: 0.6642 - val_accuracy: 0.6067\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5863 - accuracy: 0.6891 - val_loss: 0.6671 - val_accuracy: 0.6121\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5843 - accuracy: 0.6980 - val_loss: 0.6672 - val_accuracy: 0.6088\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5856 - accuracy: 0.6915 - val_loss: 0.6743 - val_accuracy: 0.6099\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5821 - accuracy: 0.7002 - val_loss: 0.6710 - val_accuracy: 0.6142\n","Epoch 97/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5798 - accuracy: 0.6996 - val_loss: 0.6699 - val_accuracy: 0.6088\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5782 - accuracy: 0.7077 - val_loss: 0.6703 - val_accuracy: 0.6099\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5747 - accuracy: 0.7034 - val_loss: 0.6713 - val_accuracy: 0.6034\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5719 - accuracy: 0.7074 - val_loss: 0.6737 - val_accuracy: 0.6056\n","{'loss': [0.6931929588317871, 0.6929662227630615, 0.6926859021186829, 0.6922556757926941, 0.691591203212738, 0.6906410455703735, 0.6890314221382141, 0.6868715882301331, 0.6847348809242249, 0.6831473112106323, 0.6819087266921997, 0.6812286972999573, 0.6801996827125549, 0.679500162601471, 0.6783466935157776, 0.677887499332428, 0.6761828660964966, 0.6747094988822937, 0.6730735301971436, 0.6710065603256226, 0.66923588514328, 0.6659087538719177, 0.6633440852165222, 0.6607970595359802, 0.6580662131309509, 0.6562367677688599, 0.6559412479400635, 0.6547379493713379, 0.6533021330833435, 0.6516677141189575, 0.6510720252990723, 0.6502507925033569, 0.6474234461784363, 0.6481099128723145, 0.6465900540351868, 0.6453978419303894, 0.6458550691604614, 0.6447867155075073, 0.6446545124053955, 0.6432607769966125, 0.6441458463668823, 0.6415848135948181, 0.6403648257255554, 0.6409211754798889, 0.640338122844696, 0.6402507424354553, 0.6390514373779297, 0.6377395987510681, 0.6371868848800659, 0.6360836029052734, 0.6362913846969604, 0.6346402168273926, 0.635328471660614, 0.6332908868789673, 0.6337481737136841, 0.6313397884368896, 0.6322492957115173, 0.6317006945610046, 0.6317480206489563, 0.6301740407943726, 0.629036545753479, 0.6285258531570435, 0.6270949840545654, 0.6270162463188171, 0.6257612109184265, 0.625699520111084, 0.6239945888519287, 0.6234167814254761, 0.6238784193992615, 0.6225932836532593, 0.6200059056282043, 0.6206166744232178, 0.6189392805099487, 0.6162494421005249, 0.6164988875389099, 0.6159325242042542, 0.612702488899231, 0.6148734092712402, 0.61259526014328, 0.6105802655220032, 0.6085315346717834, 0.6088728904724121, 0.6071038246154785, 0.6069056987762451, 0.6038179993629456, 0.6015218496322632, 0.597754180431366, 0.5964279770851135, 0.5956998467445374, 0.5946422219276428, 0.5928338170051575, 0.5923976302146912, 0.5862892270088196, 0.5842804312705994, 0.5855623483657837, 0.5821467638015747, 0.579797625541687, 0.578180730342865, 0.5747312903404236, 0.5718874931335449], 'accuracy': [0.509159505367279, 0.578125, 0.571659505367279, 0.5792025923728943, 0.576777994632721, 0.5751616358757019, 0.5738146305084229, 0.5757004022598267, 0.5751616358757019, 0.5740840435028076, 0.5770474076271057, 0.5770474076271057, 0.5827047228813171, 0.579472005367279, 0.5864762663841248, 0.5889008641242981, 0.5883620977401733, 0.5940194129943848, 0.6004849076271057, 0.603178858757019, 0.6004849076271057, 0.6066810488700867, 0.610722005367279, 0.6131465435028076, 0.6142241358757019, 0.6147629022598267, 0.615840494632721, 0.6174569129943848, 0.6258081793785095, 0.6255387663841248, 0.6258081793785095, 0.6260775923728943, 0.6268857717514038, 0.6298491358757019, 0.6260775923728943, 0.6303879022598267, 0.6293103694915771, 0.6290409564971924, 0.6328125, 0.6320043206214905, 0.6395474076271057, 0.6346982717514038, 0.639008641242981, 0.6363146305084229, 0.639008641242981, 0.6384698152542114, 0.6417025923728943, 0.6398168206214905, 0.641972005367279, 0.6452047228813171, 0.6371228694915771, 0.6435883641242981, 0.6403555870056152, 0.6465517282485962, 0.6441271305084229, 0.6478987336158752, 0.6457435488700867, 0.6462823152542114, 0.6492456793785095, 0.647090494632721, 0.6473599076271057, 0.649784505367279, 0.6495150923728943, 0.6543642282485962, 0.6530172228813171, 0.6487069129943848, 0.65625, 0.6538254022598267, 0.6559805870056152, 0.6573275923728943, 0.6589439511299133, 0.657597005367279, 0.6540948152542114, 0.6621767282485962, 0.6635237336158752, 0.6646012663841248, 0.6681034564971924, 0.6659482717514038, 0.6648706793785095, 0.6721444129943848, 0.671875, 0.6710668206214905, 0.6721444129943848, 0.6726831793785095, 0.6707974076271057, 0.6767241358757019, 0.688847005367279, 0.6802262663841248, 0.6850754022598267, 0.6842672228813171, 0.686152994632721, 0.6877694129943848, 0.689116358757019, 0.6980064511299133, 0.6915409564971924, 0.7001616358757019, 0.6996228694915771, 0.7077047228813171, 0.7033944129943848, 0.7074353694915771], 'val_loss': [0.6931315660476685, 0.6931044459342957, 0.6930555105209351, 0.6929982304573059, 0.6928748488426208, 0.6926713585853577, 0.6923086047172546, 0.6917318105697632, 0.6909465789794922, 0.6899991631507874, 0.6891223192214966, 0.688164472579956, 0.6873614192008972, 0.6865056157112122, 0.6852063536643982, 0.6837795972824097, 0.6824110150337219, 0.6809421181678772, 0.67938631772995, 0.6768296360969543, 0.6751642823219299, 0.6725752353668213, 0.670609176158905, 0.6686158180236816, 0.6667912602424622, 0.6680202484130859, 0.6650452613830566, 0.6648030877113342, 0.665026068687439, 0.6640691161155701, 0.6627680659294128, 0.6643121838569641, 0.6637990474700928, 0.667009711265564, 0.6618711948394775, 0.6643046140670776, 0.6638292670249939, 0.6627978086471558, 0.6622611880302429, 0.6645989418029785, 0.6623737812042236, 0.6638233661651611, 0.661455512046814, 0.6618832945823669, 0.6616376638412476, 0.6647791266441345, 0.6614595055580139, 0.6636680960655212, 0.662263810634613, 0.66154944896698, 0.6626681089401245, 0.661312997341156, 0.6620458364486694, 0.6597994565963745, 0.6619536280632019, 0.6614793539047241, 0.6617948412895203, 0.659837543964386, 0.6597001552581787, 0.6633493900299072, 0.6602674126625061, 0.6613166332244873, 0.6598398685455322, 0.6614865064620972, 0.6608918309211731, 0.6615265607833862, 0.6599491238594055, 0.6615992188453674, 0.6606911420822144, 0.6637846231460571, 0.6623194217681885, 0.660081684589386, 0.661526083946228, 0.6627377271652222, 0.6606385707855225, 0.6611809730529785, 0.6603631377220154, 0.6601278185844421, 0.661734402179718, 0.6646112203598022, 0.6618301272392273, 0.6607360243797302, 0.6645001173019409, 0.6659408807754517, 0.6649048924446106, 0.6640262007713318, 0.6631522178649902, 0.6641433835029602, 0.6640491485595703, 0.6638012528419495, 0.6643526554107666, 0.6641843318939209, 0.6670702695846558, 0.6672148704528809, 0.6743360757827759, 0.671048641204834, 0.6699448823928833, 0.6703249216079712, 0.6712716221809387, 0.6736966967582703], 'val_accuracy': [0.5150862336158752, 0.517241358757019, 0.5215517282485962, 0.5215517282485962, 0.5301724076271057, 0.5420258641242981, 0.5571120977401733, 0.5646551847457886, 0.5625, 0.5668103694915771, 0.568965494632721, 0.5678879022598267, 0.5700430870056152, 0.5743534564971924, 0.5721982717514038, 0.5721982717514038, 0.5732758641242981, 0.5743534564971924, 0.5711206793785095, 0.5668103694915771, 0.5721982717514038, 0.5818965435028076, 0.5862069129943848, 0.59375, 0.5991379022598267, 0.5818965435028076, 0.5894396305084229, 0.587284505367279, 0.587284505367279, 0.5883620977401733, 0.5926724076271057, 0.5883620977401733, 0.5926724076271057, 0.5959051847457886, 0.600215494632721, 0.5959051847457886, 0.5969827771186829, 0.5991379022598267, 0.5969827771186829, 0.600215494632721, 0.6034482717514038, 0.5991379022598267, 0.6056034564971924, 0.6056034564971924, 0.6066810488700867, 0.6023706793785095, 0.6088362336158752, 0.6012930870056152, 0.607758641242981, 0.6066810488700867, 0.5980603694915771, 0.6045258641242981, 0.6099137663841248, 0.6142241358757019, 0.6088362336158752, 0.6142241358757019, 0.610991358757019, 0.6142241358757019, 0.6120689511299133, 0.6120689511299133, 0.6153017282485962, 0.6174569129943848, 0.6174569129943848, 0.618534505367279, 0.6153017282485962, 0.6196120977401733, 0.6153017282485962, 0.6196120977401733, 0.6196120977401733, 0.618534505367279, 0.618534505367279, 0.6217672228813171, 0.6174569129943848, 0.6131465435028076, 0.6142241358757019, 0.6142241358757019, 0.6206896305084229, 0.618534505367279, 0.6131465435028076, 0.6142241358757019, 0.6142241358757019, 0.6163793206214905, 0.6088362336158752, 0.6120689511299133, 0.6174569129943848, 0.610991358757019, 0.6163793206214905, 0.6120689511299133, 0.6066810488700867, 0.6142241358757019, 0.6045258641242981, 0.6066810488700867, 0.6120689511299133, 0.6088362336158752, 0.6099137663841248, 0.6142241358757019, 0.6088362336158752, 0.6099137663841248, 0.6034482717514038, 0.6056034564971924]}\n","38/38 [==============================] - 1s 9ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5062"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 9s 93ms/step - loss: 0.6932 - accuracy: 0.5062 - val_loss: 0.6931 - val_accuracy: 0.5045\n","Epoch 2/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6930 - accuracy: 0.5620 - val_loss: 0.6931 - val_accuracy: 0.5045\n","Epoch 3/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6928 - accuracy: 0.5656 - val_loss: 0.6931 - val_accuracy: 0.5079\n","Epoch 4/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6925 - accuracy: 0.5662 - val_loss: 0.6931 - val_accuracy: 0.5124\n","Epoch 5/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6920 - accuracy: 0.5668 - val_loss: 0.6930 - val_accuracy: 0.5158\n","Epoch 6/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6913 - accuracy: 0.5628 - val_loss: 0.6928 - val_accuracy: 0.5226\n","Epoch 7/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6902 - accuracy: 0.5634 - val_loss: 0.6926 - val_accuracy: 0.5260\n","Epoch 8/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6886 - accuracy: 0.5679 - val_loss: 0.6922 - val_accuracy: 0.5464\n","Epoch 9/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6866 - accuracy: 0.5665 - val_loss: 0.6916 - val_accuracy: 0.5486\n","Epoch 10/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6849 - accuracy: 0.5628 - val_loss: 0.6909 - val_accuracy: 0.5430\n","Epoch 11/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6835 - accuracy: 0.5659 - val_loss: 0.6899 - val_accuracy: 0.5611\n","Epoch 12/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6828 - accuracy: 0.5671 - val_loss: 0.6892 - val_accuracy: 0.5633\n","Epoch 13/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6818 - accuracy: 0.5682 - val_loss: 0.6886 - val_accuracy: 0.5577\n","Epoch 14/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6813 - accuracy: 0.5673 - val_loss: 0.6878 - val_accuracy: 0.5667\n","Epoch 15/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6806 - accuracy: 0.5739 - val_loss: 0.6872 - val_accuracy: 0.5667\n","Epoch 16/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6798 - accuracy: 0.5781 - val_loss: 0.6861 - val_accuracy: 0.5724\n","Epoch 17/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6785 - accuracy: 0.5756 - val_loss: 0.6850 - val_accuracy: 0.5724\n","Epoch 18/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6775 - accuracy: 0.5809 - val_loss: 0.6840 - val_accuracy: 0.5713\n","Epoch 19/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6759 - accuracy: 0.5815 - val_loss: 0.6836 - val_accuracy: 0.5724\n","Epoch 20/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6747 - accuracy: 0.5872 - val_loss: 0.6811 - val_accuracy: 0.5724\n","Epoch 21/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.6725 - accuracy: 0.5954 - val_loss: 0.6796 - val_accuracy: 0.5747\n","Epoch 22/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6695 - accuracy: 0.5959 - val_loss: 0.6782 - val_accuracy: 0.5690\n","Epoch 23/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6682 - accuracy: 0.5962 - val_loss: 0.6771 - val_accuracy: 0.5713\n","Epoch 24/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6651 - accuracy: 0.6075 - val_loss: 0.6749 - val_accuracy: 0.5724\n","Epoch 25/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6644 - accuracy: 0.6010 - val_loss: 0.6753 - val_accuracy: 0.5667\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6622 - accuracy: 0.6033 - val_loss: 0.6738 - val_accuracy: 0.5724\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6598 - accuracy: 0.6104 - val_loss: 0.6744 - val_accuracy: 0.5679\n","Epoch 28/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6596 - accuracy: 0.6081 - val_loss: 0.6731 - val_accuracy: 0.5894\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6572 - accuracy: 0.6106 - val_loss: 0.6736 - val_accuracy: 0.5758\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6570 - accuracy: 0.6095 - val_loss: 0.6737 - val_accuracy: 0.5781\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6569 - accuracy: 0.6075 - val_loss: 0.6736 - val_accuracy: 0.5848\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6550 - accuracy: 0.6067 - val_loss: 0.6745 - val_accuracy: 0.5769\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6543 - accuracy: 0.6104 - val_loss: 0.6741 - val_accuracy: 0.5781\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6536 - accuracy: 0.6149 - val_loss: 0.6752 - val_accuracy: 0.5769\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6518 - accuracy: 0.6121 - val_loss: 0.6745 - val_accuracy: 0.5781\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6508 - accuracy: 0.6154 - val_loss: 0.6748 - val_accuracy: 0.5803\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6507 - accuracy: 0.6157 - val_loss: 0.6739 - val_accuracy: 0.5781\n","Epoch 38/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6488 - accuracy: 0.6169 - val_loss: 0.6737 - val_accuracy: 0.5803\n","Epoch 39/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6491 - accuracy: 0.6222 - val_loss: 0.6744 - val_accuracy: 0.5803\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6475 - accuracy: 0.6154 - val_loss: 0.6752 - val_accuracy: 0.5792\n","Epoch 41/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6472 - accuracy: 0.6222 - val_loss: 0.6739 - val_accuracy: 0.5814\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6475 - accuracy: 0.6188 - val_loss: 0.6731 - val_accuracy: 0.5871\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6476 - accuracy: 0.6186 - val_loss: 0.6743 - val_accuracy: 0.5826\n","Epoch 44/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6460 - accuracy: 0.6208 - val_loss: 0.6739 - val_accuracy: 0.5860\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6450 - accuracy: 0.6197 - val_loss: 0.6732 - val_accuracy: 0.5860\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6452 - accuracy: 0.6265 - val_loss: 0.6731 - val_accuracy: 0.5871\n","Epoch 47/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6432 - accuracy: 0.6222 - val_loss: 0.6729 - val_accuracy: 0.5882\n","Epoch 48/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6424 - accuracy: 0.6262 - val_loss: 0.6750 - val_accuracy: 0.5905\n","Epoch 49/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6406 - accuracy: 0.6239 - val_loss: 0.6728 - val_accuracy: 0.5928\n","Epoch 50/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6410 - accuracy: 0.6242 - val_loss: 0.6735 - val_accuracy: 0.5916\n","Epoch 51/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6414 - accuracy: 0.6214 - val_loss: 0.6727 - val_accuracy: 0.5962\n","Epoch 52/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6401 - accuracy: 0.6276 - val_loss: 0.6733 - val_accuracy: 0.5939\n","Epoch 53/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.6409 - accuracy: 0.6271 - val_loss: 0.6733 - val_accuracy: 0.5995\n","Epoch 54/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.6403 - accuracy: 0.6296 - val_loss: 0.6732 - val_accuracy: 0.5916\n","Epoch 55/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6383 - accuracy: 0.6324 - val_loss: 0.6730 - val_accuracy: 0.5950\n","Epoch 56/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6406 - accuracy: 0.6222 - val_loss: 0.6730 - val_accuracy: 0.5950\n","Epoch 57/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6375 - accuracy: 0.6287 - val_loss: 0.6732 - val_accuracy: 0.5973\n","Epoch 58/100\n","28/28 [==============================] - 1s 38ms/step - loss: 0.6365 - accuracy: 0.6344 - val_loss: 0.6734 - val_accuracy: 0.6007\n","Epoch 59/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6346 - accuracy: 0.6307 - val_loss: 0.6747 - val_accuracy: 0.5905\n","Epoch 60/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6334 - accuracy: 0.6353 - val_loss: 0.6727 - val_accuracy: 0.5973\n","Epoch 61/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6335 - accuracy: 0.6381 - val_loss: 0.6732 - val_accuracy: 0.5995\n","Epoch 62/100\n","28/28 [==============================] - 1s 44ms/step - loss: 0.6320 - accuracy: 0.6372 - val_loss: 0.6725 - val_accuracy: 0.6029\n","Epoch 63/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6324 - accuracy: 0.6327 - val_loss: 0.6731 - val_accuracy: 0.6007\n","Epoch 64/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6316 - accuracy: 0.6370 - val_loss: 0.6726 - val_accuracy: 0.6007\n","Epoch 65/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6278 - accuracy: 0.6437 - val_loss: 0.6738 - val_accuracy: 0.6018\n","Epoch 66/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6304 - accuracy: 0.6372 - val_loss: 0.6740 - val_accuracy: 0.5995\n","Epoch 67/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6285 - accuracy: 0.6398 - val_loss: 0.6754 - val_accuracy: 0.5995\n","Epoch 68/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.6306 - accuracy: 0.6406 - val_loss: 0.6732 - val_accuracy: 0.6131\n","Epoch 69/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.6261 - accuracy: 0.6446 - val_loss: 0.6725 - val_accuracy: 0.6120\n","Epoch 70/100\n","28/28 [==============================] - 1s 46ms/step - loss: 0.6264 - accuracy: 0.6367 - val_loss: 0.6729 - val_accuracy: 0.6097\n","Epoch 71/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6247 - accuracy: 0.6449 - val_loss: 0.6731 - val_accuracy: 0.6075\n","Epoch 72/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6250 - accuracy: 0.6426 - val_loss: 0.6733 - val_accuracy: 0.6052\n","Epoch 73/100\n","28/28 [==============================] - 2s 65ms/step - loss: 0.6229 - accuracy: 0.6483 - val_loss: 0.6718 - val_accuracy: 0.6143\n","Epoch 74/100\n","28/28 [==============================] - 1s 37ms/step - loss: 0.6194 - accuracy: 0.6570 - val_loss: 0.6795 - val_accuracy: 0.5962\n","Epoch 75/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.6249 - accuracy: 0.6415 - val_loss: 0.6732 - val_accuracy: 0.6052\n","Epoch 76/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6181 - accuracy: 0.6508 - val_loss: 0.6730 - val_accuracy: 0.6131\n","Epoch 77/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6164 - accuracy: 0.6531 - val_loss: 0.6726 - val_accuracy: 0.6086\n","Epoch 78/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6152 - accuracy: 0.6542 - val_loss: 0.6731 - val_accuracy: 0.6131\n","Epoch 79/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.6141 - accuracy: 0.6593 - val_loss: 0.6732 - val_accuracy: 0.6188\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6141 - accuracy: 0.6542 - val_loss: 0.6728 - val_accuracy: 0.6086\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6095 - accuracy: 0.6644 - val_loss: 0.6735 - val_accuracy: 0.6143\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6109 - accuracy: 0.6568 - val_loss: 0.6738 - val_accuracy: 0.6176\n","Epoch 83/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6069 - accuracy: 0.6627 - val_loss: 0.6735 - val_accuracy: 0.6154\n","Epoch 84/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6079 - accuracy: 0.6551 - val_loss: 0.6727 - val_accuracy: 0.6210\n","Epoch 85/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6048 - accuracy: 0.6661 - val_loss: 0.6727 - val_accuracy: 0.6244\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6055 - accuracy: 0.6619 - val_loss: 0.6737 - val_accuracy: 0.6176\n","Epoch 87/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6000 - accuracy: 0.6766 - val_loss: 0.6748 - val_accuracy: 0.6154\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6006 - accuracy: 0.6740 - val_loss: 0.6783 - val_accuracy: 0.6154\n","Epoch 89/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5968 - accuracy: 0.6760 - val_loss: 0.6760 - val_accuracy: 0.6199\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5956 - accuracy: 0.6732 - val_loss: 0.6744 - val_accuracy: 0.6210\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5948 - accuracy: 0.6774 - val_loss: 0.6770 - val_accuracy: 0.6176\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5873 - accuracy: 0.6859 - val_loss: 0.6780 - val_accuracy: 0.6244\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5866 - accuracy: 0.6853 - val_loss: 0.6765 - val_accuracy: 0.6233\n","Epoch 94/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5840 - accuracy: 0.6811 - val_loss: 0.6845 - val_accuracy: 0.6210\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5844 - accuracy: 0.6862 - val_loss: 0.6758 - val_accuracy: 0.6233\n","Epoch 96/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5809 - accuracy: 0.6885 - val_loss: 0.6763 - val_accuracy: 0.6210\n","Epoch 97/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.5794 - accuracy: 0.6930 - val_loss: 0.6775 - val_accuracy: 0.6301\n","Epoch 98/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5774 - accuracy: 0.6950 - val_loss: 0.6789 - val_accuracy: 0.6290\n","Epoch 99/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5738 - accuracy: 0.6845 - val_loss: 0.6839 - val_accuracy: 0.6278\n","Epoch 100/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.5732 - accuracy: 0.6944 - val_loss: 0.6875 - val_accuracy: 0.6312\n","{'loss': [0.6932172775268555, 0.6930007338523865, 0.6927976608276367, 0.6924911141395569, 0.6920345425605774, 0.6913345456123352, 0.6901713609695435, 0.6886004209518433, 0.6866479516029358, 0.6848776936531067, 0.683519184589386, 0.6827770471572876, 0.6817790269851685, 0.6813291311264038, 0.6806232929229736, 0.6797648072242737, 0.6785405278205872, 0.6774502992630005, 0.6759175658226013, 0.6746855974197388, 0.6724625825881958, 0.6695052981376648, 0.6682117581367493, 0.6651307940483093, 0.6643624305725098, 0.6622427105903625, 0.6597908735275269, 0.659609854221344, 0.6572079658508301, 0.6570385694503784, 0.6568780541419983, 0.654979407787323, 0.6543402671813965, 0.6535754799842834, 0.651800811290741, 0.6508415937423706, 0.6507347822189331, 0.6487688422203064, 0.6491400003433228, 0.6474605202674866, 0.6472495198249817, 0.6474916934967041, 0.6475787162780762, 0.6460207104682922, 0.6450060606002808, 0.6452125310897827, 0.6432321667671204, 0.642414927482605, 0.6405636072158813, 0.6409987211227417, 0.6413946151733398, 0.640117347240448, 0.6408976912498474, 0.6402593851089478, 0.6383295059204102, 0.6406296491622925, 0.6374528408050537, 0.6365254521369934, 0.6346092820167542, 0.6333925724029541, 0.6335419416427612, 0.6320343613624573, 0.632384181022644, 0.6315796971321106, 0.6278393864631653, 0.630446195602417, 0.6285247802734375, 0.6305516958236694, 0.6261246204376221, 0.6264187693595886, 0.6246660947799683, 0.624995231628418, 0.6229124665260315, 0.6193733215332031, 0.6248583197593689, 0.6181188821792603, 0.6163641810417175, 0.6152496933937073, 0.6141327619552612, 0.6141436696052551, 0.6095282435417175, 0.6108823418617249, 0.6069398522377014, 0.6079382300376892, 0.6047961115837097, 0.6054621338844299, 0.5999945998191833, 0.600602924823761, 0.5968030095100403, 0.5956093668937683, 0.5947734713554382, 0.5872681140899658, 0.5865863561630249, 0.5840119123458862, 0.584388256072998, 0.5808538794517517, 0.5793778896331787, 0.5774321556091309, 0.5738030672073364, 0.5731582641601562], 'accuracy': [0.5062252283096313, 0.5619694590568542, 0.5656480193138123, 0.5662139058113098, 0.5667798519134521, 0.5628183484077454, 0.5633842945098877, 0.5679117441177368, 0.5664969086647034, 0.5628183484077454, 0.565930962562561, 0.5670627951622009, 0.5681946873664856, 0.5673457980155945, 0.5738539695739746, 0.578098475933075, 0.5755518078804016, 0.5809281468391418, 0.5814940333366394, 0.5871533751487732, 0.5953593850135803, 0.5959252715110779, 0.5962082743644714, 0.6075268983840942, 0.6010186672210693, 0.6032823920249939, 0.6103565096855164, 0.6080927848815918, 0.6106395125389099, 0.6095076203346252, 0.6075268983840942, 0.6066780090332031, 0.6103565096855164, 0.6148839592933655, 0.6120543479919434, 0.6154499053955078, 0.6157329082489014, 0.6168647408485413, 0.6222410798072815, 0.6154499053955078, 0.6222410798072815, 0.618845522403717, 0.6185625195503235, 0.620826244354248, 0.6196944117546082, 0.6264855861663818, 0.6222410798072815, 0.6262025833129883, 0.6239388585090637, 0.6242218613624573, 0.6213921904563904, 0.6276174187660217, 0.6270514726638794, 0.6295982003211975, 0.6324278712272644, 0.6222410798072815, 0.6287493109703064, 0.6344085931777954, 0.6307300329208374, 0.6352574825286865, 0.6380871534347534, 0.6372382640838623, 0.6327108144760132, 0.6369553208351135, 0.6437464356422424, 0.6372382640838623, 0.6397849321365356, 0.6406338214874268, 0.6445953845977783, 0.63667231798172, 0.6448783278465271, 0.6426146030426025, 0.6482738852500916, 0.657045841217041, 0.6414827108383179, 0.6508206129074097, 0.6530843377113342, 0.6542161703109741, 0.6593095660209656, 0.6542161703109741, 0.664402961730957, 0.6567628979682922, 0.66270512342453, 0.6550650596618652, 0.6661007404327393, 0.6618562340736389, 0.676570475101471, 0.6740237474441528, 0.6760045289993286, 0.6731748580932617, 0.6774193644523621, 0.685908317565918, 0.6853423714637756, 0.6810979247093201, 0.6861912608146667, 0.6884549856185913, 0.6929824352264404, 0.6949632167816162, 0.6844934821128845, 0.6943972706794739], 'val_loss': [0.6931357383728027, 0.693122386932373, 0.6930965185165405, 0.6930525302886963, 0.6929804086685181, 0.6928335428237915, 0.6926235556602478, 0.6921635866165161, 0.6915687918663025, 0.6909006834030151, 0.6898878216743469, 0.6891833543777466, 0.6886124610900879, 0.6877946257591248, 0.6871591210365295, 0.6860971450805664, 0.684962809085846, 0.6839584708213806, 0.683610737323761, 0.6810857653617859, 0.6796109080314636, 0.6782044172286987, 0.6771125793457031, 0.6749129891395569, 0.6753117442131042, 0.6738273501396179, 0.674397885799408, 0.6730835437774658, 0.6736305356025696, 0.6737191677093506, 0.6735949516296387, 0.6745002269744873, 0.6740849018096924, 0.6752232909202576, 0.6744893193244934, 0.6747707724571228, 0.6739484667778015, 0.6737211346626282, 0.674373984336853, 0.675162672996521, 0.6739087700843811, 0.673104465007782, 0.6743321418762207, 0.6739362478256226, 0.6732349395751953, 0.6730839014053345, 0.6728814840316772, 0.6749642491340637, 0.6728337407112122, 0.6735007166862488, 0.6727399230003357, 0.6733042001724243, 0.6732832193374634, 0.6731889843940735, 0.6729573607444763, 0.6729640960693359, 0.6731536388397217, 0.6734470129013062, 0.6747221350669861, 0.6727110147476196, 0.6731671094894409, 0.6724585890769958, 0.67305588722229, 0.6725751161575317, 0.6737930774688721, 0.6739819645881653, 0.6753867268562317, 0.6732340455055237, 0.6725071668624878, 0.6728969812393188, 0.6731383204460144, 0.6732505559921265, 0.6718187928199768, 0.6795476675033569, 0.6732261180877686, 0.6729947328567505, 0.672637403011322, 0.6730896234512329, 0.6731760501861572, 0.6728023886680603, 0.6734886169433594, 0.6737553477287292, 0.6734746098518372, 0.6727128028869629, 0.672742486000061, 0.6736912131309509, 0.6748001575469971, 0.6782804727554321, 0.675950288772583, 0.6743909120559692, 0.6770183444023132, 0.6779896020889282, 0.6764900088310242, 0.684501588344574, 0.6758264303207397, 0.6763247847557068, 0.6775269508361816, 0.6789158582687378, 0.6838967204093933, 0.6875278949737549], 'val_accuracy': [0.5045248866081238, 0.5045248866081238, 0.5079185366630554, 0.5124434232711792, 0.5158371329307556, 0.5226244330406189, 0.5260180830955505, 0.5463801026344299, 0.5486425161361694, 0.5429864525794983, 0.5610859990119934, 0.5633484125137329, 0.557692289352417, 0.5667420625686646, 0.5667420625686646, 0.5723981857299805, 0.5723981857299805, 0.5712669491767883, 0.5723981857299805, 0.5723981857299805, 0.5746606588363647, 0.5690045356750488, 0.5712669491767883, 0.5723981857299805, 0.5667420625686646, 0.5723981857299805, 0.5678732991218567, 0.5893664956092834, 0.5757918357849121, 0.5780543088912964, 0.5848416090011597, 0.5769230723381042, 0.5780543088912964, 0.5769230723381042, 0.5780543088912964, 0.5803167223930359, 0.5780543088912964, 0.5803167223930359, 0.5803167223930359, 0.5791855454444885, 0.581447958946228, 0.587104082107544, 0.5825791954994202, 0.5859728455543518, 0.5859728455543518, 0.587104082107544, 0.5882353186607361, 0.5904977321624756, 0.5927602052688599, 0.5916289687156677, 0.5961538553237915, 0.5938913822174072, 0.5995475053787231, 0.5916289687156677, 0.5950226187705994, 0.5950226187705994, 0.5972850918769836, 0.6006787419319153, 0.5904977321624756, 0.5972850918769836, 0.5995475053787231, 0.6029411554336548, 0.6006787419319153, 0.6006787419319153, 0.6018099784851074, 0.5995475053787231, 0.5995475053787231, 0.6131221652030945, 0.6119909286499023, 0.6097285151481628, 0.6074660420417786, 0.6052036285400391, 0.6142534017562866, 0.5961538553237915, 0.6052036285400391, 0.6131221652030945, 0.6085972785949707, 0.6131221652030945, 0.6187782883644104, 0.6085972785949707, 0.6142534017562866, 0.6176470518112183, 0.6153846383094788, 0.6210407018661499, 0.6244344115257263, 0.6176470518112183, 0.6153846383094788, 0.6153846383094788, 0.6199095249176025, 0.6210407018661499, 0.6176470518112183, 0.6244344115257263, 0.6233031749725342, 0.6210407018661499, 0.6233031749725342, 0.6210407018661499, 0.6300904750823975, 0.6289592981338501, 0.627828061580658, 0.6312217116355896]}\n","45/45 [==============================] - 1s 6ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5103"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 63ms/step - loss: 0.6932 - accuracy: 0.5103 - val_loss: 0.6931 - val_accuracy: 0.5196\n","Epoch 2/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6930 - accuracy: 0.5693 - val_loss: 0.6931 - val_accuracy: 0.5186\n","Epoch 3/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6927 - accuracy: 0.5641 - val_loss: 0.6931 - val_accuracy: 0.5196\n","Epoch 4/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6921 - accuracy: 0.5641 - val_loss: 0.6930 - val_accuracy: 0.5186\n","Epoch 5/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6913 - accuracy: 0.5693 - val_loss: 0.6929 - val_accuracy: 0.5331\n","Epoch 6/100\n","31/31 [==============================] - 1s 37ms/step - loss: 0.6898 - accuracy: 0.5713 - val_loss: 0.6927 - val_accuracy: 0.5382\n","Epoch 7/100\n","31/31 [==============================] - 2s 60ms/step - loss: 0.6877 - accuracy: 0.5667 - val_loss: 0.6924 - val_accuracy: 0.5527\n","Epoch 8/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.6853 - accuracy: 0.5659 - val_loss: 0.6918 - val_accuracy: 0.5651\n","Epoch 9/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.6831 - accuracy: 0.5641 - val_loss: 0.6912 - val_accuracy: 0.5775\n","Epoch 10/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6823 - accuracy: 0.5651 - val_loss: 0.6907 - val_accuracy: 0.5764\n","Epoch 11/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6817 - accuracy: 0.5718 - val_loss: 0.6903 - val_accuracy: 0.5754\n","Epoch 12/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6808 - accuracy: 0.5780 - val_loss: 0.6898 - val_accuracy: 0.5754\n","Epoch 13/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.6807 - accuracy: 0.5749 - val_loss: 0.6891 - val_accuracy: 0.5785\n","Epoch 14/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6799 - accuracy: 0.5762 - val_loss: 0.6887 - val_accuracy: 0.5764\n","Epoch 15/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6793 - accuracy: 0.5796 - val_loss: 0.6882 - val_accuracy: 0.5764\n","Epoch 16/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6787 - accuracy: 0.5786 - val_loss: 0.6873 - val_accuracy: 0.5847\n","Epoch 17/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.6781 - accuracy: 0.5796 - val_loss: 0.6865 - val_accuracy: 0.5909\n","Epoch 18/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6773 - accuracy: 0.5814 - val_loss: 0.6857 - val_accuracy: 0.5868\n","Epoch 19/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6764 - accuracy: 0.5788 - val_loss: 0.6849 - val_accuracy: 0.5837\n","Epoch 20/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6751 - accuracy: 0.5853 - val_loss: 0.6838 - val_accuracy: 0.5857\n","Epoch 21/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6739 - accuracy: 0.5871 - val_loss: 0.6827 - val_accuracy: 0.5857\n","Epoch 22/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6720 - accuracy: 0.5889 - val_loss: 0.6814 - val_accuracy: 0.5899\n","Epoch 23/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6704 - accuracy: 0.5928 - val_loss: 0.6798 - val_accuracy: 0.5857\n","Epoch 24/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6684 - accuracy: 0.6013 - val_loss: 0.6782 - val_accuracy: 0.5826\n","Epoch 25/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6659 - accuracy: 0.6010 - val_loss: 0.6771 - val_accuracy: 0.5837\n","Epoch 26/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.6637 - accuracy: 0.6049 - val_loss: 0.6761 - val_accuracy: 0.5878\n","Epoch 27/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6631 - accuracy: 0.6106 - val_loss: 0.6771 - val_accuracy: 0.5899\n","Epoch 28/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6615 - accuracy: 0.6109 - val_loss: 0.6740 - val_accuracy: 0.5909\n","Epoch 29/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6595 - accuracy: 0.6101 - val_loss: 0.6753 - val_accuracy: 0.5857\n","Epoch 30/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6594 - accuracy: 0.6067 - val_loss: 0.6735 - val_accuracy: 0.5909\n","Epoch 31/100\n","31/31 [==============================] - 2s 65ms/step - loss: 0.6568 - accuracy: 0.6168 - val_loss: 0.6734 - val_accuracy: 0.5919\n","Epoch 32/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6570 - accuracy: 0.6121 - val_loss: 0.6737 - val_accuracy: 0.5919\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6550 - accuracy: 0.6124 - val_loss: 0.6715 - val_accuracy: 0.5919\n","Epoch 34/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6536 - accuracy: 0.6173 - val_loss: 0.6724 - val_accuracy: 0.5940\n","Epoch 35/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6543 - accuracy: 0.6140 - val_loss: 0.6697 - val_accuracy: 0.5899\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6515 - accuracy: 0.6147 - val_loss: 0.6735 - val_accuracy: 0.5919\n","Epoch 37/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6514 - accuracy: 0.6194 - val_loss: 0.6715 - val_accuracy: 0.5971\n","Epoch 38/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6506 - accuracy: 0.6171 - val_loss: 0.6709 - val_accuracy: 0.5971\n","Epoch 39/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6489 - accuracy: 0.6253 - val_loss: 0.6693 - val_accuracy: 0.5981\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6503 - accuracy: 0.6207 - val_loss: 0.6729 - val_accuracy: 0.5971\n","Epoch 41/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6482 - accuracy: 0.6202 - val_loss: 0.6743 - val_accuracy: 0.6023\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6474 - accuracy: 0.6235 - val_loss: 0.6695 - val_accuracy: 0.5961\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6467 - accuracy: 0.6240 - val_loss: 0.6719 - val_accuracy: 0.6023\n","Epoch 44/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6459 - accuracy: 0.6256 - val_loss: 0.6717 - val_accuracy: 0.5961\n","Epoch 45/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6447 - accuracy: 0.6313 - val_loss: 0.6710 - val_accuracy: 0.5992\n","Epoch 46/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6450 - accuracy: 0.6269 - val_loss: 0.6725 - val_accuracy: 0.5981\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6433 - accuracy: 0.6287 - val_loss: 0.6695 - val_accuracy: 0.6002\n","Epoch 48/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6422 - accuracy: 0.6300 - val_loss: 0.6742 - val_accuracy: 0.6002\n","Epoch 49/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6427 - accuracy: 0.6307 - val_loss: 0.6704 - val_accuracy: 0.6002\n","Epoch 50/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6425 - accuracy: 0.6287 - val_loss: 0.6706 - val_accuracy: 0.6002\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6428 - accuracy: 0.6253 - val_loss: 0.6717 - val_accuracy: 0.6023\n","Epoch 52/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6400 - accuracy: 0.6315 - val_loss: 0.6738 - val_accuracy: 0.6054\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6380 - accuracy: 0.6339 - val_loss: 0.6702 - val_accuracy: 0.6023\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6370 - accuracy: 0.6372 - val_loss: 0.6721 - val_accuracy: 0.6043\n","Epoch 55/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6391 - accuracy: 0.6344 - val_loss: 0.6711 - val_accuracy: 0.6074\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6368 - accuracy: 0.6336 - val_loss: 0.6713 - val_accuracy: 0.6064\n","Epoch 57/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6339 - accuracy: 0.6403 - val_loss: 0.6704 - val_accuracy: 0.6085\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6338 - accuracy: 0.6442 - val_loss: 0.6729 - val_accuracy: 0.6054\n","Epoch 59/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6336 - accuracy: 0.6426 - val_loss: 0.6723 - val_accuracy: 0.6105\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6309 - accuracy: 0.6434 - val_loss: 0.6747 - val_accuracy: 0.6064\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6311 - accuracy: 0.6444 - val_loss: 0.6747 - val_accuracy: 0.6054\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6292 - accuracy: 0.6439 - val_loss: 0.6731 - val_accuracy: 0.6095\n","Epoch 63/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6278 - accuracy: 0.6442 - val_loss: 0.6739 - val_accuracy: 0.6136\n","Epoch 64/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6305 - accuracy: 0.6401 - val_loss: 0.6729 - val_accuracy: 0.6157\n","Epoch 65/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6270 - accuracy: 0.6504 - val_loss: 0.6718 - val_accuracy: 0.6147\n","Epoch 66/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6264 - accuracy: 0.6475 - val_loss: 0.6728 - val_accuracy: 0.6188\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6244 - accuracy: 0.6499 - val_loss: 0.6733 - val_accuracy: 0.6188\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6218 - accuracy: 0.6556 - val_loss: 0.6706 - val_accuracy: 0.6178\n","Epoch 69/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6232 - accuracy: 0.6517 - val_loss: 0.6734 - val_accuracy: 0.6260\n","Epoch 70/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6216 - accuracy: 0.6525 - val_loss: 0.6750 - val_accuracy: 0.6178\n","Epoch 71/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6203 - accuracy: 0.6530 - val_loss: 0.6757 - val_accuracy: 0.6157\n","Epoch 72/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6193 - accuracy: 0.6525 - val_loss: 0.6748 - val_accuracy: 0.6126\n","Epoch 73/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6171 - accuracy: 0.6584 - val_loss: 0.6727 - val_accuracy: 0.6240\n","Epoch 74/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6125 - accuracy: 0.6610 - val_loss: 0.6763 - val_accuracy: 0.6085\n","Epoch 75/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6131 - accuracy: 0.6579 - val_loss: 0.6767 - val_accuracy: 0.6064\n","Epoch 76/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6104 - accuracy: 0.6654 - val_loss: 0.6763 - val_accuracy: 0.6260\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6106 - accuracy: 0.6610 - val_loss: 0.6758 - val_accuracy: 0.6105\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6071 - accuracy: 0.6703 - val_loss: 0.6780 - val_accuracy: 0.6054\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6061 - accuracy: 0.6695 - val_loss: 0.6777 - val_accuracy: 0.6116\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6032 - accuracy: 0.6752 - val_loss: 0.6791 - val_accuracy: 0.6074\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6039 - accuracy: 0.6747 - val_loss: 0.6795 - val_accuracy: 0.6188\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5999 - accuracy: 0.6824 - val_loss: 0.6787 - val_accuracy: 0.6157\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5982 - accuracy: 0.6806 - val_loss: 0.6812 - val_accuracy: 0.6147\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5992 - accuracy: 0.6801 - val_loss: 0.6789 - val_accuracy: 0.6157\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5946 - accuracy: 0.6827 - val_loss: 0.6792 - val_accuracy: 0.6136\n","Epoch 86/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5906 - accuracy: 0.6879 - val_loss: 0.6799 - val_accuracy: 0.6105\n","Epoch 87/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5902 - accuracy: 0.6842 - val_loss: 0.6890 - val_accuracy: 0.6157\n","Epoch 88/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5862 - accuracy: 0.6863 - val_loss: 0.6907 - val_accuracy: 0.6085\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5863 - accuracy: 0.6943 - val_loss: 0.6865 - val_accuracy: 0.6105\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5812 - accuracy: 0.6995 - val_loss: 0.6891 - val_accuracy: 0.6209\n","Epoch 91/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5754 - accuracy: 0.7049 - val_loss: 0.6899 - val_accuracy: 0.6178\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5750 - accuracy: 0.6979 - val_loss: 0.6920 - val_accuracy: 0.6188\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5733 - accuracy: 0.7000 - val_loss: 0.6922 - val_accuracy: 0.6085\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5710 - accuracy: 0.7044 - val_loss: 0.6943 - val_accuracy: 0.6147\n","Epoch 95/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5701 - accuracy: 0.7085 - val_loss: 0.7103 - val_accuracy: 0.6157\n","Epoch 96/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.5736 - accuracy: 0.7054 - val_loss: 0.6973 - val_accuracy: 0.6147\n","Epoch 97/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.5652 - accuracy: 0.7085 - val_loss: 0.6984 - val_accuracy: 0.6085\n","Epoch 98/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5647 - accuracy: 0.7090 - val_loss: 0.6996 - val_accuracy: 0.6136\n","Epoch 99/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5584 - accuracy: 0.7152 - val_loss: 0.7026 - val_accuracy: 0.6167\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5618 - accuracy: 0.7111 - val_loss: 0.7037 - val_accuracy: 0.6157\n","{'loss': [0.6931872367858887, 0.6929587721824646, 0.692670464515686, 0.692133367061615, 0.6912736296653748, 0.6897867321968079, 0.6877401471138, 0.6853368282318115, 0.6831469535827637, 0.682276725769043, 0.6817483305931091, 0.6808300614356995, 0.680660605430603, 0.6798635125160217, 0.6793409585952759, 0.6786983013153076, 0.6780874729156494, 0.6773080825805664, 0.6763695478439331, 0.6750830411911011, 0.6738957762718201, 0.6719638109207153, 0.6703746318817139, 0.6684215068817139, 0.6659343838691711, 0.6637137532234192, 0.6631407141685486, 0.6615384221076965, 0.6595215201377869, 0.6593871712684631, 0.656762957572937, 0.6569645404815674, 0.6550263166427612, 0.653562068939209, 0.6542803645133972, 0.6514567732810974, 0.6513757109642029, 0.6506089568138123, 0.6488627195358276, 0.6503342390060425, 0.6482228636741638, 0.6473960876464844, 0.6466534733772278, 0.6458852291107178, 0.6447230577468872, 0.6450287699699402, 0.6432778239250183, 0.6421565413475037, 0.6426655650138855, 0.6424763202667236, 0.6427998542785645, 0.6400139331817627, 0.6379784941673279, 0.6370306015014648, 0.6391289830207825, 0.6367822885513306, 0.6339166164398193, 0.6337618827819824, 0.6336314082145691, 0.6309330463409424, 0.6311399340629578, 0.6291915774345398, 0.6277868747711182, 0.6304539442062378, 0.6270259618759155, 0.6263677477836609, 0.6243809461593628, 0.6218460202217102, 0.6231579780578613, 0.6215813755989075, 0.620259165763855, 0.6193059682846069, 0.6171361207962036, 0.6125337481498718, 0.6130874156951904, 0.6104317903518677, 0.610552966594696, 0.6071305871009827, 0.6061265468597412, 0.6032209396362305, 0.6039494276046753, 0.5998587608337402, 0.5981717705726624, 0.5992106795310974, 0.5945782661437988, 0.590556263923645, 0.590154230594635, 0.5861873030662537, 0.5862635374069214, 0.5812033414840698, 0.5753795504570007, 0.5749653577804565, 0.5732815861701965, 0.5710116028785706, 0.5701117515563965, 0.573555052280426, 0.5652331113815308, 0.5646928548812866, 0.5583991408348083, 0.5618427991867065], 'accuracy': [0.5103359222412109, 0.5692506432533264, 0.564082682132721, 0.564082682132721, 0.5692506432533264, 0.5713178515434265, 0.5666666626930237, 0.565891444683075, 0.564082682132721, 0.565116286277771, 0.5718346238136292, 0.5780361890792847, 0.5749353766441345, 0.5762273669242859, 0.5795865654945374, 0.5785529613494873, 0.5795865654945374, 0.5813953280448914, 0.5788113474845886, 0.5852712988853455, 0.5870801210403442, 0.5888888835906982, 0.5927648544311523, 0.6012920141220093, 0.6010335683822632, 0.6049095392227173, 0.6105943322181702, 0.6108527183532715, 0.6100775003433228, 0.6067183613777161, 0.6167958378791809, 0.6121447086334229, 0.6124030947685242, 0.6173126697540283, 0.6139534711837769, 0.6147286891937256, 0.6193798184394836, 0.617054283618927, 0.6253229975700378, 0.620671808719635, 0.6201550364494324, 0.6235142350196838, 0.6240310072898865, 0.6255813837051392, 0.631266176700592, 0.6268733739852905, 0.6286821961402893, 0.6299741864204407, 0.6307493448257446, 0.6286821961402893, 0.6253229975700378, 0.6315245628356934, 0.6338501572608948, 0.6372092962265015, 0.6343669295310974, 0.6335917115211487, 0.6403100490570068, 0.6441860198974609, 0.6426356434822083, 0.643410861492157, 0.644444465637207, 0.6439276337623596, 0.6441860198974609, 0.6400516629219055, 0.6503875851631165, 0.6475452184677124, 0.6498708128929138, 0.6555555462837219, 0.6516795754432678, 0.6524547934532166, 0.6529715657234192, 0.6524547934532166, 0.658397912979126, 0.6609818935394287, 0.6578811407089233, 0.6653746962547302, 0.6609818935394287, 0.6702842116355896, 0.6695090532302856, 0.6751937866210938, 0.6746770143508911, 0.6824289560317993, 0.6806201338768005, 0.6801033616065979, 0.6826873421669006, 0.6878553032875061, 0.6842377185821533, 0.6863049268722534, 0.6943152546882629, 0.6994832158088684, 0.7049095630645752, 0.6979328393936157, 0.699999988079071, 0.7043927907943726, 0.708527147769928, 0.7054263353347778, 0.708527147769928, 0.7090439200401306, 0.7152454853057861, 0.7111111283302307], 'val_loss': [0.6931337714195251, 0.6931148171424866, 0.6930850744247437, 0.6930204629898071, 0.6929179430007935, 0.6927165985107422, 0.6923851370811462, 0.6918498277664185, 0.6911590099334717, 0.6906700730323792, 0.6902711391448975, 0.6897936463356018, 0.6890856027603149, 0.6887400150299072, 0.6881505250930786, 0.6872886419296265, 0.6864587664604187, 0.6856911182403564, 0.6848593354225159, 0.6838436722755432, 0.682727038860321, 0.6813948154449463, 0.6798086166381836, 0.6781921982765198, 0.6770586967468262, 0.6760883331298828, 0.6771422028541565, 0.6740221381187439, 0.6752789616584778, 0.6734814047813416, 0.6734381318092346, 0.6736679077148438, 0.6714665293693542, 0.6723676323890686, 0.6697089672088623, 0.6735454797744751, 0.6714716553688049, 0.6708508729934692, 0.6693231463432312, 0.6729090213775635, 0.6742855906486511, 0.6694669723510742, 0.6719328165054321, 0.6717252731323242, 0.6710262298583984, 0.6724853515625, 0.6695317625999451, 0.6742236614227295, 0.6704331040382385, 0.6706271171569824, 0.671700119972229, 0.6738350987434387, 0.6701569557189941, 0.672103226184845, 0.6711405515670776, 0.6713090538978577, 0.6703622341156006, 0.6729101538658142, 0.6723008155822754, 0.6746904253959656, 0.6746694445610046, 0.6730670928955078, 0.6739324331283569, 0.6729097366333008, 0.6717620491981506, 0.672792911529541, 0.673335611820221, 0.6706008315086365, 0.67341548204422, 0.6750102043151855, 0.6756589412689209, 0.6747909784317017, 0.6726688146591187, 0.6762619614601135, 0.6766840815544128, 0.676287055015564, 0.6757971048355103, 0.677955150604248, 0.6777493953704834, 0.6790937781333923, 0.6795271039009094, 0.6787055730819702, 0.6811917424201965, 0.6788665056228638, 0.679205060005188, 0.6799229383468628, 0.6889887452125549, 0.6907467246055603, 0.6864508986473083, 0.6890574097633362, 0.6899401545524597, 0.6919703483581543, 0.692241370677948, 0.6942604184150696, 0.7103150486946106, 0.6972874402999878, 0.6983507871627808, 0.6995835304260254, 0.7026131749153137, 0.703729510307312], 'val_accuracy': [0.51962810754776, 0.5185950398445129, 0.51962810754776, 0.5185950398445129, 0.5330578684806824, 0.538223147392273, 0.5526859760284424, 0.5650826692581177, 0.577479362487793, 0.5764462947845459, 0.5754132270812988, 0.5754132270812988, 0.5785123705863953, 0.5764462947845459, 0.5764462947845459, 0.5847107172012329, 0.5909090638160706, 0.586776852607727, 0.5836777091026306, 0.58574378490448, 0.58574378490448, 0.5898760557174683, 0.58574378490448, 0.5826446413993835, 0.5836777091026306, 0.5878099203109741, 0.5898760557174683, 0.5909090638160706, 0.58574378490448, 0.5909090638160706, 0.5919421315193176, 0.5919421315193176, 0.5919421315193176, 0.5940082669258118, 0.5898760557174683, 0.5919421315193176, 0.5971074104309082, 0.5971074104309082, 0.5981404781341553, 0.5971074104309082, 0.6022727489471436, 0.5960744023323059, 0.6022727489471436, 0.5960744023323059, 0.5991735458374023, 0.5981404781341553, 0.6002066135406494, 0.6002066135406494, 0.6002066135406494, 0.6002066135406494, 0.6022727489471436, 0.60537189245224, 0.6022727489471436, 0.6043388247489929, 0.6074380278587341, 0.6064049601554871, 0.6084710955619812, 0.60537189245224, 0.6105371713638306, 0.6064049601554871, 0.60537189245224, 0.6095041036605835, 0.6136363744735718, 0.6157024502754211, 0.6146694421768188, 0.6188016533851624, 0.6188016533851624, 0.6177685856819153, 0.6260330677032471, 0.6177685856819153, 0.6157024502754211, 0.6126033067703247, 0.6239669322967529, 0.6084710955619812, 0.6064049601554871, 0.6260330677032471, 0.6105371713638306, 0.60537189245224, 0.6115702390670776, 0.6074380278587341, 0.6188016533851624, 0.6157024502754211, 0.6146694421768188, 0.6157024502754211, 0.6136363744735718, 0.6105371713638306, 0.6157024502754211, 0.6084710955619812, 0.6105371713638306, 0.6208677887916565, 0.6177685856819153, 0.6188016533851624, 0.6084710955619812, 0.6146694421768188, 0.6157024502754211, 0.6146694421768188, 0.6084710955619812, 0.6136363744735718, 0.6167355179786682, 0.6157024502754211]}\n","32/32 [==============================] - 1s 9ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/29 [========================>.....] - ETA: 0s - loss: 0.6286 - accuracy: 0.6541"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 59ms/step - loss: 0.6264 - accuracy: 0.6600 - val_loss: 0.6893 - val_accuracy: 0.5237\n","Epoch 2/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6131 - accuracy: 0.6765 - val_loss: 0.6911 - val_accuracy: 0.5205\n","Epoch 3/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6039 - accuracy: 0.6808 - val_loss: 0.6908 - val_accuracy: 0.5248\n","Epoch 4/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6053 - accuracy: 0.6783 - val_loss: 0.6887 - val_accuracy: 0.5259\n","Epoch 5/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.6017 - accuracy: 0.6829 - val_loss: 0.6868 - val_accuracy: 0.5302\n","Epoch 6/100\n","29/29 [==============================] - 1s 48ms/step - loss: 0.6015 - accuracy: 0.6883 - val_loss: 0.6825 - val_accuracy: 0.5377\n","Epoch 7/100\n","29/29 [==============================] - 1s 38ms/step - loss: 0.5985 - accuracy: 0.6800 - val_loss: 0.6810 - val_accuracy: 0.5399\n","Epoch 8/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5966 - accuracy: 0.6888 - val_loss: 0.6812 - val_accuracy: 0.5399\n","Epoch 9/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.5975 - accuracy: 0.6818 - val_loss: 0.6764 - val_accuracy: 0.5528\n","Epoch 10/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.5938 - accuracy: 0.6864 - val_loss: 0.6763 - val_accuracy: 0.5550\n","Epoch 11/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5893 - accuracy: 0.6918 - val_loss: 0.6749 - val_accuracy: 0.5550\n","Epoch 12/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.5865 - accuracy: 0.6899 - val_loss: 0.6635 - val_accuracy: 0.5841\n","Epoch 13/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.5902 - accuracy: 0.6875 - val_loss: 0.6547 - val_accuracy: 0.6153\n","Epoch 14/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5859 - accuracy: 0.6948 - val_loss: 0.6521 - val_accuracy: 0.6078\n","Epoch 15/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5826 - accuracy: 0.6953 - val_loss: 0.6566 - val_accuracy: 0.5981\n","Epoch 16/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5853 - accuracy: 0.6926 - val_loss: 0.6497 - val_accuracy: 0.6099\n","Epoch 17/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.5770 - accuracy: 0.6994 - val_loss: 0.6393 - val_accuracy: 0.6315\n","Epoch 18/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5802 - accuracy: 0.6937 - val_loss: 0.6311 - val_accuracy: 0.6519\n","Epoch 19/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5700 - accuracy: 0.7023 - val_loss: 0.6292 - val_accuracy: 0.6487\n","Epoch 20/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5706 - accuracy: 0.6996 - val_loss: 0.6236 - val_accuracy: 0.6552\n","Epoch 21/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5755 - accuracy: 0.6956 - val_loss: 0.6250 - val_accuracy: 0.6509\n","Epoch 22/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5694 - accuracy: 0.7012 - val_loss: 0.6191 - val_accuracy: 0.6498\n","Epoch 23/100\n","29/29 [==============================] - 1s 45ms/step - loss: 0.5663 - accuracy: 0.7053 - val_loss: 0.6161 - val_accuracy: 0.6638\n","Epoch 24/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5641 - accuracy: 0.7080 - val_loss: 0.6162 - val_accuracy: 0.6562\n","Epoch 25/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5586 - accuracy: 0.7128 - val_loss: 0.6164 - val_accuracy: 0.6519\n","Epoch 26/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5592 - accuracy: 0.7107 - val_loss: 0.6152 - val_accuracy: 0.6573\n","Epoch 27/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5605 - accuracy: 0.7134 - val_loss: 0.6154 - val_accuracy: 0.6541\n","Epoch 28/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5552 - accuracy: 0.7134 - val_loss: 0.6143 - val_accuracy: 0.6595\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5494 - accuracy: 0.7206 - val_loss: 0.6209 - val_accuracy: 0.6466\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5513 - accuracy: 0.7152 - val_loss: 0.6181 - val_accuracy: 0.6562\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5499 - accuracy: 0.7139 - val_loss: 0.6190 - val_accuracy: 0.6562\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5485 - accuracy: 0.7185 - val_loss: 0.6192 - val_accuracy: 0.6562\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5429 - accuracy: 0.7244 - val_loss: 0.6204 - val_accuracy: 0.6552\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5407 - accuracy: 0.7241 - val_loss: 0.6210 - val_accuracy: 0.6498\n","Epoch 35/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5395 - accuracy: 0.7258 - val_loss: 0.6256 - val_accuracy: 0.6487\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5443 - accuracy: 0.7249 - val_loss: 0.6220 - val_accuracy: 0.6519\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5350 - accuracy: 0.7266 - val_loss: 0.6241 - val_accuracy: 0.6519\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5303 - accuracy: 0.7376 - val_loss: 0.6304 - val_accuracy: 0.6595\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5321 - accuracy: 0.7293 - val_loss: 0.6286 - val_accuracy: 0.6476\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5309 - accuracy: 0.7309 - val_loss: 0.6239 - val_accuracy: 0.6552\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5288 - accuracy: 0.7333 - val_loss: 0.6263 - val_accuracy: 0.6530\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5285 - accuracy: 0.7338 - val_loss: 0.6315 - val_accuracy: 0.6541\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5249 - accuracy: 0.7352 - val_loss: 0.6309 - val_accuracy: 0.6595\n","Epoch 44/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5234 - accuracy: 0.7341 - val_loss: 0.6316 - val_accuracy: 0.6562\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5214 - accuracy: 0.7395 - val_loss: 0.6359 - val_accuracy: 0.6616\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5218 - accuracy: 0.7430 - val_loss: 0.6371 - val_accuracy: 0.6616\n","Epoch 47/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5177 - accuracy: 0.7395 - val_loss: 0.6342 - val_accuracy: 0.6530\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5101 - accuracy: 0.7435 - val_loss: 0.6367 - val_accuracy: 0.6584\n","Epoch 49/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5130 - accuracy: 0.7419 - val_loss: 0.6364 - val_accuracy: 0.6498\n","Epoch 50/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5083 - accuracy: 0.7457 - val_loss: 0.6385 - val_accuracy: 0.6659\n","Epoch 51/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5038 - accuracy: 0.7503 - val_loss: 0.6418 - val_accuracy: 0.6530\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5096 - accuracy: 0.7484 - val_loss: 0.6423 - val_accuracy: 0.6552\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5045 - accuracy: 0.7481 - val_loss: 0.6411 - val_accuracy: 0.6638\n","Epoch 54/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5031 - accuracy: 0.7516 - val_loss: 0.6490 - val_accuracy: 0.6541\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4998 - accuracy: 0.7513 - val_loss: 0.6450 - val_accuracy: 0.6498\n","Epoch 56/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4974 - accuracy: 0.7592 - val_loss: 0.6477 - val_accuracy: 0.6713\n","Epoch 57/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4961 - accuracy: 0.7540 - val_loss: 0.6468 - val_accuracy: 0.6670\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4943 - accuracy: 0.7575 - val_loss: 0.6493 - val_accuracy: 0.6638\n","Epoch 59/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4944 - accuracy: 0.7532 - val_loss: 0.6537 - val_accuracy: 0.6627\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4888 - accuracy: 0.7594 - val_loss: 0.6492 - val_accuracy: 0.6649\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4913 - accuracy: 0.7621 - val_loss: 0.6560 - val_accuracy: 0.6606\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4826 - accuracy: 0.7643 - val_loss: 0.6541 - val_accuracy: 0.6638\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4791 - accuracy: 0.7707 - val_loss: 0.6648 - val_accuracy: 0.6681\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4858 - accuracy: 0.7627 - val_loss: 0.6606 - val_accuracy: 0.6638\n","Epoch 65/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4786 - accuracy: 0.7670 - val_loss: 0.6662 - val_accuracy: 0.6746\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4840 - accuracy: 0.7632 - val_loss: 0.6579 - val_accuracy: 0.6649\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4805 - accuracy: 0.7610 - val_loss: 0.6539 - val_accuracy: 0.6659\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4800 - accuracy: 0.7699 - val_loss: 0.6647 - val_accuracy: 0.6627\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4738 - accuracy: 0.7705 - val_loss: 0.6657 - val_accuracy: 0.6703\n","Epoch 70/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4731 - accuracy: 0.7732 - val_loss: 0.6734 - val_accuracy: 0.6659\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4696 - accuracy: 0.7745 - val_loss: 0.6693 - val_accuracy: 0.6670\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4628 - accuracy: 0.7721 - val_loss: 0.6737 - val_accuracy: 0.6659\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4664 - accuracy: 0.7753 - val_loss: 0.6723 - val_accuracy: 0.6692\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4621 - accuracy: 0.7753 - val_loss: 0.6785 - val_accuracy: 0.6616\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4656 - accuracy: 0.7761 - val_loss: 0.6742 - val_accuracy: 0.6659\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4594 - accuracy: 0.7837 - val_loss: 0.6988 - val_accuracy: 0.6724\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4652 - accuracy: 0.7702 - val_loss: 0.6834 - val_accuracy: 0.6530\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4562 - accuracy: 0.7826 - val_loss: 0.6840 - val_accuracy: 0.6595\n","Epoch 79/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4527 - accuracy: 0.7794 - val_loss: 0.6802 - val_accuracy: 0.6616\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4497 - accuracy: 0.7861 - val_loss: 0.6837 - val_accuracy: 0.6649\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4468 - accuracy: 0.7834 - val_loss: 0.6859 - val_accuracy: 0.6595\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4534 - accuracy: 0.7818 - val_loss: 0.7024 - val_accuracy: 0.6670\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4510 - accuracy: 0.7759 - val_loss: 0.6973 - val_accuracy: 0.6692\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4460 - accuracy: 0.7850 - val_loss: 0.6954 - val_accuracy: 0.6627\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4496 - accuracy: 0.7821 - val_loss: 0.7176 - val_accuracy: 0.6659\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4476 - accuracy: 0.7866 - val_loss: 0.6912 - val_accuracy: 0.6659\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4429 - accuracy: 0.7950 - val_loss: 0.7023 - val_accuracy: 0.6703\n","Epoch 88/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4372 - accuracy: 0.7885 - val_loss: 0.6992 - val_accuracy: 0.6638\n","Epoch 89/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4354 - accuracy: 0.8009 - val_loss: 0.6958 - val_accuracy: 0.6616\n","Epoch 90/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4319 - accuracy: 0.7990 - val_loss: 0.7031 - val_accuracy: 0.6659\n","Epoch 91/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4301 - accuracy: 0.7980 - val_loss: 0.7036 - val_accuracy: 0.6638\n","Epoch 92/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4245 - accuracy: 0.8036 - val_loss: 0.7203 - val_accuracy: 0.6670\n","Epoch 93/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4246 - accuracy: 0.8009 - val_loss: 0.7105 - val_accuracy: 0.6692\n","Epoch 94/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4242 - accuracy: 0.8017 - val_loss: 0.7264 - val_accuracy: 0.6616\n","Epoch 95/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4233 - accuracy: 0.8074 - val_loss: 0.7201 - val_accuracy: 0.6735\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4281 - accuracy: 0.7926 - val_loss: 0.7396 - val_accuracy: 0.6444\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4295 - accuracy: 0.7996 - val_loss: 0.7144 - val_accuracy: 0.6659\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4231 - accuracy: 0.8036 - val_loss: 0.7214 - val_accuracy: 0.6649\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4191 - accuracy: 0.8031 - val_loss: 0.7248 - val_accuracy: 0.6606\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4131 - accuracy: 0.8147 - val_loss: 0.7378 - val_accuracy: 0.6638\n","{'loss': [0.6263988614082336, 0.613054633140564, 0.6038544774055481, 0.6052511930465698, 0.6016851663589478, 0.6014634370803833, 0.598480224609375, 0.5966160893440247, 0.5974822044372559, 0.5938466787338257, 0.5893075466156006, 0.5864745378494263, 0.5901921987533569, 0.5859296321868896, 0.5826210975646973, 0.5852726697921753, 0.5769578814506531, 0.5801742672920227, 0.5699894428253174, 0.5705851912498474, 0.5755367875099182, 0.5693511366844177, 0.566277265548706, 0.5641162395477295, 0.5586084127426147, 0.559211254119873, 0.5604681968688965, 0.5551753044128418, 0.5494170188903809, 0.5512823462486267, 0.549891471862793, 0.5484556555747986, 0.5429330468177795, 0.5406739711761475, 0.539467453956604, 0.5443168878555298, 0.535042405128479, 0.530278205871582, 0.5321238040924072, 0.5308947563171387, 0.5288122296333313, 0.5285148024559021, 0.5248532891273499, 0.523419976234436, 0.5213918089866638, 0.5217510461807251, 0.5176838040351868, 0.5101127028465271, 0.513034462928772, 0.5082724094390869, 0.5037699341773987, 0.509564995765686, 0.5045117139816284, 0.5031293034553528, 0.4997952878475189, 0.4974037706851959, 0.49613893032073975, 0.49430376291275024, 0.49439436197280884, 0.4887843728065491, 0.4913341999053955, 0.4825572967529297, 0.47911763191223145, 0.485800176858902, 0.47859370708465576, 0.48404738306999207, 0.48053741455078125, 0.47998639941215515, 0.4738476872444153, 0.47305116057395935, 0.469618558883667, 0.4627510905265808, 0.46638020873069763, 0.46206262707710266, 0.4656292498111725, 0.45941030979156494, 0.46523317694664, 0.456243634223938, 0.4526696503162384, 0.4496597349643707, 0.44684484601020813, 0.4533616304397583, 0.45102354884147644, 0.44599130749702454, 0.44957637786865234, 0.44755977392196655, 0.44289037585258484, 0.4372390806674957, 0.4353984594345093, 0.431892454624176, 0.4301436245441437, 0.42453640699386597, 0.424550324678421, 0.42416754364967346, 0.42325612902641296, 0.42806217074394226, 0.4294985830783844, 0.4230714440345764, 0.4190814197063446, 0.4131334125995636], 'accuracy': [0.6600215435028076, 0.6764547228813171, 0.6807650923728943, 0.678340494632721, 0.6829202771186829, 0.6883081793785095, 0.6799569129943848, 0.688847005367279, 0.6818426847457886, 0.6864224076271057, 0.6918103694915771, 0.6899245977401733, 0.6875, 0.6947737336158752, 0.6953125, 0.6926185488700867, 0.6993534564971924, 0.693696141242981, 0.7023168206214905, 0.6996228694915771, 0.6955819129943848, 0.7012392282485962, 0.7052801847457886, 0.7079741358757019, 0.7128232717514038, 0.7106680870056152, 0.7133620977401733, 0.7133620977401733, 0.7206357717514038, 0.7152478694915771, 0.7139008641242981, 0.7184805870056152, 0.7244073152542114, 0.7241379022598267, 0.7257543206214905, 0.724946141242981, 0.7265625, 0.7376077771186829, 0.7292564511299133, 0.7308728694915771, 0.7332974076271057, 0.7338362336158752, 0.7351831793785095, 0.7341055870056152, 0.7394935488700867, 0.7429956793785095, 0.7394935488700867, 0.743534505367279, 0.7419180870056152, 0.7456896305084229, 0.7502694129943848, 0.748383641242981, 0.7481142282485962, 0.751616358757019, 0.751347005367279, 0.759159505367279, 0.7540409564971924, 0.7575430870056152, 0.7532327771186829, 0.759428858757019, 0.7621228694915771, 0.764277994632721, 0.7707435488700867, 0.7626616358757019, 0.766972005367279, 0.7632004022598267, 0.7610452771186829, 0.7699353694915771, 0.7704741358757019, 0.7731680870056152, 0.7745150923728943, 0.772090494632721, 0.7753232717514038, 0.7753232717514038, 0.7761314511299133, 0.7836745977401733, 0.7702047228813171, 0.782597005367279, 0.7793642282485962, 0.7860991358757019, 0.7834051847457886, 0.7817887663841248, 0.7758620977401733, 0.7850215435028076, 0.7820581793785095, 0.7866379022598267, 0.7949892282485962, 0.7885237336158752, 0.8009159564971924, 0.7990301847457886, 0.7979525923728943, 0.8036099076271057, 0.8009159564971924, 0.8017241358757019, 0.8073814511299133, 0.7925646305084229, 0.7995689511299133, 0.8036099076271057, 0.803071141242981, 0.8146551847457886], 'val_loss': [0.6892597079277039, 0.6911451816558838, 0.6908056735992432, 0.688735842704773, 0.6868385672569275, 0.6824532747268677, 0.6810494661331177, 0.6812218427658081, 0.6764134168624878, 0.6762604117393494, 0.6748824715614319, 0.6635436415672302, 0.65470951795578, 0.6521391272544861, 0.6565665602684021, 0.6497117280960083, 0.6392877101898193, 0.6310857534408569, 0.6291723847389221, 0.6235658526420593, 0.6250211596488953, 0.6190958619117737, 0.6160908341407776, 0.6162165999412537, 0.6164146065711975, 0.6151801943778992, 0.6153613924980164, 0.6142637133598328, 0.6209189891815186, 0.6180539131164551, 0.619003176689148, 0.6191814541816711, 0.620430588722229, 0.620985746383667, 0.6255534887313843, 0.6220136284828186, 0.6241246461868286, 0.6304413080215454, 0.6285760998725891, 0.6238765120506287, 0.6263340711593628, 0.6315147876739502, 0.6309431791305542, 0.6315884590148926, 0.6358586549758911, 0.6370512247085571, 0.6342059373855591, 0.6366502046585083, 0.6364364624023438, 0.6384619474411011, 0.6417954564094543, 0.6422544717788696, 0.6411176919937134, 0.649046003818512, 0.6449698209762573, 0.6476667523384094, 0.6468309164047241, 0.6492671966552734, 0.6537352800369263, 0.6491805911064148, 0.6560325026512146, 0.6541402339935303, 0.6647657752037048, 0.6606030464172363, 0.6661561131477356, 0.6578890681266785, 0.653949499130249, 0.6647123098373413, 0.6656877994537354, 0.6734087467193604, 0.6692845821380615, 0.6737068295478821, 0.6722725629806519, 0.6784883141517639, 0.6741710305213928, 0.698779284954071, 0.6833676099777222, 0.6839586496353149, 0.6802085638046265, 0.6836962103843689, 0.6858786344528198, 0.7024102210998535, 0.6972728371620178, 0.6954307556152344, 0.7175861597061157, 0.6912357211112976, 0.7022884488105774, 0.6991967558860779, 0.6957605481147766, 0.7031280994415283, 0.7035952806472778, 0.7202582359313965, 0.7105469107627869, 0.726366400718689, 0.7201000452041626, 0.7396210432052612, 0.7144056558609009, 0.7214323878288269, 0.724846601486206, 0.7378244996070862], 'val_accuracy': [0.5237069129943848, 0.5204741358757019, 0.524784505367279, 0.5258620977401733, 0.5301724076271057, 0.537715494632721, 0.5398706793785095, 0.5398706793785095, 0.5528017282485962, 0.5549569129943848, 0.5549569129943848, 0.5840517282485962, 0.6153017282485962, 0.607758641242981, 0.5980603694915771, 0.6099137663841248, 0.631465494632721, 0.6519396305084229, 0.6487069129943848, 0.6551724076271057, 0.6508620977401733, 0.649784505367279, 0.6637930870056152, 0.65625, 0.6519396305084229, 0.6573275923728943, 0.6540948152542114, 0.6594827771186829, 0.6465517282485962, 0.65625, 0.65625, 0.65625, 0.6551724076271057, 0.649784505367279, 0.6487069129943848, 0.6519396305084229, 0.6519396305084229, 0.6594827771186829, 0.6476293206214905, 0.6551724076271057, 0.6530172228813171, 0.6540948152542114, 0.6594827771186829, 0.65625, 0.6616379022598267, 0.6616379022598267, 0.6530172228813171, 0.6584051847457886, 0.649784505367279, 0.6659482717514038, 0.6530172228813171, 0.6551724076271057, 0.6637930870056152, 0.6540948152542114, 0.649784505367279, 0.6713362336158752, 0.6670258641242981, 0.6637930870056152, 0.662715494632721, 0.6648706793785095, 0.6605603694915771, 0.6637930870056152, 0.6681034564971924, 0.6637930870056152, 0.6745689511299133, 0.6648706793785095, 0.6659482717514038, 0.662715494632721, 0.670258641242981, 0.6659482717514038, 0.6670258641242981, 0.6659482717514038, 0.6691810488700867, 0.6616379022598267, 0.6659482717514038, 0.6724137663841248, 0.6530172228813171, 0.6594827771186829, 0.6616379022598267, 0.6648706793785095, 0.6594827771186829, 0.6670258641242981, 0.6691810488700867, 0.662715494632721, 0.6659482717514038, 0.6659482717514038, 0.670258641242981, 0.6637930870056152, 0.6616379022598267, 0.6659482717514038, 0.6637930870056152, 0.6670258641242981, 0.6691810488700867, 0.6616379022598267, 0.673491358757019, 0.6443965435028076, 0.6659482717514038, 0.6648706793785095, 0.6605603694915771, 0.6637930870056152]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.6315 - accuracy: 0.6384"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 53ms/step - loss: 0.6305 - accuracy: 0.6401 - val_loss: 0.6932 - val_accuracy: 0.5057\n","Epoch 2/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6172 - accuracy: 0.6616 - val_loss: 0.6932 - val_accuracy: 0.5057\n","Epoch 3/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6144 - accuracy: 0.6573 - val_loss: 0.6958 - val_accuracy: 0.5057\n","Epoch 4/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6093 - accuracy: 0.6701 - val_loss: 0.6924 - val_accuracy: 0.5079\n","Epoch 5/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6093 - accuracy: 0.6672 - val_loss: 0.6930 - val_accuracy: 0.5079\n","Epoch 6/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6075 - accuracy: 0.6692 - val_loss: 0.6905 - val_accuracy: 0.5147\n","Epoch 7/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6031 - accuracy: 0.6743 - val_loss: 0.6890 - val_accuracy: 0.5181\n","Epoch 8/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6039 - accuracy: 0.6735 - val_loss: 0.6867 - val_accuracy: 0.5271\n","Epoch 9/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5965 - accuracy: 0.6791 - val_loss: 0.6841 - val_accuracy: 0.5419\n","Epoch 10/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.5957 - accuracy: 0.6822 - val_loss: 0.6782 - val_accuracy: 0.5554\n","Epoch 11/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5954 - accuracy: 0.6834 - val_loss: 0.6757 - val_accuracy: 0.5611\n","Epoch 12/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5966 - accuracy: 0.6788 - val_loss: 0.6765 - val_accuracy: 0.5566\n","Epoch 13/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5940 - accuracy: 0.6766 - val_loss: 0.6710 - val_accuracy: 0.5803\n","Epoch 14/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5884 - accuracy: 0.6839 - val_loss: 0.6619 - val_accuracy: 0.6063\n","Epoch 15/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5871 - accuracy: 0.6836 - val_loss: 0.6647 - val_accuracy: 0.5950\n","Epoch 16/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5864 - accuracy: 0.6822 - val_loss: 0.6650 - val_accuracy: 0.5950\n","Epoch 17/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5837 - accuracy: 0.6885 - val_loss: 0.6673 - val_accuracy: 0.5894\n","Epoch 18/100\n","28/28 [==============================] - 1s 41ms/step - loss: 0.5789 - accuracy: 0.6921 - val_loss: 0.6524 - val_accuracy: 0.6199\n","Epoch 19/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.5768 - accuracy: 0.6984 - val_loss: 0.6476 - val_accuracy: 0.6448\n","Epoch 20/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5765 - accuracy: 0.6924 - val_loss: 0.6522 - val_accuracy: 0.6176\n","Epoch 21/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.5718 - accuracy: 0.7046 - val_loss: 0.6366 - val_accuracy: 0.6538\n","Epoch 22/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5738 - accuracy: 0.6952 - val_loss: 0.6408 - val_accuracy: 0.6471\n","Epoch 23/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5717 - accuracy: 0.6964 - val_loss: 0.6360 - val_accuracy: 0.6505\n","Epoch 24/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5691 - accuracy: 0.7043 - val_loss: 0.6327 - val_accuracy: 0.6640\n","Epoch 25/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5692 - accuracy: 0.6961 - val_loss: 0.6338 - val_accuracy: 0.6550\n","Epoch 26/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5638 - accuracy: 0.7054 - val_loss: 0.6332 - val_accuracy: 0.6606\n","Epoch 27/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5551 - accuracy: 0.7100 - val_loss: 0.6445 - val_accuracy: 0.6572\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5620 - accuracy: 0.7054 - val_loss: 0.6410 - val_accuracy: 0.6527\n","Epoch 29/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5558 - accuracy: 0.7162 - val_loss: 0.6399 - val_accuracy: 0.6640\n","Epoch 30/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.5574 - accuracy: 0.7125 - val_loss: 0.6368 - val_accuracy: 0.6674\n","Epoch 31/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5529 - accuracy: 0.7142 - val_loss: 0.6454 - val_accuracy: 0.6606\n","Epoch 32/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5540 - accuracy: 0.7131 - val_loss: 0.6405 - val_accuracy: 0.6686\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5478 - accuracy: 0.7142 - val_loss: 0.6449 - val_accuracy: 0.6629\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5477 - accuracy: 0.7119 - val_loss: 0.6485 - val_accuracy: 0.6686\n","Epoch 35/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5446 - accuracy: 0.7199 - val_loss: 0.6462 - val_accuracy: 0.6708\n","Epoch 36/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5412 - accuracy: 0.7114 - val_loss: 0.6490 - val_accuracy: 0.6629\n","Epoch 37/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5404 - accuracy: 0.7224 - val_loss: 0.6519 - val_accuracy: 0.6618\n","Epoch 38/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5383 - accuracy: 0.7216 - val_loss: 0.6537 - val_accuracy: 0.6606\n","Epoch 39/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5337 - accuracy: 0.7264 - val_loss: 0.6587 - val_accuracy: 0.6674\n","Epoch 40/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.5340 - accuracy: 0.7269 - val_loss: 0.6560 - val_accuracy: 0.6538\n","Epoch 41/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.5267 - accuracy: 0.7312 - val_loss: 0.6578 - val_accuracy: 0.6686\n","Epoch 42/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.5307 - accuracy: 0.7267 - val_loss: 0.6687 - val_accuracy: 0.6595\n","Epoch 43/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.5279 - accuracy: 0.7292 - val_loss: 0.6629 - val_accuracy: 0.6686\n","Epoch 44/100\n","28/28 [==============================] - 1s 39ms/step - loss: 0.5284 - accuracy: 0.7275 - val_loss: 0.6651 - val_accuracy: 0.6493\n","Epoch 45/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.5262 - accuracy: 0.7419 - val_loss: 0.6640 - val_accuracy: 0.6640\n","Epoch 46/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.5185 - accuracy: 0.7391 - val_loss: 0.6667 - val_accuracy: 0.6629\n","Epoch 47/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5219 - accuracy: 0.7312 - val_loss: 0.6689 - val_accuracy: 0.6663\n","Epoch 48/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5138 - accuracy: 0.7402 - val_loss: 0.6857 - val_accuracy: 0.6572\n","Epoch 49/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5180 - accuracy: 0.7391 - val_loss: 0.6715 - val_accuracy: 0.6629\n","Epoch 50/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5159 - accuracy: 0.7453 - val_loss: 0.6785 - val_accuracy: 0.6663\n","Epoch 51/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5149 - accuracy: 0.7351 - val_loss: 0.6764 - val_accuracy: 0.6708\n","Epoch 52/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5141 - accuracy: 0.7419 - val_loss: 0.6834 - val_accuracy: 0.6663\n","Epoch 53/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.5099 - accuracy: 0.7414 - val_loss: 0.6744 - val_accuracy: 0.6640\n","Epoch 54/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5067 - accuracy: 0.7470 - val_loss: 0.6843 - val_accuracy: 0.6618\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5080 - accuracy: 0.7422 - val_loss: 0.6862 - val_accuracy: 0.6618\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4991 - accuracy: 0.7510 - val_loss: 0.6843 - val_accuracy: 0.6618\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5031 - accuracy: 0.7476 - val_loss: 0.6901 - val_accuracy: 0.6663\n","Epoch 58/100\n","28/28 [==============================] - 2s 62ms/step - loss: 0.4997 - accuracy: 0.7533 - val_loss: 0.6951 - val_accuracy: 0.6731\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4972 - accuracy: 0.7504 - val_loss: 0.6901 - val_accuracy: 0.6618\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4980 - accuracy: 0.7521 - val_loss: 0.6937 - val_accuracy: 0.6595\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4926 - accuracy: 0.7555 - val_loss: 0.6934 - val_accuracy: 0.6719\n","Epoch 62/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4896 - accuracy: 0.7552 - val_loss: 0.7068 - val_accuracy: 0.6663\n","Epoch 63/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.4941 - accuracy: 0.7513 - val_loss: 0.7063 - val_accuracy: 0.6753\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4906 - accuracy: 0.7572 - val_loss: 0.6940 - val_accuracy: 0.6708\n","Epoch 65/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4946 - accuracy: 0.7496 - val_loss: 0.6971 - val_accuracy: 0.6652\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4900 - accuracy: 0.7521 - val_loss: 0.6986 - val_accuracy: 0.6697\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4851 - accuracy: 0.7634 - val_loss: 0.6985 - val_accuracy: 0.6674\n","Epoch 68/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4864 - accuracy: 0.7589 - val_loss: 0.7020 - val_accuracy: 0.6719\n","Epoch 69/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4811 - accuracy: 0.7705 - val_loss: 0.7032 - val_accuracy: 0.6697\n","Epoch 70/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4805 - accuracy: 0.7643 - val_loss: 0.7135 - val_accuracy: 0.6640\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4766 - accuracy: 0.7736 - val_loss: 0.7122 - val_accuracy: 0.6686\n","Epoch 72/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4761 - accuracy: 0.7697 - val_loss: 0.7093 - val_accuracy: 0.6708\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4724 - accuracy: 0.7697 - val_loss: 0.7072 - val_accuracy: 0.6652\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4668 - accuracy: 0.7801 - val_loss: 0.7184 - val_accuracy: 0.6708\n","Epoch 75/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4698 - accuracy: 0.7813 - val_loss: 0.7255 - val_accuracy: 0.6686\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4679 - accuracy: 0.7714 - val_loss: 0.7361 - val_accuracy: 0.6674\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4652 - accuracy: 0.7685 - val_loss: 0.7509 - val_accuracy: 0.6640\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4634 - accuracy: 0.7728 - val_loss: 0.7400 - val_accuracy: 0.6652\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4615 - accuracy: 0.7748 - val_loss: 0.7453 - val_accuracy: 0.6629\n","Epoch 80/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4622 - accuracy: 0.7776 - val_loss: 0.7300 - val_accuracy: 0.6606\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4558 - accuracy: 0.7793 - val_loss: 0.7361 - val_accuracy: 0.6595\n","Epoch 82/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4611 - accuracy: 0.7739 - val_loss: 0.7485 - val_accuracy: 0.6652\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4515 - accuracy: 0.7878 - val_loss: 0.7494 - val_accuracy: 0.6686\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4483 - accuracy: 0.7940 - val_loss: 0.7317 - val_accuracy: 0.6742\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4527 - accuracy: 0.7787 - val_loss: 0.7375 - val_accuracy: 0.6550\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4469 - accuracy: 0.7886 - val_loss: 0.7495 - val_accuracy: 0.6708\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4443 - accuracy: 0.7898 - val_loss: 0.7684 - val_accuracy: 0.6686\n","Epoch 88/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4487 - accuracy: 0.7762 - val_loss: 0.7497 - val_accuracy: 0.6595\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4499 - accuracy: 0.7830 - val_loss: 0.7429 - val_accuracy: 0.6697\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4469 - accuracy: 0.7929 - val_loss: 0.7378 - val_accuracy: 0.6618\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4415 - accuracy: 0.7909 - val_loss: 0.7524 - val_accuracy: 0.6708\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4413 - accuracy: 0.7912 - val_loss: 0.7519 - val_accuracy: 0.6686\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4366 - accuracy: 0.7940 - val_loss: 0.7582 - val_accuracy: 0.6686\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4355 - accuracy: 0.7900 - val_loss: 0.7683 - val_accuracy: 0.6719\n","Epoch 95/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4351 - accuracy: 0.7934 - val_loss: 0.7763 - val_accuracy: 0.6572\n","Epoch 96/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4365 - accuracy: 0.7875 - val_loss: 0.7612 - val_accuracy: 0.6708\n","Epoch 97/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4314 - accuracy: 0.8002 - val_loss: 0.7717 - val_accuracy: 0.6550\n","Epoch 98/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4328 - accuracy: 0.7903 - val_loss: 0.7870 - val_accuracy: 0.6640\n","Epoch 99/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4295 - accuracy: 0.7999 - val_loss: 0.7707 - val_accuracy: 0.6742\n","Epoch 100/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4267 - accuracy: 0.8022 - val_loss: 0.7728 - val_accuracy: 0.6697\n","{'loss': [0.6304646730422974, 0.6171627044677734, 0.6143673658370972, 0.6093403697013855, 0.6093215942382812, 0.6074652671813965, 0.6031433343887329, 0.603888213634491, 0.5965427756309509, 0.5957366824150085, 0.5953570604324341, 0.59657222032547, 0.5940084457397461, 0.5884365439414978, 0.5871286988258362, 0.5863838195800781, 0.5836812853813171, 0.5789466500282288, 0.5768175721168518, 0.5764948129653931, 0.5717545747756958, 0.5737780928611755, 0.5717207193374634, 0.5690686106681824, 0.5692362189292908, 0.5637866854667664, 0.5550724864006042, 0.5619938373565674, 0.5557506680488586, 0.5574442148208618, 0.5528638958930969, 0.5539661049842834, 0.54780113697052, 0.547704815864563, 0.5446037650108337, 0.5411847233772278, 0.5403741598129272, 0.5383206605911255, 0.5336687564849854, 0.5340442061424255, 0.5266602635383606, 0.5306612849235535, 0.5278953313827515, 0.5284494757652283, 0.5261614918708801, 0.5185359716415405, 0.5219150185585022, 0.5138207674026489, 0.51798415184021, 0.5159071087837219, 0.5149464011192322, 0.5141055583953857, 0.5098579525947571, 0.5066528916358948, 0.5079976320266724, 0.49912112951278687, 0.5030656456947327, 0.49973398447036743, 0.49719056487083435, 0.49795737862586975, 0.4926081597805023, 0.48955127596855164, 0.4940944015979767, 0.49063819646835327, 0.4945603311061859, 0.4899778664112091, 0.4851091802120209, 0.48640206456184387, 0.4810774028301239, 0.48048779368400574, 0.4765886068344116, 0.4761263430118561, 0.4723682403564453, 0.4668116867542267, 0.469775915145874, 0.46787890791893005, 0.4651600122451782, 0.46338361501693726, 0.46151241660118103, 0.4621657431125641, 0.45582008361816406, 0.4611196517944336, 0.4514863193035126, 0.4482933580875397, 0.4527023434638977, 0.44686615467071533, 0.44430986046791077, 0.4487471878528595, 0.44991493225097656, 0.4469090402126312, 0.4415174126625061, 0.44130584597587585, 0.43659842014312744, 0.43545612692832947, 0.4350857138633728, 0.43652084469795227, 0.43136724829673767, 0.43275463581085205, 0.4295210838317871, 0.4267037808895111], 'accuracy': [0.6400679349899292, 0.6615732908248901, 0.6573287844657898, 0.670062243938446, 0.6672325730323792, 0.6692133545875549, 0.6743067502975464, 0.6734578609466553, 0.6791171431541443, 0.68222975730896, 0.6833616495132446, 0.6788341999053955, 0.676570475101471, 0.6839275360107422, 0.6836445927619934, 0.68222975730896, 0.6884549856185913, 0.6921335458755493, 0.6983587741851807, 0.6924165487289429, 0.7045840620994568, 0.695246160030365, 0.6963780522346497, 0.7043010592460632, 0.6960950493812561, 0.7054329514503479, 0.709960401058197, 0.7054329514503479, 0.7161856293678284, 0.7125070691108704, 0.7142048478126526, 0.7130730152130127, 0.7142048478126526, 0.711941123008728, 0.7198641896247864, 0.7113752365112305, 0.7224108576774597, 0.7215619683265686, 0.7263723611831665, 0.7269383072853088, 0.7311828136444092, 0.7266553640365601, 0.7292020320892334, 0.7275042533874512, 0.7419354915618896, 0.7391058206558228, 0.7311828136444092, 0.7402377128601074, 0.7391058206558228, 0.7453310489654541, 0.735144317150116, 0.7419354915618896, 0.7413695454597473, 0.7470288872718811, 0.7422184348106384, 0.7509903907775879, 0.7475947737693787, 0.7532541155815125, 0.7504244446754456, 0.7521222233772278, 0.755517840385437, 0.7552348375320435, 0.7512733340263367, 0.7572156190872192, 0.7495755553245544, 0.7521222233772278, 0.7634408473968506, 0.7589133977890015, 0.7705150246620178, 0.7642897367477417, 0.7736276388168335, 0.7696660757064819, 0.7696660757064819, 0.7801358103752136, 0.7812677025794983, 0.7713639140129089, 0.768534243106842, 0.7727787494659424, 0.7747594714164734, 0.7775891423225403, 0.7792869210243225, 0.7739105820655823, 0.7877758741378784, 0.7940011024475098, 0.7787209749221802, 0.7886247634887695, 0.7897566556930542, 0.7761743068695068, 0.7829654812812805, 0.7928692698478699, 0.7908884882926941, 0.7911714911460876, 0.7940011024475098, 0.790039598941803, 0.7934352159500122, 0.7874929308891296, 0.8002263903617859, 0.7903226017951965, 0.7999433875083923, 0.8022071123123169], 'val_loss': [0.6931923031806946, 0.6932386159896851, 0.6957603096961975, 0.6923911571502686, 0.6930035352706909, 0.6904520988464355, 0.6890093088150024, 0.6866528391838074, 0.6841168999671936, 0.6782358884811401, 0.6756559610366821, 0.6765456199645996, 0.6710166335105896, 0.6619424223899841, 0.6646662354469299, 0.6650211811065674, 0.6673242449760437, 0.6523757576942444, 0.6475523114204407, 0.652249276638031, 0.6365697979927063, 0.6408134698867798, 0.6359622478485107, 0.632745087146759, 0.6338092088699341, 0.6331733465194702, 0.6444516181945801, 0.6410101056098938, 0.6398959159851074, 0.636805534362793, 0.6453607082366943, 0.6404697895050049, 0.6448673605918884, 0.6485424041748047, 0.6461520195007324, 0.6489980220794678, 0.6518764495849609, 0.65374755859375, 0.6586523056030273, 0.6560006141662598, 0.6577849388122559, 0.668720006942749, 0.6628571152687073, 0.6651170253753662, 0.6640228033065796, 0.66667640209198, 0.6688579320907593, 0.6857290863990784, 0.6714646816253662, 0.6785125136375427, 0.6764115691184998, 0.6834051012992859, 0.6744013428688049, 0.6842793822288513, 0.686199426651001, 0.6843143105506897, 0.6901161670684814, 0.6950879096984863, 0.6900675296783447, 0.6936898231506348, 0.6933895945549011, 0.7068237662315369, 0.7062605023384094, 0.6940105557441711, 0.6970654726028442, 0.6985793709754944, 0.6984599828720093, 0.7019787430763245, 0.7031880617141724, 0.7135259509086609, 0.7122175693511963, 0.7093249559402466, 0.7071642279624939, 0.7184283137321472, 0.7255133986473083, 0.7361177206039429, 0.7508530020713806, 0.7399624586105347, 0.7453172206878662, 0.7300403714179993, 0.7361276149749756, 0.7484801411628723, 0.7494350671768188, 0.7316956520080566, 0.7375170588493347, 0.74948650598526, 0.7683742046356201, 0.7497316002845764, 0.7429144382476807, 0.7377694249153137, 0.7524443864822388, 0.7518628835678101, 0.7581855654716492, 0.7682762742042542, 0.776252031326294, 0.7611883282661438, 0.7717132568359375, 0.7870372533798218, 0.7706642746925354, 0.7728347182273865], 'val_accuracy': [0.5056561231613159, 0.5056561231613159, 0.5056561231613159, 0.5079185366630554, 0.5079185366630554, 0.5147058963775635, 0.5180995464324951, 0.5271493196487427, 0.5418552160263062, 0.5554298758506775, 0.5610859990119934, 0.5565611124038696, 0.5803167223930359, 0.6063348650932312, 0.5950226187705994, 0.5950226187705994, 0.5893664956092834, 0.6199095249176025, 0.6447963714599609, 0.6176470518112183, 0.6538461446762085, 0.6470588445663452, 0.6504524946212769, 0.6640271544456482, 0.6549773812294006, 0.6606335043907166, 0.6572397947311401, 0.6527149081230164, 0.6640271544456482, 0.6674208045005798, 0.6606335043907166, 0.668552041053772, 0.662895917892456, 0.668552041053772, 0.6708144545555115, 0.662895917892456, 0.6617646813392639, 0.6606335043907166, 0.6674208045005798, 0.6538461446762085, 0.668552041053772, 0.6595022678375244, 0.668552041053772, 0.6493212580680847, 0.6640271544456482, 0.662895917892456, 0.6662895679473877, 0.6572397947311401, 0.662895917892456, 0.6662895679473877, 0.6708144545555115, 0.6662895679473877, 0.6640271544456482, 0.6617646813392639, 0.6617646813392639, 0.6617646813392639, 0.6662895679473877, 0.6730769276618958, 0.6617646813392639, 0.6595022678375244, 0.6719456911087036, 0.6662895679473877, 0.6753393411636353, 0.6708144545555115, 0.6651583909988403, 0.6696832776069641, 0.6674208045005798, 0.6719456911087036, 0.6696832776069641, 0.6640271544456482, 0.668552041053772, 0.6708144545555115, 0.6651583909988403, 0.6708144545555115, 0.668552041053772, 0.6674208045005798, 0.6640271544456482, 0.6651583909988403, 0.662895917892456, 0.6606335043907166, 0.6595022678375244, 0.6651583909988403, 0.668552041053772, 0.6742081642150879, 0.6549773812294006, 0.6708144545555115, 0.668552041053772, 0.6595022678375244, 0.6696832776069641, 0.6617646813392639, 0.6708144545555115, 0.668552041053772, 0.668552041053772, 0.6719456911087036, 0.6572397947311401, 0.6708144545555115, 0.6549773812294006, 0.6640271544456482, 0.6742081642150879, 0.6696832776069641]}\n","45/45 [==============================] - 2s 8ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.6292 - accuracy: 0.6515"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 53ms/step - loss: 0.6299 - accuracy: 0.6532 - val_loss: 0.6898 - val_accuracy: 0.5207\n","Epoch 2/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6167 - accuracy: 0.6612 - val_loss: 0.6903 - val_accuracy: 0.5217\n","Epoch 3/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6141 - accuracy: 0.6667 - val_loss: 0.6907 - val_accuracy: 0.5207\n","Epoch 4/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6118 - accuracy: 0.6674 - val_loss: 0.6879 - val_accuracy: 0.5248\n","Epoch 5/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6067 - accuracy: 0.6765 - val_loss: 0.6864 - val_accuracy: 0.5300\n","Epoch 6/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6056 - accuracy: 0.6760 - val_loss: 0.6826 - val_accuracy: 0.5413\n","Epoch 7/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6011 - accuracy: 0.6796 - val_loss: 0.6847 - val_accuracy: 0.5331\n","Epoch 8/100\n","31/31 [==============================] - 1s 39ms/step - loss: 0.5996 - accuracy: 0.6783 - val_loss: 0.6796 - val_accuracy: 0.5455\n","Epoch 9/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5983 - accuracy: 0.6801 - val_loss: 0.6747 - val_accuracy: 0.5620\n","Epoch 10/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5952 - accuracy: 0.6858 - val_loss: 0.6746 - val_accuracy: 0.5548\n","Epoch 11/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.5895 - accuracy: 0.6891 - val_loss: 0.6689 - val_accuracy: 0.5837\n","Epoch 12/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5910 - accuracy: 0.6866 - val_loss: 0.6679 - val_accuracy: 0.5775\n","Epoch 13/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5893 - accuracy: 0.6912 - val_loss: 0.6605 - val_accuracy: 0.5940\n","Epoch 14/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5832 - accuracy: 0.6910 - val_loss: 0.6609 - val_accuracy: 0.5878\n","Epoch 15/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.5866 - accuracy: 0.6889 - val_loss: 0.6519 - val_accuracy: 0.6147\n","Epoch 16/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.5785 - accuracy: 0.6922 - val_loss: 0.6489 - val_accuracy: 0.6240\n","Epoch 17/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5783 - accuracy: 0.6959 - val_loss: 0.6492 - val_accuracy: 0.6209\n","Epoch 18/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5762 - accuracy: 0.6961 - val_loss: 0.6416 - val_accuracy: 0.6477\n","Epoch 19/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5770 - accuracy: 0.6964 - val_loss: 0.6411 - val_accuracy: 0.6519\n","Epoch 20/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5734 - accuracy: 0.7010 - val_loss: 0.6414 - val_accuracy: 0.6457\n","Epoch 21/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5694 - accuracy: 0.7057 - val_loss: 0.6378 - val_accuracy: 0.6570\n","Epoch 22/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.5636 - accuracy: 0.7067 - val_loss: 0.6389 - val_accuracy: 0.6581\n","Epoch 23/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5631 - accuracy: 0.7090 - val_loss: 0.6384 - val_accuracy: 0.6550\n","Epoch 24/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5618 - accuracy: 0.7098 - val_loss: 0.6410 - val_accuracy: 0.6581\n","Epoch 25/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5599 - accuracy: 0.7078 - val_loss: 0.6418 - val_accuracy: 0.6560\n","Epoch 26/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.5588 - accuracy: 0.7067 - val_loss: 0.6442 - val_accuracy: 0.6519\n","Epoch 27/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5562 - accuracy: 0.7152 - val_loss: 0.6503 - val_accuracy: 0.6457\n","Epoch 28/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5505 - accuracy: 0.7181 - val_loss: 0.6513 - val_accuracy: 0.6508\n","Epoch 29/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5538 - accuracy: 0.7137 - val_loss: 0.6570 - val_accuracy: 0.6446\n","Epoch 30/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5475 - accuracy: 0.7225 - val_loss: 0.6573 - val_accuracy: 0.6446\n","Epoch 31/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5438 - accuracy: 0.7274 - val_loss: 0.6546 - val_accuracy: 0.6508\n","Epoch 32/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5509 - accuracy: 0.7127 - val_loss: 0.6593 - val_accuracy: 0.6467\n","Epoch 33/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5450 - accuracy: 0.7202 - val_loss: 0.6618 - val_accuracy: 0.6415\n","Epoch 34/100\n","31/31 [==============================] - 1s 36ms/step - loss: 0.5398 - accuracy: 0.7287 - val_loss: 0.6657 - val_accuracy: 0.6353\n","Epoch 35/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5448 - accuracy: 0.7134 - val_loss: 0.6675 - val_accuracy: 0.6467\n","Epoch 36/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5353 - accuracy: 0.7310 - val_loss: 0.6683 - val_accuracy: 0.6457\n","Epoch 37/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5345 - accuracy: 0.7323 - val_loss: 0.6676 - val_accuracy: 0.6446\n","Epoch 38/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5321 - accuracy: 0.7287 - val_loss: 0.6690 - val_accuracy: 0.6384\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5350 - accuracy: 0.7295 - val_loss: 0.6763 - val_accuracy: 0.6384\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5290 - accuracy: 0.7326 - val_loss: 0.6720 - val_accuracy: 0.6519\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5227 - accuracy: 0.7382 - val_loss: 0.6711 - val_accuracy: 0.6508\n","Epoch 42/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5273 - accuracy: 0.7331 - val_loss: 0.6755 - val_accuracy: 0.6488\n","Epoch 43/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5201 - accuracy: 0.7406 - val_loss: 0.6834 - val_accuracy: 0.6488\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5242 - accuracy: 0.7357 - val_loss: 0.6806 - val_accuracy: 0.6395\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5191 - accuracy: 0.7370 - val_loss: 0.6808 - val_accuracy: 0.6477\n","Epoch 46/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5139 - accuracy: 0.7401 - val_loss: 0.6817 - val_accuracy: 0.6384\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5191 - accuracy: 0.7372 - val_loss: 0.6872 - val_accuracy: 0.6395\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5153 - accuracy: 0.7439 - val_loss: 0.6825 - val_accuracy: 0.6415\n","Epoch 49/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5126 - accuracy: 0.7419 - val_loss: 0.6923 - val_accuracy: 0.6436\n","Epoch 50/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5050 - accuracy: 0.7457 - val_loss: 0.6949 - val_accuracy: 0.6477\n","Epoch 51/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5046 - accuracy: 0.7525 - val_loss: 0.6896 - val_accuracy: 0.6488\n","Epoch 52/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5035 - accuracy: 0.7468 - val_loss: 0.6973 - val_accuracy: 0.6405\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5074 - accuracy: 0.7470 - val_loss: 0.6992 - val_accuracy: 0.6529\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5022 - accuracy: 0.7525 - val_loss: 0.6973 - val_accuracy: 0.6405\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4971 - accuracy: 0.7563 - val_loss: 0.7041 - val_accuracy: 0.6457\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5061 - accuracy: 0.7519 - val_loss: 0.7064 - val_accuracy: 0.6312\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4943 - accuracy: 0.7579 - val_loss: 0.7074 - val_accuracy: 0.6384\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4915 - accuracy: 0.7548 - val_loss: 0.7063 - val_accuracy: 0.6405\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4882 - accuracy: 0.7579 - val_loss: 0.7169 - val_accuracy: 0.6374\n","Epoch 60/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4909 - accuracy: 0.7651 - val_loss: 0.7117 - val_accuracy: 0.6508\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4885 - accuracy: 0.7545 - val_loss: 0.7115 - val_accuracy: 0.6364\n","Epoch 62/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4838 - accuracy: 0.7612 - val_loss: 0.7179 - val_accuracy: 0.6498\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4850 - accuracy: 0.7641 - val_loss: 0.7175 - val_accuracy: 0.6353\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4771 - accuracy: 0.7757 - val_loss: 0.7230 - val_accuracy: 0.6498\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4795 - accuracy: 0.7711 - val_loss: 0.7211 - val_accuracy: 0.6312\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4808 - accuracy: 0.7672 - val_loss: 0.7236 - val_accuracy: 0.6291\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4778 - accuracy: 0.7685 - val_loss: 0.7297 - val_accuracy: 0.6550\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4867 - accuracy: 0.7628 - val_loss: 0.7448 - val_accuracy: 0.6436\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4836 - accuracy: 0.7690 - val_loss: 0.7356 - val_accuracy: 0.6364\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4713 - accuracy: 0.7762 - val_loss: 0.7248 - val_accuracy: 0.6384\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4726 - accuracy: 0.7744 - val_loss: 0.7546 - val_accuracy: 0.6405\n","Epoch 72/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4716 - accuracy: 0.7716 - val_loss: 0.7274 - val_accuracy: 0.6488\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4652 - accuracy: 0.7791 - val_loss: 0.7296 - val_accuracy: 0.6271\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4683 - accuracy: 0.7742 - val_loss: 0.7353 - val_accuracy: 0.6457\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4627 - accuracy: 0.7793 - val_loss: 0.7433 - val_accuracy: 0.6384\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4655 - accuracy: 0.7770 - val_loss: 0.7446 - val_accuracy: 0.6260\n","Epoch 77/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4718 - accuracy: 0.7755 - val_loss: 0.7439 - val_accuracy: 0.6271\n","Epoch 78/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4623 - accuracy: 0.7798 - val_loss: 0.7837 - val_accuracy: 0.6312\n","Epoch 79/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4661 - accuracy: 0.7757 - val_loss: 0.7422 - val_accuracy: 0.6467\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4580 - accuracy: 0.7819 - val_loss: 0.7571 - val_accuracy: 0.6384\n","Epoch 81/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4553 - accuracy: 0.7884 - val_loss: 0.7510 - val_accuracy: 0.6322\n","Epoch 82/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4567 - accuracy: 0.7824 - val_loss: 0.7578 - val_accuracy: 0.6167\n","Epoch 83/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4534 - accuracy: 0.7866 - val_loss: 0.7488 - val_accuracy: 0.6374\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4533 - accuracy: 0.7866 - val_loss: 0.7594 - val_accuracy: 0.6374\n","Epoch 85/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4531 - accuracy: 0.7868 - val_loss: 0.7593 - val_accuracy: 0.6291\n","Epoch 86/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4547 - accuracy: 0.7829 - val_loss: 0.7609 - val_accuracy: 0.6395\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4519 - accuracy: 0.7863 - val_loss: 0.7654 - val_accuracy: 0.6395\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4453 - accuracy: 0.7899 - val_loss: 0.7777 - val_accuracy: 0.6374\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4424 - accuracy: 0.7938 - val_loss: 0.7618 - val_accuracy: 0.6312\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4402 - accuracy: 0.7946 - val_loss: 0.7700 - val_accuracy: 0.6477\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4401 - accuracy: 0.7995 - val_loss: 0.7799 - val_accuracy: 0.6364\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4393 - accuracy: 0.7979 - val_loss: 0.7732 - val_accuracy: 0.6333\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4385 - accuracy: 0.7961 - val_loss: 0.7836 - val_accuracy: 0.6198\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4391 - accuracy: 0.7979 - val_loss: 0.7825 - val_accuracy: 0.6426\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4427 - accuracy: 0.7946 - val_loss: 0.7715 - val_accuracy: 0.6405\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4345 - accuracy: 0.7951 - val_loss: 0.7928 - val_accuracy: 0.6405\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4363 - accuracy: 0.7982 - val_loss: 0.7878 - val_accuracy: 0.6405\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4315 - accuracy: 0.7995 - val_loss: 0.7784 - val_accuracy: 0.6312\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4275 - accuracy: 0.8034 - val_loss: 0.7908 - val_accuracy: 0.6364\n","Epoch 100/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4298 - accuracy: 0.7969 - val_loss: 0.7873 - val_accuracy: 0.6436\n","{'loss': [0.6299119591712952, 0.616725742816925, 0.6141462326049805, 0.6118155717849731, 0.6067026257514954, 0.605630099773407, 0.6011084318161011, 0.5995675325393677, 0.5983477234840393, 0.5951510667800903, 0.5895021557807922, 0.5909756422042847, 0.58925461769104, 0.5832156538963318, 0.5865734815597534, 0.5785389542579651, 0.5783182382583618, 0.576196551322937, 0.5769919753074646, 0.5733861923217773, 0.5694413781166077, 0.5635576844215393, 0.5630525946617126, 0.5618223547935486, 0.5598886013031006, 0.558782696723938, 0.5562242269515991, 0.5505350232124329, 0.5537926554679871, 0.5474799275398254, 0.5438386797904968, 0.5509379506111145, 0.5449830889701843, 0.5397937893867493, 0.5448452830314636, 0.5352597236633301, 0.5345082879066467, 0.5321270227432251, 0.5349706411361694, 0.5290158987045288, 0.5227319002151489, 0.5272951722145081, 0.5201218724250793, 0.5242050886154175, 0.5190531611442566, 0.5139333009719849, 0.5190919637680054, 0.5153022408485413, 0.5125859975814819, 0.5049611330032349, 0.5045822262763977, 0.5034605860710144, 0.5074123740196228, 0.5021532773971558, 0.49709585309028625, 0.5061033368110657, 0.4943022131919861, 0.4915087819099426, 0.48818764090538025, 0.4909127354621887, 0.4884636104106903, 0.48382821679115295, 0.4849715530872345, 0.47712376713752747, 0.479536771774292, 0.48084011673927307, 0.47783350944519043, 0.48669180274009705, 0.48364919424057007, 0.47130292654037476, 0.47260206937789917, 0.47162672877311707, 0.4651538133621216, 0.4683261811733246, 0.46265456080436707, 0.4654666781425476, 0.47180116176605225, 0.4622608721256256, 0.46614184975624084, 0.4580309987068176, 0.45526912808418274, 0.45668959617614746, 0.4534027576446533, 0.4533330202102661, 0.4531265199184418, 0.4546906054019928, 0.4518871605396271, 0.4453422725200653, 0.4423869848251343, 0.4401806592941284, 0.44011440873146057, 0.4392780065536499, 0.4385060966014862, 0.4390532374382019, 0.4427042603492737, 0.43453702330589294, 0.4363269507884979, 0.43153902888298035, 0.4274735748767853, 0.42976099252700806], 'accuracy': [0.6532299518585205, 0.6612403392791748, 0.6666666865348816, 0.6674418449401855, 0.6764857769012451, 0.6759690046310425, 0.6795865893363953, 0.6782945990562439, 0.6801033616065979, 0.685788094997406, 0.6891472935676575, 0.6865633130073547, 0.6912144422531128, 0.6909560561180115, 0.6888889074325562, 0.6922480463981628, 0.6958656311035156, 0.6961240172386169, 0.6963824033737183, 0.7010335922241211, 0.7056847810745239, 0.7067183256149292, 0.7090439200401306, 0.7098191380500793, 0.7077519297599792, 0.7067183256149292, 0.7152454853057861, 0.7180878520011902, 0.7136951088905334, 0.7224805951118469, 0.7273901700973511, 0.7126615047454834, 0.7201550602912903, 0.7286821603775024, 0.7134366631507874, 0.7310077548027039, 0.7322997450828552, 0.7286821603775024, 0.7294573783874512, 0.7325581312179565, 0.7382428646087646, 0.733074963092804, 0.7405684590339661, 0.7356589436531067, 0.7369509339332581, 0.7400516867637634, 0.7372093200683594, 0.7439276576042175, 0.7418604493141174, 0.7457364201545715, 0.7524547576904297, 0.7467700242996216, 0.7470284104347229, 0.7524547576904297, 0.7563307285308838, 0.751937985420227, 0.7578811645507812, 0.7547803521156311, 0.7578811645507812, 0.765116274356842, 0.7545219659805298, 0.7612403035163879, 0.764082670211792, 0.7757105827331543, 0.7710594534873962, 0.7671834826469421, 0.7684754729270935, 0.7627906799316406, 0.7689922451972961, 0.7762274146080017, 0.7744185924530029, 0.7715762257575989, 0.7790697813034058, 0.7741602063179016, 0.7793281674385071, 0.7770025730133057, 0.775452196598053, 0.7798449397087097, 0.7757105827331543, 0.7819121479988098, 0.7883720993995667, 0.7824289202690125, 0.7865633368492126, 0.7865633368492126, 0.786821722984314, 0.7829457521438599, 0.7863048911094666, 0.7899224758148193, 0.7937984466552734, 0.7945736646652222, 0.7994831800460815, 0.7979328036308289, 0.7961240410804749, 0.7979328036308289, 0.7945736646652222, 0.7950904369354248, 0.7981911897659302, 0.7994831800460815, 0.8033591508865356, 0.7968991994857788], 'val_loss': [0.6898154020309448, 0.6903046369552612, 0.6907082796096802, 0.687910795211792, 0.6863851547241211, 0.6826282739639282, 0.6847217679023743, 0.6796135306358337, 0.6747347116470337, 0.6745907664299011, 0.6689358949661255, 0.6679391264915466, 0.6604662537574768, 0.6609216332435608, 0.6519487500190735, 0.6489496231079102, 0.6492001414299011, 0.6416153907775879, 0.6411399245262146, 0.6413593292236328, 0.6377535462379456, 0.6388602256774902, 0.6384415626525879, 0.6409721970558167, 0.6417891979217529, 0.644219696521759, 0.6502618789672852, 0.6513485908508301, 0.656960666179657, 0.6573135256767273, 0.6545810103416443, 0.6592941284179688, 0.6618252396583557, 0.6656535863876343, 0.6674606800079346, 0.6682921051979065, 0.6675502061843872, 0.6689765453338623, 0.6762548685073853, 0.6720008254051208, 0.6711389422416687, 0.6754684448242188, 0.68343186378479, 0.6805526614189148, 0.6808456778526306, 0.6817178726196289, 0.687153160572052, 0.6825230121612549, 0.6923101544380188, 0.6949109435081482, 0.6896491646766663, 0.6973056197166443, 0.6991972327232361, 0.6973300576210022, 0.7041270732879639, 0.7063628435134888, 0.7074210047721863, 0.7062790989875793, 0.7168950438499451, 0.7116934061050415, 0.7115028500556946, 0.7179019451141357, 0.717475414276123, 0.7229978442192078, 0.7210985422134399, 0.7235909104347229, 0.7297164797782898, 0.744763195514679, 0.7356336712837219, 0.7247641682624817, 0.754622220993042, 0.7273609638214111, 0.7296239733695984, 0.73530113697052, 0.7433103919029236, 0.7446202635765076, 0.7438941597938538, 0.7837451696395874, 0.7422279715538025, 0.7570646405220032, 0.7510051727294922, 0.7578222751617432, 0.748791515827179, 0.7593690752983093, 0.7592863440513611, 0.7609431743621826, 0.7653576731681824, 0.7777325510978699, 0.7617597579956055, 0.7699924111366272, 0.7799325585365295, 0.773235023021698, 0.7836058139801025, 0.782471776008606, 0.7715380787849426, 0.7928416728973389, 0.7878365516662598, 0.7783564329147339, 0.7908077239990234, 0.787321150302887], 'val_accuracy': [0.5206611752510071, 0.5216942429542542, 0.5206611752510071, 0.5247933864593506, 0.5299586653709412, 0.5413222908973694, 0.5330578684806824, 0.5454545617103577, 0.5619834661483765, 0.5547520518302917, 0.5836777091026306, 0.577479362487793, 0.5940082669258118, 0.5878099203109741, 0.6146694421768188, 0.6239669322967529, 0.6208677887916565, 0.6477272510528564, 0.6518595218658447, 0.6456611752510071, 0.6570248007774353, 0.6580578684806824, 0.6549586653709412, 0.6580578684806824, 0.6559917330741882, 0.6518595218658447, 0.6456611752510071, 0.6508264541625977, 0.64462810754776, 0.64462810754776, 0.6508264541625977, 0.6466942429542542, 0.6415289044380188, 0.6353305578231812, 0.6466942429542542, 0.6456611752510071, 0.64462810754776, 0.6384297609329224, 0.6384297609329224, 0.6518595218658447, 0.6508264541625977, 0.6487603187561035, 0.6487603187561035, 0.6394628286361694, 0.6477272510528564, 0.6384297609329224, 0.6394628286361694, 0.6415289044380188, 0.6435950398445129, 0.6477272510528564, 0.6487603187561035, 0.6404958963394165, 0.6528925895690918, 0.6404958963394165, 0.6456611752510071, 0.6311983466148376, 0.6384297609329224, 0.6404958963394165, 0.6373966932296753, 0.6508264541625977, 0.6363636255264282, 0.6497933864593506, 0.6353305578231812, 0.6497933864593506, 0.6311983466148376, 0.6291322112083435, 0.6549586653709412, 0.6435950398445129, 0.6363636255264282, 0.6384297609329224, 0.6404958963394165, 0.6487603187561035, 0.6270661354064941, 0.6456611752510071, 0.6384297609329224, 0.6260330677032471, 0.6270661354064941, 0.6311983466148376, 0.6466942429542542, 0.6384297609329224, 0.6322314143180847, 0.6167355179786682, 0.6373966932296753, 0.6373966932296753, 0.6291322112083435, 0.6394628286361694, 0.6394628286361694, 0.6373966932296753, 0.6311983466148376, 0.6477272510528564, 0.6363636255264282, 0.6332644820213318, 0.6198347210884094, 0.6425619721412659, 0.6404958963394165, 0.6404958963394165, 0.6404958963394165, 0.6311983466148376, 0.6363636255264282, 0.6435950398445129]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.4764 - accuracy: 0.7723"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 12s 94ms/step - loss: 0.4799 - accuracy: 0.7713 - val_loss: 0.6768 - val_accuracy: 0.5517\n","Epoch 2/100\n","29/29 [==============================] - 1s 46ms/step - loss: 0.4751 - accuracy: 0.7780 - val_loss: 0.6717 - val_accuracy: 0.5690\n","Epoch 3/100\n","29/29 [==============================] - 1s 38ms/step - loss: 0.4707 - accuracy: 0.7742 - val_loss: 0.6672 - val_accuracy: 0.5970\n","Epoch 4/100\n","29/29 [==============================] - 1s 45ms/step - loss: 0.4689 - accuracy: 0.7769 - val_loss: 0.6619 - val_accuracy: 0.6121\n","Epoch 5/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.4577 - accuracy: 0.7794 - val_loss: 0.6599 - val_accuracy: 0.6272\n","Epoch 6/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4653 - accuracy: 0.7780 - val_loss: 0.6614 - val_accuracy: 0.6099\n","Epoch 7/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.4631 - accuracy: 0.7764 - val_loss: 0.6477 - val_accuracy: 0.6670\n","Epoch 8/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4632 - accuracy: 0.7807 - val_loss: 0.6459 - val_accuracy: 0.6670\n","Epoch 9/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4546 - accuracy: 0.7877 - val_loss: 0.6375 - val_accuracy: 0.6670\n","Epoch 10/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4564 - accuracy: 0.7839 - val_loss: 0.6407 - val_accuracy: 0.6444\n","Epoch 11/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.4459 - accuracy: 0.7901 - val_loss: 0.6276 - val_accuracy: 0.6918\n","Epoch 12/100\n","29/29 [==============================] - 1s 39ms/step - loss: 0.4472 - accuracy: 0.7850 - val_loss: 0.6262 - val_accuracy: 0.6940\n","Epoch 13/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.4407 - accuracy: 0.7891 - val_loss: 0.6127 - val_accuracy: 0.7004\n","Epoch 14/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4457 - accuracy: 0.7883 - val_loss: 0.6114 - val_accuracy: 0.7091\n","Epoch 15/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4455 - accuracy: 0.7950 - val_loss: 0.6057 - val_accuracy: 0.6638\n","Epoch 16/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4393 - accuracy: 0.7920 - val_loss: 0.6052 - val_accuracy: 0.7058\n","Epoch 17/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4416 - accuracy: 0.7899 - val_loss: 0.5918 - val_accuracy: 0.6961\n","Epoch 18/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4369 - accuracy: 0.7885 - val_loss: 0.5814 - val_accuracy: 0.7101\n","Epoch 19/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4334 - accuracy: 0.7963 - val_loss: 0.5891 - val_accuracy: 0.7091\n","Epoch 20/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4292 - accuracy: 0.8023 - val_loss: 0.5731 - val_accuracy: 0.7101\n","Epoch 21/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4314 - accuracy: 0.7980 - val_loss: 0.5776 - val_accuracy: 0.7177\n","Epoch 22/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4336 - accuracy: 0.8028 - val_loss: 0.5763 - val_accuracy: 0.7112\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4266 - accuracy: 0.8082 - val_loss: 0.5748 - val_accuracy: 0.7069\n","Epoch 24/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4304 - accuracy: 0.8015 - val_loss: 0.5899 - val_accuracy: 0.7091\n","Epoch 25/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4214 - accuracy: 0.8063 - val_loss: 0.5753 - val_accuracy: 0.7101\n","Epoch 26/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4187 - accuracy: 0.8055 - val_loss: 0.5834 - val_accuracy: 0.7101\n","Epoch 27/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4150 - accuracy: 0.8085 - val_loss: 0.5875 - val_accuracy: 0.7080\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4246 - accuracy: 0.8028 - val_loss: 0.5802 - val_accuracy: 0.7004\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4150 - accuracy: 0.8050 - val_loss: 0.5880 - val_accuracy: 0.7069\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4091 - accuracy: 0.8090 - val_loss: 0.6071 - val_accuracy: 0.7101\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4126 - accuracy: 0.8071 - val_loss: 0.6016 - val_accuracy: 0.7144\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4128 - accuracy: 0.8117 - val_loss: 0.6073 - val_accuracy: 0.6918\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4078 - accuracy: 0.8090 - val_loss: 0.6023 - val_accuracy: 0.7058\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4089 - accuracy: 0.8109 - val_loss: 0.6176 - val_accuracy: 0.7155\n","Epoch 35/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4066 - accuracy: 0.8160 - val_loss: 0.6204 - val_accuracy: 0.7209\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3974 - accuracy: 0.8165 - val_loss: 0.6057 - val_accuracy: 0.6972\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4013 - accuracy: 0.8168 - val_loss: 0.6177 - val_accuracy: 0.7015\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3979 - accuracy: 0.8195 - val_loss: 0.6324 - val_accuracy: 0.7144\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3999 - accuracy: 0.8138 - val_loss: 0.6322 - val_accuracy: 0.7080\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3982 - accuracy: 0.8176 - val_loss: 0.6121 - val_accuracy: 0.7069\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3924 - accuracy: 0.8195 - val_loss: 0.6268 - val_accuracy: 0.6994\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3912 - accuracy: 0.8233 - val_loss: 0.6349 - val_accuracy: 0.7123\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3882 - accuracy: 0.8241 - val_loss: 0.6270 - val_accuracy: 0.7080\n","Epoch 44/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3887 - accuracy: 0.8176 - val_loss: 0.6274 - val_accuracy: 0.7198\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3868 - accuracy: 0.8225 - val_loss: 0.6320 - val_accuracy: 0.7188\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3861 - accuracy: 0.8206 - val_loss: 0.6280 - val_accuracy: 0.7047\n","Epoch 47/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3793 - accuracy: 0.8233 - val_loss: 0.6467 - val_accuracy: 0.7080\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3826 - accuracy: 0.8289 - val_loss: 0.6437 - val_accuracy: 0.7047\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3718 - accuracy: 0.8322 - val_loss: 0.6471 - val_accuracy: 0.7047\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3857 - accuracy: 0.8217 - val_loss: 0.6859 - val_accuracy: 0.7069\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3831 - accuracy: 0.8257 - val_loss: 0.6354 - val_accuracy: 0.7091\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3712 - accuracy: 0.8335 - val_loss: 0.6381 - val_accuracy: 0.7155\n","Epoch 53/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3785 - accuracy: 0.8279 - val_loss: 0.6427 - val_accuracy: 0.7112\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3675 - accuracy: 0.8351 - val_loss: 0.6667 - val_accuracy: 0.7123\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3735 - accuracy: 0.8265 - val_loss: 0.6487 - val_accuracy: 0.7134\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3614 - accuracy: 0.8362 - val_loss: 0.6576 - val_accuracy: 0.6972\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3671 - accuracy: 0.8330 - val_loss: 0.6726 - val_accuracy: 0.7101\n","Epoch 58/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3618 - accuracy: 0.8384 - val_loss: 0.6585 - val_accuracy: 0.7080\n","Epoch 59/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3595 - accuracy: 0.8354 - val_loss: 0.6486 - val_accuracy: 0.7058\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3565 - accuracy: 0.8438 - val_loss: 0.6756 - val_accuracy: 0.7177\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3562 - accuracy: 0.8381 - val_loss: 0.6794 - val_accuracy: 0.7209\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3587 - accuracy: 0.8308 - val_loss: 0.6878 - val_accuracy: 0.6907\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3540 - accuracy: 0.8429 - val_loss: 0.6717 - val_accuracy: 0.7198\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3518 - accuracy: 0.8429 - val_loss: 0.6903 - val_accuracy: 0.7166\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3606 - accuracy: 0.8314 - val_loss: 0.7143 - val_accuracy: 0.7058\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3521 - accuracy: 0.8413 - val_loss: 0.6931 - val_accuracy: 0.7047\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3464 - accuracy: 0.8489 - val_loss: 0.7033 - val_accuracy: 0.7080\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3410 - accuracy: 0.8462 - val_loss: 0.6866 - val_accuracy: 0.7026\n","Epoch 69/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3408 - accuracy: 0.8446 - val_loss: 0.6790 - val_accuracy: 0.7101\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3380 - accuracy: 0.8516 - val_loss: 0.6893 - val_accuracy: 0.7209\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3407 - accuracy: 0.8508 - val_loss: 0.6829 - val_accuracy: 0.7069\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3388 - accuracy: 0.8499 - val_loss: 0.6955 - val_accuracy: 0.7091\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3429 - accuracy: 0.8478 - val_loss: 0.7564 - val_accuracy: 0.6983\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3434 - accuracy: 0.8497 - val_loss: 0.6976 - val_accuracy: 0.7037\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3449 - accuracy: 0.8489 - val_loss: 0.6981 - val_accuracy: 0.7144\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3375 - accuracy: 0.8475 - val_loss: 0.6859 - val_accuracy: 0.7080\n","Epoch 77/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3424 - accuracy: 0.8529 - val_loss: 0.7041 - val_accuracy: 0.7112\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3311 - accuracy: 0.8534 - val_loss: 0.6982 - val_accuracy: 0.7101\n","Epoch 79/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3337 - accuracy: 0.8508 - val_loss: 0.6979 - val_accuracy: 0.7166\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3245 - accuracy: 0.8572 - val_loss: 0.7163 - val_accuracy: 0.7080\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3350 - accuracy: 0.8548 - val_loss: 0.7375 - val_accuracy: 0.7015\n","Epoch 82/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3278 - accuracy: 0.8583 - val_loss: 0.7169 - val_accuracy: 0.7047\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3236 - accuracy: 0.8594 - val_loss: 0.7047 - val_accuracy: 0.7037\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3204 - accuracy: 0.8634 - val_loss: 0.7412 - val_accuracy: 0.7080\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3267 - accuracy: 0.8529 - val_loss: 0.7224 - val_accuracy: 0.7015\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3233 - accuracy: 0.8599 - val_loss: 0.7167 - val_accuracy: 0.6961\n","Epoch 87/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3217 - accuracy: 0.8588 - val_loss: 0.7480 - val_accuracy: 0.7037\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3214 - accuracy: 0.8567 - val_loss: 0.7327 - val_accuracy: 0.6929\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3149 - accuracy: 0.8626 - val_loss: 0.7406 - val_accuracy: 0.7177\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3195 - accuracy: 0.8567 - val_loss: 0.7384 - val_accuracy: 0.6961\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3293 - accuracy: 0.8462 - val_loss: 0.7320 - val_accuracy: 0.7080\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3183 - accuracy: 0.8610 - val_loss: 0.7258 - val_accuracy: 0.7004\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3103 - accuracy: 0.8618 - val_loss: 0.7413 - val_accuracy: 0.7047\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3015 - accuracy: 0.8704 - val_loss: 0.7276 - val_accuracy: 0.7112\n","Epoch 95/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3129 - accuracy: 0.8618 - val_loss: 0.7408 - val_accuracy: 0.6994\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3069 - accuracy: 0.8688 - val_loss: 0.7326 - val_accuracy: 0.6897\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3038 - accuracy: 0.8661 - val_loss: 0.7318 - val_accuracy: 0.7091\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2978 - accuracy: 0.8707 - val_loss: 0.7416 - val_accuracy: 0.7112\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2959 - accuracy: 0.8726 - val_loss: 0.7297 - val_accuracy: 0.7069\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2956 - accuracy: 0.8710 - val_loss: 0.7463 - val_accuracy: 0.6983\n","{'loss': [0.4799228310585022, 0.4750959277153015, 0.4707488715648651, 0.4688815474510193, 0.45771536231040955, 0.4652782082557678, 0.4631001353263855, 0.4631563425064087, 0.4545553922653198, 0.4564143121242523, 0.44587084650993347, 0.44720324873924255, 0.4406989812850952, 0.44567590951919556, 0.44553759694099426, 0.43931928277015686, 0.4416485130786896, 0.43685874342918396, 0.4333871901035309, 0.4292309284210205, 0.4313667118549347, 0.4336257576942444, 0.4265816807746887, 0.43037286400794983, 0.42141541838645935, 0.4187287390232086, 0.4149932265281677, 0.4245803952217102, 0.41495653986930847, 0.40909457206726074, 0.41256362199783325, 0.41282621026039124, 0.407804936170578, 0.40890267491340637, 0.40664544701576233, 0.3974204361438751, 0.40125054121017456, 0.39791256189346313, 0.39988210797309875, 0.39818769693374634, 0.39235419034957886, 0.3912016749382019, 0.3881818950176239, 0.38873884081840515, 0.3867890536785126, 0.3861149549484253, 0.37932461500167847, 0.38264429569244385, 0.37177059054374695, 0.3856912851333618, 0.38309594988822937, 0.37119200825691223, 0.37848761677742004, 0.36745789647102356, 0.37353646755218506, 0.36143261194229126, 0.3671075999736786, 0.36176130175590515, 0.3594631254673004, 0.3564714193344116, 0.35619214177131653, 0.35869768261909485, 0.3540325164794922, 0.3517553210258484, 0.36056777834892273, 0.3520662188529968, 0.3463710844516754, 0.34095174074172974, 0.34075579047203064, 0.3380314111709595, 0.34070152044296265, 0.3388013243675232, 0.34285208582878113, 0.3434019982814789, 0.3448731303215027, 0.33754226565361023, 0.34244149923324585, 0.33107253909111023, 0.3336810767650604, 0.324487566947937, 0.33497682213783264, 0.3277739882469177, 0.3236171007156372, 0.3203977644443512, 0.3267362415790558, 0.32327452301979065, 0.32174938917160034, 0.3213827908039093, 0.31493279337882996, 0.3195449113845825, 0.3292589485645294, 0.3183118999004364, 0.31034189462661743, 0.3015053868293762, 0.31286099553108215, 0.3068596124649048, 0.30378568172454834, 0.2977931797504425, 0.29593271017074585, 0.2955552935600281], 'accuracy': [0.7712823152542114, 0.7780172228813171, 0.7742456793785095, 0.7769396305084229, 0.7793642282485962, 0.7780172228813171, 0.7764008641242981, 0.7807112336158752, 0.787715494632721, 0.7839439511299133, 0.7901400923728943, 0.7850215435028076, 0.7890625, 0.7882543206214905, 0.7949892282485962, 0.7920258641242981, 0.7898706793785095, 0.7885237336158752, 0.7963362336158752, 0.8022629022598267, 0.7979525923728943, 0.8028017282485962, 0.8081896305084229, 0.8014547228813171, 0.806303858757019, 0.8054956793785095, 0.8084590435028076, 0.8028017282485962, 0.8049569129943848, 0.8089978694915771, 0.8071120977401733, 0.8116918206214905, 0.8089978694915771, 0.810883641242981, 0.8160021305084229, 0.8165409564971924, 0.8168103694915771, 0.8195043206214905, 0.813847005367279, 0.8176185488700867, 0.8195043206214905, 0.8232758641242981, 0.8240840435028076, 0.8176185488700867, 0.8224676847457886, 0.8205819129943848, 0.8232758641242981, 0.8289331793785095, 0.8321659564971924, 0.821659505367279, 0.8257004022598267, 0.8335129022598267, 0.8278555870056152, 0.8351293206214905, 0.826508641242981, 0.8362069129943848, 0.8329741358757019, 0.8383620977401733, 0.8353987336158752, 0.84375, 0.8380926847457886, 0.8308189511299133, 0.8429418206214905, 0.8429418206214905, 0.8313577771186829, 0.8413254022598267, 0.8488685488700867, 0.8461745977401733, 0.8445581793785095, 0.8515625, 0.8507543206214905, 0.849946141242981, 0.8477909564971924, 0.8496767282485962, 0.8488685488700867, 0.8475215435028076, 0.852909505367279, 0.8534482717514038, 0.8507543206214905, 0.8572198152542114, 0.8547952771186829, 0.8582974076271057, 0.859375, 0.8634159564971924, 0.852909505367279, 0.8599137663841248, 0.8588362336158752, 0.8566810488700867, 0.8626077771186829, 0.8566810488700867, 0.8461745977401733, 0.860991358757019, 0.8617995977401733, 0.8704202771186829, 0.8617995977401733, 0.868803858757019, 0.8661099076271057, 0.8706896305084229, 0.8725754022598267, 0.8709590435028076], 'val_loss': [0.6768059134483337, 0.6717192530632019, 0.6672071218490601, 0.6618911623954773, 0.6598788499832153, 0.6614243984222412, 0.6477452516555786, 0.6459130644798279, 0.6375483870506287, 0.6406643390655518, 0.627566397190094, 0.6261841058731079, 0.6126900911331177, 0.6114320158958435, 0.6057321429252625, 0.6052285432815552, 0.5917934775352478, 0.5814115405082703, 0.5890741944313049, 0.5730977654457092, 0.5776034593582153, 0.5763118863105774, 0.5748025178909302, 0.5898532867431641, 0.5752659440040588, 0.5833595395088196, 0.5874631404876709, 0.5801913738250732, 0.588018000125885, 0.6071473956108093, 0.6015887260437012, 0.6072510480880737, 0.6022701859474182, 0.6175599694252014, 0.6204016208648682, 0.6056917309761047, 0.6176830530166626, 0.6323758363723755, 0.6322148442268372, 0.6121430993080139, 0.626764178276062, 0.6348588466644287, 0.626950740814209, 0.6274202466011047, 0.6319790482521057, 0.6279826760292053, 0.6467373371124268, 0.6437153816223145, 0.6471450328826904, 0.6858880519866943, 0.6354009509086609, 0.6381067037582397, 0.6426641345024109, 0.6667068600654602, 0.6487491130828857, 0.657589316368103, 0.6725817322731018, 0.6584699153900146, 0.6486263871192932, 0.6755702495574951, 0.6794286966323853, 0.687751293182373, 0.6716886162757874, 0.6903289556503296, 0.7142544984817505, 0.693112313747406, 0.7033118605613708, 0.6865512132644653, 0.6789714694023132, 0.689281702041626, 0.6829447746276855, 0.6954801082611084, 0.7564240097999573, 0.6976280808448792, 0.6980558037757874, 0.6859443783760071, 0.7041276693344116, 0.6981951594352722, 0.697902500629425, 0.7163405418395996, 0.7374595403671265, 0.7169153690338135, 0.704658031463623, 0.7412464618682861, 0.7224105596542358, 0.7166556119918823, 0.7479915022850037, 0.7326737642288208, 0.74062180519104, 0.7384141683578491, 0.7320372462272644, 0.7258497476577759, 0.7413240671157837, 0.7275615334510803, 0.7407500743865967, 0.7326424717903137, 0.7318116426467896, 0.7416044473648071, 0.729703426361084, 0.7463090419769287], 'val_accuracy': [0.5517241358757019, 0.568965494632721, 0.5969827771186829, 0.6120689511299133, 0.6271551847457886, 0.6099137663841248, 0.6670258641242981, 0.6670258641242981, 0.6670258641242981, 0.6443965435028076, 0.6918103694915771, 0.693965494632721, 0.7004310488700867, 0.7090517282485962, 0.6637930870056152, 0.7058189511299133, 0.6961206793785095, 0.7101293206214905, 0.7090517282485962, 0.7101293206214905, 0.7176724076271057, 0.7112069129943848, 0.7068965435028076, 0.7090517282485962, 0.7101293206214905, 0.7101293206214905, 0.7079741358757019, 0.7004310488700867, 0.7068965435028076, 0.7101293206214905, 0.7144396305084229, 0.6918103694915771, 0.7058189511299133, 0.7155172228813171, 0.7209051847457886, 0.6971982717514038, 0.701508641242981, 0.7144396305084229, 0.7079741358757019, 0.7068965435028076, 0.6993534564971924, 0.712284505367279, 0.7079741358757019, 0.7198275923728943, 0.71875, 0.704741358757019, 0.7079741358757019, 0.704741358757019, 0.704741358757019, 0.7068965435028076, 0.7090517282485962, 0.7155172228813171, 0.7112069129943848, 0.712284505367279, 0.7133620977401733, 0.6971982717514038, 0.7101293206214905, 0.7079741358757019, 0.7058189511299133, 0.7176724076271057, 0.7209051847457886, 0.6907327771186829, 0.7198275923728943, 0.7165948152542114, 0.7058189511299133, 0.704741358757019, 0.7079741358757019, 0.7025862336158752, 0.7101293206214905, 0.7209051847457886, 0.7068965435028076, 0.7090517282485962, 0.6982758641242981, 0.7036637663841248, 0.7144396305084229, 0.7079741358757019, 0.7112069129943848, 0.7101293206214905, 0.7165948152542114, 0.7079741358757019, 0.701508641242981, 0.704741358757019, 0.7036637663841248, 0.7079741358757019, 0.701508641242981, 0.6961206793785095, 0.7036637663841248, 0.6928879022598267, 0.7176724076271057, 0.6961206793785095, 0.7079741358757019, 0.7004310488700867, 0.704741358757019, 0.7112069129943848, 0.6993534564971924, 0.6896551847457886, 0.7090517282485962, 0.7112069129943848, 0.7068965435028076, 0.6982758641242981]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.4853 - accuracy: 0.7638"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 55ms/step - loss: 0.4875 - accuracy: 0.7629 - val_loss: 0.6822 - val_accuracy: 0.5373\n","Epoch 2/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4763 - accuracy: 0.7739 - val_loss: 0.6796 - val_accuracy: 0.5509\n","Epoch 3/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4736 - accuracy: 0.7714 - val_loss: 0.6712 - val_accuracy: 0.6131\n","Epoch 4/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4771 - accuracy: 0.7666 - val_loss: 0.6791 - val_accuracy: 0.5509\n","Epoch 5/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4711 - accuracy: 0.7714 - val_loss: 0.6672 - val_accuracy: 0.6290\n","Epoch 6/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4691 - accuracy: 0.7680 - val_loss: 0.6631 - val_accuracy: 0.6505\n","Epoch 7/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4613 - accuracy: 0.7810 - val_loss: 0.6610 - val_accuracy: 0.6550\n","Epoch 8/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4584 - accuracy: 0.7759 - val_loss: 0.6600 - val_accuracy: 0.6312\n","Epoch 9/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4625 - accuracy: 0.7680 - val_loss: 0.6557 - val_accuracy: 0.6629\n","Epoch 10/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4551 - accuracy: 0.7784 - val_loss: 0.6548 - val_accuracy: 0.6482\n","Epoch 11/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4550 - accuracy: 0.7796 - val_loss: 0.6485 - val_accuracy: 0.6719\n","Epoch 12/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4541 - accuracy: 0.7801 - val_loss: 0.6377 - val_accuracy: 0.6980\n","Epoch 13/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4508 - accuracy: 0.7821 - val_loss: 0.6295 - val_accuracy: 0.6742\n","Epoch 14/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4494 - accuracy: 0.7883 - val_loss: 0.6268 - val_accuracy: 0.6595\n","Epoch 15/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.4492 - accuracy: 0.7813 - val_loss: 0.6199 - val_accuracy: 0.6991\n","Epoch 16/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.4401 - accuracy: 0.7965 - val_loss: 0.6186 - val_accuracy: 0.7115\n","Epoch 17/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4401 - accuracy: 0.7883 - val_loss: 0.6113 - val_accuracy: 0.6810\n","Epoch 18/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4406 - accuracy: 0.7878 - val_loss: 0.6047 - val_accuracy: 0.7070\n","Epoch 19/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4406 - accuracy: 0.7912 - val_loss: 0.6094 - val_accuracy: 0.6776\n","Epoch 20/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4382 - accuracy: 0.7965 - val_loss: 0.6059 - val_accuracy: 0.6923\n","Epoch 21/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4348 - accuracy: 0.7929 - val_loss: 0.6066 - val_accuracy: 0.7206\n","Epoch 22/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4391 - accuracy: 0.7883 - val_loss: 0.6095 - val_accuracy: 0.6833\n","Epoch 23/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4345 - accuracy: 0.7923 - val_loss: 0.6012 - val_accuracy: 0.7025\n","Epoch 24/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4293 - accuracy: 0.7957 - val_loss: 0.6091 - val_accuracy: 0.6912\n","Epoch 25/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4240 - accuracy: 0.7977 - val_loss: 0.6402 - val_accuracy: 0.7070\n","Epoch 26/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4234 - accuracy: 0.7982 - val_loss: 0.6263 - val_accuracy: 0.6878\n","Epoch 27/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4274 - accuracy: 0.7926 - val_loss: 0.6259 - val_accuracy: 0.6934\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4287 - accuracy: 0.8016 - val_loss: 0.6214 - val_accuracy: 0.6991\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4213 - accuracy: 0.7994 - val_loss: 0.6238 - val_accuracy: 0.7059\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4204 - accuracy: 0.8022 - val_loss: 0.6316 - val_accuracy: 0.7002\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4135 - accuracy: 0.8053 - val_loss: 0.6610 - val_accuracy: 0.6968\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4204 - accuracy: 0.8022 - val_loss: 0.6421 - val_accuracy: 0.7115\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4198 - accuracy: 0.8025 - val_loss: 0.6440 - val_accuracy: 0.7014\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4194 - accuracy: 0.8050 - val_loss: 0.6644 - val_accuracy: 0.7036\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4089 - accuracy: 0.8132 - val_loss: 0.6607 - val_accuracy: 0.6912\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4183 - accuracy: 0.8022 - val_loss: 0.6538 - val_accuracy: 0.7059\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4135 - accuracy: 0.8059 - val_loss: 0.6652 - val_accuracy: 0.6946\n","Epoch 38/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4104 - accuracy: 0.8070 - val_loss: 0.6504 - val_accuracy: 0.7048\n","Epoch 39/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4069 - accuracy: 0.8065 - val_loss: 0.6603 - val_accuracy: 0.7115\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4047 - accuracy: 0.8096 - val_loss: 0.6605 - val_accuracy: 0.6980\n","Epoch 41/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4016 - accuracy: 0.8101 - val_loss: 0.6558 - val_accuracy: 0.7251\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3982 - accuracy: 0.8141 - val_loss: 0.6775 - val_accuracy: 0.7138\n","Epoch 43/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3942 - accuracy: 0.8214 - val_loss: 0.6650 - val_accuracy: 0.6867\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3924 - accuracy: 0.8098 - val_loss: 0.6668 - val_accuracy: 0.7172\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3902 - accuracy: 0.8144 - val_loss: 0.6804 - val_accuracy: 0.6957\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3902 - accuracy: 0.8226 - val_loss: 0.6945 - val_accuracy: 0.7059\n","Epoch 47/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3904 - accuracy: 0.8169 - val_loss: 0.7165 - val_accuracy: 0.7070\n","Epoch 48/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3895 - accuracy: 0.8183 - val_loss: 0.6749 - val_accuracy: 0.7059\n","Epoch 49/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3863 - accuracy: 0.8198 - val_loss: 0.6741 - val_accuracy: 0.7127\n","Epoch 50/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3865 - accuracy: 0.8226 - val_loss: 0.6828 - val_accuracy: 0.7025\n","Epoch 51/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3822 - accuracy: 0.8200 - val_loss: 0.6847 - val_accuracy: 0.7093\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3907 - accuracy: 0.8149 - val_loss: 0.7091 - val_accuracy: 0.6810\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3809 - accuracy: 0.8254 - val_loss: 0.7282 - val_accuracy: 0.7059\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3867 - accuracy: 0.8164 - val_loss: 0.6929 - val_accuracy: 0.6878\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3747 - accuracy: 0.8328 - val_loss: 0.6942 - val_accuracy: 0.7048\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3704 - accuracy: 0.8328 - val_loss: 0.6913 - val_accuracy: 0.6912\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3815 - accuracy: 0.8243 - val_loss: 0.6929 - val_accuracy: 0.6912\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3757 - accuracy: 0.8271 - val_loss: 0.6978 - val_accuracy: 0.6844\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3801 - accuracy: 0.8240 - val_loss: 0.6924 - val_accuracy: 0.7093\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3832 - accuracy: 0.8152 - val_loss: 0.6797 - val_accuracy: 0.7104\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3637 - accuracy: 0.8415 - val_loss: 0.7302 - val_accuracy: 0.7093\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3734 - accuracy: 0.8274 - val_loss: 0.6949 - val_accuracy: 0.7172\n","Epoch 63/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3693 - accuracy: 0.8277 - val_loss: 0.7114 - val_accuracy: 0.6787\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3609 - accuracy: 0.8373 - val_loss: 0.7267 - val_accuracy: 0.7081\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3653 - accuracy: 0.8328 - val_loss: 0.7202 - val_accuracy: 0.7070\n","Epoch 66/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3683 - accuracy: 0.8390 - val_loss: 0.7214 - val_accuracy: 0.6900\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3621 - accuracy: 0.8370 - val_loss: 0.7183 - val_accuracy: 0.6957\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3594 - accuracy: 0.8356 - val_loss: 0.7263 - val_accuracy: 0.6912\n","Epoch 69/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3524 - accuracy: 0.8387 - val_loss: 0.7505 - val_accuracy: 0.7059\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3588 - accuracy: 0.8415 - val_loss: 0.7333 - val_accuracy: 0.7081\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3503 - accuracy: 0.8381 - val_loss: 0.7277 - val_accuracy: 0.7149\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3528 - accuracy: 0.8379 - val_loss: 0.7375 - val_accuracy: 0.7014\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3583 - accuracy: 0.8353 - val_loss: 0.7278 - val_accuracy: 0.6912\n","Epoch 74/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3582 - accuracy: 0.8393 - val_loss: 0.7472 - val_accuracy: 0.7081\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3476 - accuracy: 0.8444 - val_loss: 0.7249 - val_accuracy: 0.7002\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3409 - accuracy: 0.8463 - val_loss: 0.7346 - val_accuracy: 0.7104\n","Epoch 77/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3452 - accuracy: 0.8500 - val_loss: 0.7335 - val_accuracy: 0.7036\n","Epoch 78/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3476 - accuracy: 0.8486 - val_loss: 0.7302 - val_accuracy: 0.6957\n","Epoch 79/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3571 - accuracy: 0.8370 - val_loss: 0.7318 - val_accuracy: 0.6934\n","Epoch 80/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3436 - accuracy: 0.8509 - val_loss: 0.7364 - val_accuracy: 0.7014\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3447 - accuracy: 0.8466 - val_loss: 0.7590 - val_accuracy: 0.6912\n","Epoch 82/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3405 - accuracy: 0.8492 - val_loss: 0.7311 - val_accuracy: 0.6980\n","Epoch 83/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3374 - accuracy: 0.8463 - val_loss: 0.7405 - val_accuracy: 0.6878\n","Epoch 84/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3385 - accuracy: 0.8537 - val_loss: 0.7730 - val_accuracy: 0.6968\n","Epoch 85/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3359 - accuracy: 0.8500 - val_loss: 0.7335 - val_accuracy: 0.6946\n","Epoch 86/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3324 - accuracy: 0.8466 - val_loss: 0.7345 - val_accuracy: 0.6991\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3391 - accuracy: 0.8480 - val_loss: 0.7566 - val_accuracy: 0.6889\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3331 - accuracy: 0.8483 - val_loss: 0.8013 - val_accuracy: 0.6957\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3274 - accuracy: 0.8585 - val_loss: 0.7517 - val_accuracy: 0.7048\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3196 - accuracy: 0.8605 - val_loss: 0.7611 - val_accuracy: 0.6957\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3337 - accuracy: 0.8495 - val_loss: 0.7707 - val_accuracy: 0.6991\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3286 - accuracy: 0.8514 - val_loss: 0.7619 - val_accuracy: 0.6968\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3387 - accuracy: 0.8503 - val_loss: 0.7987 - val_accuracy: 0.7002\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3231 - accuracy: 0.8565 - val_loss: 0.7932 - val_accuracy: 0.6663\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3240 - accuracy: 0.8591 - val_loss: 0.7836 - val_accuracy: 0.6799\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3218 - accuracy: 0.8574 - val_loss: 0.8063 - val_accuracy: 0.6708\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3205 - accuracy: 0.8611 - val_loss: 0.8372 - val_accuracy: 0.6934\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3224 - accuracy: 0.8560 - val_loss: 0.7572 - val_accuracy: 0.7025\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3187 - accuracy: 0.8543 - val_loss: 0.7733 - val_accuracy: 0.7048\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3107 - accuracy: 0.8605 - val_loss: 0.7673 - val_accuracy: 0.7002\n","{'loss': [0.4874553680419922, 0.4763408601284027, 0.47355327010154724, 0.47707125544548035, 0.4711320698261261, 0.4690890610218048, 0.46125176548957825, 0.458405464887619, 0.4625159502029419, 0.4551220238208771, 0.455037921667099, 0.454058974981308, 0.450787216424942, 0.44943732023239136, 0.4491721987724304, 0.44010624289512634, 0.44009706377983093, 0.44058480858802795, 0.4406212866306305, 0.438175767660141, 0.4348033368587494, 0.4391462206840515, 0.4344571828842163, 0.4293361306190491, 0.4240081012248993, 0.4233885705471039, 0.4273728132247925, 0.42871132493019104, 0.42130184173583984, 0.4204086661338806, 0.41353678703308105, 0.4203964173793793, 0.41976398229599, 0.4194468557834625, 0.40887293219566345, 0.41830548644065857, 0.41352954506874084, 0.41036221385002136, 0.40689313411712646, 0.40465179085731506, 0.4016112983226776, 0.3981981575489044, 0.3942486643791199, 0.39240241050720215, 0.390205055475235, 0.39015617966651917, 0.3904092311859131, 0.3895130455493927, 0.3863103687763214, 0.38647571206092834, 0.38224923610687256, 0.39066120982170105, 0.38090717792510986, 0.3867068290710449, 0.3747030198574066, 0.37043896317481995, 0.3815380036830902, 0.3756692111492157, 0.3801208734512329, 0.38317248225212097, 0.3637125790119171, 0.3733862340450287, 0.36925581097602844, 0.3609190583229065, 0.3652859032154083, 0.36828675866127014, 0.3620862364768982, 0.3593558371067047, 0.35242530703544617, 0.3587530553340912, 0.3502957820892334, 0.3527517318725586, 0.35833215713500977, 0.3581961393356323, 0.3476405739784241, 0.3408582806587219, 0.345226913690567, 0.34758448600769043, 0.35708412528038025, 0.3436203896999359, 0.34474891424179077, 0.3405344486236572, 0.3373807966709137, 0.3385203182697296, 0.3358604311943054, 0.3324204981327057, 0.33908864855766296, 0.33306413888931274, 0.32735735177993774, 0.3195604681968689, 0.3337495028972626, 0.32862600684165955, 0.33870041370391846, 0.32314935326576233, 0.32397356629371643, 0.3217667043209076, 0.32054728269577026, 0.32238614559173584, 0.3186669647693634, 0.3107074201107025], 'accuracy': [0.7628749012947083, 0.7739105820655823, 0.7713639140129089, 0.7665534615516663, 0.7713639140129089, 0.7679682970046997, 0.7809846997261047, 0.7758913636207581, 0.7679682970046997, 0.7784380316734314, 0.7795698642730713, 0.7801358103752136, 0.7821165919303894, 0.7883418202400208, 0.7812677025794983, 0.7965478301048279, 0.7883418202400208, 0.7877758741378784, 0.7911714911460876, 0.7965478301048279, 0.7928692698478699, 0.7883418202400208, 0.7923033237457275, 0.7956989407539368, 0.7976796627044678, 0.7982456088066101, 0.7925863265991211, 0.8016412258148193, 0.7993775010108948, 0.8022071123123169, 0.8053197264671326, 0.8022071123123169, 0.8024901151657104, 0.8050367832183838, 0.8132427930831909, 0.8022071123123169, 0.8058856725692749, 0.8070175647735596, 0.8064516186714172, 0.8095642328262329, 0.8101301789283752, 0.814091682434082, 0.821448802947998, 0.8098471760749817, 0.8143746256828308, 0.8225806355476379, 0.8169213533401489, 0.8183361887931824, 0.819750964641571, 0.8225806355476379, 0.8200339674949646, 0.8149405717849731, 0.8254103064537048, 0.8163554072380066, 0.8327674269676208, 0.8327674269676208, 0.8242784142494202, 0.8271080851554871, 0.8239954710006714, 0.8152235150337219, 0.8415393233299255, 0.8273910880088806, 0.8276740312576294, 0.83729487657547, 0.8327674269676208, 0.8389926552772522, 0.8370118737220764, 0.835597038269043, 0.8387096524238586, 0.8415393233299255, 0.8381437659263611, 0.8378607630729675, 0.8353140950202942, 0.839275598526001, 0.8443689942359924, 0.8463497161865234, 0.8500282764434814, 0.848613440990448, 0.8370118737220764, 0.8508771657943726, 0.846632719039917, 0.8491793870925903, 0.8463497161865234, 0.8537068367004395, 0.8500282764434814, 0.846632719039917, 0.8480475544929504, 0.8483304977416992, 0.8585172891616821, 0.8604980111122131, 0.8494623899459839, 0.8514431118965149, 0.850311279296875, 0.8565365076065063, 0.8590831756591797, 0.8573853969573975, 0.8610639572143555, 0.855970561504364, 0.8542727828025818, 0.8604980111122131], 'val_loss': [0.6821894645690918, 0.679594099521637, 0.6711834669113159, 0.67911297082901, 0.6671839356422424, 0.6631441712379456, 0.6610023379325867, 0.6600255966186523, 0.6556617617607117, 0.6547691822052002, 0.6484506726264954, 0.6377206444740295, 0.6295042634010315, 0.6267877221107483, 0.6198749542236328, 0.6186068654060364, 0.6113408207893372, 0.6046518087387085, 0.6094027161598206, 0.6058714985847473, 0.6065753102302551, 0.6095290780067444, 0.6011902093887329, 0.6091210842132568, 0.6401537656784058, 0.6262634992599487, 0.6258876919746399, 0.6213771104812622, 0.6238071322441101, 0.6316031217575073, 0.6610110998153687, 0.6420522928237915, 0.6440387964248657, 0.664375364780426, 0.6607189774513245, 0.6537728905677795, 0.6651968359947205, 0.6504136919975281, 0.6602985262870789, 0.660529375076294, 0.6558048725128174, 0.6774759292602539, 0.664971649646759, 0.6668376922607422, 0.6803635358810425, 0.694510281085968, 0.7165001034736633, 0.6748642325401306, 0.6740773320198059, 0.6827992796897888, 0.6846762895584106, 0.7090776562690735, 0.7282209396362305, 0.6928526759147644, 0.6941649913787842, 0.6913209557533264, 0.692876398563385, 0.6977713108062744, 0.692360520362854, 0.6796521544456482, 0.7302466630935669, 0.6949489712715149, 0.7114481329917908, 0.7266764044761658, 0.720192551612854, 0.7213819622993469, 0.7183108925819397, 0.7263234257698059, 0.7504716515541077, 0.7333166599273682, 0.7276937961578369, 0.73749178647995, 0.7278088331222534, 0.7471610307693481, 0.7249178886413574, 0.7346181869506836, 0.7334960699081421, 0.7301732301712036, 0.7318488955497742, 0.7364039421081543, 0.7590016722679138, 0.7310622334480286, 0.740471363067627, 0.7729969024658203, 0.7335302233695984, 0.7345162630081177, 0.7566013336181641, 0.8013304471969604, 0.75168776512146, 0.7610881924629211, 0.7706553339958191, 0.761854350566864, 0.7987123131752014, 0.7931819558143616, 0.7836004495620728, 0.8063464760780334, 0.8371937870979309, 0.7571848630905151, 0.773271918296814, 0.767256498336792], 'val_accuracy': [0.5373303294181824, 0.5509049892425537, 0.6131221652030945, 0.5509049892425537, 0.6289592981338501, 0.6504524946212769, 0.6549773812294006, 0.6312217116355896, 0.662895917892456, 0.6481900215148926, 0.6719456911087036, 0.6979637742042542, 0.6742081642150879, 0.6595022678375244, 0.6990950107574463, 0.7115384340286255, 0.6809954643249512, 0.7070135474205017, 0.6776018142700195, 0.692307710647583, 0.720588207244873, 0.6832579374313354, 0.7024886608123779, 0.6911764740943909, 0.7070135474205017, 0.6877828240394592, 0.6934388875961304, 0.6990950107574463, 0.7058823704719543, 0.7002262473106384, 0.6968325972557068, 0.7115384340286255, 0.7013574838638306, 0.7036198973655701, 0.6911764740943909, 0.7058823704719543, 0.6945701241493225, 0.7047511339187622, 0.7115384340286255, 0.6979637742042542, 0.7251130938529968, 0.7138009071350098, 0.6866515874862671, 0.7171945571899414, 0.6957013607025146, 0.7058823704719543, 0.7070135474205017, 0.7058823704719543, 0.7126696705818176, 0.7024886608123779, 0.709276020526886, 0.6809954643249512, 0.7058823704719543, 0.6877828240394592, 0.7047511339187622, 0.6911764740943909, 0.6911764740943909, 0.6843891143798828, 0.709276020526886, 0.7104072570800781, 0.709276020526886, 0.7171945571899414, 0.6787330508232117, 0.7081447839736938, 0.7070135474205017, 0.6900452375411987, 0.6957013607025146, 0.6911764740943909, 0.7058823704719543, 0.7081447839736938, 0.7149321436882019, 0.7013574838638306, 0.6911764740943909, 0.7081447839736938, 0.7002262473106384, 0.7104072570800781, 0.7036198973655701, 0.6957013607025146, 0.6934388875961304, 0.7013574838638306, 0.6911764740943909, 0.6979637742042542, 0.6877828240394592, 0.6968325972557068, 0.6945701241493225, 0.6990950107574463, 0.6889140009880066, 0.6957013607025146, 0.7047511339187622, 0.6957013607025146, 0.6990950107574463, 0.6968325972557068, 0.7002262473106384, 0.6662895679473877, 0.679864227771759, 0.6708144545555115, 0.6934388875961304, 0.7024886608123779, 0.7047511339187622, 0.7002262473106384]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.4846 - accuracy: 0.7656"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 56ms/step - loss: 0.4835 - accuracy: 0.7661 - val_loss: 0.6745 - val_accuracy: 0.5713\n","Epoch 2/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4765 - accuracy: 0.7739 - val_loss: 0.6734 - val_accuracy: 0.5589\n","Epoch 3/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4742 - accuracy: 0.7760 - val_loss: 0.6724 - val_accuracy: 0.5599\n","Epoch 4/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4687 - accuracy: 0.7778 - val_loss: 0.6686 - val_accuracy: 0.5764\n","Epoch 5/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4710 - accuracy: 0.7786 - val_loss: 0.6612 - val_accuracy: 0.6147\n","Epoch 6/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4630 - accuracy: 0.7866 - val_loss: 0.6616 - val_accuracy: 0.5909\n","Epoch 7/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4665 - accuracy: 0.7827 - val_loss: 0.6541 - val_accuracy: 0.6333\n","Epoch 8/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4604 - accuracy: 0.7842 - val_loss: 0.6523 - val_accuracy: 0.6343\n","Epoch 9/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4642 - accuracy: 0.7773 - val_loss: 0.6389 - val_accuracy: 0.6674\n","Epoch 10/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4545 - accuracy: 0.7868 - val_loss: 0.6371 - val_accuracy: 0.6591\n","Epoch 11/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4602 - accuracy: 0.7840 - val_loss: 0.6276 - val_accuracy: 0.6684\n","Epoch 12/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4587 - accuracy: 0.7842 - val_loss: 0.6302 - val_accuracy: 0.6798\n","Epoch 13/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4501 - accuracy: 0.7884 - val_loss: 0.6208 - val_accuracy: 0.6870\n","Epoch 14/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4444 - accuracy: 0.7871 - val_loss: 0.6299 - val_accuracy: 0.6612\n","Epoch 15/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4527 - accuracy: 0.7850 - val_loss: 0.6145 - val_accuracy: 0.6911\n","Epoch 16/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4462 - accuracy: 0.7904 - val_loss: 0.6056 - val_accuracy: 0.6890\n","Epoch 17/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4470 - accuracy: 0.7894 - val_loss: 0.6058 - val_accuracy: 0.6911\n","Epoch 18/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4477 - accuracy: 0.7917 - val_loss: 0.6094 - val_accuracy: 0.6942\n","Epoch 19/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4461 - accuracy: 0.7910 - val_loss: 0.6052 - val_accuracy: 0.6787\n","Epoch 20/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4466 - accuracy: 0.7920 - val_loss: 0.6110 - val_accuracy: 0.6911\n","Epoch 21/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4412 - accuracy: 0.7938 - val_loss: 0.6105 - val_accuracy: 0.6829\n","Epoch 22/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4409 - accuracy: 0.7902 - val_loss: 0.6119 - val_accuracy: 0.6911\n","Epoch 23/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4382 - accuracy: 0.7915 - val_loss: 0.6163 - val_accuracy: 0.6787\n","Epoch 24/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4393 - accuracy: 0.7912 - val_loss: 0.6354 - val_accuracy: 0.6952\n","Epoch 25/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4416 - accuracy: 0.7964 - val_loss: 0.6366 - val_accuracy: 0.6818\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.6378 - val_accuracy: 0.6798\n","Epoch 27/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4224 - accuracy: 0.8041 - val_loss: 0.6407 - val_accuracy: 0.6798\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4265 - accuracy: 0.8072 - val_loss: 0.6401 - val_accuracy: 0.6870\n","Epoch 29/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4213 - accuracy: 0.8070 - val_loss: 0.6526 - val_accuracy: 0.6808\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4260 - accuracy: 0.7995 - val_loss: 0.6571 - val_accuracy: 0.6818\n","Epoch 31/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4251 - accuracy: 0.8039 - val_loss: 0.6682 - val_accuracy: 0.6705\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4243 - accuracy: 0.7990 - val_loss: 0.6592 - val_accuracy: 0.6808\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4240 - accuracy: 0.8036 - val_loss: 0.6618 - val_accuracy: 0.6829\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4197 - accuracy: 0.8026 - val_loss: 0.6645 - val_accuracy: 0.6880\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4219 - accuracy: 0.8041 - val_loss: 0.6754 - val_accuracy: 0.6860\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4118 - accuracy: 0.8075 - val_loss: 0.6733 - val_accuracy: 0.6829\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4239 - accuracy: 0.8031 - val_loss: 0.6842 - val_accuracy: 0.6756\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4268 - accuracy: 0.7987 - val_loss: 0.6723 - val_accuracy: 0.6849\n","Epoch 39/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4158 - accuracy: 0.8083 - val_loss: 0.6710 - val_accuracy: 0.6880\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4020 - accuracy: 0.8196 - val_loss: 0.6890 - val_accuracy: 0.6860\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4083 - accuracy: 0.8127 - val_loss: 0.6824 - val_accuracy: 0.6829\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4074 - accuracy: 0.8090 - val_loss: 0.6913 - val_accuracy: 0.6705\n","Epoch 43/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4099 - accuracy: 0.8163 - val_loss: 0.6849 - val_accuracy: 0.6777\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4052 - accuracy: 0.8176 - val_loss: 0.7255 - val_accuracy: 0.6498\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4134 - accuracy: 0.8090 - val_loss: 0.7147 - val_accuracy: 0.6736\n","Epoch 46/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4063 - accuracy: 0.8150 - val_loss: 0.7059 - val_accuracy: 0.6870\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4086 - accuracy: 0.8103 - val_loss: 0.6989 - val_accuracy: 0.6787\n","Epoch 48/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4013 - accuracy: 0.8137 - val_loss: 0.6958 - val_accuracy: 0.6787\n","Epoch 49/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3983 - accuracy: 0.8183 - val_loss: 0.6974 - val_accuracy: 0.6798\n","Epoch 50/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3949 - accuracy: 0.8209 - val_loss: 0.7057 - val_accuracy: 0.6622\n","Epoch 51/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4023 - accuracy: 0.8127 - val_loss: 0.7095 - val_accuracy: 0.6746\n","Epoch 52/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3941 - accuracy: 0.8191 - val_loss: 0.7021 - val_accuracy: 0.6756\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3916 - accuracy: 0.8240 - val_loss: 0.7000 - val_accuracy: 0.6705\n","Epoch 54/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3894 - accuracy: 0.8243 - val_loss: 0.7266 - val_accuracy: 0.6601\n","Epoch 55/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3938 - accuracy: 0.8230 - val_loss: 0.7057 - val_accuracy: 0.6787\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3855 - accuracy: 0.8227 - val_loss: 0.7087 - val_accuracy: 0.6818\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3886 - accuracy: 0.8271 - val_loss: 0.7087 - val_accuracy: 0.6787\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3841 - accuracy: 0.8276 - val_loss: 0.7073 - val_accuracy: 0.6808\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3851 - accuracy: 0.8287 - val_loss: 0.7354 - val_accuracy: 0.6808\n","Epoch 60/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3839 - accuracy: 0.8253 - val_loss: 0.7198 - val_accuracy: 0.6839\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3815 - accuracy: 0.8230 - val_loss: 0.7195 - val_accuracy: 0.6901\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3837 - accuracy: 0.8271 - val_loss: 0.7237 - val_accuracy: 0.6849\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3742 - accuracy: 0.8344 - val_loss: 0.7214 - val_accuracy: 0.6767\n","Epoch 64/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3770 - accuracy: 0.8245 - val_loss: 0.7313 - val_accuracy: 0.6746\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3724 - accuracy: 0.8370 - val_loss: 0.7299 - val_accuracy: 0.6798\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3734 - accuracy: 0.8310 - val_loss: 0.7348 - val_accuracy: 0.6653\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3744 - accuracy: 0.8328 - val_loss: 0.7326 - val_accuracy: 0.6860\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3750 - accuracy: 0.8323 - val_loss: 0.7209 - val_accuracy: 0.6829\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3702 - accuracy: 0.8315 - val_loss: 0.7402 - val_accuracy: 0.6829\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3774 - accuracy: 0.8276 - val_loss: 0.7437 - val_accuracy: 0.6767\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3739 - accuracy: 0.8271 - val_loss: 0.7524 - val_accuracy: 0.6839\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3704 - accuracy: 0.8295 - val_loss: 0.7651 - val_accuracy: 0.6591\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3626 - accuracy: 0.8406 - val_loss: 0.7636 - val_accuracy: 0.6643\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3629 - accuracy: 0.8424 - val_loss: 0.7494 - val_accuracy: 0.6756\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3808 - accuracy: 0.8302 - val_loss: 0.7666 - val_accuracy: 0.6612\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3644 - accuracy: 0.8375 - val_loss: 0.7727 - val_accuracy: 0.6581\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3621 - accuracy: 0.8351 - val_loss: 0.7608 - val_accuracy: 0.6663\n","Epoch 78/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3595 - accuracy: 0.8424 - val_loss: 0.7692 - val_accuracy: 0.6818\n","Epoch 79/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3591 - accuracy: 0.8393 - val_loss: 0.7739 - val_accuracy: 0.6808\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3540 - accuracy: 0.8437 - val_loss: 0.7694 - val_accuracy: 0.6705\n","Epoch 81/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3522 - accuracy: 0.8468 - val_loss: 0.7634 - val_accuracy: 0.6860\n","Epoch 82/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3632 - accuracy: 0.8411 - val_loss: 0.7802 - val_accuracy: 0.6746\n","Epoch 83/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3568 - accuracy: 0.8413 - val_loss: 0.7772 - val_accuracy: 0.6653\n","Epoch 84/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3550 - accuracy: 0.8421 - val_loss: 0.7951 - val_accuracy: 0.6508\n","Epoch 85/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3503 - accuracy: 0.8455 - val_loss: 0.8095 - val_accuracy: 0.6467\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3600 - accuracy: 0.8375 - val_loss: 0.7882 - val_accuracy: 0.6643\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3549 - accuracy: 0.8426 - val_loss: 0.7698 - val_accuracy: 0.6901\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3460 - accuracy: 0.8478 - val_loss: 0.7725 - val_accuracy: 0.6715\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3442 - accuracy: 0.8437 - val_loss: 0.7794 - val_accuracy: 0.6849\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3368 - accuracy: 0.8517 - val_loss: 0.7716 - val_accuracy: 0.6736\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3423 - accuracy: 0.8501 - val_loss: 0.7881 - val_accuracy: 0.6818\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3392 - accuracy: 0.8527 - val_loss: 0.8034 - val_accuracy: 0.6808\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3329 - accuracy: 0.8568 - val_loss: 0.7957 - val_accuracy: 0.6705\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3360 - accuracy: 0.8587 - val_loss: 0.8004 - val_accuracy: 0.6663\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3327 - accuracy: 0.8584 - val_loss: 0.8327 - val_accuracy: 0.6601\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3288 - accuracy: 0.8584 - val_loss: 0.8037 - val_accuracy: 0.6643\n","Epoch 97/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3288 - accuracy: 0.8550 - val_loss: 0.8246 - val_accuracy: 0.6777\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3298 - accuracy: 0.8558 - val_loss: 0.8208 - val_accuracy: 0.6787\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3238 - accuracy: 0.8589 - val_loss: 0.8143 - val_accuracy: 0.6746\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3263 - accuracy: 0.8579 - val_loss: 0.8583 - val_accuracy: 0.6663\n","{'loss': [0.48350614309310913, 0.4764840006828308, 0.474234402179718, 0.46867406368255615, 0.47098657488822937, 0.4629786014556885, 0.4665357768535614, 0.46038591861724854, 0.46422889828681946, 0.4545345902442932, 0.4601500630378723, 0.45869553089141846, 0.4500768482685089, 0.4444195032119751, 0.45274773240089417, 0.446236252784729, 0.44700872898101807, 0.44772762060165405, 0.4460923969745636, 0.4465866982936859, 0.4411770701408386, 0.44087904691696167, 0.43816325068473816, 0.4392581582069397, 0.44157424569129944, 0.43303024768829346, 0.42244887351989746, 0.42649492621421814, 0.4212714731693268, 0.4259909987449646, 0.42509427666664124, 0.42432674765586853, 0.4240065813064575, 0.4197300374507904, 0.42185887694358826, 0.41184186935424805, 0.42386394739151, 0.42684924602508545, 0.41577306389808655, 0.40198731422424316, 0.4083191156387329, 0.4073961675167084, 0.40990132093429565, 0.4051569700241089, 0.4134023189544678, 0.40633028745651245, 0.40861040353775024, 0.4012530446052551, 0.39832213521003723, 0.3949192464351654, 0.4022811949253082, 0.39411693811416626, 0.3915814459323883, 0.3893791139125824, 0.3938010334968567, 0.38553303480148315, 0.3885807394981384, 0.38411617279052734, 0.38511747121810913, 0.38385581970214844, 0.38150331377983093, 0.3836911618709564, 0.374172180891037, 0.3769683241844177, 0.3724374771118164, 0.37337416410446167, 0.37440165877342224, 0.3750236928462982, 0.37021708488464355, 0.3773558437824249, 0.3739337921142578, 0.37037813663482666, 0.36263859272003174, 0.362898051738739, 0.38075050711631775, 0.3644450008869171, 0.3621293604373932, 0.3595268428325653, 0.35906097292900085, 0.3540164828300476, 0.35220521688461304, 0.36316418647766113, 0.3567744195461273, 0.3550417125225067, 0.35029396414756775, 0.35998815298080444, 0.35491594672203064, 0.3459683358669281, 0.34420591592788696, 0.336757630109787, 0.3423028886318207, 0.33918118476867676, 0.3329050838947296, 0.33596092462539673, 0.3326837420463562, 0.3288433849811554, 0.3288305699825287, 0.32980719208717346, 0.32378190755844116, 0.32634544372558594], 'accuracy': [0.7661498785018921, 0.7739018201828003, 0.7759689688682556, 0.7777777910232544, 0.7785529494285583, 0.7865633368492126, 0.7826873660087585, 0.7842377424240112, 0.777260959148407, 0.786821722984314, 0.7839793562889099, 0.7842377424240112, 0.7883720993995667, 0.7870801091194153, 0.7850129008293152, 0.790439248085022, 0.7894057035446167, 0.7917312383651733, 0.7909560799598694, 0.7919896841049194, 0.7937984466552734, 0.7901808619499207, 0.791472852230072, 0.7912144660949707, 0.7963824272155762, 0.7968991994857788, 0.8041343688964844, 0.8072351217269897, 0.8069767355918884, 0.7994831800460815, 0.8038759827613831, 0.7989664077758789, 0.8036175966262817, 0.8025839924812317, 0.8041343688964844, 0.8074935674667358, 0.8031007647514343, 0.7987080216407776, 0.8082687258720398, 0.8196382522583008, 0.8126614689826965, 0.8090439438819885, 0.8162790536880493, 0.8175710439682007, 0.8090439438819885, 0.814987063407898, 0.8103359341621399, 0.8136950731277466, 0.8183462619781494, 0.8209302425384521, 0.8126614689826965, 0.8191214203834534, 0.8240309953689575, 0.8242893815040588, 0.8229973912239075, 0.8227390050888062, 0.8271318078041077, 0.8276485800743103, 0.8286821842193604, 0.8253229856491089, 0.8229973912239075, 0.8271318078041077, 0.8343669176101685, 0.8245478272438049, 0.8369508981704712, 0.8310077786445618, 0.8328165411949158, 0.8322997689247131, 0.8315245509147644, 0.8276485800743103, 0.8271318078041077, 0.8294573426246643, 0.840568482875824, 0.842377245426178, 0.830232560634613, 0.8374677300453186, 0.8351421356201172, 0.842377245426178, 0.8392764925956726, 0.8436692357063293, 0.8467700481414795, 0.8410852551460266, 0.8413436412811279, 0.8421188592910767, 0.8454780578613281, 0.8374677300453186, 0.8426356315612793, 0.8478035926818848, 0.8436692357063293, 0.8516795635223389, 0.8501291871070862, 0.8527131676673889, 0.8568475246429443, 0.8586563467979431, 0.8583979606628418, 0.8583979606628418, 0.8550387620925903, 0.8558139801025391, 0.8589147329330444, 0.8578811287879944], 'val_loss': [0.6744791269302368, 0.6733769774436951, 0.6724178791046143, 0.6685675382614136, 0.6612308621406555, 0.6616353988647461, 0.6540594696998596, 0.6523479223251343, 0.6389145255088806, 0.6370859742164612, 0.6276368498802185, 0.6302171349525452, 0.6207834482192993, 0.6298844814300537, 0.6144903898239136, 0.6056499481201172, 0.6057815551757812, 0.6094281077384949, 0.6052404642105103, 0.6110272407531738, 0.610495388507843, 0.6119435429573059, 0.6163235902786255, 0.6353586912155151, 0.6365906000137329, 0.6378242373466492, 0.6406833529472351, 0.640067994594574, 0.6525620818138123, 0.6571473479270935, 0.6681668758392334, 0.6591803431510925, 0.6618034839630127, 0.6644816398620605, 0.6753802299499512, 0.6732556223869324, 0.6841694712638855, 0.6723058819770813, 0.6709877252578735, 0.6890014410018921, 0.6824320554733276, 0.6912862062454224, 0.6848899126052856, 0.7255055904388428, 0.7147421836853027, 0.7058991193771362, 0.6989074945449829, 0.6958392262458801, 0.6973587274551392, 0.7057459354400635, 0.709540605545044, 0.7021444439888, 0.6999963521957397, 0.7266308665275574, 0.7056872844696045, 0.7086665630340576, 0.7086841464042664, 0.707260251045227, 0.7353907227516174, 0.7197942733764648, 0.7194545865058899, 0.7237247228622437, 0.7214338779449463, 0.7313439846038818, 0.7298963665962219, 0.7347643375396729, 0.7325888872146606, 0.720851480960846, 0.7402362823486328, 0.7436501383781433, 0.7524397373199463, 0.765051543712616, 0.7635881304740906, 0.7493608593940735, 0.7666483521461487, 0.772723376750946, 0.7608322501182556, 0.7691923379898071, 0.7739274501800537, 0.7694482207298279, 0.7634329199790955, 0.7801931500434875, 0.777240514755249, 0.7951055765151978, 0.8094724416732788, 0.78824782371521, 0.7697864174842834, 0.772537350654602, 0.7794486880302429, 0.7715680599212646, 0.7880721688270569, 0.8034096360206604, 0.7956987619400024, 0.8003502488136292, 0.8326858878135681, 0.8037423491477966, 0.8245702981948853, 0.8208081126213074, 0.8142796158790588, 0.8582998514175415], 'val_accuracy': [0.5712810158729553, 0.55888432264328, 0.5599173307418823, 0.5764462947845459, 0.6146694421768188, 0.5909090638160706, 0.6332644820213318, 0.6342975497245789, 0.6673553586006165, 0.6590909361839294, 0.6683884263038635, 0.6797520518302917, 0.6869834661483765, 0.6611570119857788, 0.69111567735672, 0.6890496015548706, 0.69111567735672, 0.6942148804664612, 0.6787189841270447, 0.69111567735672, 0.682851254940033, 0.69111567735672, 0.6787189841270447, 0.6952479481697083, 0.6818181872367859, 0.6797520518302917, 0.6797520518302917, 0.6869834661483765, 0.6807851195335388, 0.6818181872367859, 0.6704545617103577, 0.6807851195335388, 0.682851254940033, 0.6880165338516235, 0.6859503984451294, 0.682851254940033, 0.6756198406219482, 0.6849173307418823, 0.6880165338516235, 0.6859503984451294, 0.682851254940033, 0.6704545617103577, 0.6776859760284424, 0.6497933864593506, 0.6735537052154541, 0.6869834661483765, 0.6787189841270447, 0.6787189841270447, 0.6797520518302917, 0.6621900796890259, 0.6745867729187012, 0.6756198406219482, 0.6704545617103577, 0.6601239442825317, 0.6787189841270447, 0.6818181872367859, 0.6787189841270447, 0.6807851195335388, 0.6807851195335388, 0.68388432264328, 0.6900826692581177, 0.6849173307418823, 0.6766529083251953, 0.6745867729187012, 0.6797520518302917, 0.6652892827987671, 0.6859503984451294, 0.682851254940033, 0.682851254940033, 0.6766529083251953, 0.68388432264328, 0.6590909361839294, 0.66425621509552, 0.6756198406219482, 0.6611570119857788, 0.6580578684806824, 0.6663222908973694, 0.6818181872367859, 0.6807851195335388, 0.6704545617103577, 0.6859503984451294, 0.6745867729187012, 0.6652892827987671, 0.6508264541625977, 0.6466942429542542, 0.66425621509552, 0.6900826692581177, 0.6714876294136047, 0.6849173307418823, 0.6735537052154541, 0.6818181872367859, 0.6807851195335388, 0.6704545617103577, 0.6663222908973694, 0.6601239442825317, 0.66425621509552, 0.6776859760284424, 0.6787189841270447, 0.6745867729187012, 0.6663222908973694]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 0.3870 - accuracy: 0.8218"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 53ms/step - loss: 0.3865 - accuracy: 0.8222 - val_loss: 0.6666 - val_accuracy: 0.5205\n","Epoch 2/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3616 - accuracy: 0.8367 - val_loss: 0.6584 - val_accuracy: 0.6164\n","Epoch 3/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3580 - accuracy: 0.8370 - val_loss: 0.6575 - val_accuracy: 0.5938\n","Epoch 4/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3580 - accuracy: 0.8394 - val_loss: 0.6500 - val_accuracy: 0.6067\n","Epoch 5/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3517 - accuracy: 0.8384 - val_loss: 0.6416 - val_accuracy: 0.7004\n","Epoch 6/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3509 - accuracy: 0.8427 - val_loss: 0.6429 - val_accuracy: 0.6153\n","Epoch 7/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3473 - accuracy: 0.8491 - val_loss: 0.6331 - val_accuracy: 0.6207\n","Epoch 8/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3470 - accuracy: 0.8435 - val_loss: 0.6358 - val_accuracy: 0.5916\n","Epoch 9/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3438 - accuracy: 0.8556 - val_loss: 0.6232 - val_accuracy: 0.6228\n","Epoch 10/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3440 - accuracy: 0.8451 - val_loss: 0.6080 - val_accuracy: 0.6584\n","Epoch 11/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3403 - accuracy: 0.8580 - val_loss: 0.6034 - val_accuracy: 0.6476\n","Epoch 12/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3304 - accuracy: 0.8553 - val_loss: 0.5927 - val_accuracy: 0.7198\n","Epoch 13/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3278 - accuracy: 0.8570 - val_loss: 0.5884 - val_accuracy: 0.6853\n","Epoch 14/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3287 - accuracy: 0.8545 - val_loss: 0.5926 - val_accuracy: 0.6724\n","Epoch 15/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3284 - accuracy: 0.8570 - val_loss: 0.5862 - val_accuracy: 0.6638\n","Epoch 16/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3252 - accuracy: 0.8594 - val_loss: 0.5680 - val_accuracy: 0.7166\n","Epoch 17/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3267 - accuracy: 0.8561 - val_loss: 0.5638 - val_accuracy: 0.7188\n","Epoch 18/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3200 - accuracy: 0.8580 - val_loss: 0.5558 - val_accuracy: 0.7047\n","Epoch 19/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3199 - accuracy: 0.8607 - val_loss: 0.5470 - val_accuracy: 0.7144\n","Epoch 20/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3209 - accuracy: 0.8594 - val_loss: 0.5429 - val_accuracy: 0.7080\n","Epoch 21/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3196 - accuracy: 0.8642 - val_loss: 0.5457 - val_accuracy: 0.7317\n","Epoch 22/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3237 - accuracy: 0.8588 - val_loss: 0.5487 - val_accuracy: 0.7306\n","Epoch 23/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3239 - accuracy: 0.8534 - val_loss: 0.5748 - val_accuracy: 0.6907\n","Epoch 24/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3117 - accuracy: 0.8607 - val_loss: 0.5571 - val_accuracy: 0.7338\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3135 - accuracy: 0.8669 - val_loss: 0.5665 - val_accuracy: 0.7198\n","Epoch 26/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3121 - accuracy: 0.8688 - val_loss: 0.5620 - val_accuracy: 0.7403\n","Epoch 27/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3071 - accuracy: 0.8683 - val_loss: 0.5573 - val_accuracy: 0.7575\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3097 - accuracy: 0.8640 - val_loss: 0.5724 - val_accuracy: 0.7532\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3025 - accuracy: 0.8704 - val_loss: 0.5702 - val_accuracy: 0.7478\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2986 - accuracy: 0.8763 - val_loss: 0.5817 - val_accuracy: 0.7511\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3004 - accuracy: 0.8720 - val_loss: 0.6078 - val_accuracy: 0.7198\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3064 - accuracy: 0.8656 - val_loss: 0.5966 - val_accuracy: 0.7317\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2971 - accuracy: 0.8718 - val_loss: 0.6001 - val_accuracy: 0.7209\n","Epoch 34/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3056 - accuracy: 0.8685 - val_loss: 0.5837 - val_accuracy: 0.7457\n","Epoch 35/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3007 - accuracy: 0.8720 - val_loss: 0.5946 - val_accuracy: 0.7468\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3018 - accuracy: 0.8669 - val_loss: 0.5888 - val_accuracy: 0.7500\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2952 - accuracy: 0.8745 - val_loss: 0.5997 - val_accuracy: 0.7371\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2899 - accuracy: 0.8758 - val_loss: 0.6181 - val_accuracy: 0.7425\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3028 - accuracy: 0.8680 - val_loss: 0.6416 - val_accuracy: 0.7360\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2914 - accuracy: 0.8712 - val_loss: 0.6227 - val_accuracy: 0.7306\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2852 - accuracy: 0.8763 - val_loss: 0.5960 - val_accuracy: 0.7381\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2771 - accuracy: 0.8820 - val_loss: 0.6052 - val_accuracy: 0.7414\n","Epoch 43/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2943 - accuracy: 0.8715 - val_loss: 0.6665 - val_accuracy: 0.7500\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2879 - accuracy: 0.8747 - val_loss: 0.6615 - val_accuracy: 0.7478\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2908 - accuracy: 0.8763 - val_loss: 0.6600 - val_accuracy: 0.7435\n","Epoch 46/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2874 - accuracy: 0.8761 - val_loss: 0.6248 - val_accuracy: 0.7317\n","Epoch 47/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2793 - accuracy: 0.8831 - val_loss: 0.6123 - val_accuracy: 0.7435\n","Epoch 48/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2832 - accuracy: 0.8852 - val_loss: 0.6281 - val_accuracy: 0.7532\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2791 - accuracy: 0.8836 - val_loss: 0.6093 - val_accuracy: 0.7425\n","Epoch 50/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2709 - accuracy: 0.8885 - val_loss: 0.6371 - val_accuracy: 0.7371\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2716 - accuracy: 0.8890 - val_loss: 0.6492 - val_accuracy: 0.7037\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2765 - accuracy: 0.8850 - val_loss: 0.6199 - val_accuracy: 0.7403\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2721 - accuracy: 0.8844 - val_loss: 0.6310 - val_accuracy: 0.7360\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2596 - accuracy: 0.8952 - val_loss: 0.6357 - val_accuracy: 0.7425\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2770 - accuracy: 0.8831 - val_loss: 0.6594 - val_accuracy: 0.7371\n","Epoch 56/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2579 - accuracy: 0.8914 - val_loss: 0.6336 - val_accuracy: 0.7446\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2674 - accuracy: 0.8869 - val_loss: 0.6745 - val_accuracy: 0.7123\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2634 - accuracy: 0.8928 - val_loss: 0.6352 - val_accuracy: 0.7381\n","Epoch 59/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2602 - accuracy: 0.8909 - val_loss: 0.6602 - val_accuracy: 0.7457\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2674 - accuracy: 0.8893 - val_loss: 0.6573 - val_accuracy: 0.7446\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2614 - accuracy: 0.8917 - val_loss: 0.6388 - val_accuracy: 0.7468\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2592 - accuracy: 0.8955 - val_loss: 0.6439 - val_accuracy: 0.7317\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2697 - accuracy: 0.8836 - val_loss: 0.6868 - val_accuracy: 0.7188\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2558 - accuracy: 0.8928 - val_loss: 0.7188 - val_accuracy: 0.7252\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2593 - accuracy: 0.8895 - val_loss: 0.6483 - val_accuracy: 0.7381\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2558 - accuracy: 0.8957 - val_loss: 0.6597 - val_accuracy: 0.7220\n","Epoch 67/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2586 - accuracy: 0.8949 - val_loss: 0.6885 - val_accuracy: 0.7392\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2475 - accuracy: 0.9019 - val_loss: 0.6708 - val_accuracy: 0.7360\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2415 - accuracy: 0.9033 - val_loss: 0.6438 - val_accuracy: 0.7468\n","Epoch 70/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2464 - accuracy: 0.8982 - val_loss: 0.6715 - val_accuracy: 0.7166\n","Epoch 71/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2493 - accuracy: 0.8976 - val_loss: 0.6757 - val_accuracy: 0.7371\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2464 - accuracy: 0.9019 - val_loss: 0.7089 - val_accuracy: 0.7058\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2388 - accuracy: 0.9022 - val_loss: 0.6895 - val_accuracy: 0.7295\n","Epoch 74/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2474 - accuracy: 0.8992 - val_loss: 0.6867 - val_accuracy: 0.7468\n","Epoch 75/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2445 - accuracy: 0.9009 - val_loss: 0.7092 - val_accuracy: 0.7392\n","Epoch 76/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2427 - accuracy: 0.8976 - val_loss: 0.6864 - val_accuracy: 0.7425\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2274 - accuracy: 0.9103 - val_loss: 0.7059 - val_accuracy: 0.7263\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2399 - accuracy: 0.8976 - val_loss: 0.7228 - val_accuracy: 0.7435\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2349 - accuracy: 0.9017 - val_loss: 0.6865 - val_accuracy: 0.7435\n","Epoch 80/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2432 - accuracy: 0.9014 - val_loss: 0.6891 - val_accuracy: 0.7360\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2515 - accuracy: 0.8990 - val_loss: 0.6816 - val_accuracy: 0.7468\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2302 - accuracy: 0.9076 - val_loss: 0.6902 - val_accuracy: 0.7371\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2283 - accuracy: 0.9089 - val_loss: 0.7222 - val_accuracy: 0.7371\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2311 - accuracy: 0.9073 - val_loss: 0.7002 - val_accuracy: 0.7360\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2310 - accuracy: 0.9103 - val_loss: 0.7175 - val_accuracy: 0.7263\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2358 - accuracy: 0.9049 - val_loss: 0.7027 - val_accuracy: 0.7392\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2417 - accuracy: 0.9014 - val_loss: 0.7147 - val_accuracy: 0.7349\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2378 - accuracy: 0.9036 - val_loss: 0.7267 - val_accuracy: 0.7381\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2204 - accuracy: 0.9111 - val_loss: 0.6919 - val_accuracy: 0.7446\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2229 - accuracy: 0.9092 - val_loss: 0.7282 - val_accuracy: 0.7457\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2233 - accuracy: 0.9062 - val_loss: 0.6960 - val_accuracy: 0.7457\n","Epoch 92/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2263 - accuracy: 0.9060 - val_loss: 0.7337 - val_accuracy: 0.7295\n","Epoch 93/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2291 - accuracy: 0.9044 - val_loss: 0.7691 - val_accuracy: 0.6940\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2315 - accuracy: 0.9092 - val_loss: 0.7177 - val_accuracy: 0.7349\n","Epoch 95/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2180 - accuracy: 0.9127 - val_loss: 0.7128 - val_accuracy: 0.7435\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2180 - accuracy: 0.9127 - val_loss: 0.7298 - val_accuracy: 0.7403\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2248 - accuracy: 0.9057 - val_loss: 0.7243 - val_accuracy: 0.7381\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2146 - accuracy: 0.9154 - val_loss: 0.7656 - val_accuracy: 0.7274\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2180 - accuracy: 0.9108 - val_loss: 0.7536 - val_accuracy: 0.7328\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2232 - accuracy: 0.9130 - val_loss: 0.7641 - val_accuracy: 0.7392\n","{'loss': [0.3865163326263428, 0.36160996556282043, 0.3579776883125305, 0.3580394685268402, 0.35170334577560425, 0.3508983254432678, 0.3472597002983093, 0.3469735085964203, 0.34375107288360596, 0.3440098166465759, 0.34028497338294983, 0.3303971588611603, 0.32784146070480347, 0.3286918103694916, 0.3283518850803375, 0.32521289587020874, 0.3267347514629364, 0.3200216591358185, 0.3199058771133423, 0.3208748400211334, 0.3195992708206177, 0.3237275779247284, 0.32386380434036255, 0.31173476576805115, 0.31354790925979614, 0.31212520599365234, 0.3070887625217438, 0.30968940258026123, 0.3025258481502533, 0.2985614836215973, 0.30038511753082275, 0.3063894510269165, 0.29707998037338257, 0.3056027293205261, 0.3007389008998871, 0.3017822504043579, 0.2951544523239136, 0.2898934483528137, 0.302750825881958, 0.291385680437088, 0.2851540446281433, 0.277081161737442, 0.2942960262298584, 0.28789907693862915, 0.29075556993484497, 0.2873585522174835, 0.2793428897857666, 0.28321021795272827, 0.2790951132774353, 0.27087539434432983, 0.27158814668655396, 0.27654072642326355, 0.27212196588516235, 0.25964805483818054, 0.27696502208709717, 0.2579464614391327, 0.2673608958721161, 0.2634221017360687, 0.26018044352531433, 0.2673662602901459, 0.2613776922225952, 0.2591888904571533, 0.26972803473472595, 0.2557803988456726, 0.2592867612838745, 0.25579431653022766, 0.258579283952713, 0.24754022061824799, 0.2414601445198059, 0.2464386522769928, 0.24925559759140015, 0.24639791250228882, 0.23879161477088928, 0.24736416339874268, 0.24446547031402588, 0.24267420172691345, 0.22743281722068787, 0.23990826308727264, 0.2349100261926651, 0.24319128692150116, 0.2515442967414856, 0.23021845519542694, 0.22834603488445282, 0.2311273217201233, 0.23104074597358704, 0.23581808805465698, 0.24173758924007416, 0.2377542108297348, 0.2203960418701172, 0.22293461859226227, 0.22328025102615356, 0.22634755074977875, 0.22910632193088531, 0.2314567118883133, 0.21802477538585663, 0.21804651618003845, 0.22482548654079437, 0.2146078497171402, 0.21796627342700958, 0.22322532534599304], 'accuracy': [0.8221982717514038, 0.8367456793785095, 0.8370150923728943, 0.8394396305084229, 0.8383620977401733, 0.8426724076271057, 0.8491379022598267, 0.8434805870056152, 0.8556034564971924, 0.845097005367279, 0.858027994632721, 0.8553340435028076, 0.8569504022598267, 0.8545258641242981, 0.8569504022598267, 0.859375, 0.8561422228813171, 0.858027994632721, 0.860722005367279, 0.859375, 0.8642241358757019, 0.8588362336158752, 0.8534482717514038, 0.860722005367279, 0.8669180870056152, 0.868803858757019, 0.8682650923728943, 0.8639547228813171, 0.8704202771186829, 0.876347005367279, 0.8720366358757019, 0.865571141242981, 0.8717672228813171, 0.868534505367279, 0.8720366358757019, 0.8669180870056152, 0.8744612336158752, 0.8758081793785095, 0.8679956793785095, 0.8712284564971924, 0.876347005367279, 0.8820043206214905, 0.8714978694915771, 0.8747305870056152, 0.876347005367279, 0.8760775923728943, 0.8830819129943848, 0.8852370977401733, 0.8836206793785095, 0.8884698152542114, 0.889008641242981, 0.8849676847457886, 0.884428858757019, 0.8952047228813171, 0.8830819129943848, 0.8914331793785095, 0.8868534564971924, 0.8927801847457886, 0.8908944129943848, 0.889277994632721, 0.8917025923728943, 0.8954741358757019, 0.8836206793785095, 0.8927801847457886, 0.8895474076271057, 0.8957435488700867, 0.8949353694915771, 0.9019396305084229, 0.9032866358757019, 0.8981680870056152, 0.8976293206214905, 0.9019396305084229, 0.9022090435028076, 0.8992456793785095, 0.9008620977401733, 0.8976293206214905, 0.9102909564971924, 0.8976293206214905, 0.9016702771186829, 0.9014008641242981, 0.8989762663841248, 0.907597005367279, 0.9089439511299133, 0.9073275923728943, 0.9102909564971924, 0.904902994632721, 0.9014008641242981, 0.9035560488700867, 0.9110991358757019, 0.9092133641242981, 0.90625, 0.9059805870056152, 0.9043642282485962, 0.9092133641242981, 0.912715494632721, 0.912715494632721, 0.9057112336158752, 0.915409505367279, 0.9108297228813171, 0.9129849076271057], 'val_loss': [0.666569173336029, 0.6584306359291077, 0.6575214862823486, 0.6500471830368042, 0.6416297554969788, 0.6429248452186584, 0.63310706615448, 0.6358188390731812, 0.623221755027771, 0.607954740524292, 0.6034109592437744, 0.592658519744873, 0.588431179523468, 0.592581033706665, 0.5861911773681641, 0.568037211894989, 0.5637662410736084, 0.5558115243911743, 0.5469685792922974, 0.5428951382637024, 0.5457031726837158, 0.5486985445022583, 0.5747534036636353, 0.5571287870407104, 0.5664777159690857, 0.5620148777961731, 0.5573063492774963, 0.572396457195282, 0.5702162384986877, 0.5816642045974731, 0.6077523827552795, 0.5966091752052307, 0.6000944375991821, 0.583687961101532, 0.5945591926574707, 0.5887947678565979, 0.5997219681739807, 0.6181488633155823, 0.6416447758674622, 0.6226511597633362, 0.5959759950637817, 0.6052209138870239, 0.6665283441543579, 0.6615449786186218, 0.6600148677825928, 0.6248417496681213, 0.6122945547103882, 0.6280626654624939, 0.6092904806137085, 0.637078583240509, 0.6492061018943787, 0.6199337244033813, 0.6310141086578369, 0.635675311088562, 0.65940922498703, 0.6335806250572205, 0.6744735240936279, 0.6351794004440308, 0.660189688205719, 0.6572566628456116, 0.6388309597969055, 0.6438822150230408, 0.6867896318435669, 0.7187586426734924, 0.6482567191123962, 0.6596611142158508, 0.6885193586349487, 0.6707887053489685, 0.6437833905220032, 0.6715049147605896, 0.6757169961929321, 0.7089285254478455, 0.6895173788070679, 0.6867454051971436, 0.7091600894927979, 0.6864326000213623, 0.7059142589569092, 0.7227909564971924, 0.686491072177887, 0.6891422271728516, 0.6816491484642029, 0.6901668906211853, 0.7221752405166626, 0.7001688480377197, 0.7175260186195374, 0.7026965022087097, 0.7146613001823425, 0.7267115116119385, 0.6919022798538208, 0.7281607985496521, 0.695952832698822, 0.7336816191673279, 0.7690786123275757, 0.7176960110664368, 0.7127750515937805, 0.7297741174697876, 0.7243108153343201, 0.7656353712081909, 0.753609299659729, 0.76411372423172], 'val_accuracy': [0.5204741358757019, 0.6163793206214905, 0.59375, 0.6066810488700867, 0.7004310488700867, 0.6153017282485962, 0.6206896305084229, 0.5915948152542114, 0.6228448152542114, 0.6584051847457886, 0.6476293206214905, 0.7198275923728943, 0.6853448152542114, 0.6724137663841248, 0.6637930870056152, 0.7165948152542114, 0.71875, 0.704741358757019, 0.7144396305084229, 0.7079741358757019, 0.7316810488700867, 0.7306034564971924, 0.6907327771186829, 0.7338362336158752, 0.7198275923728943, 0.7403017282485962, 0.7575430870056152, 0.7532327771186829, 0.7478448152542114, 0.7510775923728943, 0.7198275923728943, 0.7316810488700867, 0.7209051847457886, 0.7456896305084229, 0.7467672228813171, 0.75, 0.7370689511299133, 0.7424569129943848, 0.735991358757019, 0.7306034564971924, 0.7381465435028076, 0.7413793206214905, 0.75, 0.7478448152542114, 0.743534505367279, 0.7316810488700867, 0.743534505367279, 0.7532327771186829, 0.7424569129943848, 0.7370689511299133, 0.7036637663841248, 0.7403017282485962, 0.735991358757019, 0.7424569129943848, 0.7370689511299133, 0.7446120977401733, 0.712284505367279, 0.7381465435028076, 0.7456896305084229, 0.7446120977401733, 0.7467672228813171, 0.7316810488700867, 0.71875, 0.725215494632721, 0.7381465435028076, 0.7219827771186829, 0.7392241358757019, 0.735991358757019, 0.7467672228813171, 0.7165948152542114, 0.7370689511299133, 0.7058189511299133, 0.7295258641242981, 0.7467672228813171, 0.7392241358757019, 0.7424569129943848, 0.7262930870056152, 0.743534505367279, 0.743534505367279, 0.735991358757019, 0.7467672228813171, 0.7370689511299133, 0.7370689511299133, 0.735991358757019, 0.7262930870056152, 0.7392241358757019, 0.7349137663841248, 0.7381465435028076, 0.7446120977401733, 0.7456896305084229, 0.7456896305084229, 0.7295258641242981, 0.693965494632721, 0.7349137663841248, 0.743534505367279, 0.7403017282485962, 0.7381465435028076, 0.7273706793785095, 0.732758641242981, 0.7392241358757019]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.3870 - accuracy: 0.8212"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 7s 70ms/step - loss: 0.3853 - accuracy: 0.8229 - val_loss: 0.6763 - val_accuracy: 0.5170\n","Epoch 2/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3767 - accuracy: 0.8263 - val_loss: 0.6698 - val_accuracy: 0.5611\n","Epoch 3/100\n","28/28 [==============================] - 1s 17ms/step - loss: 0.3674 - accuracy: 0.8342 - val_loss: 0.6684 - val_accuracy: 0.5305\n","Epoch 4/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3616 - accuracy: 0.8359 - val_loss: 0.6700 - val_accuracy: 0.5226\n","Epoch 5/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3568 - accuracy: 0.8396 - val_loss: 0.6671 - val_accuracy: 0.5373\n","Epoch 6/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3634 - accuracy: 0.8305 - val_loss: 0.6569 - val_accuracy: 0.5826\n","Epoch 7/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3551 - accuracy: 0.8390 - val_loss: 0.6528 - val_accuracy: 0.5498\n","Epoch 8/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3541 - accuracy: 0.8415 - val_loss: 0.6523 - val_accuracy: 0.5826\n","Epoch 9/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3451 - accuracy: 0.8353 - val_loss: 0.6423 - val_accuracy: 0.6007\n","Epoch 10/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3468 - accuracy: 0.8452 - val_loss: 0.6377 - val_accuracy: 0.5916\n","Epoch 11/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3461 - accuracy: 0.8424 - val_loss: 0.6241 - val_accuracy: 0.6357\n","Epoch 12/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3368 - accuracy: 0.8497 - val_loss: 0.6323 - val_accuracy: 0.6120\n","Epoch 13/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3332 - accuracy: 0.8557 - val_loss: 0.6218 - val_accuracy: 0.6753\n","Epoch 14/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3373 - accuracy: 0.8432 - val_loss: 0.5959 - val_accuracy: 0.6708\n","Epoch 15/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3282 - accuracy: 0.8568 - val_loss: 0.5947 - val_accuracy: 0.6708\n","Epoch 16/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3263 - accuracy: 0.8520 - val_loss: 0.6032 - val_accuracy: 0.6527\n","Epoch 17/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3311 - accuracy: 0.8472 - val_loss: 0.6162 - val_accuracy: 0.6640\n","Epoch 18/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3397 - accuracy: 0.8523 - val_loss: 0.5800 - val_accuracy: 0.6934\n","Epoch 19/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3201 - accuracy: 0.8585 - val_loss: 0.5780 - val_accuracy: 0.6855\n","Epoch 20/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3234 - accuracy: 0.8580 - val_loss: 0.5569 - val_accuracy: 0.7059\n","Epoch 21/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3293 - accuracy: 0.8546 - val_loss: 0.5524 - val_accuracy: 0.7421\n","Epoch 22/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3195 - accuracy: 0.8577 - val_loss: 0.5711 - val_accuracy: 0.7014\n","Epoch 23/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3198 - accuracy: 0.8577 - val_loss: 0.5807 - val_accuracy: 0.7376\n","Epoch 24/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3247 - accuracy: 0.8529 - val_loss: 0.5765 - val_accuracy: 0.7149\n","Epoch 25/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3221 - accuracy: 0.8577 - val_loss: 0.5779 - val_accuracy: 0.7477\n","Epoch 26/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3163 - accuracy: 0.8611 - val_loss: 0.5627 - val_accuracy: 0.7387\n","Epoch 27/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3163 - accuracy: 0.8582 - val_loss: 0.5749 - val_accuracy: 0.7500\n","Epoch 28/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.3150 - accuracy: 0.8645 - val_loss: 0.6091 - val_accuracy: 0.7557\n","Epoch 29/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3172 - accuracy: 0.8577 - val_loss: 0.5930 - val_accuracy: 0.7410\n","Epoch 30/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3094 - accuracy: 0.8613 - val_loss: 0.6072 - val_accuracy: 0.7376\n","Epoch 31/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3083 - accuracy: 0.8647 - val_loss: 0.6210 - val_accuracy: 0.7262\n","Epoch 32/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3192 - accuracy: 0.8619 - val_loss: 0.6273 - val_accuracy: 0.7115\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3075 - accuracy: 0.8667 - val_loss: 0.6360 - val_accuracy: 0.7251\n","Epoch 34/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3034 - accuracy: 0.8664 - val_loss: 0.6203 - val_accuracy: 0.7364\n","Epoch 35/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3002 - accuracy: 0.8656 - val_loss: 0.6163 - val_accuracy: 0.7455\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3098 - accuracy: 0.8622 - val_loss: 0.6431 - val_accuracy: 0.7285\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2945 - accuracy: 0.8662 - val_loss: 0.6285 - val_accuracy: 0.7319\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3077 - accuracy: 0.8630 - val_loss: 0.6535 - val_accuracy: 0.7296\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2978 - accuracy: 0.8704 - val_loss: 0.6512 - val_accuracy: 0.7262\n","Epoch 40/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2928 - accuracy: 0.8704 - val_loss: 0.6440 - val_accuracy: 0.7342\n","Epoch 41/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3075 - accuracy: 0.8616 - val_loss: 0.6529 - val_accuracy: 0.7364\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2991 - accuracy: 0.8729 - val_loss: 0.6438 - val_accuracy: 0.7466\n","Epoch 43/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2887 - accuracy: 0.8775 - val_loss: 0.6612 - val_accuracy: 0.7217\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2995 - accuracy: 0.8684 - val_loss: 0.6530 - val_accuracy: 0.7443\n","Epoch 45/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3017 - accuracy: 0.8710 - val_loss: 0.6641 - val_accuracy: 0.7364\n","Epoch 46/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2936 - accuracy: 0.8766 - val_loss: 0.6333 - val_accuracy: 0.7342\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2987 - accuracy: 0.8724 - val_loss: 0.6854 - val_accuracy: 0.7477\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2853 - accuracy: 0.8778 - val_loss: 0.6643 - val_accuracy: 0.7398\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2905 - accuracy: 0.8755 - val_loss: 0.6616 - val_accuracy: 0.7296\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2941 - accuracy: 0.8746 - val_loss: 0.6450 - val_accuracy: 0.7443\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2825 - accuracy: 0.8772 - val_loss: 0.6507 - val_accuracy: 0.7443\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2819 - accuracy: 0.8772 - val_loss: 0.6682 - val_accuracy: 0.7217\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2894 - accuracy: 0.8704 - val_loss: 0.6506 - val_accuracy: 0.7262\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2836 - accuracy: 0.8786 - val_loss: 0.6524 - val_accuracy: 0.7229\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2747 - accuracy: 0.8846 - val_loss: 0.6500 - val_accuracy: 0.7319\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2743 - accuracy: 0.8834 - val_loss: 0.6695 - val_accuracy: 0.7489\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2846 - accuracy: 0.8744 - val_loss: 0.7206 - val_accuracy: 0.7285\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2739 - accuracy: 0.8820 - val_loss: 0.6959 - val_accuracy: 0.7319\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2767 - accuracy: 0.8806 - val_loss: 0.6664 - val_accuracy: 0.7500\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2687 - accuracy: 0.8857 - val_loss: 0.6677 - val_accuracy: 0.7511\n","Epoch 61/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2684 - accuracy: 0.8809 - val_loss: 0.6575 - val_accuracy: 0.7262\n","Epoch 62/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2669 - accuracy: 0.8840 - val_loss: 0.6959 - val_accuracy: 0.7376\n","Epoch 63/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2616 - accuracy: 0.8865 - val_loss: 0.6990 - val_accuracy: 0.7455\n","Epoch 64/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2598 - accuracy: 0.8871 - val_loss: 0.7628 - val_accuracy: 0.7172\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2695 - accuracy: 0.8888 - val_loss: 0.6987 - val_accuracy: 0.7229\n","Epoch 66/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2791 - accuracy: 0.8817 - val_loss: 0.7030 - val_accuracy: 0.7138\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2623 - accuracy: 0.8899 - val_loss: 0.7250 - val_accuracy: 0.7262\n","Epoch 68/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2622 - accuracy: 0.8877 - val_loss: 0.8249 - val_accuracy: 0.7206\n","Epoch 69/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2713 - accuracy: 0.8843 - val_loss: 0.7011 - val_accuracy: 0.7104\n","Epoch 70/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2614 - accuracy: 0.8865 - val_loss: 0.6763 - val_accuracy: 0.7432\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2664 - accuracy: 0.8891 - val_loss: 0.7423 - val_accuracy: 0.7387\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2566 - accuracy: 0.8896 - val_loss: 0.7522 - val_accuracy: 0.7240\n","Epoch 73/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2720 - accuracy: 0.8814 - val_loss: 0.7706 - val_accuracy: 0.7217\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2524 - accuracy: 0.8939 - val_loss: 0.7173 - val_accuracy: 0.7274\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2529 - accuracy: 0.8962 - val_loss: 0.7361 - val_accuracy: 0.6844\n","Epoch 76/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2551 - accuracy: 0.8973 - val_loss: 0.7095 - val_accuracy: 0.7421\n","Epoch 77/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2619 - accuracy: 0.8879 - val_loss: 0.7118 - val_accuracy: 0.7353\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2562 - accuracy: 0.8939 - val_loss: 0.7254 - val_accuracy: 0.7330\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2543 - accuracy: 0.8933 - val_loss: 0.7137 - val_accuracy: 0.7387\n","Epoch 80/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2533 - accuracy: 0.8885 - val_loss: 0.7058 - val_accuracy: 0.7376\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2475 - accuracy: 0.8962 - val_loss: 0.7064 - val_accuracy: 0.7296\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2585 - accuracy: 0.8896 - val_loss: 0.7190 - val_accuracy: 0.7195\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2579 - accuracy: 0.8879 - val_loss: 0.7344 - val_accuracy: 0.7432\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2448 - accuracy: 0.9001 - val_loss: 0.7324 - val_accuracy: 0.7353\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2453 - accuracy: 0.8967 - val_loss: 0.7900 - val_accuracy: 0.7387\n","Epoch 86/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2449 - accuracy: 0.9012 - val_loss: 0.7181 - val_accuracy: 0.7376\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2409 - accuracy: 0.8987 - val_loss: 0.7431 - val_accuracy: 0.7387\n","Epoch 88/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2455 - accuracy: 0.9007 - val_loss: 0.7493 - val_accuracy: 0.7195\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2441 - accuracy: 0.9032 - val_loss: 0.7292 - val_accuracy: 0.7376\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2357 - accuracy: 0.9049 - val_loss: 0.7675 - val_accuracy: 0.7229\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2321 - accuracy: 0.9100 - val_loss: 0.7775 - val_accuracy: 0.7115\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2338 - accuracy: 0.9058 - val_loss: 0.7263 - val_accuracy: 0.7285\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2238 - accuracy: 0.9111 - val_loss: 0.7615 - val_accuracy: 0.7330\n","Epoch 94/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2490 - accuracy: 0.8945 - val_loss: 0.8082 - val_accuracy: 0.7127\n","Epoch 95/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2430 - accuracy: 0.8973 - val_loss: 0.7726 - val_accuracy: 0.7285\n","Epoch 96/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2303 - accuracy: 0.9072 - val_loss: 0.7675 - val_accuracy: 0.7342\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2334 - accuracy: 0.9103 - val_loss: 0.8179 - val_accuracy: 0.7432\n","Epoch 98/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2311 - accuracy: 0.9069 - val_loss: 0.8586 - val_accuracy: 0.7149\n","Epoch 99/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2318 - accuracy: 0.9027 - val_loss: 0.8166 - val_accuracy: 0.7172\n","Epoch 100/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2257 - accuracy: 0.9080 - val_loss: 0.7980 - val_accuracy: 0.7251\n","{'loss': [0.38534942269325256, 0.3767017424106598, 0.36742499470710754, 0.3615989685058594, 0.35677391290664673, 0.36343446373939514, 0.35512787103652954, 0.35412654280662537, 0.34511902928352356, 0.34677013754844666, 0.34611260890960693, 0.3368147313594818, 0.333189994096756, 0.33730292320251465, 0.32816171646118164, 0.32625752687454224, 0.3310745358467102, 0.33969423174858093, 0.3201357424259186, 0.32336482405662537, 0.3292761743068695, 0.31947988271713257, 0.31980693340301514, 0.32474663853645325, 0.32205629348754883, 0.3162569999694824, 0.3162946403026581, 0.31500422954559326, 0.31720879673957825, 0.3093824088573456, 0.30829861760139465, 0.3192216157913208, 0.30752816796302795, 0.3033878803253174, 0.3002361059188843, 0.30977100133895874, 0.29454588890075684, 0.30766329169273376, 0.29775312542915344, 0.29278478026390076, 0.30751892924308777, 0.29910579323768616, 0.28870221972465515, 0.2995483875274658, 0.3016826808452606, 0.2936125099658966, 0.2987099587917328, 0.2853378653526306, 0.29051053524017334, 0.29406172037124634, 0.2824574410915375, 0.2818883955478668, 0.2894006669521332, 0.28360721468925476, 0.27471277117729187, 0.2742760479450226, 0.2846072316169739, 0.2739212214946747, 0.2767000198364258, 0.268716037273407, 0.2684362828731537, 0.26690351963043213, 0.2615697383880615, 0.2597762942314148, 0.26954302191734314, 0.27906957268714905, 0.26228630542755127, 0.2621877193450928, 0.271274209022522, 0.2614000141620636, 0.2664133608341217, 0.2565965950489044, 0.2719535827636719, 0.2523678243160248, 0.252930611371994, 0.2550613284111023, 0.2619415521621704, 0.25615543127059937, 0.25433677434921265, 0.25334373116493225, 0.24749909341335297, 0.25850871205329895, 0.25790607929229736, 0.24480488896369934, 0.24530015885829926, 0.24486219882965088, 0.24086643755435944, 0.245529443025589, 0.24406510591506958, 0.23570124804973602, 0.232089564204216, 0.23381014168262482, 0.22380180656909943, 0.24902936816215515, 0.24299199879169464, 0.23028959333896637, 0.2333659678697586, 0.2310730367898941, 0.23178943991661072, 0.22565732896327972], 'accuracy': [0.8228636384010315, 0.826259195804596, 0.8341822028160095, 0.8358800411224365, 0.8395586013793945, 0.8305037021636963, 0.8389926552772522, 0.8415393233299255, 0.8353140950202942, 0.8452178835868835, 0.8423882126808167, 0.8497453331947327, 0.8556876182556152, 0.8432371020317078, 0.8568194508552551, 0.8520090579986572, 0.8471986651420593, 0.852292001247406, 0.8585172891616821, 0.8579513430595398, 0.8545557260513306, 0.8576683402061462, 0.8576683402061462, 0.8528579473495483, 0.8576683402061462, 0.8610639572143555, 0.8582342863082886, 0.8644595146179199, 0.8576683402061462, 0.8613469004631042, 0.8647425174713135, 0.8619128465652466, 0.8667232394218445, 0.8664402961730957, 0.8655914068222046, 0.8621957898139954, 0.8661573529243469, 0.8630446791648865, 0.8704017996788025, 0.8704017996788025, 0.8616299033164978, 0.8729485273361206, 0.8774759769439697, 0.8684210777282715, 0.8709677457809448, 0.8766270279884338, 0.8723825812339783, 0.8777589201927185, 0.875495195388794, 0.8746463060379028, 0.8771929740905762, 0.8771929740905762, 0.8704017996788025, 0.8786078095436096, 0.8845500946044922, 0.8834182024002075, 0.8743633031845093, 0.8820033669471741, 0.8805885910987854, 0.8856819272041321, 0.8808715343475342, 0.8839841485023499, 0.8865308165550232, 0.8870967626571655, 0.8887945413589478, 0.8817204236984253, 0.8899264335632324, 0.8876627087593079, 0.8842670917510986, 0.8865308165550232, 0.8890775442123413, 0.8896434903144836, 0.8814374804496765, 0.8938879370689392, 0.8961516618728638, 0.8972835540771484, 0.8879456520080566, 0.8938879370689392, 0.8933219909667969, 0.888511598110199, 0.8961516618728638, 0.8896434903144836, 0.8879456520080566, 0.9001131653785706, 0.8967176079750061, 0.9012450575828552, 0.8986983299255371, 0.9006791114807129, 0.9032257795333862, 0.9049236178398132, 0.9100169539451599, 0.9057725071907043, 0.9111488461494446, 0.8944538831710815, 0.8972835540771484, 0.9071873426437378, 0.9102999567985535, 0.9069043397903442, 0.9026598930358887, 0.9080362319946289], 'val_loss': [0.6763490438461304, 0.669797956943512, 0.668383002281189, 0.6700113415718079, 0.6670833230018616, 0.656886875629425, 0.6527898907661438, 0.6523328423500061, 0.6423457860946655, 0.6376785635948181, 0.6240982413291931, 0.632324755191803, 0.6217795014381409, 0.5959292054176331, 0.5947024822235107, 0.6031754016876221, 0.616229236125946, 0.5800080895423889, 0.578010082244873, 0.556914746761322, 0.5524210333824158, 0.571113109588623, 0.5807144641876221, 0.5764961838722229, 0.5779086351394653, 0.562724769115448, 0.5748880505561829, 0.6091417670249939, 0.5929808020591736, 0.6071716547012329, 0.6210412979125977, 0.6273200511932373, 0.6359725594520569, 0.620326817035675, 0.6163272857666016, 0.6431438326835632, 0.6285040378570557, 0.6535486578941345, 0.6511693000793457, 0.6439819931983948, 0.6528945565223694, 0.6438112854957581, 0.6612086296081543, 0.6529651284217834, 0.664076566696167, 0.6332523822784424, 0.6854404211044312, 0.6642633676528931, 0.6615803837776184, 0.6449654698371887, 0.6506684422492981, 0.6681625843048096, 0.6505798101425171, 0.652389645576477, 0.649968683719635, 0.6694781184196472, 0.7205904722213745, 0.6959315538406372, 0.6663790941238403, 0.6677134037017822, 0.6575325727462769, 0.6958830952644348, 0.6989727020263672, 0.7627881169319153, 0.6986832618713379, 0.7029962539672852, 0.725044846534729, 0.8249498605728149, 0.7010899186134338, 0.6763077974319458, 0.742327868938446, 0.7521620392799377, 0.7705645561218262, 0.7172976136207581, 0.7361355423927307, 0.7094669342041016, 0.7117711305618286, 0.7253990173339844, 0.7136598229408264, 0.7057580947875977, 0.706398069858551, 0.7190150022506714, 0.7343966364860535, 0.7324077486991882, 0.7899989485740662, 0.7181137800216675, 0.7430511116981506, 0.7492820620536804, 0.7291867136955261, 0.7674537301063538, 0.77745521068573, 0.7263398766517639, 0.7614710927009583, 0.8081647157669067, 0.7726108431816101, 0.7675127983093262, 0.8178899884223938, 0.8585565686225891, 0.8166172504425049, 0.7980173230171204], 'val_accuracy': [0.516968309879303, 0.5610859990119934, 0.5305429697036743, 0.5226244330406189, 0.5373303294181824, 0.5825791954994202, 0.5497737526893616, 0.5825791954994202, 0.6006787419319153, 0.5916289687156677, 0.6357465982437134, 0.6119909286499023, 0.6753393411636353, 0.6708144545555115, 0.6708144545555115, 0.6527149081230164, 0.6640271544456482, 0.6934388875961304, 0.685520350933075, 0.7058823704719543, 0.7420814633369446, 0.7013574838638306, 0.7375565767288208, 0.7149321436882019, 0.7477375268936157, 0.7386877536773682, 0.75, 0.7556561231613159, 0.7409502267837524, 0.7375565767288208, 0.726244330406189, 0.7115384340286255, 0.7251130938529968, 0.7364253401756287, 0.7454751133918762, 0.7285068035125732, 0.7319004535675049, 0.7296379804611206, 0.726244330406189, 0.7341628670692444, 0.7364253401756287, 0.7466063499450684, 0.7217194437980652, 0.7443438768386841, 0.7364253401756287, 0.7341628670692444, 0.7477375268936157, 0.7398189902305603, 0.7296379804611206, 0.7443438768386841, 0.7443438768386841, 0.7217194437980652, 0.726244330406189, 0.7228506803512573, 0.7319004535675049, 0.7488687634468079, 0.7285068035125732, 0.7319004535675049, 0.75, 0.7511312365531921, 0.726244330406189, 0.7375565767288208, 0.7454751133918762, 0.7171945571899414, 0.7228506803512573, 0.7138009071350098, 0.726244330406189, 0.720588207244873, 0.7104072570800781, 0.7432126402854919, 0.7386877536773682, 0.7239819169044495, 0.7217194437980652, 0.7273755669593811, 0.6843891143798828, 0.7420814633369446, 0.7352941036224365, 0.733031690120697, 0.7386877536773682, 0.7375565767288208, 0.7296379804611206, 0.7194570302963257, 0.7432126402854919, 0.7352941036224365, 0.7386877536773682, 0.7375565767288208, 0.7386877536773682, 0.7194570302963257, 0.7375565767288208, 0.7228506803512573, 0.7115384340286255, 0.7285068035125732, 0.733031690120697, 0.7126696705818176, 0.7285068035125732, 0.7341628670692444, 0.7432126402854919, 0.7149321436882019, 0.7171945571899414, 0.7251130938529968]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.3930 - accuracy: 0.8268"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 55ms/step - loss: 0.3936 - accuracy: 0.8271 - val_loss: 0.6752 - val_accuracy: 0.5103\n","Epoch 2/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3856 - accuracy: 0.8258 - val_loss: 0.6629 - val_accuracy: 0.5382\n","Epoch 3/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3767 - accuracy: 0.8323 - val_loss: 0.6562 - val_accuracy: 0.5940\n","Epoch 4/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3729 - accuracy: 0.8372 - val_loss: 0.6566 - val_accuracy: 0.5702\n","Epoch 5/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3877 - accuracy: 0.8333 - val_loss: 0.6480 - val_accuracy: 0.5940\n","Epoch 6/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3729 - accuracy: 0.8388 - val_loss: 0.6492 - val_accuracy: 0.5455\n","Epoch 7/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3685 - accuracy: 0.8362 - val_loss: 0.6398 - val_accuracy: 0.5795\n","Epoch 8/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3673 - accuracy: 0.8349 - val_loss: 0.6297 - val_accuracy: 0.6105\n","Epoch 9/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3615 - accuracy: 0.8351 - val_loss: 0.6278 - val_accuracy: 0.5857\n","Epoch 10/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3567 - accuracy: 0.8398 - val_loss: 0.6142 - val_accuracy: 0.6395\n","Epoch 11/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3581 - accuracy: 0.8403 - val_loss: 0.6215 - val_accuracy: 0.5961\n","Epoch 12/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3577 - accuracy: 0.8434 - val_loss: 0.6060 - val_accuracy: 0.6240\n","Epoch 13/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3614 - accuracy: 0.8403 - val_loss: 0.5855 - val_accuracy: 0.6767\n","Epoch 14/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3593 - accuracy: 0.8403 - val_loss: 0.5877 - val_accuracy: 0.6725\n","Epoch 15/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3505 - accuracy: 0.8470 - val_loss: 0.5828 - val_accuracy: 0.7076\n","Epoch 16/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3586 - accuracy: 0.8426 - val_loss: 0.5790 - val_accuracy: 0.6756\n","Epoch 17/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3488 - accuracy: 0.8473 - val_loss: 0.5678 - val_accuracy: 0.6994\n","Epoch 18/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.3421 - accuracy: 0.8499 - val_loss: 0.5583 - val_accuracy: 0.7314\n","Epoch 19/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3427 - accuracy: 0.8465 - val_loss: 0.5646 - val_accuracy: 0.7107\n","Epoch 20/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3548 - accuracy: 0.8432 - val_loss: 0.5588 - val_accuracy: 0.7479\n","Epoch 21/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3472 - accuracy: 0.8504 - val_loss: 0.5683 - val_accuracy: 0.7314\n","Epoch 22/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3438 - accuracy: 0.8527 - val_loss: 0.5702 - val_accuracy: 0.7345\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3415 - accuracy: 0.8483 - val_loss: 0.5794 - val_accuracy: 0.7345\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3352 - accuracy: 0.8537 - val_loss: 0.5992 - val_accuracy: 0.7231\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3439 - accuracy: 0.8452 - val_loss: 0.6155 - val_accuracy: 0.7138\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3467 - accuracy: 0.8473 - val_loss: 0.6206 - val_accuracy: 0.7190\n","Epoch 27/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3382 - accuracy: 0.8545 - val_loss: 0.6208 - val_accuracy: 0.7335\n","Epoch 28/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3322 - accuracy: 0.8610 - val_loss: 0.6248 - val_accuracy: 0.7345\n","Epoch 29/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3305 - accuracy: 0.8597 - val_loss: 0.6250 - val_accuracy: 0.7221\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3274 - accuracy: 0.8579 - val_loss: 0.6227 - val_accuracy: 0.7335\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3289 - accuracy: 0.8592 - val_loss: 0.6654 - val_accuracy: 0.7097\n","Epoch 32/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3275 - accuracy: 0.8540 - val_loss: 0.6377 - val_accuracy: 0.7242\n","Epoch 33/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3294 - accuracy: 0.8545 - val_loss: 0.6321 - val_accuracy: 0.7366\n","Epoch 34/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3336 - accuracy: 0.8540 - val_loss: 0.6553 - val_accuracy: 0.7366\n","Epoch 35/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3286 - accuracy: 0.8563 - val_loss: 0.6498 - val_accuracy: 0.7324\n","Epoch 36/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3207 - accuracy: 0.8654 - val_loss: 0.6713 - val_accuracy: 0.7273\n","Epoch 37/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3202 - accuracy: 0.8633 - val_loss: 0.6669 - val_accuracy: 0.7262\n","Epoch 38/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3213 - accuracy: 0.8638 - val_loss: 0.6523 - val_accuracy: 0.7314\n","Epoch 39/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3172 - accuracy: 0.8651 - val_loss: 0.6542 - val_accuracy: 0.7324\n","Epoch 40/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3166 - accuracy: 0.8592 - val_loss: 0.6587 - val_accuracy: 0.7304\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3136 - accuracy: 0.8646 - val_loss: 0.6789 - val_accuracy: 0.7107\n","Epoch 42/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3098 - accuracy: 0.8677 - val_loss: 0.6754 - val_accuracy: 0.7273\n","Epoch 43/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3095 - accuracy: 0.8651 - val_loss: 0.6612 - val_accuracy: 0.7283\n","Epoch 44/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3124 - accuracy: 0.8708 - val_loss: 0.6646 - val_accuracy: 0.7304\n","Epoch 45/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3140 - accuracy: 0.8685 - val_loss: 0.6725 - val_accuracy: 0.7345\n","Epoch 46/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3125 - accuracy: 0.8682 - val_loss: 0.6909 - val_accuracy: 0.7283\n","Epoch 47/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3286 - accuracy: 0.8561 - val_loss: 0.6784 - val_accuracy: 0.7056\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3101 - accuracy: 0.8693 - val_loss: 0.7309 - val_accuracy: 0.6963\n","Epoch 49/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3069 - accuracy: 0.8736 - val_loss: 0.6752 - val_accuracy: 0.7169\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3087 - accuracy: 0.8672 - val_loss: 0.6749 - val_accuracy: 0.7335\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3032 - accuracy: 0.8713 - val_loss: 0.7138 - val_accuracy: 0.7056\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2956 - accuracy: 0.8755 - val_loss: 0.6778 - val_accuracy: 0.7273\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2947 - accuracy: 0.8773 - val_loss: 0.6708 - val_accuracy: 0.7376\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3013 - accuracy: 0.8677 - val_loss: 0.6956 - val_accuracy: 0.7283\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3065 - accuracy: 0.8705 - val_loss: 0.7032 - val_accuracy: 0.7252\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2970 - accuracy: 0.8698 - val_loss: 0.7103 - val_accuracy: 0.7118\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2985 - accuracy: 0.8783 - val_loss: 0.7024 - val_accuracy: 0.7200\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2981 - accuracy: 0.8770 - val_loss: 0.7265 - val_accuracy: 0.7221\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2970 - accuracy: 0.8700 - val_loss: 0.6956 - val_accuracy: 0.7324\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2860 - accuracy: 0.8788 - val_loss: 0.6992 - val_accuracy: 0.7335\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2849 - accuracy: 0.8791 - val_loss: 0.7016 - val_accuracy: 0.7262\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2808 - accuracy: 0.8804 - val_loss: 0.7229 - val_accuracy: 0.7304\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2808 - accuracy: 0.8848 - val_loss: 0.7090 - val_accuracy: 0.7231\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2910 - accuracy: 0.8765 - val_loss: 0.7089 - val_accuracy: 0.7293\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2857 - accuracy: 0.8842 - val_loss: 0.7189 - val_accuracy: 0.7118\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2895 - accuracy: 0.8765 - val_loss: 0.7312 - val_accuracy: 0.7283\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2890 - accuracy: 0.8809 - val_loss: 0.7165 - val_accuracy: 0.7242\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2775 - accuracy: 0.8860 - val_loss: 0.7661 - val_accuracy: 0.6787\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2918 - accuracy: 0.8767 - val_loss: 0.7261 - val_accuracy: 0.7118\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2771 - accuracy: 0.8848 - val_loss: 0.7126 - val_accuracy: 0.7211\n","Epoch 71/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2745 - accuracy: 0.8899 - val_loss: 0.7343 - val_accuracy: 0.7128\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2767 - accuracy: 0.8866 - val_loss: 0.7484 - val_accuracy: 0.7045\n","Epoch 73/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2656 - accuracy: 0.8956 - val_loss: 0.7560 - val_accuracy: 0.7025\n","Epoch 74/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2713 - accuracy: 0.8804 - val_loss: 0.7243 - val_accuracy: 0.7221\n","Epoch 75/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2659 - accuracy: 0.8879 - val_loss: 0.7502 - val_accuracy: 0.7252\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2656 - accuracy: 0.8873 - val_loss: 0.7428 - val_accuracy: 0.7180\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2643 - accuracy: 0.8904 - val_loss: 0.7651 - val_accuracy: 0.7200\n","Epoch 78/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2746 - accuracy: 0.8873 - val_loss: 0.7419 - val_accuracy: 0.7200\n","Epoch 79/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2626 - accuracy: 0.8884 - val_loss: 0.7843 - val_accuracy: 0.6849\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2643 - accuracy: 0.8868 - val_loss: 0.7556 - val_accuracy: 0.7045\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2603 - accuracy: 0.8935 - val_loss: 0.7732 - val_accuracy: 0.7097\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2668 - accuracy: 0.8902 - val_loss: 0.7837 - val_accuracy: 0.7076\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2808 - accuracy: 0.8775 - val_loss: 0.7987 - val_accuracy: 0.6901\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2635 - accuracy: 0.8933 - val_loss: 0.7759 - val_accuracy: 0.7138\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2559 - accuracy: 0.8930 - val_loss: 0.7569 - val_accuracy: 0.7149\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2620 - accuracy: 0.8922 - val_loss: 0.7661 - val_accuracy: 0.7180\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2559 - accuracy: 0.8943 - val_loss: 0.7712 - val_accuracy: 0.7190\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2509 - accuracy: 0.8961 - val_loss: 0.8077 - val_accuracy: 0.7211\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2718 - accuracy: 0.8868 - val_loss: 0.8123 - val_accuracy: 0.7118\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2700 - accuracy: 0.8873 - val_loss: 0.7938 - val_accuracy: 0.7035\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2757 - accuracy: 0.8822 - val_loss: 0.7966 - val_accuracy: 0.6963\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2516 - accuracy: 0.8997 - val_loss: 0.8109 - val_accuracy: 0.6942\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2497 - accuracy: 0.8969 - val_loss: 0.8178 - val_accuracy: 0.6942\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2474 - accuracy: 0.8959 - val_loss: 0.7951 - val_accuracy: 0.7045\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2549 - accuracy: 0.8938 - val_loss: 0.8028 - val_accuracy: 0.7242\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2503 - accuracy: 0.8969 - val_loss: 0.8254 - val_accuracy: 0.6932\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2394 - accuracy: 0.8992 - val_loss: 0.7952 - val_accuracy: 0.7180\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2390 - accuracy: 0.9018 - val_loss: 0.8021 - val_accuracy: 0.7190\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2526 - accuracy: 0.8938 - val_loss: 0.8276 - val_accuracy: 0.7149\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2416 - accuracy: 0.9041 - val_loss: 0.8075 - val_accuracy: 0.7159\n","{'loss': [0.3936009407043457, 0.38560593128204346, 0.3766677677631378, 0.3728993237018585, 0.3877451419830322, 0.3729197084903717, 0.3685038983821869, 0.36733973026275635, 0.36145374178886414, 0.35667240619659424, 0.35810789465904236, 0.35770168900489807, 0.36138367652893066, 0.35934895277023315, 0.3505021035671234, 0.35859498381614685, 0.34877198934555054, 0.34213078022003174, 0.34265151619911194, 0.35480424761772156, 0.34722036123275757, 0.34378471970558167, 0.3415015637874603, 0.33517202734947205, 0.3438972532749176, 0.3466765880584717, 0.3382394313812256, 0.33215126395225525, 0.33050912618637085, 0.32736140489578247, 0.3289419114589691, 0.32751092314720154, 0.3293899893760681, 0.3335932195186615, 0.32863739132881165, 0.32071202993392944, 0.3202228844165802, 0.3212985396385193, 0.31719088554382324, 0.3166342079639435, 0.3135809898376465, 0.3097808063030243, 0.30948159098625183, 0.3124362826347351, 0.3140439987182617, 0.312477171421051, 0.32859480381011963, 0.31006142497062683, 0.3068576455116272, 0.3086780905723572, 0.3032201826572418, 0.295579731464386, 0.2947457432746887, 0.3012791872024536, 0.30651259422302246, 0.2969975173473358, 0.2984786033630371, 0.2981146275997162, 0.29700496792793274, 0.2859717309474945, 0.2849031388759613, 0.2807523012161255, 0.2808404564857483, 0.2910361886024475, 0.28566139936447144, 0.2895015478134155, 0.2889622747898102, 0.2774621546268463, 0.29175224900245667, 0.2771018445491791, 0.2744722366333008, 0.276749849319458, 0.26561859250068665, 0.27126771211624146, 0.26586538553237915, 0.26557987928390503, 0.26433950662612915, 0.27457791566848755, 0.2625780701637268, 0.2642998993396759, 0.26029539108276367, 0.2668282985687256, 0.280800461769104, 0.26351937651634216, 0.255911648273468, 0.2619624137878418, 0.25592342019081116, 0.2509084939956665, 0.27181002497673035, 0.26999935507774353, 0.2756751775741577, 0.2516052722930908, 0.24974602460861206, 0.2474476546049118, 0.25485894083976746, 0.2502749562263489, 0.23940125107765198, 0.23900090157985687, 0.25256818532943726, 0.24164791405200958], 'accuracy': [0.8271318078041077, 0.8258398175239563, 0.8322997689247131, 0.8372092843055725, 0.8333333134651184, 0.8387596607208252, 0.8361757397651672, 0.8348837494850159, 0.8351421356201172, 0.8397932648658752, 0.8403100967407227, 0.843410849571228, 0.8403100967407227, 0.8403100967407227, 0.8470284342765808, 0.8426356315612793, 0.8472868204116821, 0.8498708009719849, 0.8465116024017334, 0.8431524634361267, 0.8503875732421875, 0.8527131676673889, 0.8483204245567322, 0.853746771812439, 0.845219612121582, 0.8472868204116821, 0.8545219898223877, 0.8609819412231445, 0.8596899509429932, 0.8578811287879944, 0.8591731190681458, 0.8540051579475403, 0.8545219898223877, 0.8540051579475403, 0.8563307523727417, 0.8653746843338013, 0.8633074760437012, 0.8638243079185486, 0.8651162981987, 0.8591731190681458, 0.8645994663238525, 0.8677002787590027, 0.8651162981987, 0.8708010315895081, 0.8684754371643066, 0.8682170510292053, 0.8560723662376404, 0.8692506551742554, 0.8736433982849121, 0.8671834468841553, 0.8713178038597107, 0.8754522204399109, 0.8772609829902649, 0.8677002787590027, 0.8705426454544067, 0.869767427444458, 0.8782945871353149, 0.8770025968551636, 0.8700258135795593, 0.8788113594055176, 0.8790697455406189, 0.8803617358207703, 0.8847545385360718, 0.8764857649803162, 0.8842377066612244, 0.8764857649803162, 0.8808785676956177, 0.8860465288162231, 0.8767442107200623, 0.8847545385360718, 0.8899224996566772, 0.8865633010864258, 0.8956072330474854, 0.8803617358207703, 0.8878552913665771, 0.8873385190963745, 0.8904392719268799, 0.8873385190963745, 0.8883720636367798, 0.8868216872215271, 0.8935400247573853, 0.8901808857917786, 0.8775193691253662, 0.8932816386222839, 0.8930232524871826, 0.8922480344772339, 0.894315242767334, 0.896124005317688, 0.8868216872215271, 0.8873385190963745, 0.882170557975769, 0.8997415900230408, 0.8968992233276367, 0.8958656191825867, 0.8937984704971313, 0.8968992233276367, 0.8992248177528381, 0.9018087983131409, 0.8937984704971313, 0.9041343927383423], 'val_loss': [0.6752400398254395, 0.6628809571266174, 0.656245231628418, 0.6566351056098938, 0.6479710936546326, 0.6491568684577942, 0.6398327946662903, 0.6297478675842285, 0.6277753710746765, 0.6142486929893494, 0.6214696764945984, 0.6060014367103577, 0.5855271816253662, 0.587736189365387, 0.5827868580818176, 0.579031229019165, 0.5677706599235535, 0.5582831501960754, 0.5646388530731201, 0.5588258504867554, 0.5682889819145203, 0.5701684951782227, 0.5794090628623962, 0.5992395877838135, 0.6155075430870056, 0.6205561757087708, 0.6207743287086487, 0.6247608661651611, 0.6250185370445251, 0.6226773858070374, 0.665418267250061, 0.6376559138298035, 0.6320593357086182, 0.6553331613540649, 0.6497976779937744, 0.6713457703590393, 0.6668649315834045, 0.6523263454437256, 0.6542348265647888, 0.6587157845497131, 0.6788933277130127, 0.6754183769226074, 0.6612446904182434, 0.664586067199707, 0.6725243330001831, 0.6909003257751465, 0.6783633232116699, 0.7309159636497498, 0.6751827597618103, 0.6749348044395447, 0.7137609720230103, 0.6777908205986023, 0.670834481716156, 0.6956207156181335, 0.7031893730163574, 0.7102946043014526, 0.7023622393608093, 0.7264680862426758, 0.6955795288085938, 0.6991949081420898, 0.7015810608863831, 0.7228981256484985, 0.7089542150497437, 0.7089036703109741, 0.7188971042633057, 0.7311736345291138, 0.7165359258651733, 0.7661451101303101, 0.726088285446167, 0.7125794887542725, 0.7343354821205139, 0.7483953237533569, 0.7559738159179688, 0.7243049740791321, 0.7501537799835205, 0.7427958250045776, 0.7650715112686157, 0.7418713569641113, 0.7843440175056458, 0.7555640935897827, 0.7732127904891968, 0.7836992740631104, 0.7987138628959656, 0.7759367227554321, 0.7569417357444763, 0.7660565972328186, 0.7711879014968872, 0.8076609969139099, 0.8123300075531006, 0.7938200831413269, 0.7965957522392273, 0.8108857870101929, 0.8178276419639587, 0.7950693964958191, 0.8028163909912109, 0.8253860473632812, 0.7951918244361877, 0.8020501136779785, 0.827610969543457, 0.8074958324432373], 'val_accuracy': [0.5103305578231812, 0.538223147392273, 0.5940082669258118, 0.5702479481697083, 0.5940082669258118, 0.5454545617103577, 0.5795454382896423, 0.6105371713638306, 0.58574378490448, 0.6394628286361694, 0.5960744023323059, 0.6239669322967529, 0.6766529083251953, 0.672520637512207, 0.7076446413993835, 0.6756198406219482, 0.6993801593780518, 0.7314049601554871, 0.71074378490448, 0.7479338645935059, 0.7314049601554871, 0.7345041036605835, 0.7345041036605835, 0.7231404781341553, 0.7138429880142212, 0.7190082669258118, 0.7334710955619812, 0.7345041036605835, 0.7221074104309082, 0.7334710955619812, 0.7097107172012329, 0.7241735458374023, 0.7365702390670776, 0.7365702390670776, 0.7324380278587341, 0.7272727489471436, 0.7262396812438965, 0.7314049601554871, 0.7324380278587341, 0.73037189245224, 0.71074378490448, 0.7272727489471436, 0.7283057570457458, 0.73037189245224, 0.7345041036605835, 0.7283057570457458, 0.7055785059928894, 0.6962810158729553, 0.7169421315193176, 0.7334710955619812, 0.7055785059928894, 0.7272727489471436, 0.7376033067703247, 0.7283057570457458, 0.7252066135406494, 0.711776852607727, 0.7200413346290588, 0.7221074104309082, 0.7324380278587341, 0.7334710955619812, 0.7262396812438965, 0.73037189245224, 0.7231404781341553, 0.7293388247489929, 0.711776852607727, 0.7283057570457458, 0.7241735458374023, 0.6787189841270447, 0.711776852607727, 0.7210744023323059, 0.7128099203109741, 0.7045454382896423, 0.702479362487793, 0.7221074104309082, 0.7252066135406494, 0.7179751992225647, 0.7200413346290588, 0.7200413346290588, 0.6849173307418823, 0.7045454382896423, 0.7097107172012329, 0.7076446413993835, 0.6900826692581177, 0.7138429880142212, 0.7148760557174683, 0.7179751992225647, 0.7190082669258118, 0.7210744023323059, 0.711776852607727, 0.7035123705863953, 0.6962810158729553, 0.6942148804664612, 0.6942148804664612, 0.7045454382896423, 0.7241735458374023, 0.6931818127632141, 0.7179751992225647, 0.7190082669258118, 0.7148760557174683, 0.7159090638160706]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 0.3164 - accuracy: 0.8695"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 68ms/step - loss: 0.3183 - accuracy: 0.8691 - val_loss: 0.6569 - val_accuracy: 0.5744\n","Epoch 2/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2613 - accuracy: 0.8906 - val_loss: 0.6563 - val_accuracy: 0.5388\n","Epoch 3/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2687 - accuracy: 0.8871 - val_loss: 0.6483 - val_accuracy: 0.5603\n","Epoch 4/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2535 - accuracy: 0.8944 - val_loss: 0.6438 - val_accuracy: 0.5722\n","Epoch 5/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2532 - accuracy: 0.8879 - val_loss: 0.6435 - val_accuracy: 0.5582\n","Epoch 6/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2625 - accuracy: 0.8955 - val_loss: 0.6445 - val_accuracy: 0.5603\n","Epoch 7/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2578 - accuracy: 0.8904 - val_loss: 0.6374 - val_accuracy: 0.5765\n","Epoch 8/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2410 - accuracy: 0.9038 - val_loss: 0.6058 - val_accuracy: 0.6681\n","Epoch 9/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2443 - accuracy: 0.8979 - val_loss: 0.6083 - val_accuracy: 0.6293\n","Epoch 10/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2505 - accuracy: 0.8984 - val_loss: 0.5943 - val_accuracy: 0.6498\n","Epoch 11/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2440 - accuracy: 0.8987 - val_loss: 0.6090 - val_accuracy: 0.6196\n","Epoch 12/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2373 - accuracy: 0.9036 - val_loss: 0.5771 - val_accuracy: 0.6659\n","Epoch 13/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2361 - accuracy: 0.8979 - val_loss: 0.5815 - val_accuracy: 0.6649\n","Epoch 14/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2365 - accuracy: 0.9027 - val_loss: 0.5746 - val_accuracy: 0.6713\n","Epoch 15/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2393 - accuracy: 0.9003 - val_loss: 0.5550 - val_accuracy: 0.7069\n","Epoch 16/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2464 - accuracy: 0.8984 - val_loss: 0.5357 - val_accuracy: 0.7091\n","Epoch 17/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2438 - accuracy: 0.9027 - val_loss: 0.6148 - val_accuracy: 0.6552\n","Epoch 18/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2430 - accuracy: 0.8979 - val_loss: 0.5583 - val_accuracy: 0.6940\n","Epoch 19/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2342 - accuracy: 0.9001 - val_loss: 0.5585 - val_accuracy: 0.6950\n","Epoch 20/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2263 - accuracy: 0.9060 - val_loss: 0.5321 - val_accuracy: 0.7209\n","Epoch 21/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2236 - accuracy: 0.9108 - val_loss: 0.5042 - val_accuracy: 0.7640\n","Epoch 22/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2314 - accuracy: 0.9014 - val_loss: 0.5553 - val_accuracy: 0.7155\n","Epoch 23/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2238 - accuracy: 0.9130 - val_loss: 0.5483 - val_accuracy: 0.7468\n","Epoch 24/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2290 - accuracy: 0.9095 - val_loss: 0.5421 - val_accuracy: 0.7586\n","Epoch 25/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2310 - accuracy: 0.9006 - val_loss: 0.5386 - val_accuracy: 0.7705\n","Epoch 26/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.2330 - accuracy: 0.9038 - val_loss: 0.5695 - val_accuracy: 0.7759\n","Epoch 27/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2284 - accuracy: 0.9022 - val_loss: 0.5556 - val_accuracy: 0.7651\n","Epoch 28/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.2319 - accuracy: 0.9073 - val_loss: 0.5641 - val_accuracy: 0.7823\n","Epoch 29/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2265 - accuracy: 0.9068 - val_loss: 0.5556 - val_accuracy: 0.7737\n","Epoch 30/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.2194 - accuracy: 0.9111 - val_loss: 0.5708 - val_accuracy: 0.7856\n","Epoch 31/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2193 - accuracy: 0.9062 - val_loss: 0.5842 - val_accuracy: 0.7586\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2243 - accuracy: 0.9052 - val_loss: 0.5763 - val_accuracy: 0.7856\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2088 - accuracy: 0.9111 - val_loss: 0.5616 - val_accuracy: 0.7780\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2150 - accuracy: 0.9149 - val_loss: 0.5817 - val_accuracy: 0.7856\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2164 - accuracy: 0.9143 - val_loss: 0.6487 - val_accuracy: 0.7608\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2152 - accuracy: 0.9176 - val_loss: 0.6162 - val_accuracy: 0.7694\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2081 - accuracy: 0.9157 - val_loss: 0.5922 - val_accuracy: 0.7705\n","Epoch 38/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2068 - accuracy: 0.9159 - val_loss: 0.6127 - val_accuracy: 0.7791\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2074 - accuracy: 0.9176 - val_loss: 0.6075 - val_accuracy: 0.7834\n","Epoch 40/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2069 - accuracy: 0.9135 - val_loss: 0.6050 - val_accuracy: 0.7834\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2050 - accuracy: 0.9184 - val_loss: 0.6116 - val_accuracy: 0.7845\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2121 - accuracy: 0.9133 - val_loss: 0.6343 - val_accuracy: 0.7705\n","Epoch 43/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2064 - accuracy: 0.9159 - val_loss: 0.6164 - val_accuracy: 0.7856\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1982 - accuracy: 0.9243 - val_loss: 0.6190 - val_accuracy: 0.7705\n","Epoch 45/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2014 - accuracy: 0.9213 - val_loss: 0.6293 - val_accuracy: 0.7748\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2076 - accuracy: 0.9189 - val_loss: 0.6346 - val_accuracy: 0.7769\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2128 - accuracy: 0.9178 - val_loss: 0.6206 - val_accuracy: 0.7834\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2039 - accuracy: 0.9211 - val_loss: 0.6433 - val_accuracy: 0.7629\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1914 - accuracy: 0.9254 - val_loss: 0.6014 - val_accuracy: 0.7683\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1934 - accuracy: 0.9211 - val_loss: 0.6027 - val_accuracy: 0.7791\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1936 - accuracy: 0.9224 - val_loss: 0.6813 - val_accuracy: 0.7371\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1911 - accuracy: 0.9219 - val_loss: 0.6302 - val_accuracy: 0.7812\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1905 - accuracy: 0.9227 - val_loss: 0.6341 - val_accuracy: 0.7812\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1928 - accuracy: 0.9270 - val_loss: 0.6765 - val_accuracy: 0.7349\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1896 - accuracy: 0.9281 - val_loss: 0.6302 - val_accuracy: 0.7694\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1849 - accuracy: 0.9291 - val_loss: 0.6493 - val_accuracy: 0.7823\n","Epoch 57/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2110 - accuracy: 0.9141 - val_loss: 0.7075 - val_accuracy: 0.7575\n","Epoch 58/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1983 - accuracy: 0.9240 - val_loss: 0.6493 - val_accuracy: 0.7759\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1869 - accuracy: 0.9240 - val_loss: 0.6543 - val_accuracy: 0.7812\n","Epoch 60/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1832 - accuracy: 0.9267 - val_loss: 0.6504 - val_accuracy: 0.7802\n","Epoch 61/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1935 - accuracy: 0.9203 - val_loss: 0.6485 - val_accuracy: 0.7769\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1913 - accuracy: 0.9240 - val_loss: 0.6738 - val_accuracy: 0.7629\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1906 - accuracy: 0.9216 - val_loss: 0.6455 - val_accuracy: 0.7672\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1852 - accuracy: 0.9224 - val_loss: 0.6496 - val_accuracy: 0.7812\n","Epoch 65/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1815 - accuracy: 0.9302 - val_loss: 0.6656 - val_accuracy: 0.7780\n","Epoch 66/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1868 - accuracy: 0.9251 - val_loss: 0.6942 - val_accuracy: 0.7457\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1865 - accuracy: 0.9197 - val_loss: 0.6619 - val_accuracy: 0.7683\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1826 - accuracy: 0.9270 - val_loss: 0.6692 - val_accuracy: 0.7748\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1747 - accuracy: 0.9305 - val_loss: 0.6742 - val_accuracy: 0.7683\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1836 - accuracy: 0.9238 - val_loss: 0.6757 - val_accuracy: 0.7769\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1840 - accuracy: 0.9291 - val_loss: 0.7464 - val_accuracy: 0.7662\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1838 - accuracy: 0.9286 - val_loss: 0.6972 - val_accuracy: 0.7651\n","Epoch 73/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1925 - accuracy: 0.9211 - val_loss: 0.6915 - val_accuracy: 0.7575\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1688 - accuracy: 0.9343 - val_loss: 0.6883 - val_accuracy: 0.7748\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1671 - accuracy: 0.9327 - val_loss: 0.7017 - val_accuracy: 0.7683\n","Epoch 76/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1692 - accuracy: 0.9353 - val_loss: 0.6751 - val_accuracy: 0.7726\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1679 - accuracy: 0.9370 - val_loss: 0.7573 - val_accuracy: 0.7565\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1792 - accuracy: 0.9240 - val_loss: 0.7329 - val_accuracy: 0.7683\n","Epoch 79/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1681 - accuracy: 0.9324 - val_loss: 0.7259 - val_accuracy: 0.7662\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1819 - accuracy: 0.9289 - val_loss: 0.7898 - val_accuracy: 0.7381\n","Epoch 81/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1944 - accuracy: 0.9219 - val_loss: 0.7219 - val_accuracy: 0.7640\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1731 - accuracy: 0.9308 - val_loss: 0.7028 - val_accuracy: 0.7705\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1674 - accuracy: 0.9367 - val_loss: 0.7373 - val_accuracy: 0.7662\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1627 - accuracy: 0.9329 - val_loss: 0.7039 - val_accuracy: 0.7554\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1575 - accuracy: 0.9399 - val_loss: 0.6973 - val_accuracy: 0.7716\n","Epoch 86/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1593 - accuracy: 0.9388 - val_loss: 0.7647 - val_accuracy: 0.7338\n","Epoch 87/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1623 - accuracy: 0.9394 - val_loss: 0.7078 - val_accuracy: 0.7683\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1611 - accuracy: 0.9372 - val_loss: 0.7287 - val_accuracy: 0.7726\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1613 - accuracy: 0.9353 - val_loss: 0.7158 - val_accuracy: 0.7716\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1537 - accuracy: 0.9370 - val_loss: 0.7776 - val_accuracy: 0.7220\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1593 - accuracy: 0.9370 - val_loss: 0.7327 - val_accuracy: 0.7662\n","Epoch 92/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1732 - accuracy: 0.9275 - val_loss: 0.7376 - val_accuracy: 0.7522\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1588 - accuracy: 0.9370 - val_loss: 0.7417 - val_accuracy: 0.7608\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1634 - accuracy: 0.9313 - val_loss: 0.7332 - val_accuracy: 0.7726\n","Epoch 95/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1526 - accuracy: 0.9407 - val_loss: 0.7492 - val_accuracy: 0.7748\n","Epoch 96/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1524 - accuracy: 0.9362 - val_loss: 0.7581 - val_accuracy: 0.7759\n","Epoch 97/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1608 - accuracy: 0.9362 - val_loss: 0.7579 - val_accuracy: 0.7511\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1540 - accuracy: 0.9394 - val_loss: 0.7411 - val_accuracy: 0.7716\n","Epoch 99/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1711 - accuracy: 0.9316 - val_loss: 0.7623 - val_accuracy: 0.7619\n","Epoch 100/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1816 - accuracy: 0.9300 - val_loss: 0.8426 - val_accuracy: 0.7058\n","{'loss': [0.3183175325393677, 0.2612958252429962, 0.26872044801712036, 0.2534564137458801, 0.25317031145095825, 0.2624545395374298, 0.2578127086162567, 0.2409551739692688, 0.24427983164787292, 0.250533789396286, 0.24404054880142212, 0.23730839788913727, 0.23613464832305908, 0.23645815253257751, 0.23931856453418732, 0.24638888239860535, 0.24384692311286926, 0.24296581745147705, 0.23420605063438416, 0.22630442678928375, 0.22355160117149353, 0.2314346432685852, 0.22375346720218658, 0.2290160357952118, 0.2309970259666443, 0.23303823173046112, 0.22836196422576904, 0.2318720817565918, 0.22651173174381256, 0.21935197710990906, 0.2192971408367157, 0.22431708872318268, 0.2088298201560974, 0.21502643823623657, 0.216388538479805, 0.21524566411972046, 0.20808571577072144, 0.20682162046432495, 0.20740877091884613, 0.20688851177692413, 0.20503869652748108, 0.2120528370141983, 0.20638002455234528, 0.19824838638305664, 0.20135560631752014, 0.20759209990501404, 0.21278806030750275, 0.203876331448555, 0.19138818979263306, 0.19341880083084106, 0.19359488785266876, 0.19113576412200928, 0.19047591090202332, 0.1927814781665802, 0.18963778018951416, 0.18491505086421967, 0.21099618077278137, 0.1983037143945694, 0.18694528937339783, 0.18316951394081116, 0.19348862767219543, 0.1913345903158188, 0.19058644771575928, 0.1852411925792694, 0.1815204620361328, 0.18679359555244446, 0.1865006685256958, 0.18255621194839478, 0.1747235357761383, 0.1836118847131729, 0.18397463858127594, 0.18379293382167816, 0.19245445728302002, 0.1687510907649994, 0.16705991327762604, 0.16920705139636993, 0.16788946092128754, 0.17919491231441498, 0.1680782437324524, 0.18194341659545898, 0.19435860216617584, 0.17306308448314667, 0.16744378209114075, 0.16271188855171204, 0.15754105150699615, 0.1593359261751175, 0.16228210926055908, 0.16107691824436188, 0.161344513297081, 0.1536675989627838, 0.15927840769290924, 0.1732068657875061, 0.15875686705112457, 0.1633734256029129, 0.15263232588768005, 0.15240655839443207, 0.16077956557273865, 0.15395992994308472, 0.17113760113716125, 0.18162427842617035], 'accuracy': [0.8690732717514038, 0.890625, 0.8871228694915771, 0.8943965435028076, 0.8879310488700867, 0.8954741358757019, 0.8903555870056152, 0.9038254022598267, 0.8978987336158752, 0.8984375, 0.8987069129943848, 0.9035560488700867, 0.8978987336158752, 0.9027478694915771, 0.9003232717514038, 0.8984375, 0.9027478694915771, 0.8978987336158752, 0.900053858757019, 0.9059805870056152, 0.9108297228813171, 0.9014008641242981, 0.9129849076271057, 0.9094827771186829, 0.9005926847457886, 0.9038254022598267, 0.9022090435028076, 0.9073275923728943, 0.9067887663841248, 0.9110991358757019, 0.90625, 0.9051724076271057, 0.9110991358757019, 0.9148706793785095, 0.9143319129943848, 0.9175646305084229, 0.915678858757019, 0.9159482717514038, 0.9175646305084229, 0.9135237336158752, 0.9183728694915771, 0.9132543206214905, 0.9159482717514038, 0.9242995977401733, 0.9213362336158752, 0.9189116358757019, 0.9178340435028076, 0.9210668206214905, 0.9253771305084229, 0.9210668206214905, 0.9224137663841248, 0.921875, 0.9226831793785095, 0.9269935488700867, 0.928071141242981, 0.9291487336158752, 0.9140625, 0.9240301847457886, 0.9240301847457886, 0.9267241358757019, 0.920258641242981, 0.9240301847457886, 0.9216055870056152, 0.9224137663841248, 0.9302262663841248, 0.9251077771186829, 0.9197198152542114, 0.9269935488700867, 0.9304956793785095, 0.9237607717514038, 0.9291487336158752, 0.9286099076271057, 0.9210668206214905, 0.9342672228813171, 0.9326508641242981, 0.9353448152542114, 0.9369612336158752, 0.9240301847457886, 0.9323814511299133, 0.9288793206214905, 0.921875, 0.9307650923728943, 0.9366918206214905, 0.9329202771186829, 0.9399245977401733, 0.938847005367279, 0.9393857717514038, 0.9372305870056152, 0.9353448152542114, 0.9369612336158752, 0.9369612336158752, 0.9275323152542114, 0.9369612336158752, 0.931303858757019, 0.9407327771186829, 0.936152994632721, 0.936152994632721, 0.9393857717514038, 0.9315732717514038, 0.9299569129943848], 'val_loss': [0.6568508744239807, 0.6562841534614563, 0.6482977271080017, 0.6437808275222778, 0.6435377597808838, 0.6444599032402039, 0.6373540759086609, 0.6058246493339539, 0.6082704067230225, 0.5942582488059998, 0.6089629530906677, 0.5770958065986633, 0.5815288424491882, 0.5745600461959839, 0.5549614429473877, 0.5356953144073486, 0.6148234009742737, 0.5583015084266663, 0.5585089921951294, 0.5320641994476318, 0.5041998028755188, 0.5553197264671326, 0.5482500195503235, 0.5421105027198792, 0.5385745167732239, 0.5694917440414429, 0.5556142330169678, 0.5641354322433472, 0.5556284189224243, 0.5707916617393494, 0.5841647982597351, 0.5763086080551147, 0.5615512728691101, 0.5816605687141418, 0.6486528515815735, 0.6162024140357971, 0.5922125577926636, 0.6127256751060486, 0.6074716448783875, 0.6050350666046143, 0.6116313338279724, 0.6342796087265015, 0.6163740754127502, 0.6189635992050171, 0.6293244957923889, 0.6345588564872742, 0.6206319332122803, 0.6433237195014954, 0.6013908982276917, 0.6027016639709473, 0.6813374757766724, 0.6302330493927002, 0.6340817213058472, 0.676498532295227, 0.6302472352981567, 0.649347186088562, 0.7075387239456177, 0.6492717862129211, 0.6542775630950928, 0.6504191160202026, 0.6484507322311401, 0.673791766166687, 0.6455179452896118, 0.6495553851127625, 0.6656118035316467, 0.6942165493965149, 0.661933183670044, 0.6692385077476501, 0.6742412447929382, 0.675735592842102, 0.7464067339897156, 0.697206437587738, 0.6914769411087036, 0.6883074045181274, 0.7017379999160767, 0.6750589609146118, 0.7573007941246033, 0.7329137325286865, 0.725946307182312, 0.789789617061615, 0.7219236493110657, 0.7028241157531738, 0.7372734546661377, 0.7038871049880981, 0.6973170638084412, 0.7646840810775757, 0.7078022956848145, 0.7287469506263733, 0.7158012390136719, 0.7776380181312561, 0.7327201962471008, 0.737601637840271, 0.7417392134666443, 0.733183741569519, 0.7491554021835327, 0.7581226229667664, 0.7578614354133606, 0.7411335706710815, 0.7623109221458435, 0.8426061868667603], 'val_accuracy': [0.5743534564971924, 0.5387930870056152, 0.5603448152542114, 0.5721982717514038, 0.5581896305084229, 0.5603448152542114, 0.576508641242981, 0.6681034564971924, 0.6293103694915771, 0.649784505367279, 0.6196120977401733, 0.6659482717514038, 0.6648706793785095, 0.6713362336158752, 0.7068965435028076, 0.7090517282485962, 0.6551724076271057, 0.693965494632721, 0.6950430870056152, 0.7209051847457886, 0.764008641242981, 0.7155172228813171, 0.7467672228813171, 0.7586206793785095, 0.7704741358757019, 0.7758620977401733, 0.7650862336158752, 0.7823275923728943, 0.7737069129943848, 0.7855603694915771, 0.7586206793785095, 0.7855603694915771, 0.7780172228813171, 0.7855603694915771, 0.7607758641242981, 0.7693965435028076, 0.7704741358757019, 0.7790948152542114, 0.7834051847457886, 0.7834051847457886, 0.7844827771186829, 0.7704741358757019, 0.7855603694915771, 0.7704741358757019, 0.774784505367279, 0.7769396305084229, 0.7834051847457886, 0.7629310488700867, 0.7683189511299133, 0.7790948152542114, 0.7370689511299133, 0.78125, 0.78125, 0.7349137663841248, 0.7693965435028076, 0.7823275923728943, 0.7575430870056152, 0.7758620977401733, 0.78125, 0.7801724076271057, 0.7769396305084229, 0.7629310488700867, 0.767241358757019, 0.78125, 0.7780172228813171, 0.7456896305084229, 0.7683189511299133, 0.774784505367279, 0.7683189511299133, 0.7769396305084229, 0.7661637663841248, 0.7650862336158752, 0.7575430870056152, 0.774784505367279, 0.7683189511299133, 0.7726293206214905, 0.756465494632721, 0.7683189511299133, 0.7661637663841248, 0.7381465435028076, 0.764008641242981, 0.7704741358757019, 0.7661637663841248, 0.7553879022598267, 0.7715517282485962, 0.7338362336158752, 0.7683189511299133, 0.7726293206214905, 0.7715517282485962, 0.7219827771186829, 0.7661637663841248, 0.7521551847457886, 0.7607758641242981, 0.7726293206214905, 0.774784505367279, 0.7758620977401733, 0.7510775923728943, 0.7715517282485962, 0.7618534564971924, 0.7058189511299133]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.2975 - accuracy: 0.8687"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 7s 54ms/step - loss: 0.2975 - accuracy: 0.8687 - val_loss: 0.6732 - val_accuracy: 0.5204\n","Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2832 - accuracy: 0.8803 - val_loss: 0.6576 - val_accuracy: 0.5407\n","Epoch 3/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2760 - accuracy: 0.8812 - val_loss: 0.6523 - val_accuracy: 0.5452\n","Epoch 4/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2815 - accuracy: 0.8755 - val_loss: 0.6578 - val_accuracy: 0.5339\n","Epoch 5/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2639 - accuracy: 0.8879 - val_loss: 0.6924 - val_accuracy: 0.5226\n","Epoch 6/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.2784 - accuracy: 0.8817 - val_loss: 0.6463 - val_accuracy: 0.5577\n","Epoch 7/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.2681 - accuracy: 0.8865 - val_loss: 0.6441 - val_accuracy: 0.5656\n","Epoch 8/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.2607 - accuracy: 0.8899 - val_loss: 0.6336 - val_accuracy: 0.5814\n","Epoch 9/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.2712 - accuracy: 0.8854 - val_loss: 0.6190 - val_accuracy: 0.6233\n","Epoch 10/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.2515 - accuracy: 0.8942 - val_loss: 0.6135 - val_accuracy: 0.6346\n","Epoch 11/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.2619 - accuracy: 0.8871 - val_loss: 0.5970 - val_accuracy: 0.6742\n","Epoch 12/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2587 - accuracy: 0.8882 - val_loss: 0.5884 - val_accuracy: 0.6697\n","Epoch 13/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2544 - accuracy: 0.8928 - val_loss: 0.5806 - val_accuracy: 0.6663\n","Epoch 14/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2427 - accuracy: 0.8987 - val_loss: 0.5634 - val_accuracy: 0.7002\n","Epoch 15/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.2599 - accuracy: 0.8953 - val_loss: 0.5551 - val_accuracy: 0.7104\n","Epoch 16/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2568 - accuracy: 0.8882 - val_loss: 0.5999 - val_accuracy: 0.7059\n","Epoch 17/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2607 - accuracy: 0.8857 - val_loss: 0.5297 - val_accuracy: 0.7534\n","Epoch 18/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2481 - accuracy: 0.8911 - val_loss: 0.5297 - val_accuracy: 0.7579\n","Epoch 19/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2521 - accuracy: 0.8933 - val_loss: 0.5376 - val_accuracy: 0.7229\n","Epoch 20/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2454 - accuracy: 0.8990 - val_loss: 0.5395 - val_accuracy: 0.7432\n","Epoch 21/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2568 - accuracy: 0.8871 - val_loss: 0.5481 - val_accuracy: 0.7692\n","Epoch 22/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2323 - accuracy: 0.9058 - val_loss: 0.5202 - val_accuracy: 0.7568\n","Epoch 23/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2445 - accuracy: 0.8987 - val_loss: 0.5414 - val_accuracy: 0.7308\n","Epoch 24/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2368 - accuracy: 0.9029 - val_loss: 0.5732 - val_accuracy: 0.7308\n","Epoch 25/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2457 - accuracy: 0.8933 - val_loss: 0.6016 - val_accuracy: 0.7511\n","Epoch 26/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2411 - accuracy: 0.9035 - val_loss: 0.5367 - val_accuracy: 0.7873\n","Epoch 27/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2293 - accuracy: 0.9069 - val_loss: 0.5589 - val_accuracy: 0.7907\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2407 - accuracy: 0.9010 - val_loss: 0.6379 - val_accuracy: 0.7387\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2597 - accuracy: 0.8874 - val_loss: 0.6102 - val_accuracy: 0.7534\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2590 - accuracy: 0.8896 - val_loss: 0.5708 - val_accuracy: 0.7828\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2229 - accuracy: 0.9103 - val_loss: 0.5882 - val_accuracy: 0.7410\n","Epoch 32/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2302 - accuracy: 0.9055 - val_loss: 0.6122 - val_accuracy: 0.7489\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2220 - accuracy: 0.9083 - val_loss: 0.6102 - val_accuracy: 0.7523\n","Epoch 34/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2404 - accuracy: 0.9004 - val_loss: 0.5944 - val_accuracy: 0.7896\n","Epoch 35/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2448 - accuracy: 0.8978 - val_loss: 0.6126 - val_accuracy: 0.7579\n","Epoch 36/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2239 - accuracy: 0.9097 - val_loss: 0.5766 - val_accuracy: 0.7885\n","Epoch 37/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2328 - accuracy: 0.9069 - val_loss: 0.6470 - val_accuracy: 0.7715\n","Epoch 38/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2222 - accuracy: 0.9080 - val_loss: 0.6077 - val_accuracy: 0.7466\n","Epoch 39/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2223 - accuracy: 0.9123 - val_loss: 0.6367 - val_accuracy: 0.7364\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2196 - accuracy: 0.9061 - val_loss: 0.5913 - val_accuracy: 0.7873\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2231 - accuracy: 0.9109 - val_loss: 0.5917 - val_accuracy: 0.7749\n","Epoch 42/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2296 - accuracy: 0.9046 - val_loss: 0.6123 - val_accuracy: 0.7726\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2153 - accuracy: 0.9089 - val_loss: 0.6062 - val_accuracy: 0.7771\n","Epoch 44/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2332 - accuracy: 0.8976 - val_loss: 0.6412 - val_accuracy: 0.7545\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2216 - accuracy: 0.9109 - val_loss: 0.6128 - val_accuracy: 0.7749\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2207 - accuracy: 0.9120 - val_loss: 0.5872 - val_accuracy: 0.7885\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2138 - accuracy: 0.9143 - val_loss: 0.6157 - val_accuracy: 0.7738\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2113 - accuracy: 0.9174 - val_loss: 0.6546 - val_accuracy: 0.7794\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2104 - accuracy: 0.9145 - val_loss: 0.6715 - val_accuracy: 0.7681\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2198 - accuracy: 0.9154 - val_loss: 0.6546 - val_accuracy: 0.7410\n","Epoch 51/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2242 - accuracy: 0.9072 - val_loss: 0.7491 - val_accuracy: 0.7387\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2243 - accuracy: 0.9041 - val_loss: 0.6606 - val_accuracy: 0.7590\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2138 - accuracy: 0.9151 - val_loss: 0.6797 - val_accuracy: 0.7421\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2169 - accuracy: 0.9151 - val_loss: 0.6488 - val_accuracy: 0.7760\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2240 - accuracy: 0.9044 - val_loss: 0.6120 - val_accuracy: 0.7760\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2154 - accuracy: 0.9154 - val_loss: 0.6737 - val_accuracy: 0.7794\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2161 - accuracy: 0.9123 - val_loss: 0.6151 - val_accuracy: 0.7636\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2063 - accuracy: 0.9134 - val_loss: 0.6585 - val_accuracy: 0.7296\n","Epoch 59/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2072 - accuracy: 0.9145 - val_loss: 0.7158 - val_accuracy: 0.7613\n","Epoch 60/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2021 - accuracy: 0.9182 - val_loss: 0.6525 - val_accuracy: 0.7443\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2020 - accuracy: 0.9154 - val_loss: 0.6896 - val_accuracy: 0.7590\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2045 - accuracy: 0.9177 - val_loss: 0.6950 - val_accuracy: 0.7296\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2009 - accuracy: 0.9233 - val_loss: 0.6793 - val_accuracy: 0.7681\n","Epoch 64/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1918 - accuracy: 0.9236 - val_loss: 0.6650 - val_accuracy: 0.7771\n","Epoch 65/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2017 - accuracy: 0.9196 - val_loss: 0.7442 - val_accuracy: 0.7115\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1957 - accuracy: 0.9267 - val_loss: 0.6868 - val_accuracy: 0.7308\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2173 - accuracy: 0.9151 - val_loss: 0.7078 - val_accuracy: 0.7262\n","Epoch 68/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2085 - accuracy: 0.9160 - val_loss: 0.6766 - val_accuracy: 0.7670\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1949 - accuracy: 0.9239 - val_loss: 0.7010 - val_accuracy: 0.7590\n","Epoch 70/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1952 - accuracy: 0.9253 - val_loss: 0.6823 - val_accuracy: 0.7658\n","Epoch 71/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1878 - accuracy: 0.9213 - val_loss: 0.7711 - val_accuracy: 0.7613\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1991 - accuracy: 0.9160 - val_loss: 0.7458 - val_accuracy: 0.7500\n","Epoch 73/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1950 - accuracy: 0.9261 - val_loss: 0.7038 - val_accuracy: 0.7738\n","Epoch 74/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2042 - accuracy: 0.9171 - val_loss: 0.7470 - val_accuracy: 0.7443\n","Epoch 75/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1915 - accuracy: 0.9219 - val_loss: 0.6890 - val_accuracy: 0.7805\n","Epoch 76/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1949 - accuracy: 0.9256 - val_loss: 0.6844 - val_accuracy: 0.7557\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2049 - accuracy: 0.9219 - val_loss: 0.7861 - val_accuracy: 0.7161\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1981 - accuracy: 0.9179 - val_loss: 0.6787 - val_accuracy: 0.7704\n","Epoch 79/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1916 - accuracy: 0.9253 - val_loss: 0.6724 - val_accuracy: 0.7692\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1919 - accuracy: 0.9196 - val_loss: 0.6724 - val_accuracy: 0.7670\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1835 - accuracy: 0.9261 - val_loss: 0.6957 - val_accuracy: 0.7590\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1796 - accuracy: 0.9287 - val_loss: 0.6593 - val_accuracy: 0.7681\n","Epoch 83/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1805 - accuracy: 0.9267 - val_loss: 0.6780 - val_accuracy: 0.7636\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1787 - accuracy: 0.9318 - val_loss: 0.7113 - val_accuracy: 0.7715\n","Epoch 85/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1736 - accuracy: 0.9335 - val_loss: 0.7172 - val_accuracy: 0.7364\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1816 - accuracy: 0.9363 - val_loss: 0.7266 - val_accuracy: 0.7421\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1725 - accuracy: 0.9324 - val_loss: 0.7484 - val_accuracy: 0.7579\n","Epoch 88/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1754 - accuracy: 0.9278 - val_loss: 0.7841 - val_accuracy: 0.7398\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1881 - accuracy: 0.9247 - val_loss: 0.7118 - val_accuracy: 0.7308\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1840 - accuracy: 0.9242 - val_loss: 0.7544 - val_accuracy: 0.7262\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1797 - accuracy: 0.9273 - val_loss: 0.7777 - val_accuracy: 0.7613\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1849 - accuracy: 0.9222 - val_loss: 0.7315 - val_accuracy: 0.7613\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1901 - accuracy: 0.9250 - val_loss: 0.6971 - val_accuracy: 0.7670\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1768 - accuracy: 0.9295 - val_loss: 0.7098 - val_accuracy: 0.7636\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1718 - accuracy: 0.9352 - val_loss: 0.7196 - val_accuracy: 0.7647\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1706 - accuracy: 0.9301 - val_loss: 0.7001 - val_accuracy: 0.7692\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1651 - accuracy: 0.9360 - val_loss: 0.7629 - val_accuracy: 0.7308\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1737 - accuracy: 0.9312 - val_loss: 0.7205 - val_accuracy: 0.7692\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1728 - accuracy: 0.9293 - val_loss: 0.7081 - val_accuracy: 0.7557\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1707 - accuracy: 0.9270 - val_loss: 0.7651 - val_accuracy: 0.7568\n","{'loss': [0.2974526286125183, 0.2832031846046448, 0.2759987711906433, 0.28151997923851013, 0.26388514041900635, 0.2783970236778259, 0.2680550217628479, 0.26068252325057983, 0.27124014496803284, 0.25150495767593384, 0.261863112449646, 0.2586500942707062, 0.254411518573761, 0.2426908016204834, 0.2598583996295929, 0.25677981972694397, 0.2606942057609558, 0.24809354543685913, 0.2521122694015503, 0.24543005228042603, 0.2568272650241852, 0.23226284980773926, 0.2445092499256134, 0.2367793321609497, 0.24574215710163116, 0.241125226020813, 0.2293449491262436, 0.2406661957502365, 0.2597487270832062, 0.25896888971328735, 0.2229425609111786, 0.2301659733057022, 0.2219604104757309, 0.2404347062110901, 0.24481210112571716, 0.22392825782299042, 0.23284617066383362, 0.2222302109003067, 0.2222817987203598, 0.21957871317863464, 0.22313928604125977, 0.22956494987010956, 0.2153216153383255, 0.23315392434597015, 0.22161978483200073, 0.22065231204032898, 0.21379734575748444, 0.21131816506385803, 0.21035237610340118, 0.21983106434345245, 0.224237322807312, 0.22430069744586945, 0.21379220485687256, 0.21687017381191254, 0.22395120561122894, 0.21539780497550964, 0.21613353490829468, 0.2062968909740448, 0.20715026557445526, 0.2020951807498932, 0.20203134417533875, 0.20450180768966675, 0.20085081458091736, 0.19179590046405792, 0.20170876383781433, 0.19570353627204895, 0.2172865867614746, 0.2085251361131668, 0.19494682550430298, 0.19519227743148804, 0.18777772784233093, 0.19913709163665771, 0.19495917856693268, 0.20418959856033325, 0.19151081144809723, 0.19494307041168213, 0.20494301617145538, 0.19810692965984344, 0.19159002602100372, 0.19189341366291046, 0.18347522616386414, 0.1795811951160431, 0.1805374175310135, 0.17873458564281464, 0.17362754046916962, 0.18161065876483917, 0.1724548637866974, 0.1753542125225067, 0.1881110817193985, 0.18403272330760956, 0.17971669137477875, 0.18491926789283752, 0.1900622695684433, 0.17682315409183502, 0.17179836332798004, 0.17063865065574646, 0.1651054322719574, 0.17371875047683716, 0.1727677285671234, 0.17074978351593018], 'accuracy': [0.8687040209770203, 0.8803055882453918, 0.881154477596283, 0.875495195388794, 0.8879456520080566, 0.8817204236984253, 0.8865308165550232, 0.8899264335632324, 0.8853989839553833, 0.8941709399223328, 0.8870967626571655, 0.8882286548614502, 0.8927561044692993, 0.8986983299255371, 0.8953027725219727, 0.8882286548614502, 0.8856819272041321, 0.8910582661628723, 0.8933219909667969, 0.8989813327789307, 0.8870967626571655, 0.9057725071907043, 0.8986983299255371, 0.9029428362846375, 0.8933219909667969, 0.9035087823867798, 0.9069043397903442, 0.9009620547294617, 0.8873797655105591, 0.8896434903144836, 0.9102999567985535, 0.9054895043373108, 0.9083191752433777, 0.9003961682319641, 0.897849440574646, 0.9097340106964111, 0.9069043397903442, 0.9080362319946289, 0.9122806787490845, 0.9060554504394531, 0.9108659029006958, 0.9046406149864197, 0.90888512134552, 0.8975664973258972, 0.9108659029006958, 0.9119977355003357, 0.9142614603042603, 0.9173740744590759, 0.914544403553009, 0.9153932929039001, 0.9071873426437378, 0.9040747284889221, 0.9151103496551514, 0.9151103496551514, 0.9043576717376709, 0.9153932929039001, 0.9122806787490845, 0.9134125709533691, 0.914544403553009, 0.918222963809967, 0.9153932929039001, 0.9176570177078247, 0.9233163595199585, 0.9235993027687073, 0.9196377992630005, 0.926711916923523, 0.9151103496551514, 0.9159592390060425, 0.9238823056221008, 0.9252971410751343, 0.9213355779647827, 0.9159592390060425, 0.9261460304260254, 0.9170911312103271, 0.921901524066925, 0.9255800843238831, 0.921901524066925, 0.9179400205612183, 0.9252971410751343, 0.9196377992630005, 0.9261460304260254, 0.9286926984786987, 0.926711916923523, 0.9318053126335144, 0.9335030913352966, 0.9363327622413635, 0.9323712587356567, 0.9278438091278076, 0.9247311949729919, 0.9241652488708496, 0.9272778630256653, 0.9221844673156738, 0.9250141382217407, 0.9295415878295898, 0.9352009296417236, 0.9301075339317322, 0.9360498189926147, 0.9312393665313721, 0.9292586445808411, 0.9269949197769165], 'val_loss': [0.6731629371643066, 0.6575781106948853, 0.6523346900939941, 0.6578152775764465, 0.6923807263374329, 0.6463416814804077, 0.6440967321395874, 0.633630633354187, 0.6189533472061157, 0.6134976744651794, 0.5970143675804138, 0.5884050726890564, 0.5806027054786682, 0.5634483695030212, 0.5551053881645203, 0.5998578667640686, 0.5297201871871948, 0.529682993888855, 0.5375561714172363, 0.5395137667655945, 0.5481234192848206, 0.5202131867408752, 0.54139643907547, 0.5731803774833679, 0.6016215085983276, 0.5367228984832764, 0.5588501691818237, 0.6379026770591736, 0.6101518869400024, 0.5707550644874573, 0.5882310271263123, 0.6121866106987, 0.6102093458175659, 0.5944318175315857, 0.6125515699386597, 0.5765640139579773, 0.6469747424125671, 0.6077266335487366, 0.636739194393158, 0.5912912487983704, 0.5917347073554993, 0.6123039126396179, 0.6061667799949646, 0.6412244439125061, 0.6128343939781189, 0.5872241854667664, 0.6157244443893433, 0.654557466506958, 0.6714887022972107, 0.6545606255531311, 0.7490988969802856, 0.6606202125549316, 0.6796603202819824, 0.6487717628479004, 0.6120358109474182, 0.6736918091773987, 0.6151048541069031, 0.6585437655448914, 0.7158005833625793, 0.6525255441665649, 0.6896265745162964, 0.6950163245201111, 0.6793458461761475, 0.6649768948554993, 0.7441756129264832, 0.6868278980255127, 0.7077831625938416, 0.6765620708465576, 0.701029360294342, 0.6822814345359802, 0.7711189389228821, 0.7458414435386658, 0.7037827968597412, 0.746996283531189, 0.688951313495636, 0.6843968629837036, 0.7860727310180664, 0.6787099242210388, 0.6724380850791931, 0.6723566055297852, 0.695725679397583, 0.6593197584152222, 0.6780290007591248, 0.7113121151924133, 0.7172355651855469, 0.7266225814819336, 0.7484461069107056, 0.7840733528137207, 0.7117858529090881, 0.754366934299469, 0.7776839733123779, 0.7315364480018616, 0.6970641613006592, 0.7098413705825806, 0.7195565104484558, 0.7001222372055054, 0.7629445195198059, 0.7205110192298889, 0.7080644965171814, 0.7651374340057373], 'val_accuracy': [0.5203620195388794, 0.540723979473114, 0.5452488660812378, 0.5339366793632507, 0.5226244330406189, 0.557692289352417, 0.5656108856201172, 0.581447958946228, 0.6233031749725342, 0.6346153616905212, 0.6742081642150879, 0.6696832776069641, 0.6662895679473877, 0.7002262473106384, 0.7104072570800781, 0.7058823704719543, 0.7533936500549316, 0.7579185366630554, 0.7228506803512573, 0.7432126402854919, 0.7692307829856873, 0.7567873597145081, 0.7307692170143127, 0.7307692170143127, 0.7511312365531921, 0.7873303294181824, 0.790723979473114, 0.7386877536773682, 0.7533936500549316, 0.7828054428100586, 0.7409502267837524, 0.7488687634468079, 0.7522624731063843, 0.7895927429199219, 0.7579185366630554, 0.7884615659713745, 0.7714931964874268, 0.7466063499450684, 0.7364253401756287, 0.7873303294181824, 0.7748869061470032, 0.7726244330406189, 0.7771493196487427, 0.7545248866081238, 0.7748869061470032, 0.7884615659713745, 0.773755669593811, 0.779411792755127, 0.7680995464324951, 0.7409502267837524, 0.7386877536773682, 0.7590497732162476, 0.7420814633369446, 0.7760180830955505, 0.7760180830955505, 0.779411792755127, 0.7635746598243713, 0.7296379804611206, 0.7613122463226318, 0.7443438768386841, 0.7590497732162476, 0.7296379804611206, 0.7680995464324951, 0.7771493196487427, 0.7115384340286255, 0.7307692170143127, 0.726244330406189, 0.766968309879303, 0.7590497732162476, 0.7658371329307556, 0.7613122463226318, 0.75, 0.773755669593811, 0.7443438768386841, 0.7805429697036743, 0.7556561231613159, 0.7160633206367493, 0.7703620195388794, 0.7692307829856873, 0.766968309879303, 0.7590497732162476, 0.7680995464324951, 0.7635746598243713, 0.7714931964874268, 0.7364253401756287, 0.7420814633369446, 0.7579185366630554, 0.7398189902305603, 0.7307692170143127, 0.726244330406189, 0.7613122463226318, 0.7613122463226318, 0.766968309879303, 0.7635746598243713, 0.7647058963775635, 0.7692307829856873, 0.7307692170143127, 0.7692307829856873, 0.7556561231613159, 0.7567873597145081]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/31 [=========================>....] - ETA: 0s - loss: 0.3174 - accuracy: 0.8657"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 50ms/step - loss: 0.3168 - accuracy: 0.8654 - val_loss: 0.6632 - val_accuracy: 0.5269\n","Epoch 2/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3052 - accuracy: 0.8713 - val_loss: 0.6472 - val_accuracy: 0.5899\n","Epoch 3/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3003 - accuracy: 0.8731 - val_loss: 0.6443 - val_accuracy: 0.5661\n","Epoch 4/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2902 - accuracy: 0.8775 - val_loss: 0.6639 - val_accuracy: 0.5300\n","Epoch 5/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3037 - accuracy: 0.8742 - val_loss: 0.6462 - val_accuracy: 0.5527\n","Epoch 6/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2867 - accuracy: 0.8817 - val_loss: 0.6494 - val_accuracy: 0.5517\n","Epoch 7/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2825 - accuracy: 0.8819 - val_loss: 0.6296 - val_accuracy: 0.5899\n","Epoch 8/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2823 - accuracy: 0.8855 - val_loss: 0.6302 - val_accuracy: 0.5795\n","Epoch 9/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2785 - accuracy: 0.8884 - val_loss: 0.6078 - val_accuracy: 0.6074\n","Epoch 10/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.2997 - accuracy: 0.8767 - val_loss: 0.6062 - val_accuracy: 0.6126\n","Epoch 11/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.2847 - accuracy: 0.8773 - val_loss: 0.5914 - val_accuracy: 0.6612\n","Epoch 12/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.2695 - accuracy: 0.8879 - val_loss: 0.5772 - val_accuracy: 0.6756\n","Epoch 13/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.2704 - accuracy: 0.8842 - val_loss: 0.5655 - val_accuracy: 0.6808\n","Epoch 14/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.2756 - accuracy: 0.8868 - val_loss: 0.5551 - val_accuracy: 0.7262\n","Epoch 15/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2669 - accuracy: 0.8871 - val_loss: 0.5767 - val_accuracy: 0.7014\n","Epoch 16/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2783 - accuracy: 0.8871 - val_loss: 0.5333 - val_accuracy: 0.7552\n","Epoch 17/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2601 - accuracy: 0.8948 - val_loss: 0.5473 - val_accuracy: 0.7273\n","Epoch 18/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2587 - accuracy: 0.8979 - val_loss: 0.5442 - val_accuracy: 0.7304\n","Epoch 19/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2675 - accuracy: 0.8840 - val_loss: 0.5263 - val_accuracy: 0.7634\n","Epoch 20/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2631 - accuracy: 0.8948 - val_loss: 0.5316 - val_accuracy: 0.7676\n","Epoch 21/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2630 - accuracy: 0.8899 - val_loss: 0.5494 - val_accuracy: 0.7583\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2557 - accuracy: 0.8972 - val_loss: 0.5954 - val_accuracy: 0.7262\n","Epoch 23/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2550 - accuracy: 0.8992 - val_loss: 0.5712 - val_accuracy: 0.7665\n","Epoch 24/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3031 - accuracy: 0.8672 - val_loss: 0.5640 - val_accuracy: 0.7696\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2638 - accuracy: 0.8920 - val_loss: 0.5867 - val_accuracy: 0.7624\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2598 - accuracy: 0.8899 - val_loss: 0.6143 - val_accuracy: 0.7583\n","Epoch 27/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2578 - accuracy: 0.8917 - val_loss: 0.6136 - val_accuracy: 0.7428\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2518 - accuracy: 0.8951 - val_loss: 0.6251 - val_accuracy: 0.7510\n","Epoch 29/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2438 - accuracy: 0.9047 - val_loss: 0.6091 - val_accuracy: 0.7624\n","Epoch 30/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2469 - accuracy: 0.8951 - val_loss: 0.6127 - val_accuracy: 0.7707\n","Epoch 31/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2487 - accuracy: 0.8946 - val_loss: 0.6244 - val_accuracy: 0.7676\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2551 - accuracy: 0.8922 - val_loss: 0.6320 - val_accuracy: 0.7541\n","Epoch 33/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.2482 - accuracy: 0.8995 - val_loss: 0.6120 - val_accuracy: 0.7717\n","Epoch 34/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2471 - accuracy: 0.8956 - val_loss: 0.6387 - val_accuracy: 0.7521\n","Epoch 35/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2575 - accuracy: 0.8977 - val_loss: 0.6642 - val_accuracy: 0.7314\n","Epoch 36/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2413 - accuracy: 0.8990 - val_loss: 0.6324 - val_accuracy: 0.7593\n","Epoch 37/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2381 - accuracy: 0.9044 - val_loss: 0.6678 - val_accuracy: 0.7479\n","Epoch 38/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2496 - accuracy: 0.9000 - val_loss: 0.6461 - val_accuracy: 0.7603\n","Epoch 39/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2350 - accuracy: 0.9057 - val_loss: 0.6608 - val_accuracy: 0.7521\n","Epoch 40/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2326 - accuracy: 0.9049 - val_loss: 0.6832 - val_accuracy: 0.7428\n","Epoch 41/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2470 - accuracy: 0.8959 - val_loss: 0.7248 - val_accuracy: 0.7417\n","Epoch 42/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2418 - accuracy: 0.9044 - val_loss: 0.6621 - val_accuracy: 0.7521\n","Epoch 43/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2451 - accuracy: 0.8992 - val_loss: 0.6699 - val_accuracy: 0.7469\n","Epoch 44/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2282 - accuracy: 0.9049 - val_loss: 0.6511 - val_accuracy: 0.7552\n","Epoch 45/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2375 - accuracy: 0.9018 - val_loss: 0.6933 - val_accuracy: 0.7376\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2307 - accuracy: 0.9062 - val_loss: 0.6735 - val_accuracy: 0.7510\n","Epoch 47/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2224 - accuracy: 0.9129 - val_loss: 0.6996 - val_accuracy: 0.7407\n","Epoch 48/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2331 - accuracy: 0.9041 - val_loss: 0.7214 - val_accuracy: 0.7283\n","Epoch 49/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2278 - accuracy: 0.9021 - val_loss: 0.6959 - val_accuracy: 0.7386\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2299 - accuracy: 0.9078 - val_loss: 0.6721 - val_accuracy: 0.7531\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2321 - accuracy: 0.9083 - val_loss: 0.6840 - val_accuracy: 0.7531\n","Epoch 52/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2289 - accuracy: 0.9021 - val_loss: 0.6941 - val_accuracy: 0.7459\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2272 - accuracy: 0.9026 - val_loss: 0.6951 - val_accuracy: 0.7355\n","Epoch 54/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2149 - accuracy: 0.9111 - val_loss: 0.6842 - val_accuracy: 0.7479\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2249 - accuracy: 0.9085 - val_loss: 0.7015 - val_accuracy: 0.7479\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2223 - accuracy: 0.9078 - val_loss: 0.6979 - val_accuracy: 0.7541\n","Epoch 57/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2254 - accuracy: 0.9103 - val_loss: 0.7362 - val_accuracy: 0.7283\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2234 - accuracy: 0.9090 - val_loss: 0.7125 - val_accuracy: 0.7510\n","Epoch 59/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2201 - accuracy: 0.9140 - val_loss: 0.7173 - val_accuracy: 0.7448\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2314 - accuracy: 0.9054 - val_loss: 0.6999 - val_accuracy: 0.7510\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2242 - accuracy: 0.9124 - val_loss: 0.7140 - val_accuracy: 0.7459\n","Epoch 62/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2329 - accuracy: 0.9023 - val_loss: 0.7173 - val_accuracy: 0.7562\n","Epoch 63/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2263 - accuracy: 0.9088 - val_loss: 0.7324 - val_accuracy: 0.7293\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2063 - accuracy: 0.9150 - val_loss: 0.7220 - val_accuracy: 0.7366\n","Epoch 65/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2179 - accuracy: 0.9140 - val_loss: 0.7499 - val_accuracy: 0.7180\n","Epoch 66/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2119 - accuracy: 0.9158 - val_loss: 0.7831 - val_accuracy: 0.7169\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2112 - accuracy: 0.9155 - val_loss: 0.7718 - val_accuracy: 0.7180\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2150 - accuracy: 0.9111 - val_loss: 0.7394 - val_accuracy: 0.7510\n","Epoch 69/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2042 - accuracy: 0.9147 - val_loss: 0.7462 - val_accuracy: 0.7438\n","Epoch 70/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2064 - accuracy: 0.9165 - val_loss: 0.7384 - val_accuracy: 0.7479\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2084 - accuracy: 0.9163 - val_loss: 0.7915 - val_accuracy: 0.7386\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2245 - accuracy: 0.9090 - val_loss: 0.7470 - val_accuracy: 0.7324\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2121 - accuracy: 0.9129 - val_loss: 0.7376 - val_accuracy: 0.7521\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2067 - accuracy: 0.9194 - val_loss: 0.7990 - val_accuracy: 0.7118\n","Epoch 75/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2057 - accuracy: 0.9186 - val_loss: 0.7620 - val_accuracy: 0.7521\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2127 - accuracy: 0.9168 - val_loss: 0.7507 - val_accuracy: 0.7438\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2041 - accuracy: 0.9145 - val_loss: 0.8033 - val_accuracy: 0.7076\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2028 - accuracy: 0.9245 - val_loss: 0.7480 - val_accuracy: 0.7469\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1983 - accuracy: 0.9204 - val_loss: 0.7711 - val_accuracy: 0.7345\n","Epoch 80/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1999 - accuracy: 0.9204 - val_loss: 0.7661 - val_accuracy: 0.7428\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2041 - accuracy: 0.9171 - val_loss: 0.7815 - val_accuracy: 0.7345\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1996 - accuracy: 0.9214 - val_loss: 0.7678 - val_accuracy: 0.7407\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2319 - accuracy: 0.9098 - val_loss: 0.7807 - val_accuracy: 0.7252\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1966 - accuracy: 0.9235 - val_loss: 0.7634 - val_accuracy: 0.7428\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2035 - accuracy: 0.9186 - val_loss: 0.7609 - val_accuracy: 0.7397\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2030 - accuracy: 0.9194 - val_loss: 0.7655 - val_accuracy: 0.7376\n","Epoch 87/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1977 - accuracy: 0.9181 - val_loss: 0.8544 - val_accuracy: 0.6901\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2304 - accuracy: 0.9031 - val_loss: 0.7916 - val_accuracy: 0.7355\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1974 - accuracy: 0.9238 - val_loss: 0.8215 - val_accuracy: 0.7314\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1963 - accuracy: 0.9222 - val_loss: 0.7903 - val_accuracy: 0.7366\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1905 - accuracy: 0.9264 - val_loss: 0.7655 - val_accuracy: 0.7428\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1850 - accuracy: 0.9274 - val_loss: 0.8283 - val_accuracy: 0.6994\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1892 - accuracy: 0.9233 - val_loss: 0.8046 - val_accuracy: 0.7169\n","Epoch 94/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2203 - accuracy: 0.9057 - val_loss: 0.7734 - val_accuracy: 0.7366\n","Epoch 95/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1918 - accuracy: 0.9202 - val_loss: 0.8061 - val_accuracy: 0.7366\n","Epoch 96/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1858 - accuracy: 0.9256 - val_loss: 0.8357 - val_accuracy: 0.7190\n","Epoch 97/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1830 - accuracy: 0.9269 - val_loss: 0.9067 - val_accuracy: 0.6860\n","Epoch 98/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1789 - accuracy: 0.9289 - val_loss: 0.8003 - val_accuracy: 0.7335\n","Epoch 99/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1987 - accuracy: 0.9194 - val_loss: 0.8974 - val_accuracy: 0.6973\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1820 - accuracy: 0.9271 - val_loss: 0.8276 - val_accuracy: 0.7335\n","{'loss': [0.31681588292121887, 0.30523380637168884, 0.30031245946884155, 0.29015254974365234, 0.30367234349250793, 0.2867121696472168, 0.28251180052757263, 0.28231051564216614, 0.2785482108592987, 0.2996613681316376, 0.28468865156173706, 0.2695156931877136, 0.27035778760910034, 0.27562832832336426, 0.26685330271720886, 0.2783496379852295, 0.26014578342437744, 0.25872719287872314, 0.267532616853714, 0.26313576102256775, 0.2630246579647064, 0.25571438670158386, 0.25499504804611206, 0.30312591791152954, 0.26382628083229065, 0.2597932815551758, 0.2577720880508423, 0.25182265043258667, 0.24376729130744934, 0.2469436228275299, 0.24874472618103027, 0.25510501861572266, 0.24818168580532074, 0.2470841109752655, 0.25750166177749634, 0.24128848314285278, 0.23809659481048584, 0.24956901371479034, 0.2350023239850998, 0.23259715735912323, 0.24699534475803375, 0.2417679727077484, 0.2451346516609192, 0.22821588814258575, 0.2374691516160965, 0.23069719970226288, 0.22237373888492584, 0.23314876854419708, 0.2278154343366623, 0.22987309098243713, 0.2320644110441208, 0.22886723279953003, 0.22721321880817413, 0.21488742530345917, 0.22493742406368256, 0.222280815243721, 0.2254277914762497, 0.22336271405220032, 0.22009332478046417, 0.2313511222600937, 0.22423771023750305, 0.2328971028327942, 0.22630682587623596, 0.20625771582126617, 0.21788233518600464, 0.21191276609897614, 0.21117696166038513, 0.2150384485721588, 0.20418334007263184, 0.20641402900218964, 0.2084101140499115, 0.22445523738861084, 0.2120966613292694, 0.206705242395401, 0.2056928277015686, 0.21274225413799286, 0.20414121448993683, 0.20282529294490814, 0.1982879936695099, 0.19985482096672058, 0.20409978926181793, 0.1995587944984436, 0.23188811540603638, 0.19657796621322632, 0.2034965306520462, 0.20295539498329163, 0.1976943463087082, 0.23039428889751434, 0.19743949174880981, 0.1963159441947937, 0.19054359197616577, 0.18498630821704865, 0.189216747879982, 0.2202906310558319, 0.1918395608663559, 0.18576210737228394, 0.18298912048339844, 0.17886702716350555, 0.19866035878658295, 0.18202081322669983], 'accuracy': [0.8653746843338013, 0.8713178038597107, 0.8731266260147095, 0.8775193691253662, 0.8741602301597595, 0.8816537261009216, 0.8819121718406677, 0.8855296969413757, 0.8883720636367798, 0.8767442107200623, 0.8772609829902649, 0.8878552913665771, 0.8842377066612244, 0.8868216872215271, 0.8870801329612732, 0.8870801329612732, 0.8948320150375366, 0.8979328274726868, 0.883979320526123, 0.8948320150375366, 0.8899224996566772, 0.897157609462738, 0.8992248177528381, 0.8671834468841553, 0.8919896483421326, 0.8899224996566772, 0.8917312622070312, 0.8950904607772827, 0.9046511650085449, 0.8950904607772827, 0.8945736289024353, 0.8922480344772339, 0.8994832038879395, 0.8956072330474854, 0.8976744413375854, 0.8989664316177368, 0.9043927788734436, 0.8999999761581421, 0.905684769153595, 0.9049095511436462, 0.8958656191825867, 0.9043927788734436, 0.8992248177528381, 0.9049095511436462, 0.9018087983131409, 0.9062015414237976, 0.9129198789596558, 0.9041343927383423, 0.9020671844482422, 0.9077519178390503, 0.9082687497138977, 0.9020671844482422, 0.9025839567184448, 0.9111111164093018, 0.908527135848999, 0.9077519178390503, 0.910335898399353, 0.9090439081192017, 0.9139534831047058, 0.9054263830184937, 0.9124031066894531, 0.9023255705833435, 0.9087855219841003, 0.9149870872497559, 0.9139534831047058, 0.9157622456550598, 0.9155038595199585, 0.9111111164093018, 0.9147287011146545, 0.9165374636650085, 0.9162790775299072, 0.9090439081192017, 0.9129198789596558, 0.9193798303604126, 0.9186046719551086, 0.9167958498001099, 0.9144702553749084, 0.9245477914810181, 0.9204134345054626, 0.9204134345054626, 0.9170542359352112, 0.9214470386505127, 0.9098191261291504, 0.923514187335968, 0.9186046719551086, 0.9193798303604126, 0.9180878400802612, 0.9031007885932922, 0.9237726330757141, 0.9222221970558167, 0.9263566136360168, 0.9273901581764221, 0.9232558012008667, 0.905684769153595, 0.9201550483703613, 0.9255813956260681, 0.9268733859062195, 0.9289405941963196, 0.9193798303604126, 0.9271317720413208], 'val_loss': [0.6632468104362488, 0.6472483277320862, 0.6442899703979492, 0.6638588309288025, 0.6461741328239441, 0.649357795715332, 0.6296495199203491, 0.6302419900894165, 0.6077588796615601, 0.6062248945236206, 0.5913604497909546, 0.5772302746772766, 0.5654518008232117, 0.5551300048828125, 0.5767210721969604, 0.5333377718925476, 0.5472671389579773, 0.5441874265670776, 0.5262967348098755, 0.5316176414489746, 0.5494266152381897, 0.5954428315162659, 0.5712348818778992, 0.5639603734016418, 0.5867367386817932, 0.6143127679824829, 0.6136059165000916, 0.625126838684082, 0.6091156005859375, 0.6126807928085327, 0.6244034767150879, 0.6320154070854187, 0.6119886636734009, 0.638664186000824, 0.6642464995384216, 0.6323798894882202, 0.6677630543708801, 0.6461310982704163, 0.6607564687728882, 0.6832295060157776, 0.7247503399848938, 0.6621382236480713, 0.669928252696991, 0.6510601043701172, 0.6932899355888367, 0.6734959483146667, 0.6996405124664307, 0.7213619351387024, 0.6959494352340698, 0.6721408367156982, 0.684005856513977, 0.694059431552887, 0.6951014399528503, 0.6841633915901184, 0.7014540433883667, 0.6978978514671326, 0.7362431883811951, 0.7124500274658203, 0.7173000574111938, 0.69993656873703, 0.7139771580696106, 0.7173142433166504, 0.7324110269546509, 0.7219933867454529, 0.7498658299446106, 0.7831152677536011, 0.7718303799629211, 0.7393955588340759, 0.7461634874343872, 0.7383601069450378, 0.7914753556251526, 0.7469761371612549, 0.7375728487968445, 0.7989597320556641, 0.7619526982307434, 0.7506753206253052, 0.803341805934906, 0.7480244636535645, 0.7711147665977478, 0.7660657167434692, 0.7814544439315796, 0.7678325176239014, 0.78068608045578, 0.763425350189209, 0.7608901858329773, 0.7655234336853027, 0.8544198274612427, 0.7915571331977844, 0.8215203881263733, 0.7902615666389465, 0.7655159831047058, 0.8282971382141113, 0.8046423196792603, 0.7733830213546753, 0.806145191192627, 0.8357095718383789, 0.9067447185516357, 0.8002541661262512, 0.8973973393440247, 0.8276433944702148], 'val_accuracy': [0.5268595218658447, 0.5898760557174683, 0.56611567735672, 0.5299586653709412, 0.5526859760284424, 0.5516529083251953, 0.5898760557174683, 0.5795454382896423, 0.6074380278587341, 0.6126033067703247, 0.6611570119857788, 0.6756198406219482, 0.6807851195335388, 0.7262396812438965, 0.7014462947845459, 0.7551652789115906, 0.7272727489471436, 0.73037189245224, 0.7634297609329224, 0.7675619721412659, 0.7582644820213318, 0.7262396812438965, 0.7665289044380188, 0.76962810754776, 0.7623966932296753, 0.7582644820213318, 0.7427685856819153, 0.7510330677032471, 0.7623966932296753, 0.7706611752510071, 0.7675619721412659, 0.7541322112083435, 0.7716942429542542, 0.7520661354064941, 0.7314049601554871, 0.7592975497245789, 0.7479338645935059, 0.7603305578231812, 0.7520661354064941, 0.7427685856819153, 0.7417355179786682, 0.7520661354064941, 0.7469007968902588, 0.7551652789115906, 0.7376033067703247, 0.7510330677032471, 0.7407024502754211, 0.7283057570457458, 0.7386363744735718, 0.7530992031097412, 0.7530992031097412, 0.7458677887916565, 0.7355371713638306, 0.7479338645935059, 0.7479338645935059, 0.7541322112083435, 0.7283057570457458, 0.7510330677032471, 0.7448347210884094, 0.7510330677032471, 0.7458677887916565, 0.7561983466148376, 0.7293388247489929, 0.7365702390670776, 0.7179751992225647, 0.7169421315193176, 0.7179751992225647, 0.7510330677032471, 0.7438016533851624, 0.7479338645935059, 0.7386363744735718, 0.7324380278587341, 0.7520661354064941, 0.711776852607727, 0.7520661354064941, 0.7438016533851624, 0.7076446413993835, 0.7469007968902588, 0.7345041036605835, 0.7427685856819153, 0.7345041036605835, 0.7407024502754211, 0.7252066135406494, 0.7427685856819153, 0.7396694421768188, 0.7376033067703247, 0.6900826692581177, 0.7355371713638306, 0.7314049601554871, 0.7365702390670776, 0.7427685856819153, 0.6993801593780518, 0.7169421315193176, 0.7365702390670776, 0.7365702390670776, 0.7190082669258118, 0.6859503984451294, 0.7334710955619812, 0.6973140239715576, 0.7334710955619812]}\n","32/32 [==============================] - 1s 4ms/step\n"]}],"source":["global_model, metrics_df = federated_learning(Theta_data)\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1717432519474,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"},"user_tz":-360},"id":"Ik5JoVP2NPvY","outputId":"9748b5c9-857c-4e26-9dc4-a27e20c42363"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.617      0.653   0.501  0.567        0.501        0.734   \n","1        1     0.635      0.728   0.431  0.541        0.431        0.839   \n","2        2     0.624      0.618   0.651  0.634        0.651        0.598   \n","3        0     0.648      0.675   0.571  0.619        0.571        0.725   \n","4        1     0.681      0.722   0.590  0.650        0.590        0.773   \n","5        2     0.653      0.641   0.695  0.667        0.695        0.610   \n","6        0     0.677      0.655   0.745  0.697        0.745        0.608   \n","7        1     0.703      0.715   0.677  0.695        0.677        0.730   \n","8        2     0.664      0.630   0.791  0.702        0.791        0.536   \n","9        0     0.694      0.752   0.580  0.655        0.580        0.809   \n","10       1     0.719      0.773   0.620  0.688        0.620        0.818   \n","11       2     0.732      0.723   0.751  0.737        0.751        0.713   \n","12       0     0.659      0.623   0.807  0.703        0.807        0.511   \n","13       1     0.751      0.776   0.706  0.740        0.706        0.797   \n","14       2     0.748      0.730   0.787  0.757        0.787        0.709   \n","\n","    Kappa  \n","0   0.235  \n","1   0.270  \n","2   0.249  \n","3   0.296  \n","4   0.363  \n","5   0.305  \n","6   0.353  \n","7   0.407  \n","8   0.327  \n","9   0.389  \n","10  0.438  \n","11  0.464  \n","12  0.318  \n","13  0.503  \n","14  0.496  "],"text/html":["\n","  <div id=\"df-ca1edc7e-bc0c-429b-a6f5-09e3549458be\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.617</td>\n","      <td>0.653</td>\n","      <td>0.501</td>\n","      <td>0.567</td>\n","      <td>0.501</td>\n","      <td>0.734</td>\n","      <td>0.235</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.635</td>\n","      <td>0.728</td>\n","      <td>0.431</td>\n","      <td>0.541</td>\n","      <td>0.431</td>\n","      <td>0.839</td>\n","      <td>0.270</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.624</td>\n","      <td>0.618</td>\n","      <td>0.651</td>\n","      <td>0.634</td>\n","      <td>0.651</td>\n","      <td>0.598</td>\n","      <td>0.249</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.648</td>\n","      <td>0.675</td>\n","      <td>0.571</td>\n","      <td>0.619</td>\n","      <td>0.571</td>\n","      <td>0.725</td>\n","      <td>0.296</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.681</td>\n","      <td>0.722</td>\n","      <td>0.590</td>\n","      <td>0.650</td>\n","      <td>0.590</td>\n","      <td>0.773</td>\n","      <td>0.363</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.653</td>\n","      <td>0.641</td>\n","      <td>0.695</td>\n","      <td>0.667</td>\n","      <td>0.695</td>\n","      <td>0.610</td>\n","      <td>0.305</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.677</td>\n","      <td>0.655</td>\n","      <td>0.745</td>\n","      <td>0.697</td>\n","      <td>0.745</td>\n","      <td>0.608</td>\n","      <td>0.353</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.703</td>\n","      <td>0.715</td>\n","      <td>0.677</td>\n","      <td>0.695</td>\n","      <td>0.677</td>\n","      <td>0.730</td>\n","      <td>0.407</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.664</td>\n","      <td>0.630</td>\n","      <td>0.791</td>\n","      <td>0.702</td>\n","      <td>0.791</td>\n","      <td>0.536</td>\n","      <td>0.327</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.694</td>\n","      <td>0.752</td>\n","      <td>0.580</td>\n","      <td>0.655</td>\n","      <td>0.580</td>\n","      <td>0.809</td>\n","      <td>0.389</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.719</td>\n","      <td>0.773</td>\n","      <td>0.620</td>\n","      <td>0.688</td>\n","      <td>0.620</td>\n","      <td>0.818</td>\n","      <td>0.438</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.732</td>\n","      <td>0.723</td>\n","      <td>0.751</td>\n","      <td>0.737</td>\n","      <td>0.751</td>\n","      <td>0.713</td>\n","      <td>0.464</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.659</td>\n","      <td>0.623</td>\n","      <td>0.807</td>\n","      <td>0.703</td>\n","      <td>0.807</td>\n","      <td>0.511</td>\n","      <td>0.318</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.751</td>\n","      <td>0.776</td>\n","      <td>0.706</td>\n","      <td>0.740</td>\n","      <td>0.706</td>\n","      <td>0.797</td>\n","      <td>0.503</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.748</td>\n","      <td>0.730</td>\n","      <td>0.787</td>\n","      <td>0.757</td>\n","      <td>0.787</td>\n","      <td>0.709</td>\n","      <td>0.496</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca1edc7e-bc0c-429b-a6f5-09e3549458be')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ca1edc7e-bc0c-429b-a6f5-09e3549458be button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ca1edc7e-bc0c-429b-a6f5-09e3549458be');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-1b64e09e-671f-4d3a-83bc-e2907c8735a2\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b64e09e-671f-4d3a-83bc-e2907c8735a2')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-1b64e09e-671f-4d3a-83bc-e2907c8735a2 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.043262763049378455,\n        \"min\": 0.617,\n        \"max\": 0.751,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.694,\n          0.732,\n          0.617\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0548575644825067,\n        \"min\": 0.618,\n        \"max\": 0.776,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.752,\n          0.723,\n          0.653\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11105288315547175,\n        \"min\": 0.431,\n        \"max\": 0.807,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.58,\n          0.751,\n          0.501\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06125458194718015,\n        \"min\": 0.541,\n        \"max\": 0.757,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.655,\n          0.737,\n          0.567\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11105288315547175,\n        \"min\": 0.431,\n        \"max\": 0.807,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.58,\n          0.751,\n          0.501\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10432549795620209,\n        \"min\": 0.511,\n        \"max\": 0.839,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.809,\n          0.713,\n          0.734\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08658675803300796,\n        \"min\": 0.235,\n        \"max\": 0.503,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.389,\n          0.464,\n          0.235\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":13}],"source":["\n","metrics_df.round(3)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"Ncf_cMAQF6g4","executionInfo":{"status":"ok","timestamp":1717432520321,"user_tz":-360,"elapsed":858,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"outputs":[],"source":["metrics_df.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Frequency Domain/CNN_LSTM/Theta_frequency_CNN_LSTM.csv', index = False)"]},{"cell_type":"markdown","source":["#Draw CNN_LSTM"],"metadata":{"id":"VNy6-RxAKjH8"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import re\n","import os\n","\n","# Function to read CSV logs and extract accuracy and validation accuracy\n","def read_logs(log_dir, num_clients, local_epochs):\n","    dataframes = []\n","    for epoch in range(local_epochs):\n","        for client in range(num_clients):\n","            log_file = os.path.join(log_dir, f'training_log_epoch_{epoch}_client_{client}.csv')\n","            if os.path.exists(log_file):\n","                df = pd.read_csv(log_file, sep=';')\n","                df['epoch_number'] = epoch\n","                df['client_number'] = client\n","                dataframes.append(df)\n","            else:\n","                print(f\"Log file not found: {log_file}\")\n","\n","    return pd.concat(dataframes) if dataframes else pd.DataFrame()\n","\n","# Function to plot the training and validation accuracy\n","def plot_accuracy(all_metrics_df, unique_epochs, output_dir):\n","    # Set the Seaborn style\n","    sns.set(style=\"whitegrid\")\n","\n","    # Create subplots for each epoch\n","    fig, axes = plt.subplots(2, len(unique_epochs), figsize=(len(unique_epochs) * 3, 4.5), sharex=True)\n","\n","    # Set the color palette\n","    palette = sns.color_palette(\"Set1\", n_colors=all_metrics_df['client_number'].nunique())\n","\n","    # Store the lines and labels for the legend\n","    lines = []\n","    labels = []\n","\n","    # Iterate through each epoch and plot the training and validation accuracy\n","    for i, epoch in enumerate(unique_epochs):\n","        epoch_df = all_metrics_df[all_metrics_df['epoch_number'] == epoch]\n","        for j, client in enumerate(epoch_df['client_number'].unique()):\n","            client_df = epoch_df[epoch_df['client_number'] == client].dropna(subset=['accuracy', 'val_accuracy'])\n","            if not client_df.empty:\n","                line, = axes[0, i].plot(client_df.index, client_df['accuracy'], label=f'Client {client}', alpha=0.6, color=palette[j], linewidth=2.0)\n","                axes[1, i].plot(client_df.index, client_df['val_accuracy'], label=f'Client {client}', alpha=0.6, color=palette[j], linewidth=2.0)\n","\n","                if i == 0:\n","                    lines.append(line)\n","                    labels.append(f'Client {client}')\n","\n","        axes[0, i].set_title(f'Epoch {epoch}', fontsize=12, fontweight='bold')\n","        axes[0, i].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","        axes[1, i].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","        axes[1, i].set_xlabel('Steps', fontsize=10, fontweight='bold')\n","        axes[0, i].grid(True)\n","        axes[1, i].grid(True)\n","        axes[0, i].tick_params(axis='both', which='major', labelsize=10)\n","        axes[1, i].tick_params(axis='both', which='major', labelsize=10)\n","\n","    # Add a single legend for the entire figure\n","    fig.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, 1.0), ncol=len(labels), fontsize=10, frameon=True)\n","\n","    # Add row labels\n","    fig.text(0.04, 0.75, 'Training Accuracy', ha='center', va='center', rotation='vertical', fontsize=12, fontweight='bold')\n","    fig.text(0.04, 0.25, 'Validation Accuracy', ha='center', va='center', rotation='vertical', fontsize=12, fontweight='bold')\n","\n","    plt.tight_layout(rect=[0.05, 0, 1, 0.95])\n","    plt.subplots_adjust(hspace=0.2, top=0.88)  # Add some space between the rows and reduce space between the legend and plot\n","\n","    # Save the figure in high DPI PNG and PDF\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    fig.savefig(os.path.join(output_dir, 'accuracy_plot.png'), dpi=300, format='png')\n","    fig.savefig(os.path.join(output_dir, 'accuracy_plot.pdf'), dpi=300, format='pdf')\n","\n","    plt.show()\n","\n","# Directory where CSV logs are saved\n","log_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Theta'\n","\n","# Output directory for saving plots\n","output_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Theta/plots'\n","\n","# Number of clients and local epochs\n","num_clients = 3\n","local_epochs = 5\n","\n","# Read logs and generate the dataframe\n","all_metrics_df = read_logs(log_dir, num_clients, local_epochs)\n","\n","# Get unique epochs from the dataframe\n","unique_epochs = sorted(all_metrics_df['epoch_number'].unique())\n","\n","# Plot the accuracy\n","plot_accuracy(all_metrics_df, unique_epochs, output_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":462},"id":"e-S2thS6KnXT","executionInfo":{"status":"ok","timestamp":1716752066509,"user_tz":-360,"elapsed":5189,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}},"outputId":"2317441e-7595-44cf-d77e-de00b3f3de1b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x450 with 10 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAABasAAAG9CAYAAAAbRyppAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3gc1bn48e/M9tUW9Wq5yFXGBQy2wRhMcegQIIHkJoRfCISEG3LvzSWBkEAS0uDmklwC6YUSQkIIBOLQiwFTXHDBvap3rdqutu+U3x8rrSRkgxGyZcvv53l4Hu3s7Mw5K3Q8884576uYpmkihBBCCCGEEEIIIYQQQowhdawbIIQQQgghhBBCCCGEEEJIsFoIIYQQQgghhBBCCCHEmJNgtRBCCCGEEEIIIYQQQogxJ8FqIYQQQgghhBBCCCGEEGNOgtVCCCGEEEIIIYQQQgghxpwEq4UQQgghhBBCCCGEEEKMOQlWCyGEEEIIIYQQQgghhBhzEqwWQgghhBBCCCGEEEIIMeasY90AIYQQQoxvuq6TSqXGuhlCCHHUs9lsWCyWsW6GEEIIIcQhI8FqIYQQQhwSpmnS2tpKT0/PWDdFCCHGjezsbIqLi1EUZaybIoQQQggx6iRYLYQQQohDoj9QXVhYiNvtlsCKEEJ8BKZpEo1GaW9vB6CkpGSMWySEEEIIMfokWC2EEEKIUafreiZQnZeXN9bNEUKIccHlcgHQ3t5OYWGhpAQRQgghxLgjBRaFEEIIMer6c1S73e4xbokQQowv/eOq1AIQQgghxHgkwWohhBBCHDKS+kMIIUaXjKtCCCGEGM8kWC2EEEIIIYQQQgghhBBizEmwWgghhBBiBGbOnMnLL78MQGNjIzNnzmTnzp1j3CoxWuT3O77J71cIIYQQ4sgkwWohhBBCiPcIBAL84Ac/4Oyzz2bOnDksW7aML3/5y6xevXq/+5eUlPDmm28yffr0UW3H4IDa++np6eGmm25iwYIFnHTSSXzrW98iEomMalvGk6Pt9/vrX/+aT3/608yfP5+TTjppVNswHh1Nv9/Gxka+9a1vcdZZZzFv3jyWL1/OvffeSzKZHNW2CCGEEEIcLaxj3QAhhBBCiCNJY2Mj//Zv/4bP5+Pmm29mxowZaJrGm2++yR133MHzzz8/7DMWi4WCgoIxaG3a17/+dQKBAA888ACpVIpvfetbfOc73+GnP/3pmLXpSHU0/n5TqRTnnXcexx9/PI8//viYteNocLT9fqurqzFNk+9///tMmjSJPXv2cPvttxOLxbjlllvGpE1CCCGEEGNJgtVCCCGEEIPccccdKIrC3//+d9xud2b79OnT+cQnPrHfzzQ2NnL22Wfz1FNPUVlZCcCePXv4yU9+woYNG3C5XJx66qnceuut5ObmAvC5z32OmTNnYrfbefzxx7HZbHz605/mq1/9KgBnnXUWAF/5ylcAKCsrY+XKlcPOXVVVxRtvvMHjjz/O3LlzAbjtttu4/vrrufnmmykqKhqlb2Z8ONp+vwD/8R//AcA//vGPUfgGxrej7fd7+umnc/rpp2del5eXU1NTw1//+lcJVgshhBDimCRpQIQQQggh+vT09PDGG2/w2c9+dkigq5/P5zuo44RCIf7f//t/zJ49m8cff5w//OEPdHZ28l//9V9D9nvyySdxu9089thjfOMb3+CXv/wlb731FkBmBu2dd97Jm2++ecAZtZs2bcLn82UC1QBLlixBVVW2bNlyUO09VhyNv19x8MbL77e3txe/33/Q+wshhBBCjCcys1oIIYQQh01yyxbiL76EmUgctnMqDgfOc8/BPiiYeyD19fWYpklFRcVHOuef//xnZs+ezX//939ntv34xz9m2bJl1NTUMGXKFCCd0/bGG28EYPLkyfz5z39m9erVnHrqqZkZnD6f731TFHR0dGT27We1WvH7/QQCgY/Ujw9rV3OQN3YFSGj6YTunw2rhtFmFzCr94EDk0fj7PZLs69nLupa1JI3Dl0/ZrtpZXHIyU7OnfeC+4+H3W1dXx5///GeZVS2EEEKIY5YEq4UQQghx2CReX4XefngDqACJ114/qGC1aZqjcr5du3axdu1aTjjhhGHv1dfXDwl2DVZQUEBnZ+eotGEsrN3XSWf48D2IAAijsXZfx0EFq+X3+9Fsat9Ed6L7sJ4zQoSN7RsPKlh9tP9+29rauO666zjvvPO48sorR3wcIYQQQoijmQSrhRBCCHHYOM5YhvnCi4d9ZrXjjGUHte+kSZNQFIXq6uqPdM5oNMqZZ57J17/+9WHvDZ5labUOvRRTFOVDB9zy8/Pp6uoask3TNILB4GGfsbt4Wj5v7Go/7DOrF0/LP6h9j8bf75FkQeEC1rasOewzqxcULjiofY/m329bWxtXX301J5xwAj/4wQ9GdAwhhBBCiPFAgtVCCCGEOGzsc+ce1AznsZKdnc3SpUt55JFH+NznPjcs720oFDqovLfHHXccL7zwAmVlZcMCWh+GzWZD198/8HvCCScQCoXYtm0bc+bMAWDNmjUYhsG8efNGfO6RmFXqO6gZzmPlaPz9HkmmZk87qBnOY+Vo/f32B6qPO+447rzzTlRVygoJIYQQ4tglV0JCCCGEEIN897vfxTAMrrjiCl544QVqa2upqqriT3/6E5/61KcO6hif+cxnCAaD/Pd//zdbtmyhvr6eN954g1tvvfVDBSfLyspYvXo1gUCAYDC4332mTp3Kaaedxu23386WLVvYsGEDP/jBD7jwwgspKio66HMdK4623y9Ac3MzO3fupLm5GV3X2blzJzt37iQSiRz0uY4VR9vvt62tjc997nOUlJRwyy230NXVRSAQOOz55oUQQgghjhQys1oIIYQQYpDy8nL+8Y9/8Jvf/Ib/+Z//ob29ndzcXI477ji+973vHdQxioqK+Otf/8rdd9/NtddeSzKZpLS0lNNOO+1DzZq85ZZbuOuuu/j73/9OUVERK1eu3O9+d999Nz/4wQ/4f//v/6GqKueccw633XbbQZ/nWHI0/n7vvfdennzyyczrSy+9FIA//elPLF68+KDPdyw42n6/b731FnV1ddTV1XH66acPeW/37t0HfS4hhBBCiPFCMY/mxHlCCCGEOCLF43FqamqYMmUKTqdzrJsjhBDjhoyvQgghhBjPJA2IEEIIIYQQQgghhBBCiDEnwWohhBBCCCGEEEIIIYQQY06C1UIIIYQQQgghhBBCCCHGnASrhRBCCCGEEEIIIYQQQow5CVYLIYQQ4pCROs5CCDG6ZFwVQgghxHg2omD1jh07RrsdQgghhBhHbDYbANFodIxbIoQQ40v/uNo/zgohhBBCjCfWkXzo8ssvp6KiggsvvJALL7yQyZMnj3KzhBBCCHE0s1gsZGdn097eDoDb7UZRlDFulRBCHL1M0yQajdLe3k52djYWi2WsmySEEEIIMeoUcwTryGbNmjXkhrOyspJLLrmE888/n6KiolFtoBBHspkzZwJQVlbGypUrx7g1Qojx6GgeZ0zTpLW1lZ6enrFuihDiAJqamgCwWq1yHX+UyM7Opri4WB4AiqPC0XwdI4Q4Osg4M/6MaGb12Wefzdtvv00sFgNg586d7Ny5k5/85CeceOKJXHTRRZx77rlkZ2ePZlvFOHfffffxi1/84oDve71e1q9ffxhbdPgYhsGjjz7KY489Rk1NDVarlblz5/KlL32JU045ZaybJ8S4cayOM8lkkt/+9rds2rSJzZs3Ew6HAVi0aBEPP/zwITuvoiiUlJRQWFhIKpU6ZOcR4kjx5z//mUceeeSA77vdbp544onD2KIP9u///u8AFBYW8tBDD43oGE1NTbz66qts2bKF1tZWuru7cTgcTJs2jUsuuYQlS5aMZpOPaTabTWZUH8OO1euY1tZW7r33XrZu3Up7ezu9vb1kZWUxdepULr74Yj796U/L34UQo+RYHWfe63vf+x5//etfM69///vfc/rpp49hi44tIwpW//KXvySZTLJ69WpWrlzJa6+9RltbG6Zpsn79etavX88PfvADTj31VC699FLOPfdcVFVqOQpxIN/61rd48sknh2xbvXo1a9as4a677uLSSy8dm4YJIcaFeDz+vhedh5rFYpGbSHFMiMViNDc3H/B9r9eL0+k8jC36YP3tVRRlxG175ZVX+OlPfzps+969e3nuuee49dZb+fznP/9RmimEOIY1NjYOe9AXCoXYtGkTmzZtYvfu3Xz/+98fo9YJIcab9evX8+ijj451M45pIwpWA9jtdpYtW8ayZcsA2LJlC3fddRcbN24EQNM0Vq1axapVq5g2bRq//vWvmTBhwui0Wox7p59+Ol/60peGbLNaR/y/6xHtlVdeyQSqCwsLufXWW2lvb+d///d/0TSNO+64g6VLl5Kfnz/GLRVifDmWxhlVVZk/fz4nnHACFouFP/7xj2PdJCHGvWNpjIF0IP6yyy5jyZIlaJrG73//ezZv3gzAPffcw5VXXonb7R7jVgoxfhxLY4zb7eaSSy5h8eLFFBcXk0gkeOyxx3jttdcAeOKJJ/jmN78pY4wQo+xYGmf6JZNJbr/9dkzTxOFwkEgkxrpJx6SP/H/Zzp07WbFiBc888wyBQABFUehPg221WkmlUuzbt48f/vCH/OY3v/nIDRbHhry8PE466aQDvr927VquvvpqAC677DIuvPBC/u///o+9e/dSUFDA1VdfPWwGTzKZ5MEHH+SZZ56hrq4O0zSZNGkSF110EZ///Oex2+1D9q+qquL3v/89a9euJRAI4PF4mDFjBjfccMN+U3M0NjZy55138vbbb2Oz2TjvvPP49re/jcPheN++Dn5i981vfpMLLrgAgOrqav72t78RjUZZsWIFX/jCF973OEKID+dYGmc8Hg+PPfYYAKtWrZJgtRCHwbE0xpxyyilceeWVQ1IAnnTSSSxduhRN04jFYuzbt4958+Z9wLcmhDhYx9IYM3v2bP73f/93yLaFCxeycOFCID1RLh6PS7BaiFF2LI0z/X75y19SXV3N0qVLSSaTrFu37qA+J0bXiILVjY2NPP300/zrX/+iuroaIBOgttlsnHXWWXzyk59kyZIlPPzww9x111288847o9dqIQbZsGEDK1asQNd1IJ038c477ySZTHL99dcD6QHxC1/4wrD/D3fv3s3u3btZtWoV999/f2ZgfOONN7jxxhuJx+OZfbu7u1m7di0LFy4cNij29vby6U9/mkAgkNn2t7/9jZycHL72ta8dsO2maWZWIwCccMIJmZ8XLFjA3/72NyC9DEWC1UKMnaN5nBFCHPmO9jFm7ty5w7bl5OTg8/no6uoCwOVyHezXIYQYZUf7GDOYaZp0d3fzl7/8JbNtxowZ5ObmHvQxhBCjbzyMM7t37+aPf/wjbrebO+64g1tvvXVkX4b4yEaUSHr58uX8/Oc/p7q6GtM0MU2T6dOn881vfpNVq1bx85//nNNOOw2LxcInPvEJAKLR6Kg2XIxvTz75JDNnzhzy3ze/+c397ltfX8/555/P7373uyFP7e67777MDdKDDz6YGRBLSkr46U9/ys9+9jNKS0sBeOedd3jwwQeBdL7JW265JTMgnnTSSfzf//0fv/71r7nmmmv2e7MVCoXwer3cd999/Od//mdme3+w+UCCwWCm0BkwJNXH4AuuxsbG9z2OEOLDO1bGGSHE2DjWx5j169dn2l5WVsbUqVNHdBwhxP4di2PM1772NWbNmsUpp5zCfffdB8CJJ56Y+VkIMbqOpXHGMAxuu+02UqkU//Vf/yVpjMfYiNOAmKZJVlYWF154IZ/85CcPuKzP6XRy4403jriBQnyQ0tJSfvKTn2CxWFi2bBlbtmxh48aNJJNJVq1axaWXXsrTTz+d2f+73/0uZ555JpDOf/blL38ZgGeeeYbrr7+et956i87OTgAmTJjAAw88kHmyd9ZZZx2wHT/72c+orKzknHPOyaw66O7upre3F6/Xu9/PxGKxIa9tNtt+f37vfkKIw+toHmeEEEe+8TbGNDQ08PWvfx1IF2687bbbpNi6EGNovI0xg1mt1sxMTiHE2Dnax5k//elPbNmyheOPP57Pfe5zH/n7EB/NiILVJ554Ip/85Cc577zzPnBJn81mk2C1+ND2l8j/QAUG58yZg8ViybyeN29eJrVG/4zk2trazPvz588fsm+//n1qamoy25YsWTIsZ9L+eDweKisrM68H52zsf7q3P+/9+0kmk5lcSqlU6oD7CSE+umNlnBFCjI1jdYypqqrimmuuoa2tDYBvf/vb73tTKYQYmWNxjPnqV7/KZz7zGTo6OnjyySd5/fXXWbt2Lddccw0vvfTSQeekFUIcnGNlnAkGg/z85z/HZrPxgx/8QB6wHwFGFKx+5JFHRrsdQgzxQYn834+iKIdk3/fj9/uHvB5cIbc/n/uBPufxeDKpQDo6OigrK8v83E+WoAgx+o6VcUYIMTaOxTFmx44dXHvttXR1daEoCrfffjuf/exnR6V9QoihjsUxpqKigoqKCgDOPfdcPvaxj9HY2EhbWxvvvPMOS5cuHZW2CiHSjpVxpre3N5O6+OKLL97vPl/84hfxer2sX79+FFoqPsiIHhc88sgjXH311dxyyy3D3rv55pu5+uqrJaAtDpvt27djGEbm9ebNmzM/9wd5J0+enNm2ZcuW/e7bv8+UKVMy295++22SyeRoNzlDURQWLFiQeb1p06bMz++++27m55H+AyGEGB1H8zgjhDjyjYcxZuPGjVx99dV0dXVhtVr5n//5HwlUC3GEONrHmMHF1Q4kFAod0jYIId7f0T7OiCPLiGZWP/HEE+zcuZNvfOMbw96bPXs2K1asIBwOywWqGLHOzs79PrGaN2/esOUfTU1N3HLLLVx00UWsWbMms9TEbrdz+umnA3DRRRexe/duAL7//e8TiURQFIW77747c5wLL7wQgFNPPZW8vDw6OztpbGzk2muv5bOf/SwOh4MNGzaQnZ3NddddN2p9/fSnP82qVasAuOuuu1AUhUAgwOOPPw6k8zddcsklo3Y+IUTasTTOADz//PMA7Ny5M7Otq6srs33atGlMmzZtVM8pxLHsWBpj1q9fzxe/+MXMrKSrr76asrKyIf2fOXOmpCsSYhQdS2PMv//7v+P1ejn11FMpKysjHA7z5JNPZlILKIrC7NmzR+18Qoi0Y2Wcyc7O5tZbbx22/ZFHHqG+vh6AT33qU8yaNWtUzic+2IiC1XV1dUD6ovO9pk+fPmQfIUZi1apVmQDuYK+88sqwlBhTp07lueeeY8WKFUO2//u//zu5ubkAfP7zn+f1119n/fr1NDU18d///d9D9l24cGGmYq3L5eLOO+/kxhtvJJlMsm7dOtatW5fZd7RzsJ999tlcdtllPPnkkwQCgSFtUxSF7373uwfMCyWEGLljaZwBhlTE7rdv377M9htvvJGvfvWro35eIY5Vx9IYs3r16kygGuD+++/n/vvvH7LPn/70JxYvXjyq5xXiWHYsjTGpVIrnn38+84D9va699tohMzaFEKPjWBlnPB5P5ryDvfLKK5lg9fLlyzNBd3HojSgNSH+13ZaWlmHv9W+TirzicJk3bx6///3vmTt3Lna7nbKyMr75zW9yww03ZPax2+088MAD3HTTTcycOROn04nD4WDGjBncdNNN3H///UOeDC5btox//OMffPzjH6e4uBibzUZ2djaLFi06JCk5fvzjH/Od73yHyspKHA4HHo+HU045hQceeIBLL7101M8nhPhwxsM4I4Q4cskYI4Q4lI72MebKK6/krLPOoqysDKfTic1mo6ioiLPPPptf//rX+13xLYQ4vI72cUYcWRRzBFWZLrzwQqqqqigtLeWPf/xjJpdMTU0N1113HU1NTUydOpVnnnlm1BssBMDatWu5+uqrAbjsssu46667xrhFQojxRsYZIcShJGOMEOJQkjFGCHGoyTgjDpURpQE566yzqKqqoqWlhYsvvjgz/b+xsRFN01AUhbPOOmtUGyqEEEIIIYQQQgghhBBi/BpRGpDrrruOkpISTNNE0zTq6uqoq6tD0zQAiouLufbaa0e1oUIIIYQQQgghhBBCCCHGrxEFq/1+P3/9618544wzUFUV0zQxTRNVVTnjjDP4y1/+QnZ29ig3VQghhBBCCCGEEEIIIcR4NaKc1YMFg0Hq6uoAmDRpEn6/f1QaJoQQQgghhBBCCCGEEOLYMaKZ1YP5/X7mzZvHvHnzJFAthBBCCDGKHnnkEc466yzmzp3LFVdcwZYtWw64byqV4he/+AXLly9n7ty5XHLJJaxateojHVMIIYQQQgghDqcRz6zu6uri8ccfZ9u2bYRCIQzDGHpgReGhhx4alUYKIYQQQhxrnn32WW6++WbuuOMO5s+fz0MPPcTzzz/P888/T15e3rD9//d//5cVK1bwwx/+kIqKCt544w3uuusuHn30UWbPnj2iYwohhBBCCCHE4TSiYHVTUxOf+tSn6Ozs3O/7pmmiKAo7d+78yA0czzZt2oRpmthstrFuihBHjVQqhaIonHDCCWPdlCOejDFCjMyRMs5cccUVzJ07l+985zsAGIbBsmXL+NznPsf1118/bP+lS5dyww038NnPfjaz7atf/SoOh4O77757RMf8IDLOCPHhHSljzNFAxhghPjwZYz4cGWeE+PAO9TgzojQgv/jFL+jo6MgUVhz8nzh44+17M02TZDI5LvoznvoC46s/4+lv5lCTMebINZ76AuOzP2Pdl2Qyyfbt21myZElmm6qqLFmyhE2bNu33M6lUCrvdPmSbw+Fg48aNIz7mBxlP48x4/P94vPRnPPUFjowx5mgxnsYYGF//L4+nvsD46s94+ps5HMbTODOe/j+G8dWf8dQXOPTjjHUkH1q7di2KovD5z3+eBx54AEVR+OlPf4ppmvz4xz9m8uTJ/PCHPxztto47NpuNZDLJtGnTcLvdY92cjywajbJz585x0Z/x1BcYX/3ZsmULiqKMdTOOCjLGHLnGU19g/PXnSBhnuru70XV9WGqOvLw8qqur9/uZpUuX8uCDD7Jw4UImTpzI6tWreemll9B1fcTH/CD940xZWRkul2tExzhSxGIxamtrx0VfYHz1Zzz1BWDv3r2o6kcuHXRMkGuZI9d46guMr/4cCdcxR5PxNM6Mp/+PYXz1Zzz1BQ79ODOiYHV7ezsAp556Kg888AAARUVFnHjiicTjcW677Tb+9re/8c1vfnP0WiqEEEIIIQ7o29/+Nrfddhvnn38+iqJQXl7O5ZdfzhNPPHHIz11bW3vIz3G4jKe+wPjqz3jqy3tXQQghhBBCiLQRBavtdjuxWAyn04nT6SSRSNDU1MSJJ56I3+/HNE3+9a9/SbBaCCGEEGIEcnJysFgsw+qDdHZ2kp+fv9/P5Obm8qtf/YpEIkFPTw+FhYXcfffdlJeXj/iYB2vy5MlH/YzX/tm746EvML76M576AumZ1UIIIYQQYv9GFKzOyckhFosRiUQoKSmhpqaGu+++m127dvHiiy8C6byJQgghhBDiw7Pb7Rx33HGsXr2a5cuXA+liiKtXr+aqq6563886HA6KiopIpVK8+OKLnH/++R/5mB/E5XKNiyWNML76AuOrP+OlL7I8XwghhBDiwEYUrJ4+fTrNzc20t7dzxhlnUFNTQyAQyKQEURSFRYsWjWpDhRDHnrgWpzpYRVJPMsFbTp4z74M/JIQQI2D09pLc9C62OceNdVMyrrnmGm655RbmzJnDvHnzeOihh4jFYlx++eUA3HzzzRQVFXHTTTcBsHnzZtra2qisrKStrY377rsPwzC47rrrDvqYQoj3p3d1kdq6FdvcuVhyc8e6OUIIQXN3lKbuGHMnZOO0W8a6OUKII0xtIExnOMn8idlYLUdHzYwRBas/+clPUlRURE5ODl/+8pdZs2YNO3fuzLw/c+ZMbr/99lFrpBDi2JIyUrzZ+Aa7u3ehm3pme54zj1nmbCyKXIQJIUaPaZpE/vQwWl09qc2bYdnpY90kAC644AK6urq49957CQQCVFZW8oc//CGTsqOlpWVIkbZEIsE999xDQ0MDbrebZcuW8ZOf/ASfz3fQxxRCvL/oo39Dq60jtW073q/8+1g3RwhxjIundB5dXUdSMwhGUyyfUzzWTRJCHEFCsRSPra3HMEw0w2Dx1IO/5jeCQRLr3sE2aybWvrSCh8uIgtXLly/PLB8FeOKJJ9i4cSNtbW2UlpYyf/58qXAthBixNxvfYEfX9mHbO+OdaKaGRZVgtRBi9OhNTWh19ekX1hFdGh0yV1111QFTdDz88MNDXi9atIhnn332Ix1TCHFgZiKRGSv0xkZM05SUHkKIMdXcHSOpGQC09MTGuDVCiCNNWzCOYZgAtHR/uDEi+uSTpHbsIvHWW/i//S0Um+1QNHG/PvQdWSwW40tf+hIAV1xxBRdffDGqqnLSSSeNeuOEEMeevd17M4Fqi2JlTv4cvHYf9aE6FMAWPnwDpBBi/Im//jqpLVtxXXQh1ilTAEi+807mffuCE8aqaUKII5ze0gJm+obP1A3McBjF6x3jVgkhxhPTNEmuX4/qzsJ23Oxh76HrKIMerDd3RzM/h2IpTF1HCCH6hWID9QSD0fevLdgVTrCjKcjE/CzKfXa0vfsAMKMxUrt3Y58z55C2dbAPHax2uVxs3bqVeDzOl7/85UPRJiHEMchMpaiLNvJaw6uZbcsmLKMyL32RNr9gPgBbtmwZk/YJIY5+qe07iD3zHADRp/6J72v/hZlMkty0GROI2J345s2DvXvHtqFCiCOS3twy5LURDKJKsFoIMYqS69cT/fsTAHj/40asEyYAYMRihO/7BUYkQu85F5GYNpMpXguNTZ2Zz3Zv30XXqw9hXn4ZisMxJu0XQhxZBgerB/88mKlpGO0BVuyN0hqMw+4AJWacpSmV/uocqc1bjuxgNcDxxx/PmjVraG5uHu32CCGOIZFUhE3tGwm21BJc8yZtzgSWslIsRcVMz53JrNzKsW6iEGKcMGIxok8+mXmtt7Sid3Wh19RixuO8qRawOX8GJ+zqYqJkGhJC7Ife1DTktdEThL5AkhBCjIbU9oFUiKmduzLB6tSWLegdnfRg46/Pbkb313F6sIo6ctGnTkf1+dADHYQ1BZIpkGC1EOOWbphY1A9OQ2b09NDT2pF5HUloaLoxpMiiaZqE/3g/yapqmiYsxTI5vfK0oamDFdYyrtZqUIHUzp2YySSK3T7q/dmfESWWvvXWW/H7/dxzzz2sXr16tNskhDgGBKIB/r7nb2xu38Se7atotUYxNR2troHc17cw/zcr6b37p+gdHR98MCGE+ADxp5/BCPUO2Zbato3EunVEsPCuJQdLQQFtQcn3KITYP+09wWozGByjlgghxiNT19GqqjOv9drazM/avioAdqk+UigYwSBryCWOitHZiRmJANCr2MAi9cOEGGt6IIA26G94tNR3Rvj587t4aFU1qb589fuj1dcT+unPCLz8OkawJ7M9+J7Z1alN76JVVRPBitYewEwmATBDIUKKjRbFlX6dTJHavXvU+3MgI5pZfcMNN2AYBh0dHXzhC1/A4XCQm5s7pMCIoii8/PLLo9ZQIcT40RJpYcW+p9BMDb2tHTMWB8Clqyzs9FMRdqGgoAc6iPz5Ebw3fmVIbjYhhPgwjGCQxDvrAVBsVsyUBkDitdcxwhF2qTngcqF4vUwt8kIq+n6HE0Icg0xNw2hrG7LNGBSsNk0Tva4OIxxGUVQsUyajut2Hu5lCiCNcVzjB6n0dTC30MKvUP+Q9vaEBM5HMvNbq6zENAxQFbd8+TGCP1Q+mApjE++YeGuEwSlYWAL3YcFtkiZgQYylVVU3kD3/A1A2yrr5qVNNnrKvqJKkZtPTEWFvVwdKZhcP2MWMxen/xKwB6rVaMrm5UfzYAoWgK91uvkdqxE8fJi4m/9np6u2ID08QIdJA1sZREOAxAtdVHWSo9mSe1eQv2uXNHrS/vZ0TRn6amJhRFyQSn4/E4LS0DOdykMrYQ4kBM0+SNxlVopoapaeRWB1jaVIjVUMm77JMYe6swurowursxwhH05haijz+OpaQExe2WJW1CiPeld3VDPI6ltCSzbfAsgNSS06jbXkV2sJpGawtTLVlsV7KxlJWhAPPKs2msbtvPkYUQxzK9rR1THzqDyejpyfyceO01Ys+9kHmt+n34vvH1w7ZcdqQeeeQR/vjHPxIIBJg1axa333478+bN2+++qVSK3/72tzz11FO0tbUxZcoUvv71r3P66adn9vntb3/Liy++SHV1NU6nkxNOOIGvf/3rVFRUHK4uCXFEe21nO3taQmyt7+H84w3mT8wBIBLXeHrVHjxqPqcYHRgovKrlkPX6Ds6Ymo0RidKuOAllF2Arm4CZjGO0tacfmmkaRmc6d3VIsZIlk3yEGDNGNEr00Ucz1wypLVtHNVjdHoxnft5Q08WpMwqGxF9N0yT65FMA6EBEsaIkBx6CdXeFyH7lVXQU9Cf/mdkewpb+TKCd42fksco0MYGa4qmc3tlLKhpD2bkTU9MOy0TCEZ/B7KuEfaDXQgixP03hRgKxdtB0fDsbOLcuG6upYF9wPK5Fi2HRYiBdxKj3F7/A1HSSG98F3gXAvOITKE7nmLVfCHHk0tvb6b3vF5iJJO5PXIZjcXo80Xalg9VtioNnI7n0epIEvduYoPSy22UQjPqx5eVRnucm1+OgcSw7IYQ4IunNTcO2GaGBmdWpXUOXxhrBEHpTE9YpUw5520bq2Wef5c477+SOO+5g/vz5PPTQQ1x77bU8//zz5OXlDdv/nnvuYcWKFfzwhz+koqKCN954gxtvvJFHH32U2bPTBbHXrVvHZz/7WebOnYuu6/zsZz/j2muv5ZlnnsEtM82FYG9rKPPz85ubcdstTC/2saG2iz0tQQxLLlPMMJ2Kgx2qH+ueNhJtbZwB7FG8qH4/apYbstwQi2dWeJjxdAAr7HCDKmlAhBgLZiJB9LHHMIIDf+daff2onsPnsmUKJcaSOo1dUQr3bUNxOrHPn49eV0fy3c0ARLBiAkpqIPVHT2eQpy2lVKsefGaKCWaURUYX4dwCCKX7kP3uO0w0ktSpWYQ92bxiOY4dTUHKjQhXdXVhLRw+m3u0jShYvWvXrtFuhxBiHEjoCZrDTVhVK26rm1xn3rBVFhvaNmAmU2h79jCn2o7VtKO4nLjOO2/IfpbSElyXXEz0H09ltimqgiIXX0KIQQav5oqvXJlZPhtb8S8skybR6IjS3rKJLMXLv5xTMB0uevO66Qmq2E0HcTfk5xcTNutpszSwObAYBVkdJoQY6r3FFQGM7p6Bn7u6hn+mowPrlCkYsRiK1Ypisx3KJn5oDzzwAFdeeSWf+MQnALjjjjt47bXXeOKJJ7j++uuH7f/Pf/6TG264gWXLlgHwmc98htWrV3P//fdz9913A/DHP/5xyGfuuusuTjnlFLZv387ChQsPcY+EOLLFkhqD5/iZJjyzqZmvfMxDdzCC0Ztedh+we2jV0qEaI9zLtpBBheJmj+pF9flQVYXpRV52htIBMZepE1PSqT+i/vzD2ykhBKZhEH9lJYk338ykOO1ndHVjhMOj9hApltSHvF6/6l3OWP0vANTs7CHB8ZCSvu4wE4nMtqrmIM2qJ/P+DsWPVjENd0khrE4XeHW3NTNVdVJHFqrPx85oFIMgdWoWLU0dlB+pwWohhBgsuW07wc3reX56lJBdy2yf4pvC+VMuBKA92k5zuJm66o3o9fV4YjAp4kdxu/Bcdy1qdvaw49oXL0axO9A7AljyC7BMngSNMudRCJHWk+jh2eqnURSVS/LOINU3i8DEZJ8jyJbnfkh0SjG9/k4Cdje5Zg4qCUKORrBaadecKA47Hl+SbmULxXYX2zu2MYfDk4tNCHF00Lu6hxQ9U3OyMbp7MEOh9OpSTRsyi6qf0Z4urhT+3e9R3G68//FVVJ/vcDb9gJLJJNu3b+dLX/pSZpuqqixZsoRNmzbt9zOpVAr7e9KaOBwONm7ceMDz9PamC9v6/f4D7iPE0aymPUxDV5QTp+SS5RgaXokmNNyDtgVCifd+nHhKpzOcoHtfHf2R7OCk6QQb2kADIxQCw+Ap6wQUux2by0VFoYdFU/PY1dgNKEwxw+xRfGgo9HqyD2V3hRD7kdq+nfhLAzX7FIuKZcIEtLp04Fivb4DJkw7qWJ3hBJtqu/G5bJTnuSn2O4dMAIwktSH776wJsAgLbnS0mhqMQEfmvbA1nULV1DRMw0BRVdoHFZO3TpqE4vXQ6vdR6HOg2O2YySQ+UrgNDUveTBSbbUhKs31N3ZSf8CG+nBEaUbD6nXfeOaj95Om5EONTfaie1kgL8wvmY4sk6H70zzxX2Ep3QsE+fx70FfWoCdWwoW09gViAfVVr0ZqaM08a5/ZkY/X58Fx3LZbi4v2eR1EUGidMZ4dSSENnBEtPJ4tyTSwWmfUoxLHOMA1eqnuR7kQ3AFve+gezDBNNMXi7KEiVOwoJSO2LUKtmoWX14HTE8HiqyFettBvZkEqBw06PspOSXCuqqpDnyoPU+59bCHHsiL30MolXXsE00kEkNTcHS1FROlitGzQ3dfDGzjbKVR+zjRDWyZPQausA0AMBzI2bMDUdM9RL4q23cJ1//lh2J6O7uxtd14el+8jLy6O6unq/n1m6dCkPPvggCxcuZOLEiaxevZqXXnoJXdf3u79hGPz4xz9mwYIFzJgx4yO1NxaLffBOR4H+foyH/oynvsDI+hNL6jy6ugZdNwmGo5w9e2C24cvb29nSEOSkKTmcPjM927khEETT0oEmj9NKOK5hRiI03PcbOiMujL5ZkO1ZOXRkJTG6Q5AcuChRPR4MXaOyyEWOE5ZMz6N+u8GCrnYa7U56FDtBq0NqiAlxmOkNAxPq7PPm4vzYcvT2drSHHwFAq687qGC1phs8tqaOYHTg735WqY9LTyoHwDBMEqmBf3NNIBUMUaV6mGsE0VtbMToHVnpFSydBc9+YlkyC04k5KH91ltdNPMtDQjNoCcaxTp+OLdCGv7Ic66SJVHTYqe+Mog6qG7avLcKZH+7rGZERBas/97nPfeDgpygKO3bsGFGjhBBHrlAyxDM1/8IwDRrDjXxst52X89vpsmuQBGdTJzNPPIctgc2YmKxtXYNWV4/e0po5hj9lpXL6KXgvugTV4zngud6t6+b5zc1DtqWyTaTAtRBifet62iNtoICZTNFQt4tpSg7PTewmOHcKyq5dGIZJWywHzZG+KIvk7aU0x49fcZFKQU80jsdpZUKuibNvxsC07GlEQtGx7JoQ4ghhplJDAtWKzYrrYx9Dq6vL7PPSu400d0WpshQxw+jFOWUyelMTZkrDCAQw+2YWAyTWrMV59tmHvR+j5dvf/ja33XYb559/PoqiUF5ezuWXX84TTzyx3/3vuOMO9u7dy1/+8pePfO7a2tqPfIwjyXjqzxHfl2QSPkSh0w/Tn9ZejY7O9ESc7ckQpUq6yKFpmry5LYJuwutbesjX20mZSV5tqqWz0YqzsYcSt0ZTTjnWpmaaetvpdE/AxMB0ONkV0VFRsSQTeI0EGipx1coED8woSBDvqGdnB3iABY5ujJ52rB4/nYVxIrYWzkqeg9vp+jDfkhDHDNM0Sa5bR2rXbpzLl2MtK/3Ix9Tb2zM/Oy+4AEtuzpA6W3p9AweTBGT1vg6627rQW1qwFBSi5mSzqzmEphtYLSqxlJ5JJZTltBLuCoGmUaV4mUsQvaU1U/xZzfYT8WQD6WC1RUti4EyPiYCddIHXtZ3p4Lemm6geD3ll+biWTQXggglJ1td0MVlx8+KuLQQUB629CcLxQz+zZ9QKLAohjg3bO7ZhmOnKts3BBh5r2EbQmR7wnLrK8ndiTFg8A0uhhY3tGzCjMfTWVmymwvwuL4UFk5h47iW4Z8zCNE2q28P4XDbyvY4h56lpD/PClpbMa6tFYWqhF7tleE5IIcSxZXd7Ew+sfxFVgfI8N66WRlrtcfZ6I3SXZ2P1eXHNmk3Fm0F6I9NIFtSg+3uZWuJHVdMP2z8zfzk7O/fQnQxkjmtVrEz0TWInO8eqa0KII4jR0ZEJVFsrppD1uatQs7IyN4JRLDR3htO1OFAIYcOXn4+an5++YezsHJKj0ozFSW7cCEdAocGcnBwsFgudnZ1Dtnd2dpKfv/+ct7m5ufzqV78ikUjQ09NDYWEhd999N+Xl5cP2/f73v89rr73Gn//8Z4oPsILuw5g8eTIu19EffIvFYtTW1o6L/hwNfUm+spLUq69hW7QQ+yUXv+++I+lPtLabnK70knun00plZbqgam88ha++NrPfxKlTWBd4nfZAFXFHGK9lOnPC7dQnHGCxEvUWYPflopaWovj9KIqC6fdjmCZztQ4WT/RinTYVx7y5wyYNpsIRki2t5NgVokWdqJ48DNX4EN/SofXII4/wxz/+kUAgwKxZs7j99tuZN2/efvdNpVL89re/5amnnqKtrY0pU6bw9a9/ndNPP32/+//ud7/jpz/9KVdffTXf/va3D2U3xDhhmiaxfz1N4s230q+jUbw3fPkjH9foC1YrdhtqTjZAuhhqth+jJ4jW0AAvvYz73U0YBQUwceKwY/REkqzZ24FWVQWJBJ7eLiInnowCJLS+YPWgfNVTCjzUNDbSBTSobuK6irO1LZNOyFJYSK9tYCwrVjWaST+IBygxYpSW5kBnB4Nluwce7mVn2Vk+pxgzFmOyESFgcUAiQVV7+JBX+BlRsPqyyy4btq27u5uNGzcSCoWYNGkSCxYs+MiNE0IcWXRDZ0fnwIoJo62NoJLOvWa12vhYUza+hJXe+37B3PlzaZySRVPDHhy6wsda8ik//QJcH1ue+fy7dd28sKUFi6rw2VOnUOx3sqmuiz0tvTR2RTMPxU6qyOOMykKsFpUtW7oPb6eFEEcU0zR5YuvbaHr6Rqy6KUxuZy+FismmgiitrlJS7RFuOOnfaFbDKC9tILdzIp6pAawWhTxnPkvLljLBW05CT7ChfSBYPck3GZt6ZBVAE0KMHb1j4AbONm0aalYWAEpf/uV6JQszmcKMp2dW9ig2JubkYikoQG9pxTRMIkqS18q6cKUsTAiUk/X6ejh//4GXw8lut3PcccexevVqli9PX5sZhsHq1au56qqr3vezDoeDoqIiUqkUL774IucPSm1imiY/+MEPeOmll3j44Yf3G8geCZfLhfsICPKPlvHUnyO5L4k33sRqtWJu3ITzwgtQvd4P/Ex/f7SaGrBasb7P/8PBRDdWazqkktDB6XShqgod0UhmO0BEU+nRukkkdTQlgseSpFDXMw/QA9mlOGbMRhm8fNRqhcpKKhaUUTgh+4Bt0KdPJ2S1orgjKDYrqqLCEVIo+tlnn+XOO+/kjjvuYP78+Tz00ENce+21PP/888NSEAHcc889rFixgh/+8IdUVFTwxhtvcOONN/Loo48ye/bsIftu2bKFRx99lJkzZx6u7ohxILZiBYm3Vmdea7V1GLEY6gEeUGl1dcRW/Avb7Nk4zz5rv/uYqRR6X+oNS0HBkAdK1vJykj1BzEQS7fVVWHu6Sb319pBgdWL9BqJr1vL0hJNIxUzMRIIT9G6ihoWavpUh8ZROlsNKdFC+arfdQkUsQBfpdCA1iodKc6B+hlpYSDiWnhBoxaTQjKeD1X0zqyeoCYqLcmDr0GC13z38XkhxuaiwJ3lHT39+X2sv053DdhtVIwpW33nnnfvdHg6Hufbaa9m+fTvf//73P1LDhBBjL6HF0U0Dty19AVoV3EdcTy8jsWEl2dqX2kOBc5ZdR9E/3kRPdGEmU6Te2ciy9Qb1WQrFsSK83lycZywbcvxNdenAs26YPPNuEyXZLrY19AzZZ1qxl7NmF2Uu5oQQ45dpmrSH4uR5HFhUBb2mltSe3cRKy3kt4SPXY6fQ66C+t7bvEyr+Zj/tznacaKjFRXRENGx4qGtx0GkD+/HzIZHk6tNmYnUkyXXm9t3IwQTvBDa0r8+cf2r2tMPfaSHEEcc0Td7YHWD7O60krVNwovMxVzYVfe+r2elgdZ3qxkwkMjd+QcWOmpuLWjAwM3m3L0KdU6fJZcebyMIdcnNJSsNqH/sHY9dccw233HILc+bMYd68eTz00EPEYjEuv/xyAG6++WaKioq46aabANi8eTNtbW1UVlbS1tbGfffdh2EYXHfddZlj3nHHHTz99NP86le/Iisri0Ag/UDQ6/XidB7iO1shBjGNobOLU1u24jh1Sfq9eJzkho0YwSAA1pkzoWRgBUBq3z7Cv/sDKAqeL16HbdrU/Z6jPRhHq63FCAaxVlQQTmj4XDa6o8kh+3X0JuiJh9Hj6Uk+HkuY7MIcCKqoHg/RGdOHBqoHKfAO/7vZ17OXnngPxxeegKWkGNvsSrSO7Siu9D2bwpGRM/GBBx7gyiuv5BOf+ASQHh9ee+01nnjiCa6//vph+//zn//khhtuYNmy9D3jZz7zGVavXs3999/P3XffndkvEonwjW98gx/+8If8+te/PjydEUc9Ixol8faaoRtNE62qCvucOfv9TPzVV9EaGtEaGrHNOQ5LUdHw43Z0ZGYzq0WFQ96zTJoIW7cNPWXXwEpxMx4n+I8n+RclNAZ2YcnNxW3qLDY6eduSjxmLodjtJFLp8WzwzGqnTaW4rYb1pNtUpXqo1AcHqwsI1afHAj2rnWYjhGEWDASr3So+lw23w0o0MRAEz95PsBqgxO/C1akTSySpDUSYPjrPog9oxGlA9sfj8fDxj3+czZs383//9388+uijo3l4IcRh1BXv4sm9/yBlJLl46scp85SxrWNgoF2emsbq3vW0OWGRdy6zpi/B+PJxxF99leTGTZjxBDZTZWo4fdHkPOccFNvAwNcVTtAejGded/Ym6OwdqJDtc9mYWerjtJmFEqgWYpzpjndTG6phevYMPPaBvPWv7mhjXVUnpcT5+PaXMLp7AHjBVkbtgtNQbDbiZid6X+61SfhJdNhgAnRas7A6vBDX8Cjl7G3tJZbUUSxWXNkOivzeYUtni7NKsCgWdFPHoliZ7Jt8uL4CIcQR7M09Ad7eEyAVivcVPLPxZtA6EKz2+zHpn1mdzMysDqp21Gw/loKBm9W9DoUqxYOSlYWtN4w/nnPEFD674IIL6Orq4t577yUQCFBZWckf/vCHTBqQlpYW1EFpTBKJBPfccw8NDQ243W6WLVvGT37yE3w+X2afv/71r0C6xtFgd955ZyYILsThYEYiQ14nt2zBceoSjFiM8G9/h948kG5QefNNrDd+JfNa272n7yAm8ZdfGhKsTryzHqOzA9sZZxJo6UBva0t/pqqKYO9sfC4bPZGhweq2UIRQPJ4JErmsEbyfvIbc3XHCCf2A86AVRSHXMzTfdle8ixdrX8DERDM0Ti49Bc/n/x/mu4+i1Pa3+2Cy4x5ayWSS7du386UvfSmzTVVVlixZwqZNm/b7mVQqhf09+cUdDgcbN24csu373/8+y5YtY8mSJRKsFgfN7AkOBJX9PoxgOrCr7dk7JFg9uECp0TGQKiu5aROu884bdtzB+aothUOD2dZJ+ymqOKjAYWrPHl42C2hUXaBpqO1tXKA3Y8fAYRqYsRj4/SS0dJA6mtAwDQOjowNrcB9F8SBuaz5Rm4N6LYukrmAn3cdUbgFac5iUNU4orw6wETTz8WkaVkyKs10oikKR30lNezjTJp9r/zn+Lbk5TOvoYquZTSqRgIPKwj1yoxasNk2TQCDAiy++CMDOnWOf7/HD5Ef63Oc+x7p164ZtX7ZsGb/73e+AdB/vvfde/v73vxMKhViwYAHf+973mDx58qHshhCHnWEavFL/cmYW9ZtNb3Ba2Wm0RNLFDnMcuRS8U8t5zfmkVJO869I3H6rfj/vSS3Gdfz7JDRuJv/46RncP1oop2BecMOQcu1pC7I+iwMdPnMCsUv8h7KEQYqwEogGe3PcEKSNFU28jF029BEj/G7u9MYgJ1G7dSzQYwgnEUanCjRIMYsnPJ0J6HHLbFM7Z2cAarYL2lIOY34kST88K8DCR7kE3imW57v0Gh6yqleMLT+Dd9k2cWHQiNsvYz3QUQoytd+u6eWt3X3qgeByF9PLabnPgtkn1+2lXnMQUC2oyiZlIP2wPuf0oqpqZWZ1EZZvTBmgobheOGV7+39zz6AwFOFJcddVVB0z78fDDDw95vWjRIp599tn3Pd7u3btHrW1CfBRGqHfIa62mFr29nejfHx8SqAYwNR191y7oS/Gjtwy8r1XXotXWYp08mdTevUT//jgAgWCcVPvAuGAmEnSu30z5BacNuQYBaA0FiRtaJljtcKawTJyIv6GWSCI2tC2mQS/1WHAwyTsZq2VoQKixtwGzLxi1s2sHC0sWoaISNvrSEODkSCgv1t3dja7rw9J95OXlUV1dvd/PLF26lAcffJCFCxcyceJEVq9ezUsvvYSuD8wmfeaZZ9ixYwePP/74qLc5Fot98E5HuP4+jIe+wOj2R+/oQNPS9wq2mTPQ172DqekY27djnnsOiqKQWrOG1IsvY11yMrazzybZ0YHZ95nouncwTjtt2D1Fsr6BhKazyZKLPebg5Egks4+Zn49yyskYbW3ofTHSZG8v0Wi6mHts4yb2koVhmNgxuDhZR6EZRwMsliRaJIKpaQR7o0SzVLp7o6RaWtDrGyDVgGFoTCbIjqJZJFvbqDacTDPSY1+76kAjTMzZi9XUsSR1go5q3GYJZXoc0+UlGo2S61LZqw3MrHYoGjvbdrKtcwuzciqZ6k+vPNVcLhYnWnFakkwst6Kb+iF9+D6iYHVlZeX7vq8oCrm5uSNq0Gj5sPmR7rvvPlKpgYqWPT09fPzjH+e8QU9Ofv/73/Pwww9z1113MWHCBH7+859z7bXX8uyzz+JwOIYdU4ij1ebAu7RH2zKvO2IBnqt5FjOewEzEmVt2Atrep1FRcGXnYp06dGmc4nDgWHIK9sWLMDo6UPPyUNShF1q7mgeC1fMn5bC5LyXIufNKJVAtxDgVSoZ4unoFie5OjI4O6kvipKaksKk2gtEUkYSGGQphRqN0KXbKXAq74w50FNRgEFtBPhGjGRQoinQxocPKHIJUW0oIO9IXfQ4lF7viGXLe8twD59I8ueQUFhUvzqQGEUIcuzp6E0OKOy+NN7HPtNHi8BPTIZHScdgsKHY7dc4c0CBsNtFVUktWJI8c0rlTLQUFALxlzSFqDYHFgs/tYFKhlfwJOXTuOHKC1UKMV2bv8IkxvT+/FzOVDsqoniyc53yM6D+eAkDfvQcWLUz/3NJCo+JCxaTUjBN/9TU813ye+CsrM8dq2bIL3VI65Pid72zCPHsRPdHUkO3t4RAxIwZ9BVvtJVkoanoJfnP30CBcTG0ioG8AYKrTx3u1RlozP0e1KPWhevwOPyg6NquKXc9FPUJWb3xY3/72t7nttts4//zzURSF8vJyLr/8cp544gkgvdrjRz/6Effff/8hib/U1taO+jHHynjqC4xOf2x79uDqSccc4qEQVqcTa2Mj9HQTXrMGw+/H+48nUaJRzH89TTgnF++gWdP0dBN55RX0srIhx3Vt2cLGhJvtTj+p+jChNduYmD0o1DqxHCaW49m1CxUItbbStHMn6DrWteuJu9Px1aJUEGe4hZ6+j6XsFqJdXWh+P3v2xdC7bexrShBpb0dNJkiGuujRI+S7VXqdx2NLpdicsJEf6Sbu8vDE2mp6EyYRexhvKg7JBKozm15HCxXNQZp7JxHfuZNIUKO7Z2DF+7v7GtkYTU/k3dO8h3Ozz0NRVOyhEM6eTqbTSbRmB9rUqcNWQoymEQWrzYN4VPeFL3xhJIceNR82P1J2dvaQ18888wxOpzMTrDZNkz/96U/ccMMNmSIkP/nJT1iyZAkvv/wyF1544aHtkBCHmGma7OvZx76evdSGaoa9H4v0kNq6jdyohbKXB9J1OBYtOuATNcVi2W9ep8EpQEqyXZw3r4SphR6cdgsT87JGqUdCiCOJaZo8X/Mc0Xgv2p49mLqBGY3SNreVUrKpeWszZsKF3pcLv1txMO2ic9j+zw1ggN7bzWnzDeJ1Bta4wuSaEC6jgNmuBKsKFxNhLQA+ZXh17QnvE6wGJFAthABg5fbWzH3OgjIPx7/ZSsBSTGtfruWeaJIif7oIU4M7D0JJgt4mFEuKkK+NnvgcYkmNTfW9VGdNYSfpWZSqzZp+aKZAc6Rl/ycXQhy05Nat6I2NOM84A+UAhdGM3t5h2/oD1YrLSda112IpLSG+8lWMniBGTQ2ccDxmb5j6sM4/rOmErAv0bk7duYvYSy+jVQ/cIwV0K9A/GzG9BiMU10i8+RY9yaFB7FgqRjASzbxWStKFHn37yQ3r8Ybpj1Z1mTswzYVD7rVao61D9t/VtZPJvskoCkwt9DDBMQ3nEZCzOicnB4vFQmdn55DtnZ2dmVRD75Wbm8uvfvUrEokEPT09FBYWcvfdd2cKtW7fvp3Ozs4hKYV0Xeedd97hkUceYevWrVgOkPv7YEyePBnXAf5/OlrEYjFqa2vHRV9gdPuT6uommZ0DgGP2bMzSUpIvvgxAoapiKSoiancQsWeRhUax202ib/9++b1hHO+ZvLvnxTfZ6yvCoSi4Cwux+LKprByauxqgt7iYUCiEz26nbNYsjKpqGtw+7HYHSpab/FCUbGsOqAqKw0Fuwo5DNfBmZ1Nclk/llBxqU6202Bow7A4KfR6Kr76O4rJSNq1tJdTRQXvYitPWw6rieVhdfnJcoJspCpMGKjYq/Vay/DXMCebhmFWJrbKS0liKbT21AJjWHuqdVeQ4sjPtLp1aRrYjGy2Zor52K6tKuinxNFJhPbTFTUcUrC4tLR22TVEUvF4vEydO5FOf+hSnnnrqR27cSI0kP9J7PfHEE1x44YWZysaNjY0EAgGWLFmS2cfr9TJ//nw2bdokwWpxVDNMg9caXmVn144h2+cXHE9zuJlArB2trh5TNzi5Iw8lkZ4toKgK9pNO/FDniiQ0Xtk+cJE1q9SHoijMKBk+c0AIMT6Ypkk4FSYQa0fv7AQ9XSTEiETZ17AT3+s11NZHSFpzM7OOgll+OqfMpMtXRzxeT7hwDxua2sjzutC625gUTl+w5lxwLifZy0jUxzHQOaFwHr1xnfZQ+oGYRU3nYhNCjA9GOIzq8Xzwjh8gltTQdBOvKx0sqm4PU90exgR8NoXTckzigN9MojidhMxaHt+7nsUTZjM7dz7tOSUYvdUo9ghuUyek2Ei4EzyzqZl9bb2knHkkjfRS92KvHbst/VCsOdyEF7nmEWKkjJ4eoo/8BdMwMZMp3B+/hOSGjaS2b8e5fDmW0hIAzOD+Uw5aKybj/sQnMisgbLMrSby9BlPTsdY3YLjcNCvpawzFZmMjOfQqVs596eUhGVo7lIGZvdbJk9Dq6ujFRvDN1cSOvwQz1Ive3o6luBjdk0BPpB9e+cwU8b6H6H7X0GC1025BcQ7MtE7QRUNvAxN96Qfx4WSY3uTQftUEa4Z8/tSKaXTVdDHW7HY7xx13HKtXr85M9jMMg9WrVx8w9VA/h8NBUVERqVSKF198kfPPPx+Ak08+mX/9619D9r311lupqKjgi1/84kcKVAO4XK5M/OdoN576Ah+uP6ZpEn/5FcyeHlwXX4TS98A5pqUwrOkQqCs/H6W8HGPlawBY6uqx+/ystJewyZLDdKOXSxsb0K1DQ6bK7t24bLZMLa5YIsXKiBtVVVDcbmw2Gx1Rfb9tjXvTD6ksqgW3qhKrriJudaKqCtYJE8hVvVi3deBcdjp6UxNtgd00FmzETS+9xrm43WVoWFA0DVVV8HmceOen0xzPnZhizd4sUvEQT1nKCTqzsVqtOOwGDj2BpTM9eqmxOGGnTkN2ijkF+Tjcblwukzyfm2A0Sdi9A8WiYB0UKo4pUUrdpWglxWwsChO3QX2ymYpDvIBjRMHqlStXfvBOY2gk+ZEG27JlC3v27OFHP/pRZlt/Jev9HbOjo+MjtVfyCR15xlNfIN2PhJFgTdMaJmaXU5o1sHRFN3ReaXyZunBtZpvT4mK6fzrz/PMpsBbwXOPf0Lu6mBpykRtR0fpmEVhnVxK3WiEaHXK+1mCc7U0hZpV4KcsZeALa0hPnqY3NmSq2FlVhYo4tk7PpYAwueCCEOHKZpkli5askN2/G6O6m2RHDWOxGb2tjUsRJbVacZsVF1bp1BBod7PGm0GMJLKQv/nonT2d7cy+qz0fQ0UYuCYxgCIvLhT2aYkokPbbYZs5kkepkd8sMdMNk8fQC6joimWB1aY5rWL5HIcTRKfnssyTWrcdxymLcl12GaZqYPT0oLlfmZnQwo7eX6N8eQ83OxnX5ZZmUZF3hBA+9UU1SM/nsScUUe2ys3N6GaZpoO3ZwYmgfdW1uavN6cARdKE4XneY7WCMW1raGeLvhXRIF00l0xskyNdS+/LFJR4x9benZnIrTiZ6K4TdTFOQMrBprjjQzU4LVQoyY1tiI2fdgO7V9O8aZZxD9+98xDZO6qEn9kuUsrMjDNSgNiPuTl6PV1GCtmIr9pBOH3EvYZs0i8fYaAKx1dRh+P1ElHSaxlJdj9PSwtwuKzTgnGN2oOdnYZsygY0M6BuC0W1GKizB6e+ntiNMdTWE0t6A1N2MzdLRoFG2uPZP3NtcOvWoK0zSHFTLzOW3o7gTZWXZslnSakHfa1lHuLUdRFNoGzaq2qTZSRgoTg+pgFQAKCoXuQroY+2A1wDXXXMMtt9zCnDlzmDdvHg899BCxWCwzM/rmm2+mqKiIm266CYDNmzfT1tZGZWUlbW1t3HfffRiGwXXXXQeAx+NhxowZQ87hdrvJzs4etl0cu7S9e4m/lJ4xrfi8uM49FwAzPFB0VfV4UIuKUD1ZGOEI2t694HCw3ZJOR7pP9dK7t5r+v1DFYcdMJDHjCfSmJqx9deu27mig10w/JOm/DgmE4iQ1g021XYRiKU6bVYjTZkHJGrgWMGIxUjt2ElGsoKiofj+5x88m+1MfA7ud2IoVNCTWAQ7iegdvBVYwMZAkmsjCTKZQAJfPmzleZZmfNzw6Ta5tNAHllinYFIWlx9l5e7MdHcjSLETD6UKKrxd2syexhnNik8hz5fGJheVsbWplSzTJewsnBmIBpmZPo8dl0uFIT1rMi1tRDlgadnSMWoHF8eTxxx9nxowZByzGONokn9CRa7z0JaJHWNO7mmhPFAWFU7xLyLOlH7zUxKvZFt0GgIrC/KzjKbOXoXSr7O3eC4ZB5ZvtxOMws92g5cwTQNewdHTSWzGV4Ppt5LnVzEVfIKLzanUMzYBVW2HpJCcT/FZ0w+TZPVF6E+mLS4cFFpc7aa7d11cu7eAdytxIQoiPzjRNYk89RWL12sy2oCNGqroVTCiJZROwa3Q57CiJNl4pcZG0R7FqHRS3zMJi2gkVlNHbEcH0u0iEesk2krh6opy+6GP4Xwzh0HtRHHYUv59CReG6M6ZimJCTZcdls/D2ngCmCVMKPvoMTCHEkUHb9C4WILnuHVznn0/i7dXEnn8BxWrBOnUqzjPPxFoxJbN/4o03Se3ZC4CtshLbcbMBWFvVSSJlYMbjbPjdo0yLBWifcw4oCgW9HfhsAZ6Nd4AfCiztmC4rBkmSWnomZXu4m07lHdxFWXhSGnrfDVvSMTDJYdrsSajVL9Gcbcfq9+G2uolqUQLRADPUmYf8Jk+I8UpvGQjYGj1B4i+8iGmYGMDTLTp6bTd7W3r5bHco81dmmzEDx6JF+z2edepUFLsNNA1bXR1GYSHhvjCJ4s7CWlCA3tDA+iad44we/GeewY6sUiKbXwVdp3hyKVGXHa2oiN7OAD3Y0BobAZhkRNgXV9DCvWCmC6j5vG50UyOmxYbPrHYYdBsxJhcMBLVaIy00hRuZ4C2nZVAaoUXFi3m7+a1MsUWAXGcudsuRc590wQUX0NXVxb333ksgEKCyspI//OEPmTQgLS0tqIPqGiUSCe655x4aGhpwu90sW7aMn/zkJ/h88oBvPEmsXUvy3c24zjsX66RJo3781I6B1eKpbdszwWqjL1ALoHg8KIqCbc4cEmvWYqY0Wt7dSdKabo8JNAbCVPTtb6usJPnuZgC0hsZMsLq1bmA8Ksp20QWYJry5p511+9IpcHwuG4un5Q9JWWR0dmL0BImqeaheD4rFgtdlQ+nPxZ6fT6QlCThA09AMgzeaVpGILALTwGXqWPwDfxdlOS56CvdgBtKjXjQnwtkz8sFWi9IXOzm+28s+LUpb37P9TiXC281vcfHUSyj0O5lopNhVl/57nJY9nX096eunrli6H7tSDShKun/Teg59zb4RBasfeeQRXnjhBUpKSvif//mfIe/dfPPNtLa2cu655/LZz352VBr5YY0kP1K/aDTKM888w3/8x38M2V7Qt0yos7OTwsKB/DOdnZ3MmjXrI7VX8gkdecZTX7riXayoeoqoEcXr9WK1Wqiz1rCgYgFuq5vquoGcROeVn8+ErAlob70Nho71tNPQd+xgYtAFuFCPK8N52aUoioJumPzprTq6e1KU57m5aH4xwViKleub8PoGBq/tIYVJk4uJxlNYXR3kuKDI7+DSBaVkOT78ELR3795R+maEEIdK/PnnSaxeiwkkFAtuXxZBaw/991PZSSuuhAccJqZikrRHQQEj10m3rYMC22Iak63YE34irh5cYRPVgMnNGjPck+npTF9sWgoLMw/K/O6Bm7MCn5PLF06kK5xgweSxLfgshBglySRmLA5WK6ZukNpXRXzVKgBMTSe1ew/a3r14v/ZfmXoZ2r59mY+n9uzGdtxsIgmNbQ09mKZBau9eWhOQhRO9vR01K4uZZjdvFnZnPtfm6UV39s2c1tIrw3rjGhoa4ZwURW0aib689wlbmKTZS4CNTCycSqxkHjYtitPipMI/lW2dWzEx0A0dVVZ8CDEixuCCZ0DinfUABLER00zsiQQR4I1OOB1AUVC83mHH6afYbFinTSO1ZStKNIq+cycRtRwUBdXtYmaJj92Uo2VnsznvBLrMfGprerEfdxxmPM60k2dQ2xGlx+slleWlM9STOfZkM8w+PKSC7WCDXDOB6ktPGAolg2S7hua1tdgGVptm2bKIpNIzQd9t38QEbzltg4orzsydhdfuZX3bejpi6VXgE32jH/j7qK666qoDpv14+OGHh7xetGgRzz777Ic6/nuPIY5sRiRC7MmnMA2TyJ8fwfeNr2eCqaPBNE1SO3dlXutt7eiBAJaCAsz+YLWSTtkBYJs3j8Sa9OSaFmXoCq0mxU2Fmf4btM2dkwlW642NmRWkLe/sBtKxj3mTcnmt70/4naqB1Q1tfbW6dKeToOrAC+itbQCEFSv09T/LMfDwKpzrwtJ342TqGrphYmLSGtmLG3Cho/iyM/sHk0G8Xoga6fHFl6WyZHoBz9WsQbGn21ccdzCt102NJ8a6/CCmzUZjuIGknsRusdMSGZhCOCt3FnWhWlJGio54J7qps6dnD9jtWOJJpnRA20H+TkZqRMHqJ554gp07d/KNb3xj2HuzZ89mxYoVhMPhMQtWf5T8SM8//zzJZJJLLrlkyPYJEyZQUFDA6tWrqexLqB4Oh9m8eTP/9m//9pHaeyznEzrSjYe+vNT8AiklvVzDZrVisVpIkuTN9jc4xzafQG8jVrsNn93HjMKZJF5/nWRfpWvVasPYu5caWzYhxc6pF16Iq2/5ytaGHnoTJlarlZZgkj+tbiSRMgAVq1XFabcQ70v38fy2QDoXk9WKosBFJ06iIHtkDwGOpBQgjzzyCH/84x8JBALMmjWL22+//X1XZDz44IP89a9/paWlhZycHM4991xuuummIdWsP+wxhTjSaE1NxF99HQ2FR23l9EyfxhUfW0T49f+FUPqCz2/JwlZQDomtmc8pdjuK00nCpdFgvgUGWHBgVdxkue0QgkndVpIbN6Uf6QPqfgq49pte7AUOfHMqhDi6qO8plhZ/+WXMaHoms6Iq6fy1hknsnyvI+uJ1EI+jNQ3ceGl9M6w31XahGyZ6fQNmNEpAceBUdMxQCMMwaM9pIWzVM59zGhBzAxokUgYem59oMh3MttlNnOVlmA1NKE47uhKnnXUk6CGgaVjN9DVLrjOXmbmz2N65HYuioiKBaiFGqr8Q83t19uWQNiIRLA4Hm6MWpiouyrNUlA/IZWw/cQGxLelrEjOZIuK0orhcZDltnDarkD2tIVSvl41JIJC+llFcLubOKGHxtHy6Is0ogFpcTGN4YMJcgZnAZ6Zo0yMoNpMcM4nqSV+b9CZ7Kc4qwW5VSWrpWh6qdSBYPb/geLZ2bKU3GaKut472aDvtsXSgPtuRjcvqYmr2NCr8UwnEAvQme5nsm/yhv08hDidt375MGh8jGCLx5ls4zzpz2H4jTf1ptLdjdPcM2ZbasQPLsmWZmdVqljuTFsxaMSWTCqQ/V32/JtUNBqAo2GbMIGR10KurWOramLBmHakXXqTLNg0Av8/N1JOO47VVNZn29+uKJNF0g0c7XDT655BltzF5exdLsBHFkgnWe5wD4dken5oJVme1ZZFKNJGMOAgaIVwU40RHHTSzenP7uxR4HQSj6dz4sye6UBVoi7ahuN04TBVvyoKCwtSwmw6vSZXFgmEaNPTWMzV7Gs3h9DWTgkJJVil5rnxaIy30JkPs7d5LTIuh2O2Ud1mw9ybS92OHMDYzoiuluro6AGbOHF79cfr06UP2GSvXXHMNjz32GE8++SRVVVV873vfG5Yf6ac//emwzz3++OMsX76cnJyhVT8VReHqq6/m17/+Na+88gq7d+/m5ptvprCwMBMQF+JIE9fiNIWbAHCrLj459QqybOlgc0PNu7z2t5+Q2LwZMxaj3DsRMxgk/spATvrEq6/SVtvCc9ZS3vZOZL2ZDaQH33eqhq5cSAeq00qyXXz57OnMKc/ObDP6/lGaU55NyQgD1UeSZ599ljvvvJOvfOUrPPnkk8yaNYtrr7122IqOfv/617/46U9/yo033sizzz7Lj370I5599ll+9rOfjfiYQhxOZiJB7OlnSKxePey9ut5amhKNGKZBcsNGdExe9Wtsnd1MffYaVla/S3ROBarXg81QyDnjY2i5Qytpu+zp4s2DZ0jrJEiY3Xh9WWRpFvITNhJr1mTetxQNr7QthBiflGAvGy15PGitYJOag948sBzedfllqDnZAKT2VZHauhWtpjbzYAtA7+wi0R5gY203Rm9vJuClo1CnZmGmUpi9bTT5gkPOm1RNHM70zV9SN8i3VqCa6dlPHqcVS2kpWQvmY8lOnz9h9pDlsGK1DNzA5bryKM4q5qrKq/hM5VWoigSrhRgJU9Mw+mpJvVd/sNqMRDABM5XiTUvB+86q7pecPouNpbOptuVgAhHFiuJ2k+W0ku91MKvUP2R/j9PKFYsnctEJZVj7cksDqHm5tDnT+6oeD9lWg1P1AA41QYkZx2pRM6kAQn2FEl1OnS5zO2GzEV0deCiX68xlfsH8zOvnap7BMNP3W8VZJZntipLOUz01eyoW9aMVGBTiUOt/cNwv/tprGJHIkG3JjZsIfu8Ook89dXDH1A1e3tbKyu2tJHbuHPZ+avuOdI2LvmC14vGg6QadvYl0IHruHABa3hOsDigOkqgoHg8v7+niT97jeMJazmO9Xn6/ch9d2EmiYiktpfT0xeT7Xditw/997wonaOmJ0Wmk/z5TqNR0x1ltyU+PNTYbisKQVefdahzFaknnpo77cIbdJNsCaFqIhLMXl6mjetPB6mgqys6undisKpVlfipL/ZhKjGAySFyPo9htlJTPHpJ+bJKlIPNzTbCGhBanK56OOeS58rFb7OQ5B+r1rWl5O/3duVxM73Uf0iB1vxHNrNb19GyDlpaWYe/1b+vfZ6x82PxIANXV1WzYsIH7779/v8f84he/SCwW4zvf+Q6hUIgTTzyRP/zhD0NmRQpxJKkN1WTymJXYS8l25HB62TKeq30WvbWVXb4o6KDV1jGx8hPEnnkWs69SNaSX1TapfVVri4rY1tjD0plDi5cV+pygQHswTq7HzoLJuRw/KQerReXC40spz3PzyrZWkpqB3aqybNb4CC498MADXHnllXziE58A4I477uC1117jiSee4Prrrx+2/6ZNm1iwYAEXX3wxkF6tcdFFF7F58+YRH1OIQ0Xv6kL1+VAGVcCOv76K+Ko3ALBMnIS1LB1cbupt5Pm1DxIOheh1dzOpahs7J3aww+7AcJegAPuC25nmNekpn0oq10Xn3IV0ra3DrmWhW8M4TDslrrPQnPWorirCkfRcAp30rElPro/J210oKJllc5BOAyKEGP9M0+TdthQ11kJUReENSwE+M8VUM4yiKtjmzkXN8hB+6E8AxJ5+Btt7JtWYwItv7CRiy0Ovr8eGSYr0UmCzr9Cz05Getai4nOmUI4AlLxfdFswcpKVTIUspo9esTc+CUqDQPwF7xz4SfSvKBj90AzI3fD7H0ICXEOLDMTo6MrMy32twsFrVNTBN2hQnEY97SElT0zSpbg+zuyWE3WrB57KxZl8HwZLZRFsSFNOCCVjcbjx9waOlMwuoauslqRnMn5TDmbOLcNoGAsP9wWpFUbFVVmKEQniKC3A3BZm+r4rpahdx00Dx+umPF4USIdoibdTrL9NtpgPXpaly6DtsjiOHkqxS1rWsI2kkCKcG8u1Oz54+Ct+mEIeXaZqk3pPS04wniL+yEvclF2e2xV99FTMWJ/H2GqwzPzjl7q6WEOur04FWd20t/f/6Z4on1tVjdHZiptJFTpUsD395u5bm7hhLZhRwyrz5dK1eT0jp+zvuuy4wgSbFRY2rnL01XSieLOgLePdGE2yy5KC43VjLy8n3u1AUhdIcF7WB9wTfNYPajggMWuFhxGJ0KE40FLDZcNmtWNSBAHB3vBs1KwtLr4kt6cQWzkNztmGmkoQ9XTijOaj+9DXFnu7d6KY2cEIFwqkwnbGBCW9l85eivPNS5tqmqNeCXbWTNJLUhWqZmj01Ezcq85QBkO8aCGj3pyTKnjSDSb0u7FOmHPKA9YiC1WVlZVRVVfGrX/2KE088kSlT0oVMampq+PWvf53ZZ6x9mPxIABUVFezevfuAx1MUhf/8z//kP//zP0etjUIcStU9VZmfi+3pJ/CT/VPw6jY6IgPLzMxgiOynXiO5I/2Ph+rJwjQMzGiMNsUJVitqfj7BaIqGrijrBs2qPmV6PjNLfIRiKfxu25DlOoqiMH9iDlMKPOxsCjIpPwuPc2ghkaNRMplk+/btfOlLX8psU1WVJUuWsGnTpv1+5oQTTmDFihVs2bKFefPm0dDQwOuvv87HP/7xER9TiEMh/vrrxJ55DuuEMjxfvTHzN63tGpT/rb4uE6zeu/U1jKYmLIkErZvfos0VxwB6HR6UvtmDvVon0aSPpu4oHvJ5fG098ZRBsfsM3JGtXLnwdGo8ZcwuqySupfjLm/WkCNFovobdbmJzuahQCoDkkLa+XxoQIcTRwTBMVqyrob2jl0tPn0mhz0mqqhq9vg77okWoWVm8va+LHSGFwXOeXrIWk5uqo7BiIqrLhTK7EtusmaR27cboCZJYuy6zrwmsVfN4t7YLJdfEDPdyut7OSu8UrFOmkNq+HQDFlc4xacnLo9RfTlOgCktpKVqqJ3OsxoCOl4n0UpsJZM0rmM+6uppMsDrH7UBBJV3yLT1LSQjx0eltAw+s+//eASwlxXQGPZACNRJmcZGD1/v2q7X56Z+H3Nwd45lNTXSGE8OOrbhcGHk51PSkZzcrXi/eviB0nsfBl86aTkLTyfUMnahmmiYux0AAXXE4sBQUUJzrweqoILFvHwk1PRZkewvpD2Pt6NrO7u5dWGx91zYKJM0QNlQsigWP3YuqqByXfxyb2jcCoCoqp5ctOyJzUwvxQYz2doye9MNfa1kpeiCAmUyRXLcO58eWo7pcGLEYettAXvrU66/DwpPe97j9OaFNXaOqNcRM0g+abcfPJ/7Kq2CaJNe9k9m/2+WluTs9IWZLfTdLz55Gqzcf4qA4neTl+ejoe4j9orWElOrHBqhZHiYbVVSp6eLte1Qfltz0w+gCbzrfdWmOe1iwGmBXc2jIJCB0nWBfcNxqt2euJ/p1xTuxTCzHVtWBzeLDFrOi6FbMVIqouxs7bpS+NCANvQ2Zz1kUK7qpEUlF6I4P5M3O9RSQ9alPEX7wIQCcxx1Huc9BVc8+4nqcjW0bMvuW9K3cyHcNzKzut3Dy6fhOTBerZsuWYe+PphEFq8866yyqqqpoaWnh4osvZsKECQA0NjaiaRqKonDWWWeNakOFEB9OykhR3zdwuSwucsgG0hc5sztdrBq0b1HcjlI98JTTef75kEwS/ecK2hVnuohZ30qEl7e2ZmZV+1w2Zpb4UFWF7KwDF0bor4A7XnR3d6PrOnl5QwfwvLw8qqur9/uZiy++mO7ubj7zmc9gmiaapvHpT3+aL3/5yyM+5sGKxWIf6fNHiv5+jIf+HMl9ia1eg6FpaLV1sHcvlgkTMKNR4nV1mQKJ0do69PnppanV9ZsxjPRNmBEOo6oqIew4rCWohoeokl5q39oTxTAMLKabcCx9k2j1lXLSiXMpnJpLeo60iUNR0XUdlSzyOQmrYzfTvNPJK/KhtQ7KcW2zEnc4UKIDD95Gy0jz5AkhPrzapi62PP9Wesl+zS7Om+Qm8eZbABgdnVgvu5z1Nd0oqRQK6Ryw/Utzn7BO5LzyWcwl/YDcdcnF6XyYfYUQkyi8kzeNXVGVsGYQ0aoIplqpKAkysSkb56Rl6FlZYLFg6imSzhAuwO3PZ9rMJbR502NbKhXKtNeCCysufA4vNquKTbUxLXsa5bleDDOI12WnMn86JxUt5LWGleQ68yh2Fx/mb1WIsWWmUii20Z+gMjhYbV+0EACtqgrr2WcTemEv9PSQk4oyNdGVCVZX4eYUIBxP8fi6eqIJbfiB+2hFRbQW5WDFgerxDMkhm+W0kvWe8El3vJsXap+jKRSg15yBV5mYbptV5YzZhVg7DRIWo//yidy8CcSVRGYWpG7qFPYFudx2K7a+FAJ+R3YmXdAJhQtoCjeR0lOcOfGsTCBJiKNNalAKENsJx2Pp7ibx1uqBgPWyZegNDUM+o+/Zi93hILF7N5YZM3GcdOKw43b0pu8rjGCIBsWNAThmzcI2e3Y6WA0kBwVWGyyezM/huEZ3TKNz6dmom+uwFBay2J/kmYb0/UsCFYvdjqIoXLp4Enm7nqdanY4JaCjY89KF3PO96YdYFYUe3t6TTlVUku2ipSd9r9fZm4C+YHWF0Uut6suMC4rNNmSs0Q2dnkQQNSsLT5EPm2062rbtlES87PVrmIpJ3BlB9XrRDT2T9jXLlkWhu4iaYDUmZmY7pMcU2+xC3Fd8Ar2+AeeZZzJZb6GqJ12IujU6UAugJCs9ISnXOTQu4bP7mJk7PBX0oTKiYPV1113H008/TUtLC5qmZfJT9ycRLy4u5tprrx29Vgoh9ss0TXZ17aQx3MgJhQvIHzRzpyFUj25q6G1tlG9qw613YVamn4JN3tHBartCSjVRPVmUdqWXpCg2K85zz8F+0onpJ5CxOMFdcSyDVkr0B6oBlswoQFUloHMw1q5dy29/+1u++93vMm/ePOrr6/nRj37EL3/5S77yla8c0nPX1tYe0uMfbuOpP0daX5R4HO+ePZnXiZUrSSxcSLhqM75IJ56kSsihs7X1VVgfY6q9gtZAPeg6OTELZa0WElaDxtQUItNPJKF1knDUA9CWTGKaEEuYmHpP5hyxzjg7k0PrScfDEWKaCThY4FtIftBGoxrA1dOd2UcvKCAyaLb3aLOPYmVyIcSB7dm4CzOVLgTd3NJNomFgNZFWU0NTRxjdMFGSSWbr3SxTunjMWUGXphJVLDwd8dCxo40zZxdhyc/HcfppxFe+BsBmNYd33SVo9ght1vUkHBGKzRh2a5KGmRMpmVRMU3cM1eslGq8nS0mBApNKZuO1D+S5tVsHrnWsOFEUhY/PPI9OfSez82ZjVa1M9JdgtaaD28flzSHPlccnZlxxGL5BIY4cZjxO9LG/k9qxA+c55+y3cNpHYQxOBVZcjOcL12DqOm29Schqhp4e8swE2TV78Jga7Vlh1tjamNc+ga17szKB6kK/k1NnFGBVFTp6E1gtCs9tagRFpTOnGIslHSZ572zHwWqC1bxc9xJJI4nNqtDNLjxmOYqicPnCcor8LsyscuKOvvFDAU9BKb5kJ92JgRmP8wvnEc2NUh0cWBGb4xion+WyurhixpWj8v0JMZa0QSlAbNOng81G4u01YJok3nobx2mnodXVD/uc84030LJziL67BdXvS392kK6+lRJGTw8aKm2Kk+mzZmIpKUGxqJi6gdE1cA/RaDqHfL42EKHF4sFWUQHAjMkqb721g56+mc+eLAeXnjyRSflZBJ12SrQYzYoLxe1GcaaPlde34mJCrpvLFpaT0gzcDiuPrRlUy89iwWMkKTZi1A5OTvSeYHV3ojuzMstrzUZxujABZ8wH/vTYEXFFULxemiPNmYdf5Z5ybJaB+5eWyEDa5mxHNgCOhQthYfpB32Rt6CowgBxHLm6bGwC7xY7f7ieYTM+GX1i8CIty+PLijyhY7ff7+etf/8r3vvc9Vq1alZlRpaoqp59+Ot/97nfJ7isyIoQ4NMLJMK82rKS+Nz0AtkXa+EzlZ6kP1bOh7R06452Y0Rh6XT3lYR+25ir0XbvRyydgaQ4wMzeLHRNMbDNmMFV3Y5+SjfNjy7H05XVHUQguOBlLtGa/559R4mP+xOzD1NsjS05ODhaLZVjhw87Ozkxe/Pf6+c9/ziWXXMIVV6RvXGfOnEk0GuU73/kON9xww4iOebAmT56My3X0F7WMxWLU1taOi/4cqX3Rdu0ikT1wg2SJxdlTmGRDzRbM+UmKonYCLg3DomN19VCf2IbDasVQVYrbrSyK5ZGwONgzYT45ubkoqp+4uWPIRVCevQQ76RxrigKnLpg6rBjJtnATDZ3pGdNLT5iMz2XDKCwktmkgx7t19mwclUOLNI6Wve/JpyeEOHSqqgdm83QpdpIo2PvmG+mdXVS1pGc1K6kUk40wzlwvnz5+Is+9sZu6wkkodjtr93WweGoebocV55lnkty4CaMnSI3qQfX56LZVYe/tochM4jM1FItK8PhplNrc6WC1z4eFLiykc1VOzpuWKUgN4OjLTWvBgaKolOdlcdqUSSjKwBh0fOHxdNR1MNE3MZPvUYhjid7VTeTBBzO1JRJvvz3qwer+mdWKzYqam57RqFgsBHoTKFnpAEuemUDbtYvJlgJ25TZiWt08sOFZCpPnoygKXpeNT588CXdfIHpqkRfdMHn+3UZgoC6rbiaw2YbX4Qone3mz+c3MjEQAi6pQkK3hN+KcM3smkwvSMzcVqxVt7kwItGDJycHt9lNmd9Kd6EJVVJZNOIPZecdRH6obEqzOdmaP6vcmxFgzNQ2tJh1XUL0e1OJiFEXBVjmT1I5dGD1BUtu2DZlZrTgdEB66EiL2jyex/vfXMis3kppBMJpKF1Xt6QGg3uansqICxWpFLSoaUpDZABq1oWHQTbVdmdnZhT4nWcXZLNY7eN1aRLkR4cITCvH3/U1bysqYUBOk2eLC0rci2u+2DbmXmVmSDkQHo0PTF2K1kqtHybEM2m6xoFgseJw2TNOkO9FNZ6wj87bPnkPUYkFxOFASPiAdrO71ayiqSuOgFCATvOVEtYEVp/1BbLfVjd0yfBKO0+rkjPIz2daxFcM0sFvsLCpePGSfiuypbGrfSIGrkBk5h29WNYwwWA3p2dO/+c1vCAaDmZnVkyZNwu+XwiFCHGqGabCi6p9DnsoHkz1saFvPpvaNpIwUmKDV1mDToDjmIEyM1MqVJPpyzJ/Q7cNzUiVFM5ZSvmgaANGEhhnXyOp7ste/bAVgVqmPXc3pG0a/284F80uP2WXydrud4447jtWrV7N8+XIADMNg9erVB8yTH4/HhxV1tfQVWTBNc0THPFgulwu32/2RjnEkGU/9Gcu+mLEYWn091smTUfoKBcda2+h2wpacXkpiDoo6mni3/R2UcBgUlfYsDVBQTLDoOh1ddSiKiqpC9oyFEHXwbDALtbwcxWplwZRCOmqLCOsDM6FKvIVEEgaablKa4yLb5xnWttNnl/DClhZmlvgozktfV5guF3peLkYwPQ65ystxHqLv7lgd24Q43Hq6w3R09eWHtdlQCwoIOhwUdzWjd3RimiZVte2YuoKqaUwggppbTMEF5/DZZafywt4ettT3AOlrlqlFXhSHA/eVV9D5p7/Q7son6Y+h20PMLJ2APWViOB0YLgcd9gQL/emHharfD6m+fNVeH+XeiWhGKtNOmyX977dFSe+/fE7RsHFiir+C6+Z+UcYPMe5p9fXobW2Yg4qYmqZJ5KGHhhRBNkK9mIlE5hrDiMVIbd6MdcoULCOoOWGmUugd6UkdlqKiTIpCgEBvHNWdfsCUb6aDTsVqEN2SQlVVwokYOUoEh+Ll4ydOyASq+1lUhWy3jf7Jlwmzh0bzVV5szqY8/3P4+4qjxrU4T+x9fEixQ789m2Cyh0K/k3kFMaYVeYcc2zjjVOx7OlGcTlxWNwsKT6TQXUhxVjE5znTAfYK3HI/Nkznu4JnVQowHRiCAmUgHaa1Tp2b+rXQsXUpqR3qlZOL1Veh9E7fULDeuKz5J1d+eQnO5UHOyoT2A3tlFfOVKXOeeC0B3JP33bkYimVVajfkTMsFsS2npkGB1QHGQUGz0jx6GmaIhFMBJLopiYf6kbNScHGYpYWakelGArILczOdts2ZSXv0a65QC1L5gdd578tj38zptWFQFva8orKIoZCspcs2BnPn97cxyWHml/mV2dw9dNZrtyCFKOqd+NO7GlnKRssUIuzUSeoKG8ECwutw7kaZw47B29M+q3p/ZebOZnTf7gO+fUrKEGTkz8dv9mdREh8uIg9X9/H4/8+bNG422CCEOUkukJROodlqcxPV0ao51rWsz+zg7QuS3ppgTzMVqpv8xMFpaSQTST+psFiuTZ16Ap+9iaG9riH9uaETTTXKy7Mwo8dETGXjqt2hqPj63jbaeOMvnFOO0H74lIEeia665hltuuYU5c+Ywb948HnroIWKxGJdffjkAN998M0VFRdx0000AnHnmmTzwwAPMnj07kwbk5z//OWeeeWYmaP1BxxRiNEUe/jOpfVXYKmfhuebzAGh1dazJ76HJnWCvN0qWZiHZasWMJ7CYoCvpIvYezUI8GsHom8FgNRQck+bzglpKMJhEAbwuG0um57O1YyK7gumbVytuKstyqCjwsK2xh4UVwwt3AEwp8PDls4cu8VMUBevUCpIb3wVALSw8BN+KEOJw2vPubuhfoZmTg7W8nNCchUys3ULs+Rfoxk5PTxjsdoq0MDariZqTvm6xZGUxpUDLBKub+4LVALZp0+j84lexbKynw3yZHKcNNdvFsonL2dm5g+ZIM73JEKV5FnI9dlrVDjweP5akndJpx+O0OjFMe2Z5rKJAntdBLOzk5On5FPn3vyJGAtVivDOiUcK//R1mSkM5bSmUpvMnG62t6C2tw/bXOzozBZnjzz5HYu06VK8H363fHFps7CAk31mfmfasFg29BgiEEuBwpIuj9abvX2yOICom9AW1DUsPF58wiwm5bprCTbxS/zITPBM4s/wsFEUhZ1D9nV7qAANV0dnbvYeTitPL5quDVZmAssvq4pSSJUzxV/DA9j9imAZ7u/dySukSknoSlzU9TsT0GErfKrr+GY6V7wkOqYrK7LzjWNe6FgWFoizJcy/Gj7VVHdRvqWEhNvyksBQP/P9tnToVS0kxeksrWsNAoNUyaSLrbQWsnH8hZjzEf50yAf13v8fUDRKvvY5tzhysZWUD+ar77kkA2j35xJM6TrsFa2kpSQaKBzYqWWBPjz0WVaFJf4u42YlXmUSZdRHHTchGUVXU3FzMvodjak525vOOU0+lwu3BVaVj9D2Iy/ftP1itqulxpb+NKXrRfWGyIgZWTDQUFHt/sNrCho6qYcfIceTRTBLF5aKzx44z7iFli2GzW6kJ1hCIpotR5jnzcNvceOzeYcfwv0+w+oMoijIk1ezhNKJg9b333ss///lPKioq+P3vfz/kveuvv56qqiouu+wybrzxxlFppBBiqJrgQMG90yaczs7OHTQOeormTsCFr0ewJdMDi7LkJHj2uSHH2HDKhbyzKYCidDB/UjZb63syT/26I0nW7htYfqKqCoU+B6U5cuHU74ILLqCrq4t7772XQCBAZWUlf/jDHzIpO1paWobMpL7hhhtQFIV77rmHtrY2cnNzOfPMM/na17520McUYrToLS2k9qUviFI7d6EHAqg5OUSbammekEBR0veDEauO0tyMS1dZ3DiJZ/OLyAnGOFNv5dmSIGY0vfrCYy/hhSYFmzuK1WrFabfwqZMn4XHamJYziV3BdAVuu+JjUl4WE/PT/31YjpNPJrVlK6rfj236tNH7QoQQY2LfroHclP1B6NZgnPl9sy7r1CzMWAwwmZAKsjc3yt6sXSzq3EFl3mxKcwaCxs3dMaIJjTf3BCjJdlHV3k0Lb6ERwefyUJpVxsycWXTEOmiONAPQk+zg8pNzeWLvSjQzfY0zvei4dHsUlSybOxOYKs9zM6OigjOmfPgZoUKMF0ZrG2YqvbQ89epr8JlPp38eVO9C9XowetN/N0ZnB/QFq7W+1dhGbxi9vgFrxZT9niOR0nn23WasFoXz55ditagkN24i+s8VmX1ss4cGewOheHoG5LQpZG1KF1LrdCTINzU6LSpel42lM5zMLkvPkF7fuo7eZIidXTuYnTeb4qwS7PYIupKeABQ120ABq0WlKdzISaSD1bWh2sw5L5hyIcV9xQ4neSdRE6ohqkV4aPsDxLQY07NncGb5WcRSA8vy+3PB7s+CohOxW+z47P73nQkpxNEkGE3y6vY2tJZesOSyXG8bsrJCURRc555L+MGHhnzOWj6RnU3pXMk9cYOYPw/vGcuIv/Iqpm4QfeQveP/zP+gMpx9OmT09ZJspehQbit/Pyh2tnDO3BEtp38MyVFoUF1WqB8WaDhDPKrezpyYdkI6Yzcwu8+HsS/tlnTEdvaMTS0lx5mETpFP7uBeeyMRUDVsCO7DiIt9TesD+53ocdPQm0M0UzcoqmNBOabuL3FiSdsUBtvRDMqs1lV4dP4hNtZFt9wEdKC43SVScMS8Rbzs2u431resw+9KmTfCWA+CxDV+xerSOJyMKVr/44os0NzfzhS98Ydh7Z555JqtWreL555+XYLUQo2hH5w46Yx2cVLyQ2mA635OCyiTvJLx2H417HwfATKZY9HYQWzI9U8mx8CTM889HX78BkukBcN8pH+Mds29pvWnybu1AwQG/204olsoUTAUo8DqwWg7vso+jwVVXXXXAFB0PP/zwkNdWq5Ubb7zxA8fF9zumEKMlueldNqo5bFBzWWR0snjDBmyVldTbo5iAJTcXo6cHUzcwdYNpnYW8oE5EyZlOR1cV7VqSqTX17PZAj2KjlRnoSZMcNzhtFq5YNDFTFXtqXgneuslEzTZy1OmU5Y48dYd18mT83/0O2GxDlv8KIY48pmmiNzaiZGWlxxTD5I139mIYJktOmoaKSW1r+kbUZQGy/cTNXnZ1BvjY/HQu6FolCzMaxVRVCo1u1hX0otrzebv5LWblVuJz2XA7rEQTGi3dMV7a1srOpiCaGaOFN0maIVRVwe9ycUb5mSiKQpF74Ca5sbeR6mAVmpm+2Z3sm8Lc/IEVo4OX5QNkuwYVRBLiGGQmE0Neq31L9rXdA8Fqx5IlxF54EQCjb2aiaZoY3QP3G1p1dSZYbWoaqa1bUXx+bFMrWFvVye6+XPVFfhcn+gyijz2GaRq8VdBDbNZEzp0xkf550PGUTjieDqAXlRfjdCwmsWYtAWeSQjNF2cQcVFUhrKdXpeqGTktkYBb47u7d9CSCbIk+T5criodlpOjFalFQFGiJtKIb6dzV/flhnRYXhYPGkuk5M6kJpe/PYlr6Qf7enj10xbuG5Irtn229PxbFwvyC4w/4vhBHi95YinhKp8DnpLtvpbYZi9GupIsRvndlhLVyFtaKyWjVtZltZnk5HbsHVnnHkjoFZ5+NtnsPWmMTekcn0X+uoHPKyZipFEY4wiK9k5d8FSgOB1vqe2jujvGp44vQUHjEOpGQRcViWLH3FTQszo9DX3kugxQzSm2Z87kuughbZSWW8vL9rppy+lsJtG8ARcHvnXPA76J/xUaCLkwlhc2i0OxOkBtN0K44MmlATDU65HP5rgLm5s8lEkyHbBV3euxwJDw4MFDs9kzhQ4CJ3okAZNmyUFAyQWz4aDOrx9KIgtVNTU1AumjXe02cOHHIPkKIj64p3MSrDa8A0BhuJJjoAUWhNKsEa0cPOXv2MqWhi92JOmYHHJR2pgPR1glluC79OLFUitjy5VhrauicOIOVyTz6x6/+GZQAU4s8XL5wIk1dUf7ydm3m/CU5R04BOCHER2OaJrFN77LWUkgKhdWWfOZu2ESW00mdJ0YClU5LFifYSknEd+GPudiUmIleVJIuJFJby17Dy/IOL9usDjoVL4WFcwjFkpRkO/nkyVPwuwduzEpy3BQqJ4ICZTnuYcUUP6z+3JdCiLFhxGJou3djKSrKFEh6LzORIPrEP0i+uxnFbsP7319jW02A1/71Npgme9ojuCyQ0tIP1iuKfexz19IQ3gQRk7+01jDXn6Ip6sSMxfA4bXTkhNBVsDgcxPU4PYluknqKoG01kXg2/uQ0djUHMU2TABtJmulgV47Lw2XTLyPHmZ65PTjAtDmwOVMANt9VwDmTzh2SkzHrPTOUBhddFOJYZMbjQ17bqqsxFy1Gq60F0svlrbNmQV+wWu9Ir9Q0Y7FMvlpIB6vhbIxolMifHiZaXYsFcBw3my15x0NfRtmtDd3MNRswDZOAI0X11CysE3xs79zGktJTgaFFzHI8dlwLLyBWtYdORxOW3HSgGiAQDWCaJu2x9kzhMYB93fuoCVbjsKoYpAgo6dVgtr40fbqp0R5rRzMGZj5O8k0aMlZM8U/JPNxSUFAVC7qp0RkfWKkK6TQgQowHpqaRePNNFLcbx6JFme3heIrfrtyHphtcefIkwvH034wZjdKlODBsVraGVXbtreX0WUWU5rjSs6svvJDe+36ZPoii0OXLxzSbM8eNpfT0rObP/Bu9P78XM5EkuX4DAdd0jFAICwYzzBCWaX5WWRQ03aSjN8GWQBxPbjZ7vXtJ2RLkdVWQp6rMLPUR1nfisFtIJHW8LiumLQikA+mK1Ypt5oELCtpcnUwqyMJmUYmbXRhmPuta0ilZF5UszowPuZ70PVGSIC6bChYL3Y4ks8wEUVeQhLeXXDOHFAPjyamlSzm+8AQAtkTSD/kUZzrQbzGs+BN2sA/ca1X4p1LeF6xOrwrLGvqg/VgKVverrq7m1FNPHbZNCDG61remL5owTdrefRsjGESx2ynsbSLUuA6AkzE5Uc3HbqQHOsXtwn3VVemndakURk42jiWfYe2mdszOCAAnVeQxt9zP23s6yHJaObOyCIuqMDE/i8sXlvPk+kZM02RWicwkEuJo1xppoaG3gVm9PtpDcVLW9M1bEpW6kMbEN16nKT9Oq+ImbmTRmHU212pFrPbkoU8pw9oXJFZdLup1nd16PvFAASVlZeBwM8NtcuWiCXjdQ6tN52bZmV3mp7o9zCnTJaWNEEcr0zRJrt9A7zPP0RCDYjOGO8eHc/lyHAtPQu/qJv700xjhMEZPD0ZPesaPmUyR2riJPdXhzNPxjpZO6JtNpGKQnNxCjxIFTDChPdLDcxOi1Me24Yz6mUApVflJwI7iSI8xrZFWtnduI6UG6DTrSSg9FBoLiNBC1EzPmrTg5MIpl1E8KP+rz+7L1PvoD1QrqJw7+TxsloFZVQAeuwSrhRisP/1XP2t1DXpNNeb/Z++9oyS7ynvtZ59z6lTOndN0T06aJI1ylkBZgGQERgJfWUTD53sxDvga7IVt4NoXbGyCr2zLgMkCESTNICQQIwlpNKPJOXbO1d2V8wnfH6e7qmt6RmGUZkbnWavX6jq1T6qwa+/fft/fq1mRx44lS5DrqvUojGmx2piaqtlP6+tDj8XI/tc3OTJV4leOhXhNjQsPDDDlMnGsXIlwOomligwP9RIB0g4NuaUdBKSKqcqxErlq6nzIoyKcTvL3/h7K7gIiWJ3DlIwiyVKSoXRtAbKCngedSvq/Rh4JCYdcXYgbzgxVIqYB5gU6a18HSeFdC+9gJDtCs68FzdD4Zc8GEsVEpY1A4JTtBXebMwPTMDASSaRwqGbRWY/FKD79DI6VK15UrC3v3kN+42MASIEAjqVLAeiNZdF067f1+Fgaj1PBNAzMQhETGI+08Ku9o1b2lTHK3ZdZGRZKezvOyy6l+OxzqOvW0J03a86XK1l9jFxXh+vqq8n/6nEMYGoyhZnPEzItuXftynk0NHTww82W7dBEJs0L7QnK04UY9bo+rl0ZYU1HIw8d+y0LGnyk82WCHpVYLsbCUG3NnJO+dqbJWG60EjWdKqU4njjG9vFtANR76lkQsuwKZ4ovFklafYwsU5INXHKWifohhMuHLO8jq62uHD+gVvutmX5JyDLC6cQsFmnNuTCmva5XRs/jirYra97D2VlhAlEpEHu2cVpidVdXFwcOHODrX/86Cxcu5JJLLgFg8+bNfOMb30AIcdKoaxsbm1fOaHaEwekqr8bkVHXyVyzRNqox8zUWCJxON3JzE3JTE87LL0eO1FaSnkgXGZgWqqM+J9cub0SSBO9a3z7nvIubA3z0uoWUNIP6gOt1vEMbG5vXG83Q2NC9gYKe53D3OM3CElykSARjaopjkh/J6EETkFWcBBwdmMJN/NY7GT04hkgXEUKwoi3Irh4PeibDM3I9wulEbmnh8sUR3LkysjQ3wlIIwe3nt2Gapl18zMbmLMU0TXIPPkhp+05+IzdxSAnQbBZ4d7yf/EMP4Vi+jMKGDZT27T/p/sXde+hJVcckRqGA0HW8psalSg/bPR48sptJQBUh8qUSedWNXiyR9U3Sa/TjUkycgFCtiV9Pqoex3BgepzWRy5j9FJnCoEzA4yCVK9OsrGNNa2vNtQghqPc0MJCu+mWviK44aeTRid6PJ0Za29i81TgxslqenETb+gIzv+6OJUsQTidSwI+RSlfF6nicCVSel+tYYGRYVk6R+ff/YCqZ5wnHPHSHSgqVX5cdmJqGNjiIY8ECTMNgz1CKq4FcyIVwWnOSdDlduYbErMjqoMcScMb0OFI0AljCT6pkiduxXIyhzMkzwBVJMHsYo8pVqWQoM0R6+hgCiQ7/3LlTwBkkMEsUevfi9/DC6NZKBkfUXWePg2zeNMxiESMeR5r2i85+69uUDx3GdfVVuG++yWpTLpN54L8wpuKUtm3D9/E/QmlrO+nxCk89Vf3/iV/jWLoUI5MhNmYtTJnAxJ4DeHIZTHcDM2ndez1NFbvR4XgeTTcqdqPu22/DdfVViECAsd3DNefLT4vVULURSeJAzxcxi0XCpiVGS5FwRbswTYMd8SfBbYIlgeBTdYrqUQzCTBUmURWJ6LR14fh0scKXIl1O1yxeJYtJynp10SyWi1XE6tawm6UtASZjWep8KqXpjI24L44pTIQkoUtxksWqpcdscdk5LVaDFYxoFousTPhxNq4n2jifhaGFc/oVn+qH3Gjlf0V6VTHKbxqnddVvf/vbOXDgAMlkkj/8wz9EVVWEEBSLxcpk9IYbbnitr9XG5i2HaZq8MLAZDBOEwDM4wUw3FjZc+HUHyvxO1JUrURYuQGpsfNFB0O6Baie4trOaFncqgidESNrY2Jx9mKbJYHLMihwyTGJTA4yFOiAno3R1UUql6NZ8yN48BZcHfCF8WIVCjo6mmJyuYN0ccrF2Xpg9oRD6+DggULo6Wdoa4vzOMAcPjr7IVWBP0GxszmJKW7dS2r4TE+iVfEjhMKPFIqXkAKphUtq2jfLBgzX7KPM7MXN59NExRscT5BVr8tVh5Gg0ptCEh3VaH4PuDMIVwS0UImIFIZYQEUl6zecRZh+mMPCaZXSo+NWbmJVi0x6nAgIwoUwGr0thfr0fv9TCzV2X43fXRksDNMwSq2WhcEHT+pPe94nitJ3Cb/NWxyp4Wot+5CiKoiAkgbJgPgBSXdQSqzNZzEIBIx7nt0oTI8JFn+RlQTmNlEyzUemg7HTjWLYMJInSnj2gaTgmxpHaWtCKZQ6bXi5HUGiJMqOKZ0rVFPfkCZHVYGVezLCybhXPDf8OgLHcKKPZEQA8ihfd1Cjq1jinzl2PKk9UnF5bvfPwOjJky1mGMoMYphUt2uxtwqm8dCCPKqtc1no5SyPL6E/30RWc/3JeYhub1xzTNEl/7evoY+O4b3g7yoL5lA8dBqC0bRuum25ECEHhN7/BmLJsJ0zdIPf9H+D94H0YU3HkxgYkv79yTCkaRR8dA0AfH0efmCD9L//KkF6PvmgVlDUmeo/iN8tozmomxDHJXzG80A2T8VSxUixZCIEIWmOF0WTtwli+PEusDlsLUVPCiVksQKlIZLr2hBSJ4FFlJEmQ1AdJF8fwq05ko4AhDBwOwd6JvSfNlJrIx15WcM1YtnbOkywmKv0IQLxY9ecXQnDbuhZG9kKpLFfE6sFAChUvmiThcpoMZaoZHwG1Kla7HFV7ELmhESOZoqmtjcVL3n7K65y90B5Uz86oajhNsfree+/lscce49ChQwAUi7WFFpYsWcK999776q/OxuYthmmaTORjiFIZ5482MD50mKMt4whZwh9u4qZDbh5rzZIKO7nopj8mFF56yiJjxbLO4ZEUXfU+ZKCsmxwcTQMSiiyxsi30Rt6ajY3Nm4BhmHzvuV4OTO3BHSkSLuUwNZ0j4Ska3SsQioLSMY/M+BEOdQUpRuqQkwZu6gHYN1hd4GqLemgJuwm3NhCXBMgKatDPtSsaAe0UV2BjY3O2o4+Okn/4EQByyGgLFuGoq8PI5kjuPEg9RQqPP1GxAXBeejHu229HSBKFp58m/+hGBkR1UjjfzLAmE0dIAXR0Ei4NoTpxC0GdqxG9KIjHQ/jLF+McCCL7h3D5EmSBdv88THcdE/lY5XiyJOh0r2M030fBnCTiU1FlJ+9c+jYC6skFpTZfG9vHrHTdVfWrTmnvMdsGRBLSixZHO1v53ve+xwMPPEAsFmPp0qV89rOfZdWqVSdtWy6Xuf/++/n5z3/O2NgYXV1d/Omf/ilXXnnlaR/T5uzCyOV5XG5iXLi4Th9g9lKQ3NVV9VWN1lWKpekTE8RjcUami6vpCOJCpV94mRBOHJ2dhMI+UnkNpaUZrX+AJUYKbbSbw1KAMhLdwke+IcDMeCOnZdENnanCFIfj+zHMBiQhE3Q7ME2zIki7ZBeLQosqYvXByYNo037Vbf42nLKTvRN7EAgub76C3UenmMSKDG33z8PtTXA0caQiVAPMDy14Ra9Z1B0l6o6+dEMbm9cJI55AH7OihvO/ehxlfmf1uUzWKn5aKlHc9FTNfvrEJKn/848ASAE/gU//BUKZzup2VL/9ZrFEactWzGKJSUVFO94NCFLCYa0ll6sLSrhqF31HErmKWD2DphvEUrUaY01k9XT2eEKomMUiZqFI2CwheT2V2jY+p0xf7gi6bqA5ndRNLqDgSKE2pTAx2DzyXOV4ilDQTI2CXiBdTtfYcJyMsdxYzeNkKVkTaT3b/gcs8XqmDzGnxeqCbNBlZCjVdxLyuyq2HW7FXWNJ5lSqkdVSKIR6wfm0vn3piwrqs8cuIVfoRe/lTOa0qhw5nU6++93vcvfddxMMVpX6YDDI3XffzXe/+12cdgEkG5uXjWEaHI0f4cdHfsSDR37ED57+V7pH9rMvYKW4mbrB8kNZ3IbMbYP1fGDlvSyPLj+lUG2aJj99YYCNu4b51jPd5Es6PfEypelCRivagrhU+aT72tjYnN0cmjrE88ObKeklJtJFhqZyFMw4U5kSxuQkJSTKAhINozgUCbm+jvRyg3SojkzJICyWIoTVPxhG1S+uPeJBCMGSlgBSMITk83Hhgjo7A8PG5hwn9+OfYJYtcSe9dj1yneU9L7weMhFrYWvmeQB1zZrK+MSx8jwA+kV1ctphZK3J8bg1cU6EHCAJhICL53dV2gmPG2FKnB/38q7eei5Ot/O26/+IJk/VfxpAlVQubTufVnE1K9zv4L3L38V7lrznRSebbf52rmi9kgubLuKipotP2W52dJLX4TvnMkQ2btzIF7/4RT7+8Y/zs5/9jKVLl3LfffcxOTl50vZf+cpX+NGPfsRnP/tZNm7cyHvf+14+8YlPcODAgdM+ps2ZialpZH/4Q7Lf+S7mrMC04XSRQ1KAKaGyd9nFaM3NyO1tOJYtxXP7bZV2Un21RoUxMcHBsVz14LLCFE4GhQcpHEIKhbhzfQfXrmhEamxCUR2s0hMsGTxU6Sf2yiHyoVqRK16M8/NjP+NwZguT7EaWBD6XwlRhkoJuRWU2e5vxqb5KVkTJqN5Lq6+VS1ou5cKmi7ip6xbq3fUsci7DgQ+XiLK8bjFt/loLhOXRFZxXZy+82JxdnJgRMbOQNIPe18eBnz3Og1I7h4Uf9YLzEa5aPc9IpTFi1YXiE49ZfP55dARJ4bDqU5gGGoIpUTtPEJ5aYXpoam62RixdrFiFzFAjVrvdCJeLpHBgFgqYpTIhykjhqt2Y6ZiiZCbRdRNViuKbv55I5CLq5y2ec74lkaXVc+dic54/kRMjq/NavmI1BFak9ewFron8rEKrclWDUYVJJOCuyXY/MRLa6ZBOeKzgdb14zHHUVV0cq3c3vGjbM5nTNi/x+Xx89rOf5TOf+QzxuBXmHg6Hz7lBnI3N60lZL3Ng6gC7Y7tI5+IgBGa5jDY6wuZ6QUExkfx+HIksi9LWIMtZ14B/1cnTVWfoHs/QN2EZM2ULGr/YOcyh4RKBoHWMdZ3hF9vdxsbmLGUsO8Zv+p8ArFX9VsWqKVE04xjFshVZoTtBkci5EyxqM9jZP0ZOG6OQFSh4qOPkEUNtEav/uHRhPfFMCbcqc6ldMNHG5pxGj8XQBqzUVLmhnvT5l8Aha9IlgHTXYpiqpq5KoSDyvHmVx3IkjNnayvC4NTkNmBpBrAgrU9MxMYn7rLmDR/GyvrOJrUdTlDUDnE6Ey0V7Jou3rpnQ5ZfhdPtpFE3sm9xbOUebv50r5zUxr85Pnd9J4CS2HydjVf3ql2zjdXhxSA7KRvmsTqU9Fd/85je56667uPPOOwH43Oc+x6ZNm3jooYf48Ic/PKf9L37xCz72sY9x1VVXAfC+972PzZs381//9V986UtfOq1j2pw5mOUyKApCCErbtlHasQsAZcECnJda44mhTFUwmmrtIre2BdeyZXg8tUKyVDdbrJ7kYGJ6QUtYi+RTQ+NMKm6UefPwOBXqA04agi5aw26IZHA/up+wWSJYzpMQDoa9USLlBGJWrE1fqpeSXqSk6RTNPha4VyOEqPGkbp0Wm+cHF9T0GwAtvlYckoP1TRcCkMvlWBkNE9DfRdjvYWFDCN3005fqQzM01jetp8nb/OpeZBubNwEzn3vR58uHDvPkYJ6EcBH3tnPhO9+Buuo88g8/Ytn4ZCxdwUilkJut78CJ/vVmsUQSldkSs/B4LFF7RniWJDghqHUoPlesHk3M3TZbrAYrujo9JlEgjuSQ8JXLSJFI5fm4ebjyv6M4H9nrR/EFePeyi9jQ8yiTBWssE3ZGaPd3sH9yHwCx3DgLXiR7Qjd0Yvm5grY56851UydTSlc87KfysxZrZ0VKo6oVa6MZAicUQ5wdWQ0Q9qovqbm2+tq4pPlSinqRJeFTF8k803nVTttCCCKzPhTHjx9nw4YNbNy4kccee+zVHt7G5pykoBXYFdvJvom9FPUiRjyBduwYmCYO1Y1pmORkE7m5GaWjnbVmB2ryIEYiifvmm2siqnNFjaF4jnq/q1JU5KlDtcUBhuMF9On+87yOEI3Bcy+N1cbGBo7EqwOzI4d/x+jxoxSz9RQbB0GS8OUdqNkmREcegWDC2IPhnYSkFUUdEiuQhIxDkSyxaJo6vxO3ag0ZXKrMnRd2vOH3ZmNj88ZTnhUxq66/gMl87WQx01xbZExdvXrOJGps4Ur08R4AOkMqYlaAUV42KLkVFKxUeZdDZnVHmG3dkwjAs2IZC9qXYC6cj9lteVQ3eWsjq+cF5iFLgvkNr33xQ0lIXNN+LUfiR7ig8cUDBc42SqUS+/fv5yMf+UhlmyRJXHrppezcufOk+5TLZVS1NkrO6XSyY8eO0z6mzZmBPjxC+v/9P4THg///+wTlA1UPen2oKv4OF6YnFEIwVdDRDfPEQwEgR6uRfaOjk0wUrDGFcKrI7e2M1/nQJDfC6aIh4Kz0Gy1hD+mLV/KzxK8we/pZPO5nK80Q8DKU7KssnAP0p/rQdBMrgNEgJ/cAqxjOVAuztXitAqtXtF1Jk7eJA5P7Gc4O0xnoOukClKoIbjuvuSK+K0Lhpq6bX/4LaWNzBmLm5orVQpEr9l3pXXtJKJZAW47Uk9UF/qVLcSxdSvG5zeR+/gvAiq5+sWNOCRW5tdUSsstllPnz0QYGMKYzayS3u6LNCiEwTZNkrkS2qOF1VqXJE/2qodazGkCORBhJjTLa1IcEaH2uilgdy8XImZYeouDFoTWBAJ9Lwe/0c8eiO3my/zf0p/s4v/F86j31leOeTIiezUR+At3UX7QNWEFDM8Lz7GOGlSglrD5qtpXKDCdmhUmSqJmXhb0vndEqhGBd4/kv2e5M5zUpCzk4OMjGjRvZsGEDR44ceS0OaWNzTmKYBjvHd7BjbEclDc1IJNCOHqU1o7Ii6cOryfy8PYepyMgtLchCZs2Kt+FefRsUiwh3VWiezBT5/nO9ZAtWtILf7SDkcTA+3cF7nQrZYjU1tzXs5obz7IgAG5tzBdM0Ke/ejanpKOvWcCxx1Nqey6P19rNbpFBLeiWFVy15yGWacDjj6EIna8SIBGAsI3AYEXxYEUhrO8NsPVaNAmiL2kXFbGzeipT3V8Vqx4oVTBxK1zyfkN3IzU3oI6PEnCWer+uhtf/XXNt+XUV86m5agNyUA0lm4aoGyo8e4InmSUqSwfKkD+GyJnMRlzXJvKArwvaeKUzTZH57HZ717eRmTYqDahCX7Kqk+Xf4X9/Fs0XhxSwKz00bPtuJx+Pouk40WuulG41G6Z5eGDiRyy+/nG9961usX7+ejo4ONm/ezBNPPIGu66d9zJdL/iSF/c5GZu7jTLuf4lOb0DJZyGRJ/fo3aIcOVYQso78fcjmrYHPexDBMhCJR1jQSBeOk92K63WiaNQfZ1xPDKFt+1ZLDgW4YDM9ED2oaAaeo+Y4fmDxAvCWI4WimJI4jjTZSjriYTBVo8DkqKfMDyQGyRa2Sbj+lHSWRTtCX6EXTNVTJidt0V47d7uqgvbWDkl7CITnmXPeZ+t6cDi+nSJzNW4eTCcvOyy6jfPAg+niMCaoCqBQOM5kpVooTi0BVPDVTVasLM59nTLhwmAYRrOKGU0JFrqureNcDyE1NGJOTeEydordaH2JZS4ADQ1ZtnOF4nkVN1eKNM1qGEOByWJHFuRMiq0UozJjPmvcoGMScJZqnvaxfGN2CIluf/5BYiBBWoJ9/2j5DlVVu7Lqp8j0xTROX7Kag5xnKDFHQCpiYHJw8QEdgHnXuaqbIcLa6eNfsbWEkW10cm028GKcDK9NsqmDNqVyyi4AnyrCworiFy4UqqZSMUmW/k1mYOWeJ1RHfW8du+bTF6lgsxsaNG9m4cSN79uwBqPGVsTtHGxurUvWu7mfobFxGW7iTbcNb2HLk1wiX0xKdE0k6dwyzfKqeSMlh9cimyYqEjxdWhMmXDC5pWIrHMS0UvYhQDZDOl0nnqwUMbl7TQncsw5Yj4wRdErevbUaRT8uq3sbG5gyk8OvfUHji1wAkSuPkPNZg1EgkAEgrBqKur9K+WAySdAUJqW3k1H1IkkACFtU3kB+7oPLbfV5biAODSTLT/UtH9OTFx2xsbM49dvXFOTaW5op2L2pfPwByUyNSNEosVRtxFM8Wcd90I7mHfsrBZSZp1eDQ1EFW16+hzl1HWTM4PJZFmdeJqkgsmh9kty/PmMuamG2tSyJclp/ijMdiyKvyrgva6I5luHjBXKshIQTLIsvZGdtBV6ALn+qf08bm9eGv/uqv+MxnPsNNN92EEIL29nbuuOMOHnroodf93L29va/7Od5I3qj7UY4fx7X5eUrLl1Nat/bkjUwT3+bnkTJWgS8efgRm+a2a6RTp/fvJlCGeLYCuY6JSTmeIB52nvBefVkbKZDhoNFOSBQJw6UXi02OUGbKTeQ4erKZcHMjuJ15MgKKQWtyMqynAeC5NrlBkYFwj4KzOZdJFg2LRErFycoKf7nyIkaLlJ9voaOTwocO8Us6Vz9qJWRA2b13MXHUBxvve9yA1NiK3NGNks5ZYLSwBVDgcCJ+PqWyJzulgYylYFU+NtCVWm6bJkYLCL5VWZEzeW+4jQolEqL5GqAaQfD6UefNYqMc5VNcCWNHBi5urYnXfRJaFjb6KcDyZsYJsAm4VCZ0RLBuQ2YswxWCYvNOa96imQV7RkcJhYrlxelI9OGQJGTd+qrUwfK7aSOaZYwkhWBxezJ6J3eimxp7YbnpSPUzkY+wc38H7l/8Bqqwykh1hy8iWyv5LI0tPKVYnCgnr3lK95DTrOiOuKO6CB6lzHlI6g9LWxsLwIg5M7q/sF3TOzfhwOuTKnOzlRFafK7wisTqRSPCrX/2KDRs2sH37dgxjuqLltEgthKC5uZm3ve1tXHPNNa/91drYnEWYpsmjT/wrwwMH2SEr/H7TreyIPU65lEMAS3wLWHUgi1ezOiT1vJW43/VOijt3kZ8oEzP6MGIlEq55GG0muZJGLF0EE7pjGXb2TqFNe3tE/U78LoWheL6y6ja/wVf5W9rgZqTvGG67qKKNzVmJaZrE8jFciquy4l7asbMiVAMc2vdbWG+l5K8b9/K8KWMgkOoCSKaBmc0xIlpQOjoIEMTr7QdMXLKL962+k8d3pemJZajzO6nzO+lq8LG3P2EJEhE7strG5q1Atqjxqz0jmKaJ0dvL26bH+I4Vy0kXtEqh5hkyBQ0WLiPwv/+Sqf3fBM3ytRzPjVPnruPoWLqyz9KWAM6GeoY91QJnZWGiTk9so7MilxY3B1jcfOoCiZe0XMrK+vPwO2yh+nQJh8PIsjyn8OHk5CR1dSevRxCJRPjGN75BsVgkkUjQ0NDAl770Jdrb20/7mC+Xzs5O3O6z38Yun8/T29v7htyPaZoUNmzEEBIcPoznXe9EeOb+nhvj4+QVB4ROXdOmpb6eQ2UXqrIHZAXh9eDy+4jnC3R2LjrpvRQvuYTCC9vJOYOoCKJmkaa2KEf8oZp268/roCFQjRYcGhgklU5WHovIFO7BRnJCpWBKzAv5Kz6vpVQRV7mEiUEk5CHtSRH2WMdf17iOZdFlL/v1eiPfm9ebo0ePvtmXYPM6YhaLFH7zJMLrwXnllS8ZKDq7GKIUCqG0WqKx0tFOadt2xsV05sN0DboZsRhA8lu/swbQE8vSlivhl02eJ4wJaAiOSX4uNCZJ1lkZ3NPxdxXkpiaWXbCe4f2jpPNllrYELH/6abZ1T7JvMMH1K5voiHor44aoT6VQtBa3TROKZQPXtJ4x6XZRdlgR2CoGeVkgRSJsHbXEZFWRCItFSLOM7n0vUphwdcMa9k7swcRk29gLFQ/qgl7gwOR+OgLz2ND9CLppicaLQouZH1zAbweePOnxpgpTPDWwqcYrv8ndhJk2kerqUJqaaPA00uxtrhGrAyexJ5qJLgdbrD4pH/rQh9i8eXMlzWt2FPXixYsr9h/33Xcfd99992t8mTY2Zx/9iR5GRqzvhaZr/LJ7AzmnFfU8L+vmku4CYHU86upVeN5zF7qQeFhpp0fO0IgVaXR4sMB/JY8zmSnNqYoL0BBw8fuXzsOtKpimSSpfJlvUa/zfoj6VccnOdrCxOVs5ljjG432PoUoq71nyXkqDKb77020IpYs7tX7caPRoYxTjfvryConjDdS5StAUt4olAVLIjRq+vJIKd+vCd5ITAywJLyXsCnPnhSGOjWVoDbsRQnDlkgYcskR7xFNJBbSxsTk7MbJZMv/+HwB4/+ADyLPqzcxmcMpK9TeBkYFq/QvHihWMpIs1bctmliRHORhz0hluZDARJ54t4XHKjEVGWR5dzvO93ZTNMg7hZWV7CBSF0RBM11hECBCqE4Go2IC8HIQQJ02VtXn5qKrKihUr2Lx5M9dffz0AhmGwefNm7rnnnhfd1+l00tjYSLlc5vHHH+emm2561cd8Kdxu95wifmczb8T96CMjlDJZJMWa8jsGB1HXrJnTrtA/gKK8uCygJhJM6GEkIUCApKoIWSGeN055L85rr2F810GQJCSg0SjR2BjheFGQZRSVIE7JT1t9sCbzsyxKJ1xPGeHtR8pLlHXIls1KnR7dKOKWoqgEcDsnUWYVI+uKzj+t1/hc+KzZWe7nLqZpkvvxTyjtsURQubERx9KlL77PLBsQ4amKxEqHZVMxE1ktha0Fq6lM1ZZC+P0gBAdEgE0TDlxPHmN9s5spoU4fz8NgSeMikScRbgQg5FHJl3QKs3ymw14H77+8i7Fkga56L4os0RB0VSw/CiWd3+4f49Z1rZV96vxOpmb5Q+dKWkWsHpCrvtYODHIyxF06vUNWjYyg049BZ83r4HOeup8LqAEWhBZyLHG0plgiwO7YLvZP7qOoW+OgNl8713VcjyzJOGVnZXtQDVLUixT0AsPZoRrLkDZfG6vqVnN04iht3nbGimOcV7eqxmJEFjJex9xs1hk/byEgYovVc3nmmWdqHi9btowbbriBG264ga6uLpa+xBfExuZcRuvvp7xvP8rixSgL5iOEYOu+xypebwAT00K15PexOF6dYLmuuhLXzVY65bZjE/TErBQ8SRKYpvWDNHHCBBFAkQVr5kW4fHF9pdMWQhD0qATP7vGVjY3NCXQnjwNQMkrsGN/B0MZJkqYMQmZX3QLm5faQlkx6B+Oo6nw0Q2Y0Nw+/6SeHNUB1ilBFqFZkieWNLShyW+UciiyxtKXaN/ndDt5ue9zb2JwTlLZsRR+xUuNzD/4Y331/SOG3mzDTaVxvf1slcmpwKoep62i9vSSmUpQQuIJ+5NZWJrqnKscLelQOZX9Hzhzjp0fGcRZX0J+zoqrT+TJPHzuGX2pm88QjCFNmifs62iMeJguTFD0OSE5HeTmdIAmCziCK9JqU0rF5Bdx77738xV/8BStXrmTVqlV8+9vfJp/Pc8cddwDw53/+5zQ2NvKpT30KgN27dzM2NsayZcsYGxvjq1/9KoZh8MEPfvBlH9PmjaN88NCcxycTq7VZNaeEU8WcjmQULidmwZqD6CMjDIlpwQTwOiRyQKJgYJwkmAYsES3evgBGrEjEerNIuN7H8OBTFMwJZJys9d4+x6IwU87MOVbQrzM13W2MpwoVsbqkGagEqGM184JHiBVGAFAltUYEsrE5Vyi98EJFqAYoHz7ykmK1USNWV4UCqakRw6kyZaggyxV/6qlZkdVClpF8Xo7m/JilErphsvlY1bZHeL1MnreS8hVdGM/0AhD1OUkVyhSSVS0k4HbgVhUCswJg3nvxPPYNJtneM1UptDijhYCVPZ4vVK8lP8u3esCoZl84MCj6nIyXqlk965rW8ORAbVb5i0VWA6xtWFep/wNWgVXN1Gr6pKirjpu6bkaWrGMH1CCxvLW4H3ZFKOgFRrMjNce9svUqVtadRz6fRwjBjR03obpUHLID3dSRhYJuagSdoZMuNF28MEqmUGZxcwDPiwju5xqv6E5nXribb76Zj3zkIyxefGYXG/ne977HAw88QCwWY+nSpXz2s59l1apVp2yfSqX453/+Z5544gkSiQStra387//9v7nqqqsA+OpXv8rXvva1mn26urp47LHHXtf7sDnzKOtlMuUMIWeI4u+epbBhA6ZhwqanUOZ1EH/beoZHqgNEpasTNA3h9eCva2PpO9+NtmMXcl0UxzIrPU3TDV44bnWwQlidd66k84vtg5imidelsKwliKpIuBwyy1sDc3yXbGxszk3GcmOV/7d2byUTCyOjIBwOjq1YR6Z3Dz2Sj1KhRChR9YqrU85nXBxAdibxFhdUtrdHPbZ/vY3NW4jyLDFK6+4h9aUvY8QTAOjDw/g++hGEw8HgZA7t6FGMpDUJjAuVrmuvQQhBLF2NYprf6GLHcWtyNhRP46A6cQYYSo3z39s3gQkmOkX3bnTzAgbTA5afZTKFbII5YwHiskWlN4Obb76Zqakp/vVf/5VYLMayZcv4z//8z4plx8jICJJU/a0oFot85StfYWBgAI/Hw1VXXcU//uM/EphVgOuljmnzxlE+dGjOY9MwELPeU7NUQpsufimFgqhr11D47VMAOC+9hMKTmwDID48y7rXew6hZJOqVOQZoBiRyZXyzggELZZ3BqRwdUS/xhcthxKpvFSbHHrGTgmkJXTpFVHei5hoN0yBbtoS1Onc9eS1Htpwl6HbgdMgUyzrloof+iSw+l4OiphMkgFtVuXXBzfz06E9IlpIsCi9GEvY450zglWgy5XKZ+++/n5///OeMjY3R1dXFn/7pn3LllVdW2tx///08/vjjdHd343K5WLt2LX/6p3/K/Pnz36hbetPQJybI/+Lhmm3a8eMvuZ+ZnyVWz7K4EZJE9rJr0DcPoLS0VvqGVL6MphuVuYLw+0nkVcxyGRNqAvKEbNkObh+oisdRvxNJEpWoaUUWNVYWM3icChcuiFIo6zx3xKqJsX/2cXxOJpPV/WYXWRwpjIMkgWGgYlDwOsiUqqJyg6cOVcnX2Je9lHbS4GmgM9BFb6qHsDPC5a2X80h39fVWJaswoypXo5uDzllitTNMXs/XiNULQgs5r7728y6EwCFb1yILmUtaLmXfxB4ubLrwpNfVEvbwgSvO/c/3iZyWLD9TWHHevHnceOON3HDDDa/1db1qNm7cyBe/+EU+97nPsXr1ar797W9z33338dhjj82pUA1QKpW49957iUaj/Mu//AuNjY0MDw/XDL4AFi1axDe/+c3KY1m2PYDfCuTK1kCp3lOPbuj89NhDTORjLO0psW5zbbGh7EAvTz6xA8NhRSWsKtZxuKHeUqCB5dHlKF4fyhWX1+y3uz9OtmhFHixpDtBRZ4366v0LSBXKdES9yLaVh43NWwpT00hufZb41AEAhNPFwFgGOVAiHG9Fbm4mq5V4OuKmlNaQDJm60TJZ4cREoAQiLHRex9rOAM8diVeO21Xve7NuycbG5g3GLJbQ+/pqts0I1QDawCC5hx7Ccee7GR1PVIRqZJn89bdytH0Rz/7mKIlcNS3Y50/CrDTZMlmcqkydz8lwPIdpGuRNa3wkJHC7Czw/splEIV4pvnTBZJBtzVbqcaO36XW4c5uXwz333HNKi47vfOc7NY8vvPBCNm7c+KqOafPGYGSzaNMFUmcw8wX03j6U+dWCY1pPT0V4cixZgvPqq9FHRhGKwujqi0lu3s28fJye4QRmlzVPaTbzhLwKx6aPEUsVaZsuxmaaJg8+38dwPM/CRj95XwRkGcMos69tnATRGj9bw1GN0ARrzmViiUt+h48GdwMHpvaDgIaAk8HJAiohpjL9FasCh/AT8DjwODy8Z8nvM5Ybo8nuU84IXqkm85WvfIWHH36Yv//7v2f+/Pk888wzfOITn+CHP/why5cvB2Dr1q3cfffdnHfeeei6zj/90z9x3333sWHDhrPevuWlKG3fjlnWarbpo2MYmQySr3ZsP5kpMZox6Kr3VgosCtWBcNQKtskVa1FLDQiqXtOmaVmBNASt32s9ECQTM6wnymWY7jM6jBzD05Y9u3qr84y2iLvGSsPvcryoNU1zqBpoM6OHANT5nByW8pU+IV+yntNNnYlCDCHLmIaBwzQouBXS5XRlX5/qw+/WmJyVof5SkdUAb593A4OZAVp8raiSSqOnsRI0dG3HdYScoZr2wVke0yFXGEe59vW9tPnSlzzn6vrVrK5f/ZLt3mq8bLH6y1/+Mhs2bOCZZ56hXLbsDPr6+rj//vu5//77K+1OLKjxZvHNb36Tu+66izvvvBOAz33uc2zatImHHnqID3/4w3PaP/TQQySTSX74wx/imP4Ct7W1zWknyzL19fWv78XbnFFM5if52bGHKOpFLm+9AlVSmcjHMKam2D12jIAvhEAwubwVdyxFfzHGlFwCA4JlhYs7ryHrNxjMDCCQWHqSQh+abvD8sep355JF1eiTqN9J1O+cs4+Njc25T+HJ39L33KPoTVb6fUooZIUXyR+jIduIaGggTT8llxNyOULpMHdpQ2yVoxwItCIUhaaQm+aQD5gtVs/1Q7M5M3mlWWLf+ta3+MEPfsDIyAjhcJgbbriBT33qUzid1u+InSX21sPo7cHUrYmecCiVia7wuEHXMYslSjt2Mdo8Hz1bruwnNzYy1dDOrj0jleLNYNXKyJo9c87TFnbjdztwOSQGp3JIkkTI7SDsVVEVid2xXQgEwufDrUssS3nxN15KobGJldGVr/OrYGNzbqHHYujDwziWL58jPgFohw5XFGEpEsaYssYA5YMHa8XqY9WoTGXxIiS3G98f3ktvLMOPNvdR9izg+sIRjuYUzKIVJTnfyODwO2FaUxpLVcWg7vEMw3FLGDs6mqQsxSkvryOf20GiqwVJErgdTnKlEmCSZ5yyXuaFsa2EnGEirmqRR6/qo93XbonVWIXFikUn5Zxn9loZKoGKj6tDdtDmnzuHt3lzeKWazC9+8Qs+9rGPVTLb3/e+97F582b+67/+iy996UsAPPDAAzX7/J//83+45JJL2L9/P+vXr3+d7+jNxUgkKv87li+lfMDKnigcPcYjhTBl3eCmlXXkywY/eH4AHYkrlzawctoG5GQFVseShZl6pbRFvAxMWpZek5kiDUEXpmnS65HRRRnJlGlxCRyGidNIcqE+yX8ry2uOVx9wsrDRTypfFZ0DL1H7pik4t6Cp16lwMLGbZyd/zaQ7j4uLyZUsP+vJ/CTFcglkCcqgYFJ0yaSK1ahsv8OHz5mpEav9L0OsdsgOuoLVKObr572dLSPP0+HvYEFo4Zz2C0IL2RXbiSIpdAY6mSxUF+DWNqwj4JxbMNHm5fGyxepbbrmFW265hXQ6zeOPP86GDRvYsmVLpeDizErJv/3bv/Hggw9y9dVX8/d///evz1W/BKVSif379/ORj3yksk2SJC699FJ27tx50n2efPJJ1qxZw9/+7d/ym9/8hkgkwq233sqHPvShmujpvr4+Lr/8cpxOJ2vWrOFTn/oULS0tr+p687Oqs57NzNzHuXA/uUQCikUSmQSPjWwkW7Y67d/1P4NbcaPlC2jHu8E0eLp+CqlzHlK9Ch1R9KNTmKkCTk3iqsEg5o3LuLwhwk6xg1ZfK6IkM5mzVv1cDgkhBM8enSSetl63rnovfodJbpa31KvlXHpvTNO0i4bYnFPMFE498XNtmialHTsqfvcAad0HiokhDDyrRnEFJYbTfQghIUXC3CK14xs7ysX6BMON55EFVrYFqfdXIxa8LoU6ewHsrOCVRiQ98sgjfPnLX+YLX/gCa9eupbe3l09/+tMIIfjLv/zLSjs7S+ythT5LjPLccQelvXsxC3k873oX+tgY2e9+H4C+Az2YUrXIoXC72TeQqAjVfreDznovF3RFeGzw6Zpz+FwKfrcDn8MHZFjWWp2cLQgu5HjSisE0MZH8PjrPuxzvmhWcd9HFNZYENjY2L41ZLJL5xr9hZHO4rrsG9w030D+R5fBIinVdEaI+J+WDByvt3bfeSvY73wXTpHzwIO5bbq48pw0MVP5Xuqoi9q4+S9wWHg/PJevICgWRSuMzNdrNHGbIDdOaTN9ErjI+33K8GnwzzjYy+gC4IBBxIIV9qJLKRXVXsHnkOQpMoJPl0e5HKoXILmisio0+h482fzuSkDBMA0kSXDCvla7AQh7rHiRX0imWJDrd0ZpAH5szg9PRZMrlMqpaW0DO6XSyY8eOU54nnbbm1cHguS8Kmqlq5LC6Zk1FrD6yv5eegCUI7xlIMpkokt/XjSiV+F1uCa25MkFqLUBmGEtWLb6WtwYqYvVU1spc2Duxh1+o+xhpKdMytJwFbp31QUFOt6KN67zqrHAYuHJpA0IIQp6qQP1Shdr9bgc+l0KmUBW4w14Hu8Z3IksCXRQZE5t5IZZmdect7J3YY9l7yDIqhhUVrjqJ5a2MLofkQJWdNeeVpZNbkbwUIWeIGzpvPOXz9Z56/seKP0QWMg7ZgVtp59KWyyjrZc5vvOAVn8+myiu2AfH7/dx5553ceeedTE5O8thjj/Hoo4+ya9euyoR7YmKChx566E0Tq+PxOLquz5nIRaNRuqc9uU5kYGCA559/nttuu41///d/p7+/n8997nNomsYnPvEJAFatWsUXv/hFurq6iMVifP3rX+fuu+/mkUcewec7/ZTq3t7e0973TOSsuh/TRB4bw3HkKKbqoLhuHXIshueXj+ErFXnkQjdjTW5M1YEoFpHiCRKFAkLXkco6hjAx/H40RYGZlNr6OtzZAlfsNSlH/BxJJiGVImSG2Xo4ybfGtzEToORxCFoDMkcnp6OcgLq6IgcPJk96ua+Ws+q9eRFOHMTY2JytlJ99jtKTT+K84grcN99U85wxMsr4VJZftvow3ArNLVHcRxaRZgeyU0Np9xPLP0HBtAaurcFGrnrHvehHj+JJJPjgqjUUDVEpQtQYdDGWLLCq/eTFO2zOPF5pRNLOnTtZt24dt912G2BliN16663s3r27pp2dJXbuoA0MUHz2WRyLl6CuW4tpGGiHDiNFwjBtZacfO4YElCQZ16LF+M5fB0CqlCLjieJUFaSSxuBkBsNrTWQFYLodTBVHcRFFCImrlzWwoi3EZH6STDmD16WQL0gYlGgJW/stj67ghdGtlfRfp+zkbZ1vp32ynedHNlPQpyMzV16BM2IXZ7exOR20wSGMrBXUUj5wENfb387PXugjm8gylSly18XzKB+zFoiE24Vj+TKUeR1ovX3o4zH0kRHk5mZM00QfHgYsv+oZG4GSZnBszBpbCI+HzHRhRVIplhopJMAb8NCsuYgnIJYuMp4qYJjQP2EJXZqZJ2NWhXC3KqNKKrctuB0XURLlUSbMHIoiKkI1wNF4tbiZz+FDlVVavK0MZqxj+VU/EXcQv9uB3+2gydvMnYuqIrvNmcPpaDKXX3453/rWt1i/fj0dHR1s3ryZJ554ohIgeSKGYfCFL3yBdevWvSb11M70wK7i1BSGpiEUmfK8TjRDB8Mk1jOAtsL6HvTH0hi7D6OnDISQKAwOsUkPcYs2iKkoNQFxhmkyOJlG0wx8LoWoW6Bpli4xMpkml/NydOIoBSTKcpGikseXT5HLZirtWvwysemMraagixa/TC6XI+yCohkjr6dp9K17yUC8qFcmkakK56Y8TqqQQpiWcGIaJn3pIzywe5iSrlHWdXCohHJuTHcaw+clX7LeP5/qJ5/Powq9cp0et+N1fX8NDMpYAUZLfNb4pjirOCScWwGE8PoHEb6qUpLRaJS7776bu+++m5GRER599FE2btzIwVkruWcLpmkSjUb5u7/7O2RZZuXKlYyNjfHAAw9UxOqZdBSApUuXsnr1aq655hp++ctf8u53v/u0z93Z2Yn7JKtcZxv5fJ7e3t6z5n6MiQmKP3oQY2S0sk2KJzDTaTRV5YVAipSWwzss4dIkTKCoTKvMssxVY3XsaSgz0DWPkLuRpcHVRP0SOT3F/PMXELqmgFRfj1BV8iWdjXtGGSjk8Adq028mdAiHrP+vWlrH+Z1hXmvOtvfmxTh69OhLN7KxORvQdTKbnmDYnaft6SdRL1yPPKsAVWn/fp6XoySc3aB6KRU9tLatop0FKNFtCMUg7INc2YlhmNyyZD2SJCEtWVI5xuxv+/sv72IiXaQh4MLmzOd0IpLWrl3Lww8/zJ49e1i1ahUDAwM89dRTvOMd76hpZ2eJnZyzaRJhmiba889TfuxXlsXHtu142lrR9u2j9OhGhKrCRz6ESKcpj46SUjz8OHQe0pPdXLOsnvpIjl/2b0A3dfRFk6jjMpPJAqaewmWU8Zkl9qvPUzJS+M1O6ljLeHEPT+3Yg0NS0TSNOq8Dw1iM5jqGKoOmaUSVKF7JR6JkxVl1erso5ot0eebTPK+FA/H9CAStzrZXlEF2Nr03Lwc7S8zm1TAjMIPlV5tMpEnt3o+RTjMw1YSxyFfxqFU6OxGShLp6NVqv5V1f2rET9y3NGJOTmNNiijzrN+DoaApNn876mmUbYJZKLDesgBrhdrOiNcCBXmsetac/UeM1W5CHKjYhHtHI+sZlXDN/dSUl/vfWruPHR+aO6ZOlROV/n+oHoDPYWRGrfQ5fjWdsvdteeD2X+Ku/+is+85nPcNNNNyGEoL29nTvuuIOHHnropO0/97nPcfToUb7//e+/Juc/0wO7/H19iEIB3e/nyM7DBJxBWkd6GCt6SXp6MH0+8nFB3fAUZWXa8m90lMOmSkfWoCmZJD9Lq5vI6oxPWH1FIKQw2p8nkchiAntySYrJMXqk4yQKJQzDIE+a2MBunnAfJlA3yVXHvXhKkySSJSQB50fdHDpkFTnM6Tl09yaErtMzlkdKLTjxdmooJ0tMJBPklWFcWiOSc4iSmkA3TVxaCyXGSWeyTIgiJd2gVDTwl1bgbM6SCbgwszmYXsRTHA4OHjzI5ESJeMKKEFdKEgcPnhljiDP9c/ZKeD2DCF+VWD2b5uZmPvShD/GhD32I7u7ul1V84/UiHA4jy/Ic/+zJyclTVqKur69HUZSaVNj58+cTi8UolUonfRMCgQCdnZ309/fPee6V4Ha7z6liAGfD/eiTk2S+812kZApJmfU1mE6tSbhgf3MRh6QiCYnrYnWkHBq/bkiRkxw0lFWKrsVMRs5HTqvk0252xQTzG3zcdbEVscT0InJZM/jxtl5GEiUURUEI6KzzUdYNBqeqE7W1nWEuX9b8uk5ezob35qWwJ3c25wryyAibIuOMeTW8mszvPfsUsStW8PzIc+TKecrDezjWEsKQdCSniqxbEdEuyc89q97DMyO/IadluaCtiQZPI+c3r33R8ymyRFPo7F6seitxOhFJt912G/F4nPe9732WmKlpvPe97+WjH/1opY2dJfbSnA33om7fjuv5LTXbhp96iuLuA2zR6ggX86x68rcoDoV0Os1Wd5CkLKNPxfnBc4Nowa0IWaOkmRR0FeErITuPUDc4n8Z8FtMrkS6nAChyBBcunu4+ONsmFoBr60J0FyL0xntxSioTvZOUs2Xi04KTWTY5mJplR4A1Bjk8cfi07vtseG9eLnaWmM3pog9XI5ExTcaf34kxbYWQHZ8gc7xaUFVpbwfAsWY14pFHMA2T0q5duG66EX1wsNJObm2t/H9wKDV9aINA2MPMjLrFzBOajhwUbjdLgj7k6WH5zr44hmH1EB6ngi+SYGz6MqOs4up55xNwVj/z9e56XLKbgn5q8ciyFYJFocXsGNtOSS+xILSAgDPIFa1XMp4bZ13D+S/3ZbN5gzkdTSYSifCNb3yDYrFIIpGgoaGBL33pS7RPf45n87d/+7ds2rSJ7373uzQ1vTYFNc+UwC5jcpLyk79FXrIYZbpOianr5FxucLnpbV7AnoQLo3kd7ynkQAnhmZiEyUlMh4OY4sXhcCALgSEEmHAwPJ81XRGKnQsZmMyzuMlHsi9BOGS9PxetbGBlW5Atk70kc9b3vDtnMCiXEE4PklRAceuUwzlkoZAJKyTb3Fx0/kqWekOA5Ss/w4Gp/UQla3HK6VdZ1j63btdsPPU5thR+iCYmyDGCHPIRdoZAF2QHl+NxrsH0HCIcTpMrCDpyy3GrjbS3TpKQMzXHWhBawLKWZShjGY5nRwDoavKxbFnzq35vXg3nUgAhvP5BhK+ZWD2b+fPnV6KR3wxUVWXFihVs3ryZ66+/HrBSRDZv3nzKytTr1q3j0UcfxTAMpGnvvN7eXurr6085mMxmswwMDNiptGcoZrlM+fARlHkdSH5/Zbs+MUHmP/4TI2kNxOSGepyXX0Zp23a0/gF0TJ5f7aIQWYLTMFiVDdPmqieDQlzNkvPkUcT5PNNm+TrO/hJ1j2cYmsrRGvGQL2mUNIMn948xkrAGYh6nwu3rWumstwZfI4k8u/ri+FwKly2qt4VYG5tzFNM0MTCQRXVBNDtwiFFPCYFEVtH52fAvKfYMgCxjFoqkC0WyzizC4UBIMk6srIulLQGaA3XcFXjPm3U7NmcoW7Zs4f777+dv/uZvWLVqFf39/Xz+85/n61//Oh//+McBO0vsxXgjJxFmJoNZKCCdYsL+ovsaBvlfPIwZqs3EqjfhISPKhNfNBLBiKo8rOYrP72fE3Yy/pRXDqzAiXrDkJkPBIflxuiS08hSmUyPX0cP6fjfdHW04ndV0XPw9hEKhmvM1eZq5oHM9a4w19KR6qHc3EHKGqM/V81j/Lwk7w1w57yoU6dVPN+wJno1NFX14pObx+JYdwLRfr6YxtmU7M7NTeV4HAJLXi7J0KeUDBzGSKbTjx9GHqhHaSpslVudLGsfHM5TNLOPyUyyM+jA9KiInWKNXnWmF243TIdMeVEhCRagGOH+hkx3JJLIskI0gQWd4ToE1IQQdgQ6OxK2FK1nI6Gat1YPXYUWGehwePrD8f6CZGk7Zqrmxqn71K3/hbN5QTkeTmcHpdNLY2Ei5XObxxx/nppuqVnmmafJ3f/d3PPHEE3znO985qZB9upwpgV3p//5v6O7FOHwY9+rVCLcbI5mkNB1kN+KOoCgKZmMjsVgd+bKKNK0jGKUyJiCExGIyxFGJSU4m8NCjhHnmhREKJZ2hZJl8WUeZPuaS1igej8qytgjbui0Bu2xmMUwTU8gIIXCqedIGSJKJISRG/WXWRyL4pm3HZjMxPlE5dtbI4vF4KGoF4sU4DZ5GJFFbr6K1HkrSFBISYKA6BYoi0xnsYkyWccl+osqV3LUiwpGhEk9NF41tCkbIFGrHGVFfFI/HQ3NUQlEsH+uGkO+MeG/hzPmcvVpeb+3qdRGrzwTuvfde/uIv/oKVK1eyatUqvv3tb5PP57njjjsA+PM//3MaGxv51Kc+BcDv//7v893vfpfPf/7z3HPPPfT19XH//ffz/ve/v3LMf/iHf+Caa66hpaWF8fFxvvrVryJJErfeeuubco82L07+4UcobtmKFAzg/5NPIrndlA8dIvuDH2LmC+QlnX1dMuEbL2Jd+3rU9evZ99TTPFfcTqFOgkSSUMt8rlz5fhySgz1HY0QPjnNiSasVbUGcDpkdPVMAPHskRtirsqN3aqYINwCqIvHei+fREKym4DeH3DTbkY42Nuc0pmnyq97HOJ48xjXt17E8alXN7k8fhVC1XUoUkYaGyageGiazFHUXKCCcKg5F4NKtBbK1nZGTnMXmXON0IpL+5V/+hdtvv70iOi9ZsoRcLsdf//Vf87GPfayyGD8bO0tsLq/3vRjJJKmvfQOzUMD3h/8Dx9KX791sGCax/UdQCkVkRUGZ34XW3YOBya6jO+l1tKNo1uRhOJZm8cQwE+EW8r4gUsBFyvEshpZDMiRUEaCVq/F6skxNfQ+HI4dH0YlFvbgbFtZMJENeJ4qiEFAD3LbgHaRLKRrcDTgVa0yz2rem0rbL08VHoh+dMxF9LThXPmd2cILN6WJqGsbYWM22eMGAWXXDYsMTFbFaam0lUyjjVhXUC86nfMDKdCht314J3AGQ29oAODicwjRNkhzF7zFRHBoXtaWYdyBPs1ldwJop1DY/orBzqnruy5bU4/D0IKUFHVEvamEhb19y8szRS5ovoaSXaPA0kComORQ/VHnOJbtrFrpkSUbGLgZ8tvFKNZndu3czNjbGsmXLGBsb46tf/SqGYfDBD36wcszPfe5zPProo3zjG9/A6/USi1lipN/vx+U6+63u9LExtO5eAExNRxsewbFgfiV7AiDusH4HhdOF/nvvoXxoEDmWwIjFYJZPcqNZYL6R4THFiih+LKEgu61FocMjqcr3MuhxEJqOir52eSOLmvyk8mV+snMnmIAkQICs5IiXyuCwrFGH3EU4yWtumibDmWoGSLKUQDM0fnzkQZKlJBc1XcwFTetr9omXx3GqMsWSjiwLVNkaQywMLGSbMg5AvqQTddcxOFnNHqn3BTlWqDkU3umsjIaAi0sX1xNLFTi/y54/nW2cs2L1zTffzNTUFP/6r/9KLBZj2bJl/Od//mdlgjcyMlIzaWtubuaBBx7gi1/8IrfffjuNjY184AMf4EMf+lClzejoKH/yJ39CIpEgEolw/vnn8+CDDxKJ2B/8M4HyoUMUNz+P85KLkefNo7R9OwBGMkXh8ceRGxro3/gTZAMURfDEogL5FfMR8Z0MlMZwmg08nH4ewyzTUXAjCYmrWq7GITkwTZPdM1WxBSxrCZIraVwwP8rCRj+abnB0NE06X6Z7PDPn2oQQvPOC9hqh2sbG5q3BWG6U40mr0NHzI8+xJLyEQmyUAWcSGRVFdWIWi2gCukeSSGkfjqlFhIVGMjpOLmqwrr2dZZ7lRL0e2iJnv1Bj89KcTkRSoVCYI0jP2JuZ5okGDhZ2ltgbT2n3HsyCNbMqbdv+kmL1bH/j3+wfZctvj1GvdPBObRDvJRdjZrPsLR7n51GNjJmjdXAFkikzLDwswmRz0CTeNkHRHKYpYDLPHULCxfVt76DeGyLslBj621/wk9Y0JjDuKlEXkWFaxxISeJ3WlOHSlssJOUM1nrEn4/UQqm1sbEAfHcU0avvzpKiNWo5jiU5yYwPPDWR49nCMxc0B3rV2KSm3j2dLfjr29rNSsuYsUsCP5PdjmiY7e6cwTI202cci37QgVqfSbMYpCwNNMnHrMsLlglKJRp9Mi+liPK1xfleESxdF+f6hXwIQ8qh84IIr8aknt5jyqX5umW8Ffe2J7a4Rq0+1j83ZxSvVZIrFIl/5ylcYGBjA4/Fw1VVX8Y//+I8EZkXu/uAHPwCoCSoE+OIXv1gRwc9mSltfqHmsDw/jWDAfM1UVq6eEs/J/qmyS8/hR2nyYrS0Qm0BLpXBJEo0jgzSZeQJmHSnhALlW/psZG86r81a2SZKoPH62D4YnQCBAkjDULHlNg+k+p+gwmdASNKgNNcedKkyR16oWP4ZpcDxxjGTJ8rw/Ej8yR6weyYzQFnYznirSFPCBgIAaoNXXilOOoWEVfx1N5Dk+ZvVdfreDrroImydqX0P/rP7jyqW112Zz9nDOitUA99xzzykndN/5znfmbFu7di0PPvjgKY/3z//8z6/Ztdm8OKamUdqyFSOdwnXttVahoBehfPgw2W99G9MwyfYeY+iKJdRRxD/9ES8+9zx7Aym2tU5bf0TCKPMXIhRrEj+SHebY6GEM06oEkkwr3By9giaP5X/VE8tWvJs6633cfn5bzfkVWeLihVGe2Fst1iiEYHGTH0UWLG0JMr/BHnTZ2LwVOTRVnXzltTy9qV4mD/0OTTKRgaVta2kZzPFQthcl30Ig2URBCAqyi0b3IuoiLdx73lJkyY4oeqvxSiOSrrnmGr75zW+yfPnyig3Iv/zLv3DNNddURGs7S+zNRztU7RPKx469aLG9/MZfUvzd73DdeCPSpZexqy+OMTXFqHDxS7WNexYtRjl2nGN9R6yJqNAouNJ48iFGJTf9QZ1tjZMYfhkhZILuEAGXj3cuvKNGcA5GWwmWYyQcGgm1TCAAjpygrJlEPX4kSdDhn8f84PzX++WxsbF5EWYXV0QIME0SonaelBAqJWEw3OrluSMjgMKRkRTji+t4qm0tPb1jHMNPVzGJB5CnLUCG4nliqSIZBnA5wa1avxtpr0JJMvhZ+xg52eDtE42EFQVKJYQQvHt9G6asEnA7OJ44TqpkzbdafW0vW3Su99QKSjN+1TZnP69Ek7nwwgtfsvbZ4cOnV/PgbMAslylu304JiSOSnxYjT9P0d97IWGJ1EYmc5KjkGYwlC9WCqEJCikQwJAlRLFJnFpCAdUacTXIDTNtyKLKEphuV884Wq2fT0SixfVoIFpKMQ2iYmkZlxCLL9KV6aTjh+zuUGeREDser71u8aInZbqWaYT6UHcLvduB3O7h72fsZy47S7GtB0mScipip18qjO6sR2xcuiOJX5167z+Gfs83m7OOcFqttzk60vj5yD/0UfdRKcTNLZTy333bq9gMDZL/7PUzDxMTkifAIseN9+Jpl7hhoREKQlTR2RqaF6pZmq9iIgJAzREkvM5VLkSlYXaBfdBIoLKdcrHbgu/qqHm1r5tV6RM6wuiPMc0cmyBY1hBC84/w2lrbM9W+ysbF565A/ephDh3+D2RhFOKyf3L2x3UwMv4AxPdRbufgqhltDKM8cJCLp4AXh8yIFQwhJYnFjnS1Uv0V5pRFJH/vYxxBC8JWvfIWxsTEikQjXXHMNn/zkJytt7CyxNxczn0ebVSDTzOXRh0dQWlvmtDXyeQpPPQ2mSWHjRkbqOignU5hla/F8INTMQ3vGWRpsZbvTDdOFz3RfFqHVoxVNdoc8aKoLWZbxuxw0euu5ofPGOZHRSmsrkb79JBwauoBRkWJBg59s0eQT53+YtBaj1ddm21fY2LzJzIjVY8JJsmsJnd17K5HVwuXCLBRICJVNjVPscztIGgYt4koAnjo4zlBdG2I4jlkqMSVUPGYeucUSq3f0TE1bgBynyT8rctNlMuIukpOtudGBaIGVs65JlgSeaU/qXbGdle1rGta87Puqc9chEJjTZVxtsdrmrYA+NUV5337U81YihcOU9+/HzOV5Tm5gjxTCI+ncNzSMFzDTVjTxlFARjmo2xWSmeNJj1wXdqNPfp2VGkl1SmKyicOHCKIok8dyRWKVtZ93Jv2+yI4/XpZAtaCBJuKZ95c3ytHSsKPSn+ljfdGHNfkOzLEBmGEwP1DweyQwzP7QAAM3QiOUsq4+gGqrJ4MppOZr8Msez1n4Taet+XQ6Z1R1hFElClZyUjOrrYGdmnBvYYrXNGYU2NETm/n/H1KoFNkrPP4/rqiuRgsE57fWpONlvfguzWAIs36RxVwlMSDt0Ys1uWjQf28URdAFycxMNi1ZTMkpEXVGum/c2dEPn37duwC/ChFiEKoJoaByKZbjUMPnd4XGOjlpCt9epsLDx5Ct1iixxx/p2dvROsbI9RFe93Una2LxV0IdHMLIZlIULK2KOkUxy6Ef/j1zdBHIxi7JgPpjQt+cZBooFYs466swAz475OT6WRG6xxKo1nWF29yUqqXkL7KyMtzSvJCJJURQ+8YlPvGiRaztL7M2lfOTInBR+7fixk4rV2rFjzBS/MA2TA09uRdeqdmJSJELPeIbjRZm8wxKqVQwa6guURBh9dIwjPi+4rOH+nQvex2UL5530uuTWViJHHHT78giniiELXLJMW7CeiMdLhJNHXdnY2Lyx5IdGeHpayHJ459Epx9AQoCjIra1ox48zrpYpeopMGgplEcNARxIy3eMZNKlIfHEapTdDIqnSZuZR2trIFjUOj6QoMoUupQh5qvOugmoy5ipVHo94SxS0wpxrG82OMJq1ij+GnRE6/Cfvb06GQ3IQdkWYKlh1GmyxyeZsprRvH8Z4DOcVl9cIyyeS+9730QYGKe/di//jf0Rpm2VjOircIEnkDBgfTxLWNIy0pUfEhQpq9ZizXd48ToWUZgnJTXVVzcKByV1aH1x4I82Lm8gWNLYcm0A3TBoCLryuk8uCyWKSjqiXoXgOd0ngyFdPJptgKgpjuTF+fORBIq4IV7ZaRZWHTyJWzyxEzTCcrYrV47mxSoHVFt/c8dCiqANPJMjBkWxl27quCKpiBWx4HG5KxWkRW3bhkE79mtucPZyWWD08O/3oFLhcLjtKx+ZFMU2T8v4DlLZsQbjduN/1TvKPPFoRqmeiA0xNp7BpE47Fi9EGh5DcboTfhxSJkPvJQ/Trk/TW51kcWsi+cBomqsWo+pZF8S+9mp7ne1ECUTztXdyx6M5KQSCAQknHSK6iQRg4FAlVlkhqGgNJjX97shuDatTa+V0RZOnUUUWtEQ+ttp+sjc1bCm1omMzXvoapGygd7bjfcTvDQYNjzz1KbyABgDEVp+W8ZvoPbaUcm2BKBBA6eL1XV3zXwEpnu2Z5I/V+J7/eN0ZT0GX3KTY25xDlWRYgM2jHjsOVV87dfuRo5X8DODqSxCCNA5O3m2M823gReR001QBZwqOX6DBySOEwqBFEMknJZyI5nbgUFxfMa5tzjhnklmaipenoTHc1LfelvKltbGxeX0xdt+w23G4KpTLfH1OYkkIIpxMRCHDMFYVSCTkSqQT2JPyTGLKLkpAQQIkULqzM0DgHybhjGG1peop+zsNNqaWNn74wgG6YZBgi4nMiSQKn7KSoF0GS6K8HpvVqU5bpTnbT6e60jlmMsyuxk55kNWtkbcPaV5yJUe+ur4jVXjuy2uYsRY/FyH7ne2CamMUC7ptuOmk7U9fRhyxRV+vrR5+YqGReZV1eJH8IY2KCcVQWjo1VPKvjqAjl5GLs6o4QW45aEcpLFzTAr6vPuTAINlh9hNel8K717ewbSHDRwpMX7QZIl1I4HRLzG3wYUpHyVLW46/yMh+NhGROT8dwY47kxFElhQXABBd1azGrztTOYGTjpsYczwyf9v9nbPKetEILrl9Xj87h44fgkXqdSUzDRo3hJFBPWvdl9xznDaYnV11577cv68QkEAtx44438yZ/8CcGTRMXavHUpH+8m/4tfVKw+APSBAfRJq5y0XBfF95EPk/rSlzGLJYrPbqb47OaaY5iY7Aml2dGcRric9K1UQA8ipkQlaqk/ahIv7MOxdAkAFzVdjFNxYRgmQlgd3ws9kxXPpvPaQ/icCk/uG8bEMvFXFAkhBBcvjHLxi3TmNjY2bz1GsyMkN/2MOl1HQqD1D9D9H1/hV1f40EYGMFUrusFThCsSjXxnZISsUDCFIGBegBqwogdUReKm1S0sa7V+K8/virK8NYjLIdtp9zY25wimYVA+aInVwuVEOBwY6Qxad7flAalUh+WmaVI+cqTy+NlAmePR/QSTTaxLulh50+WsuWwZu/sTPN93mFxWpj6VRQBqKIgm5zFWLqFc2o9TCM5racPpOLWdkNzWRn2wBZhEjkYr28POk1uf2djYvP4Y+TzpL30Zs1zG+77f58meDFO69T0WXi9CSDiWL8fIZJBCIdwulVLYR9Y3RdYZRJq2G+tqMRmxAp7JmJaXrPD7ObjGwW3nv5/v7xirWAmUpHFa/U4EguWRFeyM7QAg53PA1PSFKQrHE8fodHdSNko80vsLdFHNivUoHhaHl7zi+50XmMfh+CEEgkaPXRTN5uxE6+6uhDuXtr6A621vq/l9n8FIJmsyrQqPP4Gp6egIisEIksuNwQQx4UIfHsbIzNiAOGsiq2fTFHJz35Wd7D1QoLM5RMnjxsxVCx3OXoxe2Og/ZcY4QFErVERnl+wiP6vIpUeXWDsVYLJLITfLvmffxF6OxY9V2i0KLyJRTJAppzmRifwEZb2MQ3YwnK2K1S2+1pNejxCC61Y0sbojjNcp41arr6nHUQ3s8au2X/W5wmnbgJyqqvxskskkDz74IDt27ODBBx/EPevLYfPWwkgkyD/2GJQ1TF2nfODgnDYzQjWA66YbkYJBnJdcQmHTU5XtmjDZEk3Q48uTkBTiQiEqqwSXLLF+BBSQ29tRe4YotkQpOQSTBasqQNRVx4q6lXSPZ/jZtgHCHpW3r2pmyzHreSEEF3RF8DgVDg/FyaQSBD0OGkNerljaQHPI/vza2NhUGcuO8ZM936GU2YuvQ2ZlwsfilJfno3HK3ePMznY7L+FDefTXrHb7+U3QJCqvwfR0ccWSOkJ+D131PgLu2oHn7EGYjY3N2Y/e31+ZNDoWLQKHQmnHLsxSGb1/AGV+V6WtMTGBEU8AIM/v5Hn1ILqmk4iMsOyS9+O68nzAyvhy+v1sUpvR+koIvx/hceM2UmSyVmZY0O1gUX3Ti16bUBTq//hPiOz+T7JyubI95Aq9hq+AjY3NK0E7dAhj2qf28Dd/xDaPlTLvwOSSpY1s0UE4nchOy1+6s97L8wtVRDkI03UyHIpEV5NJJuEgnS8jo6KJPGLaMvGnIweYzFjikKqWaQ+bqIpMvaeBRm8jzNjaetwwZdXwEbLMQHqAQn2B7mI3RVFEmRbjvA4vV7ZedVq1NhaGFiEJCZfiJuyyM7Rtzk70waoFhpHNUd6/H3X16jntjMnJmselXbsByCJDMFgRuMdmxOrUtA2I6kEIiZPhcyq4VfA7reflSAQtZ12PUGRQ1Tn7TOYnORI/jMfhpcnTRIOnASEEqVJVYG7zt3NMP4pwuzDzBUIlB15d5i7HxXjWvIPdsV38bugZAAq6Nc5p8bayNLKMY4ljNWL1TMaGicFoboR2fwexnNXReBQPAfXFa37VzfLTn8GjVMVq2+/+3OHkn/KXYP369bS2Wj9qLpeL5cuXs3z5clwuy1qhtbWVZcuW4Xa7MU2TY8eO8e1vf/u1u2qbswrTNMn+4IeUduyitHdfjVCttLfhedc7EM5qx6nM68CxciWmaaJceTlSxIrq0bva2HRTGz3rmtDmtdLvjZB0+ekLt1AfWIosrA5d1M0nu/hejihhDg4lGUnkEabg2o7ryBcNHtkxSFkzGE8V+N6zPZXqued3RYj4nLgcMu+5qI13n+fjvis7ueviebZQbWNjM4fu5HH04REwIaPobFvr5+cXwYSzDCaEygq3DNVzZ38jC1J+Jgoma+IBmobWEAyuRgDntQVY3RGeI1Tb2Nice5QPzhr/LF2KsmBh5XH+l7/ESCYrj7MHjzAo3BhAfnEn8WgEye9H1AWJrmkmV86xfWwbsdw4qWIS4XHjWLYUpc0an7u9SXQpjSpDS8hF5GUIP0JRqA/XWoWE7MhqG5vXFLNYBMN46YZYFmIAOoLfyE2YJcuH44pmJ5e8bf0ca8KFjX7Sog/hcCCmo6pbw27ixUmuX9mE0yER8pu4p7MsiprBnokdaKYlLl2+UsLjtJ5r97cTnGUDJLktMUgAKDImBvum9tJT6J7eLvHeJb/P/1jxhxUf2leKEIIFoYW0niKy0sbmbEAbqLW9KG3ZetJ2xtTUSbdnJAdSIIDwWN+5SeGkNDiMmU6jIUg5Tm0P6DvBe1oKV3/Dhdt90mzNx/t+xY7x7fxu6Gl+cvRBfn7sZxS0AqlSdUxS567Do3iRgpaQHCpN6y7T+t95dato8lQXxT2Kh7d33oAkpDkZWiui1fKsQ5khyka5InAHnaHTyiidHVlt+92fO5xW2NZf/dVf8f73v5/LLruMf/7nfyYwnRKQTCb55Cc/yd69e/na175GU1MTf/zHf8wLL7zA448/zkc/+tHX9OJt3nyMTAbt+HEcS5eesk155y60nt6abcLlxH3TjagXX4wQAikSIfud7wLgvv02hjKDbBrYRFEvcMW9t9AsR/jVxFNMFiaQqKOUN1E1EwkHIRYz0NvKLedfQFEa5be7oJSX0UwZgzJjiQJBcwlCC7DhwBD5UjVNbSZBwKXKXL64/jV+dWxsbM5lBmPHMCamMzMUGbmxkaIkkHIJjGyOiyaCNHkaEJEo3+vTGBdOFhoZEuEGhKoSpYDrRdLybWxszi1mLEAQAscya9w0U59D6+sn/S//ive++xhxBXlw2ygZpZ2lRoqI14uWEgi3m4DHwURhhD0T2+hL97E7tosGT2PlHF6Hl2w5S1mkuXRZlG19Cg5FelliNViesb2pnspj27Paxua1o7htO7nv/wCv6sBcuBA8L16TYkbMGhZuEsJa1G6WNS65+10oqsK8Oi/d41bktRCCprBEybQEJqcI4/NohDwKk4VJliwM0F6n8M39bnpjhjUfMiFXKpEUx1niP5+Edrxy7g7/PILOqo2nCPgRssTChIvexdbcf+fEDsqmZXe2NLKUqNu2S7R5a2OWShijozXbyseOo09MINfVfj+MyZOL1fnG1kpUtXA6MYpFxvpHaTA1EqgwXbCxzu9kIl2kZCYpYn3vs3qEkFz93kqRCPuCaWKuEpdIYU405s2U0hWf+BmGs0M8dPTHtHiri0YBNUjIGSQTCKCPjhOq1Liw+jBJSFzbcR0/O/ZTdEPn7Z034nVYhZnDrqpYLQuFFXUr2TFuFZIcy46SKVVr95xuVHTEVbUvq3fbms65wmmJ1V/4whfIZDJ84AMfqAjVAMFgkD/4gz/gIx/5CF/4whf4zne+w//8n/+Te+65h76+vtfsom3ODEzDIPMf/4k+MorSOQ/pDz4wp42RzZLfsKHy2Pu+9yLVNyDXRRHOagqHY8kSfH/xZ4zkRtlRPMLB4wcqz/16ZBNuxU1OywHgVtw0qBdhzkp/0XSDTfsy3LR6EcVCH0JAVFpCzNiHkwjlVBcPbKoOwLxOBVWRiGenIxSWNOBSbdHIxuatjGkYaD29yI0NSL7qYClRTPCbvicIOINc234dsiRT0kuMDhzAnI6gvm7ezTzrLREvTqEsWkTbjn5a8i5ct15H71SB8X6rUNoxyYejoQEDaPLbfY6NzVsFfWoKfXSMOA6M1nZCXi9CCHz33Uv2e9/HSCQxMlle+MGjPD3/QgpxK2X2sDOKPitVuCHg4mjiKJN5a6Esr+XpT/UD1mRxaXgZ28e3AdCTPl6JUHq53tOzxSavw4sqz00ZtrGxeeWYpRKFjRsBkMfHKf3kITwfvG9OFKHW3QOyhDJvHkbciqyeEipIEpgm665ehzIdLbmkJVARq0MeB0kthkORKGsGbupZ1+YgVhwmr+XJlXNky1Zbp0PCI5rJmWOAQcrspjl8MQNpKyJUlVQavY3IQsbn8JEpZxAOB47Vq1gbvY6AmmDf5N7KNQsEFzRe8Lq+fjY2ZwP68HDFh1qoDsySZatV/N3v8LzznTVtTxVZnW9tr/wvPB7MYpFx4aLBLE77VVu/y/MbfQymRhkynwRAlgU/O36Ma5uvq+w/5jd5IWrZh0juOLVXAKO5qrDe7u9gMj9BTsuRKCYqBQsBAmqAkDPM0LT2Fz5JQeawK8L7l/8BpmnWjB1mZ2jVe+oJqIGKFUiylKr0S3D6UdGdgU6uaL0SgaDd33Fax7A58zgtsXrPnj0A7N27l6uuuqrmuf3791eeA2hrs9IJy+UyNucW2sFD6CNWB6f19iFv3w5eawVN6+4hv2ED2uBQJXzZsWI56po1Jz3WVGGKDQOPkCpZnalhmIwkC5Q1g7aIBxNLqParAW7ruo0fPjsBlJElQUPAxUgiTzJX4ld7RirHvHvttQjlEn61c4riCR+/W9a2Uu938tShcfwuhbXz7DRXG5u3Gvsn9rFl9HnW1K9lXeP5FB77FYVNTyFFwgQ++b8qC2rPDD7NaG6U0dwoLd4WVtStZDgzhBaz/NWa8k7aL3kbdwV87JvYS66c4/yVH0LJl5Dr6zn0zBHAEquF04kIBkHXafLZntQ2Nm8VtIOHmELle45OZLWdxqcPs7zNQ8gVwv3+DxH58XdJjk7wRFyB/QcqNgFSJEK8PA6A26ngcypM5GM1xzax2vodAZZEllTE6pmCRw7JgfdlRivVe6oRSXZxRRub147SC9swMtnKY+3gIYpP/hbXdddWtpX3HyDz7f8GwP8//z/0aTErrnpR164Dw6Bx9aJK+8VNfn4lGRT1HA2BZkayfXREPUxmSvzektWU5QliMatw2WRhAs2wskudikyJELJQSZt9GJSJsaOSit/qb0MW1oJ60BkiMy0mSaqTxs4VtEoKYVeYTX2/BWBJaCkB54kxmzY2bz20gcHK/86rrqK4aRNmWaO4eQvq+vUordVo5VOJ1bm6ZpjWb6VIBCMeZ1y4MElyRPIjpiOrW8MeyvI4WMkNqLIVyLd1bCsrzBUAHFSr44VBV56yUcYhVa0HR7NVsXp1/WrCzjCPdj9CvBivbBcIgs4g59WvYjg7hCfjpr44c4zaOnazjz1Dg6ehIk53BjoBS9Mp5mNkSmmSxardyOlGVgshWFU/1xfc5uzmtGbKwWCQ8fFx/u3f/o2jR4+yevVqhBDs3buXxx9/vNIGYHjY+oGMROwiCecaxWefrXlcevwJxE03ovf0kPn+DzDLWuU54VRx33Zb5fF4bpxNA7/FKTtZ07CGpwafIj0tVOuGSe94HrW4BCgyIvXSHvUQcUW5bf7tFIsOkjlLlG6LeLhoYR0PPm9F7s9ESjsUiUVNAVQlROtVUXb0xskWNYSA+fU+5jdYHeGta21PNBubtyrbxraR1/JsHd3CefWrKB+yUvSNqTjFZ5/Dde01jGZH6U9XM4N2ju9gWXQ5A907MYtWf9NevxApFEIC1jSsrZ7AB8WyztGUhtzSgjE5iTKvEyEEDkWizntaZSNsbGzOMEzDQDtyBKmhAfkU493ywYP0SF5MwAi5eCH+M7bEyzSJy/CKJq684FoSGx+3pn2FAsuMFGnVzXhrK6Xpxa6GgHPaMPbkBJ1Bwq4ITZ6mmmipsDP8sj0gA2qAZZHl9CS7WVW/5uW9ADY2NielfyLL747EWNXqp/2pasF4pr+PhSeeQL1wPZLfbz3etKnSRDt0GDORACDhCSJkGWSZqG9WZqoC/uadxJMjRBquZDgzjN/twO92sLqli+5kVUiazE+iTAtJLodMHg8+WkkzPYfS+lEVa1zSMSsyMeQMMZSxBLiAGsQhW8dYVb+asBxh+6FtXNJ06WvxctnYnLWUdu/GLBbR+/sr2xzLliIUmfwvfwWmSf6hn+L7xMcRkvU9m8maksIhEAJjKo5wucj6gpCZXiCKRhD9/YyVXDwv1dEt+VAcDlRFoiPqwaGWKmK1W7GinBOlOMOlETq1LnpEVRDXnQr9qX5ciou+ZC+r6lczkq0G+jV5mnAqLn5v8V0cnjrESHaEqcIUC0ILcCkuXIqLu5e9n8wWg/K4VYNDbmh4yddGlVXuXPRu4oUp5k2L1UE1yEQ+holZM17xq/5X+MrbnMucllj97ne/m6997WsYhsHjjz9eEajBKqYnhOCuu+4CYNP0j+7SF/E0tjn70IdHKB87XrPNzOXx/uhBih4P8nT6i1xfh7JoIc7LLiPrkyllEjx5uJ8dU0+ApOFyyByd6rUKfQjwyCGmJluJFsPIwkofKeSjnF8fRCm388zBFKZZHXjNb/TRVe8l6ncymS5Wti9u8lcGXEGPyjXLG7Gxea353ve+xwMPPEAsFmPp0qV89rOfZdWqVSdt+/73v5+tW+cW2Ljqqqv493//dwA+/elP87Of/azm+csvv5wHHnjgtb/4tzhlvVypTK2bOsOpQYKxavRBYdMm1IsvYtto7XuWLCU5njhOf/fOyraO8y4HrN+/rd2THBtNk8pbmR/1fheabqK0t7Py0vMYTxUYTxZY0eJHEqU34E5tbGxeb4pPPUX+l79CeNwE/vzPkE7woTULBbTubsZEI8LpJOOOYZhWyleSo3hpYnPGgVnXCfEUArhEn0C5+ia+k5Ep6WkcikTI8+KWHAGnlZ67LLq8ZvIXUl9ZhPS1HddhmteeVpEjG5u3MqXduyltfQHn1VfhWLSIx/eOMJEuMni4jz9MJJEBeekSSpkMDA5hGiZ6/wDSiuVoAwNofVWhq3zoUMVOIOG0gmycDolnRn7NeG6MK1qvYjQ3giEnaYt4OJzcXYmcjriiuBQX0Vk+rpOFyYqHrNMhoeBCFUE8NKLJscq8yaN4mR+sFkicXWSx7gRP6qgrSruzA0WyM8Vs3rqUjx0j+70f1GwTiozc1ITc3Exp5y700TG0wSHSX/oyyoIFOC+5BDNfAECORnFeew3Fp55GvehCMvFqfa2Q18lUYxOxwQFisrVQJVQHt5/fhltVkJWq/rE0eCE5rPnJkcIhwlMhTKcDpaMdI51Gbmpm1/gOYvkYuqkzmBlgIm8J5mFnBKdiFUtUZZXz6ldxXv3J57Seu95N/qGfIkUiyB0vz3Ij7ArXeFcH1KqV8HBmqPL/6UZW25ybnNYvy8c//nESiQTf+973aoRDsELw77nnHv7oj/4IsCKsP/GJT3DhhRe++qu1edMxMhnK+/ZR2rWrss11zVXkn3uOSTkPyTSm4gBFQSxbjO+e9yM5HOyb2MdTB37L0FSeWKow57iKLKj3hfDnV6JrKvKs+ZHLaKanz0vfxOSc/RY0+BFCsH5+lMd2D1e2L2+1U9FsXl82btzIF7/4RT73uc+xevVqvv3tb3Pffffx2GOPEY1G57T/6le/WmOHlEgkeMc73sGNN95Y0+6KK67gi1/8YuWxqtp+oa8Hs33YAAaGD+DXdabUMv6yglooMvDkw/S1WQK2Q3JQNqz3b+vQc4xPWb6OEcNFYNU6AI6Mpvnt/rGa405lqoL0us4wDQEXsXQRn2Jw5PDcPs3Gxubso3z4MGAt2pe278B1xeWV50YTeYy9e3FrOqOKCykUIi91s6DOR6FskCkk0PJ50NyYbfMgvo8FRopgSz3+qy7hmoF+xg87aAw6afbWRkwH1EDFPg2sSCWAhaFFPD34NNp0uFXoNOw8bKHaxuaVUT56lOz3fwimiT48jPzJTzGRLmJqGoW+fhKoRCnhuPJKtD27YdASaLShIRwrllP8XW3GarF/AAkoI5FVXCiAy5PmWMLKtNjQ8wjSrPo9M2MUgGZvMwARdwSBwMRkMl8dc8iSwO/0oZcgymrw7qbJE2FpZBmLwotr/Gbr3NUxbYPnpaMobWzeapQPHJyzTW5pqRRJ9NzxLtLf+H8A6BOT6BOTlXEDgBQO41i4EMfChQCknzhi7ee0iqgmkvUwOFBpf9X8EAsbrQhkIVvWPQKZ+YFFTCpjDCT7yehZdkxsR1EUlJYWFEmhbJRrxhCxWZZiM33Gy0HyePC+/56X3f5kzI6gnj2OebmWZTZvDU5LrBZC8JnPfIa7776b3/zmNwwMWF+ejo4OrrvuOjo7Oytt77vvvtfkQm3efLSBATIP/BdmLl/ZJlxOXNdcw2+Doxw8+hxyNMdFGRcjiyOMLE3T0f9LLm25jGeHngETErmqcOMSdXhpJm4eAt2BkjoffTqaOuhRuX5lIw9ttT5bfRNZTiTocRD1We1XtgV5+tA4uaKGx6nQWW93dDavL9/85je56667uPPOOwH43Oc+x6ZNm3jooYf48Ic/PKd9KBSqebxhwwZcLtccsVpVVerr7SrGrzcnitV9saPkIyn2hjKEygq3Dtaz5dhvKHk6UNxO1g2YHHElmGr2MdG9G1O3oh7aGxYjVBXDMHnqYFWodjlkCuVqZETEp9IcciOEoDnkJpfLvSH3aWNj89phJJOUduzAcd55yHVWhKFpmujD1clfads2nJdfhplIcDSp8bNdI+i7DnGz8JIRCmZURXak8bv9+N0Q9qpMjA6h6AsRHg/KooVcoE7gvfFqhCTh9xfoarCiIeeHFpApZ6xiZ0hc1XY1j3Q/XDl3cNozVpVVFoYWsj+2D4CI7T1tY/O6ok/FyX7v+5U6PUY2R88z24A6tN5ezHKZceGiadl8pI529OFqJKE+PIyRTFLevbuybQqVh+U2NARX6WMIlxXxKKupaYd6C8Oc/ajKjPDkkBwE1CDJUoKpwlSNCN3gCzEypaEKPzfOv4s1p6jf0+ZrZ039WnJajpV1553Oy2Njc06jHT8+Z5vc3lb5X+nsxPuBeyg+9TT6wACmYWIkqj7N0qwgJ8MwyRSshWa/S+GKJdYCUXwsjD4wSBt5Ll5lRTObpokhrCBABTc+l4OF9RczkKxmaAB0BObhll0cih865T00eZte6W2/KoIn8biXhVKxMrGxgdMUq2fo6urigx/84Gt1LTZnMFp3D5lvfQuzUE01QQhc119PVirT68mirFhOPB5nq9+P4nSBgP50H0NHBtFNnXxZR+g+HJi0+Bt5/5pbmEhpdI+vozeWRjesKJ4lzQFuWtOCyyEzv8FXqXINlkf1RLpIoayzqqPqwajIEneub2dbzxRrO8PIkh0RZPP6USqV2L9/Px/5yEcq2yRJ4tJLL2Xnzp0vsmeVhx56iFtuuQXPCeniW7du5ZJLLiEQCHDxxRfzv/7X/yIctoWG15rErMIhABPpUcZDVl+TDDrYVJ7igFtn4Pg4Xl3m97pdON0Fft1ydGYuiikg13gxvz0whiSqUdStEQ/3XNbJwFSOX+8dZSJT5PIlDXakoo3NWYxpmmS//d9og0MUn/kd/j/7UyS3GyOewCxUM8b0kVHyP/s5hS1bedzRRdkbwihrbJIbkcJh0r4EHmd1+K3IglBkgnLMiqhqnNfM4qsvr/QXU7OiIaOuOi5tuYznRzazsu482v0duBU3ec0KIgio1cnfhU0XMpoeRXU4afXZ9TlsTs0rsTQD+Na3vsUPfvADRkZGCIfD3HDDDXzqU5/COV2UWNd1vvrVr/Lwww8zMTFBQ0MD73rXu/ijP/qjc/Z3MPejH9UE8wD0bD+I3rQIY9qXdsLlx3PHHRQAMxBAOFXQDfThYUrbd1QsP8qSxEaphZSw+oln5IZKwWdTTnIiATVA2Bmmb1Z9jZZZ3/kGTwPJUgLd1Bid9qeVhUJrKMDI1BRCwLw67ynvTQjBZa2Xn/J5G5u3MkYmgz5iLVhLEWu+ZuZyONfXugqoK1eirlxJ/olfU3ji1zXPSZEwU5kiewcStEU8FeeCGf/5t69qRFpyI8VNm5Cbm5Gn54VFvYjPLRCSwCm8LGryE3BHeHv7jTyXexZFVVBVlUtbLiNZTNaI1T6Hr1I4FaDpFURWvxb4Z9mAzOBz+M7Z3wib0+NVidXHjx+nr6+PVCp10uff+c53vprD27zJzPiPG7kcmW99uyJUK/O7cF5/PWZDBE3189jh5xhPFTANHd0AFAWEtTIohEDHii4sFBVauRxJcvD2Bc3MiwaZF4Xzu6KUNIOeWAZZEixoqHZUF8yPVsTqqN/JXRfPwzRNkvky9X5nzfW2Rjy0RmqFPxub14N4PI6u63PsPqLRKN3d3S+5/549ezhy5Aif//zna7ZfccUVvO1tb6OtrY2BgQH+6Z/+iQ996EP86Ec/Qpbl077efD7/0o3OAmbu49Xcj2kYCEliPD2OpmlWFJQQ6Nks5nSEktTZyaBjiMmUhmEYOCbb6TYKLE5r3NYdJe4sk3UYHFv+NnbHAhAbrTnHxV0B8vk8dW7Bey9sRtMNFFmqiaZ+Le7lTOJcu5+Z3z8bmxm07h606bR9I5Ol8Ktf4XnnOzFGR+e0LT6/hePCx5SpVIokpSQVx7wOMubTtE2L1UE1RLKUQHVmUYOjpDMerl2+suazN1GYqPxf567D4/CwKLy4sm1RaDF7JnbjUTyEZnnLBpxB7ph/JweLB5HE6f9+2JzbvFJLs0ceeYQvf/nLfOELX2Dt2rX09vby6U9/GiEEf/mXfwnAf/zHf/CDH/yAf/iHf2DhwoXs27ePv/zLv8Tv9/OBD3zgjb7F1x0jk0Hr6QWgJ9jMfncjq8eOMFAAra8qICfPOx8pEIBcDoRAam6GwSGMRJLS9u0AmMAziy9l6vh4Zb+MUFCnxeqiiCMDAomVdSsZz41xZdvV6KZeEat9Dl9Nin2jt5GjCctWQDf16TZeLllQDwiaQi7CXttyzsbmdNBmzfvU887DddONYBgVC5ATUdetnStWR6Ns3DXM4FRt1mXA7aAn2cOveh+j2dvM7Te+o2Z8kC6lcTokVrYFWRpZQMBtFT+d559Hzptj2cJllaCogBog5AyRKCZYU7+WFl8LG3s2AOCSXTXjhzeCkxVS9Kt2ZrxNLaclVg8PD/Nnf/Zn7Nix45RthBC2WH2WYuTzZO7/d4x4HN8f3mulr01HDTkWLcTzBx/g8eHfcOz4MeLj7YwW+imZOQzTwJmZj1sBlQbSGTej5nNIskHYq1JvXERJWJ3oosbaDkpVJJY0z11h66r3ctmSesaSBa5d3lgp/tHgsCdeNmcvP/nJT1i8ePGcyKVbbrml8v+SJUtYsmQJ119/fSXa+nTp7e097X3PRE73flxPPY164ACFiy7i6MIU6eGjyBMT6JEIUiaDKBZBCEqFPEQjpLMJ5JyEY8rLzrp6wlIMDh+l7PRx7IKrOZgMAYmac7QHZVKjvaTm6lev6b2cqZxL92P7xdvMpvjMM7WPN29BXX8h+sjInLYmsE2OAmL6EcgtzZTVAmUzjUcN0uxtYWFoIc8MPY0kCQgeIBiEp2IH6C/N55LmS1AkB7GcJVq5FfdJ02MvbrmEBk8Djd4mZMkeG9m8Ml6ppdnOnTtZt24dt912GwBtbW3ceuut7J5lYbFz506uu+46rr766kqbDRs2sGfPntf/ht4E9MHByv9PRxaRC0bZXewjGT5EINlIINWI3NjApDdSiZg0TZPuUCuhwRhRSuixCbLIPB1eRK8aBcZrT+J0opslNDLIyNR76rmy7aqaJotCizmWOMrq+jU12xs9c4vMex1evE6F61e+san/NjbnGtqxqgWIsnABQpJAkk7ZXo5GUTrnofVWF7KMYIih+MCctj6Xwr6JveimxmBmgEQxUVOkMD3t9SxLgrBrro4yG0VSuHPRu0mVUtS7LbvJzkAXvakeVtStfMMDNBRJwevwki1XrV7t4oo2J3JaYvXf/M3fsH16Bdjm3KP4zO/Qh63JV+4nD2GWqj7T7ne9kwktwfHEMWKpAsP56sDTaYZxl7swkyF0RcEjoJnLmDT2oacbKFKHENAUcuOfXvl7KYQQFa8mG5szhXA4jCzLTE7WFsibnJykrq7uFHtZ5HI5NmzYwB//8R+/5Hna29sJh8P09fW9KrG6s7MTt/vs9wDL5/P09vae1v2Y6Qy5wSEIBDEPHkSJSnhSKdySm1I6iy6g7HTjLy2kGKijoOeRIxJ18lK8qztIB/yYa5t5eGsfmikQikIYEALO7wwznrIyT248rxGf66V/Wl/NvZyJnGv3c/To0Tf7EmzOIPTJScoHp9NnhbAyMkyT/MMPI/mqk6uZCWiP5OLo/BJqIEJkxEVJciC3tjDBFhyKhEORWBRaxKLwYraNvVCx8QDIaTn2T+4jXoizNLKUgm4FC7T4Wk86mXRIDpZElr6+L4DNOcnpWJqtXbuWhx9+mD179rBq1SoGBgZ46qmneMc73lHT5sEHH6Snp4euri4OHTrE9u3b+fSnP/2qrvdMzdwpd/egaRplBCnFheRykWpIoGllEuExAvWXQChMJl9kbCqFA42dIyUGsz5cchv3FI+hIfEj5zyK3nqk6ToY84wMfZIP4VDQDYOiNIkXE03TCMmhObUvLm+4govqLsYhOWqe85heDM3AmOV27TDV16R2xrmWVXUu3Y+dIfbGMONXLSSBMqtu24uhrltbEauFU2XKUCoLWbMJuBwcTlaLIGbLmVqxepaNx8kilU/EpbhwKa7K45u6biZXzuF1nNoG6PUkoAZrxGqvHVltcwKnJVZv3boVIQR+v5+bb76ZUCiEcopUB5uzCzOfp/hstRq1PlZd2XcsWYxcV8f+gSfRNJPR5LRHo4DWsId2xzKOzHKEifqdOJUOfMkGdKPaAS9ueunO1MbmTEZVVVasWMHmzZu5/vrrATAMg82bN3PPPS9eHfmxxx6jVCpx++23v+R5RkdHSSQSr7rgotvtnuONfTbzcu/H1DTMYhHJ66V06HDldyov65TGRxFCIlpWcRdkjvlzJPQgRX0VYiKC8B8gKDcQipxXGexv2BtDON3MXmp723nNnN8Ved3v5WzhXLkfe4JnM5viU09XCqe5rr+O8q5d6LEJtJ5ehFPFAHodQebd+R48Tz/Js+YUKXUUQZIrb7iB7v4QE/lxsuYwIaeKR/GyNLoMh+TgfUvvYSgzSKKYYDQ7ykB6AN3UGM4OMZGvWoCsOSFa0sbm1XI6lma33XYb8Xic973vfZimJZy+973v5aMf/WilzYc//GEymQw33XQTsiyj6zqf/OQnX9a458U4UzN33Dt24EjESUguUpqGkYiT9wjQPZiygkGOVML6Tdmy+xB+p8ThWBkMg1JJ40hWY0zxkRQamiRQC1muzPfQnI5xLLQaQ5YpJxLgGUBOJADIlrIcTBx82deopw0SWqLyOJ6PczD98vd/Kc7U9+Z0OVfux84Qe/0wNQ2tpwc9Zv1Oyx0dFW/5l8KxejXi4UcwNR25vp6xVOHk7RwaOa26qJSZJexCNbIaTu4B/VJIQsL3JgrEATXASHa48tjvsDUim1pOS2H2er2USiX++q//mltvvfW1viabN5Hi5ucx8yfvMJ2XXMLRsSl+dXgHmVIRY1qAjvqcNATcvGP+Oo5IvQSbWmiMBKib9pQemMzy0NYBCmXLJ22hLVbbnAPce++9/MVf/AUrV65k1apVfPvb3yafz3PHHXcA8Od//uc0NjbyqU99qma/n/zkJ1x//fVziiZms1m+9rWvccMNN1BXV8fAwAD/9//+X+bNm8cVV1zxht3XuYJZLpP5f/ejDQziefedaMePE3eU6fcWCJSrP33BssK6qQBtORcbtaXQ4kUx6hCpK2k4Qa+c6fMaAi6WtgborPPSEj77hVkbG5uTY5omhccfp/j8FgCEQ8F52aVIoSC5Hz8EgF4ssVFuodfbiH/nOB95xzvpfeIbiLIVhD1Y3MXi1hs4cmw/AB6nzPqm9Tgka9nLpbhYEFpYOWdPsrviI1kyrIyNJm/zG178yMbmZGzZsoX777+fv/mbv2HVqlX09/fz+c9/nq9//et8/OMfB+CXv/xlxdt64cKFHDx4kC9+8YuVQouny5mauZPfsBEjFCbtDBFsbEQnT1KogIoAVnUFONhtzX18dRH6JtKY5PDX1WEMD7C/XpDVZZwFD57mFj54dRfO3EH0IwXmKTqjoSC+UAgzIBEIhQBYv+BCws6XX3w7PjLF/vi+yuPFjUtYFl326u/9HMuqOpfux84Qe+0xy2WKTz1N+cgR9MHB/5+9Ow+PozoT/f+tpXe19t2SLcv7js1uIMZAhrAnYSAkA5nLcLMwYSbbnUwymSTD/ALMZCa5mIQ7IQlbCIEQCASCQyDsAYMNGO+7rMXat1bvS3XV74+SWmpLBlu2LKv9fp6HB3V1dfU5svp01VvnvC+Wkc48p8+eddjHUT0evFdfTWLDBtwXXUjXwNixl5SSXVA1MmImNUA4OWJm9RRMoZF/UIB9MgPn4sQ0rmD1JZdcwq9//esTfonMkVa3DgaD/N//+3954YUXCAQCTJs2jX/5l39h1apV4z7mVGIlEsM5GRUFvX4mxj57ZkWwzMu7jigvvP0ifaZ9hy9PmU5aDVFVYDG3aC5e3YtLV5hZ5sPrHb6zWFvi42/OqeON3d3UFHspz3ePem8hpppLL72Uvr4+7rrrLrq7u1mwYAG/+MUvMmlA2tvbUQ/KWdbQ0MC7777LfffdN+p4mqaxe/dunnrqKUKhEOXl5Zxzzjl8+ctflpkR45BYtw6jxc4jGf/jcyQVk+eqe0g4sSNIBihOB8WVdTh6A+RFC0nrLvTBi5Oh1Xh+jwPLsgjHDQAcusonT6+lUIoRCZHz4n98jvgrr2Yeu//qo6heL85ly4j94VnMWJxXtAq25hkEpm3Gkwjz0i6FUCoAgM+lk7KS7E+9gOnoxWVpzCgqZUHxwkO+Z13+TGryajgQHs6Du7xs+YT1UZy8xpPSbM2aNVx55ZVcc801gF1fIxqN8t3vfpebb74ZVVX5wQ9+wOc///lMHY558+bR1tbGPffcc1TB6hNx5Y4ZiZAIR1B1nUTVNBy6TtpKoikqlgll+W7ceTF03Q4s7+iIEginANAdDrqruhlwhIkocSrjsynL91JVUkBsxnTiDfuZq0To9njQdZ2UM4Su6zhUB1WFVajKofPiHqy2qJZdoZ2ZxyX+4mP6uzwR/22ORi70R1aIHXuJN94g9vwLo7YrmorzQ+JBeztDNPdEOGNWCXluB85TV+A8dQUAnX/ZP+Zr4mYg63H4oGB1KBWy3x8F31QMVrsOClbLzGpxkHEFq6+99lpee+01/vM//5N4PM7pp59Ofv7opQfV1dVH3cDxOtLq1slkkhtvvJGSkhLWrFlDRUUFbW1tWf060mNONcnNWzAjdiDaecoyPJd8jNCPf0Kz0cNzi13s2bEWa0Q6jwrHPC5ZPJfykiTlnnIS8cQhj12W7+bjp9VOeB+EOJ6uv/76Q6b9eOihh0Ztq6+vZ9euXWPu73a7uffee49p+05WVixG/KWXM4/NcIRthSHimomaX4heW0u6twetrIyyvLNh2x84oNgXJepBM2lmlPrwOjXW77Mv5i9YWCGBaiFyVF8kyf6+FLPTJmYgQPzV1zLPea+6Etc5KwFQnE6cp57Khje3sT7PorusAdWZR8Rq5bn9z2de43fbs6cN4iyozgcLzqs55wMLISqKwjnTzuOxXY9iYVHoKmRmQf0E9ViczMaT0iwej4+6Ea9p9t/zUM7VeDw+KlCmadqYOVmnunRra+bnSKGdss0gRl1pHn63jqoqRNJ9OPUakoaZufENkCZBJD+AFdexUEgUJakqtM9B9Jkz4eVXmW8G2VuaT8Rl4PAYgEaZp/yIAtUAFb7sQopTMbAlxGRL7Ry+4aOVlqDNmI5eV4c+Zy5a8aFXOsSTaZ56pwUjbU9+ufLUGizLIpEycTlUugbTgPg9Dk6dWcwr2ztZMK2AQLIt6ziRQ6QB8Tq8U7LAssysFh9mXMHqj3/844B9UnL77bePuY+iKGzfvn3cDTtaR1rd+oknnmBgYIBHH30Uh8O+uKipqTmqY041qfffz/zsWnk2amEh/Z+7mqe3/56WSCoTqC70OVlRM4Pr5p8ld22FECec+GuvYUVjdLuSdLmTTIu62FZozz5QCwpQvB50r33zrGTOUih7i9Y+J2gauLNXfkwv8TK/uoC0ZVHodXLKjMNfdiuEODFZph2MBlC9XhS3m5Rh8pu3D9DWlcBV1MNFfXuG81RfcH4mUD3EddaZvP3+TnrK7BlRqsOBBcTN/sw+Z1Wfwf6oXYi62F3CaRWnMado7oe2r9RTyoXTL2JfYC+nV54p51piwhxpSrPVq1dz//33s3DhwkwakDVr1rB69epM0Hr16tX89Kc/pbq6OpMG5P77789cP+WS9IHhYHU0365fYRDDqauoqv257Y33UJbvpLVveKl/fZFOMK8VTBdWMoai6cT9MaoK7XMQfd48vFdegSdt8L/PO4tNPZt4o83+/VZ4K464nQXOAtyaO1OwdbIKqgkxVVnJJOmmZsAOVOd/458O+7VdwThG2j6f2NcVwjQtnn2/lW0HBlhUU2DfyLIOEFebKSg6h69cMh+XrvKbXa9nHWdksNowjUxx5vHkqz4RjAxWO1UnLu3wcn6Lk8e4gtUjq8ueiHfJx1Pd+qWXXuKUU07h3//933nxxRcpLi7m8ssv53Of+xyapo3rmFOJGQqR2mtXs1WLi9CmT6cj3M5Pt/6B3nASAI9STrHXy7IZeZxX+xG5eBJCnDD64/2807mByEAPy97aRMqVYm1ND5bHzfrocM43T3EZycGfLQvicQeFn7qWjsffQS8uw+PSqch309QTQVHsmdVOXeWjiyVfrBBTgWWapDa+j1KQj2P27NHPx2IE19yF2WcHlRWHju/GG2ktqCCWtPNPbj8wwMotG1ABRVVwnX32qOPE84tprAxjYeFR0hQX5dMRGk6P51bz+djsj9AVm4sFVHorj+i8aV7xfOYVzz+yzgtxhI40pdnNN9+MoijceeeddHZ2UlxczOrVq/nqV7+a2edf//VfWbNmDbfeeiu9vb2Ul5fzqU99KpPTOpeMnFkd9vohbgerHdrw78y0TJbUaZimh9J8F4sqvXQd2MMzA/tRdAdqaSkKCgn6KM+3J0wpioLr3HMyr9/cszlzvPGMC4qiUOOvZW9gD27NI8FqIY6Q0dSElTYB0Gcdfn5qgO7Q8OrzRMpkW+sA2w7Y1ybbDgwQtlrptN6mQnPzcsvLVM6vwqHl05/oyzrOyBzVoWQo8/NULUzoc+ShKzqGZUzZgLuYWOMKVp9++unHuh3H1HiqW7e0tPDWW29xxRVX8LOf/Yzm5mZuvfVWDMPglltuGdcxD9dk5v620mlQVYz16zFSdg41x8IF9AR7eHDr43SH7Dt4PmsaZ1ecz18tqsTj1MCCaDSadayhfpzoucwPRy71BXKrPyNvlomTl5VOk9ywgXQqxXszTDb3bcWy0qS276CtNIpmKSgV5Wj5+aR220VmVJeTqxZdxwvNzxNIBIiGirjv1QaKfE7Ss+ehATXFXj66uJJXdnQxo9RHgVdSfggxlSTXryf6u6dAUfD/4z+gT8tOSZfaviMTqAawUgbJ9etpXnEhlmmixOMkunpoCJtUa2m6Flez0Ofi4Pk+uzp7SZUoKFE3VYWlXLngGn68/peZ52cW1KOqihRGFCe8I0lppus6t9xyC7fccsshj5eXl8e3v/1tvv3tbx/Tdh4vlmEQ/d2TYKbxXn01isNBJGEQjqcoyXOhjwhEGwfs3PKKy0lYcwNJLDWOrmafp+ruEH/7kSWAff30XrIFTbdTgigMTgDDBMcAUJj12n2BfZnl/tP9MyjxjC/15LnTzqPYXUytvxZNmXopA4SYTMbevZmfj6SYIkB3KLuA4kvbOohbfYRpxsIkZDUB4HXqWJisa3uDM6vOwrTMrNfFjCimZaIqKuHUcLB6qqbPUBSFldXnsKVnC2dUnjHZzREnoHEFq8fKxTrVWZZFSUkJ/9//9/+haRqLFy+ms7OTe++99wNPyI6FxsbGCT3+oaj9AXxPPgmKgqVqqGF70Au6Xbz27kPs6eslYVg4zSLOLlnEXHeQxn3BDz3uZPVnIuRSXyB3+iMFB09uVipF5LHfEti1lZcqe+nvzEefNQujtRUzFCau2ReOzpoa/J5CAp1dGAMDLJxxBuW+Cv56zjXs6d/PMy0xFKA/kswce3qJHaC+6tSaQzdACHHCyuSUtCyS72xAn3ZV1vPGGBMM0q2tNNWGSe/ciaO/n7TTxQ4tj43Ve0nUFPDu5qfIS5zFafUlzK6wZzBtbt8Hmorqz2fx7FNZUjWDEud0epP2MuElFfMmtqNCiAmR2rSZ5DvvAqDXTsc8/Qx+/tJe4qk0mqpQXeThvPnl1HgUzP4AAGplFaGEHXzW9AQcNKeiM9rJYuxgtWVZNMb34/XYAeMCZQ4D1h5cDpX9od3sGtiKruhcOP0iVEXl/e7hFbzLy8dfbNXn8HG6BITEJHj44Ye599576e7uZv78+XznO99h6SEKEqZSKe655x6eeuopOjs7mTlzJv/n//wfPvKRj4z7mMeCsW/43EGvH64jkUjZK7JcjuwbQBsb++gJJThvXjndwey6XqFEmHbrL5iksrZ7nfYx9gf349Kz0xICWFj0x/vZ2rOFxuBwUcaDcz9P+Nl3jwABAABJREFUJUvKlrKkbOL+3cTUNq5g9YluPNWty8rK0HU9k28N7GJo3d3dJJPJcR3zcNXV1eE5qKjX8ZB8di0p14iBsLAItbKC6OJKYg1bsDQHPs3LUt9HufKcOR86mzUWi9HY2Dhp/TmWcqkvkFv92bNnz2Q3QUymVIrErx6mv30ff6rpIa6Z0NOLGo2zuFWl1eug151Cnz0bl8vLJ+ZcjVX/cfrDXUQSZTzz3gHOmFWCx6xBsZpHHX56ydSu/i7EycyyLIz9jZnHqfc3YV1+OcqIcztjv32Bp+gaamkp6Y5O4t29tDZ3EjXbCZf2URitYpM/THWeA8PlY3PLbqZRTXcwwS1/Zeec3tVrX7iqqsLSqtkoisLq6at5Yd8buJQCVkyrO279FkIcO8aBlszPqb176ZqzlPhgQCptWrT0Rvn1G40s8yQ5HQUNC6O6mpRhz4JUtTig4VRdpMwUFiZd0a7MMTtjHQTTIYr0QrxaCYXmXAbYg9eps6t/uIDb9PwZFLmK6Ip2AlDiLmVantxIF1PL2rVrueOOO7j11ltZtmwZDz74IDfddBPPPffcqBXrAHfeeSdPP/003//+96mvr+f111/nlltu4dFHH2XhwoXjOubRsmIxjBZ7FYVWWYHq92NZFhsa+nh1RyeaqnDT+bMyqzFb+6L8aXM7YBdYPhBsA6sARVGwLItuNmKSwqErpAw7pW6BXs1f1Z3NywdeAmBn347M++c78wkOrq5Y1/4mTcHGrPYVu499n4U4ERxWsPonP/kJAH/9139NZWVl5vGHmegZyYcynurWK1as4A9/+AOmaWZyszU2NlJWVpaZxXmkxzxcHo8Hr/f4BkgsyyK1dy+6nv0n4DnjdPZG9tAbTaEqKpXKGaxaWIfPd/i5zSajPxMll/oCudEfSQFy8rIsC88rr9IdaOPP0/tJ6oAF/pTG6t1eSpJOFg3k8fgZpXSmXFxXfiF+p31CubExwbo9dlXt9kCMurLhJXOaqpA2LfweB+X5o2cyCCGmBrOzEys2vNzWjEQxdu3GsXCB/TgYJN1jTzrQamvRKipId3TSoXiId7TQU76ftGWQLI2CruAsqyHQHQYLAspu3IkSuoL28ftT9oWo3+1ier5dsHX1/Fo8+kWU+V2U+KVQkBBTUbqtPfOz0dBANJEac7/3GnpR1GLONHuJlFRCACzLBC0JeMh35WNZFr3xHvrj/Znl+9v7ttsHUKA+byGxkBsn+XhdRtbxO6MdxIzhlIuLS5fIObCYcu6//36uvfbaTIHVW2+9lVdeeYUnnniCz3/+86P2//3vf8/NN9/MqlWrAPjMZz7DunXruO+++/jv//7vcR3zsJkmqddeI71sGVrVcAovY38jEUvFjYlrVj1G2uSJDS3s77JzSKdNi72dIU6daQeNt7Xa+ajTVopnG58gkY6Sr9RTap1CmANELXuMmV5UzDzfR9jWEuGCufUsKCljW9+2zA2qIdPzZ7C1ZwsAzcHhiTaVvipmFcyiStKNiRx12MFqRVFYuXJlJlh9OF+WkxWshiOvbv3pT3+aX/3qV9x2221cf/31NDU1cc8993DDDTcc9jGnErO9g2Sgj3dKgkRLfXjc+ZSTR+0ps9i1/T2C0RROJZ9yTxULqgsmu7lCCIGxfgOp/Tt5aYlByqGiz59PWVTj/Jd7cJkqap6PxKq/IjSQhy8Mf96YwlocYPuBARq6houS9IWTBGODxdUUhb9bNYu9nSHqy/NQVbkQFGKqMsZIdZV8771MsHpoVnVCNUnVVVBQMg2AA4qXeLQdK8+k0IgRLi1FdTjoSQHYs54iVhtJQuzvjhAy+khj14CYWViLrtqn005d5SPzyye2k0KIYyLd3U30kUdRPB6cZ56BY9EiUFXSbW2ZfaxYnGhHT+bxWQtUumO97G3Mx4xG2a/mcabZS7SoDAIx0iTQBxdy+B15oCj0xnuwMImmIqiKxv6gvSrDrbmpL5/Du6EBPJThc3Vnta8r2kUsNVxrRgJSYqpJJpNs27aNL3zhC5ltqqqycuVKNm7cOOZrUqnUqHSPLpeL9957b9zHPFxKPE7y+T8TenMd+f/0f1D9dtqvnVsbeNIxC7+V4nN1s9jY1J8JVA8ZiNk3tUzTYmebPQs6ShuJtH3DKWg14PYk6Y4Nji8KXD7nIhaXz+OqpVbm+uOSukvZ1P0+HZF2AokA84rnU+opZSt2sNrCXsHhd+Zz9Zy/Pqr+CnGiG3caEMuyPvD5yb7ze6TVrauqqrj33nu54447uPLKK6moqOCzn/0sn/vc5w77mCc6y7JIt7aiFhSQ3LaNjcUhdhRE0KeVolUWsx94bdfvaey2B9986jlrThmaBG+EEJMstXcvqbVr2VeSJKGBs3421RWzubz+SpTKnVjhCM4Vy3ljVx/KQACAWDLNH95rHfN4Rtr+Dqsp9lAisyCFyAkjg9WKqmCaJqnt2zFjMVSPB2P/fiJamqdqO7E8W7msuIYioFX1kHTZM6GKSZD2OEkYFioO8pV6Qupu0mmLAfawv6uS1sRwOqqlFXOOcy+FEMdC4pVXMQ7Y5wipPXvRykrxfvo6rEQya79QSyvoZQxYDazr2UO+x0HaPR0rGqNXcWKqKhGvH4hhEMM5WIDR58zLFE8ECKfCtIZbMQeDTfMK53N6VSWRmIXHcxY96pu4dQ890W4My6A31kM4aV+TOVQHRe6i4/BbEeLY6e/vJ51Oj0rNUVJSQsMY9SMAzj33XB544AFOP/10pk+fzrp163jhhRdIp9PjPuZhS6VIpw0IRxh44ne4rr0GgC2NvaRNiwA6+/Q8drX2YRjZKyG6AxGi0ShNPVGCEXsFVpBmTGW4SKLm6oZ4GtO0qMurpz6vlmg0mnUcFZXlRStgxMe9NXxg1PsVe4tHvXZILBbL+v9Ul0v9yaW+gB1fnMi472EFq++44w7Azq088vGJ7kiqWwMsX76cxx57bNzHPJFZhkH0iSdIvrsRxaET9jvYUWCfAKlF9miYNEx2dQaxLFDQOaNmCSvq5MRICDG5Utu2E3n4Ycx0mgOlKdSKGszCIkJdi7lnfyPgJt/j56Mxi+2tYxeBzXPrXLy0ihe2dBCMDS/pnVk+NStoCyFsVixG4s11aDXTMvmqFYdO/LSF/L71eRymwic3rqdw5SqMhv3sLAiT1CxceX52Kh0s0N10KB6SzjZcmGheD+fXz6ctMsAM9wo8Sim7Er3sbO8jaDSxr2cubeZuAFwOlcUVsyax90KI8RhKhzhSuruH2B+eHbVvuK2TYG2YHmsjxapdyMzSu7BiOmkU+suqCSXtgJRBFJ9uB6vzHNnB6lDSDlYPmV80H59b5+On1Q5usceSF5qeZ3f/LtJWmqgRAaDcW4GqDE+yEiJXffvb3+Zf//VfueSSS1AUhdraWj75yU/yxBNPHId3VwiFQvaPr71GtCAfo7aWto5ekooLy+Fg3d5WGvsNUia4NEim7fVXexNBdrgCvNUcpz9gYGIQ8B7AwkRBxcLEiKcpcSr403Wc45vLjh07PrA1Q0LpEP2DE3GGxBNxdoQ++PWNY6w2m8pyqT+51JeDV0IcS4cVrP7EJz7xgY/FicuKxzGam4m//Eqmiq2VMnhH7yKtgOLzckrNGdT6a/nlpqcxTXu24ayCOVy5vG7SZ8gLIU5uyX372PTkT/E6VHTTIljqwzttGh09HmIJEwZnKEUTBg+/2ZgZw5bNKMLlUDnQG2VRTSHLpheiayq94SSvbB/OBVdfJsFqIaay2J/+ROLNt7K2abW1NM4tItJpz8R6Z/vzXHDK6aQ6OtgzI4rq9YKusbuvmW3+OZjhBAlXlAIrhebN45IZl2bV6shvX05r4DV6QwlazdcxsGczzSurldmOQkxBZm8vZn8AALWoMPOz0bB/1L79fe1019gBLC0Zx4wkSac0sCpRUOgtqSYUt2c9Zs2sduShjQgwh1Nhggn7hrqu6Pgd+WO2rdxbzu7+XVnbKr2V4++sEJOkqKgITdPo7e3N2t7b23vIlenFxcX8v//3/0gkEgQCAcrLy/nv//5vamtrx33Mw6aA3+9H0+wQWfG27ThPOYXnXHk4UVGLChlQ8snLt6895lbm0T4QJxQzcDk05s6byYutDRQVmsS1VuKKk2TaJN+qx6UUsbJeZXHxQsq9FUfUrGQ6yaZd2SlOzqg/k1L32P2NxWI0NjZSV1eHx+MZxy/ixJJL/cmlvgDs2bPnw3c6CuNOAyJObOnOTuKvvErq/fex0sPLTyws9uVFacizlx54i8o5vfIMXJqLMmMV3cqbmBhcv/wiSf8hhJhUlmXxwvqH2VVq55euKKglVZxPU28Mb2oOKODQVTRFIZ5KZwLVAKfWFVNeMLpY4rLphfxlVxdG2sLr0qkYYx8hxNRgWRapLVtHbddn1jHgs1B9XsxIlG2pZpY/+3uafXFimomWn0/atNjV0Udxfj5aLIVDi1OWjpOXN2vUjfrlZct5zfsuvaFEJlDt0FU+seCjx6WfQohjyxgxq9p15pkk332XdHdP1j56zTSMA630KREsIwWqirlzJ6l0Gt3lIerMx5X00e0rZiBqr9hKE8cxOLPa7/QfNLM6SDBpB6u9qveQE4LGCmRV+I4suCXEicDpdLJo0SLWrVvHRRddBIBpmqxbt+5DV6q7XC4qKipIpVI8//zzXHLJJUd9zA9lWWiajq4PhsiCIRIbt2CoGiqg+/OxUNEHP+OzqopIWUFiqQiGBW2hNObg8/mFAUzDTXcwTr5aS42/lsvnzh5Xs7x48Tg9pEx7nHGoDmqKaj50tYXH48Hr9Y7rPU9EudSfXOnLRE9sHXew+vHHH+c3v/kNzc3NBIOjl10risL27duPqnFifOKvvU7s2bVwUF7xUIGTDR+dzoGWbdBt53M8c95HcWkuApEkgZBOtfIRKgrcTCuUmUJCiOPPDAaJv/wyen0920sT7A7vA0DRNXpmlzLQ0UfYSFOmVuN2alx/zkw8Do2H3thPIGLnmZxW7B0zUA3gcer81ZIq3tnfx9mzS2X1iBBTWPrAAcxQeNR2va6O/vh7qGVlmJEm0gq8t+81evNToIBaUkIgmsJIW8T8YSr7BvCbYVRVoSC/etTxXLqb86afwZ6u54bqLbK8ciE1/tH7CiFObLGkwesbm3Gphcw3g/jnzMYyDNJ/fjGzj+L14FyxAuNAK0GnAckkiqZSGdHocqdxJWIEXFE7WO30k4gPphfTYpnJPj6HLyuY1BHpyBRH82nDKzcOVuopzaQNGFIhM6vFFHXjjTfyz//8zyxevJilS5fy4IMPEovF+OQnPwnAN77xDSoqKvj6178OwKZNm+js7GTBggV0dnby4x//GNM0+d//+38f9jGPpa53NwP2d73iyw4uTi/x0h6I0TI4yXt3ux0TMy0DU+sm36HTG3TippTSo6yN43P4CCQCAFRIWiBxkhhXsPrOO+/knnvuAT680KKYeOm+flIbN6LPqseKxzOB6riaZnt5EufMmTgqqnjf3U1ajaHX16OWljCnYA5LZp8DwK6O4RsO86rHXpYmhBATyTJNwvc/SHNbH6l3/8JfznZmVoaoRUVYKARiJj69BF3xcPXptZmTv0+dNYNH1zURjKU4b17ZB77P0ulFLJ0uN+SEmOpSI/I9OhbOx2hoJFZWyTMdKluTLdQUl6A0N2OZFlsK7aC2VlFOflElB9rtdEBRT4AZjk5aAfx+Ch3FY77XaVXLecrzF/qiYZy6g79edMFEd08IMQHW7e5mXUcctHLedFVyYcLNqcuWEh8RrNarq9Fn2zmkI7qBlUqimxr1YQ9d7iQaoDmDQBndOGGwFoaqDxdnzHPkoSgKCgoWFj2x7sxzXvXQM+ocqoNidzG98Z7B4/jxOqb+DDxxcrr00kvp6+vjrrvuoru7mwULFvCLX/wik7Kjvb0dVR0OvCYSCe68805aWlrwer2sWrWKH/zgB+Tn5x/2MY+WY+ECUtvt84tAWgXN3q6MSA/mdmqU+l0UeB2ZbXs77XRBUToocli4HA7qC2pwJRycOnPsc4vDlefIGw5W++TmlTg5jCtY/fjjj2eC1B6Ph/z8fDRNO6YNE4fHSiYJ33NPJteaomuZGdVvnV1M2zQP6BrQlXmN35XPR065grqCusy23e2hzM/zqiRYLYQ4/hKvvcZb7THW6bUEi/ZS1dxCGoVUqIZktR8zlMAwwUc1cyr91JYMnzQW+Zx8bvUsTAucusw2EOJkMHQx2Y+DqiuuwleYz1vbOmna30K/FcfCZFpRMdZgbkvF5USvrWVJ6RI2NyaBDiyXQXCmAyWso1RWUqAVjvleDtXBF0+7luf3vcU505dR5Bl7PyHE5Eh3d5Patg3nsmWZ4vEjpfbsIfrbx2lUp4ExmGM6v5CXtndRsbKOoqpK0u0dAGjV1agVFSh5ecQcYaxkClVLURfxsKFkgLQCqjOI4nZjKiqYFpZl4nHbwWq35kZX7ctsr8NLJBXBYniC1wcFq8GeOTkUrJYUIGKqu/766w+ZouOhhx7KenzGGWewdu3aozrm0dIqKzADAdJt7QSwi8cpTieKYzgwXVtsp/Ip8AxvS6TsCTYRpYVKh4aiwN+cdjbT8mqOeiWnzzFcY6faJ6u6xMlhXMHqcDiMoijccMMNfOtb35Jl1JMo/uprmUA1gGXYxYSCi2bQNt2Ag/5pFpUs5pzqc3FowwNrKJaitc/OwVjqd1GSd3TLVIQQ4khYlkVgzzY2bPgtm7wzsBIWA54oLhwkLCf+gTko6Xq6B97CYfrJYzpnzxk9e1rXJEgtxMli6EJyq1rAK/n1lG7s4e9W5bOnI0QS+wZ8IJJkbtlpeDteZUBP01WyDM/AdFyV9TiMFqADv1snOX06Tms6Og486UMXvJlZXMMXiv/6OPVQCHEkIg/9inRHJ6lt2/F/6e9HPZ/4yxuYgQH69RJQ7EtgdXC25nv7+7hk2TJiQ8HqWju4ZM2aTXJgPVgWzqSFJ61RbHnpVqIojhjmiKX9UX0/pX4LUCjxDM/wzHPkEUlFstryQWlAwJ45ub1vGyDFFYU43hSvF8eC+XawWrFjJorPh9/jIDS4imJ6qf0ZLvQ6s16btpJYzh4UxYdX91KdN+2YxMrmFs1lb2AP+c4CqvOmHfXxhJgKxhWsXrJkCe+88w5nn322BKqPgfSePcQHgqg+H2plJfq0w7tbZgYCJF59FbDzTys+H2YojFZRzq6VtRCxK1ovKV1KoauQCm9l5u58IJLE5VDxOHXea+zLHFNSgAghJpqVTrP1tSdY3/IGiyIFLOj38KKrgSZ/nF35Byjv92OqBt24cSYLKSwowKGVUmNcTCA+QN20AqqLpn4FZSHEkbMsi+5gAt/grOq9ih+lqIiBaJI/b+sgEjdIMbxarClYwj984jb2dUd4rSWKFYZnN7bjo5petpI/NCtKgTJ3GUpEzmuFmGqseJx0h53ax2hqJt3djVaWfVPb7O4mhUJ4MFBdbiVIlhcTA3Z3hLhw1Rk4u7tQdAeOxYsBSMyow9j+FwB8Kft106YtoN/VgzcQIlFsz5A2rCiO/Ab0wZXGZ1adlXnfPIefTjqz2vJhM6vnFM1h/0ADpmWysGTReH4lQohxUjxe9BkziL/4MgHFDkZrPh+n15fw0rYOFEWhvtye6TwyDQhAhDbcTvs8Yk7R3GOWW3p6/gxuXPR3ODSn5KsWJ41xBau/8Y1vcMMNN3DvvfeybNkyiouPLgfPSc0wiD/8CIY+/E+R97/+FsfCBR/4MsuyiD3zB6ykfXfPuXIl1gXnsm3vmzjLK9jb9RYAbs3DmZVn09wTp7M3zYGuXrYdGKCtP4ZTV7n0lGlsaLCXx6qqwpKawonppxBCAEZTE5EnnuB11ybimsnb9FEXrKJ1RpyYomE6VAbmxKBPIW2BO56HWlKE3+OgP2SgAGfNku8cIU5Wr+3sYt2eHkp3N/FJoFdxohYWArClOQBAkhBup0Y8mUa3/KzrSNAeSGWOYZoWDsXHND7CqVUxuuIHSKSTLCpaRDgSGf2mQogTWrq3L+txatNmtIsuzDy2TBOzvz+zpF+rqKCqtojiedW8ubsby7LY3B7h3E99CgAjbWIaJoHKEthuHyNvMFhdOW0eO3SN/LJy2lrt8SLq3EGVzw4gLSxZRJWvKvPeec7h5fsACgqeDwlWO1QHl9VffqS/BiHEMaB6vWi1teDxMGDYwejCYj+nzSzG5VAp8DgyK9E9ToU4PcStPiwsIrRS6rBvWs0pnHtM2+XSxy4eL0SuGlew+r/+67/w+/28++67nH/++dTX12clvQdQFIUHH3zwmDQypw3mTBsp9sc/os+fR3L9etKdXbgvvAA1b/hEx7IsYk89RXLLVsCuWK1fsIrHW56hnz7oasjsu6xsGW/s7mP93t5R75M0TJ56pyXzeEVdMYU+56j9hBDiWEht30HkV7+iT4kTr7XzupmawsbyKFZhPglfEarpIEkYxevFikRwp4ooqCrj86tns7Wpm/YDcWqKZVa1ELkquWkTyXffQ/F50aqqcJ1xBop7+AJtd0cIKxqltT9KH06injx0b3bgJ0WI+vI8drcHcZp57GwLHvw2AEzLr+ay2bOxLAsLi3gszg52jLmvEOLEZfb2ZD1Obt6Me0Sw2gwEsNImA4oDtbgYva6O8vnlLK4tZN2ebiwL3m/q5+w5ZYRiKR54rQHTslg40wBNg3Qa/2Cwurp+GTTvRdMU6qelKTTctCj9qKqKR/ewsmplVlvyHNnBap8jD9WQmZFCnKgUrwdFVTEWLCK5JQiKSnFlCaqqsGxEgfaWUDPPNz5Pt9pB0jAz271OPwXOAsq95ZPRfCFyxriC1evXr8+k/0gmk+zatSvrecuyJD3IYVLM4YEtXVKA0d+Pq7OLyAMPktpp/17TTU3kffELAKR27iT53nuktu8cPICC96+vZv3AJnpjvUSTaTRVwaWruHU3Fa45vLivbdT7uhxqpgjA0ONz5h6bCrpCCDEk9txzJDe+j+rzkW5rwzItOvITqHk+tLoZqHl57EfBgUW8O4ISsYsTOfLzMHUPvoIVnLOoGoeuMq/KjxkY19eWEGIKsAyD6ONPYCWSNPpi7G2NcsrG15j9hf+D4nZjWRYD0RTpDjuv7C41n3iNQo/1FC6KqeZcQMXljuHUXUwvKkHpy16iW1vipaXXrtMxq8IOIimKgnJwkQ8hxJRh9mRPykl3dJLu6ECrtPM9m4NFVvsVJ4rLnhFZ5HOS73EwvUznzc4X0WNudndUcKAvRjxl1wDadKAVxenEisUoMDS08hL8RVW4Wl0k0gkcrjDnznPz5F47+DyzoH7U7MeDZ1bnO/Nh9FwlIcQJosfU+cv6ZrTpy9F696D6/ZQU+7P22dG7nZdbXsbCxKmrw8FqBTxOjXnF8yUeJsRRGvdVv2VZY/4sjlB6sCCiT+H5s3Wi29o5ta+AhTt3Zi6cjAOthH72M95N7qVFC1IedzLN48ZpqTgv+xiN5Uk2tb1Pc2+UgYhBsbIIU0mxsGQOL23py/z7LJleyLQiL2V+F6V+F4+ua6I9EAPgrNmleJwSBBJCHDup7TuIv/QKQFYh2K65ZThmF4Fqj3EW9hgVTdhXb4oK9WV59PUVMre0kiW1hcez2UKISWIGg1iJJO3uBK9U9GEBodQ+qh59FN9nP0s0aZKKJ0gPBqa2uf30Fu7HwiRu9RBU9uOjBt/g4ot55ZU0h7RM4KnA6+BTZ83g1Z1dhGIpVs4eXahVCDH1pHt6Rm1Lbt6MZyhYPfh8QHFmVmoU59mrSX2FbcQ77Odf3LMFIzY8LvREA5lgdVFSRZ8/E0VRKPOUcyDcQtSI0hhszOxf7hk9k/LgmdX5DqkPJMSJ7M32OHv77Mkzem0tYN/cGrIvsJeXWl7MPC73VONJlKKgoruDnFpZy/LyFce30ULkoHFFJ1988cUP30kcHtPExOKNuiRJvxsrP4/1ygDtngQ1UTdFSQflcQfvhrazscguGNTjSrGjJI5eNwPVtQvadhFNpAlEkpQoSylU5gDQ0QtgB6OLfE4uXlKFrg0vO7vmzOm8sqMTp65xen3J8e65ECLHWJZF8q23SB9oxbF8OdHf/374SUUBy8K58kx66rsxUnEGwgkKPE50TcFIW5iGG4jider43DofO30FS8umT1p/hBDHlxUYIKqlebWiD6WoEEIhAhj0796K9sILBE4/j3RXF1j2DKbW6WFMxb7JlefW6Y/vxK37KRwseFTqLaGsvpg3dnUDcMqMInRN5cJFlZPSPyHExDBHBqsHzzeS6zfgWrkSNS8vM/N6ZLC6yGfPsEYPZlacNgc6KFaG62KkCIPLieJ0UuwtwHXuOQCUecs4ELZTKe7sG04dVDbGsv88R/aMTL/TP2ofIcSJwJ5E0xUzRz0zFKyOGTFePfBKZvvi0iWo7vm8MWCPMfNL8llZXTvxTRXiJDCuYPW0adOOdTtOarsKo3T7PegKaDU1mDt20uKN01brRS0twrF9H1EtjaKAWlKCWlaK6s/PzEoE6BiI4VOqKWA2tSU++iMJwvHhNWYXLa7MClQDeF06l54i/5ZCiGMjtXkz0SftAHViwzuZ7Y7Zs/D93Y1YqRS9VpjE7kdp6okQjpl06HHmVeUTSRj4lRlE6cTrtJfoT8urmZR+CCGOL8s0UVQVMxDgjbJ+YpqJnp+PUlmBsXMXrZ4EeS+9QrejmHSbndos5g4RKQiiYBcyml7qI5pIU+xpwFTt851idzHzq0qJDK7akBvzQuSmoWC16s9Dq60htX0nZjBE5FcPk/f5z5Hu7aXDneD9yj243E5mus7BqdvjRG+8hxK/i7a+GAkCAISsJixMUoRRUFAKi5hx1d+jFfkAKBsxgzpm2BODVEWlxD16jPE6vCioWNgBML8jnyTJCftdCCHGJ6bq9kqKMdJ3FA8WVPxL6+uZz3x9wSw+Mm0V21oHMvtVFEgRRCGOlcMKVrcNXhiUlZXhcDgyjz9MdXX1+Ft2krAUeK8khOq1T27OmvdRNlo68XgIrbwcVIXUkrno4RBqcQln1a2iwFVAd7QbExMVlVTKRVdTGDel5HudfOoseybilpYAu9qDzCzLY1aF3MUXQkwcMxwm9tTvR21XNBXPx69C0XUUXae1ayeGYRGKpShS5tNv7KS5N4JL1/BSgZcKivJ2s6R0DiUeCSwJkcssy6L73gfpaW5n9g1/TSzQzQFvAgCH24tZkI9WU0NbuId5IR+dz78Mml1fIzwtiqLZgepSfR5OvQunrmIOrigDKPWUomsqH1sq56NC5CorHscMRwBQy0rxXn01oQN3YQZDGA37if/xOczeXt4tChN3uEnqbYT0zVjWfKJGlKgRpdjnoj0QI2kGiNBBl/VO1ns48JLnGs5/P1bhtGJ3CZqqjdquKio+h49wyl4hm+/Mp4fRaUuEEJMrrajg8RBNpjPbivOc1JXlUeRz0hxsYne/XVPMpblYVXM+iqIwtzKf2pJ+UmmLpSMKMAohjs5hBasvuOACVFXlV7/6FStWrOCCCy740ITxiqKwffv2Y9LIXGaokFYtFI+HVLiG/Y0VXLH8S6TVAIFEP40D+2mmGSvfz7KyUzi14jQURWFO0dzMMR5f34xHsRM0nj2nNDODenldMcvrisd8XyGEOJZiv38aM2LPiNZrppHu7cWKxXF/7GL7xtugA+EDBOMpAHzUEFf6CUY70dCYoRShKCr/a/FnKfA6x3wfIUTuSLa282BDiqhSwYUvvktNZSrz3OzCOTRpARLVVXT0DmB2WgQVO1hkuRwkiuzZ0joe5uefxvTiJrb3bQPAqTpZVnYKFV5J9yFErhuZr1orKUX1+/HdcD3hn96DlTZJvP46lqrQNCMJmhcFCNHI1p4t5Lvs/NG6plDoddIfjhGkAUVVsMzhmky64sPtGA5E5zvzcWl2kcUhY+WrHuJ3+iVYLcQJzgJiHh+pwWKJNcVerj93pv2cZbGufV1m33Oqz8Xr8ALg1FX+5pyZx729QuS6w04DcnARRSmqeGyYiv177E1raIFy4kqY5t4oFy+tYkltDYtLlxBJRYgZMUo9paNeH4kb7OsMA3a+xqVSiEwIcYxYqRTxl19BKy3FuWL5IfdL7d5NctNmABSvB9+N/wvF6cSMRNCKh2+Ybe7eRFOwkWAshYoTJ/mUcyohpQkvlSiKyqyKPPI9jkO9lRBiijHD9jmKmpc36rnOth6iih0A2t2fIM83HMApLqwijZ99A3sxZ82gb18XwZR9EytdXwiD508epZyyfDfn1XyEfFc+Ls3N3KK5ODW54SXE4Xj44Ye599576e7uZv78+XznO99h6dKlh9z/gQce4JFHHqG9vZ2ioiIuvvhivv71r+NyuTL7dHZ28l//9V+8/vrrxGIxZsyYwe23386SJUuOeftH5qtWS+0VWfqMGbjOPZf4q69hmRZhNUUCLbMaw6WrvN76OgtLFmZeW1ngIRw3SCudVOa5ae8fXqXhVLyZtCHAYJHFMg6ED2S2jZWvesiysmX0xXuZWzQPl+Y65H5CiMnV7xpeje5xDt+gahhooCdm178o85Qzv3jBcW+bECebwwpWn3766QD4/f6sx+LomSqYDic9EZNa7Lv7Rtrk2Y2tWJa9lMTn8OFz+MZ8/c72gcyNgyW1haPyUgshxHjFX36F+J/tgrpazbSsGdJDLNMk9swfMo+1yz5GwJGiyJmHNuLCdWvPVl5vfQ3LYjAFyBI8Tp3T6qfzxm4PZX43K+eWMa/K/6Erd4QQU0O6s5PQmrsA8H/1K2hlZVnP93f3Z37ujKTpj/TRrrgJKE7mx3zMKC9i38BeFJ+X7otWEHwphV4+jUh+P4PpX/FQTonfha7qnFpx2nHrmxC5YO3atdxxxx3ceuutLFu2jAcffJCbbrqJ5557jpKS0am4nnnmGX74wx9y++23s3z5chobG/nmN7+Joih861vfAmBgYIBPf/rTnHnmmfz85z+nqKiIpqYmCgoKJqQPZm9f5mdlRJudp64g/uprgF2cPokKQ8Fqh4aFyfbebZn9XQ6VRTV2G6OJNO0jUgrlO0pHnZuUecqzg9We7PFtpFmFs6kvmIWiKESj0fF0UwhxHGzzRUhZERyKD6/LDpVZlsWGjvWZfc6oPFOuVYQ4Dg4rWP3QQw994GMxfiYWfa48NLMARVHJc+uZwogvbe9kTqUfj9P+Z2rujdDSG+WUGUX4BgfPbQeGE/ovnDYxJ4FCiJNTasuWzM/pA61jBquTb79NurMLgJ76Yl5xbSK5cz3nT7uAuvx5eJ0agUSA11tfBSCSMMi35lHAbGaW53HuvHLOml0qN9qEyEHJTZuwDDv3Y2rzFrQLL8h6fqA/NLyvBU2RAXr9LtA03t2bYEZhFYZhEUsZtJQ5SK44Bc0C1bUPJWEv0/dQRmmezFQUYjzuv/9+rr32Wq6++moAbr31Vl555RWeeOIJPv/5z4/af+PGjaxYsYIrrrgCgJqaGi6//HI2bdqU2efnP/85lZWV3HHHHZlttbW1E9aHdI8923GdWsrmHQk+4ulm5ZwytMpKtOoqAm3dPO/Jo0tJo2o6pcoyXHojABZjrxR2OVSKlcUoKKRJUuWeNWqfMu9wcFpB/dA6GxLcEuLEZmoG73qbiVomtfxVJvXP3sBeeuP2Co5ybwUz8mdMZjOFOGkcdhoQMVEUehU3+RSjKPDps+t4Y3c321sHiCfTvLKji0uWVdMfSfKbdU2kTYttBwL8zTkzSRkmbYNL1Mrz3ZTlS/VZIcSxke7pyQShhx4fzIzFiP3peWJqmhZfnHcXF2GZCQzD4qF3X6MwCYoCA463KChMkufWKWAWJvUoisKsCjstgASqhchN6abmzM9GS8uo5wcGIlmPdzt1wEBRVTTLx/ObAuxNpklaYdr691BuzkJBI60O4HVqJOMedMVDqV+C1UIcqWQyybZt2/jCF76Q2aaqKitXrmTjxo1jvmb58uU8/fTTbN68maVLl9LS0sKrr77KVVddldnnpZde4txzz+Uf//Ef2bBhAxUVFXzmM5/h2muvPar2xmKxMbcn2tpJGwbrXUVoms5LW9qoLXBQkufEWryYF9u30ujswLIsLFWlzDmNWn+StsjwrOgSdymBRD9pa0RhNb2SVMJe2eocY0Z0Hn4Mw55gVOwqIRlPkiR52P04VH+mklzqC+RWfyzLkhskR8hSTJKKRoowSYJ4nZUkjDhvtL2e2eeMyjPk9yrEcTLuYHUymeSFF15g69atBINBTNPMel5RFG6//fajbmCuMxUwNB03RSycVkCJ38XqhRXs7QyRNEw2N/ezqKaAdxr6SA8W+ugLJ/nt282U5Q9fnC2skVnVQohjJ7V9R9Zjs7c363FvOEHwT8/zZmEzne4kWkkxep6XlGGytzNMIpUmT4mTsProjrcS7FU5bcY0YpE5KIqJosDMstE5bIUQ2SYin+yRHnM8LMvCaBkOBqVbW7OeT6VTdEUGGDoVtbDoctjnOTpeVEUjkTLxUk2SXcSSaSJKGzpuHLpCoddNMFXBguoCKcgqxDj09/eTTqdHpfsoKSmhoaFhzNdcccUV9Pf385nPfMb+jBsG1113HV/84hcz+7S0tPDII49w44038sUvfpEtW7bw/e9/H4fDwSc+8Ylxt7exsXHM7f49ezDiSeJlaVLBIDG9lf98/VkurJpPtV7KHkMjrofANCh0aJxZZNHb76I/EsgcI99VQCptMGDYK1bdqhstmqY/ZO/jt8Ls2BHKel/LslBDGr1GL9O8NezYkX3eNN7+TEW51BfInf44nfLdeKQS2BNo4vTgcS7gzbY3iaTsG+vT/TOY7pdZ1UIcL+MKVvf393PDDTewb9++MZ8fupM32cHqI7kY+93vfpfJtTbE6XSyZcQy+G9+85s8+eSTWfuce+653HvvveNvpKKiuJy4KGZ2hZ0T3O9xcO68cl7a1oFlwWNvNWGks5epdQRidASG7/ouqM4ffxuEEOIgqe3bsx6PLGC0tzPE46/tpqdhJ4WFaXyKglJbS08oQW8QEil7ZpLp6CJo7gQDEikTKzyXgchwhe2hdEZCiLFNRD7ZIz3meJldXVjx+PDjgSBmIED85ZeJB/p4almKd4u24E/NwhstxFQNTNUeO5yKnwKvk4FokjxlGgFrFwARWnHix6+rFPocXLfwTGYV1RyzNgshPtjbb7/NPffcw/e+9z2WLl1Kc3Mzt912G3fffTdf+tKXAPs6cPHixXzta18DYOHChezZs4dHH330qILVdXV1eDyerG1WNErU7WHAk4+nsBBvoY+AshuAnVYTM6efi1bdCg6LEhXOnr+E5XWLMMx5tO4+QNJMALC0cind8W52BXYCMLdgHlbhdBJNAQBm1hawYMHoVGgLrAXEjCjeQ9QWGkssFqOxsXHM/kw1udQXyK3+7NmzZ7KbMCWlUNCwg9XBdCfbB+y89g7Vwfm1q2VWtRDH0bgiBXfffTd79+4d87kT5QM8nouxvLw8nnvuuczjsfpy3nnnZeVgO9o7lpamoSludLy4R1ScPXVmMfs6QzT1RLIC1WfOLmVTcz/x5PAytfryPJlVJIQ4ZsxolPRBs0rSPT1YlkUobvCHd5pJNjUSyutGwYGvspj+4AzSsWKKcdDKKzh1lZLKRhxxi4Yu8ChldHQWMDSsnj3n0IWIhBC2icgne6THHC+jeXTaj9gfnyO58X2afTFChTopC0L+brzRQgxHIrNfmTufGz9ST0tfhPL8OXz7xbdJpCPErG7i9FKie1BQqfFPO2btFeJkU1RUhKZp9B68cqq3l9LS0jFfs2bNGq688kquueYaAObNm0c0GuW73/0uN998M6qqUlZWxqxZ2Tme6+vr+dOf/nRU7fV4PHi93qxtRkcnSV0nqbjQfD4iWhuqZc+MbB2I0uSKY80sRIv7Ka7MZ1pRTeYYi8oXsaVnMwB1JXV4ol72he3r27ll8wg6/OitYQAK/d5R7z3Ex+EHqj+sP1NVLvUFcqM/J0pMZspR7PEjZvWyN/h+ZvPK6nPwO/2T1CghTk7jShT6+uuvoygKH//4xwEyM3a+9rWv4Xa7OfXUU3nggQeOYTOP3MiLsdmzZ3Prrbfidrt54oknDvkaRVEoKyvL/DfWiZrT6cza51hUtnZZRSiKgscxHKzWVIVrzpzOnMrhQbG8wM2q+eX8r/Pq+eiSKi5cXMklp1RzxQq5WBNCHDvGzl1YZvZqDisWx+jp4fH/+R0D69YTix4g5YgT1Z14Khfhii/Eq1Tioogir4/ZlX5QDfI9DlxOjWKWZE6cq4s8zCwb38WdECeLoXyyK1euzGw7nHyy27ZtY/NmOwAzlE921apV4z7meKWb7XzVrYqHVsWeoZbc+D4AXa4kqd4+0igkXGFMJU1KHw5WTy8oxe3UmFOZT4HXyaKyeYPPWFikceoqi0oW4dKlVocQ4+V0Olm0aBHr1q3LbDNNk3Xr1rF8+fIxXxOPx1HV7MtHTbOvXyzLPm9YsWIF+/fvz9qnsbGRadOO/fVKuqsTgBgaeNwEGU5fkkim2dLaTVILoeX58BfmUeYZnh19VtXZLC1dxqqa8ynxlDKvaB6nlp/GWVVnU19Qz8yyPFTVPm+pLZ7agUshxOFRBj/zaWL0JTsAKHIVs6hk8WQ2S4iT0rhmVre3twNwySWX8NRTTwGwZMkSVqxYgdvt5o477mDjxo2ceeaZx6yhR2I8BUMAotEoq1evxjRNFi5cyNe+9jXmzJmTtc/69es5++yzyc/P56yzzuIrX/kKRUVF426rBehmPoZhYKWTRKPZAaKLF5WQ71LoHIhz/vwS4vEYTgUWVAxfoFlGkqjx4QU9JlouFaXIpb5AbvVHCoZMLMuySKx/O/NYq6wg3dFJtyvJn575NVuMEGqeTtxt525M+ArQjJmZ/a88tZb29FJ29dtLaVHglIp59LQOj5PnzS+Xf0MhPsRE5JMdzzEP18HfL7F9+2hNO3jCaafp+OvkfiotOy1IpzNOIpXGUi0sLGLOEEk9ngl21RaWZBUzO3vaXN5pfwcABSh05HFK0fJRBc+OVi59V0Ju9SeX+gInzrnMjTfeyD//8z+zePFili5dyoMPPkgsFuOTn/wkAN/4xjeoqKjg61//OgCrV6/m/vvvZ+HChZk0IGvWrGH16tWZoPXf/u3f8ulPf5qf/vSnXHLJJWzevJnHHnuMf//3fz/m7R8qBB1VdBLeOEkrSInfRW/IvvmVJk6CAH63A1VVKPcOB6udmpPzaj6SeaypGmdVn515XOhzctP5s0gaJlWFUzslhBDiMCnDN+P0wRtzi0sXnxDjtRAnm3EFqzVNI5VK4fP5cDqdpFIpuru7AZgxYwaWZfHoo49mFds4nsZzMTZz5kxuv/125s2bRygU4r777uO6667j2WefpbKyErBTgHz0ox+lpqaGlpYWfvSjH/G5z32O3/zmN5kTtCNmQTqcR78ZoGnfHhza6IGwGCj2QWdLkM7xvctxlStFKSC3+gK50x8pGDI+ibffJvH6X3BfeAHOQ8yaMvbtw2hoBEArL8N52qlsevW3/KUswC4jgVFoj1E+nxtVL0Bz+enpKUDBXhEytzIfZ6guE6xWULhy/vk80d/HQDTFjFIfdaUyq1qIiXA4+WQnStb3SzJJ/q5d7HRVknApKEaKXbE0zngfAG21YSIpB6bDzmGfdnYSVxRM00TBgngqq1iZZVl4LZ3+ZBSPQ2F6fDp7d42dju6Y9yUH5FJ/cqkvJ8K5zKWXXkpfXx933XUX3d3dLFiwgF/84heZ1aXt7e1ZM6lvvvlmFEXhzjvvpLOzk+LiYlavXs1Xv/rVzD5Lly7lJz/5CT/60Y+4++67qamp4V/+5V+48sorj3n7za7BYDU6IU8bAPkeB2nTIhBJkiaBQZRSrwNN0clzHFlh55I814fvJITIHYMzq1Hs6xqH6mBe8fzJbZMQJ6lxBasLCwvp6OggGo1SXl5Oa2srd911Fz09PZk0G6FQ6EOOcmJZvnx51pK35cuXc+mll/Loo4/yla98BYDLLrss8/y8efOYN28eF110UWa29XhouCj2TcOh6yxZNHtK37XLpaIUudQXyK3+nEgFQ46kiOsNN9zA+vXrR21ftWoVP/vZzwA7IHPXXXfx29/+lmAwyIoVK/i3f/s36urqjrqtVjpN7A/PYiWSxP743JjBasuyiL/w58xj90UX0qfEeKs0QJ/ixMAen/J1i5IZlTT3RMlX6gZLkdhFEx26yvT86Xh0DzEjxoKShZT7SvnMynwaeyLMr8qf0uOcEMfLROSTHc8xD9fI75d0QwPxgkIMvRhPWSlJs4/3pvfTTorTevzo7gQoLtTBGUx5VSbhoL0KzofJGaefg6ZmTwL44jQfrx/YwKmVi1hUsuCo2nooufRdCbnVn1zqC5xY5zLXX389119//ZjPPfTQQ1mPdV3nlltu4ZZbbvnAY65evZrVq1cfszYeSnooWO3yEFXtQtAOTaG6yMNALEnaSmAQI9/jw+fwyvmHEOKDDY4RuqqAAnOL5uHS5KaVEJNhXMHq+vp6Ojo66O3tZeXKlTz22GM0NDTw/e9/H7BzPx8qYHM8HIuLMYfDwYIFC2gezLk4ltraWoqKimhqahp3sBpLRdd0/F43Pl9uzDbMhaIUQ3KpL5Ab/TlRLjSOtIjrj3/8Y1KpVOZxIBDgqquu4mMf+1hm289//nMeeugh/uM//oOamhrWrFnDTTfdxNq1a3G5ju5EKd3aipWw0wWZgQHMcBg1z55hZFkWxr4GjB07MPY3AqBVlGMunMuft/yKlALdihtfpAhvpJhVczV6C8vo7h2gkHmZ95hZbh/Ppbn4xOxP0hPrZVahXWSpwOtk2fTJn0UmxFQxMp/sRRddBAznkz1UYOnD8smO55iHa+T3S3RfA7quE9TdpAtVuhx78EUsUhZsqImjGCqGomXGc2eJE3+8m6DioF7V8eeNLmK0yLuARVUTE6T+oL7kglzqT6705UQ5l5nKzFgMcyAIQLQgHwt75YauqTh1ldpiH6lgnHKvhq4pRzyrWghxEhocmzVtKAXIkslsjRAntXEVWPzYxz7GOeecA8Df//3fU1FRgWVZmf9KS0v513/912Pa0CMxnoIhB0un0+zevZuysrJD7tPR0UEgEPjAfT7MUIbqkcUVhRAnviMt4lpYWJhVnPWNN97A7XZngtWWZfHLX/6Sm2++mYsuuoj58+fzgx/8gK6uLv785z+PecwjYRxU7Cg9WHvASqWIPvQrwj/7OfHX/2Jvw2Lvyjoe3vUwA0qcPsWJmvRS0juDpRGNixZewPWLrmOOZzWaMhyAHpneo8hdzJyiOZmZk0KII3fjjTfy2GOP8eSTT7Jv3z7+7d/+bVQ+2R/+8IeZ/VevXs0jjzzCs88+S0tLC2+88caofLIfdsyjZUYiJDdswAK6nSqdhVuwXArJobGgphpFU0mh4o0UgQLuAj/VVoz5ZpAZzty4cS+EOLYsyyJpmJnHQylAAEK+4Vo+fqd9M6M4z8nKBW4qB/NNex0ytgghPsBgChC/UodfL+K0itMp9RzdqjMhxPiNa2b1Nddck1liCvYMwxdeeIGuri6qq6tZvXr1pM8SPtKCIT/5yU845ZRTmDFjBsFgkHvvvZe2trZMPyORCD/5yU+4+OKLKS0tpaWlhf/6r/9ixowZnHfeeeNv6GC02u2UYLUQU8V4i7iO9MQTT3DZZZdlZogdOHCA7u5uVq5cmdnH7/ezbNkyNm7cmJWG6EjFYjGUnbtIG0ZmW7ShAb20jMSvf82O/T28pc9gthlipdHFtsX5bNIbIaFgWRBQ/RR31mGlFU41ukhVV2PEYlTk6ewO2wXTPE4Nv8M85gXPDu7HyP9PZbnUF8i9/pwoxc8mIp/shx3zaCXeeBMrmSKGRm9tFFNJgcMJ+eXoBcX2qo3+foygRcFABdH8IE6fl7TPizsY57S6ozinEkLkJMuy+PVbLQzETa4+Yzozy/IyKUAAwh77klZVFcq8pRwIHwCgOza8j0+C1UKIDzJ4U93HNE4pnMOZVdMnuUFCnNyOOFgdi8Uy1ZwvuugiLrzwQnw+Hx//+MePdduOypFe4AWDQb7zne/Q3d1NQUEBixYt4tFHH2X27NmAvYx29+7dPPXUU4RCIcrLyznnnHP48pe/fEwKpMjMaiGmjvEUcR1p8+bN7N69m9tuuy2zbahI7VjH7OnpOar2NjY04N+4ESWZzGxLvbcRNm2ifV8HL+bNxkordFTOIW/xct7S3qK/qx+nBgVMw9u+CCuaojzVBXkWOwdnaaeCSfoD9jHzC3V27tx5VO087P7kUIGtXOoL5FZ/ToTiZzAx+WQ/6JhHw0okGHjjLXSgzakSKQwCKhoOqj2XklezmVg6guLPQ+02caa8VMVnUl9Yz6xLLqJeKcdZIrOYhBDZTAs6BxJous7GP75BaXQ/pIdnWUecg3lmNYUSz3CwOpgMZvbxSRoQIcRh0HDgdY1rTqcQ4hg64k+hx+Nh7dq1JJNJLr300olo0zFzJBd4//Iv/8K//Mu/HPJYbrebe++995i2L+v4MrNaiJPG448/zty5c49bbv8ZXi+W1wfe4VlFqmHQNmDwZvECnJqONncuSl4eB4o6iYQc9CfT+JlBieN0/Pn7MWNdnK3EqFy5EucCO29sdV2K5r80kU5bXHhqNTPLJnbWUi4V2MqlvkDu9edEKn42lez/yzs8YlTj1tP45gVAs1deFCiz0BUPcwqW8mbb60RUD2rSPu+Zqc7isvrLJ7HVQogTnTW4EtXs6yOwaw9G+kDmuTQKcd3ewaGpFLuLUVCxMLOOkSczq4WYFEdSkB7ggQce4JFHHqG9vZ2ioiIuvvhivv71r2fq96TTaX784x/z9NNP09PTQ3l5OZ/4xCf4+7//+2OyKk7FiUdiM0JMunHdMpo/fz6bN29mYGDgWLfnpCUDohBTx9EUcY1Gozz77LP84z/+Y9b2odz3vb29lJeXZx1z/vz5R9VeR3sHpp493LeFDf6g12CiopeXoxcWYllpNvVuJZpKoSoqxcp8UqaCXlREUdcBZuop/KefhjaYusTrhb//6HwSKZPyAvdYbz0hcqXAFuRWXyB3+nMipACZinY0dGGgENBN9nqjgIqCTgFzAHAb0+nsLCJlOSm2ClH0NIWzZJmtEOKDmYCVNjGbmggpjqznomikHWmwQFdVvLoPj+4hakSy9pM0IEIcf0dakP6ZZ57hhz/8IbfffjvLly+nsbGRb37zmyiKwre+9S3ALkj/yCOP8J//+Z/Mnj2brVu38q1vfQu/389nP/vZo26zikNWvQtxAhhX5at/+qd/wul08uMf/5impqZj3aaTkgyIQkwdR1PE9bnnniOZTHLllVdmba+pqaGsrCzrmOFwmE2bNh12YdhDMUekZtBrptGmuPm9Xkty8Ctg5sxKyvJdhGghlAiTNi18SjVOJR8AtaiIlVech/8f/gGtoiLr2AVe53ENVAshTlwDA3ZwKJzXQ2qwUFGBUp8pxLqlJUS5cjrT1PPxzDsFx4oV1NRPm7T2CiGmBssCs6MdK5kkouigKlhAEoVkzXTS2Ks4dE3B6/Di0Uev8JECi0Icf0dakH7jxo2sWLGCK664gpqaGs4991wuv/xyNm/enLXPhRdeyPnnn09NTQ0f+9jHOPfcc7P2ORoaDplIKMQJYFwzq++66y4KCgpoamri0ksvZcaMGZSUlGTNRFIUhQcffPCYNTTXuSRYLcSUcqRFXIc8/vjjXHTRRRQVFWVtVxSFz372s/zP//wPM2bMoKamhjVr1lBeXs5FF100/oZaFunmZjRA8bhxLF/Oyx1bSSoWiqUww2Fw7ceWsb6hj3cDuzMvK2QuH11Sxc62IMV5TpYuqUJVZbapEOLQgqEYFirR/CCKYueHLWB25vmugXjm52Uziij2OVlRV3zc2ymEmFos08Tq6EABUoqK44s38/un1rGvN8aC2rmk2Q4MBqt1D16Hl9549jFkZrUQx9d4CtIvX76cp59+ms2bN7N06VJaWlp49dVXueqqq7L2eeyxx9i/fz8zZ85k586dvPvuu3zzm988+kabKmnLQjGNCS0aP5Fyreh5LvUnl/oCE1+QflzB6vXr16MoCoqikE6n2b9/P/sHC27BxDc6F8ndOyGmliMt4grQ0NDAu+++y3333TfmMT/3uc8Ri8X47ne/SzAY5NRTT+UXv/hFJkfbuFgWVjgCuo5eU0OwpIKGwlcJFLZTEfFzVe2pOBw6efkDpAgB4FZKqS+u4dSZxZw6UwJJQogPZ0UiBFOQcsUw3ClU7LHEqXkxTStrX01V+OjiSnRtXAv8hBAnGSuVwjItFFVBq6qiy1tMS/1iHDNN9ikqhjU4s1pV8ehevHp2OiqX5sKhOsY6tBBigoynIP0VV1xBf38/n/nMZ7AsC8MwuO666/jiF7+Y2efzn/884XCYSy65BE3TSKfTfPWrXx21anU8jCT0xwK0NSdI9k7t+EwuFT2H3OpPLvVlIgvSH3awesOGDQAsGCysZVnDFx4jfxbjI2lAhJh6jqSIK0B9fT27du065PEUReHLX/4yX/7yl49ZGzGHCwypZaU04CWY32W/n7eLv9SGuNRM0xjZhsupkUimKWQOp9WPziMnhBBjsSyLZFcPMUUj4u0HzT69zKOGaUVeWnqzc8eW57slUC2EOGzW4A0vxeNBmzaNph57TFEUexxJWwkAfA4PmqqNClb7HHnHsbVCiPF6++23ueeee/je977H0qVLaW5u5rbbbuPuu+/mS1/6EgB//OMfM7mtZ8+ezY4dO7jjjjsyhRaPhtvppchVyOIFMyjyTVwQbiLlWtHzXOpPLvUFJr4g/WEHq2+44QZUVeVXv/oVL7744kS26aTklpnVQoiJMDJYXVLK9t4AplMBA/J1aHaE+M2uR+lP9FFZ4KatG+aV1DO30j+JjRZCTCVxK05/WxgLi6ivH0V3Agp5TKO6yEPHQIyUMTwWVRVN/RN0IcTxYykKKKDPqkdRVZp7sm+ADeWs9rvsILXHkT3GHBy8FkJMvPEUpF+zZg1XXnkl11xzDQDz5s0jGo3y3e9+l5tvvhlVVfnBD37A5z//eS677LLMPm1tbdxzzz1HHazWFTe6rlNS4J/y8ZlcKXo+JJf6kyt9mehsGkeUBmRoBvW0aVIM51iTmdVCiAkxGKw2gVRhEY3721H9fpzxKL7plaAq9Cf6ACjyObl01nksK69Hk/zUQojDZFomTb0tJJ1RDD2JqnnwKGVoipviPCf5bge94URm/6pCCVYLIQ6fBajV1ag+e4Z0x8Bwvk/TMrBIA5Dvsp/3HBScznPKzGohjreRBemH6u8MFaQ/1MrUeDw+Ko2iptlxkqFYVDweHxUk0zTtqFf7K4CKA7dDw+WQ1V9CTLZx5awWx95Uv3MnhDgxKabJa3oFOxzFVB8wiVv9KA4HhSUVLJt1Jh2RDrpjdloQn8PHkrJFEqgWQhyxtlAHMa89u7E434MjWYtTV5lVnsfO1qAEq4UQ46frqNXVmYcjY1IGw5UUC9x2UNqrZ48xPl2KKwoxGY60IP3q1au5//77WbhwYSYNyJo1a1i9enUmaL169Wp++tOfUl1dnUkDcv/993P11VcfVVtVFaoL/HxsQbXUXxPiBHDEweodO3aQTqcPa9/TTz/9iBt0MlIUcOly904IcexZpslmrRhVUelMKiQZAKDA62Bp2TI+UrOKYGKAjmgHld5KHJoUIBJCHLmuRD9xtwmKQmG+l88vPZc8Zx5up0a+d3hcceoqJXlTMw+kEGKSKCoHh44sy8TEwGT4Rli+yw5KHzyz2ueQYLUQk+FIC9LffPPNKIrCnXfeSWdnJ8XFxaxevZqvfvWrmX3+9V//lTVr1nDrrbfS29tLeXk5n/rUpzI5rcdLAc6cWcH86vyjOo4Q4tg44mD197///cPaT1EUtm/ffsQNOhm5HZrcvRNCTIihlNWKy4WiKCTMAJqqUOjxUOAsACDfVUC+q2ASWymEmOp6CJJ0KqBpFHsKKM0bHlP87uHTzYoCj5zzCCHGzbBiDLCPkNVImgQepSzznNcxmLP64JnVEqwWYtIcSUF6Xde55ZZbuOWWWw55vLy8PL797W/z7W9/+5i2E8CluY75MYUQ43PEweqjzQUkRnNLTiQhxARJD85FUtxuSgs0moIxqgo9lHpLJWAkhDgmlFSKAUcKS3GgaBrTC7Jrm+R7hmdWV0txRSHEOCWsAG3W65gkAfC5dSLxbgB0TckUUjy4wKLPITmrhRAfzinBaiFOGEccrC4tLcXplOWbx5JbiisKISZIQjdJ6XEcbhfnLHCRaCsEoNQzdhVuIYQ4YpZFCvvGu+bQqfVXZz09q9yP26lhpE0W18gqDiHEkUsQoF99GzOdzGzzuXTyPQ76wkmqizyZmdWaouHW3MTTdj5rmVkthDgcLk3iXEKcKI44WH3XXXexYsWKiWjLSUuC1UKIiZJWLXrLGyn1zSduBTLbyzxlh36REEIcoaFgtdOhU5WXHaz2uXW+dNFcTMvCJec8QogjZGHRqbxJvgsSUXArJXgow+VopiTPRUWBGwDviEKKHt1LPB1HQckEsYUQ4oO4VJlZLcSJQvJPnAAkDYgQYiIlnVEKSg164z2ZbaUSrBZCHCuKwlCSOI/bS7G7eNQuDl2VQLUQYlwsxUBRkzh1DZdSTBXn4GcmLj17TBmZq3phyUIUFBaWLEJV5FpLCPHhJA2IECeOI55ZLY49j1y8CSEmWLSgk/aIHU5SUMcMJgkhxHhYuo7idKA4HJQW1EpgSAhxTFkYODQVp65SwemoigMVB9X+CoKp3sx+I3NVn1K+nEUli3FojrEOKYQQo0iBRSFOHId9NVFdXU1VVRUul3yAjzWXzKwWQkwYBRSIOnsIJoMAVHjL0VW5VymEODYMU0UpLETN81OVVznZzRFC5BrFXp1Rl1+PQ7GLJTp1lXnFs7J205TsCUASqBZCHAkJVgtx4jjsKOlLL73ESy+9xKJFiyayPSclyVkthJgoqqmiaBpelx2cdqgOPlKzapJbJYTIJcqI08na/GmT2BIhxJF6+OGHueCCC1iyZAnXXHMNmzdv/sD9H3jgAS6++GKWLl3KqlWruP3220kkEmPu+7Of/Yx58+Zx2223HXU7HZrCKWXLM4+LfE7qC2d9wCuEEOLISIFFIU4cMqX3BOBxSrBaCDExFFPD7XSgqgoKKh+ru4Qyb/lkN0sIkUMUdFQcuJUSZhVNn+zmCCEO09q1a7njjjv40pe+xJNPPsn8+fO56aab6O3tHXP/Z555hh/+8IfccsstrF27lttuu421a9fyox/9aNS+mzdv5tFHH2XevHnHpK11BdOYU1qLoigAlBe4KXGXUOmrAmB52Ypj8j5CiJOTgoKqSFxGiBOFBKsnmaLAzFKpUC2EmCCaxuq5f0W5t4KL6z7G9PwZk90iIUSOcaoaM5XLWFH4MaYV5U12c4QQh+n+++/n2muv5eqrr2b27NnceuutuN1unnjiiTH337hxIytWrOCKK66gpqaGc889l8svv3zUbOxIJMI//dM/8f3vf5+CgoKjbqeuwiX1H8Hn0rl4aRULpxVwzpwyFEXhyllXce3c6zi7euVRv48Q4uSlK5IiUYgTSU5/Ih9++GHuvfdeuru7mT9/Pt/5zndYunTpmPv+7ne/41vf+lbWNqfTyZYtWzKPLcvirrvu4re//S3BYJAVK1bwb//2b9TV1Y27jV6HgkvSgAghJojPrXPZwvPweuWmmBBiYrh0hVsunI0/z5eZ9SiEOLElk0m2bdvGF77whcw2VVVZuXIlGzduHPM1y5cv5+mnn2bz5s0sXbqUlpYWXn31Va666qqs/f793/+dVatWsXLlSv7nf/7nqNvqVb3kK/lEo1HmlrmYW+YCDKJRAwAfPmKx2FG/z/Ew1M6p0t4Pkkt9gdzqj2VZ8n18hJyqpAAR4kSSs8HqoWVtt956K8uWLePBBx/kpptu4rnnnqOkpGTM1+Tl5fHcc89lHh88wP/85z/noYce4j/+4z+oqalhzZo13HTTTaxdu3bchSflS0QIMZFkjBFCHA+6psp4I8QU0t/fTzqdHnVdVFJSQkNDw5ivueKKK+jv7+czn/kMlmVhGAbXXXcdX/ziFzP7PPvss2zfvp3HH3/8mLVVURQaGxuP2fFOBLnUn1zqC+ROf5xOCb4KIaaunA1Wj1zWBnDrrbfyyiuv8MQTT/D5z39+zNcoikJZWdmYz1mWxS9/+UtuvvlmLrroIgB+8IMfsHLlSv785z9z2WWXTUxHhBBCCCGEEGKSvf3229xzzz1873vfY+nSpTQ3N3Pbbbdx991386UvfYn29nZuu+027rvvvnFP5DmUuro6PB7PMT3mZIjFYjQ2NuZEf3KpL5Bb/dmzZ89kN0EIIY5KTgarx7OsDSAajbJ69WpM02ThwoV87WtfY86cOQAcOHCA7u5uVq4czofm9/tZtmwZGzduPKpgdS4sNYLcWjqVS32B3OqPLGsTQgghhDg6RUVFaJo2qphib28vpaWlY75mzZo1XHnllVxzzTUAzJs3j2g0yne/+11uvvlmtm3bRm9vL5/85Cczr0mn02zYsIGHH36YLVu2oGnjS3/o8XhyKqVZLvUnl/oCudEfuVYSQkx1ORmsHs+ytpkzZ3L77bczb948QqEQ9913H9dddx3PPvsslZWVdHd3Z45x8DF7enqOqr25stRoSC71J5f6ArnTH1nWJoQQQggxfk6nk0WLFrFu3brMqlHTNFm3bh3XX3/9mK+Jx+Ooqpq1bSj4bFkWZ511Fs8880zW89/61reor6/nc5/73LgD1UIIIYQ4ueRksHo8li9fzvLly7MeX3rppTz66KN85StfmZD3TKVSAOi6nhN3P4dy1+VCf3KpL5Bb/UmlUpnPjvhgQ7+nvXv3Tvl/d7D/jiE3+pNLfYHc608qlcqJfhwPuTTO5NrfcS71J5f6AifOGHPjjTfyz//8zyxevJilS5fy4IMPEovFMjOjv/GNb1BRUcHXv/51AFavXs3999/PwoULM2lA1qxZw+rVq9E0jby8PObOnZv1Hl6vl8LCwlHbD1cujTGQW3/LudQXyK3+nChjzFSRS+NMLv0dQ271J5f6AhM/zuRksHo8y9oO5nA4WLBgAc3NzQCZXNa9vb2Ul5dnHXP+/PnjaufQP+zBMxSmKkVRcmbGay71BXKrP4qi5MTgfjwM/Z5y5feVa3/HudIXyM3+5MrnZqLl0jiTi3/HudKfXOoLnDhjzKWXXkpfXx933XUX3d3dLFiwgF/84heZ66X29vas65Sbb74ZRVG488476ezspLi4mNWrV/PVr351wtqYS2MM5Nbfci71BXKrPyfKGDNV5NI4k0t/x5Bb/cmlvsDEjzOKNRTezzHXXHMNS5cu5Tvf+Q5gL2s7//zzuf766w9ZYHGkdDrNZZddxqpVq/jWt76FZVmcd955/N3f/R1/93d/B0A4HObss8/mP/7jP6TAohBCCCGEEEIIIYQQQhyFnJxZDUe+rO0nP/kJp5xyCjNmzCAYDHLvvffS1taWKSCiKAqf/exn+Z//+R9mzJhBTU0Na9asoby8PJPnTQghhBBCCCGEEEIIIcT45Gyw+kiXtQWDQb7zne/Q3d1NQUEBixYt4tFHH2X27NmZfT73uc8Ri8X47ne/SzAY5NRTT+UXv/gFLpfruPdPCCGEEEIIIYQQQgghcknOpgERQgghhBBCCCGEEEIIMXXkRmU/IYQQQgghhBBCCCGEEFOaBKuFEEIIIYQQQgghhBBCTDoJVgshhBBCCCGEEEIIIYSYdBKsFkIIIYQQQgghhBBCCDHpJFgthBBCCCGEEEIIIYQQYtJJsFoIIYQQQgghhBBCCCHEpJNgtRBCCCGEEEIIIYQQQohJJ8FqIYQQQgghhBBCCCGEEJNOgtVCCCGEEEIIIYQQQgghJp0Eq4UQQgghhBBCCCGEEEJMOglWCyGEEEIIIYQQQgghhJh0EqwWQgghhBBCCCGEEEIIMekkWC2EEEIIIYQQQgghhBBi0kmwWgghhBBCCCGEEEIIIcSkk2C1EEIIIYQQQgghhBBCiEknwWohhBBCCCGEEEIIIYQQk06C1UIIIYQQQgghhBBCCCEmnQSrhRBCCCGEEEIIIYQQQkw6CVYLIYQQQgghhBBCCCGEmHQSrBZCCCGEEEIIIYQQQggx6SRYLYQQQgghhBBCCCGEEGLSSbBaCCGEEEIIIYQQQgghxKSTYLUQQgghhBBCCCGEEEKISSfBaiGEEEIIIYQQQgghhBCTTp/sBpzMNm7ciGVZOByOyW6KEFNGKpVCURSWL18+2U054ckYI8T4yDhz+GScEeLIyRhz+GSMEeLIyRhzZGScEeLITfQ4IzOrJ5FlWZn/coFlWSSTyZzoTy71BXKrP7n0mZloMsacuHKpL5Cb/cmVvky0XBpncvHvOFf6k0t9ARljjkQujTGQW3/LudQXyK3+5NJn5njIpXEml/6OIbf6k0t9gYkfZ2Rm9SRyOBwkk0lmz56N1+ud7OYctWg0yo4dO3KiP7nUF8it/mzevBlFUSa7GVOCjDEnrlzqC+Ref2ScOXy5NM7k2t9xLvUnl/oCMsYciVwaYyC3/pZzqS+QW/2RMebI5NI4k0t/x5Bb/cmlvsDEjzMys1oIIYQQQgghhBBCHHcPP/wwF1xwAUuWLOGaa65h8+bNH7j/Aw88wMUXX8zSpUtZtWoVt99+O4lE4ji1VghxPEiwWgghhBBCCCGEEEIcV2vXruWOO+7gS1/6Ek8++STz58/npptuore3d8z9n3nmGX74wx9yyy23sHbtWm677TbWrl3Lj370o+PcciHERJJgtRBCCCGEEEIIIYQ4ru6//36uvfZarr76ambPns2tt96K2+3miSeeGHP/jRs3smLFCq644gpqamo499xzufzyyz90NrYQYmqRnNVCnMCsVIrok09hBQJ4PvkJtNLSyW6SEDmrtS/Kn7d2EE2mURVYVFPAufPKJ7tZQghx2AKRJH/c1EZZvpuzZ/onuzlCiENIm5NbYKs3nOC5TW1UF3lZvbBiUtsiTl7JZJJt27bxhS98IbNNVVVWrlzJxo0bx3zN8uXLefrpp9m8eTNLly6lpaWFV199lauuuuqo2xOLxY76GJNtqA+H6suG/f3s7gixaFo+S2sLUAdzDpuWRV84SXGeM7PtRPBh/ZlKcqkvYBdYnMic1RKsFuIEZVkW0d89SfLd9wAw73+AvFu+hOrxTHLLji8jbZI2LVwObbKbIqaoF7d1sLMtyF8tqWROZf4h93ttZxftgeGTh7/s6mZxTSGFPueY+ydSaR5f30zSMLn2rBn4XPKVKkQuGIim2NcbYE6lH/cJ9t0TSxrs6QhRV5ZHvscx6vm39/XQ1BOhqSdCfcnYY5cQYnI1BwxeeHEfNSV+PrOyDlU9/oGh13Z00dIbpaU3yuKaAsry3ce9DUL09/eTTqcpKSnJ2l5SUkJDQ8OYr7niiivo7+/nM5/5DJZlYRgG1113HV/84hePuj2NjY1HfYwTxVh9CcTSrN1tX+vsbOrkJbfKyhluCtwqb7fE2ddnUJOv8ZGZHx5vSJsWO7pTuDSFOaWjz0eOtVz/tzkSScNiR3eSQo/KjMKJ/91/EKdz4s415cpaiOPAsizSLS2oJSWoPt9hvSbxlzcygWqAdHcP0Ucexfe//hZFPTky+MSSBr94eR8JI80N586kouDkCtSLo9cdjLNhn53z7pUdXYcMVluWRcfA6LvcbYHYIYPVWw8M0NIbtX9uCXDm7MNf+WBZFgljcmdVTWWWZWHs2YPi8aDX1k52c0QOsSyLx99pJZK0WDK9kMtOmXbc3ts0rQ8MWgVjKR5+o5GBaJJSv4ubzp81akZLeyCe+bkrmGByL2GEEAcbiKZ4qyWOP9/Ngb4oB/qjTC85vGuDI9EbSrDlQICF1QWUF2QHoo20SUN3OPO4YyAuwWoxZbz99tvcc889fO9732Pp0qU0Nzdz2223cffdd/OlL33pqI5dV1eHZ4pPDIvFYjQ2No7Zl2c3dVBUGMratjPs5OPzquhraqKoECLA/PmzSZsWDd1RKgpcFIxxc3zrgSAtLZ0ALCuwqMl3otXVHdf+TDXHqi9v7eujLdlLewrOPqVuzH+f42HPnj0TenwJVgtxHCRefoXYc39CLSok/ytfRvF4DrlswozFiP/pTyTWvZ3ZpricWIkkqZ27SLz2Gu7zzz+s953opRkTbV9nmEjCAGBb64AEqwVgX+ilSFLg/fA7uZtbApmfe0MJuoNjX5ANRFMkUiYAiqJgWXYgua0/xsJpBWMeu7knMnzs8JFVIH9pRzevbIvQp3Vx+Wl1h/WavnACr1PH7Ty6mZ5G2qQvbAe7RgbGzIEBku+8iz5/Pvq0aizLojuYoMDrOOFWNhjbdxB+8JcoqoL/H/8RrboKsMe81JYtWOEIzrPOPKwbe+nubpIb3sFKJVEcTpynnzbRzRcnsFjKYiCaQtd1GrsjH/6CY8CyLB5f30xLb5RPnF7LzLK8UfuEYikeedMOVAP0hBJ0BxNZQSgjbdIdHA5W94aTVE5884UQh8k0LZ7b0olhDm9r749NSLB67aY2Wvui7OkI8bnVs7Oea+qJkBrRiK4R48bJwEib6NrJMfHnRFdUVISmaaOKKfb29lJ6iPSXa9as4corr+Saa64BYN68eUSjUb773e9y8803ox7FpC6Px4PX6x33608kB/elN5ygoSeGrut4nBoep0ZfOEkwYfLc1l50fURoUHPxTmMP6/f14vc4+MIFs0d9ZsJGEF3XMUMhmp96jUqzD88/fAmtpoYXt3USiqW4eGkV3g9YeTp0rWGYFg5NodTvOmTsIpf/bY5UMDH87xVLa1RN0u9louNMMkoLcRwk3ngDALM/QPyll0nt3Uvw9jsI//wXWObwyaIZiRC6cw2JN9+CwWCZ+4Lz8f3t38LgYBB/6WXMaPTD3/Ottxj47veIPfOHCejR8TEyANgdPLJgoMhNLQMG973eyM9f3ktH4IPzfRlpk60jgtUAu9qDY+7bMTB8oba8rijzc/tB73GgL0p3MI5lWTT1jgxWJw+3Cxhpky0H7Ha83zyQFfQeYvb3E3nst5nVFe/u7+PnL+/lpy/tIZY0Dvu9Rh3XtHhkXRP3vbqPF7d1ZD0Xfer3xP70PJEHHiBlpPn9uwe479V93PdqA0baPMQRJ0dq504ALNMi+f77me3JdW8R+dWviT71exKvv/6hx7Esi8gvHyL+yqsk3lhH/JVXiT7y6EQ1W0wBoeTwiodQLEU8lZ7w9+yLJNnXGSZpmGxs7B9zn7Wb2uiPZI8zezuzZ0f1hhNZeXB7QvK9KcRkMlrbiDz6KKlt2wHY2NRPa3/2ecXB5xnHytCNq95QYtR5w56Dxo6ugexgdXsglrMB7Hf39/LDtTt56p2WyW6KwE4hsGjRItatW5fZZpom69atY/ny5WO+Jh6PjwpIa5o9qWJosokY7a29PUPhBc6cXcpHl1Rlnjv48x6Mp2geXD0aiqXoHuN8Ipqwz4+sYIgexb5xbuxvpKU3yjsNvexqD/J+89jnNEOGrjV++XoD976yj+c2t4+7fyeTSGL43DQcT01iSyaWBKuFOA7M0PBSu8S6dUR++SvMgSCpPXsxRiyfSG7YgNkfAOzZ1J7LL8N98cU4Zs/CNTjbz4oniD//PPFXXiHyy4dId2QHnAAs0yT+p+exEknif3kDKxRCCYdJ/PbxrNQiJ7q+EQFAuegW/ZEkbzXHsSww0hZv7O7+wP33doaJJbMDTTvbxg5WjzxJm1Hqy8za7hyIZYI/m3Z3cP+9z/Hz+/7EpqZ+4iOO3XeImdUdgRjv7u8jGBs+kegKxjFHBJT+vLUj6zFA1x/+xPr39rH9t8/SvL+d599tIrl9B+Fde2nqiWBZFjvbguzpyL7g/DAbm/pp7bNPPt9v6icxIhCXbmoCoH8gxiMv7sj8rgaiyaxg/rGQWL+e0E/u/tDxKGmYbGrup/OgFC1Gy/BFZmrHDvv/+xqIPf308Hu8uS7rZuCQ+GuvE/rxT0jta8Ds7CTd2ZX1vFopc1FPZqFE9t/M4X739IYThAY/5ztaB7j3lb089lZT1jhxKNHEcCCpPzL6/UzTytzUGplD++Bg9cGf054juIl2JCzLyhobhRBjiz3zNMn33if84C9JbHiHHa0DmeeGVjaNFay2LIsNDb28va9nXMG3pGGSzJo5PTyuWJbF3oPOHToHb8KDfVP+wdcauP/VfVkrNXJBW3+MF7Z0ZM6hQrHcDfJMJTfeeCOPPfYYTz75JPv27ePf/u3fiMVifPKTnwTgG9/4Bj/84Q8z+69evZpHHnmEZ599lpaWFt544w3WrFnD6tWrM0Hrk00safDL1xu4+4XdPLelk7agkTV2BGMptrbY44/bobF8RhF1pT6qCsdetRyKpbKuXToH7DFif3eYwOCN86HVz1YiTrfisn8OBrMmm/V+wDmUkTZHTSLadiBwzM8t+sIJ9neHj/pGhmlaNHSFs34vk2XkeWM4Mf5JTCe6caUBSafTJ+1AIMSRslLZA5qVTAHD29KtbTjmzQPA2D0cuM774hfRp1VnHrs/ehHJjRuxUoY983qQGYvh/8Lns97DaNiPGRmcfW1ZGNu343n5FYxwhMj2HWgz69CKi49VFyfMyC+7UCx1WBf9IjelDJM/vN9BakQcaW9niN5QghK/a8zXbB5xN9/t0Iin0vSEEmO+ZuQs7coCN9VFHgaiSYy0RU8oToHHyQsvvo8ZCGACz7++AwoKM6+JJdPEkgYe5/DXaiKV5tdvNpI0TP68tYN5VX5WL6wYdWHaFYzz1r4ezppVSnsgxoZ9PWzZm8DUygFwvLQTMxzBDAYhGKR7dyNasorHHn4JRVW59tqPMG/WhwdYY0mD13cNB2bTgyddC6YVYEYi9IeT/EWrpkHNQ2vvzxoj2vpj1BTbS8zM/n7C992P4vOS97d/i/IBOdcsw4BUKmsfKx6n5ak/stf0suA3v6OstRXP5ZeNStlhxWK8uX+At/b24nKofPHCOXicOlYqhTniJl26swujYT/RX/0Ka8QJrtkfwNi9G8f8+cPbwmFiz64FyyL2u9/hXLEi85z7gvNxnnIKakUFbNnyob9PkZvCBwWru4PxzN/+obzf1M9zm9oAKM5zZm60dgcTPLe5jatOrfnApZIjb6r1R5KjUnj1R5OZi7e6Mh89oQQ9oQTtgRiRhJEp7tp5ULA6lkwTSx37VREvbO3gvf19zCzP41NnzTjmxxciF1iWhdHQmHkcfvwJWhdeCv588pwK1YVuOoIpBqIpInEDn3v4/GF/d4QXt9rfc+befSxzJ3jNP5P+eJpLT6n+0DRoB8+06wrGmVFqpxrpGIgTjmcHN+LJNOG4gd/joHlw1Zhl2e3IlVzWKcPkDxsPZG3rDSfwT1KuVzHs0ksvpa+vj7vuuovu7m4WLFjAL37xi0wakPb29qyZ1DfffDOKonDnnXfS2dlJcXExq1ev5qtf/epkdeG4M9Imf97Wgcehcc7cMtbt6aFtcNVGfyhGfyBOzfQwy2fZn/v3m/oxEwmsaJTlp83KpPdbObeMJ9Y3jzp+XySZFRBtD9g3qF/Y0o5TV/n7i+aOCFYnGFAcJFFxBoMEosPjz8ifDxaOGxwcPx667jqa1J/pjg6sVAq9tpZY0sisEL14aRXL68Yf/3hrXw+v7ejC69K5+cI5OPTJm/cbGfFvE5FgdbZzzjmHj33sY1x22WWcfvrpx7pNQuQUs6/vA59PH7BPnKxUCmOwMqxaVJjJwTpELSjAde45xF9+NWu70bAfMxxGzRvOcZnamh1oMda9hX7gABQWwWBOV23VqvF26bgwTWvUkueeI8wLLHLH+obezBI0bXA2kmXZ2y9ZVj1q/+5gnP2DxYPyPQ5OnVnMy9vtIiC/f/cART4np88qyQShhoI8bodGvsdBVaEnMwOqPRBnS8sA0d7h4HcqEkUbEawGOxVITfHw12pzbzQzs2loFk8qbWYFtIe8tqOLt/f2kEiZmJEIpjFixnNgACs8vDqjp7mdSHsXVjSKBbz+wjvMrb9sVDDMDIUwe3vRpk9HUVX+sqt71A2fnW1BO1jd2cUrWjlNqn1Sa0UiMCJYPTLAHn/5lcxs5MTbb+M+/3zM3l70/fsxUDAqytFrarDicUL/81PS7R3o9XW4Vq7EsWQJ7Zt38hulBkNT6FLcXPGXN7CCQbx/85lMHxLr1hF98vfsq1yONXsxiZRJU0+U+dX59knoQbMuwg8+iBWz/w3VosLMCpXEW29nBauNvXszKZbS3T3ER6QKcZ5xxpS4iSeOLcuyeGl7J619UVbNKSKUNGHER+ngpa+RuIHXpaEoCql9DUQe+y2vKNNJF5WilpbRF84+/s62IDNK+z/wAik64nNppK1M0GjIyJlJJX4XBV4nPaGEHUzqCrO4thBgzNRIA/HhYLWRNkmbVuYiNWWYGObYY9KhWJaVGRsbu8OS+1Wc9CzLIvHqq6S2bEX56F/RUVTF9BIfWnAga79enMT37kNdsoQSr0ZlgR2sBruY85xKf2bfpsGVFGYwyPM7dmCmO9hQ0oM+dw5/3NTGp86a8YE3wA6eaTdy9djIFVleHSIp++ZYVzCO3+PILO2Hw6/HYZnmqGuRD2KaFo09EUr9LvI9Dju1Wk8Ev9txyAkIR+uNPd1ZKzbB7l/dGDUCxPF3/fXXc/3114/53EMPPZT1WNd1brnlFm655Zbj0bQT0uaWAO8Ppg3rjyTZ2xketU9rf4zl2N/9G/f3kNq2DZJJFuYHYOFlAMyuyGNasZfWviiKkjlF5kBfdsrRzoF4ZqVF0jDpCsYzwWwrYY8TPYoLb3AgU1sDyPr5YIeaodweGH+wOt3ZSfD/rgHLIu/z/5v2/MpMKsONjR98LvZhth+wx/RowqA7FKe6aHLyRBtpMytFXWTEzUfLstjSEkBVFBbVFEzp2mUwzjQggUCA3/zmN3z2s59l1apV/Od//ifbtm071m0TIieYvcPBasVtn4CpeT4Ulz0rwhgMVhv792MNBqgcc+aMObi4zj8frbTEPpZncKaDZdlfPgw9tEhtzf48mj3ZRSsOfv5EFIylRi0DyrXliOLwGGmTdxrsv2EFuOaMaTgH72ZvbQmMmkFkWRYvbuvInHAtrytifnV+5vmuYJxd7UF+t6GFeDJNJG5k7kpXFLhRFIWqwuGZRJua+nlnRytWbDgQZMZH/y0enAqkaUQu6qGPc0NXhMbBILqmwOKa4XYNFXi0BgbwWGlWpPupsWKY/f14E8MnjT2d/XS1DqdAaT3QQ1OTHYhPGSYvb+/kqbf20/qjnxD6fz8l+B//ycDzL7KxoQcAXVMzRRr3dYVIGiZGVycdqn1i6MDibPr5h7+ah65lL1O20mmSmzcPt/mttzH27yd+14/xrv0jiYd/Teiun5B4cx2x518g3W7PDDMaGon86tcEn/8zT73dhDEYDdw/GBzft2Ufv/7ln9nVHsSMxYj98TkAenuCWAMBLKBh4w7Sbe2ZG3wjDQWqFa8H/y1fQi2wf6+pHTtJ9w3fZDD27M1+XdTul1ZZIYHqk4RlGDQ8/zqbnvgTZiLB3s4wG/b10tYfY926HcR37CXd0IDR1IQVj2fVS3hlwz7+7y9e4NfPbSKRShN7+mkOBOIMhGIYzS2YWzZjJRK4nRqnzyrJvO75Le088mYjO1oHxlyGenA+2f7ooW/Ulua5mFUxHFwZSgVimtaYOWYDg8Hq/kiSHz+/i/95cQ+dAzGCsRT3vLSHnzy/m00fklNypHDcyMwEtyy7OK0QJyvLsoj/8Tlia5/DaDnA48+8w+NvN7P2/VbM7uwUU52KG0wTq7eXEq9K5YjiqAevuBqqfWwOFp17Qy3DDAQw9uxlf1eY/R9S/DVy0MzpoRvyRtpkU5P9ebcGAix6/VlSW7diGQadg+PHyNmUBwd3x2SaJO67n4F//z6JN9788P2BdXt7eOytJn75egMpw2RLS4BH1zVx/2sNmRQD49XaF+Wl7R2jJrzsaR+dNk1SDIqpauRKqp1twUxAduRNr9DgOLCzPUikdwArmWS2GcKxYR1mxB5DFEXh2jOnc/UZ07nh3PrMa9v6R68CbQ/EGDqDCcZSRBJpLMvCSg6uJlNcmIGBrCB0OG6QMsZeGT1yv3lVw9dDbf0fXpsrGEvx4GsN3PfqPl7Z0ZmJEaR278lE3FObNmcFy7uC8TFvwMVTaZp6Ih+YfiQSN7LGi75xjlORhEFvNH1UKUkOnkk9cqXMvq4wa99v4w8bWw9Zp2kqGdfM6sLCQgKBAACdnZ088MADPPDAA0yfPp0rrriCSy+9lPr6+g8+iBAniZEzqz1XXIE+bRpKYQGRXz5kz4oODGCGw1lBFH3O7LEOherx4P+HWzBDIaxEgtCP7wYgtWUrrjPPBOy8s2bwg/PYGk3NpLZtJ/b886jFxfiu+xSKK3smg5VKEXnwl1ixGN6/+Ru04qJDHG1ijPVl0hNKUHFcWyEm0sFL3Q9lc0sgExyZXqhTXehheV0xb+/tIW1abG4JsHJOGWBfiO3rCtM4eCFX4HVwen0JuqZySl1RZhYCQGQgzMu/eZ6ZMyuwLCeKolAxePFYUeBBURQsy7KXvvUFADjF7Ge7WoAxGKz2uvTMhd3BRRaHcswqCiypLWRzcwDLsjInFYUelY8uKmfJDJN39vexvytMeYGbhU1tzDIa0LHAhBgaDkwe0mcSUnT6BqJolgkMpuOyTN7483uU/M1H+d2GFtoDMcxAgAOJIq4liCMwwN4X1xHPn41j7lyWza/CMC02NfVjpO1UIEVt3SQG719Xm1FOC3Tic+tUFHho7YsSiCSJJQ30hr1Y0RgpFHaq+ewM+nE98CcuOOg8dGTu6JH+9PpOurUC+4Gmoc+qx9q+h79oZXTvbqFT93JzeczOzY9KTNFQO7tQAgPsa28m9OYzaLW1meMpupa5yQfguexSVL8f5+mnE//zi2BZhH74Q5wrVuC57FJSe/ce3CR2KPm8k7cA67mdODSVc+aVMbXnIZwcLMsi3dyMWlaGephV0I3GRg489nt+NeDHAtrNN+isqAMg3d5Bc+NeIokUqisNqkK6p4cudSGWNQPLslj//Fukown2dnfzGwsubu9kx2C6HoALYy3UtAxQ9vmb0Pp7MSrcbOy08+w3Huhlf1M3n75wPnVleZjtHSS3biG1bTu9cR9W/SkoHrsf/ZEk00t8meOOnFld6ndRkufKpDba1R7itZ1dzK30Y6Tti58CrzNzgTY0s9rOUW///Nymdgq8DkLBKKQNntvUhgIsLnFiBgJo1dVjjs2WYdC+az+WZaIo9ngRiCYnbCakOD4efvhh7r33Xrq7u5k/fz7f+c53WLp06Zj73nDDDaxfv37U9lWrVvGzn/0MgG9+85s8+eSTWc+fe+653Hvvvce+8ZMs8fIrxF+xVzymUWgOxHECDV1hjMjwTWX3+avoeN0uDGx2dVGysIDKguHPTXt/jEQqjaqAQ9eIJu1ghtlvn7PEFPv73uzvx+zq4s9bXRTnuQjHDS5Q+yjeuQnLMFDcblxnnUnYWZbVzt6QXXx1W+tAJtAxM9TJ9HSYv0SjGLt20TXdvmEbTRqZgNSh6nGMpO9rIN3YhK7rJDZswHXOyg99zdDN/HDcoC0QY/dgINlIm2xs6mf1wgosw8DYvYfk1q0oum6nC3N+cPoTy7J48p0WwnGD7mAik6bIsiwGYvaY6HPpmd9BT+jwAk5DgcCpsopkZL5ykZvG+jdWVYWLFleys9UeN4Ix++/83YY+rMH6WcvMAFbaIPnW27gvvAAAl0NjTqU/q45N9KCAqGladrxi1y4Un4+uWSV2wDWZzASHuxUXVqiXwOD5hxWPY+zbx4GNz1B70/XoNTVZxxwZrJ5T5Wd3RwjLskYFysfy1t6ezE2+roE4b+/t5abzZ+HtHh53jcZGgguzb6jvaB3g3HnD522WZfHYW0209cdYMr2Qy06ZNub7NfVm3yA8+GbYwdKmhWVZWWNGNGHw8LoWWjpi+EoHOGeB7wOOkK0vnODNPT3Ul+dReFAaqJEraUZOlHq/qZ/51QWH/R4NXWG2tAQ4vb6E6qLxp2E5lsYVrH7zzTd57733eOmll3j55ZfZv38/AE1NTdx9993cfffdzJ8/nyuuuILLLruMigoJL4nclNq7j9S2rbhWrkQrGz4xTHd2knjrLZxLlpLuHZ7VrJWUZNJ76DU1GA32Zyd94ACp3bvtnRQFfc6cQ76n4vGgeTxYlpVZ7m7s3UvyvY2kdu/KzGQEcJ19Jol1bw+/1qEzdAYa/uVDYFmk2zuIPv4E3s98OuviNLVzp313EjvwlPe//nacv6XxOTjwB/Zy7ApZrZcTNndv4u32t1hStpSzqs4+5H6mafH23uHP0MJye2n8iroi3t5rzxTe1Rbk9JklPPZ2Ey29UdKdnZjhMHptLatPq82cKFyoBTgz8D6Js1byqz0xYvv2sSEcZmD7LlLuUrTptVSssE9SnLpKSZ4zcxfdDPRTbiU4O92DasF7MftEYdn0Qtbtsdsx8gZLNGFkZjlWFHhYNr2Izc2BzPPWwABVLVtJ7/Ixa8UKZlX4MdIm2v/P3n9Hy3GeZ77o76uqzrl3zhsbGzmSIAESzBIp0iIVqWDZksYaXdkj28cTdEaeuWfNjDVzdDThrrljSz4+45ElK1qJSiRFUswkSIAgABJxAxvYOYfenVN1VX33j+pd3Y0NMIoS5YtnLSzs7q6u1FVfvd/zvu/zmAbpR4aR1DLuPuzgMSp1skKjJAUOUV3FhYlFvvLQGYRmP9atXI6EcPOk2sYd5jxjShBZKKCfOkXfgA9Xb49TXXV2Ns36+VpSrVmWsdIZrHyejqiP6fkUxuQk4w/N0ZtfIomL+7ReCtXJMwYc1FrZGZdo27fDmaEGmQ7fne/CymZIPH+EIRkAww6qlEgENRZHuf0O0k+NApAdGiZxdpIAsCLc1XOfAmm/zlUkgeq4KRSB+5prKB+yxzitrxf3NbYRrWffXvRDh7ByeVvn/4XDmDMzjjxIPZ5Xm9GDMRTdpIjJ4ZEE+5rWLHYFbzOUHn2M0mOPozY3EfqX/wLhemXdUf3oMfI/+CEXRBSp2pVHL06kcHmKmHNzGJOT6GgYwsSZBhgGmRNnSO9uopLNUyyUnffHj57hJ1oPSeFG7ehAS64wkM3hms9S/OL/iTQtrvF68L/nE5yYSLJ84hRIyfj5g8TdRay6iv+C2o4xNY1r40aANZWFq1IkQghiATeKItjZF+XwhQRSSp47u8ALLw5jJNOIYJBt+7fwfNWAdrWyeqTOjHEuVWR2IYV+6hQYJtrAOn5xpII48wTdmUX8730PnhtvWHMOC//wPcZPz1IJ9eLavBnhcjmT0iv47cQvfvELvvSlL/GFL3yBXbt28Y1vfINPf/rTPPzwwzQ1rR0Iv/zlL1Op82JJpVK8733v46677mpY7qabbuJLX/qS89r9KiTjbyOsQoHSL3/pvM6gIRFIaaEbkJlfcsYS1/ZtLJ/JQDKPKJVoTswR8m53iNOxySX+yyPPEHIJPvPh68mXXchczvG9EV4vslTCJ03K6TQruTZWcjrm3BzPjp/m3eacsx+VM0MkNl+PjPY7MYFpSRLZshM3AVxVnCeGjorEzOWYO30erukhOzlL5dwYCEG2v49SZbDB2LUeUko8R4/WzsnCgk2aa69MMWSKFax8HuHxML1SYGp6Cf30WYTXy0nXFm5oUSn+z//ZUHyjdrTjuX5tvGgVi1hLS6g9PRTKplMQMJcsOkURuZLhJPM6oj5H7/9ShTFSSqZWCsQMhdawl1ypwteeHsW0LP7JTQPEg2/v5NxPXpxieD7LO7ssR/LpCv7xYfU6l6ZpS9wJuOYd1xL2avjHLpBdyZJSIJlbZxex5LK0yDId0iZ4y88/j+eWmxvuVY9LxeNSap2egMznEF4fQlUxFxeRhoFMp5mdmAdcjgQIwJLwUqmY5PO2NvaqAXrKqNB29OhasrquMzZGhaZKniXVSyJXplwxX/H6Xe1SXYWUkgsLWbYtLjjvmQuLpFKNJPPQbIY9kycwzp3D9773kgg3O+T4yckUd+/uQj91itKjj2Fdu4+x7k0MtAYbSGBYG6fVY1UnWzdMPnnTAE3VMePI2Irzux2fTHPDlrUylumCzoWFLBvaw4Tr5OAeP3CGs8eGORmP8d579jZ8p77Sul4ObmI5T7qgv6rHAdjn78GXZsiXDYbnMvzL39nszJ+LusHJqTQRv4v+5sCvdVx5Q+lBRVG45ppr+PznP89DDz3EI488wuc//3m2bt1qtwJIydmzZ/lv/+2/8c53vpP/8B/+A+XylTabK/jHBVkuk//mNyk/d5Di/Q80fFb4yU8pP3eQ/Le+hbVcCwyVplqbudpdy9xVzp51SGatq/M1VYkJIXBv327viyXJf+/76MdedtYjFIH3zjtRorWMmqt+MlHXfqIfP0H5qaca1m/Oztb278yQo6d9KVi5HJUzQ2vMJJ1NVSpUTp/Byq3V07ocLldZfQW//ZBS8uL8YXRL5+jCESYzE2uWsaTFWHqUI5OTToVgb5OfmM9+QEb8btqjdtJm+shJHvnyd5icTyGLBYzxcazlZToSM2zqsEkpaVnkv/8DOHWSwCMPsrc3bBOZwDkljNR1jNExWuvmIL1VMyJpGvRk5vmgMYkLyTVWggE9xYYmL9dvaHGkMpI5Hd2wyJcMJhOFuvX4iR15Ds+p41jpNNI0MEdGaJ8do/zt71J89DEn+14vB6Stb+xQirH2/vL5qztsWVhVHemgV0PL2xO8s0qY8fd+jMmAbVKjGRXiP/wW7SOnHCmQsaUcC4navdkk7fNtzs3REfXa5zORYOLgS+gvH+esEqGgeRrIwTNajNkbbsP9oXtxbdpICYUsGmpzE55bbsZ7221MumqtiQBKzO7WKFxzHUZTy+rFQUK3z2faHXDeW82yTYva2Ki0teG5+SaE14MSDOD/4AechJsSiRD80z/Bc8P+OsmlGee7nn12oGcCBbcPEQyiqYKWsIcbNjZWpF3B2xOV48cBMJcTVM6cWfO5fvIk6f/8X0j/5/9C/nvfI/+DH4KUzNRdQzKXR5bLGJNTzntmSwvaju0o4er1ahpMfudHTDx5sGH9slRiQXjRUVHb29l+01W4qwG8rFbhKaUyVw8f5papY84zt1jQG4hqsLsnrJQ9NoDdel/4+f2k/88vUnrpJae6MRZwOZOHWza3ceOmFmQ6hX7sGIWzw5gLCxgjI7SefZmI374/0yWLdKGy5vlpLi6CYdAui3a31cgoL+ftSWvpwIE1LarSMKicPs2y8NiT0DNnkLpOMn/p5745O4eVTl/ys1eClcthzMy+6nKL6RIPHZ9dM4G8gteHr3/963zkIx/h3nvvZXBwkC984Qt4vV7uu+++Sy4fjUZpaWlx/j333HN4vd41ZLXb7W5YLhJ57dVdvy0wx8YbErNp4QYk6PY9sbRQu8/NeDPJFpuYaJJlAlVvmY5q9VplchJZqZAp6Ax97XtkTpxumD+oXV3EVYvfMWdtTwnswhhjcpKUWEtEpM+PoR87RmX4nNPu/9xwTbO5pylAp9tCBeLVZ/7S8DiJ/+s/kzp+GlkuI0slKmfPMfvjBxoIqYZzcPYcal1RjjQtzIUFzNk5ig8/jFlX5egsIyWpkQkqp05ROX2aE2MJcuNTyHIZK50mO7PA0CMH1nSJGiOja9dlGGT/x1+S/cr/TfmZZxqSZ6WK6fgBpAq6PdZPTOA9cYzw+DBWNkuhbLCSSPPI9x7l5IGXAZjJmPzw8Axff3qUlVyZc3MZCmWDcsXi9MzrH9N+nSiUDc7NZWxJSPNKdfU/ZqxWPluJBKHkEpGVRfbqCxgXLhBYmEUUCxTOXeD8175rG5Nns/Rbeadz0MrmyP3N/0Pu7/8eo1p4aoyP4z1/1iGljaEhKqdOUzl92o4J6saBhapUhyzX7rkV4SaFC5nPUTl3znk/I1zI3NpndaZQwUwk0E+ehL/6H8RePIBxYQQp1xpGSylZqOpkZ4oVZywL1hnTTi7nnbnQKpKzja+X5leYefQZjMkpCv/wPc5Mp9Zsp3j/A5hz8/zyoRd5+NgUX3961JFcc9b7CmT1+fks2WKFcsWWOALbxHZV0hJsGZFLcR0/OzrNoyfnuf9YTfJQSsnYiQtY+Tz61DSTU8sN36kYFuWK3Y1Tf96khNPTr23MKlcsh/Re7cJZxSMn5nji9Dw/eXGKv3zknOMB9evAG6qsrodpmoyNjXHq1CnGxsacieJqkGsYBj/4wQ9QFIX/8B/+w5vd3BVcwdsGleFhZMkeZOqJXWlZmFP2xNfKF5DVtnPh0hDhmh6TWpdd1F884vx9OQmQVeT0LIlSgp5QL64d2yk9e+CSy7n370fx+/HdeSf6d79LZXAQbe+1mC++iFnVsFaCAazqw6P40COYCwv47r4bJRTCnJtrWF/xFw8R/Ow/W9MaLKUk97++ijk3j+faa/B/+ENr9qX48/spv3DYroD71//7a5J+qNfJa4/6mE8VKZSN1ywdcQVvX6TKSUpm7WH61PRTfGzT7+FSa+Tn8aWXOTB9gOG5Iu3ydlTh5dp1MQpLNf2tzZ1hZsZmsVZWOAqo2hzC7aZTFvFJk9vKZedasZaWkFXpDmN6hqvNFQ7LCnmhYSthS3xmhdDECLTswcrluG59nHLFJLI4w7bKtJ3dFQKvtLjHnCXUraFpCrGAm6VMmUSuzP/z+HkKxTLe4SHKuRLa+vV0ZS3Kjz3OgNrC8QsGSnMz0rRoNgqAz87eLyzg//CH0F96yTk+z/XXYa2sONXArRt6YaQu6BCC2+7cy+x997MoPIjlKTqv28INm1o5d+BnPEQzwu3m8ZQLY9sOlAsj9KzMoFoWpR//lK7ddzASbKdUqnC6qDmmck2yNq61dXucNuRFYUukLAsPSjyGcLvZODXEkBJGtDTzQjlEdCHP9LbbOLkUwiyXuPuWa9ijaYhIhKm+rTBhT1w7ZYnlaNReb6aMtn49ptuNOTdHQnjopUjh1jvgiZdw2kEQTCt+Npl2wKh2daE2N6P/y88jTAO1uZEMUeNx/O97L8X2LhZ+fD/tsuQE6e7rrkN4vSReOILa3Y0A+luCfGhvLwAnGmX+r+BtBiubxVyqBev64Rdx79plT64uXKB86AUqZ4Zqn1fJYQtY6BpAyRexMhlkpYK5vIyGhYFAaWvFDIcRXi+d1+xk5shJrEyG5aJFrpgB1U6wXGcuc1aJkBIulHAI4Xazc0cf/vhHKHzv+6BWSeuyjn78BG7hAa0PNI0SLgQCbWAA1/btGNPTlF5eAmlhrSRRW1pYHpuifOQ5ABbu+zmVXe9BeDw0h2oat6oiuHFTKx2P/ZznKkUmlAAW4MEi9vxTRLfcRCLSiWFavPjIIcyiG7W1FZemoFdMrKUl2mSJDxmTfFUMUkqlmFb8WCawksScmkLr7XW2Zy4sIi3JkmbvgyyVqJw5Q7LJB7Q3/D7lF16gcN9PUAJ+Qv/8z1Cq9/rlsJwt88iJOaaWMugnTuIrFXj/zRvZcNfljaAfeGnG8R/43961yTHevYLXDl3XOX36NH/0R3/kvKcoCvv37+elumfRK+G+++7j7rvvxn9RkcXhw4e5/vrrCYfDXHfddfyLf/EviMXenJxcsfjqreG/TujnzmGsdgrFoqxkBJYlMQoFUFXmF1MULC8vBLrxH57CDIaQmkZLOY82Pk7um9+ia/+dDKXTGHUJrLQJyQvjVKoktCYkVijEtTFon8pyR3aEZGA7h8fGkVKSREPceguuG/ZjvHycykMPk7EULCysRBIzl0fduZNTUytQqYCmsas7gP5kGsswiFNgQbW3NZfIUXA3Y9Ulq2ZePEHw/GnEnj2ooyOg62j33osRjlB57DEATLNW2VcYGaHyzLP2eHb2HN4//EzDecuXdErTMzbRXyiyNDGDlUw6xH9ldpZjpSSdhmHLfgh7LDWHhyGfb5gDWPML6NVnQf7oMea7NlExDKjoCJeb2eU0XTEf8ysZymfPIgtFvMYCAeFG9yRQd+/iuz88wNLEPOLEJJ+IB5hOGxjV4xmass29V3/niYU0V3cH+OWpRVbyOjdsaKK3qS4BKqW9j5cxmhxfzvPc+QQb20Jcsy76K5/PLGRKzr5eGRH/cWOVWIxUivy+YZPN3vQ6LKtCSOqAnQgbm0tTyZ4F0yQmddTmJocHMKaqvlkjo/juuZviz+/HZ7VhKEkYH68VthWLoOsNSatSqYIaAlmuzedMBBNKwI7PrFqyJI2rwfcHbL5k5cQZjIk5VCQ+TNpkiVOplCPBuFo0BHBuucLY5BSxkI99dZ4gu/psicd82WBqIY2RLzRU46aXktBZK5axFhc5r4RoshIYywlOHzsPkdr6cosJZ941RBBtaZlSRzsX1wu9kmZ1PZE9V63aPja+ska65cJ8lqbBWpVUoWw4Vd7TK0VMS6IqguVMiWKuVgQ1OT4Pgcbnaa5sQHmtPMyJqRTXb2h+1bHmYrPLg+eX2dEdRVFEg6eC3fG8zJ518YbK77cKb5isPnbsGPfffz8PP/ywo1+9SlA3NzfzgQ98gFtuuYXvfve7/OIXv+CRRx65QlZfwT8q1JsUWpksUtcRbjdWIoGs1LmyrlZYxeMNA4XS1OS09dUv79q27fLbNCv8YPj7FI0ie9quYV/fdahtrZgLiyiRML577kbrsyfEq47c7j1X49+8ieLQkF2NvW8vxQcfQrhdBD79aYyhIYq/fBQA/djLGBdGCP3zP2uQE7GA4vgk3jNDuLZtbdgna37eWbY+i7qKYjpB6YUXEAjM5QQym20g7VdhmBaKECjVCedqJVnAo9Ed9zttLaYFym+HZNwVXAZz+fmG11k9w8HZQzQrO+mO+wn7XAwnh1lYTFEsmxTURbY3b6G3ycfZuiKdTR1hHqur1rdSKQZCKncbdrJILLmd5EZ9Qgkpkc8d4L3mAseVKAysR46OstVKY5zQKBsVCj/5GVp3F/f8yR9T/MlhVsMz15ZNVM7YupPm4hJaXx9NQY9jwpYvGxgXRiin7SSQdeEC8Rk7Az1oZXnZiGHOz+PGIiLLIOxgUj9xksr58zWjQFVBGxzEtWmTI3PRvu9qxNRzjpGJEgzSOdDFlg0xKmfPQRaC3utRsi42lFa4oHoYCfZhWhKhamgbNzKYc8Nxu8K4/ezLXLjqDmSpRErYAYcaCBBPVSurZ2fxTs3gwaKMwoLiQ5qQEB7Upia80TB3BhZZTAZIdnWznM3xi+PzaJqGunUrKvD4kqQjWbC1r1u6YXIZrzQZbAuQqLYeLqSLCCHQensRfj/phIJv335S3jhKLOIEjdrgeqbHhsG0z6fW3c30SoHvPDeOlHDzFp3rBxsDsqJu8N1UkFR8O7uSE9xkLaEE/KidHXYXy/5bUZ+1g/z66owrePtBmibmxCRqZ0dDp4+O4PBoksiDB+h98Wl8hYs8G+rs7bP7bsJ09SOmpuhJzVMWKsn5Oe40ZnlQ60LE445MzaaeOAvpDVROnmS55HGqF5VYlB2LI+y2kjyvtnC2eR0DrUF64n5E005cmzaBqlI+eMjpuvLKqnnywABs6iZydaejvapOTlJ6+SHArpBS4nESQxeQ2GRDoqJgTEzg2riR5pCH8qFDlB5/As/+6/HccgtN85O8x9TRvSEWt+8h+MJzuLGInjuFtdGPurDI0WwORREIj4f3vWsHv3zyFDm9xDuMBRSgx8pzXgmho7AgvEhg4ekT7P9ol9OBYc7OUEGQFrXJiSyXWTxwCHNnC2pVMkKWSpQefsQ+nnyB0uNP4L/3g5f9XY+OJXji9AKmJTFXkshymYJQeebgOQZvu26NnwbY5PaqzFJJN5leKdCZnKXwo/twbdmM733vu5LUfg1IJpOYprlG7qOpqYnR0bVVrBfjxIkTDA8P88UvfrHh/Ztuuok77riD7u5upqam+O///b/zmc98hu9///uo6htvHx5/hQ6/3wQChw+jpmySubx+HXPzi+jeMoWVBLJcZjqVZ14Lk5QujHE77lFCIYILpwDIvPgi8dOnuSHUSiJd4pivCysYZCFXIeUyMUSZiFnilmiJTJtBcL5EKpWkmSSR5+9nNOdixhWmFItxKt6M78IFCAYQd97B4qFZ9GQeYRpIvYwxO4soFFAXFmgOqJT69pCYnkboOkpTnEJzHDWZZqxQoaQYGB0dYFlo8wtcKEmeTATQHz3P3dlzRM0iPym3kIy1ctVkjqsRZEolRLW70nz4EdT5apyXSZM5fbohcE9fmKKcr6uyvHABTHuMVKTE0sucR2E6k8e9tQslm0FbWIBUkqlDh7Dqkl/a2Bj+6m8gsxlObRghd2IUJZvFCgZ5WV0h0x3m7PEpylW+gtwybsVN2fRTWVwiN59A0e0Y7vjzL5HwtZMt27Hly2dzpEoWyaI9l8tnU0TMFQ6M2ePP0Pg8W1pd7Gx3owD+n9+PNj1Nee+1lK+9ds018/BwgZWixdmJBcYn3Wxv+9XK40ylDZIpe99k12vXw72C3y4YpkWpqi/tK9fuJSuZhIpBWFZYJasnRQBZsInOGGU8+2/BmJlBP3rM+Z4s6xTus30GAmqVk6jGTV4svNIkXyw68w97JyrV75ZpkjqJaox0QQmt6arKCJezD6so/PinrEwkAUFIGihuF+160Sa5y2WHtJWlEsbp00wvFSDgJ1us8NSQXS1tZTL0yCDLcT/n5jKUcwUSwkPLatENkElmcXVCyOcikythJhJMKAGusxIsCi8rY1O4dtU4muSFcULgGMGbS4soHe0NyR8rnyfz8nmW5w7T9E8+jlAUKufPI7xetJ6eRrI6ZfsRHK5WVdeHJufns+wbbHZez9RpdUspbU+QoIepC9POGAmwtJRCu4iszpcMsqW1nW6pvM7USoHepgDzqSKpgs6mjvCaGCl9EVmdyusMzabZ1BFeQ2SDbWQb7nrrO6be0Mzsne98J7PVif8qQa1pGjfffDMf+tCHuOWWW5xgZN26dfziF78gmXztTuNXcAVvd0jDcHSYVmGtrKC2t2POz1/yO/USIGDLeGjdXVQujDjveW+9paGS6WLM5WcpGlVdpaWT7Gm9huAffgZjYhLX4HqE13vJ7wkhnNHRc/PNqB0dKM0tqPEYamcHIhKm+OAvkIUiViZL+fnnHYKo4vXyD0YHOaFx7y8eZ9OWzZQefwJzbAzf+95L5fz52jnIZLFyOYcoP7pwhOeO3kdva5JbFuPVZTIoF5HVi+kS335uDJ9b5VM3rwdRyxjHg26a68ybTCl56/N4V/BWwUqlmDp5ABls1DR8+PwhgtkQfreXj+xvZ/r8ceZnM1iKSqlpgXduvw0hGrPFsYCb5lKG1WYkWSpxVaGubaqsYyWTqPF4Q/IFbJPRFuB2c4Hw+z9O7qtnsJJFjOFhjJERkBJjahpzehqj2imBELivvtohq63EMpXz5wktJpCmHxQFc3raqUQGaDULaNWJVIcsEZM6SeGmz8phbNyI547bsX7yU2RZd4hqhMD3vvei+P1477gdaRho3d2oA92IcBhZbQ0W4TDNIQ/Kvn02WY1d0bia8LrBXGIyVEt+CSHY+v534dLy6EdfoquUsg1g6wKW5vYmtAxIC4zzF7ByedqULqY8EYytW8maTRQyQZRIhOaoj8h7PsFdC1m+91wjsaEqAtOSWJbkJ0emeee2diqqG9eGjQyWl2i64SoYsSeD9S1ranMzuY29eG9cR/KJC2jr1oFrmo62KPP+OLlCNyemltlppdAG1vHyRNIp/HhmaJFUXud3dtXM4c5UzaS0/n5eymZpq5TYsW2z83m+XAv+gp4rZPXbCcbEBPrLL+PeuROlrY38330NY2oarb8Ptasmo/WE2s6wEoLnhxF0sEkNcIc5jxoM4Hvfe9E2bMAYHkZ4PAy7WhBnFhDBAAMyx04zBYZNCjcpBiuBAFQnWRvaQhw4p6Ft3MDc6QI5qYKm0bxjC8ETo5hLy9zGMnd/5FrcoVoV3Sq56rluH+VnnsFKZ/BiogQCiFiMokmDSZja00PJ64dyBSuTwRgdxdINiqj4MVkRdneDmUgQSZgUfv4zkJLSI79EGxx0WnCD63ppu/cuyu1hCj/7OdutNC+Pj6LmS1DdXiCfYX1rkE8Uh6kYIwjAvWsnPScnOE8IJRhkKBfjLEHM0RTLDx7mHrGA58YbMWdmWBEeJNidEDMzdqKrZJL5qy/jv+duW0P+ueex8rVJqf7ii3huuRk9HEVTFFxajbSaTxV59GRtbPYnlyhhoaMwY2gkDx8lftNas7bhuQyyWMRcmEdpaub8TIroAz8km87jff4FPHv3Of4gV/DW4Uc/+hEbN25cY8Z49913O39v2rSJTZs2cfvttzvV1m8U/f39+HxvD9MnWdYpGAZEYyitLbiuvZYjk8/jVjz4PF6Ex0My2EpRuPHH46irBGs0yvrdTcgff5+wy4WqasTLaZI+N6eDQdQdO1D821GPnkUpFIlbJtvuuA7tqu0YPkF5bNxeTzJNu7edJdWD1ttLW88AXXWGWI/nRvDNLRIYHaYgNKxKBSuZIuoSfDA3SnPPByj4A+AP0NMaZ3jdAKwDo3kf/oUSoio3JDs7mRwbw8rlUYEJrR9h5agID2G3h7OhHua0MB/Y3UbopC3NRKkM0RqR0tHWhtJcI2ROHz2L231REkrVUJHsNhMcVe1lF2O93PCB92OePYuetpOQbW432pYtztcqK0n0um0FDPCWdXB7QK/gfvFlNrRdz/nFpLPNnv5u8okUbpcHv8+HqWnI6me5kiCjSEKhIJqqoQTcKKJCzFOrNM9oAWLRGkE4p8N6bxPX+MoUc3n72Icv4L3+etQ6DyIpJQ9NXCDmAVksMn56lvVWC1e/Y8+rXW6vGaWJFLGUXdWhaVdkQP6xol6j2FesK9pZSYJeIVgtA1ZaWyjUyQnFZAV13To8N96A/4MfQBoG+a//PcZ4TY4x0hpHKfkc6c6QrNAiS5zLZhFS4pcGeaHVpD/1MuutLAnVTnouCK+T9F9FRriwCrXOWKtQIHP4CBXXIAhBfPsmPPF+Yo8/iQuJLBaZXM6Rfv4QPPYopVSanDqAe3cAQrbHj7m0BKMjhM48QNf7PsE57PtqWvgdsjqHCyufR5omndEw6sI8C6bJovBSRmFYhGz5oeUl1BbbdDE1Pk0Iuxqc6jplNosI2dXZzSEPcyMjyHKZ5bMTREZGQK+Q+8Y3QQhCf/anrGRLVEZHwTCQfX28OJqgVJUk2twR4lTBjjNnkgXyZYOAxz6fU2fHsTI5EAIRDLCSK9tk9VijNJqVXSurmisbzNfNp7Z2RThTlfI4P58l4nPx7efGMUyLPevi3LGjMUa6FCH94ugKrWGvM8/yulXnOKaTBba8XcnqmZma7mN/fz/33nsvH/jAB2iuexCtIhgMcu0lMotXcAW/zTDOn3ckQFZhrSRtsvoi+YxVKLH4mvfU7m6HrHZt3oT3rjtfcbuzudpgpVtlziXPsb15O+7tl6/GvhhCCMfEafW159pr0Xp6yPz3/wFA+eAh5/OpjVeRmdaxslleXjHp+tu/xRgdB0D+5KdrTK3M+XmUQVvKZChxBnNxidFgmb3LJj7L1uXkIoOF0zNpdMNCNyzOL2QdIwKAeNDTEIBfqZX67Ub+u//AtHmYSlDBu3MXg65OTo8eZLnsRnjmUCq9fPvZ5xifS2OhgGURErO0hr0ULsrKSylZn5ljATuAaJclOszGZaz5BZusnr20Bqrw+1Cam3Hv2kXpqaftNlSrFmQZo6NYCzYdrra2NJBk+tFjlJ54Cr8Io3u6EIqCrFS4yVzioNqM6fWxOW9n/4Ui8FxzDe8//BKzwke3kWbp6jvQNm/G8yd/TO7vv4G1kkR4PQR+72O4Nm8G7CqswEc+DIBbSrzN8WrgKYh3tuJxqcgtm1GiEaxUmsrQObv9AAhjcN3GNg5V48OmkIdowI2xfz/60ZeIUsG3NEchVJvotbZFUNJtmHPzTjDULovMdmxCeL2c6duHWjVmbAnbybHBthAfuraLo6cL9PY20xQJsr41yA9emGRmpUC2WOFnR+0kghKLsvnqbfg9mkNWr1ZIriKRLWNakpW83cbbumsru/pjzJ+YQ+3u4oCmUe4J8Y6WVi68NNzw3ROTKfqaA2zrjgJwvGpqKXw+XFu38nSuh8Fbr2W1abc+4A96r6TB3k7If/cfsJIpys8dRImEsdL2hWyMTzjP2RXh4bwSZlUqRgLDsR7233or3bu3OqSwe/duAKYOTwKgBIJ0WYWG50l3S5hkNYkhhJ0o7Y77mZKQ37gNa2EBV3sbnc0hAh//fUqPPoZr184GoroewuXC+653Ufjhj3AJ8PT32l1KeuMkzpJQaWqB2VmQ0k4gAWmXj6bbb2DllzYBZFy4gP/CtFPtJC1JuU4GTO2xn6vu/ddTOXOG4PkLvLMwwU+oud73FZeQ2SzmubMIQImE8f/uR9kQfZynzhbQ+vo4M+6yE266ztkjQ+ytjNE0Pw+WZEnYz2YlFkWJRKicPYtRKJAvVuCH91E+8FxDsm51P4/f/yRPtG5DUxQ+fet6QtXW0eG5DJVz55DlMldds5Hrl45xmDgvqnEkcOa5l7nhxuvXVAANTa043zOXljmXWkLJqjzrWk+bLPHxU6cI/grJ6uXlNBeGp+ndso6OqO+yVduVCyMUfvhDhM+He8cO3Fdf5Wjzvx0Ri8VQVZVEolH3KJFIXHJOV49CocCDDz7In/3Zn73qdnp6eojFYkxMTLwpstrn862RG3krYVmSnx+bpqibvHdPN4G6hGZlZgZdUUEBz8aNuNvayKheu0PQNBCVChnVgwJogQAutwvLksQCbrqvG2TYI2g+M4So6jBHAFdnF6rbTcrtwrNzB9biErGQQmi/fQ+Y6wcx65L8ccVEcbvQIhHKluqcG8O0MKWCq7mZ8MQ5+qwcp5c1wsLkXnOGkCZw53Lo1XXFIwG06t9Jy43LU0dyBoPI7duxFheRlQqT8wIqKqJcRqlUEEJhWfPzqNbFR1pm4RLFaZ5sDle1EEeWSuQnZ1GUtead7arJTrfBS4Z9f421ruPOdeswhKDy5DM8onZQPpHgo9e6CVQ7oQqFPFbdOcmcH3c6NAEypor545+S1XpQFB/C76fzxs2k7/8FiiJQTBOrUkFUvzOerCD9oKkamqaRWrGJI60uSTKVLKNpmpPnlxKG5ovsE1POeTyuRDnzkyPc8ck2NgzYMknpgu58rl+4ALrOsy+k2Hf7tbguUWxkzMwifF7U+Nr54+VQlhlnG6pivMrSV/DbitXYVQL+fB0JnExCpUJIVgCB0t2NTKeRlQoBaeDxulA77OtRuFwIl4vAH/wTcn/z/2AuLKJ2tNN6951oZxNQ1a0PnznCPjOBq7RImzHPqBLkgggiq4S0LOuskzleJoZ+kR2e5tIwVY10ycIq1KqGzdlZslUyWG1tJb5lAypLKECflWe8WCQ7PsUjk2e4w8yTEm4MC9ThYbQdO+xO9oUFuq0iimnSfPAp5MBNyGKRWeHjKpKoLc1kl/N2N20+T9jfirowzkL1vC3deifnD9iFPubcPEpLKwJIzSzQAyTrvADMxUWUUIiWsIctnRFmn7fnmincGCMjNR8SKSkfOUZiJYhV1euvZLMcMivgt2PFrZ1hUksacxV77BhZyLKjM0Tub/8XozOSSrXjVgmHSWxqYUN7mJm5VMN5lYUC0jQQam3sy5cN5lO1+dQNG5s5eeQsVi7HudFzuFu9VPw9CEXh6NgKG9pD9LfU4tdLkdUL6WLDHG17d9TR3Z5Z+fXIcr0hstrr9fI7v/M73HvvvVxzzTWvuKzH4+Fb3/rWG9q5K7iC3zRkLkdl0p7cilAItdOu2NNPnlqzrJlI4MI2FboU1Eu4qntu2I8xNoYIBPB/9COIV9G3mM03Em4nl0/Q7dvA9EqRwbaQ0677RqC0tTmEl6x7oEz7Yqg9bqwzZ5gWASqjIyRxsyQ8rB8dx6U2TtrMuXlcg4NY0iK9NO2Q+os+nb68D5lOY5gW5+ezNIc8tIS9joEe2FlGs86wJh500xL2cs/VXaTyOq7SpSvXr+DtD2kYZCdHSffbulrh46N0zk5yqCWBIYJkSofwCcmi6zil6r2gIQmV58npWRQar28rmWRzcYmXNT9lobDfXFqTzDDn53Ft3XJZslrr67MTOFWy+mLoh190pHzU7i6UWAyhqUjDdMizfpnDa1aomII7jHk2yiy73nUdhfWbCX37a8g0eG67Fe/ttxObnyc0OQXXXMVCdQKitrcT/ud/RmV4GK2v77L6rkIImno6qEgBmkZrpz2mCEXBfe21lB59DKSkcm64+r7g+r0bGD1sa7teO9BUPY5u1M4OzNk5OtMLDFdq91tbRzNuzw6KdZXovUGVl1vbADhdZ0TSGq5Nrnqb/ORb3GzpjzkT5vfv6ebvnxklX9Wat48B1rUEG0hiw2w0citVTGaSBec78aCb3X0x0sUKh84vo3Z0cMwA4+Sc0wYZ8budceTCQo5t3VHmU0UWq1UGQtiyKVYwyMGpHPdU9a3r9yPg+fW5W1/BK0MahtPdAzj3mvN5tZr4SKwfoUaQqRQBaVJsaUMbGKDU29tQvQx2cmt6xZ5g+AI+WoJuZJ03Qnd/Gyerl0PYZxsZ7t/QwvcTEyjRqHNfdkR9qB1NBD75iVc9Ds+11zia1oELFbLFCkXdbFimpJuoTU0XjVGCZzbfyItqL/OtaVheQQDRSuPkQD9+wvlb7emxvykEvg+8H+O//39ZV8qxrSw577aJovXLk+jHTzjasO5r9iBUlfa730Wr9zzJvI7S1OQQzhI4qURpGl/hrBaloMQQHg9C1WiJeVjcsgVjYoL0/CQBadpJLmz3dveunVTOn2e4qPLwhSxKbhy1u5uzcxlnLBo9O4FVbc3f9cRPULEYFFlexB4bh9MW+86exVVXSZnM68wNjda0My2L5dklDqi2MeqC8HLixDj733X53+Vi2bHLQUpJ+cUjfPPBk2QNUJ4fpmX3Nu7c1cm6lrVJiuIDD9jXbTJFcXaO0rPPEv78v6asuXnkxBxBj8YNS0MoHi9cJsnx64Tb7Wbbtm0cPHiQ22+/HQDLsjh48CAf//jHX/G7Dz/8MLqu8973vvdVtzM/P08qlaKl5bfLvHZ8Oc/ZWXvsOTWVamjXXjUkA9DW9SPCYTJViZx6wzGwk6UfuKYHRUB7xIewdKTfj+fjv4926hSlR36Jv7UVX1c7ugXpgk0Cq21tRNbV2tOVWLTBayYidZSorXucrIujV59rQtMINce4Ze4Eg1aWDlnCjR3PWIs1g6xIXYHI0iWMzIUQqG12DFBOpRg27WPUinm8ssIysCg9HIut4+pLkNXmwgJKe5vddbG0RMZQQLXJGCtTG9t7uppo6+mh7cAYC8JLormTRK5MvLubUVeECwQRiTwvjiW4dYu9Pxeb1SZTeRA2vaGEQqxkbAJmtUoy1NeFtylOBRMPFkYh39BebxaLjtaulU47XWvuHdsRFyVKOmN+xOI84/MZUh0dTE+P0IwtH3BAbcGsCJ5+6BAb/uT9QE3jVpZLjpyCbtmaus09jcm1ytmz5L729whNJfS/f+4VCeuVXJmVvM5AS5BMoUY4XZHx/+2GVSxSOX4crb8ftb3RF8KJXXUdn1G7Z61MFlkuE5IVpEtDqCpKZyfGxAQxKvac5yKuQfH7Cf3JH2OMjqGtHyCcriBIQLVLLESFEAa3Lg0hpWSR6nhRqSClRJZ1gtKgz2NxvlxbtwA6Qm5mdAUdhVJJR1oWQlEwZ+fIVe9TEQgQ9rlQI/Yx3mQuMl3so5zOMKSEWW9lKQW8kAepV6icO4dr/XqsfJ4eacd0kdlx3NHNFKpktQTce68l+5Dt/WElkwTzTUQXJ3hJ60L4/RzydlKILEImi1IsILNZ8PnIrNhdHJl4KxQ0MAzetXyG3k/cRizsZ3wh4+hvp4Ub48IIZl31eubUGUragPNaGgb5U0O4d2zDEwrSHffRFdGYq35lZCHHhlOHKE9MsuCqdWJYmQxzjz9Lof/9LKfWmlPKTA4Rizqvs6UKC2l7v0I+F+HpMVomhpkTXpaAY4sVrF4Xaqdt9Hv/sRncmkKubHDPVV0NZHVnzMdssoiUMDyXbXi/KeQhkS2zkC5RMd767o03RFY/99xzBAJXdJCu4B83RKFI8X/8JbpRC2L8H/pgVQbgzJrlrRU703RZGZBLBBpKJELoT/74Ne2PYRksFhrdVxPFBF997kWMUozNnWHef03Pa1rXpSCEwLVhA+U6s0eAaXwoIT9KLEo+mWJOeLlf66aMwrXmCteb9mhrIlCRTsVboZKnMl8j7ue9ZfryPqxMmpfGVnjqzAJuTeGPb99Iqi64ml0pNgx+qifJ+eQK27o2IITgxIkrZPVvK6x0miVvbULVslSmPeOh1OQBFYqeJMbULIVu+zp3Y9Fv5VEyMJ2apDe4rmF95vQ0QQw+aYxRQRCgkQQCe5JkZbPO5O5irMruqJ0dqC3NDaZtgGNCAqB1dSMUBaWpCbPObdof8vNP9Sn0ikl0+2bc+/fjWj9AE2D9q39hd110diCEIPhHf4i5uEg5EoE6jXfh8+HetetVz2FTyMNilTSrJ4s91+1DP3iw4TjVzk48fi+fvGkdBd0kVK1EEkLguW4fhR//lG5Z5FzVeBJFobWzCc9V/WibNiLzeRCCDV3duJ6ewDBlA7HcEl6rJVuPkM/FJ25cxw9emHAMUzuiPruq+lVQHxzFgx6EENy6pY2Q18WjJ+1x5US1ahrgtq1t/OLlGXTDYnI5j5SSE1P1n7fz5JkFO9Cua5PL1em7BTxXKqt/k5DFIubiImpvL7JOi34VSiQMQtjdOUASFxf8rWgdHbgmx7m+P8IzLltXMFdaW1G2lCk77Ys9TX603m5H0gegb9sAHE8BEPPb10J/S8AJ2lfRGXt9MgSuTZsA8E2OkC1WKOhmg1FwQTcQfj9afz+ebIpyIIwSj5PyeEilisj1G9CCCwSnRtEqEiUWrRH5dSZo9V0fanMz3ttvp/LAg1xbmqWnswVPJk23zFJ+5hlnOXedfEN/S8Amq6NRhMtlt/gKwXE1iolgVURbqcb/G9rDLGXKuNavp7K3D+3Ys5ydTvFLrYN2pcIn7ryLheYuHn5mBIkdG1krK4ytTHKVezdmWwezCXu8ikp7MgzQLMs09XeRGJ9hWvGTPHCI1i1bqDz1NKEHH+T0+j2YdvE5IWmQrU5461NeL6xIrl1J4oqvrWrOFiv8/bOjSAkfv6GfePDS45iUksJ3/4HM8VNkXXa3mJVMkjg/weOqwv/rtkHKzx+k9NhjuPdei/vqq9cUK8hCEf3QC7zUvZ2zsxnM+XkiIwcZlDn43Y+A6zc/5nzqU5/iz//8z9m+fTs7d+7kG9/4BsVikQ9+0NYZ//znP09bWxuf+9znGr73ox/9iNtvv32NaWI+n+crX/kKd955J83NzUxNTfHf/tt/o6+vj5tuuunXdly/CtQ/Hy6uOjNG68nqdWRdPkwUQNpGZHXmYqrfR39zwJHAKVSJZSEEnn37cO/dixCC0JMXSFxEFvvrilCEEKjd3VhVAjUiKygRO/GaqtNIzdaNf+HeLrS54/TJxq4zc7EWw4SCfoQQNvFUN6bUyf3X4PPZsQGSntQcOyrT/AMd4PXyQiFGl/DQJmvHsISH4QtJNg/9lKYJWzYwp9rErNrdTWByjGzOHl97tqzDe/0Otid/SSLrRmlqYmgmzY2bWplt7oZl2+BtYmoZHLJ6pXZMiKppNqAoaFs2U0gmqYzNUzA0hN9PvLcTJeZHAHGpM5+xY42ANMkLFSQ2cUUcc3qa1ZHFSqZQLyKr+wMCcfgpRtQ2ZDbLUCrLTcBytBWzpIFpkk7UyPhVLx5zOeF4gQBkEpk1ZPWqV4k0TIxz51CrHQnSMCj8w/cc34ZyMMy3+25C19y8Y1t7w28vrrDVv9Uo/fKXdmdZKEj43/6bBunE1RhHlsuNcx8pkaUyIWkiq88XpbUVJZkkns3iueXmS25LeL24ttpJ4ZC37qZ3uwkLe/2rSe6ArF5jhgG6jqiaI65vC3N+qugMGn5pEI+HmFm2r/u0cNFWLCICAcy5WbLV5J7w215FSnMIoQhClsFNyfM8atq8yTOtWxi8bgfygWft7ecz5IftopxeaccQCtA6fo5Rw0NRqCR9IaJ79pD9pc1pmEvL+I6naZFFBHY1dyKno7S0YmWyXGcuc3BxETXe5JDomdYu1LQtNxIzijQn53E1byBcyDjHmBIujMmphnO5kiliaRd5p0gLcznBwPp2VEXQ5FdwawoWMDE6S/HYMywLD0Y1SWkuLYFpsjSzxOj3f4os1WQiV7dt5bKo8ZgzZk8nCo65YlvES2X4JfqsPHOq19lXJZ1yyOp82SBfHaqPjK5gSYk5P4+5sMC6veuZxU6ojyzWjiUWsDsOE9mybYKZfuurq9+QTdnJkyf5yle+wte+9rU1n33ta1/jK1/5CocOHbrEN6/gCn57oM5Mr5H6KD/5FJXTp53KY22gRp5ZiRVkqeRk+dX2toZA4WLN6teLxcICZtWkya/Zk8VMscJ48SUsaXJuLsVMZh5LvvEsl7ZhsOF1Bo2MYk/ktJ4eEApPqu1UonEQClOKHbg9rrbxf7s2cFiJY1XJ+pXxcw2VcQtVktJKpxlZsIkI3bCYT9ti/6tYypYYXbQ/N9QVDi09zC8nHuF8qrHd/wp++1BOLDHnq91TrSU3CgLcAwivF0uR9AfPoSgVwrLCDlXixkKaFlNjL2Gl04g6KRBz2pakcmMRbqt1Lqhtrc69Z87PN1QsKtFGfS21zyarhRD43vselGgEz/7r0Ab61+y/2m2TQepF1WG+D7yf5r/493T+n39B4BMfx7W+llFXfD60rpqGsnC50Lq6XrWL4nJoqdNvb4vUyGolFCL4p3+C2t5Wd2x9AGiqQtjnamhdd+/ejfC46bFWyW2B2tlJW8Rucdd6enBt3oxr0ybcwQDd8bWt162hS2vk1yMacPOJG9cx2B7C51a5YaN97nxu9RUN0IbnahO8eLBWIXt1f4z+lsZkuUtTGGwLOvuYLxsspEucmU5Xj1+wqzdKtEpAJgu6E9w1aFZfMVj8jUFaFtmv/DXZv/4byk88iVVnvuXaspnARz9C6J//GZ4bb3Tef1mNQSiE8Hi44b030XbjXqezIldeS1bPJGtjR09TALWrJkclfF6aBnq5qi9KwC3Y028TcEII55pdfd0WfvXr/lJYJZ2klJQrtef0aqW12tZG/w3XoHZ0NJgKqoog0NPJO37vLgK/+1FC/+KfO228zjItzSgXafl6brsVz+//HsUPfoDd121hk7QnHKtV6ko8hlJXrbXaDipUFd/2bWy8ahOubdtsoroOij9APOimI1o7D7nmDrQ/+mccuP4eWD/I4vZrmDJdnGwasCu+RVX/VteZHJkl8+W/ZvTUCFa1Onp1wgmgNTexbf9OhMfWxz40miQzdJ7y448zZng5slRxJmt3bG8FZwIvHF3cjNA4cXBtBxzA2bkM+ZJBoWzwwxcmL7kMgH7kKPrxE+QuqusxpqdZnJyncOYshZ/9HCuXp/TEUxR/YZtkSuzk4apGQPn555lbyduE/eIiI0qourtvD6fod7/73fz5n/85f/VXf8X73vc+hoaG+OpXv+rIgMzNzbG0tNTwndHRUY4ePcqHPvShNetTVZXh4WE++9nPctddd/F//B//B9u2beM73/kO7ou6Hd7uKNXdp/VdONIwMKtdl0o8hhKNkioaCLf9jHHppZqZmKbR2Rpu0Gq/GKvPwtAlnkGBi5K7ap2MXkQYTsdHvaFXfbIusv7SPjhWXcJdDfgJ+9Zuu6XuGe/32LIX9d446woJ2mWJnWbCJtL8fg4rjfIxT2htHFso8dBsbZ+ywoUSDiNCIfZeuwEQ+Pxe1l+zFeFyseuD77LjJmBoJoOUkplgbRyeGZ+nXLGTfvVkdRbNSVop4TBCKIh4E8lP/hHqwHpcmzcRDXgcaZ4+K48sFAlIk+ut2jUuCkXIZBzNXgArn8Prauy+6qXIeiuLgl0FOSyCSCDRt8kZj/NlA6taRZ3I6UjAWl6mx6o9jzKpLEuZEt94ZpRfnpyzDeWGa3Oe+iRY5fgJ9JOnsLI5rGyOqfk0+RE7cTK6mHWSKn6PdkU28bcc5ow9d7GyuYYOBKjFOLJUwi/XxjsqEl+1W1AoCtqWLXR96vdxDQ6uWfZihOok8YQQREKNsUWwuj1ZqSDLZbzSTtMNtIcbpEHDGMRao84z+mUlxtOnZkkXdMzZObJotjazz2fPUTQNpTq/2lxaprd6jxSCUc4kdIyeHhDwAWOKbcVFbjUXaUHHNbgegI5SyjbcAZ4NrkP6AxT71ldPpoH3wlm8WLRqhhMrKPE4EU2yw0pjraxgpZLkqiR6JhxHVJOBEVnBGLaTbaFkbexMi7XPtDS19+q1+qWus7HD9uxShKAjaptZZ4ZHyEqVeeFD6+lB6+uzfychSAo3k0M1PXF/S41LktksTXXzo/qiio6oD2NklD5Z1b+uPnutbJ4t7cGacfbSEpULF5hfWCFT0DEmJvEW88SeeBhZ7TgxTImVz1MZHiY4crZBmnVmpTEJ+lbgDc3M/uZv/obDhw/zB3/wB2s+SyaTfPWrX2Xfvn1cd911b3b/ruAKfmNQ6zT8hNeDLJUxEysUf36/8773ne8gP/UNZMXAWllpqKrW+vsx/X6M0TGES7tkZfXrQb1e9d72vRxdPMro4ixlmWNePE/FzPL3J1X2dm/njr5X6H99BWgXPcRmIm2Iqlmq8Plxbd1CulhCa27CGB1lZdmghMJpJYJwuThEM/GFBa6xLJaefbS23t5uVian0YWFmsqwEK4NqHOpolPtBvYcdHXyLn3jjibcdHaajbFNb+i4ruA3j6ennuLo6OMQqWbBIxHCYjPGpl2IdA5FHsLnEuS7y2xJ5lHDMa5r2ceBYz/GFDBx+nl2/+BlRCHBtyd/jNLbTf9SlvWuCtGKC++d7yL/zW8D4Nq6hcqQwJxfwFpcxJyqmS56rruO4sOP2C+EQKub+Lk2bSLy//63ABR/8ZCjzb667Go2uj74UNtacW3b9orE668Su3pjjC3l8Lk1BttCDZ+p8TihP/4sxYcewlpJ4r1MBQXYE07/Rz+K9vzzNMkOsvE2AuHAJSfLAL3NAcaXaoRSyOd6zbJDPrfGh/b2NlSTCiEIeNRLVsBCYxVbvYa9EIJ3bmvna0+POoTzYFsITVXoawk4ia6HT9QkQjZ3RvC4VGIBN8m8TsWwyJcNgl5XQ+Wc/03IKL2V+M53vsPf/d3fsbS0xObNm/l3/+7frTE0W8UnPvEJDh8+vOb9W265hb/9278FbLL0r/7qr/jhD39IJpPh6quv5i/+4i/o7+9/Kw/jFWGl0k5XQ+X8eScxBKB2deLeczUAnr3XUnrsMWSpzLLwolQNb67qjzdUFl7quppN1Z47XTEfWk/dvb9+PUIIbtvSQjvL9DXXkjMDrUF6mvxMJQr0twRekXR6JfjctXurWDGd+6dQ9/zrjPlYypZIFyo0hTzcc1UXHdH6iaK9z67BwQbTWLXuWFYhhEDbshkTiRIKcXEa27V1a8O41d8cIORzkS1WuH5HNwOtISaeHUUJBLDyefaYK4QwyPTv5OrdXbjrzkOqUOHZc0uUFRdqdXw8NZ3mwmIOtbMTf2sz0akLTC7lyKORkyqj5yYdKY9eqza2uPftZXNXlOdbWjCmp3lJifLS9w5iubegB8u4UW1dy6DKtg/fzTP3H2dldAolHueawVYOPWJfR88NzbPtXeYagim1lLKLDiyLRHc3y9neBhNnKSU/OzjKhUdOcqfwYSLs2KhUxpieAiSV4WEmh5+kra7stHJmiHER4FGtgy3t27lta47K6dNYmSwLI1NIXMhikTElAL39oL49yGqAj3/845eV/biUlOPAwADn6jqD6uH1evm7v/u7X+n+/aaw+gyBxsSmlUggq12Xq91ZybyOcLuRuk5vOcX5alJCCQbpa35tki+X8k24uBOpftzy9nYTCnrJlYwGsjpfrj3Xwk1RXIPrG8zcwe46W4UI+AmbLtKFxurxvpaAo1e6uy/GVCLP+LJNVgtsCTSAnf4ysx6VsgwwrfgxTdC8HqTHy1LBiyyVSOLCArx7rkb3bkQTLgIejf3v2EPn5nXEY0F8/qrsgM9l+wUkCiRyZUYXc6T9EcAuUKhMTDJ+6CU27NqIrBikcbEkPHVUNaiRmpH7WN5CbbHHpajfhfB6ET4v1xQTtMsiMamjIFlVmhOFAi0LEyxS69jw5LOsbwtyupoE97pUWitZSlj0WXnGlAB5oTErfCzG22FxGnI5JFBYWCLY08VKrozM5ZClEj0yz4Vq5WImlWdubIW5VJG5VJHt+Tl8dV29ZtUrbHqlwMrRIToQaEiEpjJv+bBSKax8nnm3Srl6zdqx3FpJlyt4+6FcMZleKdDTFGh4rsq6pL3MZKCOR3A0q8tl/Fw6jg54NecKEEDzaygwAfC4bCPk1S7nSDwMyZpf3WoXlDSM6vbtay7cEqPZm2KpOhR5lTyuNi9i1B7DzilhRkdWOLKos3PJICXcCJ8PodgFNWAn7c2FRQSwy0oyqfgR4TAVw0J6vUQ6WohNnecdpj1+uTYM4v/Ih8l+5a/ZnM5wTIlTFCrT7jC/PDlHvm89TNgJLVvHGwY29nJMrRH5Vw224j55Ho9lUF5cchLUKXcQJWIRwMSNRWV4GN/d70ZdnHc6MVKrJozAjPDhQZIWdYR9bxepqkSIqFQYaAliVWVbOqNephMFZKnEnPCxEG1H6bA7LIJtzWQrFUqjo4wotefHtsF2jmTydnFkLkfcp5HM6w3yqQAdHok5v0Ar4A/4KPuDdjeNtNjlKnDbLYPMHzvJgYOnmFL8FAC9rw+QBDFolmWs5WVH/smcnMCbTmH++Cidn/tzZzszK0U2vsWex28oUhquZvv27du35rM9e/YgpbxsEHMFV/DbArWu/d9b1fKDmgOr2tyENjiIUtWitlZWGrLfakc7/ve+F/eO7fg//KE1RoSvFzO52oOiJ9TDze13kCvag1NRLmJQJF3UObN8lgMXJrjv5PN88cBf8sT4sw3rMS3J2dkMy5fQpVOCQdQ6U6KZcNvaz1ua7VbE1lZ0FMaUIMLvd1xyH6OF5372DCeWEhgIhNeD2t4BqsKiVyeVzlGumJgrK8hikdHFS8szVGQBQ60F08vFpUsu95vEd77zHd7xjnewY8cOPvzhD3PixIlXXD6TyfCFL3yBG2+8ke3bt3PnnXfy9NM1neQvf/nLbNq0qeHfXXfd9VYfxluOnJ7lgbOHOJ0oOwZd2VAfP+i4mW8WYvhpQ6ASDnigow331i1o3d1s2HoTrRU7uMroWdKawcn2EtnMIpnTL3OiOMJPexaZbBW4t2/H//734bnhejy33uo8YKVpoZ886eyLa+sWpypR6+ttqBKqh1atSl6F2tbqZKbrP/Pe/s5fG1ENdvD5+zes44PX9qBeosVTeL34P/ABgp/+p5fVvl6Fe/s2gn/4Ge754E0M9DRx586Oyx5LX1NjNXN9hfdrxcXrvngSfil5EE1ViAcaKxdawl6u6q+1nm/tCq/Zx/k6YvLqfjvAj9VVIKxqR64G/D63ivY2Io9W8Ytf/IIvfelL/Mmf/Ak/+clP2Lx5M5/+9KfXGKKt4stf/jIHDhxw/j3wwAOoqtowjvyv//W/+Na3vsVf/MVf8IMf/ACfz8enP/1pyuXf3MRWFuomZdkssk7ORgnUAnXh9eK94w4QgnJbJ8LtxutS8brUhmqg/CXI6rlq1YkQgraIF21w0JbncWm4b7jhsvsmhODevb3cu7eX9+9ZSwq/VtQnQ+pNFuv/Dng1PnnjAB+5ro9P3TxwEVFdg7Z+fcPr+irxS0Fpb0e4Gu8v17ZGY2aPS+UTN67j927o54aNLXTGfGzvieJqbmKfmWC/tcxOK8XdN26iK+4n4q/dT6emUrw0vtKwvqGZtDPZ3TTQyuBdt+DathWAWeFjfLkA5TIC6JJFQv/bnxD45Mfx3Hwz7REvg5t7cSyVq0ZOCAVt8ya2XrWRD3/2gyguF7fsHcS3ZRO7rhrkjhs30VttYU6mcnz/wIhD3oBNRKcPH8HK5ZCFApXhYZ781gNY2azz+cTZCU4+f5y8ITmhxNA3bkFtakLp6qS5Jeqsa8lcO14dU+OUwxFOL+skdu8FQEeQGJ9xZBd0FOY3Xf2Kv9cVvD1Qf+0U6u7T1esFcJ6zqYIO1Rihvy75ooRD9Da9NlPISyWLL06iauvWoVT1zt17ryVWfT4WddPZ3/pkXdCj4f/Y7+L7nTsJ/P7H6o6hVjUs/I338yqu6ouxsSPMYHuIveubGGwPIbz2mNQpi3irKTAZjdIT9yNcLsxQmCXhxb3nagptnU6STAJFVNSt2ygoLgS2N4CiCAa6m4gGGmOKrV21LriHjs+ihEJ1nWOS8w89jX7sGCaCH2i9/MLTwy+0Tuc7PT21SuyxxdqxRqvnS4lGUYBeWSCEQQCTcJXMUvJ5OhMzxGQtAdBUztLuqqX8+lsCiOp1sNGqVb2ec8dZUAMNsWVm3n5eJ3I61vIyXiya66RSMtlCg/zL0unzDefCnJ9nNpHjW09f4CeTFb7qWs9TgV7Ud9/NgrC3Y87OUtJNR7Zllfy7grc/fnZ0mh++MMkDL800vF/fYVY/5kCdDEipRECulUAE8Psa7+n6KtxXghCiYSyKNjd2pAar9wmmiSwUnMpuJR5jXcj+nqHqnO0+z/PG0xS86dqXDYNKrsAhEWekyh/k5TwH5h7mJ+d/zC/jc8x77Xsh5EqRaRun4Es5X+/csQElWIv1Xbt3o0QiBP/ppwhgcrc5g4pEeH0cn0gyVVZQIhHcWHiwEKrC4PW7ne9rqmDPLVdXj8sAJDmhUWnvoCgVhKYRD9tjnjk3j5XJYM7OEsEeG4pC5ZQS4T6th58EN/CD+Dane0oJBtm6sdPpouo2cw1FPp1RH1STUrOKj1lvFIE979nQHkJtaUHr7malWr0dlzr9G7oRwWpMLCW+cmFNV2jE76IzaRc4CmCgI4II2/vkkyYtC5ME9QKtv/w57dJORlqJFad4ICQreLAILkxXpaEsrGyeKDqyYhBJLzvHUd+x+FbhDVVW56ptMaVSac1nq5Od3CX0Bq/gCn6boCQSoNkZeM/+6yk//XRDcOfeZ2vMKfEY5vwC0jCpDNeSNGpHB2pnB4FPfJzl4jLPj/yM7mA3V7ftedVtW9Li6emnKBkl3tHzDlyqm4WCXUUVcAUIucOcntRp5VrmOeh8L1OoUNCzjE0/RkHOIbGYTT3Djpu2Osu8MLLMM0OLjl70xdWRro0bMWfn7Cyhx35AaapCb5OfIwuHKZOkmd1ooRBKczNnk7pdcVoqYa2soKPw+JFRlpv9mEqAzT3ttsuH282Cr0wpU8aan8eYnARFYUrZAZ61hGGGUVrrBuCV0oojg/J2wCqJ9IUvfIFdu3bxjW98g09/+tM8/PDDNF3CTFPXdT71qU/R1NTEX/7lX9LW1sbs7CzhcLhhuQ0bNvD1r3/dea2qb89qz9eDkdSoPZEzLYqVEP1lwQXjaiwFKoaFIjQCdBCuBjR+LcC17XsJh5rpja5jrjAEwDMdKeY1Sf2URgLP9hToLCzSsv965321vR2q5mOrFYhCU1FaWgh84uNUTp3CtfPyGtFqb6P+e70erLZ1SzUBpb0mnem3O/pbgg2O0JdCe9TXUGnR8galEOoR9Ggs1r1uCnqwLOlUswkBt29vx+Naew+8Y2sbHk3B61adCvPWsBevS22ohuttDjgaw/WkdzKv0xP3OwH/xa3Wbxd8/etf5yMf+Qj33nsvAF/4whd46qmnuO+++/jDP/zDNctHL0pQPPjgg3i9XoesllLyzW9+k89+9rOOodp//a//lf379/PYY49x9913v7UHdBnIiyZl9ZM0EWgkerw33Yhn3170x0bAsJzfzpaWsbtzcmWDfNngp0em8LhUfmeXbdQF0Br2VBMTCqF//mdgGK+aTPa6VDa0h15xmVeDr+5ZW19NXW+46HerBLwaA95Xvh+1gXUIRTgaktolKqvrITQNtasLY9xuJxV+H9q6/jXLhX2uBpLjnqu6uKvfT/ZLjwE28bZaze7WFAIerVbhVSVJ3Jri6CauYlNHGCGEQ3SdV0J2lWG5TLss4QsHbKmxntq4+5FbNzFy/jBnRpdYULyY0qLUFOKWGzewe6DVSX5t746yrUpsCSG4Y2sr3z06TxGV6YkFfuR28bHr+1EUQeX0adJzyyBqSYChmTTj/5+/on33VozzF3gpqWIpUQCyLh/6NftgIosANt1+PamDQxhTUyxbHtTmJtzXXUfxgQeRwKLwoMTt5/8QIW7o7mJhZhmrUIBVWQhV5UKojT7qJvBX8LZEY2V1nQxIveFrKES2WCGZ052EdkeVyC2hoIXDdMVeG1n9apXVGT1D0SzS/K/+JaQzKB3txI7PMpWwr61UQact4muQQQp4NZSQF+9ttzXIWtRD+P2EjbXbDvtcfPDa2j25pTPCgaCPCrDVrF2/VixGT9zHyFIRbfNmVtq2s3nfJqZ+/DBQ6wDJCxeBrh7k2JSz/sthW3eUp4cWKVVM5zmt9vWDJTEXF5nBR+mxx8mgURQqSiyGsVrBqGkMDnYyM2RHGPUV45HqNpVYtKE7BaA75CKVkSAlbVaRgvSQ9IWRpRLNskSfnkZRVCxLsq07ijVpn4N1MocLSQXB+VgPlAyEtxap5pcT6IZFJlvEXF6mReqE6qQbMvmyY5ApLYuV8WnqxVukYTJ+YdY2o5UWOgqnY720xNex6L0AerW7N7mCEo0hhLDP7cV641fwtoOUksmqd8NUoi5pb1nIYo1nk5mLyOqVDLJiQLmM7zKV1f6Qh1X7UU0VryuB0RKzOJ89SW+wH78Wp57xC1TFwSR27OarVlYrTU1safHw4kyOoj9FxCvweVz0NGfwj+p0yQJGdDPHluviO7+fZY4ynbefyZY3z0pLig9OtXGkKY3WZLLEUbqxY9jWphC+D36Awnf/AaW5GffOHYDNuQT/8DN0ffvb3C6TPNlUSwirHe2EUksIwLV7F719rQQvpMmVDHb1xQj2dpC/ajfBE0usuAPISIT0ne+EC/Z+Nne1QLU+xDh/AXN2jqiMMOeJgKbxRMFOoqmRMMLnJ1H9rdTmZq7uj3PYrWGUdbaUGz2ROqJeMO3fbkiJIIWGhu2psloQpHR1oRoG5vw823uiNLXFUbw+JwnoL+cJ+JpIJTKgqgi3m6v641gnTjvbWb+hi+F5+zdaJ3NYFy5QmJxEFku0OBr/okZWV6+npnyKfCple2tIi2g1eWdOz9AZ7WFkYpGC4UZKwVtZs/WGZmctLS3Mzc3xne98h3e+8524qkG+YRh8+9t2G3ZzXZv0FVzBbxtksYiSy0E0htrZjtA03HuvpfT4k4BNermvuQbAmZgADWZNq5WdAEfmX2QqO8lUdpJmXwu9YTsMKRklTi2fxKv52BLfgqrYk9mx9ChnEvZAE/PE6A33UrHsYKsjYFcOnJhMERCdtHEdLv8SeiHGknWMsm5Sppad1Q2Tp0fOsg6bXFp1Nl/Vi76YpHLv3k35mWdYtlwUQjEUoCfupyVmkJy3ScMVcYY2rsW1fj2LrEfFNh7SXQUKgRSBXBxDK6O7vKQ9AeKAcLuZ95Yop1w111zLojI17WhoSWmR5gIVcpSUWXzuWoBvSpNUaa3L+G8Kr5dEuu+++0in03zve99zxszu7rUEg6qqtFykifzbjvPJC3ZUY5rElge4tTDD+cHGqv11vmu5oV8n7ovRF+5HqWaid199DyefPkfRDeltfehS4tN1dp/MkHIZjAWLmAEvD449wEc2/i5+l33NXOycDbbJiFBV1OZm1FtvfcV9VkKhBiOzerkQIQSea695Xefg7MoQI6kR9rbvo8X/2/f7qoqgJ+53ZDZezVzxtSBwUTVA0KsR8gY5M5NGUwXvvbrb0Xe7GJqqcMuWizo/FEFPk5/z87Wg/rrBZl5aPMZcfo5u91XO+ys5nXLFclrn3o561bquc/r0af7oj/7IeU9RFPbv389LL730mtZx3333cffdd+OvGkNNT0+ztLTE/v37nWVCoRC7du3ipZdeelNkdbH4xo1WjMQKxmr1bM6AhQXndVlVMQqN1Ru6YVEs2YGzW3FRqH7uVmxSKZUrcuT8AmML9vPONCpUKtUA3K86yzuoVBqO4c0cy+WgSMM5pmQmTyFkP+9TuULt2M3K2n27DKz2dszJKYRLoxyNol/ie/XHo7a3Y1SlALSBAYqXKDi5JDweuGo3xpEjuK/Z07B/IY8gna9NlDtjXnb1RHmozgjZrSm0BhQM08JCIjWNC3oAkcsjTZMuI4MZCFzyuFuv2kLkbDXpaBrM3f4eeqPaK/4+kcFe3vP8IX7q7kNfWWFsIcyZqWXWhTWKP7qPjNWKJSRKawtyZQXLMHmmFODuZ59DAhfcg1iWRCiCzLoNJCuW8/t0hjVkUxNKOEzCzKPeuR3T48F69lmSK1nKmoIaDiMNg5OTCfbdcguL3/k5Vl2LrtIcY2guQ0+vRFWvqMq+nVGfSCrpJqYlURWBlbFJSgn8YEFl7lG741i4PQggRIVdZpLDrhau2db9mqWDLqUbHajKB+X0LN8/+w/ols67+u5iQ+cGoFYpDHYSti3iW1NZvQrh91/SNVHxBwhXGoksj0tZ020U9rn41G0bmD/+S9rrNHStaITuuE02CUVhWvgRikI6GKWerC51dJGTtaRd6BLHuwq3pnD1ujjPD9e6KlVFEN26kaVkkoUKlHWTYrXqUInF7K6cchmlKc761hBPDy2uWe9qJbpykTEoQnDNng2ce/IsfrNIb9DC2r2NkZwX4/x5Wq0yoeVZPn3rrZR0k664n1wqZe8rkm07Bzg5n0d2dSFo1PbOLadJ5su2VKRpEpM60V3bEGeKSGAlX3G6gWQ6Q2a1kURTHbmZ5dklrGRtDqTEmzgymcZs74JJOwlpDJ+3fVE2bCDsa4O3vujxCt4kdMNyjMtLFRPLkiiKQBaLDfepla3db5WzZ0k+8zy6y4uvUkYFlFCwoaAOwBf2s8pqxgOe19wFmiqnWFafJtaSwxPIoarXN3yuIvFJk4JQsXJ5W4ZECJRYjPbmMB81jvGca5mM3wMC+poUrjdtXsIXs9hYyvAjaVIUKgQ8uFwVoDp++HykXQZlxWLZo9McDbBSqWBhx2htYQ/uvu24/v2/A7e7wf/HNbieyL/9N+xTVRKnFjhZNWEXkSjxbZvweFvxvvt3UFSFT9y4jsVMiXVVDsT/ux+lZf04c/MFBDCFF6iS1X1dUG2cLr/wArJUYruA8WAvZbcPsxq7iEgUJRpBLRUBQbSvi6aQh9+L5snOLNBdKdjSKVJCpYJbU2hywRxgIFCr2t5X98fQqsclsLt5te4u9ty5xS7eqUuE+QpZtIKFfuK0LVfZ2sKOG7sxRuxYTyiCbVdt4PRL8yz5XFydSWJM1jpGnA4Py3KMzVflUpplmbH5eZSoPVbGqu+bU1Nc264wffwUXX6BGFyrtPGrxBuane3du5ef/vSnHDlyhHe/+91cX3WoPXjwINPT0wghLikRcgVX8HaElc1S+IfvgdtN4KMfQfh8WHVabqukl/vavZSffgZpmHbbScBuQ1EvUUWrtjQj6syORtIXnL+fnz1AV+ijDCWGeGHuICXTnjAeX3qJGzpuZmTGw9n0aUyvHRRfSJ2nbNXaw/rD/SxmSo4+3ZbmjVzVv4+fH52myBJZOYGiCNqjPmarwvcvzJynp307Rd1kKVOboCZyOv0X8WZqZwe+f/WvePboHErFDir7WwJovlrQp3gSyLJsePApAR9dTcdYdEu8njkW3V5EOMxyGiIeH5PSS9JbokdVsQp5yp4cmulGSyQwAwGsRIK8Z4zFyCzCpRFta0IIUIXqVFQvFxuzkr8pvBES6YknnmD37t38x//4H3n88ceJx+Pcc889fOYzn2monp6YmODGG2/E4/Gwe/duPve5z9HZ2XnJdb5WvBXEy2tFySgxlpzAkhZKWcUs+8h4/VSqxg1Rv4ur+qL0N/udSUSprppADAxyk/uf8djKc3auN5vF297D7p4bKP/kJ+S8cySiMdLFNC9MH2Jfm+2VYEXCNQKoCmX37tdMBAFYnR0YVR1dvanJCUheLypWhcfGHsWUJoVSnrv73/OWkmJvFdY3exieTaGqgla/0nAu38jxaJgNv5FbmOwdiNMaVOmJ+4gFtNf1ewG0hzSGpu11toQ8+FxZ7h+xpXZKPgvDsBOFC8kcSymPs32XsBq2Va+v/ZtCMpnENM01nRpNTU2Mjo6+6vdPnDjB8PAwX/ziF533Vo3SLrXO5eU3N76Oj4+/4e+6h4bwpmoTceP4cbTq69zcnGNQtYps2SKZsn+vMDmGhuwERSFTIFm0WFQSGGU/yZQPU5S4UH4RgGjpGsqhIkNDdplM1sxSMAu0ulobfu83cyyXw3yqQjJlP8vPXSjw0pAkr1tYEpJZezycHtfJzL82YkvZvAlPNktlw6AzMbkcxsfHUV0ageo5zUfCmENDr33nN26AgXW2UVLd91qFwayuE3Qr9EU1OoIVjGSWbCbPanH1upjG8Dk7kW8VCxQtC0W3z4NHGnSlx5mP91O81P5ISVBaKOk0lcFBrFj01X8bwyCUWeYapcTjUlCJRHj6WA7mTuCenCQRbaIScuFujkAkiD49x7l0md68hVuaLLd5keEwVjhMVgrE6DTJnP37JGZ19EKRvC7JKTA0NoYlwbX3WmYPnSYfbG7oCnjK7yWx61rKZ2YQpRIBq0LK001meQW9I4BPffNJvyv41UFKSeXkSYTbjWvzZsoXdQgUygYhn8sxO0vjYkZXUFb5Yo+bkKygAvusBPu6IsR2dvFacXFltaIIPC57PDiXPIdu2ePgSOoCG2I2WR3zN5LVUJNBUhTR0NEhFAUlGFhDagm/j4h+kSyX+9IUQTzowd0WppKpzQmsaJSY30XAq5EvGUyvFDAtSdbXmGwudfY0+FG8WqXnnv44L1xYdpLKHVEfbREviVgMc3GROeHFqkoFKV4vypYtWLkcSjRKU8hDPOhmJVd7dtjyBtXK6ou6kJRwiP7bb+CPoz4mpqcJ3/FO9vgCzBwYRj93jA0yizk13eChYaXtpIVQFfbcvpeh58Zr26ojq7MraZYTWcx5e24ZFxX8v3MXwaEfkZUqKyXTsWQzl5fIVHVw3dddR/nAcwAkFhJ2ZTXQrFlkQiFKuonS2oKyknCq5mWlgjk3S9i3hcoVsvptj/ouCKusk3zyaaI7t61JKFl13Rzlw0fICxUMw9GLVlpaQFGc5YSq4A/5WG3giV8kAZLTcywVF+kN9TmFcqvv/3zkZ+hWmYjfRUUWKUfXdoYEMSiggrTwSxMlGrENEiNRWmSJkjeH8NuyokXNQiJ5tjXJSvoxbkwH+YiR5udaF0m/aEi4Ca8XoQim/SUqisQXC+NPm5hFWzKsrVooczkJx1Vz6ndua6+R1UBoywb8V9eZ0/rdDdJHQggikQBi3r5pxpbSpOR5iixwUDMotOXZsxBwutPaZYnPbguyuGEHZ3/6KOFIgNLV6zkytoLW1w9ArDpWtEb9RKft9VqZLOVvfpPQ6dMYn/1ndLotVgVkhaYR8btY3xoiW2r0DxjoiBKu7m8g5HP6sny5NPrqeC4l8fkpKv/1Pztdd2pvLy6/j9+/YR35+ZfRX6gbD1WFeHMc94rdrbH6XFslq1tkyX7PqmqXr1ZWT03RNDPDp4xlyAqm5F7eytLqN0RWf+Yzn+Hhhx+mXC4zPT3ND3/4Q+czKSUej4fPfOYzv7KdvIIreK0oGyU82utrTy8++KBjPFJ64kl8d78bq84oUa2K3avxGL5/+ilKU2P4b7jF+VxpWmuc6KkzNjOliUAgq/1YiVKCb53+JnPZJG5VcWQ4UuUUXz/+Q5TUdSwyjs9XZF1LgLSeJpewJ3GqUFkXGeDwhZSz/s2dYQZagnbbl1xPlgl6mwNE/S7yJYN0QSdtzDO8tBFvcxEpwZQ6ChoruUtrlD4xV2GxSlTHAm5298U4vTJBT7Ofom7SFtbIzKZwU6tMiMRVSimLsGGCO4O/vZm8VDENL5OzftJSI6X4KIaLVESBdNQenkPZFqLTBhKJjI+DpSHLOv5iFlXE2du+l4NzzwM2WR3i0pWWv068ERJpamqKQ4cO8Z73vIe//du/ZXJyki984QsYhsGf/umfArBz506+9KUvsW7dOpaWlvjrv/5rfv/3f5/777+fYDB4yfW+FrwVxMtrxXR5ikQ6SblkEE76qOg654VGshp0xxUNb6HI/GR9/c3FcOMtB5nT7WumpdzKqDDh7nsYMIuMZp9AFou8kH6BUCJESZYpWkU6ujpwTU5hrFuHvm0rVigIQ0MY0mC5soyFiYJKs6sJTaydNCltbfjFSczWVoq5bANJ83qQNtIsZ2xyLJPK0F9YhyLs++s3+du8XkgpuSpu4ncpTI2dv+Qyq8dTNAuUZImoGrss6bu8pJNM1QKnlcUC43IZFzCfe6Xr4fKwdItspoBhwY6olyNnh0nmUgCU0qdJp8NYEs6XMoQqyyRTdmIk5cozNNTYueF2vzZ9v7crfvSjH7Fx48bLmjH+qtHf34+vLkn7eqBPz1CJ1p4nApDV1527diNCjePf9EqR2LxtnDrYH2XLZjvrerYwS2bpDClxgjHNRVP0JrIsoAp7Qmh5pti3cx/NIQ9z+TmenziApVjEWmPsat5FsVhkfHx8zbFM56Y4vXKabfFtdAdrbfGpcpIXF1+kO9DNlvhWXgmBRIEzabu6qOTxslgsOc4xsaj9/85tAw3k0itiyxa4+fImqkDj8WzZglk10VQv0rx+o9gC3HqJ98crc5yftydQt1zVyfpWO7k/Yy3y0oJdzQzw7soiXZEgri1bcG/ZcsltWJ//11hTU+i9vUzMzLym66x09VWEzo/wggDp9VKQHlomp9CjTWheP57Nm+nrjLGtK8xDJ5qQ2Syn2ELvQAehpca4SGoKMc1CCLhqxyDTxhwjVa+NaSvMqekMO3o24LlnE5GxxjGk6Ang7o4T8LYhUynu2drEQwsSTRW4XG8fWbP/f4G5tETp4UfQNm7Ac4miKmPoLPlvfxeA4B/8E0oXVRsXdJusXpUBWRTeBgkh4XbTI2sMoXdg3evav/BFZLXfrTrPzwupWtHLqiwgrK2sLuqG48kQ9Ghrnr8iGISLyepAgLDWSMy/kjSW0tIM56v7owisSAQhBH1NAc5UternU0XSrsb7tNjaiayr+r74eC9GwKuxvSfK8Qn7vuprDtAa9nCkSlbPCj/RqnYsHo/dOVclq1RF8L493Tw9tMjYUh4pJb1NfpSq18fFldVKLIZQFLzbt2KpAqGquDWFe2/ZROaZH2LlJMb0dEMie5U8FpEIXXE/zSGP4wckVA2haUjDIJ/JYRw96bT8t2xejxqPEXSrZMs4nT1S17GSSTLChRIK4r3tVoesXp5ZAksQkCa7+5t4dtWsWlXRtmzBSqcwRkarOsJFQj4XjS4CV/B2RL28kDE2RuLwcVwnXsb//vc1LCfrfBXy45OY2IV0q3rRalMTWFaNrI5EiAc01Jx9nfQ113SepZT8fOSnJMtJ2gMdvHfgfbhU+158ZvopsnqdzBFQDHuov1OVaIRgtsJi1YPIj4HaZMdgri2bybaHKfuXcVVNTfOKQdplMBIsohpZHmCM3xdtfCKQZP6mTp6YsXkbTWgYGIhAgNFgAeFxI3x+ulUTX04Q87sv6W1zKXhdKh+9vo8fHJpESsmG9lfnDkJ1ybOTqWfJS1v3GTXM6V6FnYsWLlkrJnB3dTKwvpOBz/0TANIFnaPjK06eYdUnpz5+Nc4P2x1xpol5/ASd7YMcXf1Q07iqP46i2JItmiqcqvudvVFnHfGmcI2sziTZoksmECjA7ca8wzcBaOsHnL9dgwPoL7zgvPZ/9CNYmQzND59kVviQBbvYKISB54braXnOLvJYTYStavibidrIoq3re0uJaniDZPX69ev58pe/zL/5N/9mjclPU1MTX/rSl1j/KwqEr+AKXisOzj7PscWj7GrZzY1dN72m7xgzs+jHXnZel597Ds/+6y9ZWS2l5OfWMRZjC7wj28WWJntiqsQbyWq1tcWRCAHIlDMNAwfA+EqCmZUCQhHctfEqpFpiJjPLQrqIj2F0mUYvwFJWoyXswaw+jHrDfbhVN8N1be4b2kN43So3bWrh8KhCU3Q9ineFFl8rTV0uHr9wClOWOL6cILDYQU7OsCBfwC3C9Gffs+acTCbyTmCoqYIPXNuDx6WSLqcbKgoUTwLKtWDP7U9j9PdjLiygdrTT6Q9zfj6LCz9hBkgpJ5FAMryEpdQeztnQEvnACu6Kj353hbShEM9F+b20j3Xv+RSWtOrI6qW3BVn9RiClpKmpif/0n/4Tqqqyfft2FhYW+Lu/+zuHrL7llloSZPPmzezatYvbbruNhx56iA9/+MNveNtvhkR6s5iemiJohvHkMoTLzbjdHszuAWLVqpYN6+Js2bC2O+FirDP6eXrqabIrWW7ZdCsBfy3wWppMMJEbB0DtUDm1eIKyWcb7ob3saflsw3qWiks8Nv1LctQma4VAF3f33bN2o6+BDHotGEmPEJuJOq9b+lsIiTDj4+O0drcyX5mnP9RPwBW4/EreJrgcHVdPikmX5IcXvo9u6dzaeRsbohsv+R0RzTJWN+nesqGdzR1vThcYYPNmg7JhEQ+4eXGxSGw56nzW1REkV9BQVUF7dyuxFXus37S+mS11po3nz1+ajP91IhaLoarqmjgrkUi8qtRaoVDgwQcf5M/+7M8a3l+VGEokErS2tjasc/PmzW9qf30+nyM38rphGEitLiTVK3YVL+BvaW5o9QQwkxW06udN4YCz3VjIRzYxgoKCbppk1GGKcgmlygqX1XlcgTKmpvH0wpMomoKCwpn0Ka7prj23Lz6Ww+OHSespZmdn+KOdn0VTNNtbYvJpVkoJpotTtIRbHYmvSyFeUZx9TuQN5+9VCAGxcNAhU36VcI5nx45f+bovhdu2d5EuTdES8rKtt9k5po1dcU76AxhKgt1Wkg1KCRQNX3sbnstdO34/dHTYnQ8zM6/pOlO2b0eMjbOeAqO5HOVkkjnpxa+ZaO2taIEATRE/V69v5exCgSlNowCcTZprfhcL0Kr63MFAgK7mMBMrNiF1dr6ApmkMzeWJB93Od1e186eSOm5N4HK58Ha1s+u6TawvGShCMDJ85k2d4yt4/Sg9+RT6yVNUzpzBtXMnykVxUaUuIZ37+29QfOcfNHyeL9sJhlWzsyXhAbdNcNyxo4OIWSL6cm3+oL1OstrvsclpWWU7VomZVDnVYDKeq+TIV/IEXIFqR5qJLoucnRVUTIlh2sTzuta1RQ5KKNSg1SxcGsLlIiwayepXIoXUltqzQ4nFoNod2Nsc4PnpI2TkGEdmbiGlRxBuN1LXQVEohWPor6OyGmD/hmZGFrKYlmRHT5SKaSEiYVBV8paKV6oIlwtR16G4etxtER8fua6PfNlgPlWkp86EeQ1ZfRlDaiEEak8P1tBZZKGIlUyixuPIctnRFFaiNlm/uy/GY6fqzq3Xi8zlyBd00mfOA25A0H7L9dXj15grG8iKLQ1gLi2BlGSEC/e+vY4cXSGZoWDZY2gUne3X7+TA+bJDiimqQqy7naXZOds8tlwmpFhXyOrfAtSbQctikaJQbSO/6hhTVEy8luK8thIJcrkSq+xxgFVzwzjSNGDVlyIWw+dS+L19PeiorG+txdZpPU2ybM/z5/NzPDz+EO9edzeKUJjJNZo8AuRliXgk7BDhWnc3waHaeOSXJkq1eEv4fGQ+8R7c0087/shFpUK2mpyV+QLStHg5lmV/21YUtVaw0hvuYzQ9grZuHQvBJbSmJhD2uHhzbwR9trHDTjd1nps5QMgdYk/bNWsSc+tagvzBzeso6Cb9za8+v6o36S7JauJZ2JJEor+PXEoQO1/HD3U1ds1E/G42tIcZnrPPkyM5FKrxFsbYmPO3zOfpELVj0lwau6qktBCC9oiP6ZUCvjpvHoCOljBjmoZqVAimEjSV8rgMDb8q6bnpWipDQ5jLCYTHjXtPzSfNtWmTLW+ZSuO7527cu3ejnzpFsywzK3ysityHVAvPTTcRfO6g470ggAiN1d4A7u1vfUz5hkUab7rpJh5//HEOHDjgVFL19/dz44034r1Maf4VXMFbiVWN53MrZy9LVstKxRGQByg9/HDj54ZJ8dHHkPNryeqV0gqLBfv9J6Yepz+yDp/mWxPweO+6q2FinSpfpLMsYSlbwi0iNMvdKLkB3n1VG1888GVMS5Jj2ll0Jlkg4NHwe+wgbEN0A+mCzmLaDpDaoz4n2Nu/sYX9G1vQzQFmctN0Bbs5t3KWo7PDrORK5MQyZ2YypNULgESXaSayY8BAw+7Vu2bftrWN1qqRWqqcaljOci1DebD2hiuJ0tyE0mw/sALYA7coBgi7o4RK7aTJYqr2YOfGohII2sGfS0KTSmBwNzuGzvOB0Qo+y0IdmcC7aRM+zU/RKLBcXGYdv/lE2BshkVpaWtA0rUHyY2BggKWlJXRdv2QVZzgcpr+/n8nJyTe1v2+KRHoTyOpZ5kpzSKGgSRfeShChCFL+qDOpj4f9r2nf/Pi5c91dDJWGCPgDDd/Z3r6dmXH7vjm49DxSSDRN42TyBFtbt9Dks3+TsytDPDX9JKZsJCQWywtYmknQ/eaJ0kuhnCk1bC9lpWgN2nrLL6wcYqE8z9nMGX5v88cb2vHeLigaRV6YO0TcG2dH885XlMfw+XyMFkaxFAtN0Zgrz7HLv/uSyzZHZMN5aY4EfyXXaf0qclauYRtasMhyuUCWCZ6a95NQy0TZRDzS37Dt37QECNiV3du2bePgwYOOGaJlWRw8eJCPf/zjr/jdhx9+GF3Xee9739vwfnd3Ny0tLRw8eJAt1UrWXC7H8ePH+djHPvbWHMhrQL3BYj2E37eGqIbGaqT6CsCKkqBCLZnrVMZU4XOrPD39JKY0KBo1yZqSWWIocYbBwIY12zItk7Secl6PpC6wKb6Z4eQ5Vkq1Z8BT00/ysU2/h0t1IaUkq2fwqB6n26u+YvqiDl/AJjjriepTy6c4nxxmMDrItubtjo7/bwNaw17+8B1rz+WmjhDv2NBEfuwou606/dWL9WPfJFybN1G8/wEGrSznl5eRpRIjSoj1ShG1055ghrwu25BxewffPDDmEHxAA2G4ilVd+9bLmMuuyg0EPBq7+2M8d24JKSXlir2elpDXliF4HSZXV/CrhVOdaFr2mHMRWS3Nxmr34tIKhCPO69VxZ1X+YckbRlTvy43tIYKeKOmq8alQBFrv5ZNXl4IQgqBXI1sldFfHtpG6qupVLOTnGYiux60JKuEXmErNEa9sR5/ZBNjFJjduXOuPcXGXiqhKGro0Bb9Ho1A9xtV5x6WgtNTiXFEX83bHvazIU0gsDs49S3PlDtSuLszpadSODnKGdKqI4bWR1RG/mz++fSOWlGiqQr5kIISCEotRXMxQwnRa/9e1BjFMa81xBzwa69sa47s1MiCxxtf1ULu6qAzZUkbm1BRqPO60zAMoEfu727ojPH12kYph0dPkZ9TrhVyOAhq5sgQBaixKU7cd/4X8bkgZgARdx1q0pVV0oSKvskkmtbPT6QADaF3fQ2TzIH3JccaX7OdmPOihI+pj2eeDXA4B+DJXqOq3I6RlNcQ0DcatpkkR+74z5+c5F8rzfEuKjqKHu9L2WGWMjVMQtXvTX5XJVFpbkEbt3hLV67kl7FkTVyeKjXPXyewEB+ee5+rWPY7UUD1yeo7mprhDVqvd3aw7PcYJJYoHi3ZZbOgyn83POkQ1QEWBlLvaPVCN9U5Hc2xr8VMwap0oPaFeRtMjdtzX1zh2lswiCiqWrD2nn55+iuHkOQD6wv2X9ANqi7z2Qq1Q9RkvpYVZtZQMeDQ7LlNclD74ToLztm61NrAONb62s/66QTu5ZkkYqOphN1RWj407f8t8nohRok2WWBBe9vSE8dXJL925s4OXJ5Js6Yo0+Afs39BCJWjSsjyHJ2VzNuso49qwGd977sH3nnuwUimEx9MgSSu8XsL/++eQhQJKxH6uKbE4LbLGiylAKBJCjcdx9fexcSrDCSVKn5XHHY9irTRyWq7t2+BNchSvhjflKOT1ep0J1BVcwW8Suqk72s9ls2zr4140saucPkP+O99xzCrqocSiyFIJWSyhHzmKaaxmKmNOEJSrNDrxvjh/mJu7b7HNLPp6MSYm0QbW4dpWqz1czpZ58OQwKaETC7i5tfs2JlaSzBpZgvQghMLZ2QzbuiPkMzEgD8LOxiVzOkJqzCYLDLaHUIVGf3gdJyZrAdKG9rXkmlt1sy5iE9B94T7ao16SuRK6uoxFhZKsPaQWShNUDKvB/GUmWZvA17fNZPRG5/qKkkSVFdSqfEKJtXqnfc1+NoXWcWPvII++OM/P0rVqxRbDRPO/h2RgmBwzeH0aCLhm/S34XrZbT4q/eIjCj39CMDJNYVcPpQBYwkIVv1lC742QSFdffTUPPPAAlmWhVAOV8fFxWlpaLis3kM/nmZqa+q00XJRS8vT0U5jSwLQkgWILohq9LCm1yX7A8+Yn7v3hdbgVN7qlN3QxSCyenHqCd6+7hxcXDnNq+aTzWbu/HZ/Lz1jalm2ZzE6xtemV2/hXUTZKPDz+MMmyPRmIeWK8q/8uPKqHZ6efIVVO8s7e2x3y++JEz1x+jo3BTVQsndn8DKqmktEznEmcZkfLTkxp/sav8Xo8PfWUo7tvWAZXt+15xeUnsxPO30vFtQZHq/C5G8fot8Lk8GKd+5Iyy6IcRmIxkdUoSgNdZAi4d/3Kt/2rwKc+9Sn+/M//nO3bt7Nz506+8Y1vUCwW+eAHPwjA5z//edra2vjc5z7X8L0f/ehH3H777cQuIgGFEHzyk5/kb/7mb+jr66O7u5u//Mu/pLW19Tcaz1mFS5PVymXkj+p1HuuNOpcqa0kdZ124CXgUEqXaNRFwBchX7G2/vPQylXKFs8Wz9FZ68WNP8HKVxpb504nTrI8O8sLcoYb3s3qGB0bvJ+wJM5ObIatn8Gt+7t34YUKuEOO5c6TlKCH6EChkmcSiQpgBFKE2aMQuFhZ5eto2dJ7NzzC0MsQdfe8i5v3Vkrq/bggh2Lujm8zDjROeXzVZrTQ3o8Si9CXTqIU8BoIREaRz60ZE9Xm7SpS1Rrx86uYBXppIcm4ug2lJrhmI88xF5myrVVdtkVcuyGmLeNk70MTLE8mGqrnWX4Ep7RW8Ocg6olSW15Iyq2Q22IZX+swMrjqyulC2K2BlJoMElqrP+IBHI+i1JTfU/j6M0XG0zZuda+31IHQJsvrCJcjq+YJNVi8WFoiEirhyClljnJiwyeq965uZL43zwMSLGFYFRSjsbN7FYDBE0lXhUEuK7oKX3b6aGXXY53LI6leSAVF7ehBeD7JUbpAUcrnKaBpUDEgU03hJ4G1tRa128eRLBuXqHExTxStuox6KIqq1fbWknxKPUVyatsm96jzt5s2tdERfGzklgsEGA8NXGoO0nprWrTkzC7t2OQkLwCF+fG6Nj+zrZWwpz67eKF85eQELKAiVZNUIMt7V6hBP4aCPVRdEc3HRrkCv7kvWbT+B1M5OUkN2MYbw+2m70Zav2doVccjqjqiP1rDXNtAEgtJALiw45+UKfvOQUpL/5rcwhofx/+5HcVe7nOrJakyLgtBAgjk7x1jQvjbmfGWKC3mihoE5Pk6+St9pAwOEEsNo4QCuTZuQdabJr3Q91yfZV3Ehdd7hDgBinrgzx8lX8mi99rgmPG60df30yUf4J5UxPJh4sZzKaiklsxdVZwtVZclbJaurWsoSOBlIEqzUYr+4N94Qk9WjaBTJ63leOHeQ7kgP9wy8xyGqARYLC2/avH71GW+iAxIhoK+pxrMkSyu4tt3YwPNcjM6Yjz96p52oX40x6iurrWTK+Vvm81AscK8xRVK4Wbf5dxrW1RL2cseOjjXbCHg0bun0oC81xqZqW810/rKdIi4XIlJ7pqnxGC2ydt0EZQU1bl877qt2c8v4z9hupoij49l/N8UHHnSW1Xq67e28ncnql19+mVOnTpHJZLAsa83nq63tV3AFbzUydfpKEknZLOOaT1B65Je4tm3FvWcPhZ/+9JJENYDvXe/CymUpPvhQw/tKey2Iy+qNZPWp5VPsaN5JzBsj8Kk/wDh/HtfGjTUtM0vykyNTjGYWyco8qhC0+FsZm4oREqmGdd13eAqv7CSNbd7RHfeTLxsEjc2slE6RKxnsahvEpbo4Xy8B0vbKlaBhT4S2QBNzgQIL5RQ5pqCOzMvLORazebpiIWef51JVzSKfyxloDctYM2H3ugQJTuCWYQKiDUsUnGDSOX+KYGt7B36Pxp07ruKXJ35KUbMfzDfrrRzTmmiX11GUSwT9M2xv7mJP237yj53DSmecVsWYMJkdH8e1dSsWFiq/eSLv9ZJIH/vYx/j2t7/NF7/4RT7+8Y8zMTHB//yf/5NPfOITzjr/y3/5L9x22210dnayuLjIl7/8ZRRF4Z57LiFR8TbHSPoCE5lxADS8RPLdgN02lhXuVanWXwlBqSka66ODDK3U2qq9qpeSWWKhsMDXT/9dw/LbmrZzU9fNLBUXa2R1ZoIt8S0sFZfQzUtruce9Tfhdfo4vHWc6N+W8n6/kObZwlFZ/K6cSNiH+/OzzvKv/TmBtd8V8fg4pJQljBemq3Y9HF4+QrWQ5sXSCgcgAd/S965IVvhk9gyY0/K5LVyGXjRJls0zYE7nk5xdDSslKaYWoJ7qmsnupsNRgEHto7iBRT5SB6KU7HCxpMpOtdYdk9MwaLwFLWjwx+ThDibOkZA9RYQd2Qa8LU5qky2mCriBu9bVN9HN6DiHEGhmVslFak2RMmZPIqj16sTpJ0GWGskgBb1wX/q3Cu9/9blZWVvirv/orlpaW2LJlC1/96ledDo65uTkn+bWK0dFRjh49yte+9rVLrvMzn/kMxWKRf//v/z2ZTIY9e/bw1a9+Fc9vcGIr85d2ghLBAIdHEhyfSHLdhmZ29ESBxglesEp4FCoFlnU7UaLgRmIiMQn5NMqlADE2E/LVxoi4t4k7++/iuZkDTGYnyOoZDsw/S7KYojhW4N7NHybmja3Rb5zLz/LYxKPOM7HN38ZyMYEpDWbzM8zmaxO1glHg8NwLxL1xDs49z4pIkbKGUYSGLu31lkSCNrnP8a8AW9asHkvFRR4Y/Tm/u/n3cCmvnuBbKizidwWcBOEbxdGFI5xbOceNXTfSG+57U+taha0NK5xJ6+p7v0oIIXBt3YL13EH6rTwXlCClQIiRzkHI2tdOqO7Z0xTycPv2dm7fXu2ky5XXkNWrSZGo34VLU6hUzffCPleDaVx71IfHpXLb1jYeOFa7FlouU5F9Bb9G1JHVlNc+5+sJyDIKViZrG/ZVk2b5soHM5ZCWJItG2WVrubZFvM6zOvDJT2KMjKANDq5Z/2uBTZjYcbjfrTKTm3EkQMLusDPfWcjbnZ7j6XFUVdDb5GdkIYchC4S9YXb1Bfj++R9TsWrH/OzMs3T4BznQmmTZU2HeqzOgqY64XsTnYj61uu1X0Kz2+Qj9b3+KtbSM3tsD52zSKFvJEfG7WM6UQUJOTOOlVn2YLlYo6vY8LB7wvCHJI0UReN0qxUiUUiiKnkugVp+HPtdrnxsIIVCiUcxlm7i7HLkDNmG8CnPGvqfrSSeljvzpaQo4ciO+gJcssCw8mAhQNVr7a+sKhf2AvX1zsTbeqK2tpAoV2iI+3Hv2kDxwBqG4cQ2up7lqdre5M8KR0RVSBZ2r+mK2PEq1ijKIgTW/AH2vr7L/Ct46WMkkldN2/FH65aO4tm9HCOEk3qWUIC3btBAw5+YoB2rcWkWVyGwWY2zMJrSFgtLURMudHyHUHQXAtXUrSuRRpK6jbt8BiwtcCvWV1X4tQMHIk6/kmcvVOtG6Q90OWZ2r5PC+4zaUcBj1/8fenwfJcZ5XvvDvzcza96reuwH0gh0gVq4gKS4itZASZYmSPBpTGssayeOxxr5hx9X4OsI3hnZ46Jn4Jhy2Zsa2LFpXkmVraNGULJGiRHGzSIE7SOw7GkDvW+1bVi7fH1mVVdnVjaXRAAGqTgSD6KzMrMyqysz3Pc95zlnRZ9ufNtpCSHGLrE6VUw61NAACpoI6zKMKk14d0UBMB10BEt62RcnqM+oZKq4KZ7NnODi7/DZatTDbmqq6K+pjTXwVp6sCnLnShXUrhH0uCpUC3z/+IypGhQ8s0F1qYvKKf4xJPcfNPp2eool8EZ2lC+WlNZLVFwrh89HmlXBrVshiwlSRYtY9yrVlC9IP/oW2qtrevXMHpWefte2PXNdtvuj3WwqWxBKUSiX+w3/4D7zaYNK9EFpkdQtXCpmyU/Vb0opo//wE2sgolSNHqezdV29faUuQ7QzjMRW8KCj9q3Dt2A6miTEzS/nV1+z9iIYLPzNvwmpi8NrEq3yw/0NIfj/urU5l3sGxNLPZst2SfHomT7Ho4fCYperyumQUWZCrKm/8dON1ueiKeBEC1rR1U5gYIidGmEqpbL9uB/mSxukZ6yEQ8btovwClzurYasYzU0zO5UgKyyol6FXIlTRMdA5OH6c3th2wlOC1CVhPgzoh3fD5+hWrbcfrksmawwAUXV7ikrV+yB12TO7DbmsY7AmHuX82wBMdGfqKbm5qW89Jv4tkXsUn2rmtaxO39FlVUfcN11P62XP2PhJlF0Y2iZFMYsSaC2PvBi6WROru7ubRRx/lkUce4YEHHqCzs5PPfe5zjjDaiYkJfu/3fo9UKkU8Hmfnzp089thjxBdoNbqaYZgGL43+3PrDhH5lC6eKc/Y4RTSQYsELVNacD+vj622yeiA8wNaO7Xz/+D871pGFzPv67rQV1B3+Tjyyh7Je5mz2LC+N/py9M+8s+h5e2cuvrvs3jmq+QMLE4NDcQav1rYpT6ZNU9AqKpDQpqwtagWwly6w2Q2NqSb6SZ8/UWwAcSx3lxu6biHqijm1HsiP8y4nvIwmJ9/XdwcbEJsfrs8UZvn/8CUp6iQ/138fQIqRyI14ceYEDs/sZCA9w36CzMPL65GuOv01Mfnr6p7zffD9rYs1e1JOFqaY2wuniDH2hujLpF2MvcyR5GElAkv0EzT48isIbU7s5MneYglZAEQqrY2vY0bHznGrSU+mT/GT4aUDwybWfos1Xb0meXUA94mnoIomKdaRM67scK5xgQO9kODNMb7C3abt3Ew899NCiHRvf/va3m5YNDg5y5MiRBda2IITgd3/3d/nd3/3dZTvGS4WZyy24/FXivHHAKlo+u3+CTb0RMpU0+5O7KZhx/KITpBI/HX6R4cwp5Cr5ERb9mOikzRO0hbzcMHQLq8MbMdxDZNUsK0IriXvjCCHY3rHD0Q0AkNfy/POxx/mV1R8nM69QDdgFHIHgzhV3M5Ef58WRF+zXBRKSkNBNjaPJI3anlyIJVKPQWDMmb46SEocJ5DdQMSqM5UbtYljQFUIWMmk1RUbN8Pr4a+zqvfWcn+X+mX28OPICHtnDJ/uXnnWQUTO8Mr4bgBdGXuCzGz5nTa7VLKfSp5grz7E2to7uQLPyZyHUgsmEoiDFYnZIjxQKOkLqlgveD3wA1ApriwqnaUdEwoxk60WO0DnC3RayJ6iR20IIrh+Is/vYDDsG4vTGfPywgZSuKa839UbYM5xkdM4asy1mH9LClYOpNbTcq+cjqy3SyMzloIGsNjLW/WBKeG3ldFfDeFny+23V5PmgG3pTJ2ijTUyJWZ48+XP77y3tW3l7ag+5So7p4hSGaXAqc8reri/hJ6zn+NjmjRxK7rWJalnI6KaOicG/imPMeOok09lAmdrT2ec1mDB3I+PB727OtGmE3N6O3N5OpVAnprJqhoivSlYDeXOEBNfZRH6hociYCC29OBpwK5RUHW3LdsyQCyllvd8Fh9NWIcVidbL6HAUzEQ5DKICWyyFGR211vf16ZGFhQDASJAsWUQ3IibhNNgNEIhapbQgdoZlWcVGWEeEw6UL1u4vHKN3/MVxjGYQkEa9mB7kVic/fMYhuWPYoJVXHHQpQAdrNEvpki6y+mmA02Ebqk1PoY+MovT317hvDKuIUq12VRjJFOVQfKJQlA31sHH1mlrzUjhQMICTJ0Z0gBQKE/58/AMOgqKqLk9XV7jJZKAxGB+2u0+OpevfzitAK9s3sBSyyWni9eG67lWRpjpdGnsMfy7AjGaYsGfy8I0m89A53Gp2czdZVto0q6ZJbUOWACWgyeUUn49LwNBDTfleAhDfRNB4Di6wuGHVR3O6xlx2v17rrLwVCCDb0RnhjZIKgV6Ej7KXd38F4fgLVKC+oSF8IpmnyszPPMJqzhDtvcZxt89bJeAyORMpIZdgXNekp1jsjLgQ1JbtjWdfFk9UA7rYEHxoZ54QUZLueRIpZ80opEMC9cyfl19/AtWY1UiCAsnIllSNHAXBtvorJ6r/+67/mlVdeWfC1ms/b1eD32MIvD+YTyfnZSQIj9clD5fgJ6x9CMPGJ23km9zo+RebfrPsU3po6UQj8D34C9/btZH7wA3RZQrm+3u6eU5sn0ydSJ8ipOYJupyJPN0xeOmIpIVSzOtE1vPzjy3XF4aa+CJ0RL0+9bRFc2/vb2RLcyumsdaxbugY4UQggMndD2SST9bFvZsb2UVzXE76g62xzYjOvjb5K1CdRMDS8ikI86LFJ8sNzR7kXi6weTdYHnb3x+k2z0QJkXXw9x1PHMc0MHpdEuWIQaOi6u7HrRp498zPrI0UQqH42QghudYW5+YQ1bHNv7yPh9ZCsppZH/HUVpee229COHsOsVHCtW0fPvz6P15BQz44gxa8e386LJZG2b9/OY489tuj+/vzP/3zZju3dRE7NWgMUE9r2n8U4qGFItcG8AE/9u77QNtDzoSfYyx19d5Iqp7ih8wY8ipf3r7yHE6kTmJh4ZS9b27fS7m8IBhISK0IrOZ46hmqUz0lUgzUYenr4x6Sr10NfcAUBV4AjycOU9bLtaQ+gmRon0idYFV5FeQGl9mRhgpnKDLJPQiCaQlgBRrMjTWT1O9NvY2KimzrPn32OqcIUd/TdiRCCQqXAk6eetAdtb0+9dUFk9cm0dc85lTlFVs0SqrY2TxembeV5wBWgO9DD8dQxdFPjp6d/wnRhmlt6djnuQyP5s037ny5Oo5saJ1InUHW1rtQW4HVLzKkH8Lhy7JmqF6I0U+Pw3CFOZ4b5d5s+v6AtynRhmp8O/wS96tn31uSbtpodnBYgLslFxajgqSqvAqKHKGtJcwwkg5OZ44zlR0iW5+gJ9DLE0lRxLVw8TMPAKNTtp153BXnTp+AtRsirfnugWqroTKSL7Em+xGjxCGVTYlD6KPvn3uJYyho8K7IAJMIMIOFBFxW2dvRx99DO6m+o+XvtDfZyU9fNjOZGiClx3sy8Yb2fXmT32Mu0LdJaKpC4tfdW2nxttPnaWBXup6RZ117YE+bQ7EFeHnvJvl4BvIofVbPGEi5CdjF7zjxIUT/C1/Y6A4R39eyizdfO/znyj+imztvTe/C5fHhkLx3+DhLehKWIyo/T6e/AI3ts0rysl5lZZHI1VZhC1VV6g72LjiOOztULHlk1w3h+nIn8uB14DHA8eYx/t+nzKFJd3T5ZmCDhTTg6OzJqhieO/TNu2c3HV38Cqb29TlYvs6q6Bsnnw/+pT7K2oPLsz5oDU0O+xZ89iiwR8CoOG49gA7l9x4ZOblnTjruqsHYr46jVQn9XlawWQvDAjl6e2TdBe9hDT+zdCTluoQEOGxDnc7kxMA+gVCWQG32s82UNM23dq6aEF6pk9fmsYRbCpDrJy4d/Tne4h4+v/oR9DdWKImUzxTupNwgHrONYGVrF5sR1jOfGyaWPUzEqnM4MOwiUtpCHDXGDjqjETw5a4xlZyHx89YP88/HvYZgGo6Qcx3HGk+eW6r8L8lHy5hhCAO45IHpR55RVs7bHq2GYaBQpM4dPtDV5wLdfAlnt98jM5qCiG+Srl6gQArdycfMD16ZNVI4dR+5oRzqH3V5RK/LY6lm05BwfHekgnEphpFL261J0EbI66pwbSm1ttDUE1UdiYfKBOWbahvGUAwyOD1EKRRFCkC7Wi/5z+QpCkpAlQaShmCGEqD7zwOuW+dStQxzZ8zybi7Pok5dO3rWwfDDmZRxV9uxB6e2pW5pVMxOKDdRcSa7fe1TJQN1nkcdZoSBC1jjd4zbQDM2+f2imjiEWF3VVjIotQIt743T4GoK2G+4l7b4O216xxn+ouso/HX2MilFBbS/Qn/cx6i8xEtGYyh6na26FPWcAWB/fwJuT1nhKKAomZby6RExVKHhMNFkwWx2ne2QPiqSQ8DWTsABFvUhRLxDAKvDMF8U0ZpCYpsmr46+gGiq7em61P5sLwf3beoi3TfPOXAghrLlP3BdnIj9OrpJD1dXzdn2+NfWmg7Q/WjzNRsnEbdTHWmOR6vdeKjHnkcAlX1TRvqZktyEE8hItQ6V4nP6zI/TrVuGgcUzm+8THcd9ys53f5v3AvZjlMq4N6+2OlsuNJbEEzzzzDEII3ve+9/Hiiy8ihOALX/gC2WyWxx9/nK1bt/KpTy1dzdFCCxeL+WR17sgBFsp9de/cwWFhEUpFrciB2f2sia3lRyd+iCIpPDD0MfyDA3h/80vkDx1ytHZlG9rJt7fvYM/0W5gYHJjdT4eymf1nU+wcSNAT87F/JEUqr6KbKj6vgaZLSJpz0LJlZZTOiI+o343XJdMR8XI6o9pk9UB0gJ51Cb7/xllA8OTbY7bqWZEFNw1e2E0i6A7RHxpgzj9Hly9AwOumzdvN6MwpdMqM5M5Q1ssUtSLfP/WPzJgVurnNMbFKNSirE94EO9fuZLIwye09eX566lm8bmsQKpAYiqzmYOAg4/kxOvwdDpJJikZsc365t49O3cvxSetzbRy4Sn4/oS//NmA9dLThYT5+xqQsG6Q3GVwFLiAtnANl3RpEmIUCwfE0M6ywXxNulx1I5FYkh1/6pWJzm1PNtD6+gfXxDefcZmWVrG7E6ugaIm7n5GPfzF5UQ2WygZBeF19HzBPnSPLwgvs+mjxCpIGwiXlidgL36dxpsnqGKFHafG3EvHGOJo/YpCrAaG6UTW31ynVRK3I641QcHJjdT2+wl8HoED8+9aSjq2GiMEGqnLIJ78NzhziZOsENXTfZ3m5lreQY5J1Mn2Rru9UlUlN5A+zo2MmmxGYUSeHw3CHr9em3aPd3sCZWD1I7m2smq4fTJ3llfMIRjALW/aK/LUCqOEXU7wYkBBK9wV6mCpOohkpRK5JTc0hC4ucjL5JtsCPKqhk0s04mnUgfp1C53bZHaRx4r4mt5eDsAVyy9ZsL60PIwo2fLirSBEWtQLHaungxA9sWLh1msWgnDqZQeLw3SUUpE8gX6FScAcDD03lmKjNUdAMDHcVdZKrqiy4QbG7bSHrMjatq6dIlbuSDA+uRzxFOKITg+q4buJ4bKBQKuKfdvCO/g0aFycKkw8JmTXQtx1PH6A708L6+OxwTq5A7ZBd6wLofvTP9jm1FE3aH2Rm5lUPl05hUCNDL0MAML5x5mYpm0DnPa7XN187q6BqEENzQdSOvjO/GxOQXDYoin+Kzr1+X5KI32OfYR3kBtdFbk2/ahHNPoIddPbfhU7wky0lOpU9R0krc1H2zo4ME4LWJV5u8KEt6idOZYdp97Tx75lnG82PV4qCPz6z/t/a1eHD2gPU5VODQ3EHWtbUB1v7PR1afSp/kWPIYvd6+JsLrQiArZbKut1BVN3E2IoSEIgu857EMiPhcDrI6NM+yqkaMuRSJ6wcT/OLoND0xn0OVHfG7+dj13a17ylUCp7LaSXbUAvNOCz/ucIhypvqsqW6jT02Rniqjr7PuLdPCY5MLXYuQ1fPzJwzTsIrTpsnB4n5cLhdThUmOzB22n/UbeiO8cmKCSe0NBrwWubEytIoPD9yHLMl0Bjrtgu+r480dzqO5EfZMvWWPIzYkNtIZ6GR1dA1Hk0eaCJFJV4GiVsQtuUnqp1nXE0aWBCUzdZ5PsxkZNYMkCcI+F6mqECXHCIPRPsYa8nAAWyG8FNQsSlLmMaZySeLmZsKeCxPwNH4nnl23oAwNIsXjCwb51nA8dYxS0I2eNjkdKNI9Nr6gZ/V8BAI+hNeLWSpZYWehkENRHkyEyYUssq7syRP0TqKGBgBsZbVhmPZnGQu4z2mdsqo9SLzbi3ZSt7qJTRNa4sGrAsas00JCfecdvPd9uG5pVi2K1cITNWGiN3x1qmRQOWiNvbPChRQKUTZTPHHqBdyyi/evvMcSsZx5Dt3UuW/FwvaRyVLSFsckfAlHN2INbslNwBUg4AqilufIVXKYpskLZ5+v2wq5XMy5KyTdFbtbdt/MPtsqI+wOszK00iarqQadBzWZUEVBeGUQddLZrwSqx7Qwt5FVM6hmZUFuB6y5TA1nsqd5c8p634Q34ZhHnQ+KLOHzaPZl41f8xL0WWQ2W33fXObrJZoozTfdlzdQ41a6zbrI+DhiNVAAF04SSZFAMelDzk5xIH2djYlOTUGk+5Hk2IHI8hulS2DP5Ji7Jxea26y5YOCzFnWOwRkskIcsoffVxpbJiBaH/+FsXtN/lwpJGT6NVv6Z/82/+DS+++CIAd999Nzt27KCjo4P/+T//Z1MCfQstXE40kdUnj1BrhpC7OtEnJhFuF8o9dzF2tq5s3T+zn7HcKGk1BcDe6Xe4uecWFkKNBPIpPqsVb/pti6ye2c8ro2GKquX3/MW7VvP80UOMmXtxEaAn6kORBWaxgz53EAGs7Q7bCbUr2+q33lXhfj7Ufx+GqdMf7ocwDHUGOTGZo6TWK6w7BuKOUKnzYWN8E2+deYugV0FRJNa3DfH2CZW0eZKiqrJn6i2mClPMFpKopkFSOkBXZIe9fbrBxiDiieJRvKwMr2JlGMJeLz8+9RQmJp2BTlyyiw+s+gAn0yfpjww4jkPpW2EFNPi8KH293CC5KKo6iaB7UT9HIQS++z6M9ld/g7dikl7CZLWFK4va4MNIJnEbEt2idWcAANRKSURBVKWGyZpoCEy7HIF6F4v5PqztvnbuXfWBpoBWBPVBF9X2ucgQbtlNh7/TVlW7JTdu2UOukmUke9ZhKbEuvp5Xx1/FxOBU5qStpe4J9nJL9y42xDeQ8LXx7YPfpGJUGM2NODqVjieP2X7L7b4OO7zw8NxhdFNnojBRPdS6UvtY8ig3dN3IaG7U7njQTYOPDlnP6NQ8C6WTqRNsbd+KqqucrCokvLKXjYlNyJLM3SveT5uvzbZ5eX3iNVu9XTZKzJZmUBSFuDdBupxCN3WHPUoN2zus+8ueqbfocHnt9/nEmk8S88Z4efQl3p7eA1j33uHMsN3uPB+1FmfDtIqHN3TdCGArNgA2J67j4OwBhICdK1bQoa/h8FiGoL6Sire+nlf28r6+Ozh9pLkNsYXLg1o6PMCrHj8VJQVAMTCH11PhxrXt/OKo1al0YipLLpBFq/odCyVDsjo5inpi3Nt/L4eOHLHbzSN+lyNF/ULgkty0eduYKI9T0kv2JAXgrhV3c/fK918Q+ahICrt6buWnp59GIHHXirvZUxIERD0L467+W1iR8HM6c9bht+qWPdzcfbN97W/r2M6J1ImmwNLGQlPFqDA87xopaEWkakKAaZrsHv+Fowg1lh/je8eau33G8qOOfQN2SytAT6DX9uY+MneY19XXHcGVJb3I4blDdhhrzV8XrHvMxrb65OdcZHWylOTHp35sWS1pB3HnPKxQV+C/wHbZZCnJv5z4ARXXBKmyiksECDNAyOuyPDCzZ5CFZBcFapguTFOSz2CYMSRRnWSf43l1+7p2NvZG8Lp1Ds4eoCvQTcKXYDQ3yg9P/Athd5gH134Sj9wKPHs30UhQmyWnstpIpzkt/PxA6UNyR9kiVa8lXccsFtFOnSJj6hSPnsCkbgPidcu2R+lkYYIVoZUoksIbE6/z2sSrbGnfym29t3Nw9gAvnH2e/nA/A4EhcnqeWFW5vHdmLxsTmxBCEPIqrFt7FiUlgbCe9R8euM++53T66/ePhcJiM2qGt6feBqxn484O6xrc0rbVKkBVyWq3IVAlExSF05nTuCUXJb1oW2kkS86sjQtBbZ5kkdUVwCRjniIa3sHYvN21XYSyeiI/gWHq9FTHUz6PjGpmmTX3ggmScNPpuum8+9k7/Q4vjb7Eutha3r/qXuDCfF5nS7NIgQA6UJQNtNFRm6wWiuwY1zYi4FFQBgcxpqeROjsRQKKBpJdCQQx3vQCvBaeRw1bBM1Mlq1MFFb36vLsQgl/u7EQ7OWz9oetwDhK+hSuH+cpqI51BPXHCHquYhlNZXZYMNARzwk0AjbJsYuate1ZGuBChIBWXFRZe1ss8depJx/73ze6li2ZStXFcnPAmiHnjtp1hDRFP1M6BSZbn0E2NfTN77Q42sJTSaXeFlEtDeK2OsMb70UBkkIAr6FgfLLI6UiOrGxCoFrZjnpjjeGrq7qLuHI/MR6mhg7Wxq3Km4ZgaMVOcYTw3xrr4+ialdF5zWpPEvXVieK40d06y+uDsAfvYh6KrOVENxz0cL7N2UkYgKMg6SZ+Op4GGnQvBG8NPkq/kmS5M87HVv3LO8xWRiDMgtrOT1yZeteepbf72C7Zok+ZZjc4nr99tLIkpqCkbQqEQiqKg6zqpajvMtm3bME2Tv/u7v+NXf/VXl+1Al4LvfOc7PProo0xPT7N+/Xr+6I/+iC1btiy6fiaT4c///M955plnSKVS9Pb28od/+IfccccdS95nC5cXpmlS2fM2M0d/ToUCQpIQ4TCFqSQQQu7sIPTb/xH1zbeQV61kVMnZ7bgABS1PIVe/KR2YPcD1XTc0vY9u6BQqluou5A4TdAcZig5xPHWMZDHHXPk0IbGSuZzK8ckcR3OvUiGL8CgEvNbA47b+Iba2nz+gaH7b/ke39/GNfz1hV9ldisTNQxfXetHt7yYk1xVfA5F+VvgF6fwwZc3grck3qegG5Yp1g9Vco8yVZ+ioWiY0elbPr/YNRAb58MB9HE8dtwmooDvElnanhzeA9573IyXiyCtXIrxevMAHFki6nQ+lv5/Qb34JI5VCKC1Z9dWOWoXbSKVwGTIlZJS1a6CiOUIhAp7l9ym9WARcAdp97UwXpxEI7lpxdzNRDWxv386+6b02ET8YGbQHONe1beHZM88AlprbLbt5Y/J1TKxWtBrafG1sTGzkwOx+x757g33IkkxfyFKgdwd6OJM9TUErkConKWpFPLLXoXS8e+X7eaqqpD6bPeOw6nn/ynt49szPMDE5MneY7R07eOFs3QO+0Q9ufvjjeH6squAeRq+qllfH1tgTZSEEW9q2cjx1nIn8OMnyHMdTx+jzrGBCnYDqXGogPMCZ7BkHuSaQ+MSaBwm6AgTdIYpakf0z+6gYFSQh8eGB+2x/6kaFalbNOgJhJCHZwXFtvjZu772Dx4/9EyYmB2b3s6NzJxKSvU3EHaHd386mxGZOZ4a5e+VdrAj1cfcmjclMH8+OD6MaZfsYIhcYTNnC8qBGVlcQvOO3rj2ByVojy7bVM7S1zzB36iU86iBnklF8Ht32fC6IUTzVZ3pN5Rz0KPYEMB64sJDO+Yh740yULZK6Vgz3yj5c8sXds9bE1hB2h1EkmYSvjcPuCfs1WRIkgh7awzdxS++5iRZZyHxs6GOcyZ5BMzTKepnTmdNMFiYIuyO4ZTfjCxSFSloRf1WLNJI76yCqa/kTC6GRqK6F1dYQcAX4yOBH+ftD36ag5R1FpFpYE1iTttqYoNEiaaIwQXnV9SAEhmnwcmKOwokfcFvv7Y5JIcCr4684JtGTlUn+6cT/YVffrWzt2IYsZMbz47wy9gsGo0Nsbd9mr5spp3ni+OMUtSJBr0IypzJnHsJHB+Pm6/x/B3J2Uc/EZG1sHUA1GOmfOV1Ok8ZHt3krsvA4bEAWwrR6gl8Mv0xJL+GVvfy7TZ9n7/Q76KZGsjzH6xOvsbPzev515EVckos2ltay28IloEFZzTxltZnOcEqq2tb5fJwU1r9NXceo+jIXhYwJDIsARSHjcrltVfW/nPgBs6UZNsY3cdfKu3lt4lVMTN6ZfpuByCAvj1qWQKcypxhODTvee640y2hulL5QHyfTJy3ltAC35OFD/R9yFMe6A92sDK1yPMdD7jDrY+vtjInaNbOtfTvB6rO0M9BJl7+LCXMcGcGu6SgvdCYRisJw+hRGw9wIsIuA5/w4DQ3N0DCrXVO1e2VnKER6tou0eQJFMThWeAnDvMEu/AghiF3gvXk0N8oPjj+BicnHhn6FvtAK/G6FMvXjU8k4AmoXw+sTr2NicDh5mPWJjRecTzFXnEX4rftoUdHRx0YxUilMTKTw4opuv0dGCoWQqpYNYZ/LYVWSVFQUoaNW20XTgRzRhJdc2SKpTdNkLl//nSaCC39m+2f2M1WY5ObuW5A768UMU9cvSx5ACxcPfbbZkivz1l5M3/rqCnVltQmUZYMJ4SUl3AhMUtWig4agFI7hkhVk18LPb4BTmZO0mc1cQWPHYcKXQJEUYt6Yw06oNg5vtDhtFOsACJeLlLtI2q2Bt7mIMhAZdIbAV+fuAU0hpCngc25TI7ZlSabN18Z0cYqAK0DYHVlwbDMfpYYxSyNnkZ4nyAHrvvWDarbPXHmOO/rudLxe43us47J8tGs4V8iiYRo2OS0LS9yTr+SZyI+T8plMelW6Sh7OBps73o6FCra/9+wiBHsjhBBI8Tj6lCXkMDvbHN/RTGG6iaxWdZWfnf4pyXKSD6z6kN1h20hWC0lYHv1XEZZEVkejUaampigWi7S1tTE5Ocnf/u3fIssy3/rWtwCYmpo6z14uL5566ikeeeQRHn74YbZu3co3v/lNvvCFL/D000+TWMCUXFVVPv/5z5NIJPiLv/gLOjs7GRsbI9zwhV3sPlu4MFROnES4FJSVCwdBaKNjGDPTuDZudDx09elpCo//M5WTJ0kPjGNbAc0lKVUHnK7rNiM8Hjy7LLX0mZF/PeexlPQix1PHWel1Hku+Up/UhFzWoOO6tus4njpGXtVIcZSg2YcQEk/tO2b7UEb89eONeZZWqfK6ZX7l+hV85+VTaLrJLWva8F+kz68Qgs3+zYy4RlgdX03cG6cnnONsYYi0cYyyptsJ3WANsF4ceYHNic2E3GHbo9cjexZUBg1EBhmIDDYtbzoOrxfPLQsr188HZbCq0t67d0nbt3DloBoqpqpi5PJ4jAiVYAg51hwSeTUoqwHuXHE3b0y+zproWoendSM8ipdtHdt5bcJq79qQqNuLrIutI1VKktfy3NR9M/lKnjcmXwdweFFHPTFu713BbGmWkbRllyEQ9AR7aERvsNeeiD516smmgMaE12rdWxtby5uTb2Bi2uu0+dpZG1vH4blDjORGSKtpfnjiX5r2UdEruGSXbUtSg4nJcPqUgxhfVyVxahBCcFPXTfzgxPcBS13ds7KXEfWsTVYPRVdT1IoOsnp1dDVdgfpEyqf4+MCqD7F/Zi/XtW+xVVPgJKtzlZyt2HJLbv79dV9qmhz2RwY4lT5JvpLn7w9+G6/itS1Cam2Fd664y7FNwKMw2B5G9nyAfTP7uK7tOscxtHBlYFTJ6qNSmJy3GiBsVlAwOayNceTss0juAjPld+gwdlLO131nc+YEMawupVo7a8CrQLXZaqmt5nFP85iu8Td5MegM1JV7/gZCJRH0nLOlez48itcRarqtY7v9b8M0eO7Ms02WREW9TlafzdQtem7uvoWt7dvYN7OP6YJ1jbplN92Bbl4ee8kmq61Q2jv46emf2Nve2HUzLtnF2thau/uhhntX3cubk28ykjtLWk0zkjtrtRLP85ccdmfY+J9+m70z+zhiHofsHE8ce5yPDD5gf14T+Qnb7sAr+zAwSGJ1a+we/wWzpVnuWXkvL5x9nrnSLGP5MVyS2w7QfWf6Hfs8QtXCqE6Rs+YzRJExGxqKT2dO22T1qfRJVEPFrUiUzSSjvEiveJ/ju0uWkhxJHmZNdC1xb9wOqa2hpJdIl9PMFKftZftm9pIup231+y5xG4q4Op6BvwwwTROzsnjAopFJMyGse4nw+ciI6vhd15HMWlEDkrh5VraeY8LtYlNf1ApMrhIMY/lqAF/Ds//Jkz+st8+D/e9a1wPA3um36Qv1cXD2gL3szhV3ObzfwXr+3jd4P29P7eH1idfQTZ31sfX0hvocgchdgW5u6L7Rse0H+z/Em1Nv0pYepytv4DFSGIrCcGa4yaYrWU7anV2maTJZmEA3Dbr8XcyWZnlx5AWmCpNomkYulSOQrYepRb0RPrT6Nr5/Ypp4qELJzDDHXtqxilfxoNsOwz0f9ky+aX+WJ9Mn6QutIOCRKVMnoSpm4bzhioZpUGpQZ742/gq/svoT522VN02T2dKsZeMhy5QkA/XUKX4SHSHdofEhVxeLlbfnZ7LMD5WcLM/glqBQ/eg9QS8VzwSUV6BqBkVV59XjM4tuD1Yx/8WR5wGrC/YjnfXnArretH4LVx6maWLMVTMaohHboiU7Pg2DNbK6KhZDUEFQlgxSwg2yjKnrvKMEuRmdHApS1OITTCnveB+BRNwbY7Y0i27qjKvjXIclqCxrJdJqxn7eAyS81pipzdfmJKurfEWwQRldK2wHXUGKWglNURj3ltGEieJxdkZ7ZS/dgW4kIeGWPKhGGRTrfhqsyIQrCpLXuU0jsX3XirvYO7OX9fEN7JtunvP3BHoYy485Cu7FBhuQxm7w9Ly5D1jXTK0Af6ZqragZGnOlOdp8bRQaQx8Vv8PKqVE4Mx/j+XH7eFaGVuKW3WxObGYiP45wuTgQyVlkdaA5x+iMt2CTskWt6PAhn49kaY5/HflX4p0qm6tf54novOcZ9QJiWSsR9cR46tSTdofc82ef41NrP81bU29yuniEre4KcdWFiEYdlkhnMqd5ffJ1Nic2sy6+ftFzv5xY0ihp5cqVTE1NkUql2LlzJ08++SRvv/02/+E//AfAepCuXbv2PHu5vPjGN77Bpz/9aR588EEAHn74YV544QUef/xxvvSlLzWt//jjj5NOp/nud7+Lq0qI9jV4tCxlny2cH5WDh8j9f98EIQj++9/AtWaN43V9Lknuf/9vzIqG3JbA94mP41q9urr8rzDyBUqy4fB1AqsiCeDe7PSwrRFAAomwO2STsEFXyPaV3Dv9DuGOMJpZH1hm1Lpfdcgd4vBYmhOTJmFXgrPls6hmgaw4Q5h+Jgp1T8fGIIyod+ltFd1RH79xxxDpQoX+9sUcm86NNlc7t695n90+2xH2EptYT5bTnJ0tUK7oeEQcw1QJekymCpM816CGAgi7I63w1BbOi7JetsNnXIaEmkiwUCPicoUrXio6/B3cN3D/edfb2Xk9btmDX/GxIlQvaAkhHPZBbtnNxvgmDs7VJ52SkAi5Q5Z6t/8+vnvwH0iSoi+4oqkA1Og7O59kBuwBw7rYuia1w3VtW6xncGwdI9VBSa1dvxGpcop2f/uCqoN9M/tskiXijjjajhuPsTZgTJVTvDH1OnNakhhR4lUyvd3fToP4ievam7uQ+iP99Ef6m5aH3PVCcbqctu/BIffCKqbtHTsYTg9jYpCrZO37uXWs5yagV4X7WRVuPoYWrgxqyuq9UpSy3/rBJKiSm65a6JiL2WyOMmly+fqgvLHRJl5VvzQWwS5UvTcf8xW+YHkwXioaCZX28PJZQkhC4v0r76kqi00eO/p/AOzAR8D29gZYF1uPIilsbyC8awi5w/zgxBMYpsFgZIih6GpC47vJqhni3gTrq/eftbF1DrJ6ZWgVfaEVlPUyI1Xv+gMzB1gVbu4oO5E6wfrBDexJjkKVTynpJX5w4gkeGPoVOv2d7B6rBzne1H0TfZ4V/CD7fdLVgLijySMMRgYdk+wXR54n7o3RFeh2tAJ/ct3HeWTyW1Q0AxMdt+zCrwQo6yXLQqnB6qVmf1RTQFbIkpRfgyrRllWztmJ77/Q7rI2ta+qWAchVssgNZLRhGjZR7VN8SEarPf+KQtdtb3xoDlhUU2lmhHVNCq8XEIAJuk5E0qmVHZ5SeixfWSEY6o2xuS9ihxSDpcqbb6HTSFQ3Ykf79RzLHSFfyTOcGeZs9owdzBVyh1kdXTjoVxYyOzuvZ01sLalSkt6Q5edea5n3yj4+uOqDTcHEQXeIO/ruJON+G50JVuZ9DCuK3UXViLJeJl/Js39mH4fmDtkdE27JTcXQHB0PFVPj5fGXbFI57A5zz7petg98jsePP0aqUCRrnibBViQhO0IG50M3dF6feA1v1W7wdIOCfLx6nfrdCmpDUKRGAa/r3HOTXMM8DiwLpJqa/VzIqhnr+xMgAn6KxRKTZoZxn/WMOh4t07/ItjVv7RrmW59MFibocJlopQpBNNzhNjKcxlXNeXns1TNMpKzfUsTvYm1X8zOokYwby49RHLi9/qLRsk28GmDmcphl6/cid3aCpmHk8mTz9eezadQLC0UUSlUeQygypqEzJrsYE240BFIsimkaGFIe8JLwJvjI4AMIIciqWR4/9k8AnC1bz+GKXuGxo//HYZnqU3w2Qdzma3MIVGxldQNZXUNvsI/Z0iyTPh8Vyfp9SfNsuVaF++0O1YArgFou2zYgAU0mWJGRvM5tAq46t9Hu7+D9K+8BLPvD+djZeT13ukP4FT//dPQx0mrakc/ROG/Kqll0Q0eW6vfCxo6yjJqhUCnwzOmfMJIbYVNis/26V/YiSzI+4bM7zJJla4xa1Iq8Ov4KcW/cnnc1HuvqapbP6ugado//grTLxdlAiTFfiXF/GVTwV2RUV9WbfF7XeL6Sp6gVeHvqbcIey/+7J9iLJCTemHyDkdxZhmMpBmQDnyGzzz3t2L6slUmX0/zj4e+gm3qT1ct0cYqfDD9tCQIMk2J3nvtOR+0gRbDuxT88+S+ARZBfU2T17bffzszMDMlkkt/6rd/ihRdeIN/gOejz+fiDP/iDZTvIi4Wqqhw4cIDf/M3ftJdJksSuXbvYs2fPgts899xzbNu2jT/+4z/m2WefJR6P85GPfIQvfvGLyLK8pH1eKIrFc/vwXCuoncfFnE/p5ZfQq215mSe+j/e3/6ODiFB//nMq1XRubWKS8v/+a5St12FMTVuVSSCd8CGtHkIEgxjZLMaZMxSoYHR1UoqEEdX2vYyaYSZvTV66/N2sj67nhbHnkYXMHSvu5KXxnzNbmmE8O8Y/Jv+BQi5PeC7MKvqZzk6jVY9zZs7g+WPDAEQjK8kVT2CYBjPmPrxmFznGMISBR5Fo80ZIqSmi7hhyRV605fZC4JXAG5SW9HtZ6LvZ0OnjjRMuoup6ZgpvI5DoNjcRDYLsfts+30b4hZ9CYennsBxo9PBt4eqEqqsYyRQAwpChIayhEVeLsvpCIQnJDh88H3b17OJU5qQ9aTVMwx68+V1+PjH4IC8VXmJXz61N27b72+1JZw1RT5RUOUXQFWRdzBowxLxxh3e1R/bYYYero2t4ffJ1R+CiLOqT0hpZXRvUCSR8ipeCVnCoodfG1i14vQkhuKn7Zp44/s8AvDP7tv3auuo2bb56m3vC20bXAqT3Ygg1DJKt0DZrkLWYRUd3oJuPrf4V9ky+yZnsGUxM2n0dbG67jg3nCdls4d2FmS+QR2ZCkdC9Or6yTrcqyLhoIKsVEFBk0rarAnA1+FHXlNUxf52gXiohHHVHmwb3y0FWN4bv1XIrlgtCCNr97WhG/dld83k0TZPpgjWZCbgCjvbe+egJ9vDx1Q8ymhthc2IzkpD46OBHOZU+xfr4Bvs+1uZrI+5N2GTxzd1Wwa4/MmArnk6mTzpCUCUhYZgG4/kxXhx5wVY61u5NFaPCs2eeYVv7drvIFnFH2ZDYSLlYZrP/OsrtJfbMWXYmz5151nHshmnwk+GneWjj52yLI5/iY0V4JUPhdXY4bMwb51NrP80zp3/CWH6MjJohX8mjCJmzWWuCH/WGUDDQKFCRkuyf2cf6xAZ+fOpJ+75eMSoOoror0G0T31nVWTRrxO29d1A8+94Y+18zqDgJ4xp5VMPkbM6+2oXHA7IMuoapacQkzSar54R1f/G5Fe7b1oMQgqkGtaJqqE05OjVsSmympJU4MnsYj+RmY3wjXq/HDk998uSTNuG7Ib7hvGPdsDtcvy8JuHfVBzmWOuqw/1gIUjCIDmxLhjAj/YwYc5gYuCQXPcFeTmeGAXhj8vWmQkzjuCTijpI1rHPNa3mUKiFVO6aEP85QdDV7VcvHtcwcPtpJhDycSp/ixZHn6Q32cc/Ke+1z3Tez1w5He3PyTcd7zxZnUHUVn1um7AiANBFyc2t9I+bncwC8Mv4LPh540EFkzUdj0UsEApSSeXJKnVgsLWLNAQsoq+eR9JP5SbxumYFihpiqkA2FQMlRNlN4RNQmqoWA+7f1OixEaphfGDmQP862999F5Z29CM/SirUtLC8a/aqlRNwKc83lyRdKmFhlMdk0qD0pC0ImU/uqhQSShCHp/FzuZmvIRHi9qGYWRbaumag3Zj/T/YqfqCfKjDbDrDZLRs1QrBSb7kmN1hbzQxajNWX1AuOEnmCvxXm0t2NqFYTHiwj4GYwM2UW7tQ3dmAGXn2R5zrbwDGoyEoJwuJ2MkW9Yb2Ehnk9pHicF3SFiVUGBR/GCmrZEUqZh2bY2cC0mJhk1YxPwgEM5DXAsdcwW9xxPHUOrFg781WMSQhD3xhnLj5Gv5CnrZd6Zetu+N+qmztb2bXYnmCwU+sNWN7gsyWxt38bPz1hZBz/tnrVrpqtyXmYCGjOeih1AWUOukuPl0Zfs+dieqbdYGVrFR4cesO9Jclc32m1dTCdCZOSTju1Leonx/LhtfVsby9bGYIB9vEiCuc0r0HrXEr79bnsftcI9WMXL+YHBSwm8XgqWxBR86UtfciiJf/jDH/LEE08wOTlJb28vDzzwAN3dF2bqfTmQTCbRdb3JmiORSHDy5MkFtzl79iyvvPIKH/3oR/na177GmTNnePjhh9E0jS9/+ctL2ueFYnh4+JK2v9pwweejqoReex1Ra1NKJSl/61tIMzMITaf0vtsJPPOMTTbbeLFu5WFEIhy7eQspdT9kq5OCvj6mEgrDHTfB4XpL7HDpFMlCCoDOUhdaUWeDtgmXcDE7PEuwHOR4/rjjrZ4++mNuD7+PY6VjJIspNN1keHoSqWJdoMkUlDwhyvIUoDJSeZOiawQTnbDkZaO6ienKNFEzyuHDzvbcdwPzv5v1QY3xkzH80laE6UKXJK7v9qMam8lqGQwMTpVPkdetG3uhXOBQ9tC7cOROuN2tAdjVjLJawKyFz/jCiMDCxEjwKlFWXw54FC+7em6zvayHIk6FlFv20O3uwas0B4tKQqIn2Gur8LZ37OCW7l3kKzlcstuhxF4XX8f0qDWY2RjfhEuyyDCX7OIz6/4tM6UZTNPAI3tIlVM8PfxjwPKqNk2TVDVEKewOs6V9Cy+N/tzRvrw27rQAaURPsJf18Q02AQSWrcnaqlVBp7+TvuAKJgsT3Np760UVmdyyxybsGwfZ5yIMe4O99AZ7KVQKGKZ+zsl6C1cPzHyejHBR9uRAVvCZGivzXsIVF2cjK0HARH6cgEehUHKqR2pktVvy2CqgrStjjKeKRPxuVsQvLIhvPmRJtttpa1iqDUgjBtqDbFkZpVwx2Loyesn7WwiKpNjXTs3HMaNmrFZcoMO3sNVRI7oCXQ7Lnpg3bk8OaxBCcPeK9/PK+C8Yiq6x/Q9lIbMxsanq22/YxJdAsDGxif0z+zAxbSWXQOJTaz/N82efZbIwSaqc4oVqWzvAbb23OyZI66Lr2Zt8B93UbeJMEhIJr+VzmavkGMuN2hPWmMc67nv638fZZLrqnf9xgu4gXYFuOwB2Ij/uUIxualtHakJwsvw8fo/M7vFfsH92v03Ozy9mbG/fQV9oBT88+QPAIrkWUtQOhAdYHV3NvrP7zvs9tLB8MOcLMOZ5Vo+nS4AECHC5LEWjroGuEzOd6wLcbU7ZPuaNZDU4Cc4aJCGxs/N6Aq4AK3wrmTVm8cgetrZv48DsAbJqxqFwnm+/dSFYrFNpPpTBQSrHjhMOxPnoxk9RRmM0N0rUE2U8P25fs43P9lWhVXgUL8PpU+imzs7O69nRuZPnTz7H5Kzz/Bvvlb3BPg7OHASgyDQ+2vF4Szxz+idUjApHk0foCfSwqW0zACPZul1RaV6omollR2JKPgyc15YhNQtppgvTHEsdZX18w4J2AJOFSX48/BQf7r9vUcK68Rkg+f0UZYO8Yn1PUjiE2t+z4HYAAY9zn43K6rJeJlVOIoXDRKeKrNXbeDMUJC7JhANpJsdiaLo1Frt+MMGKhJ9903vRTJ1t7dvs8VR+HvF2cPYAN9z7eXwf/GDLNvEqgTFbbzGU4gmk6Rl0oKBLoGsgK8Rlg1p/TxGZtCIBVkCmkGQMWWNSeDnTYT2XK2TxVYsXjVlSQgjWxzfwUt4KQT+RPo5Q6mNvj+xBM3Sua6t3OtbsQMB6TtdEIYEFlNV9wV7ylRwoMsqKFfbyHR07baHKynC987RG+GIHLCpIwQDRQBuZbCNZvfA8cSGyumbHCuCTrTmUiUlZL5NTc03rp8tpJ1k9Tzj4VkNRrNwQ1OhX6uPHsDtsjxVyas4RHP+LsZdJlVN24WhVeJUjtHFTYjOveX6MRjVuxe8nkK2wZS7IHleeGU/FVp7XkFWzTf7YZ7KnyalZuxAvFBnzthuZyY2Cc2iMqqsOtTlYdmof7P8gr0281uQDLkXCjG1cQ3sDz7l/xjlGKWtlW40/kh3hx6eeojvYzUrOn8d2KbhopqBYLPLoo48CcP3113PzzTfT09PDb//2by/7wV1JmKZJIpHgT/7kT5Blmc2bNzM5Ocmjjz7Kl7/85cv63v39/fh8y6uweTdQLBYZHh5e8HwKWoE3pl6n3dvO+pilFtD27aMcmkc8HKu30onnnsd0e8DtQdm4AXntGtSfPsMpaY4xf5mtuThtX/gtZqRRYtMjjt2E3BE2rN7mWDY6MkIsEwXgloFdtDeo/gDWm+vpnutmIjfN88ePkC7NsaZbR+6WiRVjROYinJjKEwt04KkmeAMEuYFR8TN8bomCOoYbGZDZuWozm9ZuXtJnudxY7LvZAPgSc/ziWBQh4Fd29DAwz2ZEN3SOpA5T1EtsSWyxybB3C8eONbcEtXB1oTg9gVltPxR9Q9SGSV63TKnBGz1wjSmrLxbrYuvIqVnOZs9ywwLBrefCzd03U9bLdAe6ubn7FoQQC5KvmxKbmSpMoRkaO7uud7zmkl3zAjbqA9ZUOUW+krdVj1FvlC3tW+kP93Nw7iCjuVGGIkNNgarzcWvPbQynh8lpVrGw299tH6cQggeGPmaFEC0QWnku1M63scUfLkzd6gh1aeGqh1HIk8FFyZNHKApuDDpKHlaJODeu/SRnMmf44ckf0B31cXzCqVRVpFrQZsKevAe8Cg/euHAGxsUg4WtzEBXLUfyQJMF92y6/L7pX8aKqqq2snmkg+Rfz5V8KOgOdfGz1x5uWW37Yex0Tv7g3zrb27RxPHnMENm5u20zCl+Dulffw2JHvOkKw10TXNpFvPsXHYGSIY6mj9rJV4X56g7124e7oXL2luWbpsmVFB/9efBKXIjHQZt1Huhruj+P5cTIN6ss18TWs2xXlqRNJsuYwFaNi349ckouPr36Q/bP7ODh7gMHIEDf33OKwVRpvsBaJexNk1QwBV4D39d3Z6g57F2A2KaudNiATeQ1wI9wu6/uRLaLR1HVihnPSv87IsLpKSJum6ehGApq6k1RdZX18vU3iDoQHKFWVwIqkcHvv+3jq1I/sbXqDfU1e1csJz513IPf1Ind1IRQFL4od7t54bdauRa/s5b7Bj9iqPN3U7blAo21ZDWFP/TndG+xFkgSyLCga0ximxr7UC1QayOZXxnczGB3CK3uZKEw07S/oCpKrWCTUeG6coNxs06TTTFY/c/qnJMtzjGRHHNkgN3ffwhsTr6OZGqczw/zo5L/w/pX32kpS06zmgLicHrVSLAYeNyk/KKtWInd1UWBhixdYSFldJ7CmCpOYmMg93fS1X8fWwbt5e/SfrSKcPMpnb7uTV47PEfAo3LG+g9HcCP86+iIAfsVnt+TPJ95KeomjySNsTGxa9LhauLJoDFeUEwn0kPU7ywsZKhZZ3aHUyeqCUEhWxzZCEsiSwJCsa3G4SrpWyBGpktXzM7HWxNby0lmLrB7ODjsEXr+24bNNBLDf5SfijpBW08S8cdsreb4NSNAVJOQOL2iTFvPGHPkcNQQayGqXKXAbAqmtzSLEG4ZzAWXhcfv88bxH9jiCrr0N51LSio6w+RrSasrx9/wCT83iaNFjBwINKvN8JefoYAMcWQNrG7JFwLKG3BTfxGtYokXJ7+fGcfAIiUTZxbEQTcrqyfzEgvZMx1LHHfkChUrBEQhZQ1kvO2zgPjr4ACurlmySkHni+OOANaeqCYKOJ4+xJrqW0dwIiqQ0WUiW9TpZ/ebkG6hGmdOZYVZIK+3Q+8uBi2YKfD4ff/M3f4Omafyv//W/LscxXTJisRiyLDM7L3l1dnaWtrbmZFSA9vZ2FEVBlutV0MHBQaanp1FVdUn7vFD4fD7bR/i9gPnnY5omPz3+NGcnjnDc68HlcbGlfSv54yfsljEpGsFIzbvBVLR6Je7OO3CtXs2RoTC/eO3bmHkdc806fmVggPKZk/Z+atCF3vSZprQUiqLgklysiK9YkDy5KXAzP9s/QaDiZ0Z/lqmsytvJPYTcISazFcqaiVcOEw/4yRQrmKaJQpSEuZlA5BQTqRIVzUCRBdev2HjVfa8L/dbu2uxjoCuKzyXTFV24aHJ98OKItsuJ1iTv6kdptsHrvGsFVMcB7SEPZ2frD9X3srIarN/q9V03cP1FEtVgEWWfWPPgeddTJIV7V33ggvYZ8UQQCDuQsdHXrUZKhz0Ru53/QuBVvNzedzs/PvEUAOtjGx2vCyGWPIgJLUBWL2YD0sK1CzOXJytclL1pULy4MOgouRHt1uQgXvNP9CpEA25S+brK0VWdrMV9yx9y3dgmC8tjA3Kl4Ff8VrCOXsbAYLoh6K9jGcnqxeBVvOzo2Mnu8brvdKe/i4gnwmc3/jvOZE9zOnMaRSjc0r0LsEjlnZ3X2yG2XtnLbb23L7j/zW2bHWT1utg6fA2T3RMNHsI1RZUQgs0roo79NBbzzmRO2974fsVPl78LIQT/dusH+T9HvmtbKrX72rmt93ba/e3c5b+bW3tuwyVZBGejorTx3jUUGeL6rhssckosbjnQwmXEfLK6QVlt6jrj5So5VCV2hCxjAoqhEy47yYA79Cm8H7Keu9nqddaIRmX1QGSA1VFnHs98DEQG6A8P2N1U6y+zdZWQZVzrFlZuLxQGvzK8yp4zSUJyzJ+6/d1Nz/jGzImQO0TYHcYtZyjpc8yKdwgZKSRJ2OORkl7ilbHdbGnfan+WUU+UQqWAJCTuWfUBvl+1HBvPj9Hlx7YUr0ETzu9I1VXbX3a6OIXccMzrYuvpCnTzoxP/gmZqjORG+MfD/8Ca2BrK5TLvpN/Bc8KN3+13hsMqMu5tW8m5I8gV635QPIe9oyJLeF0ypYpOwKPga/CwnsxXx8lC0LN6B754F4M5qwhX0kvkzHE+tnPIXr/xHn42e7ZOVi9AVJ3OnG6R1VcRjDmnDYgUtJ4TBRRMVUV4vbRJ9ftTAZl07TEhScRiAZL5IlIwiBEMIQCVrG0LM7/rKewOk/C2kSTFTGkal2aRu3FvYkGlMsD7V93LwdkDbGr43Xhkj8M+sCfYixCi6f2CrqBDSdyIGuEr3B78moxAIPf2EJknhPFfoA1Io6oacHSnlvTygjk/85ctdM0shEaiPNjwvrlK3lKXz4NAYlv7NgYjQ02vbV93Nwfe/ikFNcct/XcT+4VVeIqp1ncj5nlW14IQAUeQ5JG5eSHaWnHBe1BJLzkKj42kfk+wh7tWvJ/JwgQ3dN7AD0/+kLnSLBOFCf7x8Hcc2zWiptRuzPkIuoKI+cFxy4wlMQWDg4McPXp0QU/bqwFut5tNmzaxe/du7rnHMmg3DIPdu3fz0EMPLbjNjh07+NGPfoRhGEjVFMzh4WHa29vtitTF7rMFCyePvcbwqz/ByBcQisy/ajphOUC0aosh/D6Cv/7r5B59FLNUwrNrF+VXX8UsWQMWuS2BMjTERH6c52d+gTLQD8AYJQqVgqNFvObrWvMuqg2oCpVCw0SjY1GVX6ZYYc/wHD7a8OgdZEsppnMZRrQUs9kyEgpu2c2DN6zgX49M2SqvKOtY3+7DoxxhJlumLehxtMFczRBCMNC+uH9lCy1cLEpz9UG1aOuBvPWsSMwjq6+WgMVfFiiSQtAdIqtmSDeR1UsPgF0bW4e5wuRY5RhDCwzSloqFbBcup9qshXcHZj5PSpJR3UUkJUDC8OAxJKSENSEKuIK4JBcVo0JPzEcqr+IiSIVcXVntvTTRwEKY7+O4HDYgVwqNEzzVVJkp1cmz9guwAVkObGnfyt6Zd2wVU0115ZbdrI6uWZDA29Gxk6nCFBP5ce5Zde+iXRLdgR7bL9sre1kV7rfyLKrkV6P9Ruwc4dZexUvMEydZniNZba0FGIwO2YVxj+zhk2s+xXh+nA5/R9PvoHGSrkgKPsXX5CMbrIbrtvDuYSFltaYbHBrLIPI5UlTVeq7q/6viJY9p0J2dpsf0ksbFg5+8jXh5A+6dOwFncGkNjWpc/yKKwfm4a8XdvDjyAn6Xv0mZdyXhU3x4ZI+DgK/5ry4Et+wmrsQwGixx5l8jvcE+ToWmGUkW8QQnkCQfilC4f/Cj/PjUk6iGysG5Aw7F5MbEJjYlNiMLGVmSbXX1ZGESRXIhSwJdr7PVquEkj+YTVDXFtiIU27f/o0Mf4yfDP6agFVCNMgdm96NpGgWjgAdnbogNIUhX6vNO1VCp6BX72HVDZ640i2GaeBQP1w/GeeX4LDetdj5PGn83nX7r3rg+vsEuwr06vpu3pt4k6ArygVUfdMx1G1v4F8pCyi1ApLXw7sFhA5JIIGxltYJZqVA0pzmp7KPs8eIpBykIhVyNuxQS8Y44aaOM0rfJLguZUg65Ov5ZqANyVXAVx7GsTWvWfo3dBfPRHeie14lZ7XB0BW1lci2sPOKOOGywzjV/8Cs1stpFfPNOPD09eO+8k6ioP289ssdWc8/HfLI6OJ+slhvIaq24YGh8puz0677Q/DCHsrrh35ly2n7GB1wBOv1duGU3Ozp2LjreCPjCfO7f/v8olbJ4lBBnfK9BqUxcdVnfqaI4SOnG8cia2FremX4bgNmGsRxYZHW+Sr7LQkEAmqmh6qpDWe2VnX75GxMb2ZiwxEVromt4dcJ6Zi1GVINVAASYLkzZXbk9wV5o/siXFUtiCr785S/zO7/zOzz66KPccssthEJX3wD+85//PP/5P/9nNm/ezJYtW/jmN79JsVjkE5/4BABf+cpX6Ozs5Pd///cB+MxnPsPf//3f86d/+qc89NBDnD59mr/5m7/hs5/97AXvs4VmFN96kxde/msMl/WjNjWdypEj/Hj6UT5e0fEg4dq0Ebmnm/BX/m/LJ06SUAYGyH3zW2CaeG6/jWwly1OnnnS0h5oYnEyfsH3IPLKHiDtCqpzCxETVVbviNlmoKz1rg4KFsPvYNHrVviCoriXvf5PhmTwV3bohK8LPh7f20hHxsnVl1CarfW6Fj6y+lx+dLBH0jjIYGWq1orfwSwnTNCmlq56esoweSgDW9dfe4NcnSQKfu6Uwu9KIuCO2EmyioU09eokk8IrQSnLuhVvplor5CgqBaFrWwrUPI59nRpGhqrTr33wT7rgf7x13ANhKnqnCJG5FYkWbn3QyQnfYhyRVC2GXQVkdb1BWe2XvosqhqxGNKuOyUbZsQCRLBXOlxiaKpHBrz+08c/onuGU3q8L9591GlmTuH/zIedcTQnDfwP3sm9nL6ugae6Ib9cRsNWUNNc/qxdAd7HZs41cCXN/p7Ibxu/y2TcL5EHSFmsjq0DkCLVu4QphHVs+VdL730imm0iWMXJ3cawu6rLl3tWPTgw6pJJ/UNHApxHY4u4fm+1UDjvbtxRSD8+F3+fnwwH0XeDKXD7X7bW18IAnpvOKbdlcHk1hksE/xNdkF9gZ7SYQOEg96qDVH3th9M32hPq7vuoFfjL0MwN7pd+xtugPdjntud6CHY6mjVIwKw5lTKLKEoYOJNS9UTef4I9VA9jQi4onahaieYA+fWf9rvDT6c44k64pFgcAr+9DOYfHRiKJWwCVH0A2dx499z2EDc0Pnjfzeh29Ekpzqw1oRr9EjuC/UZ5PyNbJqiknOZE+TbSDcaoGwAVfAVonKQsYtuylqxaYAuRbeXdQCFqVIGOFyNSirZdA05sRegowzF1foHt9AEblOVksSHpeMx2OCamJfQEoe8BJwBRYcmyz0vK2RzReDkLtOVvdUt5clmagnYv9GzzX+agxpjK7ehH/FXQBEyvVCU43QXgi+ecW++dYkjYrholZyeNPXVOHz7wUXrKxuOK7G952sWvgAdPm7+dDAhy9ofz63H5/bT6FQwPB5oVTGbUhsnwtx1hfn9hXv56lTTzqyMABWhlZycPbAghkYjcrqgMuPbupoFY2yXnKQ1Z4F8pFqGIqu5tWJV+y/ewK9KJJCRk0jCdnuEqsVMEdzow3r9qCnnce73FgSWf3cc8/R29vLO++8w5133smOHTuarDCEEPzX//pfl+Ugl4L77ruPubk5/vIv/5Lp6Wk2bNjA17/+dfs4x8fHbQU1QHd3N48++iiPPPIIDzzwAJ2dnXzuc5/ji1/84gXvswUnzGKRd579B9Iha9DWWXbj1iXOUqI4NsKkN05cdfGzrjO4Dn6Lm7pvtpU2ro0bCP2n38bMZDHWDvLk8cftwX9NBQOWz1nt4kl4E/NuWkWbrJ5qIKuFHuF//vQIsYCHB29cgddlPRGOTWR450zKen9FIuoK4jN3MKvVjff7YhG7jXSoI0Qs4CaZV1ndFcIlu/jY6l9hpjizoJ9TCy38MsBMpSirRXCBNxCm3KB8CXlddktk0KO0LF3eBUS9UUZyVoBRreUYFlZmvNuYr84KuIKLhiC1cO3CLBRIukMWWS1B+9A6ArfvcqwT98Ts53gi6OHugbWousqhuYO4JY8jIGi5EHAFiLijpNUUHecocl+NaFQjzWmzVOQKiqRc8fNYE1tDm68Nj+xZdpI84ok02YR0+DscxLNbcjsUUQuhO9Bt+03KQubDA/edd5tzIewON3kYz1eDXW34zne+w6OPPsr09DTr16/nj/7oj9iyZcuC6372s5/ltddea1p+xx138LWvfQ2witZ/+Zd/yT/90z+RyWTYsWMH/+W//Bf6+/sv52mcE40Bi9PCw/fK7YjxOSrHjmGW6pP6jW0+dgOiGt7qwcCsVAP1FsgXml6ArG7EhSqrrybEPDGbrO4J9DpCnRdCI1kdWsAuqUaS1YZ8cW+CLe3W72tjYhOvT7xGxajYBJAslKYOkO5At8P6R5EEQkTQzAIaRYq6M88gVUoteKzzrcS8ipd7Vt3LTd03U6gUKJaKjJvjDA4M8r3hx+z1Et62JlVjDXmtQNgT4e3pPU3X/tHkEW7svonTmWHemnyLLe1bGIqutsNvPbLHYbGyMbHJtkKqIVlK2hZFNUzkxxmKrrb9dn2KH6/itZWWpmnSwrsPs1TCyFnfUa1brKasLoiqDYhcQjZ1NJdVeCkKhbxcvRZkCUUS+D0ypqojUNDNMpJs3ZMWsu0BSHgS+CTn/aoncPFk9ea2LUwVphiIDBJx16+dmDduk9XnUlZbQet9zJXmHNY0IXfI7kKa38XWCI/sQVDn65rJ6sbQ0hKpqrLap/gIuILMFKfJqll0Q7fnDwt5VAskeoM9jDTYbwQaxiyNY4JGTim4xEK06fNB0jrWrakwt6/+DHIkRtAdtJ0Aaoh6Y7T52ptCEcHqoqipof2KH9WokK/kKWllykrJPje3tLjYIuaNsTGxiWPJo2xp28qN3TfZ96RDswd57uyzADb5PZarH0dPsJeznG3e6TJiSWT1E088YflQCkE+n+ell15acL13k6wGeOihhxa16Pj2t7/dtGz79u089thjC6x9YftsAUShQGX3bvQNG1H37eWo27qRyfEYd+36Lcb/4e84Wx3QpN062evXUQjqoKb56emfcHD2IPcN3I9LdqH09WGaJk+detKu6kTcUT6x5kG+d/SfSKspR5vazs4bOJM9bf89kj3Ly2MvMRQZqisfTNh70iRX0siVNJ56e4wPbunmmX3jHB6r3xx2rIqSns5zONOHLnKkOUJHxMv7BuuteZIk+MyufkbnCgx1WhMRSUhXxA+yhRauVmhnzqBK1iDLE45RqtS7IbxuudoSOcP1g8uvhGzh/GgcVNbun1Zb7NWn/JtPVl9LnsEtXBjMSgWjrJL2GwhJwi3LC37P8z0SQ+4wa6JrCLvD9Ib6HO3jywUhBB8e+DAn0ydtf9BrBT5XfZI6VZmC6nzu3RifnMuGY7nR4e9wKCTj3vh5i6L94QH8ip+SXuLOFXfTFei6pGNYaPK61AntlcBTTz3FI488wsMPP8zWrVv55je/yRe+8AWefvppEonm5/RXv/pVKg0q5VQqxcc+9jE+9KEP2cv+9m//lm9/+9v82Z/9GX19ffzFX/wFX/jCF3jqqafweM5NfF42VOpk9VtSnIpuIE9PEytmaDdLnJRCBE2VRHeZ4uw0LrmqrG7o6BTzyGorXNGyPatZFTXCJbmuqY6MGhoFN/2RxS1AaojIEdq87aS0JIORwabXg+6QXfgDeF/fHbZ3u0f2sC6+nv0z++z1O/0dTYXp/sgAu8d/YX/GiiShEAUh0MwimllG1VX7817IuxYWz70IuUOE3CEKosCsNEvIHeL+gY/y9PCPAdjcdh0vjjy/4LaFSp6MmuH1ideBqjK7Shxn1Ay6ofPS6M9JlVOk1RRD0dW2AGu+zcHOzuvxyB5ylRx7pt4CLEuAzDwCazw/Tn9kwCaQAi4/XsXHTHEaE6Opu6OFdwfGXF3VK8Wt+6kUDGECKhKiooJkIBkGCBMTg7zsplidR7ndCgjLNtHIVpBQqJCz/aqjizxfhRB0ubtIYb1/zBNfUsF4KDrEYGSw6Tna4e/gZDUb4lzjCklIfGz1xy2broZ9yELmvoH7OZM5c05/dSEEfpePtGZZUDSR1XL9+smoGZuIjniiBKtktYlJRs0Q88bQTd2+ZhLeBBk1Q8Wo0B3oZkVopYOsbuyK8Sk+ZCFbAagN9kBLLWyb854lks9rn18jWS0LywKpfRGyujEbw+fyI2k1X2nNtgfxKp7zjoPuWnE3d/bd1bReoyd4zWK3dhx+JUDUE706yWrAUbFbqHrXUsy9tzGRH2c4Pcymts0OQsH33POo6QyZn/6Mkstktq+CENCxZhs9fRuQPvYZxO7/jXC7KN50O0Y0BA1BOCO5s7w9vYcbum4ErJCSmvrPI3u4f/AjeBUvq2OreXPyDXu7VaFVrAyvdFS7aqnJpzPDyML6qZfKMmpa2NX9o+MZTk5l0RrUn6s7Q9w4GONYZZJIe5x8ZRfxtkF0Ocv2zu2OzyHscxHubXmottBCDdrpM1QkqyXIG22jpDaQ1S6Z29Z1sGtNe1NLZAtXBrEFFNTdwZ6r8pk9X43YCld8byBTTlPQinT6OzGyWYrIqIoKQsKtSAt6Q88nPMPuEH6Xf0nhpReDhK+NxDlUP1crGgmQWW2GMFYBoN3X/m4d0hVB+7xJ82IT+UZ4FS+f3fjvUHV1WdTf83+/XtnbZItwNeEb3/gGn/70p3nwQSvQ9+GHH+aFF17g8ccf50tf+lLT+tFo1PH3k08+idfrtclq0zT51re+xW/91m/ZGT///b//d3bt2sXPfvYz7r///st7QovArNQJhlnhBsNAVFQ+rZ3GjYmpTzDiL/GCyDIrq8TdG5Gp2oDU4POyZ+otpgvT3NZ7OwWtYBd9e4N9nMmexjDrLdHXoqoaLO/kE+kTKEJhY3zjedcXQvDR/gfQFW1RleWtvbexe+wXbEhsaLIj2NK21UFWdweavXVD7hD/dv2vcTR5lBPpEyQ9KYziECmOUBYzSEKQUTO2SnMxG5CLyefoj/Tz0IbPokgK2XnK5kYUKgVeHn3Jtn+5rm0LRa3IsdRRTExmijM2eZ6v5KnoFZt0984jqyUhsaV9KxW9YpPV47lxh7UMWOrGYqVoq9H9it9hmZBvWYFcFTCSDWR1rBr2GwqiIzABUy8hCUDXURAYsk7KF0WXNRACTzWUM+CRyaACPke44rl+z12uOlndG7p4VXUNC80PNrddR66SI+KOXFARfKF9dAW66Zrnk70QfIqfdNUYucmzuoFMtUNLgag74hDhZNQ0MW/Mcc2E3WFu6r6Zk6kTbO/c2WSfE2iwARFCEHAFmopG88nzC0UjWS0kAd46Wd2IsDuMJCTa/QuP3RpFm37F7+Bka8R9o6/3ubDQd9TYVVPWy0wXpu17V281cPNyY0lk9be+9a3lPo4WriFM5Mf5/vEn0E2do6mjfHLNp/C7/JiahjwyAqEwmCaj7gImIHd2sqrTSp1uW7MFT3EbJiYpn4nakG5cw4HZ/ezo3IksZIen6g1dN9oT1tXRNTZZLZDY1Xsb0PzQr0E3NTBhLuUjNO/CqhHVXrfMPZu72NQboVgsIoTg1jUJ/H4/sOKSPrMWWvhlQfnsafSqIMYb76CYq0/0fFXLnRZR/e5hvt2HV/ZxZ9+d78qxnA8BVwBJSPbkv6WsvvZRqBT4h8PfQTd17hu4n643T5IVLjSlAoqCW5EILkhWNyurW1gcjWS13kCezSdz32to87XZIYvABVuyKZKyaMDTxWK+r/5Cv+erBaqqcuDAAX7zN3/TXiZJErt27WLPnj0XtI/HH3+c+++/vzpWhpGREaanp9m1q27lEwqF2Lp1K3v27HkXyWqL7DOApLDUtxG1gLtG9n34g7wsdiP8PtxZnax3nCg+PA3+oeNBzfZXFkI42tdXhFYwU5x2hNv5rtHsGq/i5cE1n7yobRRJIexd/L48EBlgYBGVdswbY2Vold0duxiBFXSH2NG5kx2dO/m5OcXL6WkU048iCxBWIbTN14Zpmosqqy82n6PWFdGYmTQf08VpW2XqV/zc2H2Tw3/7VOakY/25Ut2qaL6yugaX7CLgCpCv5G1FeiNmijNk1Hqymd8VcBRHFrI6aOHKQ5+rf9dyvGoDEgigVW0WjEoJSQhMXcdvgi4buHu6QJORfF7cijVvcikSfp+JVgKVFIFqAOxiNiAACaWNLYmt5I0cOzt2Lut5eWQPd1yhuUNNvSyAUJOyuk7ENlrwRDxRh+o5VU6xCme4ot8VYCAyyEC1G6RxfZfkaurYC7qCTWT1ciirhc9nk77zu7Ai1TnbhQgNAq4AmqE1LT+XX/X5MJ+sHss3+FUvwQN9KVjSyOzGG29c7uNo4RpBRs04gg6zaoYfDz/F3SvupnRmGPT6RTLqLyEUGbm3h5WhVYA1mIl4rBDEZGnO3k+Xvwufy8+p9EnylTyn0idZHV3jUEp3+euDl4Q3wUB4gFOZU9zQdYM9IfGd44JMFlQq5RAI6In56G8P8oujFlm+vifMvdd1E/Asz2SlhRZ+GWFqGqXxEegD4fPi9QZIJhvI6lag4ruOoDvkaFf+8MCHCV+liuVaEnltcNhSVl/7mCxM2s/98fQI8d27yaCgKTmE12spqxfw9w27w3YLJjSrV1twYn4oEVgE/2LEyHsFLslF3Btnttoae75wxcuB+b/N+ZPrqwnJZBJd15vsPhKJBCdPnlxkqzr27t3L0aNH+dM//VN72fT0tL2P+fucmVnY8/dCUSwu3dqgksuhaRop4aIiA5iE80k0TUMoMvqNN6Ieehs0DUUyqZguDMPEralo1bnNXtcMmmaRQ8dmjzLnmUWremG3Ke24TLf9N4DLcFEoNId51c7jUs7nasFyncu22Hamc1NE3FHalMSCn1sjZFND0zQkfAgZNE1jOjtNl7ubfCVPUbWOJ+QKka3UVdFu3X3OfS92PqZpOL7bRpyYO2G/NhAZRC/reE2vvezI9BHHtmPpMftvSZcWPZ6ACJDW0o5ljcW4w1OH7f3IuowsZPvv2ewsstnKhrnSMA2Dwt9/ByOTIfDZhxZWVksShj8AKuh6GUkIMAziaORdOmbUh2xa98+aghogEZKZLEGRWToVCYGg8xwFaCEEN3XebBcSr1Vs79jBbG6WNl97kyhxsTFNzOu0PakVrxrDFecTzR7ZQ1egm4n8OJ0L5HssZJe4VGW10UhWN3w/8/dXm/dEvTHHGLhRyFODT/E7lNY1XKiyeiHMJ6sn8hP23z3B5g6Yy4EWM9fCBUM3dZ46+WSTD9ZEfpx/OPwd1LMjdKwo8oEseO6+kynxGq6wF7fHT3dDlTzuTZAqpxxV6jZfO0PRIU6lrcHxvmkr4X2y6jUtCcmhYBBC8KGB+yhpJcfNaDFlNUAqX8GP9aC4fV0H/e0B+uJ+PIpEb/zavpG30MLVgMrefZRNiwSVgkHcsodi1QZEkQWKLJ1r8xauACQh8b6+Ozg0e5BtHTuuWGV8qQi5wzZZ3VLTXvtQGwbShVPHMHJ5MlIMPSQhZJmg27+g/7TVBtnBRH6ckDt83sCvX3YsNIHr8L23VdU1dAd7mC3NIpDOGdx0uTD/PhW4iv2qLxXf+973WLt27aJhjMuN4eHhJW/rPnECbyrJaVcENWjdh9zpCVKlJEYgQO7wYZLJFABqSUctaqiqRqWQJlVOknMbHNGyaMk6+TeFRcz7JB9jJ8bI5DIkKyn79UhhjkO5Q5flfK42LMe5bGU7aHDk8NHzrjuRqpBMlVElDTVUIpnUOFw8jDLlYqYyQzKbAizSKl/Oo5oVFCEzfOz0BRG4C51PPmXtZz6SpOx/p9U0h+YOkdZSJDOpptcB9hf3kawGQM4UZziUXvg3ksvnSc5TiHe6OpmsWEKuN9KvUzCsOfl0eRqv5CWZs9Y/UjrCWt863O5rzzP9WkZl/37U/VZgb/67/wfR4NEvxesqaC0YgjkwdNW2AfGbOopLpUTdssjjqot8NvT6KeYhYBbxu/0kfG2XpJq9VtAb7OVTqz/NoUPN14ksyU15AQJBb7DXQebWAlcbldULFfU/uOqDDGdOL9gFslD2xFLzfswLJauroZaykEn42mwRZ5e/i7F5HtZ+xddkZQJOq5SLhaeB6C5pJftzFoimTt3LhSWR1Rs2bDjvOkIIDh48uJTdt/AuQTd0fnzqScp6mQ8P3N/k3Xdw5oCdhBw2vdxqDPKMdAhNmBiGSTaTJx/TmNDKxNevYG7iED63TF+wzxGUEfPGwFkops3XRm+wj5gnRrKcZCw/xlhuzPYca/O1N4VtSEJqOkav7MUwTIqqjs8tI0nCTnCuaAIPcWRJsKotgBCCwY737iSihRauJEzTpPT883a4otTejlt22wGLXldLVX21YH18A+vj53+OXw3oCnQxmhvBI3suuKW/hasX9oTChMLRw4BMRigYAQUBxH2LFyTu6LuT/TP7WBtbu+g6LVhYaHKymOfhew03dN6IQNAd6H5Xgg09sscxeV6oU+BqQSwWQ5ZlZmdnHctnZ2dpazs30V8oFHjyySf5nd/5Hcfy9vZ2ex8dHfUCyezsLOvXX1pQaX9/Pz7f+bsDjLk59H37kDdvRqoqvCtTU6jRGCflBG7FIpBWCBdRbwypu4vOtYPEjkQB8FcMJrM+PG6D9UhEfTGOtWUIhMNIsWjT+62PbmBjz0bmxmcpJ0v28jXta9jQ3vysLRaLDA8PX/D5XM14t84lOFfgYHoUHS9pv59YzE8gEGDDqg0cmjtIbCIKwKauTawz1/Pm9OtsTWxjY/u5PbjPdT77j+8jpS7shV3DzsGdxL0JKkaFfYf3LrhOIBgglrOOb3XnajYkFh6PabMamUnnhPm23tt4bvRZ+29PNT13fd96Aq4gx05ZRH8ilkDJtTSJVxqNSmrtxEnkbiuwV8gSIlwf3xj+IMyZGKKCMA0wLGJ1wFvkQANZHfeG0bAIVr/P5MM3+HjqlMV9zPd+/2WFV/FRUetktaXA9mKaJh7ZQ1kvk65a5jSSuYEFbJqC7hCb2zYv+D7ziWSf4mvipi4Upr/BDzvQQFbP68yKeqP2vzclNjFdmKIn2EuHv6OZrHb58VSahRyXIu5QJMVWcZf1MsUq2e93+ZHElRGgLekutlCgYgvXPk6mT3K66hf2zvTb3NJT95srayVem3jV+sOEW16YIDZ+gnt3rmb4lgF+cWKU4YLA6wrzRk+R8sRpjk9k8bll7lqx0vE+CW9zunibrx0hBNe1bbGDEV84+7zd6nShCfZexctosshstozfo7BjRTcfX/1x3pzcw9SZMrJwkwh5Wp65LbSwzKjs348+OYXqM5BCQaRQqEVWt3DJ2Nl5PRF3hHZ/B265pRC61qHq1iTMLBYpZ1NAgmRbFOGyJhBt/uii27b52rhzxV2X/yDfA5CFjFf2ktPq/rkXOo661uF3+Xlf3x3v2vtb9kUhkmXLq/Rqtqxxu91s2rSJ3bt322GIhmGwe/duHnrooXNu+/TTT6OqKg888IBjeV9fH+3t7ezevdsWN+VyOd555x0+85nPXNLx+ny+87a0m6ZJ9h/+EWNmFun4Cfz/6csAFGUZQ1FIyT57DtAu6yiSgisaJSeVUBRrWqwo8MGNcda//TohWaciJE5ES8judtwuL4okO9qtV7etxu/3EwvEULL1qXUsGDvn8V7I+VwruNLn0oWCokwimwFC3gCKIpPVs/j9forJov1ddka66Av1cWPfjRdlibHQ+YR9YXJG3VKkRoTVIJDojvbYBFbEF1kw6DCrZ+zjiwSii35uXVonyqyTqhlqW80bs280eVLHQwmCrqC9X01UWhYgVwiVI0dAknCtWYPwO60lauS1FIshpDq5pwUCQA5TMpAMHVO3yOpOr8reBrK6IxBjrGoTU9bLZHJ1z+SFgkh/GeGVPTTGn/aF+gDrWRzxRJkqTJJTs2iGRr7huvErF+c3PV9FvVQLEADT78N1042I48fx3HrrovusKasBNiY2MRgZwiN7eGf67aZ9+l0BhxK6hkuxfxNC4JE9FLUiJb1ouyssVVG+FCyJEu/p6Wn6r1Z9FEIQDofp6WldQNcaaqppgDPZM4Bl8fHGxOv87MzPKOmWWmBIdJAYty72+DuneF/bLlyzG3GVvOQlN6NRL29NWeGHRVUn5nL+FuINZHVFMzg6nuWnb2cpVXTWxdfjlixCojbQB+j0d13QOUimm7mcNXAolDVMLYZH8bI6uB0fltqjPdRqH26hheWEaZqUnn0OAFUykXt7QIBkuuwA05ZfdQtLgUtysSGx8V1p579a8J3vfIe7776b6667jk996lPs3buwWquGTCbDww8/zG233cbmzZv54Ac/yIsvvmi//tWvfpV169Y5/vvQhz50uU8DaCCrKyqqZE3OUrFqeI6AhL/lS75cmD9B+WWxAbka0EhQX80BiwCf//zneeyxx3jiiSc4ceIE/+W//BeKxSKf+MQnAPjKV77C//gf/6Npu+9973vcc889xGLOgC8hBJ/73Of4q7/6K5599lmOHDnCV77yFTo6OmxC/HJCO3ECfcZSimtnR+ovVAMWa+GKAoiZ1v1IhIKO0DsAl08hRNX/11OhIpmgKKyJrmYwMmSvZ7WcW+SIf15b+cWSIS1cOCJ+N3dv6mJDb4T1HZbCtKDlKWpFUqW6urXWqr4cxK3DdlL2Nln+xLwxh9Iyukj4nSOE8xwt+vO3V4SCT/E5rDUbj83v8iMQ1fdoBSxeCZR37yb36DfI/e2jaMPDoDltYsySxUlI8+6Tht8i+wyhIxr8zDW34KY1YWRJ0B7xEvVF6++llxnL1dW0LWW1hfkE7YrQCvvftevfxCRdTlOs1K1s53fnnw/zieRLIasB3B/9COE//H9wrVljL/MpPmRh3UMk0Rw47lW8CCEWJKD9ih/PAqKehQjsi0FNmZ2v5G0RaWABC5XLhSUpq5977rkFl7/xxhv83u/9HgDf+ta3ln5ULbwraByozRSnGcuN8S8nvu/wlpaFwvWz9YezqelMvHMILZ0jOtfLRMcRzgo/NZugoFhJuewkh6OeKAIJE4PJTIlK2cfobJm3hufYtaaddfH17JtxTsbPFSDQiNMzRRqF/2OTXnTDZDpbb8tra5HVLbSwrNBHRtDHxq1/d8WRIlEA0vn6xdgefu/7qrXQwnLjqaee4pFHHuHhhx9m69atfPOb3+QLX/gCTz/9dFOAGYCqqnz+858nkUjwF3/xF3R2djI2NkY47JxUr1mzhm984xv237J8ZYpJZaOqQtM0KpI17E0Ja3LnVqSrWoV6raFxMhN2hX8pvC2vFnQFujiTPW0FPi5CWF0tuO+++5ibm+Mv//IvmZ6eZsOGDXz961+3bUDGx8eRJKe26eTJk7z55pv83d/93YL7/OIXv0ixWOT//X//XzKZDDt37uTrX/86Hs/lH3+ru19x/G2aJkIIzIqKCcwJ6xhCZgWlOvEW/kATWa013BLLsjWpEbJM1Buj3dfOoTnL6rLD32Hb7vjnBXZdLBnSwsXhxqEEkODnI6eYm7GCv2aLs3aYmktyNYWoXQoaixEBV7CpODG/czjqiTKaG+FcWMg3t4aQO+QIUgu5wwgh6A52cyJ9vOnYJCHhU/wUtHyT8vpawHe+8x0effRRpqenWb9+PX/0R3+0qB/+Zz/7WV577bWm5XfccQdf+9rXLvehAqBPTlJ44gf1v8fHMVV1wXXnk9VaVeRpSjqiUt+m5DLpjitctzIKOJW1WTXLTLEaYOtNXJIX8XsJ84nbRsV5o69yqpyap6y+SLJ6nq3YcuRRzC+iCSHo9Hcylh+jy9+9qNXG/PuGW3KjSMqClh9e5dKeuwsFNF5JZfWymhldf/31/MZv/AZ/9md/xp/92Z/x1a9+dTl338JlxlzROVD72ZlnHEQ1wJbEDuZePkAbULu8xg4cx8j58JZC+DJRKnEJFx7iYjMhVjGdLTPUWZ+AypJM1BNltjhLMqfiE5biee+ZFLesbuO6tuscZLVbci9anZ6P45NZx99aKcr+kRSpfP1B0BZq3dxbaGE5oY+NcdZfIuPSkFavB2FdhzPZ+v1jZaKlMGqhhYvFN77xDT796U/z4IMPAvDwww/zwgsv8Pjjj/OlL32paf3HH3+cdDrNd7/7XVwuK6iwr6+vaT1Zlm1v2SuJim4R06auU5EMykiUZOv5bJHVrRDN5ULjZKbN98vhV321YFvHdgKuAAnvtRGA9dBDDy1q+/Htb3+7adng4CBHjhxZdH9CCH73d3+X3/3d3122Y7wQGOk0lQMHnAs1DVwuqGjkUKhUZy9xsz4vkIJBZotO3+6KhNXuYZp2FwiKgkf20hdaQVegm8n8JFvbt9nbzCdGL5YMaWFpSPjqJPF4fswOZY56YstqhdFIigXdwSaSrPE4rPePnnef5yIcJSERcUftTuNwtZg73/7BI3tQJIvSCbgCFlldKS6xf/7dwcUW5r/61a9SqdRVzKlUio997GNXrEvM1DTy//CPzmUVDVNtDuAEkOLOzBXda90bDMlANJxH2YXDWibiqZPVpzPDtrL1ag9Hv5Jo/Lxcksu+FsDZnZAqJ23Paq/svWi/aZ/is8WWcOnK6sVw76oPMpwZpj/cf85jaUStMLogWb1MyupGLGcR8HxYduf9U6dOAfDyyy8v965buIzQDI2M6gxxyFYf9rJQ+MCqD4Dh4anXMsyOSeyU2rjVsGxDxk9PYEhRAKLTK1CGNuAXcSRh/bxmsmXmI+6Nc3J2At0wcQtr21Re5exsgZVtcfqCKxjJnQUs1cKFDDYMw+T4ZJaA6KHAGIoZxEWQl49MO9TUHeGWsrqFFpYTyfFhnu2axQS8rgnAeohNpRrJ6takrYUWLgaqqnLgwAF+8zd/014mSRK7du1iz549C27z3HPPsW3bNv74j/+YZ599lng8zkc+8hG++MUvOtTTp0+f5rbbbsPj8bBt2zZ+//d//5Lt24rF4nnXyRVzaJqGUVYpoZPSBaooYZgGsgBFVygUCufdz+VC7Rwu5FyudkiGhKZZ9+CwFH5XP9flwLX23fT7BgAW/dxrit8Wlg/lV1/DNJy5SmalgnC5MDWNOVFvkW4kq0XAT7J8yrFdxaggvB7MYskOjhaKgkd2IwmJT6x+kIpRcWQpzCenfa5rOzzxWkGjveS+mb0NhN7yWpI2KuUDrkATCTTfrizmPb/Qyief+zcS9dbJ6pAnbL9PY4irU/EdYLoIJsY1dY+52MJ8NBp1/P3kk0/i9XqvnKXZm2+ij0/MW6hCZRGyel4wq+6rktVCR2rYpiRDSat3g4cblNWNAsKWBUgdcoP6uC/oFGc0Kasr1vP4XB0Ni0ESEgFXgFzFEmRdLnVx0B1cNOSxhiayWlmcrL5UGxD3tUhWf+5zn2taZhgG09PTnDljeR3XFD0tXBtIlpL2w30+1sbW0h8e5B93nyYznQTTYI8c5zojRRiNKV0Gw/JbMkNhvFKdqAaYypSa9tnh72A2Z022vdSrjXvPpljZFmBL+xabrL7QAIGRuQIlVaed7cQT/fhFF+OzgkyxQrZkPQhcikTY1/ptttDCcmJy7rR99zB8bgSg6yapnIEH6Ah78XtaqeQttHAxSCaT6LrepCpKJBKcPHlywW3Onj3LK6+8wkc/+lG+9rWvcebMGR5++GE0TePLX7aCxrZs2cIjjzzCwMAA09PT/K//9b/4tV/7NX74wx8SDC598D08PHzedc5mzpLUUsjpNK5KkfFsnryWoVxWKcsaoydHmZFmzrufy40LOZerHelSmmzBmlRVZiscSh96l49oefBe+G5qcLtbobHLCfWtt5qWmaUy+P1QqdgWIABx6kIa1eduCsLTTA3h9VbJ6pqyWrbJaSFEU+hvzTPYxMQr171HW7i8SHgT9udeCwADWBlauazv02hTFXFHkCXnuHa+DUhknrJaFgq6qTn+VqRzj40bybZwtfNIEhKd/k5GqhYjjcRbI6FuYCBdA/LqpRTm5+Pxxx/n/vvvX5aQzwspiJaPHEVr8JoGKGWzoKpNywHKPj9aQ+GyYAoMw0QXOma5hFm1eilQIVPM2PuQNAlDMzCqal4ACYmYFD9nAfpaK+6eD+c6n/XhjRyfO44sZHbEr3d8Lm7DbX+WY+kxyhWLk3J5XEsq4HvwkNIsT3xFl5e0j+X4bkzDdPzOFNM6H90wmn5/ZsW8JLGC0EXTPuWGc7/cRbElsQevvfbaogdlVg2Dr1Rlq4XlwVyp3v5We+DXcF3bFv71yBRnZ/MYaUttbQBvrb6eO46/wrSwKjYhr4K5yqr0KbLA51bIFivMZssYhmmnbwP0+dYhlQ8SFz46/T2omkGponN4LM09m7voDw9wc/ctpEopKK7k+YOT3LKmDa9r8YHf0QlrUiYLL7f3X49HkXh81iK8az7W7SHPNVNlbqGFawXJ9AT4QLgURLVQmStrCNMFAla2tSxAWmjhSsA0TRKJBH/yJ3+CLMts3ryZyclJHn30UZusvuOOO+z1169fz9atW7nrrrv48Y9/zKc+9aklv3d/f78dtr0YDp88iFHS0dMpTK8HojGUgMDjchOPBNm6ceu7+owuFosMDw9f0Llc7RjShwiNhsjOZtm+esc1fz7vpe8G4NixY+/2IVzzMFIptLNnca1bZ/09l2xeSbVIabNSYXYRZXXao8E83qCiVxBea35TI6uFvLAnaA2SkEj42pgpTtPub1nvXCm4ZBdhd5h0Q4ewLGS6l1lZ3RvsY318A8VKgQ2JjYxk637UbsnTpLQMu8O257Rb8hD2hG3PYbDCFc/3vOsO9LAHqwjT6e90LK+R1Y0qx0ZrAtNcWIR2tWEphflG7N27l6NHj/Knf/qny3I8F1IQDezdi5xy3m/UU6dA03Cnmu9D2alJzHw9WHN4OouqlqkYZbR8zraymCmmyY+fJqWlEcCpoyfJpXOUjfr9qsvdxaljp+a/xZLP5VrCYuez3diBLGRGT4wyyqjjtWK6RMkokSRlLwvkgxwqXHwBP5vLklSt/Ywb46TlzEXvo4ZL/W5yqTwV0xJjzhXnOJQ9hGmapJJpB483fOwUsli6YGyqOEWymHIsGzPGyMr13/PlLLwv+cgXuwFGo1F+9Vd/ld/+7d9e8kG1cOUwkZ9AkRRHsEh/uJ9TGesm2BXoxi/FePnnL2Ik56BQwIVJBYmjbf0MjB6hogmQZXpu3MJ1gQqzUoCdQx0cHElzpFhBN0ySBRXdMAl6FPwehSPjBdrFDgC29cfIlTTeOjWHppv8/PAU917XzUrfZvYfGWM8ZR1bRTf4wHXdlFSdsVQRwzRxKxK9MT+SgKPj1g1DCMHqjhBuRSLgUciX69WgVrhiCy0sL4xcjpRuPbBEg6IhW6oQwCKuV7XI6hZauGjEYjFkWWZ21umlOjs7a4efzUd7ezuKojgsPwYHB5menkZV1QUHlOFwmP7+frszbqnw+XznVTWZEiiKAiboQiLvcqHLqkXy+GMEAlfHveJCzuVqhx8/71t5B4fyh94T51PDe+VcWsKJS4NpGGT/6q8xkim8t9+G+4brF16vGnhWVjWOS5YyVsZ0kNVJpTkUTTM0hK9GVpsISYAkLdgS3YgP9n+IU+mTrImuWdJ5tbA0JHxtDrK6O9CDS1reTlpJSLx/5T3234EGFXObL9F0TUtCYiiymmOpo6yJrSGrOnOVvMr5i2794X7ev/IeZCE7fIq7g90waf27Mfit0RJksY7p9xq+973vsXbt2kXDGC8W5yuImqpKwTQhGkO4FMyKxTMo7e2gaWgTk471hUuhZ+dOx+8jpcxw9LUTSC4Jj+Ki1nwqhYO4wi5iZpSQK8TGNZvYf3yf47f9vr730R8eOOc5vNeKu5dyPieGjzNeGHMsu6n3ZoYiQxd9HIlighdHX6An0MPO7oWfOefDcn03+4/vJVUlzle3r2FD+wYA3jzyBiXdqr7KQmbT+s2XNN7QZivMTE47lm1Zu9X227/chfclkdXPPvts0zIhBKFQiFColeR+rWAke5YfnPg+AsnxoLuh6yYmC1MUtQI3dt3IqXeOoJ0+DcB2PYkHndfCqzAVF0+tvh1pehq5q4vO3jailSlu39CD3+9nKlPiyLi1z5/uHef0TJ6Qz8Wvv2+QvWdSgJVdcl1fFFUzeOd0Et0wefPUHAVV58h4BqPBe27/2RS3r2vnWz8/RbIhMHHrqhjre8JkilZ1qb89gNdtTdQ3r4jy6vF6S3ErXLGFFpYX+sQEGZc1UBMND91cSSOECyFgRcuvuoUWLhput5tNmzaxe/du7rnHmiAbhsHu3bsXDUPbsWMHP/rRjzAMA0my2n+Hh4dpb29fVPmQz+c5e/bsFQlcVI2qyrHaUjjrMjElA4FEzBc516YttNBCCzbMfB4jmQKg9POXUIYWJh5qZPXegkJt5rDByOBuaKvPK3rTdhVDdSqrZRnEwp6gjYh6omzv2HGRZ9PCpSLhTXAyfcL+e2V4eS1AFkLUE7OV04tZVt676gPc2H0TEXeE5878zPHahQSfCSFYH9/QtLwvuIL1sfUky0k2Jer+to3qbsM0mra7GrGUwnwNhUKBJ598kt/5nd9ZtuM5X0FUm55GlS0KzbVmDZWjFlnnBqs8oDjpNbmtrakQr7g9yD4fyAayBMK0xmuy2w0yKCh0hDrx+/24XC4Uw9qnR/awrmP9BYcDvleKuzUs5XzaQ+1Mq1P232F3mE1dm5DExVvk9Pv76U/8+kVvtxAu9bsJ+8LkDEssFgvG7H0FvQG0ssWJBVyBSxaBhIthS2RShSwUYqF6eO3lLrwviazu7W2Zur8XcDJttdaYGHaYokty0eZr47MbP4dmaHhkD3t//k17mz6zQJ/X4NCqFZQAKRJBilgTzI6wF7XhOdPeQAyfnrG84LLFCv/8+lmyVWJ5sCNIqOohfe913Tz9jlX5OjRaryAKITBNE1Uz+N5rZx1ENcDeM0mmG3yxt66M2v/estJJVre3whVbaGFZoY9PkK6R1X6LrFY1g7JqIkkyXRHfOe17WmihhcXx+c9/nv/8n/8zmzdvZsuWLXzzm9+kWCzyiU98AoCvfOUrdHZ28vu///sAfOYzn+Hv//7v+dM//VMeeughTp8+zd/8zd/w2c9+1t7nf/tv/4277rqLnp4epqam+OpXv4okSXzkIx+57Oej6tXnd5WsTrp1qE4Y4t7wZX//Flpo4b0Bc16Qmd5AdMntbejT1bF/WUXTDfaUPUAZAWzX692kQpbQlWbSQjM0hNea5KuyYRNQ832qW7g6kPA5LSRWLLNf9ULwu/zcN3A/M8UZrmtbWNUrhLB9p30uJzE1PyTtYiCE4P2r7m1a3mgJcq3YgCylMF/D008/jaqqPPDAA1fiUAHQR+sqXWVgwCarTVVtui8BSPF407KKbiJ8PgxJp5HqE3L9XhT3WNulyil7WX944IKJ6hYsRD3OoNPtHTuWRFRfbfA5glXr/27s/rnUcEVrH07uLODyX9HOsCWR1a+88gpvvPEGfr+f3/iN33C89uijj1IsFrn++uu5+eabl+UgW7g8qPkjNSLmjSOEQKmGPqj79jE6VwDhRfj9rP2//m8Cfg8fmcrxvVedLcOdYQ9nHWT1wsTw6Fzd5H3LyvoNZOvKKCNzBfafTQHWg/jm1QlWtQX47u7Tjm2FgKHOEMcnspgmjCWtdgevW2Z1Z13dnwh66Iv7GZkrIAR0tJTVLSwjvvOd7/Doo48yPT3N+vXr+aM/+qNztqFlMhn+/M//nGeeeYZUKkVvby9/+Id/6PCQvdh9vtvITZ6lIlkDYlFNt07mVKSqBchQ5+VJS26hhV8G3HfffczNzfGXf/mXTE9Ps2HDBr7+9a/baqPx8XFbQQ3Q3d3No48+yiOPPMIDDzxAZ2cnn/vc5/jiF79orzMxMcHv/d7vkUqliMfj7Ny5k8cee4z4AhOq5YRu6HaafU1ZnfFiTdQERLxXhwVICy20cA1AVTGrRgcSAu1EXVUrd3XZZLWpljk0mianW5PrQfLEqBNKIhCw70uNqBgV8FrzGFUyEYqCJCSUS/D+bOHyId4QbuhX/E1hh5cLq8L9rAr3X9C6jRYdcGlk9WJwkNVcG8pquPjCfA3f+973uOeee4jFYgvt9rJAG6l7lSsDdTsOs6JCpTlcUYo3H1tFNxA+HyYGUmNRoYGIjnqt7dbF1nMkeRiAjYmNl3z8v2yIeupdez7Ft2CnwrWIxsDXkLsu9mjs2LiQ7o3zwaM49zHfm/9yY0lP3L/6q7/itdde49d//debXkulUnz961/npptuapHVVzly87yzAOLe+mTV1HXyTz3NlLCWta1ZRTBg/WBXd4a4ZU0bu49Zg0GvWybgcVb6YgE3siTQjYUru36PwlBH/QcvhOCD13WjyIKSqnPLmjY6Iz5M0yQedDOXqyuq1/dEuG9rD3/97DGHJ/XmviiK7KyWfWBLN88dmGCwI0TA2xpktrA8eOqpp3jkkUd4+OGH2bp1K9/85jf5whe+wNNPP90UEgJW2vXnP/95EokEf/EXf0FnZydjY2OEw+El7/NqQHKmPmiTfD4wYTZXRsJv2fysiL57B9dCC+8BPPTQQ4uqi7797W83Ldu+fTuPPfbYovv78z//82U7touBo0CuW+RQ1q0DMi5Z4He/d1pVW2ihhcsLU1V5oTPJ6UCRXdNR1jWQ1VJXF+zbb693eCwDhkXc7fSUaOCqLbLaqJPVXtlLSS9hYmJ4LBV1zQbEI7dC2q9WRDwRYp44yfIc6+Lrr8rvaT457VWWX0DlU3y0+dqZKU4jiWtHgXuxhXmAkydP8uabb/J3f/d3V/RY9VErwE9IAnlFH0KWMHUDs1S27zPCpaAMDKBPTuK+8aamfWi6gfD7MEo6jrNqVFZXyertHTvIV/L0BnsdvuUtXBg6/V3IQkE3NXZ07ESR3htc0HXtW0iW5mjztTv4u0Yl9HLcY5qV1VdWWLKkb+vo0aMA3HRT88W3c+dO/vZv/5YjR45c2pG1cNlgViqUnn2WlDgMnc6228bKtPr660zO5dGVBFI4TN/QCse6t6/rYC6ncmQ8w86BeHOwhCRIBD1MVS061veEOT6ZRdMt8npzX6SJWHYpEh/a4vT9EkKwZWWMFw5OVv+G29a141IkblnTxs/2T9jrNlqA1NAR9vJvbum/gE+mhRYuHN/4xjf49Kc/zYMPPgjAww8/zAsvvMDjjz/Ol770pab1H3/8cdLpNN/97ndxuSzVcV9f3yXt892GaZokU+MQBeFxgyKTK2momoELK1gx4m+1zLbQQgtVpSKAaRXDTaDgsshqRZYvi8qshRZaeG+iUMwwHLC6Kl9uT9FzxkMQBaHIyO11n1uzrFJExzQMBNDtMsDjxixbAhgpEEAz66IXT5WsBtC91lhNlQyEouCWWlaCVyskIfHg2k8yW5yhM9D1bh/OgvA32YAsf4FWCMHHV3+CudIsUyemz7/BVYSLLcwPDg5ecb7JrFQwJi0+QursRLhc4HZDsQSVit01Jjwegv/+C5imuWDhpKKbSD4/pqojFlFWx6oEZMKX4GOrf+XyndR7HH6Xn19d96tk1ewVsQe6Ugi7w3xkqNn+ptGqajmU1d53maxekmFLLmeZeZdKpabXyuWyY50Wrj4Un3qKwnPPkzp1GCOXxy158BdNfEWDNdHVAJjlMqVnfsaEsH7k8ooV9MadD1VJEvzK9X38Xx9az+3rOhZ8r1qwmkuRuGdzFzcMWmS4LAm2rrzwlp3r+qK4q55yW1bGSAStC2fbqphNhq1IBGgPt2w+Wrj8UFWVAwcOsGvXLnuZJEns2rWLPXv2LLjNc889x7Zt2/jjP/5jdu3axUc+8hH++q//Gr2qMFzKPt9tGMkUaazJovD78St+ZnPWM6BCzmHz00ILLfxyw/ar1nUwQUdQcVnLXLLAdxlUZi200MJ7E9lS2vH3awnrbykWs4MRAVBVVN0Aw8CFgeRxIxrCZkUwiGbUyerG+5DmUTAxLaszRW75VV/l8MgeeoK9yFepong+OX25nnlu2U1XoPuy7PuXHfrEBGa1Y1zuscR1wmNxEqaqQs2zunqPKWpFjiWPcnD2oKODo6IbmF4PhjCRqJPVQrZ+u34lcN4w1xYuHDFvnJXhVVdlx8Vyo5Gg9iiX/hua73t9TSir29vbGR8f5zvf+Q7vf//7bZWgpmn8/d//PcB501tbuLwwKxVQlKaLUp+dpfTKq7zqCpESLhK5HF2+Xm594gQm4OmYhqEQe576OdN5DxPCixSPIwWD9MSaVU9CCLzuxQcF71vfQVvIQ0/MR9Dr4n3rO0iEPMT8bhKLeFovhIBX4ddu7WcyXWJTX9RersgSD93az4mpHGu6QovvoIUWlhHJZBJd15usORKJBCdPnlxwm7Nnz/LKK6/w0Y9+lK997WucOXOGhx9+GE3T+PKXv7ykfV4oisXiJW2/GLThUyRlFdM0MD1uolIHc7kRTNNElgR9YZlCoXD+HV0gaudxuc7nSuK9dC7w3jufxdQwLSwdqmER0zXlUUUIDNlqgXXJEl65paxuoYUWLgy5eWT16UCJEV+JgXgcXHVS2VRVVJcBholiWt7TeDyQtURVlg1Inaz2NnR46G4FXVi+2MhKizxq4ZIw37Pa2+omuuZQswABUKrdsaLKg5llFWqEtNvF06d+zIn0cXv9nJrlxm7LlUDTDRAGyBKSAYop0IQJUi1wuiX2aWFpaCSol0NZrUgKAsn2wA9eC57VN954I9///vd54403uO+++7jlllsA2L17NyMjIwghFrQIaeHKoPzqqxSf+D7K+vUEHvo1a2BWReknP+UXZpyXPW4mhR93voTfzCAQCEB943XGvRF+uGcU5AQIgXvFChRZ0LEE1bLHJbO9v+6jI4RgcwPZfDHojPjojDQ/2EM+F9tWtW7qLVzdME2TRCLBn/zJnyDLMps3b2ZycpJHH32UL3/5y5f1vYeHhy/Lft1vvsWUkaVcNtArBm/vMymZlrJ6pa+bY0cvT3ve5TqfdwPvpXOB99b5uN0tFd1yQq16VpvVbhINyZ6YuWQJn6s1cW+hhRYuDLlKcwfv/miWoXjMsiWrwlTLVNAAEzcGuF22ryyAFAyimXXiu9Hj0+hsQ1Ms1aMUaCkdW7g0eBUvAlGNBV0eIqmFKwutYYwr9zqV1ahlW3U959UdRDXAVGGGsWSR7qgXTTcx0BCKgqhAsCKTcmtQVVbHvJc38LqF9y4alc+NIYxLhRACj+yhpFtiJP+1oKz+4he/yNNPP025XGZkZIR/+qd/sl8zTROPx+NInm/hyqL0/AuYhknl4CGKP/gXfJ/4OEIIKgcPkXx7P++4BtGVJABz+QqBcl0JVzl4iDf1hB1+JLe3I7xeuqM+ZKmlMmuhBYBYLIYsy8zOzjqWz87OLtpV0t7ejqIoyHK9E2FwcJDp6WlUVV3SPi8U/f39+HzLTwQV9++nEnLjESbZwApcpVV0UkS403zppvvoCCzvYKtYLDI8PHzZzudK4r10LvDeO59jx46924fwnoNtA1JTViNBdVzhUgS+lrK6hRZauEDky80h8TOeCiIWq5NHWLaGqrDuOS4MhOKGBs5ZBPzoRn3c1XgfMmIRXJ/7DK7RHyHFYi2yuoVLgiQkvIqXombNu1s5DVc3ynoZt+S2u+xM00Q7YXW6CrcLuZY75K4qq426nYfqdjrtmia8dHSM/ZWT3LWxk4puYKAhuRQoQkhTSLk1RDXLK+ZpifBaWBoGI0Osia4FYCAyuCz7bCSrrwkbkKGhIb761a/yB3/wB03ESiKR4JFHHmFoaGhZDrCFi4M+O0s+PcPRaJ6+gpfEq69hqipmuWwR0XI7GgJNsSaNadVAnqsP+EpFlYOHzgIgALnb8rwa6Liykv8WWria4Xa72bRpE7t37+aee+4BwDAMdu/evWg4yI4dO/jRj36EYRh2ovXw8DDt7e22gvNi93mh8Pl8+P3LH+SSTE1iegRloZBUQ3QrCl3SdTx02wDd0cs3CL9c5/Nu4L10LvDeOZ+WBcjyo+5ZbRFHGsL+nL2yC5fsercOrYUWWrjGkG1QVkcqCv//9u48Tor6Tvz/61NVXd099z0cw6XAzHCjSYyIIorBBWMiRGNWNPLla46N2TUxq4ZdTUYT0WSNkZDN1wgxBN0l/KLmEkkkxlxiyGE8EAVB7sO5z+7p7qrP74/q6ZlmBhjmnub9zINHuquri08x8qbqXe/P+1PvixExNH92TA6+WsV+3yTe79RwYWsUx/IqqX24XotEoz2RpDIyiOl4gY4yk+JQ1ImiRhdjhLzEkfSsFr2VZqURioVQqKQqfjG0vFn9Ji8efIFxWeNZfM5VALjV1bj1DQBY48YlZq4ru/NDLOeEFqlRx6UpEiZHwb6qZqKOxiWK6fOOkR4zUQAq3gYkmI8QPWEZFh8av7BPjxm0AtTHL+HTrWGQrAa4+OKL+c1vfsMf//jHxLTf8ePHM3fuXAIBCb4DScdiuO9VYowoJrZ7Ny8V1HEgPczruU1cc6AYXvkHAI1YvG7kYOTk4KR5K9m6ruZYjWJi/Fi7jExi8SeDswr9TJ9fSn1LlGkl2YNwZkIMXcuXL+fOO+9k2rRpzJgxg/Xr1xMKhViyZAkAd9xxB8XFxdx+++0AfOITn+CJJ57g61//OsuWLWP//v08+uij3Hjjjd0+5lCiXZfqhmNQCA12OrbyphpdUlbUr4lqIcTw1KlnNUbixizDP/wfcAghBk5TrDnxenSLn/rsGPtVOjWVdWT4s3BQvGbkcH5rFILxZLV2vf6yur0C0khLx2n1YpKpTCyjQ7LajSZaNgBSWS16rTSvjJeO/IlJuZMxlHH6L4hB8duDvwFgX8O7tMbC+K0AsT17Ep9bHYoyVRct42K+5GS142pcHQUF4YhDrGNlNWC7Cr9joON1ElJZLYaSqQXTqT5UTWle2YAXlvQ4WQ0QCAQSFYBi8LQ89RSRv72Cb0o5MUNzOC0MgJOXzStNDcyt9ALea8Ei1NhzMQsLya1/i8Z494933Xzm4i0Y8KbRnpSefeFUxhRKRbUQXVm0aBE1NTWsXr2ayspKysvLWbt2baJlx9GjRxMV1AAjR45k3bp1rFq1iquvvpri4mJuuummpJZJpzvmUOJWVrI/4N0sNlgB8slHKZg2JmdwByaEGJLa24B4VYxRVKJndZZ/YCs1hBDDW1PMW7zZ7yoKW200zTQpi4A/BIaXKGpVBpHWSKJHtQ8NPh9GW6sqpTDycokd8WKSZVj4TkhWO/Gqa5DKatF7s4vOY0reFGx58DFk6Q4PswAc7cWPthYgANa5HdordJWsthR0eNDluF4lNUA46hB1XDQxjPjijJZrkBWzqMdrsyAtYsRQUpZXxuRBesDWo2T1c889x+9//3tycnK48847kz578MEHqaur45JLLuGf/umf+mSQ4uR0KEQ0XjkdfXMnh9NbcYpBWSa+yZPYP7aV9xUsoDBQwOG3mjFDDkrBmAKoPOgQ1hY1Oo1tRgGGAceVVxVfZGtK3jd9EM9MiKFv2bJlJ23RsWHDhk7bZs+ezaZNm3p8zKEkeuwoB9PChDGIGn6CFDMmP510f6+egQohUlSisrqtDYgyQCmUkmS1EKL7tNa0uPH+mTGT3FYfkXgP/KjR5LUXUgaOdgm1RtFuexsQ5bPwXzwXNxTCGjsGIyeH2CEviWQaFj6j/Rom5kaTfl+prBZ9wS/tP4a0lviDsDYxHYv3q/Yqq1XAjzlmTOLzjgu6tnF8JhBrP4arcYiitY4nq73ktWEYmHm52FUuc0fMYXfuGMryyqQVnRhyBmsmSI+yCuvXr+fVV1/lc5/7XKfPsrKyePzxx9m3b58kqwdAbO+7SQ39Dwa8izcjO9u7CQwGeJl3uSRnCrUhb1Xa0blpNLiKPN3Ke7F0FIq/mHmYRUXw3nsAnFc+GmWanX9DIYQAjhzdRdh0qVcBgsYIDGVSOjJrsIclhBiiTqysjsWTS5ZpEPRJFZEQontaYi24rhdH0mMW2VGLCCbKtGjV9fFFdwyIuTRH3Q6V1S7K8mHk5JB+3bWJ4znxY1ldtQHpUGUp1bBCpL661tr2Nxpqm8L4wy24jV6ffGv8+KS+947PxEET7zoNtFVWt3NcF3DROISjCq3x2oAosCZOJHv6TMaVXsx4Q1rDCNFRj/5G7N3rTYOYMWNGp8+mTp2atI/oO05lJa1//RtuKJTYFt29K2mfthYgRnY2WbaXODrSfJhXDx9J7DOuyIcbsMnVUc6JRhOh1RwzBl/JaOZMKuD9H72sf09GCDGs7a3ZDUC98pFhjUUpKJNktRDiJNqT1TEM7S2wiDLwmYZMeRVCdFtTpAnteAnmtJhB2oIF+Ox8VHo6UZoAJ1Fw0xTpkKzWLvg612nFdLxndRdtQFqd1sR7v7QBESLl1XZIVlc3tfLDP+zmsed30hiv8ezYAqQh0sD/6O38ePxRms32lkGO2Z6sNpWF44UgXKKJlvleslqBoQiMLElKgAshPD2qrA6HvYRofX19p8/atoU6JFRF7+lYjKb/9yhuYxNGRjrBq67CN3sWsV1ewgilaDCjNPi8QDmqeDLj8kr5/cGX8JmKfxzZA4wEYEQevNZso0yDqZEwk6P7eTmjBP+oHC69fDLF2XLTKIQ4Oa0174YO0YpBRJmk+cZSkpdGekBagAghutaWrNaOgx3zgQkYSpLVQogz0hRtSiSg02MWgUsuxv5LDar6bUCTkxXlvXjipymqIT4D1YdG+ZITzq52ceM9aS1lJi0eFXNj7Q/ZkDYgQpwN6iJ1iddVTRHycKmra+aX1miWxg6QOWFC4vO/HNtOq+EQMzTbC+qYfzwfgJivPfGc4cvAcRsB4n2rg4nXRjynLQ/ChOhajx7hjBgxAoDHHnuMurq6xPa6ujrWrl2btI/oG25VVWL6idvUTPPGH9PyxJM4VdUAWOPH8d6sEgCM7CzGjyijqjbIzsP1vHm4nsONXmV1QaYfwwqDAhUMkhEzKaSVJSUWH//gOElUCyFOq7LxKI2xJkLKJOjkYRl+zimSxViFECfX1rNaxWIYbjwhpBQ+SxEwpYenEKJ7mqKNHZLVJtg2bqT9GiQtPZSorG6OgY63+fDRubK6rQUIdL3AoiSrhTi7tFVWxxxNKBJD46BjMSqVn+fNkRhZ7bNIQ9EWr+UQUOVv73Ef65BhS/el48QfmLUtsgh4CyzGe1P7DElWC9GVHpXBzZ07l//5n/9h9+7dXHHFFYl2IK+//joNDQ0opZg7d26fDvRs51RVddoWef2NxGvj3HM5MK4OX2UYIxhgbOY4XtlZi8Ig5riEqAIFJYWKN6peB9qS1d5FmikPF4QQ3bRj7zbQEFOKNO3N2MhJkwstIcTJReNJH19Ug2t662qgMA1FQCqrhRDd1BxpTrQByVA2KEUk7C3S6rMMYqoB4pXVzZgQ89p8tPWs7sjR7clqU5lYHRZYjDrJbUCkZ7UQqa+utQ4UNLXGQINWLsTjzR4jg1rHID++b9CXhjK8B2Ohjm1AOvSs7pisdjokq11itHUL6TijQwjRrkeV1Z/61KfIzs4GoLGxkZdeeomXXnqJxkZvikNWVhaf+tSn+m6UArdDsto3aWKnz/9a1Mix0DGMjHQyAjlk+fKobozhV7kARGmiSR/kzZbnONR0EACVlkZuxAuO5uhRA3AWQojhruXAu7zxt+cAcLVFpjEegMygXGgJIU4uVFuJW1+PHXHRrpVIJpmGtAERYjA9+eSTXHbZZUyfPp1rr72W11577ZT7NzQ0UFFRwdy5c5k2bRoLFy7kd7/7XeLz73znO5SWlib9uvLKK/tsvI3RxkTyKF0FaIk4EPMqqwM+g+Ot+6jJOsCxEW/z8vidVFlvAm09q5OvVWJue/LIMnxJldWxDj2rFSrpMyFE6tFaE3a8VrZNYS82aFzy3XB8D0WD054+85t+iM/icDqsqRgz218nV1a3z9RwiWLE+4DYUlktRJd6VFk9YsQIfvjDH3LHHXewe/fupJWSJ02axIMPPihtQPqYW9merA7805WYI/5B+A9/BGB3fpQ39KF4lZLB5WMXcLw+jNaaAAUYfq+PuA68jt/nTbUNWkEumvVxio/9HRUI4Js2beBPSggxrERefZV/PPcDojnezVtmtBhjtFdZnSn9qoUQJxHbt4+W11/FQZMZsYhqC5Q3jd80kGS1EINk8+bNrFq1ioqKCmbOnMn69etZsWIFW7ZsIT8/v9P+kUiE5cuXk5+fzyOPPEJxcTFHjhwhKyt5geVJkybx+OOPJ96bpnnioXosqWe1mUZ1UysmAUwC+H2aqG6hIf0oOtyKD0XYOkg2k73K6hPagMQ6VlYb5gltQNp7VtumjVIKIUTqcnETrxtD3owMlMu5biOV2GCZhKLtMSPmxhIP3gE0GoXqVhsQt0MbEFt6VgvRpR5nF8rLy/nFL37BW2+9xbvvvgvAhAkTKCsr67PBiXZOdXuy2iwowFy8CLe+nshrr/PmtGyIB7tLx1xKSWYJLx/39g9SQGbmQfIz2qeuFaUVc/U5V+O3ArB8xsCeiBBi2NFaE35+K6GtW9k5pgEAIzODvMJF1IctlIKMgFQcCSG61vKnP+IQX+TMNWhxTZThvbekslqIQfP4449z3XXXsXTpUgAqKip48cUXeeqpp7qcJfvUU09RX1/Pxo0b8cWrlEtKSjrtZ5omhYWF/TLmpoiXrA64Bj47QE1TBKUURZxPTto+Qk49KC9bFMMAHQOl8aHhxDYgbizx2lJWUhuQjpXV0q9aiNTXlqyOxlxa40npvAyL7EgLYKNMk1CkPWZE3WiishqgxXRJd8wTktUZJ6msjiUWWJRZG0J0rdelcGVlZZ0S1C+//DKbN2/m3nvv7e3hRVxbZbWRmYEKeNXR6ctuIBBqoeXtxwGXgmAhU/KnAnC4pgWAAPkE/MkB8OLRl3iJaiGE6IbYzrcIb/0NxwIR6n0xzMICxk67iEP7c4EYaX4L05CKIyFEZ25LC80734B4Pst2DVy3vbLaMgxJBAkxCCKRCDt27ODTn/50YpthGMyZM4dXXnmly++88MILzJo1i3vvvZff/OY35OXlcdVVV3HLLbckVU/v37+fuXPn4vf7mTVrFrfffjujRvW+5aCrXZqjTWjXJS3mQ9k2Nc1eQjlNjeCacy+gIVLH/76+lRr3dWJWK8rVuMrB7qqy2k2urDaUgaksHB0j2iFZLf2qhUh9WmtQ0BhuT0gXZ9sEWlvAyMHxx/jtkZ9TY4xmwdgriLkxVIfK6kZfLJ6s9pLTCkWaLw0nPhPEpf24ro5iKK+9kMzaEKJrfTZv+x//+AfPPvssW7ZsoSreX1mS1X1Dh8O4jU0AGIUFSZ+FTAcdfwqY6fP6tWmtOVLr9VtKswOMyhpBZeg9ACblTGZEurRoEUJ0Xyw+e+ZgehizZBTW6BLKC6aza5d30ZUlVdVCiJOI/v0VIrr9Bs3nKrS2QHkVRmm+oNyoCTEIamtrcRynU7uP/Px89u7d2+V3Dh48yMsvv8yHP/xhvv/973PgwAEqKiqIxWLceuutAMyYMYNVq1YxYcIEKisr+e53v8sNN9zAL37xCzIyMno83lAoRHO0mWikFe26BFshGoBjNU3E4osoBg0HV6URjBZhR9OIpofBcYgRQ8UihB2HaEtL4phNLe3fdaIOLS0t4GpiToyGUENiYVjlKO+zPhAKhZL+fzhLpXOB1DofrbX823qG2iqr2/pVAxSlKwJuDAxoTK8m0hplV20T0wume5XVHZLVDb4YI8J+nMTMMQu/6ScW7y7idKis1sRQSuGTftVCnFSvktVvvfUWzz77LJs3b+bIkSOJ7RIc+5bTYXFFMz85Wd0UbUq8zrAzAWgIRWlu9S68RuYGmZQ7mcrQe/hNPxeOmjMAIxZCpBK3wWv9cTTYiplfgFKKXN9ItPYWa5XFFYUQXdFa0/qXvxCNV1Er5SWrHdcCvOvEDDttEEcohDgTWmvy8/O57777ME2TadOmcfz4cdatW5dIVs+bNy+xf1lZGTNnzmT+/Pk899xzXHvttT3+vfft20d1tJq6uhp8ra2oes3xlhp27T9CY6vGVHDo3d00tGqaQyEc18UNuuhYlEgsTHN9LXv27cPpkIh8L/oetY11ABwNH2VnzU7q6xoIuSFqqUvs528OsDO0s8djP9n5pIpUOhdInfOxbUmEnglXu6CgNdbeuzrb5xKMP3B3fA4xx0tEh2LhTm1AGn3efjHVnqw28aFP6Fnt6AgOEQzDj23KPZQQJ3PGyep33303kaBu61UNJC2yWF5ezvz58/tmhAK3Q7L6xMrqpGR1vLL6cG37Rdio3CAzC2eSH8gjx59DZjyhLYQQ3eXW19NquNTaUWyfj7xAPtFY+z8fsriiEP3nySefZN26dVRWVlJWVsbdd9/NjBknX2+ioaGBhx9+mOeff566ujpGjx7NypUrkxJIZ3rMnnIOH8Y5eoxoQGNkZmCdcw72toO4rRbK702rl2S1EIMjNzcX0zSprq5O2l5dXU1BQUGX3yksLMSyrKSWH+eccw6VlZVEIpEuk2NZWVmMHz+eAwcO9Gq848ePx2g1yHYycfx+RthZFJeMxZeWTW4QCjP9TJkylsZwlD++Xkdrg5+wYaCUwgyYFGZlkltejlFcnDhmWmOQXQff8o5fNJ7ygnLeeOd16iK1Sb/3uOxxlI8u79X424RCIfbt28f48eMJBod3v/5UOhdIrfPZvXv3YA9h2NHxtTVijpesNgyFjoYJ4LUL0qZLNP5Z1I14bUDMDm1ALG+/9mS1D3R7MtoliqtjHOMlNA6GUuQFOi9kK4TwdDvD8Nhjj7F582beeuutxLa2BLVpmjiOg1KKO++8k5tvvrnPB3o2cyo7JKsLkhcraYp0rKxuS1a3T1MbnZuGoQzGZo3r51EKIVKVbmzkeKAVTAMsk5LMEhpD7VPkpLJaiP6xefNmVq1aRUVFBTNnzmT9+vWsWLGCLVu2dJq6D14P2uXLl5Ofn88jjzxCcXExR44cISsrq8fH7A3ngDf7ImK4GPn5qGCAnKuXoHZGUM7LoCDdHt4JASGGK9u2mTp1Ktu2bWPBggUAuK7Ltm3bWLZsWZffOe+88/jlL3+J67oY8env+/bto7Cw8KRVnM3NzRw8eLDXCy4Gg0FaI2EsZeAqgxzXj05LxzS929mczCBpaWmYPgfTZ2Nits/0NTVByySYlYWZ1v6AzGq1sCzv++nBdNLS0gj6gzS5jUm/d2ZaJmlpfftgLRgM9vkxB0sqnQukxvnILPdecANAC5ahcFrD+NBYaFzTTVRJR5woMTfqLeaqAN1eWd02m8xSFo7Tnsx2ifIefyWsvQeEQSsos96FOAXj9Lt4HnroId566y201mitMU2TOXPmUFFRwR/+8IfEfm0rQ4u+41Z3aANSkHwj2WVldU2HyuocuQkUQvSO29jI0WArxG9ER2eMTlp8JEuS1UL0i8cff5zrrruOpUuXMnHiRCoqKggEAjz11FNd7v/UU09RX1/Pd7/7Xc4//3xKSkr4wAc+kLQQ9pkeszfc5mYAWk03UUkdyM5D+73kuWUo0n3pff77CiG6Z/ny5WzatIlnnnmGPXv28NWvfpVQKMSSJUsAuOOOO3jooYcS+3/iE5+grq6Or3/967z77ru8+OKLPProo9xwww2JfR588EG2b9/OoUOH+Pvf/86tt96KYRhcddVVvR5vQ2sDOr5YWWbUJGy1J8gDPq/a27YMMA2U2179rQ0HA42KJ6bDsTCO6xBz269lTOV95jM6X9PY0ldWiLOC1mC58WsU0yAWCaGAgHZwTZ2ouo66Ua8NiCKxyGKDL4ZWEItXYluGRSSmMfBiSlQ306wPA2BgMX/0InL8OQN7gkIMI2c8d1spxaJFi/iP//gP8vLy+mNM4gRuW2W1UhgnVD0lV1ZnEo44HK/3ktVFWQECtokQQvSUDofR4VaOFbSifEEUilHpo9h7qC6xT4a0ARGiz0UiEXbs2MGnP/3pxDbDMJgzZw6vvPJKl9954YUXmDVrFvfeey+/+c1vyMvL46qrruKWW27BNM0eHbO7ulqQKlJXRywWo5kojgI3FsNwDKKhNPxuIYbZxPjg+D5buKy3UmlxLUit80mlc4Ghs77PokWLqKmpYfXq1VRWVlJeXs7atWsTbUCOHj2aqKAGGDlyJOvWrWPVqlVcffXVFBcXc9NNN3HLLbck9jl27Bhf/OIXqaurIy8vj/PPP59Nmzb1yX1jfaQeXBcFZEYtGs32JHJa/J5HKYXfZ2Lo9nsgU8W8Lvk+H7trd/Hr/b8iL5DP1PypiX0sw9vf10UP2ZxATq/HLoQY+hxXY5NDM8ewTK+yGiCIgzYdYq4GDVEn0v6wyzTBcYkYmnCgPe74DIvWqIOB7bUA6bDAYoYaQ1Fa0YCemxDDTY8yDJs3b+bll19mwYIFXHnllVxwwQV9PS4Rp7VOLLBo5GSjTqhcb4x609QUXnXSnmPNtLUPH1sg1UpCiN5xGxtpNVxq7BimbVMQLMBvBZLagGQFpLJaiL5WW1uL4zidWnPk5+ezd+/eLr9z8OBBXn75ZT784Q/z/e9/nwMHDlBRUUEsFuPWW2/t0TG7q6sFqYJ79uCrq6U6GKa+qRkdjXEoeojK6iB+ppCXpqjcV0UlVZ0POIhSZXGtNql0Pql0LkNl8bNly5adtO3Hhg0bOm2bPXs2mzZtOunxHn744T4b24kaWuvBcUiLmZgoQh2qoDsW6Ni2heG2J9mVii+QZhn8etevAKgJV1MZqkzsc6rK6lHpo/v2RIQQQ1LM1dhuFro1hGlDLBJPVmsH13BBKxxXE3EjXmU1QIcHenXp7eu4+Qwf4aiDqXzEdNJvg49MfObgP7AUYijrdrL6uuuu49e//jV1dXWAt/jGpk2b2LRpE9nZ2f01vrOebm5Gh7wgaXax2ElzvA1I0ErDVCb7q5sTn42TZLUQopfchkaOBVu9N7aP0RklADR0SFZLZbUQQ4PWmvz8fO677z5M02TatGkcP36cdevWceutt/br793VglTh7X/BycnFzKojpyAfLItJY6fwl6Pe4mXjCtIoLx86SaBUWlwLUut8UulcQBY/64lWp5WwEwbXITPmJabDhkV8TTSCvvZktd/2JbUBMYwYZnERb9a/lXTMlmj7rI62ymrLSL6myfHnJNYFEkKkNu0qjCMNuL5GaK4jNtLLcwWJoQ0HsIi6Lq1OK672WoJgmoSUiQvUBJzEsax4srqtDUhHNplYZrc78gpxVup2huHee+/lnnvu4U9/+hObN29m69atNMd7EdbV1SWmsj388MNs376dyy+/nKuvvrp/Rn0WcY4eTbzuuHo1gKOdxEVW20XU/krvZ6IUjMkf3gtDCCEGn26op9r2EtPKZzMqYxRAomd1mt+Siy0h+kFubi6maVJdXZ20vbq6OjFF/0SFhYVYloVptidpzjnnHCorK4lEIj06Znd1tSCVE4uhLIuorbD8flCKNH82luXNCstMH5qLWKXC4lodpdL5pMq5DIUWIMNNQ6QBAO24ZEW9W9hWwyLeHja5stpvYej2axPDcGBsCX8//rekYzZH24t82pLUJ1ZWtz2kF0KkvoCRRUtLK2SDFYsSa6jzthPDNTQKcBxNqMODrlZlsUd5cWNshzhkGRbhSIdkdXwhRmirrJb7JyFO5Yz+hliWxbx583jwwQfZtm0bjzzyCB/60Ifw+/2JhRebm5v51a9+xV133dVfYz6rOAcPJV5bJckXS83RZnQ84mX4MmhujVHV6FVAjsgOJhYaEUKInnIbGmiKr26tbB9Zdjauq2mKJ6szpapaiH5h2zZTp05l27ZtiW2u67Jt2zZmz57d5XfOO+88Dhw4gBtfgAy8tgmFhYXYtt2jY/ZG2wKLYb8BSqFQuG6Hafs+uVETQnRPW7Ia1yUznqwOq/ZrkI6V1QG/nVRZjRFj9whNSyy5P35LrD1ZfbI2IKMzhs7sDyFE/woYWRD1rqFMNNF4stpSUa8aEK9VSHOHWNKi/YnXf6H9tWVYhKMuBl7LJzuenFaYWKRJGxAhTqPHdwm2bbNw4UJWr17NSy+9xIMPPsgll1ySqObRWp/mCKI7nEPtyWqzJPliqePiipl2Jgeq2i+4pF+1EKIv6IZGWsx42ZLPJtPOpLk1lojxmUHpVy1Ef1m+fDmbNm3imWeeYc+ePXz1q18lFAqxZMkSAO644w4eeuihxP6f+MQnqKur4+tf/zrvvvsuL774Io8++ig33HBDt4/Zl3SLtxhea8C73AxYAVpj7Yl0eaguhOiu9mS1056s7nArG7TbE9e234fRMVmtYhzJbJ+e3yYcCyden6yyepQkq4U4a/h0JirmxQoLl2izl2+xjQ7Jascl1CFZHSSQeB2zIjiud49kGRatsfbKan/8Ab1PZaCUkspqIU6jT0ri0tPT+chHPsJHPvIR6urq2LJlC88++2xfHPqsFzt8GADltzEKC5M+a+tXDZDuy2D/MelXLYToW25jI02Wd9Fm+9OwTZuqcPsFWpYkq4XoN4sWLaKmpobVq1dTWVlJeXk5a9euTbTsOHr0KEaHhX1GjhzJunXrWLVqFVdffTXFxcXcdNNN3HLLLd0+Zl/RrosOe4mgsK0wgIAZpDUqyWohxJlrjHZsA+LFjhAdqqk7zNTwB+zkNiAWhIMWhJKP2TZDFcBUXcejdJ/cUwlxtjDc9KTKaiceIwwV9QIJXmV1S7Q9mFikAV58ilkR6lui5GXYndqA2JYJxLDJ9I5vSGW1EKfS5/O3c3JyuP7667n++uv7+tBnHbepCbe2DgBz9KhO/e2aOiSro60+3jjo7WsYipK84d/PTwgx+JyGOlriyeqs9DwA6lpkcUUhBsqyZctYtmxZl59t2LCh07bZs2ezadOmHh+zr+gW76FWVLk4PhMDCFpBwtH26ka/JKuFEN2U1AYkFq+s7pCQTutQWe23zaQ2ICrDT9g5IVN9grbK6o6tQkwl1zhCnE1UNIhyvZyLpTWuildJmzGI96WOORpN+4N3U7Uv+qsNl7qWCHkZNj7DR2vUxUwkq+OV1WRimUrWLhDiNFJ67sGTTz7JZZddxvTp07n22mt57bXXTrrv008/TWlpadKv6dOnJ+1z1113ddpnxYoV/Tb+ji1ArNGdF/doaG0gEnUJRRz++FYjMccLprPG5SaCoRBC9EZLUx2OAmWaZAZzANj7XvuDsuKswEm+KYQ4m7Ulq1tNF2V5SaOgLzlZLZXVQojuaojUA+B3FLbr3eeEtZfsUap9ij2A3zJRKFRbMjvdTmr50ZW2yuqyvPLEtqvOuarPxi+EGAZa2h9Qmbg48WS1GVC0pZZjHdYF8QRQ8ViEUjSGojiOxjJ8hKPxymrV3rPaR4YsTi9EN6Ts4+LNmzezatUqKioqmDlzJuvXr2fFihVs2bKF/Pz8Lr+TkZHBli1bEu+7etp18cUXs2rVqsR727b7fvBxzuEjidfmmPZk9f6GfbxT9w7P7/oH1U3ezeA4ZWEpKM4OcNmU4n4bkxDi7KG1pqmlFjIA20e6nUHMcdl11Ktu8vsMaTkkhOhSW7I6ZLpgeVVFQStIONQxWS03a0KI09PaWxzRtEwyHR/gxZG2ZLXfZybdt7UV7RiugWO66HSLiBsBINPOorGtSrsDX7yyuiitiGsmLsHVmpLMzsVCQojUZGARDkVRKAytMKE9We1vv15pKxBs4+DDcC0c0+trrTXUhSL4DCuerLYxlcKML6hokyn9qoXohpRNVj/++ONcd911LF26FICKigpefPFFnnrqKT71qU91+R2lFIUn9IU+kW3bp92nr8QOHky8Nku8iyXHdfj1vl9R3dycSFQDmAQI+Eyued8YeVInhOgb4TBNuhUAZdtk+jLZV9VMJL5A2qQRWRJvhBBd0s3eNUrYdFGWH4CgGaRGKquFEGdIx/8HkBW1SCSrHcCANDs5lvgTyWoTx4zhBNuvVbJPkqw2jfbbYllUUYizj+v4aAl5D7V88QdhblvBdMAEBWivZ3VHjrLjsaZ9Ecb6lqjXBiTmYuDDNBSW0d4GxGdKCxAhTiclswyRSIQdO3YwZ86cxDbDMJgzZw6vvPLKSb/X0tLC/PnzmTdvHp/97GfZvXt3p322b9/OhRdeyMKFC/nKV75CbW1tv5wDgNO2uGIggBGvBq9trSXiRDhW3z6VrSA9m1nj8/n4hePISe+/Sm8hxNnFbWhILK6obB8ZdiZvH22/wSsdmTlYQxNCDHFuS1uy2oG2NiBWkHBEktVCiDPTcSHEYCyeRAJa45tPjCW2ZWCNG4fSJioYxLTaE9GZdhbtE/rbnWyBRSHE2UFraEokq73gEotXVscCFlZ8QUTHSW4DEsPCdCxMNL74Po3hKGiTcNTBjCerTQMsghjKkmIfIbohJSura2trcRynU7uP/Px89u7d2+V3JkyYwP33309paSmNjY384Ac/4Prrr+fZZ59lxIgRgNcC5IorrqCkpISDBw/yrW99i1tuuYUf//jHmGbPL3BCoc4LfujGJiLVNQCYRYWJfQ7VHaS2KUxjPJD6fSYXj5/EvNE5gKalpaXTsQZK2xi7Op/hJpXOBVLrfLTWsiDFAHEbGxOLK+KzCZpp7D7aCHg3ghMKMwZxdEKIoUy3NAMQNlxUPFEU9AVpjbbf5EmyWghxpqyolzwKY4IRfxBmn5isNjFHjMDnjsehCqNDXihoBfGbfsJOe+GPqUy5thRCgOPd99guYJJYYDHqNzFNTcxxOlVWx7TXBsREk2Ub1ALahcM1rbiu9tqAGArTMPAp795J2oAIcXopmazuidmzZzN79uyk94sWLWLjxo3cdtttACxevDjxedsCiwsWLEhUW/fUvn37Om0zDx8mvc6r2o44Ywjv3AnAy7Wvsbe2logD2a2zuGBUFkX1+exs2Nnj37+vdXU+w1UqnQukzvn0Z6940U43NNJsxiurfT72HI0lFkebWJwpVQFCiJPSLe1tQLB8aA0BM0g46j1sP3FBNCGEOJmOldW++AOvVsuXSDAH7eRb2rbYYigfaDA6JKIDVhDbtJOS1ZYht8RCCCAWA8AXDzltPasjtoFluLQCrqu9JLShQIOTno1Z40cbipz8bGrrvOucXUeagTQsFaTQPxa/2cCoQCm0QmGWfxBOTojhpcf/Mv/kJz/hxz/+MQcOHKChoXPfL6UUb775Zq8G11O5ubmYpkl1dXXS9urqagoKCrp1DJ/PR3l5OQcOHDjpPmPGjCE3N5f9+/f3Klk9fvx4gsFg0rZYuJXWnFwAXhs1hb116bgadjY2oywbvwVT8iezdM6kIVMJEAqF2LdvX5fnM9yk0rlAap1PV+15RP9wG+pp9nnJ6SNRg+a3m1DxabJTS7IHc2hCiCFOt3gzecKmSwSDvUfqCR0/ghPxFmX1W1LJKIQ4c23J6rAvkNh24iyNRM9qvMVdOyarg1YAv5mcKJIWIEIIAB1PVtsnJKtjPgOrw/P1mKuxDYXjagzDj2/sJMyASWZWGkZDFNfVHK2N4FdpAHygcAHzpxRS1xLjYHULZSOzBvS8hBiOepSs/va3v82jjz4KeFPyhxrbtpk6dSrbtm1jwYIFALiuy7Zt21i2bFm3juE4Drt27WLevHkn3efYsWPU1dX1esHFYDBIWlpa0rZwayuOZXFc+Xm5JYDpd9BaE1WNGBhk+TP4xIXlpKcPvadyXZ3PcJVK5wKpcT5DKbnx5JNPsm7dOiorKykrK+Puu+9mxowZXe779NNP8+Uvfzlpm23bvP7664n3d911F88880zSPnPnzmXdunV9P/hTONBwgBcP/Zbsyv00WjEalEVtq02O37uZu3BSAecUSQsQIcTJ6WavDUiL6bK/MUokBpGYSduaQn5pASKE6CatNW1tpq143/vWDsnqExdYtON98o34ra5pdExWB7FPSFZLZbUQAkhUVtvxHJervJkdEZ/C6rAoYszR2BY4rkZhYSobZRoYhiIz4KO+JYLCi0MB2+R9E/IwDZP8DJP8jKGXvxFiKOrRv8w/+clPEknqYDBIVlZWr3o294fly5dz5513Mm3aNGbMmMH69esJhUIsWbIEgDvuuIPi4mJuv/12ANasWcOsWbMYN24cDQ0NrFu3jiNHjnDttdcC0NzczJo1a1i4cCEFBQUcPHiQb37zm4wbN46LL764z8fv1tUB8KaRjbK9gOaoEIYRozgzyPtKJpIngU6IQbN582ZWrVpFRUUFM2fOZP369axYsYItW7Z06pffJiMjgy1btiTed5V4v/jii1m1alXi/UC3PKkKVbFl32aiToTq+r1o06XFCGD5vErq+VOKuWBi92aoCCHOXm0LLO7yBWiJaRQKg/Z4FpAWIEKIbmsvjvKS1SZhX3s8OfHhl52orPZudZPagJjBLiqrJVkthAAcL1ntj4ccjbeYa9RSibgCEIrESPObxFyNgYmJHxV/KJad5iWrDSwMQ7Hk/WPISZcWlkKcqR79y9zU1IRSihtvvJEvf/nLQ6rSsc2iRYuoqalh9erVVFZWUl5eztq1axNtQI4ePYrRYbWNhoYG7r77biorK8nOzmbq1Kls3LiRiRMnAmCaJrt27eKnP/0pjY2NFBUVcdFFF/Fv//Zv/ZJMcuvqiKF428hC2TaWaXDNB3PZejAHgKK03lVzCyF65/HHH+e6665j6dKlAFRUVPDiiy/y1FNP8alPfarL7yilTjsTw7btXs/W6KmWaAvP7v0lUTeK29iEjnnVS05aGr74NLZJIzIHZWxCiOFFt7RwXPk5ZEUTiWql2q+7ZHFFIUR36Q4vfGEvWd3aIeF8YmV1pzYgSQssBrDN5Hs3y5B4JIQA4vc+flcTjW9ylCZiQWbAx1G8FmcNoRj5mX4c1/Uqq7G9HtZ4yWq/z8CnLRbNGsXY/PTBOBMhhr0eJaunT5/OX//6Vy688MIhmahus2zZspO2/diwYUPS+5UrV7Jy5cqTHisQCAzoVHy3ro53VCYRZWH7fJSNyqIhejjxeUGaVDYKMVgikQg7duzg05/+dGKbYRjMmTOHV1555aTfa2lpYf78+biuy5QpU/jiF7/IpEmTkvZpW7A1KyuLD37wg9x2223k5ub2aryhUKhb+/3p6B+pC3kLu7rV1Wjt9YWM2gFMx0+MGIYbpaXF6dV4eqrtPLp7PkNZKp0LpN75aK2H9PXNcKBDIY6oNFyrAQUUZmRBS/vnkqwWQnRXYoFF7RJfSoOw5Ut8HjghWW2ZBqahMJwuKqutLiqrpQ2IEAKvZ7UCAoYipkBrL1kdNTVB28Q0FY6jaQxH0ZpEZbWBD+LJatNQlI3KZvmUKaT7paJaiJ7q0b/Md9xxBzfeeCPr1q1j5syZ5OXl9fW4znpuXR1vmkUov40CZozN4Y2GfyQ+LwhKZbUQg6W2thbHcTq1+8jPz2fv3r1dfmfChAncf//9lJaW0tjYyA9+8AOuv/56nn32WUaMGAF4LUCuuOIKSkpKOHjwIN/61re45ZZb+PGPf9yrVkv79u3r1n6v1b9Go9OIQjHtzUbeTm8FpWhywQ65NLl17Nn9do/H0Ve6ez7DQSqdC6TW+Qx0C55UorVGNzfTqLJxTY0JnFOQy3sd1qyOue6gjU8IMTxp18WnvTLpVqM9Rge7ePhlWwaG4yW0zXiy2lQmPsPXKVltyQKLQghI9KwO+Hw02Ta0RnAVRAyNUpAV8FHbHMF1Nc2tMRxX44tXVtOhp7WhDNJs38l+FyFEN/QoWf3Nb36TzMxM/va3v3HppZdyzjnnkJWVvKKpUor169f3ySDPNjoUojHscMgXxLBtctNtRuX6+e2x9wDwGT6y7exBHqUQ4kzMnj2b2bNnJ71ftGgRGzdu5LbbbgNg8eLFic9LS0spLS1lwYIFiWrrnho/fjzBYPCU+8TcKH966w/kkkOuE+TCmgb25TWjMjKw/AFyfPmMSS+kvHx8j8fRW6FQiH379nXrfIa6VDoXSL3z2b1792APYXiLRNAxh3o/iR6OWf50skZk8s6xRmBoLZYrhBjaEpXVjoPP9WJHuEM1dNDuKlltolrjldXxOBSwAiilumgDIkklIQReGxAFAZ+Nsm10a4SY4RIzNArIDHrJaoDGUBTDUNiYGPhRHfoN+QxLrnOE6KUeJau3b9+e+MsXiUR4++3kSjuZPts7bn09dSp+0WTbFOSF2PT2j2mKNgGQH8iXP18hBlFubi6maVJdXZ20vbq6OtEX/3R8Ph/l5eUcOHDgpPuMGTOG3Nxc9u/f36tkdTAYJC0t7ZT7HGs+hml5N3tFtQ5B02ZSUwZ7xuaho4o0M4+cjLTTHmcgdOd8hotUOhdInfORf2N7R8cXV2wwFMT7VOcEMvjA+JEcqm6hNeZw/gSZlSeEODM61iFZbXVcsLVzsjrdb2I0W5iGoi2kB0zvYWrnNiBSWS3EYHryySdZt24dlZWVlJWVcffddzNjxoyT7t/Q0MDDDz/M888/T11dHaNHj2blypXMmzevx2MwlJfHMpQizbZRAT80NhG2NPi83Ex+ehoHqpq9MYSiZKd5D8BM7Us8FAOwpLWQEL3W479FWusuX4vec+vqCONdNGm/yRuNWymIJ68ViqkF0wZzeEKc9WzbZurUqWzbto0FCxYA4Lou27ZtO2mf/BM5jsOuXbtOeVF17Ngx6urqBmTBxapQVeJ17hGv8vGDVdlYoy7gvQMKW2WTGZALLyHE6bktXu/yRkuDYaAUZAbSyAr6uOWyiURiLrnp0mZFCNE9bZXVKhbD1MnJasNQ2JbR6TsXlxbR/GYVltU+2ydoBYDOyWpLyfWNEINl8+bNrFq1ioqKCmbOnMn69etZsWIFW7Zs6dRyEbxiyeXLl5Ofn88jjzxCcXExR44c6TTT/0z5DPDjMMNpwOcPYI7MREeiuBMvQNneDPecQBZBu4ZQxCEUcUjzebFHKRO/aQNeizNJVgvRez36W/Sb3/ymr8chOnDr6gjFe6dFAxF8hhf08gL5XD52AUVpRYM5PCEEsHz5cu68806mTZvGjBkzWL9+PaFQiCVLlgBeb//i4mJuv/12ANasWcOsWbMYN24cDQ0NrFu3jiNHjnDttdcC0NzczJo1a1i4cCEFBQUcPHiQb37zm4wbN46LL76438+nMuRdhKE1OQdrAYU/I4upJQt47eB+ADKCcuElhDg93eJVHTWbLhgKn2kQjCeM0v0W6f5TfVsIIbrmc7zCHYBwvHVH0Gd2ORtmQlEGH8+ayP++9efEtkA8DtlSWS3EkPH4449z3XXXsXTpUgAqKip48cUXeeqpp/jUpz7Vaf+nnnqK+vp6Nm7ciC9e8VxSUtLrcfiU5v+27sJnWbxiF6LSbHzlZbglU+CQd5+U7ksnK+gjFPFWem1sccmJh590O0hEe9c/0lpIiN7rUeZh9OjRfT0O0YFbV0co/qOJ+SME4/2PpuRPkUS1EEPEokWLqKmpYfXq1VRWVlJeXs7atWsTbUCOHj2K0aF3WUNDA3fffTeVlZVkZ2czdepUNm7cyMSJEwEwTZNdu3bx05/+lMbGRoqKirjooov4t3/7twFZ6K2ypRIA3RIit1EDCmvCBJrjF2MAGX658BJCnJ5uacEBGvxhlDKwTIMcf+5gD0sI0YX+mH5/psc8Ha01KLCi7bN5W+OVi4Eu+lW3sU9IGAXildW2cULPaqmsFmJQRCIRduzYwac//enENsMwmDNnDq+88kqX33nhhReYNWsW9957L7/5zW/Iy8vjqquu4pZbbunVgvRojevEiAGuYRGLL7ZY21SbeG1rG7+lcLVXTOi6Cu8bYGPSEt9PxzQt8ZZoAy0UCiX9/3CXSueTSucC/d/+uVf/Mr/22ms8++yz7Nu3D/AW8Vq8eHGvLkaE17O6JV5ZHbOjWPH+R9l2ziCOSghxomXLlp207ceGDRuS3q9cuZKVK1ee9FiBQIB169b16fi6y9EONWGv/3ZWk4NPe0l2a8IEGsPRxH4Z0gZECHEaOholunMnLVi0BprA8OEzDUamjxzsoQkhTtAf0+/P9JhnwhfzktUxFDHDwsCrrD6ZEyuo0yxvTQW/JZXVQgwFtbW1OI7TKTbk5+ezd+/eLr9z8OBBXn75ZT784Q/z/e9/nwMHDlBRUUEsFuPWW2/t+WC0prHRa4VY05BNba2XeN7Tsofa1jpvvOFaWlsaaW31PnPdKLXhOgwFOTUN1Ma8/Uyfyc7WnT0fSx9oy9GlilQ6n1Q6l/4squtx5uGhhx5i7dq1Sdt+//vf86Mf/YhPfepTfOELX+j14M5Wbm17z+qo1YpleomjbH/2YA5LCJGiasO1ONqroM6riSS2WxMm0By/UANJVgshTs2pqaV57VqcqmpqLIuoL4xhBskPFOIzZWaGEENNf0y/P9Njdkdbz2pf1LtWqVY2+Lxrkuy0k8cW34mV1Wa8Z/UJldUn7ieEGLq01uTn53PfffdhmibTpk3j+PHjrFu3rtfJ6szMTEzTYuTosRzNrgEgLzOP+sY6ACaNmETVsUreC9fjuJqAziA3kEPQNhk3ehxOg3ffNCpjNOVjy3t7qj0SCoXYt28f48ePJxgMnv4LQ1wqnU8qnQvA7t27+/X4Pco8bNmyhcceewylVJeLK37/+99nypQpLFy4sNcDPBt5bUDSwbKIGfVYpkKhyLJ7t2iAEEJ0pbKlrV81ZB9pAGxUMIAxcgSNRw8n9svwS7JaiIF2JtPpn376ab785S8nbbNtm9dffz3x/q677uKZZ55J2mfu3Ll9MrMj8te/4FR5szQOpjsYGeng81EcHNXrYwsh+lZ/TL/vyTHPhNXqTb0/roIoy0swj8w5+Q2/Ugqf4SPqerPEOvasVqhEEtxUUlktxGDIzc3FNE2qq6uTtldXVydaK56osLAQy7KSWn6cc845VFZWEolEel7pqTWmaWFZFsGsbCyrAYCYEcOyvHugzLQs0vxppPtbaArHsAwbS1lkptlkBbOwWrz90gJppKWl9WwcfSQYDA76GPpSKp1PqpxLf7YAgR4mq5988knAuwH653/+Z2bMmIFSildffZX//d//JRwO88QTT0iyuge01uj6ekIqC2XbxGjGVOlk2JkyRU0I0S8qQ/F+1aEQeQ3xVawnjEcpRVO4Y2W1VB4JMZB6Mp0+IyODLVu2JN53dSF58cUXs2rVqsT7vprCV1l7iH8U1pIeM6n8wAdRjfsAKMns/cJHQoi+1R/T73tyzO6KxRxUSyuxmMMRy0cMULEYOQFO2RtWuUai3yyxDvu6EHO97bFIbMD6y6ZSz9JUOhdIrfPp716yfcW2baZOncq2bdtYsGABAK7rsm3btpO2WjzvvPP45S9/ieu6ifWB9u3bR2FhYe+uZzoUYfr8aeDdEhGKtccGv2njM2yCtkVTOIYRnw0f8JlJ7YVktoYQvdejZPVbb72FUoovfvGLfPKTn0xsv/LKKxkxYgSrVq3irbfe6rNBnk10YyPacQlZJq5fYZhRUJBtSwsQIUT/ONJ0BAC3sZH8Vu8iz5owAYDmVq8aybYMbMvo+gBCiH7Rk+n0SikKCwtPeVzbtk+7z5nQWvPn4y/zmvM3nEzvpq5WHW0bEWOyZGFuIVJBv02/74bGxkbClbXU1TnszxlNXUMDhqGoORyl/ujJk3L19XU0Oc0AHHIO0hCvlmysayLkeknJQ5FDmO8N7OyxVOpZmkrnAqlzPgOxQHtfWL58OXfeeSfTpk1jxowZrF+/nlAoxJIlSwC44447KC4u5vbbbwfgE5/4BE888QRf//rXWbZsGfv37+fRRx/lxhtv7NU4VIdktRkMghc2aIm2P7ywTT+2aROML+yq4um0gM9MtBkCsAyZjSpEb/Xob1E4HAZg3LhxnT5r29a2jzgzbn09GggpCyfoYBnSr1oI0X8aWuupDleB45B3uAG/G0QDR/NHkx+K0hivrJZ+1UIMrJ5Op29paWH+/Pm4rsuUKVP44he/yKRJk5L22b59OxdeeCFZWVl88IMf5LbbbiM3N7fHY43pKK9Vv4ob9XreK9MgGr/n86tcslOgL58QqaY/pt/35JjdlZmZSa5dSzAnQDgzn9zcXIqz/UybOvaU33t771tUhr12Z9MmTSfdlw7Am3t2UNPqjfPcUecyKWdyr8bXXanUszSVzgVS63z6u5dsX1q0aBE1NTWsXr2ayspKysvLWbt2bSJmHD16NFFBDTBy5EjWrVvHqlWruPrqqykuLuamm27illtu6d1AOiSrrWB6IlkdcVsT2/2mH59hkRZPVrdVVgdtM9FmCMCnpLJaiN7qUfZhxIgRHDp0iB/+8IfMnj2b7GwvkVpfX88Pf/jDxD7izLnV1UQxcIFYwMEyvUqBbH/OoI5LCJGa9tbvBQ2xve9ScsxLTO/IH88f94Sx9u3Gcb0LN2kBIsTA6sl0+gkTJnD//fdTWlpKY2MjP/jBD7j++ut59tlnE9dlF198MVdccQUlJSUcPHiQb33rW9xyyy38+Mc/TkpAnYmojhFzHHS4Fd2UR0NumEg0hqtdbDcXU0doaem8xslQk0pTwCG1zieVzgWGxhT9/pp+f6bH7C7LNAlEHGp8GRi2jWVZjCvKPm3fz4KMAmpjNQTMAHlZeYn+1BmBdBqcegDS09IHvH9oqvQshdQ6F0iN8xns+HKmli1bdtIYsWHDhk7bZs+ezaZNm/p2EI6TeGkFuv75B8wAPsPG7zNRKrmyOq1Dsto2h0dVuxBDWY+S1fPmzeOJJ57gz3/+M5dccgljx3pPtA8cOEAkEkEpxbx58/p0oGcLp7KKlvgTumgghhm/EMyRymohRD94t34vzrFjONU1jGsuQgX8HDn/YlQLiUQ1QKZUVgsx5M2ePZvZs2cnvV+0aBEbN27ktttuA2Dx4sWJz0tLSyktLWXBggWJauue0Gga6+uxa/w0VpVSa1bSlO6VJEXD6ezfsxvTGD43zqkyBbxNKp1PKp3LUJii3x/T7093zB5zXXwxOKYCqPhiZ6daXLHNB0ddSJovjfFZ45MWUvSb7f1lTSXXOEKc9dz4uj0lozF9/i53CfqC2KaNUhCwLYxIvGe1bTI6s4SSjBKao81Mzh2YmRpCpLIe/cv8mc98hi1btlBVVUVrayvvvPMO4FUJgDdF7DOf+UzfjfIs4lZXEYpfSDl2lEC8sjpLelYLIfpYS7SFI01HcI4cITtqkROzSb/hemqOWEAkad90SVYLMaD6Yjq9z+ejvLycAwcOnHSfMWPGkJuby/79+3ucrAbI9Pupj52LbfsZ4UwnZJsY+MhPH8u0qef0+LgDKZWmgENqnU8qnQsMnSn6/TH9/nTH7Ckdi2K5iuMqAD5vtteobiSrs+ws5o6+uNN22+y4GJpc4wghvDZmwaVLsYxYp88CZgBTmYnFE9NsEyLtldWmMvnIxGsGdLxCpLIe/ctcUFDAxo0b+epXv8qf/vSnRJJaKcXcuXO55557en1BcrZyK6sIYwKKqK+VDOlZLYToJ/sa3sWtrUFHY4xrzsCeOgU9uZSGPTs77ZvhlzYgQgyknkzRP5HjOOzateuUs92OHTtGXV1drxdc9GuDUeEMjhsKMxAk1/Jm3eVk+IfddOpUmALeUSqdT6qcy1Caot8f0+9Pdcwei8XwuQbH45XVtmWQl9Hz6vSAJYuhCSGS+RYswBo9CrPpcKfPgvE2Hz6zPVkdis+Iz5R2iUL0uR7/y1xSUsLatWupr69n//79AIwdO5acnJy+GttZR2uNU1lFSNkov02MFizTJMOXIRdRQog+FXNjvFH1Bs5xb9Ghsc1B7As/SHVTa8f1RRLS/D3rZSuE6LkznaK/Zs0aZs2axbhx42hoaGDdunUcOXKEa6+9FoDm5mbWrFnDwoULKSgo4ODBg3zzm99k3LhxXHxx58rDMzFO53FYu6BA+doTSLI4qxCiT8RiRF2LZmVhWhYjc4K9SvpPzi3l7Zq3yQnkUJRW3IcDFUIMSz4f1gUXAF23BmpLVtuGd42Tm25T4suhOJDDxOKMgRunEGeJXt9BZGdnM2PGjL4Yy1lPNzejw2FCRho6aOHQimVkSAsQIUSf0lrz24Mv8F7tQdz6BrKiJkXpRVgTJ1J1qL7L7+SmDX5vTSHONmc6Rb+hoYG7776byspKsrOzmTp1Khs3bmTixIkAmKbJrl27+OlPf0pjYyNFRUVcdNFF/Nu//Vuv++ee25rDLhq8N3Z7hVG6X5LVQoje09EY1dqrqlc+H6PzeldhX5RWxPJp/weFGlKV7kKIwaGD7Q/ATKNzkU7Q8mJO26wMw1DMLy9hQvbogRukEGeRbt1BfPnLXwbgs5/9LGPHjk28PxWlFPfff3/vRneWcauqAAhhEkuLN/g3FTn+nEEclRAiVYR/9zvCL/yW19JqeCO3DrTG0opLj+cRWPBBlFJUNbUm9r9i+gh2HKonN91mVO7w7xEqxHB0JlP0V65cycqVK096rEAgwLp16/p0fACWsihuMmmJVyKpDolv6XcvhOgTsRhVZHmvLYtxBem9PqShjNPvJIQ4O3R4aNVxMdY2QZ93LzQpZxI7q3cStAKMyRwzYMMT4mzTrTuIZ555BqUU1157LWPHjk28Px1JVp8ZpzKerFYmkTQvYWQZioKg9P8WQvSO29REeMuvaHVjvDqiDu16vT4ueS+XAieA/b73AVDV2J6snlicyfkT8gdlvEKI4cNv+InUN+PG33dMVtumJIOEEH0gFuM97SWoLdvHaHmILoToJ11VVqfFK6sz7Ew+UfbPMiNDiH7W43IX3VVT0w7kL++Zc6vbK6tbAy0AWKYhfdSEEL0W+etf0Y7LnqwWYgEfyjQpbc3h3Nwx2HPmYGR4vdaq48lqyzTICspiIUKI7mlqaAbiySNfe+wI2tLvXgjRe5FojCb8WMCovDQseRAmhOgn1il6VoPkuoQYCN1KVv/oRz8CYPLkyUnvRd9yO1ZW282gwDYtqawWQvSK1prWl/+MRvNWdjO+8qmogJ8PlH6CzA7xJea41LVEACjI9MuFmBCi25qaQkAQLItJo7I5UNWM32cyZbSsuyGE6L3miIvheg+/xhVlDfJohBCpzOyiRVDHZLUQov91K1n9gQ984JTvRd9w4j2rmw1FxGzBMgwK0gq6nIYihBDd5b6zB7emlqPBVhoK0vAF/IxKH9XpQVh1Uyttk2YKMv2DMFIhxLCkNS3NrWB5LUDGFaTz0fNLAKT6UQjRJ5pjmkztxZNxo/MGeTRCiFRmGqeurBZC9L8e3UGUlZUxZcoU/v73v3f6bNeuXdx000188pOf7PXgziZa68QCi/VZGoXCMgyKpQWIEKIXVFMTrZs2odHsyG7CLC4CYFrBjE77duxXLclqIUS3aU2T683EULZNht/CMg1JVAsh+kxL1EShME2D0YWZgz0cIUQK63KBxXjPaiHEwOjzntWNjY1s375dpo+fAffoUSLH36M6ahBSQZozogBYppJ+1UKI3nEcdCjM6wUhDmc72Dm5pFnpnJNzTqddKzskq/MzJFkthOgmrWmJ93dUPh/pgR5fXgohRGfRKNGId2850ufKgzAhRL9SSmEoA1e7iW1pUlktxIDq1d1EVwnpHTt2nPQz0YVYjNB/f4/3zCBP+iaggUiwEkAqq4UQvRbxwUslzezNjWCNGw+G4pKSeZ0qBt44VMf2PdWJ94VSWS2E6CbV0kKzii+qGK+sFkKIvqIBw/US1CWSLxJCDABTmYlktcLANuXeSIiB1O27iTVr1vDd73438V5rzT//8z+fdP/CwsLejewsoSIR0LDXyEADGk0kzatuDFg2Of6cQR2fEGJ4i/gt9l0yGdvywv0FIz7IuTnnJu3z+sE6nn3lcOJ9+ehsctLtAR2nEGIYc11CeA/AlG2TLslqIUQf0iiU9mJMcUCqqoUQ/c9UFlG8Ge9pvqAUYwoxwM7obuLE1h8nawUCcOmll/ZoQGedaAyA48EcrFHjcYLg+A+jgMK0IgmKQog+U5ZXzvnF70va5rqa37/1XuL9rPG5fGjayIEemhBimGuOtwHx+W1sS5JJQoi+07Gyusg++f2nEEL0FdMwwPFeS79qIQZet5PVmZmZjBo1CoAjR46glCI/Px/bbq++MwyDrKwsLrjgAm699da+H20KilguEeXy3sjxmMXFhI09FKUHcByX2aMnDPbwhBDDXNAIcs2EJWSkZ5Lrz+30AGx/dTONIa9qYEJRBgunj5SHZEKIM9bWszozK01iiBCiT2nDxNAmQe2QN23qYA9HCHEWiLmxxOug9KsWYsB1O1n9yU9+kk9+8pMAlJWVAbB69WrOO++8/hnZWSJqaH4zspFQXiFKa2L+/ZTkesFwWmH5II9OCDHcGcqgIFhIWqDrioBX99cmXs8a1zmZLYQQp6PT04lm5WBmZJCRnzPYwxFCpBqlMEeOpWT8DPwXvO/0+wshRC9FnEjidZpUVgsx4HrUVHDVqlUAjB8/vi/HctZ6Z0SAkG8XQQoxfSEgSElGCXmBvMEemhAixWitOVjTwr7KZoqzA+w+1ghAmt/i3KKMQR6dEGI4ck0Ts7QUy7JkcUUhRL8wfUFGlY5HmebpdxZCiF7StLcckspqIQZej+4orrnmmsTr5uZmGhsbcV23035tbUPEqYWzcqhzd9HAXsbbAQCmF8wY5FEJIVLNu5VN/PbN47xXH+702dSSbCxT+swKIc5cxyVMMgKSrBZC9D2TACOyJWEkhBh4ASsw2EMQ4qzT4zuKn/3sZ3zve99j//79XX6ulOLNN9/s8cDOFpYVJGTa4GpcYqT5LTJ8mYzPln7VQoi+87d3a9j6xlFOti7ujDE5AzoeIUTq6BhW0qWyWgjRx5Q2yWQ8I7IlYSSEGHi2YZ9+JyFEn+rRHcXWrVu58847UUqhT5b5EN0ScW0yI+cTVTuwfK1YpmJ6wXQMJRWOQojec1zNc68dY/d7ocS2ETlBykdnsftoI4dqWpg5LpfCLLkBFEL0TMdLwXSprBZC9DFD26T5AmSn+QZ7KEKIs5BtSrJaiIHWozuKDRs2AJCbm0tNTQ1KKSZNmsTx48epr69nwoQJFBQU9OlAU1maHk2GMZrc3OOcX5zNzKJZgz0kIUSKCEU1O481YlleuL9gYgGXlhehlOKCc704LQ8dhRC90RprjyHSs1oI0R+KsgKyCLQQYlDYpn+whyDEWadH5btvvfUWSinuuOOOxLavfvWrvPjii1x00UXU19dzzz339NkgU1r8mstQFheOfj8fGHkBppKFQ4QYDp588kkuu+wypk+fzrXXXstrr7120n2ffvppSktLk35Nnz49aR+tNY888ghz585lxowZ3Hzzzezbt69PxmpbBlfOHMX8KcWdbvbk5k8I0Vdy0qT6SAjR90ZmS7JICDFwitKKE6/zA3mDOBIhzk49SlY3NzcDMHr06ESSIxqNEgwGuemmm6ipqeHrX/96340yhaX5FFNGZzF9bA7TSrIHezhCiG7avHkzq1at4nOf+xzPPPMMZWVlrFixgurq6pN+JyMjgz/+8Y+JX7/97W+TPn/sscfYsGEDX/3qV9m0aRPBYJAVK1bQ2tra43GaBlw2pZBbP1TKrHG5PT6OEEKcjKFgRHaAS8qLyM+UhJIQom9ZJrxvglzDCCEGzhXjPsS52RO5ZPQ8svySpxFioPUoWZ2RkQGA4zhkZmYC8Kc//QmAt99+G4BXX321L8aX8gyluHJ6MYtnjcYypU+1EMPF448/znXXXcfSpUuZOHEiFRUVBAIBnnrqqZN+RylFYWFh4lfHdklaa370ox/x2c9+lgULFlBWVsY3vvEN3nvvPbZu3drjcQZ9BrPG5mBbEl+EEP0jzTb45wvHMGdS4WAPRQiRggKWQcAnM0+FEAMnx5/DlRP+iemFMwZ7KEKclXqUvSgu9qZENDU1MXnyZLTWPPbYY1x44YU8/PDDKKXIy5OpEkKI1BSJRNixYwdz5sxJbDMMgzlz5vDKK6+c9HstLS3Mnz+fefPm8dnPfpbdu3cnPjt06BCVlZVJx8zMzGTmzJmnPKYQQgghhBBCCCFEqujRKjhTpkzh7bffZt++fXzsYx/jr3/9KwB1dXWJhbquu+66vhulEEIMIbW1tTiOQ35+ftL2/Px89u7d2+V3JkyYwP33309paSmNjY384Ac/4Prrr+fZZ59lxIgRVFZWJo5x4jGrqqp6Nd5QKNSr7w8VbeeRCueTSucCqXc+Wmvp5S6EEEIIIYQQg6BHyerbbruN66+/noKCAkaPHk1dXR1PPPEEx48fZ9SoUXz84x/n5ptv7uOhCiHE8DV79mxmz56d9H7RokVs3LiR2267rV9/775apHGoSKXzSaVzgdQ6H9uWhQKFEEIIIYQQYqD1KFldXFycaAUCcPPNN0tyugei0SgA77zzTkpUcLVV1afC+aTSuUBqnU80Gh30c8jNzcU0zU6LKVZXVyf1oT4Vn89HeXk5Bw4cAKCwsDBxjKKioqRjlpWV9WicbTHGsqxB/zPrC1prYrFYSpxPKp0LpN75RKPRxN8fcWqpdC2TSv9WQmqdTyqdCwyNa5nhIpViDKTWf8updC6QWucjMebMpFKcSaX/jiG1zieVzgX6P87IiluDSCmV+JUKlFLYtp0S55NK5wKpdT5D4e+MbdtMnTqVbdu2Jba5rsu2bduSqqdPxXEcdu3alUhSl5SUUFhYmHTMpqYmXn311W4f80Rtf1aGYSTFm+H6yzAMbNtOifNJpXNJxfNp+yVOL5X+vJRKnX8rIbXOJ5XOBYbGtcxwkUoxBlLrv+VUOhdIrfNJpb8zAyGV4kwq/XcMqXU+qXQu0P9xpluV1ZdffvkZH1gpxdatW8/4e2eTniaghBCDb/ny5dx5551MmzaNGTNmsH79ekKhEEuWLAHgjjvuoLi4mNtvvx2ANWvWMGvWLMaNG0dDQwPr1q3jyJEjXHvttYAXM2+66Sa+973vMW7cOEpKSnjkkUcoKipiwYIFPRqjxBghRH+TOCOE6E8SY4QQ/U3ijBBDT7eS1YcPH+6UMW8rYe/udiGESCWLFi2ipqaG1atXU1lZSXl5OWvXrk20ATl69CiG0T55paGhgbvvvpvKykqys7OZOnUqGzduZOLEiYl9brnlFkKhEPfccw8NDQ2cf/75rF27Fr/fP+DnJ4QQQgghhBBCCDHQlG7LLp/CmfRLVUqhtUYpxc6dO3s1OCGEEEIIIYQQQgghhBBnh24lq09UW1vLzTffTEtLC/feey/Tp09HKcWrr75KRUUFSik2bNiQ6MUqhBBCCCGEEEIIIYQQQpxKjxZYfOCBB9i1axf//u//zoUXXkhGRgbp6enMmTOHL3zhC+zbt48HHnigr8cqhBBCCCGEEEIIIYQQIkX1KFn9wgsvANDS0tLps1AoBMDvf//7XgxLCCGEEEIIIYQQQgghxNmkWwssnqitc8iDDz5IOBxm2rRpALzxxhusXr2670YnhBBCCCGEEEIIIYQQ4qzQo2T1ZZddxs9//nPq6uqoqKhI+qxtccX58+f3yQCFEEIIIYQQQgghhBBCpL4eL7D4f/7P/2Hnzp1dfl5WVsbjjz9Obm5urwcohBBCCCGEEEIIIYQQIvX1KFkNEI1Geeqpp3jhhRc4ePAgAGPGjOGyyy5j6dKl+Hy+Ph2oEEIIIYQQQgghhBBCiNTV42S1EEIIIYQQQgghhBBCCNFXjMEegBBCCCGEEEIIIYQQQgjRrQUWy8rKMAyDJ554gvPOO4/y8vLTfkcpxZtvvtnrAQohhBBCCCGEEEIIIYRIfd2urO7YLURr3a1f4uSefPJJLrvsMqZPn861117La6+9NthD6pZHH32UpUuXMnv2bC688EL+5V/+hb179ybtc+ONN1JaWpr065577hmkEZ/cd77znU7jvPLKKxOft7a2UlFRwQUXXMDs2bP5/Oc/T1VV1SCO+NQuu+yyTudTWlpKRUUFMPR/Ln/5y1/4zGc+w9y5cyktLWXr1q1Jn2uteeSRR5g7dy4zZszg5ptvZt++fUn71NXVcfvtt3Peeefxvve9j5UrV9Lc3DyAZzG0DMc4k0oxBlIrzkiMkRhzouEYYyC14kwqxRgY3nFGYkz/GI5xJpViDKRWnBnOMQYkzvQHiTGDL5ViDAzvODOUYky3KqtHjRoFgN/vT3ovembz5s2sWrWKiooKZs6cyfr161mxYgVbtmwhPz9/sId3Stu3b+eGG25g+vTpOI7Dt771LVasWMGzzz5LWlpaYr/rrruOf/3Xf028DwaDgzHc05o0aRKPP/544r1pmonX999/P7/73e/49re/TWZmJvfddx+33norGzduHIyhntZPfvITHMdJvN+9ezfLly9PCvRD+efS0tJCaWkpS5cu5dZbb+30+WOPPcaGDRt44IEHKCkp4ZFHHmHFihVs3rw5EZu+9KUvUVlZyeOPP040GmXlypXcc889PPTQQwN9OoNuuMaZVIsxkDpxRmKMxJiOhmuMgdSLM6kSY2B4xxmJMX1vuMaZVIsxkDpxZjjHGJA409ckxgwdqRJjYHjHmSEVY7QYcB/72Md0RUVF4r3jOHru3Ln60UcfHcRR9Ux1dbWePHmy3r59e2LbsmXL9Ne+9rVBHFX3rF69Wl999dVdftbQ0KCnTp2qn3vuucS2d955R0+ePFm/8sorAzTC3vna176mFyxYoF3X1VoPn5+L1lpPnjxZP//884n3ruvqiy66SK9duzaxraGhQU+bNk3/8pe/1Fq3/3xee+21xD6/+93vdGlpqT527NjADX6ISJU4M5xjjNapHWckxkiMSYUYo/XwjjOpHGO0Hr5xRmJM30iVODOcY4zWqR1nhmuM0VriTF+QGDM0pHKM0Xr4xpnBjjGywOIAi0Qi7Nixgzlz5iS2GYbBnDlzeOWVVwZxZD3T2NgIQHZ2dtL2X/ziF1xwwQVcddVVPPTQQ4RCocEY3mnt37+fuXPncvnll3P77bdz5MgRAN544w2i0WjSz+ncc89l1KhR/OMf/xik0XZfJBLh5z//OUuXLkUpldg+XH4uJzp06BCVlZVJP4/MzExmzpyZ+HvzyiuvkJWVxfTp0xP7zJkzB8MwhsV0rr6USnFmuMcYSM04IzHGIzFm+McYGP5xJhVjDKRWnJEYc+ZSKc4M9xgDqRlnUinGgMSZMyUxZmhJxRgDqRVnBjrGdKsNyE9/+tMzOmibj370oz36Xiqrra3FcZxO00ry8/M79Rka6lzX5f777+e8885j8uTJie1XXXUVo0aNoqioiLfffpv/+q//4t1332XNmjWDONrOZsyYwapVq5gwYQKVlZV897vf5YYbbuAXv/gFVVVV+Hw+srKykr6Tn59PZWXlII24+7Zu3UpjYyPXXHNNYttw+bl0pe3PvKu/N239qqqqqsjLy0v63LIssrOzh8XPrC+lSpwZ7jEGUjfOSIzxSIwZ3jEGhn+cSdUYA6kVZyTGnLlUiTPDPcZA6saZVIoxIHHmTEmMGTpSNcZAasWZgY4x3UpW33XXXUlPAbpDKSXJ6hRXUVHB7t27+Z//+Z+k7R//+McTr0tLSyksLOTmm2/mwIEDjB07dqCHeVLz5s1LvC4rK2PmzJnMnz+f5557jkAgMIgj672nnnqKSy65hOLi4sS24fJzEaLNcI8xkLpxRmKMSBXDPc6kaowBiTMiNQz3GAOpG2ckxohUIDFmaJM403PdbgOitT7jX6Kz3NxcTNOkuro6aXt1dTUFBQWDNKozd++99/Liiy+yfv16RowYccp9Z86cCXhTO4ayrKwsxo8fz4EDBygoKCAajdLQ0JC0T3V1NYWFhYM0wu45fPgwL730Eh/72MdOud9w+bkAiT/zU/29KSgooKamJunzWCxGfX39kP+Z9bVUiDOpGGMgNeKMxJh2EmOGb4yB1IwzqRBjIPXijMSYM5cKcSYVYwykRpxJtRgDEmfOlMSYoSsVYgykXpwZ6BjTrWT1rbfeesa/Pve5z53RQM4Wtm0zdepUtm3bltjmui7btm1j9uzZgziy7tFac++99/L888+zfv16xowZc9rv7Ny5E2DIB5Pm5mYOHjxIYWEh06ZNw+fzJf2c9u7dy5EjR5g1a9bgDbIbnn76afLz87n00ktPud9w+bkAlJSUUFhYmPTzaGpq4tVXX038vZk9ezYNDQ288cYbiX1efvllXNdlxowZAz7mwTSc40wqxxhIjTgjMUZizHCOMZDacSYVYgykXpyRGHPmhnOcSeUYA6kRZ1ItxoDEmTMlMWboSoUYA6kXZwY6xnSrDcitt956RgcVp7Z8+XLuvPNOpk2bxowZM1i/fj2hUIglS5YM9tBOq6Kigl/+8pf893//N+np6Ym+M5mZmQQCAQ4cOMAvfvEL5s2bR05ODm+//TarVq3i/e9/P2VlZYM8+mQPPvgg8+fPZ9SoUbz33nt85zvfwTAMrrrqKjIzM1m6dCkPPPAA2dnZZGRk8LWvfY3Zs2cP6aDoui5PP/00H/3oR7Gs9r/ew+Hn0tzczIEDBxLvDx06xM6dO8nOzmbUqFHcdNNNfO9732PcuHGUlJTwyCOPUFRUxIIFCwBvoYWLL76Yu+++m4qKCqLRKPfddx+LFy9OmnZzthiucSaVYgykXpyRGCMxps1wjTGQWnEm1WIMDN84IzGm7w3XOJNKMQZSL84M1xgDEmf6msSYoSHVYgwM3zgzlGKM0tKvY1A88cQTrFu3jsrKSsrLy/nP//zPRPn/UFZaWtrl9lWrVrFkyRKOHj3Kv//7v7N7925aWloYOXIkCxYs4F/+5V/IyMgY4NGe2he+8AX+8pe/UFdXR15eHueffz5f+MIXEn2CWltbeeCBB3j22WeJRCLMnTuXr3zlK0P6idcf//hHVqxYwZYtW5gwYUJi+3D4ufz5z3/mpptu6rT9mmuu4YEHHkBrzerVq9m0aRMNDQ2cf/75fOUrX0k6z7q6Ou677z5eeOEFDMPgQx/6EP/5n/9Jenr6QJ7KkDEc40wqxRhIvTgjMUZiTEfDMcZAasWZVIsxMHzjjMSY/jEc40wqxRhIvTgzXGMMSJzpDxJjBl+qxRgYvnFmKMWYHier9+7dyw9/+EPeeOMNGhsbcV03+cBKsXXr1p4cWgghhBBCCCGEEEIIIcRZplttQE709ttvc/311xMOhxMLKSqlADq9F0IIIYQQQgghhBBCCCFOp0fJ6u9973uEQqHEe6VUUpJaOosIIYQQQgghhBBCCCGEOBNGT770t7/9DaUUX/rSlxLbnnjiCTZu3MiYMWM4//zz2b59e58NUgghhBBCCCGEEEIIIURq61Gyura2FoCpU6cmbZ81axa33XYbf/vb37j//vt7PzohhBBCCCGEEEIIIYQQZ4UeJauDwSAAlmUlXu/Zswdo71n9wgsv9MX4hBBCCCGEEEIIIYQQQpwFetSzOi8vj6amJpqbmxkzZgy7du3iG9/4Bi+99BIvv/wyAKZp9ulAhRBCCCGEEEIIIYQQQqSuHlVWl5aWorXm8OHDfOhDHwKgpaWFX//61zQ0NKCUYt68eX06UCGEEEIIIYQQQgghhBCpq0eV1TfddBPTpk1j4sSJzJw5kx07dvDb3/428fmll17KypUr+2yQQgghhBBCCCGEEEIIIVKb0m1Npk/jnnvuYfHixXzgAx9AKdXp86NHj3L8+HFGjRpFUVFRnw9UCCGEEEIIIYQQQgghROrqdrK6rKwMpRT5+fksWrSIRYsWMWvWrH4enhDdE4lE+MEPfsDPf/5zjhw5gmEY5OfnM3nyZD7/+c9TVlYGwF133cUzzzzDBz7wATZs2DDIoxZCDBcSY4QQ/U3ijBCiP0mMEUL0N4kzoq+ccc/q6upqNmzYwCc+8Qkuv/xyvvWtb/HWW2/1x9iE6LZvfOMbPPzww+zZs4fi4mJGjx5NdXU1W7duZd++fYM9PCHEMCcxRgjR3yTOCCH6k8QYIUR/kzgj+kq3K6sfeughfvWrX3HgwIH2L3doBzJhwgQWLVrE4sWLmTBhQt+PVIhTuOiii6iqquJzn/sc//qv/wqA1pq///3v5OfnM378eC677DIOHz7c6bs/+tGPuOCCCzh+/Djf/va3+cMf/kBdXR3FxcUsWbKET3/601iW1979xhtvZPv27XzkIx+hpKSEH//4xzQ3NzN//nwqKirIysoC4He/+x3//d//zZ49e4hGoxQVFTF16lQqKirIzs4euD8YIUSfkBgjhOhvEmeEEP1JYowQor9JnBF9pdsLLN5+++3cfvvtvPnmm2zZsoUtW7YkJa7fffddvvvd7/Ld736XsrIyFi9ezP/9v/+3XwYtxIlc1wXgT3/6E9OnT2f69OkUFBRw/vnnJ/YpLy+npaWF2tpa0tPTmThxIgAZGRnU1tby8Y9/nKNHj5Kens4555zDnj17WL16NYcOHWLVqlVJv99zzz2HbdsUFhZSVVXF5s2biUajrFmzhpqaGj73uc8RjUYZNWoUmZmZHD16lOeee44vfelLEhSFGIYkxggh+pvEGSFEf5IYI4TobxJnRJ/RvbBjxw79zW9+Uy9YsECXlpYm/SorK+vNoYU4I6tXr9aTJ09O+rVw4UK9Zs0aHQ6HE/vdeeedevLkyXrZsmVJ3//Od76jJ0+erOfMmaOrq6u11lo///zzevLkybq0tFTv27dPa631smXL9OTJk/X73vc+/d5772mttf6v//qvxO/5zjvv6Ndff11PnjxZz549W4dCIa211q7r6ldffVU3NzcPxB+HEKKPSYwRQvQ3iTNCiP4kMUYI0d8kzoi+csY9qzuaMmUKX/rSl3j++ed57LHHGDlyZFJrECEGyuc//3nWrFnD/PnzycjIALxq/9WrV/OVr3zltN9/7bXXAKiqquLCCy+ktLSUz33uc4A3beXVV19N2v+CCy6gsLAQgMWLFye279q1i0mTJjFmzBiam5u58MILueaaa7jrrruorKwkLS2tT85XCDGwJMYIIfqbxBkhRH+SGCOE6G8SZ0Rf6XYbkK7U1dXx/PPP89xzz7F9+3Ycx+mrcQlxxq644gquuOIKXNfljTfe4D/+4z/YtWsXW7du7fYxOk5D6SgYDHb7GH6/n6effpqf/exnvPrqq+zZs4ef/exn/PSnP+Xb3/42//RP/9TtYwkhhg6JMUKI/iZxRgjRnyTGCCH6m8QZ0RfOOFnd0NDAr3/9a5577jn+/Oc/JxLUusM6jTk5OSxcuLDvRinEaTz88MNceeWVlJeXYxgGM2bMYMKECezatYvMzMzEfoFAAICWlpak70+fPp3f/e53WJbFt771LUpKSgBoampi69atXHHFFUn7b9++naqqKgoKCnjuuecS2ydPnkxTUxN79uxh2bJl3HjjjQCsWLGCP/7xj/z1r3+VoCjEMCQxRgjR3yTOCCH6k8QYIUR/kzgj+kq3k9VPP/00zz33HNu2besyQZ2ens6CBQtYtGgRF110UWKVTiEGwk9+8hP+3//7f+Tm5jJq1Ciqq6s5duwYAFdddVViv3POOQeAN954gw9/+MMEg0F+9KMfccMNN/D//X//H8ePH+fKK6/k3HPPpbm5mWPHjhGNRvnoRz+a9PtFo1EWLlxIYWEh7777LgCXX3455557Lvv37+f6668nOzub4uJiotFoYp/S0tIB+NMQQvQ1iTFCiP4mcUYI0Z8kxggh+pvEGdFXup1RXrlyJUqppAS13+9n3rx5LF68mEsvvRS/398vgxTidG677TZ++9vf8vbbb7N3715isRgTJkxg8eLFfPazn03st3TpUv7617/y0ksvsWvXLgAcxyEvL49NmzbxyCOP8Ic//IF33nmH3Nxczj//fObPn9/p91u4cCHjxo3jiSeeIBAIcOmll1JRUQF4MwuWLFnCP/7xDw4dOoTWmnPOOYePfvSjXHvttQPzByKE6FMSY4QQ/U3ijBCiP0mMEUL0N4kzoq8o3TH7fAplZWUAWJbFnDlzWLx4MQsWLCA9Pb1fByjEUHLjjTeyfft2rrnmGh544IHBHo4QIsVIjBFC9DeJM0KI/iQxRgjR3yTOpL5uV1a///3v56qrrmLhwoXk5OT045CEEEIIIYQQQgghhBBCnG26nazesGFDf45DCCGEEEIIIYQQQgghxFms221AhBBCCCGEEEIIIYQQQoj+Ygz2AIQQQgghhBBCCCGEEEIISVYLIYQQQgghhBBCCCGEGHSSrBZCCCGEEEIIIYQQQggx6CRZLYQQQgghhBBCCCGEEGLQSbJaCCGEEEIIIYQQQgghxKCTZLUQQgghhBBCCCGEEEKIQSfJaiGEEEIIIYQQQgghhBCDTpLVQgghhBBCCCGEEEIIIQadJKuFEEIIIYQQQgghhBBCDLr/H7+bfMK/dgPTAAAAAElFTkSuQmCC\n"},"metadata":{}}]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import re\n","import os\n","\n","# Function to read CSV logs and extract accuracy and validation accuracy\n","def read_logs(log_dir, num_clients, local_epochs):\n","    dataframes = []\n","    for epoch in range(local_epochs):\n","        for client in range(num_clients):\n","            log_file = os.path.join(log_dir, f'training_log_epoch_{epoch}_client_{client}.csv')\n","            if os.path.exists(log_file):\n","                df = pd.read_csv(log_file, sep=';')\n","                df['epoch_number'] = epoch\n","                df['client_number'] = client\n","                dataframes.append(df)\n","            else:\n","                print(f\"Log file not found: {log_file}\")\n","\n","    return pd.concat(dataframes) if dataframes else pd.DataFrame()\n","\n","# Function to plot the training and validation accuracy for the final epoch\n","def plot_final_epoch_accuracy(all_metrics_df, output_dir):\n","    # Set the Seaborn style\n","    sns.set(style=\"whitegrid\")\n","\n","    # Get the final epoch number\n","    final_epoch = all_metrics_df['epoch_number'].max()\n","\n","    # Filter the data for the final epoch\n","    final_epoch_df = all_metrics_df[all_metrics_df['epoch_number'] == final_epoch]\n","\n","    # Calculate the average training and validation accuracy for the final epoch\n","    avg_train_accuracy = final_epoch_df['accuracy'].mean()\n","    avg_val_accuracy = final_epoch_df['val_accuracy'].mean()\n","\n","    print(f\"Final Epoch: {final_epoch}\")\n","    print(f\"Average Training Accuracy: {avg_train_accuracy:.4f}\")\n","    print(f\"Average Validation Accuracy: {avg_val_accuracy:.4f}\")\n","\n","    # Create subplots for the final epoch\n","    fig, axes = plt.subplots(1, 2, figsize=(12, 4.5), sharex=True)\n","\n","    # Set the color palette\n","    palette = sns.color_palette(\"Set1\", n_colors=final_epoch_df['client_number'].nunique())\n","\n","    # Store the lines and labels for the legend\n","    lines = []\n","    labels = []\n","\n","    # Plot the training and validation accuracy for the final epoch\n","    for client in final_epoch_df['client_number'].unique():\n","        client_df = final_epoch_df[final_epoch_df['client_number'] == client].dropna(subset=['accuracy', 'val_accuracy'])\n","        if not client_df.empty:\n","            line, = axes[0].plot(client_df.index, client_df['accuracy'], label=f'Client {client}', alpha=0.6, color=palette[client], linewidth=2.0)\n","            axes[1].plot(client_df.index, client_df['val_accuracy'], label=f'Client {client}', alpha=0.6, color=palette[client], linewidth=2.0)\n","\n","            if len(lines) < final_epoch_df['client_number'].nunique():\n","                lines.append(line)\n","                labels.append(f'Client {client}')\n","\n","    axes[0].set_title(f'Training Accuracy (Epoch {final_epoch})', fontsize=12, fontweight='bold')\n","    axes[0].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","\n","    axes[1].set_title(f'Validation Accuracy (Epoch {final_epoch})', fontsize=12, fontweight='bold')\n","\n","\n","    for ax in axes:\n","        ax.set_xlabel('Steps', fontsize=10, fontweight='bold')\n","        ax.grid(True)\n","        ax.tick_params(axis='both', which='major', labelsize=10)\n","\n","    # Add a single legend for the entire figure\n","    fig.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, 1.05), ncol=len(labels), fontsize=10, frameon=True)\n","\n","    plt.tight_layout(rect=[0.05, 0.05, 1, 0.95])\n","    plt.subplots_adjust(hspace=0.2, top=0.85)  # Add some space between the rows and reduce space between the legend and plot\n","\n","    # Save the figure in high DPI PNG and PDF\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    fig.savefig(os.path.join(output_dir, 'final_epoch_accuracy_plot.png'), dpi=300, format='png')\n","    fig.savefig(os.path.join(output_dir, 'final_epoch_accuracy_plot.pdf'), dpi=300, format='pdf')\n","\n","    plt.show()\n","\n","# Directory where CSV logs are saved\n","log_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Theta'\n","\n","# Output directory for saving plots\n","output_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Theta/plots'\n","\n","# Number of clients and local epochs\n","num_clients = 3\n","local_epochs = 5\n","\n","# Read logs and generate the dataframe\n","all_metrics_df = read_logs(log_dir, num_clients, local_epochs)\n","\n","# Plot the accuracy for the final epoch\n","plot_final_epoch_accuracy(all_metrics_df, output_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"id":"NlC1cJDfRFjG","executionInfo":{"status":"ok","timestamp":1716752185517,"user_tz":-360,"elapsed":3105,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}},"outputId":"2242a445-3bb9-4d84-f492-92bc7f4614c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Final Epoch: 4\n","Average Training Accuracy: 0.9229\n","Average Validation Accuracy: 0.7394\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x450 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"QUuWzfMHSNmi"},"source":["# CNN"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"8xrx_fxBSWGd","executionInfo":{"status":"ok","timestamp":1717432520321,"user_tz":-360,"elapsed":18,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    # model.add(Dropout(0.5))\n","    # model.add(LSTM(256, return_sequences=True))\n","    # model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Theta/CNN/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Theta/CNN/training_log_{run_name}.csv', append=True, separator=';')\n","\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":867312,"status":"ok","timestamp":1717433387615,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"},"user_tz":-360},"id":"H1TaNdIbSfkq","outputId":"0df0b882-ee05-47ea-d85e-43c53ac8cac4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 4s 33ms/step - loss: 1.7699 - accuracy: 0.5383 - val_loss: 1.7679 - val_accuracy: 0.5205\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 1.7679 - accuracy: 0.5312"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 17ms/step - loss: 1.7550 - accuracy: 0.5436 - val_loss: 1.7575 - val_accuracy: 0.5550\n","Epoch 3/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.7431 - accuracy: 0.5598 - val_loss: 1.7473 - val_accuracy: 0.5754\n","Epoch 4/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.7315 - accuracy: 0.5744 - val_loss: 1.7371 - val_accuracy: 0.5679\n","Epoch 5/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.7203 - accuracy: 0.5776 - val_loss: 1.7271 - val_accuracy: 0.5657\n","Epoch 6/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.7087 - accuracy: 0.5808 - val_loss: 1.7171 - val_accuracy: 0.5668\n","Epoch 7/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.6977 - accuracy: 0.5862 - val_loss: 1.7070 - val_accuracy: 0.5679\n","Epoch 8/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.6862 - accuracy: 0.5851 - val_loss: 1.6975 - val_accuracy: 0.5582\n","Epoch 9/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.6746 - accuracy: 0.5932 - val_loss: 1.6876 - val_accuracy: 0.5690\n","Epoch 10/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.6635 - accuracy: 0.5967 - val_loss: 1.6776 - val_accuracy: 0.5711\n","Epoch 11/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.6523 - accuracy: 0.5973 - val_loss: 1.6679 - val_accuracy: 0.5776\n","Epoch 12/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.6410 - accuracy: 0.6056 - val_loss: 1.6575 - val_accuracy: 0.5851\n","Epoch 13/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.6305 - accuracy: 0.6013 - val_loss: 1.6486 - val_accuracy: 0.5787\n","Epoch 14/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.6196 - accuracy: 0.6061 - val_loss: 1.6383 - val_accuracy: 0.5851\n","Epoch 15/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.6092 - accuracy: 0.6078 - val_loss: 1.6279 - val_accuracy: 0.5722\n","Epoch 16/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.5988 - accuracy: 0.6083 - val_loss: 1.6180 - val_accuracy: 0.5754\n","Epoch 17/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.5887 - accuracy: 0.6148 - val_loss: 1.6073 - val_accuracy: 0.5700\n","Epoch 18/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.5776 - accuracy: 0.6177 - val_loss: 1.6006 - val_accuracy: 0.5744\n","Epoch 19/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5697 - accuracy: 0.6207 - val_loss: 1.5881 - val_accuracy: 0.5841\n","Epoch 20/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.5592 - accuracy: 0.6220 - val_loss: 1.5780 - val_accuracy: 0.5905\n","Epoch 21/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.5493 - accuracy: 0.6226 - val_loss: 1.5688 - val_accuracy: 0.5884\n","Epoch 22/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.5410 - accuracy: 0.6177 - val_loss: 1.5600 - val_accuracy: 0.5894\n","Epoch 23/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.5327 - accuracy: 0.6218 - val_loss: 1.5519 - val_accuracy: 0.5808\n","Epoch 24/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.5224 - accuracy: 0.6282 - val_loss: 1.5429 - val_accuracy: 0.5862\n","Epoch 25/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.5134 - accuracy: 0.6317 - val_loss: 1.5351 - val_accuracy: 0.5905\n","Epoch 26/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5056 - accuracy: 0.6307 - val_loss: 1.5265 - val_accuracy: 0.5873\n","Epoch 27/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.4964 - accuracy: 0.6298 - val_loss: 1.5189 - val_accuracy: 0.5970\n","Epoch 28/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4875 - accuracy: 0.6377 - val_loss: 1.5113 - val_accuracy: 0.5959\n","Epoch 29/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4800 - accuracy: 0.6336 - val_loss: 1.5049 - val_accuracy: 0.5927\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4705 - accuracy: 0.6379 - val_loss: 1.4971 - val_accuracy: 0.5959\n","Epoch 31/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.4631 - accuracy: 0.6404 - val_loss: 1.4901 - val_accuracy: 0.5991\n","Epoch 32/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4539 - accuracy: 0.6455 - val_loss: 1.4851 - val_accuracy: 0.5927\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4452 - accuracy: 0.6466 - val_loss: 1.4764 - val_accuracy: 0.5970\n","Epoch 34/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.4380 - accuracy: 0.6433 - val_loss: 1.4706 - val_accuracy: 0.5938\n","Epoch 35/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.4297 - accuracy: 0.6449 - val_loss: 1.4628 - val_accuracy: 0.6002\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4233 - accuracy: 0.6484 - val_loss: 1.4573 - val_accuracy: 0.5981\n","Epoch 37/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.4130 - accuracy: 0.6530 - val_loss: 1.4494 - val_accuracy: 0.6002\n","Epoch 38/100\n","29/29 [==============================] - 1s 36ms/step - loss: 1.4058 - accuracy: 0.6474 - val_loss: 1.4431 - val_accuracy: 0.6024\n","Epoch 39/100\n","29/29 [==============================] - 1s 49ms/step - loss: 1.3983 - accuracy: 0.6506 - val_loss: 1.4372 - val_accuracy: 0.6034\n","Epoch 40/100\n","29/29 [==============================] - 1s 41ms/step - loss: 1.3902 - accuracy: 0.6541 - val_loss: 1.4321 - val_accuracy: 0.6067\n","Epoch 41/100\n","29/29 [==============================] - 1s 31ms/step - loss: 1.3821 - accuracy: 0.6562 - val_loss: 1.4248 - val_accuracy: 0.6045\n","Epoch 42/100\n","29/29 [==============================] - 1s 34ms/step - loss: 1.3755 - accuracy: 0.6603 - val_loss: 1.4195 - val_accuracy: 0.6131\n","Epoch 43/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.3658 - accuracy: 0.6565 - val_loss: 1.4145 - val_accuracy: 0.6099\n","Epoch 44/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.3594 - accuracy: 0.6616 - val_loss: 1.4091 - val_accuracy: 0.6099\n","Epoch 45/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.3504 - accuracy: 0.6646 - val_loss: 1.4026 - val_accuracy: 0.6175\n","Epoch 46/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3436 - accuracy: 0.6654 - val_loss: 1.3975 - val_accuracy: 0.6056\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3356 - accuracy: 0.6713 - val_loss: 1.3919 - val_accuracy: 0.6099\n","Epoch 48/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.3276 - accuracy: 0.6713 - val_loss: 1.3858 - val_accuracy: 0.6207\n","Epoch 49/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.3198 - accuracy: 0.6719 - val_loss: 1.3797 - val_accuracy: 0.6121\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3109 - accuracy: 0.6751 - val_loss: 1.3793 - val_accuracy: 0.6067\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3026 - accuracy: 0.6837 - val_loss: 1.3716 - val_accuracy: 0.6078\n","Epoch 52/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.2958 - accuracy: 0.6813 - val_loss: 1.3670 - val_accuracy: 0.6153\n","Epoch 53/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2898 - accuracy: 0.6851 - val_loss: 1.3623 - val_accuracy: 0.6131\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2813 - accuracy: 0.6853 - val_loss: 1.3592 - val_accuracy: 0.6153\n","Epoch 55/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2719 - accuracy: 0.6872 - val_loss: 1.3530 - val_accuracy: 0.6110\n","Epoch 56/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.2645 - accuracy: 0.6872 - val_loss: 1.3509 - val_accuracy: 0.5981\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2556 - accuracy: 0.6977 - val_loss: 1.3431 - val_accuracy: 0.6099\n","Epoch 58/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2481 - accuracy: 0.6961 - val_loss: 1.3411 - val_accuracy: 0.6142\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2410 - accuracy: 0.6977 - val_loss: 1.3366 - val_accuracy: 0.6099\n","Epoch 60/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.2330 - accuracy: 0.7020 - val_loss: 1.3308 - val_accuracy: 0.6121\n","Epoch 61/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2254 - accuracy: 0.7039 - val_loss: 1.3288 - val_accuracy: 0.6131\n","Epoch 62/100\n","29/29 [==============================] - 1s 32ms/step - loss: 1.2187 - accuracy: 0.7082 - val_loss: 1.3245 - val_accuracy: 0.6067\n","Epoch 63/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.2102 - accuracy: 0.7107 - val_loss: 1.3260 - val_accuracy: 0.6024\n","Epoch 64/100\n","29/29 [==============================] - 1s 34ms/step - loss: 1.2050 - accuracy: 0.7077 - val_loss: 1.3366 - val_accuracy: 0.5948\n","Epoch 65/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1973 - accuracy: 0.7104 - val_loss: 1.3159 - val_accuracy: 0.6088\n","Epoch 66/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.1886 - accuracy: 0.7179 - val_loss: 1.3170 - val_accuracy: 0.6067\n","Epoch 67/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1828 - accuracy: 0.7131 - val_loss: 1.3121 - val_accuracy: 0.6164\n","Epoch 68/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1748 - accuracy: 0.7169 - val_loss: 1.3064 - val_accuracy: 0.6121\n","Epoch 69/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1676 - accuracy: 0.7214 - val_loss: 1.3094 - val_accuracy: 0.5970\n","Epoch 70/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.1585 - accuracy: 0.7268 - val_loss: 1.3051 - val_accuracy: 0.6078\n","Epoch 71/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.1541 - accuracy: 0.7179 - val_loss: 1.3039 - val_accuracy: 0.6164\n","Epoch 72/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1452 - accuracy: 0.7349 - val_loss: 1.2958 - val_accuracy: 0.6034\n","Epoch 73/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1368 - accuracy: 0.7336 - val_loss: 1.2966 - val_accuracy: 0.6164\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1299 - accuracy: 0.7381 - val_loss: 1.2946 - val_accuracy: 0.6142\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1235 - accuracy: 0.7341 - val_loss: 1.2940 - val_accuracy: 0.6110\n","Epoch 76/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1167 - accuracy: 0.7363 - val_loss: 1.2870 - val_accuracy: 0.6131\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1076 - accuracy: 0.7492 - val_loss: 1.2902 - val_accuracy: 0.6002\n","Epoch 78/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1031 - accuracy: 0.7468 - val_loss: 1.2886 - val_accuracy: 0.6110\n","Epoch 79/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0990 - accuracy: 0.7416 - val_loss: 1.2868 - val_accuracy: 0.6142\n","Epoch 80/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0902 - accuracy: 0.7446 - val_loss: 1.2830 - val_accuracy: 0.6088\n","Epoch 81/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0813 - accuracy: 0.7530 - val_loss: 1.2845 - val_accuracy: 0.5981\n","Epoch 82/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0749 - accuracy: 0.7489 - val_loss: 1.2778 - val_accuracy: 0.6088\n","Epoch 83/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0678 - accuracy: 0.7567 - val_loss: 1.2872 - val_accuracy: 0.6024\n","Epoch 84/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0631 - accuracy: 0.7548 - val_loss: 1.2829 - val_accuracy: 0.6034\n","Epoch 85/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0571 - accuracy: 0.7527 - val_loss: 1.2825 - val_accuracy: 0.6024\n","Epoch 86/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0492 - accuracy: 0.7581 - val_loss: 1.2854 - val_accuracy: 0.6013\n","Epoch 87/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0420 - accuracy: 0.7662 - val_loss: 1.2808 - val_accuracy: 0.6088\n","Epoch 88/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0361 - accuracy: 0.7659 - val_loss: 1.2804 - val_accuracy: 0.5970\n","Epoch 89/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0281 - accuracy: 0.7680 - val_loss: 1.2782 - val_accuracy: 0.5991\n","Epoch 90/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0207 - accuracy: 0.7718 - val_loss: 1.2877 - val_accuracy: 0.6034\n","Epoch 91/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0174 - accuracy: 0.7716 - val_loss: 1.2904 - val_accuracy: 0.6078\n","Epoch 92/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0131 - accuracy: 0.7672 - val_loss: 1.2891 - val_accuracy: 0.6088\n","Epoch 93/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0077 - accuracy: 0.7724 - val_loss: 1.2783 - val_accuracy: 0.5991\n","Epoch 94/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9991 - accuracy: 0.7753 - val_loss: 1.2843 - val_accuracy: 0.6056\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9912 - accuracy: 0.7815 - val_loss: 1.2820 - val_accuracy: 0.6056\n","Epoch 96/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9900 - accuracy: 0.7799 - val_loss: 1.2825 - val_accuracy: 0.6045\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9793 - accuracy: 0.7783 - val_loss: 1.2843 - val_accuracy: 0.6078\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9738 - accuracy: 0.7864 - val_loss: 1.2806 - val_accuracy: 0.6088\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9681 - accuracy: 0.7872 - val_loss: 1.2854 - val_accuracy: 0.6067\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9609 - accuracy: 0.7904 - val_loss: 1.2818 - val_accuracy: 0.6067\n","{'loss': [1.76993727684021, 1.7549554109573364, 1.7430933713912964, 1.7315289974212646, 1.72026526927948, 1.7087401151657104, 1.6976802349090576, 1.6862446069717407, 1.674631953239441, 1.663494348526001, 1.652299165725708, 1.6410431861877441, 1.630460500717163, 1.6195836067199707, 1.6092374324798584, 1.598756194114685, 1.588685393333435, 1.5775989294052124, 1.5696982145309448, 1.5591976642608643, 1.549255132675171, 1.540988802909851, 1.5327389240264893, 1.5223681926727295, 1.5134193897247314, 1.5056499242782593, 1.4964449405670166, 1.48746919631958, 1.4799726009368896, 1.4704643487930298, 1.4630615711212158, 1.4538501501083374, 1.4451682567596436, 1.4379539489746094, 1.4296621084213257, 1.423311710357666, 1.4130120277404785, 1.40575110912323, 1.3982815742492676, 1.3901643753051758, 1.382056474685669, 1.3754968643188477, 1.3657937049865723, 1.3593547344207764, 1.3503731489181519, 1.343614101409912, 1.3355621099472046, 1.327630877494812, 1.319778323173523, 1.3108627796173096, 1.3026208877563477, 1.2958029508590698, 1.2897748947143555, 1.2812960147857666, 1.27194344997406, 1.2644667625427246, 1.2556354999542236, 1.2481324672698975, 1.2409604787826538, 1.2330255508422852, 1.2253586053848267, 1.2187068462371826, 1.2102125883102417, 1.2050281763076782, 1.1973258256912231, 1.188626766204834, 1.182753086090088, 1.1748156547546387, 1.167647361755371, 1.1585172414779663, 1.1541259288787842, 1.1452422142028809, 1.1368352174758911, 1.129878044128418, 1.1235055923461914, 1.116745114326477, 1.1075879335403442, 1.1030789613723755, 1.0990008115768433, 1.0902000665664673, 1.081337571144104, 1.0748978853225708, 1.0678430795669556, 1.063085675239563, 1.0571361780166626, 1.0492151975631714, 1.0419719219207764, 1.0360625982284546, 1.0281364917755127, 1.0207287073135376, 1.0174181461334229, 1.0130996704101562, 1.007658839225769, 0.999137818813324, 0.9912117719650269, 0.989961564540863, 0.979304850101471, 0.9738109111785889, 0.968092143535614, 0.9609068632125854], 'accuracy': [0.5382543206214905, 0.5436422228813171, 0.5598060488700867, 0.5743534564971924, 0.5775862336158752, 0.5808189511299133, 0.5862069129943848, 0.5851293206214905, 0.5932112336158752, 0.5967133641242981, 0.5972521305084229, 0.6056034564971924, 0.6012930870056152, 0.6061422228813171, 0.607758641242981, 0.6082974076271057, 0.6147629022598267, 0.6177262663841248, 0.6206896305084229, 0.6220366358757019, 0.6225754022598267, 0.6177262663841248, 0.6217672228813171, 0.6282327771186829, 0.6317349076271057, 0.6306573152542114, 0.6298491358757019, 0.6376616358757019, 0.6336206793785095, 0.6379310488700867, 0.6403555870056152, 0.6454741358757019, 0.6465517282485962, 0.6433189511299133, 0.6449353694915771, 0.6484375, 0.6530172228813171, 0.6473599076271057, 0.6505926847457886, 0.6540948152542114, 0.65625, 0.6602909564971924, 0.6565194129943848, 0.6616379022598267, 0.6646012663841248, 0.665409505367279, 0.6713362336158752, 0.6713362336158752, 0.671875, 0.6751077771186829, 0.6837284564971924, 0.681303858757019, 0.6850754022598267, 0.6853448152542114, 0.6872305870056152, 0.6872305870056152, 0.6977370977401733, 0.6961206793785095, 0.6977370977401733, 0.7020474076271057, 0.7039331793785095, 0.7082435488700867, 0.7106680870056152, 0.7077047228813171, 0.7103987336158752, 0.7179418206214905, 0.7130926847457886, 0.7168642282485962, 0.7214439511299133, 0.7268319129943848, 0.7179418206214905, 0.7349137663841248, 0.7335668206214905, 0.7381465435028076, 0.7341055870056152, 0.7362607717514038, 0.7491918206214905, 0.7467672228813171, 0.7416487336158752, 0.7446120977401733, 0.7529633641242981, 0.7489224076271057, 0.7567349076271057, 0.7548491358757019, 0.7526939511299133, 0.7580819129943848, 0.7661637663841248, 0.7658944129943848, 0.7680495977401733, 0.771821141242981, 0.7715517282485962, 0.767241358757019, 0.7723599076271057, 0.7753232717514038, 0.7815194129943848, 0.779902994632721, 0.7782866358757019, 0.7863685488700867, 0.7871767282485962, 0.790409505367279], 'val_loss': [1.7678968906402588, 1.7575170993804932, 1.747261881828308, 1.7371373176574707, 1.7271108627319336, 1.7170597314834595, 1.7070270776748657, 1.6974650621414185, 1.6875512599945068, 1.6775838136672974, 1.667858600616455, 1.6575334072113037, 1.648551106452942, 1.6382501125335693, 1.627879023551941, 1.6180109977722168, 1.6072759628295898, 1.6006009578704834, 1.588140845298767, 1.5779706239700317, 1.5687634944915771, 1.5600004196166992, 1.551916241645813, 1.542907476425171, 1.5350959300994873, 1.5265249013900757, 1.5188875198364258, 1.511346459388733, 1.5048736333847046, 1.4970535039901733, 1.4901492595672607, 1.4851008653640747, 1.4764386415481567, 1.4705554246902466, 1.4627739191055298, 1.457302212715149, 1.4493908882141113, 1.4430842399597168, 1.4371639490127563, 1.4320790767669678, 1.4248329401016235, 1.4195059537887573, 1.4144556522369385, 1.409123182296753, 1.4026092290878296, 1.3974847793579102, 1.3919367790222168, 1.3858399391174316, 1.3796573877334595, 1.3793046474456787, 1.3715600967407227, 1.3670378923416138, 1.3622931241989136, 1.3591623306274414, 1.353028416633606, 1.3508838415145874, 1.3430711030960083, 1.3410708904266357, 1.3365943431854248, 1.3307547569274902, 1.3287603855133057, 1.3244657516479492, 1.326005458831787, 1.3366435766220093, 1.3159047365188599, 1.3170305490493774, 1.312073826789856, 1.3063808679580688, 1.309443712234497, 1.30512535572052, 1.3039052486419678, 1.295827031135559, 1.2966372966766357, 1.294629693031311, 1.2939867973327637, 1.2869588136672974, 1.2901713848114014, 1.288596272468567, 1.2867839336395264, 1.2830067873001099, 1.2844973802566528, 1.27781081199646, 1.2871843576431274, 1.2828953266143799, 1.2825407981872559, 1.285395860671997, 1.2807844877243042, 1.280432105064392, 1.2781847715377808, 1.287719964981079, 1.2904396057128906, 1.2891215085983276, 1.2783337831497192, 1.28427255153656, 1.2819547653198242, 1.2825368642807007, 1.2843188047409058, 1.280619502067566, 1.285431981086731, 1.281796932220459], 'val_accuracy': [0.5204741358757019, 0.5549569129943848, 0.5754310488700867, 0.5678879022598267, 0.5657327771186829, 0.5668103694915771, 0.5678879022598267, 0.5581896305084229, 0.568965494632721, 0.5711206793785095, 0.5775862336158752, 0.5851293206214905, 0.5786637663841248, 0.5851293206214905, 0.5721982717514038, 0.5754310488700867, 0.5700430870056152, 0.5743534564971924, 0.5840517282485962, 0.5905172228813171, 0.5883620977401733, 0.5894396305084229, 0.5808189511299133, 0.5862069129943848, 0.5905172228813171, 0.587284505367279, 0.5969827771186829, 0.5959051847457886, 0.5926724076271057, 0.5959051847457886, 0.5991379022598267, 0.5926724076271057, 0.5969827771186829, 0.59375, 0.600215494632721, 0.5980603694915771, 0.600215494632721, 0.6023706793785095, 0.6034482717514038, 0.6066810488700867, 0.6045258641242981, 0.6131465435028076, 0.6099137663841248, 0.6099137663841248, 0.6174569129943848, 0.6056034564971924, 0.6099137663841248, 0.6206896305084229, 0.6120689511299133, 0.6066810488700867, 0.607758641242981, 0.6153017282485962, 0.6131465435028076, 0.6153017282485962, 0.610991358757019, 0.5980603694915771, 0.6099137663841248, 0.6142241358757019, 0.6099137663841248, 0.6120689511299133, 0.6131465435028076, 0.6066810488700867, 0.6023706793785095, 0.5948275923728943, 0.6088362336158752, 0.6066810488700867, 0.6163793206214905, 0.6120689511299133, 0.5969827771186829, 0.607758641242981, 0.6163793206214905, 0.6034482717514038, 0.6163793206214905, 0.6142241358757019, 0.610991358757019, 0.6131465435028076, 0.600215494632721, 0.610991358757019, 0.6142241358757019, 0.6088362336158752, 0.5980603694915771, 0.6088362336158752, 0.6023706793785095, 0.6034482717514038, 0.6023706793785095, 0.6012930870056152, 0.6088362336158752, 0.5969827771186829, 0.5991379022598267, 0.6034482717514038, 0.607758641242981, 0.6088362336158752, 0.5991379022598267, 0.6056034564971924, 0.6056034564971924, 0.6045258641242981, 0.607758641242981, 0.6088362336158752, 0.6066810488700867, 0.6066810488700867]}\n","38/38 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 3s 29ms/step - loss: 1.7712 - accuracy: 0.5433 - val_loss: 1.7683 - val_accuracy: 0.5622\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 1.7569 - accuracy: 0.5781"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 1s 18ms/step - loss: 1.7568 - accuracy: 0.5357 - val_loss: 1.7583 - val_accuracy: 0.5724\n","Epoch 3/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.7451 - accuracy: 0.5509 - val_loss: 1.7484 - val_accuracy: 0.5588\n","Epoch 4/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.7340 - accuracy: 0.5634 - val_loss: 1.7387 - val_accuracy: 0.5441\n","Epoch 5/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.7229 - accuracy: 0.5733 - val_loss: 1.7291 - val_accuracy: 0.5498\n","Epoch 6/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.7118 - accuracy: 0.5719 - val_loss: 1.7195 - val_accuracy: 0.5430\n","Epoch 7/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.7010 - accuracy: 0.5756 - val_loss: 1.7099 - val_accuracy: 0.5475\n","Epoch 8/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6902 - accuracy: 0.5815 - val_loss: 1.7007 - val_accuracy: 0.5452\n","Epoch 9/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.6793 - accuracy: 0.5840 - val_loss: 1.6911 - val_accuracy: 0.5452\n","Epoch 10/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.6687 - accuracy: 0.5905 - val_loss: 1.6818 - val_accuracy: 0.5509\n","Epoch 11/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6583 - accuracy: 0.5954 - val_loss: 1.6724 - val_accuracy: 0.5566\n","Epoch 12/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.6477 - accuracy: 0.6005 - val_loss: 1.6632 - val_accuracy: 0.5532\n","Epoch 13/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.6370 - accuracy: 0.6002 - val_loss: 1.6539 - val_accuracy: 0.5566\n","Epoch 14/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.6267 - accuracy: 0.6084 - val_loss: 1.6440 - val_accuracy: 0.5735\n","Epoch 15/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.6165 - accuracy: 0.6092 - val_loss: 1.6350 - val_accuracy: 0.5735\n","Epoch 16/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6066 - accuracy: 0.6087 - val_loss: 1.6270 - val_accuracy: 0.5600\n","Epoch 17/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.5969 - accuracy: 0.6087 - val_loss: 1.6164 - val_accuracy: 0.5803\n","Epoch 18/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.5878 - accuracy: 0.6129 - val_loss: 1.6044 - val_accuracy: 0.5792\n","Epoch 19/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5780 - accuracy: 0.6112 - val_loss: 1.5969 - val_accuracy: 0.5747\n","Epoch 20/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.5682 - accuracy: 0.6129 - val_loss: 1.5886 - val_accuracy: 0.5814\n","Epoch 21/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5592 - accuracy: 0.6163 - val_loss: 1.5838 - val_accuracy: 0.5690\n","Epoch 22/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5506 - accuracy: 0.6214 - val_loss: 1.5706 - val_accuracy: 0.5735\n","Epoch 23/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.5422 - accuracy: 0.6171 - val_loss: 1.5623 - val_accuracy: 0.5747\n","Epoch 24/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5329 - accuracy: 0.6237 - val_loss: 1.5556 - val_accuracy: 0.5758\n","Epoch 25/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5263 - accuracy: 0.6197 - val_loss: 1.5477 - val_accuracy: 0.5781\n","Epoch 26/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5160 - accuracy: 0.6231 - val_loss: 1.5395 - val_accuracy: 0.5769\n","Epoch 27/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.5069 - accuracy: 0.6254 - val_loss: 1.5347 - val_accuracy: 0.5792\n","Epoch 28/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4987 - accuracy: 0.6248 - val_loss: 1.5305 - val_accuracy: 0.5826\n","Epoch 29/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.4907 - accuracy: 0.6239 - val_loss: 1.5224 - val_accuracy: 0.5758\n","Epoch 30/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4834 - accuracy: 0.6287 - val_loss: 1.5148 - val_accuracy: 0.5848\n","Epoch 31/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4739 - accuracy: 0.6313 - val_loss: 1.5074 - val_accuracy: 0.5837\n","Epoch 32/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4671 - accuracy: 0.6338 - val_loss: 1.5001 - val_accuracy: 0.5860\n","Epoch 33/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4578 - accuracy: 0.6327 - val_loss: 1.4954 - val_accuracy: 0.5905\n","Epoch 34/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4507 - accuracy: 0.6372 - val_loss: 1.4873 - val_accuracy: 0.5860\n","Epoch 35/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4432 - accuracy: 0.6347 - val_loss: 1.4833 - val_accuracy: 0.5860\n","Epoch 36/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4355 - accuracy: 0.6387 - val_loss: 1.4759 - val_accuracy: 0.5848\n","Epoch 37/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4270 - accuracy: 0.6471 - val_loss: 1.4719 - val_accuracy: 0.5905\n","Epoch 38/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4190 - accuracy: 0.6449 - val_loss: 1.4672 - val_accuracy: 0.5984\n","Epoch 39/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4116 - accuracy: 0.6440 - val_loss: 1.4595 - val_accuracy: 0.5905\n","Epoch 40/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4039 - accuracy: 0.6466 - val_loss: 1.4531 - val_accuracy: 0.5939\n","Epoch 41/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.3969 - accuracy: 0.6500 - val_loss: 1.4496 - val_accuracy: 0.5928\n","Epoch 42/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.3883 - accuracy: 0.6556 - val_loss: 1.4438 - val_accuracy: 0.5973\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3815 - accuracy: 0.6471 - val_loss: 1.4414 - val_accuracy: 0.6018\n","Epoch 44/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.3742 - accuracy: 0.6500 - val_loss: 1.4320 - val_accuracy: 0.5939\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3656 - accuracy: 0.6551 - val_loss: 1.4253 - val_accuracy: 0.5905\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3581 - accuracy: 0.6582 - val_loss: 1.4236 - val_accuracy: 0.5973\n","Epoch 47/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.3525 - accuracy: 0.6539 - val_loss: 1.4211 - val_accuracy: 0.6052\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3436 - accuracy: 0.6641 - val_loss: 1.4185 - val_accuracy: 0.6041\n","Epoch 49/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3391 - accuracy: 0.6559 - val_loss: 1.4059 - val_accuracy: 0.5916\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3284 - accuracy: 0.6627 - val_loss: 1.4013 - val_accuracy: 0.5984\n","Epoch 51/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3207 - accuracy: 0.6675 - val_loss: 1.3980 - val_accuracy: 0.6041\n","Epoch 52/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3133 - accuracy: 0.6686 - val_loss: 1.3907 - val_accuracy: 0.5939\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3044 - accuracy: 0.6720 - val_loss: 1.3884 - val_accuracy: 0.6052\n","Epoch 54/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2985 - accuracy: 0.6715 - val_loss: 1.3826 - val_accuracy: 0.6052\n","Epoch 55/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2914 - accuracy: 0.6763 - val_loss: 1.3777 - val_accuracy: 0.6007\n","Epoch 56/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2833 - accuracy: 0.6769 - val_loss: 1.3759 - val_accuracy: 0.6154\n","Epoch 57/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.2762 - accuracy: 0.6732 - val_loss: 1.3691 - val_accuracy: 0.5995\n","Epoch 58/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2684 - accuracy: 0.6763 - val_loss: 1.3638 - val_accuracy: 0.6029\n","Epoch 59/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2603 - accuracy: 0.6836 - val_loss: 1.3616 - val_accuracy: 0.6075\n","Epoch 60/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.2542 - accuracy: 0.6842 - val_loss: 1.3560 - val_accuracy: 0.6075\n","Epoch 61/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2478 - accuracy: 0.6851 - val_loss: 1.3562 - val_accuracy: 0.6143\n","Epoch 62/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.2384 - accuracy: 0.6885 - val_loss: 1.3503 - val_accuracy: 0.6120\n","Epoch 63/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.2293 - accuracy: 0.6952 - val_loss: 1.3487 - val_accuracy: 0.6154\n","Epoch 64/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.2224 - accuracy: 0.6967 - val_loss: 1.3420 - val_accuracy: 0.6086\n","Epoch 65/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2171 - accuracy: 0.6986 - val_loss: 1.3402 - val_accuracy: 0.6143\n","Epoch 66/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.2109 - accuracy: 0.6961 - val_loss: 1.3325 - val_accuracy: 0.6052\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2011 - accuracy: 0.7054 - val_loss: 1.3355 - val_accuracy: 0.6210\n","Epoch 68/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1959 - accuracy: 0.7026 - val_loss: 1.3302 - val_accuracy: 0.6165\n","Epoch 69/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1901 - accuracy: 0.7074 - val_loss: 1.3250 - val_accuracy: 0.6097\n","Epoch 70/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1848 - accuracy: 0.7071 - val_loss: 1.3269 - val_accuracy: 0.6210\n","Epoch 71/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1745 - accuracy: 0.7162 - val_loss: 1.3206 - val_accuracy: 0.6210\n","Epoch 72/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1678 - accuracy: 0.7182 - val_loss: 1.3166 - val_accuracy: 0.6176\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1601 - accuracy: 0.7193 - val_loss: 1.3246 - val_accuracy: 0.6256\n","Epoch 74/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1553 - accuracy: 0.7159 - val_loss: 1.3140 - val_accuracy: 0.6143\n","Epoch 75/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1464 - accuracy: 0.7227 - val_loss: 1.3176 - val_accuracy: 0.6256\n","Epoch 76/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1454 - accuracy: 0.7182 - val_loss: 1.3084 - val_accuracy: 0.6176\n","Epoch 77/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1394 - accuracy: 0.7184 - val_loss: 1.3074 - val_accuracy: 0.6222\n","Epoch 78/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1262 - accuracy: 0.7298 - val_loss: 1.3046 - val_accuracy: 0.6154\n","Epoch 79/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1245 - accuracy: 0.7230 - val_loss: 1.3045 - val_accuracy: 0.6222\n","Epoch 80/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1175 - accuracy: 0.7275 - val_loss: 1.3045 - val_accuracy: 0.6199\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1072 - accuracy: 0.7340 - val_loss: 1.3085 - val_accuracy: 0.6290\n","Epoch 82/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1001 - accuracy: 0.7388 - val_loss: 1.2946 - val_accuracy: 0.6233\n","Epoch 83/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0966 - accuracy: 0.7434 - val_loss: 1.2977 - val_accuracy: 0.6278\n","Epoch 84/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0892 - accuracy: 0.7425 - val_loss: 1.2990 - val_accuracy: 0.6233\n","Epoch 85/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0815 - accuracy: 0.7465 - val_loss: 1.2932 - val_accuracy: 0.6222\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0748 - accuracy: 0.7496 - val_loss: 1.2921 - val_accuracy: 0.6244\n","Epoch 87/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.0657 - accuracy: 0.7516 - val_loss: 1.2906 - val_accuracy: 0.6324\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0615 - accuracy: 0.7544 - val_loss: 1.2884 - val_accuracy: 0.6188\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0543 - accuracy: 0.7544 - val_loss: 1.2867 - val_accuracy: 0.6301\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0469 - accuracy: 0.7612 - val_loss: 1.2901 - val_accuracy: 0.6267\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0420 - accuracy: 0.7598 - val_loss: 1.2894 - val_accuracy: 0.6267\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0349 - accuracy: 0.7651 - val_loss: 1.2857 - val_accuracy: 0.6324\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0283 - accuracy: 0.7663 - val_loss: 1.2936 - val_accuracy: 0.6222\n","Epoch 94/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0239 - accuracy: 0.7677 - val_loss: 1.2929 - val_accuracy: 0.6188\n","Epoch 95/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0215 - accuracy: 0.7671 - val_loss: 1.2925 - val_accuracy: 0.6267\n","Epoch 96/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0116 - accuracy: 0.7699 - val_loss: 1.2892 - val_accuracy: 0.6176\n","Epoch 97/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0045 - accuracy: 0.7748 - val_loss: 1.2929 - val_accuracy: 0.6244\n","Epoch 98/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9962 - accuracy: 0.7773 - val_loss: 1.2865 - val_accuracy: 0.6222\n","Epoch 99/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9908 - accuracy: 0.7804 - val_loss: 1.2903 - val_accuracy: 0.6278\n","Epoch 100/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9862 - accuracy: 0.7810 - val_loss: 1.2945 - val_accuracy: 0.6188\n","{'loss': [1.771169900894165, 1.7568001747131348, 1.7451305389404297, 1.7339730262756348, 1.7228749990463257, 1.711816430091858, 1.701019287109375, 1.6901986598968506, 1.6793397665023804, 1.6686569452285767, 1.6582973003387451, 1.6476984024047852, 1.6370155811309814, 1.626702904701233, 1.6164512634277344, 1.6065590381622314, 1.5968513488769531, 1.5877840518951416, 1.5779509544372559, 1.568200707435608, 1.5591827630996704, 1.5505849123001099, 1.5422006845474243, 1.532868504524231, 1.526256799697876, 1.516021728515625, 1.5069384574890137, 1.4986557960510254, 1.4907433986663818, 1.4834014177322388, 1.4738584756851196, 1.467050313949585, 1.4577505588531494, 1.4507410526275635, 1.4431904554367065, 1.4355413913726807, 1.4270012378692627, 1.4189943075180054, 1.4116096496582031, 1.4038945436477661, 1.3968875408172607, 1.388278841972351, 1.3815041780471802, 1.3742327690124512, 1.3655954599380493, 1.358112096786499, 1.3524619340896606, 1.3435999155044556, 1.3390722274780273, 1.3283679485321045, 1.3206591606140137, 1.3132712841033936, 1.3043979406356812, 1.2984824180603027, 1.2914032936096191, 1.2833393812179565, 1.276175856590271, 1.268408179283142, 1.2603305578231812, 1.254172921180725, 1.2478044033050537, 1.2384244203567505, 1.2293341159820557, 1.2223503589630127, 1.2170946598052979, 1.2109122276306152, 1.201130747795105, 1.1959247589111328, 1.1900908946990967, 1.1848187446594238, 1.1745182275772095, 1.1677730083465576, 1.1601334810256958, 1.1552824974060059, 1.1463960409164429, 1.1454267501831055, 1.1394402980804443, 1.126183032989502, 1.1244633197784424, 1.1175299882888794, 1.1071852445602417, 1.1001392602920532, 1.0966167449951172, 1.089200496673584, 1.081451416015625, 1.074753761291504, 1.0656877756118774, 1.0614680051803589, 1.0542688369750977, 1.0468521118164062, 1.0420440435409546, 1.0349310636520386, 1.0282628536224365, 1.023866057395935, 1.021459937095642, 1.0115951299667358, 1.0044586658477783, 0.9961562156677246, 0.9907721281051636, 0.9862242937088013], 'accuracy': [0.5432937145233154, 0.5356536507606506, 0.5509337782859802, 0.5633842945098877, 0.573288083076477, 0.5718732476234436, 0.5755518078804016, 0.5814940333366394, 0.5840407609939575, 0.5905489325523376, 0.5953593850135803, 0.600452721118927, 0.6001697778701782, 0.6083757877349854, 0.6092246770858765, 0.6086587309837341, 0.6086587309837341, 0.6129032373428345, 0.6112054586410522, 0.6129032373428345, 0.6162987947463989, 0.6213921904563904, 0.61714768409729, 0.6236559152603149, 0.6196944117546082, 0.6230899691581726, 0.6253536939620972, 0.6247877478599548, 0.6239388585090637, 0.6287493109703064, 0.6312959790229797, 0.6338426470756531, 0.6327108144760132, 0.6372382640838623, 0.634691596031189, 0.6386530995368958, 0.6471420526504517, 0.6448783278465271, 0.644029438495636, 0.6465761065483093, 0.6499717235565186, 0.6556310057640076, 0.6471420526504517, 0.6499717235565186, 0.6550650596618652, 0.6581776738166809, 0.6539332270622253, 0.6641199588775635, 0.6559139490127563, 0.66270512342453, 0.6675155758857727, 0.6686474084854126, 0.6720430254936218, 0.6714770793914795, 0.6762874722480774, 0.6768534183502197, 0.6731748580932617, 0.6762874722480774, 0.6836445927619934, 0.6842105388641357, 0.6850594282150269, 0.6884549856185913, 0.695246160030365, 0.6966609954833984, 0.6986417770385742, 0.6960950493812561, 0.7054329514503479, 0.702603280544281, 0.7074136734008789, 0.7071307301521301, 0.7161856293678284, 0.7181664109230042, 0.719298243522644, 0.7159026861190796, 0.7226938605308533, 0.7181664109230042, 0.7184493541717529, 0.7297679781913757, 0.722976803779602, 0.7275042533874512, 0.7340124249458313, 0.738822877407074, 0.7433503270149231, 0.742501437664032, 0.7464629411697388, 0.7495755553245544, 0.7515563368797302, 0.7543859481811523, 0.7543859481811523, 0.761177122592926, 0.7597622871398926, 0.7651386260986328, 0.7662705183029175, 0.7676853537559509, 0.7671194076538086, 0.7699490785598755, 0.7747594714164734, 0.7773061394691467, 0.7804188132286072, 0.7809846997261047], 'val_loss': [1.768263816833496, 1.7582980394363403, 1.7484160661697388, 1.7387118339538574, 1.7290735244750977, 1.7194719314575195, 1.7099268436431885, 1.7006913423538208, 1.6911057233810425, 1.681756854057312, 1.672383189201355, 1.6632436513900757, 1.6538969278335571, 1.6439599990844727, 1.6349995136260986, 1.6270321607589722, 1.6163660287857056, 1.6043860912322998, 1.5969282388687134, 1.5886467695236206, 1.5837866067886353, 1.5705991983413696, 1.5623096227645874, 1.5556223392486572, 1.5477336645126343, 1.5395359992980957, 1.5346781015396118, 1.5304707288742065, 1.5224313735961914, 1.5148388147354126, 1.5073912143707275, 1.500105857849121, 1.4954265356063843, 1.4872729778289795, 1.4833241701126099, 1.4758918285369873, 1.471893310546875, 1.4672163724899292, 1.4594871997833252, 1.4530946016311646, 1.449556827545166, 1.4438285827636719, 1.441352128982544, 1.4319937229156494, 1.425253987312317, 1.4236124753952026, 1.4211372137069702, 1.4185137748718262, 1.4059137105941772, 1.401312232017517, 1.3979861736297607, 1.3907434940338135, 1.3883973360061646, 1.3826334476470947, 1.3777270317077637, 1.3759185075759888, 1.3691331148147583, 1.3638349771499634, 1.3616111278533936, 1.3560206890106201, 1.3561638593673706, 1.3503259420394897, 1.3486552238464355, 1.3420242071151733, 1.3402029275894165, 1.332493543624878, 1.3354696035385132, 1.3301520347595215, 1.324992299079895, 1.326854944229126, 1.3206197023391724, 1.316597819328308, 1.3246431350708008, 1.3140143156051636, 1.3175770044326782, 1.3084313869476318, 1.3074451684951782, 1.304600477218628, 1.3044893741607666, 1.304456353187561, 1.3084716796875, 1.2946425676345825, 1.297730565071106, 1.299038052558899, 1.2931755781173706, 1.292064905166626, 1.2905594110488892, 1.2883946895599365, 1.2867205142974854, 1.2901318073272705, 1.289387583732605, 1.2856884002685547, 1.2935744524002075, 1.2928553819656372, 1.292498230934143, 1.2892084121704102, 1.2929344177246094, 1.2865239381790161, 1.2902944087982178, 1.2945168018341064], 'val_accuracy': [0.5622171759605408, 0.5723981857299805, 0.5588235259056091, 0.5441176295280457, 0.5497737526893616, 0.5429864525794983, 0.5475113391876221, 0.5452488660812378, 0.5452488660812378, 0.5509049892425537, 0.5565611124038696, 0.5531674027442932, 0.5565611124038696, 0.5735294222831726, 0.5735294222831726, 0.5599547624588013, 0.5803167223930359, 0.5791855454444885, 0.5746606588363647, 0.581447958946228, 0.5690045356750488, 0.5735294222831726, 0.5746606588363647, 0.5757918357849121, 0.5780543088912964, 0.5769230723381042, 0.5791855454444885, 0.5825791954994202, 0.5757918357849121, 0.5848416090011597, 0.5837104320526123, 0.5859728455543518, 0.5904977321624756, 0.5859728455543518, 0.5859728455543518, 0.5848416090011597, 0.5904977321624756, 0.598416268825531, 0.5904977321624756, 0.5938913822174072, 0.5927602052688599, 0.5972850918769836, 0.6018099784851074, 0.5938913822174072, 0.5904977321624756, 0.5972850918769836, 0.6052036285400391, 0.6040723919868469, 0.5916289687156677, 0.598416268825531, 0.6040723919868469, 0.5938913822174072, 0.6052036285400391, 0.6052036285400391, 0.6006787419319153, 0.6153846383094788, 0.5995475053787231, 0.6029411554336548, 0.6074660420417786, 0.6074660420417786, 0.6142534017562866, 0.6119909286499023, 0.6153846383094788, 0.6085972785949707, 0.6142534017562866, 0.6052036285400391, 0.6210407018661499, 0.6165158152580261, 0.6097285151481628, 0.6210407018661499, 0.6210407018661499, 0.6176470518112183, 0.6255655884742737, 0.6142534017562866, 0.6255655884742737, 0.6176470518112183, 0.622171938419342, 0.6153846383094788, 0.622171938419342, 0.6199095249176025, 0.6289592981338501, 0.6233031749725342, 0.627828061580658, 0.6233031749725342, 0.622171938419342, 0.6244344115257263, 0.6323529481887817, 0.6187782883644104, 0.6300904750823975, 0.6266968250274658, 0.6266968250274658, 0.6323529481887817, 0.622171938419342, 0.6187782883644104, 0.6266968250274658, 0.6176470518112183, 0.6244344115257263, 0.622171938419342, 0.627828061580658, 0.6187782883644104]}\n","45/45 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 4s 30ms/step - loss: 1.7699 - accuracy: 0.5429 - val_loss: 1.7671 - val_accuracy: 0.5444\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 1s 17ms/step - loss: 1.7542 - accuracy: 0.5398 - val_loss: 1.7561 - val_accuracy: 0.5775\n","Epoch 3/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.7412 - accuracy: 0.5512 - val_loss: 1.7452 - val_accuracy: 0.5548\n","Epoch 4/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.7292 - accuracy: 0.5718 - val_loss: 1.7345 - val_accuracy: 0.5455\n","Epoch 5/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.7173 - accuracy: 0.5721 - val_loss: 1.7238 - val_accuracy: 0.5403\n","Epoch 6/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.7056 - accuracy: 0.5747 - val_loss: 1.7132 - val_accuracy: 0.5393\n","Epoch 7/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.6941 - accuracy: 0.5765 - val_loss: 1.7026 - val_accuracy: 0.5382\n","Epoch 8/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.6824 - accuracy: 0.5786 - val_loss: 1.6922 - val_accuracy: 0.5413\n","Epoch 9/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.6710 - accuracy: 0.5817 - val_loss: 1.6816 - val_accuracy: 0.5527\n","Epoch 10/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.6594 - accuracy: 0.5863 - val_loss: 1.6711 - val_accuracy: 0.5661\n","Epoch 11/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.6483 - accuracy: 0.5891 - val_loss: 1.6606 - val_accuracy: 0.5682\n","Epoch 12/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.6370 - accuracy: 0.5935 - val_loss: 1.6503 - val_accuracy: 0.5733\n","Epoch 13/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.6259 - accuracy: 0.5928 - val_loss: 1.6399 - val_accuracy: 0.5723\n","Epoch 14/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.6146 - accuracy: 0.5984 - val_loss: 1.6288 - val_accuracy: 0.5785\n","Epoch 15/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.6052 - accuracy: 0.5884 - val_loss: 1.6187 - val_accuracy: 0.5806\n","Epoch 16/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5930 - accuracy: 0.6065 - val_loss: 1.6077 - val_accuracy: 0.5806\n","Epoch 17/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.5826 - accuracy: 0.6078 - val_loss: 1.5978 - val_accuracy: 0.5847\n","Epoch 18/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.5726 - accuracy: 0.6080 - val_loss: 1.5874 - val_accuracy: 0.5868\n","Epoch 19/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.5634 - accuracy: 0.6111 - val_loss: 1.5776 - val_accuracy: 0.5899\n","Epoch 20/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.5524 - accuracy: 0.6183 - val_loss: 1.5680 - val_accuracy: 0.5806\n","Epoch 21/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.5424 - accuracy: 0.6127 - val_loss: 1.5587 - val_accuracy: 0.5930\n","Epoch 22/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.5329 - accuracy: 0.6196 - val_loss: 1.5492 - val_accuracy: 0.5857\n","Epoch 23/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.5231 - accuracy: 0.6196 - val_loss: 1.5407 - val_accuracy: 0.5847\n","Epoch 24/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.5138 - accuracy: 0.6155 - val_loss: 1.5334 - val_accuracy: 0.5888\n","Epoch 25/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.5058 - accuracy: 0.6171 - val_loss: 1.5256 - val_accuracy: 0.6002\n","Epoch 26/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.4959 - accuracy: 0.6202 - val_loss: 1.5170 - val_accuracy: 0.5981\n","Epoch 27/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.4862 - accuracy: 0.6212 - val_loss: 1.5090 - val_accuracy: 0.5888\n","Epoch 28/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.4762 - accuracy: 0.6261 - val_loss: 1.5013 - val_accuracy: 0.5961\n","Epoch 29/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.4678 - accuracy: 0.6271 - val_loss: 1.4952 - val_accuracy: 0.5961\n","Epoch 30/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.4592 - accuracy: 0.6320 - val_loss: 1.4864 - val_accuracy: 0.5971\n","Epoch 31/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4504 - accuracy: 0.6341 - val_loss: 1.4842 - val_accuracy: 0.6116\n","Epoch 32/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.4431 - accuracy: 0.6323 - val_loss: 1.4762 - val_accuracy: 0.6074\n","Epoch 33/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.4326 - accuracy: 0.6372 - val_loss: 1.4663 - val_accuracy: 0.6085\n","Epoch 34/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.4237 - accuracy: 0.6419 - val_loss: 1.4607 - val_accuracy: 0.6002\n","Epoch 35/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.4149 - accuracy: 0.6432 - val_loss: 1.4568 - val_accuracy: 0.6064\n","Epoch 36/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.4064 - accuracy: 0.6403 - val_loss: 1.4535 - val_accuracy: 0.6095\n","Epoch 37/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.3990 - accuracy: 0.6439 - val_loss: 1.4517 - val_accuracy: 0.6023\n","Epoch 38/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3900 - accuracy: 0.6463 - val_loss: 1.4342 - val_accuracy: 0.6064\n","Epoch 39/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.3855 - accuracy: 0.6468 - val_loss: 1.4266 - val_accuracy: 0.6002\n","Epoch 40/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3736 - accuracy: 0.6491 - val_loss: 1.4228 - val_accuracy: 0.6074\n","Epoch 41/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.3636 - accuracy: 0.6553 - val_loss: 1.4167 - val_accuracy: 0.6095\n","Epoch 42/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3561 - accuracy: 0.6566 - val_loss: 1.4114 - val_accuracy: 0.6064\n","Epoch 43/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3483 - accuracy: 0.6605 - val_loss: 1.4055 - val_accuracy: 0.5961\n","Epoch 44/100\n","31/31 [==============================] - 1s 29ms/step - loss: 1.3401 - accuracy: 0.6620 - val_loss: 1.4011 - val_accuracy: 0.6033\n","Epoch 45/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3306 - accuracy: 0.6659 - val_loss: 1.3979 - val_accuracy: 0.6085\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3222 - accuracy: 0.6685 - val_loss: 1.3977 - val_accuracy: 0.5981\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3141 - accuracy: 0.6674 - val_loss: 1.3849 - val_accuracy: 0.5992\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3063 - accuracy: 0.6726 - val_loss: 1.3813 - val_accuracy: 0.6064\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2994 - accuracy: 0.6724 - val_loss: 1.3753 - val_accuracy: 0.6054\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2893 - accuracy: 0.6749 - val_loss: 1.3715 - val_accuracy: 0.6085\n","Epoch 51/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.2803 - accuracy: 0.6798 - val_loss: 1.3659 - val_accuracy: 0.6105\n","Epoch 52/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2734 - accuracy: 0.6858 - val_loss: 1.3636 - val_accuracy: 0.6054\n","Epoch 53/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2645 - accuracy: 0.6871 - val_loss: 1.3579 - val_accuracy: 0.6116\n","Epoch 54/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2608 - accuracy: 0.6866 - val_loss: 1.3589 - val_accuracy: 0.6064\n","Epoch 55/100\n","31/31 [==============================] - 2s 54ms/step - loss: 1.2484 - accuracy: 0.6953 - val_loss: 1.3494 - val_accuracy: 0.6167\n","Epoch 56/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2413 - accuracy: 0.6917 - val_loss: 1.3479 - val_accuracy: 0.6105\n","Epoch 57/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2323 - accuracy: 0.6951 - val_loss: 1.3406 - val_accuracy: 0.6116\n","Epoch 58/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2258 - accuracy: 0.6961 - val_loss: 1.3403 - val_accuracy: 0.6105\n","Epoch 59/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2179 - accuracy: 0.7039 - val_loss: 1.3368 - val_accuracy: 0.6136\n","Epoch 60/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2076 - accuracy: 0.7080 - val_loss: 1.3322 - val_accuracy: 0.6188\n","Epoch 61/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2027 - accuracy: 0.7028 - val_loss: 1.3297 - val_accuracy: 0.6157\n","Epoch 62/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1942 - accuracy: 0.7054 - val_loss: 1.3368 - val_accuracy: 0.6116\n","Epoch 63/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1849 - accuracy: 0.7106 - val_loss: 1.3241 - val_accuracy: 0.6157\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1770 - accuracy: 0.7129 - val_loss: 1.3312 - val_accuracy: 0.6209\n","Epoch 65/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1708 - accuracy: 0.7134 - val_loss: 1.3188 - val_accuracy: 0.6178\n","Epoch 66/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1608 - accuracy: 0.7165 - val_loss: 1.3168 - val_accuracy: 0.6188\n","Epoch 67/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1538 - accuracy: 0.7217 - val_loss: 1.3142 - val_accuracy: 0.6147\n","Epoch 68/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1461 - accuracy: 0.7227 - val_loss: 1.3112 - val_accuracy: 0.6157\n","Epoch 69/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1385 - accuracy: 0.7258 - val_loss: 1.3195 - val_accuracy: 0.6167\n","Epoch 70/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1330 - accuracy: 0.7253 - val_loss: 1.3220 - val_accuracy: 0.6064\n","Epoch 71/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1259 - accuracy: 0.7261 - val_loss: 1.3071 - val_accuracy: 0.6188\n","Epoch 72/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.1160 - accuracy: 0.7307 - val_loss: 1.3053 - val_accuracy: 0.6167\n","Epoch 73/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1096 - accuracy: 0.7295 - val_loss: 1.3007 - val_accuracy: 0.6178\n","Epoch 74/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1034 - accuracy: 0.7377 - val_loss: 1.3062 - val_accuracy: 0.6219\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0924 - accuracy: 0.7439 - val_loss: 1.3021 - val_accuracy: 0.6157\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0871 - accuracy: 0.7426 - val_loss: 1.3137 - val_accuracy: 0.6271\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0799 - accuracy: 0.7437 - val_loss: 1.2987 - val_accuracy: 0.6147\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0710 - accuracy: 0.7481 - val_loss: 1.3115 - val_accuracy: 0.6198\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0668 - accuracy: 0.7496 - val_loss: 1.3065 - val_accuracy: 0.6188\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0587 - accuracy: 0.7504 - val_loss: 1.3033 - val_accuracy: 0.6219\n","Epoch 81/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0505 - accuracy: 0.7568 - val_loss: 1.3307 - val_accuracy: 0.5992\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0509 - accuracy: 0.7522 - val_loss: 1.3430 - val_accuracy: 0.5961\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0444 - accuracy: 0.7473 - val_loss: 1.2985 - val_accuracy: 0.6095\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0337 - accuracy: 0.7594 - val_loss: 1.3090 - val_accuracy: 0.6147\n","Epoch 85/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0246 - accuracy: 0.7656 - val_loss: 1.2897 - val_accuracy: 0.6023\n","Epoch 86/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0192 - accuracy: 0.7667 - val_loss: 1.2974 - val_accuracy: 0.6157\n","Epoch 87/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0101 - accuracy: 0.7651 - val_loss: 1.3015 - val_accuracy: 0.6209\n","Epoch 88/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0089 - accuracy: 0.7687 - val_loss: 1.3002 - val_accuracy: 0.6074\n","Epoch 89/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0003 - accuracy: 0.7690 - val_loss: 1.2918 - val_accuracy: 0.6095\n","Epoch 90/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9922 - accuracy: 0.7661 - val_loss: 1.3049 - val_accuracy: 0.6085\n","Epoch 91/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9870 - accuracy: 0.7760 - val_loss: 1.2953 - val_accuracy: 0.6064\n","Epoch 92/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9813 - accuracy: 0.7770 - val_loss: 1.2996 - val_accuracy: 0.6136\n","Epoch 93/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9717 - accuracy: 0.7780 - val_loss: 1.3092 - val_accuracy: 0.6147\n","Epoch 94/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9737 - accuracy: 0.7729 - val_loss: 1.3099 - val_accuracy: 0.6116\n","Epoch 95/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9674 - accuracy: 0.7736 - val_loss: 1.3156 - val_accuracy: 0.6074\n","Epoch 96/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9591 - accuracy: 0.7767 - val_loss: 1.2948 - val_accuracy: 0.6105\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9536 - accuracy: 0.7817 - val_loss: 1.3016 - val_accuracy: 0.6136\n","Epoch 98/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9471 - accuracy: 0.7829 - val_loss: 1.3012 - val_accuracy: 0.6167\n","Epoch 99/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9377 - accuracy: 0.7860 - val_loss: 1.3027 - val_accuracy: 0.6178\n","Epoch 100/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9377 - accuracy: 0.7855 - val_loss: 1.3263 - val_accuracy: 0.6023\n","{'loss': [1.7698880434036255, 1.7541650533676147, 1.7412300109863281, 1.7291685342788696, 1.7172731161117554, 1.7056227922439575, 1.6940666437149048, 1.6824027299880981, 1.6710026264190674, 1.6594082117080688, 1.648306965827942, 1.637044906616211, 1.6258516311645508, 1.6145668029785156, 1.6051967144012451, 1.592995285987854, 1.5826138257980347, 1.572581171989441, 1.5633889436721802, 1.552382230758667, 1.542435884475708, 1.5328954458236694, 1.523053526878357, 1.5138161182403564, 1.5058015584945679, 1.4958902597427368, 1.4862085580825806, 1.4762152433395386, 1.4677643775939941, 1.459181547164917, 1.4504176378250122, 1.4430640935897827, 1.432550072669983, 1.4237395524978638, 1.4149478673934937, 1.4063537120819092, 1.399009108543396, 1.3899617195129395, 1.385473608970642, 1.3735594749450684, 1.3636022806167603, 1.356054663658142, 1.348349690437317, 1.3400875329971313, 1.3305504322052002, 1.3222168684005737, 1.3140780925750732, 1.3063476085662842, 1.2993988990783691, 1.2892906665802002, 1.2802735567092896, 1.273421049118042, 1.2645127773284912, 1.2608224153518677, 1.2484328746795654, 1.241280198097229, 1.2322862148284912, 1.2257928848266602, 1.2179183959960938, 1.2075831890106201, 1.202701210975647, 1.1941897869110107, 1.1849141120910645, 1.1770013570785522, 1.1708345413208008, 1.1607953310012817, 1.1537503004074097, 1.146056890487671, 1.1385008096694946, 1.1329514980316162, 1.125943899154663, 1.116001009941101, 1.1096043586730957, 1.1034376621246338, 1.0924311876296997, 1.0871351957321167, 1.079856038093567, 1.0709995031356812, 1.0668352842330933, 1.058748483657837, 1.0505450963974, 1.0508681535720825, 1.0444114208221436, 1.0336939096450806, 1.0245620012283325, 1.0191679000854492, 1.0101370811462402, 1.0089389085769653, 1.0003451108932495, 0.992171049118042, 0.9869546890258789, 0.9813235998153687, 0.9717336297035217, 0.973716676235199, 0.967382550239563, 0.9590852856636047, 0.9536218643188477, 0.9471253156661987, 0.937728226184845, 0.937720000743866], 'accuracy': [0.5428940653800964, 0.5397932529449463, 0.5511627793312073, 0.5718346238136292, 0.5720930099487305, 0.5746769905090332, 0.576485812664032, 0.5785529613494873, 0.5816537737846375, 0.5863049030303955, 0.5891472697257996, 0.5935400724411011, 0.5927648544311523, 0.5984495878219604, 0.5883721113204956, 0.6064599752426147, 0.6077519655227661, 0.6080103516578674, 0.6111111044883728, 0.6183462738990784, 0.6126614809036255, 0.6196382641792297, 0.6196382641792297, 0.6155038475990295, 0.617054283618927, 0.6201550364494324, 0.6211886405944824, 0.6260982155799866, 0.6271317601203918, 0.632041335105896, 0.6341085433959961, 0.6322997212409973, 0.6372092962265015, 0.6418604850769043, 0.6431524753570557, 0.6403100490570068, 0.6439276337623596, 0.646253228187561, 0.6467700004577637, 0.6490955948829651, 0.6552971601486206, 0.656589150428772, 0.6604651212692261, 0.6620154976844788, 0.6658914685249329, 0.6684754490852356, 0.6674418449401855, 0.672609806060791, 0.6723514199256897, 0.6749354004859924, 0.6798449754714966, 0.685788094997406, 0.6870800852775574, 0.6865633130073547, 0.695348858833313, 0.6917312741279602, 0.6950904130935669, 0.6961240172386169, 0.7038759589195251, 0.7080103158950806, 0.7028423547744751, 0.7054263353347778, 0.7105942964553833, 0.7129198908805847, 0.7134366631507874, 0.7165374755859375, 0.721705436706543, 0.722739040851593, 0.7258397936820984, 0.7253230214118958, 0.7260981798171997, 0.7307493686676025, 0.7294573783874512, 0.737726092338562, 0.7439276576042175, 0.7426356673240662, 0.7436692714691162, 0.748062014579773, 0.7496123909950256, 0.7503876090049744, 0.7568475604057312, 0.7521963715553284, 0.7472867965698242, 0.7594315409660339, 0.7656330466270447, 0.7666666507720947, 0.765116274356842, 0.7687338590621948, 0.7689922451972961, 0.7661498785018921, 0.7759689688682556, 0.7770025730133057, 0.7780361771583557, 0.7728682160377502, 0.773643434047699, 0.7767441868782043, 0.7816537618637085, 0.7829457521438599, 0.7860465049743652, 0.7855297327041626], 'val_loss': [1.7671433687210083, 1.7560750246047974, 1.7452306747436523, 1.7344897985458374, 1.7237745523452759, 1.713204026222229, 1.7026162147521973, 1.692155122756958, 1.6816211938858032, 1.6710951328277588, 1.6605939865112305, 1.6503161191940308, 1.639909267425537, 1.6287968158721924, 1.6186535358428955, 1.6077243089675903, 1.5978307723999023, 1.5873512029647827, 1.5776216983795166, 1.568048357963562, 1.55874764919281, 1.5491949319839478, 1.540719985961914, 1.5333608388900757, 1.5255740880966187, 1.5169678926467896, 1.509016990661621, 1.501277208328247, 1.4951612949371338, 1.4863959550857544, 1.484174370765686, 1.476243019104004, 1.4663046598434448, 1.4607343673706055, 1.4568291902542114, 1.4535411596298218, 1.45167076587677, 1.4341837167739868, 1.426640510559082, 1.4227501153945923, 1.4167252779006958, 1.4114431142807007, 1.405474305152893, 1.4010732173919678, 1.3978763818740845, 1.3977296352386475, 1.384912371635437, 1.3812657594680786, 1.375285029411316, 1.3714772462844849, 1.365907073020935, 1.3636078834533691, 1.3578580617904663, 1.3589386940002441, 1.3493951559066772, 1.3479316234588623, 1.3405516147613525, 1.3403316736221313, 1.33675217628479, 1.3322237730026245, 1.3296610116958618, 1.3368312120437622, 1.3240762948989868, 1.3312187194824219, 1.3188121318817139, 1.3168259859085083, 1.3141615390777588, 1.3111515045166016, 1.3195141553878784, 1.3219966888427734, 1.3070541620254517, 1.305297613143921, 1.3007314205169678, 1.3061772584915161, 1.3021472692489624, 1.3136749267578125, 1.2986705303192139, 1.3114925622940063, 1.3065096139907837, 1.3033254146575928, 1.330714225769043, 1.3429863452911377, 1.298545479774475, 1.3089534044265747, 1.289724349975586, 1.2973929643630981, 1.3015317916870117, 1.3002451658248901, 1.29177725315094, 1.3049331903457642, 1.2952752113342285, 1.2995672225952148, 1.3092036247253418, 1.309873104095459, 1.3155510425567627, 1.294798493385315, 1.301623821258545, 1.3012334108352661, 1.3026632070541382, 1.3262516260147095], 'val_accuracy': [0.5444214940071106, 0.577479362487793, 0.5547520518302917, 0.5454545617103577, 0.5402892827987671, 0.53925621509552, 0.538223147392273, 0.5413222908973694, 0.5526859760284424, 0.56611567735672, 0.5681818127632141, 0.5733470916748047, 0.5723140239715576, 0.5785123705863953, 0.5805785059928894, 0.5805785059928894, 0.5847107172012329, 0.586776852607727, 0.5898760557174683, 0.5805785059928894, 0.5929751992225647, 0.58574378490448, 0.5847107172012329, 0.5888429880142212, 0.6002066135406494, 0.5981404781341553, 0.5888429880142212, 0.5960744023323059, 0.5960744023323059, 0.5971074104309082, 0.6115702390670776, 0.6074380278587341, 0.6084710955619812, 0.6002066135406494, 0.6064049601554871, 0.6095041036605835, 0.6022727489471436, 0.6064049601554871, 0.6002066135406494, 0.6074380278587341, 0.6095041036605835, 0.6064049601554871, 0.5960744023323059, 0.6033057570457458, 0.6084710955619812, 0.5981404781341553, 0.5991735458374023, 0.6064049601554871, 0.60537189245224, 0.6084710955619812, 0.6105371713638306, 0.60537189245224, 0.6115702390670776, 0.6064049601554871, 0.6167355179786682, 0.6105371713638306, 0.6115702390670776, 0.6105371713638306, 0.6136363744735718, 0.6188016533851624, 0.6157024502754211, 0.6115702390670776, 0.6157024502754211, 0.6208677887916565, 0.6177685856819153, 0.6188016533851624, 0.6146694421768188, 0.6157024502754211, 0.6167355179786682, 0.6064049601554871, 0.6188016533851624, 0.6167355179786682, 0.6177685856819153, 0.6219007968902588, 0.6157024502754211, 0.6270661354064941, 0.6146694421768188, 0.6198347210884094, 0.6188016533851624, 0.6219007968902588, 0.5991735458374023, 0.5960744023323059, 0.6095041036605835, 0.6146694421768188, 0.6022727489471436, 0.6157024502754211, 0.6208677887916565, 0.6074380278587341, 0.6095041036605835, 0.6084710955619812, 0.6064049601554871, 0.6136363744735718, 0.6146694421768188, 0.6115702390670776, 0.6074380278587341, 0.6105371713638306, 0.6136363744735718, 0.6167355179786682, 0.6177685856819153, 0.6022727489471436]}\n","32/32 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 10s 27ms/step - loss: 1.0472 - accuracy: 0.7293 - val_loss: 1.2244 - val_accuracy: 0.5183\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 1.0142 - accuracy: 0.7656"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 16ms/step - loss: 1.0315 - accuracy: 0.7373 - val_loss: 1.2127 - val_accuracy: 0.5216\n","Epoch 3/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.0206 - accuracy: 0.7435 - val_loss: 1.2078 - val_accuracy: 0.5269\n","Epoch 4/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0159 - accuracy: 0.7454 - val_loss: 1.2058 - val_accuracy: 0.5259\n","Epoch 5/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0147 - accuracy: 0.7416 - val_loss: 1.1968 - val_accuracy: 0.5377\n","Epoch 6/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9993 - accuracy: 0.7540 - val_loss: 1.1895 - val_accuracy: 0.5377\n","Epoch 7/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9943 - accuracy: 0.7594 - val_loss: 1.1806 - val_accuracy: 0.5485\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9887 - accuracy: 0.7530 - val_loss: 1.1786 - val_accuracy: 0.5539\n","Epoch 9/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9813 - accuracy: 0.7643 - val_loss: 1.1661 - val_accuracy: 0.5690\n","Epoch 10/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9762 - accuracy: 0.7592 - val_loss: 1.1636 - val_accuracy: 0.5690\n","Epoch 11/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9698 - accuracy: 0.7716 - val_loss: 1.1531 - val_accuracy: 0.5797\n","Epoch 12/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9640 - accuracy: 0.7699 - val_loss: 1.1483 - val_accuracy: 0.5841\n","Epoch 13/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9595 - accuracy: 0.7707 - val_loss: 1.1198 - val_accuracy: 0.6164\n","Epoch 14/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9525 - accuracy: 0.7734 - val_loss: 1.1225 - val_accuracy: 0.6121\n","Epoch 15/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9484 - accuracy: 0.7716 - val_loss: 1.1137 - val_accuracy: 0.6153\n","Epoch 16/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9431 - accuracy: 0.7716 - val_loss: 1.0950 - val_accuracy: 0.6401\n","Epoch 17/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9391 - accuracy: 0.7718 - val_loss: 1.0896 - val_accuracy: 0.6390\n","Epoch 18/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9333 - accuracy: 0.7796 - val_loss: 1.0868 - val_accuracy: 0.6401\n","Epoch 19/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9276 - accuracy: 0.7783 - val_loss: 1.0773 - val_accuracy: 0.6487\n","Epoch 20/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9227 - accuracy: 0.7858 - val_loss: 1.0687 - val_accuracy: 0.6638\n","Epoch 21/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9143 - accuracy: 0.7912 - val_loss: 1.0670 - val_accuracy: 0.6562\n","Epoch 22/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9143 - accuracy: 0.7804 - val_loss: 1.0615 - val_accuracy: 0.6584\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9103 - accuracy: 0.7829 - val_loss: 1.0583 - val_accuracy: 0.6606\n","Epoch 24/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9032 - accuracy: 0.7931 - val_loss: 1.0585 - val_accuracy: 0.6627\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8971 - accuracy: 0.7945 - val_loss: 1.0641 - val_accuracy: 0.6562\n","Epoch 26/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8949 - accuracy: 0.7872 - val_loss: 1.0615 - val_accuracy: 0.6573\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8862 - accuracy: 0.7980 - val_loss: 1.0604 - val_accuracy: 0.6606\n","Epoch 28/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8823 - accuracy: 0.7974 - val_loss: 1.0617 - val_accuracy: 0.6681\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8749 - accuracy: 0.8025 - val_loss: 1.0634 - val_accuracy: 0.6616\n","Epoch 30/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8709 - accuracy: 0.8025 - val_loss: 1.0695 - val_accuracy: 0.6659\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8718 - accuracy: 0.7961 - val_loss: 1.0785 - val_accuracy: 0.6530\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8634 - accuracy: 0.8066 - val_loss: 1.0649 - val_accuracy: 0.6606\n","Epoch 33/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8599 - accuracy: 0.8009 - val_loss: 1.0698 - val_accuracy: 0.6659\n","Epoch 34/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8563 - accuracy: 0.8039 - val_loss: 1.0650 - val_accuracy: 0.6659\n","Epoch 35/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8578 - accuracy: 0.7958 - val_loss: 1.0693 - val_accuracy: 0.6681\n","Epoch 36/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8496 - accuracy: 0.8009 - val_loss: 1.0755 - val_accuracy: 0.6638\n","Epoch 37/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8405 - accuracy: 0.8106 - val_loss: 1.0668 - val_accuracy: 0.6659\n","Epoch 38/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8391 - accuracy: 0.8109 - val_loss: 1.0642 - val_accuracy: 0.6659\n","Epoch 39/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8313 - accuracy: 0.8141 - val_loss: 1.0665 - val_accuracy: 0.6638\n","Epoch 40/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8251 - accuracy: 0.8165 - val_loss: 1.0701 - val_accuracy: 0.6681\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8223 - accuracy: 0.8136 - val_loss: 1.0664 - val_accuracy: 0.6692\n","Epoch 42/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8195 - accuracy: 0.8168 - val_loss: 1.0890 - val_accuracy: 0.6681\n","Epoch 43/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.8183 - accuracy: 0.8152 - val_loss: 1.0646 - val_accuracy: 0.6703\n","Epoch 44/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8135 - accuracy: 0.8206 - val_loss: 1.0827 - val_accuracy: 0.6606\n","Epoch 45/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8065 - accuracy: 0.8200 - val_loss: 1.0687 - val_accuracy: 0.6649\n","Epoch 46/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8038 - accuracy: 0.8265 - val_loss: 1.0711 - val_accuracy: 0.6703\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7948 - accuracy: 0.8332 - val_loss: 1.0739 - val_accuracy: 0.6724\n","Epoch 48/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7908 - accuracy: 0.8324 - val_loss: 1.0724 - val_accuracy: 0.6670\n","Epoch 49/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7862 - accuracy: 0.8343 - val_loss: 1.0713 - val_accuracy: 0.6681\n","Epoch 50/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7856 - accuracy: 0.8268 - val_loss: 1.0798 - val_accuracy: 0.6627\n","Epoch 51/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7802 - accuracy: 0.8327 - val_loss: 1.0759 - val_accuracy: 0.6692\n","Epoch 52/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7774 - accuracy: 0.8268 - val_loss: 1.0875 - val_accuracy: 0.6616\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7762 - accuracy: 0.8330 - val_loss: 1.0805 - val_accuracy: 0.6778\n","Epoch 54/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7667 - accuracy: 0.8373 - val_loss: 1.0855 - val_accuracy: 0.6703\n","Epoch 55/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7633 - accuracy: 0.8384 - val_loss: 1.0958 - val_accuracy: 0.6724\n","Epoch 56/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7640 - accuracy: 0.8373 - val_loss: 1.0828 - val_accuracy: 0.6703\n","Epoch 57/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7580 - accuracy: 0.8397 - val_loss: 1.0874 - val_accuracy: 0.6713\n","Epoch 58/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7569 - accuracy: 0.8338 - val_loss: 1.1046 - val_accuracy: 0.6573\n","Epoch 59/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7506 - accuracy: 0.8413 - val_loss: 1.0847 - val_accuracy: 0.6659\n","Epoch 60/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7468 - accuracy: 0.8405 - val_loss: 1.0898 - val_accuracy: 0.6735\n","Epoch 61/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7429 - accuracy: 0.8421 - val_loss: 1.0960 - val_accuracy: 0.6638\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7418 - accuracy: 0.8386 - val_loss: 1.1239 - val_accuracy: 0.6649\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7381 - accuracy: 0.8370 - val_loss: 1.0984 - val_accuracy: 0.6724\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7289 - accuracy: 0.8564 - val_loss: 1.0913 - val_accuracy: 0.6692\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7290 - accuracy: 0.8470 - val_loss: 1.0953 - val_accuracy: 0.6659\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7284 - accuracy: 0.8416 - val_loss: 1.1006 - val_accuracy: 0.6724\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7170 - accuracy: 0.8540 - val_loss: 1.0945 - val_accuracy: 0.6692\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7177 - accuracy: 0.8537 - val_loss: 1.0969 - val_accuracy: 0.6767\n","Epoch 69/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7133 - accuracy: 0.8572 - val_loss: 1.0946 - val_accuracy: 0.6713\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7066 - accuracy: 0.8580 - val_loss: 1.0972 - val_accuracy: 0.6703\n","Epoch 71/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7032 - accuracy: 0.8578 - val_loss: 1.1064 - val_accuracy: 0.6670\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6965 - accuracy: 0.8621 - val_loss: 1.1103 - val_accuracy: 0.6649\n","Epoch 73/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6943 - accuracy: 0.8599 - val_loss: 1.1097 - val_accuracy: 0.6649\n","Epoch 74/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6950 - accuracy: 0.8591 - val_loss: 1.1057 - val_accuracy: 0.6735\n","Epoch 75/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6924 - accuracy: 0.8631 - val_loss: 1.1158 - val_accuracy: 0.6595\n","Epoch 76/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6949 - accuracy: 0.8618 - val_loss: 1.1218 - val_accuracy: 0.6638\n","Epoch 77/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6896 - accuracy: 0.8629 - val_loss: 1.1312 - val_accuracy: 0.6692\n","Epoch 78/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6833 - accuracy: 0.8648 - val_loss: 1.1159 - val_accuracy: 0.6595\n","Epoch 79/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6760 - accuracy: 0.8704 - val_loss: 1.1252 - val_accuracy: 0.6649\n","Epoch 80/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6702 - accuracy: 0.8656 - val_loss: 1.1204 - val_accuracy: 0.6703\n","Epoch 81/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6711 - accuracy: 0.8702 - val_loss: 1.1202 - val_accuracy: 0.6670\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6664 - accuracy: 0.8693 - val_loss: 1.1294 - val_accuracy: 0.6713\n","Epoch 83/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6611 - accuracy: 0.8723 - val_loss: 1.1260 - val_accuracy: 0.6735\n","Epoch 84/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6614 - accuracy: 0.8745 - val_loss: 1.1316 - val_accuracy: 0.6713\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6631 - accuracy: 0.8742 - val_loss: 1.1409 - val_accuracy: 0.6649\n","Epoch 86/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6661 - accuracy: 0.8691 - val_loss: 1.1522 - val_accuracy: 0.6616\n","Epoch 87/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6586 - accuracy: 0.8731 - val_loss: 1.1391 - val_accuracy: 0.6659\n","Epoch 88/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6630 - accuracy: 0.8718 - val_loss: 1.1645 - val_accuracy: 0.6606\n","Epoch 89/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6550 - accuracy: 0.8688 - val_loss: 1.1407 - val_accuracy: 0.6681\n","Epoch 90/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6436 - accuracy: 0.8798 - val_loss: 1.1458 - val_accuracy: 0.6659\n","Epoch 91/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6369 - accuracy: 0.8817 - val_loss: 1.1506 - val_accuracy: 0.6638\n","Epoch 92/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6356 - accuracy: 0.8834 - val_loss: 1.1401 - val_accuracy: 0.6670\n","Epoch 93/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6386 - accuracy: 0.8758 - val_loss: 1.1854 - val_accuracy: 0.6530\n","Epoch 94/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6315 - accuracy: 0.8809 - val_loss: 1.1620 - val_accuracy: 0.6627\n","Epoch 95/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6254 - accuracy: 0.8869 - val_loss: 1.1539 - val_accuracy: 0.6606\n","Epoch 96/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6240 - accuracy: 0.8836 - val_loss: 1.1653 - val_accuracy: 0.6616\n","Epoch 97/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6228 - accuracy: 0.8852 - val_loss: 1.2064 - val_accuracy: 0.6541\n","Epoch 98/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6281 - accuracy: 0.8793 - val_loss: 1.1632 - val_accuracy: 0.6659\n","Epoch 99/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6252 - accuracy: 0.8863 - val_loss: 1.2037 - val_accuracy: 0.6659\n","Epoch 100/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6186 - accuracy: 0.8852 - val_loss: 1.1612 - val_accuracy: 0.6627\n","{'loss': [1.047176718711853, 1.0315349102020264, 1.0205507278442383, 1.0158607959747314, 1.0146920680999756, 0.9993070363998413, 0.994314432144165, 0.9887160062789917, 0.9813003540039062, 0.9762497544288635, 0.9697843194007874, 0.9640011787414551, 0.9595337510108948, 0.9524962902069092, 0.9483954906463623, 0.943114697933197, 0.9391409158706665, 0.9333363175392151, 0.9275837540626526, 0.9226989150047302, 0.9143074750900269, 0.9142672419548035, 0.9103179574012756, 0.9031784534454346, 0.8971101641654968, 0.894946813583374, 0.886177122592926, 0.8822805285453796, 0.8749421238899231, 0.870919406414032, 0.8718357682228088, 0.8633794188499451, 0.8598538041114807, 0.8562684655189514, 0.8577876091003418, 0.8496252298355103, 0.8404792547225952, 0.8390548229217529, 0.8312990665435791, 0.8251147866249084, 0.8222883939743042, 0.8195347189903259, 0.8182533383369446, 0.8135324716567993, 0.8065040707588196, 0.8037527203559875, 0.7948107123374939, 0.7908113598823547, 0.7861613631248474, 0.785595715045929, 0.7801839709281921, 0.7774211764335632, 0.7761561870574951, 0.7667340040206909, 0.7632693648338318, 0.7640218138694763, 0.7579737901687622, 0.7569414377212524, 0.7506147027015686, 0.7468465566635132, 0.7428815960884094, 0.7418276071548462, 0.7380833625793457, 0.7289484739303589, 0.7290429472923279, 0.7283565998077393, 0.7169942259788513, 0.7177164554595947, 0.7132537364959717, 0.7066104412078857, 0.7031648755073547, 0.6965442299842834, 0.6943319439888, 0.6949503421783447, 0.6923519372940063, 0.6948775053024292, 0.6896469593048096, 0.6833121180534363, 0.6760019659996033, 0.6701722741127014, 0.6711154580116272, 0.6663975119590759, 0.6610591411590576, 0.6614209413528442, 0.6630638241767883, 0.6660768985748291, 0.6585871577262878, 0.6630428433418274, 0.6550456881523132, 0.6435897350311279, 0.6369258165359497, 0.6355979442596436, 0.6385891437530518, 0.6315061450004578, 0.6253931522369385, 0.6239929795265198, 0.6227636933326721, 0.6281405091285706, 0.6251553297042847, 0.6185657382011414], 'accuracy': [0.7292564511299133, 0.7373383641242981, 0.743534505367279, 0.7454202771186829, 0.7416487336158752, 0.7540409564971924, 0.759428858757019, 0.7529633641242981, 0.764277994632721, 0.759159505367279, 0.7715517282485962, 0.7699353694915771, 0.7707435488700867, 0.7734375, 0.7715517282485962, 0.7715517282485962, 0.771821141242981, 0.779633641242981, 0.7782866358757019, 0.7858297228813171, 0.7912176847457886, 0.7804418206214905, 0.782866358757019, 0.7931034564971924, 0.7944504022598267, 0.7871767282485962, 0.7979525923728943, 0.7974137663841248, 0.8025323152542114, 0.8025323152542114, 0.7960668206214905, 0.8065732717514038, 0.8009159564971924, 0.8038793206214905, 0.7957974076271057, 0.8009159564971924, 0.8106142282485962, 0.810883641242981, 0.814116358757019, 0.8165409564971924, 0.8135775923728943, 0.8168103694915771, 0.8151939511299133, 0.8205819129943848, 0.8200430870056152, 0.826508641242981, 0.8332435488700867, 0.8324353694915771, 0.834321141242981, 0.826777994632721, 0.8327047228813171, 0.826777994632721, 0.8329741358757019, 0.837284505367279, 0.8383620977401733, 0.837284505367279, 0.8397090435028076, 0.8337823152542114, 0.8413254022598267, 0.8405172228813171, 0.842133641242981, 0.8386314511299133, 0.8370150923728943, 0.8564116358757019, 0.8469827771186829, 0.8415948152542114, 0.8539870977401733, 0.8537176847457886, 0.8572198152542114, 0.858027994632721, 0.857758641242981, 0.8620689511299133, 0.8599137663841248, 0.8591055870056152, 0.8631465435028076, 0.8617995977401733, 0.8628771305084229, 0.8647629022598267, 0.8704202771186829, 0.865571141242981, 0.8701508641242981, 0.8693426847457886, 0.8723060488700867, 0.8744612336158752, 0.8741918206214905, 0.8690732717514038, 0.8731142282485962, 0.8717672228813171, 0.868803858757019, 0.8798491358757019, 0.8817349076271057, 0.8833512663841248, 0.8758081793785095, 0.8809267282485962, 0.8868534564971924, 0.8836206793785095, 0.8852370977401733, 0.8793103694915771, 0.8863146305084229, 0.8852370977401733], 'val_loss': [1.224426507949829, 1.21274995803833, 1.2077730894088745, 1.2057846784591675, 1.1967697143554688, 1.1894704103469849, 1.180596113204956, 1.1786412000656128, 1.1660679578781128, 1.163588285446167, 1.1531387567520142, 1.1483052968978882, 1.1197805404663086, 1.122464895248413, 1.1137213706970215, 1.0950441360473633, 1.0896213054656982, 1.086809754371643, 1.077275276184082, 1.0686675310134888, 1.067043423652649, 1.0614502429962158, 1.0582661628723145, 1.058451533317566, 1.0641483068466187, 1.061495065689087, 1.0603971481323242, 1.0617350339889526, 1.0634369850158691, 1.069533348083496, 1.0784575939178467, 1.064855933189392, 1.0698379278182983, 1.0649912357330322, 1.0693268775939941, 1.0754863023757935, 1.0667685270309448, 1.064216136932373, 1.0665439367294312, 1.0701346397399902, 1.0664429664611816, 1.0889745950698853, 1.0645973682403564, 1.0826811790466309, 1.0686544179916382, 1.071129322052002, 1.0738797187805176, 1.0723897218704224, 1.0713304281234741, 1.0798121690750122, 1.0758841037750244, 1.0874762535095215, 1.0804822444915771, 1.0855309963226318, 1.095798134803772, 1.0827972888946533, 1.0873582363128662, 1.104607343673706, 1.0846538543701172, 1.089821696281433, 1.0959535837173462, 1.123942494392395, 1.098423719406128, 1.0913097858428955, 1.0953309535980225, 1.1006367206573486, 1.0945451259613037, 1.0968612432479858, 1.0946043729782104, 1.0972356796264648, 1.1063884496688843, 1.1102702617645264, 1.1097204685211182, 1.1057112216949463, 1.1158205270767212, 1.1218143701553345, 1.1311774253845215, 1.1158798933029175, 1.1252408027648926, 1.1204497814178467, 1.1202419996261597, 1.1293678283691406, 1.1259812116622925, 1.1315501928329468, 1.1408753395080566, 1.1522390842437744, 1.1390841007232666, 1.1644893884658813, 1.140737771987915, 1.1457914113998413, 1.1506015062332153, 1.1401349306106567, 1.1854333877563477, 1.1620104312896729, 1.1538670063018799, 1.165297031402588, 1.2064200639724731, 1.163161039352417, 1.203694224357605, 1.1612166166305542], 'val_accuracy': [0.5183189511299133, 0.5215517282485962, 0.5269396305084229, 0.5258620977401733, 0.537715494632721, 0.537715494632721, 0.548491358757019, 0.5538793206214905, 0.568965494632721, 0.568965494632721, 0.579741358757019, 0.5840517282485962, 0.6163793206214905, 0.6120689511299133, 0.6153017282485962, 0.6400862336158752, 0.639008641242981, 0.6400862336158752, 0.6487069129943848, 0.6637930870056152, 0.65625, 0.6584051847457886, 0.6605603694915771, 0.662715494632721, 0.65625, 0.6573275923728943, 0.6605603694915771, 0.6681034564971924, 0.6616379022598267, 0.6659482717514038, 0.6530172228813171, 0.6605603694915771, 0.6659482717514038, 0.6659482717514038, 0.6681034564971924, 0.6637930870056152, 0.6659482717514038, 0.6659482717514038, 0.6637930870056152, 0.6681034564971924, 0.6691810488700867, 0.6681034564971924, 0.670258641242981, 0.6605603694915771, 0.6648706793785095, 0.670258641242981, 0.6724137663841248, 0.6670258641242981, 0.6681034564971924, 0.662715494632721, 0.6691810488700867, 0.6616379022598267, 0.6778017282485962, 0.670258641242981, 0.6724137663841248, 0.670258641242981, 0.6713362336158752, 0.6573275923728943, 0.6659482717514038, 0.673491358757019, 0.6637930870056152, 0.6648706793785095, 0.6724137663841248, 0.6691810488700867, 0.6659482717514038, 0.6724137663841248, 0.6691810488700867, 0.6767241358757019, 0.6713362336158752, 0.670258641242981, 0.6670258641242981, 0.6648706793785095, 0.6648706793785095, 0.673491358757019, 0.6594827771186829, 0.6637930870056152, 0.6691810488700867, 0.6594827771186829, 0.6648706793785095, 0.670258641242981, 0.6670258641242981, 0.6713362336158752, 0.673491358757019, 0.6713362336158752, 0.6648706793785095, 0.6616379022598267, 0.6659482717514038, 0.6605603694915771, 0.6681034564971924, 0.6659482717514038, 0.6637930870056152, 0.6670258641242981, 0.6530172228813171, 0.662715494632721, 0.6605603694915771, 0.6616379022598267, 0.6540948152542114, 0.6659482717514038, 0.6659482717514038, 0.662715494632721]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 3s 29ms/step - loss: 1.0517 - accuracy: 0.7184 - val_loss: 1.2266 - val_accuracy: 0.5090\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 1.0228 - accuracy: 0.7500"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 16ms/step - loss: 1.0391 - accuracy: 0.7289 - val_loss: 1.2177 - val_accuracy: 0.5113\n","Epoch 3/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0309 - accuracy: 0.7278 - val_loss: 1.2119 - val_accuracy: 0.5124\n","Epoch 4/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0249 - accuracy: 0.7337 - val_loss: 1.1990 - val_accuracy: 0.5181\n","Epoch 5/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0174 - accuracy: 0.7408 - val_loss: 1.1936 - val_accuracy: 0.5215\n","Epoch 6/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0089 - accuracy: 0.7422 - val_loss: 1.1857 - val_accuracy: 0.5407\n","Epoch 7/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.0055 - accuracy: 0.7487 - val_loss: 1.1826 - val_accuracy: 0.5452\n","Epoch 8/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9982 - accuracy: 0.7450 - val_loss: 1.1731 - val_accuracy: 0.5532\n","Epoch 9/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.9948 - accuracy: 0.7487 - val_loss: 1.1699 - val_accuracy: 0.5588\n","Epoch 10/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9852 - accuracy: 0.7516 - val_loss: 1.1637 - val_accuracy: 0.5588\n","Epoch 11/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9837 - accuracy: 0.7547 - val_loss: 1.1509 - val_accuracy: 0.5747\n","Epoch 12/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9748 - accuracy: 0.7521 - val_loss: 1.1380 - val_accuracy: 0.5894\n","Epoch 13/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9694 - accuracy: 0.7552 - val_loss: 1.1452 - val_accuracy: 0.5735\n","Epoch 14/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9635 - accuracy: 0.7606 - val_loss: 1.1214 - val_accuracy: 0.6131\n","Epoch 15/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9576 - accuracy: 0.7620 - val_loss: 1.1209 - val_accuracy: 0.6131\n","Epoch 16/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9535 - accuracy: 0.7691 - val_loss: 1.1057 - val_accuracy: 0.6312\n","Epoch 17/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9487 - accuracy: 0.7637 - val_loss: 1.1025 - val_accuracy: 0.6335\n","Epoch 18/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9443 - accuracy: 0.7708 - val_loss: 1.0881 - val_accuracy: 0.6459\n","Epoch 19/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9416 - accuracy: 0.7677 - val_loss: 1.0819 - val_accuracy: 0.6505\n","Epoch 20/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9346 - accuracy: 0.7663 - val_loss: 1.0776 - val_accuracy: 0.6538\n","Epoch 21/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9342 - accuracy: 0.7680 - val_loss: 1.0748 - val_accuracy: 0.6561\n","Epoch 22/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9220 - accuracy: 0.7745 - val_loss: 1.0767 - val_accuracy: 0.6572\n","Epoch 23/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9180 - accuracy: 0.7753 - val_loss: 1.0788 - val_accuracy: 0.6652\n","Epoch 24/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9176 - accuracy: 0.7736 - val_loss: 1.0743 - val_accuracy: 0.6663\n","Epoch 25/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9198 - accuracy: 0.7702 - val_loss: 1.0644 - val_accuracy: 0.6821\n","Epoch 26/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9069 - accuracy: 0.7832 - val_loss: 1.0664 - val_accuracy: 0.6753\n","Epoch 27/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9057 - accuracy: 0.7790 - val_loss: 1.0711 - val_accuracy: 0.6833\n","Epoch 28/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8958 - accuracy: 0.7866 - val_loss: 1.0734 - val_accuracy: 0.6844\n","Epoch 29/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8922 - accuracy: 0.7881 - val_loss: 1.0835 - val_accuracy: 0.6742\n","Epoch 30/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8877 - accuracy: 0.7895 - val_loss: 1.0739 - val_accuracy: 0.6889\n","Epoch 31/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8837 - accuracy: 0.7832 - val_loss: 1.0812 - val_accuracy: 0.6855\n","Epoch 32/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8754 - accuracy: 0.7940 - val_loss: 1.0785 - val_accuracy: 0.6844\n","Epoch 33/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8735 - accuracy: 0.7951 - val_loss: 1.0808 - val_accuracy: 0.6810\n","Epoch 34/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8694 - accuracy: 0.7954 - val_loss: 1.0829 - val_accuracy: 0.6844\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8659 - accuracy: 0.7954 - val_loss: 1.0822 - val_accuracy: 0.6833\n","Epoch 36/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8623 - accuracy: 0.8002 - val_loss: 1.0915 - val_accuracy: 0.6708\n","Epoch 37/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8582 - accuracy: 0.7985 - val_loss: 1.0935 - val_accuracy: 0.6550\n","Epoch 38/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8576 - accuracy: 0.7934 - val_loss: 1.0902 - val_accuracy: 0.6799\n","Epoch 39/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8503 - accuracy: 0.7977 - val_loss: 1.0992 - val_accuracy: 0.6765\n","Epoch 40/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8454 - accuracy: 0.7994 - val_loss: 1.0845 - val_accuracy: 0.6810\n","Epoch 41/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8393 - accuracy: 0.8093 - val_loss: 1.0802 - val_accuracy: 0.6833\n","Epoch 42/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8354 - accuracy: 0.8059 - val_loss: 1.0894 - val_accuracy: 0.6787\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8327 - accuracy: 0.8093 - val_loss: 1.0991 - val_accuracy: 0.6629\n","Epoch 44/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8316 - accuracy: 0.8084 - val_loss: 1.0918 - val_accuracy: 0.6765\n","Epoch 45/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8281 - accuracy: 0.8050 - val_loss: 1.0933 - val_accuracy: 0.6855\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8157 - accuracy: 0.8166 - val_loss: 1.0917 - val_accuracy: 0.6799\n","Epoch 47/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8123 - accuracy: 0.8186 - val_loss: 1.0911 - val_accuracy: 0.6686\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8084 - accuracy: 0.8169 - val_loss: 1.0891 - val_accuracy: 0.6753\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8059 - accuracy: 0.8200 - val_loss: 1.0935 - val_accuracy: 0.6731\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8044 - accuracy: 0.8172 - val_loss: 1.0938 - val_accuracy: 0.6810\n","Epoch 51/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8012 - accuracy: 0.8229 - val_loss: 1.0896 - val_accuracy: 0.6787\n","Epoch 52/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7960 - accuracy: 0.8209 - val_loss: 1.0930 - val_accuracy: 0.6708\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7894 - accuracy: 0.8285 - val_loss: 1.0980 - val_accuracy: 0.6674\n","Epoch 54/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7862 - accuracy: 0.8257 - val_loss: 1.1000 - val_accuracy: 0.6708\n","Epoch 55/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7813 - accuracy: 0.8325 - val_loss: 1.0901 - val_accuracy: 0.6844\n","Epoch 56/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7762 - accuracy: 0.8328 - val_loss: 1.0913 - val_accuracy: 0.6867\n","Epoch 57/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7775 - accuracy: 0.8328 - val_loss: 1.1018 - val_accuracy: 0.6652\n","Epoch 58/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7695 - accuracy: 0.8336 - val_loss: 1.1078 - val_accuracy: 0.6640\n","Epoch 59/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7698 - accuracy: 0.8322 - val_loss: 1.1050 - val_accuracy: 0.6776\n","Epoch 60/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7645 - accuracy: 0.8268 - val_loss: 1.1175 - val_accuracy: 0.6674\n","Epoch 61/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7614 - accuracy: 0.8376 - val_loss: 1.1153 - val_accuracy: 0.6674\n","Epoch 62/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7551 - accuracy: 0.8387 - val_loss: 1.0974 - val_accuracy: 0.6833\n","Epoch 63/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7500 - accuracy: 0.8387 - val_loss: 1.1103 - val_accuracy: 0.6833\n","Epoch 64/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7497 - accuracy: 0.8396 - val_loss: 1.1123 - val_accuracy: 0.6652\n","Epoch 65/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7478 - accuracy: 0.8347 - val_loss: 1.1099 - val_accuracy: 0.6799\n","Epoch 66/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7409 - accuracy: 0.8410 - val_loss: 1.1123 - val_accuracy: 0.6719\n","Epoch 67/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7353 - accuracy: 0.8452 - val_loss: 1.1067 - val_accuracy: 0.6765\n","Epoch 68/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7353 - accuracy: 0.8463 - val_loss: 1.1410 - val_accuracy: 0.6550\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7338 - accuracy: 0.8407 - val_loss: 1.1200 - val_accuracy: 0.6742\n","Epoch 70/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7238 - accuracy: 0.8514 - val_loss: 1.1117 - val_accuracy: 0.6799\n","Epoch 71/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7227 - accuracy: 0.8478 - val_loss: 1.1193 - val_accuracy: 0.6674\n","Epoch 72/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7222 - accuracy: 0.8489 - val_loss: 1.1269 - val_accuracy: 0.6753\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7178 - accuracy: 0.8497 - val_loss: 1.1230 - val_accuracy: 0.6719\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7163 - accuracy: 0.8500 - val_loss: 1.1272 - val_accuracy: 0.6765\n","Epoch 75/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7138 - accuracy: 0.8517 - val_loss: 1.1462 - val_accuracy: 0.6708\n","Epoch 76/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7151 - accuracy: 0.8492 - val_loss: 1.1402 - val_accuracy: 0.6561\n","Epoch 77/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7126 - accuracy: 0.8492 - val_loss: 1.1384 - val_accuracy: 0.6697\n","Epoch 78/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7060 - accuracy: 0.8526 - val_loss: 1.1285 - val_accuracy: 0.6731\n","Epoch 79/100\n","28/28 [==============================] - 1s 51ms/step - loss: 0.6989 - accuracy: 0.8642 - val_loss: 1.1215 - val_accuracy: 0.6900\n","Epoch 80/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6952 - accuracy: 0.8630 - val_loss: 1.1472 - val_accuracy: 0.6731\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6970 - accuracy: 0.8571 - val_loss: 1.1438 - val_accuracy: 0.6674\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6846 - accuracy: 0.8630 - val_loss: 1.1357 - val_accuracy: 0.6731\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6808 - accuracy: 0.8667 - val_loss: 1.1538 - val_accuracy: 0.6810\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6823 - accuracy: 0.8633 - val_loss: 1.1455 - val_accuracy: 0.6674\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6748 - accuracy: 0.8727 - val_loss: 1.1509 - val_accuracy: 0.6674\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6695 - accuracy: 0.8715 - val_loss: 1.1423 - val_accuracy: 0.6810\n","Epoch 87/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6714 - accuracy: 0.8710 - val_loss: 1.1366 - val_accuracy: 0.6787\n","Epoch 88/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6683 - accuracy: 0.8735 - val_loss: 1.1640 - val_accuracy: 0.6708\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6665 - accuracy: 0.8710 - val_loss: 1.1559 - val_accuracy: 0.6719\n","Epoch 90/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6652 - accuracy: 0.8701 - val_loss: 1.1641 - val_accuracy: 0.6742\n","Epoch 91/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6852 - accuracy: 0.8611 - val_loss: 1.1767 - val_accuracy: 0.6584\n","Epoch 92/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6632 - accuracy: 0.8681 - val_loss: 1.1567 - val_accuracy: 0.6844\n","Epoch 93/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6560 - accuracy: 0.8701 - val_loss: 1.1552 - val_accuracy: 0.6731\n","Epoch 94/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6487 - accuracy: 0.8789 - val_loss: 1.1494 - val_accuracy: 0.6697\n","Epoch 95/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6449 - accuracy: 0.8792 - val_loss: 1.1695 - val_accuracy: 0.6731\n","Epoch 96/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6428 - accuracy: 0.8857 - val_loss: 1.1534 - val_accuracy: 0.6776\n","Epoch 97/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6414 - accuracy: 0.8780 - val_loss: 1.1637 - val_accuracy: 0.6663\n","Epoch 98/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6384 - accuracy: 0.8812 - val_loss: 1.1677 - val_accuracy: 0.6810\n","Epoch 99/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6394 - accuracy: 0.8766 - val_loss: 1.1702 - val_accuracy: 0.6595\n","Epoch 100/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6334 - accuracy: 0.8834 - val_loss: 1.1817 - val_accuracy: 0.6731\n","{'loss': [1.0516880750656128, 1.0390727519989014, 1.03089439868927, 1.0249073505401611, 1.017421841621399, 1.0089354515075684, 1.0054928064346313, 0.9981797337532043, 0.9948437809944153, 0.9851841926574707, 0.9836599826812744, 0.9748066067695618, 0.9693626761436462, 0.9635334014892578, 0.9576235413551331, 0.9534974694252014, 0.9486646056175232, 0.9443449378013611, 0.9415856003761292, 0.9346114993095398, 0.9341781735420227, 0.9220319390296936, 0.918022871017456, 0.917576789855957, 0.9198092818260193, 0.9068740010261536, 0.9056529402732849, 0.8957987427711487, 0.8921611309051514, 0.8876675367355347, 0.8836519718170166, 0.8753507137298584, 0.8734853267669678, 0.8693541884422302, 0.8658918142318726, 0.8622840046882629, 0.8582020998001099, 0.8575958013534546, 0.8502655029296875, 0.8453856110572815, 0.8392855525016785, 0.8354352116584778, 0.8326886296272278, 0.8315607905387878, 0.8281052708625793, 0.8157363533973694, 0.8123137950897217, 0.8083861470222473, 0.8059394955635071, 0.8044288754463196, 0.8012229800224304, 0.7960423827171326, 0.789397120475769, 0.7861505746841431, 0.7812770009040833, 0.7762354612350464, 0.7774522304534912, 0.7695351839065552, 0.7697605490684509, 0.7644772529602051, 0.7613772749900818, 0.7550705075263977, 0.7499833106994629, 0.7497038841247559, 0.7477877140045166, 0.7408559322357178, 0.735292375087738, 0.7352900505065918, 0.7337701320648193, 0.7237851619720459, 0.7226766347885132, 0.7221810221672058, 0.7177707552909851, 0.716283917427063, 0.7137587666511536, 0.715117335319519, 0.7126433849334717, 0.7059845924377441, 0.6988584995269775, 0.6951720714569092, 0.6970187425613403, 0.6846359372138977, 0.6808242797851562, 0.6822958588600159, 0.6747819185256958, 0.6695038080215454, 0.671396791934967, 0.6683028936386108, 0.6665355563163757, 0.6651613116264343, 0.6852366924285889, 0.6632190346717834, 0.6559597849845886, 0.6486748456954956, 0.6448516845703125, 0.6428091526031494, 0.6413778066635132, 0.6383911371231079, 0.6393718123435974, 0.6334276795387268], 'accuracy': [0.7184493541717529, 0.7289190888404846, 0.7277871966362, 0.7337294816970825, 0.740803599357605, 0.7422184348106384, 0.7487266659736633, 0.7450481057167053, 0.7487266659736633, 0.7515563368797302, 0.7546689510345459, 0.7521222233772278, 0.7552348375320435, 0.7606111764907837, 0.7620260119438171, 0.7691001892089844, 0.7637238502502441, 0.7707979679107666, 0.7676853537559509, 0.7662705183029175, 0.7679682970046997, 0.7744765281677246, 0.7753254175186157, 0.7736276388168335, 0.7702320218086243, 0.7832484245300293, 0.7790039777755737, 0.7866440415382385, 0.788058876991272, 0.7894737124443054, 0.7832484245300293, 0.7940011024475098, 0.7951329946517944, 0.7954159379005432, 0.7954159379005432, 0.8002263903617859, 0.7985285520553589, 0.7934352159500122, 0.7976796627044678, 0.7993775010108948, 0.8092812895774841, 0.8058856725692749, 0.8092812895774841, 0.808432400226593, 0.8050367832183838, 0.8166383504867554, 0.8186191320419312, 0.8169213533401489, 0.8200339674949646, 0.8172042965888977, 0.8228636384010315, 0.8208828568458557, 0.8285229206085205, 0.8256932497024536, 0.8324844241142273, 0.8327674269676208, 0.8327674269676208, 0.833616316318512, 0.8322014808654785, 0.8268251419067383, 0.8375778198242188, 0.8387096524238586, 0.8387096524238586, 0.8395586013793945, 0.8347481489181519, 0.8409733772277832, 0.8452178835868835, 0.8463497161865234, 0.8406904339790344, 0.8514431118965149, 0.8477645516395569, 0.8488964438438416, 0.8497453331947327, 0.8500282764434814, 0.8517261147499084, 0.8491793870925903, 0.8491793870925903, 0.8525750041007996, 0.8641765713691711, 0.8630446791648865, 0.8571024537086487, 0.8630446791648865, 0.8667232394218445, 0.86332768201828, 0.872665524482727, 0.8715336918830872, 0.8709677457809448, 0.8735144138336182, 0.8709677457809448, 0.8701188564300537, 0.8610639572143555, 0.8681380748748779, 0.8701188564300537, 0.8788907527923584, 0.879173755645752, 0.8856819272041321, 0.8780418634414673, 0.881154477596283, 0.8766270279884338, 0.8834182024002075], 'val_loss': [1.226643443107605, 1.2177129983901978, 1.2118667364120483, 1.1989967823028564, 1.1936134099960327, 1.1857231855392456, 1.1826485395431519, 1.1730728149414062, 1.1698938608169556, 1.1637015342712402, 1.1508688926696777, 1.1380293369293213, 1.1452243328094482, 1.1213808059692383, 1.120915174484253, 1.1056677103042603, 1.102455496788025, 1.088072419166565, 1.0818887948989868, 1.0776499509811401, 1.0748071670532227, 1.0767381191253662, 1.0788356065750122, 1.074318528175354, 1.064404010772705, 1.0663772821426392, 1.0710530281066895, 1.073415994644165, 1.0834929943084717, 1.073907732963562, 1.0811764001846313, 1.0785164833068848, 1.080777645111084, 1.0828760862350464, 1.0821641683578491, 1.091472864151001, 1.0934776067733765, 1.0902334451675415, 1.0991606712341309, 1.0845431089401245, 1.0802117586135864, 1.0893901586532593, 1.0990570783615112, 1.0918266773223877, 1.0933020114898682, 1.091657042503357, 1.0911403894424438, 1.0890737771987915, 1.0934842824935913, 1.093773365020752, 1.089566707611084, 1.0930098295211792, 1.0980348587036133, 1.1000406742095947, 1.0900884866714478, 1.091325283050537, 1.1018452644348145, 1.1077589988708496, 1.1049518585205078, 1.117480754852295, 1.1152560710906982, 1.0973622798919678, 1.110342264175415, 1.112349033355713, 1.1098614931106567, 1.1123000383377075, 1.1066607236862183, 1.1409815549850464, 1.1200199127197266, 1.111656665802002, 1.1193149089813232, 1.126922369003296, 1.1229712963104248, 1.127203106880188, 1.146209478378296, 1.1401782035827637, 1.1383696794509888, 1.1284706592559814, 1.1214905977249146, 1.1471877098083496, 1.1438382863998413, 1.1357022523880005, 1.1538012027740479, 1.1454578638076782, 1.1509026288986206, 1.1422722339630127, 1.1365861892700195, 1.1640422344207764, 1.155895709991455, 1.1641210317611694, 1.1767088174819946, 1.1567081212997437, 1.1551909446716309, 1.1494141817092896, 1.1694765090942383, 1.1534180641174316, 1.163734793663025, 1.1677035093307495, 1.1702314615249634, 1.1817033290863037], 'val_accuracy': [0.5090497732162476, 0.5113122463226318, 0.5124434232711792, 0.5180995464324951, 0.5214931964874268, 0.540723979473114, 0.5452488660812378, 0.5531674027442932, 0.5588235259056091, 0.5588235259056091, 0.5746606588363647, 0.5893664956092834, 0.5735294222831726, 0.6131221652030945, 0.6131221652030945, 0.6312217116355896, 0.6334841847419739, 0.6459276080131531, 0.6504524946212769, 0.6538461446762085, 0.6561086177825928, 0.6572397947311401, 0.6651583909988403, 0.6662895679473877, 0.6821267008781433, 0.6753393411636353, 0.6832579374313354, 0.6843891143798828, 0.6742081642150879, 0.6889140009880066, 0.685520350933075, 0.6843891143798828, 0.6809954643249512, 0.6843891143798828, 0.6832579374313354, 0.6708144545555115, 0.6549773812294006, 0.679864227771759, 0.6764705777168274, 0.6809954643249512, 0.6832579374313354, 0.6787330508232117, 0.662895917892456, 0.6764705777168274, 0.685520350933075, 0.679864227771759, 0.668552041053772, 0.6753393411636353, 0.6730769276618958, 0.6809954643249512, 0.6787330508232117, 0.6708144545555115, 0.6674208045005798, 0.6708144545555115, 0.6843891143798828, 0.6866515874862671, 0.6651583909988403, 0.6640271544456482, 0.6776018142700195, 0.6674208045005798, 0.6674208045005798, 0.6832579374313354, 0.6832579374313354, 0.6651583909988403, 0.679864227771759, 0.6719456911087036, 0.6764705777168274, 0.6549773812294006, 0.6742081642150879, 0.679864227771759, 0.6674208045005798, 0.6753393411636353, 0.6719456911087036, 0.6764705777168274, 0.6708144545555115, 0.6561086177825928, 0.6696832776069641, 0.6730769276618958, 0.6900452375411987, 0.6730769276618958, 0.6674208045005798, 0.6730769276618958, 0.6809954643249512, 0.6674208045005798, 0.6674208045005798, 0.6809954643249512, 0.6787330508232117, 0.6708144545555115, 0.6719456911087036, 0.6742081642150879, 0.6583710312843323, 0.6843891143798828, 0.6730769276618958, 0.6696832776069641, 0.6730769276618958, 0.6776018142700195, 0.6662895679473877, 0.6809954643249512, 0.6595022678375244, 0.6730769276618958]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 5s 28ms/step - loss: 1.0533 - accuracy: 0.7194 - val_loss: 1.2137 - val_accuracy: 0.5279\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 1.0232 - accuracy: 0.7344"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 1s 19ms/step - loss: 1.0357 - accuracy: 0.7302 - val_loss: 1.2102 - val_accuracy: 0.5289\n","Epoch 3/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0272 - accuracy: 0.7313 - val_loss: 1.2021 - val_accuracy: 0.5331\n","Epoch 4/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0211 - accuracy: 0.7349 - val_loss: 1.1966 - val_accuracy: 0.5382\n","Epoch 5/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0123 - accuracy: 0.7403 - val_loss: 1.1983 - val_accuracy: 0.5362\n","Epoch 6/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0068 - accuracy: 0.7393 - val_loss: 1.1809 - val_accuracy: 0.5434\n","Epoch 7/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9989 - accuracy: 0.7429 - val_loss: 1.1712 - val_accuracy: 0.5475\n","Epoch 8/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9916 - accuracy: 0.7463 - val_loss: 1.1662 - val_accuracy: 0.5465\n","Epoch 9/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9855 - accuracy: 0.7478 - val_loss: 1.1602 - val_accuracy: 0.5496\n","Epoch 10/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9797 - accuracy: 0.7556 - val_loss: 1.1551 - val_accuracy: 0.5589\n","Epoch 11/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9745 - accuracy: 0.7509 - val_loss: 1.1430 - val_accuracy: 0.5723\n","Epoch 12/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9670 - accuracy: 0.7587 - val_loss: 1.1303 - val_accuracy: 0.5878\n","Epoch 13/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9611 - accuracy: 0.7628 - val_loss: 1.1201 - val_accuracy: 0.6095\n","Epoch 14/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9576 - accuracy: 0.7615 - val_loss: 1.1090 - val_accuracy: 0.6209\n","Epoch 15/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.9478 - accuracy: 0.7636 - val_loss: 1.1013 - val_accuracy: 0.6291\n","Epoch 16/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9423 - accuracy: 0.7698 - val_loss: 1.0958 - val_accuracy: 0.6312\n","Epoch 17/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9405 - accuracy: 0.7649 - val_loss: 1.1045 - val_accuracy: 0.6136\n","Epoch 18/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9345 - accuracy: 0.7672 - val_loss: 1.0808 - val_accuracy: 0.6519\n","Epoch 19/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9279 - accuracy: 0.7749 - val_loss: 1.0896 - val_accuracy: 0.6519\n","Epoch 20/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9254 - accuracy: 0.7669 - val_loss: 1.0756 - val_accuracy: 0.6632\n","Epoch 21/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9190 - accuracy: 0.7724 - val_loss: 1.0743 - val_accuracy: 0.6653\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9143 - accuracy: 0.7762 - val_loss: 1.0765 - val_accuracy: 0.6653\n","Epoch 23/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9092 - accuracy: 0.7767 - val_loss: 1.0762 - val_accuracy: 0.6684\n","Epoch 24/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9004 - accuracy: 0.7819 - val_loss: 1.0787 - val_accuracy: 0.6653\n","Epoch 25/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8972 - accuracy: 0.7804 - val_loss: 1.0789 - val_accuracy: 0.6663\n","Epoch 26/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8907 - accuracy: 0.7884 - val_loss: 1.0856 - val_accuracy: 0.6601\n","Epoch 27/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8872 - accuracy: 0.7881 - val_loss: 1.0825 - val_accuracy: 0.6632\n","Epoch 28/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8842 - accuracy: 0.7876 - val_loss: 1.0889 - val_accuracy: 0.6632\n","Epoch 29/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8764 - accuracy: 0.7912 - val_loss: 1.0917 - val_accuracy: 0.6519\n","Epoch 30/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8743 - accuracy: 0.7910 - val_loss: 1.0969 - val_accuracy: 0.6684\n","Epoch 31/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8701 - accuracy: 0.7938 - val_loss: 1.0922 - val_accuracy: 0.6560\n","Epoch 32/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8627 - accuracy: 0.7990 - val_loss: 1.0980 - val_accuracy: 0.6591\n","Epoch 33/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8586 - accuracy: 0.7997 - val_loss: 1.1000 - val_accuracy: 0.6653\n","Epoch 34/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8555 - accuracy: 0.7956 - val_loss: 1.1018 - val_accuracy: 0.6539\n","Epoch 35/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8535 - accuracy: 0.7969 - val_loss: 1.1073 - val_accuracy: 0.6488\n","Epoch 36/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8471 - accuracy: 0.7997 - val_loss: 1.1030 - val_accuracy: 0.6581\n","Epoch 37/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8402 - accuracy: 0.8049 - val_loss: 1.0995 - val_accuracy: 0.6529\n","Epoch 38/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8351 - accuracy: 0.8034 - val_loss: 1.1013 - val_accuracy: 0.6550\n","Epoch 39/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8321 - accuracy: 0.8018 - val_loss: 1.1015 - val_accuracy: 0.6581\n","Epoch 40/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8262 - accuracy: 0.8090 - val_loss: 1.1127 - val_accuracy: 0.6467\n","Epoch 41/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8219 - accuracy: 0.8129 - val_loss: 1.1010 - val_accuracy: 0.6581\n","Epoch 42/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8172 - accuracy: 0.8121 - val_loss: 1.0992 - val_accuracy: 0.6539\n","Epoch 43/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8128 - accuracy: 0.8096 - val_loss: 1.1130 - val_accuracy: 0.6498\n","Epoch 44/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8143 - accuracy: 0.8078 - val_loss: 1.1183 - val_accuracy: 0.6384\n","Epoch 45/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8101 - accuracy: 0.8121 - val_loss: 1.1208 - val_accuracy: 0.6395\n","Epoch 46/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8044 - accuracy: 0.8080 - val_loss: 1.1140 - val_accuracy: 0.6477\n","Epoch 47/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7983 - accuracy: 0.8155 - val_loss: 1.1235 - val_accuracy: 0.6436\n","Epoch 48/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7917 - accuracy: 0.8176 - val_loss: 1.1077 - val_accuracy: 0.6550\n","Epoch 49/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7885 - accuracy: 0.8178 - val_loss: 1.1125 - val_accuracy: 0.6550\n","Epoch 50/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7870 - accuracy: 0.8132 - val_loss: 1.1203 - val_accuracy: 0.6539\n","Epoch 51/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7804 - accuracy: 0.8196 - val_loss: 1.1190 - val_accuracy: 0.6508\n","Epoch 52/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7767 - accuracy: 0.8240 - val_loss: 1.1351 - val_accuracy: 0.6477\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7732 - accuracy: 0.8271 - val_loss: 1.1195 - val_accuracy: 0.6529\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7694 - accuracy: 0.8271 - val_loss: 1.1245 - val_accuracy: 0.6457\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7645 - accuracy: 0.8251 - val_loss: 1.1311 - val_accuracy: 0.6457\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7638 - accuracy: 0.8253 - val_loss: 1.1287 - val_accuracy: 0.6477\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7576 - accuracy: 0.8266 - val_loss: 1.1383 - val_accuracy: 0.6467\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7565 - accuracy: 0.8284 - val_loss: 1.1307 - val_accuracy: 0.6581\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7527 - accuracy: 0.8357 - val_loss: 1.1222 - val_accuracy: 0.6550\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7442 - accuracy: 0.8313 - val_loss: 1.1377 - val_accuracy: 0.6384\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7423 - accuracy: 0.8377 - val_loss: 1.1318 - val_accuracy: 0.6539\n","Epoch 62/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7403 - accuracy: 0.8315 - val_loss: 1.1393 - val_accuracy: 0.6488\n","Epoch 63/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7342 - accuracy: 0.8354 - val_loss: 1.1403 - val_accuracy: 0.6508\n","Epoch 64/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7295 - accuracy: 0.8434 - val_loss: 1.1301 - val_accuracy: 0.6477\n","Epoch 65/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7279 - accuracy: 0.8434 - val_loss: 1.1466 - val_accuracy: 0.6508\n","Epoch 66/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7313 - accuracy: 0.8310 - val_loss: 1.1615 - val_accuracy: 0.6457\n","Epoch 67/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7245 - accuracy: 0.8416 - val_loss: 1.1481 - val_accuracy: 0.6529\n","Epoch 68/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7237 - accuracy: 0.8401 - val_loss: 1.1503 - val_accuracy: 0.6457\n","Epoch 69/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7128 - accuracy: 0.8442 - val_loss: 1.1566 - val_accuracy: 0.6488\n","Epoch 70/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7108 - accuracy: 0.8447 - val_loss: 1.1537 - val_accuracy: 0.6488\n","Epoch 71/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7071 - accuracy: 0.8437 - val_loss: 1.1869 - val_accuracy: 0.6415\n","Epoch 72/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7048 - accuracy: 0.8506 - val_loss: 1.1542 - val_accuracy: 0.6436\n","Epoch 73/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6982 - accuracy: 0.8519 - val_loss: 1.1775 - val_accuracy: 0.6488\n","Epoch 74/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6964 - accuracy: 0.8486 - val_loss: 1.1517 - val_accuracy: 0.6560\n","Epoch 75/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6913 - accuracy: 0.8514 - val_loss: 1.1973 - val_accuracy: 0.6426\n","Epoch 76/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6915 - accuracy: 0.8540 - val_loss: 1.1626 - val_accuracy: 0.6519\n","Epoch 77/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6906 - accuracy: 0.8452 - val_loss: 1.1799 - val_accuracy: 0.6426\n","Epoch 78/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6874 - accuracy: 0.8504 - val_loss: 1.1636 - val_accuracy: 0.6550\n","Epoch 79/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6786 - accuracy: 0.8558 - val_loss: 1.1659 - val_accuracy: 0.6488\n","Epoch 80/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6778 - accuracy: 0.8579 - val_loss: 1.2032 - val_accuracy: 0.6426\n","Epoch 81/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6772 - accuracy: 0.8525 - val_loss: 1.1956 - val_accuracy: 0.6405\n","Epoch 82/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6727 - accuracy: 0.8587 - val_loss: 1.1717 - val_accuracy: 0.6519\n","Epoch 83/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6735 - accuracy: 0.8556 - val_loss: 1.1931 - val_accuracy: 0.6488\n","Epoch 84/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6682 - accuracy: 0.8599 - val_loss: 1.1832 - val_accuracy: 0.6498\n","Epoch 85/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6629 - accuracy: 0.8646 - val_loss: 1.1870 - val_accuracy: 0.6488\n","Epoch 86/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6573 - accuracy: 0.8649 - val_loss: 1.1929 - val_accuracy: 0.6508\n","Epoch 87/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6570 - accuracy: 0.8651 - val_loss: 1.1931 - val_accuracy: 0.6488\n","Epoch 88/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6512 - accuracy: 0.8718 - val_loss: 1.2050 - val_accuracy: 0.6498\n","Epoch 89/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6493 - accuracy: 0.8682 - val_loss: 1.1944 - val_accuracy: 0.6622\n","Epoch 90/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6467 - accuracy: 0.8731 - val_loss: 1.2204 - val_accuracy: 0.6436\n","Epoch 91/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6428 - accuracy: 0.8718 - val_loss: 1.2387 - val_accuracy: 0.6364\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6460 - accuracy: 0.8643 - val_loss: 1.2247 - val_accuracy: 0.6426\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6364 - accuracy: 0.8726 - val_loss: 1.2149 - val_accuracy: 0.6529\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6376 - accuracy: 0.8734 - val_loss: 1.2493 - val_accuracy: 0.6436\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6336 - accuracy: 0.8752 - val_loss: 1.2128 - val_accuracy: 0.6529\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6284 - accuracy: 0.8762 - val_loss: 1.2300 - val_accuracy: 0.6498\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6327 - accuracy: 0.8752 - val_loss: 1.2250 - val_accuracy: 0.6467\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6281 - accuracy: 0.8731 - val_loss: 1.2229 - val_accuracy: 0.6477\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6289 - accuracy: 0.8736 - val_loss: 1.2543 - val_accuracy: 0.6457\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6295 - accuracy: 0.8716 - val_loss: 1.2443 - val_accuracy: 0.6395\n","{'loss': [1.05328369140625, 1.0357024669647217, 1.027221918106079, 1.0210932493209839, 1.0123467445373535, 1.0068068504333496, 0.998906672000885, 0.9915598630905151, 0.9854996800422668, 0.9797282814979553, 0.9744539856910706, 0.966957688331604, 0.9611351490020752, 0.9575923681259155, 0.947841465473175, 0.942315936088562, 0.9404565691947937, 0.9344949722290039, 0.9278650283813477, 0.9253960251808167, 0.9190272092819214, 0.9142782092094421, 0.9091843962669373, 0.9004435539245605, 0.897243320941925, 0.8906649351119995, 0.8871919512748718, 0.8842055797576904, 0.8764320015907288, 0.8742673993110657, 0.8701178431510925, 0.86273592710495, 0.8585803508758545, 0.8554829359054565, 0.8534623384475708, 0.8471441268920898, 0.8402292132377625, 0.8350668549537659, 0.8320873379707336, 0.8262487649917603, 0.8219252824783325, 0.8172021508216858, 0.8127908706665039, 0.8143105506896973, 0.8101435899734497, 0.804445743560791, 0.7982863187789917, 0.7916939854621887, 0.7885056734085083, 0.7869512438774109, 0.7803535461425781, 0.7766845226287842, 0.7731973528862, 0.7693626284599304, 0.7645220756530762, 0.7638410925865173, 0.7575518488883972, 0.7565233111381531, 0.7526822090148926, 0.7441621422767639, 0.7423238754272461, 0.7403428554534912, 0.734173059463501, 0.729541003704071, 0.727945864200592, 0.7313489317893982, 0.7245347499847412, 0.7236952185630798, 0.7127830982208252, 0.7108100652694702, 0.7071489095687866, 0.7048076391220093, 0.698213517665863, 0.6963840126991272, 0.6912703514099121, 0.6914724707603455, 0.6906243562698364, 0.6874290704727173, 0.6785697340965271, 0.6777600646018982, 0.6771624088287354, 0.6726688742637634, 0.6735100746154785, 0.6681560277938843, 0.6629021763801575, 0.657322347164154, 0.6569719314575195, 0.6511688232421875, 0.6492762565612793, 0.6467449069023132, 0.642837643623352, 0.6459901928901672, 0.6363873481750488, 0.6376379728317261, 0.6336231231689453, 0.6284018158912659, 0.6326691508293152, 0.6281449198722839, 0.6288644671440125, 0.6294572949409485], 'accuracy': [0.7193798422813416, 0.7302325367927551, 0.7312661409378052, 0.734883725643158, 0.7403100728988647, 0.7392764687538147, 0.7428940534591675, 0.746253252029419, 0.7478036284446716, 0.7555555701255798, 0.750904381275177, 0.7586563229560852, 0.7627906799316406, 0.7614986896514893, 0.7635658979415894, 0.7697674632072449, 0.7648578882217407, 0.7671834826469421, 0.7749354243278503, 0.766925036907196, 0.7723514437675476, 0.7762274146080017, 0.7767441868782043, 0.7819121479988098, 0.7803617715835571, 0.7883720993995667, 0.7881137132644653, 0.7875968813896179, 0.7912144660949707, 0.7909560799598694, 0.7937984466552734, 0.7989664077758789, 0.7997416257858276, 0.7956072092056274, 0.7968991994857788, 0.7997416257858276, 0.8049095869064331, 0.8033591508865356, 0.801808774471283, 0.8090439438819885, 0.8129199147224426, 0.8121446967124939, 0.8095607161521912, 0.8077519536018372, 0.8121446967124939, 0.8080103397369385, 0.8155038952827454, 0.8175710439682007, 0.817829430103302, 0.813178300857544, 0.8196382522583008, 0.8240309953689575, 0.8271318078041077, 0.8271318078041077, 0.8250645995140076, 0.8253229856491089, 0.8266149759292603, 0.828423798084259, 0.8356589078903198, 0.8312661647796631, 0.8377261161804199, 0.8315245509147644, 0.8354005217552185, 0.843410849571228, 0.843410849571228, 0.8310077786445618, 0.841602087020874, 0.8400516510009766, 0.8441860675811768, 0.8447028398513794, 0.8436692357063293, 0.8506460189819336, 0.851938009262085, 0.8485788106918335, 0.8514211773872375, 0.8540051579475403, 0.845219612121582, 0.8503875732421875, 0.8558139801025391, 0.8578811287879944, 0.8524547815322876, 0.8586563467979431, 0.855555534362793, 0.8599483370780945, 0.8645994663238525, 0.8648578524589539, 0.8651162981987, 0.8718346357345581, 0.8682170510292053, 0.8731266260147095, 0.8718346357345581, 0.8643410801887512, 0.8726097941398621, 0.8733850121498108, 0.8751937747001648, 0.8762273788452148, 0.8751937747001648, 0.8731266260147095, 0.8736433982849121, 0.8715762495994568], 'val_loss': [1.2137380838394165, 1.2101597785949707, 1.202069640159607, 1.1966427564620972, 1.1982921361923218, 1.180867075920105, 1.171244740486145, 1.1661967039108276, 1.1602379083633423, 1.1551499366760254, 1.1430139541625977, 1.1303446292877197, 1.120097041130066, 1.1090443134307861, 1.1013236045837402, 1.095819115638733, 1.104486346244812, 1.080804705619812, 1.0895687341690063, 1.0756090879440308, 1.0742805004119873, 1.0765339136123657, 1.0762126445770264, 1.0786516666412354, 1.0789155960083008, 1.085646390914917, 1.0824695825576782, 1.0889192819595337, 1.0916614532470703, 1.0969007015228271, 1.0922410488128662, 1.0980310440063477, 1.100029706954956, 1.1017870903015137, 1.107330083847046, 1.1030381917953491, 1.0995196104049683, 1.1013156175613403, 1.1015424728393555, 1.112650752067566, 1.101008415222168, 1.099205493927002, 1.1130362749099731, 1.118303656578064, 1.12079656124115, 1.113989233970642, 1.1235450506210327, 1.1076892614364624, 1.112503170967102, 1.1203051805496216, 1.1190152168273926, 1.1351336240768433, 1.1195155382156372, 1.1245033740997314, 1.1311252117156982, 1.1286855936050415, 1.138339877128601, 1.1306601762771606, 1.1222374439239502, 1.137699842453003, 1.1318223476409912, 1.1392576694488525, 1.1403483152389526, 1.130071997642517, 1.1466224193572998, 1.1615301370620728, 1.1481386423110962, 1.1502578258514404, 1.1566327810287476, 1.1536763906478882, 1.1868847608566284, 1.1542158126831055, 1.1775068044662476, 1.1516637802124023, 1.197271704673767, 1.162556529045105, 1.179855227470398, 1.1636420488357544, 1.1659332513809204, 1.203170895576477, 1.1956017017364502, 1.171746015548706, 1.1930854320526123, 1.183170199394226, 1.1870313882827759, 1.1928993463516235, 1.1930571794509888, 1.2049599885940552, 1.1944435834884644, 1.2204161882400513, 1.2386783361434937, 1.2246577739715576, 1.2148635387420654, 1.249326229095459, 1.212837815284729, 1.2299792766571045, 1.2250157594680786, 1.2229467630386353, 1.2542580366134644, 1.2443081140518188], 'val_accuracy': [0.5278925895690918, 0.5289255976676941, 0.5330578684806824, 0.538223147392273, 0.5361570119857788, 0.5433884263038635, 0.547520637512207, 0.5464876294136047, 0.5495867729187012, 0.55888432264328, 0.5723140239715576, 0.5878099203109741, 0.6095041036605835, 0.6208677887916565, 0.6291322112083435, 0.6311983466148376, 0.6136363744735718, 0.6518595218658447, 0.6518595218658447, 0.663223147392273, 0.6652892827987671, 0.6652892827987671, 0.6683884263038635, 0.6652892827987671, 0.6663222908973694, 0.6601239442825317, 0.663223147392273, 0.663223147392273, 0.6518595218658447, 0.6683884263038635, 0.6559917330741882, 0.6590909361839294, 0.6652892827987671, 0.6539255976676941, 0.6487603187561035, 0.6580578684806824, 0.6528925895690918, 0.6549586653709412, 0.6580578684806824, 0.6466942429542542, 0.6580578684806824, 0.6539255976676941, 0.6497933864593506, 0.6384297609329224, 0.6394628286361694, 0.6477272510528564, 0.6435950398445129, 0.6549586653709412, 0.6549586653709412, 0.6539255976676941, 0.6508264541625977, 0.6477272510528564, 0.6528925895690918, 0.6456611752510071, 0.6456611752510071, 0.6477272510528564, 0.6466942429542542, 0.6580578684806824, 0.6549586653709412, 0.6384297609329224, 0.6539255976676941, 0.6487603187561035, 0.6508264541625977, 0.6477272510528564, 0.6508264541625977, 0.6456611752510071, 0.6528925895690918, 0.6456611752510071, 0.6487603187561035, 0.6487603187561035, 0.6415289044380188, 0.6435950398445129, 0.6487603187561035, 0.6559917330741882, 0.6425619721412659, 0.6518595218658447, 0.6425619721412659, 0.6549586653709412, 0.6487603187561035, 0.6425619721412659, 0.6404958963394165, 0.6518595218658447, 0.6487603187561035, 0.6497933864593506, 0.6487603187561035, 0.6508264541625977, 0.6487603187561035, 0.6497933864593506, 0.6621900796890259, 0.6435950398445129, 0.6363636255264282, 0.6425619721412659, 0.6528925895690918, 0.6435950398445129, 0.6528925895690918, 0.6497933864593506, 0.6466942429542542, 0.6477272510528564, 0.6456611752510071, 0.6394628286361694]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 28ms/step - loss: 0.7168 - accuracy: 0.8332 - val_loss: 1.0570 - val_accuracy: 0.5550\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.7319 - accuracy: 0.8047"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 10ms/step - loss: 0.6897 - accuracy: 0.8381 - val_loss: 1.0718 - val_accuracy: 0.5550\n","Epoch 3/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6776 - accuracy: 0.8483 - val_loss: 1.0375 - val_accuracy: 0.5776\n","Epoch 4/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6720 - accuracy: 0.8478 - val_loss: 1.0119 - val_accuracy: 0.5938\n","Epoch 5/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.6676 - accuracy: 0.8526 - val_loss: 1.0162 - val_accuracy: 0.5991\n","Epoch 6/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6631 - accuracy: 0.8529 - val_loss: 0.9978 - val_accuracy: 0.6067\n","Epoch 7/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6664 - accuracy: 0.8588 - val_loss: 0.9836 - val_accuracy: 0.6131\n","Epoch 8/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6547 - accuracy: 0.8580 - val_loss: 0.9754 - val_accuracy: 0.6142\n","Epoch 9/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6501 - accuracy: 0.8575 - val_loss: 0.9623 - val_accuracy: 0.6261\n","Epoch 10/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6476 - accuracy: 0.8658 - val_loss: 0.9512 - val_accuracy: 0.6422\n","Epoch 11/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6440 - accuracy: 0.8688 - val_loss: 0.9436 - val_accuracy: 0.6562\n","Epoch 12/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6383 - accuracy: 0.8707 - val_loss: 0.9375 - val_accuracy: 0.6616\n","Epoch 13/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6355 - accuracy: 0.8707 - val_loss: 0.9297 - val_accuracy: 0.6670\n","Epoch 14/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6310 - accuracy: 0.8691 - val_loss: 0.9150 - val_accuracy: 0.6843\n","Epoch 15/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6336 - accuracy: 0.8737 - val_loss: 0.9088 - val_accuracy: 0.6907\n","Epoch 16/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6238 - accuracy: 0.8726 - val_loss: 0.9033 - val_accuracy: 0.7166\n","Epoch 17/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6248 - accuracy: 0.8720 - val_loss: 0.8922 - val_accuracy: 0.7069\n","Epoch 18/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6161 - accuracy: 0.8828 - val_loss: 0.8878 - val_accuracy: 0.7134\n","Epoch 19/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6145 - accuracy: 0.8834 - val_loss: 0.8850 - val_accuracy: 0.7198\n","Epoch 20/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6121 - accuracy: 0.8842 - val_loss: 0.8975 - val_accuracy: 0.6950\n","Epoch 21/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6098 - accuracy: 0.8834 - val_loss: 0.8853 - val_accuracy: 0.7338\n","Epoch 22/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6095 - accuracy: 0.8820 - val_loss: 0.8924 - val_accuracy: 0.7220\n","Epoch 23/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6046 - accuracy: 0.8893 - val_loss: 0.8888 - val_accuracy: 0.7317\n","Epoch 24/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6062 - accuracy: 0.8825 - val_loss: 0.9017 - val_accuracy: 0.7252\n","Epoch 25/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6026 - accuracy: 0.8815 - val_loss: 0.9020 - val_accuracy: 0.7349\n","Epoch 26/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5988 - accuracy: 0.8850 - val_loss: 0.9043 - val_accuracy: 0.7360\n","Epoch 27/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5984 - accuracy: 0.8879 - val_loss: 0.9237 - val_accuracy: 0.7209\n","Epoch 28/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5897 - accuracy: 0.8920 - val_loss: 0.9339 - val_accuracy: 0.7198\n","Epoch 29/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5892 - accuracy: 0.8909 - val_loss: 0.9278 - val_accuracy: 0.7284\n","Epoch 30/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5867 - accuracy: 0.8901 - val_loss: 0.9381 - val_accuracy: 0.7241\n","Epoch 31/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5858 - accuracy: 0.8882 - val_loss: 0.9341 - val_accuracy: 0.7295\n","Epoch 32/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5798 - accuracy: 0.8949 - val_loss: 0.9395 - val_accuracy: 0.7349\n","Epoch 33/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5770 - accuracy: 0.8974 - val_loss: 0.9480 - val_accuracy: 0.7263\n","Epoch 34/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5752 - accuracy: 0.8944 - val_loss: 0.9530 - val_accuracy: 0.7360\n","Epoch 35/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5737 - accuracy: 0.8941 - val_loss: 0.9486 - val_accuracy: 0.7274\n","Epoch 36/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5690 - accuracy: 0.8976 - val_loss: 0.9541 - val_accuracy: 0.7263\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5711 - accuracy: 0.8952 - val_loss: 0.9690 - val_accuracy: 0.7220\n","Epoch 38/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5768 - accuracy: 0.8941 - val_loss: 0.9734 - val_accuracy: 0.7166\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5729 - accuracy: 0.8998 - val_loss: 0.9587 - val_accuracy: 0.7274\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5644 - accuracy: 0.8971 - val_loss: 0.9692 - val_accuracy: 0.7241\n","Epoch 41/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5607 - accuracy: 0.9030 - val_loss: 0.9575 - val_accuracy: 0.7328\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5522 - accuracy: 0.9033 - val_loss: 0.9663 - val_accuracy: 0.7274\n","Epoch 43/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5547 - accuracy: 0.9054 - val_loss: 0.9728 - val_accuracy: 0.7241\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5548 - accuracy: 0.9038 - val_loss: 0.9771 - val_accuracy: 0.7252\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5511 - accuracy: 0.9092 - val_loss: 0.9814 - val_accuracy: 0.7252\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5450 - accuracy: 0.9046 - val_loss: 0.9728 - val_accuracy: 0.7306\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5389 - accuracy: 0.9151 - val_loss: 0.9726 - val_accuracy: 0.7252\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5397 - accuracy: 0.9141 - val_loss: 0.9718 - val_accuracy: 0.7317\n","Epoch 49/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5383 - accuracy: 0.9116 - val_loss: 0.9814 - val_accuracy: 0.7284\n","Epoch 50/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5341 - accuracy: 0.9122 - val_loss: 0.9799 - val_accuracy: 0.7306\n","Epoch 51/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5331 - accuracy: 0.9138 - val_loss: 1.0103 - val_accuracy: 0.7155\n","Epoch 52/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5370 - accuracy: 0.9089 - val_loss: 0.9870 - val_accuracy: 0.7263\n","Epoch 53/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5253 - accuracy: 0.9181 - val_loss: 0.9892 - val_accuracy: 0.7252\n","Epoch 54/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5264 - accuracy: 0.9154 - val_loss: 1.0081 - val_accuracy: 0.7241\n","Epoch 55/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5377 - accuracy: 0.9060 - val_loss: 1.0073 - val_accuracy: 0.7252\n","Epoch 56/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5317 - accuracy: 0.9079 - val_loss: 1.0266 - val_accuracy: 0.7263\n","Epoch 57/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5353 - accuracy: 0.9044 - val_loss: 1.0627 - val_accuracy: 0.7058\n","Epoch 58/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5262 - accuracy: 0.9146 - val_loss: 1.0229 - val_accuracy: 0.7295\n","Epoch 59/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5218 - accuracy: 0.9138 - val_loss: 1.0350 - val_accuracy: 0.7166\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5195 - accuracy: 0.9205 - val_loss: 1.0038 - val_accuracy: 0.7252\n","Epoch 61/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5145 - accuracy: 0.9168 - val_loss: 1.0023 - val_accuracy: 0.7241\n","Epoch 62/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5126 - accuracy: 0.9203 - val_loss: 1.0166 - val_accuracy: 0.7284\n","Epoch 63/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5106 - accuracy: 0.9170 - val_loss: 1.0167 - val_accuracy: 0.7220\n","Epoch 64/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5088 - accuracy: 0.9189 - val_loss: 1.0576 - val_accuracy: 0.7112\n","Epoch 65/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5046 - accuracy: 0.9238 - val_loss: 1.0379 - val_accuracy: 0.7231\n","Epoch 66/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5195 - accuracy: 0.9154 - val_loss: 1.0337 - val_accuracy: 0.7209\n","Epoch 67/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5178 - accuracy: 0.9106 - val_loss: 1.0832 - val_accuracy: 0.7112\n","Epoch 68/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5484 - accuracy: 0.8995 - val_loss: 1.1135 - val_accuracy: 0.7058\n","Epoch 69/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5238 - accuracy: 0.9165 - val_loss: 1.1120 - val_accuracy: 0.7177\n","Epoch 70/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5228 - accuracy: 0.9165 - val_loss: 1.0658 - val_accuracy: 0.7091\n","Epoch 71/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5025 - accuracy: 0.9184 - val_loss: 1.0331 - val_accuracy: 0.7231\n","Epoch 72/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4917 - accuracy: 0.9273 - val_loss: 1.0298 - val_accuracy: 0.7188\n","Epoch 73/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4964 - accuracy: 0.9232 - val_loss: 1.0350 - val_accuracy: 0.7263\n","Epoch 74/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4984 - accuracy: 0.9186 - val_loss: 1.0289 - val_accuracy: 0.7209\n","Epoch 75/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4902 - accuracy: 0.9265 - val_loss: 1.0420 - val_accuracy: 0.7220\n","Epoch 76/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4913 - accuracy: 0.9254 - val_loss: 1.0442 - val_accuracy: 0.7198\n","Epoch 77/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4852 - accuracy: 0.9283 - val_loss: 1.0715 - val_accuracy: 0.7058\n","Epoch 78/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4963 - accuracy: 0.9208 - val_loss: 1.0446 - val_accuracy: 0.7188\n","Epoch 79/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4896 - accuracy: 0.9259 - val_loss: 1.0893 - val_accuracy: 0.7144\n","Epoch 80/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4840 - accuracy: 0.9283 - val_loss: 1.0600 - val_accuracy: 0.7198\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4797 - accuracy: 0.9286 - val_loss: 1.0572 - val_accuracy: 0.7198\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4805 - accuracy: 0.9313 - val_loss: 1.0828 - val_accuracy: 0.7166\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4836 - accuracy: 0.9275 - val_loss: 1.0615 - val_accuracy: 0.7155\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4757 - accuracy: 0.9286 - val_loss: 1.0600 - val_accuracy: 0.7198\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4738 - accuracy: 0.9351 - val_loss: 1.0805 - val_accuracy: 0.7220\n","Epoch 86/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4713 - accuracy: 0.9353 - val_loss: 1.0821 - val_accuracy: 0.7177\n","Epoch 87/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4735 - accuracy: 0.9294 - val_loss: 1.0785 - val_accuracy: 0.7274\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4796 - accuracy: 0.9275 - val_loss: 1.0921 - val_accuracy: 0.7198\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4711 - accuracy: 0.9308 - val_loss: 1.0808 - val_accuracy: 0.7112\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4747 - accuracy: 0.9310 - val_loss: 1.1139 - val_accuracy: 0.7220\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4655 - accuracy: 0.9351 - val_loss: 1.1064 - val_accuracy: 0.7101\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4634 - accuracy: 0.9391 - val_loss: 1.0826 - val_accuracy: 0.7134\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4778 - accuracy: 0.9254 - val_loss: 1.1345 - val_accuracy: 0.7091\n","Epoch 94/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4755 - accuracy: 0.9294 - val_loss: 1.1537 - val_accuracy: 0.7155\n","Epoch 95/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4778 - accuracy: 0.9256 - val_loss: 1.2246 - val_accuracy: 0.6832\n","Epoch 96/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4785 - accuracy: 0.9286 - val_loss: 1.1542 - val_accuracy: 0.7198\n","Epoch 97/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4663 - accuracy: 0.9329 - val_loss: 1.1122 - val_accuracy: 0.7209\n","Epoch 98/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4626 - accuracy: 0.9327 - val_loss: 1.1361 - val_accuracy: 0.7123\n","Epoch 99/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4669 - accuracy: 0.9399 - val_loss: 1.1005 - val_accuracy: 0.7177\n","Epoch 100/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4509 - accuracy: 0.9423 - val_loss: 1.1008 - val_accuracy: 0.7123\n","{'loss': [0.7167915105819702, 0.6897171139717102, 0.6776455640792847, 0.6719589233398438, 0.6676106452941895, 0.6631169319152832, 0.6663949489593506, 0.6546667814254761, 0.6501116752624512, 0.6476088762283325, 0.6440151929855347, 0.6383264064788818, 0.6355353593826294, 0.6310229301452637, 0.6335758566856384, 0.6238477826118469, 0.62481290102005, 0.6160670518875122, 0.6144517660140991, 0.6121090650558472, 0.6097788214683533, 0.6094785332679749, 0.6046419739723206, 0.60617995262146, 0.6025590300559998, 0.598755419254303, 0.598353922367096, 0.5897231101989746, 0.5891782641410828, 0.5867422819137573, 0.5857921838760376, 0.5798062682151794, 0.5770236253738403, 0.5752442479133606, 0.5737331509590149, 0.5690186023712158, 0.5710835456848145, 0.5768464207649231, 0.572891891002655, 0.5643919110298157, 0.5607102513313293, 0.552217960357666, 0.5547345280647278, 0.5548385381698608, 0.55113685131073, 0.5450419187545776, 0.5389044284820557, 0.5397027730941772, 0.5383279323577881, 0.5340678095817566, 0.533053994178772, 0.5370133519172668, 0.5253289341926575, 0.5263523459434509, 0.5377265810966492, 0.5317455530166626, 0.5353138446807861, 0.5261843204498291, 0.5217624306678772, 0.5195372104644775, 0.5145284533500671, 0.5126141309738159, 0.5106364488601685, 0.508843183517456, 0.5046272873878479, 0.5194881558418274, 0.5178404450416565, 0.5484267473220825, 0.5238419771194458, 0.5227957367897034, 0.5024959444999695, 0.49170616269111633, 0.496444433927536, 0.49838611483573914, 0.49018269777297974, 0.49131256341934204, 0.485238254070282, 0.4963042140007019, 0.4896034002304077, 0.48401713371276855, 0.47965502738952637, 0.48053473234176636, 0.48355230689048767, 0.4756564199924469, 0.47383826971054077, 0.47130724787712097, 0.4735219478607178, 0.47961169481277466, 0.47109726071357727, 0.4747035503387451, 0.46552762389183044, 0.46336087584495544, 0.4778467118740082, 0.47550150752067566, 0.47778022289276123, 0.47849345207214355, 0.46629950404167175, 0.4625537693500519, 0.46691077947616577, 0.4509050250053406], 'accuracy': [0.8332435488700867, 0.8380926847457886, 0.8483297228813171, 0.8477909564971924, 0.8526400923728943, 0.852909505367279, 0.8588362336158752, 0.858027994632721, 0.8574892282485962, 0.865840494632721, 0.868803858757019, 0.8706896305084229, 0.8706896305084229, 0.8690732717514038, 0.873652994632721, 0.8725754022598267, 0.8720366358757019, 0.8828125, 0.8833512663841248, 0.884159505367279, 0.8833512663841248, 0.8820043206214905, 0.889277994632721, 0.8825430870056152, 0.881465494632721, 0.8849676847457886, 0.8879310488700867, 0.891972005367279, 0.8908944129943848, 0.8900862336158752, 0.8882004022598267, 0.8949353694915771, 0.8973599076271057, 0.8943965435028076, 0.8941271305084229, 0.8976293206214905, 0.8952047228813171, 0.8941271305084229, 0.899784505367279, 0.897090494632721, 0.9030172228813171, 0.9032866358757019, 0.9054418206214905, 0.9038254022598267, 0.9092133641242981, 0.904633641242981, 0.9151400923728943, 0.9140625, 0.9116379022598267, 0.9121767282485962, 0.9137930870056152, 0.9089439511299133, 0.9181034564971924, 0.915409505367279, 0.9059805870056152, 0.907866358757019, 0.9043642282485962, 0.9146012663841248, 0.9137930870056152, 0.920527994632721, 0.9167564511299133, 0.920258641242981, 0.9170258641242981, 0.9189116358757019, 0.9237607717514038, 0.915409505367279, 0.9105603694915771, 0.8995150923728943, 0.9164870977401733, 0.9164870977401733, 0.9183728694915771, 0.9272629022598267, 0.923222005367279, 0.9186422228813171, 0.9264547228813171, 0.9253771305084229, 0.928340494632721, 0.9207974076271057, 0.9259159564971924, 0.928340494632721, 0.9286099076271057, 0.931303858757019, 0.9275323152542114, 0.9286099076271057, 0.9350754022598267, 0.9353448152542114, 0.9294180870056152, 0.9275323152542114, 0.9307650923728943, 0.931034505367279, 0.9350754022598267, 0.939116358757019, 0.9253771305084229, 0.9294180870056152, 0.9256465435028076, 0.9286099076271057, 0.9329202771186829, 0.9326508641242981, 0.9399245977401733, 0.9423491358757019], 'val_loss': [1.0569732189178467, 1.0717847347259521, 1.0374815464019775, 1.011940836906433, 1.0161552429199219, 0.9978286027908325, 0.9836337566375732, 0.9754306674003601, 0.9622674584388733, 0.9511542916297913, 0.9436306357383728, 0.9375015497207642, 0.9296616315841675, 0.9150068163871765, 0.908804178237915, 0.9033066034317017, 0.8921999931335449, 0.8877739906311035, 0.8849934339523315, 0.8974747061729431, 0.885288417339325, 0.8923801779747009, 0.8888256549835205, 0.901724100112915, 0.9019924402236938, 0.9042569398880005, 0.9236611127853394, 0.9338904023170471, 0.9277952313423157, 0.9381046891212463, 0.9340616464614868, 0.939520537853241, 0.9479772448539734, 0.952962338924408, 0.948578417301178, 0.954124391078949, 0.9689584374427795, 0.9733790755271912, 0.9586585760116577, 0.9692242741584778, 0.9574798941612244, 0.9663374423980713, 0.9728335738182068, 0.9770654439926147, 0.9813883304595947, 0.9727676510810852, 0.9725982546806335, 0.9717875123023987, 0.9814245104789734, 0.9799257516860962, 1.0103212594985962, 0.9870085716247559, 0.989249587059021, 1.0080580711364746, 1.0072537660598755, 1.0266156196594238, 1.0626884698867798, 1.022864818572998, 1.0350321531295776, 1.0038334131240845, 1.0022660493850708, 1.0165886878967285, 1.0166760683059692, 1.05763578414917, 1.0378599166870117, 1.0337259769439697, 1.0832393169403076, 1.113482117652893, 1.1120457649230957, 1.0658292770385742, 1.033144235610962, 1.0297750234603882, 1.0350072383880615, 1.0288581848144531, 1.042033314704895, 1.0442334413528442, 1.0715312957763672, 1.0446337461471558, 1.0892523527145386, 1.0599541664123535, 1.057171106338501, 1.082809329032898, 1.061537265777588, 1.06001877784729, 1.0805050134658813, 1.0820808410644531, 1.0785256624221802, 1.0921494960784912, 1.0808483362197876, 1.1139161586761475, 1.1064189672470093, 1.0826494693756104, 1.1345096826553345, 1.1537059545516968, 1.2246465682983398, 1.1541777849197388, 1.1122385263442993, 1.1361364126205444, 1.1004507541656494, 1.1008172035217285], 'val_accuracy': [0.5549569129943848, 0.5549569129943848, 0.5775862336158752, 0.59375, 0.5991379022598267, 0.6066810488700867, 0.6131465435028076, 0.6142241358757019, 0.6260775923728943, 0.642241358757019, 0.65625, 0.6616379022598267, 0.6670258641242981, 0.6842672228813171, 0.6907327771186829, 0.7165948152542114, 0.7068965435028076, 0.7133620977401733, 0.7198275923728943, 0.6950430870056152, 0.7338362336158752, 0.7219827771186829, 0.7316810488700867, 0.725215494632721, 0.7349137663841248, 0.735991358757019, 0.7209051847457886, 0.7198275923728943, 0.7284482717514038, 0.7241379022598267, 0.7295258641242981, 0.7349137663841248, 0.7262930870056152, 0.735991358757019, 0.7273706793785095, 0.7262930870056152, 0.7219827771186829, 0.7165948152542114, 0.7273706793785095, 0.7241379022598267, 0.732758641242981, 0.7273706793785095, 0.7241379022598267, 0.725215494632721, 0.725215494632721, 0.7306034564971924, 0.725215494632721, 0.7316810488700867, 0.7284482717514038, 0.7306034564971924, 0.7155172228813171, 0.7262930870056152, 0.725215494632721, 0.7241379022598267, 0.725215494632721, 0.7262930870056152, 0.7058189511299133, 0.7295258641242981, 0.7165948152542114, 0.725215494632721, 0.7241379022598267, 0.7284482717514038, 0.7219827771186829, 0.7112069129943848, 0.7230603694915771, 0.7209051847457886, 0.7112069129943848, 0.7058189511299133, 0.7176724076271057, 0.7090517282485962, 0.7230603694915771, 0.71875, 0.7262930870056152, 0.7209051847457886, 0.7219827771186829, 0.7198275923728943, 0.7058189511299133, 0.71875, 0.7144396305084229, 0.7198275923728943, 0.7198275923728943, 0.7165948152542114, 0.7155172228813171, 0.7198275923728943, 0.7219827771186829, 0.7176724076271057, 0.7273706793785095, 0.7198275923728943, 0.7112069129943848, 0.7219827771186829, 0.7101293206214905, 0.7133620977401733, 0.7090517282485962, 0.7155172228813171, 0.6831896305084229, 0.7198275923728943, 0.7209051847457886, 0.712284505367279, 0.7176724076271057, 0.712284505367279]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 3s 33ms/step - loss: 0.7166 - accuracy: 0.8271 - val_loss: 1.0685 - val_accuracy: 0.5452\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 1s 22ms/step - loss: 0.7004 - accuracy: 0.8430 - val_loss: 1.0520 - val_accuracy: 0.5520\n","Epoch 3/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6884 - accuracy: 0.8401 - val_loss: 1.0328 - val_accuracy: 0.5622\n","Epoch 4/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6862 - accuracy: 0.8381 - val_loss: 1.0339 - val_accuracy: 0.5679\n","Epoch 5/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6805 - accuracy: 0.8441 - val_loss: 1.0026 - val_accuracy: 0.5962\n","Epoch 6/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6768 - accuracy: 0.8480 - val_loss: 0.9900 - val_accuracy: 0.6052\n","Epoch 7/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6710 - accuracy: 0.8512 - val_loss: 0.9929 - val_accuracy: 0.6029\n","Epoch 8/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6668 - accuracy: 0.8514 - val_loss: 0.9747 - val_accuracy: 0.6256\n","Epoch 9/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6607 - accuracy: 0.8588 - val_loss: 0.9645 - val_accuracy: 0.6346\n","Epoch 10/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6558 - accuracy: 0.8642 - val_loss: 0.9515 - val_accuracy: 0.6493\n","Epoch 11/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6496 - accuracy: 0.8613 - val_loss: 0.9486 - val_accuracy: 0.6572\n","Epoch 12/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6506 - accuracy: 0.8622 - val_loss: 0.9412 - val_accuracy: 0.6527\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6497 - accuracy: 0.8701 - val_loss: 0.9251 - val_accuracy: 0.6787\n","Epoch 14/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6447 - accuracy: 0.8656 - val_loss: 0.9229 - val_accuracy: 0.6731\n","Epoch 15/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6398 - accuracy: 0.8710 - val_loss: 0.9127 - val_accuracy: 0.6991\n","Epoch 16/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6397 - accuracy: 0.8684 - val_loss: 0.9096 - val_accuracy: 0.6957\n","Epoch 17/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6323 - accuracy: 0.8713 - val_loss: 0.8976 - val_accuracy: 0.6946\n","Epoch 18/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6330 - accuracy: 0.8653 - val_loss: 0.8904 - val_accuracy: 0.7183\n","Epoch 19/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6277 - accuracy: 0.8744 - val_loss: 0.8916 - val_accuracy: 0.7251\n","Epoch 20/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6237 - accuracy: 0.8718 - val_loss: 0.8939 - val_accuracy: 0.7285\n","Epoch 21/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6195 - accuracy: 0.8778 - val_loss: 0.8960 - val_accuracy: 0.7240\n","Epoch 22/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6175 - accuracy: 0.8795 - val_loss: 0.8872 - val_accuracy: 0.7353\n","Epoch 23/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6134 - accuracy: 0.8795 - val_loss: 0.8825 - val_accuracy: 0.7308\n","Epoch 24/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6151 - accuracy: 0.8778 - val_loss: 0.8901 - val_accuracy: 0.7342\n","Epoch 25/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6080 - accuracy: 0.8809 - val_loss: 0.8919 - val_accuracy: 0.7410\n","Epoch 26/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6079 - accuracy: 0.8803 - val_loss: 0.9113 - val_accuracy: 0.7240\n","Epoch 27/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6049 - accuracy: 0.8809 - val_loss: 0.9233 - val_accuracy: 0.7410\n","Epoch 28/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6101 - accuracy: 0.8823 - val_loss: 0.9340 - val_accuracy: 0.7330\n","Epoch 29/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6033 - accuracy: 0.8820 - val_loss: 0.9254 - val_accuracy: 0.7466\n","Epoch 30/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6035 - accuracy: 0.8840 - val_loss: 0.9246 - val_accuracy: 0.7432\n","Epoch 31/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5945 - accuracy: 0.8908 - val_loss: 0.9504 - val_accuracy: 0.7319\n","Epoch 32/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5902 - accuracy: 0.8902 - val_loss: 0.9517 - val_accuracy: 0.7342\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5867 - accuracy: 0.8962 - val_loss: 0.9423 - val_accuracy: 0.7376\n","Epoch 34/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5845 - accuracy: 0.8913 - val_loss: 0.9505 - val_accuracy: 0.7342\n","Epoch 35/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5814 - accuracy: 0.8962 - val_loss: 0.9325 - val_accuracy: 0.7387\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5825 - accuracy: 0.8939 - val_loss: 0.9545 - val_accuracy: 0.7398\n","Epoch 37/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5763 - accuracy: 0.8981 - val_loss: 0.9437 - val_accuracy: 0.7523\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5743 - accuracy: 0.8959 - val_loss: 0.9617 - val_accuracy: 0.7217\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5721 - accuracy: 0.8998 - val_loss: 0.9600 - val_accuracy: 0.7342\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5709 - accuracy: 0.8990 - val_loss: 0.9677 - val_accuracy: 0.7387\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5685 - accuracy: 0.9004 - val_loss: 0.9516 - val_accuracy: 0.7353\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5665 - accuracy: 0.8993 - val_loss: 0.9716 - val_accuracy: 0.7398\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5626 - accuracy: 0.9027 - val_loss: 0.9589 - val_accuracy: 0.7330\n","Epoch 44/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5663 - accuracy: 0.8970 - val_loss: 1.0477 - val_accuracy: 0.6821\n","Epoch 45/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5641 - accuracy: 0.8973 - val_loss: 0.9796 - val_accuracy: 0.7364\n","Epoch 46/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5608 - accuracy: 0.9004 - val_loss: 0.9666 - val_accuracy: 0.7353\n","Epoch 47/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5728 - accuracy: 0.8928 - val_loss: 1.0336 - val_accuracy: 0.7217\n","Epoch 48/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5662 - accuracy: 0.8995 - val_loss: 1.0010 - val_accuracy: 0.7251\n","Epoch 49/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5659 - accuracy: 0.9007 - val_loss: 1.0036 - val_accuracy: 0.7285\n","Epoch 50/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5748 - accuracy: 0.8956 - val_loss: 1.0130 - val_accuracy: 0.7319\n","Epoch 51/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5472 - accuracy: 0.9126 - val_loss: 0.9869 - val_accuracy: 0.7308\n","Epoch 52/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5428 - accuracy: 0.9117 - val_loss: 0.9861 - val_accuracy: 0.7319\n","Epoch 53/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5411 - accuracy: 0.9126 - val_loss: 1.0050 - val_accuracy: 0.7296\n","Epoch 54/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5398 - accuracy: 0.9089 - val_loss: 0.9865 - val_accuracy: 0.7195\n","Epoch 55/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5395 - accuracy: 0.9103 - val_loss: 0.9827 - val_accuracy: 0.7353\n","Epoch 56/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5379 - accuracy: 0.9123 - val_loss: 1.0127 - val_accuracy: 0.7296\n","Epoch 57/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5357 - accuracy: 0.9109 - val_loss: 0.9904 - val_accuracy: 0.7376\n","Epoch 58/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5299 - accuracy: 0.9126 - val_loss: 0.9820 - val_accuracy: 0.7353\n","Epoch 59/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5267 - accuracy: 0.9196 - val_loss: 0.9952 - val_accuracy: 0.7364\n","Epoch 60/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5224 - accuracy: 0.9228 - val_loss: 0.9963 - val_accuracy: 0.7398\n","Epoch 61/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5258 - accuracy: 0.9137 - val_loss: 1.0626 - val_accuracy: 0.7138\n","Epoch 62/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5328 - accuracy: 0.9072 - val_loss: 0.9973 - val_accuracy: 0.7319\n","Epoch 63/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5200 - accuracy: 0.9177 - val_loss: 1.0030 - val_accuracy: 0.7274\n","Epoch 64/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5175 - accuracy: 0.9222 - val_loss: 1.0171 - val_accuracy: 0.7262\n","Epoch 65/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5158 - accuracy: 0.9211 - val_loss: 1.0122 - val_accuracy: 0.7274\n","Epoch 66/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5137 - accuracy: 0.9222 - val_loss: 1.0085 - val_accuracy: 0.7262\n","Epoch 67/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5153 - accuracy: 0.9162 - val_loss: 1.0456 - val_accuracy: 0.7172\n","Epoch 68/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5136 - accuracy: 0.9188 - val_loss: 1.0087 - val_accuracy: 0.7183\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5307 - accuracy: 0.9109 - val_loss: 1.0162 - val_accuracy: 0.7285\n","Epoch 70/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5119 - accuracy: 0.9216 - val_loss: 1.0363 - val_accuracy: 0.7296\n","Epoch 71/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5078 - accuracy: 0.9196 - val_loss: 1.0796 - val_accuracy: 0.7138\n","Epoch 72/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5056 - accuracy: 0.9213 - val_loss: 1.0234 - val_accuracy: 0.7296\n","Epoch 73/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5008 - accuracy: 0.9264 - val_loss: 1.0310 - val_accuracy: 0.7274\n","Epoch 74/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4993 - accuracy: 0.9264 - val_loss: 1.0420 - val_accuracy: 0.7127\n","Epoch 75/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5041 - accuracy: 0.9213 - val_loss: 1.0714 - val_accuracy: 0.7229\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5069 - accuracy: 0.9188 - val_loss: 1.0573 - val_accuracy: 0.7308\n","Epoch 77/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5043 - accuracy: 0.9256 - val_loss: 1.0542 - val_accuracy: 0.7353\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5144 - accuracy: 0.9185 - val_loss: 1.0734 - val_accuracy: 0.7206\n","Epoch 79/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5050 - accuracy: 0.9256 - val_loss: 1.0701 - val_accuracy: 0.7206\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5061 - accuracy: 0.9157 - val_loss: 1.0466 - val_accuracy: 0.7319\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4962 - accuracy: 0.9239 - val_loss: 1.0342 - val_accuracy: 0.7353\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4924 - accuracy: 0.9267 - val_loss: 1.1042 - val_accuracy: 0.7229\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4940 - accuracy: 0.9219 - val_loss: 1.0530 - val_accuracy: 0.7229\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4910 - accuracy: 0.9239 - val_loss: 1.0840 - val_accuracy: 0.6968\n","Epoch 85/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4941 - accuracy: 0.9216 - val_loss: 1.2035 - val_accuracy: 0.7059\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4923 - accuracy: 0.9253 - val_loss: 1.0868 - val_accuracy: 0.6844\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4829 - accuracy: 0.9352 - val_loss: 1.0652 - val_accuracy: 0.7093\n","Epoch 88/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4800 - accuracy: 0.9324 - val_loss: 1.0536 - val_accuracy: 0.7330\n","Epoch 89/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4848 - accuracy: 0.9261 - val_loss: 1.1476 - val_accuracy: 0.7070\n","Epoch 90/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4773 - accuracy: 0.9324 - val_loss: 1.0844 - val_accuracy: 0.7138\n","Epoch 91/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4790 - accuracy: 0.9304 - val_loss: 1.1005 - val_accuracy: 0.7172\n","Epoch 92/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4765 - accuracy: 0.9287 - val_loss: 1.0879 - val_accuracy: 0.7172\n","Epoch 93/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4713 - accuracy: 0.9383 - val_loss: 1.0784 - val_accuracy: 0.7330\n","Epoch 94/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4728 - accuracy: 0.9338 - val_loss: 1.0971 - val_accuracy: 0.7093\n","Epoch 95/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4732 - accuracy: 0.9315 - val_loss: 1.1007 - val_accuracy: 0.7149\n","Epoch 96/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4710 - accuracy: 0.9318 - val_loss: 1.0879 - val_accuracy: 0.7240\n","Epoch 97/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4650 - accuracy: 0.9400 - val_loss: 1.0830 - val_accuracy: 0.7206\n","Epoch 98/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4668 - accuracy: 0.9355 - val_loss: 1.0895 - val_accuracy: 0.7183\n","Epoch 99/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4605 - accuracy: 0.9383 - val_loss: 1.1198 - val_accuracy: 0.6765\n","Epoch 100/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4673 - accuracy: 0.9318 - val_loss: 1.1001 - val_accuracy: 0.7149\n","{'loss': [0.7166066765785217, 0.7003850340843201, 0.6884335279464722, 0.6861712336540222, 0.6805284023284912, 0.6767570376396179, 0.6709556579589844, 0.666815996170044, 0.6606885194778442, 0.6557883620262146, 0.6496043801307678, 0.6505900025367737, 0.6496725082397461, 0.644690215587616, 0.6398119330406189, 0.6396995186805725, 0.6322791576385498, 0.6330285668373108, 0.627673327922821, 0.6237015724182129, 0.6194890141487122, 0.6175344586372375, 0.6134136915206909, 0.6151018738746643, 0.6079901456832886, 0.6078522801399231, 0.6049109101295471, 0.6100744009017944, 0.6033421158790588, 0.6034996509552002, 0.5944526195526123, 0.5902255773544312, 0.5867496728897095, 0.5844804048538208, 0.5813990831375122, 0.5824791789054871, 0.5762775540351868, 0.574255645275116, 0.5721478462219238, 0.5709400773048401, 0.5684505105018616, 0.5665377378463745, 0.5626451373100281, 0.5663397312164307, 0.5640963315963745, 0.5607796907424927, 0.5728310942649841, 0.5661922097206116, 0.5658851861953735, 0.5748215913772583, 0.5472107529640198, 0.5427524447441101, 0.5410791039466858, 0.5398378968238831, 0.5395001173019409, 0.5379061102867126, 0.5357072353363037, 0.5299190282821655, 0.5266917943954468, 0.5223838686943054, 0.5257847905158997, 0.5328043103218079, 0.5199965834617615, 0.5175427794456482, 0.5157586336135864, 0.5137001872062683, 0.5153045654296875, 0.5136380791664124, 0.530710756778717, 0.5119302868843079, 0.5078388452529907, 0.5056494474411011, 0.5007950663566589, 0.4992991089820862, 0.5041157007217407, 0.506926417350769, 0.5043381452560425, 0.5144186019897461, 0.50504469871521, 0.5060737133026123, 0.49615421891212463, 0.4924033582210541, 0.4939616918563843, 0.49103638529777527, 0.49408453702926636, 0.4922862648963928, 0.48287492990493774, 0.4799553155899048, 0.48481476306915283, 0.47730425000190735, 0.4789752662181854, 0.4765465557575226, 0.47132501006126404, 0.472773939371109, 0.4731665551662445, 0.471004456281662, 0.46495482325553894, 0.46676334738731384, 0.460470050573349, 0.46730363368988037], 'accuracy': [0.8271080851554871, 0.842954158782959, 0.8401244878768921, 0.8381437659263611, 0.8440860509872437, 0.8480475544929504, 0.8511601686477661, 0.8514431118965149, 0.8588002324104309, 0.8641765713691711, 0.8613469004631042, 0.8621957898139954, 0.8701188564300537, 0.8655914068222046, 0.8709677457809448, 0.8684210777282715, 0.8712506890296936, 0.865308403968811, 0.8743633031845093, 0.8718166351318359, 0.8777589201927185, 0.8794566988945007, 0.8794566988945007, 0.8777589201927185, 0.8808715343475342, 0.8803055882453918, 0.8808715343475342, 0.8822863698005676, 0.8820033669471741, 0.8839841485023499, 0.8907753229141235, 0.8902093768119812, 0.8961516618728638, 0.8913412690162659, 0.8961516618728638, 0.8938879370689392, 0.8981324434280396, 0.895868718624115, 0.8998302221298218, 0.8989813327789307, 0.9003961682319641, 0.8992642760276794, 0.9026598930358887, 0.8970005512237549, 0.8972835540771484, 0.9003961682319641, 0.8927561044692993, 0.899547278881073, 0.9006791114807129, 0.8955857157707214, 0.912563681602478, 0.9117147922515869, 0.912563681602478, 0.90888512134552, 0.9102999567985535, 0.9122806787490845, 0.9108659029006958, 0.912563681602478, 0.9196377992630005, 0.9227504134178162, 0.9136955142021179, 0.9071873426437378, 0.9176570177078247, 0.9221844673156738, 0.9210526347160339, 0.9221844673156738, 0.916242241859436, 0.9187889099121094, 0.9108659029006958, 0.9216185808181763, 0.9196377992630005, 0.9213355779647827, 0.9264289736747742, 0.9264289736747742, 0.9213355779647827, 0.9187889099121094, 0.9255800843238831, 0.9185059666633606, 0.9255800843238831, 0.9156762957572937, 0.9238823056221008, 0.926711916923523, 0.921901524066925, 0.9238823056221008, 0.9216185808181763, 0.9252971410751343, 0.9352009296417236, 0.9323712587356567, 0.9261460304260254, 0.9323712587356567, 0.930390477180481, 0.9286926984786987, 0.9383135437965393, 0.9337860941886902, 0.9315223693847656, 0.9318053126335144, 0.9400113224983215, 0.9354838728904724, 0.9383135437965393, 0.9318053126335144], 'val_loss': [1.0684936046600342, 1.0520238876342773, 1.032845377922058, 1.033875584602356, 1.0025967359542847, 0.9900258183479309, 0.9928601980209351, 0.9747447967529297, 0.9645468592643738, 0.951471745967865, 0.9486172199249268, 0.9411695599555969, 0.9250667095184326, 0.9228976964950562, 0.9126877784729004, 0.9095873832702637, 0.8976199626922607, 0.89042067527771, 0.8915857672691345, 0.8939457535743713, 0.896014392375946, 0.8872188329696655, 0.8824756741523743, 0.8900543451309204, 0.8919391632080078, 0.9112974405288696, 0.9232703447341919, 0.9340317249298096, 0.9254361391067505, 0.9246155023574829, 0.9504392743110657, 0.9516693949699402, 0.942306637763977, 0.9504984021186829, 0.9325379729270935, 0.9544708132743835, 0.9436543583869934, 0.9617036581039429, 0.959954023361206, 0.9677397608757019, 0.9516382217407227, 0.9715839624404907, 0.9589169025421143, 1.0476861000061035, 0.9795637726783752, 0.9665597081184387, 1.033634066581726, 1.0010325908660889, 1.0035955905914307, 1.0130001306533813, 0.9869370460510254, 0.9861130714416504, 1.0049506425857544, 0.9865317940711975, 0.9827344417572021, 1.0126736164093018, 0.9904402494430542, 0.9820300340652466, 0.9952094554901123, 0.9962506890296936, 1.0626075267791748, 0.9972864985466003, 1.0029550790786743, 1.0171446800231934, 1.0122088193893433, 1.0085089206695557, 1.0456197261810303, 1.008671522140503, 1.0162417888641357, 1.0363448858261108, 1.0795565843582153, 1.0233986377716064, 1.030988335609436, 1.0420080423355103, 1.0713539123535156, 1.0573152303695679, 1.054233193397522, 1.0734342336654663, 1.070069432258606, 1.046582579612732, 1.034197449684143, 1.1042128801345825, 1.0530318021774292, 1.0839823484420776, 1.2034997940063477, 1.0868281126022339, 1.0651954412460327, 1.05362868309021, 1.147560954093933, 1.084424614906311, 1.1005051136016846, 1.087863802909851, 1.078363299369812, 1.097118616104126, 1.1007230281829834, 1.0878533124923706, 1.083025336265564, 1.089501976966858, 1.1198036670684814, 1.1001135110855103], 'val_accuracy': [0.5452488660812378, 0.5520362257957458, 0.5622171759605408, 0.5678732991218567, 0.5961538553237915, 0.6052036285400391, 0.6029411554336548, 0.6255655884742737, 0.6346153616905212, 0.6493212580680847, 0.6572397947311401, 0.6527149081230164, 0.6787330508232117, 0.6730769276618958, 0.6990950107574463, 0.6957013607025146, 0.6945701241493225, 0.7183257937431335, 0.7251130938529968, 0.7285068035125732, 0.7239819169044495, 0.7352941036224365, 0.7307692170143127, 0.7341628670692444, 0.7409502267837524, 0.7239819169044495, 0.7409502267837524, 0.733031690120697, 0.7466063499450684, 0.7432126402854919, 0.7319004535675049, 0.7341628670692444, 0.7375565767288208, 0.7341628670692444, 0.7386877536773682, 0.7398189902305603, 0.7522624731063843, 0.7217194437980652, 0.7341628670692444, 0.7386877536773682, 0.7352941036224365, 0.7398189902305603, 0.733031690120697, 0.6821267008781433, 0.7364253401756287, 0.7352941036224365, 0.7217194437980652, 0.7251130938529968, 0.7285068035125732, 0.7319004535675049, 0.7307692170143127, 0.7319004535675049, 0.7296379804611206, 0.7194570302963257, 0.7352941036224365, 0.7296379804611206, 0.7375565767288208, 0.7352941036224365, 0.7364253401756287, 0.7398189902305603, 0.7138009071350098, 0.7319004535675049, 0.7273755669593811, 0.726244330406189, 0.7273755669593811, 0.726244330406189, 0.7171945571899414, 0.7183257937431335, 0.7285068035125732, 0.7296379804611206, 0.7138009071350098, 0.7296379804611206, 0.7273755669593811, 0.7126696705818176, 0.7228506803512573, 0.7307692170143127, 0.7352941036224365, 0.720588207244873, 0.720588207244873, 0.7319004535675049, 0.7352941036224365, 0.7228506803512573, 0.7228506803512573, 0.6968325972557068, 0.7058823704719543, 0.6843891143798828, 0.709276020526886, 0.733031690120697, 0.7070135474205017, 0.7138009071350098, 0.7171945571899414, 0.7171945571899414, 0.733031690120697, 0.709276020526886, 0.7149321436882019, 0.7239819169044495, 0.720588207244873, 0.7183257937431335, 0.6764705777168274, 0.7149321436882019]}\n","45/45 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 5s 31ms/step - loss: 0.7219 - accuracy: 0.8243 - val_loss: 1.0350 - val_accuracy: 0.5496\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.7931 - accuracy: 0.7422"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 13ms/step - loss: 0.7029 - accuracy: 0.8375 - val_loss: 1.0535 - val_accuracy: 0.5465\n","Epoch 3/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7018 - accuracy: 0.8351 - val_loss: 1.0230 - val_accuracy: 0.5692\n","Epoch 4/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6902 - accuracy: 0.8426 - val_loss: 1.0128 - val_accuracy: 0.5857\n","Epoch 5/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6827 - accuracy: 0.8432 - val_loss: 1.0202 - val_accuracy: 0.5785\n","Epoch 6/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6857 - accuracy: 0.8395 - val_loss: 0.9980 - val_accuracy: 0.5950\n","Epoch 7/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6716 - accuracy: 0.8527 - val_loss: 0.9880 - val_accuracy: 0.6043\n","Epoch 8/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6706 - accuracy: 0.8504 - val_loss: 0.9672 - val_accuracy: 0.6322\n","Epoch 9/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6720 - accuracy: 0.8450 - val_loss: 0.9589 - val_accuracy: 0.6498\n","Epoch 10/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6647 - accuracy: 0.8540 - val_loss: 0.9504 - val_accuracy: 0.6529\n","Epoch 11/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6665 - accuracy: 0.8514 - val_loss: 0.9383 - val_accuracy: 0.6767\n","Epoch 12/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6595 - accuracy: 0.8581 - val_loss: 0.9277 - val_accuracy: 0.6880\n","Epoch 13/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6622 - accuracy: 0.8491 - val_loss: 0.9199 - val_accuracy: 0.6911\n","Epoch 14/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6540 - accuracy: 0.8594 - val_loss: 0.9262 - val_accuracy: 0.6994\n","Epoch 15/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6513 - accuracy: 0.8594 - val_loss: 0.9103 - val_accuracy: 0.6983\n","Epoch 16/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6436 - accuracy: 0.8651 - val_loss: 0.9067 - val_accuracy: 0.7014\n","Epoch 17/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6442 - accuracy: 0.8594 - val_loss: 0.9055 - val_accuracy: 0.7025\n","Epoch 18/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6477 - accuracy: 0.8605 - val_loss: 0.9117 - val_accuracy: 0.6870\n","Epoch 19/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6369 - accuracy: 0.8674 - val_loss: 0.9265 - val_accuracy: 0.6880\n","Epoch 20/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6381 - accuracy: 0.8680 - val_loss: 0.9151 - val_accuracy: 0.7045\n","Epoch 21/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6296 - accuracy: 0.8677 - val_loss: 0.9145 - val_accuracy: 0.7097\n","Epoch 22/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6280 - accuracy: 0.8685 - val_loss: 0.9170 - val_accuracy: 0.7118\n","Epoch 23/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6240 - accuracy: 0.8749 - val_loss: 0.9360 - val_accuracy: 0.7159\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6220 - accuracy: 0.8736 - val_loss: 0.9376 - val_accuracy: 0.7118\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6190 - accuracy: 0.8765 - val_loss: 0.9518 - val_accuracy: 0.7138\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6146 - accuracy: 0.8788 - val_loss: 0.9675 - val_accuracy: 0.6911\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6112 - accuracy: 0.8739 - val_loss: 0.9713 - val_accuracy: 0.6952\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6154 - accuracy: 0.8770 - val_loss: 0.9721 - val_accuracy: 0.7107\n","Epoch 29/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6145 - accuracy: 0.8742 - val_loss: 0.9805 - val_accuracy: 0.7014\n","Epoch 30/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6051 - accuracy: 0.8814 - val_loss: 0.9828 - val_accuracy: 0.6963\n","Epoch 31/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6095 - accuracy: 0.8739 - val_loss: 1.0030 - val_accuracy: 0.7004\n","Epoch 32/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6194 - accuracy: 0.8739 - val_loss: 1.0063 - val_accuracy: 0.7014\n","Epoch 33/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6129 - accuracy: 0.8721 - val_loss: 1.0144 - val_accuracy: 0.6983\n","Epoch 34/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5957 - accuracy: 0.8871 - val_loss: 0.9952 - val_accuracy: 0.7066\n","Epoch 35/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5943 - accuracy: 0.8822 - val_loss: 1.0020 - val_accuracy: 0.6901\n","Epoch 36/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5876 - accuracy: 0.8941 - val_loss: 0.9968 - val_accuracy: 0.7107\n","Epoch 37/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5873 - accuracy: 0.8889 - val_loss: 1.0101 - val_accuracy: 0.6890\n","Epoch 38/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5921 - accuracy: 0.8842 - val_loss: 1.0029 - val_accuracy: 0.7087\n","Epoch 39/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5882 - accuracy: 0.8853 - val_loss: 1.0347 - val_accuracy: 0.6942\n","Epoch 40/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5878 - accuracy: 0.8860 - val_loss: 1.0039 - val_accuracy: 0.7025\n","Epoch 41/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5803 - accuracy: 0.8935 - val_loss: 1.0272 - val_accuracy: 0.6921\n","Epoch 42/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5807 - accuracy: 0.8894 - val_loss: 1.0357 - val_accuracy: 0.7004\n","Epoch 43/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5778 - accuracy: 0.8920 - val_loss: 1.0219 - val_accuracy: 0.6994\n","Epoch 44/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5878 - accuracy: 0.8829 - val_loss: 1.0185 - val_accuracy: 0.6932\n","Epoch 45/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5737 - accuracy: 0.8933 - val_loss: 1.0791 - val_accuracy: 0.6870\n","Epoch 46/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5850 - accuracy: 0.8822 - val_loss: 1.0424 - val_accuracy: 0.6880\n","Epoch 47/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5861 - accuracy: 0.8824 - val_loss: 1.0486 - val_accuracy: 0.7035\n","Epoch 48/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5899 - accuracy: 0.8842 - val_loss: 1.0314 - val_accuracy: 0.6983\n","Epoch 49/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5687 - accuracy: 0.8990 - val_loss: 1.0421 - val_accuracy: 0.7076\n","Epoch 50/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5763 - accuracy: 0.8866 - val_loss: 1.0365 - val_accuracy: 0.6911\n","Epoch 51/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5613 - accuracy: 0.9010 - val_loss: 1.0553 - val_accuracy: 0.6921\n","Epoch 52/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5538 - accuracy: 0.9023 - val_loss: 1.0321 - val_accuracy: 0.7076\n","Epoch 53/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5610 - accuracy: 0.8941 - val_loss: 1.0433 - val_accuracy: 0.6952\n","Epoch 54/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5610 - accuracy: 0.8972 - val_loss: 1.0527 - val_accuracy: 0.6952\n","Epoch 55/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5513 - accuracy: 0.9036 - val_loss: 1.0575 - val_accuracy: 0.7066\n","Epoch 56/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5532 - accuracy: 0.9000 - val_loss: 1.0545 - val_accuracy: 0.6963\n","Epoch 57/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5485 - accuracy: 0.9059 - val_loss: 1.0425 - val_accuracy: 0.6983\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5496 - accuracy: 0.9039 - val_loss: 1.0481 - val_accuracy: 0.7107\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5520 - accuracy: 0.9028 - val_loss: 1.0585 - val_accuracy: 0.7128\n","Epoch 60/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5489 - accuracy: 0.9021 - val_loss: 1.1061 - val_accuracy: 0.6921\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5468 - accuracy: 0.9021 - val_loss: 1.0780 - val_accuracy: 0.6818\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5383 - accuracy: 0.9106 - val_loss: 1.0658 - val_accuracy: 0.6818\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5426 - accuracy: 0.9062 - val_loss: 1.0805 - val_accuracy: 0.6839\n","Epoch 64/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5310 - accuracy: 0.9111 - val_loss: 1.0804 - val_accuracy: 0.7118\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5345 - accuracy: 0.9106 - val_loss: 1.0863 - val_accuracy: 0.6983\n","Epoch 66/100\n","31/31 [==============================] - 2s 53ms/step - loss: 0.5363 - accuracy: 0.9078 - val_loss: 1.0915 - val_accuracy: 0.7180\n","Epoch 67/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5272 - accuracy: 0.9145 - val_loss: 1.1138 - val_accuracy: 0.6870\n","Epoch 68/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5291 - accuracy: 0.9124 - val_loss: 1.0767 - val_accuracy: 0.7035\n","Epoch 69/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5229 - accuracy: 0.9178 - val_loss: 1.0878 - val_accuracy: 0.7107\n","Epoch 70/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5271 - accuracy: 0.9155 - val_loss: 1.0858 - val_accuracy: 0.6963\n","Epoch 71/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5201 - accuracy: 0.9173 - val_loss: 1.0942 - val_accuracy: 0.7056\n","Epoch 72/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5232 - accuracy: 0.9124 - val_loss: 1.1436 - val_accuracy: 0.6798\n","Epoch 73/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5225 - accuracy: 0.9155 - val_loss: 1.0968 - val_accuracy: 0.7107\n","Epoch 74/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5186 - accuracy: 0.9137 - val_loss: 1.1449 - val_accuracy: 0.6942\n","Epoch 75/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5294 - accuracy: 0.9067 - val_loss: 1.1374 - val_accuracy: 0.6777\n","Epoch 76/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5306 - accuracy: 0.9067 - val_loss: 1.1138 - val_accuracy: 0.6890\n","Epoch 77/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5113 - accuracy: 0.9160 - val_loss: 1.1213 - val_accuracy: 0.6849\n","Epoch 78/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5122 - accuracy: 0.9160 - val_loss: 1.1205 - val_accuracy: 0.6901\n","Epoch 79/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5085 - accuracy: 0.9227 - val_loss: 1.1047 - val_accuracy: 0.7014\n","Epoch 80/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5198 - accuracy: 0.9116 - val_loss: 1.1283 - val_accuracy: 0.7004\n","Epoch 81/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5143 - accuracy: 0.9101 - val_loss: 1.1152 - val_accuracy: 0.7128\n","Epoch 82/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5137 - accuracy: 0.9152 - val_loss: 1.1270 - val_accuracy: 0.6942\n","Epoch 83/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5063 - accuracy: 0.9199 - val_loss: 1.1244 - val_accuracy: 0.6911\n","Epoch 84/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4977 - accuracy: 0.9235 - val_loss: 1.1185 - val_accuracy: 0.6994\n","Epoch 85/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4983 - accuracy: 0.9238 - val_loss: 1.1277 - val_accuracy: 0.6942\n","Epoch 86/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5052 - accuracy: 0.9186 - val_loss: 1.1400 - val_accuracy: 0.6963\n","Epoch 87/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5005 - accuracy: 0.9173 - val_loss: 1.1380 - val_accuracy: 0.6839\n","Epoch 88/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5079 - accuracy: 0.9194 - val_loss: 1.1447 - val_accuracy: 0.6973\n","Epoch 89/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5004 - accuracy: 0.9196 - val_loss: 1.1629 - val_accuracy: 0.6932\n","Epoch 90/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4987 - accuracy: 0.9233 - val_loss: 1.1294 - val_accuracy: 0.7118\n","Epoch 91/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4885 - accuracy: 0.9271 - val_loss: 1.1562 - val_accuracy: 0.6942\n","Epoch 92/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4891 - accuracy: 0.9243 - val_loss: 1.1367 - val_accuracy: 0.6942\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4855 - accuracy: 0.9253 - val_loss: 1.1582 - val_accuracy: 0.6870\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4868 - accuracy: 0.9235 - val_loss: 1.1654 - val_accuracy: 0.6849\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4848 - accuracy: 0.9251 - val_loss: 1.1574 - val_accuracy: 0.6860\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4846 - accuracy: 0.9282 - val_loss: 1.1686 - val_accuracy: 0.6839\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4919 - accuracy: 0.9202 - val_loss: 1.1619 - val_accuracy: 0.7035\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4861 - accuracy: 0.9266 - val_loss: 1.1794 - val_accuracy: 0.6860\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4813 - accuracy: 0.9289 - val_loss: 1.1686 - val_accuracy: 0.6942\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4803 - accuracy: 0.9266 - val_loss: 1.1632 - val_accuracy: 0.7056\n","{'loss': [0.7218656539916992, 0.7028693556785583, 0.7017819285392761, 0.6902352571487427, 0.6827412247657776, 0.6857436299324036, 0.6716334819793701, 0.6705808043479919, 0.6719525456428528, 0.6646559834480286, 0.6664833426475525, 0.6595170497894287, 0.6622216701507568, 0.6539897918701172, 0.6512972116470337, 0.6436334252357483, 0.6442071199417114, 0.6477344632148743, 0.6369218230247498, 0.6380560398101807, 0.6296045780181885, 0.6279866695404053, 0.6239784359931946, 0.6219664812088013, 0.6190204620361328, 0.6146174073219299, 0.6111829280853271, 0.6154232025146484, 0.6145439743995667, 0.6050570011138916, 0.6094520688056946, 0.619381308555603, 0.612904965877533, 0.5957448482513428, 0.5942745804786682, 0.5876493453979492, 0.5872510671615601, 0.592096209526062, 0.5882289409637451, 0.5878412127494812, 0.580319344997406, 0.5806896686553955, 0.5778194069862366, 0.5877894163131714, 0.5736768245697021, 0.5849945545196533, 0.5861133933067322, 0.589913010597229, 0.5687490105628967, 0.576287567615509, 0.561337947845459, 0.5537870526313782, 0.5609641671180725, 0.5610067844390869, 0.5512630343437195, 0.5531663298606873, 0.5485461354255676, 0.5496349334716797, 0.5519598126411438, 0.5489104390144348, 0.5468131899833679, 0.5383499264717102, 0.5426145792007446, 0.5309715867042542, 0.5344680547714233, 0.5362918972969055, 0.5272256731987, 0.5291438698768616, 0.5229321718215942, 0.5270571112632751, 0.5200979113578796, 0.5231543779373169, 0.5224936008453369, 0.5186439752578735, 0.5294352173805237, 0.5306038856506348, 0.5112868547439575, 0.5121825933456421, 0.5084529519081116, 0.5198448300361633, 0.5142601132392883, 0.5136550068855286, 0.5063367486000061, 0.4977279603481293, 0.4983255863189697, 0.505171000957489, 0.5004952549934387, 0.5079332590103149, 0.5003625750541687, 0.49865540862083435, 0.48848748207092285, 0.48912808299064636, 0.48547351360321045, 0.4867773652076721, 0.4848490059375763, 0.48461291193962097, 0.4918554723262787, 0.48606476187705994, 0.48129162192344666, 0.4803030788898468], 'accuracy': [0.8242893815040588, 0.8374677300453186, 0.8351421356201172, 0.8426356315612793, 0.8431524634361267, 0.8395348787307739, 0.8527131676673889, 0.8503875732421875, 0.8449612259864807, 0.8540051579475403, 0.8514211773872375, 0.8581395149230957, 0.8490955829620361, 0.8594315052032471, 0.8594315052032471, 0.8651162981987, 0.8594315052032471, 0.8604651093482971, 0.8674418330192566, 0.867958664894104, 0.8677002787590027, 0.8684754371643066, 0.8749353885650635, 0.8736433982849121, 0.8764857649803162, 0.8788113594055176, 0.8739017844200134, 0.8770025968551636, 0.8741602301597595, 0.8813953399658203, 0.8739017844200134, 0.8739017844200134, 0.8720930218696594, 0.8870801329612732, 0.882170557975769, 0.8940568566322327, 0.8888888955116272, 0.8842377066612244, 0.8852713108062744, 0.8860465288162231, 0.8935400247573853, 0.8894056677818298, 0.8919896483421326, 0.882945716381073, 0.8932816386222839, 0.882170557975769, 0.8824289441108704, 0.8842377066612244, 0.8989664316177368, 0.8865633010864258, 0.9010335803031921, 0.9023255705833435, 0.8940568566322327, 0.897157609462738, 0.9036175608634949, 0.8999999761581421, 0.9059431552886963, 0.9038759469985962, 0.9028424024581909, 0.9020671844482422, 0.9020671844482422, 0.9105943441390991, 0.9062015414237976, 0.9111111164093018, 0.9105943441390991, 0.9077519178390503, 0.9144702553749084, 0.9124031066894531, 0.9178294539451599, 0.9155038595199585, 0.9173126816749573, 0.9124031066894531, 0.9155038595199585, 0.9136950969696045, 0.906718373298645, 0.906718373298645, 0.9160206913948059, 0.9160206913948059, 0.9227390289306641, 0.9116278886795044, 0.9100775122642517, 0.9152454733848572, 0.91989666223526, 0.923514187335968, 0.9237726330757141, 0.9186046719551086, 0.9173126816749573, 0.9193798303604126, 0.9196382164955139, 0.9232558012008667, 0.9271317720413208, 0.9242894053459167, 0.9253230094909668, 0.923514187335968, 0.9250646233558655, 0.9281653761863708, 0.9201550483703613, 0.9266149997711182, 0.9289405941963196, 0.9266149997711182], 'val_loss': [1.0349959135055542, 1.0534895658493042, 1.0230321884155273, 1.0127527713775635, 1.0201725959777832, 0.9980077147483826, 0.9879845976829529, 0.9671775698661804, 0.9589090943336487, 0.9504044651985168, 0.9383046627044678, 0.9276655316352844, 0.919883131980896, 0.9262433648109436, 0.9103068113327026, 0.90671706199646, 0.9055107235908508, 0.9117382168769836, 0.9265004396438599, 0.915056049823761, 0.9144771099090576, 0.9169743061065674, 0.9359689354896545, 0.9376106858253479, 0.9518262147903442, 0.9674957394599915, 0.9713443517684937, 0.9720978736877441, 0.9804955124855042, 0.9827761054039001, 1.0029752254486084, 1.0062791109085083, 1.0143685340881348, 0.9951505661010742, 1.002042293548584, 0.9968014359474182, 1.0100553035736084, 1.0028812885284424, 1.0347498655319214, 1.0039091110229492, 1.027214527130127, 1.0356940031051636, 1.0219409465789795, 1.018518090248108, 1.0790966749191284, 1.042412281036377, 1.048567771911621, 1.0313984155654907, 1.0420504808425903, 1.0365331172943115, 1.0552891492843628, 1.0320818424224854, 1.0433379411697388, 1.052664875984192, 1.057548999786377, 1.0544826984405518, 1.0425211191177368, 1.0480605363845825, 1.0585442781448364, 1.1061094999313354, 1.0779892206192017, 1.0658094882965088, 1.08054518699646, 1.0804314613342285, 1.0863001346588135, 1.0914874076843262, 1.1138195991516113, 1.0766745805740356, 1.0878089666366577, 1.0857926607131958, 1.0942083597183228, 1.143550157546997, 1.0967754125595093, 1.1449308395385742, 1.1373571157455444, 1.1137802600860596, 1.1212682723999023, 1.120544672012329, 1.1047385931015015, 1.1282819509506226, 1.115237832069397, 1.1270027160644531, 1.1243590116500854, 1.1184996366500854, 1.1277135610580444, 1.139998435974121, 1.138034701347351, 1.1446583271026611, 1.1629070043563843, 1.1294111013412476, 1.1561661958694458, 1.1366521120071411, 1.1582348346710205, 1.16539466381073, 1.1573892831802368, 1.1685642004013062, 1.161875605583191, 1.1794127225875854, 1.1686292886734009, 1.1632438898086548], 'val_accuracy': [0.5495867729187012, 0.5464876294136047, 0.5692148804664612, 0.58574378490448, 0.5785123705863953, 0.5950413346290588, 0.6043388247489929, 0.6322314143180847, 0.6497933864593506, 0.6528925895690918, 0.6766529083251953, 0.6880165338516235, 0.69111567735672, 0.6993801593780518, 0.6983470916748047, 0.7014462947845459, 0.702479362487793, 0.6869834661483765, 0.6880165338516235, 0.7045454382896423, 0.7097107172012329, 0.711776852607727, 0.7159090638160706, 0.711776852607727, 0.7138429880142212, 0.69111567735672, 0.6952479481697083, 0.71074378490448, 0.7014462947845459, 0.6962810158729553, 0.7004132270812988, 0.7014462947845459, 0.6983470916748047, 0.7066115736961365, 0.6900826692581177, 0.71074378490448, 0.6890496015548706, 0.7086777091026306, 0.6942148804664612, 0.702479362487793, 0.692148745059967, 0.7004132270812988, 0.6993801593780518, 0.6931818127632141, 0.6869834661483765, 0.6880165338516235, 0.7035123705863953, 0.6983470916748047, 0.7076446413993835, 0.69111567735672, 0.692148745059967, 0.7076446413993835, 0.6952479481697083, 0.6952479481697083, 0.7066115736961365, 0.6962810158729553, 0.6983470916748047, 0.71074378490448, 0.7128099203109741, 0.692148745059967, 0.6818181872367859, 0.6818181872367859, 0.68388432264328, 0.711776852607727, 0.6983470916748047, 0.7179751992225647, 0.6869834661483765, 0.7035123705863953, 0.71074378490448, 0.6962810158729553, 0.7055785059928894, 0.6797520518302917, 0.71074378490448, 0.6942148804664612, 0.6776859760284424, 0.6890496015548706, 0.6849173307418823, 0.6900826692581177, 0.7014462947845459, 0.7004132270812988, 0.7128099203109741, 0.6942148804664612, 0.69111567735672, 0.6993801593780518, 0.6942148804664612, 0.6962810158729553, 0.68388432264328, 0.6973140239715576, 0.6931818127632141, 0.711776852607727, 0.6942148804664612, 0.6942148804664612, 0.6869834661483765, 0.6849173307418823, 0.6859503984451294, 0.68388432264328, 0.7035123705863953, 0.6859503984451294, 0.6942148804664612, 0.7055785059928894]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 28ms/step - loss: 0.5412 - accuracy: 0.8998 - val_loss: 1.0045 - val_accuracy: 0.5894\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.4948 - accuracy: 0.8984"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 16ms/step - loss: 0.5171 - accuracy: 0.9087 - val_loss: 0.9641 - val_accuracy: 0.5970\n","Epoch 3/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5140 - accuracy: 0.9098 - val_loss: 0.9456 - val_accuracy: 0.5884\n","Epoch 4/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5065 - accuracy: 0.9146 - val_loss: 0.9508 - val_accuracy: 0.5884\n","Epoch 5/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4982 - accuracy: 0.9124 - val_loss: 0.9408 - val_accuracy: 0.5981\n","Epoch 6/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4957 - accuracy: 0.9146 - val_loss: 0.9357 - val_accuracy: 0.6239\n","Epoch 7/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4976 - accuracy: 0.9149 - val_loss: 0.9336 - val_accuracy: 0.6142\n","Epoch 8/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4966 - accuracy: 0.9184 - val_loss: 0.9243 - val_accuracy: 0.6401\n","Epoch 9/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4899 - accuracy: 0.9203 - val_loss: 0.9139 - val_accuracy: 0.6390\n","Epoch 10/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4831 - accuracy: 0.9230 - val_loss: 0.9118 - val_accuracy: 0.6530\n","Epoch 11/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4787 - accuracy: 0.9267 - val_loss: 0.8985 - val_accuracy: 0.6670\n","Epoch 12/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4848 - accuracy: 0.9208 - val_loss: 0.8838 - val_accuracy: 0.6821\n","Epoch 13/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.4754 - accuracy: 0.9297 - val_loss: 0.8626 - val_accuracy: 0.7004\n","Epoch 14/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4773 - accuracy: 0.9300 - val_loss: 0.8666 - val_accuracy: 0.7101\n","Epoch 15/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4735 - accuracy: 0.9302 - val_loss: 0.8464 - val_accuracy: 0.7198\n","Epoch 16/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4778 - accuracy: 0.9205 - val_loss: 0.8928 - val_accuracy: 0.6929\n","Epoch 17/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4759 - accuracy: 0.9248 - val_loss: 0.8271 - val_accuracy: 0.7478\n","Epoch 18/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4772 - accuracy: 0.9224 - val_loss: 0.8179 - val_accuracy: 0.7468\n","Epoch 19/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4766 - accuracy: 0.9251 - val_loss: 0.8443 - val_accuracy: 0.7478\n","Epoch 20/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4681 - accuracy: 0.9281 - val_loss: 0.8374 - val_accuracy: 0.7608\n","Epoch 21/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4726 - accuracy: 0.9232 - val_loss: 0.8365 - val_accuracy: 0.7629\n","Epoch 22/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4625 - accuracy: 0.9291 - val_loss: 0.8318 - val_accuracy: 0.7640\n","Epoch 23/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4636 - accuracy: 0.9286 - val_loss: 0.8260 - val_accuracy: 0.7759\n","Epoch 24/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4558 - accuracy: 0.9337 - val_loss: 0.8309 - val_accuracy: 0.7759\n","Epoch 25/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4529 - accuracy: 0.9321 - val_loss: 0.8470 - val_accuracy: 0.7716\n","Epoch 26/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4610 - accuracy: 0.9318 - val_loss: 0.8995 - val_accuracy: 0.7478\n","Epoch 27/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4612 - accuracy: 0.9316 - val_loss: 0.8624 - val_accuracy: 0.7877\n","Epoch 28/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4544 - accuracy: 0.9321 - val_loss: 0.8746 - val_accuracy: 0.7780\n","Epoch 29/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4719 - accuracy: 0.9248 - val_loss: 0.9384 - val_accuracy: 0.7608\n","Epoch 30/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4793 - accuracy: 0.9227 - val_loss: 0.9886 - val_accuracy: 0.7511\n","Epoch 31/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4598 - accuracy: 0.9335 - val_loss: 0.9375 - val_accuracy: 0.7672\n","Epoch 32/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4529 - accuracy: 0.9367 - val_loss: 0.9188 - val_accuracy: 0.7683\n","Epoch 33/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4491 - accuracy: 0.9402 - val_loss: 0.9086 - val_accuracy: 0.7759\n","Epoch 34/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4471 - accuracy: 0.9383 - val_loss: 0.8941 - val_accuracy: 0.7866\n","Epoch 35/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4467 - accuracy: 0.9340 - val_loss: 0.9154 - val_accuracy: 0.7812\n","Epoch 36/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4467 - accuracy: 0.9415 - val_loss: 0.9784 - val_accuracy: 0.7500\n","Epoch 37/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4478 - accuracy: 0.9388 - val_loss: 0.9585 - val_accuracy: 0.7737\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4470 - accuracy: 0.9343 - val_loss: 0.9109 - val_accuracy: 0.7899\n","Epoch 39/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4366 - accuracy: 0.9434 - val_loss: 0.9108 - val_accuracy: 0.7920\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4345 - accuracy: 0.9399 - val_loss: 0.9090 - val_accuracy: 0.7888\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4370 - accuracy: 0.9378 - val_loss: 0.9393 - val_accuracy: 0.7726\n","Epoch 42/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4321 - accuracy: 0.9423 - val_loss: 0.9117 - val_accuracy: 0.7888\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4339 - accuracy: 0.9434 - val_loss: 0.9339 - val_accuracy: 0.7769\n","Epoch 44/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4343 - accuracy: 0.9423 - val_loss: 0.9190 - val_accuracy: 0.7877\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4342 - accuracy: 0.9429 - val_loss: 0.9550 - val_accuracy: 0.7619\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4261 - accuracy: 0.9475 - val_loss: 0.9274 - val_accuracy: 0.7812\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4258 - accuracy: 0.9469 - val_loss: 0.9379 - val_accuracy: 0.7737\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4330 - accuracy: 0.9394 - val_loss: 0.9639 - val_accuracy: 0.7619\n","Epoch 49/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4272 - accuracy: 0.9445 - val_loss: 0.9503 - val_accuracy: 0.7823\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4388 - accuracy: 0.9407 - val_loss: 0.9545 - val_accuracy: 0.7791\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4309 - accuracy: 0.9415 - val_loss: 0.9564 - val_accuracy: 0.7802\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4244 - accuracy: 0.9459 - val_loss: 0.9560 - val_accuracy: 0.7737\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4250 - accuracy: 0.9453 - val_loss: 0.9453 - val_accuracy: 0.7856\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4226 - accuracy: 0.9453 - val_loss: 0.9543 - val_accuracy: 0.7780\n","Epoch 55/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4219 - accuracy: 0.9445 - val_loss: 0.9435 - val_accuracy: 0.7791\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4181 - accuracy: 0.9472 - val_loss: 0.9853 - val_accuracy: 0.7683\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4179 - accuracy: 0.9477 - val_loss: 0.9598 - val_accuracy: 0.7769\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4155 - accuracy: 0.9499 - val_loss: 0.9667 - val_accuracy: 0.7683\n","Epoch 59/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4175 - accuracy: 0.9504 - val_loss: 0.9847 - val_accuracy: 0.7769\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4127 - accuracy: 0.9531 - val_loss: 0.9641 - val_accuracy: 0.7716\n","Epoch 61/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4118 - accuracy: 0.9504 - val_loss: 0.9693 - val_accuracy: 0.7748\n","Epoch 62/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4102 - accuracy: 0.9512 - val_loss: 0.9731 - val_accuracy: 0.7823\n","Epoch 63/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4129 - accuracy: 0.9483 - val_loss: 0.9888 - val_accuracy: 0.7726\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4065 - accuracy: 0.9526 - val_loss: 0.9638 - val_accuracy: 0.7802\n","Epoch 65/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4079 - accuracy: 0.9507 - val_loss: 1.0089 - val_accuracy: 0.7554\n","Epoch 66/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4574 - accuracy: 0.9399 - val_loss: 1.0702 - val_accuracy: 0.7565\n","Epoch 67/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4583 - accuracy: 0.9370 - val_loss: 1.1914 - val_accuracy: 0.7522\n","Epoch 68/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4968 - accuracy: 0.9254 - val_loss: 1.0524 - val_accuracy: 0.7543\n","Epoch 69/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4243 - accuracy: 0.9440 - val_loss: 1.0125 - val_accuracy: 0.7737\n","Epoch 70/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4092 - accuracy: 0.9542 - val_loss: 0.9793 - val_accuracy: 0.7759\n","Epoch 71/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4067 - accuracy: 0.9461 - val_loss: 0.9997 - val_accuracy: 0.7716\n","Epoch 72/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4039 - accuracy: 0.9520 - val_loss: 0.9906 - val_accuracy: 0.7726\n","Epoch 73/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4125 - accuracy: 0.9529 - val_loss: 0.9847 - val_accuracy: 0.7716\n","Epoch 74/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4023 - accuracy: 0.9539 - val_loss: 0.9969 - val_accuracy: 0.7748\n","Epoch 75/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4031 - accuracy: 0.9504 - val_loss: 0.9890 - val_accuracy: 0.7705\n","Epoch 76/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4011 - accuracy: 0.9545 - val_loss: 0.9830 - val_accuracy: 0.7705\n","Epoch 77/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3970 - accuracy: 0.9510 - val_loss: 0.9795 - val_accuracy: 0.7716\n","Epoch 78/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3939 - accuracy: 0.9596 - val_loss: 0.9841 - val_accuracy: 0.7791\n","Epoch 79/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3981 - accuracy: 0.9539 - val_loss: 1.0004 - val_accuracy: 0.7705\n","Epoch 80/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3956 - accuracy: 0.9545 - val_loss: 1.0011 - val_accuracy: 0.7705\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3919 - accuracy: 0.9612 - val_loss: 1.0023 - val_accuracy: 0.7748\n","Epoch 82/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3973 - accuracy: 0.9526 - val_loss: 1.0115 - val_accuracy: 0.7705\n","Epoch 83/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3929 - accuracy: 0.9542 - val_loss: 1.0050 - val_accuracy: 0.7619\n","Epoch 84/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3938 - accuracy: 0.9534 - val_loss: 1.0314 - val_accuracy: 0.7629\n","Epoch 85/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3960 - accuracy: 0.9545 - val_loss: 1.0065 - val_accuracy: 0.7726\n","Epoch 86/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3899 - accuracy: 0.9547 - val_loss: 1.0107 - val_accuracy: 0.7597\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3925 - accuracy: 0.9539 - val_loss: 1.0322 - val_accuracy: 0.7554\n","Epoch 88/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3925 - accuracy: 0.9488 - val_loss: 1.0343 - val_accuracy: 0.7608\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3895 - accuracy: 0.9569 - val_loss: 1.0222 - val_accuracy: 0.7769\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3893 - accuracy: 0.9512 - val_loss: 1.0416 - val_accuracy: 0.7543\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3860 - accuracy: 0.9588 - val_loss: 1.0270 - val_accuracy: 0.7597\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3874 - accuracy: 0.9545 - val_loss: 1.0586 - val_accuracy: 0.7683\n","Epoch 93/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3899 - accuracy: 0.9526 - val_loss: 1.0138 - val_accuracy: 0.7737\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3935 - accuracy: 0.9510 - val_loss: 1.0085 - val_accuracy: 0.7726\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3855 - accuracy: 0.9582 - val_loss: 1.0129 - val_accuracy: 0.7705\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3807 - accuracy: 0.9644 - val_loss: 1.0229 - val_accuracy: 0.7737\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3859 - accuracy: 0.9569 - val_loss: 1.0549 - val_accuracy: 0.7619\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3800 - accuracy: 0.9591 - val_loss: 1.0403 - val_accuracy: 0.7694\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3786 - accuracy: 0.9604 - val_loss: 1.0394 - val_accuracy: 0.7705\n","Epoch 100/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3771 - accuracy: 0.9607 - val_loss: 1.0566 - val_accuracy: 0.7640\n","{'loss': [0.5412436723709106, 0.5171340703964233, 0.5140020847320557, 0.5065029263496399, 0.4981505572795868, 0.4957314729690552, 0.4976288378238678, 0.49663135409355164, 0.489861398935318, 0.48311102390289307, 0.4786730706691742, 0.4847652316093445, 0.4753592014312744, 0.47726181149482727, 0.47349709272384644, 0.4777713119983673, 0.4758612811565399, 0.47715622186660767, 0.4765891432762146, 0.46811479330062866, 0.47263890504837036, 0.4624843895435333, 0.4636196196079254, 0.4558366537094116, 0.4528704583644867, 0.4609701335430145, 0.4611515700817108, 0.4543732702732086, 0.4718775451183319, 0.47928324341773987, 0.459784597158432, 0.4528599679470062, 0.44912150502204895, 0.44705429673194885, 0.4467208981513977, 0.4467436969280243, 0.4477947950363159, 0.44700682163238525, 0.4366285800933838, 0.43451836705207825, 0.4370056390762329, 0.43205946683883667, 0.4338797330856323, 0.4343477785587311, 0.4341839849948883, 0.42605650424957275, 0.42582863569259644, 0.4330165386199951, 0.42716509103775024, 0.4388081133365631, 0.430938184261322, 0.424419641494751, 0.42504265904426575, 0.4225861430168152, 0.4219140410423279, 0.4181392788887024, 0.4179299473762512, 0.4155067801475525, 0.4175153374671936, 0.4126923978328705, 0.41177061200141907, 0.410161554813385, 0.41288334131240845, 0.40647628903388977, 0.407863587141037, 0.45740529894828796, 0.45834895968437195, 0.4968302249908447, 0.4242818057537079, 0.4092400074005127, 0.4067383408546448, 0.40391770005226135, 0.41249552369117737, 0.4022890031337738, 0.4030904769897461, 0.40114328265190125, 0.39704108238220215, 0.39388594031333923, 0.39806967973709106, 0.3956374526023865, 0.39188215136528015, 0.3972756564617157, 0.3929450809955597, 0.3937869966030121, 0.39602458477020264, 0.3899157643318176, 0.3925418257713318, 0.3925146162509918, 0.38946932554244995, 0.389295756816864, 0.3860350549221039, 0.38744279742240906, 0.38994577527046204, 0.39352789521217346, 0.3855425715446472, 0.3806597888469696, 0.3858650028705597, 0.38002365827560425, 0.37861400842666626, 0.37712615728378296], 'accuracy': [0.899784505367279, 0.9086745977401733, 0.9097521305084229, 0.9146012663841248, 0.912446141242981, 0.9146012663841248, 0.9148706793785095, 0.9183728694915771, 0.920258641242981, 0.9229525923728943, 0.9267241358757019, 0.9207974076271057, 0.9296875, 0.9299569129943848, 0.9302262663841248, 0.920527994632721, 0.9248383641242981, 0.9224137663841248, 0.9251077771186829, 0.928071141242981, 0.923222005367279, 0.9291487336158752, 0.9286099076271057, 0.9337284564971924, 0.9321120977401733, 0.9318426847457886, 0.9315732717514038, 0.9321120977401733, 0.9248383641242981, 0.9226831793785095, 0.9334590435028076, 0.9366918206214905, 0.9401939511299133, 0.9383081793785095, 0.9339978694915771, 0.9415409564971924, 0.938847005367279, 0.9342672228813171, 0.9434267282485962, 0.9399245977401733, 0.9377694129943848, 0.9423491358757019, 0.9434267282485962, 0.9423491358757019, 0.9428879022598267, 0.9474676847457886, 0.946928858757019, 0.9393857717514038, 0.9445043206214905, 0.9407327771186829, 0.9415409564971924, 0.9458512663841248, 0.9453125, 0.9453125, 0.9445043206214905, 0.9471982717514038, 0.9477370977401733, 0.9498922228813171, 0.9504310488700867, 0.953125, 0.9504310488700867, 0.9512392282485962, 0.9482758641242981, 0.9525862336158752, 0.9507004022598267, 0.9399245977401733, 0.9369612336158752, 0.9253771305084229, 0.943965494632721, 0.9542025923728943, 0.9461206793785095, 0.9520474076271057, 0.9528555870056152, 0.9539331793785095, 0.9504310488700867, 0.954472005367279, 0.9509698152542114, 0.959590494632721, 0.9539331793785095, 0.954472005367279, 0.9612069129943848, 0.9525862336158752, 0.9542025923728943, 0.9533944129943848, 0.954472005367279, 0.954741358757019, 0.9539331793785095, 0.9488146305084229, 0.9568965435028076, 0.9512392282485962, 0.9587823152542114, 0.954472005367279, 0.9525862336158752, 0.9509698152542114, 0.9582435488700867, 0.9644396305084229, 0.9568965435028076, 0.9590517282485962, 0.9603987336158752, 0.9606680870056152], 'val_loss': [1.00452721118927, 0.9641274213790894, 0.9456170201301575, 0.9507509469985962, 0.9407988786697388, 0.9357189536094666, 0.9336394667625427, 0.9243276119232178, 0.9138938784599304, 0.9118239283561707, 0.8985440731048584, 0.8838218450546265, 0.8625658750534058, 0.866569459438324, 0.8463745713233948, 0.8928080201148987, 0.8270959258079529, 0.8179156184196472, 0.8442928791046143, 0.83740234375, 0.8365055322647095, 0.8318260312080383, 0.8260231018066406, 0.8308567404747009, 0.8470108509063721, 0.8995433449745178, 0.8624265193939209, 0.8745809197425842, 0.9383975267410278, 0.988574206829071, 0.9375059008598328, 0.9187932014465332, 0.9085789322853088, 0.8940703868865967, 0.9154137969017029, 0.9784392714500427, 0.9584867358207703, 0.9108827710151672, 0.9107524752616882, 0.908961832523346, 0.939297080039978, 0.9117485284805298, 0.9338938593864441, 0.9189804792404175, 0.9550371766090393, 0.9273680448532104, 0.9379454851150513, 0.9639067053794861, 0.9503392577171326, 0.9544843435287476, 0.956414520740509, 0.9560458660125732, 0.9453199505805969, 0.954343855381012, 0.9435389041900635, 0.9853266477584839, 0.9597682356834412, 0.9667377471923828, 0.9847326874732971, 0.9640986323356628, 0.969278872013092, 0.9730691313743591, 0.9888429045677185, 0.9637827277183533, 1.0089077949523926, 1.0702025890350342, 1.1914256811141968, 1.0524166822433472, 1.0124820470809937, 0.9792983531951904, 0.9996511340141296, 0.9906272888183594, 0.9847432374954224, 0.9969421625137329, 0.9889523983001709, 0.9830119013786316, 0.9794504642486572, 0.9840577840805054, 1.0004355907440186, 1.0010842084884644, 1.0023188591003418, 1.0115283727645874, 1.0050499439239502, 1.0313875675201416, 1.0064783096313477, 1.0107091665267944, 1.0322271585464478, 1.034306526184082, 1.0222469568252563, 1.0416412353515625, 1.0270264148712158, 1.0585588216781616, 1.013841152191162, 1.008469820022583, 1.0129162073135376, 1.022874116897583, 1.0549336671829224, 1.040300726890564, 1.0394444465637207, 1.056572437286377], 'val_accuracy': [0.5894396305084229, 0.5969827771186829, 0.5883620977401733, 0.5883620977401733, 0.5980603694915771, 0.6239224076271057, 0.6142241358757019, 0.6400862336158752, 0.639008641242981, 0.6530172228813171, 0.6670258641242981, 0.6821120977401733, 0.7004310488700867, 0.7101293206214905, 0.7198275923728943, 0.6928879022598267, 0.7478448152542114, 0.7467672228813171, 0.7478448152542114, 0.7607758641242981, 0.7629310488700867, 0.764008641242981, 0.7758620977401733, 0.7758620977401733, 0.7715517282485962, 0.7478448152542114, 0.787715494632721, 0.7780172228813171, 0.7607758641242981, 0.7510775923728943, 0.767241358757019, 0.7683189511299133, 0.7758620977401733, 0.7866379022598267, 0.78125, 0.75, 0.7737069129943848, 0.7898706793785095, 0.7920258641242981, 0.7887930870056152, 0.7726293206214905, 0.7887930870056152, 0.7769396305084229, 0.787715494632721, 0.7618534564971924, 0.78125, 0.7737069129943848, 0.7618534564971924, 0.7823275923728943, 0.7790948152542114, 0.7801724076271057, 0.7737069129943848, 0.7855603694915771, 0.7780172228813171, 0.7790948152542114, 0.7683189511299133, 0.7769396305084229, 0.7683189511299133, 0.7769396305084229, 0.7715517282485962, 0.774784505367279, 0.7823275923728943, 0.7726293206214905, 0.7801724076271057, 0.7553879022598267, 0.756465494632721, 0.7521551847457886, 0.7543103694915771, 0.7737069129943848, 0.7758620977401733, 0.7715517282485962, 0.7726293206214905, 0.7715517282485962, 0.774784505367279, 0.7704741358757019, 0.7704741358757019, 0.7715517282485962, 0.7790948152542114, 0.7704741358757019, 0.7704741358757019, 0.774784505367279, 0.7704741358757019, 0.7618534564971924, 0.7629310488700867, 0.7726293206214905, 0.7596982717514038, 0.7553879022598267, 0.7607758641242981, 0.7769396305084229, 0.7543103694915771, 0.7596982717514038, 0.7683189511299133, 0.7737069129943848, 0.7726293206214905, 0.7704741358757019, 0.7737069129943848, 0.7618534564971924, 0.7693965435028076, 0.7704741358757019, 0.764008641242981]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 3s 29ms/step - loss: 0.5505 - accuracy: 0.8896 - val_loss: 0.9491 - val_accuracy: 0.6063\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.5875 - accuracy: 0.8359"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 14ms/step - loss: 0.5356 - accuracy: 0.8950 - val_loss: 0.9534 - val_accuracy: 0.6029\n","Epoch 3/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5300 - accuracy: 0.9012 - val_loss: 0.9483 - val_accuracy: 0.6063\n","Epoch 4/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5172 - accuracy: 0.9095 - val_loss: 0.9317 - val_accuracy: 0.6256\n","Epoch 5/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5080 - accuracy: 0.9140 - val_loss: 0.9271 - val_accuracy: 0.6256\n","Epoch 6/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5103 - accuracy: 0.9103 - val_loss: 0.9258 - val_accuracy: 0.6233\n","Epoch 7/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5029 - accuracy: 0.9157 - val_loss: 0.9124 - val_accuracy: 0.6527\n","Epoch 8/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5080 - accuracy: 0.9083 - val_loss: 0.9306 - val_accuracy: 0.6256\n","Epoch 9/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5175 - accuracy: 0.9044 - val_loss: 0.9206 - val_accuracy: 0.6437\n","Epoch 10/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5090 - accuracy: 0.9140 - val_loss: 0.9151 - val_accuracy: 0.6493\n","Epoch 11/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4938 - accuracy: 0.9219 - val_loss: 0.9001 - val_accuracy: 0.6550\n","Epoch 12/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4934 - accuracy: 0.9219 - val_loss: 0.8816 - val_accuracy: 0.6572\n","Epoch 13/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4866 - accuracy: 0.9256 - val_loss: 0.8753 - val_accuracy: 0.6787\n","Epoch 14/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4860 - accuracy: 0.9247 - val_loss: 0.8875 - val_accuracy: 0.6855\n","Epoch 15/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4859 - accuracy: 0.9222 - val_loss: 0.8519 - val_accuracy: 0.7014\n","Epoch 16/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4832 - accuracy: 0.9228 - val_loss: 0.8793 - val_accuracy: 0.7059\n","Epoch 17/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4935 - accuracy: 0.9165 - val_loss: 0.8296 - val_accuracy: 0.7172\n","Epoch 18/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4921 - accuracy: 0.9162 - val_loss: 0.8665 - val_accuracy: 0.7093\n","Epoch 19/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4774 - accuracy: 0.9284 - val_loss: 0.8322 - val_accuracy: 0.7387\n","Epoch 20/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4732 - accuracy: 0.9256 - val_loss: 0.8501 - val_accuracy: 0.7285\n","Epoch 21/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4763 - accuracy: 0.9278 - val_loss: 0.8246 - val_accuracy: 0.7229\n","Epoch 22/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4759 - accuracy: 0.9259 - val_loss: 0.8011 - val_accuracy: 0.7602\n","Epoch 23/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4678 - accuracy: 0.9310 - val_loss: 0.8190 - val_accuracy: 0.7534\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4702 - accuracy: 0.9290 - val_loss: 0.8016 - val_accuracy: 0.7715\n","Epoch 25/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4714 - accuracy: 0.9284 - val_loss: 0.8050 - val_accuracy: 0.7805\n","Epoch 26/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4632 - accuracy: 0.9301 - val_loss: 0.8173 - val_accuracy: 0.7670\n","Epoch 27/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4636 - accuracy: 0.9349 - val_loss: 0.8219 - val_accuracy: 0.7828\n","Epoch 28/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4592 - accuracy: 0.9346 - val_loss: 0.8495 - val_accuracy: 0.7805\n","Epoch 29/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4609 - accuracy: 0.9358 - val_loss: 0.8175 - val_accuracy: 0.7896\n","Epoch 30/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4708 - accuracy: 0.9264 - val_loss: 0.8682 - val_accuracy: 0.7568\n","Epoch 31/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4632 - accuracy: 0.9366 - val_loss: 0.8510 - val_accuracy: 0.7817\n","Epoch 32/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4597 - accuracy: 0.9389 - val_loss: 0.8350 - val_accuracy: 0.7851\n","Epoch 33/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4544 - accuracy: 0.9386 - val_loss: 0.8497 - val_accuracy: 0.7749\n","Epoch 34/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4551 - accuracy: 0.9355 - val_loss: 0.8412 - val_accuracy: 0.7839\n","Epoch 35/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4560 - accuracy: 0.9366 - val_loss: 0.8437 - val_accuracy: 0.7839\n","Epoch 36/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4495 - accuracy: 0.9392 - val_loss: 0.8463 - val_accuracy: 0.7907\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4579 - accuracy: 0.9329 - val_loss: 0.9007 - val_accuracy: 0.7794\n","Epoch 38/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4604 - accuracy: 0.9352 - val_loss: 0.9741 - val_accuracy: 0.7670\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4691 - accuracy: 0.9256 - val_loss: 0.8701 - val_accuracy: 0.7624\n","Epoch 40/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4532 - accuracy: 0.9332 - val_loss: 0.8606 - val_accuracy: 0.7805\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4636 - accuracy: 0.9310 - val_loss: 0.8909 - val_accuracy: 0.7658\n","Epoch 42/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4482 - accuracy: 0.9380 - val_loss: 0.8861 - val_accuracy: 0.7760\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4469 - accuracy: 0.9423 - val_loss: 0.8734 - val_accuracy: 0.7817\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4389 - accuracy: 0.9445 - val_loss: 0.8766 - val_accuracy: 0.7715\n","Epoch 45/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4470 - accuracy: 0.9349 - val_loss: 0.9060 - val_accuracy: 0.7692\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4380 - accuracy: 0.9431 - val_loss: 0.8822 - val_accuracy: 0.7670\n","Epoch 47/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4469 - accuracy: 0.9335 - val_loss: 0.9328 - val_accuracy: 0.7534\n","Epoch 48/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4491 - accuracy: 0.9403 - val_loss: 0.9061 - val_accuracy: 0.7794\n","Epoch 49/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4400 - accuracy: 0.9386 - val_loss: 0.9044 - val_accuracy: 0.7794\n","Epoch 50/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4330 - accuracy: 0.9403 - val_loss: 0.8856 - val_accuracy: 0.7839\n","Epoch 51/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4361 - accuracy: 0.9397 - val_loss: 0.8854 - val_accuracy: 0.7839\n","Epoch 52/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4292 - accuracy: 0.9468 - val_loss: 0.9332 - val_accuracy: 0.7432\n","Epoch 53/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4426 - accuracy: 0.9389 - val_loss: 0.9370 - val_accuracy: 0.7523\n","Epoch 54/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4719 - accuracy: 0.9287 - val_loss: 1.1498 - val_accuracy: 0.7342\n","Epoch 55/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4794 - accuracy: 0.9287 - val_loss: 0.9889 - val_accuracy: 0.7443\n","Epoch 56/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4451 - accuracy: 0.9403 - val_loss: 0.9142 - val_accuracy: 0.7783\n","Epoch 57/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4315 - accuracy: 0.9423 - val_loss: 0.8899 - val_accuracy: 0.7760\n","Epoch 58/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4284 - accuracy: 0.9428 - val_loss: 0.8900 - val_accuracy: 0.7828\n","Epoch 59/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4285 - accuracy: 0.9431 - val_loss: 0.9043 - val_accuracy: 0.7794\n","Epoch 60/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4270 - accuracy: 0.9451 - val_loss: 0.9256 - val_accuracy: 0.7466\n","Epoch 61/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4228 - accuracy: 0.9443 - val_loss: 0.9107 - val_accuracy: 0.7738\n","Epoch 62/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4229 - accuracy: 0.9457 - val_loss: 0.8884 - val_accuracy: 0.7738\n","Epoch 63/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4196 - accuracy: 0.9493 - val_loss: 0.9006 - val_accuracy: 0.7817\n","Epoch 64/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4177 - accuracy: 0.9488 - val_loss: 0.9305 - val_accuracy: 0.7443\n","Epoch 65/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4235 - accuracy: 0.9454 - val_loss: 0.9424 - val_accuracy: 0.7545\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4156 - accuracy: 0.9505 - val_loss: 0.9070 - val_accuracy: 0.7636\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4221 - accuracy: 0.9457 - val_loss: 0.9348 - val_accuracy: 0.7670\n","Epoch 68/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4260 - accuracy: 0.9457 - val_loss: 0.9124 - val_accuracy: 0.7670\n","Epoch 69/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4457 - accuracy: 0.9352 - val_loss: 0.9918 - val_accuracy: 0.7342\n","Epoch 70/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4425 - accuracy: 0.9315 - val_loss: 1.0165 - val_accuracy: 0.7251\n","Epoch 71/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4252 - accuracy: 0.9474 - val_loss: 0.9619 - val_accuracy: 0.7568\n","Epoch 72/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4149 - accuracy: 0.9468 - val_loss: 0.9223 - val_accuracy: 0.7749\n","Epoch 73/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4098 - accuracy: 0.9505 - val_loss: 0.9093 - val_accuracy: 0.7749\n","Epoch 74/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4079 - accuracy: 0.9536 - val_loss: 0.9133 - val_accuracy: 0.7715\n","Epoch 75/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4121 - accuracy: 0.9491 - val_loss: 0.9077 - val_accuracy: 0.7760\n","Epoch 76/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4044 - accuracy: 0.9559 - val_loss: 0.9193 - val_accuracy: 0.7771\n","Epoch 77/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4047 - accuracy: 0.9530 - val_loss: 0.9181 - val_accuracy: 0.7805\n","Epoch 78/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4076 - accuracy: 0.9491 - val_loss: 0.9296 - val_accuracy: 0.7704\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4036 - accuracy: 0.9519 - val_loss: 0.9166 - val_accuracy: 0.7738\n","Epoch 80/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4041 - accuracy: 0.9553 - val_loss: 0.9405 - val_accuracy: 0.7670\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4024 - accuracy: 0.9522 - val_loss: 0.9422 - val_accuracy: 0.7545\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4057 - accuracy: 0.9522 - val_loss: 0.9363 - val_accuracy: 0.7613\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3997 - accuracy: 0.9559 - val_loss: 0.9288 - val_accuracy: 0.7670\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4089 - accuracy: 0.9493 - val_loss: 0.9871 - val_accuracy: 0.7613\n","Epoch 85/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3987 - accuracy: 0.9542 - val_loss: 0.9477 - val_accuracy: 0.7738\n","Epoch 86/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4006 - accuracy: 0.9530 - val_loss: 0.9493 - val_accuracy: 0.7681\n","Epoch 87/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3981 - accuracy: 0.9547 - val_loss: 0.9470 - val_accuracy: 0.7749\n","Epoch 88/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3984 - accuracy: 0.9527 - val_loss: 0.9562 - val_accuracy: 0.7715\n","Epoch 89/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4046 - accuracy: 0.9499 - val_loss: 0.9634 - val_accuracy: 0.7647\n","Epoch 90/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3950 - accuracy: 0.9567 - val_loss: 0.9734 - val_accuracy: 0.7590\n","Epoch 91/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3916 - accuracy: 0.9559 - val_loss: 0.9620 - val_accuracy: 0.7670\n","Epoch 92/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3911 - accuracy: 0.9544 - val_loss: 0.9761 - val_accuracy: 0.7579\n","Epoch 93/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3898 - accuracy: 0.9584 - val_loss: 0.9992 - val_accuracy: 0.7613\n","Epoch 94/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3897 - accuracy: 0.9573 - val_loss: 0.9956 - val_accuracy: 0.7647\n","Epoch 95/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3929 - accuracy: 0.9567 - val_loss: 0.9898 - val_accuracy: 0.7376\n","Epoch 96/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3902 - accuracy: 0.9581 - val_loss: 0.9602 - val_accuracy: 0.7670\n","Epoch 97/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3916 - accuracy: 0.9584 - val_loss: 0.9635 - val_accuracy: 0.7692\n","Epoch 98/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4175 - accuracy: 0.9417 - val_loss: 0.9916 - val_accuracy: 0.7579\n","Epoch 99/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3893 - accuracy: 0.9542 - val_loss: 1.0116 - val_accuracy: 0.7387\n","Epoch 100/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4145 - accuracy: 0.9556 - val_loss: 1.0616 - val_accuracy: 0.7443\n","{'loss': [0.5505011677742004, 0.5356467962265015, 0.5300382971763611, 0.5171911120414734, 0.5079697966575623, 0.5103170275688171, 0.5028844475746155, 0.5079907774925232, 0.5175110697746277, 0.5090445876121521, 0.4938351511955261, 0.49336403608322144, 0.48657843470573425, 0.48597511649131775, 0.48587945103645325, 0.4831608533859253, 0.49349796772003174, 0.4920845627784729, 0.47742098569869995, 0.4731729328632355, 0.476258248090744, 0.4759260416030884, 0.46780794858932495, 0.4702274203300476, 0.47136634588241577, 0.46317291259765625, 0.4636405110359192, 0.45923805236816406, 0.46086665987968445, 0.47079846262931824, 0.4631621837615967, 0.45971623063087463, 0.4544001817703247, 0.4551394283771515, 0.455981582403183, 0.4495484232902527, 0.45791658759117126, 0.46044039726257324, 0.46906623244285583, 0.45320016145706177, 0.46357908844947815, 0.44815126061439514, 0.4468831419944763, 0.43892771005630493, 0.4469989538192749, 0.43797728419303894, 0.44692447781562805, 0.4490872621536255, 0.44004735350608826, 0.4330179989337921, 0.43614447116851807, 0.4291500449180603, 0.4425695836544037, 0.47191596031188965, 0.4794498085975647, 0.4451075494289398, 0.43152549862861633, 0.42839515209198, 0.4285362660884857, 0.4269673526287079, 0.4228250980377197, 0.4229486286640167, 0.4196072220802307, 0.4177226424217224, 0.4235275089740753, 0.4156290292739868, 0.42209070920944214, 0.42602020502090454, 0.4456973075866699, 0.4424721300601959, 0.42518892884254456, 0.4148918688297272, 0.40980255603790283, 0.40794339776039124, 0.4121244549751282, 0.40439650416374207, 0.40468263626098633, 0.40759673714637756, 0.4035899341106415, 0.4040646255016327, 0.4023933410644531, 0.40568140149116516, 0.399736613035202, 0.40893471240997314, 0.3987196385860443, 0.4005817174911499, 0.3980823755264282, 0.398415207862854, 0.4046474099159241, 0.3950135409832001, 0.39164409041404724, 0.39114347100257874, 0.38984984159469604, 0.3896808922290802, 0.3928672969341278, 0.3901813328266144, 0.391613245010376, 0.4174995720386505, 0.38934633135795593, 0.41448748111724854], 'accuracy': [0.8896434903144836, 0.8950198292732239, 0.9012450575828552, 0.9094510674476624, 0.9139785170555115, 0.9102999567985535, 0.9156762957572937, 0.9083191752433777, 0.9043576717376709, 0.9139785170555115, 0.921901524066925, 0.921901524066925, 0.9255800843238831, 0.9247311949729919, 0.9221844673156738, 0.9227504134178162, 0.9165251851081848, 0.916242241859436, 0.92840975522995, 0.9255800843238831, 0.9278438091278076, 0.9258630275726318, 0.9309564232826233, 0.9289756417274475, 0.92840975522995, 0.9301075339317322, 0.9349179267883301, 0.9346349835395813, 0.9357668161392212, 0.9264289736747742, 0.9366157054901123, 0.9388794302940369, 0.9385964870452881, 0.9354838728904724, 0.9366157054901123, 0.9391624331474304, 0.9329372048377991, 0.9352009296417236, 0.9255800843238831, 0.9332201480865479, 0.9309564232826233, 0.9380305409431458, 0.9422750473022461, 0.9445387721061707, 0.9349179267883301, 0.9431239366531372, 0.9335030913352966, 0.9402942657470703, 0.9385964870452881, 0.9402942657470703, 0.9397283792495728, 0.9468024969100952, 0.9388794302940369, 0.9286926984786987, 0.9286926984786987, 0.9402942657470703, 0.9422750473022461, 0.9428409934043884, 0.9431239366531372, 0.945104718208313, 0.9442558288574219, 0.9456706047058105, 0.9493491649627686, 0.9487832188606262, 0.9453876614570618, 0.9504810571670532, 0.9456706047058105, 0.9456706047058105, 0.9352009296417236, 0.9315223693847656, 0.9473684430122375, 0.9468024969100952, 0.9504810571670532, 0.9535936713218689, 0.9490662217140198, 0.9558573961257935, 0.9530277252197266, 0.9490662217140198, 0.9518958926200867, 0.9552914500236511, 0.9521788358688354, 0.9521788358688354, 0.9558573961257935, 0.9493491649627686, 0.9541596174240112, 0.9530277252197266, 0.9547255039215088, 0.9527447819709778, 0.9499151110649109, 0.9567062854766846, 0.9558573961257935, 0.95444256067276, 0.9584040641784668, 0.9572722315788269, 0.9567062854766846, 0.958121120929718, 0.9584040641784668, 0.9417091012001038, 0.9541596174240112, 0.9555743932723999], 'val_loss': [0.9491010904312134, 0.9534041881561279, 0.948313295841217, 0.9316565990447998, 0.9270569682121277, 0.9257715344429016, 0.9124276041984558, 0.9305816292762756, 0.9205688834190369, 0.915106475353241, 0.900058388710022, 0.8816478848457336, 0.8752553462982178, 0.8875090479850769, 0.8518751263618469, 0.8792862296104431, 0.8295550346374512, 0.8664533495903015, 0.8321740627288818, 0.8501245975494385, 0.8246140480041504, 0.8011268973350525, 0.8190255761146545, 0.8016088008880615, 0.8050167560577393, 0.8173030614852905, 0.821916937828064, 0.8494603633880615, 0.8175095915794373, 0.8682234287261963, 0.8509518504142761, 0.8350280523300171, 0.8497205376625061, 0.8411937952041626, 0.8436999917030334, 0.846278965473175, 0.9006586074829102, 0.9740583896636963, 0.8700936436653137, 0.8606324791908264, 0.8908941149711609, 0.886054277420044, 0.8733736872673035, 0.8765798807144165, 0.9060310125350952, 0.8821552395820618, 0.9328207969665527, 0.9061233997344971, 0.90440833568573, 0.8856253623962402, 0.8853902816772461, 0.9331521391868591, 0.9370320439338684, 1.1498361825942993, 0.9888724088668823, 0.9141809940338135, 0.8899211883544922, 0.8899657726287842, 0.9043264389038086, 0.9255512356758118, 0.9107307195663452, 0.8884143829345703, 0.9006340503692627, 0.9304676055908203, 0.9424412846565247, 0.9069918394088745, 0.934760332107544, 0.9124463200569153, 0.9918301701545715, 1.016501545906067, 0.9619389772415161, 0.9223370552062988, 0.9092729687690735, 0.9132944941520691, 0.9076734781265259, 0.9192514419555664, 0.9181165099143982, 0.9296206831932068, 0.9165982007980347, 0.9404609203338623, 0.9422212243080139, 0.9362586736679077, 0.9287509918212891, 0.987076997756958, 0.9477460980415344, 0.9492822885513306, 0.9470118880271912, 0.9561612010002136, 0.9634369015693665, 0.97342848777771, 0.961950957775116, 0.9760857224464417, 0.9992262721061707, 0.9955767393112183, 0.9898337721824646, 0.9602058529853821, 0.9635279178619385, 0.991590142250061, 1.0115503072738647, 1.0616402626037598], 'val_accuracy': [0.6063348650932312, 0.6029411554336548, 0.6063348650932312, 0.6255655884742737, 0.6255655884742737, 0.6233031749725342, 0.6527149081230164, 0.6255655884742737, 0.6436651349067688, 0.6493212580680847, 0.6549773812294006, 0.6572397947311401, 0.6787330508232117, 0.685520350933075, 0.7013574838638306, 0.7058823704719543, 0.7171945571899414, 0.709276020526886, 0.7386877536773682, 0.7285068035125732, 0.7228506803512573, 0.7601810097694397, 0.7533936500549316, 0.7714931964874268, 0.7805429697036743, 0.766968309879303, 0.7828054428100586, 0.7805429697036743, 0.7895927429199219, 0.7567873597145081, 0.7816742062568665, 0.7850678563117981, 0.7748869061470032, 0.7839366793632507, 0.7839366793632507, 0.790723979473114, 0.779411792755127, 0.766968309879303, 0.7624434232711792, 0.7805429697036743, 0.7658371329307556, 0.7760180830955505, 0.7816742062568665, 0.7714931964874268, 0.7692307829856873, 0.766968309879303, 0.7533936500549316, 0.779411792755127, 0.779411792755127, 0.7839366793632507, 0.7839366793632507, 0.7432126402854919, 0.7522624731063843, 0.7341628670692444, 0.7443438768386841, 0.7782805562019348, 0.7760180830955505, 0.7828054428100586, 0.779411792755127, 0.7466063499450684, 0.773755669593811, 0.773755669593811, 0.7816742062568665, 0.7443438768386841, 0.7545248866081238, 0.7635746598243713, 0.766968309879303, 0.766968309879303, 0.7341628670692444, 0.7251130938529968, 0.7567873597145081, 0.7748869061470032, 0.7748869061470032, 0.7714931964874268, 0.7760180830955505, 0.7771493196487427, 0.7805429697036743, 0.7703620195388794, 0.773755669593811, 0.766968309879303, 0.7545248866081238, 0.7613122463226318, 0.766968309879303, 0.7613122463226318, 0.773755669593811, 0.7680995464324951, 0.7748869061470032, 0.7714931964874268, 0.7647058963775635, 0.7590497732162476, 0.766968309879303, 0.7579185366630554, 0.7613122463226318, 0.7647058963775635, 0.7375565767288208, 0.766968309879303, 0.7692307829856873, 0.7579185366630554, 0.7386877536773682, 0.7443438768386841]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.5577 - accuracy: 0.8912"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 5s 37ms/step - loss: 0.5577 - accuracy: 0.8912 - val_loss: 1.0160 - val_accuracy: 0.5651\n","Epoch 2/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5386 - accuracy: 0.8961 - val_loss: 0.9647 - val_accuracy: 0.5961\n","Epoch 3/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5370 - accuracy: 0.8992 - val_loss: 0.9533 - val_accuracy: 0.6002\n","Epoch 4/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5301 - accuracy: 0.9008 - val_loss: 0.9388 - val_accuracy: 0.6219\n","Epoch 5/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5243 - accuracy: 0.9065 - val_loss: 0.9291 - val_accuracy: 0.6260\n","Epoch 6/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5146 - accuracy: 0.9080 - val_loss: 0.9265 - val_accuracy: 0.6519\n","Epoch 7/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5257 - accuracy: 0.8992 - val_loss: 0.9431 - val_accuracy: 0.6539\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5511 - accuracy: 0.8935 - val_loss: 0.8989 - val_accuracy: 0.6705\n","Epoch 9/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5274 - accuracy: 0.8974 - val_loss: 0.9252 - val_accuracy: 0.6477\n","Epoch 10/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5165 - accuracy: 0.9034 - val_loss: 0.9165 - val_accuracy: 0.6539\n","Epoch 11/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5091 - accuracy: 0.9140 - val_loss: 0.8948 - val_accuracy: 0.6694\n","Epoch 12/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5014 - accuracy: 0.9181 - val_loss: 0.9010 - val_accuracy: 0.6725\n","Epoch 13/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4999 - accuracy: 0.9181 - val_loss: 0.8546 - val_accuracy: 0.7180\n","Epoch 14/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4986 - accuracy: 0.9183 - val_loss: 0.8454 - val_accuracy: 0.7200\n","Epoch 15/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4949 - accuracy: 0.9204 - val_loss: 0.8503 - val_accuracy: 0.7242\n","Epoch 16/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4965 - accuracy: 0.9171 - val_loss: 0.8797 - val_accuracy: 0.7128\n","Epoch 17/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4978 - accuracy: 0.9147 - val_loss: 0.8605 - val_accuracy: 0.7293\n","Epoch 18/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5072 - accuracy: 0.9057 - val_loss: 0.9306 - val_accuracy: 0.6787\n","Epoch 19/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5029 - accuracy: 0.9150 - val_loss: 0.8688 - val_accuracy: 0.7345\n","Epoch 20/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4920 - accuracy: 0.9196 - val_loss: 0.8736 - val_accuracy: 0.7200\n","Epoch 21/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4872 - accuracy: 0.9214 - val_loss: 0.8634 - val_accuracy: 0.7314\n","Epoch 22/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4842 - accuracy: 0.9225 - val_loss: 0.8962 - val_accuracy: 0.7355\n","Epoch 23/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4853 - accuracy: 0.9220 - val_loss: 0.8871 - val_accuracy: 0.7407\n","Epoch 24/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4842 - accuracy: 0.9225 - val_loss: 0.9020 - val_accuracy: 0.7541\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4905 - accuracy: 0.9204 - val_loss: 0.9115 - val_accuracy: 0.7438\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4802 - accuracy: 0.9274 - val_loss: 0.9278 - val_accuracy: 0.7407\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4820 - accuracy: 0.9204 - val_loss: 1.0427 - val_accuracy: 0.7138\n","Epoch 28/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5078 - accuracy: 0.9016 - val_loss: 0.9272 - val_accuracy: 0.7624\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4776 - accuracy: 0.9238 - val_loss: 0.9385 - val_accuracy: 0.7479\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4710 - accuracy: 0.9331 - val_loss: 0.9350 - val_accuracy: 0.7552\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4715 - accuracy: 0.9274 - val_loss: 0.9571 - val_accuracy: 0.7531\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4736 - accuracy: 0.9271 - val_loss: 0.9446 - val_accuracy: 0.7510\n","Epoch 33/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4686 - accuracy: 0.9302 - val_loss: 0.9728 - val_accuracy: 0.7541\n","Epoch 34/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4688 - accuracy: 0.9282 - val_loss: 0.9498 - val_accuracy: 0.7593\n","Epoch 35/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4752 - accuracy: 0.9235 - val_loss: 0.9505 - val_accuracy: 0.7510\n","Epoch 36/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4670 - accuracy: 0.9269 - val_loss: 0.9641 - val_accuracy: 0.7438\n","Epoch 37/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4671 - accuracy: 0.9302 - val_loss: 0.9581 - val_accuracy: 0.7521\n","Epoch 38/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4664 - accuracy: 0.9297 - val_loss: 0.9843 - val_accuracy: 0.7366\n","Epoch 39/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4608 - accuracy: 0.9279 - val_loss: 0.9922 - val_accuracy: 0.7221\n","Epoch 40/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4605 - accuracy: 0.9323 - val_loss: 1.0037 - val_accuracy: 0.7355\n","Epoch 41/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4621 - accuracy: 0.9295 - val_loss: 0.9878 - val_accuracy: 0.7304\n","Epoch 42/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4585 - accuracy: 0.9318 - val_loss: 0.9977 - val_accuracy: 0.7355\n","Epoch 43/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4574 - accuracy: 0.9320 - val_loss: 0.9853 - val_accuracy: 0.7541\n","Epoch 44/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4537 - accuracy: 0.9336 - val_loss: 0.9946 - val_accuracy: 0.7397\n","Epoch 45/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4547 - accuracy: 0.9362 - val_loss: 1.0301 - val_accuracy: 0.7386\n","Epoch 46/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4541 - accuracy: 0.9333 - val_loss: 0.9761 - val_accuracy: 0.7355\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4600 - accuracy: 0.9295 - val_loss: 1.0075 - val_accuracy: 0.7428\n","Epoch 48/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4533 - accuracy: 0.9328 - val_loss: 0.9946 - val_accuracy: 0.7304\n","Epoch 49/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4484 - accuracy: 0.9344 - val_loss: 0.9969 - val_accuracy: 0.7417\n","Epoch 50/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4456 - accuracy: 0.9382 - val_loss: 1.0002 - val_accuracy: 0.7386\n","Epoch 51/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4430 - accuracy: 0.9375 - val_loss: 1.0092 - val_accuracy: 0.7459\n","Epoch 52/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4384 - accuracy: 0.9411 - val_loss: 1.0011 - val_accuracy: 0.7407\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4439 - accuracy: 0.9390 - val_loss: 0.9950 - val_accuracy: 0.7366\n","Epoch 54/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4465 - accuracy: 0.9323 - val_loss: 1.0163 - val_accuracy: 0.7490\n","Epoch 55/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4487 - accuracy: 0.9359 - val_loss: 1.0087 - val_accuracy: 0.7397\n","Epoch 56/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4603 - accuracy: 0.9297 - val_loss: 1.1139 - val_accuracy: 0.7283\n","Epoch 57/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4676 - accuracy: 0.9251 - val_loss: 1.1154 - val_accuracy: 0.7004\n","Epoch 58/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4742 - accuracy: 0.9194 - val_loss: 1.2971 - val_accuracy: 0.7087\n","Epoch 59/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5565 - accuracy: 0.8941 - val_loss: 1.0768 - val_accuracy: 0.7438\n","Epoch 60/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4920 - accuracy: 0.9147 - val_loss: 1.1402 - val_accuracy: 0.7304\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4604 - accuracy: 0.9297 - val_loss: 1.0708 - val_accuracy: 0.7304\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4564 - accuracy: 0.9377 - val_loss: 1.1420 - val_accuracy: 0.7118\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4458 - accuracy: 0.9380 - val_loss: 0.9999 - val_accuracy: 0.7469\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4385 - accuracy: 0.9390 - val_loss: 0.9977 - val_accuracy: 0.7376\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4298 - accuracy: 0.9406 - val_loss: 1.0066 - val_accuracy: 0.7397\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4329 - accuracy: 0.9429 - val_loss: 0.9969 - val_accuracy: 0.7417\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4303 - accuracy: 0.9426 - val_loss: 1.0339 - val_accuracy: 0.7262\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4264 - accuracy: 0.9413 - val_loss: 1.0112 - val_accuracy: 0.7438\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4306 - accuracy: 0.9375 - val_loss: 1.0085 - val_accuracy: 0.7448\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4280 - accuracy: 0.9385 - val_loss: 1.0166 - val_accuracy: 0.7490\n","Epoch 71/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4265 - accuracy: 0.9398 - val_loss: 1.0853 - val_accuracy: 0.7252\n","Epoch 72/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4243 - accuracy: 0.9442 - val_loss: 1.0226 - val_accuracy: 0.7335\n","Epoch 73/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4262 - accuracy: 0.9426 - val_loss: 1.0236 - val_accuracy: 0.7428\n","Epoch 74/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4219 - accuracy: 0.9411 - val_loss: 1.0582 - val_accuracy: 0.7355\n","Epoch 75/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4204 - accuracy: 0.9434 - val_loss: 1.1028 - val_accuracy: 0.7262\n","Epoch 76/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4247 - accuracy: 0.9416 - val_loss: 1.0349 - val_accuracy: 0.7438\n","Epoch 77/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4244 - accuracy: 0.9419 - val_loss: 1.0536 - val_accuracy: 0.7479\n","Epoch 78/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4186 - accuracy: 0.9421 - val_loss: 1.0592 - val_accuracy: 0.7252\n","Epoch 79/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4197 - accuracy: 0.9457 - val_loss: 1.0467 - val_accuracy: 0.7324\n","Epoch 80/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4197 - accuracy: 0.9421 - val_loss: 1.0534 - val_accuracy: 0.7355\n","Epoch 81/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4180 - accuracy: 0.9429 - val_loss: 1.0525 - val_accuracy: 0.7397\n","Epoch 82/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4162 - accuracy: 0.9447 - val_loss: 1.0592 - val_accuracy: 0.7438\n","Epoch 83/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4135 - accuracy: 0.9457 - val_loss: 1.0471 - val_accuracy: 0.7335\n","Epoch 84/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4128 - accuracy: 0.9460 - val_loss: 1.0482 - val_accuracy: 0.7335\n","Epoch 85/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4351 - accuracy: 0.9331 - val_loss: 1.0914 - val_accuracy: 0.7521\n","Epoch 86/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4584 - accuracy: 0.9300 - val_loss: 1.0713 - val_accuracy: 0.7304\n","Epoch 87/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4229 - accuracy: 0.9447 - val_loss: 1.1817 - val_accuracy: 0.7004\n","Epoch 88/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4349 - accuracy: 0.9359 - val_loss: 1.1243 - val_accuracy: 0.7345\n","Epoch 89/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4147 - accuracy: 0.9450 - val_loss: 1.0948 - val_accuracy: 0.7273\n","Epoch 90/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4113 - accuracy: 0.9473 - val_loss: 1.1127 - val_accuracy: 0.7293\n","Epoch 91/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4123 - accuracy: 0.9475 - val_loss: 1.0803 - val_accuracy: 0.7262\n","Epoch 92/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4051 - accuracy: 0.9486 - val_loss: 1.0845 - val_accuracy: 0.7428\n","Epoch 93/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4079 - accuracy: 0.9463 - val_loss: 1.1000 - val_accuracy: 0.7211\n","Epoch 94/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4140 - accuracy: 0.9434 - val_loss: 1.0915 - val_accuracy: 0.7314\n","Epoch 95/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4106 - accuracy: 0.9483 - val_loss: 1.1208 - val_accuracy: 0.7324\n","Epoch 96/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4037 - accuracy: 0.9470 - val_loss: 1.1257 - val_accuracy: 0.7304\n","Epoch 97/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4048 - accuracy: 0.9486 - val_loss: 1.1073 - val_accuracy: 0.7169\n","Epoch 98/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4026 - accuracy: 0.9501 - val_loss: 1.1264 - val_accuracy: 0.7159\n","Epoch 99/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4026 - accuracy: 0.9512 - val_loss: 1.0841 - val_accuracy: 0.7376\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4079 - accuracy: 0.9457 - val_loss: 1.1697 - val_accuracy: 0.7138\n","{'loss': [0.5577036142349243, 0.5386242866516113, 0.5370412468910217, 0.5301477313041687, 0.524319589138031, 0.514643132686615, 0.5257008075714111, 0.5510998368263245, 0.527380108833313, 0.5164991617202759, 0.5090611577033997, 0.5013566017150879, 0.49990642070770264, 0.4986070394515991, 0.49491262435913086, 0.49649280309677124, 0.4977652430534363, 0.5071737766265869, 0.5029467344284058, 0.4919804334640503, 0.48722758889198303, 0.48421913385391235, 0.4852827191352844, 0.48421552777290344, 0.49048665165901184, 0.4801880717277527, 0.48197832703590393, 0.5077645182609558, 0.47756004333496094, 0.4710102677345276, 0.4714887738227844, 0.4736059904098511, 0.46861132979393005, 0.46883267164230347, 0.4751603603363037, 0.4669933021068573, 0.4671391546726227, 0.4664060175418854, 0.460813969373703, 0.4604508876800537, 0.46210402250289917, 0.45851391553878784, 0.45741739869117737, 0.4536729156970978, 0.454670786857605, 0.454130083322525, 0.459970623254776, 0.45333170890808105, 0.44839417934417725, 0.4456128776073456, 0.4430399537086487, 0.43843162059783936, 0.44387972354888916, 0.44651922583580017, 0.4486541748046875, 0.4603448212146759, 0.4675622582435608, 0.47421422600746155, 0.5564850568771362, 0.4920352101325989, 0.4603569805622101, 0.4564293920993805, 0.4458251893520355, 0.43852660059928894, 0.4298116862773895, 0.43291234970092773, 0.4303220808506012, 0.4264148473739624, 0.43064215779304504, 0.42796191573143005, 0.42647334933280945, 0.4243380129337311, 0.4262143671512604, 0.42188116908073425, 0.42041003704071045, 0.4246733486652374, 0.42440077662467957, 0.4186442494392395, 0.41969653964042664, 0.4197022318840027, 0.41796159744262695, 0.4162209630012512, 0.4135485291481018, 0.4128287732601166, 0.4351364076137543, 0.4583524167537689, 0.42292752861976624, 0.4349069595336914, 0.41467738151550293, 0.41125890612602234, 0.4123344421386719, 0.40510210394859314, 0.40792515873908997, 0.41397011280059814, 0.41061556339263916, 0.40367603302001953, 0.4047725200653076, 0.40259724855422974, 0.4025632441043854, 0.4078676700592041], 'accuracy': [0.8912144899368286, 0.896124005317688, 0.8992248177528381, 0.9007751941680908, 0.9064599275588989, 0.9080103635787964, 0.8992248177528381, 0.8935400247573853, 0.8974159955978394, 0.9033591747283936, 0.9139534831047058, 0.9180878400802612, 0.9180878400802612, 0.9183462262153625, 0.9204134345054626, 0.9170542359352112, 0.9147287011146545, 0.905684769153595, 0.9149870872497559, 0.9196382164955139, 0.9214470386505127, 0.9224806427955627, 0.9219638109207153, 0.9224806427955627, 0.9204134345054626, 0.9273901581764221, 0.9204134345054626, 0.9015504121780396, 0.9237726330757141, 0.933074951171875, 0.9273901581764221, 0.9271317720413208, 0.930232584476471, 0.9281653761863708, 0.923514187335968, 0.9268733859062195, 0.930232584476471, 0.9297157526016235, 0.9279069900512695, 0.9322997331619263, 0.9294573664665222, 0.9317829608917236, 0.932041347026825, 0.9335917234420776, 0.9361757040023804, 0.9333333373069763, 0.9294573664665222, 0.9328165650367737, 0.9343669414520264, 0.9382429122924805, 0.9374676942825317, 0.9410852789878845, 0.9390180706977844, 0.9322997331619263, 0.935917317867279, 0.9297157526016235, 0.9250646233558655, 0.9193798303604126, 0.8940568566322327, 0.9147287011146545, 0.9297157526016235, 0.9377260804176331, 0.9379844665527344, 0.9390180706977844, 0.9405684471130371, 0.9428940415382385, 0.9426356554031372, 0.9413436651229858, 0.9374676942825317, 0.9385012984275818, 0.9397932887077332, 0.9441860318183899, 0.9426356554031372, 0.9410852789878845, 0.9434108734130859, 0.9416020512580872, 0.9418604373931885, 0.9421188831329346, 0.9457364082336426, 0.9421188831329346, 0.9428940415382385, 0.9447028636932373, 0.9457364082336426, 0.9459948539733887, 0.933074951171875, 0.9299741387367249, 0.9447028636932373, 0.935917317867279, 0.9449612498283386, 0.94728684425354, 0.9475452303886414, 0.9485788345336914, 0.94625324010849, 0.9434108734130859, 0.9483203887939453, 0.947028398513794, 0.9485788345336914, 0.9501292109489441, 0.9511628150939941, 0.9457364082336426], 'val_loss': [1.0160243511199951, 0.9647130966186523, 0.9533103108406067, 0.9387716054916382, 0.9290680885314941, 0.926483154296875, 0.9431260824203491, 0.8989342451095581, 0.9251842498779297, 0.9165021777153015, 0.8947626352310181, 0.9009641408920288, 0.8545967936515808, 0.8454144597053528, 0.8503388166427612, 0.8797207474708557, 0.8604579567909241, 0.9306474328041077, 0.8687950372695923, 0.8735711574554443, 0.8633543848991394, 0.8961610198020935, 0.8870967030525208, 0.9020001888275146, 0.9114904403686523, 0.9278379082679749, 1.0427045822143555, 0.9271708726882935, 0.9384796619415283, 0.9349932670593262, 0.9571241140365601, 0.9446451663970947, 0.972845196723938, 0.9498281478881836, 0.9505256414413452, 0.9640783667564392, 0.958128809928894, 0.9843332767486572, 0.9922153353691101, 1.0037490129470825, 0.9877954125404358, 0.9977173805236816, 0.9853404760360718, 0.9945685267448425, 1.0301480293273926, 0.9760681390762329, 1.0074750185012817, 0.9946427345275879, 0.9968758821487427, 1.0001661777496338, 1.0091811418533325, 1.0010771751403809, 0.9949986338615417, 1.0162652730941772, 1.0087127685546875, 1.1139272451400757, 1.1154253482818604, 1.29714035987854, 1.0767560005187988, 1.1401910781860352, 1.0708194971084595, 1.1420314311981201, 0.9999358654022217, 0.9976994395256042, 1.0065940618515015, 0.9968748092651367, 1.033860206604004, 1.0111839771270752, 1.008484125137329, 1.0165882110595703, 1.0852605104446411, 1.0225598812103271, 1.023633599281311, 1.058220624923706, 1.1028403043746948, 1.034867286682129, 1.0536168813705444, 1.059188723564148, 1.0467458963394165, 1.0533909797668457, 1.0525346994400024, 1.0592116117477417, 1.047149419784546, 1.0481631755828857, 1.091371774673462, 1.0713157653808594, 1.181721568107605, 1.1242806911468506, 1.0947916507720947, 1.1126646995544434, 1.0802948474884033, 1.0844825506210327, 1.100019097328186, 1.0915071964263916, 1.1207802295684814, 1.1257319450378418, 1.1072505712509155, 1.126368522644043, 1.0840669870376587, 1.169714331626892], 'val_accuracy': [0.5650826692581177, 0.5960744023323059, 0.6002066135406494, 0.6219007968902588, 0.6260330677032471, 0.6518595218658447, 0.6539255976676941, 0.6704545617103577, 0.6477272510528564, 0.6539255976676941, 0.6694214940071106, 0.672520637512207, 0.7179751992225647, 0.7200413346290588, 0.7241735458374023, 0.7128099203109741, 0.7293388247489929, 0.6787189841270447, 0.7345041036605835, 0.7200413346290588, 0.7314049601554871, 0.7355371713638306, 0.7407024502754211, 0.7541322112083435, 0.7438016533851624, 0.7407024502754211, 0.7138429880142212, 0.7623966932296753, 0.7479338645935059, 0.7551652789115906, 0.7530992031097412, 0.7510330677032471, 0.7541322112083435, 0.7592975497245789, 0.7510330677032471, 0.7438016533851624, 0.7520661354064941, 0.7365702390670776, 0.7221074104309082, 0.7355371713638306, 0.73037189245224, 0.7355371713638306, 0.7541322112083435, 0.7396694421768188, 0.7386363744735718, 0.7355371713638306, 0.7427685856819153, 0.73037189245224, 0.7417355179786682, 0.7386363744735718, 0.7458677887916565, 0.7407024502754211, 0.7365702390670776, 0.7489669322967529, 0.7396694421768188, 0.7283057570457458, 0.7004132270812988, 0.7086777091026306, 0.7438016533851624, 0.73037189245224, 0.73037189245224, 0.711776852607727, 0.7469007968902588, 0.7376033067703247, 0.7396694421768188, 0.7417355179786682, 0.7262396812438965, 0.7438016533851624, 0.7448347210884094, 0.7489669322967529, 0.7252066135406494, 0.7334710955619812, 0.7427685856819153, 0.7355371713638306, 0.7262396812438965, 0.7438016533851624, 0.7479338645935059, 0.7252066135406494, 0.7324380278587341, 0.7355371713638306, 0.7396694421768188, 0.7438016533851624, 0.7334710955619812, 0.7334710955619812, 0.7520661354064941, 0.73037189245224, 0.7004132270812988, 0.7345041036605835, 0.7272727489471436, 0.7293388247489929, 0.7262396812438965, 0.7427685856819153, 0.7210744023323059, 0.7314049601554871, 0.7324380278587341, 0.73037189245224, 0.7169421315193176, 0.7159090638160706, 0.7376033067703247, 0.7138429880142212]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 28ms/step - loss: 0.4735 - accuracy: 0.9219 - val_loss: 0.9797 - val_accuracy: 0.5916\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.4391 - accuracy: 0.9297"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 12ms/step - loss: 0.4418 - accuracy: 0.9232 - val_loss: 0.9606 - val_accuracy: 0.5797\n","Epoch 3/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4286 - accuracy: 0.9362 - val_loss: 0.9405 - val_accuracy: 0.5981\n","Epoch 4/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4209 - accuracy: 0.9405 - val_loss: 0.9466 - val_accuracy: 0.6034\n","Epoch 5/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4172 - accuracy: 0.9421 - val_loss: 0.9503 - val_accuracy: 0.6088\n","Epoch 6/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4109 - accuracy: 0.9442 - val_loss: 0.9525 - val_accuracy: 0.6325\n","Epoch 7/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4241 - accuracy: 0.9407 - val_loss: 0.9248 - val_accuracy: 0.6239\n","Epoch 8/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4192 - accuracy: 0.9383 - val_loss: 0.9882 - val_accuracy: 0.6218\n","Epoch 9/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4114 - accuracy: 0.9434 - val_loss: 0.9561 - val_accuracy: 0.6422\n","Epoch 10/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4050 - accuracy: 0.9456 - val_loss: 0.9312 - val_accuracy: 0.6401\n","Epoch 11/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4004 - accuracy: 0.9512 - val_loss: 0.9284 - val_accuracy: 0.6595\n","Epoch 12/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3996 - accuracy: 0.9512 - val_loss: 0.9319 - val_accuracy: 0.6595\n","Epoch 13/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3954 - accuracy: 0.9545 - val_loss: 0.9312 - val_accuracy: 0.6638\n","Epoch 14/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3963 - accuracy: 0.9550 - val_loss: 0.8818 - val_accuracy: 0.6961\n","Epoch 15/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3935 - accuracy: 0.9545 - val_loss: 0.8643 - val_accuracy: 0.7123\n","Epoch 16/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3969 - accuracy: 0.9518 - val_loss: 0.8890 - val_accuracy: 0.7015\n","Epoch 17/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3941 - accuracy: 0.9523 - val_loss: 0.7961 - val_accuracy: 0.7565\n","Epoch 18/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3912 - accuracy: 0.9531 - val_loss: 0.8275 - val_accuracy: 0.7522\n","Epoch 19/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3904 - accuracy: 0.9550 - val_loss: 0.7912 - val_accuracy: 0.7866\n","Epoch 20/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3944 - accuracy: 0.9515 - val_loss: 0.8309 - val_accuracy: 0.7737\n","Epoch 21/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3873 - accuracy: 0.9537 - val_loss: 0.8783 - val_accuracy: 0.7500\n","Epoch 22/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3886 - accuracy: 0.9561 - val_loss: 0.8890 - val_accuracy: 0.7554\n","Epoch 23/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3873 - accuracy: 0.9564 - val_loss: 0.7918 - val_accuracy: 0.8050\n","Epoch 24/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3927 - accuracy: 0.9512 - val_loss: 0.8274 - val_accuracy: 0.7899\n","Epoch 25/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3827 - accuracy: 0.9566 - val_loss: 0.8235 - val_accuracy: 0.8093\n","Epoch 26/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3814 - accuracy: 0.9572 - val_loss: 0.8176 - val_accuracy: 0.8093\n","Epoch 27/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3808 - accuracy: 0.9593 - val_loss: 0.8438 - val_accuracy: 0.8082\n","Epoch 28/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3793 - accuracy: 0.9591 - val_loss: 0.8472 - val_accuracy: 0.8028\n","Epoch 29/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4201 - accuracy: 0.9429 - val_loss: 0.9795 - val_accuracy: 0.7619\n","Epoch 30/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4097 - accuracy: 0.9453 - val_loss: 0.8494 - val_accuracy: 0.8211\n","Epoch 31/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3968 - accuracy: 0.9550 - val_loss: 0.8915 - val_accuracy: 0.8147\n","Epoch 32/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3812 - accuracy: 0.9588 - val_loss: 0.8564 - val_accuracy: 0.8093\n","Epoch 33/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3764 - accuracy: 0.9588 - val_loss: 0.8672 - val_accuracy: 0.8103\n","Epoch 34/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3790 - accuracy: 0.9572 - val_loss: 0.8914 - val_accuracy: 0.8006\n","Epoch 35/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3824 - accuracy: 0.9534 - val_loss: 0.8609 - val_accuracy: 0.8168\n","Epoch 36/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4084 - accuracy: 0.9421 - val_loss: 1.0298 - val_accuracy: 0.7586\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3981 - accuracy: 0.9515 - val_loss: 0.8975 - val_accuracy: 0.8125\n","Epoch 38/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3734 - accuracy: 0.9577 - val_loss: 0.8832 - val_accuracy: 0.8147\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3717 - accuracy: 0.9591 - val_loss: 0.9022 - val_accuracy: 0.7996\n","Epoch 40/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3791 - accuracy: 0.9577 - val_loss: 0.8788 - val_accuracy: 0.8168\n","Epoch 41/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3859 - accuracy: 0.9496 - val_loss: 0.9030 - val_accuracy: 0.8039\n","Epoch 42/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3680 - accuracy: 0.9591 - val_loss: 0.8903 - val_accuracy: 0.8136\n","Epoch 43/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3676 - accuracy: 0.9623 - val_loss: 0.9372 - val_accuracy: 0.7888\n","Epoch 44/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3721 - accuracy: 0.9596 - val_loss: 0.8972 - val_accuracy: 0.8103\n","Epoch 45/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3671 - accuracy: 0.9601 - val_loss: 0.8965 - val_accuracy: 0.8060\n","Epoch 46/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3656 - accuracy: 0.9615 - val_loss: 0.8911 - val_accuracy: 0.8125\n","Epoch 47/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3684 - accuracy: 0.9596 - val_loss: 0.9077 - val_accuracy: 0.8028\n","Epoch 48/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3685 - accuracy: 0.9599 - val_loss: 0.9021 - val_accuracy: 0.8071\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3680 - accuracy: 0.9582 - val_loss: 0.9859 - val_accuracy: 0.7683\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3660 - accuracy: 0.9628 - val_loss: 0.8965 - val_accuracy: 0.8168\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3650 - accuracy: 0.9604 - val_loss: 0.8946 - val_accuracy: 0.8136\n","Epoch 52/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3635 - accuracy: 0.9615 - val_loss: 0.9173 - val_accuracy: 0.7942\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3647 - accuracy: 0.9647 - val_loss: 0.9019 - val_accuracy: 0.8082\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3639 - accuracy: 0.9609 - val_loss: 0.9075 - val_accuracy: 0.8071\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3627 - accuracy: 0.9617 - val_loss: 0.9154 - val_accuracy: 0.8060\n","Epoch 56/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3593 - accuracy: 0.9644 - val_loss: 0.9063 - val_accuracy: 0.8093\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3602 - accuracy: 0.9636 - val_loss: 0.9343 - val_accuracy: 0.8028\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4584 - accuracy: 0.9399 - val_loss: 1.0500 - val_accuracy: 0.7823\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4276 - accuracy: 0.9539 - val_loss: 0.9582 - val_accuracy: 0.7931\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4050 - accuracy: 0.9440 - val_loss: 1.0316 - val_accuracy: 0.7877\n","Epoch 61/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4239 - accuracy: 0.9464 - val_loss: 0.9766 - val_accuracy: 0.7759\n","Epoch 62/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3669 - accuracy: 0.9569 - val_loss: 1.0029 - val_accuracy: 0.7694\n","Epoch 63/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3560 - accuracy: 0.9674 - val_loss: 0.9569 - val_accuracy: 0.7942\n","Epoch 64/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3556 - accuracy: 0.9652 - val_loss: 0.9356 - val_accuracy: 0.7963\n","Epoch 65/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3570 - accuracy: 0.9652 - val_loss: 0.9249 - val_accuracy: 0.8039\n","Epoch 66/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3550 - accuracy: 0.9652 - val_loss: 0.9198 - val_accuracy: 0.8103\n","Epoch 67/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3542 - accuracy: 0.9642 - val_loss: 0.9301 - val_accuracy: 0.8060\n","Epoch 68/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3533 - accuracy: 0.9663 - val_loss: 0.9199 - val_accuracy: 0.8093\n","Epoch 69/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3520 - accuracy: 0.9682 - val_loss: 0.9367 - val_accuracy: 0.7899\n","Epoch 70/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3523 - accuracy: 0.9693 - val_loss: 0.9348 - val_accuracy: 0.7899\n","Epoch 71/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3658 - accuracy: 0.9550 - val_loss: 1.0018 - val_accuracy: 0.7769\n","Epoch 72/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3550 - accuracy: 0.9636 - val_loss: 0.9596 - val_accuracy: 0.7931\n","Epoch 73/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3490 - accuracy: 0.9677 - val_loss: 0.9320 - val_accuracy: 0.8028\n","Epoch 74/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3499 - accuracy: 0.9693 - val_loss: 0.9451 - val_accuracy: 0.7996\n","Epoch 75/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3544 - accuracy: 0.9669 - val_loss: 0.9660 - val_accuracy: 0.7866\n","Epoch 76/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3482 - accuracy: 0.9666 - val_loss: 0.9310 - val_accuracy: 0.8082\n","Epoch 77/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3479 - accuracy: 0.9631 - val_loss: 0.9839 - val_accuracy: 0.7812\n","Epoch 78/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3472 - accuracy: 0.9644 - val_loss: 0.9687 - val_accuracy: 0.7963\n","Epoch 79/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3480 - accuracy: 0.9682 - val_loss: 0.9529 - val_accuracy: 0.8017\n","Epoch 80/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3459 - accuracy: 0.9661 - val_loss: 0.9694 - val_accuracy: 0.7888\n","Epoch 81/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3553 - accuracy: 0.9599 - val_loss: 0.9671 - val_accuracy: 0.8050\n","Epoch 82/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3441 - accuracy: 0.9693 - val_loss: 0.9565 - val_accuracy: 0.7909\n","Epoch 83/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3415 - accuracy: 0.9712 - val_loss: 0.9458 - val_accuracy: 0.8082\n","Epoch 84/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3441 - accuracy: 0.9701 - val_loss: 0.9555 - val_accuracy: 0.7953\n","Epoch 85/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3439 - accuracy: 0.9685 - val_loss: 0.9712 - val_accuracy: 0.7834\n","Epoch 86/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3412 - accuracy: 0.9714 - val_loss: 0.9616 - val_accuracy: 0.8060\n","Epoch 87/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3434 - accuracy: 0.9682 - val_loss: 0.9830 - val_accuracy: 0.7877\n","Epoch 88/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3436 - accuracy: 0.9671 - val_loss: 0.9643 - val_accuracy: 0.8039\n","Epoch 89/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3405 - accuracy: 0.9712 - val_loss: 0.9672 - val_accuracy: 0.8006\n","Epoch 90/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3442 - accuracy: 0.9647 - val_loss: 0.9696 - val_accuracy: 0.7974\n","Epoch 91/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3406 - accuracy: 0.9696 - val_loss: 0.9724 - val_accuracy: 0.8028\n","Epoch 92/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3401 - accuracy: 0.9690 - val_loss: 1.0626 - val_accuracy: 0.7672\n","Epoch 93/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3407 - accuracy: 0.9706 - val_loss: 1.0067 - val_accuracy: 0.7866\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3406 - accuracy: 0.9685 - val_loss: 1.0060 - val_accuracy: 0.7791\n","Epoch 95/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3439 - accuracy: 0.9696 - val_loss: 1.0222 - val_accuracy: 0.7866\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3377 - accuracy: 0.9744 - val_loss: 0.9978 - val_accuracy: 0.7931\n","Epoch 97/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3391 - accuracy: 0.9701 - val_loss: 0.9984 - val_accuracy: 0.7953\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3367 - accuracy: 0.9723 - val_loss: 1.0313 - val_accuracy: 0.7845\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3327 - accuracy: 0.9723 - val_loss: 1.0048 - val_accuracy: 0.7953\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3338 - accuracy: 0.9725 - val_loss: 1.0020 - val_accuracy: 0.7985\n","{'loss': [0.47346794605255127, 0.4417564272880554, 0.42860791087150574, 0.4208931028842926, 0.41720592975616455, 0.410907506942749, 0.4241158366203308, 0.4191516935825348, 0.4113960862159729, 0.4050233066082001, 0.40044593811035156, 0.3996288478374481, 0.39538541436195374, 0.39627212285995483, 0.39351266622543335, 0.39686957001686096, 0.3940863013267517, 0.39122217893600464, 0.3903709650039673, 0.39443132281303406, 0.3873356878757477, 0.38864365220069885, 0.38729071617126465, 0.39274969696998596, 0.3826947808265686, 0.3813927471637726, 0.3808080554008484, 0.37927669286727905, 0.42014533281326294, 0.4097212851047516, 0.39677122235298157, 0.38123971223831177, 0.3764464855194092, 0.378950297832489, 0.3823602497577667, 0.40844374895095825, 0.3980958163738251, 0.37342050671577454, 0.3717118501663208, 0.37906333804130554, 0.3859204947948456, 0.36801719665527344, 0.3676483631134033, 0.37214604020118713, 0.3671225309371948, 0.36558958888053894, 0.3684476315975189, 0.36846932768821716, 0.3680132031440735, 0.36603114008903503, 0.3650052845478058, 0.3634917140007019, 0.36473140120506287, 0.3639122247695923, 0.3626917898654938, 0.35929200053215027, 0.36020493507385254, 0.4583889842033386, 0.4275505542755127, 0.404975950717926, 0.4238724112510681, 0.3669334053993225, 0.35597461462020874, 0.3555869162082672, 0.3569812774658203, 0.3549671173095703, 0.3542177379131317, 0.3532792329788208, 0.3520301878452301, 0.3522702157497406, 0.365825355052948, 0.35502365231513977, 0.3490244746208191, 0.3498893082141876, 0.35438042879104614, 0.3482016324996948, 0.3479408323764801, 0.3471739888191223, 0.34800776839256287, 0.34585660696029663, 0.355308473110199, 0.34407562017440796, 0.3414614498615265, 0.3440970778465271, 0.3438999056816101, 0.3412160873413086, 0.3433944880962372, 0.3436281979084015, 0.34050312638282776, 0.3442226052284241, 0.3406383991241455, 0.34008538722991943, 0.34072354435920715, 0.34059059619903564, 0.3438752293586731, 0.33772051334381104, 0.3391425311565399, 0.3367408514022827, 0.3327481746673584, 0.33377715945243835], 'accuracy': [0.921875, 0.923222005367279, 0.936152994632721, 0.9404633641242981, 0.9420797228813171, 0.9442349076271057, 0.9407327771186829, 0.9383081793785095, 0.9434267282485962, 0.9455819129943848, 0.9512392282485962, 0.9512392282485962, 0.954472005367279, 0.9550107717514038, 0.954472005367279, 0.951777994632721, 0.9523168206214905, 0.953125, 0.9550107717514038, 0.951508641242981, 0.9536637663841248, 0.9560883641242981, 0.9563577771186829, 0.9512392282485962, 0.9566271305084229, 0.9571659564971924, 0.959321141242981, 0.9590517282485962, 0.9428879022598267, 0.9453125, 0.9550107717514038, 0.9587823152542114, 0.9587823152542114, 0.9571659564971924, 0.9533944129943848, 0.9420797228813171, 0.951508641242981, 0.9577047228813171, 0.9590517282485962, 0.9577047228813171, 0.9496228694915771, 0.9590517282485962, 0.962284505367279, 0.959590494632721, 0.9601293206214905, 0.9614762663841248, 0.959590494632721, 0.9598599076271057, 0.9582435488700867, 0.9628232717514038, 0.9603987336158752, 0.9614762663841248, 0.9647090435028076, 0.9609375, 0.9617456793785095, 0.9644396305084229, 0.9636314511299133, 0.9399245977401733, 0.9539331793785095, 0.943965494632721, 0.9463900923728943, 0.9568965435028076, 0.967402994632721, 0.9652478694915771, 0.9652478694915771, 0.9652478694915771, 0.9641702771186829, 0.9663254022598267, 0.9682112336158752, 0.9692887663841248, 0.9550107717514038, 0.9636314511299133, 0.9676724076271057, 0.9692887663841248, 0.9668642282485962, 0.9665948152542114, 0.9630926847457886, 0.9644396305084229, 0.9682112336158752, 0.9660560488700867, 0.9598599076271057, 0.9692887663841248, 0.9711745977401733, 0.970097005367279, 0.9684805870056152, 0.9714439511299133, 0.9682112336158752, 0.967133641242981, 0.9711745977401733, 0.9647090435028076, 0.9695581793785095, 0.9690194129943848, 0.9706357717514038, 0.9684805870056152, 0.9695581793785095, 0.9744073152542114, 0.970097005367279, 0.9722521305084229, 0.9722521305084229, 0.9725215435028076], 'val_loss': [0.9796921014785767, 0.9606356620788574, 0.9405039548873901, 0.9465563297271729, 0.9503185749053955, 0.9524770975112915, 0.9247890114784241, 0.9881631731987, 0.9561087489128113, 0.9311782717704773, 0.9283863306045532, 0.9319183230400085, 0.9311661720275879, 0.8818067312240601, 0.8643491268157959, 0.8890311121940613, 0.7961111664772034, 0.827515721321106, 0.7911902070045471, 0.8308639526367188, 0.8782657384872437, 0.8889502286911011, 0.7918192744255066, 0.8273513913154602, 0.8234966397285461, 0.8175621032714844, 0.843766450881958, 0.8472095131874084, 0.9795157313346863, 0.8494085669517517, 0.891470730304718, 0.8563671112060547, 0.8672279715538025, 0.8913591504096985, 0.8609378337860107, 1.0298444032669067, 0.8974603414535522, 0.88320392370224, 0.902167022228241, 0.8787605166435242, 0.9030023217201233, 0.8903159499168396, 0.9372094869613647, 0.8971799612045288, 0.8965008854866028, 0.8910772204399109, 0.9077451229095459, 0.9020565152168274, 0.9858739972114563, 0.8965104222297668, 0.8946151733398438, 0.9172896146774292, 0.9018763899803162, 0.9075295925140381, 0.9153741002082825, 0.9062575697898865, 0.9343317151069641, 1.0500129461288452, 0.9581745862960815, 1.031615138053894, 0.9766431450843811, 1.0029091835021973, 0.9569332003593445, 0.9356112480163574, 0.9248713254928589, 0.9197585582733154, 0.9300747513771057, 0.9198597073554993, 0.9367438554763794, 0.9347590208053589, 1.0017749071121216, 0.9595765471458435, 0.9320425391197205, 0.9451414942741394, 0.9660138487815857, 0.9310249090194702, 0.9838840365409851, 0.9686771035194397, 0.9528859257698059, 0.9693571925163269, 0.9671160578727722, 0.9564553499221802, 0.9458138942718506, 0.9555002450942993, 0.9711899161338806, 0.9615548253059387, 0.9829699993133545, 0.9643428325653076, 0.9671595096588135, 0.9696130156517029, 0.9723571538925171, 1.0626275539398193, 1.0067477226257324, 1.0060486793518066, 1.022177815437317, 0.9977526664733887, 0.9984370470046997, 1.031333565711975, 1.0048010349273682, 1.0020055770874023], 'val_accuracy': [0.5915948152542114, 0.579741358757019, 0.5980603694915771, 0.6034482717514038, 0.6088362336158752, 0.6325430870056152, 0.6239224076271057, 0.6217672228813171, 0.642241358757019, 0.6400862336158752, 0.6594827771186829, 0.6594827771186829, 0.6637930870056152, 0.6961206793785095, 0.712284505367279, 0.701508641242981, 0.756465494632721, 0.7521551847457886, 0.7866379022598267, 0.7737069129943848, 0.75, 0.7553879022598267, 0.8049569129943848, 0.7898706793785095, 0.8092672228813171, 0.8092672228813171, 0.8081896305084229, 0.8028017282485962, 0.7618534564971924, 0.8211206793785095, 0.8146551847457886, 0.8092672228813171, 0.8103448152542114, 0.8006465435028076, 0.8168103694915771, 0.7586206793785095, 0.8125, 0.8146551847457886, 0.7995689511299133, 0.8168103694915771, 0.8038793206214905, 0.8135775923728943, 0.7887930870056152, 0.8103448152542114, 0.806034505367279, 0.8125, 0.8028017282485962, 0.8071120977401733, 0.7683189511299133, 0.8168103694915771, 0.8135775923728943, 0.7941810488700867, 0.8081896305084229, 0.8071120977401733, 0.806034505367279, 0.8092672228813171, 0.8028017282485962, 0.7823275923728943, 0.7931034564971924, 0.787715494632721, 0.7758620977401733, 0.7693965435028076, 0.7941810488700867, 0.7963362336158752, 0.8038793206214905, 0.8103448152542114, 0.806034505367279, 0.8092672228813171, 0.7898706793785095, 0.7898706793785095, 0.7769396305084229, 0.7931034564971924, 0.8028017282485962, 0.7995689511299133, 0.7866379022598267, 0.8081896305084229, 0.78125, 0.7963362336158752, 0.8017241358757019, 0.7887930870056152, 0.8049569129943848, 0.7909482717514038, 0.8081896305084229, 0.795258641242981, 0.7834051847457886, 0.806034505367279, 0.787715494632721, 0.8038793206214905, 0.8006465435028076, 0.7974137663841248, 0.8028017282485962, 0.767241358757019, 0.7866379022598267, 0.7790948152542114, 0.7866379022598267, 0.7931034564971924, 0.795258641242981, 0.7844827771186829, 0.795258641242981, 0.798491358757019]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 3s 30ms/step - loss: 0.4624 - accuracy: 0.9205 - val_loss: 0.9296 - val_accuracy: 0.6188\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.3954 - accuracy: 0.9453"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 12ms/step - loss: 0.4429 - accuracy: 0.9270 - val_loss: 0.9430 - val_accuracy: 0.6109\n","Epoch 3/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4276 - accuracy: 0.9392 - val_loss: 0.9319 - val_accuracy: 0.6256\n","Epoch 4/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4328 - accuracy: 0.9366 - val_loss: 0.9241 - val_accuracy: 0.6301\n","Epoch 5/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4223 - accuracy: 0.9411 - val_loss: 0.9182 - val_accuracy: 0.6267\n","Epoch 6/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4177 - accuracy: 0.9423 - val_loss: 0.9195 - val_accuracy: 0.6278\n","Epoch 7/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4221 - accuracy: 0.9383 - val_loss: 0.9541 - val_accuracy: 0.6244\n","Epoch 8/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4177 - accuracy: 0.9457 - val_loss: 0.9482 - val_accuracy: 0.6290\n","Epoch 9/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4075 - accuracy: 0.9457 - val_loss: 0.9722 - val_accuracy: 0.6244\n","Epoch 10/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4112 - accuracy: 0.9420 - val_loss: 0.9783 - val_accuracy: 0.6448\n","Epoch 11/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4224 - accuracy: 0.9411 - val_loss: 0.9235 - val_accuracy: 0.6538\n","Epoch 12/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4176 - accuracy: 0.9394 - val_loss: 0.9957 - val_accuracy: 0.6176\n","Epoch 13/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4171 - accuracy: 0.9437 - val_loss: 0.9642 - val_accuracy: 0.6403\n","Epoch 14/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4158 - accuracy: 0.9474 - val_loss: 0.8975 - val_accuracy: 0.6618\n","Epoch 15/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4079 - accuracy: 0.9493 - val_loss: 0.9776 - val_accuracy: 0.6063\n","Epoch 16/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4174 - accuracy: 0.9414 - val_loss: 0.8559 - val_accuracy: 0.6957\n","Epoch 17/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4056 - accuracy: 0.9482 - val_loss: 0.8221 - val_accuracy: 0.7364\n","Epoch 18/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3977 - accuracy: 0.9505 - val_loss: 0.8049 - val_accuracy: 0.7466\n","Epoch 19/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3984 - accuracy: 0.9513 - val_loss: 0.8637 - val_accuracy: 0.6867\n","Epoch 20/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3952 - accuracy: 0.9553 - val_loss: 0.7720 - val_accuracy: 0.7692\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3956 - accuracy: 0.9527 - val_loss: 0.7589 - val_accuracy: 0.7839\n","Epoch 22/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3975 - accuracy: 0.9533 - val_loss: 0.7957 - val_accuracy: 0.7511\n","Epoch 23/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4213 - accuracy: 0.9434 - val_loss: 0.8864 - val_accuracy: 0.7387\n","Epoch 24/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4463 - accuracy: 0.9448 - val_loss: 0.8891 - val_accuracy: 0.7387\n","Epoch 25/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4046 - accuracy: 0.9550 - val_loss: 0.7499 - val_accuracy: 0.8179\n","Epoch 26/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3957 - accuracy: 0.9530 - val_loss: 0.7648 - val_accuracy: 0.8043\n","Epoch 27/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3899 - accuracy: 0.9539 - val_loss: 0.7663 - val_accuracy: 0.8111\n","Epoch 28/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3880 - accuracy: 0.9539 - val_loss: 0.7980 - val_accuracy: 0.7952\n","Epoch 29/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3867 - accuracy: 0.9542 - val_loss: 0.7805 - val_accuracy: 0.8156\n","Epoch 30/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3836 - accuracy: 0.9564 - val_loss: 0.8195 - val_accuracy: 0.8133\n","Epoch 31/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3822 - accuracy: 0.9587 - val_loss: 0.8070 - val_accuracy: 0.8088\n","Epoch 32/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3817 - accuracy: 0.9584 - val_loss: 0.8129 - val_accuracy: 0.8032\n","Epoch 33/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3808 - accuracy: 0.9632 - val_loss: 0.8093 - val_accuracy: 0.8066\n","Epoch 34/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3823 - accuracy: 0.9553 - val_loss: 0.8018 - val_accuracy: 0.8122\n","Epoch 35/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3834 - accuracy: 0.9578 - val_loss: 0.8295 - val_accuracy: 0.8122\n","Epoch 36/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3818 - accuracy: 0.9542 - val_loss: 0.8370 - val_accuracy: 0.8088\n","Epoch 37/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3882 - accuracy: 0.9527 - val_loss: 0.8105 - val_accuracy: 0.8145\n","Epoch 38/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3838 - accuracy: 0.9559 - val_loss: 0.8966 - val_accuracy: 0.7930\n","Epoch 39/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4006 - accuracy: 0.9530 - val_loss: 1.0546 - val_accuracy: 0.7681\n","Epoch 40/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4040 - accuracy: 0.9443 - val_loss: 0.8423 - val_accuracy: 0.7907\n","Epoch 41/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4219 - accuracy: 0.9428 - val_loss: 0.8480 - val_accuracy: 0.7998\n","Epoch 42/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3858 - accuracy: 0.9559 - val_loss: 0.8299 - val_accuracy: 0.8077\n","Epoch 43/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3768 - accuracy: 0.9593 - val_loss: 0.8163 - val_accuracy: 0.8100\n","Epoch 44/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3730 - accuracy: 0.9629 - val_loss: 0.8317 - val_accuracy: 0.8111\n","Epoch 45/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3725 - accuracy: 0.9604 - val_loss: 0.8647 - val_accuracy: 0.7783\n","Epoch 46/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3770 - accuracy: 0.9610 - val_loss: 0.8438 - val_accuracy: 0.8043\n","Epoch 47/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3791 - accuracy: 0.9550 - val_loss: 0.8203 - val_accuracy: 0.8179\n","Epoch 48/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3855 - accuracy: 0.9587 - val_loss: 1.0711 - val_accuracy: 0.7681\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4345 - accuracy: 0.9346 - val_loss: 0.9250 - val_accuracy: 0.7704\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3862 - accuracy: 0.9581 - val_loss: 0.8570 - val_accuracy: 0.8100\n","Epoch 51/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3693 - accuracy: 0.9649 - val_loss: 0.8790 - val_accuracy: 0.8009\n","Epoch 52/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3725 - accuracy: 0.9576 - val_loss: 0.8844 - val_accuracy: 0.7919\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3694 - accuracy: 0.9621 - val_loss: 0.8740 - val_accuracy: 0.7907\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3643 - accuracy: 0.9677 - val_loss: 0.8445 - val_accuracy: 0.8088\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3672 - accuracy: 0.9621 - val_loss: 0.8514 - val_accuracy: 0.8009\n","Epoch 56/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3643 - accuracy: 0.9632 - val_loss: 0.8377 - val_accuracy: 0.8077\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3649 - accuracy: 0.9646 - val_loss: 0.8470 - val_accuracy: 0.8145\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3616 - accuracy: 0.9689 - val_loss: 0.8617 - val_accuracy: 0.7930\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3606 - accuracy: 0.9658 - val_loss: 0.8554 - val_accuracy: 0.8100\n","Epoch 60/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3663 - accuracy: 0.9601 - val_loss: 0.8679 - val_accuracy: 0.8054\n","Epoch 61/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3587 - accuracy: 0.9658 - val_loss: 0.8478 - val_accuracy: 0.8077\n","Epoch 62/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3606 - accuracy: 0.9658 - val_loss: 0.8732 - val_accuracy: 0.8009\n","Epoch 63/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3611 - accuracy: 0.9663 - val_loss: 0.8517 - val_accuracy: 0.8066\n","Epoch 64/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3583 - accuracy: 0.9660 - val_loss: 0.8686 - val_accuracy: 0.8100\n","Epoch 65/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3629 - accuracy: 0.9607 - val_loss: 0.8904 - val_accuracy: 0.7952\n","Epoch 66/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3569 - accuracy: 0.9666 - val_loss: 0.8601 - val_accuracy: 0.7964\n","Epoch 67/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3583 - accuracy: 0.9643 - val_loss: 0.8810 - val_accuracy: 0.8032\n","Epoch 68/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3603 - accuracy: 0.9610 - val_loss: 0.8557 - val_accuracy: 0.8088\n","Epoch 69/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3561 - accuracy: 0.9646 - val_loss: 0.8913 - val_accuracy: 0.8032\n","Epoch 70/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3534 - accuracy: 0.9694 - val_loss: 0.8609 - val_accuracy: 0.8066\n","Epoch 71/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3527 - accuracy: 0.9692 - val_loss: 0.8717 - val_accuracy: 0.8020\n","Epoch 72/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3556 - accuracy: 0.9666 - val_loss: 0.8567 - val_accuracy: 0.8111\n","Epoch 73/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3554 - accuracy: 0.9672 - val_loss: 0.8779 - val_accuracy: 0.7930\n","Epoch 74/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3526 - accuracy: 0.9686 - val_loss: 0.8771 - val_accuracy: 0.7907\n","Epoch 75/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3538 - accuracy: 0.9663 - val_loss: 0.8755 - val_accuracy: 0.8043\n","Epoch 76/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3534 - accuracy: 0.9638 - val_loss: 0.9650 - val_accuracy: 0.7873\n","Epoch 77/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3570 - accuracy: 0.9632 - val_loss: 0.8732 - val_accuracy: 0.8088\n","Epoch 78/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3484 - accuracy: 0.9709 - val_loss: 0.8849 - val_accuracy: 0.7930\n","Epoch 79/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3507 - accuracy: 0.9666 - val_loss: 0.8800 - val_accuracy: 0.8066\n","Epoch 80/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3474 - accuracy: 0.9703 - val_loss: 0.8971 - val_accuracy: 0.7907\n","Epoch 81/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3490 - accuracy: 0.9709 - val_loss: 0.9662 - val_accuracy: 0.7726\n","Epoch 82/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3463 - accuracy: 0.9745 - val_loss: 0.9357 - val_accuracy: 0.7749\n","Epoch 83/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3568 - accuracy: 0.9641 - val_loss: 1.0178 - val_accuracy: 0.7851\n","Epoch 84/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3462 - accuracy: 0.9706 - val_loss: 0.9542 - val_accuracy: 0.7896\n","Epoch 85/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3590 - accuracy: 0.9621 - val_loss: 0.9438 - val_accuracy: 0.7873\n","Epoch 86/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3488 - accuracy: 0.9697 - val_loss: 0.9177 - val_accuracy: 0.7986\n","Epoch 87/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3632 - accuracy: 0.9660 - val_loss: 1.2596 - val_accuracy: 0.7308\n","Epoch 88/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4126 - accuracy: 0.9460 - val_loss: 0.9617 - val_accuracy: 0.7715\n","Epoch 89/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4399 - accuracy: 0.9457 - val_loss: 1.1475 - val_accuracy: 0.7500\n","Epoch 90/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4283 - accuracy: 0.9491 - val_loss: 1.1050 - val_accuracy: 0.7557\n","Epoch 91/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3739 - accuracy: 0.9626 - val_loss: 0.9048 - val_accuracy: 0.7964\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3793 - accuracy: 0.9618 - val_loss: 0.9101 - val_accuracy: 0.7975\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3480 - accuracy: 0.9655 - val_loss: 0.9509 - val_accuracy: 0.7952\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3414 - accuracy: 0.9706 - val_loss: 0.9170 - val_accuracy: 0.7975\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3436 - accuracy: 0.9689 - val_loss: 0.9126 - val_accuracy: 0.7907\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3431 - accuracy: 0.9669 - val_loss: 0.8942 - val_accuracy: 0.8111\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3384 - accuracy: 0.9743 - val_loss: 0.9135 - val_accuracy: 0.7986\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3395 - accuracy: 0.9706 - val_loss: 0.8966 - val_accuracy: 0.8088\n","Epoch 99/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3411 - accuracy: 0.9694 - val_loss: 0.8964 - val_accuracy: 0.8032\n","Epoch 100/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3358 - accuracy: 0.9728 - val_loss: 0.8965 - val_accuracy: 0.8032\n","{'loss': [0.4623824954032898, 0.4429361820220947, 0.4275873005390167, 0.432822585105896, 0.42225080728530884, 0.4177367389202118, 0.4221404790878296, 0.41771361231803894, 0.40752026438713074, 0.4112338125705719, 0.422412246465683, 0.4175909459590912, 0.4170752167701721, 0.4158169627189636, 0.40788403153419495, 0.4174456298351288, 0.405566543340683, 0.39766037464141846, 0.39838430285453796, 0.39517173171043396, 0.39555713534355164, 0.39749959111213684, 0.42128944396972656, 0.44632723927497864, 0.4046395421028137, 0.39571934938430786, 0.38988545536994934, 0.3879626989364624, 0.3866511583328247, 0.38358232378959656, 0.3821714520454407, 0.3817291557788849, 0.38077741861343384, 0.38231655955314636, 0.3834167420864105, 0.38179099559783936, 0.38816094398498535, 0.3837748169898987, 0.4006156623363495, 0.404020756483078, 0.42193329334259033, 0.3858353793621063, 0.3768216669559479, 0.37298715114593506, 0.37251389026641846, 0.3770201504230499, 0.37914392352104187, 0.3854871690273285, 0.4345460534095764, 0.3862382471561432, 0.3693183660507202, 0.37245601415634155, 0.3693811595439911, 0.36425796151161194, 0.36721354722976685, 0.36432433128356934, 0.3649422824382782, 0.36157408356666565, 0.3605673015117645, 0.36626335978507996, 0.3587166666984558, 0.36064571142196655, 0.361121267080307, 0.358308345079422, 0.3628731966018677, 0.3568584620952606, 0.35828882455825806, 0.3602544963359833, 0.3560982942581177, 0.3534136712551117, 0.3527277708053589, 0.35558873414993286, 0.3553640842437744, 0.35259103775024414, 0.35382279753685, 0.3533593714237213, 0.3569604456424713, 0.3483518958091736, 0.3507448434829712, 0.3474437892436981, 0.34900158643722534, 0.3462587594985962, 0.35678616166114807, 0.34624555706977844, 0.35898032784461975, 0.3487528860569, 0.36317554116249084, 0.41256657242774963, 0.4398657977581024, 0.42834725975990295, 0.37385860085487366, 0.37927114963531494, 0.3480055630207062, 0.3414313495159149, 0.34363120794296265, 0.343127578496933, 0.33839136362075806, 0.3394506871700287, 0.3411019444465637, 0.3358380198478699], 'accuracy': [0.9204866886138916, 0.9269949197769165, 0.9391624331474304, 0.9366157054901123, 0.9411431550979614, 0.9422750473022461, 0.9383135437965393, 0.9456706047058105, 0.9456706047058105, 0.9419921040534973, 0.9411431550979614, 0.9394453763961792, 0.9436898827552795, 0.9473684430122375, 0.9493491649627686, 0.941426157951355, 0.9482173323631287, 0.9504810571670532, 0.9513299465179443, 0.9552914500236511, 0.9527447819709778, 0.9533106684684753, 0.943406879901886, 0.9448217153549194, 0.9550085067749023, 0.9530277252197266, 0.9538766145706177, 0.9538766145706177, 0.9541596174240112, 0.9564233422279358, 0.9586870670318604, 0.9584040641784668, 0.9632145166397095, 0.9552914500236511, 0.9578381180763245, 0.9541596174240112, 0.9527447819709778, 0.9558573961257935, 0.9530277252197266, 0.9442558288574219, 0.9428409934043884, 0.9558573961257935, 0.9592529535293579, 0.9629315137863159, 0.9603848457336426, 0.9609507918357849, 0.9550085067749023, 0.9586870670318604, 0.9346349835395813, 0.958121120929718, 0.9649122953414917, 0.9575551748275757, 0.9620826244354248, 0.9677419066429138, 0.9620826244354248, 0.9632145166397095, 0.9646292924880981, 0.9688737988471985, 0.9657611846923828, 0.960101842880249, 0.9657611846923828, 0.9657611846923828, 0.9663271307945251, 0.9660441279411316, 0.9606677889823914, 0.9666100740432739, 0.9643463492393494, 0.9609507918357849, 0.9646292924880981, 0.9694397449493408, 0.9691567420959473, 0.9666100740432739, 0.9671760201454163, 0.9685908555984497, 0.9663271307945251, 0.963780403137207, 0.9632145166397095, 0.9708545804023743, 0.9666100740432739, 0.9702886343002319, 0.9708545804023743, 0.9745330810546875, 0.9640634059906006, 0.9705715775489807, 0.9620826244354248, 0.9697226881980896, 0.9660441279411316, 0.9459536075592041, 0.9456706047058105, 0.9490662217140198, 0.9626485705375671, 0.961799681186676, 0.965478241443634, 0.9705715775489807, 0.9688737988471985, 0.9668930172920227, 0.9742501378059387, 0.9705715775489807, 0.9694397449493408, 0.9728353023529053], 'val_loss': [0.9296137690544128, 0.9430424571037292, 0.9318585395812988, 0.9241355061531067, 0.9181602597236633, 0.919517993927002, 0.9540532231330872, 0.9482492804527283, 0.972199022769928, 0.9782806634902954, 0.923531711101532, 0.9956614375114441, 0.9642113447189331, 0.8974902629852295, 0.9776021838188171, 0.8558607697486877, 0.8220863938331604, 0.8048836588859558, 0.8637482523918152, 0.771966278553009, 0.758866548538208, 0.7956517934799194, 0.8864173293113708, 0.8891268968582153, 0.749901533126831, 0.7648089528083801, 0.7663452625274658, 0.7980220317840576, 0.7804580330848694, 0.8194594979286194, 0.8069733381271362, 0.8128954172134399, 0.8092655539512634, 0.8017865419387817, 0.8294734954833984, 0.8369877934455872, 0.8105010390281677, 0.8966307044029236, 1.0546022653579712, 0.8423402309417725, 0.8479639887809753, 0.8299117088317871, 0.8162963390350342, 0.8316701650619507, 0.8647003769874573, 0.8438121676445007, 0.8203456997871399, 1.071056604385376, 0.9250158071517944, 0.8570400476455688, 0.8790210485458374, 0.8843948841094971, 0.8739792704582214, 0.8445232510566711, 0.851402997970581, 0.8377391695976257, 0.8469961881637573, 0.8616796135902405, 0.8554472923278809, 0.8679413199424744, 0.8478084206581116, 0.8731840252876282, 0.8516574501991272, 0.8686073422431946, 0.8904005289077759, 0.8600854873657227, 0.8810458183288574, 0.8556586503982544, 0.8913277387619019, 0.8608507513999939, 0.8717412352561951, 0.8566956520080566, 0.8778958320617676, 0.8771173357963562, 0.8755436539649963, 0.9650194644927979, 0.8732078671455383, 0.8849154710769653, 0.8799602389335632, 0.897087574005127, 0.9661697745323181, 0.9357497096061707, 1.0178128480911255, 0.9542431235313416, 0.9437930583953857, 0.9176677465438843, 1.2595609426498413, 0.9616912603378296, 1.147486925125122, 1.1049702167510986, 0.904771089553833, 0.910051167011261, 0.9509459733963013, 0.9170217514038086, 0.9125708937644958, 0.8942437767982483, 0.9134700298309326, 0.8965802788734436, 0.896446168422699, 0.8964524865150452], 'val_accuracy': [0.6187782883644104, 0.610859751701355, 0.6255655884742737, 0.6300904750823975, 0.6266968250274658, 0.627828061580658, 0.6244344115257263, 0.6289592981338501, 0.6244344115257263, 0.6447963714599609, 0.6538461446762085, 0.6176470518112183, 0.6402714848518372, 0.6617646813392639, 0.6063348650932312, 0.6957013607025146, 0.7364253401756287, 0.7466063499450684, 0.6866515874862671, 0.7692307829856873, 0.7839366793632507, 0.7511312365531921, 0.7386877536773682, 0.7386877536773682, 0.8178732991218567, 0.8042986392974854, 0.8110859990119934, 0.7952488660812378, 0.8156108856201172, 0.8133484125137329, 0.8088235259056091, 0.8031674027442932, 0.8065611124038696, 0.8122171759605408, 0.8122171759605408, 0.8088235259056091, 0.814479649066925, 0.7929864525794983, 0.7680995464324951, 0.790723979473114, 0.7997737526893616, 0.807692289352417, 0.8099547624588013, 0.8110859990119934, 0.7782805562019348, 0.8042986392974854, 0.8178732991218567, 0.7680995464324951, 0.7703620195388794, 0.8099547624588013, 0.8009049892425537, 0.7918552160263062, 0.790723979473114, 0.8088235259056091, 0.8009049892425537, 0.807692289352417, 0.814479649066925, 0.7929864525794983, 0.8099547624588013, 0.8054298758506775, 0.807692289352417, 0.8009049892425537, 0.8065611124038696, 0.8099547624588013, 0.7952488660812378, 0.7963801026344299, 0.8031674027442932, 0.8088235259056091, 0.8031674027442932, 0.8065611124038696, 0.8020362257957458, 0.8110859990119934, 0.7929864525794983, 0.790723979473114, 0.8042986392974854, 0.7873303294181824, 0.8088235259056091, 0.7929864525794983, 0.8065611124038696, 0.790723979473114, 0.7726244330406189, 0.7748869061470032, 0.7850678563117981, 0.7895927429199219, 0.7873303294181824, 0.7986425161361694, 0.7307692170143127, 0.7714931964874268, 0.75, 0.7556561231613159, 0.7963801026344299, 0.7975113391876221, 0.7952488660812378, 0.7975113391876221, 0.790723979473114, 0.8110859990119934, 0.7986425161361694, 0.8088235259056091, 0.8031674027442932, 0.8031674027442932]}\n","45/45 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 4s 34ms/step - loss: 0.4640 - accuracy: 0.9176 - val_loss: 0.9463 - val_accuracy: 0.6198\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 13ms/step - loss: 0.4654 - accuracy: 0.9204 - val_loss: 0.9373 - val_accuracy: 0.6178\n","Epoch 3/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4413 - accuracy: 0.9307 - val_loss: 0.9513 - val_accuracy: 0.6281\n","Epoch 4/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4412 - accuracy: 0.9310 - val_loss: 0.9432 - val_accuracy: 0.6374\n","Epoch 5/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4353 - accuracy: 0.9302 - val_loss: 0.9592 - val_accuracy: 0.6312\n","Epoch 6/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4399 - accuracy: 0.9274 - val_loss: 0.9099 - val_accuracy: 0.6477\n","Epoch 7/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4377 - accuracy: 0.9315 - val_loss: 0.9367 - val_accuracy: 0.6395\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4318 - accuracy: 0.9367 - val_loss: 0.8974 - val_accuracy: 0.6612\n","Epoch 9/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4576 - accuracy: 0.9227 - val_loss: 0.9623 - val_accuracy: 0.6312\n","Epoch 10/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4373 - accuracy: 0.9318 - val_loss: 0.9844 - val_accuracy: 0.6178\n","Epoch 11/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4265 - accuracy: 0.9375 - val_loss: 0.9726 - val_accuracy: 0.6281\n","Epoch 12/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4236 - accuracy: 0.9375 - val_loss: 0.9043 - val_accuracy: 0.6581\n","Epoch 13/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4191 - accuracy: 0.9398 - val_loss: 0.8760 - val_accuracy: 0.6808\n","Epoch 14/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4165 - accuracy: 0.9444 - val_loss: 0.8787 - val_accuracy: 0.6973\n","Epoch 15/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4186 - accuracy: 0.9432 - val_loss: 0.8708 - val_accuracy: 0.7045\n","Epoch 16/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4182 - accuracy: 0.9426 - val_loss: 0.8919 - val_accuracy: 0.6952\n","Epoch 17/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4107 - accuracy: 0.9442 - val_loss: 0.8056 - val_accuracy: 0.7541\n","Epoch 18/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4352 - accuracy: 0.9326 - val_loss: 0.9173 - val_accuracy: 0.6818\n","Epoch 19/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4097 - accuracy: 0.9468 - val_loss: 0.8926 - val_accuracy: 0.7293\n","Epoch 20/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4180 - accuracy: 0.9382 - val_loss: 0.8973 - val_accuracy: 0.7345\n","Epoch 21/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4719 - accuracy: 0.9302 - val_loss: 0.9891 - val_accuracy: 0.7138\n","Epoch 22/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4138 - accuracy: 0.9429 - val_loss: 0.8455 - val_accuracy: 0.7820\n","Epoch 23/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4066 - accuracy: 0.9486 - val_loss: 0.9291 - val_accuracy: 0.7231\n","Epoch 24/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4075 - accuracy: 0.9432 - val_loss: 0.8797 - val_accuracy: 0.7593\n","Epoch 25/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4065 - accuracy: 0.9452 - val_loss: 0.8846 - val_accuracy: 0.7676\n","Epoch 26/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4055 - accuracy: 0.9444 - val_loss: 0.8583 - val_accuracy: 0.7893\n","Epoch 27/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4149 - accuracy: 0.9434 - val_loss: 0.8801 - val_accuracy: 0.7893\n","Epoch 28/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4002 - accuracy: 0.9506 - val_loss: 0.8866 - val_accuracy: 0.7903\n","Epoch 29/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4039 - accuracy: 0.9481 - val_loss: 0.8985 - val_accuracy: 0.7789\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3995 - accuracy: 0.9473 - val_loss: 0.8903 - val_accuracy: 0.7893\n","Epoch 31/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4011 - accuracy: 0.9447 - val_loss: 0.9028 - val_accuracy: 0.7779\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3987 - accuracy: 0.9494 - val_loss: 1.0007 - val_accuracy: 0.7552\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4028 - accuracy: 0.9447 - val_loss: 0.9312 - val_accuracy: 0.7634\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3967 - accuracy: 0.9491 - val_loss: 0.9561 - val_accuracy: 0.7758\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3984 - accuracy: 0.9506 - val_loss: 0.8987 - val_accuracy: 0.7882\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3923 - accuracy: 0.9537 - val_loss: 0.9494 - val_accuracy: 0.7831\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3995 - accuracy: 0.9509 - val_loss: 0.9182 - val_accuracy: 0.7789\n","Epoch 38/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3982 - accuracy: 0.9504 - val_loss: 0.9597 - val_accuracy: 0.7779\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4029 - accuracy: 0.9437 - val_loss: 0.9421 - val_accuracy: 0.7572\n","Epoch 40/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3894 - accuracy: 0.9553 - val_loss: 0.9476 - val_accuracy: 0.7800\n","Epoch 41/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3872 - accuracy: 0.9530 - val_loss: 0.9492 - val_accuracy: 0.7789\n","Epoch 42/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3946 - accuracy: 0.9463 - val_loss: 0.9428 - val_accuracy: 0.7779\n","Epoch 43/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3969 - accuracy: 0.9494 - val_loss: 0.9744 - val_accuracy: 0.7645\n","Epoch 44/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3924 - accuracy: 0.9501 - val_loss: 0.9650 - val_accuracy: 0.7665\n","Epoch 45/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3871 - accuracy: 0.9548 - val_loss: 1.0233 - val_accuracy: 0.7645\n","Epoch 46/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3936 - accuracy: 0.9475 - val_loss: 0.9528 - val_accuracy: 0.7758\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3949 - accuracy: 0.9491 - val_loss: 1.0470 - val_accuracy: 0.7624\n","Epoch 48/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4009 - accuracy: 0.9558 - val_loss: 1.0321 - val_accuracy: 0.7696\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4435 - accuracy: 0.9315 - val_loss: 0.9925 - val_accuracy: 0.7593\n","Epoch 50/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3989 - accuracy: 0.9465 - val_loss: 0.9648 - val_accuracy: 0.7707\n","Epoch 51/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3945 - accuracy: 0.9465 - val_loss: 0.9946 - val_accuracy: 0.7583\n","Epoch 52/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3840 - accuracy: 0.9556 - val_loss: 1.0418 - val_accuracy: 0.7717\n","Epoch 53/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3922 - accuracy: 0.9470 - val_loss: 0.9907 - val_accuracy: 0.7717\n","Epoch 54/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3849 - accuracy: 0.9504 - val_loss: 0.9988 - val_accuracy: 0.7717\n","Epoch 55/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3816 - accuracy: 0.9535 - val_loss: 0.9580 - val_accuracy: 0.7810\n","Epoch 56/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3826 - accuracy: 0.9532 - val_loss: 0.9591 - val_accuracy: 0.7758\n","Epoch 57/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3786 - accuracy: 0.9563 - val_loss: 0.9686 - val_accuracy: 0.7655\n","Epoch 58/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3774 - accuracy: 0.9581 - val_loss: 0.9675 - val_accuracy: 0.7748\n","Epoch 59/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3788 - accuracy: 0.9543 - val_loss: 0.9651 - val_accuracy: 0.7748\n","Epoch 60/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3820 - accuracy: 0.9527 - val_loss: 1.0858 - val_accuracy: 0.7614\n","Epoch 61/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3764 - accuracy: 0.9558 - val_loss: 0.9687 - val_accuracy: 0.7717\n","Epoch 62/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3741 - accuracy: 0.9568 - val_loss: 0.9638 - val_accuracy: 0.7769\n","Epoch 63/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3702 - accuracy: 0.9592 - val_loss: 0.9748 - val_accuracy: 0.7655\n","Epoch 64/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3723 - accuracy: 0.9563 - val_loss: 1.0557 - val_accuracy: 0.7469\n","Epoch 65/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3820 - accuracy: 0.9504 - val_loss: 0.9697 - val_accuracy: 0.7655\n","Epoch 66/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4105 - accuracy: 0.9432 - val_loss: 1.0332 - val_accuracy: 0.7676\n","Epoch 67/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3868 - accuracy: 0.9517 - val_loss: 1.0585 - val_accuracy: 0.7707\n","Epoch 68/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3922 - accuracy: 0.9501 - val_loss: 1.2660 - val_accuracy: 0.7531\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4787 - accuracy: 0.9276 - val_loss: 1.0569 - val_accuracy: 0.7448\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4168 - accuracy: 0.9483 - val_loss: 1.0257 - val_accuracy: 0.7624\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4068 - accuracy: 0.9475 - val_loss: 1.0871 - val_accuracy: 0.7438\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3874 - accuracy: 0.9556 - val_loss: 0.9852 - val_accuracy: 0.7676\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3849 - accuracy: 0.9589 - val_loss: 0.9824 - val_accuracy: 0.7562\n","Epoch 74/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3803 - accuracy: 0.9537 - val_loss: 1.0224 - val_accuracy: 0.7717\n","Epoch 75/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3727 - accuracy: 0.9610 - val_loss: 0.9792 - val_accuracy: 0.7717\n","Epoch 76/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3756 - accuracy: 0.9558 - val_loss: 0.9968 - val_accuracy: 0.7707\n","Epoch 77/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3643 - accuracy: 0.9599 - val_loss: 0.9854 - val_accuracy: 0.7645\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3661 - accuracy: 0.9605 - val_loss: 1.0284 - val_accuracy: 0.7645\n","Epoch 79/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3650 - accuracy: 0.9589 - val_loss: 1.0327 - val_accuracy: 0.7479\n","Epoch 80/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3617 - accuracy: 0.9630 - val_loss: 1.0234 - val_accuracy: 0.7562\n","Epoch 81/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3646 - accuracy: 0.9633 - val_loss: 0.9887 - val_accuracy: 0.7738\n","Epoch 82/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3639 - accuracy: 0.9610 - val_loss: 1.0100 - val_accuracy: 0.7738\n","Epoch 83/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3622 - accuracy: 0.9610 - val_loss: 1.0450 - val_accuracy: 0.7665\n","Epoch 84/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3606 - accuracy: 0.9597 - val_loss: 1.0158 - val_accuracy: 0.7676\n","Epoch 85/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3632 - accuracy: 0.9579 - val_loss: 1.1000 - val_accuracy: 0.7479\n","Epoch 86/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3687 - accuracy: 0.9522 - val_loss: 1.0224 - val_accuracy: 0.7707\n","Epoch 87/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3591 - accuracy: 0.9607 - val_loss: 1.0360 - val_accuracy: 0.7634\n","Epoch 88/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3579 - accuracy: 0.9615 - val_loss: 1.0181 - val_accuracy: 0.7748\n","Epoch 89/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3553 - accuracy: 0.9649 - val_loss: 1.0236 - val_accuracy: 0.7696\n","Epoch 90/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3602 - accuracy: 0.9618 - val_loss: 1.0205 - val_accuracy: 0.7686\n","Epoch 91/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3588 - accuracy: 0.9568 - val_loss: 1.0482 - val_accuracy: 0.7500\n","Epoch 92/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3561 - accuracy: 0.9630 - val_loss: 1.0499 - val_accuracy: 0.7572\n","Epoch 93/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3523 - accuracy: 0.9641 - val_loss: 1.0063 - val_accuracy: 0.7614\n","Epoch 94/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3563 - accuracy: 0.9633 - val_loss: 1.0221 - val_accuracy: 0.7593\n","Epoch 95/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3529 - accuracy: 0.9625 - val_loss: 1.0329 - val_accuracy: 0.7686\n","Epoch 96/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3603 - accuracy: 0.9594 - val_loss: 1.0239 - val_accuracy: 0.7655\n","Epoch 97/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3543 - accuracy: 0.9643 - val_loss: 1.0656 - val_accuracy: 0.7490\n","Epoch 98/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3550 - accuracy: 0.9612 - val_loss: 1.0222 - val_accuracy: 0.7603\n","Epoch 99/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3518 - accuracy: 0.9646 - val_loss: 1.0748 - val_accuracy: 0.7593\n","Epoch 100/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3474 - accuracy: 0.9643 - val_loss: 1.0317 - val_accuracy: 0.7665\n","{'loss': [0.46400973200798035, 0.46537521481513977, 0.4412672221660614, 0.4411821663379669, 0.43528881669044495, 0.4398611783981323, 0.43765711784362793, 0.4317827820777893, 0.4575555622577667, 0.43726032972335815, 0.4264613389968872, 0.42357563972473145, 0.4191455841064453, 0.41652563214302063, 0.4186221659183502, 0.4181993305683136, 0.41068756580352783, 0.43519216775894165, 0.40973010659217834, 0.41797664761543274, 0.47192639112472534, 0.41377004981040955, 0.40657463669776917, 0.4075353443622589, 0.4065309166908264, 0.40551912784576416, 0.41491320729255676, 0.4002355635166168, 0.4039439260959625, 0.39951926469802856, 0.4011399447917938, 0.3987363874912262, 0.4027705788612366, 0.39672988653182983, 0.3983779847621918, 0.39227110147476196, 0.3994966149330139, 0.3981914520263672, 0.4028916358947754, 0.389436274766922, 0.3871796429157257, 0.39459213614463806, 0.39692115783691406, 0.3924465775489807, 0.38709551095962524, 0.39355599880218506, 0.39488109946250916, 0.4008994996547699, 0.44353148341178894, 0.39894887804985046, 0.39449188113212585, 0.38395848870277405, 0.39222729206085205, 0.3849309980869293, 0.3816133737564087, 0.38260895013809204, 0.3785647451877594, 0.3773587942123413, 0.37876027822494507, 0.3819522261619568, 0.37640711665153503, 0.3741310238838196, 0.37017562985420227, 0.37226641178131104, 0.3820432722568512, 0.4104680120944977, 0.38678935170173645, 0.3922428786754608, 0.47867515683174133, 0.41683706641197205, 0.4068010151386261, 0.3874218761920929, 0.384872168302536, 0.3803023099899292, 0.37270742654800415, 0.3756333887577057, 0.3643370270729065, 0.3661012053489685, 0.3650203049182892, 0.3616867661476135, 0.36460572481155396, 0.36394673585891724, 0.3622229993343353, 0.36055630445480347, 0.3631913363933563, 0.36870354413986206, 0.35906749963760376, 0.3579201102256775, 0.3552716076374054, 0.3601665198802948, 0.3587506413459778, 0.3561036288738251, 0.35231825709342957, 0.3562798500061035, 0.35289114713668823, 0.36029312014579773, 0.3542875349521637, 0.35504308342933655, 0.3517651855945587, 0.3474402129650116], 'accuracy': [0.9175710678100586, 0.9204134345054626, 0.9307493567466736, 0.9310077428817749, 0.930232584476471, 0.9273901581764221, 0.9315245747566223, 0.9366925358772278, 0.9227390289306641, 0.9317829608917236, 0.9374676942825317, 0.9374676942825317, 0.9397932887077332, 0.9444444179534912, 0.9431524276733398, 0.9426356554031372, 0.9441860318183899, 0.9325581192970276, 0.9467700123786926, 0.9382429122924805, 0.930232584476471, 0.9428940415382385, 0.9485788345336914, 0.9431524276733398, 0.9452196359634399, 0.9444444179534912, 0.9434108734130859, 0.9506459832191467, 0.948062002658844, 0.94728684425354, 0.9447028636932373, 0.9493539929389954, 0.9447028636932373, 0.949095606803894, 0.9506459832191467, 0.9537467956542969, 0.950904369354248, 0.9503875970840454, 0.9436692595481873, 0.9552971720695496, 0.9529715776443481, 0.94625324010849, 0.9493539929389954, 0.9501292109489441, 0.9547803401947021, 0.9475452303886414, 0.949095606803894, 0.9558139443397522, 0.9315245747566223, 0.9465116262435913, 0.9465116262435913, 0.9555555582046509, 0.947028398513794, 0.9503875970840454, 0.9534883499145508, 0.9532299637794495, 0.9563307762145996, 0.9581395387649536, 0.9542635679244995, 0.9527131915092468, 0.9558139443397522, 0.9568475484848022, 0.9591731429100037, 0.9563307762145996, 0.9503875970840454, 0.9431524276733398, 0.9516795873641968, 0.9501292109489441, 0.9276486039161682, 0.9483203887939453, 0.9475452303886414, 0.9555555582046509, 0.9589147567749023, 0.9537467956542969, 0.9609819054603577, 0.9558139443397522, 0.9599483013153076, 0.960465133190155, 0.9589147567749023, 0.9630491137504578, 0.9633074998855591, 0.9609819054603577, 0.9609819054603577, 0.9596899151802063, 0.9578811526298523, 0.9521963596343994, 0.9607235193252563, 0.9614987373352051, 0.9648578763008118, 0.9617571234703064, 0.9568475484848022, 0.9630491137504578, 0.964082658290863, 0.9633074998855591, 0.9625322818756104, 0.959431529045105, 0.9643411040306091, 0.961240291595459, 0.9645994901657104, 0.9643411040306091], 'val_loss': [0.9463250637054443, 0.9372932314872742, 0.9512834548950195, 0.9431830644607544, 0.9592016339302063, 0.9099189043045044, 0.9366921782493591, 0.8974311947822571, 0.9623371958732605, 0.9844351410865784, 0.9725858569145203, 0.9043463468551636, 0.8760419487953186, 0.8787355422973633, 0.8708115220069885, 0.8918840289115906, 0.8055873513221741, 0.9172648191452026, 0.8925941586494446, 0.8972991704940796, 0.9891093373298645, 0.8455013036727905, 0.9291353821754456, 0.8797184228897095, 0.8846381306648254, 0.858308732509613, 0.8800894618034363, 0.8865954279899597, 0.89853835105896, 0.8902928233146667, 0.9027507305145264, 1.0006580352783203, 0.9312496781349182, 0.9560529589653015, 0.8986755609512329, 0.9494476318359375, 0.9182289838790894, 0.9596895575523376, 0.9421170949935913, 0.9476071000099182, 0.9492228627204895, 0.9428060054779053, 0.9743916988372803, 0.9650074243545532, 1.0233139991760254, 0.9528303146362305, 1.046991229057312, 1.0321178436279297, 0.9924700260162354, 0.9647826552391052, 0.9946013689041138, 1.0418158769607544, 0.9906719326972961, 0.9988434314727783, 0.9579678177833557, 0.959132969379425, 0.9686033725738525, 0.9675338268280029, 0.965083658695221, 1.0858490467071533, 0.9687004685401917, 0.9637565016746521, 0.9748208522796631, 1.0557262897491455, 0.9696811437606812, 1.0332046747207642, 1.0585131645202637, 1.2659541368484497, 1.0569220781326294, 1.0256617069244385, 1.087088942527771, 0.9852367043495178, 0.982395589351654, 1.0223745107650757, 0.9791617393493652, 0.9968222975730896, 0.9853591322898865, 1.0284498929977417, 1.0326883792877197, 1.023414969444275, 0.9886749982833862, 1.0099735260009766, 1.0450456142425537, 1.0158151388168335, 1.099961519241333, 1.0224109888076782, 1.035976529121399, 1.018149495124817, 1.0235739946365356, 1.0204570293426514, 1.048187494277954, 1.049912452697754, 1.0063327550888062, 1.0221046209335327, 1.0329234600067139, 1.0239241123199463, 1.0656064748764038, 1.0222194194793701, 1.0747748613357544, 1.0316896438598633], 'val_accuracy': [0.6198347210884094, 0.6177685856819153, 0.6280992031097412, 0.6373966932296753, 0.6311983466148376, 0.6477272510528564, 0.6394628286361694, 0.6611570119857788, 0.6311983466148376, 0.6177685856819153, 0.6280992031097412, 0.6580578684806824, 0.6807851195335388, 0.6973140239715576, 0.7045454382896423, 0.6952479481697083, 0.7541322112083435, 0.6818181872367859, 0.7293388247489929, 0.7345041036605835, 0.7138429880142212, 0.7820248007774353, 0.7231404781341553, 0.7592975497245789, 0.7675619721412659, 0.78925621509552, 0.78925621509552, 0.7902892827987671, 0.7789255976676941, 0.78925621509552, 0.7778925895690918, 0.7551652789115906, 0.7634297609329224, 0.7758264541625977, 0.788223147392273, 0.7830578684806824, 0.7789255976676941, 0.7778925895690918, 0.7572314143180847, 0.7799586653709412, 0.7789255976676941, 0.7778925895690918, 0.7644628286361694, 0.7665289044380188, 0.7644628286361694, 0.7758264541625977, 0.7623966932296753, 0.76962810754776, 0.7592975497245789, 0.7706611752510071, 0.7582644820213318, 0.7716942429542542, 0.7716942429542542, 0.7716942429542542, 0.7809917330741882, 0.7758264541625977, 0.7654958963394165, 0.7747933864593506, 0.7747933864593506, 0.7613636255264282, 0.7716942429542542, 0.7768595218658447, 0.7654958963394165, 0.7469007968902588, 0.7654958963394165, 0.7675619721412659, 0.7706611752510071, 0.7530992031097412, 0.7448347210884094, 0.7623966932296753, 0.7438016533851624, 0.7675619721412659, 0.7561983466148376, 0.7716942429542542, 0.7716942429542542, 0.7706611752510071, 0.7644628286361694, 0.7644628286361694, 0.7479338645935059, 0.7561983466148376, 0.7737603187561035, 0.7737603187561035, 0.7665289044380188, 0.7675619721412659, 0.7479338645935059, 0.7706611752510071, 0.7634297609329224, 0.7747933864593506, 0.76962810754776, 0.7685950398445129, 0.75, 0.7572314143180847, 0.7613636255264282, 0.7592975497245789, 0.7685950398445129, 0.7654958963394165, 0.7489669322967529, 0.7603305578231812, 0.7592975497245789, 0.7665289044380188]}\n","32/32 [==============================] - 0s 3ms/step\n"]}],"source":["global_model_CNN, metrics_df_CNN = federated_learning(Theta_data)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1717433387616,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"},"user_tz":-360},"id":"y3RXIk-qZ7ts","outputId":"3fc9c740-9da0-45c0-a2ba-abe1cae43171"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.600      0.636   0.466  0.538        0.466        0.734   \n","1        1     0.629      0.670   0.508  0.578        0.508        0.750   \n","2        2     0.618      0.613   0.643  0.627        0.643        0.594   \n","3        0     0.645      0.652   0.621  0.636        0.621        0.668   \n","4        1     0.681      0.700   0.634  0.666        0.634        0.729   \n","5        2     0.676      0.691   0.635  0.662        0.635        0.717   \n","6        0     0.696      0.720   0.642  0.678        0.642        0.750   \n","7        1     0.734      0.759   0.686  0.721        0.686        0.782   \n","8        2     0.705      0.704   0.707  0.705        0.707        0.703   \n","9        0     0.724      0.751   0.668  0.707        0.668        0.779   \n","10       1     0.763      0.775   0.743  0.758        0.743        0.784   \n","11       2     0.764      0.790   0.719  0.753        0.719        0.809   \n","12       0     0.744      0.763   0.707  0.734        0.707        0.781   \n","13       1     0.785      0.772   0.809  0.790        0.809        0.761   \n","14       2     0.806      0.808   0.803  0.806        0.803        0.809   \n","\n","    Kappa  \n","0   0.199  \n","1   0.258  \n","2   0.237  \n","3   0.290  \n","4   0.363  \n","5   0.351  \n","6   0.392  \n","7   0.469  \n","8   0.410  \n","9   0.447  \n","10  0.527  \n","11  0.528  \n","12  0.487  \n","13  0.571  \n","14  0.612  "],"text/html":["\n","  <div id=\"df-af8485ea-e1c5-4b16-8be6-4ed7682b2fac\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.600</td>\n","      <td>0.636</td>\n","      <td>0.466</td>\n","      <td>0.538</td>\n","      <td>0.466</td>\n","      <td>0.734</td>\n","      <td>0.199</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.629</td>\n","      <td>0.670</td>\n","      <td>0.508</td>\n","      <td>0.578</td>\n","      <td>0.508</td>\n","      <td>0.750</td>\n","      <td>0.258</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.618</td>\n","      <td>0.613</td>\n","      <td>0.643</td>\n","      <td>0.627</td>\n","      <td>0.643</td>\n","      <td>0.594</td>\n","      <td>0.237</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.645</td>\n","      <td>0.652</td>\n","      <td>0.621</td>\n","      <td>0.636</td>\n","      <td>0.621</td>\n","      <td>0.668</td>\n","      <td>0.290</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.681</td>\n","      <td>0.700</td>\n","      <td>0.634</td>\n","      <td>0.666</td>\n","      <td>0.634</td>\n","      <td>0.729</td>\n","      <td>0.363</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.676</td>\n","      <td>0.691</td>\n","      <td>0.635</td>\n","      <td>0.662</td>\n","      <td>0.635</td>\n","      <td>0.717</td>\n","      <td>0.351</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.696</td>\n","      <td>0.720</td>\n","      <td>0.642</td>\n","      <td>0.678</td>\n","      <td>0.642</td>\n","      <td>0.750</td>\n","      <td>0.392</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.734</td>\n","      <td>0.759</td>\n","      <td>0.686</td>\n","      <td>0.721</td>\n","      <td>0.686</td>\n","      <td>0.782</td>\n","      <td>0.469</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.705</td>\n","      <td>0.704</td>\n","      <td>0.707</td>\n","      <td>0.705</td>\n","      <td>0.707</td>\n","      <td>0.703</td>\n","      <td>0.410</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.724</td>\n","      <td>0.751</td>\n","      <td>0.668</td>\n","      <td>0.707</td>\n","      <td>0.668</td>\n","      <td>0.779</td>\n","      <td>0.447</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.763</td>\n","      <td>0.775</td>\n","      <td>0.743</td>\n","      <td>0.758</td>\n","      <td>0.743</td>\n","      <td>0.784</td>\n","      <td>0.527</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.764</td>\n","      <td>0.790</td>\n","      <td>0.719</td>\n","      <td>0.753</td>\n","      <td>0.719</td>\n","      <td>0.809</td>\n","      <td>0.528</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.744</td>\n","      <td>0.763</td>\n","      <td>0.707</td>\n","      <td>0.734</td>\n","      <td>0.707</td>\n","      <td>0.781</td>\n","      <td>0.487</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.785</td>\n","      <td>0.772</td>\n","      <td>0.809</td>\n","      <td>0.790</td>\n","      <td>0.809</td>\n","      <td>0.761</td>\n","      <td>0.571</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.806</td>\n","      <td>0.808</td>\n","      <td>0.803</td>\n","      <td>0.806</td>\n","      <td>0.803</td>\n","      <td>0.809</td>\n","      <td>0.612</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af8485ea-e1c5-4b16-8be6-4ed7682b2fac')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-af8485ea-e1c5-4b16-8be6-4ed7682b2fac button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-af8485ea-e1c5-4b16-8be6-4ed7682b2fac');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-e8e728bc-5854-4fca-9e01-db20e144f342\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e8e728bc-5854-4fca-9e01-db20e144f342')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-e8e728bc-5854-4fca-9e01-db20e144f342 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df_CNN\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06303929235764295,\n        \"min\": 0.6,\n        \"max\": 0.806,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.724,\n          0.764,\n          0.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0596591109874219,\n        \"min\": 0.613,\n        \"max\": 0.808,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.751,\n          0.79,\n          0.636\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09327414790104849,\n        \"min\": 0.466,\n        \"max\": 0.809,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.668,\n          0.719,\n          0.466\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07535231534977165,\n        \"min\": 0.538,\n        \"max\": 0.806,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.707,\n          0.753,\n          0.538\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09327414790104849,\n        \"min\": 0.466,\n        \"max\": 0.809,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.668,\n          0.719,\n          0.466\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.056979528487577605,\n        \"min\": 0.594,\n        \"max\": 0.809,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.781,\n          0.784,\n          0.734\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12623096744799647,\n        \"min\": 0.199,\n        \"max\": 0.612,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.447,\n          0.528,\n          0.199\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":17}],"source":["metrics_df_CNN.round(3)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"_iOLsKpkfzdG","executionInfo":{"status":"ok","timestamp":1717433387617,"user_tz":-360,"elapsed":14,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"outputs":[],"source":["metrics_df_CNN.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Frequency Domain/CNN/Theta_time_CNN.csv', index = False)"]},{"cell_type":"markdown","source":["# GRU\n"],"metadata":{"id":"OpZcHk115lPB"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout, GRU\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model_gru(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(GRU(256, return_sequences=True))\n","    model.add(GRU(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning_gru(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model_gru(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model_gru(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Theta/CNN_GRU/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Theta/CNN_GRU/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"m2idq1-m5npg","executionInfo":{"status":"ok","timestamp":1717433387618,"user_tz":-360,"elapsed":15,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["global_model_gru, metrics_df_gru = federated_learning_gru(Theta_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"76OL1ptb6dgq","executionInfo":{"status":"ok","timestamp":1717434636087,"user_tz":-360,"elapsed":302282,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}},"outputId":"ed63badf-d7ae-4405-b284-44bd30ed785e"},"execution_count":20,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Train shape: (4640, 19, 29), Test shape: (1194, 19, 29)\n","Train shape: (4418, 19, 29), Test shape: (1416, 19, 29)\n","Train shape: (4838, 19, 29), Test shape: (996, 19, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 1.4306 - accuracy: 0.5031"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 7s 48ms/step - loss: 1.4305 - accuracy: 0.5032 - val_loss: 1.4276 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.4235 - accuracy: 0.5261 - val_loss: 1.4214 - val_accuracy: 0.5582\n","Epoch 3/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.4165 - accuracy: 0.5442 - val_loss: 1.4153 - val_accuracy: 0.5593\n","Epoch 4/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.4093 - accuracy: 0.5520 - val_loss: 1.4092 - val_accuracy: 0.5571\n","Epoch 5/100\n","29/29 [==============================] - 1s 30ms/step - loss: 1.4019 - accuracy: 0.5555 - val_loss: 1.4031 - val_accuracy: 0.5603\n","Epoch 6/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.3945 - accuracy: 0.5606 - val_loss: 1.3970 - val_accuracy: 0.5603\n","Epoch 7/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.3875 - accuracy: 0.5673 - val_loss: 1.3908 - val_accuracy: 0.5733\n","Epoch 8/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3807 - accuracy: 0.5700 - val_loss: 1.3848 - val_accuracy: 0.5722\n","Epoch 9/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3741 - accuracy: 0.5725 - val_loss: 1.3787 - val_accuracy: 0.5711\n","Epoch 10/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3680 - accuracy: 0.5768 - val_loss: 1.3727 - val_accuracy: 0.5711\n","Epoch 11/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3616 - accuracy: 0.5776 - val_loss: 1.3666 - val_accuracy: 0.5722\n","Epoch 12/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3558 - accuracy: 0.5765 - val_loss: 1.3604 - val_accuracy: 0.5700\n","Epoch 13/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.3493 - accuracy: 0.5824 - val_loss: 1.3544 - val_accuracy: 0.5776\n","Epoch 14/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.3431 - accuracy: 0.5849 - val_loss: 1.3484 - val_accuracy: 0.5787\n","Epoch 15/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.3371 - accuracy: 0.5838 - val_loss: 1.3423 - val_accuracy: 0.5754\n","Epoch 16/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3307 - accuracy: 0.5878 - val_loss: 1.3360 - val_accuracy: 0.5668\n","Epoch 17/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3245 - accuracy: 0.5962 - val_loss: 1.3299 - val_accuracy: 0.5625\n","Epoch 18/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3178 - accuracy: 0.5924 - val_loss: 1.3235 - val_accuracy: 0.5636\n","Epoch 19/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3109 - accuracy: 0.5981 - val_loss: 1.3173 - val_accuracy: 0.5668\n","Epoch 20/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3031 - accuracy: 0.6064 - val_loss: 1.3105 - val_accuracy: 0.5711\n","Epoch 21/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2968 - accuracy: 0.6053 - val_loss: 1.3038 - val_accuracy: 0.5765\n","Epoch 22/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2895 - accuracy: 0.6088 - val_loss: 1.2975 - val_accuracy: 0.5754\n","Epoch 23/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.2820 - accuracy: 0.6110 - val_loss: 1.2911 - val_accuracy: 0.5744\n","Epoch 24/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2749 - accuracy: 0.6183 - val_loss: 1.2847 - val_accuracy: 0.5776\n","Epoch 25/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2688 - accuracy: 0.6102 - val_loss: 1.2785 - val_accuracy: 0.5927\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2616 - accuracy: 0.6231 - val_loss: 1.2727 - val_accuracy: 0.5841\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2559 - accuracy: 0.6218 - val_loss: 1.2681 - val_accuracy: 0.5797\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2493 - accuracy: 0.6272 - val_loss: 1.2610 - val_accuracy: 0.5916\n","Epoch 29/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.2442 - accuracy: 0.6228 - val_loss: 1.2557 - val_accuracy: 0.5981\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2385 - accuracy: 0.6202 - val_loss: 1.2510 - val_accuracy: 0.5927\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2315 - accuracy: 0.6304 - val_loss: 1.2475 - val_accuracy: 0.5905\n","Epoch 32/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2256 - accuracy: 0.6320 - val_loss: 1.2408 - val_accuracy: 0.6002\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2194 - accuracy: 0.6342 - val_loss: 1.2375 - val_accuracy: 0.5938\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2150 - accuracy: 0.6360 - val_loss: 1.2319 - val_accuracy: 0.5970\n","Epoch 35/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.2107 - accuracy: 0.6309 - val_loss: 1.2278 - val_accuracy: 0.6002\n","Epoch 36/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.2058 - accuracy: 0.6398 - val_loss: 1.2239 - val_accuracy: 0.6056\n","Epoch 37/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.2019 - accuracy: 0.6298 - val_loss: 1.2196 - val_accuracy: 0.6078\n","Epoch 38/100\n","29/29 [==============================] - 1s 16ms/step - loss: 1.1953 - accuracy: 0.6387 - val_loss: 1.2156 - val_accuracy: 0.6034\n","Epoch 39/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1902 - accuracy: 0.6422 - val_loss: 1.2112 - val_accuracy: 0.6078\n","Epoch 40/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1861 - accuracy: 0.6404 - val_loss: 1.2082 - val_accuracy: 0.6078\n","Epoch 41/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1813 - accuracy: 0.6401 - val_loss: 1.2035 - val_accuracy: 0.6045\n","Epoch 42/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1751 - accuracy: 0.6417 - val_loss: 1.1993 - val_accuracy: 0.5981\n","Epoch 43/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1714 - accuracy: 0.6401 - val_loss: 1.1955 - val_accuracy: 0.6034\n","Epoch 44/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1667 - accuracy: 0.6436 - val_loss: 1.1925 - val_accuracy: 0.6121\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1614 - accuracy: 0.6484 - val_loss: 1.1879 - val_accuracy: 0.6045\n","Epoch 46/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.1585 - accuracy: 0.6414 - val_loss: 1.1853 - val_accuracy: 0.6131\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1547 - accuracy: 0.6468 - val_loss: 1.1810 - val_accuracy: 0.6088\n","Epoch 48/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1499 - accuracy: 0.6414 - val_loss: 1.1790 - val_accuracy: 0.6142\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1440 - accuracy: 0.6498 - val_loss: 1.1741 - val_accuracy: 0.6088\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1391 - accuracy: 0.6495 - val_loss: 1.1721 - val_accuracy: 0.6131\n","Epoch 51/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1337 - accuracy: 0.6565 - val_loss: 1.1680 - val_accuracy: 0.6121\n","Epoch 52/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1300 - accuracy: 0.6554 - val_loss: 1.1644 - val_accuracy: 0.6099\n","Epoch 53/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1261 - accuracy: 0.6530 - val_loss: 1.1598 - val_accuracy: 0.6088\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1220 - accuracy: 0.6522 - val_loss: 1.1595 - val_accuracy: 0.6142\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1158 - accuracy: 0.6530 - val_loss: 1.1542 - val_accuracy: 0.6142\n","Epoch 56/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1116 - accuracy: 0.6546 - val_loss: 1.1512 - val_accuracy: 0.6164\n","Epoch 57/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.1090 - accuracy: 0.6584 - val_loss: 1.1472 - val_accuracy: 0.6175\n","Epoch 58/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1043 - accuracy: 0.6562 - val_loss: 1.1457 - val_accuracy: 0.6185\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1021 - accuracy: 0.6568 - val_loss: 1.1404 - val_accuracy: 0.6088\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0927 - accuracy: 0.6624 - val_loss: 1.1379 - val_accuracy: 0.6164\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0904 - accuracy: 0.6649 - val_loss: 1.1384 - val_accuracy: 0.6175\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0876 - accuracy: 0.6614 - val_loss: 1.1313 - val_accuracy: 0.6142\n","Epoch 63/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0816 - accuracy: 0.6697 - val_loss: 1.1302 - val_accuracy: 0.6239\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0768 - accuracy: 0.6684 - val_loss: 1.1274 - val_accuracy: 0.6239\n","Epoch 65/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0724 - accuracy: 0.6700 - val_loss: 1.1225 - val_accuracy: 0.6228\n","Epoch 66/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0684 - accuracy: 0.6670 - val_loss: 1.1203 - val_accuracy: 0.6196\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0641 - accuracy: 0.6724 - val_loss: 1.1152 - val_accuracy: 0.6131\n","Epoch 68/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0596 - accuracy: 0.6711 - val_loss: 1.1121 - val_accuracy: 0.6142\n","Epoch 69/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0536 - accuracy: 0.6794 - val_loss: 1.1114 - val_accuracy: 0.6196\n","Epoch 70/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0475 - accuracy: 0.6794 - val_loss: 1.1141 - val_accuracy: 0.6207\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0464 - accuracy: 0.6773 - val_loss: 1.1059 - val_accuracy: 0.6218\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0389 - accuracy: 0.6886 - val_loss: 1.1010 - val_accuracy: 0.6207\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0353 - accuracy: 0.6859 - val_loss: 1.1028 - val_accuracy: 0.6175\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0319 - accuracy: 0.6888 - val_loss: 1.1032 - val_accuracy: 0.6164\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0230 - accuracy: 0.6926 - val_loss: 1.0975 - val_accuracy: 0.6175\n","Epoch 76/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0220 - accuracy: 0.6897 - val_loss: 1.0931 - val_accuracy: 0.6175\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0140 - accuracy: 0.6964 - val_loss: 1.0941 - val_accuracy: 0.6088\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0080 - accuracy: 0.6964 - val_loss: 1.0893 - val_accuracy: 0.6164\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0066 - accuracy: 0.6972 - val_loss: 1.0858 - val_accuracy: 0.6142\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0006 - accuracy: 0.7034 - val_loss: 1.0831 - val_accuracy: 0.6121\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9971 - accuracy: 0.6975 - val_loss: 1.0818 - val_accuracy: 0.6131\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9885 - accuracy: 0.7053 - val_loss: 1.0777 - val_accuracy: 0.6142\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9853 - accuracy: 0.7077 - val_loss: 1.0790 - val_accuracy: 0.6067\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9778 - accuracy: 0.7198 - val_loss: 1.0729 - val_accuracy: 0.6175\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9721 - accuracy: 0.7185 - val_loss: 1.0729 - val_accuracy: 0.6153\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9688 - accuracy: 0.7158 - val_loss: 1.0735 - val_accuracy: 0.6164\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9681 - accuracy: 0.7150 - val_loss: 1.0736 - val_accuracy: 0.6131\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9631 - accuracy: 0.7163 - val_loss: 1.0745 - val_accuracy: 0.6078\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9567 - accuracy: 0.7177 - val_loss: 1.0662 - val_accuracy: 0.6207\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9526 - accuracy: 0.7201 - val_loss: 1.0663 - val_accuracy: 0.6228\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9450 - accuracy: 0.7239 - val_loss: 1.0681 - val_accuracy: 0.6121\n","Epoch 92/100\n","29/29 [==============================] - 2s 62ms/step - loss: 0.9412 - accuracy: 0.7231 - val_loss: 1.0600 - val_accuracy: 0.6250\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9378 - accuracy: 0.7284 - val_loss: 1.0671 - val_accuracy: 0.6153\n","Epoch 94/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9384 - accuracy: 0.7225 - val_loss: 1.0559 - val_accuracy: 0.6261\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9240 - accuracy: 0.7341 - val_loss: 1.0566 - val_accuracy: 0.6164\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9246 - accuracy: 0.7341 - val_loss: 1.0517 - val_accuracy: 0.6218\n","Epoch 97/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.9178 - accuracy: 0.7338 - val_loss: 1.0530 - val_accuracy: 0.6282\n","Epoch 98/100\n","29/29 [==============================] - 1s 16ms/step - loss: 0.9148 - accuracy: 0.7344 - val_loss: 1.0571 - val_accuracy: 0.6164\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9092 - accuracy: 0.7381 - val_loss: 1.0534 - val_accuracy: 0.6218\n","Epoch 100/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9044 - accuracy: 0.7328 - val_loss: 1.0590 - val_accuracy: 0.6207\n","{'loss': [1.430460810661316, 1.423548936843872, 1.4165352582931519, 1.4092564582824707, 1.4018800258636475, 1.3945063352584839, 1.38748300075531, 1.380721926689148, 1.3740804195404053, 1.367952585220337, 1.3615918159484863, 1.3557868003845215, 1.349279761314392, 1.3431493043899536, 1.3370919227600098, 1.330746054649353, 1.3244842290878296, 1.3178448677062988, 1.3108714818954468, 1.303096055984497, 1.2967509031295776, 1.289526104927063, 1.2820242643356323, 1.2748783826828003, 1.2687634229660034, 1.2616467475891113, 1.2559293508529663, 1.2492915391921997, 1.2441611289978027, 1.2385458946228027, 1.231490135192871, 1.2256046533584595, 1.2194324731826782, 1.215041995048523, 1.2106658220291138, 1.205777883529663, 1.2019200325012207, 1.1953442096710205, 1.1901956796646118, 1.1860517263412476, 1.1813485622406006, 1.1751389503479004, 1.1713846921920776, 1.1667314767837524, 1.1614301204681396, 1.158454418182373, 1.1546833515167236, 1.1499124765396118, 1.1439900398254395, 1.1390525102615356, 1.1336660385131836, 1.1300063133239746, 1.1260604858398438, 1.1220453977584839, 1.115814208984375, 1.1116267442703247, 1.109012246131897, 1.1042860746383667, 1.1021369695663452, 1.092689037322998, 1.0904220342636108, 1.0876071453094482, 1.081566333770752, 1.0767923593521118, 1.0723505020141602, 1.0683891773223877, 1.0641146898269653, 1.0596004724502563, 1.0535688400268555, 1.0474634170532227, 1.0464417934417725, 1.0389280319213867, 1.0353457927703857, 1.0318840742111206, 1.0230156183242798, 1.0219827890396118, 1.013985276222229, 1.0079889297485352, 1.0065544843673706, 1.0006334781646729, 0.997146725654602, 0.9885398745536804, 0.9852536916732788, 0.9778404831886292, 0.9720504879951477, 0.9687879681587219, 0.9681212306022644, 0.9631462097167969, 0.9566988945007324, 0.9526411294937134, 0.9450311064720154, 0.9412203431129456, 0.9377961158752441, 0.9384282827377319, 0.9239643812179565, 0.9245559573173523, 0.9177627563476562, 0.9148209691047668, 0.9092181921005249, 0.9043668508529663], 'accuracy': [0.5032327771186829, 0.5261314511299133, 0.5441810488700867, 0.5519935488700867, 0.5554956793785095, 0.5606142282485962, 0.5673491358757019, 0.5700430870056152, 0.5724676847457886, 0.576777994632721, 0.5775862336158752, 0.576508641242981, 0.5824353694915771, 0.5848599076271057, 0.5837823152542114, 0.5878232717514038, 0.5961745977401733, 0.592402994632721, 0.5980603694915771, 0.6064116358757019, 0.6053340435028076, 0.6088362336158752, 0.610991358757019, 0.6182650923728943, 0.6101831793785095, 0.6231142282485962, 0.6217672228813171, 0.6271551847457886, 0.6228448152542114, 0.6201508641242981, 0.6303879022598267, 0.6320043206214905, 0.634159505367279, 0.6360452771186829, 0.6309267282485962, 0.6398168206214905, 0.6298491358757019, 0.6387392282485962, 0.642241358757019, 0.6403555870056152, 0.6400862336158752, 0.6417025923728943, 0.6400862336158752, 0.6435883641242981, 0.6484375, 0.6414331793785095, 0.646821141242981, 0.6414331793785095, 0.649784505367279, 0.6495150923728943, 0.6565194129943848, 0.6554418206214905, 0.6530172228813171, 0.6522090435028076, 0.6530172228813171, 0.654633641242981, 0.6584051847457886, 0.65625, 0.6567887663841248, 0.662446141242981, 0.6648706793785095, 0.6613685488700867, 0.6697198152542114, 0.6683728694915771, 0.6699892282485962, 0.6670258641242981, 0.6724137663841248, 0.6710668206214905, 0.6794180870056152, 0.6794180870056152, 0.6772629022598267, 0.6885775923728943, 0.685883641242981, 0.688847005367279, 0.6926185488700867, 0.6896551847457886, 0.6963900923728943, 0.6963900923728943, 0.6971982717514038, 0.7033944129943848, 0.6974676847457886, 0.7052801847457886, 0.7077047228813171, 0.7198275923728943, 0.7184805870056152, 0.7157866358757019, 0.7149784564971924, 0.7163254022598267, 0.7176724076271057, 0.720097005367279, 0.7238685488700867, 0.7230603694915771, 0.7284482717514038, 0.7225215435028076, 0.7341055870056152, 0.7341055870056152, 0.7338362336158752, 0.734375, 0.7381465435028076, 0.732758641242981], 'val_loss': [1.427598237991333, 1.4214144945144653, 1.415270447731018, 1.4091506004333496, 1.4030673503875732, 1.396968960762024, 1.3908207416534424, 1.384764552116394, 1.3786989450454712, 1.3726524114608765, 1.3665693998336792, 1.3604233264923096, 1.354414701461792, 1.3483513593673706, 1.3422976732254028, 1.3359814882278442, 1.3298981189727783, 1.3234694004058838, 1.3172913789749146, 1.3104802370071411, 1.3037761449813843, 1.2974534034729004, 1.2911350727081299, 1.284687876701355, 1.278496265411377, 1.2726939916610718, 1.2680754661560059, 1.2610208988189697, 1.255678653717041, 1.25102698802948, 1.2474809885025024, 1.2408454418182373, 1.2374927997589111, 1.2319096326828003, 1.2278307676315308, 1.223929524421692, 1.2195500135421753, 1.2156418561935425, 1.2112337350845337, 1.2082031965255737, 1.2035256624221802, 1.1992863416671753, 1.1955183744430542, 1.1924548149108887, 1.1879328489303589, 1.185287356376648, 1.1809748411178589, 1.178995966911316, 1.174055576324463, 1.172143816947937, 1.1679555177688599, 1.1643857955932617, 1.1598371267318726, 1.1595313549041748, 1.1542139053344727, 1.1511954069137573, 1.1472477912902832, 1.1456660032272339, 1.140418529510498, 1.1378982067108154, 1.1383875608444214, 1.1313059329986572, 1.130249261856079, 1.1273870468139648, 1.1225183010101318, 1.1202514171600342, 1.1152234077453613, 1.1121342182159424, 1.1114403009414673, 1.1141235828399658, 1.1059460639953613, 1.1010411977767944, 1.1027634143829346, 1.103204607963562, 1.097519040107727, 1.093082070350647, 1.094063639640808, 1.0892695188522339, 1.0857908725738525, 1.0831224918365479, 1.0817815065383911, 1.077690839767456, 1.0789740085601807, 1.0728567838668823, 1.072871208190918, 1.0735430717468262, 1.0736161470413208, 1.074501395225525, 1.0661845207214355, 1.0663224458694458, 1.0680773258209229, 1.0599967241287231, 1.0670949220657349, 1.0559345483779907, 1.0565896034240723, 1.0517041683197021, 1.0529669523239136, 1.0570718050003052, 1.0534303188323975, 1.0590009689331055], 'val_accuracy': [0.48491379618644714, 0.5581896305084229, 0.5592672228813171, 0.5571120977401733, 0.5603448152542114, 0.5603448152542114, 0.5732758641242981, 0.5721982717514038, 0.5711206793785095, 0.5711206793785095, 0.5721982717514038, 0.5700430870056152, 0.5775862336158752, 0.5786637663841248, 0.5754310488700867, 0.5668103694915771, 0.5625, 0.5635775923728943, 0.5668103694915771, 0.5711206793785095, 0.576508641242981, 0.5754310488700867, 0.5743534564971924, 0.5775862336158752, 0.5926724076271057, 0.5840517282485962, 0.579741358757019, 0.5915948152542114, 0.5980603694915771, 0.5926724076271057, 0.5905172228813171, 0.600215494632721, 0.59375, 0.5969827771186829, 0.600215494632721, 0.6056034564971924, 0.607758641242981, 0.6034482717514038, 0.607758641242981, 0.607758641242981, 0.6045258641242981, 0.5980603694915771, 0.6034482717514038, 0.6120689511299133, 0.6045258641242981, 0.6131465435028076, 0.6088362336158752, 0.6142241358757019, 0.6088362336158752, 0.6131465435028076, 0.6120689511299133, 0.6099137663841248, 0.6088362336158752, 0.6142241358757019, 0.6142241358757019, 0.6163793206214905, 0.6174569129943848, 0.618534505367279, 0.6088362336158752, 0.6163793206214905, 0.6174569129943848, 0.6142241358757019, 0.6239224076271057, 0.6239224076271057, 0.6228448152542114, 0.6196120977401733, 0.6131465435028076, 0.6142241358757019, 0.6196120977401733, 0.6206896305084229, 0.6217672228813171, 0.6206896305084229, 0.6174569129943848, 0.6163793206214905, 0.6174569129943848, 0.6174569129943848, 0.6088362336158752, 0.6163793206214905, 0.6142241358757019, 0.6120689511299133, 0.6131465435028076, 0.6142241358757019, 0.6066810488700867, 0.6174569129943848, 0.6153017282485962, 0.6163793206214905, 0.6131465435028076, 0.607758641242981, 0.6206896305084229, 0.6228448152542114, 0.6120689511299133, 0.625, 0.6153017282485962, 0.6260775923728943, 0.6163793206214905, 0.6217672228813171, 0.6282327771186829, 0.6163793206214905, 0.6217672228813171, 0.6206896305084229]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 7s 53ms/step - loss: 1.4307 - accuracy: 0.5000 - val_loss: 1.4278 - val_accuracy: 0.4955\n","Epoch 2/100\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 1s 21ms/step - loss: 1.4241 - accuracy: 0.5156 - val_loss: 1.4218 - val_accuracy: 0.5464\n","Epoch 3/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.4174 - accuracy: 0.5422 - val_loss: 1.4159 - val_accuracy: 0.5317\n","Epoch 4/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.4107 - accuracy: 0.5526 - val_loss: 1.4100 - val_accuracy: 0.5385\n","Epoch 5/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4037 - accuracy: 0.5555 - val_loss: 1.4041 - val_accuracy: 0.5430\n","Epoch 6/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.3967 - accuracy: 0.5614 - val_loss: 1.3983 - val_accuracy: 0.5486\n","Epoch 7/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3900 - accuracy: 0.5546 - val_loss: 1.3923 - val_accuracy: 0.5419\n","Epoch 8/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.3831 - accuracy: 0.5634 - val_loss: 1.3864 - val_accuracy: 0.5509\n","Epoch 9/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.3769 - accuracy: 0.5557 - val_loss: 1.3805 - val_accuracy: 0.5532\n","Epoch 10/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3706 - accuracy: 0.5656 - val_loss: 1.3747 - val_accuracy: 0.5520\n","Epoch 11/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.3647 - accuracy: 0.5690 - val_loss: 1.3689 - val_accuracy: 0.5577\n","Epoch 12/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.3589 - accuracy: 0.5654 - val_loss: 1.3629 - val_accuracy: 0.5713\n","Epoch 13/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3533 - accuracy: 0.5693 - val_loss: 1.3572 - val_accuracy: 0.5679\n","Epoch 14/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.3474 - accuracy: 0.5719 - val_loss: 1.3514 - val_accuracy: 0.5735\n","Epoch 15/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3414 - accuracy: 0.5730 - val_loss: 1.3456 - val_accuracy: 0.5724\n","Epoch 16/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3358 - accuracy: 0.5710 - val_loss: 1.3398 - val_accuracy: 0.5645\n","Epoch 17/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3301 - accuracy: 0.5733 - val_loss: 1.3336 - val_accuracy: 0.5701\n","Epoch 18/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3238 - accuracy: 0.5818 - val_loss: 1.3285 - val_accuracy: 0.5679\n","Epoch 19/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.3173 - accuracy: 0.5826 - val_loss: 1.3219 - val_accuracy: 0.5735\n","Epoch 20/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.3112 - accuracy: 0.5840 - val_loss: 1.3160 - val_accuracy: 0.5747\n","Epoch 21/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3050 - accuracy: 0.5908 - val_loss: 1.3100 - val_accuracy: 0.5701\n","Epoch 22/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2978 - accuracy: 0.5939 - val_loss: 1.3051 - val_accuracy: 0.5701\n","Epoch 23/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2917 - accuracy: 0.6038 - val_loss: 1.2990 - val_accuracy: 0.5679\n","Epoch 24/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2847 - accuracy: 0.6075 - val_loss: 1.2933 - val_accuracy: 0.5701\n","Epoch 25/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.2778 - accuracy: 0.6112 - val_loss: 1.2880 - val_accuracy: 0.5769\n","Epoch 26/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2718 - accuracy: 0.6154 - val_loss: 1.2823 - val_accuracy: 0.5769\n","Epoch 27/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.2659 - accuracy: 0.6118 - val_loss: 1.2771 - val_accuracy: 0.5758\n","Epoch 28/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.2607 - accuracy: 0.6058 - val_loss: 1.2727 - val_accuracy: 0.5792\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2538 - accuracy: 0.6106 - val_loss: 1.2695 - val_accuracy: 0.5769\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2483 - accuracy: 0.6112 - val_loss: 1.2652 - val_accuracy: 0.5792\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2421 - accuracy: 0.6217 - val_loss: 1.2592 - val_accuracy: 0.5792\n","Epoch 32/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2351 - accuracy: 0.6225 - val_loss: 1.2558 - val_accuracy: 0.5871\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2321 - accuracy: 0.6197 - val_loss: 1.2511 - val_accuracy: 0.5826\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2246 - accuracy: 0.6194 - val_loss: 1.2464 - val_accuracy: 0.5860\n","Epoch 35/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.2204 - accuracy: 0.6171 - val_loss: 1.2429 - val_accuracy: 0.5905\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2160 - accuracy: 0.6234 - val_loss: 1.2396 - val_accuracy: 0.5905\n","Epoch 37/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2087 - accuracy: 0.6245 - val_loss: 1.2351 - val_accuracy: 0.5871\n","Epoch 38/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.2061 - accuracy: 0.6220 - val_loss: 1.2308 - val_accuracy: 0.5916\n","Epoch 39/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2006 - accuracy: 0.6256 - val_loss: 1.2282 - val_accuracy: 0.5814\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1951 - accuracy: 0.6225 - val_loss: 1.2238 - val_accuracy: 0.5860\n","Epoch 41/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1901 - accuracy: 0.6299 - val_loss: 1.2198 - val_accuracy: 0.5871\n","Epoch 42/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1864 - accuracy: 0.6271 - val_loss: 1.2153 - val_accuracy: 0.5871\n","Epoch 43/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.1811 - accuracy: 0.6262 - val_loss: 1.2131 - val_accuracy: 0.5950\n","Epoch 44/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1778 - accuracy: 0.6285 - val_loss: 1.2102 - val_accuracy: 0.5973\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1729 - accuracy: 0.6251 - val_loss: 1.2049 - val_accuracy: 0.5860\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1676 - accuracy: 0.6336 - val_loss: 1.2021 - val_accuracy: 0.5939\n","Epoch 47/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1632 - accuracy: 0.6372 - val_loss: 1.1981 - val_accuracy: 0.5871\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1590 - accuracy: 0.6341 - val_loss: 1.1971 - val_accuracy: 0.5962\n","Epoch 49/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1548 - accuracy: 0.6324 - val_loss: 1.1922 - val_accuracy: 0.6018\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1494 - accuracy: 0.6367 - val_loss: 1.1886 - val_accuracy: 0.5928\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1443 - accuracy: 0.6384 - val_loss: 1.1849 - val_accuracy: 0.5973\n","Epoch 52/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.1417 - accuracy: 0.6378 - val_loss: 1.1851 - val_accuracy: 0.6029\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1386 - accuracy: 0.6333 - val_loss: 1.1785 - val_accuracy: 0.5939\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1298 - accuracy: 0.6432 - val_loss: 1.1760 - val_accuracy: 0.5973\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1256 - accuracy: 0.6446 - val_loss: 1.1750 - val_accuracy: 0.6018\n","Epoch 56/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1266 - accuracy: 0.6398 - val_loss: 1.1688 - val_accuracy: 0.6041\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1177 - accuracy: 0.6463 - val_loss: 1.1670 - val_accuracy: 0.6018\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1142 - accuracy: 0.6480 - val_loss: 1.1632 - val_accuracy: 0.5995\n","Epoch 59/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1095 - accuracy: 0.6477 - val_loss: 1.1605 - val_accuracy: 0.6007\n","Epoch 60/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1056 - accuracy: 0.6522 - val_loss: 1.1614 - val_accuracy: 0.6086\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1007 - accuracy: 0.6466 - val_loss: 1.1545 - val_accuracy: 0.6018\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0976 - accuracy: 0.6491 - val_loss: 1.1527 - val_accuracy: 0.6007\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0922 - accuracy: 0.6517 - val_loss: 1.1492 - val_accuracy: 0.6041\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0887 - accuracy: 0.6573 - val_loss: 1.1457 - val_accuracy: 0.6086\n","Epoch 65/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.0832 - accuracy: 0.6570 - val_loss: 1.1440 - val_accuracy: 0.6143\n","Epoch 66/100\n","28/28 [==============================] - 1s 17ms/step - loss: 1.0794 - accuracy: 0.6610 - val_loss: 1.1416 - val_accuracy: 0.6052\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0733 - accuracy: 0.6599 - val_loss: 1.1388 - val_accuracy: 0.6097\n","Epoch 68/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0700 - accuracy: 0.6636 - val_loss: 1.1363 - val_accuracy: 0.6086\n","Epoch 69/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.0648 - accuracy: 0.6658 - val_loss: 1.1343 - val_accuracy: 0.6120\n","Epoch 70/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0633 - accuracy: 0.6624 - val_loss: 1.1316 - val_accuracy: 0.6029\n","Epoch 71/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.0569 - accuracy: 0.6658 - val_loss: 1.1294 - val_accuracy: 0.6165\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0492 - accuracy: 0.6720 - val_loss: 1.1257 - val_accuracy: 0.6086\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0464 - accuracy: 0.6712 - val_loss: 1.1265 - val_accuracy: 0.6018\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0434 - accuracy: 0.6712 - val_loss: 1.1201 - val_accuracy: 0.6075\n","Epoch 75/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0365 - accuracy: 0.6808 - val_loss: 1.1191 - val_accuracy: 0.6052\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0347 - accuracy: 0.6791 - val_loss: 1.1171 - val_accuracy: 0.6041\n","Epoch 77/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0279 - accuracy: 0.6777 - val_loss: 1.1150 - val_accuracy: 0.6131\n","Epoch 78/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0239 - accuracy: 0.6802 - val_loss: 1.1151 - val_accuracy: 0.6052\n","Epoch 79/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0200 - accuracy: 0.6834 - val_loss: 1.1113 - val_accuracy: 0.6075\n","Epoch 80/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0132 - accuracy: 0.6842 - val_loss: 1.1125 - val_accuracy: 0.6165\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0128 - accuracy: 0.6856 - val_loss: 1.1078 - val_accuracy: 0.6075\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0063 - accuracy: 0.6924 - val_loss: 1.1051 - val_accuracy: 0.6154\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0008 - accuracy: 0.6899 - val_loss: 1.1065 - val_accuracy: 0.6143\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9922 - accuracy: 0.7054 - val_loss: 1.1032 - val_accuracy: 0.6154\n","Epoch 85/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9888 - accuracy: 0.6986 - val_loss: 1.1042 - val_accuracy: 0.6165\n","Epoch 86/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9851 - accuracy: 0.6984 - val_loss: 1.1039 - val_accuracy: 0.6109\n","Epoch 87/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9852 - accuracy: 0.7003 - val_loss: 1.1004 - val_accuracy: 0.6165\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9753 - accuracy: 0.7040 - val_loss: 1.0957 - val_accuracy: 0.6165\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9704 - accuracy: 0.7077 - val_loss: 1.0978 - val_accuracy: 0.6165\n","Epoch 90/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9640 - accuracy: 0.7071 - val_loss: 1.0971 - val_accuracy: 0.6176\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9591 - accuracy: 0.7151 - val_loss: 1.0967 - val_accuracy: 0.6154\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9579 - accuracy: 0.7077 - val_loss: 1.0966 - val_accuracy: 0.6120\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9517 - accuracy: 0.7159 - val_loss: 1.0956 - val_accuracy: 0.6052\n","Epoch 94/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9460 - accuracy: 0.7148 - val_loss: 1.0919 - val_accuracy: 0.6188\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9384 - accuracy: 0.7176 - val_loss: 1.1053 - val_accuracy: 0.6097\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9362 - accuracy: 0.7264 - val_loss: 1.0959 - val_accuracy: 0.6086\n","Epoch 97/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9329 - accuracy: 0.7224 - val_loss: 1.1044 - val_accuracy: 0.6109\n","Epoch 98/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9347 - accuracy: 0.7281 - val_loss: 1.0954 - val_accuracy: 0.6120\n","Epoch 99/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9200 - accuracy: 0.7301 - val_loss: 1.0980 - val_accuracy: 0.6109\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9165 - accuracy: 0.7332 - val_loss: 1.1006 - val_accuracy: 0.6143\n","{'loss': [1.4306522607803345, 1.4241255521774292, 1.4174290895462036, 1.4106913805007935, 1.4037017822265625, 1.3966935873031616, 1.3899610042572021, 1.3830957412719727, 1.3769116401672363, 1.3705929517745972, 1.3647124767303467, 1.3589247465133667, 1.3533086776733398, 1.3473602533340454, 1.3414201736450195, 1.335769534111023, 1.3300806283950806, 1.323820948600769, 1.3173186779022217, 1.3111512660980225, 1.3049557209014893, 1.2977608442306519, 1.291669487953186, 1.284738302230835, 1.2777624130249023, 1.2717881202697754, 1.2658594846725464, 1.2606950998306274, 1.2538225650787354, 1.2482995986938477, 1.2421345710754395, 1.2350983619689941, 1.2320512533187866, 1.2246389389038086, 1.2203521728515625, 1.2160344123840332, 1.2086701393127441, 1.206099510192871, 1.2006083726882935, 1.1951367855072021, 1.1900887489318848, 1.1863712072372437, 1.1810985803604126, 1.1778143644332886, 1.1728516817092896, 1.1676151752471924, 1.163185954093933, 1.1590417623519897, 1.1547611951828003, 1.1493951082229614, 1.1442511081695557, 1.1416527032852173, 1.1386209726333618, 1.1297953128814697, 1.1256147623062134, 1.1266214847564697, 1.1176981925964355, 1.1141676902770996, 1.1094961166381836, 1.1056462526321411, 1.1006702184677124, 1.0976126194000244, 1.0922183990478516, 1.0886541604995728, 1.0831725597381592, 1.0794246196746826, 1.0732510089874268, 1.0700478553771973, 1.0648036003112793, 1.0633082389831543, 1.0569491386413574, 1.049186110496521, 1.04641592502594, 1.0434247255325317, 1.0365082025527954, 1.0346777439117432, 1.0279090404510498, 1.0238546133041382, 1.0200040340423584, 1.0132280588150024, 1.0127748250961304, 1.006282925605774, 1.0008457899093628, 0.9921795725822449, 0.988818347454071, 0.9851292371749878, 0.9852243661880493, 0.9752657413482666, 0.9703947901725769, 0.964005708694458, 0.959118127822876, 0.9578619003295898, 0.9517257809638977, 0.945966899394989, 0.9383958578109741, 0.9361928105354309, 0.9328518509864807, 0.9347388744354248, 0.9200323224067688, 0.9164557456970215], 'accuracy': [0.5, 0.5155631303787231, 0.5421618819236755, 0.5526315569877625, 0.5554612278938293, 0.5614035129547119, 0.5546123385429382, 0.5633842945098877, 0.5557441711425781, 0.5656480193138123, 0.5690435767173767, 0.5653650164604187, 0.5693265199661255, 0.5718732476234436, 0.5730050802230835, 0.5710243582725525, 0.573288083076477, 0.581777036190033, 0.5826259255409241, 0.5840407609939575, 0.5908319354057312, 0.5939445495605469, 0.6038483381271362, 0.6075268983840942, 0.6112054586410522, 0.6154499053955078, 0.6117713451385498, 0.6058290600776672, 0.6106395125389099, 0.6112054586410522, 0.6216751337051392, 0.6225240230560303, 0.6196944117546082, 0.6194114089012146, 0.61714768409729, 0.6233729720115662, 0.624504804611206, 0.6219581365585327, 0.6256366968154907, 0.6225240230560303, 0.6298811435699463, 0.6270514726638794, 0.6262025833129883, 0.6284663081169128, 0.6250707507133484, 0.6335597038269043, 0.6372382640838623, 0.6341256499290466, 0.6324278712272644, 0.63667231798172, 0.6383700966835022, 0.6378042101860046, 0.6332767605781555, 0.6431805491447449, 0.6445953845977783, 0.6397849321365356, 0.6462931632995605, 0.6479909420013428, 0.647707998752594, 0.6522354483604431, 0.6465761065483093, 0.6491228342056274, 0.6516695022583008, 0.6573287844657898, 0.657045841217041, 0.6610073447227478, 0.6598755121231079, 0.6635540723800659, 0.6658177971839905, 0.6624221801757812, 0.6658177971839905, 0.6720430254936218, 0.6711941361427307, 0.6711941361427307, 0.6808149218559265, 0.6791171431541443, 0.6777023077011108, 0.680249035358429, 0.6833616495132446, 0.6842105388641357, 0.6856253743171692, 0.6924165487289429, 0.6898698210716248, 0.7054329514503479, 0.6986417770385742, 0.6983587741851807, 0.7003395557403564, 0.7040181159973145, 0.7076966762542725, 0.7071307301521301, 0.7150537371635437, 0.7076966762542725, 0.7159026861190796, 0.7147707939147949, 0.7176004648208618, 0.7263723611831665, 0.7224108576774597, 0.7280701994895935, 0.7300509214401245, 0.7331635355949402], 'val_loss': [1.427782416343689, 1.4218183755874634, 1.4159022569656372, 1.4099977016448975, 1.404133677482605, 1.3982762098312378, 1.3923499584197998, 1.386400580406189, 1.38048255443573, 1.3747494220733643, 1.3689119815826416, 1.3629090785980225, 1.3572109937667847, 1.3514113426208496, 1.3455674648284912, 1.339849591255188, 1.3336398601531982, 1.328468680381775, 1.321862816810608, 1.316048502922058, 1.3100239038467407, 1.3051390647888184, 1.2989623546600342, 1.2933210134506226, 1.2879565954208374, 1.2822942733764648, 1.2770801782608032, 1.2726664543151855, 1.2694655656814575, 1.2651985883712769, 1.2591838836669922, 1.2557694911956787, 1.2511259317398071, 1.2463603019714355, 1.2429063320159912, 1.2395927906036377, 1.2351280450820923, 1.2308357954025269, 1.2282459735870361, 1.2238248586654663, 1.2198117971420288, 1.2153186798095703, 1.2131409645080566, 1.210204839706421, 1.204871654510498, 1.202134609222412, 1.1981403827667236, 1.1971310377120972, 1.1921625137329102, 1.1886100769042969, 1.1849241256713867, 1.1851024627685547, 1.1784613132476807, 1.1759718656539917, 1.1750285625457764, 1.168816328048706, 1.1669691801071167, 1.163245439529419, 1.1605463027954102, 1.1614354848861694, 1.1544867753982544, 1.1527081727981567, 1.1491655111312866, 1.1457115411758423, 1.1439865827560425, 1.1416239738464355, 1.1387556791305542, 1.136330008506775, 1.1343384981155396, 1.1316195726394653, 1.1294018030166626, 1.125709891319275, 1.126454472541809, 1.1201269626617432, 1.1190705299377441, 1.1171029806137085, 1.1149928569793701, 1.1151126623153687, 1.1112595796585083, 1.1125296354293823, 1.1077964305877686, 1.1051040887832642, 1.1064714193344116, 1.103173851966858, 1.1041756868362427, 1.103903889656067, 1.100391149520874, 1.0957462787628174, 1.0977692604064941, 1.0970730781555176, 1.0967293977737427, 1.0966079235076904, 1.095621943473816, 1.091863989830017, 1.1052709817886353, 1.0959060192108154, 1.1044176816940308, 1.0954198837280273, 1.0979585647583008, 1.1005574464797974], 'val_accuracy': [0.4954751133918762, 0.5463801026344299, 0.5316742062568665, 0.5384615659713745, 0.5429864525794983, 0.5486425161361694, 0.5418552160263062, 0.5509049892425537, 0.5531674027442932, 0.5520362257957458, 0.557692289352417, 0.5712669491767883, 0.5678732991218567, 0.5735294222831726, 0.5723981857299805, 0.564479649066925, 0.570135772228241, 0.5678732991218567, 0.5735294222831726, 0.5746606588363647, 0.570135772228241, 0.570135772228241, 0.5678732991218567, 0.570135772228241, 0.5769230723381042, 0.5769230723381042, 0.5757918357849121, 0.5791855454444885, 0.5769230723381042, 0.5791855454444885, 0.5791855454444885, 0.587104082107544, 0.5825791954994202, 0.5859728455543518, 0.5904977321624756, 0.5904977321624756, 0.587104082107544, 0.5916289687156677, 0.581447958946228, 0.5859728455543518, 0.587104082107544, 0.587104082107544, 0.5950226187705994, 0.5972850918769836, 0.5859728455543518, 0.5938913822174072, 0.587104082107544, 0.5961538553237915, 0.6018099784851074, 0.5927602052688599, 0.5972850918769836, 0.6029411554336548, 0.5938913822174072, 0.5972850918769836, 0.6018099784851074, 0.6040723919868469, 0.6018099784851074, 0.5995475053787231, 0.6006787419319153, 0.6085972785949707, 0.6018099784851074, 0.6006787419319153, 0.6040723919868469, 0.6085972785949707, 0.6142534017562866, 0.6052036285400391, 0.6097285151481628, 0.6085972785949707, 0.6119909286499023, 0.6029411554336548, 0.6165158152580261, 0.6085972785949707, 0.6018099784851074, 0.6074660420417786, 0.6052036285400391, 0.6040723919868469, 0.6131221652030945, 0.6052036285400391, 0.6074660420417786, 0.6165158152580261, 0.6074660420417786, 0.6153846383094788, 0.6142534017562866, 0.6153846383094788, 0.6165158152580261, 0.610859751701355, 0.6165158152580261, 0.6165158152580261, 0.6165158152580261, 0.6176470518112183, 0.6153846383094788, 0.6119909286499023, 0.6052036285400391, 0.6187782883644104, 0.6097285151481628, 0.6085972785949707, 0.610859751701355, 0.6119909286499023, 0.610859751701355, 0.6142534017562866]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 7s 46ms/step - loss: 1.4303 - accuracy: 0.5191 - val_loss: 1.4271 - val_accuracy: 0.5857\n","Epoch 2/100\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 0s 13ms/step - loss: 1.4228 - accuracy: 0.5403 - val_loss: 1.4205 - val_accuracy: 0.5382\n","Epoch 3/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.4153 - accuracy: 0.5527 - val_loss: 1.4140 - val_accuracy: 0.5403\n","Epoch 4/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.4074 - accuracy: 0.5550 - val_loss: 1.4075 - val_accuracy: 0.5351\n","Epoch 5/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3995 - accuracy: 0.5628 - val_loss: 1.4010 - val_accuracy: 0.5496\n","Epoch 6/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3915 - accuracy: 0.5584 - val_loss: 1.3946 - val_accuracy: 0.5496\n","Epoch 7/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3840 - accuracy: 0.5659 - val_loss: 1.3882 - val_accuracy: 0.5579\n","Epoch 8/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3768 - accuracy: 0.5669 - val_loss: 1.3817 - val_accuracy: 0.5671\n","Epoch 9/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3702 - accuracy: 0.5721 - val_loss: 1.3754 - val_accuracy: 0.5661\n","Epoch 10/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3636 - accuracy: 0.5698 - val_loss: 1.3691 - val_accuracy: 0.5661\n","Epoch 11/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.3571 - accuracy: 0.5708 - val_loss: 1.3628 - val_accuracy: 0.5702\n","Epoch 12/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3509 - accuracy: 0.5765 - val_loss: 1.3566 - val_accuracy: 0.5702\n","Epoch 13/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.3444 - accuracy: 0.5791 - val_loss: 1.3504 - val_accuracy: 0.5754\n","Epoch 14/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3381 - accuracy: 0.5796 - val_loss: 1.3440 - val_accuracy: 0.5764\n","Epoch 15/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3317 - accuracy: 0.5765 - val_loss: 1.3379 - val_accuracy: 0.5775\n","Epoch 16/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3256 - accuracy: 0.5796 - val_loss: 1.3315 - val_accuracy: 0.5806\n","Epoch 17/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3190 - accuracy: 0.5822 - val_loss: 1.3253 - val_accuracy: 0.5764\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3128 - accuracy: 0.5845 - val_loss: 1.3189 - val_accuracy: 0.5795\n","Epoch 19/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.3061 - accuracy: 0.5910 - val_loss: 1.3127 - val_accuracy: 0.5878\n","Epoch 20/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2999 - accuracy: 0.5917 - val_loss: 1.3063 - val_accuracy: 0.5857\n","Epoch 21/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2928 - accuracy: 0.5917 - val_loss: 1.2998 - val_accuracy: 0.5826\n","Epoch 22/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.2863 - accuracy: 0.5946 - val_loss: 1.2935 - val_accuracy: 0.5919\n","Epoch 23/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2794 - accuracy: 0.5982 - val_loss: 1.2874 - val_accuracy: 0.5961\n","Epoch 24/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2721 - accuracy: 0.6039 - val_loss: 1.2819 - val_accuracy: 0.5971\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2659 - accuracy: 0.6016 - val_loss: 1.2745 - val_accuracy: 0.5919\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2598 - accuracy: 0.6096 - val_loss: 1.2683 - val_accuracy: 0.5950\n","Epoch 27/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.2531 - accuracy: 0.6129 - val_loss: 1.2647 - val_accuracy: 0.5992\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2468 - accuracy: 0.6103 - val_loss: 1.2567 - val_accuracy: 0.5950\n","Epoch 29/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2405 - accuracy: 0.6121 - val_loss: 1.2519 - val_accuracy: 0.5992\n","Epoch 30/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2346 - accuracy: 0.6152 - val_loss: 1.2470 - val_accuracy: 0.6012\n","Epoch 31/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.2281 - accuracy: 0.6158 - val_loss: 1.2438 - val_accuracy: 0.6054\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2242 - accuracy: 0.6204 - val_loss: 1.2379 - val_accuracy: 0.6054\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2186 - accuracy: 0.6150 - val_loss: 1.2320 - val_accuracy: 0.6033\n","Epoch 34/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.2100 - accuracy: 0.6248 - val_loss: 1.2237 - val_accuracy: 0.6002\n","Epoch 35/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.2074 - accuracy: 0.6207 - val_loss: 1.2197 - val_accuracy: 0.5981\n","Epoch 36/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2013 - accuracy: 0.6264 - val_loss: 1.2203 - val_accuracy: 0.6095\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1954 - accuracy: 0.6207 - val_loss: 1.2128 - val_accuracy: 0.6043\n","Epoch 38/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1902 - accuracy: 0.6274 - val_loss: 1.2076 - val_accuracy: 0.6074\n","Epoch 39/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1841 - accuracy: 0.6274 - val_loss: 1.2005 - val_accuracy: 0.5992\n","Epoch 40/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1792 - accuracy: 0.6256 - val_loss: 1.1969 - val_accuracy: 0.5961\n","Epoch 41/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.1754 - accuracy: 0.6245 - val_loss: 1.1996 - val_accuracy: 0.6105\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1722 - accuracy: 0.6266 - val_loss: 1.1920 - val_accuracy: 0.5992\n","Epoch 43/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1662 - accuracy: 0.6251 - val_loss: 1.1905 - val_accuracy: 0.6095\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1603 - accuracy: 0.6370 - val_loss: 1.1802 - val_accuracy: 0.6002\n","Epoch 45/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.1548 - accuracy: 0.6320 - val_loss: 1.1849 - val_accuracy: 0.6116\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1512 - accuracy: 0.6375 - val_loss: 1.1782 - val_accuracy: 0.6074\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1457 - accuracy: 0.6367 - val_loss: 1.1691 - val_accuracy: 0.6012\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1408 - accuracy: 0.6323 - val_loss: 1.1679 - val_accuracy: 0.6074\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1345 - accuracy: 0.6385 - val_loss: 1.1661 - val_accuracy: 0.6074\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1317 - accuracy: 0.6455 - val_loss: 1.1628 - val_accuracy: 0.6074\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1254 - accuracy: 0.6491 - val_loss: 1.1575 - val_accuracy: 0.6064\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1220 - accuracy: 0.6455 - val_loss: 1.1540 - val_accuracy: 0.6074\n","Epoch 53/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1132 - accuracy: 0.6483 - val_loss: 1.1491 - val_accuracy: 0.6033\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1122 - accuracy: 0.6452 - val_loss: 1.1481 - val_accuracy: 0.6054\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1049 - accuracy: 0.6475 - val_loss: 1.1453 - val_accuracy: 0.6085\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1011 - accuracy: 0.6506 - val_loss: 1.1454 - val_accuracy: 0.6105\n","Epoch 57/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0989 - accuracy: 0.6556 - val_loss: 1.1411 - val_accuracy: 0.6126\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0915 - accuracy: 0.6545 - val_loss: 1.1389 - val_accuracy: 0.6085\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0854 - accuracy: 0.6607 - val_loss: 1.1333 - val_accuracy: 0.6126\n","Epoch 60/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0818 - accuracy: 0.6576 - val_loss: 1.1314 - val_accuracy: 0.6116\n","Epoch 61/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0776 - accuracy: 0.6584 - val_loss: 1.1265 - val_accuracy: 0.6188\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0717 - accuracy: 0.6623 - val_loss: 1.1230 - val_accuracy: 0.6116\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0669 - accuracy: 0.6628 - val_loss: 1.1216 - val_accuracy: 0.6126\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0601 - accuracy: 0.6654 - val_loss: 1.1157 - val_accuracy: 0.6136\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0554 - accuracy: 0.6651 - val_loss: 1.1150 - val_accuracy: 0.6136\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0515 - accuracy: 0.6623 - val_loss: 1.1195 - val_accuracy: 0.6085\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0488 - accuracy: 0.6664 - val_loss: 1.1113 - val_accuracy: 0.6136\n","Epoch 68/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0438 - accuracy: 0.6693 - val_loss: 1.1132 - val_accuracy: 0.6054\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0355 - accuracy: 0.6819 - val_loss: 1.1097 - val_accuracy: 0.6095\n","Epoch 70/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0302 - accuracy: 0.6742 - val_loss: 1.1068 - val_accuracy: 0.6054\n","Epoch 71/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0229 - accuracy: 0.6873 - val_loss: 1.1014 - val_accuracy: 0.6167\n","Epoch 72/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0183 - accuracy: 0.6796 - val_loss: 1.1088 - val_accuracy: 0.5992\n","Epoch 73/100\n","31/31 [==============================] - 1s 29ms/step - loss: 1.0147 - accuracy: 0.6855 - val_loss: 1.1008 - val_accuracy: 0.6219\n","Epoch 74/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0075 - accuracy: 0.6873 - val_loss: 1.0979 - val_accuracy: 0.6126\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0011 - accuracy: 0.6938 - val_loss: 1.1045 - val_accuracy: 0.6054\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9967 - accuracy: 0.6894 - val_loss: 1.0977 - val_accuracy: 0.6054\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9898 - accuracy: 0.7010 - val_loss: 1.0946 - val_accuracy: 0.6116\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9888 - accuracy: 0.6922 - val_loss: 1.0955 - val_accuracy: 0.6074\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9843 - accuracy: 0.6928 - val_loss: 1.0966 - val_accuracy: 0.6085\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9710 - accuracy: 0.7000 - val_loss: 1.0996 - val_accuracy: 0.6074\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9703 - accuracy: 0.7041 - val_loss: 1.0976 - val_accuracy: 0.6054\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9659 - accuracy: 0.6987 - val_loss: 1.0913 - val_accuracy: 0.6126\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9553 - accuracy: 0.7119 - val_loss: 1.0907 - val_accuracy: 0.6074\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9527 - accuracy: 0.7158 - val_loss: 1.0881 - val_accuracy: 0.6136\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9507 - accuracy: 0.7041 - val_loss: 1.0927 - val_accuracy: 0.5981\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9443 - accuracy: 0.7178 - val_loss: 1.0894 - val_accuracy: 0.6116\n","Epoch 87/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9371 - accuracy: 0.7207 - val_loss: 1.0876 - val_accuracy: 0.6043\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9393 - accuracy: 0.7124 - val_loss: 1.0973 - val_accuracy: 0.5992\n","Epoch 89/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9277 - accuracy: 0.7220 - val_loss: 1.0880 - val_accuracy: 0.6105\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9255 - accuracy: 0.7158 - val_loss: 1.0869 - val_accuracy: 0.6105\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9168 - accuracy: 0.7212 - val_loss: 1.0926 - val_accuracy: 0.6085\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9136 - accuracy: 0.7276 - val_loss: 1.0888 - val_accuracy: 0.6074\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9073 - accuracy: 0.7310 - val_loss: 1.0959 - val_accuracy: 0.6064\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9040 - accuracy: 0.7289 - val_loss: 1.0928 - val_accuracy: 0.6043\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9005 - accuracy: 0.7300 - val_loss: 1.0861 - val_accuracy: 0.6012\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8971 - accuracy: 0.7333 - val_loss: 1.0893 - val_accuracy: 0.6074\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8880 - accuracy: 0.7333 - val_loss: 1.0966 - val_accuracy: 0.6064\n","Epoch 98/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8917 - accuracy: 0.7302 - val_loss: 1.0967 - val_accuracy: 0.6012\n","Epoch 99/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8804 - accuracy: 0.7388 - val_loss: 1.0975 - val_accuracy: 0.6043\n","Epoch 100/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8736 - accuracy: 0.7354 - val_loss: 1.1011 - val_accuracy: 0.6012\n","{'loss': [1.430289626121521, 1.422843337059021, 1.415311574935913, 1.4074463844299316, 1.3994947671890259, 1.3914892673492432, 1.3839800357818604, 1.3768324851989746, 1.3702343702316284, 1.3635928630828857, 1.3571443557739258, 1.3509055376052856, 1.344447374343872, 1.338140845298767, 1.331676721572876, 1.32562255859375, 1.3190264701843262, 1.3128286600112915, 1.3060911893844604, 1.2998647689819336, 1.2927899360656738, 1.2863026857376099, 1.279352068901062, 1.2720978260040283, 1.2658928632736206, 1.2598377466201782, 1.2531001567840576, 1.2467823028564453, 1.240525245666504, 1.2345863580703735, 1.2281477451324463, 1.2241657972335815, 1.2186254262924194, 1.2100237607955933, 1.2074482440948486, 1.201332688331604, 1.1954128742218018, 1.190159797668457, 1.1841042041778564, 1.1791794300079346, 1.175419569015503, 1.1721842288970947, 1.1662379503250122, 1.1602611541748047, 1.154820203781128, 1.1512197256088257, 1.1456698179244995, 1.1407891511917114, 1.1345140933990479, 1.1317001581192017, 1.125383973121643, 1.122049331665039, 1.1132071018218994, 1.1122281551361084, 1.1048569679260254, 1.1010658740997314, 1.0988667011260986, 1.0914629697799683, 1.085411548614502, 1.0818341970443726, 1.0775877237319946, 1.0717363357543945, 1.0669013261795044, 1.060078501701355, 1.0554176568984985, 1.0514724254608154, 1.0487650632858276, 1.0438148975372314, 1.035493016242981, 1.0301896333694458, 1.0229171514511108, 1.018325924873352, 1.0147371292114258, 1.0075366497039795, 1.0011059045791626, 0.9967179894447327, 0.9898213148117065, 0.9887627959251404, 0.9842671155929565, 0.97096848487854, 0.9703246355056763, 0.9659364819526672, 0.9553025960922241, 0.9527252912521362, 0.9506593942642212, 0.9442757964134216, 0.9371378421783447, 0.939263105392456, 0.9277408123016357, 0.9254880547523499, 0.9167900681495667, 0.9135634303092957, 0.9072870016098022, 0.9040476083755493, 0.9004858732223511, 0.8971002101898193, 0.8879994750022888, 0.8917432427406311, 0.8803688883781433, 0.8736487030982971], 'accuracy': [0.5191214680671692, 0.5403100848197937, 0.55271315574646, 0.5550387501716614, 0.5627906918525696, 0.5583979487419128, 0.565891444683075, 0.566925048828125, 0.5720930099487305, 0.569767415523529, 0.5708010196685791, 0.576485812664032, 0.5790697932243347, 0.5795865654945374, 0.576485812664032, 0.5795865654945374, 0.5821705460548401, 0.5844961404800415, 0.5909560918807983, 0.5917312502861023, 0.5917312502861023, 0.5945736169815063, 0.5981912016868591, 0.603875994682312, 0.6015504002571106, 0.6095607280731201, 0.6129198670387268, 0.6103359460830688, 0.6121447086334229, 0.6152454614639282, 0.6157622933387756, 0.6204134225845337, 0.6149870753288269, 0.6248062252998352, 0.620671808719635, 0.6263566017150879, 0.620671808719635, 0.6273902058601379, 0.6273902058601379, 0.6255813837051392, 0.6245477795600891, 0.6266149878501892, 0.6250646114349365, 0.6369509100914001, 0.632041335105896, 0.6374676823616028, 0.6366925239562988, 0.6322997212409973, 0.6385012865066528, 0.6454780101776123, 0.6490955948829651, 0.6454780101776123, 0.6483204364776611, 0.645219624042511, 0.6475452184677124, 0.6506459712982178, 0.6555555462837219, 0.6545219421386719, 0.6607235074043274, 0.657622754573822, 0.658397912979126, 0.6622738838195801, 0.6627907156944275, 0.6653746962547302, 0.6651162505149841, 0.6622738838195801, 0.6664082407951355, 0.6692506670951843, 0.6819121241569519, 0.6741601824760437, 0.6873385310173035, 0.6795865893363953, 0.6855297088623047, 0.6873385310173035, 0.6937984228134155, 0.6894056797027588, 0.7010335922241211, 0.6922480463981628, 0.6927648782730103, 0.699999988079071, 0.7041343450546265, 0.6987079977989197, 0.7118862867355347, 0.7157622575759888, 0.7041343450546265, 0.7178294658660889, 0.7206718325614929, 0.7124031186103821, 0.7219638228416443, 0.7157622575759888, 0.7211886048316956, 0.7276485562324524, 0.7310077548027039, 0.7289405465126038, 0.7299741506576538, 0.7333333492279053, 0.7333333492279053, 0.7302325367927551, 0.7387596964836121, 0.7354004979133606], 'val_loss': [1.4271199703216553, 1.420515537261963, 1.4139702320098877, 1.4074865579605103, 1.4010244607925415, 1.394592046737671, 1.388170838356018, 1.3817108869552612, 1.3754113912582397, 1.3691191673278809, 1.3628125190734863, 1.3565759658813477, 1.3503636121749878, 1.3439902067184448, 1.3378710746765137, 1.3314539194107056, 1.3253452777862549, 1.318936824798584, 1.312726378440857, 1.306328535079956, 1.299835205078125, 1.2934600114822388, 1.2873947620391846, 1.2818706035614014, 1.2745146751403809, 1.2682617902755737, 1.2647061347961426, 1.2566967010498047, 1.2519115209579468, 1.2469892501831055, 1.2438037395477295, 1.2378956079483032, 1.2319906949996948, 1.2237069606781006, 1.2197264432907104, 1.220345377922058, 1.2128181457519531, 1.207585096359253, 1.2004694938659668, 1.1969281435012817, 1.1996212005615234, 1.1920229196548462, 1.1904963254928589, 1.180209994316101, 1.1849048137664795, 1.1781905889511108, 1.1690949201583862, 1.167931318283081, 1.1660914421081543, 1.1627717018127441, 1.157483458518982, 1.153956651687622, 1.149117350578308, 1.1481125354766846, 1.1452805995941162, 1.14535653591156, 1.141120433807373, 1.138880968093872, 1.1333038806915283, 1.131433367729187, 1.126535415649414, 1.1229912042617798, 1.1215969324111938, 1.1156704425811768, 1.1149919033050537, 1.1195383071899414, 1.1113479137420654, 1.113211750984192, 1.1096580028533936, 1.1068453788757324, 1.1014025211334229, 1.108789086341858, 1.1007827520370483, 1.0979236364364624, 1.1045222282409668, 1.0977468490600586, 1.0945712327957153, 1.0954794883728027, 1.0966075658798218, 1.099586844444275, 1.0975756645202637, 1.091284155845642, 1.0906970500946045, 1.088135004043579, 1.0926802158355713, 1.0894320011138916, 1.08763587474823, 1.0973000526428223, 1.0879933834075928, 1.0868664979934692, 1.092552900314331, 1.0887902975082397, 1.095925211906433, 1.0927786827087402, 1.0860766172409058, 1.0892857313156128, 1.0965790748596191, 1.0966858863830566, 1.0974681377410889, 1.1011395454406738], 'val_accuracy': [0.58574378490448, 0.538223147392273, 0.5402892827987671, 0.5351239442825317, 0.5495867729187012, 0.5495867729187012, 0.557851254940033, 0.567148745059967, 0.56611567735672, 0.56611567735672, 0.5702479481697083, 0.5702479481697083, 0.5754132270812988, 0.5764462947845459, 0.577479362487793, 0.5805785059928894, 0.5764462947845459, 0.5795454382896423, 0.5878099203109741, 0.58574378490448, 0.5826446413993835, 0.5919421315193176, 0.5960744023323059, 0.5971074104309082, 0.5919421315193176, 0.5950413346290588, 0.5991735458374023, 0.5950413346290588, 0.5991735458374023, 0.6012396812438965, 0.60537189245224, 0.60537189245224, 0.6033057570457458, 0.6002066135406494, 0.5981404781341553, 0.6095041036605835, 0.6043388247489929, 0.6074380278587341, 0.5991735458374023, 0.5960744023323059, 0.6105371713638306, 0.5991735458374023, 0.6095041036605835, 0.6002066135406494, 0.6115702390670776, 0.6074380278587341, 0.6012396812438965, 0.6074380278587341, 0.6074380278587341, 0.6074380278587341, 0.6064049601554871, 0.6074380278587341, 0.6033057570457458, 0.60537189245224, 0.6084710955619812, 0.6105371713638306, 0.6126033067703247, 0.6084710955619812, 0.6126033067703247, 0.6115702390670776, 0.6188016533851624, 0.6115702390670776, 0.6126033067703247, 0.6136363744735718, 0.6136363744735718, 0.6084710955619812, 0.6136363744735718, 0.60537189245224, 0.6095041036605835, 0.60537189245224, 0.6167355179786682, 0.5991735458374023, 0.6219007968902588, 0.6126033067703247, 0.60537189245224, 0.60537189245224, 0.6115702390670776, 0.6074380278587341, 0.6084710955619812, 0.6074380278587341, 0.60537189245224, 0.6126033067703247, 0.6074380278587341, 0.6136363744735718, 0.5981404781341553, 0.6115702390670776, 0.6043388247489929, 0.5991735458374023, 0.6105371713638306, 0.6105371713638306, 0.6084710955619812, 0.6074380278587341, 0.6064049601554871, 0.6043388247489929, 0.6012396812438965, 0.6074380278587341, 0.6064049601554871, 0.6012396812438965, 0.6043388247489929, 0.6012396812438965]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 0.9589 - accuracy: 0.6982"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 6s 49ms/step - loss: 0.9589 - accuracy: 0.6985 - val_loss: 1.0565 - val_accuracy: 0.5312\n","Epoch 2/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9460 - accuracy: 0.7055 - val_loss: 1.0534 - val_accuracy: 0.5323\n","Epoch 3/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9400 - accuracy: 0.7107 - val_loss: 1.0512 - val_accuracy: 0.5323\n","Epoch 4/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.9349 - accuracy: 0.7042 - val_loss: 1.0471 - val_accuracy: 0.5334\n","Epoch 5/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9284 - accuracy: 0.7080 - val_loss: 1.0395 - val_accuracy: 0.5539\n","Epoch 6/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9254 - accuracy: 0.7112 - val_loss: 1.0374 - val_accuracy: 0.5496\n","Epoch 7/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9204 - accuracy: 0.7147 - val_loss: 1.0320 - val_accuracy: 0.5625\n","Epoch 8/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9161 - accuracy: 0.7096 - val_loss: 1.0265 - val_accuracy: 0.5733\n","Epoch 9/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.9128 - accuracy: 0.7128 - val_loss: 1.0228 - val_accuracy: 0.5744\n","Epoch 10/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.9028 - accuracy: 0.7228 - val_loss: 1.0137 - val_accuracy: 0.5830\n","Epoch 11/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.9019 - accuracy: 0.7188 - val_loss: 1.0059 - val_accuracy: 0.6088\n","Epoch 12/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8973 - accuracy: 0.7293 - val_loss: 1.0014 - val_accuracy: 0.6067\n","Epoch 13/100\n","29/29 [==============================] - 1s 45ms/step - loss: 0.8966 - accuracy: 0.7198 - val_loss: 0.9976 - val_accuracy: 0.6099\n","Epoch 14/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.8884 - accuracy: 0.7252 - val_loss: 0.9827 - val_accuracy: 0.6444\n","Epoch 15/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8877 - accuracy: 0.7147 - val_loss: 0.9807 - val_accuracy: 0.6304\n","Epoch 16/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.8826 - accuracy: 0.7266 - val_loss: 0.9712 - val_accuracy: 0.6455\n","Epoch 17/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.8751 - accuracy: 0.7360 - val_loss: 0.9581 - val_accuracy: 0.6649\n","Epoch 18/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8723 - accuracy: 0.7317 - val_loss: 0.9549 - val_accuracy: 0.6627\n","Epoch 19/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8685 - accuracy: 0.7293 - val_loss: 0.9520 - val_accuracy: 0.6649\n","Epoch 20/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8634 - accuracy: 0.7349 - val_loss: 0.9417 - val_accuracy: 0.6606\n","Epoch 21/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8604 - accuracy: 0.7314 - val_loss: 0.9373 - val_accuracy: 0.6595\n","Epoch 22/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8616 - accuracy: 0.7301 - val_loss: 0.9400 - val_accuracy: 0.6616\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8617 - accuracy: 0.7306 - val_loss: 0.9343 - val_accuracy: 0.6649\n","Epoch 24/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8493 - accuracy: 0.7425 - val_loss: 0.9291 - val_accuracy: 0.6595\n","Epoch 25/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8433 - accuracy: 0.7457 - val_loss: 0.9303 - val_accuracy: 0.6670\n","Epoch 26/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8401 - accuracy: 0.7379 - val_loss: 0.9293 - val_accuracy: 0.6692\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8363 - accuracy: 0.7446 - val_loss: 0.9340 - val_accuracy: 0.6616\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8368 - accuracy: 0.7449 - val_loss: 0.9315 - val_accuracy: 0.6692\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8375 - accuracy: 0.7365 - val_loss: 0.9326 - val_accuracy: 0.6616\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8231 - accuracy: 0.7452 - val_loss: 0.9287 - val_accuracy: 0.6681\n","Epoch 31/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8234 - accuracy: 0.7478 - val_loss: 0.9295 - val_accuracy: 0.6659\n","Epoch 32/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8179 - accuracy: 0.7492 - val_loss: 0.9306 - val_accuracy: 0.6659\n","Epoch 33/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8150 - accuracy: 0.7557 - val_loss: 0.9350 - val_accuracy: 0.6649\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8203 - accuracy: 0.7478 - val_loss: 0.9332 - val_accuracy: 0.6692\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8147 - accuracy: 0.7484 - val_loss: 0.9303 - val_accuracy: 0.6692\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8046 - accuracy: 0.7570 - val_loss: 0.9301 - val_accuracy: 0.6573\n","Epoch 37/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8007 - accuracy: 0.7478 - val_loss: 0.9303 - val_accuracy: 0.6767\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7998 - accuracy: 0.7584 - val_loss: 0.9304 - val_accuracy: 0.6756\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7937 - accuracy: 0.7586 - val_loss: 0.9300 - val_accuracy: 0.6681\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7876 - accuracy: 0.7616 - val_loss: 0.9439 - val_accuracy: 0.6606\n","Epoch 41/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7842 - accuracy: 0.7629 - val_loss: 0.9350 - val_accuracy: 0.6606\n","Epoch 42/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7807 - accuracy: 0.7670 - val_loss: 0.9318 - val_accuracy: 0.6649\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7768 - accuracy: 0.7624 - val_loss: 0.9374 - val_accuracy: 0.6627\n","Epoch 44/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7750 - accuracy: 0.7699 - val_loss: 0.9311 - val_accuracy: 0.6606\n","Epoch 45/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7704 - accuracy: 0.7702 - val_loss: 0.9343 - val_accuracy: 0.6616\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7682 - accuracy: 0.7718 - val_loss: 0.9330 - val_accuracy: 0.6767\n","Epoch 47/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7676 - accuracy: 0.7686 - val_loss: 0.9339 - val_accuracy: 0.6713\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7600 - accuracy: 0.7756 - val_loss: 0.9438 - val_accuracy: 0.6541\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7634 - accuracy: 0.7645 - val_loss: 0.9450 - val_accuracy: 0.6616\n","Epoch 50/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7576 - accuracy: 0.7651 - val_loss: 0.9400 - val_accuracy: 0.6659\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7431 - accuracy: 0.7850 - val_loss: 0.9333 - val_accuracy: 0.6713\n","Epoch 52/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7510 - accuracy: 0.7756 - val_loss: 0.9373 - val_accuracy: 0.6670\n","Epoch 53/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7373 - accuracy: 0.7823 - val_loss: 0.9373 - val_accuracy: 0.6649\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7345 - accuracy: 0.7783 - val_loss: 0.9458 - val_accuracy: 0.6627\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7326 - accuracy: 0.7775 - val_loss: 0.9546 - val_accuracy: 0.6552\n","Epoch 56/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7300 - accuracy: 0.7796 - val_loss: 0.9397 - val_accuracy: 0.6703\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7316 - accuracy: 0.7853 - val_loss: 0.9339 - val_accuracy: 0.6735\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7301 - accuracy: 0.7831 - val_loss: 0.9418 - val_accuracy: 0.6681\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7244 - accuracy: 0.7802 - val_loss: 0.9496 - val_accuracy: 0.6627\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7249 - accuracy: 0.7839 - val_loss: 0.9438 - val_accuracy: 0.6670\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7200 - accuracy: 0.7931 - val_loss: 0.9446 - val_accuracy: 0.6670\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7166 - accuracy: 0.7893 - val_loss: 0.9505 - val_accuracy: 0.6703\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7115 - accuracy: 0.7866 - val_loss: 0.9412 - val_accuracy: 0.6670\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7097 - accuracy: 0.7877 - val_loss: 0.9447 - val_accuracy: 0.6627\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7047 - accuracy: 0.7899 - val_loss: 0.9433 - val_accuracy: 0.6595\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7001 - accuracy: 0.7931 - val_loss: 0.9518 - val_accuracy: 0.6616\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7020 - accuracy: 0.7915 - val_loss: 0.9416 - val_accuracy: 0.6659\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6942 - accuracy: 0.8020 - val_loss: 0.9562 - val_accuracy: 0.6724\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6991 - accuracy: 0.7909 - val_loss: 0.9415 - val_accuracy: 0.6670\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6906 - accuracy: 0.7942 - val_loss: 0.9470 - val_accuracy: 0.6681\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6804 - accuracy: 0.8066 - val_loss: 0.9470 - val_accuracy: 0.6638\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6851 - accuracy: 0.7996 - val_loss: 0.9467 - val_accuracy: 0.6616\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6759 - accuracy: 0.8025 - val_loss: 0.9502 - val_accuracy: 0.6670\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6751 - accuracy: 0.8095 - val_loss: 0.9506 - val_accuracy: 0.6670\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6726 - accuracy: 0.8117 - val_loss: 0.9617 - val_accuracy: 0.6649\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6692 - accuracy: 0.8125 - val_loss: 0.9546 - val_accuracy: 0.6681\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6669 - accuracy: 0.8060 - val_loss: 0.9580 - val_accuracy: 0.6746\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6611 - accuracy: 0.8211 - val_loss: 0.9569 - val_accuracy: 0.6573\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6576 - accuracy: 0.8179 - val_loss: 0.9498 - val_accuracy: 0.6562\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6558 - accuracy: 0.8114 - val_loss: 0.9662 - val_accuracy: 0.6703\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6555 - accuracy: 0.8117 - val_loss: 0.9605 - val_accuracy: 0.6638\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6537 - accuracy: 0.8117 - val_loss: 0.9674 - val_accuracy: 0.6756\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6492 - accuracy: 0.8125 - val_loss: 0.9636 - val_accuracy: 0.6681\n","Epoch 84/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6439 - accuracy: 0.8192 - val_loss: 0.9741 - val_accuracy: 0.6476\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6511 - accuracy: 0.8163 - val_loss: 0.9867 - val_accuracy: 0.6422\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6349 - accuracy: 0.8209 - val_loss: 0.9651 - val_accuracy: 0.6681\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6430 - accuracy: 0.8198 - val_loss: 0.9663 - val_accuracy: 0.6649\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6275 - accuracy: 0.8268 - val_loss: 0.9771 - val_accuracy: 0.6573\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6288 - accuracy: 0.8327 - val_loss: 0.9801 - val_accuracy: 0.6659\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6242 - accuracy: 0.8254 - val_loss: 0.9674 - val_accuracy: 0.6562\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6293 - accuracy: 0.8171 - val_loss: 0.9860 - val_accuracy: 0.6498\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6190 - accuracy: 0.8322 - val_loss: 0.9685 - val_accuracy: 0.6606\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6162 - accuracy: 0.8281 - val_loss: 0.9980 - val_accuracy: 0.6325\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6133 - accuracy: 0.8260 - val_loss: 0.9803 - val_accuracy: 0.6649\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6131 - accuracy: 0.8343 - val_loss: 0.9773 - val_accuracy: 0.6638\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6037 - accuracy: 0.8351 - val_loss: 0.9925 - val_accuracy: 0.6649\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6025 - accuracy: 0.8338 - val_loss: 0.9933 - val_accuracy: 0.6552\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6038 - accuracy: 0.8314 - val_loss: 0.9953 - val_accuracy: 0.6681\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5953 - accuracy: 0.8429 - val_loss: 0.9960 - val_accuracy: 0.6552\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5926 - accuracy: 0.8354 - val_loss: 0.9862 - val_accuracy: 0.6670\n","{'loss': [0.9589282274246216, 0.9459719657897949, 0.9400481581687927, 0.9349262118339539, 0.9283608794212341, 0.9253808856010437, 0.920393168926239, 0.9160787463188171, 0.9128239750862122, 0.902849555015564, 0.9019222855567932, 0.8972762823104858, 0.8966184258460999, 0.8883942365646362, 0.8877100348472595, 0.8826353549957275, 0.8751217126846313, 0.8722952604293823, 0.8685154914855957, 0.8633989691734314, 0.8604076504707336, 0.8616012930870056, 0.8616601824760437, 0.8493292331695557, 0.8432693481445312, 0.8400570154190063, 0.8362919092178345, 0.8367859125137329, 0.8374659419059753, 0.8231392502784729, 0.8233949542045593, 0.8179485201835632, 0.8150229454040527, 0.8202691674232483, 0.814723789691925, 0.8045806288719177, 0.8007373809814453, 0.7997800707817078, 0.7937268614768982, 0.7876429557800293, 0.7842262983322144, 0.7806578278541565, 0.7768452763557434, 0.7750034332275391, 0.7703967690467834, 0.7681500911712646, 0.7676383852958679, 0.7600475549697876, 0.763425350189209, 0.7575783729553223, 0.7430526614189148, 0.7510170936584473, 0.737334132194519, 0.7345367670059204, 0.7325511574745178, 0.7299936413764954, 0.7315611839294434, 0.7301243543624878, 0.7243583798408508, 0.7248624563217163, 0.7200213670730591, 0.7165769934654236, 0.7115108370780945, 0.7097300887107849, 0.7047078609466553, 0.7001051306724548, 0.7020224928855896, 0.6941565275192261, 0.6991112232208252, 0.6905894875526428, 0.6804257035255432, 0.6851017475128174, 0.6759045720100403, 0.6750810742378235, 0.6725996732711792, 0.669221043586731, 0.6669281125068665, 0.6610894203186035, 0.6576066017150879, 0.6557705402374268, 0.6554845571517944, 0.6536961197853088, 0.6491994261741638, 0.6439192295074463, 0.6511183381080627, 0.6348594427108765, 0.6429914832115173, 0.627507746219635, 0.6288464665412903, 0.6242473125457764, 0.629339873790741, 0.61900395154953, 0.6161800622940063, 0.6132509708404541, 0.6131253242492676, 0.603745698928833, 0.6024640202522278, 0.6037741899490356, 0.5953415036201477, 0.5925990343093872], 'accuracy': [0.6985452771186829, 0.7055495977401733, 0.7106680870056152, 0.7042025923728943, 0.7079741358757019, 0.7112069129943848, 0.7147090435028076, 0.709590494632721, 0.7128232717514038, 0.7227909564971924, 0.71875, 0.7292564511299133, 0.7198275923728943, 0.725215494632721, 0.7147090435028076, 0.7265625, 0.735991358757019, 0.7316810488700867, 0.7292564511299133, 0.7349137663841248, 0.7314116358757019, 0.7300646305084229, 0.7306034564971924, 0.7424569129943848, 0.7456896305084229, 0.7378771305084229, 0.7446120977401733, 0.7448814511299133, 0.7365301847457886, 0.7451508641242981, 0.7478448152542114, 0.7491918206214905, 0.7556573152542114, 0.7478448152542114, 0.748383641242981, 0.7570043206214905, 0.7478448152542114, 0.7583512663841248, 0.7586206793785095, 0.7615840435028076, 0.7629310488700867, 0.766972005367279, 0.7623922228813171, 0.7699353694915771, 0.7702047228813171, 0.771821141242981, 0.7685883641242981, 0.7755926847457886, 0.7645474076271057, 0.7650862336158752, 0.7850215435028076, 0.7755926847457886, 0.7823275923728943, 0.7782866358757019, 0.7774784564971924, 0.779633641242981, 0.7852909564971924, 0.7831357717514038, 0.7801724076271057, 0.7839439511299133, 0.7931034564971924, 0.7893319129943848, 0.7866379022598267, 0.787715494632721, 0.7898706793785095, 0.7931034564971924, 0.7914870977401733, 0.8019935488700867, 0.7909482717514038, 0.7941810488700867, 0.8065732717514038, 0.7995689511299133, 0.8025323152542114, 0.8095366358757019, 0.8116918206214905, 0.8125, 0.806034505367279, 0.8211206793785095, 0.8178879022598267, 0.8114224076271057, 0.8116918206214905, 0.8116918206214905, 0.8125, 0.8192349076271057, 0.8162715435028076, 0.8208512663841248, 0.8197737336158752, 0.826777994632721, 0.8327047228813171, 0.8254310488700867, 0.8170797228813171, 0.8321659564971924, 0.828125, 0.8259698152542114, 0.834321141242981, 0.8351293206214905, 0.8337823152542114, 0.8313577771186829, 0.8429418206214905, 0.8353987336158752], 'val_loss': [1.056493878364563, 1.053440809249878, 1.051236867904663, 1.0470796823501587, 1.039482831954956, 1.0374146699905396, 1.0319504737854004, 1.0265434980392456, 1.0227534770965576, 1.0137461423873901, 1.0058645009994507, 1.0013543367385864, 0.9975986480712891, 0.9826539158821106, 0.980696976184845, 0.9712017774581909, 0.958060085773468, 0.9549189805984497, 0.9519579410552979, 0.9417425990104675, 0.9372662305831909, 0.9399762749671936, 0.9342732429504395, 0.929092526435852, 0.930303692817688, 0.929347574710846, 0.9340122938156128, 0.9314823150634766, 0.9326104521751404, 0.9287481904029846, 0.929473340511322, 0.9305523037910461, 0.9350031614303589, 0.9331951141357422, 0.9302515983581543, 0.9301245212554932, 0.9303016662597656, 0.9303869605064392, 0.9299845695495605, 0.9438527226448059, 0.9349628686904907, 0.9318166375160217, 0.9374061226844788, 0.931053876876831, 0.9343252778053284, 0.9329581260681152, 0.9339084625244141, 0.9437828063964844, 0.944999635219574, 0.9400471448898315, 0.9333036541938782, 0.937285840511322, 0.9373282194137573, 0.9458150267601013, 0.95460045337677, 0.9397303462028503, 0.9338781833648682, 0.9418203234672546, 0.9496057033538818, 0.9438496232032776, 0.9446059465408325, 0.9505063891410828, 0.9411559104919434, 0.9446779489517212, 0.9432895183563232, 0.9517525434494019, 0.9415899515151978, 0.9561569690704346, 0.9415199756622314, 0.9469596147537231, 0.9469524025917053, 0.9467463493347168, 0.9502342939376831, 0.950609564781189, 0.9617320895195007, 0.9546339511871338, 0.9579644203186035, 0.9568697214126587, 0.9497612118721008, 0.9662403464317322, 0.9604769945144653, 0.9674311876296997, 0.9636270999908447, 0.9740532040596008, 0.9866819977760315, 0.9651481509208679, 0.9662657380104065, 0.9771166443824768, 0.9800978302955627, 0.9673569202423096, 0.986035943031311, 0.9684628844261169, 0.9980489611625671, 0.9802670478820801, 0.9772669076919556, 0.9924633502960205, 0.9932613372802734, 0.9953348636627197, 0.9959830641746521, 0.9861553311347961], 'val_accuracy': [0.53125, 0.5323275923728943, 0.5323275923728943, 0.5334051847457886, 0.5538793206214905, 0.5495689511299133, 0.5625, 0.5732758641242981, 0.5743534564971924, 0.5829741358757019, 0.6088362336158752, 0.6066810488700867, 0.6099137663841248, 0.6443965435028076, 0.6303879022598267, 0.6454741358757019, 0.6648706793785095, 0.662715494632721, 0.6648706793785095, 0.6605603694915771, 0.6594827771186829, 0.6616379022598267, 0.6648706793785095, 0.6594827771186829, 0.6670258641242981, 0.6691810488700867, 0.6616379022598267, 0.6691810488700867, 0.6616379022598267, 0.6681034564971924, 0.6659482717514038, 0.6659482717514038, 0.6648706793785095, 0.6691810488700867, 0.6691810488700867, 0.6573275923728943, 0.6767241358757019, 0.6756465435028076, 0.6681034564971924, 0.6605603694915771, 0.6605603694915771, 0.6648706793785095, 0.662715494632721, 0.6605603694915771, 0.6616379022598267, 0.6767241358757019, 0.6713362336158752, 0.6540948152542114, 0.6616379022598267, 0.6659482717514038, 0.6713362336158752, 0.6670258641242981, 0.6648706793785095, 0.662715494632721, 0.6551724076271057, 0.670258641242981, 0.673491358757019, 0.6681034564971924, 0.662715494632721, 0.6670258641242981, 0.6670258641242981, 0.670258641242981, 0.6670258641242981, 0.662715494632721, 0.6594827771186829, 0.6616379022598267, 0.6659482717514038, 0.6724137663841248, 0.6670258641242981, 0.6681034564971924, 0.6637930870056152, 0.6616379022598267, 0.6670258641242981, 0.6670258641242981, 0.6648706793785095, 0.6681034564971924, 0.6745689511299133, 0.6573275923728943, 0.65625, 0.670258641242981, 0.6637930870056152, 0.6756465435028076, 0.6681034564971924, 0.6476293206214905, 0.642241358757019, 0.6681034564971924, 0.6648706793785095, 0.6573275923728943, 0.6659482717514038, 0.65625, 0.649784505367279, 0.6605603694915771, 0.6325430870056152, 0.6648706793785095, 0.6637930870056152, 0.6648706793785095, 0.6551724076271057, 0.6681034564971924, 0.6551724076271057, 0.6670258641242981]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.9649 - accuracy: 0.6896"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 8s 51ms/step - loss: 0.9654 - accuracy: 0.6859 - val_loss: 1.0619 - val_accuracy: 0.5124\n","Epoch 2/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9489 - accuracy: 0.6941 - val_loss: 1.0611 - val_accuracy: 0.5113\n","Epoch 3/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9433 - accuracy: 0.6998 - val_loss: 1.0582 - val_accuracy: 0.5136\n","Epoch 4/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9380 - accuracy: 0.7026 - val_loss: 1.0516 - val_accuracy: 0.5249\n","Epoch 5/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9352 - accuracy: 0.7051 - val_loss: 1.0487 - val_accuracy: 0.5283\n","Epoch 6/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9338 - accuracy: 0.6998 - val_loss: 1.0461 - val_accuracy: 0.5328\n","Epoch 7/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9266 - accuracy: 0.7026 - val_loss: 1.0416 - val_accuracy: 0.5407\n","Epoch 8/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9196 - accuracy: 0.7066 - val_loss: 1.0370 - val_accuracy: 0.5509\n","Epoch 9/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9209 - accuracy: 0.7100 - val_loss: 1.0381 - val_accuracy: 0.5339\n","Epoch 10/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9168 - accuracy: 0.7083 - val_loss: 1.0220 - val_accuracy: 0.5894\n","Epoch 11/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9152 - accuracy: 0.7074 - val_loss: 1.0207 - val_accuracy: 0.5837\n","Epoch 12/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9103 - accuracy: 0.7134 - val_loss: 1.0213 - val_accuracy: 0.5713\n","Epoch 13/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.9006 - accuracy: 0.7218 - val_loss: 1.0113 - val_accuracy: 0.6018\n","Epoch 14/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8970 - accuracy: 0.7142 - val_loss: 1.0036 - val_accuracy: 0.6018\n","Epoch 15/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.8938 - accuracy: 0.7151 - val_loss: 0.9979 - val_accuracy: 0.6143\n","Epoch 16/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.8902 - accuracy: 0.7131 - val_loss: 0.9908 - val_accuracy: 0.6222\n","Epoch 17/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.8850 - accuracy: 0.7204 - val_loss: 0.9904 - val_accuracy: 0.6233\n","Epoch 18/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.8780 - accuracy: 0.7261 - val_loss: 0.9786 - val_accuracy: 0.6471\n","Epoch 19/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8839 - accuracy: 0.7159 - val_loss: 0.9762 - val_accuracy: 0.6538\n","Epoch 20/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8716 - accuracy: 0.7269 - val_loss: 0.9670 - val_accuracy: 0.6561\n","Epoch 21/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8735 - accuracy: 0.7337 - val_loss: 0.9630 - val_accuracy: 0.6550\n","Epoch 22/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8611 - accuracy: 0.7377 - val_loss: 0.9661 - val_accuracy: 0.6572\n","Epoch 23/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8635 - accuracy: 0.7250 - val_loss: 0.9636 - val_accuracy: 0.6550\n","Epoch 24/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8604 - accuracy: 0.7312 - val_loss: 0.9599 - val_accuracy: 0.6652\n","Epoch 25/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8570 - accuracy: 0.7340 - val_loss: 0.9679 - val_accuracy: 0.6561\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8500 - accuracy: 0.7343 - val_loss: 0.9598 - val_accuracy: 0.6595\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8532 - accuracy: 0.7241 - val_loss: 0.9658 - val_accuracy: 0.6652\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8451 - accuracy: 0.7411 - val_loss: 0.9660 - val_accuracy: 0.6618\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8371 - accuracy: 0.7411 - val_loss: 0.9669 - val_accuracy: 0.6606\n","Epoch 30/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8310 - accuracy: 0.7507 - val_loss: 0.9672 - val_accuracy: 0.6595\n","Epoch 31/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8321 - accuracy: 0.7419 - val_loss: 0.9683 - val_accuracy: 0.6686\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8243 - accuracy: 0.7436 - val_loss: 0.9670 - val_accuracy: 0.6652\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8268 - accuracy: 0.7473 - val_loss: 0.9702 - val_accuracy: 0.6663\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8224 - accuracy: 0.7414 - val_loss: 0.9742 - val_accuracy: 0.6629\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8239 - accuracy: 0.7521 - val_loss: 0.9719 - val_accuracy: 0.6606\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8124 - accuracy: 0.7521 - val_loss: 0.9733 - val_accuracy: 0.6629\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8086 - accuracy: 0.7550 - val_loss: 0.9753 - val_accuracy: 0.6663\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8070 - accuracy: 0.7501 - val_loss: 0.9762 - val_accuracy: 0.6595\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8017 - accuracy: 0.7552 - val_loss: 0.9704 - val_accuracy: 0.6652\n","Epoch 40/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8053 - accuracy: 0.7501 - val_loss: 0.9755 - val_accuracy: 0.6561\n","Epoch 41/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7959 - accuracy: 0.7620 - val_loss: 0.9787 - val_accuracy: 0.6640\n","Epoch 42/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.7936 - accuracy: 0.7615 - val_loss: 0.9791 - val_accuracy: 0.6606\n","Epoch 43/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7837 - accuracy: 0.7674 - val_loss: 0.9735 - val_accuracy: 0.6674\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7878 - accuracy: 0.7668 - val_loss: 0.9831 - val_accuracy: 0.6606\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7863 - accuracy: 0.7632 - val_loss: 0.9733 - val_accuracy: 0.6595\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7762 - accuracy: 0.7725 - val_loss: 0.9778 - val_accuracy: 0.6618\n","Epoch 47/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7791 - accuracy: 0.7694 - val_loss: 0.9701 - val_accuracy: 0.6652\n","Epoch 48/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7723 - accuracy: 0.7683 - val_loss: 0.9828 - val_accuracy: 0.6629\n","Epoch 49/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7684 - accuracy: 0.7671 - val_loss: 0.9875 - val_accuracy: 0.6550\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7700 - accuracy: 0.7731 - val_loss: 0.9909 - val_accuracy: 0.6595\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7667 - accuracy: 0.7711 - val_loss: 0.9774 - val_accuracy: 0.6572\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7570 - accuracy: 0.7765 - val_loss: 0.9856 - val_accuracy: 0.6640\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7517 - accuracy: 0.7787 - val_loss: 0.9884 - val_accuracy: 0.6618\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7486 - accuracy: 0.7832 - val_loss: 0.9880 - val_accuracy: 0.6584\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7480 - accuracy: 0.7770 - val_loss: 1.0025 - val_accuracy: 0.6505\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7464 - accuracy: 0.7759 - val_loss: 0.9848 - val_accuracy: 0.6652\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7453 - accuracy: 0.7728 - val_loss: 0.9964 - val_accuracy: 0.6674\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7373 - accuracy: 0.7745 - val_loss: 0.9910 - val_accuracy: 0.6629\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7344 - accuracy: 0.7807 - val_loss: 0.9926 - val_accuracy: 0.6584\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7291 - accuracy: 0.7878 - val_loss: 0.9983 - val_accuracy: 0.6538\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7267 - accuracy: 0.7878 - val_loss: 0.9980 - val_accuracy: 0.6618\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7252 - accuracy: 0.7821 - val_loss: 0.9920 - val_accuracy: 0.6606\n","Epoch 63/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7190 - accuracy: 0.7895 - val_loss: 0.9948 - val_accuracy: 0.6652\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7178 - accuracy: 0.7835 - val_loss: 0.9974 - val_accuracy: 0.6584\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7127 - accuracy: 0.7929 - val_loss: 1.0047 - val_accuracy: 0.6629\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7098 - accuracy: 0.7866 - val_loss: 1.0029 - val_accuracy: 0.6674\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7073 - accuracy: 0.7932 - val_loss: 1.0086 - val_accuracy: 0.6606\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7042 - accuracy: 0.7909 - val_loss: 1.0027 - val_accuracy: 0.6640\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6984 - accuracy: 0.7957 - val_loss: 1.0202 - val_accuracy: 0.6493\n","Epoch 70/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7014 - accuracy: 0.7934 - val_loss: 1.0128 - val_accuracy: 0.6618\n","Epoch 71/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7006 - accuracy: 0.7835 - val_loss: 1.0127 - val_accuracy: 0.6606\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6960 - accuracy: 0.7982 - val_loss: 1.0040 - val_accuracy: 0.6663\n","Epoch 73/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6848 - accuracy: 0.7988 - val_loss: 1.0165 - val_accuracy: 0.6640\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6829 - accuracy: 0.7994 - val_loss: 1.0163 - val_accuracy: 0.6652\n","Epoch 75/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6821 - accuracy: 0.8005 - val_loss: 1.0176 - val_accuracy: 0.6652\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6728 - accuracy: 0.8042 - val_loss: 1.0147 - val_accuracy: 0.6618\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6775 - accuracy: 0.8031 - val_loss: 1.0235 - val_accuracy: 0.6561\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6780 - accuracy: 0.8014 - val_loss: 1.0280 - val_accuracy: 0.6505\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6710 - accuracy: 0.8036 - val_loss: 1.0242 - val_accuracy: 0.6618\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6750 - accuracy: 0.8002 - val_loss: 1.0226 - val_accuracy: 0.6561\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6609 - accuracy: 0.8093 - val_loss: 1.0264 - val_accuracy: 0.6561\n","Epoch 82/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6697 - accuracy: 0.8113 - val_loss: 1.0277 - val_accuracy: 0.6663\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6665 - accuracy: 0.8031 - val_loss: 1.0263 - val_accuracy: 0.6606\n","Epoch 84/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6540 - accuracy: 0.8132 - val_loss: 1.0284 - val_accuracy: 0.6686\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6588 - accuracy: 0.8084 - val_loss: 1.0324 - val_accuracy: 0.6516\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6475 - accuracy: 0.8166 - val_loss: 1.0282 - val_accuracy: 0.6674\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6490 - accuracy: 0.8172 - val_loss: 1.0527 - val_accuracy: 0.6403\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6496 - accuracy: 0.8155 - val_loss: 1.0441 - val_accuracy: 0.6516\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6542 - accuracy: 0.8115 - val_loss: 1.0393 - val_accuracy: 0.6674\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6338 - accuracy: 0.8229 - val_loss: 1.0339 - val_accuracy: 0.6629\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6337 - accuracy: 0.8192 - val_loss: 1.0328 - val_accuracy: 0.6640\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6339 - accuracy: 0.8158 - val_loss: 1.0367 - val_accuracy: 0.6595\n","Epoch 93/100\n","28/28 [==============================] - 2s 65ms/step - loss: 0.6330 - accuracy: 0.8192 - val_loss: 1.0411 - val_accuracy: 0.6742\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6319 - accuracy: 0.8246 - val_loss: 1.0448 - val_accuracy: 0.6584\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6285 - accuracy: 0.8166 - val_loss: 1.0460 - val_accuracy: 0.6663\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6210 - accuracy: 0.8285 - val_loss: 1.0540 - val_accuracy: 0.6606\n","Epoch 97/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6242 - accuracy: 0.8212 - val_loss: 1.0559 - val_accuracy: 0.6652\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6163 - accuracy: 0.8331 - val_loss: 1.0587 - val_accuracy: 0.6572\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6088 - accuracy: 0.8243 - val_loss: 1.0685 - val_accuracy: 0.6595\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6130 - accuracy: 0.8260 - val_loss: 1.0682 - val_accuracy: 0.6493\n","{'loss': [0.9654449820518494, 0.9489321112632751, 0.943272590637207, 0.9380124807357788, 0.935188889503479, 0.9337936639785767, 0.9266110062599182, 0.9196060299873352, 0.9209235310554504, 0.9168382883071899, 0.9152037501335144, 0.9103367924690247, 0.9005855917930603, 0.896980345249176, 0.8937858939170837, 0.8902165293693542, 0.8850194215774536, 0.8779520988464355, 0.8839333057403564, 0.8716464638710022, 0.8734763860702515, 0.8610601425170898, 0.8634610176086426, 0.8604265451431274, 0.8570164442062378, 0.8500475287437439, 0.8532201647758484, 0.8450832366943359, 0.8370751142501831, 0.8309842944145203, 0.8320838809013367, 0.8242889642715454, 0.8268164396286011, 0.8224301338195801, 0.8238794803619385, 0.8124345541000366, 0.8085682392120361, 0.8070151805877686, 0.8017455339431763, 0.8052670359611511, 0.795945405960083, 0.7936087250709534, 0.7836666703224182, 0.7877936363220215, 0.7862676382064819, 0.7762216925621033, 0.779130220413208, 0.7722680568695068, 0.7684102058410645, 0.7700374722480774, 0.7666715979576111, 0.7569849491119385, 0.7516841292381287, 0.7485697865486145, 0.7480126023292542, 0.7463787198066711, 0.7453481554985046, 0.7372894883155823, 0.7344430685043335, 0.729137659072876, 0.7266701459884644, 0.7251723408699036, 0.7189647555351257, 0.7178431153297424, 0.7127491235733032, 0.7097510695457458, 0.7072826027870178, 0.7042309045791626, 0.69837886095047, 0.7013652324676514, 0.7005705237388611, 0.6960240006446838, 0.6847848296165466, 0.6828826069831848, 0.682125449180603, 0.6728286743164062, 0.6774758100509644, 0.6780491471290588, 0.6710490584373474, 0.6750178337097168, 0.6609000563621521, 0.6697251200675964, 0.6664653420448303, 0.6540228128433228, 0.6588447690010071, 0.6474522948265076, 0.6489868760108948, 0.6495580077171326, 0.6542163491249084, 0.6337626576423645, 0.6337220668792725, 0.6338620185852051, 0.6329712271690369, 0.6319212317466736, 0.6284927129745483, 0.6210070252418518, 0.6242103576660156, 0.6163281798362732, 0.6088432669639587, 0.6129664182662964], 'accuracy': [0.685908317565918, 0.6941143274307251, 0.6997736096382141, 0.702603280544281, 0.7051499485969543, 0.6997736096382141, 0.702603280544281, 0.7065647840499878, 0.709960401058197, 0.70826256275177, 0.7074136734008789, 0.7133559584617615, 0.7218449115753174, 0.7142048478126526, 0.7150537371635437, 0.7130730152130127, 0.7204301357269287, 0.7260894179344177, 0.7159026861190796, 0.7269383072853088, 0.7337294816970825, 0.7376909852027893, 0.7249575257301331, 0.7311828136444092, 0.7340124249458313, 0.7342954277992249, 0.7241086363792419, 0.7410866022109985, 0.7410866022109985, 0.7507073879241943, 0.7419354915618896, 0.7436332702636719, 0.7473118305206299, 0.7413695454597473, 0.7521222233772278, 0.7521222233772278, 0.7549518942832947, 0.7501415014266968, 0.7552348375320435, 0.7501415014266968, 0.7620260119438171, 0.7614601254463196, 0.7674023509025574, 0.7668364644050598, 0.7631579041481018, 0.7724957466125488, 0.7693831324577332, 0.7682512998580933, 0.7671194076538086, 0.7730616927146912, 0.7710809111595154, 0.7764572501182556, 0.7787209749221802, 0.7832484245300293, 0.777023196220398, 0.7758913636207581, 0.7727787494659424, 0.7744765281677246, 0.780701756477356, 0.7877758741378784, 0.7877758741378784, 0.7821165919303894, 0.7894737124443054, 0.7835314273834229, 0.7928692698478699, 0.7866440415382385, 0.7931522130966187, 0.7908884882926941, 0.7956989407539368, 0.7934352159500122, 0.7835314273834229, 0.7982456088066101, 0.7988115549087524, 0.7993775010108948, 0.8005093336105347, 0.8041878938674927, 0.803056001663208, 0.8013582229614258, 0.8036219477653503, 0.8002263903617859, 0.8092812895774841, 0.8112620115280151, 0.803056001663208, 0.8132427930831909, 0.808432400226593, 0.8166383504867554, 0.8172042965888977, 0.8155065178871155, 0.8115450143814087, 0.8228636384010315, 0.8191850781440735, 0.8157894611358643, 0.8191850781440735, 0.8245614171028137, 0.8166383504867554, 0.8285229206085205, 0.8211658000946045, 0.8330503702163696, 0.8242784142494202, 0.8259762525558472], 'val_loss': [1.061867356300354, 1.061137080192566, 1.058172583580017, 1.0516271591186523, 1.04874849319458, 1.0460963249206543, 1.0415594577789307, 1.036953091621399, 1.0381306409835815, 1.0219529867172241, 1.0207009315490723, 1.0212500095367432, 1.0113297700881958, 1.0035878419876099, 0.9978526830673218, 0.9908154606819153, 0.9904084801673889, 0.9786389470100403, 0.9762042164802551, 0.9669599533081055, 0.9629661440849304, 0.9661094546318054, 0.9636192917823792, 0.9598692655563354, 0.9678640961647034, 0.9597779512405396, 0.9658050537109375, 0.9659826159477234, 0.9669173359870911, 0.9671900272369385, 0.9682608246803284, 0.9669848084449768, 0.9702461361885071, 0.9742101430892944, 0.9719492197036743, 0.9733331203460693, 0.9752832055091858, 0.9762090444564819, 0.9703606367111206, 0.975468099117279, 0.9786836504936218, 0.9790941476821899, 0.9734715223312378, 0.9831088781356812, 0.973311185836792, 0.9778403043746948, 0.9700638651847839, 0.9828152060508728, 0.9874828457832336, 0.9908647537231445, 0.9774042963981628, 0.985554575920105, 0.9883802533149719, 0.9880030155181885, 1.0025120973587036, 0.9847978949546814, 0.996417760848999, 0.9910144209861755, 0.9926342368125916, 0.9983102083206177, 0.997951090335846, 0.9920489192008972, 0.9947831630706787, 0.9974375367164612, 1.0046619176864624, 1.0029025077819824, 1.008644938468933, 1.00272798538208, 1.0202199220657349, 1.0128135681152344, 1.012741208076477, 1.0040230751037598, 1.0164579153060913, 1.016295075416565, 1.017635703086853, 1.0147093534469604, 1.0235357284545898, 1.0280131101608276, 1.0242352485656738, 1.0226011276245117, 1.026436448097229, 1.0277392864227295, 1.0262736082077026, 1.0283770561218262, 1.0324186086654663, 1.0282479524612427, 1.0526918172836304, 1.0440796613693237, 1.0393331050872803, 1.0339434146881104, 1.0327900648117065, 1.0367223024368286, 1.0411155223846436, 1.0448139905929565, 1.045954942703247, 1.0540211200714111, 1.055908441543579, 1.0586680173873901, 1.0684527158737183, 1.0681966543197632], 'val_accuracy': [0.5124434232711792, 0.5113122463226318, 0.5135746598243713, 0.5248869061470032, 0.5282805562019348, 0.5328054428100586, 0.540723979473114, 0.5509049892425537, 0.5339366793632507, 0.5893664956092834, 0.5837104320526123, 0.5712669491767883, 0.6018099784851074, 0.6018099784851074, 0.6142534017562866, 0.622171938419342, 0.6233031749725342, 0.6470588445663452, 0.6538461446762085, 0.6561086177825928, 0.6549773812294006, 0.6572397947311401, 0.6549773812294006, 0.6651583909988403, 0.6561086177825928, 0.6595022678375244, 0.6651583909988403, 0.6617646813392639, 0.6606335043907166, 0.6595022678375244, 0.668552041053772, 0.6651583909988403, 0.6662895679473877, 0.662895917892456, 0.6606335043907166, 0.662895917892456, 0.6662895679473877, 0.6595022678375244, 0.6651583909988403, 0.6561086177825928, 0.6640271544456482, 0.6606335043907166, 0.6674208045005798, 0.6606335043907166, 0.6595022678375244, 0.6617646813392639, 0.6651583909988403, 0.662895917892456, 0.6549773812294006, 0.6595022678375244, 0.6572397947311401, 0.6640271544456482, 0.6617646813392639, 0.6583710312843323, 0.6504524946212769, 0.6651583909988403, 0.6674208045005798, 0.662895917892456, 0.6583710312843323, 0.6538461446762085, 0.6617646813392639, 0.6606335043907166, 0.6651583909988403, 0.6583710312843323, 0.662895917892456, 0.6674208045005798, 0.6606335043907166, 0.6640271544456482, 0.6493212580680847, 0.6617646813392639, 0.6606335043907166, 0.6662895679473877, 0.6640271544456482, 0.6651583909988403, 0.6651583909988403, 0.6617646813392639, 0.6561086177825928, 0.6504524946212769, 0.6617646813392639, 0.6561086177825928, 0.6561086177825928, 0.6662895679473877, 0.6606335043907166, 0.668552041053772, 0.651583731174469, 0.6674208045005798, 0.6402714848518372, 0.651583731174469, 0.6674208045005798, 0.662895917892456, 0.6640271544456482, 0.6595022678375244, 0.6742081642150879, 0.6583710312843323, 0.6662895679473877, 0.6606335043907166, 0.6651583909988403, 0.6572397947311401, 0.6595022678375244, 0.6493212580680847]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 9s 49ms/step - loss: 0.9619 - accuracy: 0.6920 - val_loss: 1.0581 - val_accuracy: 0.5238\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 2/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9493 - accuracy: 0.6972 - val_loss: 1.0535 - val_accuracy: 0.5320\n","Epoch 3/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9483 - accuracy: 0.6948 - val_loss: 1.0488 - val_accuracy: 0.5372\n","Epoch 4/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9411 - accuracy: 0.6984 - val_loss: 1.0464 - val_accuracy: 0.5351\n","Epoch 5/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9350 - accuracy: 0.6935 - val_loss: 1.0395 - val_accuracy: 0.5548\n","Epoch 6/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9279 - accuracy: 0.7085 - val_loss: 1.0365 - val_accuracy: 0.5475\n","Epoch 7/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9215 - accuracy: 0.7078 - val_loss: 1.0320 - val_accuracy: 0.5548\n","Epoch 8/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9212 - accuracy: 0.7103 - val_loss: 1.0222 - val_accuracy: 0.5837\n","Epoch 9/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.9138 - accuracy: 0.7121 - val_loss: 1.0170 - val_accuracy: 0.5878\n","Epoch 10/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9099 - accuracy: 0.7194 - val_loss: 1.0105 - val_accuracy: 0.6012\n","Epoch 11/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9059 - accuracy: 0.7106 - val_loss: 1.0034 - val_accuracy: 0.6085\n","Epoch 12/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8971 - accuracy: 0.7181 - val_loss: 0.9945 - val_accuracy: 0.6302\n","Epoch 13/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8939 - accuracy: 0.7155 - val_loss: 0.9878 - val_accuracy: 0.6405\n","Epoch 14/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8902 - accuracy: 0.7168 - val_loss: 0.9869 - val_accuracy: 0.6188\n","Epoch 15/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8861 - accuracy: 0.7258 - val_loss: 0.9827 - val_accuracy: 0.6229\n","Epoch 16/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8827 - accuracy: 0.7207 - val_loss: 0.9760 - val_accuracy: 0.6353\n","Epoch 17/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8754 - accuracy: 0.7256 - val_loss: 0.9695 - val_accuracy: 0.6529\n","Epoch 18/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8722 - accuracy: 0.7287 - val_loss: 0.9632 - val_accuracy: 0.6632\n","Epoch 19/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8691 - accuracy: 0.7292 - val_loss: 0.9597 - val_accuracy: 0.6612\n","Epoch 20/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8686 - accuracy: 0.7271 - val_loss: 0.9574 - val_accuracy: 0.6612\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8611 - accuracy: 0.7341 - val_loss: 0.9600 - val_accuracy: 0.6529\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8578 - accuracy: 0.7380 - val_loss: 0.9604 - val_accuracy: 0.6519\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8533 - accuracy: 0.7307 - val_loss: 0.9638 - val_accuracy: 0.6498\n","Epoch 24/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8531 - accuracy: 0.7390 - val_loss: 0.9585 - val_accuracy: 0.6519\n","Epoch 25/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8475 - accuracy: 0.7351 - val_loss: 0.9606 - val_accuracy: 0.6384\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8391 - accuracy: 0.7393 - val_loss: 0.9601 - val_accuracy: 0.6446\n","Epoch 27/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8377 - accuracy: 0.7390 - val_loss: 0.9670 - val_accuracy: 0.6570\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8301 - accuracy: 0.7434 - val_loss: 0.9661 - val_accuracy: 0.6539\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8299 - accuracy: 0.7426 - val_loss: 0.9679 - val_accuracy: 0.6550\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8221 - accuracy: 0.7390 - val_loss: 0.9768 - val_accuracy: 0.6529\n","Epoch 31/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8261 - accuracy: 0.7426 - val_loss: 0.9716 - val_accuracy: 0.6477\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8173 - accuracy: 0.7481 - val_loss: 0.9706 - val_accuracy: 0.6498\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8101 - accuracy: 0.7561 - val_loss: 0.9744 - val_accuracy: 0.6488\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8133 - accuracy: 0.7519 - val_loss: 0.9764 - val_accuracy: 0.6508\n","Epoch 35/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8080 - accuracy: 0.7535 - val_loss: 0.9821 - val_accuracy: 0.6591\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8048 - accuracy: 0.7473 - val_loss: 0.9687 - val_accuracy: 0.6488\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7965 - accuracy: 0.7550 - val_loss: 0.9787 - val_accuracy: 0.6570\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7942 - accuracy: 0.7587 - val_loss: 0.9761 - val_accuracy: 0.6529\n","Epoch 39/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7874 - accuracy: 0.7646 - val_loss: 0.9821 - val_accuracy: 0.6529\n","Epoch 40/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7935 - accuracy: 0.7576 - val_loss: 0.9762 - val_accuracy: 0.6477\n","Epoch 41/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7829 - accuracy: 0.7649 - val_loss: 0.9817 - val_accuracy: 0.6529\n","Epoch 42/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7834 - accuracy: 0.7633 - val_loss: 0.9810 - val_accuracy: 0.6508\n","Epoch 43/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7748 - accuracy: 0.7661 - val_loss: 0.9776 - val_accuracy: 0.6395\n","Epoch 44/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7724 - accuracy: 0.7667 - val_loss: 0.9826 - val_accuracy: 0.6550\n","Epoch 45/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7711 - accuracy: 0.7667 - val_loss: 0.9849 - val_accuracy: 0.6322\n","Epoch 46/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7650 - accuracy: 0.7649 - val_loss: 0.9789 - val_accuracy: 0.6550\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7628 - accuracy: 0.7674 - val_loss: 0.9778 - val_accuracy: 0.6570\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7595 - accuracy: 0.7698 - val_loss: 0.9842 - val_accuracy: 0.6529\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7511 - accuracy: 0.7734 - val_loss: 0.9906 - val_accuracy: 0.6508\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7457 - accuracy: 0.7775 - val_loss: 0.9928 - val_accuracy: 0.6281\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7709 - accuracy: 0.7488 - val_loss: 0.9937 - val_accuracy: 0.6508\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7526 - accuracy: 0.7700 - val_loss: 0.9861 - val_accuracy: 0.6498\n","Epoch 53/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7393 - accuracy: 0.7811 - val_loss: 0.9921 - val_accuracy: 0.6581\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7384 - accuracy: 0.7824 - val_loss: 0.9958 - val_accuracy: 0.6353\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7411 - accuracy: 0.7729 - val_loss: 0.9896 - val_accuracy: 0.6353\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7318 - accuracy: 0.7811 - val_loss: 0.9878 - val_accuracy: 0.6415\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7257 - accuracy: 0.7806 - val_loss: 1.0145 - val_accuracy: 0.6467\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7204 - accuracy: 0.7873 - val_loss: 0.9942 - val_accuracy: 0.6498\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7213 - accuracy: 0.7928 - val_loss: 0.9911 - val_accuracy: 0.6477\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7156 - accuracy: 0.7915 - val_loss: 0.9977 - val_accuracy: 0.6436\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7148 - accuracy: 0.7899 - val_loss: 0.9948 - val_accuracy: 0.6467\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7094 - accuracy: 0.7948 - val_loss: 0.9974 - val_accuracy: 0.6426\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7098 - accuracy: 0.7868 - val_loss: 0.9956 - val_accuracy: 0.6488\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6999 - accuracy: 0.7997 - val_loss: 1.0055 - val_accuracy: 0.6457\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7028 - accuracy: 0.7912 - val_loss: 1.0059 - val_accuracy: 0.6508\n","Epoch 66/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6992 - accuracy: 0.7953 - val_loss: 1.0128 - val_accuracy: 0.6498\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6938 - accuracy: 0.7982 - val_loss: 1.0194 - val_accuracy: 0.6498\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6947 - accuracy: 0.7933 - val_loss: 1.0089 - val_accuracy: 0.6529\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6883 - accuracy: 0.7984 - val_loss: 1.0139 - val_accuracy: 0.6446\n","Epoch 70/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6907 - accuracy: 0.8013 - val_loss: 1.0150 - val_accuracy: 0.6467\n","Epoch 71/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6845 - accuracy: 0.8000 - val_loss: 1.0140 - val_accuracy: 0.6426\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6776 - accuracy: 0.7974 - val_loss: 1.0143 - val_accuracy: 0.6467\n","Epoch 73/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6820 - accuracy: 0.8013 - val_loss: 1.0205 - val_accuracy: 0.6436\n","Epoch 74/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6708 - accuracy: 0.8054 - val_loss: 1.0205 - val_accuracy: 0.6488\n","Epoch 75/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6717 - accuracy: 0.8028 - val_loss: 1.0267 - val_accuracy: 0.6446\n","Epoch 76/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6752 - accuracy: 0.7982 - val_loss: 1.0130 - val_accuracy: 0.6488\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6622 - accuracy: 0.8065 - val_loss: 1.0237 - val_accuracy: 0.6415\n","Epoch 78/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6643 - accuracy: 0.8088 - val_loss: 1.0276 - val_accuracy: 0.6426\n","Epoch 79/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6603 - accuracy: 0.8098 - val_loss: 1.0353 - val_accuracy: 0.6374\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6594 - accuracy: 0.8096 - val_loss: 1.0261 - val_accuracy: 0.6436\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6540 - accuracy: 0.8059 - val_loss: 1.0236 - val_accuracy: 0.6498\n","Epoch 82/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6544 - accuracy: 0.8101 - val_loss: 1.0318 - val_accuracy: 0.6457\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6484 - accuracy: 0.8171 - val_loss: 1.0371 - val_accuracy: 0.6519\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6467 - accuracy: 0.8111 - val_loss: 1.0359 - val_accuracy: 0.6374\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6456 - accuracy: 0.8150 - val_loss: 1.0365 - val_accuracy: 0.6498\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6352 - accuracy: 0.8253 - val_loss: 1.0338 - val_accuracy: 0.6467\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6364 - accuracy: 0.8261 - val_loss: 1.0452 - val_accuracy: 0.6477\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6373 - accuracy: 0.8165 - val_loss: 1.0502 - val_accuracy: 0.6446\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6267 - accuracy: 0.8230 - val_loss: 1.0423 - val_accuracy: 0.6519\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6270 - accuracy: 0.8271 - val_loss: 1.0516 - val_accuracy: 0.6343\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6323 - accuracy: 0.8212 - val_loss: 1.0571 - val_accuracy: 0.6498\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6302 - accuracy: 0.8168 - val_loss: 1.0571 - val_accuracy: 0.6374\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6173 - accuracy: 0.8266 - val_loss: 1.0577 - val_accuracy: 0.6457\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6208 - accuracy: 0.8248 - val_loss: 1.0609 - val_accuracy: 0.6426\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6118 - accuracy: 0.8238 - val_loss: 1.0560 - val_accuracy: 0.6467\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6099 - accuracy: 0.8284 - val_loss: 1.0872 - val_accuracy: 0.6364\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6221 - accuracy: 0.8235 - val_loss: 1.0531 - val_accuracy: 0.6488\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6138 - accuracy: 0.8248 - val_loss: 1.0596 - val_accuracy: 0.6374\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6076 - accuracy: 0.8276 - val_loss: 1.0513 - val_accuracy: 0.6498\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6015 - accuracy: 0.8320 - val_loss: 1.0624 - val_accuracy: 0.6467\n","{'loss': [0.9618574976921082, 0.949324369430542, 0.9482619762420654, 0.9411223530769348, 0.9349612593650818, 0.9278900623321533, 0.9215266704559326, 0.9212386608123779, 0.9138346314430237, 0.9098516702651978, 0.9059171676635742, 0.8971385955810547, 0.8938701748847961, 0.8902472257614136, 0.886053204536438, 0.8827133774757385, 0.8753759264945984, 0.8722236752510071, 0.8691125512123108, 0.8685545325279236, 0.8611301183700562, 0.8578278422355652, 0.8532721996307373, 0.8530940413475037, 0.8474681973457336, 0.8391395807266235, 0.8376742601394653, 0.8301224112510681, 0.8298526406288147, 0.8221422433853149, 0.8260979652404785, 0.817326009273529, 0.8101383447647095, 0.8133383393287659, 0.807975709438324, 0.8047646880149841, 0.796535074710846, 0.7942019104957581, 0.787423849105835, 0.7935075759887695, 0.782854437828064, 0.7834023833274841, 0.7748481631278992, 0.77237468957901, 0.771100640296936, 0.7649769186973572, 0.7628210783004761, 0.7595157027244568, 0.7510820627212524, 0.745711624622345, 0.7708917856216431, 0.7526194453239441, 0.739278256893158, 0.7383911609649658, 0.7410979270935059, 0.7317883372306824, 0.7257291674613953, 0.7203525304794312, 0.7212866544723511, 0.7156396508216858, 0.7148379683494568, 0.7093547582626343, 0.7097509503364563, 0.6999204754829407, 0.7027736902236938, 0.699237585067749, 0.6938138008117676, 0.6946859955787659, 0.688257098197937, 0.6907275915145874, 0.6845283508300781, 0.6775522828102112, 0.6819513440132141, 0.670771062374115, 0.6717415452003479, 0.6752098798751831, 0.6622244715690613, 0.6643125414848328, 0.6602666974067688, 0.6594257950782776, 0.6540288925170898, 0.6543722152709961, 0.6484395861625671, 0.6467031836509705, 0.6456417441368103, 0.6352418661117554, 0.6363888382911682, 0.6373371481895447, 0.6266846060752869, 0.6270278692245483, 0.6323413252830505, 0.6301862597465515, 0.6173482537269592, 0.6207940578460693, 0.6117972135543823, 0.6099424362182617, 0.6220697164535522, 0.6138074398040771, 0.607576310634613, 0.6014732718467712], 'accuracy': [0.6919896602630615, 0.697157621383667, 0.6948320269584656, 0.6984496116638184, 0.6935400366783142, 0.708527147769928, 0.7077519297599792, 0.710335910320282, 0.7121447324752808, 0.7193798422813416, 0.7105942964553833, 0.7180878520011902, 0.7155038714408875, 0.7167958617210388, 0.7258397936820984, 0.7206718325614929, 0.7255814075469971, 0.7286821603775024, 0.7291989922523499, 0.7271317839622498, 0.7341085076332092, 0.7379844784736633, 0.7307493686676025, 0.7390180826187134, 0.7351421117782593, 0.7392764687538147, 0.7390180826187134, 0.7434108257293701, 0.7426356673240662, 0.7390180826187134, 0.7426356673240662, 0.748062014579773, 0.7560723423957825, 0.751937985420227, 0.7534883618354797, 0.7472867965698242, 0.7550387382507324, 0.7586563229560852, 0.7645995020866394, 0.7576227188110352, 0.7648578882217407, 0.763307511806488, 0.7661498785018921, 0.7666666507720947, 0.7666666507720947, 0.7648578882217407, 0.7674418687820435, 0.7697674632072449, 0.7733849883079529, 0.7775194048881531, 0.7488372325897217, 0.7700258493423462, 0.7811369299888611, 0.7824289202690125, 0.7728682160377502, 0.7811369299888611, 0.7806201577186584, 0.7873384952545166, 0.7927648425102234, 0.791472852230072, 0.7899224758148193, 0.7948320508003235, 0.786821722984314, 0.7997416257858276, 0.7912144660949707, 0.7953488230705261, 0.7981911897659302, 0.7932816743850708, 0.7984496355056763, 0.8012920022010803, 0.800000011920929, 0.7974160313606262, 0.8012920022010803, 0.8054263591766357, 0.802842378616333, 0.7981911897659302, 0.8064599633216858, 0.8087855577468872, 0.8098191022872925, 0.8095607161521912, 0.8059431314468384, 0.8100775480270386, 0.817054271697998, 0.8111110925674438, 0.814987063407898, 0.8253229856491089, 0.8260982036590576, 0.8165374398231506, 0.8229973912239075, 0.8271318078041077, 0.8211886286735535, 0.8167958855628967, 0.8266149759292603, 0.8248062133789062, 0.8237726092338562, 0.828423798084259, 0.8235142230987549, 0.8248062133789062, 0.8276485800743103, 0.832041323184967], 'val_loss': [1.058132290840149, 1.053547978401184, 1.0487849712371826, 1.046446681022644, 1.0394989252090454, 1.0364612340927124, 1.0320061445236206, 1.0221564769744873, 1.0170425176620483, 1.0104786157608032, 1.0033814907073975, 0.9945264458656311, 0.9878411293029785, 0.9868738055229187, 0.9826958179473877, 0.9759604334831238, 0.9695307612419128, 0.9631620645523071, 0.9596701264381409, 0.9573909044265747, 0.9599685668945312, 0.9603605270385742, 0.963763415813446, 0.9585099220275879, 0.9605858325958252, 0.9601321220397949, 0.9670431613922119, 0.9661410450935364, 0.9678536057472229, 0.9767898321151733, 0.9715904593467712, 0.9706147909164429, 0.9743927121162415, 0.9764112234115601, 0.982105016708374, 0.9687232375144958, 0.9787155389785767, 0.9761070609092712, 0.9820995330810547, 0.9761999249458313, 0.9817271828651428, 0.9810482263565063, 0.9775797128677368, 0.9826319813728333, 0.9848663210868835, 0.9788673520088196, 0.9777811169624329, 0.9841732978820801, 0.9905779361724854, 0.9927759170532227, 0.9937316179275513, 0.9860559701919556, 0.9921202659606934, 0.9958093166351318, 0.9896053671836853, 0.9878042340278625, 1.0145031213760376, 0.9942297339439392, 0.9911260008811951, 0.9976664185523987, 0.9947662353515625, 0.997353196144104, 0.9956244826316833, 1.005488395690918, 1.0059444904327393, 1.0128027200698853, 1.0193560123443604, 1.0089237689971924, 1.0139195919036865, 1.0150374174118042, 1.013950228691101, 1.0143108367919922, 1.0204708576202393, 1.0204521417617798, 1.0267442464828491, 1.0130200386047363, 1.0237312316894531, 1.0275534391403198, 1.0352981090545654, 1.0261402130126953, 1.0235857963562012, 1.0318373441696167, 1.0370550155639648, 1.0359026193618774, 1.0364524126052856, 1.0338400602340698, 1.045188069343567, 1.0501586198806763, 1.0422502756118774, 1.0516080856323242, 1.057120442390442, 1.0570652484893799, 1.0577208995819092, 1.0609108209609985, 1.0560280084609985, 1.08721125125885, 1.05314040184021, 1.0595747232437134, 1.0512588024139404, 1.0624490976333618], 'val_accuracy': [0.5237603187561035, 0.5320248007774353, 0.5371900796890259, 0.5351239442825317, 0.5547520518302917, 0.547520637512207, 0.5547520518302917, 0.5836777091026306, 0.5878099203109741, 0.6012396812438965, 0.6084710955619812, 0.6301652789115906, 0.6404958963394165, 0.6188016533851624, 0.6229338645935059, 0.6353305578231812, 0.6528925895690918, 0.663223147392273, 0.6611570119857788, 0.6611570119857788, 0.6528925895690918, 0.6518595218658447, 0.6497933864593506, 0.6518595218658447, 0.6384297609329224, 0.64462810754776, 0.6570248007774353, 0.6539255976676941, 0.6549586653709412, 0.6528925895690918, 0.6477272510528564, 0.6497933864593506, 0.6487603187561035, 0.6508264541625977, 0.6590909361839294, 0.6487603187561035, 0.6570248007774353, 0.6528925895690918, 0.6528925895690918, 0.6477272510528564, 0.6528925895690918, 0.6508264541625977, 0.6394628286361694, 0.6549586653709412, 0.6322314143180847, 0.6549586653709412, 0.6570248007774353, 0.6528925895690918, 0.6508264541625977, 0.6280992031097412, 0.6508264541625977, 0.6497933864593506, 0.6580578684806824, 0.6353305578231812, 0.6353305578231812, 0.6415289044380188, 0.6466942429542542, 0.6497933864593506, 0.6477272510528564, 0.6435950398445129, 0.6466942429542542, 0.6425619721412659, 0.6487603187561035, 0.6456611752510071, 0.6508264541625977, 0.6497933864593506, 0.6497933864593506, 0.6528925895690918, 0.64462810754776, 0.6466942429542542, 0.6425619721412659, 0.6466942429542542, 0.6435950398445129, 0.6487603187561035, 0.64462810754776, 0.6487603187561035, 0.6415289044380188, 0.6425619721412659, 0.6373966932296753, 0.6435950398445129, 0.6497933864593506, 0.6456611752510071, 0.6518595218658447, 0.6373966932296753, 0.6497933864593506, 0.6466942429542542, 0.6477272510528564, 0.64462810754776, 0.6518595218658447, 0.6342975497245789, 0.6497933864593506, 0.6373966932296753, 0.6456611752510071, 0.6425619721412659, 0.6466942429542542, 0.6363636255264282, 0.6487603187561035, 0.6373966932296753, 0.6497933864593506, 0.6466942429542542]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 6s 48ms/step - loss: 0.6781 - accuracy: 0.7923 - val_loss: 0.8992 - val_accuracy: 0.5636\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 2/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6662 - accuracy: 0.7923 - val_loss: 0.8897 - val_accuracy: 0.5959\n","Epoch 3/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6603 - accuracy: 0.7993 - val_loss: 0.8912 - val_accuracy: 0.5733\n","Epoch 4/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6468 - accuracy: 0.8058 - val_loss: 0.8769 - val_accuracy: 0.6110\n","Epoch 5/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6449 - accuracy: 0.8052 - val_loss: 0.8749 - val_accuracy: 0.6067\n","Epoch 6/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6388 - accuracy: 0.8103 - val_loss: 0.8660 - val_accuracy: 0.6347\n","Epoch 7/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6380 - accuracy: 0.8050 - val_loss: 0.8623 - val_accuracy: 0.6078\n","Epoch 8/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6376 - accuracy: 0.7993 - val_loss: 0.8529 - val_accuracy: 0.6606\n","Epoch 9/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6318 - accuracy: 0.8114 - val_loss: 0.8479 - val_accuracy: 0.6562\n","Epoch 10/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6230 - accuracy: 0.8203 - val_loss: 0.8439 - val_accuracy: 0.6358\n","Epoch 11/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6290 - accuracy: 0.8122 - val_loss: 0.8279 - val_accuracy: 0.6778\n","Epoch 12/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6177 - accuracy: 0.8176 - val_loss: 0.8219 - val_accuracy: 0.6767\n","Epoch 13/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6191 - accuracy: 0.8125 - val_loss: 0.8097 - val_accuracy: 0.6875\n","Epoch 14/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6072 - accuracy: 0.8241 - val_loss: 0.8033 - val_accuracy: 0.7026\n","Epoch 15/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6101 - accuracy: 0.8168 - val_loss: 0.7928 - val_accuracy: 0.6918\n","Epoch 16/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6073 - accuracy: 0.8222 - val_loss: 0.7883 - val_accuracy: 0.7015\n","Epoch 17/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5978 - accuracy: 0.8279 - val_loss: 0.7843 - val_accuracy: 0.7047\n","Epoch 18/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5960 - accuracy: 0.8252 - val_loss: 0.7802 - val_accuracy: 0.7080\n","Epoch 19/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5884 - accuracy: 0.8308 - val_loss: 0.7833 - val_accuracy: 0.6994\n","Epoch 20/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5994 - accuracy: 0.8284 - val_loss: 0.7736 - val_accuracy: 0.7112\n","Epoch 21/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5979 - accuracy: 0.8235 - val_loss: 0.7881 - val_accuracy: 0.7069\n","Epoch 22/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5912 - accuracy: 0.8260 - val_loss: 0.7862 - val_accuracy: 0.7037\n","Epoch 23/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5846 - accuracy: 0.8316 - val_loss: 0.7933 - val_accuracy: 0.7004\n","Epoch 24/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5839 - accuracy: 0.8262 - val_loss: 0.7952 - val_accuracy: 0.7047\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5770 - accuracy: 0.8303 - val_loss: 0.8032 - val_accuracy: 0.7026\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5781 - accuracy: 0.8349 - val_loss: 0.8196 - val_accuracy: 0.6940\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5814 - accuracy: 0.8308 - val_loss: 0.8179 - val_accuracy: 0.7101\n","Epoch 28/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5732 - accuracy: 0.8381 - val_loss: 0.8148 - val_accuracy: 0.7123\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5704 - accuracy: 0.8405 - val_loss: 0.8328 - val_accuracy: 0.7058\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5687 - accuracy: 0.8416 - val_loss: 0.8329 - val_accuracy: 0.7080\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5603 - accuracy: 0.8397 - val_loss: 0.8331 - val_accuracy: 0.7047\n","Epoch 32/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5643 - accuracy: 0.8443 - val_loss: 0.8326 - val_accuracy: 0.7134\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5605 - accuracy: 0.8435 - val_loss: 0.8513 - val_accuracy: 0.6994\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5636 - accuracy: 0.8394 - val_loss: 0.8437 - val_accuracy: 0.7123\n","Epoch 35/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5541 - accuracy: 0.8448 - val_loss: 0.8488 - val_accuracy: 0.6918\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5504 - accuracy: 0.8467 - val_loss: 0.8346 - val_accuracy: 0.7091\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5491 - accuracy: 0.8499 - val_loss: 0.8548 - val_accuracy: 0.6994\n","Epoch 38/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5501 - accuracy: 0.8551 - val_loss: 0.8496 - val_accuracy: 0.7026\n","Epoch 39/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5416 - accuracy: 0.8521 - val_loss: 0.8473 - val_accuracy: 0.7155\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5398 - accuracy: 0.8464 - val_loss: 0.8339 - val_accuracy: 0.7047\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5341 - accuracy: 0.8486 - val_loss: 0.8405 - val_accuracy: 0.7112\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5406 - accuracy: 0.8486 - val_loss: 0.8719 - val_accuracy: 0.6983\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5281 - accuracy: 0.8605 - val_loss: 0.8676 - val_accuracy: 0.6994\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5366 - accuracy: 0.8513 - val_loss: 0.8714 - val_accuracy: 0.7026\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5327 - accuracy: 0.8529 - val_loss: 0.8676 - val_accuracy: 0.7069\n","Epoch 46/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5247 - accuracy: 0.8516 - val_loss: 0.8584 - val_accuracy: 0.7209\n","Epoch 47/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5220 - accuracy: 0.8629 - val_loss: 0.8770 - val_accuracy: 0.7037\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5256 - accuracy: 0.8570 - val_loss: 0.8787 - val_accuracy: 0.6983\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5211 - accuracy: 0.8618 - val_loss: 0.9605 - val_accuracy: 0.6800\n","Epoch 50/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5396 - accuracy: 0.8435 - val_loss: 0.8673 - val_accuracy: 0.6994\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5110 - accuracy: 0.8615 - val_loss: 0.8917 - val_accuracy: 0.6929\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5103 - accuracy: 0.8656 - val_loss: 0.8918 - val_accuracy: 0.6950\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5146 - accuracy: 0.8637 - val_loss: 0.8754 - val_accuracy: 0.7069\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5095 - accuracy: 0.8596 - val_loss: 0.8872 - val_accuracy: 0.7037\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5181 - accuracy: 0.8637 - val_loss: 0.8951 - val_accuracy: 0.6875\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5095 - accuracy: 0.8613 - val_loss: 0.8902 - val_accuracy: 0.6897\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5099 - accuracy: 0.8664 - val_loss: 0.8890 - val_accuracy: 0.6767\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5045 - accuracy: 0.8656 - val_loss: 0.8912 - val_accuracy: 0.6853\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5097 - accuracy: 0.8634 - val_loss: 0.8829 - val_accuracy: 0.7091\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4984 - accuracy: 0.8650 - val_loss: 0.8832 - val_accuracy: 0.7080\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4993 - accuracy: 0.8699 - val_loss: 0.9002 - val_accuracy: 0.7080\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4908 - accuracy: 0.8680 - val_loss: 0.8952 - val_accuracy: 0.7015\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4905 - accuracy: 0.8737 - val_loss: 0.8924 - val_accuracy: 0.7069\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4944 - accuracy: 0.8737 - val_loss: 0.8967 - val_accuracy: 0.6929\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4874 - accuracy: 0.8815 - val_loss: 0.8946 - val_accuracy: 0.7091\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4873 - accuracy: 0.8761 - val_loss: 0.8987 - val_accuracy: 0.7026\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4813 - accuracy: 0.8731 - val_loss: 0.9162 - val_accuracy: 0.6940\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4854 - accuracy: 0.8712 - val_loss: 0.9231 - val_accuracy: 0.6929\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4804 - accuracy: 0.8774 - val_loss: 0.9217 - val_accuracy: 0.7026\n","Epoch 70/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4734 - accuracy: 0.8788 - val_loss: 0.9127 - val_accuracy: 0.6875\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4676 - accuracy: 0.8852 - val_loss: 0.9185 - val_accuracy: 0.7004\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4723 - accuracy: 0.8798 - val_loss: 0.9091 - val_accuracy: 0.7058\n","Epoch 73/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4646 - accuracy: 0.8885 - val_loss: 0.9045 - val_accuracy: 0.7004\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4668 - accuracy: 0.8836 - val_loss: 0.9109 - val_accuracy: 0.7101\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4730 - accuracy: 0.8815 - val_loss: 0.9156 - val_accuracy: 0.6983\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4718 - accuracy: 0.8790 - val_loss: 0.9350 - val_accuracy: 0.6864\n","Epoch 77/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4655 - accuracy: 0.8850 - val_loss: 0.9049 - val_accuracy: 0.7069\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4698 - accuracy: 0.8793 - val_loss: 0.9184 - val_accuracy: 0.7112\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4648 - accuracy: 0.8836 - val_loss: 0.9338 - val_accuracy: 0.6972\n","Epoch 80/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4542 - accuracy: 0.8893 - val_loss: 0.9315 - val_accuracy: 0.7058\n","Epoch 81/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4559 - accuracy: 0.8901 - val_loss: 0.9323 - val_accuracy: 0.7047\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4509 - accuracy: 0.8909 - val_loss: 0.9480 - val_accuracy: 0.6929\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4608 - accuracy: 0.8828 - val_loss: 0.9338 - val_accuracy: 0.7026\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4499 - accuracy: 0.8914 - val_loss: 0.9594 - val_accuracy: 0.6843\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4713 - accuracy: 0.8825 - val_loss: 0.9940 - val_accuracy: 0.6703\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4485 - accuracy: 0.8914 - val_loss: 0.9472 - val_accuracy: 0.6843\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4531 - accuracy: 0.8869 - val_loss: 0.9396 - val_accuracy: 0.7069\n","Epoch 88/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4477 - accuracy: 0.8877 - val_loss: 0.9782 - val_accuracy: 0.6810\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4385 - accuracy: 0.8971 - val_loss: 0.9464 - val_accuracy: 0.6929\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4355 - accuracy: 0.8957 - val_loss: 0.9492 - val_accuracy: 0.6961\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4369 - accuracy: 0.8957 - val_loss: 0.9597 - val_accuracy: 0.7047\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4432 - accuracy: 0.8909 - val_loss: 0.9490 - val_accuracy: 0.7047\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4354 - accuracy: 0.8976 - val_loss: 0.9619 - val_accuracy: 0.6983\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4273 - accuracy: 0.9017 - val_loss: 0.9495 - val_accuracy: 0.7058\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4229 - accuracy: 0.9036 - val_loss: 0.9765 - val_accuracy: 0.6875\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4282 - accuracy: 0.8990 - val_loss: 0.9663 - val_accuracy: 0.7069\n","Epoch 97/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4284 - accuracy: 0.8949 - val_loss: 0.9631 - val_accuracy: 0.7069\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4275 - accuracy: 0.8998 - val_loss: 0.9680 - val_accuracy: 0.7026\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4272 - accuracy: 0.8941 - val_loss: 0.9740 - val_accuracy: 0.6929\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4196 - accuracy: 0.9030 - val_loss: 0.9876 - val_accuracy: 0.6950\n","{'loss': [0.6781037449836731, 0.6662164330482483, 0.6602895855903625, 0.6467628479003906, 0.6449319124221802, 0.638798177242279, 0.638039767742157, 0.6375579833984375, 0.6318101286888123, 0.6230278611183167, 0.629002034664154, 0.617702841758728, 0.6191452145576477, 0.6071637272834778, 0.6101469993591309, 0.6072770953178406, 0.597751796245575, 0.5960317254066467, 0.5884214043617249, 0.5994295477867126, 0.5978922247886658, 0.5912182927131653, 0.5846220850944519, 0.583915650844574, 0.5770444273948669, 0.5781440734863281, 0.5813864469528198, 0.5732027888298035, 0.5704441666603088, 0.5686794519424438, 0.5603004097938538, 0.5643435120582581, 0.560482919216156, 0.5635657906532288, 0.5540637969970703, 0.550389289855957, 0.5490752458572388, 0.5500649213790894, 0.5415845513343811, 0.5398220419883728, 0.5340878963470459, 0.5405905246734619, 0.5281381607055664, 0.5366007685661316, 0.5327069759368896, 0.5246648192405701, 0.5220088362693787, 0.5255758166313171, 0.521050214767456, 0.5396384000778198, 0.5109550952911377, 0.5102999806404114, 0.5145630240440369, 0.5095449090003967, 0.5181032419204712, 0.5094996094703674, 0.509857177734375, 0.5045284628868103, 0.5097010731697083, 0.4983557462692261, 0.49926257133483887, 0.49082210659980774, 0.49049004912376404, 0.49444958567619324, 0.4874328076839447, 0.4872705638408661, 0.4812667667865753, 0.4854029715061188, 0.4804117977619171, 0.47341930866241455, 0.46761468052864075, 0.47233378887176514, 0.464592844247818, 0.4667617082595825, 0.47302496433258057, 0.47179165482521057, 0.4655015170574188, 0.4698318839073181, 0.4647548198699951, 0.4542040228843689, 0.4558645784854889, 0.4509214460849762, 0.4607974886894226, 0.44986221194267273, 0.4713231325149536, 0.44848597049713135, 0.45307475328445435, 0.4476945698261261, 0.43845248222351074, 0.4354909062385559, 0.43686962127685547, 0.4432375133037567, 0.4353558421134949, 0.427303284406662, 0.42286771535873413, 0.4282341003417969, 0.4284383952617645, 0.4274885356426239, 0.4272440969944, 0.419638454914093], 'accuracy': [0.7922952771186829, 0.7922952771186829, 0.7992995977401733, 0.8057650923728943, 0.8052262663841248, 0.8103448152542114, 0.8049569129943848, 0.7992995977401733, 0.8114224076271057, 0.8203125, 0.8122305870056152, 0.8176185488700867, 0.8125, 0.8240840435028076, 0.8168103694915771, 0.8221982717514038, 0.8278555870056152, 0.8251616358757019, 0.8308189511299133, 0.8283944129943848, 0.8235452771186829, 0.8259698152542114, 0.8316271305084229, 0.8262392282485962, 0.8302801847457886, 0.8348599076271057, 0.8308189511299133, 0.8380926847457886, 0.8405172228813171, 0.8415948152542114, 0.8397090435028076, 0.8442887663841248, 0.8434805870056152, 0.8394396305084229, 0.8448275923728943, 0.8467133641242981, 0.849946141242981, 0.8550646305084229, 0.8521012663841248, 0.8464439511299133, 0.8485991358757019, 0.8485991358757019, 0.8604525923728943, 0.8512930870056152, 0.852909505367279, 0.8515625, 0.8628771305084229, 0.8569504022598267, 0.8617995977401733, 0.8434805870056152, 0.8615301847457886, 0.865571141242981, 0.8636853694915771, 0.8596444129943848, 0.8636853694915771, 0.8612607717514038, 0.8663793206214905, 0.865571141242981, 0.8634159564971924, 0.8650323152542114, 0.8698814511299133, 0.8679956793785095, 0.873652994632721, 0.873652994632721, 0.881465494632721, 0.8760775923728943, 0.8731142282485962, 0.8712284564971924, 0.8774245977401733, 0.8787715435028076, 0.8852370977401733, 0.8798491358757019, 0.8884698152542114, 0.8836206793785095, 0.881465494632721, 0.8790409564971924, 0.8849676847457886, 0.8793103694915771, 0.8836206793785095, 0.889277994632721, 0.8900862336158752, 0.8908944129943848, 0.8828125, 0.8914331793785095, 0.8825430870056152, 0.8914331793785095, 0.8868534564971924, 0.8876616358757019, 0.897090494632721, 0.8957435488700867, 0.8957435488700867, 0.8908944129943848, 0.8976293206214905, 0.9016702771186829, 0.9035560488700867, 0.8989762663841248, 0.8949353694915771, 0.899784505367279, 0.8941271305084229, 0.9030172228813171], 'val_loss': [0.8992368578910828, 0.8896747827529907, 0.8912478685379028, 0.8769484758377075, 0.8748759031295776, 0.8659725785255432, 0.8622857332229614, 0.852899432182312, 0.8479272127151489, 0.8438903093338013, 0.8279122710227966, 0.8218972682952881, 0.8096845746040344, 0.8033449649810791, 0.7928342223167419, 0.7883356809616089, 0.7842894196510315, 0.7802469730377197, 0.7832716703414917, 0.7736431360244751, 0.7880997657775879, 0.7862014174461365, 0.7933282256126404, 0.7951585054397583, 0.8031808137893677, 0.8196168541908264, 0.817870557308197, 0.8148344159126282, 0.8327537775039673, 0.8329229950904846, 0.833058774471283, 0.8326433897018433, 0.851336658000946, 0.8436981439590454, 0.848785936832428, 0.8345752954483032, 0.8547976016998291, 0.8495806455612183, 0.8473053574562073, 0.8339035511016846, 0.8405308127403259, 0.8719448447227478, 0.8675824403762817, 0.8713902831077576, 0.8675638437271118, 0.8583791255950928, 0.8770439624786377, 0.8786811828613281, 0.9605094790458679, 0.8672583103179932, 0.8917069435119629, 0.8918278813362122, 0.8753768801689148, 0.8872482776641846, 0.8951191306114197, 0.8901806473731995, 0.8890137672424316, 0.8912291526794434, 0.882872998714447, 0.8831952810287476, 0.9001650214195251, 0.8952180743217468, 0.8924275636672974, 0.8967145681381226, 0.8945799469947815, 0.8987346291542053, 0.9161861538887024, 0.9230504035949707, 0.9217451214790344, 0.9127445816993713, 0.9185070991516113, 0.9091199636459351, 0.9044590592384338, 0.9109135270118713, 0.9156122803688049, 0.935019850730896, 0.9049363136291504, 0.9184147119522095, 0.9337807297706604, 0.931534469127655, 0.9323208332061768, 0.9479540586471558, 0.9338263273239136, 0.9594083428382874, 0.9940259456634521, 0.9471921324729919, 0.9396355748176575, 0.9782012701034546, 0.9463858604431152, 0.949174702167511, 0.9597480893135071, 0.9489608407020569, 0.9618645310401917, 0.9494745135307312, 0.976529598236084, 0.9662649035453796, 0.963108479976654, 0.9680342078208923, 0.9739625453948975, 0.9875522255897522], 'val_accuracy': [0.5635775923728943, 0.5959051847457886, 0.5732758641242981, 0.610991358757019, 0.6066810488700867, 0.6346982717514038, 0.607758641242981, 0.6605603694915771, 0.65625, 0.6357758641242981, 0.6778017282485962, 0.6767241358757019, 0.6875, 0.7025862336158752, 0.6918103694915771, 0.701508641242981, 0.704741358757019, 0.7079741358757019, 0.6993534564971924, 0.7112069129943848, 0.7068965435028076, 0.7036637663841248, 0.7004310488700867, 0.704741358757019, 0.7025862336158752, 0.693965494632721, 0.7101293206214905, 0.712284505367279, 0.7058189511299133, 0.7079741358757019, 0.704741358757019, 0.7133620977401733, 0.6993534564971924, 0.712284505367279, 0.6918103694915771, 0.7090517282485962, 0.6993534564971924, 0.7025862336158752, 0.7155172228813171, 0.704741358757019, 0.7112069129943848, 0.6982758641242981, 0.6993534564971924, 0.7025862336158752, 0.7068965435028076, 0.7209051847457886, 0.7036637663841248, 0.6982758641242981, 0.6799569129943848, 0.6993534564971924, 0.6928879022598267, 0.6950430870056152, 0.7068965435028076, 0.7036637663841248, 0.6875, 0.6896551847457886, 0.6767241358757019, 0.6853448152542114, 0.7090517282485962, 0.7079741358757019, 0.7079741358757019, 0.701508641242981, 0.7068965435028076, 0.6928879022598267, 0.7090517282485962, 0.7025862336158752, 0.693965494632721, 0.6928879022598267, 0.7025862336158752, 0.6875, 0.7004310488700867, 0.7058189511299133, 0.7004310488700867, 0.7101293206214905, 0.6982758641242981, 0.6864224076271057, 0.7068965435028076, 0.7112069129943848, 0.6971982717514038, 0.7058189511299133, 0.704741358757019, 0.6928879022598267, 0.7025862336158752, 0.6842672228813171, 0.670258641242981, 0.6842672228813171, 0.7068965435028076, 0.681034505367279, 0.6928879022598267, 0.6961206793785095, 0.704741358757019, 0.704741358757019, 0.6982758641242981, 0.7058189511299133, 0.6875, 0.7068965435028076, 0.7068965435028076, 0.7025862336158752, 0.6928879022598267, 0.6950430870056152]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.6888 - accuracy: 0.7875"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 7s 52ms/step - loss: 0.6888 - accuracy: 0.7875 - val_loss: 0.9042 - val_accuracy: 0.5532\n","Epoch 2/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6691 - accuracy: 0.7937 - val_loss: 0.8946 - val_accuracy: 0.6007\n","Epoch 3/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6582 - accuracy: 0.7963 - val_loss: 0.8985 - val_accuracy: 0.5622\n","Epoch 4/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6569 - accuracy: 0.7977 - val_loss: 0.8870 - val_accuracy: 0.6109\n","Epoch 5/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.6496 - accuracy: 0.8028 - val_loss: 0.8838 - val_accuracy: 0.6176\n","Epoch 6/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.6515 - accuracy: 0.8059 - val_loss: 0.8790 - val_accuracy: 0.6278\n","Epoch 7/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6396 - accuracy: 0.8062 - val_loss: 0.8740 - val_accuracy: 0.6143\n","Epoch 8/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6404 - accuracy: 0.8067 - val_loss: 0.8680 - val_accuracy: 0.6256\n","Epoch 9/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6350 - accuracy: 0.8014 - val_loss: 0.8677 - val_accuracy: 0.6131\n","Epoch 10/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6365 - accuracy: 0.8132 - val_loss: 0.8536 - val_accuracy: 0.6606\n","Epoch 11/100\n","28/28 [==============================] - 1s 17ms/step - loss: 0.6343 - accuracy: 0.8076 - val_loss: 0.8477 - val_accuracy: 0.6606\n","Epoch 12/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6295 - accuracy: 0.8098 - val_loss: 0.8426 - val_accuracy: 0.6652\n","Epoch 13/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6282 - accuracy: 0.8079 - val_loss: 0.8439 - val_accuracy: 0.6538\n","Epoch 14/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6260 - accuracy: 0.8025 - val_loss: 0.8389 - val_accuracy: 0.6697\n","Epoch 15/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6220 - accuracy: 0.8164 - val_loss: 0.8404 - val_accuracy: 0.6505\n","Epoch 16/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6141 - accuracy: 0.8127 - val_loss: 0.8206 - val_accuracy: 0.6753\n","Epoch 17/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6092 - accuracy: 0.8178 - val_loss: 0.8146 - val_accuracy: 0.6946\n","Epoch 18/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6138 - accuracy: 0.8181 - val_loss: 0.8242 - val_accuracy: 0.6708\n","Epoch 19/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6087 - accuracy: 0.8147 - val_loss: 0.8099 - val_accuracy: 0.7014\n","Epoch 20/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6136 - accuracy: 0.8104 - val_loss: 0.8108 - val_accuracy: 0.6980\n","Epoch 21/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6064 - accuracy: 0.8246 - val_loss: 0.8122 - val_accuracy: 0.7036\n","Epoch 22/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6043 - accuracy: 0.8186 - val_loss: 0.8428 - val_accuracy: 0.6889\n","Epoch 23/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6018 - accuracy: 0.8195 - val_loss: 0.8191 - val_accuracy: 0.7048\n","Epoch 24/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6014 - accuracy: 0.8212 - val_loss: 0.8544 - val_accuracy: 0.6821\n","Epoch 25/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5964 - accuracy: 0.8217 - val_loss: 0.8273 - val_accuracy: 0.7014\n","Epoch 26/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5889 - accuracy: 0.8316 - val_loss: 0.8333 - val_accuracy: 0.7048\n","Epoch 27/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5811 - accuracy: 0.8288 - val_loss: 0.8597 - val_accuracy: 0.6889\n","Epoch 28/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5831 - accuracy: 0.8325 - val_loss: 0.8534 - val_accuracy: 0.7081\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5939 - accuracy: 0.8175 - val_loss: 0.8789 - val_accuracy: 0.6991\n","Epoch 30/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5765 - accuracy: 0.8308 - val_loss: 0.8569 - val_accuracy: 0.7161\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5730 - accuracy: 0.8305 - val_loss: 0.8712 - val_accuracy: 0.7059\n","Epoch 32/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5634 - accuracy: 0.8384 - val_loss: 0.8695 - val_accuracy: 0.7104\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5748 - accuracy: 0.8359 - val_loss: 0.9011 - val_accuracy: 0.6957\n","Epoch 34/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5737 - accuracy: 0.8299 - val_loss: 0.8781 - val_accuracy: 0.7048\n","Epoch 35/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5599 - accuracy: 0.8447 - val_loss: 0.8863 - val_accuracy: 0.7025\n","Epoch 36/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5684 - accuracy: 0.8314 - val_loss: 0.8928 - val_accuracy: 0.7014\n","Epoch 37/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5594 - accuracy: 0.8390 - val_loss: 0.8865 - val_accuracy: 0.7093\n","Epoch 38/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5617 - accuracy: 0.8424 - val_loss: 0.8886 - val_accuracy: 0.7070\n","Epoch 39/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5618 - accuracy: 0.8407 - val_loss: 0.8990 - val_accuracy: 0.6923\n","Epoch 40/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5610 - accuracy: 0.8393 - val_loss: 0.8926 - val_accuracy: 0.7002\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5576 - accuracy: 0.8404 - val_loss: 0.8969 - val_accuracy: 0.7059\n","Epoch 42/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5451 - accuracy: 0.8520 - val_loss: 0.9084 - val_accuracy: 0.7036\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5448 - accuracy: 0.8478 - val_loss: 0.8973 - val_accuracy: 0.7048\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5439 - accuracy: 0.8531 - val_loss: 0.9084 - val_accuracy: 0.7059\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5426 - accuracy: 0.8512 - val_loss: 0.9096 - val_accuracy: 0.7002\n","Epoch 46/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5472 - accuracy: 0.8430 - val_loss: 0.9160 - val_accuracy: 0.6991\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5395 - accuracy: 0.8449 - val_loss: 0.9134 - val_accuracy: 0.7014\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5412 - accuracy: 0.8475 - val_loss: 0.9216 - val_accuracy: 0.6934\n","Epoch 49/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5374 - accuracy: 0.8495 - val_loss: 0.9309 - val_accuracy: 0.6934\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5321 - accuracy: 0.8563 - val_loss: 0.9207 - val_accuracy: 0.7014\n","Epoch 51/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5413 - accuracy: 0.8475 - val_loss: 0.9154 - val_accuracy: 0.6900\n","Epoch 52/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5306 - accuracy: 0.8492 - val_loss: 0.9180 - val_accuracy: 0.7002\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5291 - accuracy: 0.8506 - val_loss: 0.9194 - val_accuracy: 0.7036\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5253 - accuracy: 0.8529 - val_loss: 0.9318 - val_accuracy: 0.7059\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5200 - accuracy: 0.8563 - val_loss: 0.9162 - val_accuracy: 0.7048\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5326 - accuracy: 0.8503 - val_loss: 0.9396 - val_accuracy: 0.6776\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5134 - accuracy: 0.8602 - val_loss: 0.9348 - val_accuracy: 0.7059\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5175 - accuracy: 0.8585 - val_loss: 0.9296 - val_accuracy: 0.6968\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5192 - accuracy: 0.8580 - val_loss: 0.9372 - val_accuracy: 0.6900\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5164 - accuracy: 0.8557 - val_loss: 0.9324 - val_accuracy: 0.6968\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5104 - accuracy: 0.8568 - val_loss: 0.9291 - val_accuracy: 0.6957\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5070 - accuracy: 0.8656 - val_loss: 0.9252 - val_accuracy: 0.7014\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5025 - accuracy: 0.8630 - val_loss: 0.9387 - val_accuracy: 0.6957\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5018 - accuracy: 0.8693 - val_loss: 0.9331 - val_accuracy: 0.7036\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4945 - accuracy: 0.8698 - val_loss: 0.9356 - val_accuracy: 0.7002\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5067 - accuracy: 0.8585 - val_loss: 0.9545 - val_accuracy: 0.6889\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5095 - accuracy: 0.8599 - val_loss: 0.9456 - val_accuracy: 0.6968\n","Epoch 68/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4930 - accuracy: 0.8693 - val_loss: 0.9530 - val_accuracy: 0.6844\n","Epoch 69/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4907 - accuracy: 0.8687 - val_loss: 0.9476 - val_accuracy: 0.7048\n","Epoch 70/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4882 - accuracy: 0.8701 - val_loss: 0.9542 - val_accuracy: 0.6934\n","Epoch 71/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4931 - accuracy: 0.8738 - val_loss: 1.0021 - val_accuracy: 0.6550\n","Epoch 72/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4837 - accuracy: 0.8681 - val_loss: 0.9468 - val_accuracy: 0.7081\n","Epoch 73/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4825 - accuracy: 0.8735 - val_loss: 0.9489 - val_accuracy: 0.7036\n","Epoch 74/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4891 - accuracy: 0.8696 - val_loss: 0.9550 - val_accuracy: 0.6912\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4882 - accuracy: 0.8662 - val_loss: 0.9856 - val_accuracy: 0.7036\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4829 - accuracy: 0.8701 - val_loss: 0.9529 - val_accuracy: 0.6991\n","Epoch 77/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4824 - accuracy: 0.8698 - val_loss: 0.9546 - val_accuracy: 0.7048\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4804 - accuracy: 0.8724 - val_loss: 0.9708 - val_accuracy: 0.6991\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4707 - accuracy: 0.8769 - val_loss: 0.9595 - val_accuracy: 0.7002\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4751 - accuracy: 0.8721 - val_loss: 0.9660 - val_accuracy: 0.6957\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4706 - accuracy: 0.8783 - val_loss: 0.9708 - val_accuracy: 0.6900\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4702 - accuracy: 0.8744 - val_loss: 0.9745 - val_accuracy: 0.7025\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4670 - accuracy: 0.8755 - val_loss: 0.9686 - val_accuracy: 0.6934\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4726 - accuracy: 0.8732 - val_loss: 1.0224 - val_accuracy: 0.6855\n","Epoch 85/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4767 - accuracy: 0.8707 - val_loss: 0.9690 - val_accuracy: 0.6923\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4697 - accuracy: 0.8780 - val_loss: 0.9987 - val_accuracy: 0.6753\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4635 - accuracy: 0.8786 - val_loss: 0.9739 - val_accuracy: 0.6980\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4581 - accuracy: 0.8843 - val_loss: 1.0025 - val_accuracy: 0.6934\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4608 - accuracy: 0.8831 - val_loss: 1.0039 - val_accuracy: 0.6821\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4519 - accuracy: 0.8851 - val_loss: 0.9861 - val_accuracy: 0.6934\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4552 - accuracy: 0.8758 - val_loss: 0.9778 - val_accuracy: 0.6968\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4403 - accuracy: 0.8908 - val_loss: 0.9790 - val_accuracy: 0.7014\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4458 - accuracy: 0.8888 - val_loss: 0.9807 - val_accuracy: 0.6946\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4486 - accuracy: 0.8803 - val_loss: 0.9987 - val_accuracy: 0.7115\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4471 - accuracy: 0.8820 - val_loss: 1.0015 - val_accuracy: 0.6867\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4423 - accuracy: 0.8919 - val_loss: 0.9908 - val_accuracy: 0.6912\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4445 - accuracy: 0.8848 - val_loss: 0.9904 - val_accuracy: 0.7070\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4375 - accuracy: 0.8851 - val_loss: 0.9983 - val_accuracy: 0.6968\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4351 - accuracy: 0.8933 - val_loss: 1.0035 - val_accuracy: 0.7025\n","Epoch 100/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4530 - accuracy: 0.8789 - val_loss: 1.0116 - val_accuracy: 0.7025\n","{'loss': [0.6888083219528198, 0.6690941452980042, 0.6581563949584961, 0.6569116115570068, 0.6496151089668274, 0.6515237092971802, 0.6396434903144836, 0.6403603553771973, 0.6350210309028625, 0.6364718675613403, 0.6343254446983337, 0.6295291185379028, 0.6282082200050354, 0.6259886026382446, 0.6220029592514038, 0.614050567150116, 0.6091585159301758, 0.6138195395469666, 0.6087296009063721, 0.613551139831543, 0.6063584685325623, 0.6043206453323364, 0.6017606258392334, 0.6014434099197388, 0.5963633060455322, 0.5888702869415283, 0.5811011791229248, 0.5830554366111755, 0.5939282774925232, 0.5765264630317688, 0.573012113571167, 0.5634280443191528, 0.5748134255409241, 0.5737178325653076, 0.559917151927948, 0.5683532357215881, 0.5593965649604797, 0.5616612434387207, 0.5618003010749817, 0.5609582662582397, 0.557614803314209, 0.5450609922409058, 0.5447899103164673, 0.5438879728317261, 0.5426369905471802, 0.5472193360328674, 0.5394992232322693, 0.5412437915802002, 0.5374467968940735, 0.5321092009544373, 0.5413105487823486, 0.5306128263473511, 0.5291450619697571, 0.5252553224563599, 0.5199590921401978, 0.5325692892074585, 0.5134384632110596, 0.5175201892852783, 0.5191926956176758, 0.5164390802383423, 0.5103822946548462, 0.5070472359657288, 0.5024542212486267, 0.5018404722213745, 0.49451273679733276, 0.5066668391227722, 0.5094967484474182, 0.4929606318473816, 0.4907243847846985, 0.48818162083625793, 0.4930872619152069, 0.4837398827075958, 0.482545405626297, 0.4891180098056793, 0.4882306456565857, 0.48287901282310486, 0.4823765158653259, 0.48035338521003723, 0.4707413911819458, 0.47511720657348633, 0.47061407566070557, 0.4701929986476898, 0.4669986963272095, 0.47262758016586304, 0.47666943073272705, 0.46971628069877625, 0.4635107219219208, 0.4581412672996521, 0.4607745110988617, 0.4518987834453583, 0.4552476704120636, 0.4403343200683594, 0.44578054547309875, 0.4485512971878052, 0.4471001625061035, 0.4423239827156067, 0.4445364475250244, 0.4374831020832062, 0.43514153361320496, 0.4529755115509033], 'accuracy': [0.7874929308891296, 0.793718159198761, 0.7962648272514343, 0.7976796627044678, 0.8027730584144592, 0.8058856725692749, 0.8061686754226685, 0.806734561920166, 0.8013582229614258, 0.8132427930831909, 0.8075834512710571, 0.8098471760749817, 0.8078664541244507, 0.8024901151657104, 0.8163554072380066, 0.8126768469810486, 0.81777024269104, 0.8180531859397888, 0.8146576285362244, 0.810413122177124, 0.8245614171028137, 0.8186191320419312, 0.8194680213928223, 0.8211658000946045, 0.8217317461967468, 0.8316355347633362, 0.8288058638572693, 0.8324844241142273, 0.8174872398376465, 0.8307866454124451, 0.8305037021636963, 0.8384267091751099, 0.8358800411224365, 0.829937756061554, 0.8446519374847412, 0.8313525915145874, 0.8389926552772522, 0.8423882126808167, 0.8406904339790344, 0.839275598526001, 0.8404074907302856, 0.8520090579986572, 0.8477645516395569, 0.8531408905982971, 0.8511601686477661, 0.842954158782959, 0.8449349403381348, 0.8474816083908081, 0.8494623899459839, 0.8562535643577576, 0.8474816083908081, 0.8491793870925903, 0.8505942225456238, 0.8528579473495483, 0.8562535643577576, 0.850311279296875, 0.8602150678634644, 0.8585172891616821, 0.8579513430595398, 0.8556876182556152, 0.8568194508552551, 0.8655914068222046, 0.8630446791648865, 0.8692699670791626, 0.8698358535766602, 0.8585172891616821, 0.8599320650100708, 0.8692699670791626, 0.8687040209770203, 0.8701188564300537, 0.8737974166870117, 0.8681380748748779, 0.8735144138336182, 0.8695529103279114, 0.8661573529243469, 0.8701188564300537, 0.8698358535766602, 0.8723825812339783, 0.8769100308418274, 0.8720995783805847, 0.8783248662948608, 0.8743633031845093, 0.875495195388794, 0.8732314705848694, 0.870684802532196, 0.8780418634414673, 0.8786078095436096, 0.8842670917510986, 0.8831352591514587, 0.8851160407066345, 0.8757781386375427, 0.8907753229141235, 0.8887945413589478, 0.8803055882453918, 0.8820033669471741, 0.8919072151184082, 0.884833037853241, 0.8851160407066345, 0.8933219909667969, 0.8788907527923584], 'val_loss': [0.9042069315910339, 0.8945709466934204, 0.8984614014625549, 0.8870050311088562, 0.8838182687759399, 0.8790377378463745, 0.8740130066871643, 0.8679781556129456, 0.8677266240119934, 0.8535617589950562, 0.8476865887641907, 0.842629075050354, 0.8439337015151978, 0.8388500809669495, 0.840447723865509, 0.8206206560134888, 0.8145956993103027, 0.8241541981697083, 0.8098790049552917, 0.810839056968689, 0.8122398853302002, 0.8428282141685486, 0.8190917372703552, 0.8544140458106995, 0.8273141384124756, 0.8332597017288208, 0.8597365021705627, 0.8533579111099243, 0.8789470791816711, 0.8569498658180237, 0.8711805939674377, 0.8695162534713745, 0.9010903835296631, 0.8780802488327026, 0.8862993717193604, 0.8927562832832336, 0.8865334987640381, 0.8886173963546753, 0.8989951610565186, 0.8926118612289429, 0.8968687653541565, 0.9083653688430786, 0.8972663283348083, 0.9084298610687256, 0.9095849990844727, 0.916000485420227, 0.9134284853935242, 0.9215552806854248, 0.9308553338050842, 0.9207093119621277, 0.9153812527656555, 0.9180017113685608, 0.9193665385246277, 0.931837260723114, 0.916183590888977, 0.9395757913589478, 0.9348359107971191, 0.9296111464500427, 0.9372013211250305, 0.9324008822441101, 0.9291129112243652, 0.9252132177352905, 0.9386543035507202, 0.9331064820289612, 0.9355712532997131, 0.954494833946228, 0.9455720782279968, 0.9530493021011353, 0.9476103186607361, 0.9541775584220886, 1.0021079778671265, 0.9467751383781433, 0.948866605758667, 0.9549932479858398, 0.9856343269348145, 0.9529199600219727, 0.9545601606369019, 0.9708289504051208, 0.9594895243644714, 0.9660260677337646, 0.9707918763160706, 0.9744850397109985, 0.9685502648353577, 1.022354245185852, 0.9689939618110657, 0.9986660480499268, 0.9739359021186829, 1.0025410652160645, 1.0038542747497559, 0.9861024022102356, 0.9778315424919128, 0.9789590239524841, 0.9807025194168091, 0.9987266659736633, 1.0014562606811523, 0.990759015083313, 0.9904100894927979, 0.9983370900154114, 1.0034714937210083, 1.0115783214569092], 'val_accuracy': [0.5531674027442932, 0.6006787419319153, 0.5622171759605408, 0.610859751701355, 0.6176470518112183, 0.627828061580658, 0.6142534017562866, 0.6255655884742737, 0.6131221652030945, 0.6606335043907166, 0.6606335043907166, 0.6651583909988403, 0.6538461446762085, 0.6696832776069641, 0.6504524946212769, 0.6753393411636353, 0.6945701241493225, 0.6708144545555115, 0.7013574838638306, 0.6979637742042542, 0.7036198973655701, 0.6889140009880066, 0.7047511339187622, 0.6821267008781433, 0.7013574838638306, 0.7047511339187622, 0.6889140009880066, 0.7081447839736938, 0.6990950107574463, 0.7160633206367493, 0.7058823704719543, 0.7104072570800781, 0.6957013607025146, 0.7047511339187622, 0.7024886608123779, 0.7013574838638306, 0.709276020526886, 0.7070135474205017, 0.692307710647583, 0.7002262473106384, 0.7058823704719543, 0.7036198973655701, 0.7047511339187622, 0.7058823704719543, 0.7002262473106384, 0.6990950107574463, 0.7013574838638306, 0.6934388875961304, 0.6934388875961304, 0.7013574838638306, 0.6900452375411987, 0.7002262473106384, 0.7036198973655701, 0.7058823704719543, 0.7047511339187622, 0.6776018142700195, 0.7058823704719543, 0.6968325972557068, 0.6900452375411987, 0.6968325972557068, 0.6957013607025146, 0.7013574838638306, 0.6957013607025146, 0.7036198973655701, 0.7002262473106384, 0.6889140009880066, 0.6968325972557068, 0.6843891143798828, 0.7047511339187622, 0.6934388875961304, 0.6549773812294006, 0.7081447839736938, 0.7036198973655701, 0.6911764740943909, 0.7036198973655701, 0.6990950107574463, 0.7047511339187622, 0.6990950107574463, 0.7002262473106384, 0.6957013607025146, 0.6900452375411987, 0.7024886608123779, 0.6934388875961304, 0.685520350933075, 0.692307710647583, 0.6753393411636353, 0.6979637742042542, 0.6934388875961304, 0.6821267008781433, 0.6934388875961304, 0.6968325972557068, 0.7013574838638306, 0.6945701241493225, 0.7115384340286255, 0.6866515874862671, 0.6911764740943909, 0.7070135474205017, 0.6968325972557068, 0.7024886608123779, 0.7024886608123779]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.6863 - accuracy: 0.7896"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 7s 48ms/step - loss: 0.6849 - accuracy: 0.7894 - val_loss: 0.8931 - val_accuracy: 0.5878\n","Epoch 2/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6710 - accuracy: 0.7943 - val_loss: 0.8904 - val_accuracy: 0.5754\n","Epoch 3/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6637 - accuracy: 0.7959 - val_loss: 0.8830 - val_accuracy: 0.6074\n","Epoch 4/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6618 - accuracy: 0.8000 - val_loss: 0.8795 - val_accuracy: 0.5971\n","Epoch 5/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6567 - accuracy: 0.8000 - val_loss: 0.8733 - val_accuracy: 0.6085\n","Epoch 6/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6476 - accuracy: 0.8080 - val_loss: 0.8617 - val_accuracy: 0.6818\n","Epoch 7/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6477 - accuracy: 0.8010 - val_loss: 0.8566 - val_accuracy: 0.6570\n","Epoch 8/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6483 - accuracy: 0.8041 - val_loss: 0.8491 - val_accuracy: 0.6839\n","Epoch 9/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6545 - accuracy: 0.7964 - val_loss: 0.8553 - val_accuracy: 0.6281\n","Epoch 10/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6407 - accuracy: 0.8041 - val_loss: 0.8367 - val_accuracy: 0.6632\n","Epoch 11/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6336 - accuracy: 0.8098 - val_loss: 0.8292 - val_accuracy: 0.6777\n","Epoch 12/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6366 - accuracy: 0.8090 - val_loss: 0.8224 - val_accuracy: 0.6849\n","Epoch 13/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6285 - accuracy: 0.8111 - val_loss: 0.8165 - val_accuracy: 0.6870\n","Epoch 14/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6174 - accuracy: 0.8230 - val_loss: 0.8202 - val_accuracy: 0.6674\n","Epoch 15/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6164 - accuracy: 0.8207 - val_loss: 0.8088 - val_accuracy: 0.6767\n","Epoch 16/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6123 - accuracy: 0.8217 - val_loss: 0.8080 - val_accuracy: 0.6849\n","Epoch 17/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6146 - accuracy: 0.8186 - val_loss: 0.8106 - val_accuracy: 0.6829\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6143 - accuracy: 0.8189 - val_loss: 0.8122 - val_accuracy: 0.6870\n","Epoch 19/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6119 - accuracy: 0.8202 - val_loss: 0.8156 - val_accuracy: 0.6787\n","Epoch 20/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6017 - accuracy: 0.8261 - val_loss: 0.8196 - val_accuracy: 0.6870\n","Epoch 21/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5988 - accuracy: 0.8238 - val_loss: 0.8260 - val_accuracy: 0.6942\n","Epoch 22/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6010 - accuracy: 0.8243 - val_loss: 0.8479 - val_accuracy: 0.6849\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5967 - accuracy: 0.8243 - val_loss: 0.8584 - val_accuracy: 0.6880\n","Epoch 24/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5995 - accuracy: 0.8176 - val_loss: 0.8574 - val_accuracy: 0.6973\n","Epoch 25/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5934 - accuracy: 0.8240 - val_loss: 0.8817 - val_accuracy: 0.6777\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5854 - accuracy: 0.8289 - val_loss: 0.8820 - val_accuracy: 0.6725\n","Epoch 27/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5881 - accuracy: 0.8248 - val_loss: 0.8868 - val_accuracy: 0.6777\n","Epoch 28/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5854 - accuracy: 0.8310 - val_loss: 0.9026 - val_accuracy: 0.6756\n","Epoch 29/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5799 - accuracy: 0.8313 - val_loss: 0.8874 - val_accuracy: 0.6849\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5820 - accuracy: 0.8318 - val_loss: 0.9195 - val_accuracy: 0.6818\n","Epoch 31/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5816 - accuracy: 0.8323 - val_loss: 0.8946 - val_accuracy: 0.6860\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5717 - accuracy: 0.8375 - val_loss: 0.9069 - val_accuracy: 0.6901\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5867 - accuracy: 0.8302 - val_loss: 0.9125 - val_accuracy: 0.6777\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5681 - accuracy: 0.8341 - val_loss: 0.9179 - val_accuracy: 0.6787\n","Epoch 35/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5642 - accuracy: 0.8408 - val_loss: 0.9055 - val_accuracy: 0.6870\n","Epoch 36/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5693 - accuracy: 0.8359 - val_loss: 0.9130 - val_accuracy: 0.6818\n","Epoch 37/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5586 - accuracy: 0.8362 - val_loss: 0.9102 - val_accuracy: 0.6901\n","Epoch 38/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5593 - accuracy: 0.8362 - val_loss: 0.9135 - val_accuracy: 0.6798\n","Epoch 39/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5576 - accuracy: 0.8388 - val_loss: 0.9356 - val_accuracy: 0.6756\n","Epoch 40/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5509 - accuracy: 0.8442 - val_loss: 0.9330 - val_accuracy: 0.6767\n","Epoch 41/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5504 - accuracy: 0.8491 - val_loss: 0.9767 - val_accuracy: 0.6715\n","Epoch 42/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5591 - accuracy: 0.8377 - val_loss: 0.9302 - val_accuracy: 0.6818\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5463 - accuracy: 0.8470 - val_loss: 0.9240 - val_accuracy: 0.6756\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5406 - accuracy: 0.8488 - val_loss: 0.9294 - val_accuracy: 0.6787\n","Epoch 45/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5414 - accuracy: 0.8444 - val_loss: 0.9299 - val_accuracy: 0.6736\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5492 - accuracy: 0.8380 - val_loss: 0.9370 - val_accuracy: 0.6725\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5333 - accuracy: 0.8530 - val_loss: 0.9447 - val_accuracy: 0.6860\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5399 - accuracy: 0.8424 - val_loss: 0.9816 - val_accuracy: 0.6591\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5285 - accuracy: 0.8561 - val_loss: 0.9441 - val_accuracy: 0.6715\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5308 - accuracy: 0.8545 - val_loss: 0.9457 - val_accuracy: 0.6715\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5264 - accuracy: 0.8537 - val_loss: 0.9452 - val_accuracy: 0.6787\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5290 - accuracy: 0.8488 - val_loss: 0.9892 - val_accuracy: 0.6632\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5250 - accuracy: 0.8563 - val_loss: 0.9604 - val_accuracy: 0.6818\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5195 - accuracy: 0.8605 - val_loss: 0.9601 - val_accuracy: 0.6756\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5300 - accuracy: 0.8494 - val_loss: 0.9601 - val_accuracy: 0.6777\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5245 - accuracy: 0.8491 - val_loss: 1.0013 - val_accuracy: 0.6725\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5117 - accuracy: 0.8633 - val_loss: 0.9697 - val_accuracy: 0.6725\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5196 - accuracy: 0.8618 - val_loss: 0.9723 - val_accuracy: 0.6684\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5253 - accuracy: 0.8506 - val_loss: 0.9887 - val_accuracy: 0.6570\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5097 - accuracy: 0.8599 - val_loss: 0.9625 - val_accuracy: 0.6777\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5061 - accuracy: 0.8643 - val_loss: 0.9895 - val_accuracy: 0.6694\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5083 - accuracy: 0.8599 - val_loss: 0.9828 - val_accuracy: 0.6808\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5045 - accuracy: 0.8636 - val_loss: 0.9747 - val_accuracy: 0.6839\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5037 - accuracy: 0.8628 - val_loss: 0.9871 - val_accuracy: 0.6829\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5075 - accuracy: 0.8594 - val_loss: 0.9716 - val_accuracy: 0.6746\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4954 - accuracy: 0.8664 - val_loss: 0.9735 - val_accuracy: 0.6725\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4946 - accuracy: 0.8690 - val_loss: 0.9945 - val_accuracy: 0.6736\n","Epoch 68/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4970 - accuracy: 0.8685 - val_loss: 1.0081 - val_accuracy: 0.6632\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4931 - accuracy: 0.8661 - val_loss: 1.0212 - val_accuracy: 0.6550\n","Epoch 70/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4928 - accuracy: 0.8687 - val_loss: 0.9952 - val_accuracy: 0.6736\n","Epoch 71/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4835 - accuracy: 0.8765 - val_loss: 1.0079 - val_accuracy: 0.6777\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4771 - accuracy: 0.8755 - val_loss: 1.0071 - val_accuracy: 0.6818\n","Epoch 73/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4809 - accuracy: 0.8695 - val_loss: 1.0144 - val_accuracy: 0.6725\n","Epoch 74/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4782 - accuracy: 0.8783 - val_loss: 1.0281 - val_accuracy: 0.6601\n","Epoch 75/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4788 - accuracy: 0.8744 - val_loss: 1.0114 - val_accuracy: 0.6715\n","Epoch 76/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4761 - accuracy: 0.8726 - val_loss: 1.0081 - val_accuracy: 0.6736\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4812 - accuracy: 0.8760 - val_loss: 1.0004 - val_accuracy: 0.6756\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4754 - accuracy: 0.8726 - val_loss: 1.0243 - val_accuracy: 0.6818\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4666 - accuracy: 0.8796 - val_loss: 1.0335 - val_accuracy: 0.6663\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4728 - accuracy: 0.8796 - val_loss: 1.0490 - val_accuracy: 0.6643\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4758 - accuracy: 0.8736 - val_loss: 1.0375 - val_accuracy: 0.6767\n","Epoch 82/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4757 - accuracy: 0.8739 - val_loss: 1.0500 - val_accuracy: 0.6570\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4772 - accuracy: 0.8677 - val_loss: 1.0510 - val_accuracy: 0.6643\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4565 - accuracy: 0.8840 - val_loss: 1.0321 - val_accuracy: 0.6767\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4671 - accuracy: 0.8726 - val_loss: 1.0554 - val_accuracy: 0.6829\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4638 - accuracy: 0.8780 - val_loss: 1.0438 - val_accuracy: 0.6808\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4598 - accuracy: 0.8819 - val_loss: 1.0400 - val_accuracy: 0.6756\n","Epoch 88/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4574 - accuracy: 0.8811 - val_loss: 1.0564 - val_accuracy: 0.6736\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4619 - accuracy: 0.8791 - val_loss: 1.0268 - val_accuracy: 0.6798\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4491 - accuracy: 0.8840 - val_loss: 1.0343 - val_accuracy: 0.6808\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4428 - accuracy: 0.8902 - val_loss: 1.0427 - val_accuracy: 0.6829\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4456 - accuracy: 0.8873 - val_loss: 1.0602 - val_accuracy: 0.6787\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4459 - accuracy: 0.8863 - val_loss: 1.0623 - val_accuracy: 0.6787\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4496 - accuracy: 0.8860 - val_loss: 1.0575 - val_accuracy: 0.6756\n","Epoch 95/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4499 - accuracy: 0.8837 - val_loss: 1.0637 - val_accuracy: 0.6725\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4393 - accuracy: 0.8925 - val_loss: 1.0781 - val_accuracy: 0.6818\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4387 - accuracy: 0.8946 - val_loss: 1.0835 - val_accuracy: 0.6736\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4412 - accuracy: 0.8881 - val_loss: 1.0600 - val_accuracy: 0.6756\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4347 - accuracy: 0.8904 - val_loss: 1.0819 - val_accuracy: 0.6612\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4267 - accuracy: 0.8946 - val_loss: 1.1071 - val_accuracy: 0.6653\n","{'loss': [0.6849005222320557, 0.671044111251831, 0.6636984944343567, 0.661763608455658, 0.6566755771636963, 0.647648274898529, 0.6477299332618713, 0.6483251452445984, 0.6544526815414429, 0.6406928896903992, 0.6336159110069275, 0.6366297602653503, 0.6285363435745239, 0.6174295544624329, 0.6164186000823975, 0.6122941374778748, 0.6145977973937988, 0.6142937541007996, 0.6119104623794556, 0.6016592383384705, 0.5988308787345886, 0.600985586643219, 0.5966711044311523, 0.5994732975959778, 0.5933939814567566, 0.5854401588439941, 0.5881114602088928, 0.5854266285896301, 0.5799426436424255, 0.5819581747055054, 0.5816346406936646, 0.5716740489006042, 0.5866900682449341, 0.5680643320083618, 0.5642035603523254, 0.5693001747131348, 0.5586082935333252, 0.5592511296272278, 0.5575799942016602, 0.5509130954742432, 0.5503650307655334, 0.5590763688087463, 0.5463077425956726, 0.5405978560447693, 0.5413747429847717, 0.5491864085197449, 0.5332887172698975, 0.5398980379104614, 0.5285245180130005, 0.5307907462120056, 0.5263858437538147, 0.5290252566337585, 0.5250388383865356, 0.5195307731628418, 0.5299863815307617, 0.5245475769042969, 0.5116956233978271, 0.5195834636688232, 0.5253379344940186, 0.5096960663795471, 0.5061432123184204, 0.5082533955574036, 0.5044634938240051, 0.5037028193473816, 0.5074811577796936, 0.4953964352607727, 0.49460697174072266, 0.4969586133956909, 0.49307313561439514, 0.49278494715690613, 0.48352399468421936, 0.47711411118507385, 0.4808903932571411, 0.4782163202762604, 0.47880247235298157, 0.47614333033561707, 0.48118773102760315, 0.47538140416145325, 0.466572642326355, 0.4727810025215149, 0.47579628229141235, 0.47570154070854187, 0.4772348701953888, 0.45646050572395325, 0.4671464264392853, 0.4638122618198395, 0.45982441306114197, 0.45736896991729736, 0.4618968069553375, 0.44907501339912415, 0.4427901804447174, 0.44563689827919006, 0.4458525776863098, 0.4496166408061981, 0.4498530328273773, 0.43925973773002625, 0.4386802911758423, 0.44123512506484985, 0.4347429573535919, 0.426749050617218], 'accuracy': [0.7894057035446167, 0.7943152189254761, 0.7958656549453735, 0.800000011920929, 0.800000011920929, 0.8080103397369385, 0.801033616065979, 0.8041343688964844, 0.7963824272155762, 0.8041343688964844, 0.8098191022872925, 0.8090439438819885, 0.8111110925674438, 0.8229973912239075, 0.8206718564033508, 0.8217054009437561, 0.8186046481132507, 0.818863034248352, 0.8201550245285034, 0.8260982036590576, 0.8237726092338562, 0.8242893815040588, 0.8242893815040588, 0.8175710439682007, 0.8240309953689575, 0.8289405703544617, 0.8248062133789062, 0.8310077786445618, 0.8312661647796631, 0.8317829370498657, 0.8322997689247131, 0.8374677300453186, 0.830232560634613, 0.8341085314750671, 0.8408268690109253, 0.8359172940254211, 0.8361757397651672, 0.8361757397651672, 0.8387596607208252, 0.8441860675811768, 0.8490955829620361, 0.8377261161804199, 0.8470284342765808, 0.8488371968269348, 0.8444444537162781, 0.8379845023155212, 0.8529715538024902, 0.842377245426178, 0.8560723662376404, 0.8545219898223877, 0.853746771812439, 0.8488371968269348, 0.8563307523727417, 0.8604651093482971, 0.8493540287017822, 0.8490955829620361, 0.8633074760437012, 0.8617570996284485, 0.8506460189819336, 0.8599483370780945, 0.8643410801887512, 0.8599483370780945, 0.8635658621788025, 0.8627907037734985, 0.8594315052032471, 0.8664082884788513, 0.868992269039154, 0.8684754371643066, 0.8661498427391052, 0.868733823299408, 0.8764857649803162, 0.8754522204399109, 0.8695090413093567, 0.8782945871353149, 0.8744186162948608, 0.8726097941398621, 0.8759689927101135, 0.8726097941398621, 0.8795865774154663, 0.8795865774154663, 0.8736433982849121, 0.8739017844200134, 0.8677002787590027, 0.883979320526123, 0.8726097941398621, 0.8780362010002136, 0.8819121718406677, 0.881136953830719, 0.8790697455406189, 0.883979320526123, 0.8901808857917786, 0.8873385190963745, 0.8863049149513245, 0.8860465288162231, 0.8837209343910217, 0.89250648021698, 0.8945736289024353, 0.8881136775016785, 0.8904392719268799, 0.8945736289024353], 'val_loss': [0.8931289315223694, 0.8903976082801819, 0.882968008518219, 0.879463255405426, 0.8733356595039368, 0.8616659641265869, 0.8566485047340393, 0.8490988612174988, 0.8552700281143188, 0.8367419838905334, 0.8291836380958557, 0.8223527073860168, 0.8164523243904114, 0.8202052712440491, 0.8088200092315674, 0.8080289959907532, 0.8105596303939819, 0.8122181296348572, 0.8155838251113892, 0.8196401596069336, 0.8259685039520264, 0.847944974899292, 0.8583587408065796, 0.8573850393295288, 0.8816605806350708, 0.8820159435272217, 0.8867525458335876, 0.9026370048522949, 0.8874385356903076, 0.9194764494895935, 0.8946109414100647, 0.9068608283996582, 0.9125174283981323, 0.9179070591926575, 0.9055405855178833, 0.9130486249923706, 0.9101758003234863, 0.9134934544563293, 0.9355835914611816, 0.9329726099967957, 0.9767065048217773, 0.9301577210426331, 0.9240091443061829, 0.9293681383132935, 0.9298503994941711, 0.9369847178459167, 0.9447325468063354, 0.9816100001335144, 0.9440769553184509, 0.9456818103790283, 0.9451858997344971, 0.9892070293426514, 0.9603663682937622, 0.9600872993469238, 0.9600908756256104, 1.0012922286987305, 0.9696981906890869, 0.9723071455955505, 0.9886989593505859, 0.9624627232551575, 0.9894862174987793, 0.982790470123291, 0.9747027158737183, 0.9871033430099487, 0.9715656638145447, 0.9734950661659241, 0.9944828748703003, 1.0080913305282593, 1.021220326423645, 0.9951609373092651, 1.0078625679016113, 1.00711989402771, 1.0143920183181763, 1.0281003713607788, 1.0113900899887085, 1.0080761909484863, 1.0004216432571411, 1.0242730379104614, 1.0335345268249512, 1.0490455627441406, 1.0375090837478638, 1.0500197410583496, 1.0510170459747314, 1.0320628881454468, 1.0554362535476685, 1.0438222885131836, 1.0400354862213135, 1.0563666820526123, 1.026753306388855, 1.0343279838562012, 1.0426831245422363, 1.0602377653121948, 1.0623100996017456, 1.0574674606323242, 1.063727617263794, 1.0781073570251465, 1.0835139751434326, 1.0600214004516602, 1.0818583965301514, 1.1070556640625], 'val_accuracy': [0.5878099203109741, 0.5754132270812988, 0.6074380278587341, 0.5971074104309082, 0.6084710955619812, 0.6818181872367859, 0.6570248007774353, 0.68388432264328, 0.6280992031097412, 0.663223147392273, 0.6776859760284424, 0.6849173307418823, 0.6869834661483765, 0.6673553586006165, 0.6766529083251953, 0.6849173307418823, 0.682851254940033, 0.6869834661483765, 0.6787189841270447, 0.6869834661483765, 0.6942148804664612, 0.6849173307418823, 0.6880165338516235, 0.6973140239715576, 0.6776859760284424, 0.672520637512207, 0.6776859760284424, 0.6756198406219482, 0.6849173307418823, 0.6818181872367859, 0.6859503984451294, 0.6900826692581177, 0.6776859760284424, 0.6787189841270447, 0.6869834661483765, 0.6818181872367859, 0.6900826692581177, 0.6797520518302917, 0.6756198406219482, 0.6766529083251953, 0.6714876294136047, 0.6818181872367859, 0.6756198406219482, 0.6787189841270447, 0.6735537052154541, 0.672520637512207, 0.6859503984451294, 0.6590909361839294, 0.6714876294136047, 0.6714876294136047, 0.6787189841270447, 0.663223147392273, 0.6818181872367859, 0.6756198406219482, 0.6776859760284424, 0.672520637512207, 0.672520637512207, 0.6683884263038635, 0.6570248007774353, 0.6776859760284424, 0.6694214940071106, 0.6807851195335388, 0.68388432264328, 0.682851254940033, 0.6745867729187012, 0.672520637512207, 0.6735537052154541, 0.663223147392273, 0.6549586653709412, 0.6735537052154541, 0.6776859760284424, 0.6818181872367859, 0.672520637512207, 0.6601239442825317, 0.6714876294136047, 0.6735537052154541, 0.6756198406219482, 0.6818181872367859, 0.6663222908973694, 0.66425621509552, 0.6766529083251953, 0.6570248007774353, 0.66425621509552, 0.6766529083251953, 0.682851254940033, 0.6807851195335388, 0.6756198406219482, 0.6735537052154541, 0.6797520518302917, 0.6807851195335388, 0.682851254940033, 0.6787189841270447, 0.6787189841270447, 0.6756198406219482, 0.672520637512207, 0.6818181872367859, 0.6735537052154541, 0.6756198406219482, 0.6611570119857788, 0.6652892827987671]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.5029 - accuracy: 0.8564"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 6s 54ms/step - loss: 0.5034 - accuracy: 0.8575 - val_loss: 0.8263 - val_accuracy: 0.5636\n","Epoch 2/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4937 - accuracy: 0.8658 - val_loss: 0.8158 - val_accuracy: 0.6552\n","Epoch 3/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4934 - accuracy: 0.8618 - val_loss: 0.8102 - val_accuracy: 0.6045\n","Epoch 4/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4752 - accuracy: 0.8688 - val_loss: 0.8000 - val_accuracy: 0.6293\n","Epoch 5/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4697 - accuracy: 0.8742 - val_loss: 0.7945 - val_accuracy: 0.6573\n","Epoch 6/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4705 - accuracy: 0.8718 - val_loss: 0.7862 - val_accuracy: 0.6595\n","Epoch 7/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4663 - accuracy: 0.8772 - val_loss: 0.7795 - val_accuracy: 0.6616\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4606 - accuracy: 0.8742 - val_loss: 0.7748 - val_accuracy: 0.6325\n","Epoch 9/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.4689 - accuracy: 0.8737 - val_loss: 0.7663 - val_accuracy: 0.6638\n","Epoch 10/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4636 - accuracy: 0.8718 - val_loss: 0.7649 - val_accuracy: 0.6562\n","Epoch 11/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4564 - accuracy: 0.8772 - val_loss: 0.7484 - val_accuracy: 0.6735\n","Epoch 12/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.4527 - accuracy: 0.8758 - val_loss: 0.7388 - val_accuracy: 0.6864\n","Epoch 13/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.4452 - accuracy: 0.8874 - val_loss: 0.7226 - val_accuracy: 0.7134\n","Epoch 14/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4497 - accuracy: 0.8801 - val_loss: 0.7167 - val_accuracy: 0.7155\n","Epoch 15/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4439 - accuracy: 0.8836 - val_loss: 0.7283 - val_accuracy: 0.7004\n","Epoch 16/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4458 - accuracy: 0.8807 - val_loss: 0.7179 - val_accuracy: 0.7004\n","Epoch 17/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4400 - accuracy: 0.8914 - val_loss: 0.7087 - val_accuracy: 0.7231\n","Epoch 18/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4423 - accuracy: 0.8817 - val_loss: 0.7000 - val_accuracy: 0.7457\n","Epoch 19/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4473 - accuracy: 0.8877 - val_loss: 0.7068 - val_accuracy: 0.7468\n","Epoch 20/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4371 - accuracy: 0.8858 - val_loss: 0.7132 - val_accuracy: 0.7522\n","Epoch 21/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4424 - accuracy: 0.8850 - val_loss: 0.7078 - val_accuracy: 0.7532\n","Epoch 22/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4393 - accuracy: 0.8890 - val_loss: 0.7120 - val_accuracy: 0.7478\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4263 - accuracy: 0.8925 - val_loss: 0.7138 - val_accuracy: 0.7500\n","Epoch 24/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4388 - accuracy: 0.8906 - val_loss: 0.7302 - val_accuracy: 0.7543\n","Epoch 25/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4391 - accuracy: 0.8855 - val_loss: 0.7423 - val_accuracy: 0.7446\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4200 - accuracy: 0.8976 - val_loss: 0.7501 - val_accuracy: 0.7457\n","Epoch 27/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4246 - accuracy: 0.8936 - val_loss: 0.7514 - val_accuracy: 0.7554\n","Epoch 28/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4179 - accuracy: 0.8957 - val_loss: 0.7615 - val_accuracy: 0.7554\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4140 - accuracy: 0.8984 - val_loss: 0.7816 - val_accuracy: 0.7414\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4226 - accuracy: 0.8922 - val_loss: 0.7822 - val_accuracy: 0.7403\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4095 - accuracy: 0.9011 - val_loss: 0.7949 - val_accuracy: 0.7489\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4039 - accuracy: 0.9001 - val_loss: 0.8269 - val_accuracy: 0.7328\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4069 - accuracy: 0.9006 - val_loss: 0.7927 - val_accuracy: 0.7457\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4141 - accuracy: 0.8941 - val_loss: 0.8185 - val_accuracy: 0.7425\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4091 - accuracy: 0.9019 - val_loss: 0.7963 - val_accuracy: 0.7478\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4112 - accuracy: 0.9022 - val_loss: 0.8254 - val_accuracy: 0.7446\n","Epoch 37/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4002 - accuracy: 0.9044 - val_loss: 0.8071 - val_accuracy: 0.7446\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3983 - accuracy: 0.9062 - val_loss: 0.8710 - val_accuracy: 0.7284\n","Epoch 39/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3975 - accuracy: 0.9060 - val_loss: 0.8108 - val_accuracy: 0.7468\n","Epoch 40/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3984 - accuracy: 0.9022 - val_loss: 0.8633 - val_accuracy: 0.7241\n","Epoch 41/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4030 - accuracy: 0.9006 - val_loss: 0.8358 - val_accuracy: 0.7489\n","Epoch 42/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3944 - accuracy: 0.9068 - val_loss: 0.8325 - val_accuracy: 0.7478\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4010 - accuracy: 0.9030 - val_loss: 0.9158 - val_accuracy: 0.7220\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3974 - accuracy: 0.9025 - val_loss: 0.8381 - val_accuracy: 0.7435\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3924 - accuracy: 0.9057 - val_loss: 0.8593 - val_accuracy: 0.7295\n","Epoch 46/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3872 - accuracy: 0.9098 - val_loss: 0.8440 - val_accuracy: 0.7392\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3853 - accuracy: 0.9100 - val_loss: 0.8439 - val_accuracy: 0.7489\n","Epoch 48/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3827 - accuracy: 0.9098 - val_loss: 0.8724 - val_accuracy: 0.7220\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3864 - accuracy: 0.9095 - val_loss: 0.8802 - val_accuracy: 0.7241\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3953 - accuracy: 0.9044 - val_loss: 0.8654 - val_accuracy: 0.7403\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3887 - accuracy: 0.9095 - val_loss: 0.8810 - val_accuracy: 0.7381\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3838 - accuracy: 0.9111 - val_loss: 0.8405 - val_accuracy: 0.7403\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3767 - accuracy: 0.9106 - val_loss: 0.8473 - val_accuracy: 0.7403\n","Epoch 54/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3806 - accuracy: 0.9146 - val_loss: 0.8461 - val_accuracy: 0.7371\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3746 - accuracy: 0.9149 - val_loss: 0.8814 - val_accuracy: 0.7414\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3882 - accuracy: 0.9084 - val_loss: 0.8799 - val_accuracy: 0.7403\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3840 - accuracy: 0.9111 - val_loss: 0.9104 - val_accuracy: 0.7338\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3726 - accuracy: 0.9103 - val_loss: 0.8482 - val_accuracy: 0.7328\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3749 - accuracy: 0.9138 - val_loss: 0.8613 - val_accuracy: 0.7489\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3762 - accuracy: 0.9087 - val_loss: 0.8961 - val_accuracy: 0.7328\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3730 - accuracy: 0.9133 - val_loss: 0.8797 - val_accuracy: 0.7414\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3690 - accuracy: 0.9168 - val_loss: 0.8841 - val_accuracy: 0.7392\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3599 - accuracy: 0.9200 - val_loss: 0.8842 - val_accuracy: 0.7511\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3661 - accuracy: 0.9195 - val_loss: 0.8819 - val_accuracy: 0.7371\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3616 - accuracy: 0.9213 - val_loss: 0.8861 - val_accuracy: 0.7392\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3683 - accuracy: 0.9149 - val_loss: 0.8752 - val_accuracy: 0.7371\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3706 - accuracy: 0.9124 - val_loss: 0.9155 - val_accuracy: 0.7306\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3828 - accuracy: 0.9076 - val_loss: 0.9038 - val_accuracy: 0.7403\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3606 - accuracy: 0.9230 - val_loss: 0.9003 - val_accuracy: 0.7425\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3580 - accuracy: 0.9240 - val_loss: 0.8934 - val_accuracy: 0.7425\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3482 - accuracy: 0.9273 - val_loss: 0.8954 - val_accuracy: 0.7392\n","Epoch 72/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3463 - accuracy: 0.9246 - val_loss: 0.8923 - val_accuracy: 0.7468\n","Epoch 73/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3505 - accuracy: 0.9246 - val_loss: 0.8993 - val_accuracy: 0.7446\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3501 - accuracy: 0.9216 - val_loss: 0.8954 - val_accuracy: 0.7489\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3496 - accuracy: 0.9246 - val_loss: 0.9303 - val_accuracy: 0.7435\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3547 - accuracy: 0.9221 - val_loss: 0.8879 - val_accuracy: 0.7500\n","Epoch 77/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3526 - accuracy: 0.9238 - val_loss: 0.8934 - val_accuracy: 0.7532\n","Epoch 78/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3533 - accuracy: 0.9230 - val_loss: 0.9064 - val_accuracy: 0.7414\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3587 - accuracy: 0.9181 - val_loss: 0.9254 - val_accuracy: 0.7381\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3405 - accuracy: 0.9254 - val_loss: 0.9103 - val_accuracy: 0.7349\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3352 - accuracy: 0.9281 - val_loss: 0.9199 - val_accuracy: 0.7425\n","Epoch 82/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3331 - accuracy: 0.9313 - val_loss: 0.9257 - val_accuracy: 0.7306\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3480 - accuracy: 0.9235 - val_loss: 0.9458 - val_accuracy: 0.7231\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3475 - accuracy: 0.9195 - val_loss: 0.9356 - val_accuracy: 0.7306\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3424 - accuracy: 0.9286 - val_loss: 0.9487 - val_accuracy: 0.7295\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3344 - accuracy: 0.9270 - val_loss: 0.9528 - val_accuracy: 0.7252\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3402 - accuracy: 0.9224 - val_loss: 0.9258 - val_accuracy: 0.7392\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3398 - accuracy: 0.9308 - val_loss: 0.9707 - val_accuracy: 0.7241\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3504 - accuracy: 0.9195 - val_loss: 0.9493 - val_accuracy: 0.7403\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3520 - accuracy: 0.9211 - val_loss: 0.9342 - val_accuracy: 0.7414\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3407 - accuracy: 0.9305 - val_loss: 0.9401 - val_accuracy: 0.7317\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3421 - accuracy: 0.9232 - val_loss: 0.9215 - val_accuracy: 0.7457\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3376 - accuracy: 0.9240 - val_loss: 0.9173 - val_accuracy: 0.7284\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3236 - accuracy: 0.9329 - val_loss: 0.9589 - val_accuracy: 0.7209\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3300 - accuracy: 0.9332 - val_loss: 0.9424 - val_accuracy: 0.7274\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3452 - accuracy: 0.9184 - val_loss: 1.0058 - val_accuracy: 0.7188\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3298 - accuracy: 0.9356 - val_loss: 0.9901 - val_accuracy: 0.7177\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3254 - accuracy: 0.9343 - val_loss: 0.9456 - val_accuracy: 0.7338\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3245 - accuracy: 0.9318 - val_loss: 0.9628 - val_accuracy: 0.7241\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3165 - accuracy: 0.9327 - val_loss: 0.9564 - val_accuracy: 0.7403\n","{'loss': [0.5033568739891052, 0.4936678409576416, 0.49336203932762146, 0.4751627743244171, 0.469698965549469, 0.47051578760147095, 0.4662606120109558, 0.4606187641620636, 0.46894150972366333, 0.46357449889183044, 0.4564303159713745, 0.4527133107185364, 0.44524380564689636, 0.44971463084220886, 0.44389474391937256, 0.4458431899547577, 0.439959317445755, 0.44229453802108765, 0.4473167359828949, 0.4370906949043274, 0.4423958361148834, 0.4393385648727417, 0.4263337254524231, 0.4388028085231781, 0.43914419412612915, 0.4199657440185547, 0.4245709180831909, 0.4179436266422272, 0.4139748215675354, 0.4226243495941162, 0.40948981046676636, 0.4039026200771332, 0.4068688750267029, 0.41407978534698486, 0.4091314971446991, 0.4112377464771271, 0.40021681785583496, 0.3982679545879364, 0.3975178897380829, 0.3984372019767761, 0.4029754400253296, 0.3944301903247833, 0.40103015303611755, 0.3973904550075531, 0.39236027002334595, 0.3871717154979706, 0.38531723618507385, 0.38267478346824646, 0.38643237948417664, 0.39534005522727966, 0.3887381851673126, 0.3838246166706085, 0.3767252266407013, 0.38062992691993713, 0.3745705783367157, 0.38816654682159424, 0.38401731848716736, 0.37263229489326477, 0.3749291002750397, 0.3762367367744446, 0.37302741408348083, 0.3690088987350464, 0.35989391803741455, 0.3660578429698944, 0.3615746796131134, 0.3682587444782257, 0.3706205487251282, 0.38283902406692505, 0.36062315106391907, 0.3579963445663452, 0.34823301434516907, 0.3463064134120941, 0.3504738211631775, 0.3500872850418091, 0.3495664596557617, 0.3546693027019501, 0.3525637686252594, 0.35329413414001465, 0.35873228311538696, 0.3405185639858246, 0.3352498412132263, 0.33310168981552124, 0.3479897081851959, 0.3475021421909332, 0.34241390228271484, 0.334431529045105, 0.34024810791015625, 0.33979982137680054, 0.35036441683769226, 0.35197946429252625, 0.3406904339790344, 0.3421214520931244, 0.3375588655471802, 0.32358720898628235, 0.3300451636314392, 0.3452078104019165, 0.3297639489173889, 0.3253920078277588, 0.32451021671295166, 0.31645968556404114], 'accuracy': [0.8574892282485962, 0.865840494632721, 0.8617995977401733, 0.868803858757019, 0.8741918206214905, 0.8717672228813171, 0.8771551847457886, 0.8741918206214905, 0.873652994632721, 0.8717672228813171, 0.8771551847457886, 0.8758081793785095, 0.8873922228813171, 0.8801185488700867, 0.8836206793785095, 0.8806573152542114, 0.8914331793785095, 0.8817349076271057, 0.8876616358757019, 0.8857758641242981, 0.8849676847457886, 0.889008641242981, 0.8925107717514038, 0.890625, 0.8855064511299133, 0.8976293206214905, 0.8935883641242981, 0.8957435488700867, 0.8984375, 0.892241358757019, 0.9011314511299133, 0.900053858757019, 0.9005926847457886, 0.8941271305084229, 0.9019396305084229, 0.9022090435028076, 0.9043642282485962, 0.90625, 0.9059805870056152, 0.9022090435028076, 0.9005926847457886, 0.9067887663841248, 0.9030172228813171, 0.9024784564971924, 0.9057112336158752, 0.9097521305084229, 0.9100215435028076, 0.9097521305084229, 0.9094827771186829, 0.9043642282485962, 0.9094827771186829, 0.9110991358757019, 0.9105603694915771, 0.9146012663841248, 0.9148706793785095, 0.9084051847457886, 0.9110991358757019, 0.9102909564971924, 0.9137930870056152, 0.9086745977401733, 0.9132543206214905, 0.9167564511299133, 0.9199892282485962, 0.9194504022598267, 0.9213362336158752, 0.9148706793785095, 0.912446141242981, 0.907597005367279, 0.9229525923728943, 0.9240301847457886, 0.9272629022598267, 0.9245689511299133, 0.9245689511299133, 0.9216055870056152, 0.9245689511299133, 0.9221444129943848, 0.9237607717514038, 0.9229525923728943, 0.9181034564971924, 0.9253771305084229, 0.928071141242981, 0.931303858757019, 0.923491358757019, 0.9194504022598267, 0.9286099076271057, 0.9269935488700867, 0.9224137663841248, 0.9307650923728943, 0.9194504022598267, 0.9210668206214905, 0.9304956793785095, 0.923222005367279, 0.9240301847457886, 0.9329202771186829, 0.9331896305084229, 0.9183728694915771, 0.9356142282485962, 0.9342672228813171, 0.9318426847457886, 0.9326508641242981], 'val_loss': [0.8262895941734314, 0.8158469200134277, 0.8101871609687805, 0.8000208735466003, 0.7944827675819397, 0.7861526608467102, 0.7795436978340149, 0.7748335003852844, 0.7662836909294128, 0.7649134993553162, 0.7483813166618347, 0.738778293132782, 0.7226239442825317, 0.7167119383811951, 0.7282832860946655, 0.7179408073425293, 0.7087492942810059, 0.6999843120574951, 0.7067602276802063, 0.7131873965263367, 0.7078463435173035, 0.7120371460914612, 0.7137572169303894, 0.7302495241165161, 0.7423455715179443, 0.7501415014266968, 0.7514095306396484, 0.7615472674369812, 0.7815771698951721, 0.7822170853614807, 0.7948809266090393, 0.8268596529960632, 0.7926760315895081, 0.8185172080993652, 0.7963138818740845, 0.8254406452178955, 0.8070784211158752, 0.8710231781005859, 0.8108404278755188, 0.8632702231407166, 0.8357917070388794, 0.8325105905532837, 0.9157840013504028, 0.838134229183197, 0.8592936396598816, 0.8440094590187073, 0.8438553214073181, 0.8724092841148376, 0.8802205920219421, 0.8654149174690247, 0.8809523582458496, 0.8405327796936035, 0.8473128080368042, 0.8461303114891052, 0.8813983201980591, 0.8799479007720947, 0.9103648066520691, 0.8482340574264526, 0.8612662553787231, 0.8961259722709656, 0.8797340989112854, 0.8840560913085938, 0.8841589689254761, 0.8818609118461609, 0.8861095309257507, 0.8752440214157104, 0.9154606461524963, 0.9038185477256775, 0.9002788066864014, 0.8934446573257446, 0.8954103589057922, 0.8922717571258545, 0.8992747068405151, 0.8954431414604187, 0.9303266406059265, 0.8879320025444031, 0.8934057950973511, 0.9063985347747803, 0.9253571629524231, 0.9102779626846313, 0.9199430346488953, 0.9257091879844666, 0.9458490610122681, 0.9355792999267578, 0.9487379193305969, 0.9527752995491028, 0.9257733821868896, 0.9707228541374207, 0.949250340461731, 0.9342080354690552, 0.9400902986526489, 0.9215114116668701, 0.9172827005386353, 0.9589188694953918, 0.9423893094062805, 1.0058060884475708, 0.990118682384491, 0.9456436038017273, 0.9628247618675232, 0.9563763737678528], 'val_accuracy': [0.5635775923728943, 0.6551724076271057, 0.6045258641242981, 0.6293103694915771, 0.6573275923728943, 0.6594827771186829, 0.6616379022598267, 0.6325430870056152, 0.6637930870056152, 0.65625, 0.673491358757019, 0.6864224076271057, 0.7133620977401733, 0.7155172228813171, 0.7004310488700867, 0.7004310488700867, 0.7230603694915771, 0.7456896305084229, 0.7467672228813171, 0.7521551847457886, 0.7532327771186829, 0.7478448152542114, 0.75, 0.7543103694915771, 0.7446120977401733, 0.7456896305084229, 0.7553879022598267, 0.7553879022598267, 0.7413793206214905, 0.7403017282485962, 0.7489224076271057, 0.732758641242981, 0.7456896305084229, 0.7424569129943848, 0.7478448152542114, 0.7446120977401733, 0.7446120977401733, 0.7284482717514038, 0.7467672228813171, 0.7241379022598267, 0.7489224076271057, 0.7478448152542114, 0.7219827771186829, 0.743534505367279, 0.7295258641242981, 0.7392241358757019, 0.7489224076271057, 0.7219827771186829, 0.7241379022598267, 0.7403017282485962, 0.7381465435028076, 0.7403017282485962, 0.7403017282485962, 0.7370689511299133, 0.7413793206214905, 0.7403017282485962, 0.7338362336158752, 0.732758641242981, 0.7489224076271057, 0.732758641242981, 0.7413793206214905, 0.7392241358757019, 0.7510775923728943, 0.7370689511299133, 0.7392241358757019, 0.7370689511299133, 0.7306034564971924, 0.7403017282485962, 0.7424569129943848, 0.7424569129943848, 0.7392241358757019, 0.7467672228813171, 0.7446120977401733, 0.7489224076271057, 0.743534505367279, 0.75, 0.7532327771186829, 0.7413793206214905, 0.7381465435028076, 0.7349137663841248, 0.7424569129943848, 0.7306034564971924, 0.7230603694915771, 0.7306034564971924, 0.7295258641242981, 0.725215494632721, 0.7392241358757019, 0.7241379022598267, 0.7403017282485962, 0.7413793206214905, 0.7316810488700867, 0.7456896305084229, 0.7284482717514038, 0.7209051847457886, 0.7273706793785095, 0.71875, 0.7176724076271057, 0.7338362336158752, 0.7241379022598267, 0.7403017282485962]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 9s 51ms/step - loss: 0.5244 - accuracy: 0.8432 - val_loss: 0.8278 - val_accuracy: 0.6471\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5048 - accuracy: 0.8520 - val_loss: 0.8239 - val_accuracy: 0.6086\n","Epoch 3/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5028 - accuracy: 0.8588 - val_loss: 0.8209 - val_accuracy: 0.6550\n","Epoch 4/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4870 - accuracy: 0.8588 - val_loss: 0.8110 - val_accuracy: 0.6380\n","Epoch 5/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4774 - accuracy: 0.8696 - val_loss: 0.8118 - val_accuracy: 0.6109\n","Epoch 6/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4961 - accuracy: 0.8582 - val_loss: 0.7992 - val_accuracy: 0.6335\n","Epoch 7/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4806 - accuracy: 0.8625 - val_loss: 0.7949 - val_accuracy: 0.6459\n","Epoch 8/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4768 - accuracy: 0.8647 - val_loss: 0.7870 - val_accuracy: 0.6493\n","Epoch 9/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4818 - accuracy: 0.8650 - val_loss: 0.7843 - val_accuracy: 0.6765\n","Epoch 10/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4851 - accuracy: 0.8613 - val_loss: 0.7702 - val_accuracy: 0.6946\n","Epoch 11/100\n","28/28 [==============================] - 1s 17ms/step - loss: 0.4803 - accuracy: 0.8676 - val_loss: 0.7701 - val_accuracy: 0.6708\n","Epoch 12/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4635 - accuracy: 0.8693 - val_loss: 0.7528 - val_accuracy: 0.7025\n","Epoch 13/100\n","28/28 [==============================] - 1s 17ms/step - loss: 0.4641 - accuracy: 0.8749 - val_loss: 0.7461 - val_accuracy: 0.6900\n","Epoch 14/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.4589 - accuracy: 0.8684 - val_loss: 0.7359 - val_accuracy: 0.7093\n","Epoch 15/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4574 - accuracy: 0.8778 - val_loss: 0.7298 - val_accuracy: 0.7172\n","Epoch 16/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4623 - accuracy: 0.8718 - val_loss: 0.7412 - val_accuracy: 0.6855\n","Epoch 17/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4488 - accuracy: 0.8817 - val_loss: 0.7247 - val_accuracy: 0.7149\n","Epoch 18/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4530 - accuracy: 0.8744 - val_loss: 0.7134 - val_accuracy: 0.7353\n","Epoch 19/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4507 - accuracy: 0.8778 - val_loss: 0.7403 - val_accuracy: 0.7059\n","Epoch 20/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4565 - accuracy: 0.8778 - val_loss: 0.7149 - val_accuracy: 0.7398\n","Epoch 21/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4717 - accuracy: 0.8619 - val_loss: 0.7585 - val_accuracy: 0.7195\n","Epoch 22/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4657 - accuracy: 0.8693 - val_loss: 0.7522 - val_accuracy: 0.7149\n","Epoch 23/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4547 - accuracy: 0.8766 - val_loss: 0.7185 - val_accuracy: 0.7489\n","Epoch 24/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4393 - accuracy: 0.8885 - val_loss: 0.7249 - val_accuracy: 0.7455\n","Epoch 25/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4431 - accuracy: 0.8789 - val_loss: 0.7412 - val_accuracy: 0.7398\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4347 - accuracy: 0.8877 - val_loss: 0.7652 - val_accuracy: 0.7285\n","Epoch 27/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4323 - accuracy: 0.8843 - val_loss: 0.7569 - val_accuracy: 0.7534\n","Epoch 28/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4326 - accuracy: 0.8806 - val_loss: 0.7521 - val_accuracy: 0.7557\n","Epoch 29/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4286 - accuracy: 0.8899 - val_loss: 0.7633 - val_accuracy: 0.7579\n","Epoch 30/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4243 - accuracy: 0.8933 - val_loss: 0.7776 - val_accuracy: 0.7568\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4312 - accuracy: 0.8916 - val_loss: 0.7799 - val_accuracy: 0.7568\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4274 - accuracy: 0.8891 - val_loss: 0.7888 - val_accuracy: 0.7523\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4248 - accuracy: 0.8874 - val_loss: 0.7854 - val_accuracy: 0.7455\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4222 - accuracy: 0.8911 - val_loss: 0.7875 - val_accuracy: 0.7523\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4191 - accuracy: 0.8945 - val_loss: 0.7948 - val_accuracy: 0.7500\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4192 - accuracy: 0.8905 - val_loss: 0.7835 - val_accuracy: 0.7568\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4276 - accuracy: 0.8882 - val_loss: 0.7982 - val_accuracy: 0.7489\n","Epoch 38/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4257 - accuracy: 0.8916 - val_loss: 0.8147 - val_accuracy: 0.7489\n","Epoch 39/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4180 - accuracy: 0.8874 - val_loss: 0.8072 - val_accuracy: 0.7545\n","Epoch 40/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4247 - accuracy: 0.8888 - val_loss: 0.8202 - val_accuracy: 0.7511\n","Epoch 41/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4184 - accuracy: 0.8916 - val_loss: 0.8138 - val_accuracy: 0.7557\n","Epoch 42/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4103 - accuracy: 0.8973 - val_loss: 0.8480 - val_accuracy: 0.7330\n","Epoch 43/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4087 - accuracy: 0.8962 - val_loss: 0.8586 - val_accuracy: 0.7172\n","Epoch 44/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4162 - accuracy: 0.8922 - val_loss: 0.8424 - val_accuracy: 0.7364\n","Epoch 45/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4080 - accuracy: 0.8959 - val_loss: 0.8107 - val_accuracy: 0.7545\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4042 - accuracy: 0.8967 - val_loss: 0.8529 - val_accuracy: 0.7398\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3998 - accuracy: 0.9015 - val_loss: 0.8307 - val_accuracy: 0.7432\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4002 - accuracy: 0.9066 - val_loss: 0.8102 - val_accuracy: 0.7443\n","Epoch 49/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3979 - accuracy: 0.9015 - val_loss: 0.8491 - val_accuracy: 0.7410\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4127 - accuracy: 0.8899 - val_loss: 0.9194 - val_accuracy: 0.7240\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4207 - accuracy: 0.8916 - val_loss: 0.8476 - val_accuracy: 0.7489\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3950 - accuracy: 0.9015 - val_loss: 0.8358 - val_accuracy: 0.7410\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3983 - accuracy: 0.9029 - val_loss: 0.8430 - val_accuracy: 0.7443\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3894 - accuracy: 0.9089 - val_loss: 0.8416 - val_accuracy: 0.7387\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4016 - accuracy: 0.8987 - val_loss: 0.8625 - val_accuracy: 0.7251\n","Epoch 56/100\n","28/28 [==============================] - 2s 62ms/step - loss: 0.3875 - accuracy: 0.9089 - val_loss: 0.8385 - val_accuracy: 0.7613\n","Epoch 57/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3984 - accuracy: 0.9049 - val_loss: 0.8801 - val_accuracy: 0.7319\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3926 - accuracy: 0.9061 - val_loss: 0.8456 - val_accuracy: 0.7500\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3903 - accuracy: 0.9024 - val_loss: 0.9411 - val_accuracy: 0.6957\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3811 - accuracy: 0.9137 - val_loss: 0.8687 - val_accuracy: 0.7262\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3896 - accuracy: 0.9058 - val_loss: 0.8858 - val_accuracy: 0.7364\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3805 - accuracy: 0.9086 - val_loss: 0.9577 - val_accuracy: 0.6867\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3834 - accuracy: 0.9143 - val_loss: 0.8757 - val_accuracy: 0.7489\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3703 - accuracy: 0.9182 - val_loss: 0.8700 - val_accuracy: 0.7421\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3832 - accuracy: 0.9097 - val_loss: 0.8975 - val_accuracy: 0.7443\n","Epoch 66/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3677 - accuracy: 0.9160 - val_loss: 0.8642 - val_accuracy: 0.7353\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3678 - accuracy: 0.9162 - val_loss: 0.8941 - val_accuracy: 0.7387\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3727 - accuracy: 0.9143 - val_loss: 0.8913 - val_accuracy: 0.7240\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3744 - accuracy: 0.9114 - val_loss: 0.9130 - val_accuracy: 0.7195\n","Epoch 70/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3683 - accuracy: 0.9120 - val_loss: 0.8726 - val_accuracy: 0.7455\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3665 - accuracy: 0.9095 - val_loss: 0.8923 - val_accuracy: 0.7376\n","Epoch 72/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3725 - accuracy: 0.9120 - val_loss: 0.9024 - val_accuracy: 0.7432\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3910 - accuracy: 0.8978 - val_loss: 0.9572 - val_accuracy: 0.7387\n","Epoch 74/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3858 - accuracy: 0.9109 - val_loss: 0.9246 - val_accuracy: 0.7308\n","Epoch 75/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3814 - accuracy: 0.9123 - val_loss: 0.8971 - val_accuracy: 0.7353\n","Epoch 76/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3740 - accuracy: 0.9143 - val_loss: 0.9033 - val_accuracy: 0.7421\n","Epoch 77/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3652 - accuracy: 0.9179 - val_loss: 0.8975 - val_accuracy: 0.7330\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3686 - accuracy: 0.9128 - val_loss: 0.9039 - val_accuracy: 0.7308\n","Epoch 79/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3558 - accuracy: 0.9219 - val_loss: 0.8998 - val_accuracy: 0.7364\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3545 - accuracy: 0.9205 - val_loss: 0.9095 - val_accuracy: 0.7308\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3552 - accuracy: 0.9219 - val_loss: 0.9098 - val_accuracy: 0.7398\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3608 - accuracy: 0.9174 - val_loss: 0.9059 - val_accuracy: 0.7308\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3611 - accuracy: 0.9151 - val_loss: 0.9529 - val_accuracy: 0.7127\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3556 - accuracy: 0.9239 - val_loss: 0.9544 - val_accuracy: 0.7296\n","Epoch 85/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3634 - accuracy: 0.9154 - val_loss: 0.9195 - val_accuracy: 0.7274\n","Epoch 86/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3484 - accuracy: 0.9267 - val_loss: 0.9444 - val_accuracy: 0.7421\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3534 - accuracy: 0.9239 - val_loss: 0.9183 - val_accuracy: 0.7319\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3490 - accuracy: 0.9211 - val_loss: 0.9119 - val_accuracy: 0.7353\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3352 - accuracy: 0.9349 - val_loss: 0.9161 - val_accuracy: 0.7353\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3536 - accuracy: 0.9247 - val_loss: 0.9119 - val_accuracy: 0.7398\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3628 - accuracy: 0.9154 - val_loss: 0.9441 - val_accuracy: 0.7319\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3401 - accuracy: 0.9293 - val_loss: 0.9352 - val_accuracy: 0.7353\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3430 - accuracy: 0.9267 - val_loss: 0.9214 - val_accuracy: 0.7376\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3430 - accuracy: 0.9233 - val_loss: 0.9450 - val_accuracy: 0.7206\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3351 - accuracy: 0.9242 - val_loss: 0.9265 - val_accuracy: 0.7376\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3378 - accuracy: 0.9256 - val_loss: 0.9299 - val_accuracy: 0.7364\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3390 - accuracy: 0.9270 - val_loss: 0.9828 - val_accuracy: 0.7342\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3457 - accuracy: 0.9261 - val_loss: 0.9588 - val_accuracy: 0.7387\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3372 - accuracy: 0.9293 - val_loss: 0.9695 - val_accuracy: 0.7353\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3424 - accuracy: 0.9219 - val_loss: 0.9530 - val_accuracy: 0.7240\n","{'loss': [0.5244348645210266, 0.5048359036445618, 0.50278240442276, 0.4870311915874481, 0.4774467647075653, 0.4961250126361847, 0.48062536120414734, 0.4767549932003021, 0.48183420300483704, 0.48514050245285034, 0.48029735684394836, 0.4635351002216339, 0.4640682339668274, 0.4589170217514038, 0.457360178232193, 0.4623362720012665, 0.44881927967071533, 0.4529528319835663, 0.45071402192115784, 0.4564851224422455, 0.47170132398605347, 0.46574053168296814, 0.4546952247619629, 0.4392693042755127, 0.4430534839630127, 0.4347155690193176, 0.43234783411026, 0.4326448440551758, 0.42858952283859253, 0.424338161945343, 0.4311605989933014, 0.42740145325660706, 0.424786239862442, 0.4222372770309448, 0.4191109538078308, 0.41921448707580566, 0.42764654755592346, 0.4257335364818573, 0.41799303889274597, 0.4246557056903839, 0.41837379336357117, 0.41029781103134155, 0.40870431065559387, 0.4162207543849945, 0.40795382857322693, 0.4041752517223358, 0.3997843861579895, 0.4002426862716675, 0.3978725075721741, 0.4127255976200104, 0.4207329750061035, 0.3949578106403351, 0.39831286668777466, 0.3894191086292267, 0.4015531837940216, 0.3875417113304138, 0.39840033650398254, 0.3926159739494324, 0.3903042674064636, 0.3810637295246124, 0.3895644545555115, 0.38050079345703125, 0.3834170699119568, 0.37029674649238586, 0.38322752714157104, 0.367747038602829, 0.36782127618789673, 0.3727225959300995, 0.3743540644645691, 0.3682889938354492, 0.3664807081222534, 0.3724660277366638, 0.3909766376018524, 0.38575035333633423, 0.3813530504703522, 0.3739685118198395, 0.36517050862312317, 0.36857545375823975, 0.3557586967945099, 0.3545491397380829, 0.35521066188812256, 0.36076563596725464, 0.36114174127578735, 0.35564810037612915, 0.36341381072998047, 0.3484291136264801, 0.3533630073070526, 0.3490135073661804, 0.3352126181125641, 0.3535977005958557, 0.36283615231513977, 0.3401109278202057, 0.34295088052749634, 0.3429582118988037, 0.3350701928138733, 0.3378027379512787, 0.3389851152896881, 0.34568941593170166, 0.33716881275177, 0.3424495458602905], 'accuracy': [0.8432371020317078, 0.8520090579986572, 0.8588002324104309, 0.8588002324104309, 0.8695529103279114, 0.8582342863082886, 0.8624787926673889, 0.8647425174713135, 0.8650254607200623, 0.8613469004631042, 0.8675721287727356, 0.8692699670791626, 0.8749292492866516, 0.8684210777282715, 0.8777589201927185, 0.8718166351318359, 0.8817204236984253, 0.8743633031845093, 0.8777589201927185, 0.8777589201927185, 0.8619128465652466, 0.8692699670791626, 0.8766270279884338, 0.888511598110199, 0.8788907527923584, 0.8876627087593079, 0.8842670917510986, 0.8805885910987854, 0.8899264335632324, 0.8933219909667969, 0.8916242122650146, 0.8890775442123413, 0.8873797655105591, 0.8910582661628723, 0.8944538831710815, 0.8904923796653748, 0.8882286548614502, 0.8916242122650146, 0.8873797655105591, 0.8887945413589478, 0.8916242122650146, 0.8972835540771484, 0.8961516618728638, 0.892190158367157, 0.895868718624115, 0.8967176079750061, 0.901528000831604, 0.9066213965415955, 0.901528000831604, 0.8899264335632324, 0.8916242122650146, 0.901528000831604, 0.9029428362846375, 0.90888512134552, 0.8986983299255371, 0.90888512134552, 0.9049236178398132, 0.9060554504394531, 0.9023768901824951, 0.9136955142021179, 0.9057725071907043, 0.9086021780967712, 0.9142614603042603, 0.918222963809967, 0.9097340106964111, 0.9159592390060425, 0.916242241859436, 0.9142614603042603, 0.9114317893981934, 0.9119977355003357, 0.9094510674476624, 0.9119977355003357, 0.897849440574646, 0.9108659029006958, 0.9122806787490845, 0.9142614603042603, 0.9179400205612183, 0.9128466248512268, 0.921901524066925, 0.9204866886138916, 0.921901524066925, 0.9173740744590759, 0.9151103496551514, 0.9238823056221008, 0.9153932929039001, 0.926711916923523, 0.9238823056221008, 0.9210526347160339, 0.9349179267883301, 0.9247311949729919, 0.9153932929039001, 0.9292586445808411, 0.926711916923523, 0.9233163595199585, 0.9241652488708496, 0.9255800843238831, 0.9269949197769165, 0.9261460304260254, 0.9292586445808411, 0.921901524066925], 'val_loss': [0.8278104066848755, 0.8238734602928162, 0.8209433555603027, 0.8110411763191223, 0.8118366003036499, 0.7992299795150757, 0.7948601245880127, 0.7870339155197144, 0.7842544913291931, 0.770224392414093, 0.7701144218444824, 0.7528499960899353, 0.7461390495300293, 0.7359387874603271, 0.7298229336738586, 0.7412332892417908, 0.7247409820556641, 0.7133517265319824, 0.7402952909469604, 0.7148643732070923, 0.7585188150405884, 0.7521758675575256, 0.7184919118881226, 0.7249454259872437, 0.7412296533584595, 0.7651950716972351, 0.7568789124488831, 0.7520530223846436, 0.7633469104766846, 0.7776275873184204, 0.7799103856086731, 0.7887711524963379, 0.7854238152503967, 0.7874759435653687, 0.7947679758071899, 0.7834627032279968, 0.798241376876831, 0.8147333860397339, 0.8071551322937012, 0.8201969265937805, 0.8137669563293457, 0.8479848504066467, 0.8586413264274597, 0.8424173593521118, 0.8107423186302185, 0.8529402613639832, 0.8307390213012695, 0.8101914525032043, 0.8491120338439941, 0.919427216053009, 0.8475612998008728, 0.835839569568634, 0.8429690003395081, 0.8416298031806946, 0.8624783158302307, 0.8384929895401001, 0.8800554871559143, 0.845592737197876, 0.9411405920982361, 0.8686789274215698, 0.8858100175857544, 0.9576883912086487, 0.8756771683692932, 0.8699694275856018, 0.8974732160568237, 0.8642287850379944, 0.8940733671188354, 0.8913147449493408, 0.9130054116249084, 0.8725546002388, 0.8923391699790955, 0.902442216873169, 0.9571871757507324, 0.9245842695236206, 0.8970671892166138, 0.9033334851264954, 0.8974589109420776, 0.9039166569709778, 0.8997716903686523, 0.9095335602760315, 0.9097961783409119, 0.9059205651283264, 0.9529454112052917, 0.9544466733932495, 0.9194999933242798, 0.9444428086280823, 0.9182806015014648, 0.9119119048118591, 0.9161094427108765, 0.9119082689285278, 0.9441072344779968, 0.9352142214775085, 0.9213807582855225, 0.9450308680534363, 0.9264713525772095, 0.929917573928833, 0.982801079750061, 0.9588004946708679, 0.9695430397987366, 0.953041136264801], 'val_accuracy': [0.6470588445663452, 0.6085972785949707, 0.6549773812294006, 0.6380090713500977, 0.610859751701355, 0.6334841847419739, 0.6459276080131531, 0.6493212580680847, 0.6764705777168274, 0.6945701241493225, 0.6708144545555115, 0.7024886608123779, 0.6900452375411987, 0.709276020526886, 0.7171945571899414, 0.685520350933075, 0.7149321436882019, 0.7352941036224365, 0.7058823704719543, 0.7398189902305603, 0.7194570302963257, 0.7149321436882019, 0.7488687634468079, 0.7454751133918762, 0.7398189902305603, 0.7285068035125732, 0.7533936500549316, 0.7556561231613159, 0.7579185366630554, 0.7567873597145081, 0.7567873597145081, 0.7522624731063843, 0.7454751133918762, 0.7522624731063843, 0.75, 0.7567873597145081, 0.7488687634468079, 0.7488687634468079, 0.7545248866081238, 0.7511312365531921, 0.7556561231613159, 0.733031690120697, 0.7171945571899414, 0.7364253401756287, 0.7545248866081238, 0.7398189902305603, 0.7432126402854919, 0.7443438768386841, 0.7409502267837524, 0.7239819169044495, 0.7488687634468079, 0.7409502267837524, 0.7443438768386841, 0.7386877536773682, 0.7251130938529968, 0.7613122463226318, 0.7319004535675049, 0.75, 0.6957013607025146, 0.726244330406189, 0.7364253401756287, 0.6866515874862671, 0.7488687634468079, 0.7420814633369446, 0.7443438768386841, 0.7352941036224365, 0.7386877536773682, 0.7239819169044495, 0.7194570302963257, 0.7454751133918762, 0.7375565767288208, 0.7432126402854919, 0.7386877536773682, 0.7307692170143127, 0.7352941036224365, 0.7420814633369446, 0.733031690120697, 0.7307692170143127, 0.7364253401756287, 0.7307692170143127, 0.7398189902305603, 0.7307692170143127, 0.7126696705818176, 0.7296379804611206, 0.7273755669593811, 0.7420814633369446, 0.7319004535675049, 0.7352941036224365, 0.7352941036224365, 0.7398189902305603, 0.7319004535675049, 0.7352941036224365, 0.7375565767288208, 0.720588207244873, 0.7375565767288208, 0.7364253401756287, 0.7341628670692444, 0.7386877536773682, 0.7352941036224365, 0.7239819169044495]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 8s 50ms/step - loss: 0.5100 - accuracy: 0.8504 - val_loss: 0.8202 - val_accuracy: 0.6033\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 1s 20ms/step - loss: 0.5202 - accuracy: 0.8494 - val_loss: 0.8129 - val_accuracy: 0.6632\n","Epoch 3/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5008 - accuracy: 0.8535 - val_loss: 0.8174 - val_accuracy: 0.6012\n","Epoch 4/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4912 - accuracy: 0.8674 - val_loss: 0.8001 - val_accuracy: 0.6529\n","Epoch 5/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4943 - accuracy: 0.8628 - val_loss: 0.7938 - val_accuracy: 0.6767\n","Epoch 6/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4928 - accuracy: 0.8636 - val_loss: 0.7840 - val_accuracy: 0.6756\n","Epoch 7/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4742 - accuracy: 0.8669 - val_loss: 0.7769 - val_accuracy: 0.6860\n","Epoch 8/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4897 - accuracy: 0.8607 - val_loss: 0.7663 - val_accuracy: 0.6808\n","Epoch 9/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4845 - accuracy: 0.8672 - val_loss: 0.7597 - val_accuracy: 0.6952\n","Epoch 10/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4647 - accuracy: 0.8760 - val_loss: 0.7500 - val_accuracy: 0.6952\n","Epoch 11/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4737 - accuracy: 0.8682 - val_loss: 0.7401 - val_accuracy: 0.7014\n","Epoch 12/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4748 - accuracy: 0.8656 - val_loss: 0.7341 - val_accuracy: 0.7138\n","Epoch 13/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4642 - accuracy: 0.8762 - val_loss: 0.7233 - val_accuracy: 0.7107\n","Epoch 14/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4618 - accuracy: 0.8809 - val_loss: 0.7184 - val_accuracy: 0.7097\n","Epoch 15/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4623 - accuracy: 0.8801 - val_loss: 0.7132 - val_accuracy: 0.7128\n","Epoch 16/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4559 - accuracy: 0.8811 - val_loss: 0.7291 - val_accuracy: 0.7283\n","Epoch 17/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4573 - accuracy: 0.8739 - val_loss: 0.7255 - val_accuracy: 0.7304\n","Epoch 18/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4585 - accuracy: 0.8780 - val_loss: 0.7177 - val_accuracy: 0.7345\n","Epoch 19/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4552 - accuracy: 0.8804 - val_loss: 0.7406 - val_accuracy: 0.7293\n","Epoch 20/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4469 - accuracy: 0.8817 - val_loss: 0.7404 - val_accuracy: 0.7252\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4449 - accuracy: 0.8829 - val_loss: 0.7507 - val_accuracy: 0.7273\n","Epoch 22/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4466 - accuracy: 0.8837 - val_loss: 0.7635 - val_accuracy: 0.7314\n","Epoch 23/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4438 - accuracy: 0.8824 - val_loss: 0.7742 - val_accuracy: 0.7345\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4476 - accuracy: 0.8817 - val_loss: 0.8212 - val_accuracy: 0.7118\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4446 - accuracy: 0.8868 - val_loss: 0.8242 - val_accuracy: 0.7252\n","Epoch 26/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4400 - accuracy: 0.8915 - val_loss: 0.8363 - val_accuracy: 0.7366\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4306 - accuracy: 0.8863 - val_loss: 0.8239 - val_accuracy: 0.7242\n","Epoch 28/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4400 - accuracy: 0.8876 - val_loss: 0.8347 - val_accuracy: 0.7324\n","Epoch 29/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4319 - accuracy: 0.8917 - val_loss: 0.8586 - val_accuracy: 0.7231\n","Epoch 30/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4331 - accuracy: 0.8915 - val_loss: 0.8551 - val_accuracy: 0.7324\n","Epoch 31/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4376 - accuracy: 0.8760 - val_loss: 0.8718 - val_accuracy: 0.7149\n","Epoch 32/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4264 - accuracy: 0.8897 - val_loss: 0.8615 - val_accuracy: 0.7169\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4294 - accuracy: 0.8889 - val_loss: 0.8843 - val_accuracy: 0.7231\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4302 - accuracy: 0.8910 - val_loss: 0.8620 - val_accuracy: 0.7242\n","Epoch 35/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4282 - accuracy: 0.8884 - val_loss: 0.8629 - val_accuracy: 0.7293\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4211 - accuracy: 0.8941 - val_loss: 0.9602 - val_accuracy: 0.6890\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4198 - accuracy: 0.8951 - val_loss: 0.8914 - val_accuracy: 0.7221\n","Epoch 38/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4127 - accuracy: 0.8979 - val_loss: 0.8857 - val_accuracy: 0.7262\n","Epoch 39/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4208 - accuracy: 0.8943 - val_loss: 0.8751 - val_accuracy: 0.7283\n","Epoch 40/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4194 - accuracy: 0.8943 - val_loss: 0.9201 - val_accuracy: 0.7128\n","Epoch 41/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4165 - accuracy: 0.8894 - val_loss: 0.9132 - val_accuracy: 0.7159\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4125 - accuracy: 0.8977 - val_loss: 0.9412 - val_accuracy: 0.7128\n","Epoch 43/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4145 - accuracy: 0.8925 - val_loss: 0.9131 - val_accuracy: 0.7190\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4100 - accuracy: 0.8984 - val_loss: 0.9214 - val_accuracy: 0.7231\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4026 - accuracy: 0.9000 - val_loss: 0.8986 - val_accuracy: 0.7304\n","Epoch 46/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4062 - accuracy: 0.8943 - val_loss: 0.9067 - val_accuracy: 0.7221\n","Epoch 47/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3956 - accuracy: 0.9005 - val_loss: 0.9329 - val_accuracy: 0.7149\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3959 - accuracy: 0.9047 - val_loss: 0.9319 - val_accuracy: 0.7180\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3950 - accuracy: 0.9039 - val_loss: 0.9184 - val_accuracy: 0.7180\n","Epoch 50/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4015 - accuracy: 0.8992 - val_loss: 0.9336 - val_accuracy: 0.7045\n","Epoch 51/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3983 - accuracy: 0.8984 - val_loss: 0.9583 - val_accuracy: 0.7190\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3927 - accuracy: 0.9070 - val_loss: 0.9449 - val_accuracy: 0.7159\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4020 - accuracy: 0.9031 - val_loss: 0.9450 - val_accuracy: 0.7252\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4088 - accuracy: 0.8984 - val_loss: 0.9859 - val_accuracy: 0.7180\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3986 - accuracy: 0.9044 - val_loss: 0.9567 - val_accuracy: 0.7180\n","Epoch 56/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3965 - accuracy: 0.9031 - val_loss: 0.9575 - val_accuracy: 0.7118\n","Epoch 57/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3899 - accuracy: 0.9047 - val_loss: 0.9645 - val_accuracy: 0.7076\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3917 - accuracy: 0.9062 - val_loss: 0.9809 - val_accuracy: 0.7056\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3849 - accuracy: 0.9049 - val_loss: 0.9769 - val_accuracy: 0.7221\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3795 - accuracy: 0.9127 - val_loss: 0.9776 - val_accuracy: 0.7035\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3924 - accuracy: 0.9021 - val_loss: 0.9590 - val_accuracy: 0.7107\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3868 - accuracy: 0.9093 - val_loss: 0.9742 - val_accuracy: 0.7231\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3831 - accuracy: 0.9103 - val_loss: 0.9516 - val_accuracy: 0.7221\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3758 - accuracy: 0.9114 - val_loss: 0.9728 - val_accuracy: 0.7138\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3805 - accuracy: 0.9119 - val_loss: 1.0452 - val_accuracy: 0.7252\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3728 - accuracy: 0.9124 - val_loss: 0.9681 - val_accuracy: 0.7314\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3701 - accuracy: 0.9152 - val_loss: 0.9806 - val_accuracy: 0.7200\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3804 - accuracy: 0.9075 - val_loss: 1.0559 - val_accuracy: 0.7149\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3924 - accuracy: 0.9057 - val_loss: 1.0296 - val_accuracy: 0.7107\n","Epoch 70/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3777 - accuracy: 0.9080 - val_loss: 0.9942 - val_accuracy: 0.7200\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3731 - accuracy: 0.9132 - val_loss: 0.9994 - val_accuracy: 0.7076\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3745 - accuracy: 0.9116 - val_loss: 1.0189 - val_accuracy: 0.7149\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3715 - accuracy: 0.9114 - val_loss: 1.0326 - val_accuracy: 0.7025\n","Epoch 74/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3908 - accuracy: 0.9067 - val_loss: 1.0164 - val_accuracy: 0.7252\n","Epoch 75/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4033 - accuracy: 0.9049 - val_loss: 1.0153 - val_accuracy: 0.6983\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3679 - accuracy: 0.9070 - val_loss: 1.0136 - val_accuracy: 0.7128\n","Epoch 77/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3672 - accuracy: 0.9183 - val_loss: 0.9996 - val_accuracy: 0.7056\n","Epoch 78/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3673 - accuracy: 0.9163 - val_loss: 1.0339 - val_accuracy: 0.7045\n","Epoch 79/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3609 - accuracy: 0.9204 - val_loss: 1.0251 - val_accuracy: 0.7107\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3644 - accuracy: 0.9181 - val_loss: 1.0316 - val_accuracy: 0.7004\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3524 - accuracy: 0.9227 - val_loss: 1.0108 - val_accuracy: 0.7045\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3565 - accuracy: 0.9212 - val_loss: 1.0988 - val_accuracy: 0.7035\n","Epoch 83/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3645 - accuracy: 0.9124 - val_loss: 1.0328 - val_accuracy: 0.7221\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3606 - accuracy: 0.9202 - val_loss: 1.0615 - val_accuracy: 0.7231\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3638 - accuracy: 0.9160 - val_loss: 1.0272 - val_accuracy: 0.7180\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3661 - accuracy: 0.9098 - val_loss: 1.2361 - val_accuracy: 0.6467\n","Epoch 87/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4145 - accuracy: 0.8881 - val_loss: 1.0075 - val_accuracy: 0.7056\n","Epoch 88/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3712 - accuracy: 0.9132 - val_loss: 1.0574 - val_accuracy: 0.7159\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3745 - accuracy: 0.9106 - val_loss: 1.1113 - val_accuracy: 0.6994\n","Epoch 90/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3592 - accuracy: 0.9152 - val_loss: 1.0430 - val_accuracy: 0.6973\n","Epoch 91/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3560 - accuracy: 0.9158 - val_loss: 1.0219 - val_accuracy: 0.7231\n","Epoch 92/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3550 - accuracy: 0.9217 - val_loss: 1.0685 - val_accuracy: 0.7180\n","Epoch 93/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3509 - accuracy: 0.9256 - val_loss: 1.1469 - val_accuracy: 0.6746\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3480 - accuracy: 0.9225 - val_loss: 1.0187 - val_accuracy: 0.7293\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3528 - accuracy: 0.9207 - val_loss: 1.0652 - val_accuracy: 0.7066\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3447 - accuracy: 0.9225 - val_loss: 1.0780 - val_accuracy: 0.7076\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3495 - accuracy: 0.9209 - val_loss: 1.0752 - val_accuracy: 0.7066\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3532 - accuracy: 0.9207 - val_loss: 1.0573 - val_accuracy: 0.7118\n","Epoch 99/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3489 - accuracy: 0.9245 - val_loss: 1.0764 - val_accuracy: 0.7138\n","Epoch 100/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3564 - accuracy: 0.9204 - val_loss: 1.0744 - val_accuracy: 0.7107\n","{'loss': [0.5099803805351257, 0.5202174782752991, 0.500812292098999, 0.4912372827529907, 0.4943089187145233, 0.49279648065567017, 0.474176824092865, 0.489727646112442, 0.4844597280025482, 0.46470049023628235, 0.47374844551086426, 0.4748111665248871, 0.4642004370689392, 0.4618031978607178, 0.4623492360115051, 0.4558749794960022, 0.4572679102420807, 0.4585358500480652, 0.45518872141838074, 0.4468793272972107, 0.4448601007461548, 0.4465694725513458, 0.44382840394973755, 0.4476313591003418, 0.4445849657058716, 0.44001173973083496, 0.4305734634399414, 0.44001731276512146, 0.4318595826625824, 0.43314942717552185, 0.43759995698928833, 0.42637547850608826, 0.42944151163101196, 0.43023666739463806, 0.42823779582977295, 0.4211360216140747, 0.41983628273010254, 0.4126743674278259, 0.4207761287689209, 0.41939088702201843, 0.4165034592151642, 0.412460058927536, 0.41454073786735535, 0.4099859893321991, 0.40264207124710083, 0.4061679244041443, 0.3956102132797241, 0.39588817954063416, 0.3949551582336426, 0.4015458822250366, 0.3982710540294647, 0.3927023410797119, 0.4020328223705292, 0.40876325964927673, 0.3985672891139984, 0.3964656889438629, 0.389902263879776, 0.3917466104030609, 0.38490140438079834, 0.379501074552536, 0.3924477994441986, 0.386787474155426, 0.38305461406707764, 0.37578025460243225, 0.3804742395877838, 0.3727656602859497, 0.37010055780410767, 0.3804416358470917, 0.3924402594566345, 0.37767624855041504, 0.37310197949409485, 0.374531626701355, 0.37152594327926636, 0.3908064663410187, 0.4032561182975769, 0.3678576648235321, 0.3671836853027344, 0.36733686923980713, 0.3608522117137909, 0.3643719255924225, 0.35235166549682617, 0.3564568758010864, 0.3645065128803253, 0.3606048822402954, 0.36377599835395813, 0.36606982350349426, 0.4144676625728607, 0.371227502822876, 0.37453150749206543, 0.3591517210006714, 0.35603755712509155, 0.35495856404304504, 0.3508918583393097, 0.3479904234409332, 0.3528175950050354, 0.34471848607063293, 0.3494567275047302, 0.35316163301467896, 0.348893404006958, 0.35640954971313477], 'accuracy': [0.8503875732421875, 0.8493540287017822, 0.8534883856773376, 0.8674418330192566, 0.8627907037734985, 0.8635658621788025, 0.866925060749054, 0.8607234954833984, 0.8671834468841553, 0.8759689927101135, 0.8682170510292053, 0.8656330704689026, 0.8762273788452148, 0.8808785676956177, 0.880103349685669, 0.881136953830719, 0.8739017844200134, 0.8780362010002136, 0.8803617358207703, 0.8816537261009216, 0.882945716381073, 0.8837209343910217, 0.8824289441108704, 0.8816537261009216, 0.8868216872215271, 0.8914728760719299, 0.8863049149513245, 0.8875969052314758, 0.8917312622070312, 0.8914728760719299, 0.8759689927101135, 0.8896640539169312, 0.8888888955116272, 0.8909560441970825, 0.8883720636367798, 0.8940568566322327, 0.8950904607772827, 0.8979328274726868, 0.894315242767334, 0.894315242767334, 0.8894056677818298, 0.8976744413375854, 0.89250648021698, 0.8984495997428894, 0.8999999761581421, 0.894315242767334, 0.9005168080329895, 0.9046511650085449, 0.9038759469985962, 0.8992248177528381, 0.8984495997428894, 0.9069767594337463, 0.9031007885932922, 0.8984495997428894, 0.9043927788734436, 0.9031007885932922, 0.9046511650085449, 0.9062015414237976, 0.9049095511436462, 0.9126614928245544, 0.9020671844482422, 0.9093023538589478, 0.910335898399353, 0.9113695025444031, 0.9118863344192505, 0.9124031066894531, 0.9152454733848572, 0.907493531703949, 0.905684769153595, 0.9080103635787964, 0.9131782650947571, 0.9116278886795044, 0.9113695025444031, 0.906718373298645, 0.9049095511436462, 0.9069767594337463, 0.9183462262153625, 0.9162790775299072, 0.9204134345054626, 0.9180878400802612, 0.9227390289306641, 0.9211886525154114, 0.9124031066894531, 0.9201550483703613, 0.9160206913948059, 0.9098191261291504, 0.8881136775016785, 0.9131782650947571, 0.9105943441390991, 0.9152454733848572, 0.9157622456550598, 0.921705424785614, 0.9255813956260681, 0.9224806427955627, 0.920671820640564, 0.9224806427955627, 0.9209302067756653, 0.920671820640564, 0.9245477914810181, 0.9204134345054626], 'val_loss': [0.8202490210533142, 0.8128675818443298, 0.8173721432685852, 0.8000941276550293, 0.7938230037689209, 0.7840043306350708, 0.7769055366516113, 0.766288161277771, 0.7596750855445862, 0.7499946355819702, 0.7401445508003235, 0.7340869903564453, 0.7232510447502136, 0.7183747887611389, 0.7131622433662415, 0.7291417121887207, 0.725456953048706, 0.7176538705825806, 0.7406184673309326, 0.7404410243034363, 0.7506636381149292, 0.7634649276733398, 0.7742270827293396, 0.8212394118309021, 0.8241845965385437, 0.8362613320350647, 0.8238982558250427, 0.8347230553627014, 0.858640193939209, 0.855056643486023, 0.8718319535255432, 0.8614513874053955, 0.8842869400978088, 0.861950695514679, 0.8628689050674438, 0.9601847529411316, 0.8914291262626648, 0.8857347965240479, 0.8750897645950317, 0.9201008677482605, 0.9131503701210022, 0.9411927461624146, 0.9130856394767761, 0.9213507175445557, 0.8986065983772278, 0.9066965579986572, 0.93287593126297, 0.9318878054618835, 0.9183798432350159, 0.9336457848548889, 0.9583308696746826, 0.9448739886283875, 0.9449559450149536, 0.9858914613723755, 0.956749677658081, 0.9574825167655945, 0.9645262360572815, 0.9808557629585266, 0.9768810272216797, 0.9776018857955933, 0.9590266942977905, 0.9742282032966614, 0.9515864253044128, 0.972772479057312, 1.0451549291610718, 0.9680918455123901, 0.9806082248687744, 1.0559278726577759, 1.0296443700790405, 0.9941585063934326, 0.9993895888328552, 1.0188617706298828, 1.0325798988342285, 1.016353726387024, 1.0153053998947144, 1.0135573148727417, 0.9995582699775696, 1.0338793992996216, 1.0250657796859741, 1.0315837860107422, 1.0108026266098022, 1.0988415479660034, 1.0328056812286377, 1.0614840984344482, 1.0271778106689453, 1.2361438274383545, 1.0074576139450073, 1.0574373006820679, 1.1112582683563232, 1.0430335998535156, 1.0218662023544312, 1.0684807300567627, 1.1468700170516968, 1.01865553855896, 1.0652471780776978, 1.0780017375946045, 1.075211524963379, 1.0573279857635498, 1.0763839483261108, 1.0744472742080688], 'val_accuracy': [0.6033057570457458, 0.663223147392273, 0.6012396812438965, 0.6528925895690918, 0.6766529083251953, 0.6756198406219482, 0.6859503984451294, 0.6807851195335388, 0.6952479481697083, 0.6952479481697083, 0.7014462947845459, 0.7138429880142212, 0.71074378490448, 0.7097107172012329, 0.7128099203109741, 0.7283057570457458, 0.73037189245224, 0.7345041036605835, 0.7293388247489929, 0.7252066135406494, 0.7272727489471436, 0.7314049601554871, 0.7345041036605835, 0.711776852607727, 0.7252066135406494, 0.7365702390670776, 0.7241735458374023, 0.7324380278587341, 0.7231404781341553, 0.7324380278587341, 0.7148760557174683, 0.7169421315193176, 0.7231404781341553, 0.7241735458374023, 0.7293388247489929, 0.6890496015548706, 0.7221074104309082, 0.7262396812438965, 0.7283057570457458, 0.7128099203109741, 0.7159090638160706, 0.7128099203109741, 0.7190082669258118, 0.7231404781341553, 0.73037189245224, 0.7221074104309082, 0.7148760557174683, 0.7179751992225647, 0.7179751992225647, 0.7045454382896423, 0.7190082669258118, 0.7159090638160706, 0.7252066135406494, 0.7179751992225647, 0.7179751992225647, 0.711776852607727, 0.7076446413993835, 0.7055785059928894, 0.7221074104309082, 0.7035123705863953, 0.71074378490448, 0.7231404781341553, 0.7221074104309082, 0.7138429880142212, 0.7252066135406494, 0.7314049601554871, 0.7200413346290588, 0.7148760557174683, 0.71074378490448, 0.7200413346290588, 0.7076446413993835, 0.7148760557174683, 0.702479362487793, 0.7252066135406494, 0.6983470916748047, 0.7128099203109741, 0.7055785059928894, 0.7045454382896423, 0.71074378490448, 0.7004132270812988, 0.7045454382896423, 0.7035123705863953, 0.7221074104309082, 0.7231404781341553, 0.7179751992225647, 0.6466942429542542, 0.7055785059928894, 0.7159090638160706, 0.6993801593780518, 0.6973140239715576, 0.7231404781341553, 0.7179751992225647, 0.6745867729187012, 0.7293388247489929, 0.7066115736961365, 0.7076446413993835, 0.7066115736961365, 0.711776852607727, 0.7138429880142212, 0.71074378490448]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/29 [========================>.....] - ETA: 0s - loss: 0.4313 - accuracy: 0.8916"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 51ms/step - loss: 0.4194 - accuracy: 0.8963 - val_loss: 0.7913 - val_accuracy: 0.6369\n","Epoch 2/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4000 - accuracy: 0.8947 - val_loss: 0.7825 - val_accuracy: 0.6228\n","Epoch 3/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3791 - accuracy: 0.9081 - val_loss: 0.7760 - val_accuracy: 0.6293\n","Epoch 4/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3781 - accuracy: 0.9068 - val_loss: 0.7722 - val_accuracy: 0.6185\n","Epoch 5/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3702 - accuracy: 0.9116 - val_loss: 0.7647 - val_accuracy: 0.6272\n","Epoch 6/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3675 - accuracy: 0.9057 - val_loss: 0.7566 - val_accuracy: 0.6584\n","Epoch 7/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3638 - accuracy: 0.9141 - val_loss: 0.7479 - val_accuracy: 0.6498\n","Epoch 8/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3684 - accuracy: 0.9114 - val_loss: 0.7517 - val_accuracy: 0.6293\n","Epoch 9/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3593 - accuracy: 0.9122 - val_loss: 0.7280 - val_accuracy: 0.6800\n","Epoch 10/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3699 - accuracy: 0.9071 - val_loss: 0.7199 - val_accuracy: 0.6843\n","Epoch 11/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3526 - accuracy: 0.9127 - val_loss: 0.7261 - val_accuracy: 0.6756\n","Epoch 12/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3572 - accuracy: 0.9208 - val_loss: 0.6969 - val_accuracy: 0.7037\n","Epoch 13/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3465 - accuracy: 0.9224 - val_loss: 0.6797 - val_accuracy: 0.7188\n","Epoch 14/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3501 - accuracy: 0.9203 - val_loss: 0.6724 - val_accuracy: 0.7274\n","Epoch 15/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3525 - accuracy: 0.9192 - val_loss: 0.6731 - val_accuracy: 0.7360\n","Epoch 16/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3414 - accuracy: 0.9232 - val_loss: 0.6573 - val_accuracy: 0.7425\n","Epoch 17/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3444 - accuracy: 0.9238 - val_loss: 0.6607 - val_accuracy: 0.7586\n","Epoch 18/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3511 - accuracy: 0.9162 - val_loss: 0.6561 - val_accuracy: 0.7619\n","Epoch 19/100\n","29/29 [==============================] - 1s 49ms/step - loss: 0.3380 - accuracy: 0.9235 - val_loss: 0.6775 - val_accuracy: 0.7629\n","Epoch 20/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3367 - accuracy: 0.9248 - val_loss: 0.6488 - val_accuracy: 0.7705\n","Epoch 21/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3276 - accuracy: 0.9278 - val_loss: 0.6523 - val_accuracy: 0.7791\n","Epoch 22/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3338 - accuracy: 0.9230 - val_loss: 0.6696 - val_accuracy: 0.7737\n","Epoch 23/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3221 - accuracy: 0.9305 - val_loss: 0.6721 - val_accuracy: 0.7888\n","Epoch 24/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3286 - accuracy: 0.9265 - val_loss: 0.7976 - val_accuracy: 0.7241\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3230 - accuracy: 0.9297 - val_loss: 0.6897 - val_accuracy: 0.7866\n","Epoch 26/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3210 - accuracy: 0.9329 - val_loss: 0.7060 - val_accuracy: 0.7888\n","Epoch 27/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3266 - accuracy: 0.9308 - val_loss: 0.7722 - val_accuracy: 0.7780\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3371 - accuracy: 0.9224 - val_loss: 0.7317 - val_accuracy: 0.7877\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3328 - accuracy: 0.9262 - val_loss: 0.7615 - val_accuracy: 0.7737\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3386 - accuracy: 0.9213 - val_loss: 0.8322 - val_accuracy: 0.7532\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3304 - accuracy: 0.9254 - val_loss: 0.8039 - val_accuracy: 0.7737\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3268 - accuracy: 0.9262 - val_loss: 0.7693 - val_accuracy: 0.7845\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3130 - accuracy: 0.9367 - val_loss: 0.7651 - val_accuracy: 0.7823\n","Epoch 34/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3150 - accuracy: 0.9332 - val_loss: 0.7765 - val_accuracy: 0.7759\n","Epoch 35/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3068 - accuracy: 0.9375 - val_loss: 0.7728 - val_accuracy: 0.7856\n","Epoch 36/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3110 - accuracy: 0.9318 - val_loss: 0.7882 - val_accuracy: 0.7780\n","Epoch 37/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3159 - accuracy: 0.9316 - val_loss: 0.7680 - val_accuracy: 0.7791\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3152 - accuracy: 0.9345 - val_loss: 0.7943 - val_accuracy: 0.7726\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3199 - accuracy: 0.9256 - val_loss: 0.8101 - val_accuracy: 0.7834\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3318 - accuracy: 0.9270 - val_loss: 0.7896 - val_accuracy: 0.7866\n","Epoch 41/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3529 - accuracy: 0.9157 - val_loss: 0.8209 - val_accuracy: 0.7791\n","Epoch 42/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3121 - accuracy: 0.9362 - val_loss: 0.8254 - val_accuracy: 0.7780\n","Epoch 43/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3034 - accuracy: 0.9415 - val_loss: 0.8319 - val_accuracy: 0.7651\n","Epoch 44/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3107 - accuracy: 0.9305 - val_loss: 0.8309 - val_accuracy: 0.7834\n","Epoch 45/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3079 - accuracy: 0.9386 - val_loss: 0.8168 - val_accuracy: 0.7737\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3168 - accuracy: 0.9286 - val_loss: 0.8433 - val_accuracy: 0.7705\n","Epoch 47/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3030 - accuracy: 0.9380 - val_loss: 0.8251 - val_accuracy: 0.7780\n","Epoch 48/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3044 - accuracy: 0.9351 - val_loss: 0.8054 - val_accuracy: 0.7780\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3052 - accuracy: 0.9308 - val_loss: 0.8165 - val_accuracy: 0.7802\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3031 - accuracy: 0.9380 - val_loss: 0.8245 - val_accuracy: 0.7737\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3076 - accuracy: 0.9305 - val_loss: 0.8365 - val_accuracy: 0.7640\n","Epoch 52/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3079 - accuracy: 0.9348 - val_loss: 0.8200 - val_accuracy: 0.7748\n","Epoch 53/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3109 - accuracy: 0.9375 - val_loss: 0.8154 - val_accuracy: 0.7769\n","Epoch 54/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3048 - accuracy: 0.9337 - val_loss: 0.8185 - val_accuracy: 0.7769\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2870 - accuracy: 0.9418 - val_loss: 0.8322 - val_accuracy: 0.7726\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2920 - accuracy: 0.9418 - val_loss: 0.8335 - val_accuracy: 0.7769\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2907 - accuracy: 0.9378 - val_loss: 0.8694 - val_accuracy: 0.7705\n","Epoch 58/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3054 - accuracy: 0.9378 - val_loss: 0.8553 - val_accuracy: 0.7672\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2964 - accuracy: 0.9415 - val_loss: 0.8801 - val_accuracy: 0.7737\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2918 - accuracy: 0.9397 - val_loss: 0.8509 - val_accuracy: 0.7737\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3188 - accuracy: 0.9318 - val_loss: 0.9336 - val_accuracy: 0.7414\n","Epoch 62/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3039 - accuracy: 0.9394 - val_loss: 0.8320 - val_accuracy: 0.7769\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2813 - accuracy: 0.9480 - val_loss: 0.8958 - val_accuracy: 0.7446\n","Epoch 64/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2998 - accuracy: 0.9380 - val_loss: 0.8742 - val_accuracy: 0.7586\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2982 - accuracy: 0.9397 - val_loss: 0.8922 - val_accuracy: 0.7554\n","Epoch 66/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2818 - accuracy: 0.9456 - val_loss: 0.8676 - val_accuracy: 0.7662\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3016 - accuracy: 0.9356 - val_loss: 0.8817 - val_accuracy: 0.7672\n","Epoch 68/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2870 - accuracy: 0.9413 - val_loss: 0.8861 - val_accuracy: 0.7726\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2912 - accuracy: 0.9410 - val_loss: 0.8847 - val_accuracy: 0.7619\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2860 - accuracy: 0.9394 - val_loss: 0.9442 - val_accuracy: 0.7543\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2974 - accuracy: 0.9289 - val_loss: 0.9038 - val_accuracy: 0.7629\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3171 - accuracy: 0.9308 - val_loss: 0.9664 - val_accuracy: 0.7338\n","Epoch 73/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3035 - accuracy: 0.9397 - val_loss: 0.8470 - val_accuracy: 0.7737\n","Epoch 74/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2941 - accuracy: 0.9429 - val_loss: 0.8918 - val_accuracy: 0.7694\n","Epoch 75/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2944 - accuracy: 0.9410 - val_loss: 0.9113 - val_accuracy: 0.7489\n","Epoch 76/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2723 - accuracy: 0.9491 - val_loss: 0.8796 - val_accuracy: 0.7683\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2756 - accuracy: 0.9464 - val_loss: 0.8636 - val_accuracy: 0.7662\n","Epoch 78/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2802 - accuracy: 0.9426 - val_loss: 0.8801 - val_accuracy: 0.7812\n","Epoch 79/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2687 - accuracy: 0.9523 - val_loss: 0.8731 - val_accuracy: 0.7759\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2704 - accuracy: 0.9483 - val_loss: 0.8760 - val_accuracy: 0.7716\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2763 - accuracy: 0.9491 - val_loss: 0.9219 - val_accuracy: 0.7705\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2823 - accuracy: 0.9415 - val_loss: 0.9164 - val_accuracy: 0.7554\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2774 - accuracy: 0.9437 - val_loss: 0.8940 - val_accuracy: 0.7672\n","Epoch 84/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2811 - accuracy: 0.9467 - val_loss: 0.9302 - val_accuracy: 0.7586\n","Epoch 85/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2777 - accuracy: 0.9402 - val_loss: 0.9309 - val_accuracy: 0.7629\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2879 - accuracy: 0.9407 - val_loss: 0.9105 - val_accuracy: 0.7694\n","Epoch 87/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2785 - accuracy: 0.9442 - val_loss: 1.0446 - val_accuracy: 0.7274\n","Epoch 88/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2698 - accuracy: 0.9461 - val_loss: 0.9076 - val_accuracy: 0.7629\n","Epoch 89/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2675 - accuracy: 0.9499 - val_loss: 0.9106 - val_accuracy: 0.7586\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2677 - accuracy: 0.9445 - val_loss: 0.9474 - val_accuracy: 0.7608\n","Epoch 91/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2775 - accuracy: 0.9415 - val_loss: 0.9225 - val_accuracy: 0.7629\n","Epoch 92/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2806 - accuracy: 0.9386 - val_loss: 0.9192 - val_accuracy: 0.7672\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2789 - accuracy: 0.9432 - val_loss: 1.0643 - val_accuracy: 0.7177\n","Epoch 94/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2729 - accuracy: 0.9445 - val_loss: 0.9497 - val_accuracy: 0.7651\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2715 - accuracy: 0.9502 - val_loss: 0.9491 - val_accuracy: 0.7608\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2614 - accuracy: 0.9531 - val_loss: 0.9315 - val_accuracy: 0.7640\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2660 - accuracy: 0.9499 - val_loss: 0.9308 - val_accuracy: 0.7565\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2571 - accuracy: 0.9534 - val_loss: 0.9513 - val_accuracy: 0.7532\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2798 - accuracy: 0.9453 - val_loss: 1.0457 - val_accuracy: 0.7392\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2771 - accuracy: 0.9407 - val_loss: 0.9509 - val_accuracy: 0.7619\n","{'loss': [0.41943931579589844, 0.3999723494052887, 0.3790598213672638, 0.3781316876411438, 0.3702092468738556, 0.36750298738479614, 0.36382654309272766, 0.3684377670288086, 0.3593355417251587, 0.369942307472229, 0.35257458686828613, 0.3571930527687073, 0.3465239703655243, 0.350068598985672, 0.3525203764438629, 0.3413720726966858, 0.3444214165210724, 0.3511177897453308, 0.3379627764225006, 0.33668938279151917, 0.32756665349006653, 0.3337985873222351, 0.3221435844898224, 0.32860463857650757, 0.32302799820899963, 0.32096078991889954, 0.32655495405197144, 0.33710333704948425, 0.3327830731868744, 0.3385670483112335, 0.3304172456264496, 0.32676962018013, 0.31298375129699707, 0.31500810384750366, 0.3068349063396454, 0.3110246956348419, 0.3159162998199463, 0.3152104318141937, 0.31991294026374817, 0.3317752480506897, 0.35285577178001404, 0.31210413575172424, 0.30340927839279175, 0.3107238709926605, 0.30785074830055237, 0.31679990887641907, 0.3030148446559906, 0.30438703298568726, 0.3052113950252533, 0.3031480610370636, 0.3076183497905731, 0.3078998029232025, 0.3109399080276489, 0.3047695755958557, 0.28696924448013306, 0.29198625683784485, 0.29070013761520386, 0.30544936656951904, 0.29641640186309814, 0.2918092906475067, 0.31879591941833496, 0.30388638377189636, 0.28133928775787354, 0.2998272478580475, 0.29822838306427, 0.2818368077278137, 0.30159056186676025, 0.28703218698501587, 0.2911713123321533, 0.28598278760910034, 0.2974238991737366, 0.3171483874320984, 0.3034900426864624, 0.29408299922943115, 0.29436901211738586, 0.27234479784965515, 0.27562496066093445, 0.28020986914634705, 0.26870015263557434, 0.27038055658340454, 0.2763059139251709, 0.2823089361190796, 0.2774384617805481, 0.2811434268951416, 0.2777281701564789, 0.2879396378993988, 0.27845585346221924, 0.26977643370628357, 0.2675330638885498, 0.2676708996295929, 0.27748867869377136, 0.28064900636672974, 0.2789250314235687, 0.27291569113731384, 0.2715248763561249, 0.26135334372520447, 0.2659851312637329, 0.25710180401802063, 0.27975139021873474, 0.2770731449127197], 'accuracy': [0.8962823152542114, 0.8946659564971924, 0.9081357717514038, 0.9067887663841248, 0.9116379022598267, 0.9057112336158752, 0.9140625, 0.9113685488700867, 0.9121767282485962, 0.9070581793785095, 0.912715494632721, 0.9207974076271057, 0.9224137663841248, 0.920258641242981, 0.9191810488700867, 0.923222005367279, 0.9237607717514038, 0.9162176847457886, 0.923491358757019, 0.9248383641242981, 0.9278017282485962, 0.9229525923728943, 0.9304956793785095, 0.9264547228813171, 0.9296875, 0.9329202771186829, 0.9307650923728943, 0.9224137663841248, 0.9261853694915771, 0.9213362336158752, 0.9253771305084229, 0.9261853694915771, 0.9366918206214905, 0.9331896305084229, 0.9375, 0.9318426847457886, 0.9315732717514038, 0.9345366358757019, 0.9256465435028076, 0.9269935488700867, 0.915678858757019, 0.936152994632721, 0.9415409564971924, 0.9304956793785095, 0.9385775923728943, 0.9286099076271057, 0.9380387663841248, 0.9350754022598267, 0.9307650923728943, 0.9380387663841248, 0.9304956793785095, 0.9348060488700867, 0.9375, 0.9337284564971924, 0.9418103694915771, 0.9418103694915771, 0.9377694129943848, 0.9377694129943848, 0.9415409564971924, 0.9396551847457886, 0.9318426847457886, 0.9393857717514038, 0.9480064511299133, 0.9380387663841248, 0.9396551847457886, 0.9455819129943848, 0.9356142282485962, 0.9412715435028076, 0.9410021305084229, 0.9393857717514038, 0.9288793206214905, 0.9307650923728943, 0.9396551847457886, 0.9428879022598267, 0.9410021305084229, 0.9490840435028076, 0.9463900923728943, 0.9426185488700867, 0.9523168206214905, 0.9482758641242981, 0.9490840435028076, 0.9415409564971924, 0.943696141242981, 0.946659505367279, 0.9401939511299133, 0.9407327771186829, 0.9442349076271057, 0.9461206793785095, 0.9498922228813171, 0.9445043206214905, 0.9415409564971924, 0.9385775923728943, 0.9431573152542114, 0.9445043206214905, 0.9501616358757019, 0.953125, 0.9498922228813171, 0.9533944129943848, 0.9453125, 0.9407327771186829], 'val_loss': [0.7912635207176208, 0.7824982404708862, 0.7759836912155151, 0.772171139717102, 0.7646874785423279, 0.7565894722938538, 0.7478615045547485, 0.75174480676651, 0.7279667258262634, 0.7198973298072815, 0.7261337041854858, 0.6968802809715271, 0.6797290444374084, 0.6724036931991577, 0.6731131076812744, 0.6572749614715576, 0.6606801152229309, 0.6560842394828796, 0.6775269508361816, 0.6487813591957092, 0.6523236632347107, 0.6695651412010193, 0.6721295118331909, 0.797629714012146, 0.6896768808364868, 0.7059675455093384, 0.7722316980361938, 0.7317277193069458, 0.7615406513214111, 0.83222496509552, 0.8039034008979797, 0.7692837119102478, 0.7651470899581909, 0.776467502117157, 0.7727595567703247, 0.7881594300270081, 0.7680186629295349, 0.7943450212478638, 0.8100507855415344, 0.78962641954422, 0.820894718170166, 0.8254339098930359, 0.8318877220153809, 0.8308614492416382, 0.8167994022369385, 0.843257486820221, 0.8251134157180786, 0.8053584098815918, 0.8165210485458374, 0.8245078325271606, 0.8365345001220703, 0.819998562335968, 0.8153837323188782, 0.8185105323791504, 0.8322421908378601, 0.8334566950798035, 0.8693786859512329, 0.855263888835907, 0.8801455497741699, 0.8508850336074829, 0.9336071610450745, 0.8320372104644775, 0.8958054184913635, 0.874204695224762, 0.8922125101089478, 0.8675765991210938, 0.881718099117279, 0.8860974311828613, 0.8846801519393921, 0.9441546201705933, 0.9038340449333191, 0.9663862586021423, 0.846989095211029, 0.891809344291687, 0.9112862348556519, 0.8796362280845642, 0.8636205792427063, 0.8800793886184692, 0.8730676174163818, 0.8760120868682861, 0.9218806028366089, 0.9164403676986694, 0.8939583897590637, 0.9301834106445312, 0.9309338927268982, 0.9105173349380493, 1.044615626335144, 0.9075696468353271, 0.9105883240699768, 0.9473650455474854, 0.9225367903709412, 0.9191520810127258, 1.0642892122268677, 0.9497247934341431, 0.9491464495658875, 0.931536078453064, 0.9307802319526672, 0.9513167142868042, 1.0456609725952148, 0.9509152770042419], 'val_accuracy': [0.6368534564971924, 0.6228448152542114, 0.6293103694915771, 0.618534505367279, 0.6271551847457886, 0.6584051847457886, 0.649784505367279, 0.6293103694915771, 0.6799569129943848, 0.6842672228813171, 0.6756465435028076, 0.7036637663841248, 0.71875, 0.7273706793785095, 0.735991358757019, 0.7424569129943848, 0.7586206793785095, 0.7618534564971924, 0.7629310488700867, 0.7704741358757019, 0.7790948152542114, 0.7737069129943848, 0.7887930870056152, 0.7241379022598267, 0.7866379022598267, 0.7887930870056152, 0.7780172228813171, 0.787715494632721, 0.7737069129943848, 0.7532327771186829, 0.7737069129943848, 0.7844827771186829, 0.7823275923728943, 0.7758620977401733, 0.7855603694915771, 0.7780172228813171, 0.7790948152542114, 0.7726293206214905, 0.7834051847457886, 0.7866379022598267, 0.7790948152542114, 0.7780172228813171, 0.7650862336158752, 0.7834051847457886, 0.7737069129943848, 0.7704741358757019, 0.7780172228813171, 0.7780172228813171, 0.7801724076271057, 0.7737069129943848, 0.764008641242981, 0.774784505367279, 0.7769396305084229, 0.7769396305084229, 0.7726293206214905, 0.7769396305084229, 0.7704741358757019, 0.767241358757019, 0.7737069129943848, 0.7737069129943848, 0.7413793206214905, 0.7769396305084229, 0.7446120977401733, 0.7586206793785095, 0.7553879022598267, 0.7661637663841248, 0.767241358757019, 0.7726293206214905, 0.7618534564971924, 0.7543103694915771, 0.7629310488700867, 0.7338362336158752, 0.7737069129943848, 0.7693965435028076, 0.7489224076271057, 0.7683189511299133, 0.7661637663841248, 0.78125, 0.7758620977401733, 0.7715517282485962, 0.7704741358757019, 0.7553879022598267, 0.767241358757019, 0.7586206793785095, 0.7629310488700867, 0.7693965435028076, 0.7273706793785095, 0.7629310488700867, 0.7586206793785095, 0.7607758641242981, 0.7629310488700867, 0.767241358757019, 0.7176724076271057, 0.7650862336158752, 0.7607758641242981, 0.764008641242981, 0.756465494632721, 0.7532327771186829, 0.7392241358757019, 0.7618534564971924]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.4282 - accuracy: 0.8877"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 56ms/step - loss: 0.4282 - accuracy: 0.8877 - val_loss: 0.7976 - val_accuracy: 0.6018\n","Epoch 2/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.3991 - accuracy: 0.8995 - val_loss: 0.7896 - val_accuracy: 0.6414\n","Epoch 3/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.3856 - accuracy: 0.9055 - val_loss: 0.7862 - val_accuracy: 0.6550\n","Epoch 4/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3867 - accuracy: 0.9032 - val_loss: 0.7814 - val_accuracy: 0.6210\n","Epoch 5/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3806 - accuracy: 0.9038 - val_loss: 0.7727 - val_accuracy: 0.6459\n","Epoch 6/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3791 - accuracy: 0.9049 - val_loss: 0.7644 - val_accuracy: 0.6505\n","Epoch 7/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3671 - accuracy: 0.9106 - val_loss: 0.7597 - val_accuracy: 0.6459\n","Epoch 8/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.3678 - accuracy: 0.9111 - val_loss: 0.7482 - val_accuracy: 0.6776\n","Epoch 9/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.3818 - accuracy: 0.9058 - val_loss: 0.7358 - val_accuracy: 0.6799\n","Epoch 10/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.3825 - accuracy: 0.9069 - val_loss: 0.7270 - val_accuracy: 0.6833\n","Epoch 11/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3632 - accuracy: 0.9134 - val_loss: 0.7133 - val_accuracy: 0.7070\n","Epoch 12/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.3562 - accuracy: 0.9202 - val_loss: 0.7122 - val_accuracy: 0.7183\n","Epoch 13/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3573 - accuracy: 0.9157 - val_loss: 0.6974 - val_accuracy: 0.7183\n","Epoch 14/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.3774 - accuracy: 0.9046 - val_loss: 0.6824 - val_accuracy: 0.7319\n","Epoch 15/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3538 - accuracy: 0.9199 - val_loss: 0.6672 - val_accuracy: 0.7455\n","Epoch 16/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3532 - accuracy: 0.9168 - val_loss: 0.6694 - val_accuracy: 0.7523\n","Epoch 17/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3520 - accuracy: 0.9174 - val_loss: 0.6520 - val_accuracy: 0.7658\n","Epoch 18/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3428 - accuracy: 0.9188 - val_loss: 0.6711 - val_accuracy: 0.7443\n","Epoch 19/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3581 - accuracy: 0.9154 - val_loss: 0.7008 - val_accuracy: 0.7308\n","Epoch 20/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3564 - accuracy: 0.9123 - val_loss: 0.6539 - val_accuracy: 0.7794\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3557 - accuracy: 0.9157 - val_loss: 0.6495 - val_accuracy: 0.7749\n","Epoch 22/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3619 - accuracy: 0.9145 - val_loss: 0.6545 - val_accuracy: 0.7783\n","Epoch 23/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3488 - accuracy: 0.9222 - val_loss: 0.6526 - val_accuracy: 0.7704\n","Epoch 24/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3478 - accuracy: 0.9225 - val_loss: 0.6697 - val_accuracy: 0.7907\n","Epoch 25/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3469 - accuracy: 0.9222 - val_loss: 0.6597 - val_accuracy: 0.7952\n","Epoch 26/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3404 - accuracy: 0.9208 - val_loss: 0.6787 - val_accuracy: 0.7986\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3403 - accuracy: 0.9273 - val_loss: 0.7040 - val_accuracy: 0.7771\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3652 - accuracy: 0.9123 - val_loss: 0.6943 - val_accuracy: 0.7896\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3389 - accuracy: 0.9228 - val_loss: 0.7373 - val_accuracy: 0.7738\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3539 - accuracy: 0.9117 - val_loss: 0.7189 - val_accuracy: 0.7907\n","Epoch 31/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3289 - accuracy: 0.9278 - val_loss: 0.7230 - val_accuracy: 0.7817\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3386 - accuracy: 0.9236 - val_loss: 0.7558 - val_accuracy: 0.7828\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3288 - accuracy: 0.9278 - val_loss: 0.7568 - val_accuracy: 0.7805\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3439 - accuracy: 0.9211 - val_loss: 0.7531 - val_accuracy: 0.7828\n","Epoch 35/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3241 - accuracy: 0.9310 - val_loss: 0.7385 - val_accuracy: 0.7907\n","Epoch 36/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3228 - accuracy: 0.9360 - val_loss: 0.7279 - val_accuracy: 0.7986\n","Epoch 37/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3202 - accuracy: 0.9298 - val_loss: 0.7486 - val_accuracy: 0.7839\n","Epoch 38/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3310 - accuracy: 0.9244 - val_loss: 0.7586 - val_accuracy: 0.7738\n","Epoch 39/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3447 - accuracy: 0.9290 - val_loss: 0.7826 - val_accuracy: 0.7794\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3349 - accuracy: 0.9250 - val_loss: 0.7686 - val_accuracy: 0.7817\n","Epoch 41/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3383 - accuracy: 0.9284 - val_loss: 0.7710 - val_accuracy: 0.7817\n","Epoch 42/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3299 - accuracy: 0.9261 - val_loss: 0.7536 - val_accuracy: 0.7839\n","Epoch 43/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3297 - accuracy: 0.9261 - val_loss: 0.7961 - val_accuracy: 0.7590\n","Epoch 44/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3208 - accuracy: 0.9318 - val_loss: 0.7685 - val_accuracy: 0.7794\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3299 - accuracy: 0.9256 - val_loss: 0.7725 - val_accuracy: 0.7794\n","Epoch 46/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3177 - accuracy: 0.9310 - val_loss: 0.7786 - val_accuracy: 0.7817\n","Epoch 47/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3209 - accuracy: 0.9321 - val_loss: 0.7873 - val_accuracy: 0.7805\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3445 - accuracy: 0.9148 - val_loss: 0.7676 - val_accuracy: 0.7749\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3295 - accuracy: 0.9264 - val_loss: 0.7860 - val_accuracy: 0.7738\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3105 - accuracy: 0.9411 - val_loss: 0.7897 - val_accuracy: 0.7851\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3262 - accuracy: 0.9287 - val_loss: 0.7982 - val_accuracy: 0.7704\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3345 - accuracy: 0.9290 - val_loss: 0.8172 - val_accuracy: 0.7545\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3189 - accuracy: 0.9315 - val_loss: 0.7923 - val_accuracy: 0.7771\n","Epoch 54/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3217 - accuracy: 0.9349 - val_loss: 0.8064 - val_accuracy: 0.7738\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3017 - accuracy: 0.9428 - val_loss: 0.8308 - val_accuracy: 0.7579\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3029 - accuracy: 0.9380 - val_loss: 0.8316 - val_accuracy: 0.7647\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3154 - accuracy: 0.9380 - val_loss: 0.7703 - val_accuracy: 0.7828\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2962 - accuracy: 0.9417 - val_loss: 0.7946 - val_accuracy: 0.7681\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3036 - accuracy: 0.9352 - val_loss: 0.8085 - val_accuracy: 0.7794\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3028 - accuracy: 0.9414 - val_loss: 0.8065 - val_accuracy: 0.7738\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3190 - accuracy: 0.9287 - val_loss: 0.8082 - val_accuracy: 0.7726\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3038 - accuracy: 0.9389 - val_loss: 0.8382 - val_accuracy: 0.7523\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3041 - accuracy: 0.9403 - val_loss: 0.8501 - val_accuracy: 0.7466\n","Epoch 64/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3059 - accuracy: 0.9372 - val_loss: 0.8758 - val_accuracy: 0.7353\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2961 - accuracy: 0.9417 - val_loss: 0.8391 - val_accuracy: 0.7715\n","Epoch 66/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2980 - accuracy: 0.9440 - val_loss: 0.8188 - val_accuracy: 0.7692\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2920 - accuracy: 0.9414 - val_loss: 0.8240 - val_accuracy: 0.7771\n","Epoch 68/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2911 - accuracy: 0.9403 - val_loss: 0.8234 - val_accuracy: 0.7715\n","Epoch 69/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2900 - accuracy: 0.9440 - val_loss: 0.8396 - val_accuracy: 0.7749\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3072 - accuracy: 0.9304 - val_loss: 0.8743 - val_accuracy: 0.7624\n","Epoch 71/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2987 - accuracy: 0.9386 - val_loss: 0.8369 - val_accuracy: 0.7771\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3088 - accuracy: 0.9344 - val_loss: 0.8495 - val_accuracy: 0.7647\n","Epoch 73/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3115 - accuracy: 0.9341 - val_loss: 0.8407 - val_accuracy: 0.7794\n","Epoch 74/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2945 - accuracy: 0.9406 - val_loss: 0.8373 - val_accuracy: 0.7715\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3201 - accuracy: 0.9355 - val_loss: 0.8298 - val_accuracy: 0.7749\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2962 - accuracy: 0.9383 - val_loss: 0.8771 - val_accuracy: 0.7704\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3075 - accuracy: 0.9420 - val_loss: 0.8432 - val_accuracy: 0.7828\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2919 - accuracy: 0.9460 - val_loss: 0.8508 - val_accuracy: 0.7692\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2880 - accuracy: 0.9468 - val_loss: 0.8449 - val_accuracy: 0.7771\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2884 - accuracy: 0.9428 - val_loss: 0.8357 - val_accuracy: 0.7715\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2827 - accuracy: 0.9460 - val_loss: 0.8368 - val_accuracy: 0.7726\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2906 - accuracy: 0.9428 - val_loss: 0.9014 - val_accuracy: 0.7681\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2959 - accuracy: 0.9431 - val_loss: 0.9066 - val_accuracy: 0.7692\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2925 - accuracy: 0.9445 - val_loss: 0.8455 - val_accuracy: 0.7692\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2802 - accuracy: 0.9423 - val_loss: 0.8479 - val_accuracy: 0.7771\n","Epoch 86/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2847 - accuracy: 0.9462 - val_loss: 0.9332 - val_accuracy: 0.7568\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2832 - accuracy: 0.9451 - val_loss: 0.8525 - val_accuracy: 0.7749\n","Epoch 88/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2915 - accuracy: 0.9394 - val_loss: 0.9001 - val_accuracy: 0.7670\n","Epoch 89/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2948 - accuracy: 0.9372 - val_loss: 0.8507 - val_accuracy: 0.7760\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2771 - accuracy: 0.9542 - val_loss: 0.8355 - val_accuracy: 0.7839\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2763 - accuracy: 0.9491 - val_loss: 0.8712 - val_accuracy: 0.7760\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2864 - accuracy: 0.9437 - val_loss: 0.8773 - val_accuracy: 0.7760\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2823 - accuracy: 0.9485 - val_loss: 0.8747 - val_accuracy: 0.7636\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2769 - accuracy: 0.9468 - val_loss: 0.8977 - val_accuracy: 0.7817\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2808 - accuracy: 0.9423 - val_loss: 0.9329 - val_accuracy: 0.7647\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2990 - accuracy: 0.9406 - val_loss: 0.9462 - val_accuracy: 0.7636\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2968 - accuracy: 0.9344 - val_loss: 0.9195 - val_accuracy: 0.7681\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2958 - accuracy: 0.9363 - val_loss: 0.9164 - val_accuracy: 0.7692\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2840 - accuracy: 0.9474 - val_loss: 0.9016 - val_accuracy: 0.7647\n","Epoch 100/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2822 - accuracy: 0.9428 - val_loss: 0.8966 - val_accuracy: 0.7636\n","{'loss': [0.4282446801662445, 0.39909934997558594, 0.3856084644794464, 0.38665682077407837, 0.3806328773498535, 0.3791472017765045, 0.3670869469642639, 0.36776894330978394, 0.38184818625450134, 0.38250675797462463, 0.3632369637489319, 0.35616955161094666, 0.3573039174079895, 0.3773701786994934, 0.3537580370903015, 0.353155255317688, 0.35199499130249023, 0.3427868187427521, 0.35811519622802734, 0.3564431369304657, 0.3557203412055969, 0.36185699701309204, 0.3488220274448395, 0.34778642654418945, 0.34686851501464844, 0.34037119150161743, 0.3403347134590149, 0.3652251064777374, 0.33887654542922974, 0.3539324104785919, 0.3289424180984497, 0.33863601088523865, 0.32884305715560913, 0.3438834547996521, 0.3240625858306885, 0.3227885663509369, 0.32016128301620483, 0.3310023248195648, 0.34469273686408997, 0.3349107801914215, 0.3382885158061981, 0.32993608713150024, 0.32966798543930054, 0.32080987095832825, 0.3298787772655487, 0.31768566370010376, 0.32093346118927, 0.3445248007774353, 0.3294687271118164, 0.31047776341438293, 0.32618629932403564, 0.33452287316322327, 0.3188687562942505, 0.3217291831970215, 0.3017388582229614, 0.30291658639907837, 0.3153951168060303, 0.2961988151073456, 0.30361440777778625, 0.302837610244751, 0.319013774394989, 0.3037709593772888, 0.3040655553340912, 0.30590125918388367, 0.29612311720848083, 0.2980402708053589, 0.29198944568634033, 0.29106688499450684, 0.29000866413116455, 0.3071623146533966, 0.29869404435157776, 0.3088114559650421, 0.3115174174308777, 0.29445725679397583, 0.32006287574768066, 0.29615092277526855, 0.3074793219566345, 0.2918786108493805, 0.2880173623561859, 0.2883504331111908, 0.2827431559562683, 0.29060083627700806, 0.2959001362323761, 0.2925430238246918, 0.28024816513061523, 0.2847261428833008, 0.2832150161266327, 0.29154783487319946, 0.2947753965854645, 0.27710965275764465, 0.2763406038284302, 0.28639692068099976, 0.2822704017162323, 0.276867151260376, 0.2807506024837494, 0.29901477694511414, 0.29684337973594666, 0.29579609632492065, 0.28401488065719604, 0.2822018563747406], 'accuracy': [0.8876627087593079, 0.899547278881073, 0.9054895043373108, 0.9032257795333862, 0.9037917256355286, 0.9049236178398132, 0.9105829000473022, 0.9111488461494446, 0.9057725071907043, 0.9069043397903442, 0.9134125709533691, 0.9202037453651428, 0.9156762957572937, 0.9046406149864197, 0.9199207425117493, 0.9168081283569336, 0.9173740744590759, 0.9187889099121094, 0.9153932929039001, 0.9122806787490845, 0.9156762957572937, 0.914544403553009, 0.9221844673156738, 0.9224674701690674, 0.9221844673156738, 0.9207696914672852, 0.9272778630256653, 0.9122806787490845, 0.9227504134178162, 0.9117147922515869, 0.9278438091278076, 0.9235993027687073, 0.9278438091278076, 0.9210526347160339, 0.9309564232826233, 0.9360498189926147, 0.9298245906829834, 0.9244481921195984, 0.9289756417274475, 0.9250141382217407, 0.92840975522995, 0.9261460304260254, 0.9261460304260254, 0.9318053126335144, 0.9255800843238831, 0.9309564232826233, 0.9320882558822632, 0.9148274064064026, 0.9264289736747742, 0.9411431550979614, 0.9286926984786987, 0.9289756417274475, 0.9315223693847656, 0.9349179267883301, 0.9428409934043884, 0.9380305409431458, 0.9380305409431458, 0.9417091012001038, 0.9352009296417236, 0.941426157951355, 0.9286926984786987, 0.9388794302940369, 0.9402942657470703, 0.9371816515922546, 0.9417091012001038, 0.9439728260040283, 0.941426157951355, 0.9402942657470703, 0.9439728260040283, 0.930390477180481, 0.9385964870452881, 0.9343519806861877, 0.934069037437439, 0.9405772686004639, 0.9354838728904724, 0.9383135437965393, 0.9419921040534973, 0.9459536075592041, 0.9468024969100952, 0.9428409934043884, 0.9459536075592041, 0.9428409934043884, 0.9431239366531372, 0.9445387721061707, 0.9422750473022461, 0.9462365508079529, 0.945104718208313, 0.9394453763961792, 0.9371816515922546, 0.9541596174240112, 0.9490662217140198, 0.9436898827552795, 0.9485002756118774, 0.9468024969100952, 0.9422750473022461, 0.9405772686004639, 0.9343519806861877, 0.9363327622413635, 0.9473684430122375, 0.9428409934043884], 'val_loss': [0.7975778579711914, 0.789569079875946, 0.7861990332603455, 0.7814457416534424, 0.7727487087249756, 0.7644181251525879, 0.7597031593322754, 0.7482430934906006, 0.7357980608940125, 0.7270330190658569, 0.713303804397583, 0.7121768593788147, 0.6974412798881531, 0.6824071407318115, 0.6671843528747559, 0.6694004535675049, 0.6520467400550842, 0.6710827946662903, 0.7008271217346191, 0.6539480686187744, 0.6495069265365601, 0.6544724702835083, 0.6526327729225159, 0.6697361469268799, 0.6596580147743225, 0.6786677241325378, 0.7040327787399292, 0.6943144202232361, 0.7372725009918213, 0.7189075350761414, 0.7230329513549805, 0.7557659149169922, 0.7567653656005859, 0.753071665763855, 0.7384949922561646, 0.7279397249221802, 0.7486382126808167, 0.7585944533348083, 0.7825949788093567, 0.7686230540275574, 0.7709648013114929, 0.7536306381225586, 0.7961217164993286, 0.7685355544090271, 0.7725388407707214, 0.7785846590995789, 0.7872570157051086, 0.7676159143447876, 0.7860423922538757, 0.7896506190299988, 0.7981961369514465, 0.817226767539978, 0.792314350605011, 0.8063635230064392, 0.8307733535766602, 0.8315927386283875, 0.7702876329421997, 0.7946472764015198, 0.8084641695022583, 0.8064675331115723, 0.808244526386261, 0.8381630778312683, 0.8501219749450684, 0.875775158405304, 0.8391366600990295, 0.8188263773918152, 0.823992133140564, 0.8233836889266968, 0.8395956754684448, 0.8743122220039368, 0.8369349837303162, 0.8495120406150818, 0.8406559824943542, 0.8373472690582275, 0.8298389315605164, 0.8771380186080933, 0.8432367444038391, 0.8507869243621826, 0.8448758125305176, 0.835684597492218, 0.8367763757705688, 0.9014443755149841, 0.9065691232681274, 0.8454512357711792, 0.8479373455047607, 0.9332116842269897, 0.8525072932243347, 0.9000511765480042, 0.8507166504859924, 0.8355033993721008, 0.8711904287338257, 0.8773224353790283, 0.8747268319129944, 0.8976945281028748, 0.9329075217247009, 0.9462155699729919, 0.919499933719635, 0.9163756966590881, 0.9015541672706604, 0.896554172039032], 'val_accuracy': [0.6018099784851074, 0.6414027214050293, 0.6549773812294006, 0.6210407018661499, 0.6459276080131531, 0.6504524946212769, 0.6459276080131531, 0.6776018142700195, 0.679864227771759, 0.6832579374313354, 0.7070135474205017, 0.7183257937431335, 0.7183257937431335, 0.7319004535675049, 0.7454751133918762, 0.7522624731063843, 0.7658371329307556, 0.7443438768386841, 0.7307692170143127, 0.779411792755127, 0.7748869061470032, 0.7782805562019348, 0.7703620195388794, 0.790723979473114, 0.7952488660812378, 0.7986425161361694, 0.7771493196487427, 0.7895927429199219, 0.773755669593811, 0.790723979473114, 0.7816742062568665, 0.7828054428100586, 0.7805429697036743, 0.7828054428100586, 0.790723979473114, 0.7986425161361694, 0.7839366793632507, 0.773755669593811, 0.779411792755127, 0.7816742062568665, 0.7816742062568665, 0.7839366793632507, 0.7590497732162476, 0.779411792755127, 0.779411792755127, 0.7816742062568665, 0.7805429697036743, 0.7748869061470032, 0.773755669593811, 0.7850678563117981, 0.7703620195388794, 0.7545248866081238, 0.7771493196487427, 0.773755669593811, 0.7579185366630554, 0.7647058963775635, 0.7828054428100586, 0.7680995464324951, 0.779411792755127, 0.773755669593811, 0.7726244330406189, 0.7522624731063843, 0.7466063499450684, 0.7352941036224365, 0.7714931964874268, 0.7692307829856873, 0.7771493196487427, 0.7714931964874268, 0.7748869061470032, 0.7624434232711792, 0.7771493196487427, 0.7647058963775635, 0.779411792755127, 0.7714931964874268, 0.7748869061470032, 0.7703620195388794, 0.7828054428100586, 0.7692307829856873, 0.7771493196487427, 0.7714931964874268, 0.7726244330406189, 0.7680995464324951, 0.7692307829856873, 0.7692307829856873, 0.7771493196487427, 0.7567873597145081, 0.7748869061470032, 0.766968309879303, 0.7760180830955505, 0.7839366793632507, 0.7760180830955505, 0.7760180830955505, 0.7635746598243713, 0.7816742062568665, 0.7647058963775635, 0.7635746598243713, 0.7680995464324951, 0.7692307829856873, 0.7647058963775635, 0.7635746598243713]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.4153 - accuracy: 0.8904"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 69ms/step - loss: 0.4152 - accuracy: 0.8904 - val_loss: 0.7844 - val_accuracy: 0.6198\n","Epoch 2/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4085 - accuracy: 0.8912 - val_loss: 0.7803 - val_accuracy: 0.6229\n","Epoch 3/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3961 - accuracy: 0.8992 - val_loss: 0.7712 - val_accuracy: 0.6374\n","Epoch 4/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3860 - accuracy: 0.9023 - val_loss: 0.7672 - val_accuracy: 0.6302\n","Epoch 5/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3854 - accuracy: 0.9005 - val_loss: 0.7675 - val_accuracy: 0.6229\n","Epoch 6/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3918 - accuracy: 0.9005 - val_loss: 0.7492 - val_accuracy: 0.6477\n","Epoch 7/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3870 - accuracy: 0.9026 - val_loss: 0.7396 - val_accuracy: 0.6901\n","Epoch 8/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3788 - accuracy: 0.9080 - val_loss: 0.7270 - val_accuracy: 0.6870\n","Epoch 9/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3778 - accuracy: 0.9127 - val_loss: 0.7277 - val_accuracy: 0.7169\n","Epoch 10/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3727 - accuracy: 0.9140 - val_loss: 0.7100 - val_accuracy: 0.7066\n","Epoch 11/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3784 - accuracy: 0.9018 - val_loss: 0.7178 - val_accuracy: 0.7273\n","Epoch 12/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3787 - accuracy: 0.9052 - val_loss: 0.6982 - val_accuracy: 0.7324\n","Epoch 13/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3650 - accuracy: 0.9114 - val_loss: 0.6955 - val_accuracy: 0.7386\n","Epoch 14/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3685 - accuracy: 0.9127 - val_loss: 0.6848 - val_accuracy: 0.7428\n","Epoch 15/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3673 - accuracy: 0.9129 - val_loss: 0.6660 - val_accuracy: 0.7345\n","Epoch 16/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3672 - accuracy: 0.9155 - val_loss: 0.6735 - val_accuracy: 0.7428\n","Epoch 17/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3522 - accuracy: 0.9178 - val_loss: 0.6685 - val_accuracy: 0.7572\n","Epoch 18/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3570 - accuracy: 0.9150 - val_loss: 0.6784 - val_accuracy: 0.7593\n","Epoch 19/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3589 - accuracy: 0.9152 - val_loss: 0.6862 - val_accuracy: 0.7593\n","Epoch 20/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.3515 - accuracy: 0.9171 - val_loss: 0.6913 - val_accuracy: 0.7738\n","Epoch 21/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3510 - accuracy: 0.9183 - val_loss: 0.7131 - val_accuracy: 0.7510\n","Epoch 22/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3560 - accuracy: 0.9124 - val_loss: 0.7322 - val_accuracy: 0.7572\n","Epoch 23/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3506 - accuracy: 0.9171 - val_loss: 0.7536 - val_accuracy: 0.7417\n","Epoch 24/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3487 - accuracy: 0.9178 - val_loss: 0.7418 - val_accuracy: 0.7614\n","Epoch 25/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3555 - accuracy: 0.9163 - val_loss: 0.7571 - val_accuracy: 0.7686\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3450 - accuracy: 0.9240 - val_loss: 0.7788 - val_accuracy: 0.7634\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3528 - accuracy: 0.9168 - val_loss: 0.8714 - val_accuracy: 0.7283\n","Epoch 28/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3452 - accuracy: 0.9214 - val_loss: 0.8608 - val_accuracy: 0.7345\n","Epoch 29/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3507 - accuracy: 0.9160 - val_loss: 0.8418 - val_accuracy: 0.7479\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3527 - accuracy: 0.9155 - val_loss: 0.8368 - val_accuracy: 0.7386\n","Epoch 31/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3429 - accuracy: 0.9225 - val_loss: 0.8784 - val_accuracy: 0.7386\n","Epoch 32/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3333 - accuracy: 0.9305 - val_loss: 0.8400 - val_accuracy: 0.7624\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3374 - accuracy: 0.9230 - val_loss: 0.8262 - val_accuracy: 0.7645\n","Epoch 34/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3334 - accuracy: 0.9225 - val_loss: 0.8374 - val_accuracy: 0.7614\n","Epoch 35/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3474 - accuracy: 0.9142 - val_loss: 0.9193 - val_accuracy: 0.7386\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3377 - accuracy: 0.9209 - val_loss: 0.8666 - val_accuracy: 0.7417\n","Epoch 37/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3423 - accuracy: 0.9207 - val_loss: 0.8519 - val_accuracy: 0.7603\n","Epoch 38/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3390 - accuracy: 0.9191 - val_loss: 0.8575 - val_accuracy: 0.7521\n","Epoch 39/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3353 - accuracy: 0.9243 - val_loss: 0.8562 - val_accuracy: 0.7541\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3492 - accuracy: 0.9199 - val_loss: 0.9558 - val_accuracy: 0.7479\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3579 - accuracy: 0.9134 - val_loss: 0.9243 - val_accuracy: 0.7469\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3345 - accuracy: 0.9266 - val_loss: 0.9075 - val_accuracy: 0.7324\n","Epoch 43/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3301 - accuracy: 0.9261 - val_loss: 0.9670 - val_accuracy: 0.7345\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3418 - accuracy: 0.9176 - val_loss: 0.9047 - val_accuracy: 0.7469\n","Epoch 45/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3531 - accuracy: 0.9137 - val_loss: 0.9798 - val_accuracy: 0.7262\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3282 - accuracy: 0.9295 - val_loss: 0.9346 - val_accuracy: 0.7242\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3262 - accuracy: 0.9227 - val_loss: 0.9315 - val_accuracy: 0.7262\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3201 - accuracy: 0.9362 - val_loss: 0.9101 - val_accuracy: 0.7376\n","Epoch 49/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3187 - accuracy: 0.9297 - val_loss: 0.8931 - val_accuracy: 0.7572\n","Epoch 50/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3274 - accuracy: 0.9233 - val_loss: 0.9004 - val_accuracy: 0.7552\n","Epoch 51/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3264 - accuracy: 0.9276 - val_loss: 1.0147 - val_accuracy: 0.7345\n","Epoch 52/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3201 - accuracy: 0.9318 - val_loss: 0.9146 - val_accuracy: 0.7304\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3294 - accuracy: 0.9235 - val_loss: 0.8950 - val_accuracy: 0.7479\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3179 - accuracy: 0.9310 - val_loss: 0.9159 - val_accuracy: 0.7500\n","Epoch 55/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3220 - accuracy: 0.9305 - val_loss: 0.9671 - val_accuracy: 0.7417\n","Epoch 56/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3119 - accuracy: 0.9331 - val_loss: 0.9504 - val_accuracy: 0.7366\n","Epoch 57/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3260 - accuracy: 0.9271 - val_loss: 1.0343 - val_accuracy: 0.7149\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3175 - accuracy: 0.9295 - val_loss: 0.9728 - val_accuracy: 0.7562\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3109 - accuracy: 0.9339 - val_loss: 0.9669 - val_accuracy: 0.7335\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3208 - accuracy: 0.9292 - val_loss: 0.9987 - val_accuracy: 0.7345\n","Epoch 61/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3148 - accuracy: 0.9326 - val_loss: 0.9441 - val_accuracy: 0.7417\n","Epoch 62/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3116 - accuracy: 0.9323 - val_loss: 1.0415 - val_accuracy: 0.7221\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3156 - accuracy: 0.9313 - val_loss: 0.9975 - val_accuracy: 0.7273\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3027 - accuracy: 0.9341 - val_loss: 0.9641 - val_accuracy: 0.7479\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3022 - accuracy: 0.9349 - val_loss: 0.9630 - val_accuracy: 0.7428\n","Epoch 66/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3100 - accuracy: 0.9297 - val_loss: 1.0230 - val_accuracy: 0.7366\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3143 - accuracy: 0.9302 - val_loss: 0.9948 - val_accuracy: 0.7335\n","Epoch 68/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3187 - accuracy: 0.9313 - val_loss: 1.0688 - val_accuracy: 0.7128\n","Epoch 69/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3240 - accuracy: 0.9258 - val_loss: 1.0249 - val_accuracy: 0.7293\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3035 - accuracy: 0.9326 - val_loss: 0.9827 - val_accuracy: 0.7479\n","Epoch 71/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3028 - accuracy: 0.9354 - val_loss: 0.9616 - val_accuracy: 0.7469\n","Epoch 72/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2986 - accuracy: 0.9354 - val_loss: 1.0687 - val_accuracy: 0.7200\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3044 - accuracy: 0.9323 - val_loss: 0.9660 - val_accuracy: 0.7469\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3019 - accuracy: 0.9377 - val_loss: 0.9630 - val_accuracy: 0.7438\n","Epoch 75/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2993 - accuracy: 0.9341 - val_loss: 0.9901 - val_accuracy: 0.7262\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3041 - accuracy: 0.9339 - val_loss: 1.0371 - val_accuracy: 0.7242\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2982 - accuracy: 0.9390 - val_loss: 0.9277 - val_accuracy: 0.7500\n","Epoch 78/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3194 - accuracy: 0.9292 - val_loss: 1.0593 - val_accuracy: 0.7087\n","Epoch 79/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3015 - accuracy: 0.9320 - val_loss: 0.9928 - val_accuracy: 0.7438\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3118 - accuracy: 0.9300 - val_loss: 1.0674 - val_accuracy: 0.7159\n","Epoch 81/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2938 - accuracy: 0.9372 - val_loss: 1.0048 - val_accuracy: 0.7242\n","Epoch 82/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2962 - accuracy: 0.9388 - val_loss: 0.9559 - val_accuracy: 0.7490\n","Epoch 83/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3038 - accuracy: 0.9336 - val_loss: 0.9653 - val_accuracy: 0.7304\n","Epoch 84/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2962 - accuracy: 0.9372 - val_loss: 0.9871 - val_accuracy: 0.7428\n","Epoch 85/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2823 - accuracy: 0.9447 - val_loss: 0.9579 - val_accuracy: 0.7510\n","Epoch 86/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2852 - accuracy: 0.9411 - val_loss: 1.0387 - val_accuracy: 0.7242\n","Epoch 87/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2935 - accuracy: 0.9398 - val_loss: 1.0830 - val_accuracy: 0.7417\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2923 - accuracy: 0.9385 - val_loss: 1.0242 - val_accuracy: 0.7293\n","Epoch 89/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2759 - accuracy: 0.9455 - val_loss: 0.9892 - val_accuracy: 0.7417\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2874 - accuracy: 0.9385 - val_loss: 0.9892 - val_accuracy: 0.7490\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2832 - accuracy: 0.9408 - val_loss: 0.9951 - val_accuracy: 0.7376\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2835 - accuracy: 0.9398 - val_loss: 1.0443 - val_accuracy: 0.7397\n","Epoch 93/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2925 - accuracy: 0.9372 - val_loss: 1.0920 - val_accuracy: 0.7376\n","Epoch 94/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2883 - accuracy: 0.9382 - val_loss: 1.0124 - val_accuracy: 0.7376\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2779 - accuracy: 0.9457 - val_loss: 1.0187 - val_accuracy: 0.7366\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2774 - accuracy: 0.9439 - val_loss: 1.0702 - val_accuracy: 0.7376\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2894 - accuracy: 0.9398 - val_loss: 1.0183 - val_accuracy: 0.7335\n","Epoch 98/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2791 - accuracy: 0.9444 - val_loss: 1.0684 - val_accuracy: 0.7200\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2750 - accuracy: 0.9470 - val_loss: 1.0497 - val_accuracy: 0.7459\n","Epoch 100/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2857 - accuracy: 0.9450 - val_loss: 1.0239 - val_accuracy: 0.7428\n","{'loss': [0.41518744826316833, 0.40853172540664673, 0.39608705043792725, 0.38603633642196655, 0.3853723704814911, 0.3917716145515442, 0.3869658410549164, 0.3788003921508789, 0.3777644634246826, 0.37269434332847595, 0.3784128725528717, 0.37874364852905273, 0.36498573422431946, 0.3685184419155121, 0.36731499433517456, 0.3672028183937073, 0.3521796762943268, 0.3569703996181488, 0.3588714897632599, 0.35152503848075867, 0.35099074244499207, 0.3559788763523102, 0.3506026268005371, 0.34867578744888306, 0.35549497604370117, 0.3449837267398834, 0.3528217375278473, 0.3451908528804779, 0.35072648525238037, 0.35270899534225464, 0.34287866950035095, 0.333312064409256, 0.3373790383338928, 0.3334384560585022, 0.3474436104297638, 0.3376710116863251, 0.34227797389030457, 0.3389998972415924, 0.3353325426578522, 0.34923818707466125, 0.3578973710536957, 0.33446767926216125, 0.330098032951355, 0.3417765200138092, 0.3531118333339691, 0.32822251319885254, 0.32622936367988586, 0.32005876302719116, 0.3187481760978699, 0.3273949921131134, 0.32640787959098816, 0.3201286792755127, 0.3293870985507965, 0.3178602159023285, 0.321981281042099, 0.31192195415496826, 0.3260311484336853, 0.3175136148929596, 0.3109145760536194, 0.32078811526298523, 0.3147551119327545, 0.31161704659461975, 0.3156191408634186, 0.3027276396751404, 0.30220702290534973, 0.3099679946899414, 0.3143197298049927, 0.3187384009361267, 0.32403621077537537, 0.30350953340530396, 0.30276626348495483, 0.2986160218715668, 0.30435213446617126, 0.3018657863140106, 0.2993200719356537, 0.30411189794540405, 0.29822099208831787, 0.3194487392902374, 0.301509290933609, 0.31182244420051575, 0.29375889897346497, 0.2962126135826111, 0.303814560174942, 0.29615843296051025, 0.2822935879230499, 0.285238653421402, 0.29346081614494324, 0.29232263565063477, 0.2759091556072235, 0.2874019742012024, 0.28320226073265076, 0.2834508717060089, 0.2925354838371277, 0.2883376479148865, 0.27785956859588623, 0.2774259150028229, 0.2894086241722107, 0.2790617346763611, 0.27496814727783203, 0.2856675386428833], 'accuracy': [0.8904392719268799, 0.8912144899368286, 0.8992248177528381, 0.9023255705833435, 0.9005168080329895, 0.9005168080329895, 0.9025839567184448, 0.9080103635787964, 0.9126614928245544, 0.9139534831047058, 0.9018087983131409, 0.9051679372787476, 0.9113695025444031, 0.9126614928245544, 0.9129198789596558, 0.9155038595199585, 0.9178294539451599, 0.9149870872497559, 0.9152454733848572, 0.9170542359352112, 0.9183462262153625, 0.9124031066894531, 0.9170542359352112, 0.9178294539451599, 0.9162790775299072, 0.9240310192108154, 0.9167958498001099, 0.9214470386505127, 0.9160206913948059, 0.9155038595199585, 0.9224806427955627, 0.9304909706115723, 0.9229974150657654, 0.9224806427955627, 0.9142118692398071, 0.9209302067756653, 0.920671820640564, 0.9191214442253113, 0.9242894053459167, 0.91989666223526, 0.9134367108345032, 0.9266149997711182, 0.9260981678962708, 0.9175710678100586, 0.9136950969696045, 0.9294573664665222, 0.9227390289306641, 0.9361757040023804, 0.9297157526016235, 0.9232558012008667, 0.9276486039161682, 0.9317829608917236, 0.923514187335968, 0.9310077428817749, 0.9304909706115723, 0.933074951171875, 0.9271317720413208, 0.9294573664665222, 0.933850109577179, 0.9291989803314209, 0.9325581192970276, 0.9322997331619263, 0.9312661290168762, 0.934108555316925, 0.934883713722229, 0.9297157526016235, 0.930232584476471, 0.9312661290168762, 0.9258397817611694, 0.9325581192970276, 0.9354005455970764, 0.9354005455970764, 0.9322997331619263, 0.9377260804176331, 0.934108555316925, 0.933850109577179, 0.9390180706977844, 0.9291989803314209, 0.932041347026825, 0.9299741387367249, 0.9372093081474304, 0.9387596845626831, 0.9335917234420776, 0.9372093081474304, 0.9447028636932373, 0.9410852789878845, 0.9397932887077332, 0.9385012984275818, 0.9454780220985413, 0.9385012984275818, 0.9408268928527832, 0.9397932887077332, 0.9372093081474304, 0.9382429122924805, 0.9457364082336426, 0.9439276456832886, 0.9397932887077332, 0.9444444179534912, 0.947028398513794, 0.9449612498283386], 'val_loss': [0.7843675017356873, 0.7803199291229248, 0.771178126335144, 0.7672215104103088, 0.7675065994262695, 0.7492064833641052, 0.739585816860199, 0.7269508838653564, 0.7277360558509827, 0.7100000381469727, 0.7177897691726685, 0.6982095837593079, 0.6954968571662903, 0.6847895383834839, 0.6660359501838684, 0.6734640002250671, 0.668492317199707, 0.6783832311630249, 0.6861650943756104, 0.6912829279899597, 0.7130501866340637, 0.7321538925170898, 0.7536402940750122, 0.7418027520179749, 0.7570531964302063, 0.7787628173828125, 0.8713849186897278, 0.860824465751648, 0.841829776763916, 0.8368174433708191, 0.8784376978874207, 0.8400261402130127, 0.8262286186218262, 0.8373773694038391, 0.9192671775817871, 0.8665568232536316, 0.8519112467765808, 0.857538640499115, 0.8562423586845398, 0.9557701349258423, 0.9243181347846985, 0.9075441956520081, 0.9670355916023254, 0.9047084450721741, 0.9798086285591125, 0.9345836639404297, 0.931503176689148, 0.9101323485374451, 0.8931008577346802, 0.9004223942756653, 1.0147063732147217, 0.9146222472190857, 0.894975483417511, 0.9159184694290161, 0.9671400189399719, 0.950386106967926, 1.034312129020691, 0.9727877974510193, 0.9669138789176941, 0.9987146258354187, 0.9440652132034302, 1.0415050983428955, 0.9974982738494873, 0.9640610814094543, 0.9630168676376343, 1.0230045318603516, 0.9948440194129944, 1.0687685012817383, 1.0248687267303467, 0.982746422290802, 0.9616415500640869, 1.068725347518921, 0.9660288691520691, 0.96298748254776, 0.9900606274604797, 1.0370731353759766, 0.9277040362358093, 1.059324026107788, 0.9927615523338318, 1.0674011707305908, 1.0048282146453857, 0.9558860063552856, 0.9652516841888428, 0.9871278405189514, 0.957892894744873, 1.0387054681777954, 1.082987904548645, 1.0241976976394653, 0.9891817569732666, 0.9891747236251831, 0.9950998425483704, 1.044345736503601, 1.0919866561889648, 1.012397289276123, 1.0187448263168335, 1.0702065229415894, 1.0182896852493286, 1.0683823823928833, 1.049709677696228, 1.0239111185073853], 'val_accuracy': [0.6198347210884094, 0.6229338645935059, 0.6373966932296753, 0.6301652789115906, 0.6229338645935059, 0.6477272510528564, 0.6900826692581177, 0.6869834661483765, 0.7169421315193176, 0.7066115736961365, 0.7272727489471436, 0.7324380278587341, 0.7386363744735718, 0.7427685856819153, 0.7345041036605835, 0.7427685856819153, 0.7572314143180847, 0.7592975497245789, 0.7592975497245789, 0.7737603187561035, 0.7510330677032471, 0.7572314143180847, 0.7417355179786682, 0.7613636255264282, 0.7685950398445129, 0.7634297609329224, 0.7283057570457458, 0.7345041036605835, 0.7479338645935059, 0.7386363744735718, 0.7386363744735718, 0.7623966932296753, 0.7644628286361694, 0.7613636255264282, 0.7386363744735718, 0.7417355179786682, 0.7603305578231812, 0.7520661354064941, 0.7541322112083435, 0.7479338645935059, 0.7469007968902588, 0.7324380278587341, 0.7345041036605835, 0.7469007968902588, 0.7262396812438965, 0.7241735458374023, 0.7262396812438965, 0.7376033067703247, 0.7572314143180847, 0.7551652789115906, 0.7345041036605835, 0.73037189245224, 0.7479338645935059, 0.75, 0.7417355179786682, 0.7365702390670776, 0.7148760557174683, 0.7561983466148376, 0.7334710955619812, 0.7345041036605835, 0.7417355179786682, 0.7221074104309082, 0.7272727489471436, 0.7479338645935059, 0.7427685856819153, 0.7365702390670776, 0.7334710955619812, 0.7128099203109741, 0.7293388247489929, 0.7479338645935059, 0.7469007968902588, 0.7200413346290588, 0.7469007968902588, 0.7438016533851624, 0.7262396812438965, 0.7241735458374023, 0.75, 0.7086777091026306, 0.7438016533851624, 0.7159090638160706, 0.7241735458374023, 0.7489669322967529, 0.73037189245224, 0.7427685856819153, 0.7510330677032471, 0.7241735458374023, 0.7417355179786682, 0.7293388247489929, 0.7417355179786682, 0.7489669322967529, 0.7376033067703247, 0.7396694421768188, 0.7376033067703247, 0.7376033067703247, 0.7365702390670776, 0.7376033067703247, 0.7334710955619812, 0.7200413346290588, 0.7458677887916565, 0.7427685856819153]}\n","32/32 [==============================] - 1s 3ms/step\n"]}]},{"cell_type":"code","source":["metrics_df_gru"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"id":"LcuyNm1d6ivL","executionInfo":{"status":"ok","timestamp":1717434636102,"user_tz":-360,"elapsed":9,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}},"outputId":"6e0a87e4-3682-4f3c-adb1-387baf0ecec8"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision    Recall        F1  Sensitivity  Specificity  \\\n","0        0  0.597990   0.648101  0.428811  0.516129     0.428811     0.767169   \n","1        1  0.634181   0.693089  0.481638  0.568333     0.481638     0.786723   \n","2        2  0.619478   0.634921  0.562249  0.596379     0.562249     0.676707   \n","3        0  0.641541   0.680171  0.534338  0.598499     0.534338     0.748744   \n","4        1  0.678672   0.699842  0.625706  0.660701     0.625706     0.731638   \n","5        2  0.678715   0.711905  0.600402  0.651416     0.600402     0.757028   \n","6        0  0.670854   0.693182  0.613065  0.650667     0.613065     0.728643   \n","7        1  0.716102   0.723684  0.699153  0.711207     0.699153     0.733051   \n","8        2  0.697791   0.686200  0.728916  0.706913     0.728916     0.666667   \n","9        0  0.711893   0.732110  0.668342  0.698774     0.668342     0.755444   \n","10       1  0.750706   0.799325  0.669492  0.728670     0.669492     0.831921   \n","11       2  0.737952   0.716636  0.787149  0.750239     0.787149     0.688755   \n","12       0  0.744556   0.742525  0.748744  0.745621     0.748744     0.740369   \n","13       1  0.787429   0.807867  0.754237  0.780131     0.754237     0.820621   \n","14       2  0.780120   0.776238  0.787149  0.781655     0.787149     0.773092   \n","\n","       Kappa  \n","0   0.195980  \n","1   0.268362  \n","2   0.238956  \n","3   0.283082  \n","4   0.357345  \n","5   0.357430  \n","6   0.341709  \n","7   0.432203  \n","8   0.395582  \n","9   0.423786  \n","10  0.501412  \n","11  0.475904  \n","12  0.489112  \n","13  0.574859  \n","14  0.560241  "],"text/html":["\n","  <div id=\"df-8b0a4c81-4e53-486e-8d2e-4eda174d985c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.597990</td>\n","      <td>0.648101</td>\n","      <td>0.428811</td>\n","      <td>0.516129</td>\n","      <td>0.428811</td>\n","      <td>0.767169</td>\n","      <td>0.195980</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.634181</td>\n","      <td>0.693089</td>\n","      <td>0.481638</td>\n","      <td>0.568333</td>\n","      <td>0.481638</td>\n","      <td>0.786723</td>\n","      <td>0.268362</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.619478</td>\n","      <td>0.634921</td>\n","      <td>0.562249</td>\n","      <td>0.596379</td>\n","      <td>0.562249</td>\n","      <td>0.676707</td>\n","      <td>0.238956</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.641541</td>\n","      <td>0.680171</td>\n","      <td>0.534338</td>\n","      <td>0.598499</td>\n","      <td>0.534338</td>\n","      <td>0.748744</td>\n","      <td>0.283082</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.678672</td>\n","      <td>0.699842</td>\n","      <td>0.625706</td>\n","      <td>0.660701</td>\n","      <td>0.625706</td>\n","      <td>0.731638</td>\n","      <td>0.357345</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.678715</td>\n","      <td>0.711905</td>\n","      <td>0.600402</td>\n","      <td>0.651416</td>\n","      <td>0.600402</td>\n","      <td>0.757028</td>\n","      <td>0.357430</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.670854</td>\n","      <td>0.693182</td>\n","      <td>0.613065</td>\n","      <td>0.650667</td>\n","      <td>0.613065</td>\n","      <td>0.728643</td>\n","      <td>0.341709</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.716102</td>\n","      <td>0.723684</td>\n","      <td>0.699153</td>\n","      <td>0.711207</td>\n","      <td>0.699153</td>\n","      <td>0.733051</td>\n","      <td>0.432203</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.697791</td>\n","      <td>0.686200</td>\n","      <td>0.728916</td>\n","      <td>0.706913</td>\n","      <td>0.728916</td>\n","      <td>0.666667</td>\n","      <td>0.395582</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.711893</td>\n","      <td>0.732110</td>\n","      <td>0.668342</td>\n","      <td>0.698774</td>\n","      <td>0.668342</td>\n","      <td>0.755444</td>\n","      <td>0.423786</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.750706</td>\n","      <td>0.799325</td>\n","      <td>0.669492</td>\n","      <td>0.728670</td>\n","      <td>0.669492</td>\n","      <td>0.831921</td>\n","      <td>0.501412</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.737952</td>\n","      <td>0.716636</td>\n","      <td>0.787149</td>\n","      <td>0.750239</td>\n","      <td>0.787149</td>\n","      <td>0.688755</td>\n","      <td>0.475904</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.744556</td>\n","      <td>0.742525</td>\n","      <td>0.748744</td>\n","      <td>0.745621</td>\n","      <td>0.748744</td>\n","      <td>0.740369</td>\n","      <td>0.489112</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.787429</td>\n","      <td>0.807867</td>\n","      <td>0.754237</td>\n","      <td>0.780131</td>\n","      <td>0.754237</td>\n","      <td>0.820621</td>\n","      <td>0.574859</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.780120</td>\n","      <td>0.776238</td>\n","      <td>0.787149</td>\n","      <td>0.781655</td>\n","      <td>0.787149</td>\n","      <td>0.773092</td>\n","      <td>0.560241</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b0a4c81-4e53-486e-8d2e-4eda174d985c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8b0a4c81-4e53-486e-8d2e-4eda174d985c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8b0a4c81-4e53-486e-8d2e-4eda174d985c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-9be3025c-782a-4aaa-893b-6c28c1c2a5d9\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9be3025c-782a-4aaa-893b-6c28c1c2a5d9')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-9be3025c-782a-4aaa-893b-6c28c1c2a5d9 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"metrics_df_gru","summary":"{\n  \"name\": \"metrics_df_gru\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.057744482497826634,\n        \"min\": 0.5979899497487438,\n        \"max\": 0.7874293785310734,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.711892797319933,\n          0.7379518072289156,\n          0.5979899497487438\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04979301840701094,\n        \"min\": 0.6349206349206349,\n        \"max\": 0.8078668683812406,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7321100917431193,\n          0.716636197440585,\n          0.6481012658227848\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11023119275733674,\n        \"min\": 0.4288107202680067,\n        \"max\": 0.7871485943775101,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.6683417085427136,\n          0.7871485943775101,\n          0.4288107202680067\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07965458751915276,\n        \"min\": 0.5161290322580645,\n        \"max\": 0.7816550348953141,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.6987740805604203,\n          0.7502392344497608,\n          0.5161290322580645\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11023119275733674,\n        \"min\": 0.4288107202680067,\n        \"max\": 0.7871485943775101,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.6683417085427136,\n          0.7871485943775101,\n          0.4288107202680067\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04710968462148206,\n        \"min\": 0.6666666666666666,\n        \"max\": 0.8319209039548022,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7554438860971524,\n          0.6887550200803213,\n          0.7671691792294807\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11548896499565328,\n        \"min\": 0.1959798994974874,\n        \"max\": 0.5748587570621468,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.423785594639866,\n          0.47590361445783136,\n          0.1959798994974874\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["metrics_df_gru.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Frequency Domain/GRU/Theta_frequency_gru.csv', index = False)"],"metadata":{"id":"iTgxBDZm6kPj","executionInfo":{"status":"ok","timestamp":1717434636103,"user_tz":-360,"elapsed":7,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Rwaj8ziH64Cg"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}