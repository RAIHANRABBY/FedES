{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"3Xcq8gkVSDFl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709132273836,"user_tz":-360,"elapsed":24244,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"f167c354-5ee6-4dd0-f25e-180cef4df37a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wandb\n","  Downloading wandb-0.16.3-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Downloading sentry_sdk-1.40.6-py2.py3-none-any.whl (258 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.5/258.5 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n","Collecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n","Successfully installed GitPython-3.1.42 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.40.6 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.3\n"]}],"source":["# %%capture\n","# pip install mne\n","\n","!pip install wandb"],"id":"3Xcq8gkVSDFl"},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3556,"status":"ok","timestamp":1709132277388,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"93a18c25-dbcd-4490-9858-181b74ce589a"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","# import mne\n","import pywt\n","import wandb\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import KFold"],"id":"93a18c25-dbcd-4490-9858-181b74ce589a"},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":29079,"status":"ok","timestamp":1709132306462,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"ASsHs2eSO901","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7b7ba425-59c8-4bc3-d11b-76ea44a3ffa6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"ASsHs2eSO901"},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":14080,"status":"ok","timestamp":1709132320538,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"EYgYULqtvBy5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c0fa4609-1006-4d08-a0e2-8b14a8f9aa4e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5834, 52, 29)"]},"metadata":{},"execution_count":4}],"source":["DWT_file = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/DWT/DWT.npz'\n","DWT = np.load(DWT_file, allow_pickle=True)  # Allow loading pickled object arrays\n","X = DWT['X'].astype('float64')\n","Y = DWT['Y'].astype('float64')\n","group = DWT['G'].astype('float64')\n","X= np.moveaxis(X,1,2)\n","X.shape"],"id":"EYgYULqtvBy5"},{"cell_type":"markdown","metadata":{"id":"2H0JfBvo6od9"},"source":["#Split the data"],"id":"2H0JfBvo6od9"},{"cell_type":"code","execution_count":5,"metadata":{"id":"nD0o3WYWlL8n","executionInfo":{"status":"ok","timestamp":1709132320538,"user_tz":-360,"elapsed":16,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"outputs":[],"source":["X_reshaped = X.reshape(X.shape[0],-1)\n","X_reshaped.shape\n","\n","\n","\n","#Scale data\n","scaler = StandardScaler()\n","scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","# Reshape back to original shape if necessary\n","scaled_data = scaled_data_reshaped.reshape(X.shape)\n"],"id":"nD0o3WYWlL8n"},{"cell_type":"code","execution_count":6,"metadata":{"id":"bas2WWLtG1So","executionInfo":{"status":"ok","timestamp":1709132320539,"user_tz":-360,"elapsed":16,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"outputs":[],"source":["# Configuration\n","n_splits = 5  # Number of folds\n","random_state = 42\n","shuffle = True\n","\n","# Initialize KFold\n","kf = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n","\n","# Create a placeholder array for fold assignments\n","fold_assignments = np.empty(len(Y), dtype=int)\n","\n","# Split the data using kf.split. Note: kf.split does not need Y for splitting, but it's kept here for consistency\n","for fold, (train_idx, test_idx) in enumerate(kf.split(scaled_data, Y)):\n","    # Assign fold number\n","    fold_assignments[test_idx] = fold\n","\n","# Example: To get the train and test sets for the first fold\n","fold_number = 0  # Choose which fold to use (0 to n_splits-1)\n","train_idx = np.where(fold_assignments != fold_number)[0]\n","test_idx = np.where(fold_assignments == fold_number)[0]\n","\n","X_train, X_test = scaled_data[train_idx], scaled_data[test_idx]\n","Y_train, Y_test = Y[train_idx], Y[test_idx]"],"id":"bas2WWLtG1So"},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1709132320539,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"DmwhZ36OLwqA","outputId":"13a6767f-af25-459b-ea3b-67496d261293"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((4667, 52, 29), (4667,), (1167, 52, 29))"]},"metadata":{},"execution_count":7}],"source":["X_train.shape,Y_train.shape,X_test.shape"],"id":"DmwhZ36OLwqA"},{"cell_type":"markdown","metadata":{"id":"XPsf5sgfbCle"},"source":["#CNN Model"],"id":"XPsf5sgfbCle"},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ri5z9_6ML7K","executionInfo":{"status":"ok","timestamp":1709135289273,"user_tz":-360,"elapsed":2968748,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"3297babb-9b9f-434f-91e2-7776bd7392a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["\n","!wandb login"],"id":"5ri5z9_6ML7K"},{"cell_type":"markdown","metadata":{"id":"8eFhlc8pdl-s"},"source":["This is with using only the data with out any transformations applied. So This is just plain Deep learning."],"id":"8eFhlc8pdl-s"},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1709135289274,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"pTr-PyBDb28J","outputId":"157aa9c0-53de-4af2-d329-5340c2eeaa29"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((4667, 52, 29), (4667,), (1167, 52, 29))"]},"metadata":{},"execution_count":9}],"source":["X_train.shape, Y_train.shape,X_test.shape"],"id":"pTr-PyBDb28J"},{"cell_type":"code","execution_count":10,"metadata":{"id":"HezQuWaXPOR-","executionInfo":{"status":"ok","timestamp":1709135293979,"user_tz":-360,"elapsed":4709,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"outputs":[],"source":["from wandb.keras import WandbCallback"],"id":"HezQuWaXPOR-"},{"cell_type":"code","execution_count":11,"metadata":{"id":"7ab6b447-708a-4618-8f16-6683eeb7ba5e","executionInfo":{"status":"ok","timestamp":1709135293979,"user_tz":-360,"elapsed":4,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"outputs":[],"source":["from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras import callbacks\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.layers import  Conv1D,BatchNormalization,LeakyReLU,MaxPool1D,Flatten,\\\n","GlobalAveragePooling1D,Dense,Dropout,AveragePooling1D,ReLU,Conv2D,MaxPool2D,GlobalAveragePooling2D,AveragePooling2D,Bidirectional, LSTM, concatenate\n","from tensorflow.keras.regularizers import l2\n","from keras.layers import ConvLSTM1D, LSTM\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.backend import clear_session\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import LSTM\n","\n","# early_stopping = callbacks.EarlyStopping(\n","#     min_delta=0.001,\n","#     patience=10,\n","#     restore_best_weights=True\n","# )\n","\n","from keras import backend as K\n","\n","def focal_loss(alpha=0.25,gamma=2.0):\n","    def focal_crossentropy(y_true, y_pred):\n","        bce = K.binary_crossentropy(y_true, y_pred)\n","\n","        y_pred = K.clip(y_pred, K.epsilon(), 1.- K.epsilon())\n","        p_t = (y_true*y_pred) + ((1-y_true)*(1-y_pred))\n","\n","        alpha_factor = 1\n","        modulating_factor = 1\n","\n","        alpha_factor = y_true*alpha + ((1-alpha)*(1-y_true))\n","        modulating_factor = K.pow((1-p_t), gamma)\n","\n","        # compute the final loss and return\n","        return K.mean(alpha_factor*modulating_factor*bce, axis=-1)\n","    return focal_crossentropy"],"id":"7ab6b447-708a-4618-8f16-6683eeb7ba5e"},{"cell_type":"code","source":["from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","#from keras_radam import RAdam\n","\n","checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Mobilenet1.h5\",\n","                             monitor=\"val_loss\",\n","                             mode=\"min\",\n","                             save_best_only = True,\n","                             verbose=1)\n","\n","earlystop = EarlyStopping(monitor = 'val_loss',\n","                          min_delta = 0,\n","                          patience = 5,\n","                          verbose = 1,\n","                          restore_best_weights = True)\n","\n","reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n","                              factor = .25,\n","                              patience = 2,\n","                              verbose = 1)\n","\n","\n","# tf_callback = tf.keras.callbacks.TensorBoard(\n","#                             log_dir=\"/content/drive/MyDrive/DeepLearning/TomatoLeaf/logs\",\n","#                             histogram_freq=1,\n","#                             write_graph=True,\n","#                             write_images=True,\n","#                             update_freq=\"epoch\"\n","#                             )\n","\n","# we put our call backs into a callback list\n","wandb.init(project=\"Epileptic Seizure\", entity=\"RaihanRabby\", dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/wandb')\n","callbacks = [checkpoint,reduce_lr,WandbCallback()]"],"metadata":{"id":"bWPTknlS2YjM","executionInfo":{"status":"ok","timestamp":1709146749353,"user_tz":-360,"elapsed":7378,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"colab":{"base_uri":"https://localhost:8080/","height":456,"referenced_widgets":["f907f8ed57394d46a68d978e18160861","daaf142e2edd43d5968a0a752a7404e4","2c4b820da5424bf9a22ef8727f75b0e1","0862a2bbb3ca48378331783b9d58e749","0bd5d12fd39f4cb3bcd6c6937f39ca7b","10dd6d42672a46ae91385d86aaf7f176","7f751ab78fd2414884c50eadde2a9184","277f4940a187403b802fc3e92265e444"]},"outputId":"4af1d597-82e5-4395-d1b1-209fdedfa2fb"},"id":"bWPTknlS2YjM","execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Finishing last run (ID:tvbv9v84) before initializing another..."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='107.946 MB of 107.946 MB uploaded (0.134 MB deduped)\\r'), FloatProgress(value=1.0,…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f907f8ed57394d46a68d978e18160861"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▆▇████████████████▁▆▇█████████████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇█▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>loss</td><td>█▄▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>███▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▃▇▇█████████████████▁▇▅█████████████████</td></tr><tr><td>val_loss</td><td>▄▂█▃▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▁▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.97364</td></tr><tr><td>best_epoch</td><td>3</td></tr><tr><td>best_val_loss</td><td>0.02165</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>0.00772</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>val_accuracy</td><td>0.93745</td></tr><tr><td>val_loss</td><td>0.03938</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">copper-oath-40</strong> at: <a href='https://wandb.ai/raihanrabby/Epileptic%20Seizure/runs/tvbv9v84' target=\"_blank\">https://wandb.ai/raihanrabby/Epileptic%20Seizure/runs/tvbv9v84</a><br/>Synced 5 W&B file(s), 1 media file(s), 25 artifact file(s) and 1 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./drive/MyDrive/EEG Signal /Epileptic seizure/wandb/wandb/run-20240228_175134-tvbv9v84/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Successfully finished last run (ID:tvbv9v84). Initializing new run:<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.16.3"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/EEG Signal /Epileptic seizure/wandb/wandb/run-20240228_185902-cotkt2hj</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/raihanrabby/Epileptic%20Seizure/runs/cotkt2hj' target=\"_blank\">rich-haze-43</a></strong> to <a href='https://wandb.ai/raihanrabby/Epileptic%20Seizure' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/raihanrabby/Epileptic%20Seizure' target=\"_blank\">https://wandb.ai/raihanrabby/Epileptic%20Seizure</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/raihanrabby/Epileptic%20Seizure/runs/cotkt2hj' target=\"_blank\">https://wandb.ai/raihanrabby/Epileptic%20Seizure/runs/cotkt2hj</a>"]},"metadata":{}}]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i10jiBrCdc4W","outputId":"c2ee275e-970f-49aa-a832-0d3ce71023f9","executionInfo":{"status":"ok","timestamp":1709147611621,"user_tz":-360,"elapsed":577756,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.6925\n","Epoch 1: val_loss improved from inf to 0.03980, saving model to /content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Mobilenet1.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/drive/MyDrive/EEG Signal /Epileptic seizure/wandb/wandb/run-20240228_185902-cotkt2hj/files/model-best)... Done. 0.1s\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/73 [==============================] - 27s 281ms/step - loss: 0.0546 - accuracy: 0.6925 - val_loss: 0.0398 - val_accuracy: 0.8355 - lr: 1.0000e-04\n","Epoch 2/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.8410\n","Epoch 2: val_loss improved from 0.03980 to 0.03079, saving model to /content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Mobilenet1.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/drive/MyDrive/EEG Signal /Epileptic seizure/wandb/wandb/run-20240228_185902-cotkt2hj/files/model-best)... Done. 0.1s\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/73 [==============================] - 23s 320ms/step - loss: 0.0351 - accuracy: 0.8410 - val_loss: 0.0308 - val_accuracy: 0.8980 - lr: 1.0000e-04\n","Epoch 3/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.8864\n","Epoch 3: val_loss improved from 0.03079 to 0.02429, saving model to /content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Mobilenet1.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/drive/MyDrive/EEG Signal /Epileptic seizure/wandb/wandb/run-20240228_185902-cotkt2hj/files/model-best)... Done. 0.1s\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/73 [==============================] - 21s 288ms/step - loss: 0.0279 - accuracy: 0.8864 - val_loss: 0.0243 - val_accuracy: 0.9075 - lr: 1.0000e-04\n","Epoch 4/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 0.8995\n","Epoch 4: val_loss did not improve from 0.02429\n","73/73 [==============================] - 11s 143ms/step - loss: 0.0252 - accuracy: 0.8995 - val_loss: 0.0276 - val_accuracy: 0.9169 - lr: 1.0000e-04\n","Epoch 5/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9087\n","Epoch 5: val_loss improved from 0.02429 to 0.02340, saving model to /content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Mobilenet1.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/drive/MyDrive/EEG Signal /Epileptic seizure/wandb/wandb/run-20240228_185902-cotkt2hj/files/model-best)... Done. 0.1s\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/73 [==============================] - 23s 320ms/step - loss: 0.0235 - accuracy: 0.9087 - val_loss: 0.0234 - val_accuracy: 0.9066 - lr: 1.0000e-04\n","Epoch 6/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9177\n","Epoch 6: val_loss did not improve from 0.02340\n","73/73 [==============================] - 11s 151ms/step - loss: 0.0223 - accuracy: 0.9177 - val_loss: 0.0246 - val_accuracy: 0.9117 - lr: 1.0000e-04\n","Epoch 7/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9244\n","Epoch 7: val_loss did not improve from 0.02340\n","\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n","73/73 [==============================] - 10s 130ms/step - loss: 0.0205 - accuracy: 0.9244 - val_loss: 0.0237 - val_accuracy: 0.9083 - lr: 1.0000e-04\n","Epoch 8/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9400\n","Epoch 8: val_loss did not improve from 0.02340\n","73/73 [==============================] - 11s 149ms/step - loss: 0.0167 - accuracy: 0.9400 - val_loss: 0.0259 - val_accuracy: 0.9237 - lr: 2.5000e-05\n","Epoch 9/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9441\n","Epoch 9: val_loss did not improve from 0.02340\n","\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n","73/73 [==============================] - 11s 152ms/step - loss: 0.0161 - accuracy: 0.9441 - val_loss: 0.0249 - val_accuracy: 0.9229 - lr: 2.5000e-05\n","Epoch 10/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9460\n","Epoch 10: val_loss did not improve from 0.02340\n","73/73 [==============================] - 9s 127ms/step - loss: 0.0154 - accuracy: 0.9460 - val_loss: 0.0257 - val_accuracy: 0.9254 - lr: 6.2500e-06\n","Epoch 11/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9475\n","Epoch 11: val_loss did not improve from 0.02340\n","\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n","73/73 [==============================] - 11s 150ms/step - loss: 0.0152 - accuracy: 0.9475 - val_loss: 0.0261 - val_accuracy: 0.9272 - lr: 6.2500e-06\n","Epoch 12/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9486\n","Epoch 12: val_loss did not improve from 0.02340\n","73/73 [==============================] - 11s 150ms/step - loss: 0.0151 - accuracy: 0.9486 - val_loss: 0.0257 - val_accuracy: 0.9254 - lr: 1.5625e-06\n","Epoch 13/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9477\n","Epoch 13: val_loss did not improve from 0.02340\n","\n","Epoch 13: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n","73/73 [==============================] - 10s 142ms/step - loss: 0.0151 - accuracy: 0.9477 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 1.5625e-06\n","Epoch 14/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9494\n","Epoch 14: val_loss did not improve from 0.02340\n","73/73 [==============================] - 10s 132ms/step - loss: 0.0151 - accuracy: 0.9494 - val_loss: 0.0262 - val_accuracy: 0.9272 - lr: 3.9062e-07\n","Epoch 15/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9479\n","Epoch 15: val_loss did not improve from 0.02340\n","\n","Epoch 15: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n","73/73 [==============================] - 11s 149ms/step - loss: 0.0148 - accuracy: 0.9479 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 3.9062e-07\n","Epoch 16/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9490\n","Epoch 16: val_loss did not improve from 0.02340\n","73/73 [==============================] - 11s 155ms/step - loss: 0.0148 - accuracy: 0.9490 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 9.7656e-08\n","Epoch 17/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9492\n","Epoch 17: val_loss did not improve from 0.02340\n","\n","Epoch 17: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n","73/73 [==============================] - 9s 125ms/step - loss: 0.0149 - accuracy: 0.9492 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 9.7656e-08\n","Epoch 18/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9492\n","Epoch 18: val_loss did not improve from 0.02340\n","73/73 [==============================] - 11s 149ms/step - loss: 0.0149 - accuracy: 0.9492 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 2.4414e-08\n","Epoch 19/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9484\n","Epoch 19: val_loss did not improve from 0.02340\n","\n","Epoch 19: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n","73/73 [==============================] - 11s 149ms/step - loss: 0.0149 - accuracy: 0.9484 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 2.4414e-08\n","Epoch 20/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9486\n","Epoch 20: val_loss did not improve from 0.02340\n","73/73 [==============================] - 10s 139ms/step - loss: 0.0150 - accuracy: 0.9486 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 6.1035e-09\n","Epoch 21/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9488\n","Epoch 21: val_loss did not improve from 0.02340\n","\n","Epoch 21: ReduceLROnPlateau reducing learning rate to 1.5258788677030566e-09.\n","73/73 [==============================] - 10s 133ms/step - loss: 0.0150 - accuracy: 0.9488 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 6.1035e-09\n","Epoch 22/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9479\n","Epoch 22: val_loss did not improve from 0.02340\n","73/73 [==============================] - 11s 148ms/step - loss: 0.0151 - accuracy: 0.9479 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 1.5259e-09\n","Epoch 23/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9479\n","Epoch 23: val_loss did not improve from 0.02340\n","\n","Epoch 23: ReduceLROnPlateau reducing learning rate to 3.8146971692576415e-10.\n","73/73 [==============================] - 11s 154ms/step - loss: 0.0149 - accuracy: 0.9479 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 1.5259e-09\n","Epoch 24/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9473\n","Epoch 24: val_loss did not improve from 0.02340\n","73/73 [==============================] - 9s 125ms/step - loss: 0.0150 - accuracy: 0.9473 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 3.8147e-10\n","Epoch 25/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9488\n","Epoch 25: val_loss did not improve from 0.02340\n","\n","Epoch 25: ReduceLROnPlateau reducing learning rate to 9.536742923144104e-11.\n","73/73 [==============================] - 11s 148ms/step - loss: 0.0148 - accuracy: 0.9488 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 3.8147e-10\n","Epoch 26/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9490\n","Epoch 26: val_loss did not improve from 0.02340\n","73/73 [==============================] - 11s 152ms/step - loss: 0.0149 - accuracy: 0.9490 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 9.5367e-11\n","Epoch 27/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9481\n","Epoch 27: val_loss did not improve from 0.02340\n","\n","Epoch 27: ReduceLROnPlateau reducing learning rate to 2.384185730786026e-11.\n","73/73 [==============================] - 10s 136ms/step - loss: 0.0150 - accuracy: 0.9481 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 9.5367e-11\n","Epoch 28/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9479\n","Epoch 28: val_loss did not improve from 0.02340\n","73/73 [==============================] - 10s 136ms/step - loss: 0.0148 - accuracy: 0.9479 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 2.3842e-11\n","Epoch 29/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9473\n","Epoch 29: val_loss did not improve from 0.02340\n","\n","Epoch 29: ReduceLROnPlateau reducing learning rate to 5.960464326965065e-12.\n","73/73 [==============================] - 11s 154ms/step - loss: 0.0150 - accuracy: 0.9473 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 2.3842e-11\n","Epoch 30/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9484\n","Epoch 30: val_loss did not improve from 0.02340\n","73/73 [==============================] - 11s 157ms/step - loss: 0.0149 - accuracy: 0.9484 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 5.9605e-12\n","Epoch 31/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9503\n","Epoch 31: val_loss did not improve from 0.02340\n","\n","Epoch 31: ReduceLROnPlateau reducing learning rate to 1.4901160817412662e-12.\n","73/73 [==============================] - 9s 128ms/step - loss: 0.0149 - accuracy: 0.9503 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 5.9605e-12\n","Epoch 32/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9484\n","Epoch 32: val_loss did not improve from 0.02340\n","73/73 [==============================] - 11s 154ms/step - loss: 0.0150 - accuracy: 0.9484 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 1.4901e-12\n","Epoch 33/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9488\n","Epoch 33: val_loss did not improve from 0.02340\n","\n","Epoch 33: ReduceLROnPlateau reducing learning rate to 3.7252902043531655e-13.\n","73/73 [==============================] - 11s 150ms/step - loss: 0.0148 - accuracy: 0.9488 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 1.4901e-12\n","Epoch 34/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9488\n","Epoch 34: val_loss did not improve from 0.02340\n","73/73 [==============================] - 10s 140ms/step - loss: 0.0150 - accuracy: 0.9488 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 3.7253e-13\n","Epoch 35/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9469\n","Epoch 35: val_loss did not improve from 0.02340\n","\n","Epoch 35: ReduceLROnPlateau reducing learning rate to 9.313225510882914e-14.\n","73/73 [==============================] - 10s 135ms/step - loss: 0.0147 - accuracy: 0.9469 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 3.7253e-13\n","Epoch 36/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9488\n","Epoch 36: val_loss did not improve from 0.02340\n","73/73 [==============================] - 11s 150ms/step - loss: 0.0149 - accuracy: 0.9488 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 9.3132e-14\n","Epoch 37/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9479\n","Epoch 37: val_loss did not improve from 0.02340\n","\n","Epoch 37: ReduceLROnPlateau reducing learning rate to 2.3283063777207284e-14.\n","73/73 [==============================] - 11s 148ms/step - loss: 0.0150 - accuracy: 0.9479 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 9.3132e-14\n","Epoch 38/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9484\n","Epoch 38: val_loss did not improve from 0.02340\n","73/73 [==============================] - 9s 127ms/step - loss: 0.0150 - accuracy: 0.9484 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 2.3283e-14\n","Epoch 39/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9490\n","Epoch 39: val_loss did not improve from 0.02340\n","\n","Epoch 39: ReduceLROnPlateau reducing learning rate to 5.820765944301821e-15.\n","73/73 [==============================] - 11s 148ms/step - loss: 0.0148 - accuracy: 0.9490 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 2.3283e-14\n","Epoch 40/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9477\n","Epoch 40: val_loss did not improve from 0.02340\n","73/73 [==============================] - 11s 150ms/step - loss: 0.0149 - accuracy: 0.9477 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 5.8208e-15\n","Epoch 41/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9488\n","Epoch 41: val_loss did not improve from 0.02340\n","\n","Epoch 41: ReduceLROnPlateau reducing learning rate to 1.4551914860754553e-15.\n","73/73 [==============================] - 10s 137ms/step - loss: 0.0148 - accuracy: 0.9488 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 5.8208e-15\n","Epoch 42/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9477\n","Epoch 42: val_loss did not improve from 0.02340\n","73/73 [==============================] - 10s 136ms/step - loss: 0.0148 - accuracy: 0.9477 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 1.4552e-15\n","Epoch 43/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9494\n","Epoch 43: val_loss did not improve from 0.02340\n","\n","Epoch 43: ReduceLROnPlateau reducing learning rate to 3.637978715188638e-16.\n","73/73 [==============================] - 11s 150ms/step - loss: 0.0148 - accuracy: 0.9494 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 1.4552e-15\n","Epoch 44/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9488\n","Epoch 44: val_loss did not improve from 0.02340\n","73/73 [==============================] - 11s 153ms/step - loss: 0.0150 - accuracy: 0.9488 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 3.6380e-16\n","Epoch 45/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9490\n","Epoch 45: val_loss did not improve from 0.02340\n","\n","Epoch 45: ReduceLROnPlateau reducing learning rate to 9.094946787971595e-17.\n","73/73 [==============================] - 9s 126ms/step - loss: 0.0148 - accuracy: 0.9490 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 3.6380e-16\n","Epoch 46/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9475\n","Epoch 46: val_loss did not improve from 0.02340\n","73/73 [==============================] - 11s 149ms/step - loss: 0.0150 - accuracy: 0.9475 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 9.0949e-17\n","Epoch 47/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9492\n","Epoch 47: val_loss did not improve from 0.02340\n","\n","Epoch 47: ReduceLROnPlateau reducing learning rate to 2.273736696992899e-17.\n","73/73 [==============================] - 11s 151ms/step - loss: 0.0149 - accuracy: 0.9492 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 9.0949e-17\n","Epoch 48/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9484\n","Epoch 48: val_loss did not improve from 0.02340\n","73/73 [==============================] - 10s 134ms/step - loss: 0.0148 - accuracy: 0.9484 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 2.2737e-17\n","Epoch 49/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9488\n","Epoch 49: val_loss did not improve from 0.02340\n","\n","Epoch 49: ReduceLROnPlateau reducing learning rate to 5.684341742482247e-18.\n","73/73 [==============================] - 10s 139ms/step - loss: 0.0148 - accuracy: 0.9488 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 2.2737e-17\n","Epoch 50/50\n","73/73 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9473\n","Epoch 50: val_loss did not improve from 0.02340\n","73/73 [==============================] - 11s 148ms/step - loss: 0.0149 - accuracy: 0.9473 - val_loss: 0.0263 - val_accuracy: 0.9272 - lr: 5.6843e-18\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7bafcf677700>"]},"metadata":{},"execution_count":17}],"source":[" # Replace 'your_loss_module' with the actual module name where focal_loss is defined\n","from keras.models import Sequential\n","from keras.layers import Conv1D, MaxPool1D, Flatten, Dense, Dropout, GRU\n","from keras.optimizers import Adam\n","from keras.backend import clear_session\n","\n","def build_sequential_model(input_shape):\n","    clear_session()  # Clear the previous Keras session to avoid clutter\n","    model = Sequential()\n","\n","    # Conv1D layers\n","    model.add(Conv1D(filters=64, kernel_size=5, strides=1, activation='relu', input_shape=input_shape))\n","    model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n","    model.add(Conv1D(filters=256, kernel_size=5, activation='relu'))\n","    # model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n","    # model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n","    model.add(MaxPool1D(pool_size=4, padding='same'))\n","    model.add(MaxPool1D(pool_size=4, padding='same'))\n","    model.add(MaxPool1D(pool_size=4, padding='same'))\n","\n","    # GRU layers\n","    model.add(GRU(64, return_sequences=True))\n","    model.add(GRU(32, return_sequences=False))  # The last GRU layer should not return sequences to flatten the output\n","\n","    # Dropout for regularization\n","    model.add(Dropout(0.25))\n","\n","    # Dense layers for classification or regression\n","    model.add(Dense(1024, activation='relu'))\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))  # Adjust based on your application\n","\n","    # Compile the model\n","    opt = Adam(learning_rate=0.0001, beta_1=0.09, beta_2=0.999, epsilon=1e-08)\n","    model.compile(optimizer=opt, loss=focal_loss(), metrics=['accuracy'])\n","\n","    return model\n","\n","# Usage\n","Model = build_sequential_model(input_shape=(52, 29))\n","Model.fit(X_train, Y_train, epochs=50, batch_size=64, callbacks=[callbacks], validation_data=(X_test, Y_test), shuffle=True)"],"id":"i10jiBrCdc4W"},{"cell_type":"code","source":["pred = Model.predict(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tt2rwFTdHBAi","executionInfo":{"status":"ok","timestamp":1709046519488,"user_tz":-360,"elapsed":1726,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"137f4d65-7024-4c48-edad-c52c4707bffa"},"id":"Tt2rwFTdHBAi","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["37/37 [==============================] - 1s 24ms/step\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f907f8ed57394d46a68d978e18160861":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_daaf142e2edd43d5968a0a752a7404e4","IPY_MODEL_2c4b820da5424bf9a22ef8727f75b0e1"],"layout":"IPY_MODEL_0862a2bbb3ca48378331783b9d58e749"}},"daaf142e2edd43d5968a0a752a7404e4":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0bd5d12fd39f4cb3bcd6c6937f39ca7b","placeholder":"​","style":"IPY_MODEL_10dd6d42672a46ae91385d86aaf7f176","value":"103.362 MB of 103.362 MB uploaded (0.134 MB deduped)\r"}},"2c4b820da5424bf9a22ef8727f75b0e1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f751ab78fd2414884c50eadde2a9184","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_277f4940a187403b802fc3e92265e444","value":1}},"0862a2bbb3ca48378331783b9d58e749":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bd5d12fd39f4cb3bcd6c6937f39ca7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10dd6d42672a46ae91385d86aaf7f176":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f751ab78fd2414884c50eadde2a9184":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"277f4940a187403b802fc3e92265e444":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":5}