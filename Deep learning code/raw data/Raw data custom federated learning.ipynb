{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Mbfw8uvdftFM","executionInfo":{"status":"ok","timestamp":1716484162143,"user_tz":-360,"elapsed":1256,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sb"]},{"cell_type":"code","source":["from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"INiFJfLjgOkx","executionInfo":{"status":"ok","timestamp":1716484162144,"user_tz":-360,"elapsed":43,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import ExtraTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score, cross_val_predict"],"metadata":{"id":"lYo2Uq77gQSH","executionInfo":{"status":"ok","timestamp":1716484165286,"user_tz":-360,"elapsed":3179,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPool1D, Flatten, Dropout,LSTM"],"metadata":{"id":"g66575_xgVzz","executionInfo":{"status":"ok","timestamp":1716484169577,"user_tz":-360,"elapsed":4302,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MOCNWlamfr3v","executionInfo":{"status":"ok","timestamp":1716484195777,"user_tz":-360,"elapsed":26217,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}},"outputId":"d9835796-f4bc-4fcb-968e-10c59ba3e803"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Raw_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/only data/raw_data.npz'\n","\n","DWT_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/DWT/DWT.npz'\n","\n","Time_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/time domain /time_domain_data.npz'\n","\n","frequency_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/feature domain/frequency_domain_data.npz'\n","\n","# RAW = np.load(Raw_data, allow_pickle=True)  # Allow loading pickled object arrays\n","# X = RAW['X'].astype('float64')\n","# Y = RAW['Y'].astype('float64')\n","# group = RAW['Group'].astype('float64')"],"metadata":{"id":"iNy9eOGMf2qO","executionInfo":{"status":"ok","timestamp":1716484202580,"user_tz":-360,"elapsed":8,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["This is a good performing model"],"metadata":{"id":"PzeABzSyHgKg"}},{"cell_type":"code","source":["# import numpy as np\n","# from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n","# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","# from tensorflow.keras.models import Sequential\n","# from tensorflow.keras.layers import Conv1D, MaxPool1D, Flatten, Dense, BatchNormalization, LSTM,MaxPooling1D\n","# from tensorflow.keras.optimizers import Adam\n","# from tensorflow.keras.regularizers import l2\n","# from tensorflow.keras.backend import clear_session\n","\n","# class FederatedData:\n","#     def __init__(self, data_path, num_clients, scaler_type='MinMax'):\n","#         self.data_path = data_path\n","#         self.num_clients = num_clients\n","#         self.scaler_type = scaler_type\n","#         self.load_data()\n","#         self.scale_data()\n","#         self.partitions = []\n","\n","#     def load_data(self):\n","#         try:\n","#             data = np.load(self.data_path)\n","#             self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","#             self.Y = data['Y']\n","#         except KeyError as e:\n","#             raise ValueError(f\"Missing expected data field: {e}\")\n","#         except FileNotFoundError as e:\n","#             raise ValueError(f\"Data file not found: {e}\")\n","\n","#     def scale_data(self):\n","#         # Reshape data to 2D array for scaling\n","#         X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","#         # Select scaler based on input\n","#         if self.scaler_type == 'Standard':\n","#             scaler = StandardScaler()\n","#         elif self.scaler_type == 'MinMax':\n","#             scaler = MinMaxScaler(feature_range=(0, 1))\n","#         else:\n","#             raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","#         # Fit and transform the data\n","#         scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","#         # Reshape back to original shape\n","#         self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","#     def create_partitions(self):\n","#         sss = StratifiedShuffleSplit(n_splits=self.num_clients, test_size=0.2, random_state=42)\n","#         for train_idx, test_idx in sss.split(self.X, self.Y):\n","#             partition_X_train, partition_X_test = self.X[train_idx], self.X[test_idx]\n","#             partition_Y_train, partition_Y_test = self.Y[train_idx], self.Y[test_idx]\n","#             self.partitions.append((partition_X_train, partition_Y_train, partition_X_test, partition_Y_test))\n","\n","#     def get_training_and_validation_data(self, client_idx):\n","#         if client_idx < 0 or client_idx >= len(self.partitions):\n","#             raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","#         partition_X_train, partition_Y_train, _, _ = self.partitions[client_idx]\n","#         X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","#         return X_train, X_val, Y_train, Y_val\n","\n","#     def get_testing_data(self, client_idx):\n","#         if client_idx < 0 or client_idx >= len(self.partitions):\n","#             raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","#         _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","#         return partition_X_test, partition_Y_test\n","\n","# def build_sequential_model(input_shape):\n","#     clear_session()\n","#     model = Sequential()\n","\n","#     model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","#     model.add(BatchNormalization())\n","#     model.add(MaxPooling1D(2, padding=\"same\"))\n","#     model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","#     model.add(MaxPooling1D(2, padding=\"same\"))\n","#     model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","#     model.add(MaxPooling1D(2, padding=\"same\"))\n","#     model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","#     model.add(LSTM(256, return_sequences=True))\n","#     model.add(LSTM(256, return_sequences=False))\n","#     model.add(Flatten())\n","#     model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.001)))\n","#     model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.001)))\n","#     model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","#     opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","#     model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","#     model.summary()\n","#     return model\n","\n","# def federated_learning(data_path):\n","#     federated_data = FederatedData(data_path, num_clients=2, scaler_type='MinMax')\n","#     federated_data.create_partitions()\n","\n","#     # Get the input shape from the data\n","#     input_shape = federated_data.X.shape[1:]\n","#     global_model = build_sequential_model(input_shape)\n","\n","#     num_clients = 2\n","#     local_epochs = 20\n","#     global_optimizer = Adam()\n","\n","#     # Initialize m and v for Adam optimizer\n","#     m = [np.zeros_like(w) for w in global_model.get_weights()]\n","#     v = [np.zeros_like(w) for w in global_model.get_weights()]\n","#     beta1 = 0.9\n","#     beta2 = 0.999\n","#     epsilon = 1e-7\n","#     t = 0\n","\n","#     client_data = []\n","#     for client_idx in range(num_clients):\n","#         x_train, _, y_train, _ = federated_data.get_training_and_validation_data(client_idx)\n","#         client_data.append((x_train, y_train))\n","\n","#     for epoch in range(local_epochs):\n","#         client_models = []\n","\n","#         for client in range(num_clients):\n","#             x, y = client_data[client]\n","#             client_model = build_sequential_model(input_shape)\n","#             client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","#             client_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","#             history = client_model.fit(x, y, epochs=1, batch_size=64)\n","#             client_models.append(client_model)\n","\n","#             print(history.history)\n","\n","#         global_weights = global_model.get_weights()\n","#         for layer in range(len(global_model.layers)):\n","#             layer_weights = []\n","#             layer_biases = []\n","#             for i in range(num_clients):\n","#                 layer_weights.append(client_models[i].layers[layer].get_weights()[0])\n","#                 layer_biases.append(client_models[i].layers[layer].get_weights()[1])\n","#             averaged_layer_weights = np.mean(layer_weights, axis=0)\n","#             averaged_layer_biases = np.mean(layer_biases, axis=0)\n","#             global_weights[layer * 2] = averaged_layer_weights.reshape(global_weights[layer * 2].shape)\n","#             global_weights[layer * 2 + 1] = averaged_layer_biases.reshape(global_weights[layer * 2 + 1].shape)\n","\n","#         # Apply FedOpt (Adam) update to global weights\n","#         t += 1\n","#         for i in range(len(global_weights)):\n","#             g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","#             m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","#             v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","#             m_hat = m[i] / (1 - beta1 ** t)\n","#             v_hat = v[i] / (1 - beta2 ** t)\n","#             global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","#         global_model.set_weights(global_weights)\n","\n","#     return global_model\n"],"metadata":{"id":"6cLRGG8qDAWq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# DWT"],"metadata":{"id":"6DhAYwXUSE9z"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split,KFold,StratifiedKFold\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM,Dropout, GRU\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from keras.optimizers import RMSprop, Adam\n","# from wandb.keras import WandbCallback\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', k_folds=5, stratified=False):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.k_folds = k_folds\n","        self.stratified = stratified\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle= True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        X = scaled_data_reshaped.reshape(self.X.shape)\n","        np.moveaxis(X, 1, 2)\n","        self.X = X\n","\n","    def create_partitions(self):\n","        if self.stratified:\n","            kf = StratifiedKFold(n_splits=self.k_folds, shuffle=True, random_state=42)\n","        else:\n","            kf = KFold(n_splits=self.k_folds, shuffle=True, random_state=42)\n","\n","        for train_index, test_index in kf.split(self.X, self.Y):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(LSTM(256, return_sequences=True))\n","    model.add(LSTM(256, return_sequences=True))\n","        # GRU layers\n","    # model.add(GRU(256, return_sequences=True))\n","    # model.add(GRU(128, return_sequences=False))\n","\n","    model.add(Flatten())\n","    # model.add(Dense(1024, activation='relu'))\n","    # model.add(Dense(512, activation='relu'))\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dense(32, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Evaluate client model\n","            y_pred = (client_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"VvjC2xCQNHLP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["global_model, metrics_df = federated_learning(DWT_data)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVURUnmYNNNg","outputId":"919a25af-f080-480f-c168-364a5e10a2c4","executionInfo":{"status":"ok","timestamp":1716482933454,"user_tz":-360,"elapsed":163465,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4667, 52, 29), Test shape: (1167, 52, 29)\n","Train shape: (4667, 52, 29), Test shape: (1167, 52, 29)\n","Train shape: (4667, 52, 29), Test shape: (1167, 52, 29)\n","Train shape: (4667, 52, 29), Test shape: (1167, 52, 29)\n","Train shape: (4668, 52, 29), Test shape: (1166, 52, 29)\n","Train shape: (4667, 52, 29), Test shape: (1167, 52, 29)\n","Train shape: (4667, 52, 29), Test shape: (1167, 52, 29)\n","Train shape: (4667, 52, 29), Test shape: (1167, 52, 29)\n","Train shape: (4667, 52, 29), Test shape: (1167, 52, 29)\n","Train shape: (4668, 52, 29), Test shape: (1166, 52, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 9s 59ms/step - loss: 0.6928 - accuracy: 0.5031 - val_loss: 0.6930 - val_accuracy: 0.5525\n","Epoch 2/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.6886 - accuracy: 0.5660 - val_loss: 0.6925 - val_accuracy: 0.7216\n","Epoch 3/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.6806 - accuracy: 0.6885 - val_loss: 0.6916 - val_accuracy: 0.6328\n","Epoch 4/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.6663 - accuracy: 0.6962 - val_loss: 0.6897 - val_accuracy: 0.6253\n","Epoch 5/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.6436 - accuracy: 0.7118 - val_loss: 0.6861 - val_accuracy: 0.6435\n","Epoch 6/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.6134 - accuracy: 0.7289 - val_loss: 0.6796 - val_accuracy: 0.6777\n","Epoch 7/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.5806 - accuracy: 0.7292 - val_loss: 0.6697 - val_accuracy: 0.7141\n","Epoch 8/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.5591 - accuracy: 0.7268 - val_loss: 0.6588 - val_accuracy: 0.7056\n","Epoch 9/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.5477 - accuracy: 0.7257 - val_loss: 0.6486 - val_accuracy: 0.7355\n","Epoch 10/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.5415 - accuracy: 0.7348 - val_loss: 0.6368 - val_accuracy: 0.7281\n","Epoch 11/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.5321 - accuracy: 0.7442 - val_loss: 0.6270 - val_accuracy: 0.7313\n","Epoch 12/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.5271 - accuracy: 0.7385 - val_loss: 0.6156 - val_accuracy: 0.7334\n","Epoch 13/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.5223 - accuracy: 0.7477 - val_loss: 0.6054 - val_accuracy: 0.7409\n","Epoch 14/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.5129 - accuracy: 0.7533 - val_loss: 0.5924 - val_accuracy: 0.7409\n","Epoch 15/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.5106 - accuracy: 0.7576 - val_loss: 0.5789 - val_accuracy: 0.7409\n","Epoch 16/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.5023 - accuracy: 0.7653 - val_loss: 0.5627 - val_accuracy: 0.7495\n","Epoch 17/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4987 - accuracy: 0.7648 - val_loss: 0.5604 - val_accuracy: 0.7463\n","Epoch 18/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4954 - accuracy: 0.7664 - val_loss: 0.5412 - val_accuracy: 0.7516\n","Epoch 19/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4934 - accuracy: 0.7688 - val_loss: 0.5517 - val_accuracy: 0.7366\n","Epoch 20/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4919 - accuracy: 0.7704 - val_loss: 0.5301 - val_accuracy: 0.7505\n","Epoch 21/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4845 - accuracy: 0.7752 - val_loss: 0.5236 - val_accuracy: 0.7505\n","Epoch 22/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4858 - accuracy: 0.7777 - val_loss: 0.5282 - val_accuracy: 0.7505\n","Epoch 23/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4843 - accuracy: 0.7763 - val_loss: 0.5177 - val_accuracy: 0.7559\n","Epoch 24/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4796 - accuracy: 0.7809 - val_loss: 0.5346 - val_accuracy: 0.7463\n","Epoch 25/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4836 - accuracy: 0.7769 - val_loss: 0.5203 - val_accuracy: 0.7484\n","Epoch 26/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4774 - accuracy: 0.7819 - val_loss: 0.5244 - val_accuracy: 0.7505\n","Epoch 27/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4771 - accuracy: 0.7844 - val_loss: 0.5276 - val_accuracy: 0.7505\n","Epoch 28/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4763 - accuracy: 0.7798 - val_loss: 0.5217 - val_accuracy: 0.7548\n","Epoch 29/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4736 - accuracy: 0.7897 - val_loss: 0.5219 - val_accuracy: 0.7537\n","Epoch 30/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4731 - accuracy: 0.7862 - val_loss: 0.5246 - val_accuracy: 0.7527\n","Epoch 31/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4711 - accuracy: 0.7889 - val_loss: 0.5256 - val_accuracy: 0.7537\n","Epoch 32/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.5238 - val_accuracy: 0.7527\n","Epoch 33/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4691 - accuracy: 0.7873 - val_loss: 0.5393 - val_accuracy: 0.7473\n","Epoch 34/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4717 - accuracy: 0.7889 - val_loss: 0.5320 - val_accuracy: 0.7527\n","Epoch 35/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4711 - accuracy: 0.7833 - val_loss: 0.5277 - val_accuracy: 0.7537\n","Epoch 36/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4653 - accuracy: 0.7921 - val_loss: 0.5220 - val_accuracy: 0.7548\n","Epoch 37/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4670 - accuracy: 0.7908 - val_loss: 0.5233 - val_accuracy: 0.7548\n","Epoch 38/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4651 - accuracy: 0.7897 - val_loss: 0.5239 - val_accuracy: 0.7602\n","Epoch 39/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4650 - accuracy: 0.7881 - val_loss: 0.5275 - val_accuracy: 0.7559\n","Epoch 40/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.4591 - accuracy: 0.7921 - val_loss: 0.5241 - val_accuracy: 0.7612\n","Epoch 41/100\n","30/30 [==============================] - 1s 35ms/step - loss: 0.4610 - accuracy: 0.7972 - val_loss: 0.5255 - val_accuracy: 0.7537\n","Epoch 42/100\n","30/30 [==============================] - 1s 35ms/step - loss: 0.4579 - accuracy: 0.7956 - val_loss: 0.5268 - val_accuracy: 0.7580\n","Epoch 43/100\n","30/30 [==============================] - 1s 37ms/step - loss: 0.4594 - accuracy: 0.7892 - val_loss: 0.5248 - val_accuracy: 0.7559\n","Epoch 44/100\n","30/30 [==============================] - 1s 39ms/step - loss: 0.4552 - accuracy: 0.7956 - val_loss: 0.5243 - val_accuracy: 0.7537\n","Epoch 45/100\n","30/30 [==============================] - 1s 38ms/step - loss: 0.4557 - accuracy: 0.7961 - val_loss: 0.5253 - val_accuracy: 0.7548\n","Epoch 46/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.4545 - accuracy: 0.7956 - val_loss: 0.5273 - val_accuracy: 0.7559\n","Epoch 47/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.4519 - accuracy: 0.8002 - val_loss: 0.5232 - val_accuracy: 0.7580\n","Epoch 48/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.4507 - accuracy: 0.7961 - val_loss: 0.5228 - val_accuracy: 0.7612\n","Epoch 49/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.4495 - accuracy: 0.8028 - val_loss: 0.5234 - val_accuracy: 0.7655\n","Epoch 50/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.4479 - accuracy: 0.7986 - val_loss: 0.5305 - val_accuracy: 0.7527\n","Epoch 51/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.4506 - accuracy: 0.7986 - val_loss: 0.5220 - val_accuracy: 0.7634\n","Epoch 52/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.4442 - accuracy: 0.8063 - val_loss: 0.5203 - val_accuracy: 0.7580\n","Epoch 53/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4455 - accuracy: 0.8074 - val_loss: 0.5331 - val_accuracy: 0.7570\n","Epoch 54/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.4519 - accuracy: 0.7964 - val_loss: 0.5210 - val_accuracy: 0.7580\n","Epoch 55/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.4461 - accuracy: 0.8004 - val_loss: 0.5234 - val_accuracy: 0.7612\n","Epoch 56/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.4424 - accuracy: 0.8034 - val_loss: 0.5194 - val_accuracy: 0.7612\n","Epoch 57/100\n","30/30 [==============================] - 1s 33ms/step - loss: 0.4397 - accuracy: 0.8109 - val_loss: 0.5206 - val_accuracy: 0.7612\n","Epoch 58/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.4360 - accuracy: 0.8087 - val_loss: 0.5207 - val_accuracy: 0.7623\n","Epoch 59/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4385 - accuracy: 0.8069 - val_loss: 0.5196 - val_accuracy: 0.7623\n","Epoch 60/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4342 - accuracy: 0.8069 - val_loss: 0.5200 - val_accuracy: 0.7623\n","Epoch 61/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4351 - accuracy: 0.8069 - val_loss: 0.5189 - val_accuracy: 0.7634\n","Epoch 62/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4338 - accuracy: 0.8053 - val_loss: 0.5218 - val_accuracy: 0.7602\n","Epoch 63/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4398 - accuracy: 0.8066 - val_loss: 0.5164 - val_accuracy: 0.7623\n","Epoch 64/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4341 - accuracy: 0.8111 - val_loss: 0.5216 - val_accuracy: 0.7612\n","Epoch 65/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.4308 - accuracy: 0.8114 - val_loss: 0.5159 - val_accuracy: 0.7655\n","Epoch 66/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4323 - accuracy: 0.8154 - val_loss: 0.5118 - val_accuracy: 0.7655\n","Epoch 67/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4307 - accuracy: 0.8109 - val_loss: 0.5136 - val_accuracy: 0.7634\n","Epoch 68/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4269 - accuracy: 0.8141 - val_loss: 0.5168 - val_accuracy: 0.7634\n","Epoch 69/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4224 - accuracy: 0.8133 - val_loss: 0.5142 - val_accuracy: 0.7645\n","Epoch 70/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4235 - accuracy: 0.8138 - val_loss: 0.5116 - val_accuracy: 0.7645\n","Epoch 71/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4212 - accuracy: 0.8165 - val_loss: 0.5163 - val_accuracy: 0.7623\n","Epoch 72/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4241 - accuracy: 0.8117 - val_loss: 0.5078 - val_accuracy: 0.7698\n","Epoch 73/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4188 - accuracy: 0.8165 - val_loss: 0.5083 - val_accuracy: 0.7612\n","Epoch 74/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4166 - accuracy: 0.8146 - val_loss: 0.5178 - val_accuracy: 0.7612\n","Epoch 75/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4112 - accuracy: 0.8184 - val_loss: 0.5069 - val_accuracy: 0.7623\n","Epoch 76/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4093 - accuracy: 0.8205 - val_loss: 0.5122 - val_accuracy: 0.7612\n","Epoch 77/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4072 - accuracy: 0.8261 - val_loss: 0.5058 - val_accuracy: 0.7709\n","Epoch 78/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4096 - accuracy: 0.8237 - val_loss: 0.5005 - val_accuracy: 0.7762\n","Epoch 79/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4089 - accuracy: 0.8213 - val_loss: 0.5092 - val_accuracy: 0.7666\n","Epoch 80/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4061 - accuracy: 0.8296 - val_loss: 0.4994 - val_accuracy: 0.7709\n","Epoch 81/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4034 - accuracy: 0.8235 - val_loss: 0.4996 - val_accuracy: 0.7773\n","Epoch 82/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4028 - accuracy: 0.8267 - val_loss: 0.4957 - val_accuracy: 0.7816\n","Epoch 83/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3937 - accuracy: 0.8280 - val_loss: 0.4957 - val_accuracy: 0.7827\n","Epoch 84/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3966 - accuracy: 0.8240 - val_loss: 0.4984 - val_accuracy: 0.7827\n","Epoch 85/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3914 - accuracy: 0.8288 - val_loss: 0.4951 - val_accuracy: 0.7827\n","Epoch 86/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3933 - accuracy: 0.8339 - val_loss: 0.4939 - val_accuracy: 0.7859\n","Epoch 87/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3942 - accuracy: 0.8299 - val_loss: 0.4934 - val_accuracy: 0.7794\n","Epoch 88/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3888 - accuracy: 0.8326 - val_loss: 0.4956 - val_accuracy: 0.7848\n","Epoch 89/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3862 - accuracy: 0.8336 - val_loss: 0.4945 - val_accuracy: 0.7741\n","Epoch 90/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3840 - accuracy: 0.8350 - val_loss: 0.4900 - val_accuracy: 0.7816\n","Epoch 91/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3810 - accuracy: 0.8342 - val_loss: 0.4938 - val_accuracy: 0.7848\n","Epoch 92/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3746 - accuracy: 0.8390 - val_loss: 0.4900 - val_accuracy: 0.7891\n","Epoch 93/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3755 - accuracy: 0.8387 - val_loss: 0.4885 - val_accuracy: 0.7859\n","Epoch 94/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3731 - accuracy: 0.8382 - val_loss: 0.4884 - val_accuracy: 0.7805\n","Epoch 95/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3707 - accuracy: 0.8428 - val_loss: 0.5094 - val_accuracy: 0.7709\n","Epoch 96/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3697 - accuracy: 0.8470 - val_loss: 0.4848 - val_accuracy: 0.7859\n","Epoch 97/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3635 - accuracy: 0.8457 - val_loss: 0.4919 - val_accuracy: 0.7805\n","Epoch 98/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3622 - accuracy: 0.8513 - val_loss: 0.4943 - val_accuracy: 0.7794\n","Epoch 99/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3591 - accuracy: 0.8476 - val_loss: 0.4866 - val_accuracy: 0.7859\n","Epoch 100/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3551 - accuracy: 0.8489 - val_loss: 0.4979 - val_accuracy: 0.7816\n","{'loss': [0.6927823424339294, 0.6886005997657776, 0.6805983781814575, 0.6663342714309692, 0.6435669660568237, 0.6133990287780762, 0.5806451439857483, 0.5591051578521729, 0.5477378964424133, 0.5415157675743103, 0.5320699214935303, 0.5271093249320984, 0.5222705006599426, 0.5129191279411316, 0.5106022953987122, 0.5023308992385864, 0.4986805021762848, 0.4953937232494354, 0.4934157133102417, 0.49189305305480957, 0.48449015617370605, 0.48579540848731995, 0.48433926701545715, 0.4796038269996643, 0.4835614860057831, 0.4773975908756256, 0.47709813714027405, 0.4762794077396393, 0.47358039021492004, 0.4730650782585144, 0.4711058735847473, 0.47030627727508545, 0.46910199522972107, 0.4716934859752655, 0.4710817337036133, 0.46529388427734375, 0.4669560194015503, 0.4650746285915375, 0.4650290012359619, 0.45912137627601624, 0.4610045552253723, 0.4578617811203003, 0.4594079852104187, 0.45521923899650574, 0.4557279348373413, 0.4544711112976074, 0.4518980085849762, 0.4507191479206085, 0.4495472311973572, 0.44790950417518616, 0.45063483715057373, 0.4441784918308258, 0.445467084646225, 0.4519213140010834, 0.44610995054244995, 0.4423781633377075, 0.43970024585723877, 0.43596357107162476, 0.43845993280410767, 0.4342329800128937, 0.4351462423801422, 0.4337579011917114, 0.43978747725486755, 0.4340605139732361, 0.43077534437179565, 0.4322926700115204, 0.4307357966899872, 0.4269155263900757, 0.4223993122577667, 0.42345601320266724, 0.42118218541145325, 0.4241081178188324, 0.4188458025455475, 0.4166116416454315, 0.4112315773963928, 0.40932074189186096, 0.4072309136390686, 0.4096100628376007, 0.40890565514564514, 0.40613406896591187, 0.4034045934677124, 0.40275663137435913, 0.3936508595943451, 0.39656537771224976, 0.3913746476173401, 0.3932704031467438, 0.39417141675949097, 0.38878950476646423, 0.3862049877643585, 0.3839569687843323, 0.38095125555992126, 0.37456247210502625, 0.3755418062210083, 0.3730705678462982, 0.37068110704421997, 0.36973798274993896, 0.36349815130233765, 0.362235963344574, 0.3590857684612274, 0.3551118075847626], 'accuracy': [0.5030806064605713, 0.5660327076911926, 0.6884543299674988, 0.6962229013442993, 0.7117599844932556, 0.7289043664932251, 0.7291722297668457, 0.7267613410949707, 0.7256897687911987, 0.7347977757453918, 0.7441735863685608, 0.7385480999946594, 0.7476560473442078, 0.7532815337181091, 0.7575676441192627, 0.7653362154960632, 0.7648004293441772, 0.7664077281951904, 0.7688186168670654, 0.7704259157180786, 0.7752478122711182, 0.7776587009429932, 0.7763193249702454, 0.7808732986450195, 0.7768550515174866, 0.7819448113441467, 0.7843557596206665, 0.7798017859458923, 0.7897133827209473, 0.7862309217453003, 0.7889097332954407, 0.7840878367424011, 0.7873024344444275, 0.7889097332954407, 0.7832842469215393, 0.7921242713928223, 0.7907848954200745, 0.7897133827209473, 0.7881060838699341, 0.7921242713928223, 0.7972140312194824, 0.7956067323684692, 0.7891775965690613, 0.7956067323684692, 0.7961425185203552, 0.7956067323684692, 0.8001607060432434, 0.7961425185203552, 0.8028395175933838, 0.798553466796875, 0.798553466796875, 0.8063219785690308, 0.807393491268158, 0.7964103817939758, 0.8004286289215088, 0.8033753037452698, 0.8108759522438049, 0.8087329268455505, 0.8068577647209167, 0.8068577647209167, 0.8068577647209167, 0.8052504658699036, 0.8065899014472961, 0.8111438751220703, 0.8114117383956909, 0.8154299259185791, 0.8108759522438049, 0.8140905499458313, 0.8132869005203247, 0.8138226866722107, 0.8165014982223511, 0.8116796016693115, 0.8165014982223511, 0.8146262764930725, 0.8183766603469849, 0.8205196857452393, 0.8261451721191406, 0.8237342834472656, 0.8213233351707458, 0.8296276330947876, 0.8234663605690002, 0.8266809582710266, 0.8280203342437744, 0.8240021467208862, 0.828823983669281, 0.8339137434959412, 0.829895555973053, 0.8325743079185486, 0.8336458802223206, 0.8349852561950684, 0.8341816067695618, 0.8390035033226013, 0.8387355804443359, 0.8381998538970947, 0.8427538275718689, 0.8470399379730225, 0.8457005023956299, 0.8513259887695312, 0.8475756645202637, 0.8489151000976562], 'val_loss': [0.6930257678031921, 0.692512035369873, 0.6915682554244995, 0.689696729183197, 0.6860841512680054, 0.6795814037322998, 0.6697421669960022, 0.6588415503501892, 0.6485723257064819, 0.6367762088775635, 0.626980721950531, 0.6156149506568909, 0.6053827404975891, 0.5924158096313477, 0.578877866268158, 0.5626738667488098, 0.5603528618812561, 0.5411974191665649, 0.5516706109046936, 0.5300647020339966, 0.5236304998397827, 0.5282449126243591, 0.517733633518219, 0.5345781445503235, 0.5202656388282776, 0.5244258046150208, 0.5276456475257874, 0.5217265486717224, 0.521906852722168, 0.524567186832428, 0.5256215929985046, 0.5237559080123901, 0.5393413305282593, 0.5320441722869873, 0.5276936292648315, 0.5220170021057129, 0.5233281254768372, 0.5239307284355164, 0.5275086760520935, 0.5240817070007324, 0.5255195498466492, 0.5268409848213196, 0.5247739553451538, 0.5242884159088135, 0.5253310799598694, 0.5272919535636902, 0.5231995582580566, 0.5228191018104553, 0.5234141945838928, 0.5305101871490479, 0.5219766497612, 0.5202918648719788, 0.5331203937530518, 0.5210348963737488, 0.5234068036079407, 0.5194156169891357, 0.5205873250961304, 0.5207200050354004, 0.5195885300636292, 0.5199832916259766, 0.5188813209533691, 0.5217874050140381, 0.5164169073104858, 0.5216236114501953, 0.515929102897644, 0.511806845664978, 0.5136019587516785, 0.5167652368545532, 0.5141894221305847, 0.5115796327590942, 0.5162718296051025, 0.5078362822532654, 0.5082617998123169, 0.5177674889564514, 0.5069372653961182, 0.512216329574585, 0.5057549476623535, 0.5004818439483643, 0.5091829299926758, 0.499437153339386, 0.4995589554309845, 0.4957248568534851, 0.49567365646362305, 0.49843430519104004, 0.49513959884643555, 0.4938572943210602, 0.49344152212142944, 0.49560391902923584, 0.49449729919433594, 0.489993691444397, 0.4938456118106842, 0.48997101187705994, 0.4885443150997162, 0.4884372651576996, 0.5093756914138794, 0.4847569465637207, 0.49185338616371155, 0.4943380057811737, 0.48660773038864136, 0.4978793263435364], 'val_accuracy': [0.5524625182151794, 0.721627414226532, 0.6327623128890991, 0.6252676844596863, 0.643468976020813, 0.6777302026748657, 0.7141327857971191, 0.705567479133606, 0.7355460524559021, 0.7280513644218445, 0.7312633991241455, 0.7334046959877014, 0.740899384021759, 0.740899384021759, 0.740899384021759, 0.7494646906852722, 0.7462526559829712, 0.7516059875488281, 0.7366167306900024, 0.7505353093147278, 0.7505353093147278, 0.7505353093147278, 0.7558886408805847, 0.7462526559829712, 0.7483940124511719, 0.7505353093147278, 0.7505353093147278, 0.7548179626464844, 0.7537473440170288, 0.7526766657829285, 0.7537473440170288, 0.7526766657829285, 0.7473233342170715, 0.7526766657829285, 0.7537473440170288, 0.7548179626464844, 0.7548179626464844, 0.7601712942123413, 0.7558886408805847, 0.7612419724464417, 0.7537473440170288, 0.7580299973487854, 0.7558886408805847, 0.7537473440170288, 0.7548179626464844, 0.7558886408805847, 0.7580299973487854, 0.7612419724464417, 0.7655246257781982, 0.7526766657829285, 0.7633832693099976, 0.7580299973487854, 0.7569593191146851, 0.7580299973487854, 0.7612419724464417, 0.7612419724464417, 0.7612419724464417, 0.762312650680542, 0.762312650680542, 0.762312650680542, 0.7633832693099976, 0.7601712942123413, 0.762312650680542, 0.7612419724464417, 0.7655246257781982, 0.7655246257781982, 0.7633832693099976, 0.7633832693099976, 0.7644539475440979, 0.7644539475440979, 0.762312650680542, 0.7698072791099548, 0.7612419724464417, 0.7612419724464417, 0.762312650680542, 0.7612419724464417, 0.7708779573440552, 0.7762312889099121, 0.7665953040122986, 0.7708779573440552, 0.7773019075393677, 0.7815845608711243, 0.7826552391052246, 0.7826552391052246, 0.7826552391052246, 0.7858672142028809, 0.7794432640075684, 0.7847965955734253, 0.7740899324417114, 0.7815845608711243, 0.7847965955734253, 0.7890792489051819, 0.7858672142028809, 0.7805139422416687, 0.7708779573440552, 0.7858672142028809, 0.7805139422416687, 0.7794432640075684, 0.7858672142028809, 0.7815845608711243]}\n","37/37 [==============================] - 1s 6ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 9s 52ms/step - loss: 0.6928 - accuracy: 0.5020 - val_loss: 0.6930 - val_accuracy: 0.4861\n","Epoch 2/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.6889 - accuracy: 0.5526 - val_loss: 0.6926 - val_accuracy: 0.5139\n","Epoch 3/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.6810 - accuracy: 0.6501 - val_loss: 0.6916 - val_accuracy: 0.5921\n","Epoch 4/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.6649 - accuracy: 0.6919 - val_loss: 0.6897 - val_accuracy: 0.5664\n","Epoch 5/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.6399 - accuracy: 0.7168 - val_loss: 0.6852 - val_accuracy: 0.6210\n","Epoch 6/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.6072 - accuracy: 0.7177 - val_loss: 0.6767 - val_accuracy: 0.7270\n","Epoch 7/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.5749 - accuracy: 0.7262 - val_loss: 0.6677 - val_accuracy: 0.6809\n","Epoch 8/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.5536 - accuracy: 0.7302 - val_loss: 0.6538 - val_accuracy: 0.7495\n","Epoch 9/100\n","30/30 [==============================] - 1s 33ms/step - loss: 0.5423 - accuracy: 0.7329 - val_loss: 0.6423 - val_accuracy: 0.7398\n","Epoch 10/100\n","30/30 [==============================] - 1s 42ms/step - loss: 0.5384 - accuracy: 0.7343 - val_loss: 0.6314 - val_accuracy: 0.7409\n","Epoch 11/100\n","30/30 [==============================] - 1s 40ms/step - loss: 0.5359 - accuracy: 0.7383 - val_loss: 0.6202 - val_accuracy: 0.7634\n","Epoch 12/100\n","30/30 [==============================] - 1s 31ms/step - loss: 0.5280 - accuracy: 0.7418 - val_loss: 0.6064 - val_accuracy: 0.7687\n","Epoch 13/100\n","30/30 [==============================] - 1s 34ms/step - loss: 0.5238 - accuracy: 0.7442 - val_loss: 0.5907 - val_accuracy: 0.7655\n","Epoch 14/100\n","30/30 [==============================] - 1s 38ms/step - loss: 0.5190 - accuracy: 0.7498 - val_loss: 0.5772 - val_accuracy: 0.7677\n","Epoch 15/100\n","30/30 [==============================] - 1s 33ms/step - loss: 0.5168 - accuracy: 0.7501 - val_loss: 0.5602 - val_accuracy: 0.7677\n","Epoch 16/100\n","30/30 [==============================] - 1s 32ms/step - loss: 0.5115 - accuracy: 0.7527 - val_loss: 0.5476 - val_accuracy: 0.7773\n","Epoch 17/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.5088 - accuracy: 0.7586 - val_loss: 0.5321 - val_accuracy: 0.7784\n","Epoch 18/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.5075 - accuracy: 0.7592 - val_loss: 0.5162 - val_accuracy: 0.7762\n","Epoch 19/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.5048 - accuracy: 0.7619 - val_loss: 0.5257 - val_accuracy: 0.7741\n","Epoch 20/100\n","30/30 [==============================] - 1s 35ms/step - loss: 0.4999 - accuracy: 0.7613 - val_loss: 0.4918 - val_accuracy: 0.7912\n","Epoch 21/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.4968 - accuracy: 0.7688 - val_loss: 0.4822 - val_accuracy: 0.7912\n","Epoch 22/100\n","30/30 [==============================] - 1s 33ms/step - loss: 0.4938 - accuracy: 0.7683 - val_loss: 0.4753 - val_accuracy: 0.7934\n","Epoch 23/100\n","30/30 [==============================] - 1s 45ms/step - loss: 0.4896 - accuracy: 0.7739 - val_loss: 0.4706 - val_accuracy: 0.7944\n","Epoch 24/100\n","30/30 [==============================] - 1s 34ms/step - loss: 0.4877 - accuracy: 0.7736 - val_loss: 0.4647 - val_accuracy: 0.7891\n","Epoch 25/100\n","30/30 [==============================] - 1s 34ms/step - loss: 0.4814 - accuracy: 0.7785 - val_loss: 0.4594 - val_accuracy: 0.7955\n","Epoch 26/100\n","30/30 [==============================] - 1s 33ms/step - loss: 0.4819 - accuracy: 0.7787 - val_loss: 0.4660 - val_accuracy: 0.7998\n","Epoch 27/100\n","30/30 [==============================] - 1s 37ms/step - loss: 0.4801 - accuracy: 0.7793 - val_loss: 0.4568 - val_accuracy: 0.7923\n","Epoch 28/100\n","30/30 [==============================] - 1s 38ms/step - loss: 0.4831 - accuracy: 0.7750 - val_loss: 0.4530 - val_accuracy: 0.7966\n","Epoch 29/100\n","30/30 [==============================] - 1s 42ms/step - loss: 0.4791 - accuracy: 0.7852 - val_loss: 0.4522 - val_accuracy: 0.7944\n","Epoch 30/100\n","30/30 [==============================] - 1s 39ms/step - loss: 0.4773 - accuracy: 0.7814 - val_loss: 0.4533 - val_accuracy: 0.8019\n","Epoch 31/100\n","30/30 [==============================] - 1s 42ms/step - loss: 0.4772 - accuracy: 0.7819 - val_loss: 0.4536 - val_accuracy: 0.7944\n","Epoch 32/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4732 - accuracy: 0.7846 - val_loss: 0.4491 - val_accuracy: 0.8051\n","Epoch 33/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4698 - accuracy: 0.7876 - val_loss: 0.4495 - val_accuracy: 0.7966\n","Epoch 34/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4685 - accuracy: 0.7862 - val_loss: 0.4474 - val_accuracy: 0.8030\n","Epoch 35/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4655 - accuracy: 0.7884 - val_loss: 0.4624 - val_accuracy: 0.7901\n","Epoch 36/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4724 - accuracy: 0.7873 - val_loss: 0.4520 - val_accuracy: 0.8094\n","Epoch 37/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4671 - accuracy: 0.7852 - val_loss: 0.4443 - val_accuracy: 0.8019\n","Epoch 38/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4658 - accuracy: 0.7886 - val_loss: 0.4446 - val_accuracy: 0.8009\n","Epoch 39/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4667 - accuracy: 0.7900 - val_loss: 0.4428 - val_accuracy: 0.7987\n","Epoch 40/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4644 - accuracy: 0.7841 - val_loss: 0.4427 - val_accuracy: 0.8019\n","Epoch 41/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4621 - accuracy: 0.7927 - val_loss: 0.4435 - val_accuracy: 0.8030\n","Epoch 42/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4666 - accuracy: 0.7937 - val_loss: 0.4449 - val_accuracy: 0.7998\n","Epoch 43/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.4625 - accuracy: 0.7919 - val_loss: 0.4497 - val_accuracy: 0.7987\n","Epoch 44/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.4605 - accuracy: 0.7921 - val_loss: 0.4404 - val_accuracy: 0.8051\n","Epoch 45/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.4604 - accuracy: 0.7913 - val_loss: 0.4401 - val_accuracy: 0.8019\n","Epoch 46/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.4580 - accuracy: 0.7935 - val_loss: 0.4393 - val_accuracy: 0.8094\n","Epoch 47/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.4544 - accuracy: 0.7929 - val_loss: 0.4401 - val_accuracy: 0.8073\n","Epoch 48/100\n","30/30 [==============================] - 1s 31ms/step - loss: 0.4534 - accuracy: 0.7948 - val_loss: 0.4397 - val_accuracy: 0.8084\n","Epoch 49/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.4548 - accuracy: 0.8012 - val_loss: 0.4371 - val_accuracy: 0.8084\n","Epoch 50/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.4515 - accuracy: 0.7967 - val_loss: 0.4367 - val_accuracy: 0.8094\n","Epoch 51/100\n","30/30 [==============================] - 1s 39ms/step - loss: 0.4504 - accuracy: 0.8012 - val_loss: 0.4376 - val_accuracy: 0.8041\n","Epoch 52/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.4464 - accuracy: 0.7996 - val_loss: 0.4381 - val_accuracy: 0.8084\n","Epoch 53/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.4451 - accuracy: 0.8026 - val_loss: 0.4461 - val_accuracy: 0.7998\n","Epoch 54/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.4450 - accuracy: 0.7991 - val_loss: 0.4371 - val_accuracy: 0.8116\n","Epoch 55/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4480 - accuracy: 0.7916 - val_loss: 0.4374 - val_accuracy: 0.8105\n","Epoch 56/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.4415 - accuracy: 0.7986 - val_loss: 0.4320 - val_accuracy: 0.8073\n","Epoch 57/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.4405 - accuracy: 0.8044 - val_loss: 0.4332 - val_accuracy: 0.8137\n","Epoch 58/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.4400 - accuracy: 0.8020 - val_loss: 0.4316 - val_accuracy: 0.8116\n","Epoch 59/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.4367 - accuracy: 0.8082 - val_loss: 0.4300 - val_accuracy: 0.8116\n","Epoch 60/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.4385 - accuracy: 0.8106 - val_loss: 0.4354 - val_accuracy: 0.8105\n","Epoch 61/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4341 - accuracy: 0.8077 - val_loss: 0.4313 - val_accuracy: 0.8126\n","Epoch 62/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.4347 - accuracy: 0.8031 - val_loss: 0.4292 - val_accuracy: 0.8137\n","Epoch 63/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.4359 - accuracy: 0.8039 - val_loss: 0.4279 - val_accuracy: 0.8105\n","Epoch 64/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.4283 - accuracy: 0.8074 - val_loss: 0.4315 - val_accuracy: 0.8148\n","Epoch 65/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.4250 - accuracy: 0.8077 - val_loss: 0.4264 - val_accuracy: 0.8116\n","Epoch 66/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.4252 - accuracy: 0.8157 - val_loss: 0.4237 - val_accuracy: 0.8158\n","Epoch 67/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.4273 - accuracy: 0.8066 - val_loss: 0.4230 - val_accuracy: 0.8148\n","Epoch 68/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4197 - accuracy: 0.8122 - val_loss: 0.4401 - val_accuracy: 0.8009\n","Epoch 69/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.4244 - accuracy: 0.8111 - val_loss: 0.4328 - val_accuracy: 0.8094\n","Epoch 70/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.4202 - accuracy: 0.8111 - val_loss: 0.4199 - val_accuracy: 0.8126\n","Epoch 71/100\n","30/30 [==============================] - 1s 34ms/step - loss: 0.4185 - accuracy: 0.8157 - val_loss: 0.4276 - val_accuracy: 0.8148\n","Epoch 72/100\n","30/30 [==============================] - 1s 36ms/step - loss: 0.4188 - accuracy: 0.8119 - val_loss: 0.4287 - val_accuracy: 0.8094\n","Epoch 73/100\n","30/30 [==============================] - 1s 36ms/step - loss: 0.4154 - accuracy: 0.8170 - val_loss: 0.4244 - val_accuracy: 0.8126\n","Epoch 74/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4167 - accuracy: 0.8173 - val_loss: 0.4167 - val_accuracy: 0.8148\n","Epoch 75/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4086 - accuracy: 0.8197 - val_loss: 0.4207 - val_accuracy: 0.8169\n","Epoch 76/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4109 - accuracy: 0.8170 - val_loss: 0.4210 - val_accuracy: 0.8126\n","Epoch 77/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4108 - accuracy: 0.8181 - val_loss: 0.4148 - val_accuracy: 0.8212\n","Epoch 78/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4048 - accuracy: 0.8229 - val_loss: 0.4153 - val_accuracy: 0.8233\n","Epoch 79/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4006 - accuracy: 0.8205 - val_loss: 0.4135 - val_accuracy: 0.8223\n","Epoch 80/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4019 - accuracy: 0.8235 - val_loss: 0.4145 - val_accuracy: 0.8137\n","Epoch 81/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3993 - accuracy: 0.8264 - val_loss: 0.4135 - val_accuracy: 0.8212\n","Epoch 82/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3961 - accuracy: 0.8299 - val_loss: 0.4141 - val_accuracy: 0.8180\n","Epoch 83/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3940 - accuracy: 0.8275 - val_loss: 0.4241 - val_accuracy: 0.8105\n","Epoch 84/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3929 - accuracy: 0.8320 - val_loss: 0.4154 - val_accuracy: 0.8137\n","Epoch 85/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3944 - accuracy: 0.8296 - val_loss: 0.4094 - val_accuracy: 0.8276\n","Epoch 86/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3974 - accuracy: 0.8253 - val_loss: 0.4097 - val_accuracy: 0.8191\n","Epoch 87/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3843 - accuracy: 0.8328 - val_loss: 0.4072 - val_accuracy: 0.8266\n","Epoch 88/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3869 - accuracy: 0.8353 - val_loss: 0.4108 - val_accuracy: 0.8212\n","Epoch 89/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.3875 - accuracy: 0.8299 - val_loss: 0.4228 - val_accuracy: 0.8084\n","Epoch 90/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.3794 - accuracy: 0.8355 - val_loss: 0.4072 - val_accuracy: 0.8255\n","Epoch 91/100\n","30/30 [==============================] - 1s 44ms/step - loss: 0.3747 - accuracy: 0.8379 - val_loss: 0.4316 - val_accuracy: 0.8084\n","Epoch 92/100\n","30/30 [==============================] - 1s 32ms/step - loss: 0.3894 - accuracy: 0.8283 - val_loss: 0.4578 - val_accuracy: 0.7955\n","Epoch 93/100\n","30/30 [==============================] - 1s 32ms/step - loss: 0.3800 - accuracy: 0.8398 - val_loss: 0.4013 - val_accuracy: 0.8287\n","Epoch 94/100\n","30/30 [==============================] - 1s 31ms/step - loss: 0.3734 - accuracy: 0.8406 - val_loss: 0.4042 - val_accuracy: 0.8319\n","Epoch 95/100\n","30/30 [==============================] - 1s 41ms/step - loss: 0.3725 - accuracy: 0.8417 - val_loss: 0.4053 - val_accuracy: 0.8308\n","Epoch 96/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.3732 - accuracy: 0.8422 - val_loss: 0.4166 - val_accuracy: 0.8319\n","Epoch 97/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.3729 - accuracy: 0.8377 - val_loss: 0.4023 - val_accuracy: 0.8276\n","Epoch 98/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.3682 - accuracy: 0.8441 - val_loss: 0.4008 - val_accuracy: 0.8340\n","Epoch 99/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3616 - accuracy: 0.8489 - val_loss: 0.4026 - val_accuracy: 0.8276\n","Epoch 100/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3599 - accuracy: 0.8521 - val_loss: 0.4032 - val_accuracy: 0.8276\n","{'loss': [0.6928271055221558, 0.6889367699623108, 0.6810041069984436, 0.6648910641670227, 0.6398904919624329, 0.6071672439575195, 0.5749256610870361, 0.5535914301872253, 0.5422961711883545, 0.5384219884872437, 0.5358515381813049, 0.528007984161377, 0.5237798094749451, 0.5189822912216187, 0.5167726278305054, 0.5114736557006836, 0.5087522268295288, 0.5075087547302246, 0.5047604441642761, 0.4999046325683594, 0.4967779815196991, 0.49376824498176575, 0.48960140347480774, 0.48773065209388733, 0.48141905665397644, 0.48187488317489624, 0.4800560772418976, 0.4830561876296997, 0.47914204001426697, 0.4773496687412262, 0.4771675169467926, 0.4731592833995819, 0.46977493166923523, 0.4685283899307251, 0.4655008316040039, 0.47238293290138245, 0.46705374121665955, 0.46583354473114014, 0.46671804785728455, 0.46439340710639954, 0.46213939785957336, 0.4665907919406891, 0.46246978640556335, 0.4605160653591156, 0.4604167938232422, 0.45802125334739685, 0.45444798469543457, 0.45340457558631897, 0.45484909415245056, 0.45151063799858093, 0.45043572783470154, 0.4463728666305542, 0.44510456919670105, 0.44504043459892273, 0.4479852020740509, 0.441495805978775, 0.4405117332935333, 0.43995824456214905, 0.43665921688079834, 0.4384816288948059, 0.43411585688591003, 0.43472355604171753, 0.4359097182750702, 0.42825958132743835, 0.4250316321849823, 0.4251684546470642, 0.4273209571838379, 0.41965630650520325, 0.42442843317985535, 0.4201825261116028, 0.41852182149887085, 0.41875308752059937, 0.4153969883918762, 0.4166885316371918, 0.40859419107437134, 0.41094252467155457, 0.41077670454978943, 0.4047602117061615, 0.4006441831588745, 0.4019124507904053, 0.399260014295578, 0.39612385630607605, 0.3940008282661438, 0.39293548464775085, 0.39435192942619324, 0.39737048745155334, 0.3843350410461426, 0.386948823928833, 0.3874798119068146, 0.379366010427475, 0.37473511695861816, 0.38941478729248047, 0.3800346255302429, 0.37342405319213867, 0.37249335646629333, 0.3731716573238373, 0.37285900115966797, 0.3681623935699463, 0.3615628480911255, 0.359897643327713], 'accuracy': [0.5020090937614441, 0.5526386499404907, 0.6501473188400269, 0.6919367909431458, 0.7168497443199158, 0.7176533341407776, 0.7262255549430847, 0.7302437424659729, 0.7329225540161133, 0.7342619895935059, 0.738280177116394, 0.741762638092041, 0.7441735863685608, 0.7497990727424622, 0.7500669956207275, 0.7527458071708679, 0.7586391568183899, 0.7591749429702759, 0.7618537545204163, 0.7613179683685303, 0.7688186168670654, 0.7682828903198242, 0.7739083766937256, 0.773640513420105, 0.7784623503684998, 0.7787302732467651, 0.7792659997940063, 0.7749798893928528, 0.7851594090461731, 0.7814090251922607, 0.7819448113441467, 0.7846236228942871, 0.7875702977180481, 0.7862309217453003, 0.7883739471435547, 0.7873024344444275, 0.7851594090461731, 0.7886418700218201, 0.7899812459945679, 0.7840878367424011, 0.7926600575447083, 0.7937315702438354, 0.7918564081192017, 0.7921242713928223, 0.7913206815719604, 0.7934637069702148, 0.7929279208183289, 0.7948030829429626, 0.8012322783470154, 0.7966782450675964, 0.8012322783470154, 0.7996249794960022, 0.8025716543197632, 0.7990891933441162, 0.791588544845581, 0.798553466796875, 0.804446816444397, 0.8020358681678772, 0.8081971406936646, 0.8106080889701843, 0.8076614141464233, 0.8031074404716492, 0.8039110898971558, 0.807393491268158, 0.8076614141464233, 0.8156978487968445, 0.8065899014472961, 0.8122153878211975, 0.8111438751220703, 0.8111438751220703, 0.8156978487968445, 0.8119475245475769, 0.8170372247695923, 0.8173050880432129, 0.8197160363197327, 0.8170372247695923, 0.8181087374687195, 0.822930634021759, 0.8205196857452393, 0.8234663605690002, 0.826413094997406, 0.829895555973053, 0.8274846076965332, 0.8320385813713074, 0.8296276330947876, 0.825341522693634, 0.832842230796814, 0.835253119468689, 0.829895555973053, 0.8355210423469543, 0.8379319310188293, 0.8282882571220398, 0.8398071527481079, 0.8406107425689697, 0.8416823148727417, 0.8422180414199829, 0.8376640677452087, 0.8440932035446167, 0.8489151000976562, 0.8521296381950378], 'val_loss': [0.6930256485939026, 0.6926018595695496, 0.6916009783744812, 0.6896512508392334, 0.6851819753646851, 0.6767000555992126, 0.6676877737045288, 0.653755784034729, 0.6422650218009949, 0.6314170360565186, 0.6201766729354858, 0.6063935160636902, 0.5906680226325989, 0.5771536827087402, 0.5601807236671448, 0.5475562810897827, 0.5321398377418518, 0.5162116289138794, 0.5257327556610107, 0.4917798340320587, 0.4821516275405884, 0.4753391146659851, 0.47061654925346375, 0.46466314792633057, 0.45941364765167236, 0.46598947048187256, 0.4567503035068512, 0.4529813230037689, 0.4522364139556885, 0.45334580540657043, 0.4536489248275757, 0.4491034150123596, 0.44950422644615173, 0.44736865162849426, 0.4623548686504364, 0.4520055651664734, 0.4443134665489197, 0.4446435868740082, 0.44276759028434753, 0.44271227717399597, 0.44349682331085205, 0.4449182152748108, 0.4497198462486267, 0.4403643310070038, 0.4400658905506134, 0.4392739534378052, 0.44009724259376526, 0.43971267342567444, 0.43707287311553955, 0.43669378757476807, 0.4375545084476471, 0.43812501430511475, 0.44606971740722656, 0.43705350160598755, 0.4374326467514038, 0.4320419132709503, 0.4332316219806671, 0.4315713047981262, 0.4300065338611603, 0.43536877632141113, 0.4313049018383026, 0.42921182513237, 0.42793354392051697, 0.4314599335193634, 0.42643892765045166, 0.4237443804740906, 0.42295727133750916, 0.44008076190948486, 0.43280228972435, 0.4199466407299042, 0.4276030659675598, 0.4286573827266693, 0.4244140386581421, 0.4167002737522125, 0.42069998383522034, 0.42097246646881104, 0.41483524441719055, 0.41533327102661133, 0.41351598501205444, 0.41453006863594055, 0.413474977016449, 0.4141417145729065, 0.4241238534450531, 0.41542139649391174, 0.4093610644340515, 0.40973684191703796, 0.40718376636505127, 0.410778671503067, 0.42278429865837097, 0.4071710705757141, 0.4315840005874634, 0.4578109085559845, 0.40133941173553467, 0.4041670858860016, 0.4053387939929962, 0.4166339039802551, 0.4023445248603821, 0.40082433819770813, 0.40261128544807434, 0.4032342731952667], 'val_accuracy': [0.4860813617706299, 0.5139186382293701, 0.5920770764350891, 0.5663811564445496, 0.6209850311279297, 0.7269807457923889, 0.680942177772522, 0.7494646906852722, 0.7398287057876587, 0.740899384021759, 0.7633832693099976, 0.7687366008758545, 0.7655246257781982, 0.7676659822463989, 0.7676659822463989, 0.7773019075393677, 0.778372585773468, 0.7762312889099121, 0.7740899324417114, 0.7912205457687378, 0.7912205457687378, 0.7933619022369385, 0.794432520866394, 0.7890792489051819, 0.7955031991004944, 0.799785852432251, 0.7922912240028381, 0.7965738773345947, 0.794432520866394, 0.8019272089004517, 0.794432520866394, 0.8051391839981079, 0.7965738773345947, 0.802997887134552, 0.7901498675346375, 0.8094218373298645, 0.8019272089004517, 0.8008565306663513, 0.7987151741981506, 0.8019272089004517, 0.802997887134552, 0.799785852432251, 0.7987151741981506, 0.8051391839981079, 0.8019272089004517, 0.8094218373298645, 0.8072805404663086, 0.8083511590957642, 0.8083511590957642, 0.8094218373298645, 0.8040685057640076, 0.8083511590957642, 0.799785852432251, 0.8115631937980652, 0.8104925155639648, 0.8072805404663086, 0.8137044906616211, 0.8115631937980652, 0.8115631937980652, 0.8104925155639648, 0.8126338124275208, 0.8137044906616211, 0.8104925155639648, 0.8147751688957214, 0.8115631937980652, 0.8158458471298218, 0.8147751688957214, 0.8008565306663513, 0.8094218373298645, 0.8126338124275208, 0.8147751688957214, 0.8094218373298645, 0.8126338124275208, 0.8147751688957214, 0.8169164657592773, 0.8126338124275208, 0.8211991190910339, 0.8233404755592346, 0.8222697973251343, 0.8137044906616211, 0.8211991190910339, 0.8179871439933777, 0.8104925155639648, 0.8137044906616211, 0.8276231288909912, 0.819057822227478, 0.8265524506568909, 0.8211991190910339, 0.8083511590957642, 0.8254817724227905, 0.8083511590957642, 0.7955031991004944, 0.8286938071250916, 0.8319057822227478, 0.8308351039886475, 0.8319057822227478, 0.8276231288909912, 0.8340471386909485, 0.8276231288909912, 0.8276231288909912]}\n","37/37 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 9s 53ms/step - loss: 0.6930 - accuracy: 0.5050 - val_loss: 0.6931 - val_accuracy: 0.6895\n","Epoch 2/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.6901 - accuracy: 0.6086 - val_loss: 0.6927 - val_accuracy: 0.6713\n","Epoch 3/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.6837 - accuracy: 0.6418 - val_loss: 0.6918 - val_accuracy: 0.5428\n","Epoch 4/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.6705 - accuracy: 0.6818 - val_loss: 0.6898 - val_accuracy: 0.5996\n","Epoch 5/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.6454 - accuracy: 0.7115 - val_loss: 0.6852 - val_accuracy: 0.6210\n","Epoch 6/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.6109 - accuracy: 0.7284 - val_loss: 0.6774 - val_accuracy: 0.7013\n","Epoch 7/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.5805 - accuracy: 0.7214 - val_loss: 0.6678 - val_accuracy: 0.7109\n","Epoch 8/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.5581 - accuracy: 0.7305 - val_loss: 0.6555 - val_accuracy: 0.7259\n","Epoch 9/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.5484 - accuracy: 0.7265 - val_loss: 0.6444 - val_accuracy: 0.7291\n","Epoch 10/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.5391 - accuracy: 0.7359 - val_loss: 0.6347 - val_accuracy: 0.7420\n","Epoch 11/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.5369 - accuracy: 0.7340 - val_loss: 0.6227 - val_accuracy: 0.7420\n","Epoch 12/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.5319 - accuracy: 0.7383 - val_loss: 0.6107 - val_accuracy: 0.7463\n","Epoch 13/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.5271 - accuracy: 0.7463 - val_loss: 0.5969 - val_accuracy: 0.7484\n","Epoch 14/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.5288 - accuracy: 0.7477 - val_loss: 0.5870 - val_accuracy: 0.7452\n","Epoch 15/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.5189 - accuracy: 0.7471 - val_loss: 0.5734 - val_accuracy: 0.7473\n","Epoch 16/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.5128 - accuracy: 0.7586 - val_loss: 0.5709 - val_accuracy: 0.7463\n","Epoch 17/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.5135 - accuracy: 0.7565 - val_loss: 0.5499 - val_accuracy: 0.7420\n","Epoch 18/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.5069 - accuracy: 0.7635 - val_loss: 0.5378 - val_accuracy: 0.7484\n","Epoch 19/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.5025 - accuracy: 0.7664 - val_loss: 0.5310 - val_accuracy: 0.7527\n","Epoch 20/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.5015 - accuracy: 0.7702 - val_loss: 0.5189 - val_accuracy: 0.7591\n","Epoch 21/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4972 - accuracy: 0.7712 - val_loss: 0.5159 - val_accuracy: 0.7559\n","Epoch 22/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4983 - accuracy: 0.7669 - val_loss: 0.5009 - val_accuracy: 0.7548\n","Epoch 23/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4903 - accuracy: 0.7763 - val_loss: 0.5071 - val_accuracy: 0.7570\n","Epoch 24/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4909 - accuracy: 0.7750 - val_loss: 0.5133 - val_accuracy: 0.7602\n","Epoch 25/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4895 - accuracy: 0.7798 - val_loss: 0.4986 - val_accuracy: 0.7655\n","Epoch 26/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4881 - accuracy: 0.7715 - val_loss: 0.4958 - val_accuracy: 0.7645\n","Epoch 27/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4842 - accuracy: 0.7801 - val_loss: 0.4913 - val_accuracy: 0.7762\n","Epoch 28/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4861 - accuracy: 0.7755 - val_loss: 0.4886 - val_accuracy: 0.7655\n","Epoch 29/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4847 - accuracy: 0.7782 - val_loss: 0.4873 - val_accuracy: 0.7687\n","Epoch 30/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4832 - accuracy: 0.7803 - val_loss: 0.4869 - val_accuracy: 0.7677\n","Epoch 31/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4808 - accuracy: 0.7822 - val_loss: 0.4938 - val_accuracy: 0.7719\n","Epoch 32/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4817 - accuracy: 0.7795 - val_loss: 0.4872 - val_accuracy: 0.7730\n","Epoch 33/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4798 - accuracy: 0.7798 - val_loss: 0.4846 - val_accuracy: 0.7752\n","Epoch 34/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4728 - accuracy: 0.7873 - val_loss: 0.4851 - val_accuracy: 0.7752\n","Epoch 35/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4762 - accuracy: 0.7849 - val_loss: 0.4924 - val_accuracy: 0.7762\n","Epoch 36/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4741 - accuracy: 0.7841 - val_loss: 0.4834 - val_accuracy: 0.7741\n","Epoch 37/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4728 - accuracy: 0.7873 - val_loss: 0.4829 - val_accuracy: 0.7752\n","Epoch 38/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4723 - accuracy: 0.7878 - val_loss: 0.4902 - val_accuracy: 0.7762\n","Epoch 39/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4737 - accuracy: 0.7841 - val_loss: 0.4841 - val_accuracy: 0.7784\n","Epoch 40/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4733 - accuracy: 0.7884 - val_loss: 0.4811 - val_accuracy: 0.7741\n","Epoch 41/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4654 - accuracy: 0.7916 - val_loss: 0.4808 - val_accuracy: 0.7794\n","Epoch 42/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4699 - accuracy: 0.7889 - val_loss: 0.4805 - val_accuracy: 0.7794\n","Epoch 43/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4666 - accuracy: 0.7919 - val_loss: 0.4852 - val_accuracy: 0.7762\n","Epoch 44/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.4704 - accuracy: 0.7886 - val_loss: 0.4794 - val_accuracy: 0.7752\n","Epoch 45/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4651 - accuracy: 0.7905 - val_loss: 0.4821 - val_accuracy: 0.7837\n","Epoch 46/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4629 - accuracy: 0.7969 - val_loss: 0.4796 - val_accuracy: 0.7827\n","Epoch 47/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4674 - accuracy: 0.7900 - val_loss: 0.4808 - val_accuracy: 0.7827\n","Epoch 48/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4626 - accuracy: 0.7961 - val_loss: 0.4771 - val_accuracy: 0.7784\n","Epoch 49/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4623 - accuracy: 0.7916 - val_loss: 0.4766 - val_accuracy: 0.7880\n","Epoch 50/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4641 - accuracy: 0.7937 - val_loss: 0.4776 - val_accuracy: 0.7762\n","Epoch 51/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4611 - accuracy: 0.7932 - val_loss: 0.4811 - val_accuracy: 0.7773\n","Epoch 52/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4611 - accuracy: 0.7943 - val_loss: 0.4759 - val_accuracy: 0.7773\n","Epoch 53/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4577 - accuracy: 0.7948 - val_loss: 0.4761 - val_accuracy: 0.7848\n","Epoch 54/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4525 - accuracy: 0.7972 - val_loss: 0.4712 - val_accuracy: 0.7805\n","Epoch 55/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.4560 - accuracy: 0.7991 - val_loss: 0.4728 - val_accuracy: 0.7901\n","Epoch 56/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4562 - accuracy: 0.7953 - val_loss: 0.4728 - val_accuracy: 0.7912\n","Epoch 57/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4544 - accuracy: 0.7945 - val_loss: 0.4680 - val_accuracy: 0.7934\n","Epoch 58/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4509 - accuracy: 0.8026 - val_loss: 0.4700 - val_accuracy: 0.7934\n","Epoch 59/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4475 - accuracy: 0.8012 - val_loss: 0.4657 - val_accuracy: 0.7944\n","Epoch 60/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.4488 - accuracy: 0.8028 - val_loss: 0.4652 - val_accuracy: 0.7901\n","Epoch 61/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4458 - accuracy: 0.8036 - val_loss: 0.4721 - val_accuracy: 0.7848\n","Epoch 62/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4459 - accuracy: 0.8031 - val_loss: 0.4739 - val_accuracy: 0.7827\n","Epoch 63/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4442 - accuracy: 0.8028 - val_loss: 0.4633 - val_accuracy: 0.7976\n","Epoch 64/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.4426 - accuracy: 0.8007 - val_loss: 0.4632 - val_accuracy: 0.7966\n","Epoch 65/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4401 - accuracy: 0.8058 - val_loss: 0.4631 - val_accuracy: 0.7955\n","Epoch 66/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4435 - accuracy: 0.8020 - val_loss: 0.4617 - val_accuracy: 0.8030\n","Epoch 67/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.4383 - accuracy: 0.8077 - val_loss: 0.4675 - val_accuracy: 0.7891\n","Epoch 68/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4365 - accuracy: 0.8063 - val_loss: 0.4591 - val_accuracy: 0.8062\n","Epoch 69/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4339 - accuracy: 0.8069 - val_loss: 0.4644 - val_accuracy: 0.7976\n","Epoch 70/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4299 - accuracy: 0.8119 - val_loss: 0.4595 - val_accuracy: 0.8062\n","Epoch 71/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4322 - accuracy: 0.8074 - val_loss: 0.4588 - val_accuracy: 0.7923\n","Epoch 72/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4325 - accuracy: 0.8069 - val_loss: 0.4632 - val_accuracy: 0.7998\n","Epoch 73/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4243 - accuracy: 0.8109 - val_loss: 0.4571 - val_accuracy: 0.7912\n","Epoch 74/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4223 - accuracy: 0.8130 - val_loss: 0.4574 - val_accuracy: 0.8019\n","Epoch 75/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4227 - accuracy: 0.8144 - val_loss: 0.4583 - val_accuracy: 0.8041\n","Epoch 76/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4165 - accuracy: 0.8173 - val_loss: 0.4571 - val_accuracy: 0.7912\n","Epoch 77/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4147 - accuracy: 0.8162 - val_loss: 0.4552 - val_accuracy: 0.8041\n","Epoch 78/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4169 - accuracy: 0.8133 - val_loss: 0.4536 - val_accuracy: 0.8062\n","Epoch 79/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4081 - accuracy: 0.8205 - val_loss: 0.4531 - val_accuracy: 0.8051\n","Epoch 80/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4135 - accuracy: 0.8205 - val_loss: 0.4506 - val_accuracy: 0.8062\n","Epoch 81/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4071 - accuracy: 0.8224 - val_loss: 0.4575 - val_accuracy: 0.7923\n","Epoch 82/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4033 - accuracy: 0.8208 - val_loss: 0.4683 - val_accuracy: 0.7901\n","Epoch 83/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4139 - accuracy: 0.8109 - val_loss: 0.4849 - val_accuracy: 0.7784\n","Epoch 84/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4087 - accuracy: 0.8186 - val_loss: 0.4572 - val_accuracy: 0.7934\n","Epoch 85/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4008 - accuracy: 0.8253 - val_loss: 0.4533 - val_accuracy: 0.7998\n","Epoch 86/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3974 - accuracy: 0.8259 - val_loss: 0.4507 - val_accuracy: 0.8009\n","Epoch 87/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3975 - accuracy: 0.8205 - val_loss: 0.4642 - val_accuracy: 0.7901\n","Epoch 88/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3976 - accuracy: 0.8288 - val_loss: 0.4443 - val_accuracy: 0.8073\n","Epoch 89/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3897 - accuracy: 0.8377 - val_loss: 0.4454 - val_accuracy: 0.8073\n","Epoch 90/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3859 - accuracy: 0.8318 - val_loss: 0.4466 - val_accuracy: 0.8116\n","Epoch 91/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3835 - accuracy: 0.8310 - val_loss: 0.4529 - val_accuracy: 0.8030\n","Epoch 92/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3803 - accuracy: 0.8353 - val_loss: 0.4480 - val_accuracy: 0.8051\n","Epoch 93/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3813 - accuracy: 0.8342 - val_loss: 0.4464 - val_accuracy: 0.8062\n","Epoch 94/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3779 - accuracy: 0.8358 - val_loss: 0.4442 - val_accuracy: 0.8137\n","Epoch 95/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3779 - accuracy: 0.8377 - val_loss: 0.4438 - val_accuracy: 0.8105\n","Epoch 96/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3781 - accuracy: 0.8355 - val_loss: 0.4489 - val_accuracy: 0.8051\n","Epoch 97/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3726 - accuracy: 0.8393 - val_loss: 0.4460 - val_accuracy: 0.8073\n","Epoch 98/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3720 - accuracy: 0.8401 - val_loss: 0.4575 - val_accuracy: 0.8041\n","Epoch 99/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3741 - accuracy: 0.8403 - val_loss: 0.4394 - val_accuracy: 0.8169\n","Epoch 100/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3709 - accuracy: 0.8422 - val_loss: 0.4404 - val_accuracy: 0.8158\n","{'loss': [0.6930481195449829, 0.6900927424430847, 0.6837303042411804, 0.6705176830291748, 0.6454123854637146, 0.6109458208084106, 0.5804518461227417, 0.55808424949646, 0.5483847260475159, 0.5391172170639038, 0.5369381308555603, 0.5318651795387268, 0.527105450630188, 0.5287812948226929, 0.5189163684844971, 0.512775182723999, 0.5135291814804077, 0.5068754553794861, 0.5025379061698914, 0.5014765858650208, 0.49720561504364014, 0.49833381175994873, 0.49028268456459045, 0.4909464120864868, 0.48954862356185913, 0.48808690905570984, 0.4842081069946289, 0.48606792092323303, 0.4847370982170105, 0.4832444489002228, 0.4808069169521332, 0.4816669225692749, 0.4798409044742584, 0.47277772426605225, 0.47622641921043396, 0.47405698895454407, 0.47281646728515625, 0.47230541706085205, 0.47366178035736084, 0.4733388125896454, 0.46537667512893677, 0.46989327669143677, 0.4666396379470825, 0.4704122543334961, 0.4650647044181824, 0.4628785252571106, 0.4673941433429718, 0.4625530242919922, 0.4623117446899414, 0.464099645614624, 0.4611136019229889, 0.4610948860645294, 0.4576896131038666, 0.4524829685688019, 0.4559640884399414, 0.4562136232852936, 0.4544219970703125, 0.4508548080921173, 0.4474669396877289, 0.4488091766834259, 0.4457683563232422, 0.44590601325035095, 0.4442327916622162, 0.44258353114128113, 0.44014325737953186, 0.4434540569782257, 0.43827709555625916, 0.43648311495780945, 0.4338946044445038, 0.42989927530288696, 0.4321635067462921, 0.432522714138031, 0.42431318759918213, 0.4222779870033264, 0.4226788282394409, 0.4164799451828003, 0.41469985246658325, 0.4169445037841797, 0.40813741087913513, 0.4135086238384247, 0.4070977568626404, 0.40325719118118286, 0.41394248604774475, 0.40871021151542664, 0.4007686972618103, 0.397434800863266, 0.39754554629325867, 0.3976312279701233, 0.3896978199481964, 0.3859483599662781, 0.38348904252052307, 0.38034895062446594, 0.3812880516052246, 0.37792497873306274, 0.37785768508911133, 0.3780865967273712, 0.3726253807544708, 0.3719797432422638, 0.3740762770175934, 0.3709343671798706], 'accuracy': [0.5049558281898499, 0.6086257696151733, 0.6418430209159851, 0.6817572712898254, 0.711492121219635, 0.7283685803413391, 0.7214037179946899, 0.7305116653442383, 0.7264934182167053, 0.735869288444519, 0.7339941263198853, 0.738280177116394, 0.7463166117668152, 0.7476560473442078, 0.7471202611923218, 0.7586391568183899, 0.7564961314201355, 0.7634609937667847, 0.7664077281951904, 0.770158052444458, 0.7712295651435852, 0.7669434547424316, 0.7763193249702454, 0.7749798893928528, 0.7798017859458923, 0.7714974284172058, 0.7800696492195129, 0.7755156755447388, 0.7781944870948792, 0.7803375124931335, 0.7822126746177673, 0.779533863067627, 0.7798017859458923, 0.7873024344444275, 0.7848914861679077, 0.7840878367424011, 0.7873024344444275, 0.7878382205963135, 0.7840878367424011, 0.7883739471435547, 0.791588544845581, 0.7889097332954407, 0.7918564081192017, 0.7886418700218201, 0.7905170321464539, 0.7969461679458618, 0.7899812459945679, 0.7961425185203552, 0.791588544845581, 0.7937315702438354, 0.7931958436965942, 0.7942673563957214, 0.7948030829429626, 0.7972140312194824, 0.7990891933441162, 0.7953388690948486, 0.794535219669342, 0.8025716543197632, 0.8012322783470154, 0.8028395175933838, 0.8036431670188904, 0.8031074404716492, 0.8028395175933838, 0.8006964921951294, 0.8057862520217896, 0.8020358681678772, 0.8076614141464233, 0.8063219785690308, 0.8068577647209167, 0.8119475245475769, 0.807393491268158, 0.8068577647209167, 0.8108759522438049, 0.8130190372467041, 0.8143584132194519, 0.8173050880432129, 0.8162335753440857, 0.8132869005203247, 0.8205196857452393, 0.8205196857452393, 0.822394847869873, 0.8207875490188599, 0.8108759522438049, 0.8186445236206055, 0.825341522693634, 0.82587730884552, 0.8205196857452393, 0.828823983669281, 0.8376640677452087, 0.8317707180976868, 0.8309670686721802, 0.835253119468689, 0.8341816067695618, 0.835788905620575, 0.8376640677452087, 0.8355210423469543, 0.8392713665962219, 0.8400750160217285, 0.8403428792953491, 0.8422180414199829], 'val_loss': [0.6930540800094604, 0.6926590204238892, 0.6918212175369263, 0.6897876262664795, 0.6852267980575562, 0.6774085760116577, 0.6678296327590942, 0.6555380821228027, 0.6444423198699951, 0.6346888542175293, 0.6226643919944763, 0.6107019782066345, 0.596863329410553, 0.586979329586029, 0.5733900666236877, 0.5708909630775452, 0.5498631596565247, 0.537830114364624, 0.5309711694717407, 0.518944263458252, 0.5158842206001282, 0.5009414553642273, 0.5070982575416565, 0.5133102536201477, 0.49861201643943787, 0.4958290457725525, 0.4912686347961426, 0.48861971497535706, 0.4872983396053314, 0.48691704869270325, 0.4938187599182129, 0.48716917634010315, 0.4846438765525818, 0.48514872789382935, 0.492420494556427, 0.4834328293800354, 0.48286741971969604, 0.4901827871799469, 0.48408693075180054, 0.4811146557331085, 0.4808414876461029, 0.48045676946640015, 0.48519259691238403, 0.47943738102912903, 0.4820890426635742, 0.4796167314052582, 0.48084232211112976, 0.47709327936172485, 0.4765687882900238, 0.4776310622692108, 0.48112595081329346, 0.47591632604599, 0.476062536239624, 0.47116076946258545, 0.47282564640045166, 0.4728439152240753, 0.4680376946926117, 0.47003278136253357, 0.46572673320770264, 0.46517834067344666, 0.4721188545227051, 0.473876953125, 0.46328386664390564, 0.46316155791282654, 0.46306896209716797, 0.4616559147834778, 0.46745073795318604, 0.4590959846973419, 0.4643896222114563, 0.4595367908477783, 0.4588117301464081, 0.4631761610507965, 0.4571492373943329, 0.45743632316589355, 0.45829275250434875, 0.45712971687316895, 0.4552142024040222, 0.4535512626171112, 0.4531278610229492, 0.4506245255470276, 0.45748215913772583, 0.4683030843734741, 0.48489272594451904, 0.457180917263031, 0.45325663685798645, 0.45068639516830444, 0.46421101689338684, 0.44432759284973145, 0.44540420174598694, 0.4466146230697632, 0.4528951644897461, 0.4479838013648987, 0.44644132256507874, 0.44421225786209106, 0.44377315044403076, 0.44889387488365173, 0.4459967017173767, 0.45751476287841797, 0.4393545389175415, 0.4403627812862396], 'val_accuracy': [0.6895074844360352, 0.6713061928749084, 0.5428265333175659, 0.599571704864502, 0.6209850311279297, 0.7012848258018494, 0.7109207510948181, 0.7259100675582886, 0.7291220426559448, 0.7419700026512146, 0.7419700026512146, 0.7462526559829712, 0.7483940124511719, 0.7451820373535156, 0.7473233342170715, 0.7462526559829712, 0.7419700026512146, 0.7483940124511719, 0.7526766657829285, 0.759100615978241, 0.7558886408805847, 0.7548179626464844, 0.7569593191146851, 0.7601712942123413, 0.7655246257781982, 0.7644539475440979, 0.7762312889099121, 0.7655246257781982, 0.7687366008758545, 0.7676659822463989, 0.7719486355781555, 0.7730192542076111, 0.7751606106758118, 0.7751606106758118, 0.7762312889099121, 0.7740899324417114, 0.7751606106758118, 0.7762312889099121, 0.778372585773468, 0.7740899324417114, 0.7794432640075684, 0.7794432640075684, 0.7762312889099121, 0.7751606106758118, 0.783725917339325, 0.7826552391052246, 0.7826552391052246, 0.778372585773468, 0.7880085706710815, 0.7762312889099121, 0.7773019075393677, 0.7773019075393677, 0.7847965955734253, 0.7805139422416687, 0.7901498675346375, 0.7912205457687378, 0.7933619022369385, 0.7933619022369385, 0.794432520866394, 0.7901498675346375, 0.7847965955734253, 0.7826552391052246, 0.7976445555686951, 0.7965738773345947, 0.7955031991004944, 0.802997887134552, 0.7890792489051819, 0.8062098622322083, 0.7976445555686951, 0.8062098622322083, 0.7922912240028381, 0.799785852432251, 0.7912205457687378, 0.8019272089004517, 0.8040685057640076, 0.7912205457687378, 0.8040685057640076, 0.8062098622322083, 0.8051391839981079, 0.8062098622322083, 0.7922912240028381, 0.7901498675346375, 0.778372585773468, 0.7933619022369385, 0.799785852432251, 0.8008565306663513, 0.7901498675346375, 0.8072805404663086, 0.8072805404663086, 0.8115631937980652, 0.802997887134552, 0.8051391839981079, 0.8062098622322083, 0.8137044906616211, 0.8104925155639648, 0.8051391839981079, 0.8072805404663086, 0.8040685057640076, 0.8169164657592773, 0.8158458471298218]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 54ms/step - loss: 0.4066 - accuracy: 0.8184 - val_loss: 0.6769 - val_accuracy: 0.7173\n","Epoch 2/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4038 - accuracy: 0.8227 - val_loss: 0.6735 - val_accuracy: 0.7291\n","Epoch 3/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4000 - accuracy: 0.8294 - val_loss: 0.6704 - val_accuracy: 0.6756\n","Epoch 4/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4055 - accuracy: 0.8221 - val_loss: 0.6646 - val_accuracy: 0.7516\n","Epoch 5/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3881 - accuracy: 0.8403 - val_loss: 0.6600 - val_accuracy: 0.7612\n","Epoch 6/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3901 - accuracy: 0.8318 - val_loss: 0.6531 - val_accuracy: 0.7570\n","Epoch 7/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3851 - accuracy: 0.8344 - val_loss: 0.6456 - val_accuracy: 0.7591\n","Epoch 8/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3824 - accuracy: 0.8326 - val_loss: 0.6383 - val_accuracy: 0.7548\n","Epoch 9/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3804 - accuracy: 0.8387 - val_loss: 0.6292 - val_accuracy: 0.7505\n","Epoch 10/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3794 - accuracy: 0.8387 - val_loss: 0.6143 - val_accuracy: 0.7677\n","Epoch 11/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3722 - accuracy: 0.8428 - val_loss: 0.5996 - val_accuracy: 0.7719\n","Epoch 12/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3727 - accuracy: 0.8406 - val_loss: 0.5853 - val_accuracy: 0.7741\n","Epoch 13/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3710 - accuracy: 0.8428 - val_loss: 0.5675 - val_accuracy: 0.7794\n","Epoch 14/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.3670 - accuracy: 0.8462 - val_loss: 0.5471 - val_accuracy: 0.7816\n","Epoch 15/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3692 - accuracy: 0.8428 - val_loss: 0.5311 - val_accuracy: 0.7816\n","Epoch 16/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3581 - accuracy: 0.8508 - val_loss: 0.5067 - val_accuracy: 0.7880\n","Epoch 17/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3617 - accuracy: 0.8500 - val_loss: 0.4934 - val_accuracy: 0.7816\n","Epoch 18/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3577 - accuracy: 0.8484 - val_loss: 0.4685 - val_accuracy: 0.7859\n","Epoch 19/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3616 - accuracy: 0.8486 - val_loss: 0.4604 - val_accuracy: 0.7869\n","Epoch 20/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3536 - accuracy: 0.8556 - val_loss: 0.4656 - val_accuracy: 0.7912\n","Epoch 21/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3500 - accuracy: 0.8545 - val_loss: 0.4386 - val_accuracy: 0.7966\n","Epoch 22/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3439 - accuracy: 0.8607 - val_loss: 0.4913 - val_accuracy: 0.7805\n","Epoch 23/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3533 - accuracy: 0.8521 - val_loss: 0.4416 - val_accuracy: 0.7901\n","Epoch 24/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3482 - accuracy: 0.8594 - val_loss: 0.4308 - val_accuracy: 0.7987\n","Epoch 25/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3482 - accuracy: 0.8556 - val_loss: 0.4532 - val_accuracy: 0.7891\n","Epoch 26/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3576 - accuracy: 0.8508 - val_loss: 0.4443 - val_accuracy: 0.7934\n","Epoch 27/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3355 - accuracy: 0.8610 - val_loss: 0.4377 - val_accuracy: 0.8019\n","Epoch 28/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3333 - accuracy: 0.8647 - val_loss: 0.4444 - val_accuracy: 0.7998\n","Epoch 29/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3308 - accuracy: 0.8674 - val_loss: 0.4506 - val_accuracy: 0.7944\n","Epoch 30/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3327 - accuracy: 0.8669 - val_loss: 0.4422 - val_accuracy: 0.8094\n","Epoch 31/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3267 - accuracy: 0.8706 - val_loss: 0.4435 - val_accuracy: 0.8105\n","Epoch 32/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3278 - accuracy: 0.8701 - val_loss: 0.4462 - val_accuracy: 0.8051\n","Epoch 33/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3367 - accuracy: 0.8615 - val_loss: 0.4694 - val_accuracy: 0.7944\n","Epoch 34/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3342 - accuracy: 0.8588 - val_loss: 0.4462 - val_accuracy: 0.8073\n","Epoch 35/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3315 - accuracy: 0.8647 - val_loss: 0.4462 - val_accuracy: 0.7998\n","Epoch 36/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3224 - accuracy: 0.8706 - val_loss: 0.4516 - val_accuracy: 0.8009\n","Epoch 37/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3219 - accuracy: 0.8687 - val_loss: 0.4458 - val_accuracy: 0.8084\n","Epoch 38/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3170 - accuracy: 0.8733 - val_loss: 0.4486 - val_accuracy: 0.8105\n","Epoch 39/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3169 - accuracy: 0.8722 - val_loss: 0.4646 - val_accuracy: 0.7966\n","Epoch 40/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3191 - accuracy: 0.8711 - val_loss: 0.4515 - val_accuracy: 0.8105\n","Epoch 41/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3149 - accuracy: 0.8728 - val_loss: 0.4478 - val_accuracy: 0.8084\n","Epoch 42/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3048 - accuracy: 0.8829 - val_loss: 0.4491 - val_accuracy: 0.8084\n","Epoch 43/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3055 - accuracy: 0.8762 - val_loss: 0.4602 - val_accuracy: 0.8030\n","Epoch 44/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3059 - accuracy: 0.8837 - val_loss: 0.4556 - val_accuracy: 0.8073\n","Epoch 45/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3046 - accuracy: 0.8768 - val_loss: 0.4485 - val_accuracy: 0.8094\n","Epoch 46/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3019 - accuracy: 0.8797 - val_loss: 0.4534 - val_accuracy: 0.8105\n","Epoch 47/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2951 - accuracy: 0.8845 - val_loss: 0.4540 - val_accuracy: 0.8084\n","Epoch 48/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3002 - accuracy: 0.8800 - val_loss: 0.4584 - val_accuracy: 0.8116\n","Epoch 49/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3054 - accuracy: 0.8848 - val_loss: 0.4507 - val_accuracy: 0.8137\n","Epoch 50/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2976 - accuracy: 0.8862 - val_loss: 0.4651 - val_accuracy: 0.7998\n","Epoch 51/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2934 - accuracy: 0.8878 - val_loss: 0.4530 - val_accuracy: 0.8137\n","Epoch 52/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2834 - accuracy: 0.8904 - val_loss: 0.4594 - val_accuracy: 0.8094\n","Epoch 53/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2819 - accuracy: 0.8894 - val_loss: 0.4636 - val_accuracy: 0.8073\n","Epoch 54/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2829 - accuracy: 0.8931 - val_loss: 0.4560 - val_accuracy: 0.8148\n","Epoch 55/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2808 - accuracy: 0.8896 - val_loss: 0.4670 - val_accuracy: 0.8051\n","Epoch 56/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2833 - accuracy: 0.8891 - val_loss: 0.4904 - val_accuracy: 0.7998\n","Epoch 57/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2851 - accuracy: 0.8888 - val_loss: 0.4674 - val_accuracy: 0.8062\n","Epoch 58/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2811 - accuracy: 0.8910 - val_loss: 0.4566 - val_accuracy: 0.8158\n","Epoch 59/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2830 - accuracy: 0.8939 - val_loss: 0.4749 - val_accuracy: 0.8084\n","Epoch 60/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2764 - accuracy: 0.8937 - val_loss: 0.4572 - val_accuracy: 0.8137\n","Epoch 61/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2681 - accuracy: 0.8987 - val_loss: 0.4615 - val_accuracy: 0.8126\n","Epoch 62/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2686 - accuracy: 0.8990 - val_loss: 0.4624 - val_accuracy: 0.8126\n","Epoch 63/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2669 - accuracy: 0.9001 - val_loss: 0.4627 - val_accuracy: 0.8126\n","Epoch 64/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2743 - accuracy: 0.8947 - val_loss: 0.4697 - val_accuracy: 0.8073\n","Epoch 65/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.2699 - accuracy: 0.8969 - val_loss: 0.4621 - val_accuracy: 0.8169\n","Epoch 66/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2577 - accuracy: 0.9054 - val_loss: 0.4635 - val_accuracy: 0.8148\n","Epoch 67/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2756 - accuracy: 0.8915 - val_loss: 0.4727 - val_accuracy: 0.8105\n","Epoch 68/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2583 - accuracy: 0.9028 - val_loss: 0.4639 - val_accuracy: 0.8148\n","Epoch 69/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2661 - accuracy: 0.9017 - val_loss: 0.4868 - val_accuracy: 0.7966\n","Epoch 70/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2628 - accuracy: 0.8974 - val_loss: 0.4671 - val_accuracy: 0.8073\n","Epoch 71/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2518 - accuracy: 0.9076 - val_loss: 0.4806 - val_accuracy: 0.8030\n","Epoch 72/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2536 - accuracy: 0.9062 - val_loss: 0.4789 - val_accuracy: 0.8094\n","Epoch 73/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2471 - accuracy: 0.9078 - val_loss: 0.4801 - val_accuracy: 0.8073\n","Epoch 74/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2466 - accuracy: 0.9095 - val_loss: 0.4721 - val_accuracy: 0.8191\n","Epoch 75/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2416 - accuracy: 0.9100 - val_loss: 0.4825 - val_accuracy: 0.8158\n","Epoch 76/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2442 - accuracy: 0.9076 - val_loss: 0.4864 - val_accuracy: 0.8051\n","Epoch 77/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2519 - accuracy: 0.9033 - val_loss: 0.4748 - val_accuracy: 0.8201\n","Epoch 78/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2380 - accuracy: 0.9121 - val_loss: 0.4911 - val_accuracy: 0.8084\n","Epoch 79/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2414 - accuracy: 0.9137 - val_loss: 0.4868 - val_accuracy: 0.8137\n","Epoch 80/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2415 - accuracy: 0.9100 - val_loss: 0.4896 - val_accuracy: 0.8137\n","Epoch 81/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2443 - accuracy: 0.9041 - val_loss: 0.4808 - val_accuracy: 0.8137\n","Epoch 82/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2398 - accuracy: 0.9121 - val_loss: 0.4862 - val_accuracy: 0.8073\n","Epoch 83/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2459 - accuracy: 0.9057 - val_loss: 0.4871 - val_accuracy: 0.8105\n","Epoch 84/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2307 - accuracy: 0.9167 - val_loss: 0.4815 - val_accuracy: 0.8180\n","Epoch 85/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2215 - accuracy: 0.9202 - val_loss: 0.4841 - val_accuracy: 0.8201\n","Epoch 86/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2216 - accuracy: 0.9223 - val_loss: 0.4893 - val_accuracy: 0.8201\n","Epoch 87/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2216 - accuracy: 0.9207 - val_loss: 0.4930 - val_accuracy: 0.8169\n","Epoch 88/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2220 - accuracy: 0.9191 - val_loss: 0.4920 - val_accuracy: 0.8169\n","Epoch 89/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2254 - accuracy: 0.9121 - val_loss: 0.5064 - val_accuracy: 0.8084\n","Epoch 90/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2178 - accuracy: 0.9210 - val_loss: 0.4931 - val_accuracy: 0.8137\n","Epoch 91/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2158 - accuracy: 0.9210 - val_loss: 0.5144 - val_accuracy: 0.8137\n","Epoch 92/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2166 - accuracy: 0.9234 - val_loss: 0.5109 - val_accuracy: 0.8126\n","Epoch 93/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2164 - accuracy: 0.9239 - val_loss: 0.5111 - val_accuracy: 0.8105\n","Epoch 94/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2129 - accuracy: 0.9245 - val_loss: 0.4976 - val_accuracy: 0.8148\n","Epoch 95/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2041 - accuracy: 0.9255 - val_loss: 0.5044 - val_accuracy: 0.8180\n","Epoch 96/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2059 - accuracy: 0.9271 - val_loss: 0.5083 - val_accuracy: 0.8169\n","Epoch 97/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2051 - accuracy: 0.9271 - val_loss: 0.5043 - val_accuracy: 0.8158\n","Epoch 98/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2001 - accuracy: 0.9269 - val_loss: 0.5100 - val_accuracy: 0.8158\n","Epoch 99/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2031 - accuracy: 0.9287 - val_loss: 0.5104 - val_accuracy: 0.8169\n","Epoch 100/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2078 - accuracy: 0.9207 - val_loss: 0.5179 - val_accuracy: 0.8191\n","{'loss': [0.4066285490989685, 0.4038103520870209, 0.399959534406662, 0.40546107292175293, 0.38810795545578003, 0.390089750289917, 0.38508203625679016, 0.3823767304420471, 0.38042929768562317, 0.37938350439071655, 0.37223488092422485, 0.3727371096611023, 0.3710464537143707, 0.3670045733451843, 0.36915746331214905, 0.3580586016178131, 0.36168771982192993, 0.3577234447002411, 0.3615812063217163, 0.3535747230052948, 0.3499833941459656, 0.34385019540786743, 0.3532547950744629, 0.3482336401939392, 0.3481542766094208, 0.35764676332473755, 0.33546698093414307, 0.3333263397216797, 0.33081063628196716, 0.3327109217643738, 0.326698899269104, 0.3277739882469177, 0.33672675490379333, 0.3341562747955322, 0.33149459958076477, 0.3224460780620575, 0.32192423939704895, 0.31703197956085205, 0.31691378355026245, 0.3191365897655487, 0.31486260890960693, 0.30477526783943176, 0.3055483400821686, 0.3059369921684265, 0.3045991361141205, 0.3019498586654663, 0.29506757855415344, 0.300222247838974, 0.30535832047462463, 0.2976211905479431, 0.29336386919021606, 0.28337937593460083, 0.28193676471710205, 0.28294214606285095, 0.2807520627975464, 0.2833154499530792, 0.28514084219932556, 0.28108081221580505, 0.2830273509025574, 0.27638566493988037, 0.26811671257019043, 0.2685677111148834, 0.266918808221817, 0.27431580424308777, 0.26986441016197205, 0.25765755772590637, 0.2755852937698364, 0.2582884728908539, 0.266117125749588, 0.26279160380363464, 0.2518391013145447, 0.2536439895629883, 0.24707816541194916, 0.24656857550144196, 0.24163903295993805, 0.2441844791173935, 0.25188684463500977, 0.23796814680099487, 0.2414175122976303, 0.24146775901317596, 0.24429771304130554, 0.23984895646572113, 0.24585317075252533, 0.23070165514945984, 0.22145842015743256, 0.22158238291740417, 0.2215890884399414, 0.22198373079299927, 0.22539545595645905, 0.21782062947750092, 0.21576698124408722, 0.2166300266981125, 0.21635417640209198, 0.21292421221733093, 0.20407548546791077, 0.2059364914894104, 0.20505309104919434, 0.2001078724861145, 0.20306776463985443, 0.20776289701461792], 'accuracy': [0.8183766603469849, 0.8226627111434937, 0.829359769821167, 0.8221269845962524, 0.8403428792953491, 0.8317707180976868, 0.8344495296478271, 0.8325743079185486, 0.8387355804443359, 0.8387355804443359, 0.8427538275718689, 0.8406107425689697, 0.8427538275718689, 0.8462362885475159, 0.8427538275718689, 0.85079026222229, 0.8499866127967834, 0.8483793139457703, 0.8486471772193909, 0.8556120991706848, 0.8545405864715576, 0.860701858997345, 0.8521296381950378, 0.8593624234199524, 0.8556120991706848, 0.85079026222229, 0.8609697222709656, 0.8647200465202332, 0.8673988580703735, 0.8668631315231323, 0.8706134557723999, 0.8700776696205139, 0.8615055084228516, 0.8588266968727112, 0.8647200465202332, 0.8706134557723999, 0.8687382936477661, 0.8732922673225403, 0.8722207546234131, 0.8711491823196411, 0.8727564811706543, 0.8829360008239746, 0.8762389421463013, 0.8837395906448364, 0.8767747282981873, 0.8797214031219482, 0.884543240070343, 0.8799892663955688, 0.8848111629486084, 0.8861505389213562, 0.8877578377723694, 0.8904366493225098, 0.8893651366233826, 0.8931154608726501, 0.8896329998970032, 0.8890972137451172, 0.8888293504714966, 0.8909724354743958, 0.8939191102981567, 0.8936512470245361, 0.8987409472465515, 0.8990088105201721, 0.9000803828239441, 0.8947227597236633, 0.8968657851219177, 0.9054380059242249, 0.891508162021637, 0.9027591943740845, 0.9016876220703125, 0.8974015712738037, 0.9075810313224792, 0.9062416553497314, 0.9078488945960999, 0.909456193447113, 0.909991979598999, 0.9075810313224792, 0.9032949209213257, 0.9121350049972534, 0.9137423038482666, 0.909991979598999, 0.9040985703468323, 0.9121350049972534, 0.9057058691978455, 0.9166889786720276, 0.9201714396476746, 0.922314465045929, 0.9207072257995605, 0.9190999269485474, 0.9121350049972534, 0.9209750890731812, 0.9209750890731812, 0.9233860373497009, 0.9239217638969421, 0.9244575500488281, 0.9255290627479553, 0.9271363615989685, 0.9271363615989685, 0.9268684983253479, 0.9287436604499817, 0.9207072257995605], 'val_loss': [0.6769341230392456, 0.6735410690307617, 0.6704497337341309, 0.6646003723144531, 0.6599732041358948, 0.6531215906143188, 0.6455869078636169, 0.6382641196250916, 0.6291922926902771, 0.6142854690551758, 0.5996152758598328, 0.5853287577629089, 0.5675433874130249, 0.547094464302063, 0.531052827835083, 0.5067375302314758, 0.493373841047287, 0.468495637178421, 0.46037623286247253, 0.465582937002182, 0.4386080503463745, 0.4912797510623932, 0.44163838028907776, 0.4307762086391449, 0.45321381092071533, 0.4443456530570984, 0.43772661685943604, 0.44437935948371887, 0.450551837682724, 0.4422077536582947, 0.44354692101478577, 0.4462282657623291, 0.46941423416137695, 0.4462223947048187, 0.44617345929145813, 0.4516356289386749, 0.4458167552947998, 0.44862738251686096, 0.4646317958831787, 0.4514547288417816, 0.4477847218513489, 0.44906654953956604, 0.4601878821849823, 0.4555545151233673, 0.4485102891921997, 0.4533655643463135, 0.4540158212184906, 0.45837637782096863, 0.45068830251693726, 0.4650534987449646, 0.45301753282546997, 0.4593743681907654, 0.46361419558525085, 0.45596012473106384, 0.46695274114608765, 0.49040529131889343, 0.4674444794654846, 0.4566403031349182, 0.4749376177787781, 0.4572015404701233, 0.4614697992801666, 0.46240347623825073, 0.4626561999320984, 0.4697338044643402, 0.4620981812477112, 0.4635305404663086, 0.4727417826652527, 0.4639228582382202, 0.4867810010910034, 0.46714770793914795, 0.4806247651576996, 0.478861004114151, 0.4800691604614258, 0.4720804691314697, 0.4825034737586975, 0.48640337586402893, 0.4747520387172699, 0.4910789430141449, 0.48677781224250793, 0.48959848284721375, 0.480773001909256, 0.48617517948150635, 0.48707109689712524, 0.48146113753318787, 0.48406723141670227, 0.48931750655174255, 0.4930420219898224, 0.491964727640152, 0.506415069103241, 0.4931236207485199, 0.5143651962280273, 0.510891318321228, 0.511128306388855, 0.4976351261138916, 0.5044326782226562, 0.5082775950431824, 0.5043496489524841, 0.5099794268608093, 0.5103633403778076, 0.5178878307342529], 'val_accuracy': [0.7173447608947754, 0.7291220426559448, 0.675588846206665, 0.7516059875488281, 0.7612419724464417, 0.7569593191146851, 0.759100615978241, 0.7548179626464844, 0.7505353093147278, 0.7676659822463989, 0.7719486355781555, 0.7740899324417114, 0.7794432640075684, 0.7815845608711243, 0.7815845608711243, 0.7880085706710815, 0.7815845608711243, 0.7858672142028809, 0.7869378924369812, 0.7912205457687378, 0.7965738773345947, 0.7805139422416687, 0.7901498675346375, 0.7987151741981506, 0.7890792489051819, 0.7933619022369385, 0.8019272089004517, 0.799785852432251, 0.794432520866394, 0.8094218373298645, 0.8104925155639648, 0.8051391839981079, 0.794432520866394, 0.8072805404663086, 0.799785852432251, 0.8008565306663513, 0.8083511590957642, 0.8104925155639648, 0.7965738773345947, 0.8104925155639648, 0.8083511590957642, 0.8083511590957642, 0.802997887134552, 0.8072805404663086, 0.8094218373298645, 0.8104925155639648, 0.8083511590957642, 0.8115631937980652, 0.8137044906616211, 0.799785852432251, 0.8137044906616211, 0.8094218373298645, 0.8072805404663086, 0.8147751688957214, 0.8051391839981079, 0.799785852432251, 0.8062098622322083, 0.8158458471298218, 0.8083511590957642, 0.8137044906616211, 0.8126338124275208, 0.8126338124275208, 0.8126338124275208, 0.8072805404663086, 0.8169164657592773, 0.8147751688957214, 0.8104925155639648, 0.8147751688957214, 0.7965738773345947, 0.8072805404663086, 0.802997887134552, 0.8094218373298645, 0.8072805404663086, 0.819057822227478, 0.8158458471298218, 0.8051391839981079, 0.8201285004615784, 0.8083511590957642, 0.8137044906616211, 0.8137044906616211, 0.8137044906616211, 0.8072805404663086, 0.8104925155639648, 0.8179871439933777, 0.8201285004615784, 0.8201285004615784, 0.8169164657592773, 0.8169164657592773, 0.8083511590957642, 0.8137044906616211, 0.8137044906616211, 0.8126338124275208, 0.8104925155639648, 0.8147751688957214, 0.8179871439933777, 0.8169164657592773, 0.8158458471298218, 0.8158458471298218, 0.8169164657592773, 0.819057822227478]}\n","37/37 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 9s 51ms/step - loss: 0.4073 - accuracy: 0.8216 - val_loss: 0.6757 - val_accuracy: 0.7505\n","Epoch 2/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4048 - accuracy: 0.8197 - val_loss: 0.6720 - val_accuracy: 0.7473\n","Epoch 3/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4039 - accuracy: 0.8224 - val_loss: 0.6692 - val_accuracy: 0.6713\n","Epoch 4/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3960 - accuracy: 0.8240 - val_loss: 0.6636 - val_accuracy: 0.7398\n","Epoch 5/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3892 - accuracy: 0.8288 - val_loss: 0.6575 - val_accuracy: 0.7752\n","Epoch 6/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3888 - accuracy: 0.8299 - val_loss: 0.6526 - val_accuracy: 0.7206\n","Epoch 7/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3883 - accuracy: 0.8291 - val_loss: 0.6433 - val_accuracy: 0.7794\n","Epoch 8/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3917 - accuracy: 0.8253 - val_loss: 0.6347 - val_accuracy: 0.7752\n","Epoch 9/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3932 - accuracy: 0.8328 - val_loss: 0.6222 - val_accuracy: 0.7944\n","Epoch 10/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3798 - accuracy: 0.8315 - val_loss: 0.6102 - val_accuracy: 0.7869\n","Epoch 11/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3803 - accuracy: 0.8312 - val_loss: 0.5958 - val_accuracy: 0.7987\n","Epoch 12/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3767 - accuracy: 0.8320 - val_loss: 0.5745 - val_accuracy: 0.8137\n","Epoch 13/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3750 - accuracy: 0.8411 - val_loss: 0.5551 - val_accuracy: 0.8169\n","Epoch 14/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3717 - accuracy: 0.8401 - val_loss: 0.5339 - val_accuracy: 0.8148\n","Epoch 15/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3724 - accuracy: 0.8409 - val_loss: 0.5114 - val_accuracy: 0.8062\n","Epoch 16/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3690 - accuracy: 0.8406 - val_loss: 0.4850 - val_accuracy: 0.8298\n","Epoch 17/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3700 - accuracy: 0.8414 - val_loss: 0.4645 - val_accuracy: 0.8266\n","Epoch 18/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3647 - accuracy: 0.8462 - val_loss: 0.4389 - val_accuracy: 0.8276\n","Epoch 19/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3604 - accuracy: 0.8495 - val_loss: 0.4190 - val_accuracy: 0.8319\n","Epoch 20/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3614 - accuracy: 0.8460 - val_loss: 0.4066 - val_accuracy: 0.8383\n","Epoch 21/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3593 - accuracy: 0.8497 - val_loss: 0.3913 - val_accuracy: 0.8287\n","Epoch 22/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3554 - accuracy: 0.8508 - val_loss: 0.3822 - val_accuracy: 0.8330\n","Epoch 23/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3536 - accuracy: 0.8508 - val_loss: 0.3767 - val_accuracy: 0.8340\n","Epoch 24/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3530 - accuracy: 0.8604 - val_loss: 0.3814 - val_accuracy: 0.8308\n","Epoch 25/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3516 - accuracy: 0.8545 - val_loss: 0.3743 - val_accuracy: 0.8373\n","Epoch 26/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3500 - accuracy: 0.8527 - val_loss: 0.3833 - val_accuracy: 0.8287\n","Epoch 27/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3482 - accuracy: 0.8532 - val_loss: 0.3724 - val_accuracy: 0.8426\n","Epoch 28/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3449 - accuracy: 0.8543 - val_loss: 0.3689 - val_accuracy: 0.8480\n","Epoch 29/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3409 - accuracy: 0.8586 - val_loss: 0.3671 - val_accuracy: 0.8533\n","Epoch 30/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3431 - accuracy: 0.8610 - val_loss: 0.3673 - val_accuracy: 0.8480\n","Epoch 31/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3377 - accuracy: 0.8551 - val_loss: 0.3757 - val_accuracy: 0.8469\n","Epoch 32/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3485 - accuracy: 0.8521 - val_loss: 0.3668 - val_accuracy: 0.8501\n","Epoch 33/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3309 - accuracy: 0.8639 - val_loss: 0.3817 - val_accuracy: 0.8426\n","Epoch 34/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3384 - accuracy: 0.8602 - val_loss: 0.3714 - val_accuracy: 0.8362\n","Epoch 35/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3348 - accuracy: 0.8602 - val_loss: 0.3719 - val_accuracy: 0.8340\n","Epoch 36/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3292 - accuracy: 0.8669 - val_loss: 0.3675 - val_accuracy: 0.8544\n","Epoch 37/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3289 - accuracy: 0.8645 - val_loss: 0.3708 - val_accuracy: 0.8383\n","Epoch 38/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3253 - accuracy: 0.8639 - val_loss: 0.3678 - val_accuracy: 0.8448\n","Epoch 39/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3205 - accuracy: 0.8677 - val_loss: 0.3758 - val_accuracy: 0.8512\n","Epoch 40/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3204 - accuracy: 0.8671 - val_loss: 0.3685 - val_accuracy: 0.8576\n","Epoch 41/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3159 - accuracy: 0.8760 - val_loss: 0.3728 - val_accuracy: 0.8383\n","Epoch 42/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3196 - accuracy: 0.8663 - val_loss: 0.3694 - val_accuracy: 0.8394\n","Epoch 43/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.3206 - accuracy: 0.8706 - val_loss: 0.3890 - val_accuracy: 0.8437\n","Epoch 44/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3135 - accuracy: 0.8728 - val_loss: 0.3692 - val_accuracy: 0.8448\n","Epoch 45/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3099 - accuracy: 0.8738 - val_loss: 0.3707 - val_accuracy: 0.8415\n","Epoch 46/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3089 - accuracy: 0.8722 - val_loss: 0.3680 - val_accuracy: 0.8501\n","Epoch 47/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3115 - accuracy: 0.8757 - val_loss: 0.3879 - val_accuracy: 0.8340\n","Epoch 48/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3077 - accuracy: 0.8781 - val_loss: 0.3682 - val_accuracy: 0.8501\n","Epoch 49/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3031 - accuracy: 0.8797 - val_loss: 0.3718 - val_accuracy: 0.8458\n","Epoch 50/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3028 - accuracy: 0.8773 - val_loss: 0.3707 - val_accuracy: 0.8426\n","Epoch 51/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2945 - accuracy: 0.8870 - val_loss: 0.3717 - val_accuracy: 0.8533\n","Epoch 52/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2979 - accuracy: 0.8827 - val_loss: 0.3747 - val_accuracy: 0.8565\n","Epoch 53/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2946 - accuracy: 0.8853 - val_loss: 0.3732 - val_accuracy: 0.8501\n","Epoch 54/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2992 - accuracy: 0.8789 - val_loss: 0.4313 - val_accuracy: 0.8137\n","Epoch 55/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2996 - accuracy: 0.8797 - val_loss: 0.3736 - val_accuracy: 0.8555\n","Epoch 56/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2839 - accuracy: 0.8878 - val_loss: 0.3739 - val_accuracy: 0.8522\n","Epoch 57/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2842 - accuracy: 0.8894 - val_loss: 0.3753 - val_accuracy: 0.8490\n","Epoch 58/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2876 - accuracy: 0.8878 - val_loss: 0.3800 - val_accuracy: 0.8501\n","Epoch 59/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2804 - accuracy: 0.8904 - val_loss: 0.3804 - val_accuracy: 0.8522\n","Epoch 60/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2919 - accuracy: 0.8776 - val_loss: 0.3925 - val_accuracy: 0.8298\n","Epoch 61/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2872 - accuracy: 0.8875 - val_loss: 0.3906 - val_accuracy: 0.8437\n","Epoch 62/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2837 - accuracy: 0.8888 - val_loss: 0.3861 - val_accuracy: 0.8340\n","Epoch 63/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2750 - accuracy: 0.8942 - val_loss: 0.3850 - val_accuracy: 0.8490\n","Epoch 64/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2736 - accuracy: 0.8953 - val_loss: 0.3786 - val_accuracy: 0.8512\n","Epoch 65/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2771 - accuracy: 0.8923 - val_loss: 0.3994 - val_accuracy: 0.8298\n","Epoch 66/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2725 - accuracy: 0.8958 - val_loss: 0.3832 - val_accuracy: 0.8448\n","Epoch 67/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2694 - accuracy: 0.8953 - val_loss: 0.3821 - val_accuracy: 0.8480\n","Epoch 68/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2670 - accuracy: 0.8971 - val_loss: 0.3807 - val_accuracy: 0.8512\n","Epoch 69/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2625 - accuracy: 0.8998 - val_loss: 0.4123 - val_accuracy: 0.8287\n","Epoch 70/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2633 - accuracy: 0.8955 - val_loss: 0.3887 - val_accuracy: 0.8458\n","Epoch 71/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2590 - accuracy: 0.9044 - val_loss: 0.4055 - val_accuracy: 0.8308\n","Epoch 72/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2594 - accuracy: 0.9014 - val_loss: 0.3849 - val_accuracy: 0.8480\n","Epoch 73/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2537 - accuracy: 0.9076 - val_loss: 0.4309 - val_accuracy: 0.8244\n","Epoch 74/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2628 - accuracy: 0.8979 - val_loss: 0.3883 - val_accuracy: 0.8501\n","Epoch 75/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2517 - accuracy: 0.9057 - val_loss: 0.3925 - val_accuracy: 0.8469\n","Epoch 76/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2536 - accuracy: 0.9060 - val_loss: 0.3926 - val_accuracy: 0.8448\n","Epoch 77/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2459 - accuracy: 0.9095 - val_loss: 0.3944 - val_accuracy: 0.8490\n","Epoch 78/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2421 - accuracy: 0.9097 - val_loss: 0.4443 - val_accuracy: 0.8233\n","Epoch 79/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2415 - accuracy: 0.9084 - val_loss: 0.4013 - val_accuracy: 0.8405\n","Epoch 80/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2460 - accuracy: 0.9113 - val_loss: 0.4024 - val_accuracy: 0.8383\n","Epoch 81/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2419 - accuracy: 0.9105 - val_loss: 0.3998 - val_accuracy: 0.8448\n","Epoch 82/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2470 - accuracy: 0.9073 - val_loss: 0.4127 - val_accuracy: 0.8383\n","Epoch 83/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2410 - accuracy: 0.9103 - val_loss: 0.4051 - val_accuracy: 0.8405\n","Epoch 84/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2453 - accuracy: 0.9049 - val_loss: 0.4349 - val_accuracy: 0.8244\n","Epoch 85/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2357 - accuracy: 0.9162 - val_loss: 0.4490 - val_accuracy: 0.8244\n","Epoch 86/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2448 - accuracy: 0.9052 - val_loss: 0.4905 - val_accuracy: 0.8105\n","Epoch 87/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2661 - accuracy: 0.8993 - val_loss: 0.3975 - val_accuracy: 0.8394\n","Epoch 88/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2401 - accuracy: 0.9121 - val_loss: 0.3999 - val_accuracy: 0.8405\n","Epoch 89/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2270 - accuracy: 0.9172 - val_loss: 0.4030 - val_accuracy: 0.8405\n","Epoch 90/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2213 - accuracy: 0.9191 - val_loss: 0.3960 - val_accuracy: 0.8480\n","Epoch 91/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.2236 - accuracy: 0.9196 - val_loss: 0.4010 - val_accuracy: 0.8490\n","Epoch 92/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2284 - accuracy: 0.9159 - val_loss: 0.4075 - val_accuracy: 0.8426\n","Epoch 93/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2213 - accuracy: 0.9186 - val_loss: 0.4060 - val_accuracy: 0.8394\n","Epoch 94/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2162 - accuracy: 0.9199 - val_loss: 0.4212 - val_accuracy: 0.8426\n","Epoch 95/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2162 - accuracy: 0.9183 - val_loss: 0.4170 - val_accuracy: 0.8448\n","Epoch 96/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2202 - accuracy: 0.9196 - val_loss: 0.4185 - val_accuracy: 0.8426\n","Epoch 97/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2117 - accuracy: 0.9250 - val_loss: 0.4117 - val_accuracy: 0.8448\n","Epoch 98/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2113 - accuracy: 0.9253 - val_loss: 0.4172 - val_accuracy: 0.8448\n","Epoch 99/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2098 - accuracy: 0.9261 - val_loss: 0.4170 - val_accuracy: 0.8458\n","Epoch 100/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2075 - accuracy: 0.9242 - val_loss: 0.4192 - val_accuracy: 0.8426\n","{'loss': [0.4072876572608948, 0.40476804971694946, 0.40389391779899597, 0.39598289132118225, 0.38919034600257874, 0.3888401687145233, 0.3883472681045532, 0.3916771113872528, 0.39322802424430847, 0.3798423409461975, 0.38031652569770813, 0.37673741579055786, 0.37504056096076965, 0.37171095609664917, 0.3724285662174225, 0.3689587116241455, 0.36996614933013916, 0.364709734916687, 0.3603871762752533, 0.36139819025993347, 0.35930225253105164, 0.3554193079471588, 0.3535861670970917, 0.35303419828414917, 0.35164833068847656, 0.3499608337879181, 0.34821200370788574, 0.3449054956436157, 0.34086647629737854, 0.3430960476398468, 0.3377036452293396, 0.34851008653640747, 0.3309493660926819, 0.338442862033844, 0.33479490876197815, 0.32916733622550964, 0.3288806676864624, 0.32532915472984314, 0.3205472230911255, 0.32037997245788574, 0.31594592332839966, 0.31959056854248047, 0.3205725848674774, 0.3135145604610443, 0.3099341094493866, 0.3088627755641937, 0.31154686212539673, 0.3077123463153839, 0.3031032681465149, 0.3028126358985901, 0.2944708466529846, 0.2978895902633667, 0.2946350872516632, 0.29917851090431213, 0.29955774545669556, 0.28385376930236816, 0.2841724753379822, 0.2875928282737732, 0.2804497182369232, 0.2918660044670105, 0.2872435450553894, 0.2836751341819763, 0.2750127613544464, 0.273550808429718, 0.2771056592464447, 0.2724991738796234, 0.2693820595741272, 0.26702454686164856, 0.2624981105327606, 0.2633066475391388, 0.25901538133621216, 0.25944265723228455, 0.2537406086921692, 0.26283887028694153, 0.2516743540763855, 0.25359001755714417, 0.2458585649728775, 0.24205835163593292, 0.24149936437606812, 0.24598334729671478, 0.24189171195030212, 0.24697747826576233, 0.24098855257034302, 0.2453029751777649, 0.23574107885360718, 0.24484536051750183, 0.2660852372646332, 0.2401181161403656, 0.22700829803943634, 0.22130349278450012, 0.22363604605197906, 0.22838963568210602, 0.22128278017044067, 0.21622928977012634, 0.21621723473072052, 0.22016967833042145, 0.2116849571466446, 0.21130181849002838, 0.2098422348499298, 0.20749728381633759], 'accuracy': [0.8215911984443665, 0.8197160363197327, 0.822394847869873, 0.8240021467208862, 0.828823983669281, 0.829895555973053, 0.8290919065475464, 0.825341522693634, 0.832842230796814, 0.8315027952194214, 0.8312349319458008, 0.8320385813713074, 0.8411465287208557, 0.8400750160217285, 0.8408786654472351, 0.8406107425689697, 0.8414143919944763, 0.8462362885475159, 0.8494508266448975, 0.8459683656692505, 0.8497187495231628, 0.85079026222229, 0.85079026222229, 0.8604339957237244, 0.8545405864715576, 0.8526654243469238, 0.853201150894165, 0.854272723197937, 0.8585587739944458, 0.8609697222709656, 0.8550763726234436, 0.8521296381950378, 0.8639163970947266, 0.860166072845459, 0.860166072845459, 0.8668631315231323, 0.8644521832466125, 0.8639163970947266, 0.8676667809486389, 0.8671309947967529, 0.8759710788726807, 0.8663273453712463, 0.8706134557723999, 0.8727564811706543, 0.8738279938697815, 0.8722207546234131, 0.8757032155990601, 0.8781141042709351, 0.8797214031219482, 0.8773104548454285, 0.8869541883468628, 0.8826680779457092, 0.8853468894958496, 0.8789177536964417, 0.8797214031219482, 0.8877578377723694, 0.8893651366233826, 0.8877578377723694, 0.8904366493225098, 0.8775783777236938, 0.8874899744987488, 0.8888293504714966, 0.8941869735717773, 0.8952584862709045, 0.8923118114471436, 0.8957942724227905, 0.8952584862709045, 0.8971336483955383, 0.8998124599456787, 0.8955264091491699, 0.9043664336204529, 0.9014197587966919, 0.9075810313224792, 0.8979372978210449, 0.9057058691978455, 0.9059737324714661, 0.909456193447113, 0.9097240567207336, 0.9083846807479858, 0.9113313555717468, 0.9105277061462402, 0.9073131680488586, 0.9102598428726196, 0.9049022197723389, 0.9161532521247864, 0.9051700830459595, 0.8992767333984375, 0.9121350049972534, 0.9172247648239136, 0.9190999269485474, 0.9196356534957886, 0.915885329246521, 0.9185641407966614, 0.919903576374054, 0.9182962775230408, 0.9196356534957886, 0.9249932765960693, 0.9252611994743347, 0.9260648488998413, 0.9241896867752075], 'val_loss': [0.6756899952888489, 0.6720072627067566, 0.6691561341285706, 0.6636374592781067, 0.6575252413749695, 0.6525960564613342, 0.6432558298110962, 0.6347209215164185, 0.6221645474433899, 0.6102336049079895, 0.5958122611045837, 0.5745334029197693, 0.5550529360771179, 0.5338822603225708, 0.5113958120346069, 0.4849541187286377, 0.46451812982559204, 0.4388638138771057, 0.4189518094062805, 0.40664389729499817, 0.39131414890289307, 0.38216862082481384, 0.3766755163669586, 0.3813669979572296, 0.3742755651473999, 0.38333162665367126, 0.3724175691604614, 0.36894190311431885, 0.3671329915523529, 0.3673165738582611, 0.37566938996315, 0.3667866289615631, 0.38170090317726135, 0.37136662006378174, 0.3718757629394531, 0.3675164580345154, 0.37076666951179504, 0.36776965856552124, 0.37582260370254517, 0.368549108505249, 0.37279385328292847, 0.3693774342536926, 0.38897374272346497, 0.3691778779029846, 0.3706762492656708, 0.36799997091293335, 0.3878856301307678, 0.36819520592689514, 0.3717629909515381, 0.37068504095077515, 0.3717253506183624, 0.37465399503707886, 0.37324514985084534, 0.43127870559692383, 0.37355440855026245, 0.37390485405921936, 0.37528014183044434, 0.3800400495529175, 0.3804025650024414, 0.3924619257450104, 0.39057520031929016, 0.38608524203300476, 0.3849867582321167, 0.378597229719162, 0.3993968069553375, 0.3831785023212433, 0.3821188509464264, 0.38068100810050964, 0.4123002588748932, 0.38866984844207764, 0.4054988622665405, 0.3849044442176819, 0.4308628737926483, 0.38831305503845215, 0.3925214409828186, 0.3926280438899994, 0.3944207429885864, 0.4443049430847168, 0.4013291001319885, 0.40241503715515137, 0.39977407455444336, 0.41270387172698975, 0.4050672948360443, 0.4349057078361511, 0.44899237155914307, 0.4904732406139374, 0.39751625061035156, 0.3998906910419464, 0.4029819965362549, 0.3959900736808777, 0.4010373055934906, 0.40745916962623596, 0.4059550166130066, 0.42124423384666443, 0.41702234745025635, 0.4185015559196472, 0.4116627275943756, 0.41720759868621826, 0.41700923442840576, 0.41921013593673706], 'val_accuracy': [0.7505353093147278, 0.7473233342170715, 0.6713061928749084, 0.7398287057876587, 0.7751606106758118, 0.7205567359924316, 0.7794432640075684, 0.7751606106758118, 0.794432520866394, 0.7869378924369812, 0.7987151741981506, 0.8137044906616211, 0.8169164657592773, 0.8147751688957214, 0.8062098622322083, 0.8297644257545471, 0.8265524506568909, 0.8276231288909912, 0.8319057822227478, 0.8383297920227051, 0.8286938071250916, 0.8329764604568481, 0.8340471386909485, 0.8308351039886475, 0.8372591137886047, 0.8286938071250916, 0.8426124453544617, 0.8479657173156738, 0.8533190488815308, 0.8479657173156738, 0.8468950986862183, 0.8501070737838745, 0.8426124453544617, 0.8361884355545044, 0.8340471386909485, 0.8543897271156311, 0.8383297920227051, 0.8447537422180176, 0.8511777520179749, 0.8576017022132874, 0.8383297920227051, 0.8394004106521606, 0.8436830639839172, 0.8447537422180176, 0.8415417671203613, 0.8501070737838745, 0.8340471386909485, 0.8501070737838745, 0.8458244204521179, 0.8426124453544617, 0.8533190488815308, 0.856531023979187, 0.8501070737838745, 0.8137044906616211, 0.8554604053497314, 0.8522483706474304, 0.8490363955497742, 0.8501070737838745, 0.8522483706474304, 0.8297644257545471, 0.8436830639839172, 0.8340471386909485, 0.8490363955497742, 0.8511777520179749, 0.8297644257545471, 0.8447537422180176, 0.8479657173156738, 0.8511777520179749, 0.8286938071250916, 0.8458244204521179, 0.8308351039886475, 0.8479657173156738, 0.824411153793335, 0.8501070737838745, 0.8468950986862183, 0.8447537422180176, 0.8490363955497742, 0.8233404755592346, 0.840471088886261, 0.8383297920227051, 0.8447537422180176, 0.8383297920227051, 0.840471088886261, 0.824411153793335, 0.824411153793335, 0.8104925155639648, 0.8394004106521606, 0.840471088886261, 0.840471088886261, 0.8479657173156738, 0.8490363955497742, 0.8426124453544617, 0.8394004106521606, 0.8426124453544617, 0.8447537422180176, 0.8426124453544617, 0.8447537422180176, 0.8447537422180176, 0.8458244204521179, 0.8426124453544617]}\n","37/37 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 54ms/step - loss: 0.4152 - accuracy: 0.8197 - val_loss: 0.6761 - val_accuracy: 0.7409\n","Epoch 2/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4070 - accuracy: 0.8245 - val_loss: 0.6726 - val_accuracy: 0.7495\n","Epoch 3/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4046 - accuracy: 0.8181 - val_loss: 0.6686 - val_accuracy: 0.7388\n","Epoch 4/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3990 - accuracy: 0.8259 - val_loss: 0.6647 - val_accuracy: 0.7291\n","Epoch 5/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3945 - accuracy: 0.8248 - val_loss: 0.6582 - val_accuracy: 0.7730\n","Epoch 6/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3919 - accuracy: 0.8280 - val_loss: 0.6513 - val_accuracy: 0.7934\n","Epoch 7/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3895 - accuracy: 0.8310 - val_loss: 0.6449 - val_accuracy: 0.7430\n","Epoch 8/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3887 - accuracy: 0.8328 - val_loss: 0.6362 - val_accuracy: 0.7452\n","Epoch 9/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3906 - accuracy: 0.8291 - val_loss: 0.6263 - val_accuracy: 0.7548\n","Epoch 10/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3914 - accuracy: 0.8213 - val_loss: 0.6124 - val_accuracy: 0.8019\n","Epoch 11/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3831 - accuracy: 0.8336 - val_loss: 0.5977 - val_accuracy: 0.7912\n","Epoch 12/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3947 - accuracy: 0.8259 - val_loss: 0.5816 - val_accuracy: 0.7998\n","Epoch 13/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3718 - accuracy: 0.8401 - val_loss: 0.5629 - val_accuracy: 0.8084\n","Epoch 14/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3710 - accuracy: 0.8433 - val_loss: 0.5390 - val_accuracy: 0.8137\n","Epoch 15/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3717 - accuracy: 0.8406 - val_loss: 0.5189 - val_accuracy: 0.8158\n","Epoch 16/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3708 - accuracy: 0.8385 - val_loss: 0.4962 - val_accuracy: 0.8116\n","Epoch 17/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3640 - accuracy: 0.8438 - val_loss: 0.4732 - val_accuracy: 0.8148\n","Epoch 18/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3717 - accuracy: 0.8371 - val_loss: 0.4541 - val_accuracy: 0.8094\n","Epoch 19/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3644 - accuracy: 0.8465 - val_loss: 0.4361 - val_accuracy: 0.8169\n","Epoch 20/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3594 - accuracy: 0.8476 - val_loss: 0.4229 - val_accuracy: 0.8191\n","Epoch 21/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3613 - accuracy: 0.8454 - val_loss: 0.4164 - val_accuracy: 0.8212\n","Epoch 22/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.3599 - accuracy: 0.8406 - val_loss: 0.4139 - val_accuracy: 0.8212\n","Epoch 23/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3538 - accuracy: 0.8473 - val_loss: 0.4026 - val_accuracy: 0.8212\n","Epoch 24/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3704 - accuracy: 0.8401 - val_loss: 0.4042 - val_accuracy: 0.8266\n","Epoch 25/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3627 - accuracy: 0.8449 - val_loss: 0.3988 - val_accuracy: 0.8308\n","Epoch 26/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3463 - accuracy: 0.8540 - val_loss: 0.4012 - val_accuracy: 0.8308\n","Epoch 27/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3461 - accuracy: 0.8551 - val_loss: 0.4008 - val_accuracy: 0.8298\n","Epoch 28/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3459 - accuracy: 0.8551 - val_loss: 0.3960 - val_accuracy: 0.8276\n","Epoch 29/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3391 - accuracy: 0.8548 - val_loss: 0.4020 - val_accuracy: 0.8319\n","Epoch 30/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3425 - accuracy: 0.8545 - val_loss: 0.4353 - val_accuracy: 0.8169\n","Epoch 31/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3506 - accuracy: 0.8508 - val_loss: 0.4016 - val_accuracy: 0.8298\n","Epoch 32/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3365 - accuracy: 0.8570 - val_loss: 0.4014 - val_accuracy: 0.8298\n","Epoch 33/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3345 - accuracy: 0.8631 - val_loss: 0.3967 - val_accuracy: 0.8308\n","Epoch 34/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3325 - accuracy: 0.8618 - val_loss: 0.4105 - val_accuracy: 0.8266\n","Epoch 35/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3323 - accuracy: 0.8634 - val_loss: 0.4003 - val_accuracy: 0.8330\n","Epoch 36/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3279 - accuracy: 0.8626 - val_loss: 0.3985 - val_accuracy: 0.8298\n","Epoch 37/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3225 - accuracy: 0.8650 - val_loss: 0.4057 - val_accuracy: 0.8276\n","Epoch 38/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3294 - accuracy: 0.8628 - val_loss: 0.4011 - val_accuracy: 0.8330\n","Epoch 39/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3285 - accuracy: 0.8623 - val_loss: 0.4051 - val_accuracy: 0.8266\n","Epoch 40/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3246 - accuracy: 0.8653 - val_loss: 0.3982 - val_accuracy: 0.8340\n","Epoch 41/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.3261 - accuracy: 0.8626 - val_loss: 0.3976 - val_accuracy: 0.8351\n","Epoch 42/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.3211 - accuracy: 0.8645 - val_loss: 0.3991 - val_accuracy: 0.8319\n","Epoch 43/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3171 - accuracy: 0.8706 - val_loss: 0.3990 - val_accuracy: 0.8330\n","Epoch 44/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.3106 - accuracy: 0.8741 - val_loss: 0.4033 - val_accuracy: 0.8276\n","Epoch 45/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.3127 - accuracy: 0.8661 - val_loss: 0.4014 - val_accuracy: 0.8340\n","Epoch 46/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.3136 - accuracy: 0.8706 - val_loss: 0.3987 - val_accuracy: 0.8340\n","Epoch 47/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3080 - accuracy: 0.8714 - val_loss: 0.4201 - val_accuracy: 0.8266\n","Epoch 48/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3181 - accuracy: 0.8671 - val_loss: 0.4099 - val_accuracy: 0.8233\n","Epoch 49/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3136 - accuracy: 0.8720 - val_loss: 0.4348 - val_accuracy: 0.8191\n","Epoch 50/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3077 - accuracy: 0.8733 - val_loss: 0.4098 - val_accuracy: 0.8233\n","Epoch 51/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3021 - accuracy: 0.8778 - val_loss: 0.3986 - val_accuracy: 0.8351\n","Epoch 52/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3005 - accuracy: 0.8803 - val_loss: 0.4234 - val_accuracy: 0.8148\n","Epoch 53/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3054 - accuracy: 0.8690 - val_loss: 0.3964 - val_accuracy: 0.8351\n","Epoch 54/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2990 - accuracy: 0.8792 - val_loss: 0.4108 - val_accuracy: 0.8244\n","Epoch 55/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2932 - accuracy: 0.8853 - val_loss: 0.4061 - val_accuracy: 0.8276\n","Epoch 56/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2952 - accuracy: 0.8800 - val_loss: 0.4004 - val_accuracy: 0.8351\n","Epoch 57/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2838 - accuracy: 0.8896 - val_loss: 0.3995 - val_accuracy: 0.8351\n","Epoch 58/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2932 - accuracy: 0.8795 - val_loss: 0.3975 - val_accuracy: 0.8394\n","Epoch 59/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2896 - accuracy: 0.8816 - val_loss: 0.4008 - val_accuracy: 0.8308\n","Epoch 60/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2851 - accuracy: 0.8832 - val_loss: 0.3985 - val_accuracy: 0.8373\n","Epoch 61/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2813 - accuracy: 0.8843 - val_loss: 0.4017 - val_accuracy: 0.8351\n","Epoch 62/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2836 - accuracy: 0.8864 - val_loss: 0.4037 - val_accuracy: 0.8383\n","Epoch 63/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2811 - accuracy: 0.8848 - val_loss: 0.4094 - val_accuracy: 0.8308\n","Epoch 64/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2838 - accuracy: 0.8840 - val_loss: 0.4016 - val_accuracy: 0.8394\n","Epoch 65/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2760 - accuracy: 0.8883 - val_loss: 0.4861 - val_accuracy: 0.8019\n","Epoch 66/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2857 - accuracy: 0.8851 - val_loss: 0.3974 - val_accuracy: 0.8362\n","Epoch 67/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2696 - accuracy: 0.8969 - val_loss: 0.3986 - val_accuracy: 0.8383\n","Epoch 68/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.2662 - accuracy: 0.8942 - val_loss: 0.4005 - val_accuracy: 0.8415\n","Epoch 69/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2693 - accuracy: 0.9006 - val_loss: 0.3997 - val_accuracy: 0.8415\n","Epoch 70/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2630 - accuracy: 0.8945 - val_loss: 0.4088 - val_accuracy: 0.8319\n","Epoch 71/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2665 - accuracy: 0.8966 - val_loss: 0.4073 - val_accuracy: 0.8351\n","Epoch 72/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2679 - accuracy: 0.8945 - val_loss: 0.4199 - val_accuracy: 0.8180\n","Epoch 73/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2634 - accuracy: 0.8987 - val_loss: 0.4124 - val_accuracy: 0.8298\n","Epoch 74/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2590 - accuracy: 0.8947 - val_loss: 0.4232 - val_accuracy: 0.8255\n","Epoch 75/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2547 - accuracy: 0.9017 - val_loss: 0.4183 - val_accuracy: 0.8308\n","Epoch 76/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2539 - accuracy: 0.8953 - val_loss: 0.4044 - val_accuracy: 0.8415\n","Epoch 77/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2490 - accuracy: 0.9054 - val_loss: 0.4066 - val_accuracy: 0.8415\n","Epoch 78/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2536 - accuracy: 0.9060 - val_loss: 0.4106 - val_accuracy: 0.8383\n","Epoch 79/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2441 - accuracy: 0.9062 - val_loss: 0.4266 - val_accuracy: 0.8276\n","Epoch 80/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2506 - accuracy: 0.8987 - val_loss: 0.4078 - val_accuracy: 0.8415\n","Epoch 81/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2569 - accuracy: 0.8979 - val_loss: 0.4158 - val_accuracy: 0.8255\n","Epoch 82/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2459 - accuracy: 0.9073 - val_loss: 0.4277 - val_accuracy: 0.8255\n","Epoch 83/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2451 - accuracy: 0.9020 - val_loss: 0.4076 - val_accuracy: 0.8405\n","Epoch 84/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2517 - accuracy: 0.8995 - val_loss: 0.4761 - val_accuracy: 0.8084\n","Epoch 85/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2393 - accuracy: 0.9089 - val_loss: 0.4114 - val_accuracy: 0.8426\n","Epoch 86/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2394 - accuracy: 0.9097 - val_loss: 0.4125 - val_accuracy: 0.8437\n","Epoch 87/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2361 - accuracy: 0.9070 - val_loss: 0.4149 - val_accuracy: 0.8415\n","Epoch 88/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2336 - accuracy: 0.9178 - val_loss: 0.4190 - val_accuracy: 0.8415\n","Epoch 89/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2361 - accuracy: 0.9089 - val_loss: 0.4136 - val_accuracy: 0.8448\n","Epoch 90/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2262 - accuracy: 0.9135 - val_loss: 0.4169 - val_accuracy: 0.8490\n","Epoch 91/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2268 - accuracy: 0.9092 - val_loss: 0.4154 - val_accuracy: 0.8383\n","Epoch 92/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.2223 - accuracy: 0.9153 - val_loss: 0.4209 - val_accuracy: 0.8351\n","Epoch 93/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.2199 - accuracy: 0.9140 - val_loss: 0.4320 - val_accuracy: 0.8191\n","Epoch 94/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2280 - accuracy: 0.9121 - val_loss: 0.4846 - val_accuracy: 0.8126\n","Epoch 95/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2614 - accuracy: 0.8942 - val_loss: 0.4183 - val_accuracy: 0.8330\n","Epoch 96/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2268 - accuracy: 0.9143 - val_loss: 0.4164 - val_accuracy: 0.8415\n","Epoch 97/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2136 - accuracy: 0.9220 - val_loss: 0.4177 - val_accuracy: 0.8415\n","Epoch 98/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2135 - accuracy: 0.9170 - val_loss: 0.4237 - val_accuracy: 0.8340\n","Epoch 99/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2202 - accuracy: 0.9186 - val_loss: 0.4497 - val_accuracy: 0.8223\n","Epoch 100/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2222 - accuracy: 0.9132 - val_loss: 0.4839 - val_accuracy: 0.8094\n","{'loss': [0.415179967880249, 0.4069906771183014, 0.40463241934776306, 0.39895960688591003, 0.3944946527481079, 0.39186277985572815, 0.38951629400253296, 0.3887174129486084, 0.39058589935302734, 0.3913508951663971, 0.3830990195274353, 0.3947341740131378, 0.3718101382255554, 0.37104570865631104, 0.3716695010662079, 0.3707643151283264, 0.3639680743217468, 0.3717080056667328, 0.3643515408039093, 0.3593786060810089, 0.36125922203063965, 0.3598996102809906, 0.3538073003292084, 0.37043899297714233, 0.3626571595668793, 0.3462904095649719, 0.3461430072784424, 0.3458614647388458, 0.33910250663757324, 0.3424626886844635, 0.350629061460495, 0.33647528290748596, 0.3344820439815521, 0.33250150084495544, 0.33233019709587097, 0.32788899540901184, 0.3224812150001526, 0.3293509781360626, 0.32846343517303467, 0.32462555170059204, 0.3261066675186157, 0.3210979104042053, 0.31714633107185364, 0.3106021583080292, 0.312738299369812, 0.3135557174682617, 0.30802208185195923, 0.3180891275405884, 0.31358879804611206, 0.30765828490257263, 0.30209752917289734, 0.30047857761383057, 0.30537712574005127, 0.29895561933517456, 0.29324832558631897, 0.29516491293907166, 0.2838301658630371, 0.29316726326942444, 0.2895844280719757, 0.28512662649154663, 0.28133437037467957, 0.2835780382156372, 0.2811082899570465, 0.28376561403274536, 0.27596715092658997, 0.2856738269329071, 0.26956528425216675, 0.26622772216796875, 0.2693122923374176, 0.26297250390052795, 0.2664748728275299, 0.26791200041770935, 0.26335418224334717, 0.25904151797294617, 0.25473448634147644, 0.25388845801353455, 0.2490137368440628, 0.2536134123802185, 0.24412354826927185, 0.25062379240989685, 0.2569366991519928, 0.24587514996528625, 0.24509942531585693, 0.2516668736934662, 0.23934996128082275, 0.2394285947084427, 0.23613876104354858, 0.23355592787265778, 0.2360740751028061, 0.22621779143810272, 0.2267751544713974, 0.22232533991336823, 0.2198885977268219, 0.2279624491930008, 0.26136845350265503, 0.22676382958889008, 0.21357138454914093, 0.21350517868995667, 0.22016985714435577, 0.2221691906452179], 'accuracy': [0.8197160363197327, 0.8245379328727722, 0.8181087374687195, 0.82587730884552, 0.8248057961463928, 0.8280203342437744, 0.8309670686721802, 0.832842230796814, 0.8290919065475464, 0.8213233351707458, 0.8336458802223206, 0.82587730884552, 0.8400750160217285, 0.8432895541191101, 0.8406107425689697, 0.8384677171707153, 0.8438253402709961, 0.8371283411979675, 0.8465041518211365, 0.8475756645202637, 0.8454326391220093, 0.8406107425689697, 0.8473078012466431, 0.8400750160217285, 0.8448968529701233, 0.8540048003196716, 0.8550763726234436, 0.8550763726234436, 0.8548084497451782, 0.8545405864715576, 0.85079026222229, 0.8569515347480774, 0.8631128072738647, 0.8617733716964722, 0.8633806705474854, 0.8625770211219788, 0.8649879693984985, 0.8628448843955994, 0.8623091578483582, 0.8652558326721191, 0.8625770211219788, 0.8644521832466125, 0.8706134557723999, 0.8740959167480469, 0.8660594820976257, 0.8706134557723999, 0.8714171051979065, 0.8671309947967529, 0.8719528317451477, 0.8732922673225403, 0.8778462409973145, 0.8802571892738342, 0.8690061569213867, 0.8791856169700623, 0.8853468894958496, 0.8799892663955688, 0.8896329998970032, 0.8794535398483276, 0.881596565246582, 0.8832038640975952, 0.8842753767967224, 0.8864184021949768, 0.8848111629486084, 0.8840075135231018, 0.8882936239242554, 0.885079026222229, 0.8968657851219177, 0.8941869735717773, 0.9006161093711853, 0.894454836845398, 0.8965979218482971, 0.894454836845398, 0.8987409472465515, 0.8947227597236633, 0.9016876220703125, 0.8952584862709045, 0.9054380059242249, 0.9059737324714661, 0.9062416553497314, 0.8987409472465515, 0.8979372978210449, 0.9073131680488586, 0.9019555449485779, 0.8995445966720581, 0.9089204668998718, 0.9097240567207336, 0.9070452451705933, 0.9177604913711548, 0.9089204668998718, 0.913474440574646, 0.9091883301734924, 0.9153496026992798, 0.9140101671218872, 0.9121350049972534, 0.8941869735717773, 0.9142780900001526, 0.9220466017723083, 0.9169568419456482, 0.9185641407966614, 0.9132065176963806], 'val_loss': [0.6761084198951721, 0.6726400256156921, 0.6686388850212097, 0.6646855473518372, 0.658215343952179, 0.6512560248374939, 0.6449481844902039, 0.6361973881721497, 0.626258134841919, 0.6124494075775146, 0.5976741909980774, 0.5815708637237549, 0.5629012584686279, 0.5390306711196899, 0.5189199447631836, 0.49616938829421997, 0.47318121790885925, 0.4540632665157318, 0.43610963225364685, 0.42292946577072144, 0.4164096415042877, 0.4138801097869873, 0.4025926887989044, 0.40422895550727844, 0.39883953332901, 0.40119221806526184, 0.4008128046989441, 0.39598020911216736, 0.4020218253135681, 0.43527838587760925, 0.4015907645225525, 0.4013531804084778, 0.39666059613227844, 0.4104517102241516, 0.40030232071876526, 0.3984570801258087, 0.4057424068450928, 0.40109866857528687, 0.4050513505935669, 0.3982207477092743, 0.39759552478790283, 0.399109810590744, 0.39898231625556946, 0.403293251991272, 0.4013783633708954, 0.39865347743034363, 0.420112669467926, 0.4099499583244324, 0.43481042981147766, 0.4098169803619385, 0.3985683023929596, 0.4233957529067993, 0.3963572680950165, 0.4108303189277649, 0.4060945510864258, 0.4003557860851288, 0.3995124101638794, 0.3975397050380707, 0.40076860785484314, 0.3984987437725067, 0.4016736149787903, 0.40368932485580444, 0.40944600105285645, 0.40158721804618835, 0.48614832758903503, 0.39741456508636475, 0.39860203862190247, 0.4004918038845062, 0.3997077941894531, 0.4087686538696289, 0.4073408246040344, 0.41991111636161804, 0.41235587000846863, 0.4231770932674408, 0.41832202672958374, 0.40438196063041687, 0.4065735340118408, 0.41062065958976746, 0.42661306262016296, 0.40783435106277466, 0.41577431559562683, 0.42774805426597595, 0.40764012932777405, 0.4760759770870209, 0.41136375069618225, 0.4125067889690399, 0.41486093401908875, 0.4190397262573242, 0.4136059880256653, 0.4169488251209259, 0.415359228849411, 0.420868456363678, 0.43198442459106445, 0.4846348166465759, 0.4182787537574768, 0.4163622260093689, 0.41768524050712585, 0.42366495728492737, 0.4497029483318329, 0.4839347302913666], 'val_accuracy': [0.740899384021759, 0.7494646906852722, 0.7387580275535583, 0.7291220426559448, 0.7730192542076111, 0.7933619022369385, 0.7430406808853149, 0.7451820373535156, 0.7548179626464844, 0.8019272089004517, 0.7912205457687378, 0.799785852432251, 0.8083511590957642, 0.8137044906616211, 0.8158458471298218, 0.8115631937980652, 0.8147751688957214, 0.8094218373298645, 0.8169164657592773, 0.819057822227478, 0.8211991190910339, 0.8211991190910339, 0.8211991190910339, 0.8265524506568909, 0.8308351039886475, 0.8308351039886475, 0.8297644257545471, 0.8276231288909912, 0.8319057822227478, 0.8169164657592773, 0.8297644257545471, 0.8297644257545471, 0.8308351039886475, 0.8265524506568909, 0.8329764604568481, 0.8297644257545471, 0.8276231288909912, 0.8329764604568481, 0.8265524506568909, 0.8340471386909485, 0.835117757320404, 0.8319057822227478, 0.8329764604568481, 0.8276231288909912, 0.8340471386909485, 0.8340471386909485, 0.8265524506568909, 0.8233404755592346, 0.819057822227478, 0.8233404755592346, 0.835117757320404, 0.8147751688957214, 0.835117757320404, 0.824411153793335, 0.8276231288909912, 0.835117757320404, 0.835117757320404, 0.8394004106521606, 0.8308351039886475, 0.8372591137886047, 0.835117757320404, 0.8383297920227051, 0.8308351039886475, 0.8394004106521606, 0.8019272089004517, 0.8361884355545044, 0.8383297920227051, 0.8415417671203613, 0.8415417671203613, 0.8319057822227478, 0.835117757320404, 0.8179871439933777, 0.8297644257545471, 0.8254817724227905, 0.8308351039886475, 0.8415417671203613, 0.8415417671203613, 0.8383297920227051, 0.8276231288909912, 0.8415417671203613, 0.8254817724227905, 0.8254817724227905, 0.840471088886261, 0.8083511590957642, 0.8426124453544617, 0.8436830639839172, 0.8415417671203613, 0.8415417671203613, 0.8447537422180176, 0.8490363955497742, 0.8383297920227051, 0.835117757320404, 0.819057822227478, 0.8126338124275208, 0.8329764604568481, 0.8415417671203613, 0.8415417671203613, 0.8340471386909485, 0.8222697973251343, 0.8094218373298645]}\n","37/37 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 10s 55ms/step - loss: 0.2842 - accuracy: 0.8821 - val_loss: 0.6723 - val_accuracy: 0.7045\n","Epoch 2/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2566 - accuracy: 0.9054 - val_loss: 0.6670 - val_accuracy: 0.7869\n","Epoch 3/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2575 - accuracy: 0.8990 - val_loss: 0.6633 - val_accuracy: 0.7762\n","Epoch 4/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2516 - accuracy: 0.9012 - val_loss: 0.6583 - val_accuracy: 0.7719\n","Epoch 5/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2495 - accuracy: 0.9057 - val_loss: 0.6502 - val_accuracy: 0.8009\n","Epoch 6/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2557 - accuracy: 0.9041 - val_loss: 0.6437 - val_accuracy: 0.8062\n","Epoch 7/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2450 - accuracy: 0.9076 - val_loss: 0.6340 - val_accuracy: 0.8084\n","Epoch 8/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2390 - accuracy: 0.9153 - val_loss: 0.6234 - val_accuracy: 0.8105\n","Epoch 9/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2387 - accuracy: 0.9137 - val_loss: 0.6100 - val_accuracy: 0.7976\n","Epoch 10/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2341 - accuracy: 0.9188 - val_loss: 0.5928 - val_accuracy: 0.8041\n","Epoch 11/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2380 - accuracy: 0.9151 - val_loss: 0.5754 - val_accuracy: 0.8094\n","Epoch 12/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2367 - accuracy: 0.9060 - val_loss: 0.5588 - val_accuracy: 0.7987\n","Epoch 13/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2371 - accuracy: 0.9119 - val_loss: 0.5316 - val_accuracy: 0.8158\n","Epoch 14/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2300 - accuracy: 0.9127 - val_loss: 0.5079 - val_accuracy: 0.8137\n","Epoch 15/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.2317 - accuracy: 0.9137 - val_loss: 0.4801 - val_accuracy: 0.8191\n","Epoch 16/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.2292 - accuracy: 0.9167 - val_loss: 0.4685 - val_accuracy: 0.8116\n","Epoch 17/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2162 - accuracy: 0.9194 - val_loss: 0.4337 - val_accuracy: 0.8169\n","Epoch 18/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2102 - accuracy: 0.9245 - val_loss: 0.4169 - val_accuracy: 0.8244\n","Epoch 19/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.2284 - accuracy: 0.9140 - val_loss: 0.4073 - val_accuracy: 0.8233\n","Epoch 20/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2196 - accuracy: 0.9183 - val_loss: 0.4173 - val_accuracy: 0.8180\n","Epoch 21/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2274 - accuracy: 0.9119 - val_loss: 0.4132 - val_accuracy: 0.8201\n","Epoch 22/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2213 - accuracy: 0.9191 - val_loss: 0.3880 - val_accuracy: 0.8276\n","Epoch 23/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2346 - accuracy: 0.9121 - val_loss: 0.3843 - val_accuracy: 0.8330\n","Epoch 24/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2057 - accuracy: 0.9255 - val_loss: 0.3871 - val_accuracy: 0.8362\n","Epoch 25/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2112 - accuracy: 0.9223 - val_loss: 0.4014 - val_accuracy: 0.8362\n","Epoch 26/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2018 - accuracy: 0.9271 - val_loss: 0.3994 - val_accuracy: 0.8351\n","Epoch 27/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2070 - accuracy: 0.9258 - val_loss: 0.4070 - val_accuracy: 0.8340\n","Epoch 28/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2064 - accuracy: 0.9239 - val_loss: 0.4154 - val_accuracy: 0.8330\n","Epoch 29/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1953 - accuracy: 0.9293 - val_loss: 0.4351 - val_accuracy: 0.8266\n","Epoch 30/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2037 - accuracy: 0.9250 - val_loss: 0.4516 - val_accuracy: 0.8351\n","Epoch 31/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2023 - accuracy: 0.9290 - val_loss: 0.4410 - val_accuracy: 0.8330\n","Epoch 32/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2014 - accuracy: 0.9301 - val_loss: 0.4297 - val_accuracy: 0.8351\n","Epoch 33/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1985 - accuracy: 0.9317 - val_loss: 0.4435 - val_accuracy: 0.8244\n","Epoch 34/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1917 - accuracy: 0.9325 - val_loss: 0.4364 - val_accuracy: 0.8362\n","Epoch 35/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1933 - accuracy: 0.9304 - val_loss: 0.4354 - val_accuracy: 0.8351\n","Epoch 36/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1861 - accuracy: 0.9379 - val_loss: 0.4504 - val_accuracy: 0.8362\n","Epoch 37/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1844 - accuracy: 0.9389 - val_loss: 0.4439 - val_accuracy: 0.8308\n","Epoch 38/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1917 - accuracy: 0.9346 - val_loss: 0.4506 - val_accuracy: 0.8244\n","Epoch 39/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2018 - accuracy: 0.9239 - val_loss: 0.4480 - val_accuracy: 0.8330\n","Epoch 40/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.1936 - accuracy: 0.9317 - val_loss: 0.4488 - val_accuracy: 0.8319\n","Epoch 41/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1844 - accuracy: 0.9328 - val_loss: 0.4465 - val_accuracy: 0.8319\n","Epoch 42/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1729 - accuracy: 0.9411 - val_loss: 0.4556 - val_accuracy: 0.8319\n","Epoch 43/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1749 - accuracy: 0.9395 - val_loss: 0.4769 - val_accuracy: 0.8298\n","Epoch 44/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1732 - accuracy: 0.9389 - val_loss: 0.4618 - val_accuracy: 0.8287\n","Epoch 45/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1736 - accuracy: 0.9440 - val_loss: 0.4652 - val_accuracy: 0.8255\n","Epoch 46/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1726 - accuracy: 0.9440 - val_loss: 0.4639 - val_accuracy: 0.8276\n","Epoch 47/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1696 - accuracy: 0.9443 - val_loss: 0.4978 - val_accuracy: 0.8180\n","Epoch 48/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1717 - accuracy: 0.9421 - val_loss: 0.4854 - val_accuracy: 0.8201\n","Epoch 49/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1674 - accuracy: 0.9424 - val_loss: 0.4670 - val_accuracy: 0.8223\n","Epoch 50/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1730 - accuracy: 0.9365 - val_loss: 0.4721 - val_accuracy: 0.8319\n","Epoch 51/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1693 - accuracy: 0.9435 - val_loss: 0.4832 - val_accuracy: 0.8223\n","Epoch 52/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1576 - accuracy: 0.9467 - val_loss: 0.4770 - val_accuracy: 0.8244\n","Epoch 53/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1564 - accuracy: 0.9488 - val_loss: 0.4808 - val_accuracy: 0.8298\n","Epoch 54/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1640 - accuracy: 0.9464 - val_loss: 0.4780 - val_accuracy: 0.8308\n","Epoch 55/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1644 - accuracy: 0.9443 - val_loss: 0.4830 - val_accuracy: 0.8266\n","Epoch 56/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1515 - accuracy: 0.9518 - val_loss: 0.4859 - val_accuracy: 0.8266\n","Epoch 57/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1594 - accuracy: 0.9467 - val_loss: 0.5291 - val_accuracy: 0.8212\n","Epoch 58/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1614 - accuracy: 0.9451 - val_loss: 0.4953 - val_accuracy: 0.8223\n","Epoch 59/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1593 - accuracy: 0.9472 - val_loss: 0.4861 - val_accuracy: 0.8287\n","Epoch 60/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1525 - accuracy: 0.9520 - val_loss: 0.4878 - val_accuracy: 0.8276\n","Epoch 61/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1587 - accuracy: 0.9443 - val_loss: 0.4934 - val_accuracy: 0.8255\n","Epoch 62/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1549 - accuracy: 0.9448 - val_loss: 0.5027 - val_accuracy: 0.8169\n","Epoch 63/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1752 - accuracy: 0.9330 - val_loss: 0.5173 - val_accuracy: 0.8255\n","Epoch 64/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1450 - accuracy: 0.9553 - val_loss: 0.4873 - val_accuracy: 0.8276\n","Epoch 65/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1378 - accuracy: 0.9579 - val_loss: 0.5239 - val_accuracy: 0.8223\n","Epoch 66/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1349 - accuracy: 0.9545 - val_loss: 0.5657 - val_accuracy: 0.8180\n","Epoch 67/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1467 - accuracy: 0.9494 - val_loss: 0.5499 - val_accuracy: 0.8223\n","Epoch 68/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1403 - accuracy: 0.9558 - val_loss: 0.5497 - val_accuracy: 0.8223\n","Epoch 69/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1421 - accuracy: 0.9537 - val_loss: 0.5373 - val_accuracy: 0.8212\n","Epoch 70/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1386 - accuracy: 0.9545 - val_loss: 0.5314 - val_accuracy: 0.8244\n","Epoch 71/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1368 - accuracy: 0.9553 - val_loss: 0.5281 - val_accuracy: 0.8233\n","Epoch 72/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1286 - accuracy: 0.9601 - val_loss: 0.5683 - val_accuracy: 0.8158\n","Epoch 73/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1282 - accuracy: 0.9587 - val_loss: 0.5686 - val_accuracy: 0.8191\n","Epoch 74/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1559 - accuracy: 0.9462 - val_loss: 0.5814 - val_accuracy: 0.8212\n","Epoch 75/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1446 - accuracy: 0.9518 - val_loss: 0.5107 - val_accuracy: 0.8266\n","Epoch 76/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1265 - accuracy: 0.9609 - val_loss: 0.5150 - val_accuracy: 0.8223\n","Epoch 77/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1265 - accuracy: 0.9593 - val_loss: 0.5340 - val_accuracy: 0.8201\n","Epoch 78/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1266 - accuracy: 0.9555 - val_loss: 0.5282 - val_accuracy: 0.8298\n","Epoch 79/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1335 - accuracy: 0.9585 - val_loss: 0.5269 - val_accuracy: 0.8201\n","Epoch 80/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1280 - accuracy: 0.9566 - val_loss: 0.5279 - val_accuracy: 0.8180\n","Epoch 81/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1264 - accuracy: 0.9604 - val_loss: 0.5334 - val_accuracy: 0.8233\n","Epoch 82/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1356 - accuracy: 0.9529 - val_loss: 0.5276 - val_accuracy: 0.8201\n","Epoch 83/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1244 - accuracy: 0.9579 - val_loss: 0.5545 - val_accuracy: 0.8212\n","Epoch 84/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1195 - accuracy: 0.9625 - val_loss: 0.5687 - val_accuracy: 0.8244\n","Epoch 85/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1145 - accuracy: 0.9662 - val_loss: 0.5635 - val_accuracy: 0.8233\n","Epoch 86/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1232 - accuracy: 0.9604 - val_loss: 0.5948 - val_accuracy: 0.8233\n","Epoch 87/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1145 - accuracy: 0.9657 - val_loss: 0.5957 - val_accuracy: 0.8233\n","Epoch 88/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1157 - accuracy: 0.9625 - val_loss: 0.5598 - val_accuracy: 0.8233\n","Epoch 89/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1174 - accuracy: 0.9630 - val_loss: 0.5667 - val_accuracy: 0.8287\n","Epoch 90/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1090 - accuracy: 0.9662 - val_loss: 0.5682 - val_accuracy: 0.8255\n","Epoch 91/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1087 - accuracy: 0.9679 - val_loss: 0.5692 - val_accuracy: 0.8201\n","Epoch 92/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1075 - accuracy: 0.9665 - val_loss: 0.5631 - val_accuracy: 0.8191\n","Epoch 93/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1174 - accuracy: 0.9625 - val_loss: 0.5644 - val_accuracy: 0.8298\n","Epoch 94/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1225 - accuracy: 0.9612 - val_loss: 0.5630 - val_accuracy: 0.8223\n","Epoch 95/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1023 - accuracy: 0.9719 - val_loss: 0.5572 - val_accuracy: 0.8266\n","Epoch 96/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1067 - accuracy: 0.9684 - val_loss: 0.5643 - val_accuracy: 0.8233\n","Epoch 97/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1047 - accuracy: 0.9676 - val_loss: 0.5592 - val_accuracy: 0.8266\n","Epoch 98/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1076 - accuracy: 0.9649 - val_loss: 0.5768 - val_accuracy: 0.8212\n","Epoch 99/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1170 - accuracy: 0.9614 - val_loss: 0.5899 - val_accuracy: 0.8244\n","Epoch 100/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1094 - accuracy: 0.9654 - val_loss: 0.7647 - val_accuracy: 0.7912\n","{'loss': [0.28418585658073425, 0.25659725069999695, 0.2575030028820038, 0.2516458332538605, 0.2494608461856842, 0.2557145357131958, 0.24503766000270844, 0.2389940619468689, 0.23866038024425507, 0.23411856591701508, 0.2380191534757614, 0.23665952682495117, 0.2370753139257431, 0.2299787849187851, 0.2316574901342392, 0.22924481332302094, 0.21618671715259552, 0.21019038558006287, 0.22835151851177216, 0.21960337460041046, 0.22736407816410065, 0.22125175595283508, 0.23455524444580078, 0.2057047188282013, 0.21124665439128876, 0.2018364667892456, 0.20695838332176208, 0.20639657974243164, 0.19533342123031616, 0.20374968647956848, 0.20232342183589935, 0.2014336884021759, 0.19847045838832855, 0.19172373414039612, 0.19325348734855652, 0.18613053858280182, 0.1844141185283661, 0.19173097610473633, 0.2017642706632614, 0.19361530244350433, 0.18438293039798737, 0.17285531759262085, 0.17491421103477478, 0.1732286959886551, 0.17361615598201752, 0.17260606586933136, 0.16963735222816467, 0.17174217104911804, 0.1673857718706131, 0.17303195595741272, 0.1692628264427185, 0.15760178864002228, 0.1563551276922226, 0.1640259176492691, 0.16444732248783112, 0.15149250626564026, 0.1593974530696869, 0.16135655343532562, 0.15926086902618408, 0.15250499546527863, 0.15872642397880554, 0.15490420162677765, 0.17524537444114685, 0.14502257108688354, 0.13777261972427368, 0.13487395644187927, 0.14670084416866302, 0.1403341442346573, 0.14211392402648926, 0.13855589926242828, 0.13679812848567963, 0.12857253849506378, 0.12816882133483887, 0.15592992305755615, 0.14461380243301392, 0.1265106499195099, 0.12649857997894287, 0.12655599415302277, 0.13345882296562195, 0.1279868632555008, 0.12644989788532257, 0.13558033108711243, 0.12439727783203125, 0.11948760598897934, 0.11449019610881805, 0.12321678549051285, 0.11446956545114517, 0.11572617292404175, 0.11742542684078217, 0.10903174430131912, 0.10872843861579895, 0.10752930492162704, 0.11741837859153748, 0.12252494692802429, 0.10225366801023483, 0.10666429996490479, 0.10469323396682739, 0.10763110220432281, 0.11704065650701523, 0.10944376140832901], 'accuracy': [0.882132351398468, 0.9054380059242249, 0.8990088105201721, 0.9011518955230713, 0.9057058691978455, 0.9040985703468323, 0.9075810313224792, 0.9153496026992798, 0.9137423038482666, 0.9188320636749268, 0.9150816798210144, 0.9059737324714661, 0.9118671417236328, 0.9126707911491394, 0.9137423038482666, 0.9166889786720276, 0.919367790222168, 0.9244575500488281, 0.9140101671218872, 0.9182962775230408, 0.9118671417236328, 0.9190999269485474, 0.9121350049972534, 0.9255290627479553, 0.922314465045929, 0.9271363615989685, 0.9257969260215759, 0.9239217638969421, 0.9292793869972229, 0.9249932765960693, 0.9290115237236023, 0.9300830364227295, 0.9316903352737427, 0.9324939846992493, 0.9303508996963501, 0.93785160779953, 0.9389231204986572, 0.9346370100975037, 0.9239217638969421, 0.9316903352737427, 0.9327618479728699, 0.9410661458969116, 0.9394589066505432, 0.9389231204986572, 0.9440128803253174, 0.9440128803253174, 0.944280743598938, 0.9421377182006836, 0.9424055814743042, 0.9365121722221375, 0.9434770941734314, 0.9466916918754578, 0.9488347172737122, 0.9464237689971924, 0.944280743598938, 0.9517813920974731, 0.9466916918754578, 0.9450843930244446, 0.947227418422699, 0.9520493149757385, 0.944280743598938, 0.944816529750824, 0.9330297112464905, 0.9552638530731201, 0.9579426646232605, 0.9544602036476135, 0.9493705034255981, 0.9557996392250061, 0.9536565542221069, 0.9544602036476135, 0.9552638530731201, 0.9600857496261597, 0.9587463140487671, 0.9461559057235718, 0.9517813920974731, 0.9608893394470215, 0.9592821002006531, 0.9555317163467407, 0.9584784507751465, 0.9566032886505127, 0.9603536128997803, 0.9528529047966003, 0.9579426646232605, 0.9624966382980347, 0.9662469625473022, 0.9603536128997803, 0.965711236000061, 0.9624966382980347, 0.9630324244499207, 0.9662469625473022, 0.9678542613983154, 0.9665148854255676, 0.9624966382980347, 0.9611572623252869, 0.9718725085258484, 0.9683900475502014, 0.9675863981246948, 0.9649075865745544, 0.9614251255989075, 0.9654433727264404], 'val_loss': [0.6722986102104187, 0.6670364737510681, 0.6632549166679382, 0.6582537293434143, 0.6501889824867249, 0.6437179446220398, 0.633990466594696, 0.6234461665153503, 0.6099544167518616, 0.5928160548210144, 0.5753742456436157, 0.5587632656097412, 0.5316303968429565, 0.5078807473182678, 0.4800734221935272, 0.46845972537994385, 0.43374520540237427, 0.4169120788574219, 0.4072691798210144, 0.41733524203300476, 0.4132298231124878, 0.3880051374435425, 0.38427433371543884, 0.38711777329444885, 0.4014129340648651, 0.3993963599205017, 0.4070053696632385, 0.41539886593818665, 0.43513888120651245, 0.45160678029060364, 0.4410078525543213, 0.4297281801700592, 0.4435006380081177, 0.43642544746398926, 0.4353727400302887, 0.4504309892654419, 0.4439031183719635, 0.4505804181098938, 0.44799697399139404, 0.44876033067703247, 0.44647544622421265, 0.4556024372577667, 0.4768765866756439, 0.46184754371643066, 0.4652373790740967, 0.463876873254776, 0.4977985918521881, 0.4854114353656769, 0.46699053049087524, 0.4721195101737976, 0.483232319355011, 0.4769889712333679, 0.48076343536376953, 0.47803017497062683, 0.48296689987182617, 0.4859398603439331, 0.5291301012039185, 0.4952707886695862, 0.4861026704311371, 0.4877565801143646, 0.4933810532093048, 0.5026856064796448, 0.5172961354255676, 0.48734432458877563, 0.5239187479019165, 0.5657118558883667, 0.5498797297477722, 0.5497332215309143, 0.537288248538971, 0.531445324420929, 0.5281374454498291, 0.568274974822998, 0.568554699420929, 0.5813712477684021, 0.5106658935546875, 0.515036940574646, 0.5340424180030823, 0.5281701683998108, 0.5268587470054626, 0.5279362797737122, 0.5334336161613464, 0.5276191234588623, 0.5545043349266052, 0.5687222480773926, 0.5634667873382568, 0.594778835773468, 0.5956827402114868, 0.559830904006958, 0.5666998624801636, 0.5681746602058411, 0.5691879391670227, 0.5630561709403992, 0.5643838047981262, 0.5629966855049133, 0.5572100877761841, 0.564286470413208, 0.5592316389083862, 0.576819896697998, 0.5898860096931458, 0.764710009098053], 'val_accuracy': [0.7044968008995056, 0.7869378924369812, 0.7762312889099121, 0.7719486355781555, 0.8008565306663513, 0.8062098622322083, 0.8083511590957642, 0.8104925155639648, 0.7976445555686951, 0.8040685057640076, 0.8094218373298645, 0.7987151741981506, 0.8158458471298218, 0.8137044906616211, 0.819057822227478, 0.8115631937980652, 0.8169164657592773, 0.824411153793335, 0.8233404755592346, 0.8179871439933777, 0.8201285004615784, 0.8276231288909912, 0.8329764604568481, 0.8361884355545044, 0.8361884355545044, 0.835117757320404, 0.8340471386909485, 0.8329764604568481, 0.8265524506568909, 0.835117757320404, 0.8329764604568481, 0.835117757320404, 0.824411153793335, 0.8361884355545044, 0.835117757320404, 0.8361884355545044, 0.8308351039886475, 0.824411153793335, 0.8329764604568481, 0.8319057822227478, 0.8319057822227478, 0.8319057822227478, 0.8297644257545471, 0.8286938071250916, 0.8254817724227905, 0.8276231288909912, 0.8179871439933777, 0.8201285004615784, 0.8222697973251343, 0.8319057822227478, 0.8222697973251343, 0.824411153793335, 0.8297644257545471, 0.8308351039886475, 0.8265524506568909, 0.8265524506568909, 0.8211991190910339, 0.8222697973251343, 0.8286938071250916, 0.8276231288909912, 0.8254817724227905, 0.8169164657592773, 0.8254817724227905, 0.8276231288909912, 0.8222697973251343, 0.8179871439933777, 0.8222697973251343, 0.8222697973251343, 0.8211991190910339, 0.824411153793335, 0.8233404755592346, 0.8158458471298218, 0.819057822227478, 0.8211991190910339, 0.8265524506568909, 0.8222697973251343, 0.8201285004615784, 0.8297644257545471, 0.8201285004615784, 0.8179871439933777, 0.8233404755592346, 0.8201285004615784, 0.8211991190910339, 0.824411153793335, 0.8233404755592346, 0.8233404755592346, 0.8233404755592346, 0.8233404755592346, 0.8286938071250916, 0.8254817724227905, 0.8201285004615784, 0.819057822227478, 0.8297644257545471, 0.8222697973251343, 0.8265524506568909, 0.8233404755592346, 0.8265524506568909, 0.8211991190910339, 0.824411153793335, 0.7912205457687378]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 51ms/step - loss: 0.2740 - accuracy: 0.8910 - val_loss: 0.6716 - val_accuracy: 0.7238\n","Epoch 2/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2640 - accuracy: 0.8934 - val_loss: 0.6670 - val_accuracy: 0.7784\n","Epoch 3/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2624 - accuracy: 0.8955 - val_loss: 0.6631 - val_accuracy: 0.7859\n","Epoch 4/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2578 - accuracy: 0.9068 - val_loss: 0.6561 - val_accuracy: 0.7859\n","Epoch 5/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2546 - accuracy: 0.9022 - val_loss: 0.6500 - val_accuracy: 0.8084\n","Epoch 6/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2529 - accuracy: 0.9057 - val_loss: 0.6414 - val_accuracy: 0.8009\n","Epoch 7/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2500 - accuracy: 0.9038 - val_loss: 0.6295 - val_accuracy: 0.8340\n","Epoch 8/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2771 - accuracy: 0.8888 - val_loss: 0.6182 - val_accuracy: 0.8340\n","Epoch 9/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2425 - accuracy: 0.9097 - val_loss: 0.6063 - val_accuracy: 0.8201\n","Epoch 10/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2454 - accuracy: 0.9065 - val_loss: 0.5902 - val_accuracy: 0.8169\n","Epoch 11/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2475 - accuracy: 0.9020 - val_loss: 0.5692 - val_accuracy: 0.8405\n","Epoch 12/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2371 - accuracy: 0.9089 - val_loss: 0.5489 - val_accuracy: 0.8287\n","Epoch 13/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2439 - accuracy: 0.9076 - val_loss: 0.5185 - val_accuracy: 0.8394\n","Epoch 14/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2427 - accuracy: 0.9084 - val_loss: 0.4922 - val_accuracy: 0.8501\n","Epoch 15/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.2286 - accuracy: 0.9212 - val_loss: 0.4621 - val_accuracy: 0.8480\n","Epoch 16/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2258 - accuracy: 0.9178 - val_loss: 0.4283 - val_accuracy: 0.8533\n","Epoch 17/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.2271 - accuracy: 0.9196 - val_loss: 0.4050 - val_accuracy: 0.8576\n","Epoch 18/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.2199 - accuracy: 0.9231 - val_loss: 0.3728 - val_accuracy: 0.8619\n","Epoch 19/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2269 - accuracy: 0.9145 - val_loss: 0.3534 - val_accuracy: 0.8597\n","Epoch 20/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.2234 - accuracy: 0.9194 - val_loss: 0.3518 - val_accuracy: 0.8490\n","Epoch 21/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2285 - accuracy: 0.9129 - val_loss: 0.3372 - val_accuracy: 0.8565\n","Epoch 22/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2156 - accuracy: 0.9202 - val_loss: 0.3156 - val_accuracy: 0.8683\n","Epoch 23/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2198 - accuracy: 0.9210 - val_loss: 0.3142 - val_accuracy: 0.8683\n","Epoch 24/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2140 - accuracy: 0.9178 - val_loss: 0.4069 - val_accuracy: 0.8330\n","Epoch 25/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2671 - accuracy: 0.8979 - val_loss: 0.3411 - val_accuracy: 0.8533\n","Epoch 26/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2130 - accuracy: 0.9212 - val_loss: 0.3104 - val_accuracy: 0.8662\n","Epoch 27/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2068 - accuracy: 0.9245 - val_loss: 0.3150 - val_accuracy: 0.8683\n","Epoch 28/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2048 - accuracy: 0.9242 - val_loss: 0.3473 - val_accuracy: 0.8555\n","Epoch 29/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2111 - accuracy: 0.9207 - val_loss: 0.3230 - val_accuracy: 0.8608\n","Epoch 30/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2009 - accuracy: 0.9301 - val_loss: 0.3484 - val_accuracy: 0.8533\n","Epoch 31/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2033 - accuracy: 0.9247 - val_loss: 0.3251 - val_accuracy: 0.8672\n","Epoch 32/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2056 - accuracy: 0.9247 - val_loss: 0.3431 - val_accuracy: 0.8683\n","Epoch 33/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1987 - accuracy: 0.9325 - val_loss: 0.3297 - val_accuracy: 0.8662\n","Epoch 34/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1977 - accuracy: 0.9298 - val_loss: 0.3313 - val_accuracy: 0.8640\n","Epoch 35/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1944 - accuracy: 0.9336 - val_loss: 0.3393 - val_accuracy: 0.8576\n","Epoch 36/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1928 - accuracy: 0.9333 - val_loss: 0.3362 - val_accuracy: 0.8640\n","Epoch 37/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1879 - accuracy: 0.9349 - val_loss: 0.3348 - val_accuracy: 0.8608\n","Epoch 38/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1911 - accuracy: 0.9309 - val_loss: 0.3499 - val_accuracy: 0.8576\n","Epoch 39/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1965 - accuracy: 0.9287 - val_loss: 0.3386 - val_accuracy: 0.8683\n","Epoch 40/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.1900 - accuracy: 0.9330 - val_loss: 0.3387 - val_accuracy: 0.8630\n","Epoch 41/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1854 - accuracy: 0.9354 - val_loss: 0.3483 - val_accuracy: 0.8597\n","Epoch 42/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1869 - accuracy: 0.9346 - val_loss: 0.3426 - val_accuracy: 0.8640\n","Epoch 43/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1828 - accuracy: 0.9376 - val_loss: 0.3447 - val_accuracy: 0.8619\n","Epoch 44/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1811 - accuracy: 0.9360 - val_loss: 0.3511 - val_accuracy: 0.8597\n","Epoch 45/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1886 - accuracy: 0.9333 - val_loss: 0.3466 - val_accuracy: 0.8619\n","Epoch 46/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1782 - accuracy: 0.9373 - val_loss: 0.3617 - val_accuracy: 0.8565\n","Epoch 47/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1758 - accuracy: 0.9424 - val_loss: 0.3570 - val_accuracy: 0.8597\n","Epoch 48/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1722 - accuracy: 0.9400 - val_loss: 0.3523 - val_accuracy: 0.8630\n","Epoch 49/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1667 - accuracy: 0.9437 - val_loss: 0.3542 - val_accuracy: 0.8608\n","Epoch 50/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1731 - accuracy: 0.9360 - val_loss: 0.3578 - val_accuracy: 0.8597\n","Epoch 51/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1667 - accuracy: 0.9443 - val_loss: 0.3629 - val_accuracy: 0.8587\n","Epoch 52/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1671 - accuracy: 0.9413 - val_loss: 0.3579 - val_accuracy: 0.8597\n","Epoch 53/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1659 - accuracy: 0.9421 - val_loss: 0.3574 - val_accuracy: 0.8619\n","Epoch 54/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1689 - accuracy: 0.9419 - val_loss: 0.3640 - val_accuracy: 0.8576\n","Epoch 55/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1665 - accuracy: 0.9440 - val_loss: 0.4418 - val_accuracy: 0.8383\n","Epoch 56/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1827 - accuracy: 0.9295 - val_loss: 0.4412 - val_accuracy: 0.8448\n","Epoch 57/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1705 - accuracy: 0.9373 - val_loss: 0.3659 - val_accuracy: 0.8576\n","Epoch 58/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1600 - accuracy: 0.9470 - val_loss: 0.3736 - val_accuracy: 0.8565\n","Epoch 59/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1539 - accuracy: 0.9475 - val_loss: 0.3639 - val_accuracy: 0.8533\n","Epoch 60/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1598 - accuracy: 0.9419 - val_loss: 0.3636 - val_accuracy: 0.8565\n","Epoch 61/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1553 - accuracy: 0.9478 - val_loss: 0.4061 - val_accuracy: 0.8448\n","Epoch 62/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1639 - accuracy: 0.9445 - val_loss: 0.3738 - val_accuracy: 0.8597\n","Epoch 63/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1445 - accuracy: 0.9515 - val_loss: 0.3770 - val_accuracy: 0.8501\n","Epoch 64/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1472 - accuracy: 0.9526 - val_loss: 0.3715 - val_accuracy: 0.8576\n","Epoch 65/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1435 - accuracy: 0.9563 - val_loss: 0.3770 - val_accuracy: 0.8544\n","Epoch 66/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1471 - accuracy: 0.9502 - val_loss: 0.4109 - val_accuracy: 0.8437\n","Epoch 67/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1539 - accuracy: 0.9478 - val_loss: 0.3841 - val_accuracy: 0.8576\n","Epoch 68/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1469 - accuracy: 0.9478 - val_loss: 0.4465 - val_accuracy: 0.8469\n","Epoch 69/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1458 - accuracy: 0.9491 - val_loss: 0.3818 - val_accuracy: 0.8555\n","Epoch 70/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1379 - accuracy: 0.9563 - val_loss: 0.3825 - val_accuracy: 0.8555\n","Epoch 71/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1426 - accuracy: 0.9518 - val_loss: 0.4127 - val_accuracy: 0.8512\n","Epoch 72/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1420 - accuracy: 0.9520 - val_loss: 0.3892 - val_accuracy: 0.8544\n","Epoch 73/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1404 - accuracy: 0.9545 - val_loss: 0.3871 - val_accuracy: 0.8555\n","Epoch 74/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1275 - accuracy: 0.9598 - val_loss: 0.3935 - val_accuracy: 0.8533\n","Epoch 75/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1354 - accuracy: 0.9547 - val_loss: 0.3879 - val_accuracy: 0.8522\n","Epoch 76/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1298 - accuracy: 0.9590 - val_loss: 0.3861 - val_accuracy: 0.8512\n","Epoch 77/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1374 - accuracy: 0.9558 - val_loss: 0.3962 - val_accuracy: 0.8512\n","Epoch 78/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1181 - accuracy: 0.9636 - val_loss: 0.4013 - val_accuracy: 0.8544\n","Epoch 79/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1312 - accuracy: 0.9563 - val_loss: 0.4023 - val_accuracy: 0.8533\n","Epoch 80/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1283 - accuracy: 0.9601 - val_loss: 0.3968 - val_accuracy: 0.8512\n","Epoch 81/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1401 - accuracy: 0.9507 - val_loss: 0.4177 - val_accuracy: 0.8512\n","Epoch 82/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1252 - accuracy: 0.9590 - val_loss: 0.4061 - val_accuracy: 0.8533\n","Epoch 83/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1213 - accuracy: 0.9601 - val_loss: 0.3981 - val_accuracy: 0.8576\n","Epoch 84/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1266 - accuracy: 0.9593 - val_loss: 0.4137 - val_accuracy: 0.8555\n","Epoch 85/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1197 - accuracy: 0.9628 - val_loss: 0.4147 - val_accuracy: 0.8555\n","Epoch 86/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1192 - accuracy: 0.9641 - val_loss: 0.4185 - val_accuracy: 0.8533\n","Epoch 87/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1119 - accuracy: 0.9654 - val_loss: 0.4113 - val_accuracy: 0.8555\n","Epoch 88/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1149 - accuracy: 0.9636 - val_loss: 0.4135 - val_accuracy: 0.8544\n","Epoch 89/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1144 - accuracy: 0.9649 - val_loss: 0.4127 - val_accuracy: 0.8501\n","Epoch 90/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1143 - accuracy: 0.9628 - val_loss: 0.4335 - val_accuracy: 0.8512\n","Epoch 91/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1106 - accuracy: 0.9679 - val_loss: 0.4164 - val_accuracy: 0.8501\n","Epoch 92/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1168 - accuracy: 0.9609 - val_loss: 0.4395 - val_accuracy: 0.8544\n","Epoch 93/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1060 - accuracy: 0.9684 - val_loss: 0.4257 - val_accuracy: 0.8522\n","Epoch 94/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1068 - accuracy: 0.9665 - val_loss: 0.4226 - val_accuracy: 0.8565\n","Epoch 95/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1045 - accuracy: 0.9676 - val_loss: 0.4261 - val_accuracy: 0.8533\n","Epoch 96/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1116 - accuracy: 0.9654 - val_loss: 0.4244 - val_accuracy: 0.8512\n","Epoch 97/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1061 - accuracy: 0.9700 - val_loss: 0.4254 - val_accuracy: 0.8522\n","Epoch 98/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1008 - accuracy: 0.9695 - val_loss: 0.4304 - val_accuracy: 0.8512\n","Epoch 99/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1039 - accuracy: 0.9705 - val_loss: 0.4495 - val_accuracy: 0.8501\n","Epoch 100/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1011 - accuracy: 0.9692 - val_loss: 0.4622 - val_accuracy: 0.8512\n","{'loss': [0.27396321296691895, 0.26399940252304077, 0.2623828053474426, 0.257758766412735, 0.2545667886734009, 0.25289982557296753, 0.24995951354503632, 0.2770967185497284, 0.24250395596027374, 0.24536703526973724, 0.2475353628396988, 0.23706689476966858, 0.2438536137342453, 0.24265728890895844, 0.2285735309123993, 0.2257510870695114, 0.22708463668823242, 0.21990104019641876, 0.22691074013710022, 0.22340638935565948, 0.2284594625234604, 0.21555368602275848, 0.21981465816497803, 0.21395546197891235, 0.267091304063797, 0.21297508478164673, 0.20675455033779144, 0.20480303466320038, 0.2111327052116394, 0.20090991258621216, 0.20333243906497955, 0.20558059215545654, 0.19866082072257996, 0.19768022000789642, 0.19441697001457214, 0.1928359717130661, 0.18794377148151398, 0.1911485195159912, 0.1964629590511322, 0.19002175331115723, 0.18543434143066406, 0.1868939846754074, 0.1828494817018509, 0.181126669049263, 0.18856675922870636, 0.1782139390707016, 0.17583416402339935, 0.17218725383281708, 0.16674809157848358, 0.1730705350637436, 0.16666783392429352, 0.16710703074932098, 0.16585738956928253, 0.16889731585979462, 0.16648846864700317, 0.18269076943397522, 0.17050085961818695, 0.15999117493629456, 0.15392456948757172, 0.15979894995689392, 0.15530003607273102, 0.16389110684394836, 0.14452849328517914, 0.1471991389989853, 0.143485888838768, 0.1470910757780075, 0.1538579910993576, 0.14689099788665771, 0.1458457112312317, 0.13789290189743042, 0.14264552295207977, 0.1419840157032013, 0.1404428333044052, 0.12754635512828827, 0.1353815495967865, 0.12976287305355072, 0.13737887144088745, 0.11808369308710098, 0.1312008798122406, 0.12825925648212433, 0.14011098444461823, 0.12517181038856506, 0.12134970724582672, 0.12663355469703674, 0.11971182376146317, 0.11920059472322464, 0.11189161241054535, 0.11486632376909256, 0.11442852765321732, 0.11432363092899323, 0.11061399430036545, 0.11683395504951477, 0.10599740594625473, 0.10676930099725723, 0.10449466109275818, 0.11155489832162857, 0.10611224174499512, 0.10084262490272522, 0.10386452078819275, 0.10109858214855194], 'accuracy': [0.8909724354743958, 0.8933833241462708, 0.8955264091491699, 0.9067773818969727, 0.9022234082221985, 0.9057058691978455, 0.9038307070732117, 0.8888293504714966, 0.9097240567207336, 0.906509518623352, 0.9019555449485779, 0.9089204668998718, 0.9075810313224792, 0.9083846807479858, 0.9212429523468018, 0.9177604913711548, 0.9196356534957886, 0.9231181144714355, 0.9145459532737732, 0.919367790222168, 0.91293865442276, 0.9201714396476746, 0.9209750890731812, 0.9177604913711548, 0.8979372978210449, 0.9212429523468018, 0.9244575500488281, 0.9241896867752075, 0.9207072257995605, 0.9300830364227295, 0.9247254133224487, 0.9247254133224487, 0.9324939846992493, 0.9298151731491089, 0.9335654973983765, 0.9332976341247559, 0.9349048733711243, 0.9308866858482361, 0.9287436604499817, 0.9330297112464905, 0.9354406595230103, 0.9346370100975037, 0.9375836849212646, 0.9359764456748962, 0.9332976341247559, 0.937315821647644, 0.9424055814743042, 0.9399946331977844, 0.943744957447052, 0.9359764456748962, 0.944280743598938, 0.941334068775177, 0.9421377182006836, 0.9418697953224182, 0.9440128803253174, 0.9295473098754883, 0.937315821647644, 0.9469595551490784, 0.9474953413009644, 0.9418697953224182, 0.947763204574585, 0.9445486068725586, 0.9515135288238525, 0.9525850415229797, 0.9563353657722473, 0.95017409324646, 0.947763204574585, 0.947763204574585, 0.9491025805473328, 0.9563353657722473, 0.9517813920974731, 0.9520493149757385, 0.9544602036476135, 0.9598178267478943, 0.9547281265258789, 0.9590141773223877, 0.9557996392250061, 0.9635681509971619, 0.9563353657722473, 0.9600857496261597, 0.950709879398346, 0.9590141773223877, 0.9600857496261597, 0.9592821002006531, 0.9627645611763, 0.9641039371490479, 0.9654433727264404, 0.9635681509971619, 0.9649075865745544, 0.9627645611763, 0.9678542613983154, 0.9608893394470215, 0.9683900475502014, 0.9665148854255676, 0.9675863981246948, 0.9654433727264404, 0.9699973464012146, 0.9694615602493286, 0.9705330729484558, 0.969193696975708], 'val_loss': [0.6716097593307495, 0.6669698357582092, 0.6631067395210266, 0.6560876965522766, 0.6499788165092468, 0.6413500905036926, 0.6294597387313843, 0.618224024772644, 0.6062740087509155, 0.5902234315872192, 0.5692440867424011, 0.5489391684532166, 0.5185466408729553, 0.4921855330467224, 0.4621346890926361, 0.42834100127220154, 0.4050222337245941, 0.37278228998184204, 0.3534456491470337, 0.3518230617046356, 0.3372173011302948, 0.3155893087387085, 0.3141837418079376, 0.4069388210773468, 0.34107398986816406, 0.3103550970554352, 0.31501317024230957, 0.3473269045352936, 0.3230271637439728, 0.34844112396240234, 0.3251126706600189, 0.34309515357017517, 0.32969915866851807, 0.33127427101135254, 0.3393037021160126, 0.33624473214149475, 0.3347870409488678, 0.3499353528022766, 0.3385528028011322, 0.3387311100959778, 0.34826046228408813, 0.3425523340702057, 0.3447388708591461, 0.35107421875, 0.34662896394729614, 0.36167478561401367, 0.3569927215576172, 0.35231608152389526, 0.3542484939098358, 0.35776567459106445, 0.36285656690597534, 0.3578779399394989, 0.3574254512786865, 0.36399608850479126, 0.4418219327926636, 0.44116124510765076, 0.3658623993396759, 0.3735843896865845, 0.36394163966178894, 0.36360806226730347, 0.406074583530426, 0.37384963035583496, 0.3770468533039093, 0.37146300077438354, 0.37698638439178467, 0.4108502268791199, 0.38408002257347107, 0.4464949369430542, 0.381751149892807, 0.3825409412384033, 0.41271230578422546, 0.3891754150390625, 0.3870526850223541, 0.3935365080833435, 0.38792046904563904, 0.38607293367385864, 0.39619001746177673, 0.4013206362724304, 0.40230467915534973, 0.39684444665908813, 0.4176516830921173, 0.40611687302589417, 0.3981136083602905, 0.4137386679649353, 0.41471296548843384, 0.41845208406448364, 0.4112659990787506, 0.413504421710968, 0.41270390152931213, 0.433525025844574, 0.4163660407066345, 0.4394742250442505, 0.4257145822048187, 0.42258891463279724, 0.42610928416252136, 0.4244304597377777, 0.42535459995269775, 0.43037477135658264, 0.44945618510246277, 0.4622285068035126], 'val_accuracy': [0.7237687110900879, 0.778372585773468, 0.7858672142028809, 0.7858672142028809, 0.8083511590957642, 0.8008565306663513, 0.8340471386909485, 0.8340471386909485, 0.8201285004615784, 0.8169164657592773, 0.840471088886261, 0.8286938071250916, 0.8394004106521606, 0.8501070737838745, 0.8479657173156738, 0.8533190488815308, 0.8576017022132874, 0.861884355545044, 0.859743058681488, 0.8490363955497742, 0.856531023979187, 0.8683083653450012, 0.8683083653450012, 0.8329764604568481, 0.8533190488815308, 0.8661670088768005, 0.8683083653450012, 0.8554604053497314, 0.8608136773109436, 0.8533190488815308, 0.8672376871109009, 0.8683083653450012, 0.8661670088768005, 0.8640257120132446, 0.8576017022132874, 0.8640257120132446, 0.8608136773109436, 0.8576017022132874, 0.8683083653450012, 0.8629550337791443, 0.859743058681488, 0.8640257120132446, 0.861884355545044, 0.859743058681488, 0.861884355545044, 0.856531023979187, 0.859743058681488, 0.8629550337791443, 0.8608136773109436, 0.859743058681488, 0.8586723804473877, 0.859743058681488, 0.861884355545044, 0.8576017022132874, 0.8383297920227051, 0.8447537422180176, 0.8576017022132874, 0.856531023979187, 0.8533190488815308, 0.856531023979187, 0.8447537422180176, 0.859743058681488, 0.8501070737838745, 0.8576017022132874, 0.8543897271156311, 0.8436830639839172, 0.8576017022132874, 0.8468950986862183, 0.8554604053497314, 0.8554604053497314, 0.8511777520179749, 0.8543897271156311, 0.8554604053497314, 0.8533190488815308, 0.8522483706474304, 0.8511777520179749, 0.8511777520179749, 0.8543897271156311, 0.8533190488815308, 0.8511777520179749, 0.8511777520179749, 0.8533190488815308, 0.8576017022132874, 0.8554604053497314, 0.8554604053497314, 0.8533190488815308, 0.8554604053497314, 0.8543897271156311, 0.8501070737838745, 0.8511777520179749, 0.8501070737838745, 0.8543897271156311, 0.8522483706474304, 0.856531023979187, 0.8533190488815308, 0.8511777520179749, 0.8522483706474304, 0.8511777520179749, 0.8501070737838745, 0.8511777520179749]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 53ms/step - loss: 0.2794 - accuracy: 0.8856 - val_loss: 0.6707 - val_accuracy: 0.7687\n","Epoch 2/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2682 - accuracy: 0.8904 - val_loss: 0.6670 - val_accuracy: 0.7966\n","Epoch 3/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2621 - accuracy: 0.8937 - val_loss: 0.6625 - val_accuracy: 0.7869\n","Epoch 4/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2616 - accuracy: 0.8937 - val_loss: 0.6573 - val_accuracy: 0.7976\n","Epoch 5/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2607 - accuracy: 0.8961 - val_loss: 0.6506 - val_accuracy: 0.7891\n","Epoch 6/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2561 - accuracy: 0.8971 - val_loss: 0.6428 - val_accuracy: 0.8158\n","Epoch 7/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2498 - accuracy: 0.9009 - val_loss: 0.6322 - val_accuracy: 0.8137\n","Epoch 8/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2597 - accuracy: 0.8923 - val_loss: 0.6217 - val_accuracy: 0.7976\n","Epoch 9/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2462 - accuracy: 0.9052 - val_loss: 0.6076 - val_accuracy: 0.8223\n","Epoch 10/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2444 - accuracy: 0.9065 - val_loss: 0.5918 - val_accuracy: 0.8244\n","Epoch 11/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2395 - accuracy: 0.9054 - val_loss: 0.5732 - val_accuracy: 0.8212\n","Epoch 12/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.2436 - accuracy: 0.9057 - val_loss: 0.5528 - val_accuracy: 0.8298\n","Epoch 13/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.2328 - accuracy: 0.9087 - val_loss: 0.5319 - val_accuracy: 0.8212\n","Epoch 14/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2340 - accuracy: 0.9089 - val_loss: 0.4985 - val_accuracy: 0.8340\n","Epoch 15/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.2309 - accuracy: 0.9132 - val_loss: 0.4738 - val_accuracy: 0.8276\n","Epoch 16/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2388 - accuracy: 0.9095 - val_loss: 0.4519 - val_accuracy: 0.8233\n","Epoch 17/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.2327 - accuracy: 0.9148 - val_loss: 0.4172 - val_accuracy: 0.8340\n","Epoch 18/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2227 - accuracy: 0.9153 - val_loss: 0.3952 - val_accuracy: 0.8383\n","Epoch 19/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2235 - accuracy: 0.9132 - val_loss: 0.3693 - val_accuracy: 0.8426\n","Epoch 20/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2292 - accuracy: 0.9100 - val_loss: 0.3680 - val_accuracy: 0.8469\n","Epoch 21/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2222 - accuracy: 0.9156 - val_loss: 0.4005 - val_accuracy: 0.8340\n","Epoch 22/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2331 - accuracy: 0.9070 - val_loss: 0.3479 - val_accuracy: 0.8501\n","Epoch 23/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2195 - accuracy: 0.9151 - val_loss: 0.3328 - val_accuracy: 0.8576\n","Epoch 24/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2211 - accuracy: 0.9119 - val_loss: 0.3424 - val_accuracy: 0.8555\n","Epoch 25/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2105 - accuracy: 0.9215 - val_loss: 0.3237 - val_accuracy: 0.8608\n","Epoch 26/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2054 - accuracy: 0.9269 - val_loss: 0.3298 - val_accuracy: 0.8630\n","Epoch 27/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2076 - accuracy: 0.9231 - val_loss: 0.3291 - val_accuracy: 0.8672\n","Epoch 28/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2050 - accuracy: 0.9226 - val_loss: 0.3446 - val_accuracy: 0.8619\n","Epoch 29/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2042 - accuracy: 0.9250 - val_loss: 0.3438 - val_accuracy: 0.8640\n","Epoch 30/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2003 - accuracy: 0.9261 - val_loss: 0.3356 - val_accuracy: 0.8726\n","Epoch 31/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1999 - accuracy: 0.9298 - val_loss: 0.4065 - val_accuracy: 0.8383\n","Epoch 32/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2128 - accuracy: 0.9167 - val_loss: 0.3407 - val_accuracy: 0.8672\n","Epoch 33/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1944 - accuracy: 0.9336 - val_loss: 0.3446 - val_accuracy: 0.8683\n","Epoch 34/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1990 - accuracy: 0.9258 - val_loss: 0.3451 - val_accuracy: 0.8715\n","Epoch 35/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1873 - accuracy: 0.9352 - val_loss: 0.3740 - val_accuracy: 0.8619\n","Epoch 36/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1913 - accuracy: 0.9285 - val_loss: 0.3907 - val_accuracy: 0.8448\n","Epoch 37/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1952 - accuracy: 0.9312 - val_loss: 0.3484 - val_accuracy: 0.8662\n","Epoch 38/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.1867 - accuracy: 0.9346 - val_loss: 0.3605 - val_accuracy: 0.8533\n","Epoch 39/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1997 - accuracy: 0.9237 - val_loss: 0.3620 - val_accuracy: 0.8640\n","Epoch 40/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1834 - accuracy: 0.9357 - val_loss: 0.4463 - val_accuracy: 0.8340\n","Epoch 41/100\n","30/30 [==============================] - 1s 31ms/step - loss: 0.2082 - accuracy: 0.9188 - val_loss: 0.3608 - val_accuracy: 0.8683\n","Epoch 42/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1851 - accuracy: 0.9312 - val_loss: 0.3593 - val_accuracy: 0.8597\n","Epoch 43/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1835 - accuracy: 0.9336 - val_loss: 0.3614 - val_accuracy: 0.8597\n","Epoch 44/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1754 - accuracy: 0.9360 - val_loss: 0.3643 - val_accuracy: 0.8576\n","Epoch 45/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1739 - accuracy: 0.9416 - val_loss: 0.3586 - val_accuracy: 0.8651\n","Epoch 46/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1809 - accuracy: 0.9333 - val_loss: 0.3678 - val_accuracy: 0.8587\n","Epoch 47/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1811 - accuracy: 0.9314 - val_loss: 0.3568 - val_accuracy: 0.8704\n","Epoch 48/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1704 - accuracy: 0.9387 - val_loss: 0.3901 - val_accuracy: 0.8597\n","Epoch 49/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1696 - accuracy: 0.9392 - val_loss: 0.3653 - val_accuracy: 0.8608\n","Epoch 50/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1722 - accuracy: 0.9379 - val_loss: 0.3848 - val_accuracy: 0.8512\n","Epoch 51/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1603 - accuracy: 0.9432 - val_loss: 0.3641 - val_accuracy: 0.8683\n","Epoch 52/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1641 - accuracy: 0.9459 - val_loss: 0.3680 - val_accuracy: 0.8683\n","Epoch 53/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1666 - accuracy: 0.9397 - val_loss: 0.3880 - val_accuracy: 0.8630\n","Epoch 54/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1752 - accuracy: 0.9389 - val_loss: 0.3683 - val_accuracy: 0.8683\n","Epoch 55/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1567 - accuracy: 0.9459 - val_loss: 0.3704 - val_accuracy: 0.8683\n","Epoch 56/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1615 - accuracy: 0.9437 - val_loss: 0.3725 - val_accuracy: 0.8630\n","Epoch 57/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1664 - accuracy: 0.9365 - val_loss: 0.3700 - val_accuracy: 0.8672\n","Epoch 58/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1502 - accuracy: 0.9510 - val_loss: 0.3861 - val_accuracy: 0.8555\n","Epoch 59/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1450 - accuracy: 0.9515 - val_loss: 0.3771 - val_accuracy: 0.8672\n","Epoch 60/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1566 - accuracy: 0.9440 - val_loss: 0.3818 - val_accuracy: 0.8576\n","Epoch 61/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1762 - accuracy: 0.9322 - val_loss: 0.3854 - val_accuracy: 0.8576\n","Epoch 62/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1690 - accuracy: 0.9384 - val_loss: 0.3951 - val_accuracy: 0.8608\n","Epoch 63/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1531 - accuracy: 0.9456 - val_loss: 0.3815 - val_accuracy: 0.8651\n","Epoch 64/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1472 - accuracy: 0.9507 - val_loss: 0.4002 - val_accuracy: 0.8597\n","Epoch 65/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1495 - accuracy: 0.9467 - val_loss: 0.4230 - val_accuracy: 0.8565\n","Epoch 66/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1472 - accuracy: 0.9478 - val_loss: 0.4662 - val_accuracy: 0.8394\n","Epoch 67/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1615 - accuracy: 0.9397 - val_loss: 0.3927 - val_accuracy: 0.8662\n","Epoch 68/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1427 - accuracy: 0.9529 - val_loss: 0.4096 - val_accuracy: 0.8512\n","Epoch 69/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1565 - accuracy: 0.9445 - val_loss: 0.3825 - val_accuracy: 0.8587\n","Epoch 70/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1574 - accuracy: 0.9443 - val_loss: 0.3982 - val_accuracy: 0.8480\n","Epoch 71/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1437 - accuracy: 0.9491 - val_loss: 0.3905 - val_accuracy: 0.8555\n","Epoch 72/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1384 - accuracy: 0.9531 - val_loss: 0.3873 - val_accuracy: 0.8640\n","Epoch 73/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1406 - accuracy: 0.9523 - val_loss: 0.3895 - val_accuracy: 0.8683\n","Epoch 74/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1329 - accuracy: 0.9561 - val_loss: 0.3923 - val_accuracy: 0.8683\n","Epoch 75/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1264 - accuracy: 0.9577 - val_loss: 0.3978 - val_accuracy: 0.8662\n","Epoch 76/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1264 - accuracy: 0.9590 - val_loss: 0.3977 - val_accuracy: 0.8672\n","Epoch 77/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1307 - accuracy: 0.9579 - val_loss: 0.3975 - val_accuracy: 0.8662\n","Epoch 78/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1253 - accuracy: 0.9617 - val_loss: 0.4202 - val_accuracy: 0.8512\n","Epoch 79/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1222 - accuracy: 0.9612 - val_loss: 0.4668 - val_accuracy: 0.8319\n","Epoch 80/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1315 - accuracy: 0.9542 - val_loss: 0.4191 - val_accuracy: 0.8544\n","Epoch 81/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1208 - accuracy: 0.9617 - val_loss: 0.4211 - val_accuracy: 0.8662\n","Epoch 82/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1167 - accuracy: 0.9644 - val_loss: 0.4198 - val_accuracy: 0.8651\n","Epoch 83/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1202 - accuracy: 0.9585 - val_loss: 0.4183 - val_accuracy: 0.8619\n","Epoch 84/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1176 - accuracy: 0.9622 - val_loss: 0.4698 - val_accuracy: 0.8522\n","Epoch 85/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1365 - accuracy: 0.9518 - val_loss: 0.4086 - val_accuracy: 0.8672\n","Epoch 86/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1144 - accuracy: 0.9633 - val_loss: 0.4293 - val_accuracy: 0.8533\n","Epoch 87/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1191 - accuracy: 0.9593 - val_loss: 0.4361 - val_accuracy: 0.8533\n","Epoch 88/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1134 - accuracy: 0.9633 - val_loss: 0.4248 - val_accuracy: 0.8672\n","Epoch 89/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1098 - accuracy: 0.9644 - val_loss: 0.4316 - val_accuracy: 0.8651\n","Epoch 90/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1116 - accuracy: 0.9638 - val_loss: 0.4335 - val_accuracy: 0.8565\n","Epoch 91/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1201 - accuracy: 0.9630 - val_loss: 0.4408 - val_accuracy: 0.8544\n","Epoch 92/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1087 - accuracy: 0.9654 - val_loss: 0.4376 - val_accuracy: 0.8490\n","Epoch 93/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1101 - accuracy: 0.9665 - val_loss: 0.4476 - val_accuracy: 0.8555\n","Epoch 94/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1081 - accuracy: 0.9684 - val_loss: 0.4353 - val_accuracy: 0.8651\n","Epoch 95/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0992 - accuracy: 0.9711 - val_loss: 0.4688 - val_accuracy: 0.8405\n","Epoch 96/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1050 - accuracy: 0.9700 - val_loss: 0.4435 - val_accuracy: 0.8587\n","Epoch 97/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1049 - accuracy: 0.9668 - val_loss: 0.4605 - val_accuracy: 0.8458\n","Epoch 98/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1035 - accuracy: 0.9673 - val_loss: 0.4392 - val_accuracy: 0.8662\n","Epoch 99/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0956 - accuracy: 0.9713 - val_loss: 0.4507 - val_accuracy: 0.8651\n","Epoch 100/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1059 - accuracy: 0.9654 - val_loss: 0.4893 - val_accuracy: 0.8330\n","{'loss': [0.27943944931030273, 0.26818472146987915, 0.26209625601768494, 0.26163822412490845, 0.2607246935367584, 0.256090372800827, 0.24981427192687988, 0.2597198188304901, 0.24621173739433289, 0.24440878629684448, 0.2394581139087677, 0.24358470737934113, 0.23284579813480377, 0.23397953808307648, 0.23087316751480103, 0.23876486718654633, 0.23267729580402374, 0.2227272242307663, 0.2234705239534378, 0.22919407486915588, 0.22217194736003876, 0.23309451341629028, 0.21952475607395172, 0.22113579511642456, 0.2104586660861969, 0.20541974902153015, 0.20762932300567627, 0.20504459738731384, 0.20424111187458038, 0.20033110678195953, 0.19992944598197937, 0.2127717137336731, 0.1944192349910736, 0.1990257054567337, 0.187334343791008, 0.19125309586524963, 0.1952359825372696, 0.18670210242271423, 0.1997126191854477, 0.18344253301620483, 0.20819590985774994, 0.1850605458021164, 0.1834707260131836, 0.1753574013710022, 0.17388390004634857, 0.18092772364616394, 0.18110129237174988, 0.1703711599111557, 0.16964833438396454, 0.17215406894683838, 0.1602931171655655, 0.16407477855682373, 0.16662131249904633, 0.17517229914665222, 0.15668180584907532, 0.16145353019237518, 0.16644629836082458, 0.15020973980426788, 0.14501260221004486, 0.1566237211227417, 0.17616717517375946, 0.1689601093530655, 0.15312089025974274, 0.14717625081539154, 0.14950387179851532, 0.14719480276107788, 0.1614898443222046, 0.14270254969596863, 0.15654009580612183, 0.15737003087997437, 0.14365357160568237, 0.1383666694164276, 0.14057600498199463, 0.132925882935524, 0.12641744315624237, 0.12635166943073273, 0.13071508705615997, 0.1253497451543808, 0.1221882626414299, 0.13154204189777374, 0.12075718492269516, 0.11672092974185944, 0.12021037191152573, 0.11755890399217606, 0.1365266591310501, 0.11436072736978531, 0.11912950128316879, 0.11337895691394806, 0.10984300076961517, 0.11163344979286194, 0.12006045877933502, 0.10869447141885757, 0.11014063656330109, 0.1081225797533989, 0.09917094558477402, 0.10500286519527435, 0.10494919121265411, 0.10348883271217346, 0.09559210389852524, 0.10589079558849335], 'accuracy': [0.885614812374115, 0.8904366493225098, 0.8936512470245361, 0.8936512470245361, 0.8960621356964111, 0.8971336483955383, 0.9008840322494507, 0.8923118114471436, 0.9051700830459595, 0.906509518623352, 0.9054380059242249, 0.9057058691978455, 0.9086525440216064, 0.9089204668998718, 0.9132065176963806, 0.909456193447113, 0.9148138165473938, 0.9153496026992798, 0.9132065176963806, 0.909991979598999, 0.9156174659729004, 0.9070452451705933, 0.9150816798210144, 0.9118671417236328, 0.9215108752250671, 0.9268684983253479, 0.9231181144714355, 0.9225823879241943, 0.9249932765960693, 0.9260648488998413, 0.9298151731491089, 0.9166889786720276, 0.9335654973983765, 0.9257969260215759, 0.9351727962493896, 0.9284757375717163, 0.9311545491218567, 0.9346370100975037, 0.9236539006233215, 0.9357085227966309, 0.9188320636749268, 0.9311545491218567, 0.9335654973983765, 0.9359764456748962, 0.9416019320487976, 0.9332976341247559, 0.9314224720001221, 0.9386552572250366, 0.9391909837722778, 0.93785160779953, 0.9432092308998108, 0.9458880424499512, 0.9397267699241638, 0.9389231204986572, 0.9458880424499512, 0.943744957447052, 0.9365121722221375, 0.9509777426719666, 0.9515135288238525, 0.9440128803253174, 0.9322260618209839, 0.9383873343467712, 0.9456201195716858, 0.950709879398346, 0.9466916918754578, 0.947763204574585, 0.9397267699241638, 0.9528529047966003, 0.9445486068725586, 0.944280743598938, 0.9491025805473328, 0.9531208276748657, 0.9523171782493591, 0.9560675024986267, 0.9576748013496399, 0.9590141773223877, 0.9579426646232605, 0.9616929888725281, 0.9611572623252869, 0.9541923403739929, 0.9616929888725281, 0.9643718004226685, 0.9584784507751465, 0.9622287750244141, 0.9517813920974731, 0.9633002877235413, 0.9592821002006531, 0.9633002877235413, 0.9643718004226685, 0.9638360738754272, 0.9630324244499207, 0.9654433727264404, 0.9665148854255676, 0.9683900475502014, 0.9710688591003418, 0.9699973464012146, 0.9667827486991882, 0.9673185348510742, 0.9713367223739624, 0.9654433727264404], 'val_loss': [0.6706938743591309, 0.6670395135879517, 0.6625291705131531, 0.6572598814964294, 0.6506473422050476, 0.6427700519561768, 0.6322392225265503, 0.6216596364974976, 0.6076045632362366, 0.5917862057685852, 0.573199987411499, 0.5527829527854919, 0.5319002866744995, 0.49850112199783325, 0.47377902269363403, 0.451861172914505, 0.4171724319458008, 0.3952212333679199, 0.36929529905319214, 0.3680361211299896, 0.40045350790023804, 0.3479360044002533, 0.3327920436859131, 0.34235522150993347, 0.3237307369709015, 0.32981234788894653, 0.32910996675491333, 0.34457603096961975, 0.3438114821910858, 0.3356151580810547, 0.406536728143692, 0.3406502306461334, 0.34463953971862793, 0.3450649380683899, 0.37397390604019165, 0.39074137806892395, 0.3483632504940033, 0.3605015277862549, 0.3619667589664459, 0.44626083970069885, 0.3607737421989441, 0.35927826166152954, 0.36141711473464966, 0.36427149176597595, 0.3585506081581116, 0.36775141954421997, 0.3568307161331177, 0.3901400864124298, 0.36525583267211914, 0.38478460907936096, 0.3641154170036316, 0.36802807450294495, 0.38803380727767944, 0.3683162331581116, 0.37041381001472473, 0.37245720624923706, 0.37000572681427, 0.3861013948917389, 0.3771446645259857, 0.3818461298942566, 0.3853510022163391, 0.39510872960090637, 0.3815440237522125, 0.4002113938331604, 0.4229593276977539, 0.466169148683548, 0.3926873505115509, 0.4096128046512604, 0.3825182020664215, 0.39824211597442627, 0.3905153274536133, 0.3872703015804291, 0.3895379900932312, 0.39226505160331726, 0.39784252643585205, 0.39767903089523315, 0.39747223258018494, 0.4201867878437042, 0.46675801277160645, 0.41907525062561035, 0.4211369454860687, 0.419800728559494, 0.4183000922203064, 0.4697956144809723, 0.40856829285621643, 0.42929351329803467, 0.4361189603805542, 0.42483755946159363, 0.4316141903400421, 0.4335373640060425, 0.4407748281955719, 0.4376223683357239, 0.44759100675582886, 0.43525686860084534, 0.4687969386577606, 0.4435420036315918, 0.4605138301849365, 0.43924009799957275, 0.45074471831321716, 0.4892910420894623], 'val_accuracy': [0.7687366008758545, 0.7965738773345947, 0.7869378924369812, 0.7976445555686951, 0.7890792489051819, 0.8158458471298218, 0.8137044906616211, 0.7976445555686951, 0.8222697973251343, 0.824411153793335, 0.8211991190910339, 0.8297644257545471, 0.8211991190910339, 0.8340471386909485, 0.8276231288909912, 0.8233404755592346, 0.8340471386909485, 0.8383297920227051, 0.8426124453544617, 0.8468950986862183, 0.8340471386909485, 0.8501070737838745, 0.8576017022132874, 0.8554604053497314, 0.8608136773109436, 0.8629550337791443, 0.8672376871109009, 0.861884355545044, 0.8640257120132446, 0.8725910186767578, 0.8383297920227051, 0.8672376871109009, 0.8683083653450012, 0.8715203404426575, 0.861884355545044, 0.8447537422180176, 0.8661670088768005, 0.8533190488815308, 0.8640257120132446, 0.8340471386909485, 0.8683083653450012, 0.859743058681488, 0.859743058681488, 0.8576017022132874, 0.8650963306427002, 0.8586723804473877, 0.8704496622085571, 0.859743058681488, 0.8608136773109436, 0.8511777520179749, 0.8683083653450012, 0.8683083653450012, 0.8629550337791443, 0.8683083653450012, 0.8683083653450012, 0.8629550337791443, 0.8672376871109009, 0.8554604053497314, 0.8672376871109009, 0.8576017022132874, 0.8576017022132874, 0.8608136773109436, 0.8650963306427002, 0.859743058681488, 0.856531023979187, 0.8394004106521606, 0.8661670088768005, 0.8511777520179749, 0.8586723804473877, 0.8479657173156738, 0.8554604053497314, 0.8640257120132446, 0.8683083653450012, 0.8683083653450012, 0.8661670088768005, 0.8672376871109009, 0.8661670088768005, 0.8511777520179749, 0.8319057822227478, 0.8543897271156311, 0.8661670088768005, 0.8650963306427002, 0.861884355545044, 0.8522483706474304, 0.8672376871109009, 0.8533190488815308, 0.8533190488815308, 0.8672376871109009, 0.8650963306427002, 0.856531023979187, 0.8543897271156311, 0.8490363955497742, 0.8554604053497314, 0.8650963306427002, 0.840471088886261, 0.8586723804473877, 0.8458244204521179, 0.8661670088768005, 0.8650963306427002, 0.8329764604568481]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 53ms/step - loss: 0.1845 - accuracy: 0.9330 - val_loss: 0.6632 - val_accuracy: 0.7901\n","Epoch 2/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1655 - accuracy: 0.9437 - val_loss: 0.6584 - val_accuracy: 0.8137\n","Epoch 3/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1750 - accuracy: 0.9346 - val_loss: 0.6517 - val_accuracy: 0.8073\n","Epoch 4/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1500 - accuracy: 0.9510 - val_loss: 0.6458 - val_accuracy: 0.8148\n","Epoch 5/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1390 - accuracy: 0.9545 - val_loss: 0.6366 - val_accuracy: 0.8126\n","Epoch 6/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1454 - accuracy: 0.9518 - val_loss: 0.6266 - val_accuracy: 0.8116\n","Epoch 7/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1494 - accuracy: 0.9486 - val_loss: 0.6137 - val_accuracy: 0.8137\n","Epoch 8/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1417 - accuracy: 0.9512 - val_loss: 0.6037 - val_accuracy: 0.8116\n","Epoch 9/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1479 - accuracy: 0.9456 - val_loss: 0.5847 - val_accuracy: 0.8148\n","Epoch 10/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1350 - accuracy: 0.9561 - val_loss: 0.5650 - val_accuracy: 0.8105\n","Epoch 11/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1631 - accuracy: 0.9392 - val_loss: 0.5493 - val_accuracy: 0.8051\n","Epoch 12/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1356 - accuracy: 0.9550 - val_loss: 0.5215 - val_accuracy: 0.8223\n","Epoch 13/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1299 - accuracy: 0.9550 - val_loss: 0.4963 - val_accuracy: 0.8169\n","Epoch 14/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1240 - accuracy: 0.9614 - val_loss: 0.4640 - val_accuracy: 0.8233\n","Epoch 15/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1371 - accuracy: 0.9531 - val_loss: 0.4647 - val_accuracy: 0.8073\n","Epoch 16/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.1622 - accuracy: 0.9384 - val_loss: 0.4382 - val_accuracy: 0.8094\n","Epoch 17/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1426 - accuracy: 0.9491 - val_loss: 0.3968 - val_accuracy: 0.8330\n","Epoch 18/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1240 - accuracy: 0.9595 - val_loss: 0.3783 - val_accuracy: 0.8405\n","Epoch 19/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1245 - accuracy: 0.9612 - val_loss: 0.3700 - val_accuracy: 0.8373\n","Epoch 20/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1217 - accuracy: 0.9622 - val_loss: 0.3793 - val_accuracy: 0.8448\n","Epoch 21/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1160 - accuracy: 0.9609 - val_loss: 0.3924 - val_accuracy: 0.8405\n","Epoch 22/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1207 - accuracy: 0.9598 - val_loss: 0.3712 - val_accuracy: 0.8426\n","Epoch 23/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1159 - accuracy: 0.9644 - val_loss: 0.3798 - val_accuracy: 0.8448\n","Epoch 24/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1129 - accuracy: 0.9665 - val_loss: 0.3867 - val_accuracy: 0.8458\n","Epoch 25/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1155 - accuracy: 0.9620 - val_loss: 0.3955 - val_accuracy: 0.8576\n","Epoch 26/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1119 - accuracy: 0.9649 - val_loss: 0.4031 - val_accuracy: 0.8544\n","Epoch 27/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1149 - accuracy: 0.9641 - val_loss: 0.4187 - val_accuracy: 0.8480\n","Epoch 28/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1120 - accuracy: 0.9652 - val_loss: 0.4297 - val_accuracy: 0.8480\n","Epoch 29/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1135 - accuracy: 0.9652 - val_loss: 0.4556 - val_accuracy: 0.8480\n","Epoch 30/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1078 - accuracy: 0.9668 - val_loss: 0.4361 - val_accuracy: 0.8448\n","Epoch 31/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1120 - accuracy: 0.9649 - val_loss: 0.4641 - val_accuracy: 0.8522\n","Epoch 32/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1278 - accuracy: 0.9574 - val_loss: 0.4506 - val_accuracy: 0.8533\n","Epoch 33/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1152 - accuracy: 0.9598 - val_loss: 0.4507 - val_accuracy: 0.8351\n","Epoch 34/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1032 - accuracy: 0.9700 - val_loss: 0.4478 - val_accuracy: 0.8458\n","Epoch 35/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0986 - accuracy: 0.9729 - val_loss: 0.4676 - val_accuracy: 0.8437\n","Epoch 36/100\n","30/30 [==============================] - 1s 31ms/step - loss: 0.0994 - accuracy: 0.9695 - val_loss: 0.4665 - val_accuracy: 0.8426\n","Epoch 37/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0963 - accuracy: 0.9713 - val_loss: 0.4852 - val_accuracy: 0.8426\n","Epoch 38/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0977 - accuracy: 0.9708 - val_loss: 0.4682 - val_accuracy: 0.8458\n","Epoch 39/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0948 - accuracy: 0.9719 - val_loss: 0.4621 - val_accuracy: 0.8448\n","Epoch 40/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0957 - accuracy: 0.9711 - val_loss: 0.4782 - val_accuracy: 0.8373\n","Epoch 41/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0926 - accuracy: 0.9711 - val_loss: 0.4821 - val_accuracy: 0.8501\n","Epoch 42/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0960 - accuracy: 0.9732 - val_loss: 0.4867 - val_accuracy: 0.8448\n","Epoch 43/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0975 - accuracy: 0.9689 - val_loss: 0.4820 - val_accuracy: 0.8448\n","Epoch 44/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0890 - accuracy: 0.9748 - val_loss: 0.4939 - val_accuracy: 0.8383\n","Epoch 45/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0938 - accuracy: 0.9737 - val_loss: 0.5005 - val_accuracy: 0.8362\n","Epoch 46/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0906 - accuracy: 0.9740 - val_loss: 0.4937 - val_accuracy: 0.8448\n","Epoch 47/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0890 - accuracy: 0.9737 - val_loss: 0.4959 - val_accuracy: 0.8469\n","Epoch 48/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0980 - accuracy: 0.9708 - val_loss: 0.5210 - val_accuracy: 0.8426\n","Epoch 49/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0946 - accuracy: 0.9708 - val_loss: 0.5696 - val_accuracy: 0.8394\n","Epoch 50/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0991 - accuracy: 0.9700 - val_loss: 0.4961 - val_accuracy: 0.8458\n","Epoch 51/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0903 - accuracy: 0.9754 - val_loss: 0.5554 - val_accuracy: 0.8437\n","Epoch 52/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0861 - accuracy: 0.9770 - val_loss: 0.4988 - val_accuracy: 0.8426\n","Epoch 53/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0808 - accuracy: 0.9786 - val_loss: 0.5048 - val_accuracy: 0.8448\n","Epoch 54/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0839 - accuracy: 0.9751 - val_loss: 0.5182 - val_accuracy: 0.8383\n","Epoch 55/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0750 - accuracy: 0.9807 - val_loss: 0.5100 - val_accuracy: 0.8448\n","Epoch 56/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0824 - accuracy: 0.9786 - val_loss: 0.5164 - val_accuracy: 0.8448\n","Epoch 57/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0834 - accuracy: 0.9764 - val_loss: 0.5483 - val_accuracy: 0.8415\n","Epoch 58/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0871 - accuracy: 0.9735 - val_loss: 0.5534 - val_accuracy: 0.8415\n","Epoch 59/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0808 - accuracy: 0.9783 - val_loss: 0.5173 - val_accuracy: 0.8415\n","Epoch 60/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0725 - accuracy: 0.9834 - val_loss: 0.5300 - val_accuracy: 0.8405\n","Epoch 61/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0789 - accuracy: 0.9772 - val_loss: 0.5302 - val_accuracy: 0.8415\n","Epoch 62/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0777 - accuracy: 0.9786 - val_loss: 0.5436 - val_accuracy: 0.8415\n","Epoch 63/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0804 - accuracy: 0.9791 - val_loss: 0.5627 - val_accuracy: 0.8340\n","Epoch 64/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0783 - accuracy: 0.9788 - val_loss: 0.5620 - val_accuracy: 0.8362\n","Epoch 65/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0996 - accuracy: 0.9681 - val_loss: 0.5398 - val_accuracy: 0.8394\n","Epoch 66/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0755 - accuracy: 0.9799 - val_loss: 0.5472 - val_accuracy: 0.8426\n","Epoch 67/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0771 - accuracy: 0.9778 - val_loss: 0.5320 - val_accuracy: 0.8512\n","Epoch 68/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0749 - accuracy: 0.9778 - val_loss: 0.5433 - val_accuracy: 0.8405\n","Epoch 69/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0986 - accuracy: 0.9684 - val_loss: 0.6286 - val_accuracy: 0.8223\n","Epoch 70/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1085 - accuracy: 0.9641 - val_loss: 0.5291 - val_accuracy: 0.8458\n","Epoch 71/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0801 - accuracy: 0.9772 - val_loss: 0.5295 - val_accuracy: 0.8469\n","Epoch 72/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0741 - accuracy: 0.9788 - val_loss: 0.5527 - val_accuracy: 0.8394\n","Epoch 73/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0652 - accuracy: 0.9831 - val_loss: 0.5441 - val_accuracy: 0.8437\n","Epoch 74/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0873 - accuracy: 0.9721 - val_loss: 0.5343 - val_accuracy: 0.8458\n","Epoch 75/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0641 - accuracy: 0.9845 - val_loss: 0.5562 - val_accuracy: 0.8437\n","Epoch 76/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0709 - accuracy: 0.9810 - val_loss: 0.5656 - val_accuracy: 0.8448\n","Epoch 77/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0669 - accuracy: 0.9829 - val_loss: 0.5593 - val_accuracy: 0.8426\n","Epoch 78/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1200 - accuracy: 0.9587 - val_loss: 0.5963 - val_accuracy: 0.8319\n","Epoch 79/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0863 - accuracy: 0.9724 - val_loss: 0.5632 - val_accuracy: 0.8362\n","Epoch 80/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0707 - accuracy: 0.9799 - val_loss: 0.5505 - val_accuracy: 0.8405\n","Epoch 81/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0648 - accuracy: 0.9823 - val_loss: 0.6019 - val_accuracy: 0.8383\n","Epoch 82/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0613 - accuracy: 0.9858 - val_loss: 0.5949 - val_accuracy: 0.8426\n","Epoch 83/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0573 - accuracy: 0.9866 - val_loss: 0.5917 - val_accuracy: 0.8362\n","Epoch 84/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0589 - accuracy: 0.9853 - val_loss: 0.5989 - val_accuracy: 0.8383\n","Epoch 85/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0579 - accuracy: 0.9847 - val_loss: 0.5721 - val_accuracy: 0.8415\n","Epoch 86/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0746 - accuracy: 0.9794 - val_loss: 0.5765 - val_accuracy: 0.8448\n","Epoch 87/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0633 - accuracy: 0.9837 - val_loss: 0.6040 - val_accuracy: 0.8362\n","Epoch 88/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0583 - accuracy: 0.9853 - val_loss: 0.5830 - val_accuracy: 0.8458\n","Epoch 89/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0548 - accuracy: 0.9861 - val_loss: 0.6850 - val_accuracy: 0.8287\n","Epoch 90/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0567 - accuracy: 0.9853 - val_loss: 0.6838 - val_accuracy: 0.8308\n","Epoch 91/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0564 - accuracy: 0.9853 - val_loss: 0.6283 - val_accuracy: 0.8373\n","Epoch 92/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0588 - accuracy: 0.9871 - val_loss: 0.5920 - val_accuracy: 0.8426\n","Epoch 93/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0564 - accuracy: 0.9861 - val_loss: 0.6081 - val_accuracy: 0.8394\n","Epoch 94/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0572 - accuracy: 0.9858 - val_loss: 0.7179 - val_accuracy: 0.8308\n","Epoch 95/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0600 - accuracy: 0.9842 - val_loss: 0.6403 - val_accuracy: 0.8373\n","Epoch 96/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0619 - accuracy: 0.9834 - val_loss: 0.5993 - val_accuracy: 0.8383\n","Epoch 97/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0571 - accuracy: 0.9850 - val_loss: 0.6076 - val_accuracy: 0.8415\n","Epoch 98/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0589 - accuracy: 0.9845 - val_loss: 0.6408 - val_accuracy: 0.8383\n","Epoch 99/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0589 - accuracy: 0.9837 - val_loss: 0.7462 - val_accuracy: 0.8308\n","Epoch 100/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0639 - accuracy: 0.9831 - val_loss: 0.7666 - val_accuracy: 0.8201\n","{'loss': [0.18450987339019775, 0.16546529531478882, 0.1749889850616455, 0.14995799958705902, 0.13903263211250305, 0.14539912343025208, 0.14939314126968384, 0.14173291623592377, 0.14792469143867493, 0.1350354701280594, 0.16311591863632202, 0.13563624024391174, 0.12987321615219116, 0.12400121241807938, 0.13713586330413818, 0.16216455399990082, 0.14255701005458832, 0.12404338270425797, 0.12453430145978928, 0.12170509994029999, 0.11598889529705048, 0.1207183450460434, 0.1158522218465805, 0.11291610449552536, 0.1154753565788269, 0.11186326295137405, 0.11486289650201797, 0.11203855276107788, 0.11346504092216492, 0.10777439922094345, 0.11201324313879013, 0.12780293822288513, 0.11521965265274048, 0.10323900729417801, 0.09860522300004959, 0.0994097962975502, 0.09632086753845215, 0.09769503027200699, 0.09483007341623306, 0.09570092707872391, 0.09262712299823761, 0.09603071212768555, 0.0975361242890358, 0.08898351341485977, 0.09382539242506027, 0.09056076407432556, 0.08897868543863297, 0.09795957803726196, 0.09460315853357315, 0.09912806004285812, 0.09030638635158539, 0.08613623678684235, 0.08079087734222412, 0.08385537564754486, 0.07502187043428421, 0.08237088471651077, 0.08335962891578674, 0.0871446505188942, 0.0808386504650116, 0.07254597544670105, 0.07893924415111542, 0.07770442962646484, 0.0803779810667038, 0.07834374904632568, 0.09959138184785843, 0.07545206695795059, 0.07705862820148468, 0.07485336810350418, 0.09858036786317825, 0.10846468806266785, 0.08014605194330215, 0.07410707324743271, 0.06515688449144363, 0.08731091022491455, 0.0641166940331459, 0.07088387757539749, 0.06693331897258759, 0.12004920840263367, 0.08630091696977615, 0.07065422832965851, 0.06482772529125214, 0.061300016939640045, 0.05732527747750282, 0.05885205790400505, 0.05790496990084648, 0.0745888277888298, 0.06326738744974136, 0.05828244984149933, 0.05477369576692581, 0.056731924414634705, 0.05642079561948776, 0.058803703635931015, 0.05636436119675636, 0.05721679702401161, 0.06003711745142937, 0.06189539656043053, 0.057064030319452286, 0.058939769864082336, 0.058934710919857025, 0.06391096115112305], 'accuracy': [0.9330297112464905, 0.943744957447052, 0.9346370100975037, 0.9509777426719666, 0.9544602036476135, 0.9517813920974731, 0.9485668540000916, 0.9512456655502319, 0.9456201195716858, 0.9560675024986267, 0.9391909837722778, 0.9549959897994995, 0.9549959897994995, 0.9614251255989075, 0.9531208276748657, 0.9383873343467712, 0.9491025805473328, 0.9595499634742737, 0.9611572623252869, 0.9622287750244141, 0.9608893394470215, 0.9598178267478943, 0.9643718004226685, 0.9665148854255676, 0.9619609117507935, 0.9649075865745544, 0.9641039371490479, 0.965175449848175, 0.965175449848175, 0.9667827486991882, 0.9649075865745544, 0.9574069380760193, 0.9598178267478943, 0.9699973464012146, 0.9729440212249756, 0.9694615602493286, 0.9713367223739624, 0.9708009362220764, 0.9718725085258484, 0.9710688591003418, 0.9710688591003418, 0.9732118844985962, 0.9689257740974426, 0.9748191833496094, 0.9737476706504822, 0.9740155339241028, 0.9737476706504822, 0.9708009362220764, 0.9708009362220764, 0.9699973464012146, 0.9753549695014954, 0.9769622087478638, 0.978569507598877, 0.97508704662323, 0.9807125926017761, 0.978569507598877, 0.9764264822006226, 0.9734797477722168, 0.9783016443252563, 0.9833913445472717, 0.9772301316261292, 0.978569507598877, 0.9791052937507629, 0.9788373708724976, 0.968122124671936, 0.9799089431762695, 0.9777658581733704, 0.9777658581733704, 0.9683900475502014, 0.9641039371490479, 0.9772301316261292, 0.9788373708724976, 0.9831234812736511, 0.972140371799469, 0.9844629168510437, 0.9809804558753967, 0.9828556180000305, 0.9587463140487671, 0.9724082350730896, 0.9799089431762695, 0.9823198318481445, 0.9858022928237915, 0.9866059422492981, 0.9852665662765503, 0.9847307801246643, 0.9793731570243835, 0.9836592674255371, 0.9852665662765503, 0.9860701560974121, 0.9852665662765503, 0.9852665662765503, 0.9871417284011841, 0.9860701560974121, 0.9858022928237915, 0.9841949939727783, 0.9833913445472717, 0.9849986433982849, 0.9844629168510437, 0.9836592674255371, 0.9831234812736511], 'val_loss': [0.6631971001625061, 0.6583841443061829, 0.6516945362091064, 0.645776629447937, 0.6366182565689087, 0.62664794921875, 0.6136799454689026, 0.6036757826805115, 0.5847389698028564, 0.5649535655975342, 0.5492687225341797, 0.5214714407920837, 0.49631041288375854, 0.46404409408569336, 0.4647368788719177, 0.43824148178100586, 0.3968469202518463, 0.37826505303382874, 0.36995649337768555, 0.37927618622779846, 0.39239707589149475, 0.3712148368358612, 0.3798235058784485, 0.386681467294693, 0.39545413851737976, 0.40310466289520264, 0.41865238547325134, 0.4297431707382202, 0.4555543065071106, 0.43612730503082275, 0.46412667632102966, 0.4506427049636841, 0.45069384574890137, 0.4477664828300476, 0.46755942702293396, 0.46652328968048096, 0.485232949256897, 0.46817171573638916, 0.46213969588279724, 0.47817137837409973, 0.48214495182037354, 0.4867253303527832, 0.48204585909843445, 0.4939104914665222, 0.5005378723144531, 0.49372756481170654, 0.4958663284778595, 0.520965039730072, 0.5695629119873047, 0.49607929587364197, 0.5553827881813049, 0.4988461136817932, 0.504767894744873, 0.5182005763053894, 0.5100401639938354, 0.516395092010498, 0.5482513904571533, 0.5533717274665833, 0.5173012614250183, 0.5299556255340576, 0.5302431583404541, 0.5436086654663086, 0.5627001523971558, 0.5619748830795288, 0.5397798418998718, 0.5472160577774048, 0.5319516062736511, 0.5433316826820374, 0.6286460757255554, 0.5290854573249817, 0.5295076966285706, 0.5527336597442627, 0.544144332408905, 0.5343085527420044, 0.5561714172363281, 0.5655719637870789, 0.5592753291130066, 0.5963401198387146, 0.5632416605949402, 0.550477921962738, 0.6018814444541931, 0.594932496547699, 0.5917297601699829, 0.5988767147064209, 0.5720972418785095, 0.5765233039855957, 0.6039547920227051, 0.5829627513885498, 0.6850482821464539, 0.6837995052337646, 0.6283015012741089, 0.5920000672340393, 0.6080926656723022, 0.7179180979728699, 0.6403490304946899, 0.5993098020553589, 0.6076346635818481, 0.6408268213272095, 0.7461650371551514, 0.7665912508964539], 'val_accuracy': [0.7901498675346375, 0.8137044906616211, 0.8072805404663086, 0.8147751688957214, 0.8126338124275208, 0.8115631937980652, 0.8137044906616211, 0.8115631937980652, 0.8147751688957214, 0.8104925155639648, 0.8051391839981079, 0.8222697973251343, 0.8169164657592773, 0.8233404755592346, 0.8072805404663086, 0.8094218373298645, 0.8329764604568481, 0.840471088886261, 0.8372591137886047, 0.8447537422180176, 0.840471088886261, 0.8426124453544617, 0.8447537422180176, 0.8458244204521179, 0.8576017022132874, 0.8543897271156311, 0.8479657173156738, 0.8479657173156738, 0.8479657173156738, 0.8447537422180176, 0.8522483706474304, 0.8533190488815308, 0.835117757320404, 0.8458244204521179, 0.8436830639839172, 0.8426124453544617, 0.8426124453544617, 0.8458244204521179, 0.8447537422180176, 0.8372591137886047, 0.8501070737838745, 0.8447537422180176, 0.8447537422180176, 0.8383297920227051, 0.8361884355545044, 0.8447537422180176, 0.8468950986862183, 0.8426124453544617, 0.8394004106521606, 0.8458244204521179, 0.8436830639839172, 0.8426124453544617, 0.8447537422180176, 0.8383297920227051, 0.8447537422180176, 0.8447537422180176, 0.8415417671203613, 0.8415417671203613, 0.8415417671203613, 0.840471088886261, 0.8415417671203613, 0.8415417671203613, 0.8340471386909485, 0.8361884355545044, 0.8394004106521606, 0.8426124453544617, 0.8511777520179749, 0.840471088886261, 0.8222697973251343, 0.8458244204521179, 0.8468950986862183, 0.8394004106521606, 0.8436830639839172, 0.8458244204521179, 0.8436830639839172, 0.8447537422180176, 0.8426124453544617, 0.8319057822227478, 0.8361884355545044, 0.840471088886261, 0.8383297920227051, 0.8426124453544617, 0.8361884355545044, 0.8383297920227051, 0.8415417671203613, 0.8447537422180176, 0.8361884355545044, 0.8458244204521179, 0.8286938071250916, 0.8308351039886475, 0.8372591137886047, 0.8426124453544617, 0.8394004106521606, 0.8308351039886475, 0.8372591137886047, 0.8383297920227051, 0.8415417671203613, 0.8383297920227051, 0.8308351039886475, 0.8201285004615784]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 55ms/step - loss: 0.1837 - accuracy: 0.9346 - val_loss: 0.6631 - val_accuracy: 0.7441\n","Epoch 2/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1768 - accuracy: 0.9365 - val_loss: 0.6581 - val_accuracy: 0.7859\n","Epoch 3/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1682 - accuracy: 0.9397 - val_loss: 0.6493 - val_accuracy: 0.8169\n","Epoch 4/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1671 - accuracy: 0.9411 - val_loss: 0.6446 - val_accuracy: 0.7987\n","Epoch 5/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1520 - accuracy: 0.9464 - val_loss: 0.6341 - val_accuracy: 0.8362\n","Epoch 6/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1537 - accuracy: 0.9456 - val_loss: 0.6249 - val_accuracy: 0.8276\n","Epoch 7/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1414 - accuracy: 0.9531 - val_loss: 0.6105 - val_accuracy: 0.8458\n","Epoch 8/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1484 - accuracy: 0.9478 - val_loss: 0.5959 - val_accuracy: 0.8394\n","Epoch 9/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1525 - accuracy: 0.9464 - val_loss: 0.5792 - val_accuracy: 0.8469\n","Epoch 10/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1624 - accuracy: 0.9435 - val_loss: 0.5582 - val_accuracy: 0.8394\n","Epoch 11/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1377 - accuracy: 0.9537 - val_loss: 0.5349 - val_accuracy: 0.8223\n","Epoch 12/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1404 - accuracy: 0.9518 - val_loss: 0.5077 - val_accuracy: 0.8469\n","Epoch 13/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1442 - accuracy: 0.9488 - val_loss: 0.4830 - val_accuracy: 0.8490\n","Epoch 14/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1438 - accuracy: 0.9470 - val_loss: 0.4409 - val_accuracy: 0.8437\n","Epoch 15/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1338 - accuracy: 0.9547 - val_loss: 0.4100 - val_accuracy: 0.8640\n","Epoch 16/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1254 - accuracy: 0.9569 - val_loss: 0.3822 - val_accuracy: 0.8308\n","Epoch 17/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1651 - accuracy: 0.9370 - val_loss: 0.3485 - val_accuracy: 0.8683\n","Epoch 18/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.1263 - accuracy: 0.9595 - val_loss: 0.3354 - val_accuracy: 0.8715\n","Epoch 19/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1266 - accuracy: 0.9598 - val_loss: 0.3099 - val_accuracy: 0.8683\n","Epoch 20/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1253 - accuracy: 0.9579 - val_loss: 0.2986 - val_accuracy: 0.8779\n","Epoch 21/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1175 - accuracy: 0.9628 - val_loss: 0.3086 - val_accuracy: 0.8737\n","Epoch 22/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1274 - accuracy: 0.9585 - val_loss: 0.3016 - val_accuracy: 0.8651\n","Epoch 23/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1282 - accuracy: 0.9579 - val_loss: 0.2811 - val_accuracy: 0.8897\n","Epoch 24/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1206 - accuracy: 0.9585 - val_loss: 0.2869 - val_accuracy: 0.8801\n","Epoch 25/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1095 - accuracy: 0.9646 - val_loss: 0.2823 - val_accuracy: 0.8865\n","Epoch 26/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1077 - accuracy: 0.9646 - val_loss: 0.2935 - val_accuracy: 0.8833\n","Epoch 27/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1125 - accuracy: 0.9636 - val_loss: 0.3058 - val_accuracy: 0.8779\n","Epoch 28/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1116 - accuracy: 0.9625 - val_loss: 0.2938 - val_accuracy: 0.8812\n","Epoch 29/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1273 - accuracy: 0.9558 - val_loss: 0.3154 - val_accuracy: 0.8822\n","Epoch 30/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1325 - accuracy: 0.9537 - val_loss: 0.2958 - val_accuracy: 0.8865\n","Epoch 31/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1018 - accuracy: 0.9671 - val_loss: 0.3042 - val_accuracy: 0.8844\n","Epoch 32/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1083 - accuracy: 0.9649 - val_loss: 0.3078 - val_accuracy: 0.8833\n","Epoch 33/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1103 - accuracy: 0.9657 - val_loss: 0.3120 - val_accuracy: 0.8876\n","Epoch 34/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1054 - accuracy: 0.9671 - val_loss: 0.3111 - val_accuracy: 0.8897\n","Epoch 35/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1085 - accuracy: 0.9654 - val_loss: 0.3156 - val_accuracy: 0.8812\n","Epoch 36/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1083 - accuracy: 0.9644 - val_loss: 0.3166 - val_accuracy: 0.8908\n","Epoch 37/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1054 - accuracy: 0.9620 - val_loss: 0.3116 - val_accuracy: 0.8854\n","Epoch 38/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1078 - accuracy: 0.9671 - val_loss: 0.3151 - val_accuracy: 0.8865\n","Epoch 39/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0999 - accuracy: 0.9695 - val_loss: 0.3437 - val_accuracy: 0.8737\n","Epoch 40/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0999 - accuracy: 0.9695 - val_loss: 0.3237 - val_accuracy: 0.8790\n","Epoch 41/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0959 - accuracy: 0.9721 - val_loss: 0.3256 - val_accuracy: 0.8929\n","Epoch 42/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0921 - accuracy: 0.9735 - val_loss: 0.3278 - val_accuracy: 0.8854\n","Epoch 43/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0893 - accuracy: 0.9735 - val_loss: 0.3375 - val_accuracy: 0.8919\n","Epoch 44/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1098 - accuracy: 0.9638 - val_loss: 0.3674 - val_accuracy: 0.8801\n","Epoch 45/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0974 - accuracy: 0.9695 - val_loss: 0.3318 - val_accuracy: 0.8822\n","Epoch 46/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0854 - accuracy: 0.9756 - val_loss: 0.3389 - val_accuracy: 0.8897\n","Epoch 47/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0861 - accuracy: 0.9735 - val_loss: 0.3633 - val_accuracy: 0.8812\n","Epoch 48/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0974 - accuracy: 0.9697 - val_loss: 0.3396 - val_accuracy: 0.8897\n","Epoch 49/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0824 - accuracy: 0.9791 - val_loss: 0.3524 - val_accuracy: 0.8908\n","Epoch 50/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0883 - accuracy: 0.9748 - val_loss: 0.3481 - val_accuracy: 0.8929\n","Epoch 51/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0894 - accuracy: 0.9746 - val_loss: 0.3745 - val_accuracy: 0.8747\n","Epoch 52/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1142 - accuracy: 0.9606 - val_loss: 0.3455 - val_accuracy: 0.8854\n","Epoch 53/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0854 - accuracy: 0.9748 - val_loss: 0.3399 - val_accuracy: 0.8854\n","Epoch 54/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0897 - accuracy: 0.9727 - val_loss: 0.3445 - val_accuracy: 0.8844\n","Epoch 55/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0774 - accuracy: 0.9780 - val_loss: 0.3457 - val_accuracy: 0.8801\n","Epoch 56/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0782 - accuracy: 0.9764 - val_loss: 0.3608 - val_accuracy: 0.8865\n","Epoch 57/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0814 - accuracy: 0.9767 - val_loss: 0.3575 - val_accuracy: 0.8897\n","Epoch 58/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0796 - accuracy: 0.9767 - val_loss: 0.3850 - val_accuracy: 0.8812\n","Epoch 59/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0796 - accuracy: 0.9764 - val_loss: 0.3560 - val_accuracy: 0.8801\n","Epoch 60/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0777 - accuracy: 0.9778 - val_loss: 0.3663 - val_accuracy: 0.8865\n","Epoch 61/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0739 - accuracy: 0.9794 - val_loss: 0.3871 - val_accuracy: 0.8865\n","Epoch 62/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0863 - accuracy: 0.9746 - val_loss: 0.3772 - val_accuracy: 0.8726\n","Epoch 63/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0878 - accuracy: 0.9719 - val_loss: 0.3676 - val_accuracy: 0.8865\n","Epoch 64/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0831 - accuracy: 0.9735 - val_loss: 0.3635 - val_accuracy: 0.8790\n","Epoch 65/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0752 - accuracy: 0.9775 - val_loss: 0.3571 - val_accuracy: 0.8833\n","Epoch 66/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.0690 - accuracy: 0.9818 - val_loss: 0.3624 - val_accuracy: 0.8854\n","Epoch 67/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0722 - accuracy: 0.9804 - val_loss: 0.4080 - val_accuracy: 0.8790\n","Epoch 68/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0727 - accuracy: 0.9786 - val_loss: 0.4132 - val_accuracy: 0.8769\n","Epoch 69/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0712 - accuracy: 0.9804 - val_loss: 0.3635 - val_accuracy: 0.8833\n","Epoch 70/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0704 - accuracy: 0.9796 - val_loss: 0.3697 - val_accuracy: 0.8822\n","Epoch 71/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0722 - accuracy: 0.9799 - val_loss: 0.4091 - val_accuracy: 0.8779\n","Epoch 72/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0838 - accuracy: 0.9740 - val_loss: 0.3689 - val_accuracy: 0.8876\n","Epoch 73/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0713 - accuracy: 0.9796 - val_loss: 0.3787 - val_accuracy: 0.8865\n","Epoch 74/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0706 - accuracy: 0.9794 - val_loss: 0.4631 - val_accuracy: 0.8694\n","Epoch 75/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0694 - accuracy: 0.9794 - val_loss: 0.3781 - val_accuracy: 0.8833\n","Epoch 76/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0707 - accuracy: 0.9804 - val_loss: 0.3975 - val_accuracy: 0.8737\n","Epoch 77/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0684 - accuracy: 0.9799 - val_loss: 0.3759 - val_accuracy: 0.8779\n","Epoch 78/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0678 - accuracy: 0.9802 - val_loss: 0.3755 - val_accuracy: 0.8822\n","Epoch 79/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0723 - accuracy: 0.9783 - val_loss: 0.4070 - val_accuracy: 0.8876\n","Epoch 80/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0647 - accuracy: 0.9823 - val_loss: 0.3797 - val_accuracy: 0.8769\n","Epoch 81/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0634 - accuracy: 0.9821 - val_loss: 0.3831 - val_accuracy: 0.8854\n","Epoch 82/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0556 - accuracy: 0.9871 - val_loss: 0.3897 - val_accuracy: 0.8844\n","Epoch 83/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0614 - accuracy: 0.9861 - val_loss: 0.3881 - val_accuracy: 0.8747\n","Epoch 84/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0652 - accuracy: 0.9823 - val_loss: 0.3900 - val_accuracy: 0.8854\n","Epoch 85/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0562 - accuracy: 0.9853 - val_loss: 0.3886 - val_accuracy: 0.8801\n","Epoch 86/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0541 - accuracy: 0.9874 - val_loss: 0.4299 - val_accuracy: 0.8812\n","Epoch 87/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0617 - accuracy: 0.9823 - val_loss: 0.4419 - val_accuracy: 0.8737\n","Epoch 88/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0606 - accuracy: 0.9834 - val_loss: 0.4285 - val_accuracy: 0.8844\n","Epoch 89/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0556 - accuracy: 0.9866 - val_loss: 0.4222 - val_accuracy: 0.8694\n","Epoch 90/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0907 - accuracy: 0.9705 - val_loss: 0.4825 - val_accuracy: 0.8640\n","Epoch 91/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0719 - accuracy: 0.9772 - val_loss: 0.3923 - val_accuracy: 0.8801\n","Epoch 92/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0593 - accuracy: 0.9842 - val_loss: 0.4008 - val_accuracy: 0.8854\n","Epoch 93/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0529 - accuracy: 0.9863 - val_loss: 0.4323 - val_accuracy: 0.8812\n","Epoch 94/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0481 - accuracy: 0.9890 - val_loss: 0.4119 - val_accuracy: 0.8876\n","Epoch 95/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0496 - accuracy: 0.9890 - val_loss: 0.4098 - val_accuracy: 0.8854\n","Epoch 96/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0555 - accuracy: 0.9847 - val_loss: 0.4698 - val_accuracy: 0.8737\n","Epoch 97/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0586 - accuracy: 0.9837 - val_loss: 0.4070 - val_accuracy: 0.8790\n","Epoch 98/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0483 - accuracy: 0.9893 - val_loss: 0.4719 - val_accuracy: 0.8779\n","Epoch 99/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0652 - accuracy: 0.9815 - val_loss: 0.4182 - val_accuracy: 0.8876\n","Epoch 100/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0492 - accuracy: 0.9898 - val_loss: 0.4364 - val_accuracy: 0.8833\n","{'loss': [0.183749720454216, 0.17681141197681427, 0.1682358831167221, 0.16708484292030334, 0.1519988626241684, 0.1537410467863083, 0.14137287437915802, 0.14843802154064178, 0.15247920155525208, 0.1624334156513214, 0.1377030909061432, 0.14036060869693756, 0.14422477781772614, 0.1437789648771286, 0.1337982565164566, 0.1253693401813507, 0.16508851945400238, 0.12626901268959045, 0.1266387701034546, 0.125348761677742, 0.1175338625907898, 0.12744885683059692, 0.12823492288589478, 0.12055860459804535, 0.109490767121315, 0.1077367439866066, 0.11245813965797424, 0.11162378638982773, 0.1273331493139267, 0.13251972198486328, 0.10183238238096237, 0.10833695530891418, 0.11030592769384384, 0.10539231449365616, 0.10848931968212128, 0.10830678045749664, 0.10542580485343933, 0.10776834189891815, 0.09987477958202362, 0.09991665929555893, 0.09587278962135315, 0.09213589876890182, 0.08927842229604721, 0.10984119772911072, 0.09743192046880722, 0.08539708703756332, 0.08611754328012466, 0.09737373888492584, 0.08236125856637955, 0.08829855918884277, 0.08941779285669327, 0.11422602832317352, 0.08544357866048813, 0.08968912065029144, 0.07741443067789078, 0.07824350148439407, 0.08138509094715118, 0.07956848293542862, 0.07958303391933441, 0.07768835127353668, 0.07388030737638474, 0.08628527075052261, 0.08780543506145477, 0.0830751359462738, 0.07515405118465424, 0.0689777210354805, 0.0722464770078659, 0.07271982729434967, 0.0712345540523529, 0.07036829739809036, 0.07223808020353317, 0.08380559086799622, 0.07134901732206345, 0.07064805179834366, 0.06943172961473465, 0.07068460434675217, 0.06844274699687958, 0.06784822046756744, 0.07227293401956558, 0.06468698382377625, 0.06339698284864426, 0.05562802776694298, 0.061372872442007065, 0.06522925198078156, 0.05618002638220787, 0.054148297756910324, 0.06168251112103462, 0.060568589717149734, 0.05562477558851242, 0.09071889519691467, 0.0719163715839386, 0.05934099853038788, 0.05286622792482376, 0.04811101034283638, 0.04957014322280884, 0.055460795760154724, 0.05864670127630234, 0.048256997019052505, 0.06522111594676971, 0.04920501261949539], 'accuracy': [0.9346370100975037, 0.9365121722221375, 0.9397267699241638, 0.9410661458969116, 0.9464237689971924, 0.9456201195716858, 0.9531208276748657, 0.947763204574585, 0.9464237689971924, 0.9434770941734314, 0.9536565542221069, 0.9517813920974731, 0.9488347172737122, 0.9469595551490784, 0.9547281265258789, 0.9568711519241333, 0.9370479583740234, 0.9595499634742737, 0.9598178267478943, 0.9579426646232605, 0.9627645611763, 0.9584784507751465, 0.9579426646232605, 0.9584784507751465, 0.9646397233009338, 0.9646397233009338, 0.9635681509971619, 0.9624966382980347, 0.9557996392250061, 0.9536565542221069, 0.9670506119728088, 0.9649075865745544, 0.965711236000061, 0.9670506119728088, 0.9654433727264404, 0.9643718004226685, 0.9619609117507935, 0.9670506119728088, 0.9694615602493286, 0.9694615602493286, 0.972140371799469, 0.9734797477722168, 0.9734797477722168, 0.9638360738754272, 0.9694615602493286, 0.975622832775116, 0.9734797477722168, 0.9697294235229492, 0.9791052937507629, 0.9748191833496094, 0.9745513200759888, 0.9606214761734009, 0.9748191833496094, 0.972676157951355, 0.9780337810516357, 0.9764264822006226, 0.9766943454742432, 0.9766943454742432, 0.9764264822006226, 0.9777658581733704, 0.9793731570243835, 0.9745513200759888, 0.9718725085258484, 0.9734797477722168, 0.9774979948997498, 0.9817841053009033, 0.9804446697235107, 0.978569507598877, 0.9804446697235107, 0.9796410202980042, 0.9799089431762695, 0.9740155339241028, 0.9796410202980042, 0.9793731570243835, 0.9793731570243835, 0.9804446697235107, 0.9799089431762695, 0.9801768064498901, 0.9783016443252563, 0.9823198318481445, 0.9820519685745239, 0.9871417284011841, 0.9860701560974121, 0.9823198318481445, 0.9852665662765503, 0.9874095916748047, 0.9823198318481445, 0.9833913445472717, 0.9866059422492981, 0.9705330729484558, 0.9772301316261292, 0.9841949939727783, 0.9863380789756775, 0.9890168905258179, 0.9890168905258179, 0.9847307801246643, 0.9836592674255371, 0.9892847537994385, 0.9815161824226379, 0.9898205399513245], 'val_loss': [0.6630986928939819, 0.6581323146820068, 0.6492765545845032, 0.6445565223693848, 0.6341450214385986, 0.6248903274536133, 0.6104576587677002, 0.5959041118621826, 0.5792173147201538, 0.558204174041748, 0.5349072217941284, 0.50773024559021, 0.4829869866371155, 0.44093552231788635, 0.4100036919116974, 0.38220879435539246, 0.3485242426395416, 0.33535197377204895, 0.3098759055137634, 0.2986024022102356, 0.30861082673072815, 0.3016156852245331, 0.2811390459537506, 0.28690460324287415, 0.2822703421115875, 0.2935134172439575, 0.3057674467563629, 0.2938450276851654, 0.3154495060443878, 0.29583027958869934, 0.3042219281196594, 0.3078136444091797, 0.31198424100875854, 0.31111735105514526, 0.315594345331192, 0.3166205585002899, 0.3115522265434265, 0.3150833547115326, 0.3436906635761261, 0.3236633539199829, 0.32560354471206665, 0.3277866244316101, 0.3374897241592407, 0.36741605401039124, 0.33181291818618774, 0.33887526392936707, 0.3632742166519165, 0.3395930230617523, 0.35240986943244934, 0.3480587899684906, 0.37449297308921814, 0.3455091118812561, 0.3398677706718445, 0.3445037603378296, 0.3457441031932831, 0.360796719789505, 0.35752028226852417, 0.38500604033470154, 0.355986088514328, 0.36634311079978943, 0.38709625601768494, 0.37723466753959656, 0.367642343044281, 0.36353009939193726, 0.35711878538131714, 0.3623883128166199, 0.40795522928237915, 0.4132448732852936, 0.3635265529155731, 0.36967363953590393, 0.4090770184993744, 0.3688862919807434, 0.37870973348617554, 0.4630536437034607, 0.37805381417274475, 0.3975473940372467, 0.3758604824542999, 0.3754573166370392, 0.40702351927757263, 0.3796956241130829, 0.3831240236759186, 0.38969388604164124, 0.38807201385498047, 0.39004942774772644, 0.38864338397979736, 0.4298998713493347, 0.44194942712783813, 0.42851293087005615, 0.42215707898139954, 0.4825373888015747, 0.3923269510269165, 0.4007534682750702, 0.43230706453323364, 0.41186368465423584, 0.40976929664611816, 0.4697502553462982, 0.4070180654525757, 0.4718901216983795, 0.4182094633579254, 0.4364250600337982], 'val_accuracy': [0.7441113591194153, 0.7858672142028809, 0.8169164657592773, 0.7987151741981506, 0.8361884355545044, 0.8276231288909912, 0.8458244204521179, 0.8394004106521606, 0.8468950986862183, 0.8394004106521606, 0.8222697973251343, 0.8468950986862183, 0.8490363955497742, 0.8436830639839172, 0.8640257120132446, 0.8308351039886475, 0.8683083653450012, 0.8715203404426575, 0.8683083653450012, 0.8779443502426147, 0.8736616969108582, 0.8650963306427002, 0.8897216320037842, 0.8800856471061707, 0.8865096569061279, 0.8832976222038269, 0.8779443502426147, 0.881156325340271, 0.8822270035743713, 0.8865096569061279, 0.8843683004379272, 0.8832976222038269, 0.8875802755355835, 0.8897216320037842, 0.881156325340271, 0.8907923102378845, 0.8854389786720276, 0.8865096569061279, 0.8736616969108582, 0.8790149688720703, 0.8929336071014404, 0.8854389786720276, 0.8918629288673401, 0.8800856471061707, 0.8822270035743713, 0.8897216320037842, 0.881156325340271, 0.8897216320037842, 0.8907923102378845, 0.8929336071014404, 0.8747323155403137, 0.8854389786720276, 0.8854389786720276, 0.8843683004379272, 0.8800856471061707, 0.8865096569061279, 0.8897216320037842, 0.881156325340271, 0.8800856471061707, 0.8865096569061279, 0.8865096569061279, 0.8725910186767578, 0.8865096569061279, 0.8790149688720703, 0.8832976222038269, 0.8854389786720276, 0.8790149688720703, 0.8768736720085144, 0.8832976222038269, 0.8822270035743713, 0.8779443502426147, 0.8875802755355835, 0.8865096569061279, 0.8693790435791016, 0.8832976222038269, 0.8736616969108582, 0.8779443502426147, 0.8822270035743713, 0.8875802755355835, 0.8768736720085144, 0.8854389786720276, 0.8843683004379272, 0.8747323155403137, 0.8854389786720276, 0.8800856471061707, 0.881156325340271, 0.8736616969108582, 0.8843683004379272, 0.8693790435791016, 0.8640257120132446, 0.8800856471061707, 0.8854389786720276, 0.881156325340271, 0.8875802755355835, 0.8854389786720276, 0.8736616969108582, 0.8790149688720703, 0.8779443502426147, 0.8875802755355835, 0.8832976222038269]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 10s 53ms/step - loss: 0.2034 - accuracy: 0.9258 - val_loss: 0.6619 - val_accuracy: 0.7944\n","Epoch 2/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1777 - accuracy: 0.9349 - val_loss: 0.6578 - val_accuracy: 0.8041\n","Epoch 3/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1583 - accuracy: 0.9429 - val_loss: 0.6516 - val_accuracy: 0.8009\n","Epoch 4/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1616 - accuracy: 0.9432 - val_loss: 0.6436 - val_accuracy: 0.8212\n","Epoch 5/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1663 - accuracy: 0.9341 - val_loss: 0.6361 - val_accuracy: 0.8233\n","Epoch 6/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1476 - accuracy: 0.9451 - val_loss: 0.6266 - val_accuracy: 0.8158\n","Epoch 7/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1423 - accuracy: 0.9480 - val_loss: 0.6128 - val_accuracy: 0.8201\n","Epoch 8/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1421 - accuracy: 0.9507 - val_loss: 0.5972 - val_accuracy: 0.8212\n","Epoch 9/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1435 - accuracy: 0.9512 - val_loss: 0.5788 - val_accuracy: 0.8255\n","Epoch 10/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1457 - accuracy: 0.9488 - val_loss: 0.5612 - val_accuracy: 0.8223\n","Epoch 11/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1445 - accuracy: 0.9510 - val_loss: 0.5399 - val_accuracy: 0.8287\n","Epoch 12/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1365 - accuracy: 0.9542 - val_loss: 0.5164 - val_accuracy: 0.8266\n","Epoch 13/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1349 - accuracy: 0.9539 - val_loss: 0.4822 - val_accuracy: 0.8308\n","Epoch 14/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1363 - accuracy: 0.9523 - val_loss: 0.4590 - val_accuracy: 0.8383\n","Epoch 15/100\n","30/30 [==============================] - 1s 31ms/step - loss: 0.1357 - accuracy: 0.9545 - val_loss: 0.4196 - val_accuracy: 0.8448\n","Epoch 16/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1287 - accuracy: 0.9571 - val_loss: 0.3891 - val_accuracy: 0.8458\n","Epoch 17/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.1369 - accuracy: 0.9515 - val_loss: 0.3646 - val_accuracy: 0.8373\n","Epoch 18/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.1320 - accuracy: 0.9515 - val_loss: 0.3494 - val_accuracy: 0.8576\n","Epoch 19/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1245 - accuracy: 0.9566 - val_loss: 0.3392 - val_accuracy: 0.8587\n","Epoch 20/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1260 - accuracy: 0.9571 - val_loss: 0.3262 - val_accuracy: 0.8597\n","Epoch 21/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1226 - accuracy: 0.9555 - val_loss: 0.3170 - val_accuracy: 0.8630\n","Epoch 22/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1284 - accuracy: 0.9526 - val_loss: 0.3503 - val_accuracy: 0.8565\n","Epoch 23/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1195 - accuracy: 0.9622 - val_loss: 0.3158 - val_accuracy: 0.8715\n","Epoch 24/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1179 - accuracy: 0.9577 - val_loss: 0.3040 - val_accuracy: 0.8812\n","Epoch 25/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1298 - accuracy: 0.9542 - val_loss: 0.3687 - val_accuracy: 0.8651\n","Epoch 26/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1251 - accuracy: 0.9561 - val_loss: 0.3332 - val_accuracy: 0.8812\n","Epoch 27/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1128 - accuracy: 0.9628 - val_loss: 0.3243 - val_accuracy: 0.8801\n","Epoch 28/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1081 - accuracy: 0.9649 - val_loss: 0.3254 - val_accuracy: 0.8801\n","Epoch 29/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1144 - accuracy: 0.9593 - val_loss: 0.3260 - val_accuracy: 0.8790\n","Epoch 30/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1106 - accuracy: 0.9617 - val_loss: 0.3344 - val_accuracy: 0.8779\n","Epoch 31/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1047 - accuracy: 0.9673 - val_loss: 0.3391 - val_accuracy: 0.8790\n","Epoch 32/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1091 - accuracy: 0.9668 - val_loss: 0.3437 - val_accuracy: 0.8865\n","Epoch 33/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1093 - accuracy: 0.9620 - val_loss: 0.4019 - val_accuracy: 0.8694\n","Epoch 34/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1007 - accuracy: 0.9689 - val_loss: 0.3606 - val_accuracy: 0.8790\n","Epoch 35/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1127 - accuracy: 0.9614 - val_loss: 0.3595 - val_accuracy: 0.8737\n","Epoch 36/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1003 - accuracy: 0.9689 - val_loss: 0.3523 - val_accuracy: 0.8801\n","Epoch 37/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1010 - accuracy: 0.9684 - val_loss: 0.3668 - val_accuracy: 0.8758\n","Epoch 38/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.1072 - accuracy: 0.9628 - val_loss: 0.3590 - val_accuracy: 0.8822\n","Epoch 39/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0992 - accuracy: 0.9676 - val_loss: 0.3658 - val_accuracy: 0.8747\n","Epoch 40/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0978 - accuracy: 0.9711 - val_loss: 0.3882 - val_accuracy: 0.8672\n","Epoch 41/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0969 - accuracy: 0.9697 - val_loss: 0.3625 - val_accuracy: 0.8769\n","Epoch 42/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0967 - accuracy: 0.9687 - val_loss: 0.3668 - val_accuracy: 0.8769\n","Epoch 43/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0943 - accuracy: 0.9703 - val_loss: 0.3848 - val_accuracy: 0.8715\n","Epoch 44/100\n","30/30 [==============================] - 1s 31ms/step - loss: 0.0958 - accuracy: 0.9700 - val_loss: 0.3838 - val_accuracy: 0.8769\n","Epoch 45/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0914 - accuracy: 0.9708 - val_loss: 0.3755 - val_accuracy: 0.8790\n","Epoch 46/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0928 - accuracy: 0.9673 - val_loss: 0.3777 - val_accuracy: 0.8812\n","Epoch 47/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0878 - accuracy: 0.9751 - val_loss: 0.3805 - val_accuracy: 0.8833\n","Epoch 48/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0824 - accuracy: 0.9751 - val_loss: 0.3787 - val_accuracy: 0.8812\n","Epoch 49/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0818 - accuracy: 0.9732 - val_loss: 0.3988 - val_accuracy: 0.8715\n","Epoch 50/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1080 - accuracy: 0.9638 - val_loss: 0.3796 - val_accuracy: 0.8769\n","Epoch 51/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0890 - accuracy: 0.9721 - val_loss: 0.4047 - val_accuracy: 0.8662\n","Epoch 52/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0814 - accuracy: 0.9754 - val_loss: 0.3900 - val_accuracy: 0.8779\n","Epoch 53/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0783 - accuracy: 0.9786 - val_loss: 0.4116 - val_accuracy: 0.8726\n","Epoch 54/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0818 - accuracy: 0.9764 - val_loss: 0.4169 - val_accuracy: 0.8758\n","Epoch 55/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0876 - accuracy: 0.9711 - val_loss: 0.3963 - val_accuracy: 0.8747\n","Epoch 56/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0768 - accuracy: 0.9775 - val_loss: 0.4199 - val_accuracy: 0.8672\n","Epoch 57/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0918 - accuracy: 0.9724 - val_loss: 0.3933 - val_accuracy: 0.8779\n","Epoch 58/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0714 - accuracy: 0.9815 - val_loss: 0.4038 - val_accuracy: 0.8758\n","Epoch 59/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0817 - accuracy: 0.9729 - val_loss: 0.4178 - val_accuracy: 0.8747\n","Epoch 60/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0670 - accuracy: 0.9815 - val_loss: 0.4083 - val_accuracy: 0.8769\n","Epoch 61/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0917 - accuracy: 0.9700 - val_loss: 0.5700 - val_accuracy: 0.8405\n","Epoch 62/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0853 - accuracy: 0.9700 - val_loss: 0.4105 - val_accuracy: 0.8779\n","Epoch 63/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0702 - accuracy: 0.9791 - val_loss: 0.4227 - val_accuracy: 0.8715\n","Epoch 64/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0751 - accuracy: 0.9762 - val_loss: 0.4108 - val_accuracy: 0.8747\n","Epoch 65/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0692 - accuracy: 0.9818 - val_loss: 0.4219 - val_accuracy: 0.8758\n","Epoch 66/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0689 - accuracy: 0.9815 - val_loss: 0.4109 - val_accuracy: 0.8801\n","Epoch 67/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0688 - accuracy: 0.9794 - val_loss: 0.4195 - val_accuracy: 0.8747\n","Epoch 68/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0721 - accuracy: 0.9786 - val_loss: 0.4576 - val_accuracy: 0.8694\n","Epoch 69/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0741 - accuracy: 0.9775 - val_loss: 0.4193 - val_accuracy: 0.8779\n","Epoch 70/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0637 - accuracy: 0.9812 - val_loss: 0.4288 - val_accuracy: 0.8769\n","Epoch 71/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0648 - accuracy: 0.9829 - val_loss: 0.4206 - val_accuracy: 0.8726\n","Epoch 72/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0649 - accuracy: 0.9837 - val_loss: 0.4619 - val_accuracy: 0.8672\n","Epoch 73/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0710 - accuracy: 0.9802 - val_loss: 0.4255 - val_accuracy: 0.8769\n","Epoch 74/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0685 - accuracy: 0.9802 - val_loss: 0.4379 - val_accuracy: 0.8726\n","Epoch 75/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0844 - accuracy: 0.9721 - val_loss: 0.4429 - val_accuracy: 0.8715\n","Epoch 76/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0679 - accuracy: 0.9791 - val_loss: 0.4421 - val_accuracy: 0.8704\n","Epoch 77/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0697 - accuracy: 0.9778 - val_loss: 0.4448 - val_accuracy: 0.8704\n","Epoch 78/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0575 - accuracy: 0.9861 - val_loss: 0.4519 - val_accuracy: 0.8683\n","Epoch 79/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0532 - accuracy: 0.9869 - val_loss: 0.4383 - val_accuracy: 0.8715\n","Epoch 80/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0655 - accuracy: 0.9791 - val_loss: 0.5024 - val_accuracy: 0.8597\n","Epoch 81/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0661 - accuracy: 0.9796 - val_loss: 0.4591 - val_accuracy: 0.8737\n","Epoch 82/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0571 - accuracy: 0.9829 - val_loss: 0.4493 - val_accuracy: 0.8758\n","Epoch 83/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0565 - accuracy: 0.9850 - val_loss: 0.4749 - val_accuracy: 0.8651\n","Epoch 84/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0667 - accuracy: 0.9810 - val_loss: 0.4553 - val_accuracy: 0.8769\n","Epoch 85/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0520 - accuracy: 0.9869 - val_loss: 0.4544 - val_accuracy: 0.8704\n","Epoch 86/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0530 - accuracy: 0.9853 - val_loss: 0.4551 - val_accuracy: 0.8758\n","Epoch 87/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0667 - accuracy: 0.9775 - val_loss: 0.4548 - val_accuracy: 0.8737\n","Epoch 88/100\n","30/30 [==============================] - 1s 31ms/step - loss: 0.0572 - accuracy: 0.9855 - val_loss: 0.4444 - val_accuracy: 0.8747\n","Epoch 89/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0479 - accuracy: 0.9898 - val_loss: 0.4572 - val_accuracy: 0.8737\n","Epoch 90/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0520 - accuracy: 0.9879 - val_loss: 0.4576 - val_accuracy: 0.8747\n","Epoch 91/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0652 - accuracy: 0.9775 - val_loss: 0.4702 - val_accuracy: 0.8662\n","Epoch 92/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0525 - accuracy: 0.9866 - val_loss: 0.4570 - val_accuracy: 0.8790\n","Epoch 93/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0520 - accuracy: 0.9871 - val_loss: 0.4643 - val_accuracy: 0.8758\n","Epoch 94/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0492 - accuracy: 0.9855 - val_loss: 0.4959 - val_accuracy: 0.8651\n","Epoch 95/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0470 - accuracy: 0.9871 - val_loss: 0.4817 - val_accuracy: 0.8694\n","Epoch 96/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0480 - accuracy: 0.9855 - val_loss: 0.4807 - val_accuracy: 0.8715\n","Epoch 97/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0447 - accuracy: 0.9877 - val_loss: 0.4827 - val_accuracy: 0.8715\n","Epoch 98/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0447 - accuracy: 0.9890 - val_loss: 0.4867 - val_accuracy: 0.8662\n","Epoch 99/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0537 - accuracy: 0.9842 - val_loss: 0.5268 - val_accuracy: 0.8544\n","Epoch 100/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0696 - accuracy: 0.9770 - val_loss: 0.4923 - val_accuracy: 0.8630\n","{'loss': [0.20341439545154572, 0.17770951986312866, 0.1582697331905365, 0.16159462928771973, 0.16627630591392517, 0.1475919932126999, 0.14233942329883575, 0.14211289584636688, 0.14348909258842468, 0.14574213325977325, 0.1444912850856781, 0.1364782750606537, 0.13487572968006134, 0.13632415235042572, 0.13568894565105438, 0.128662571310997, 0.1368970274925232, 0.13200059533119202, 0.12446577847003937, 0.12601283192634583, 0.12261577695608139, 0.1283644139766693, 0.11949405074119568, 0.11789508908987045, 0.1297609508037567, 0.12514877319335938, 0.11282803863286972, 0.10808790475130081, 0.11440631002187729, 0.11055313050746918, 0.10473577678203583, 0.10905825346708298, 0.10928235203027725, 0.10071074962615967, 0.11266805231571198, 0.10030921548604965, 0.10095743089914322, 0.10715589672327042, 0.0992332473397255, 0.09778479486703873, 0.09692762047052383, 0.09668388217687607, 0.09428655356168747, 0.09583152830600739, 0.09136394411325455, 0.09275394678115845, 0.08782309293746948, 0.08242078125476837, 0.08176751434803009, 0.10803430527448654, 0.08900334686040878, 0.08144587278366089, 0.07826525717973709, 0.08175425231456757, 0.08757235109806061, 0.07678108662366867, 0.09184808284044266, 0.0713915228843689, 0.0816994458436966, 0.06698857247829437, 0.09167134016752243, 0.08526728302240372, 0.07023611664772034, 0.07514280080795288, 0.069155752658844, 0.06892435252666473, 0.06884653121232986, 0.07212129980325699, 0.07408413290977478, 0.06370586156845093, 0.06482494622468948, 0.0648738294839859, 0.07102063298225403, 0.06848260760307312, 0.08437909185886383, 0.0679178237915039, 0.06965503096580505, 0.05753316730260849, 0.053184133023023605, 0.06554180383682251, 0.06607236713171005, 0.05707211419939995, 0.05651864409446716, 0.066733717918396, 0.05198673531413078, 0.05298295617103577, 0.06672240793704987, 0.057203296571969986, 0.04792618751525879, 0.05203510448336601, 0.06523551046848297, 0.052474722266197205, 0.05199720337986946, 0.04915398359298706, 0.047024838626384735, 0.048017825931310654, 0.044687628746032715, 0.04472806677222252, 0.05372489616274834, 0.0696268230676651], 'accuracy': [0.9257969260215759, 0.9349048733711243, 0.9429413080215454, 0.9432092308998108, 0.9341012835502625, 0.9450843930244446, 0.9480310678482056, 0.950709879398346, 0.9512456655502319, 0.9488347172737122, 0.9509777426719666, 0.9541923403739929, 0.9539244771003723, 0.9523171782493591, 0.9544602036476135, 0.9571390151977539, 0.9515135288238525, 0.9515135288238525, 0.9566032886505127, 0.9571390151977539, 0.9555317163467407, 0.9525850415229797, 0.9622287750244141, 0.9576748013496399, 0.9541923403739929, 0.9560675024986267, 0.9627645611763, 0.9649075865745544, 0.9592821002006531, 0.9616929888725281, 0.9673185348510742, 0.9667827486991882, 0.9619609117507935, 0.9689257740974426, 0.9614251255989075, 0.9689257740974426, 0.9683900475502014, 0.9627645611763, 0.9675863981246948, 0.9710688591003418, 0.9697294235229492, 0.968657910823822, 0.9702652096748352, 0.9699973464012146, 0.9708009362220764, 0.9673185348510742, 0.97508704662323, 0.97508704662323, 0.9732118844985962, 0.9638360738754272, 0.972140371799469, 0.9753549695014954, 0.978569507598877, 0.9764264822006226, 0.9710688591003418, 0.9774979948997498, 0.9724082350730896, 0.9815161824226379, 0.9729440212249756, 0.9815161824226379, 0.9699973464012146, 0.9699973464012146, 0.9791052937507629, 0.9761585593223572, 0.9817841053009033, 0.9815161824226379, 0.9793731570243835, 0.978569507598877, 0.9774979948997498, 0.9812483191490173, 0.9828556180000305, 0.9836592674255371, 0.9801768064498901, 0.9801768064498901, 0.972140371799469, 0.9791052937507629, 0.9777658581733704, 0.9860701560974121, 0.9868738055229187, 0.9791052937507629, 0.9796410202980042, 0.9828556180000305, 0.9849986433982849, 0.9809804558753967, 0.9868738055229187, 0.9852665662765503, 0.9774979948997498, 0.9855344295501709, 0.9898205399513245, 0.9879453778266907, 0.9774979948997498, 0.9866059422492981, 0.9871417284011841, 0.9855344295501709, 0.9871417284011841, 0.9855344295501709, 0.9876774549484253, 0.9890168905258179, 0.9841949939727783, 0.9769622087478638], 'val_loss': [0.6619253754615784, 0.657772958278656, 0.6516091227531433, 0.6435957551002502, 0.6361344456672668, 0.6265684962272644, 0.6127853393554688, 0.597197949886322, 0.5787827968597412, 0.5611634850502014, 0.5398945808410645, 0.5164218544960022, 0.4821677505970001, 0.4590094983577728, 0.41963016986846924, 0.389137864112854, 0.36455702781677246, 0.3493524193763733, 0.3392272889614105, 0.32623380422592163, 0.3170367181301117, 0.35033512115478516, 0.31578290462493896, 0.30398833751678467, 0.36866816878318787, 0.33318817615509033, 0.3243039846420288, 0.3253501355648041, 0.326022744178772, 0.3343619108200073, 0.3391250967979431, 0.3436952829360962, 0.4018994867801666, 0.36056897044181824, 0.35948437452316284, 0.35226577520370483, 0.36676883697509766, 0.3590329885482788, 0.3657729923725128, 0.3881824314594269, 0.36246800422668457, 0.36683568358421326, 0.3847852051258087, 0.38376879692077637, 0.3755042850971222, 0.37770339846611023, 0.380485475063324, 0.3786517381668091, 0.39881566166877747, 0.379554808139801, 0.404692679643631, 0.3899838328361511, 0.4116448163986206, 0.41693559288978577, 0.39633089303970337, 0.41989606618881226, 0.39331352710723877, 0.40383675694465637, 0.4178030788898468, 0.408349871635437, 0.5699613690376282, 0.4105261564254761, 0.4227004647254944, 0.4107570946216583, 0.4218868911266327, 0.4108818471431732, 0.4195459187030792, 0.4575917422771454, 0.419303297996521, 0.4288141131401062, 0.4206174314022064, 0.46190571784973145, 0.4254639148712158, 0.43787747621536255, 0.44285494089126587, 0.44209009408950806, 0.44478920102119446, 0.4519038200378418, 0.4383167624473572, 0.5024107098579407, 0.45908206701278687, 0.4493486285209656, 0.4748968780040741, 0.4552750587463379, 0.4543614089488983, 0.45505431294441223, 0.45480021834373474, 0.4443979859352112, 0.45723390579223633, 0.45762088894844055, 0.47024115920066833, 0.45695066452026367, 0.4642801582813263, 0.49586138129234314, 0.4816856384277344, 0.48074132204055786, 0.482684463262558, 0.48667946457862854, 0.5268373489379883, 0.4923132061958313], 'val_accuracy': [0.794432520866394, 0.8040685057640076, 0.8008565306663513, 0.8211991190910339, 0.8233404755592346, 0.8158458471298218, 0.8201285004615784, 0.8211991190910339, 0.8254817724227905, 0.8222697973251343, 0.8286938071250916, 0.8265524506568909, 0.8308351039886475, 0.8383297920227051, 0.8447537422180176, 0.8458244204521179, 0.8372591137886047, 0.8576017022132874, 0.8586723804473877, 0.859743058681488, 0.8629550337791443, 0.856531023979187, 0.8715203404426575, 0.881156325340271, 0.8650963306427002, 0.881156325340271, 0.8800856471061707, 0.8800856471061707, 0.8790149688720703, 0.8779443502426147, 0.8790149688720703, 0.8865096569061279, 0.8693790435791016, 0.8790149688720703, 0.8736616969108582, 0.8800856471061707, 0.8758029937744141, 0.8822270035743713, 0.8747323155403137, 0.8672376871109009, 0.8768736720085144, 0.8768736720085144, 0.8715203404426575, 0.8768736720085144, 0.8790149688720703, 0.881156325340271, 0.8832976222038269, 0.881156325340271, 0.8715203404426575, 0.8768736720085144, 0.8661670088768005, 0.8779443502426147, 0.8725910186767578, 0.8758029937744141, 0.8747323155403137, 0.8672376871109009, 0.8779443502426147, 0.8758029937744141, 0.8747323155403137, 0.8768736720085144, 0.840471088886261, 0.8779443502426147, 0.8715203404426575, 0.8747323155403137, 0.8758029937744141, 0.8800856471061707, 0.8747323155403137, 0.8693790435791016, 0.8779443502426147, 0.8768736720085144, 0.8725910186767578, 0.8672376871109009, 0.8768736720085144, 0.8725910186767578, 0.8715203404426575, 0.8704496622085571, 0.8704496622085571, 0.8683083653450012, 0.8715203404426575, 0.859743058681488, 0.8736616969108582, 0.8758029937744141, 0.8650963306427002, 0.8768736720085144, 0.8704496622085571, 0.8758029937744141, 0.8736616969108582, 0.8747323155403137, 0.8736616969108582, 0.8747323155403137, 0.8661670088768005, 0.8790149688720703, 0.8758029937744141, 0.8650963306427002, 0.8693790435791016, 0.8715203404426575, 0.8715203404426575, 0.8661670088768005, 0.8543897271156311, 0.8629550337791443]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 9s 53ms/step - loss: 0.1299 - accuracy: 0.9569 - val_loss: 0.6557 - val_accuracy: 0.8009\n","Epoch 2/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1298 - accuracy: 0.9561 - val_loss: 0.6495 - val_accuracy: 0.7623\n","Epoch 3/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1017 - accuracy: 0.9697 - val_loss: 0.6430 - val_accuracy: 0.8158\n","Epoch 4/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0984 - accuracy: 0.9684 - val_loss: 0.6337 - val_accuracy: 0.7976\n","Epoch 5/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0910 - accuracy: 0.9705 - val_loss: 0.6245 - val_accuracy: 0.7784\n","Epoch 6/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0905 - accuracy: 0.9713 - val_loss: 0.6137 - val_accuracy: 0.8148\n","Epoch 7/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0831 - accuracy: 0.9743 - val_loss: 0.5972 - val_accuracy: 0.7976\n","Epoch 8/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0815 - accuracy: 0.9767 - val_loss: 0.5788 - val_accuracy: 0.8073\n","Epoch 9/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0849 - accuracy: 0.9759 - val_loss: 0.5593 - val_accuracy: 0.7955\n","Epoch 10/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0846 - accuracy: 0.9751 - val_loss: 0.5385 - val_accuracy: 0.8116\n","Epoch 11/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0852 - accuracy: 0.9700 - val_loss: 0.5151 - val_accuracy: 0.7987\n","Epoch 12/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0802 - accuracy: 0.9770 - val_loss: 0.4876 - val_accuracy: 0.8158\n","Epoch 13/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0965 - accuracy: 0.9673 - val_loss: 0.4642 - val_accuracy: 0.8266\n","Epoch 14/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0980 - accuracy: 0.9673 - val_loss: 0.4312 - val_accuracy: 0.8255\n","Epoch 15/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0767 - accuracy: 0.9778 - val_loss: 0.4103 - val_accuracy: 0.8319\n","Epoch 16/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0767 - accuracy: 0.9783 - val_loss: 0.3844 - val_accuracy: 0.8330\n","Epoch 17/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0698 - accuracy: 0.9818 - val_loss: 0.3712 - val_accuracy: 0.8287\n","Epoch 18/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.0733 - accuracy: 0.9794 - val_loss: 0.3673 - val_accuracy: 0.8287\n","Epoch 19/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0879 - accuracy: 0.9746 - val_loss: 0.3688 - val_accuracy: 0.8351\n","Epoch 20/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0713 - accuracy: 0.9810 - val_loss: 0.3639 - val_accuracy: 0.8469\n","Epoch 21/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0691 - accuracy: 0.9802 - val_loss: 0.3708 - val_accuracy: 0.8555\n","Epoch 22/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0901 - accuracy: 0.9716 - val_loss: 0.3897 - val_accuracy: 0.8565\n","Epoch 23/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0730 - accuracy: 0.9812 - val_loss: 0.3933 - val_accuracy: 0.8555\n","Epoch 24/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0772 - accuracy: 0.9783 - val_loss: 0.4420 - val_accuracy: 0.8522\n","Epoch 25/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0799 - accuracy: 0.9770 - val_loss: 0.4391 - val_accuracy: 0.8576\n","Epoch 26/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0872 - accuracy: 0.9724 - val_loss: 0.4052 - val_accuracy: 0.8608\n","Epoch 27/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0695 - accuracy: 0.9807 - val_loss: 0.4247 - val_accuracy: 0.8619\n","Epoch 28/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0630 - accuracy: 0.9839 - val_loss: 0.4202 - val_accuracy: 0.8630\n","Epoch 29/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0613 - accuracy: 0.9826 - val_loss: 0.4270 - val_accuracy: 0.8662\n","Epoch 30/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0625 - accuracy: 0.9842 - val_loss: 0.4761 - val_accuracy: 0.8544\n","Epoch 31/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0663 - accuracy: 0.9818 - val_loss: 0.4731 - val_accuracy: 0.8587\n","Epoch 32/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0672 - accuracy: 0.9815 - val_loss: 0.4854 - val_accuracy: 0.8565\n","Epoch 33/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0696 - accuracy: 0.9796 - val_loss: 0.4891 - val_accuracy: 0.8608\n","Epoch 34/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0718 - accuracy: 0.9804 - val_loss: 0.5003 - val_accuracy: 0.8597\n","Epoch 35/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0836 - accuracy: 0.9748 - val_loss: 0.4846 - val_accuracy: 0.8662\n","Epoch 36/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0633 - accuracy: 0.9812 - val_loss: 0.4684 - val_accuracy: 0.8672\n","Epoch 37/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0596 - accuracy: 0.9853 - val_loss: 0.4566 - val_accuracy: 0.8630\n","Epoch 38/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0651 - accuracy: 0.9823 - val_loss: 0.5032 - val_accuracy: 0.8587\n","Epoch 39/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0568 - accuracy: 0.9861 - val_loss: 0.4641 - val_accuracy: 0.8672\n","Epoch 40/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0526 - accuracy: 0.9855 - val_loss: 0.4765 - val_accuracy: 0.8630\n","Epoch 41/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0677 - accuracy: 0.9804 - val_loss: 0.4867 - val_accuracy: 0.8640\n","Epoch 42/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0641 - accuracy: 0.9829 - val_loss: 0.4710 - val_accuracy: 0.8672\n","Epoch 43/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0702 - accuracy: 0.9799 - val_loss: 0.4749 - val_accuracy: 0.8683\n","Epoch 44/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0647 - accuracy: 0.9812 - val_loss: 0.4791 - val_accuracy: 0.8662\n","Epoch 45/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0559 - accuracy: 0.9853 - val_loss: 0.4966 - val_accuracy: 0.8630\n","Epoch 46/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0564 - accuracy: 0.9847 - val_loss: 0.4864 - val_accuracy: 0.8672\n","Epoch 47/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0580 - accuracy: 0.9839 - val_loss: 0.4940 - val_accuracy: 0.8630\n","Epoch 48/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0701 - accuracy: 0.9775 - val_loss: 0.4989 - val_accuracy: 0.8576\n","Epoch 49/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0579 - accuracy: 0.9834 - val_loss: 0.4945 - val_accuracy: 0.8608\n","Epoch 50/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0667 - accuracy: 0.9794 - val_loss: 0.4927 - val_accuracy: 0.8608\n","Epoch 51/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0627 - accuracy: 0.9807 - val_loss: 0.4922 - val_accuracy: 0.8662\n","Epoch 52/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0501 - accuracy: 0.9879 - val_loss: 0.4968 - val_accuracy: 0.8651\n","Epoch 53/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0590 - accuracy: 0.9845 - val_loss: 0.5248 - val_accuracy: 0.8630\n","Epoch 54/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0486 - accuracy: 0.9858 - val_loss: 0.5018 - val_accuracy: 0.8672\n","Epoch 55/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0475 - accuracy: 0.9887 - val_loss: 0.4955 - val_accuracy: 0.8694\n","Epoch 56/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0532 - accuracy: 0.9866 - val_loss: 0.5448 - val_accuracy: 0.8597\n","Epoch 57/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0672 - accuracy: 0.9810 - val_loss: 0.5485 - val_accuracy: 0.8662\n","Epoch 58/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0591 - accuracy: 0.9829 - val_loss: 0.5042 - val_accuracy: 0.8597\n","Epoch 59/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0605 - accuracy: 0.9847 - val_loss: 0.5638 - val_accuracy: 0.8565\n","Epoch 60/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0467 - accuracy: 0.9877 - val_loss: 0.5500 - val_accuracy: 0.8576\n","Epoch 61/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0509 - accuracy: 0.9879 - val_loss: 0.5446 - val_accuracy: 0.8608\n","Epoch 62/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0493 - accuracy: 0.9882 - val_loss: 0.5393 - val_accuracy: 0.8640\n","Epoch 63/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0617 - accuracy: 0.9818 - val_loss: 0.6371 - val_accuracy: 0.8533\n","Epoch 64/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0587 - accuracy: 0.9855 - val_loss: 0.5246 - val_accuracy: 0.8544\n","Epoch 65/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0853 - accuracy: 0.9735 - val_loss: 0.5319 - val_accuracy: 0.8480\n","Epoch 66/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0705 - accuracy: 0.9788 - val_loss: 0.5088 - val_accuracy: 0.8630\n","Epoch 67/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0490 - accuracy: 0.9882 - val_loss: 0.5422 - val_accuracy: 0.8608\n","Epoch 68/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0461 - accuracy: 0.9893 - val_loss: 0.5134 - val_accuracy: 0.8651\n","Epoch 69/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0454 - accuracy: 0.9896 - val_loss: 0.5538 - val_accuracy: 0.8608\n","Epoch 70/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0433 - accuracy: 0.9917 - val_loss: 0.5282 - val_accuracy: 0.8597\n","Epoch 71/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0449 - accuracy: 0.9887 - val_loss: 0.5340 - val_accuracy: 0.8597\n","Epoch 72/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0489 - accuracy: 0.9871 - val_loss: 0.5290 - val_accuracy: 0.8619\n","Epoch 73/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0532 - accuracy: 0.9858 - val_loss: 0.5288 - val_accuracy: 0.8608\n","Epoch 74/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0520 - accuracy: 0.9866 - val_loss: 0.5367 - val_accuracy: 0.8619\n","Epoch 75/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0419 - accuracy: 0.9914 - val_loss: 0.5617 - val_accuracy: 0.8619\n","Epoch 76/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0456 - accuracy: 0.9898 - val_loss: 0.5419 - val_accuracy: 0.8608\n","Epoch 77/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0420 - accuracy: 0.9912 - val_loss: 0.5574 - val_accuracy: 0.8576\n","Epoch 78/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0432 - accuracy: 0.9890 - val_loss: 0.5495 - val_accuracy: 0.8608\n","Epoch 79/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0544 - accuracy: 0.9850 - val_loss: 0.6743 - val_accuracy: 0.8448\n","Epoch 80/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0535 - accuracy: 0.9847 - val_loss: 0.6317 - val_accuracy: 0.8555\n","Epoch 81/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0487 - accuracy: 0.9877 - val_loss: 0.5734 - val_accuracy: 0.8597\n","Epoch 82/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0492 - accuracy: 0.9861 - val_loss: 0.5481 - val_accuracy: 0.8587\n","Epoch 83/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0449 - accuracy: 0.9896 - val_loss: 0.5625 - val_accuracy: 0.8608\n","Epoch 84/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0503 - accuracy: 0.9879 - val_loss: 0.6344 - val_accuracy: 0.8480\n","Epoch 85/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0476 - accuracy: 0.9877 - val_loss: 0.5431 - val_accuracy: 0.8662\n","Epoch 86/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0474 - accuracy: 0.9893 - val_loss: 0.5964 - val_accuracy: 0.8555\n","Epoch 87/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0417 - accuracy: 0.9914 - val_loss: 0.6242 - val_accuracy: 0.8544\n","Epoch 88/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0433 - accuracy: 0.9893 - val_loss: 0.5873 - val_accuracy: 0.8608\n","Epoch 89/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0404 - accuracy: 0.9917 - val_loss: 0.6314 - val_accuracy: 0.8587\n","Epoch 90/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0427 - accuracy: 0.9909 - val_loss: 0.6136 - val_accuracy: 0.8533\n","Epoch 91/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0407 - accuracy: 0.9914 - val_loss: 0.5843 - val_accuracy: 0.8544\n","Epoch 92/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0373 - accuracy: 0.9922 - val_loss: 0.5734 - val_accuracy: 0.8640\n","Epoch 93/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0365 - accuracy: 0.9928 - val_loss: 0.5951 - val_accuracy: 0.8555\n","Epoch 94/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0383 - accuracy: 0.9920 - val_loss: 0.6099 - val_accuracy: 0.8565\n","Epoch 95/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0627 - accuracy: 0.9804 - val_loss: 0.6131 - val_accuracy: 0.8437\n","Epoch 96/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0526 - accuracy: 0.9855 - val_loss: 0.5783 - val_accuracy: 0.8565\n","Epoch 97/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0413 - accuracy: 0.9906 - val_loss: 0.6966 - val_accuracy: 0.8426\n","Epoch 98/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0425 - accuracy: 0.9901 - val_loss: 0.5644 - val_accuracy: 0.8619\n","Epoch 99/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0412 - accuracy: 0.9901 - val_loss: 0.6565 - val_accuracy: 0.8490\n","Epoch 100/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0394 - accuracy: 0.9920 - val_loss: 0.6149 - val_accuracy: 0.8544\n","{'loss': [0.12991763651371002, 0.12976796925067902, 0.10172021389007568, 0.09835854172706604, 0.09102251380681992, 0.09051453322172165, 0.08309178799390793, 0.08146078139543533, 0.08488278836011887, 0.08462943881750107, 0.08518711477518082, 0.08020854741334915, 0.09654552489519119, 0.09797661006450653, 0.07668479532003403, 0.07667084038257599, 0.0698167160153389, 0.07327700406312943, 0.08793876320123672, 0.0713268592953682, 0.0690939798951149, 0.09007006883621216, 0.07302113622426987, 0.07721910625696182, 0.07986107468605042, 0.08716435730457306, 0.06950952112674713, 0.06303325295448303, 0.061333708465099335, 0.06252480298280716, 0.06632158905267715, 0.06721676141023636, 0.06957834959030151, 0.07177095115184784, 0.08360055834054947, 0.06329365074634552, 0.059598103165626526, 0.06505431979894638, 0.05678458884358406, 0.05258627235889435, 0.06772508472204208, 0.064053475856781, 0.07021541893482208, 0.06466594338417053, 0.05587540939450264, 0.056419819593429565, 0.05797242000699043, 0.07012572884559631, 0.057929206639528275, 0.06673269718885422, 0.06265424191951752, 0.05007566139101982, 0.05900324881076813, 0.04861340671777725, 0.04750867933034897, 0.05317316949367523, 0.06722033023834229, 0.059111449867486954, 0.06047091260552406, 0.04671385511755943, 0.05092201754450798, 0.04933888837695122, 0.0617196261882782, 0.05868588387966156, 0.0852503851056099, 0.07048545032739639, 0.04899162799119949, 0.04614788666367531, 0.04540875181555748, 0.0432649627327919, 0.04487410932779312, 0.04889465123414993, 0.05318339914083481, 0.05203135311603546, 0.041867539286613464, 0.0455828495323658, 0.041952766478061676, 0.043203260749578476, 0.054418448358774185, 0.05349915102124214, 0.04871802031993866, 0.04920553043484688, 0.04491099715232849, 0.050260044634342194, 0.04764844477176666, 0.047430381178855896, 0.041736628860235214, 0.04326537996530533, 0.040387216955423355, 0.04272647574543953, 0.040682271122932434, 0.03731899708509445, 0.036516398191452026, 0.03833260014653206, 0.06269925087690353, 0.05263928696513176, 0.041279617697000504, 0.042456015944480896, 0.04117263853549957, 0.039350345730781555], 'accuracy': [0.9568711519241333, 0.9560675024986267, 0.9697294235229492, 0.9683900475502014, 0.9705330729484558, 0.9713367223739624, 0.9742833971977234, 0.9766943454742432, 0.9758906960487366, 0.97508704662323, 0.9699973464012146, 0.9769622087478638, 0.9673185348510742, 0.9673185348510742, 0.9777658581733704, 0.9783016443252563, 0.9817841053009033, 0.9793731570243835, 0.9745513200759888, 0.9809804558753967, 0.9801768064498901, 0.971604585647583, 0.9812483191490173, 0.9783016443252563, 0.9769622087478638, 0.9724082350730896, 0.9807125926017761, 0.9839271306991577, 0.9825877547264099, 0.9841949939727783, 0.9817841053009033, 0.9815161824226379, 0.9796410202980042, 0.9804446697235107, 0.9748191833496094, 0.9812483191490173, 0.9852665662765503, 0.9823198318481445, 0.9860701560974121, 0.9855344295501709, 0.9804446697235107, 0.9828556180000305, 0.9799089431762695, 0.9812483191490173, 0.9852665662765503, 0.9847307801246643, 0.9839271306991577, 0.9774979948997498, 0.9833913445472717, 0.9793731570243835, 0.9807125926017761, 0.9879453778266907, 0.9844629168510437, 0.9858022928237915, 0.9887489676475525, 0.9866059422492981, 0.9809804558753967, 0.9828556180000305, 0.9847307801246643, 0.9876774549484253, 0.9879453778266907, 0.9882132411003113, 0.9817841053009033, 0.9855344295501709, 0.9734797477722168, 0.9788373708724976, 0.9882132411003113, 0.9892847537994385, 0.9895526170730591, 0.9916957020759583, 0.9887489676475525, 0.9871417284011841, 0.9858022928237915, 0.9866059422492981, 0.9914277791976929, 0.9898205399513245, 0.9911599159240723, 0.9890168905258179, 0.9849986433982849, 0.9847307801246643, 0.9876774549484253, 0.9860701560974121, 0.9895526170730591, 0.9879453778266907, 0.9876774549484253, 0.9892847537994385, 0.9914277791976929, 0.9892847537994385, 0.9916957020759583, 0.9908920526504517, 0.9914277791976929, 0.9922314286231995, 0.9927672147750854, 0.9919635653495789, 0.9804446697235107, 0.9855344295501709, 0.990624189376831, 0.9900884032249451, 0.9900884032249451, 0.9919635653495789], 'val_loss': [0.6556721925735474, 0.6495050191879272, 0.642959475517273, 0.6336504817008972, 0.6245169043540955, 0.6136637330055237, 0.597203254699707, 0.5788173675537109, 0.5592562556266785, 0.5385122299194336, 0.5151157379150391, 0.4875963628292084, 0.4642331302165985, 0.4312317669391632, 0.4102940559387207, 0.3844200074672699, 0.3712497353553772, 0.36734580993652344, 0.36880552768707275, 0.3639078140258789, 0.37084999680519104, 0.38974377512931824, 0.3933057487010956, 0.44203704595565796, 0.43907615542411804, 0.40520355105400085, 0.4246751070022583, 0.4202461838722229, 0.4269520342350006, 0.47606226801872253, 0.4730713963508606, 0.4853827953338623, 0.48908382654190063, 0.5002856254577637, 0.4846137464046478, 0.4683643579483032, 0.45664846897125244, 0.503240168094635, 0.4640759229660034, 0.47654280066490173, 0.4866660535335541, 0.4710170030593872, 0.47489818930625916, 0.4790708124637604, 0.4965934455394745, 0.4864269495010376, 0.49398505687713623, 0.49886608123779297, 0.49449145793914795, 0.49274107813835144, 0.49217525124549866, 0.4967963397502899, 0.5248286128044128, 0.5018360614776611, 0.4955170452594757, 0.5448377132415771, 0.5484951734542847, 0.5041795372962952, 0.5638182163238525, 0.549966037273407, 0.544633686542511, 0.5392535924911499, 0.6371466517448425, 0.5245875716209412, 0.5318685173988342, 0.5088267922401428, 0.5422082543373108, 0.5133937001228333, 0.5538430213928223, 0.5282049179077148, 0.5339965224266052, 0.5290402173995972, 0.5288394093513489, 0.5367090106010437, 0.5616694092750549, 0.5419338941574097, 0.5574421286582947, 0.5495221018791199, 0.6743447780609131, 0.63173508644104, 0.5734457969665527, 0.5481018424034119, 0.562513530254364, 0.6344138979911804, 0.543097972869873, 0.5963853597640991, 0.6242361068725586, 0.5873287320137024, 0.6313684582710266, 0.6135988831520081, 0.5843054056167603, 0.5733999013900757, 0.5950785279273987, 0.6099333763122559, 0.6131449937820435, 0.5783496499061584, 0.6965603828430176, 0.5644494295120239, 0.65653395652771, 0.6148741245269775], 'val_accuracy': [0.8008565306663513, 0.762312650680542, 0.8158458471298218, 0.7976445555686951, 0.778372585773468, 0.8147751688957214, 0.7976445555686951, 0.8072805404663086, 0.7955031991004944, 0.8115631937980652, 0.7987151741981506, 0.8158458471298218, 0.8265524506568909, 0.8254817724227905, 0.8319057822227478, 0.8329764604568481, 0.8286938071250916, 0.8286938071250916, 0.835117757320404, 0.8468950986862183, 0.8554604053497314, 0.856531023979187, 0.8554604053497314, 0.8522483706474304, 0.8576017022132874, 0.8608136773109436, 0.861884355545044, 0.8629550337791443, 0.8661670088768005, 0.8543897271156311, 0.8586723804473877, 0.856531023979187, 0.8608136773109436, 0.859743058681488, 0.8661670088768005, 0.8672376871109009, 0.8629550337791443, 0.8586723804473877, 0.8672376871109009, 0.8629550337791443, 0.8640257120132446, 0.8672376871109009, 0.8683083653450012, 0.8661670088768005, 0.8629550337791443, 0.8672376871109009, 0.8629550337791443, 0.8576017022132874, 0.8608136773109436, 0.8608136773109436, 0.8661670088768005, 0.8650963306427002, 0.8629550337791443, 0.8672376871109009, 0.8693790435791016, 0.859743058681488, 0.8661670088768005, 0.859743058681488, 0.856531023979187, 0.8576017022132874, 0.8608136773109436, 0.8640257120132446, 0.8533190488815308, 0.8543897271156311, 0.8479657173156738, 0.8629550337791443, 0.8608136773109436, 0.8650963306427002, 0.8608136773109436, 0.859743058681488, 0.859743058681488, 0.861884355545044, 0.8608136773109436, 0.861884355545044, 0.861884355545044, 0.8608136773109436, 0.8576017022132874, 0.8608136773109436, 0.8447537422180176, 0.8554604053497314, 0.859743058681488, 0.8586723804473877, 0.8608136773109436, 0.8479657173156738, 0.8661670088768005, 0.8554604053497314, 0.8543897271156311, 0.8608136773109436, 0.8586723804473877, 0.8533190488815308, 0.8543897271156311, 0.8640257120132446, 0.8554604053497314, 0.856531023979187, 0.8436830639839172, 0.856531023979187, 0.8426124453544617, 0.861884355545044, 0.8490363955497742, 0.8543897271156311]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 71ms/step - loss: 0.1370 - accuracy: 0.9515 - val_loss: 0.6517 - val_accuracy: 0.7805\n","Epoch 2/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.1021 - accuracy: 0.9671 - val_loss: 0.6477 - val_accuracy: 0.7794\n","Epoch 3/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.1017 - accuracy: 0.9697 - val_loss: 0.6398 - val_accuracy: 0.7837\n","Epoch 4/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1133 - accuracy: 0.9590 - val_loss: 0.6288 - val_accuracy: 0.8051\n","Epoch 5/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1039 - accuracy: 0.9657 - val_loss: 0.6199 - val_accuracy: 0.7891\n","Epoch 6/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0928 - accuracy: 0.9721 - val_loss: 0.6058 - val_accuracy: 0.8244\n","Epoch 7/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0894 - accuracy: 0.9708 - val_loss: 0.5904 - val_accuracy: 0.7987\n","Epoch 8/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0923 - accuracy: 0.9681 - val_loss: 0.5699 - val_accuracy: 0.8383\n","Epoch 9/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0869 - accuracy: 0.9705 - val_loss: 0.5506 - val_accuracy: 0.8426\n","Epoch 10/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0749 - accuracy: 0.9780 - val_loss: 0.5241 - val_accuracy: 0.8383\n","Epoch 11/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0764 - accuracy: 0.9778 - val_loss: 0.4941 - val_accuracy: 0.8405\n","Epoch 12/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0753 - accuracy: 0.9778 - val_loss: 0.4706 - val_accuracy: 0.8019\n","Epoch 13/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0801 - accuracy: 0.9767 - val_loss: 0.4317 - val_accuracy: 0.8426\n","Epoch 14/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0842 - accuracy: 0.9729 - val_loss: 0.4016 - val_accuracy: 0.8522\n","Epoch 15/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0684 - accuracy: 0.9807 - val_loss: 0.3694 - val_accuracy: 0.8565\n","Epoch 16/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0723 - accuracy: 0.9767 - val_loss: 0.3408 - val_accuracy: 0.8555\n","Epoch 17/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0782 - accuracy: 0.9737 - val_loss: 0.3199 - val_accuracy: 0.8790\n","Epoch 18/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0772 - accuracy: 0.9775 - val_loss: 0.3010 - val_accuracy: 0.8704\n","Epoch 19/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0669 - accuracy: 0.9815 - val_loss: 0.2811 - val_accuracy: 0.8833\n","Epoch 20/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0664 - accuracy: 0.9786 - val_loss: 0.2762 - val_accuracy: 0.8919\n","Epoch 21/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0789 - accuracy: 0.9724 - val_loss: 0.2721 - val_accuracy: 0.8940\n","Epoch 22/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0637 - accuracy: 0.9804 - val_loss: 0.2767 - val_accuracy: 0.8929\n","Epoch 23/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0682 - accuracy: 0.9788 - val_loss: 0.2658 - val_accuracy: 0.9004\n","Epoch 24/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0716 - accuracy: 0.9794 - val_loss: 0.2751 - val_accuracy: 0.9004\n","Epoch 25/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0599 - accuracy: 0.9834 - val_loss: 0.3397 - val_accuracy: 0.8844\n","Epoch 26/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1053 - accuracy: 0.9638 - val_loss: 0.3045 - val_accuracy: 0.8972\n","Epoch 27/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0687 - accuracy: 0.9788 - val_loss: 0.2792 - val_accuracy: 0.9026\n","Epoch 28/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0640 - accuracy: 0.9826 - val_loss: 0.2939 - val_accuracy: 0.9004\n","Epoch 29/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0644 - accuracy: 0.9818 - val_loss: 0.2889 - val_accuracy: 0.9058\n","Epoch 30/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0621 - accuracy: 0.9812 - val_loss: 0.3281 - val_accuracy: 0.8983\n","Epoch 31/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0650 - accuracy: 0.9796 - val_loss: 0.3133 - val_accuracy: 0.9026\n","Epoch 32/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0598 - accuracy: 0.9823 - val_loss: 0.2973 - val_accuracy: 0.9047\n","Epoch 33/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0559 - accuracy: 0.9855 - val_loss: 0.3045 - val_accuracy: 0.8994\n","Epoch 34/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0526 - accuracy: 0.9882 - val_loss: 0.3117 - val_accuracy: 0.9004\n","Epoch 35/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0519 - accuracy: 0.9853 - val_loss: 0.3035 - val_accuracy: 0.9015\n","Epoch 36/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0588 - accuracy: 0.9853 - val_loss: 0.3084 - val_accuracy: 0.9004\n","Epoch 37/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0606 - accuracy: 0.9850 - val_loss: 0.3491 - val_accuracy: 0.9004\n","Epoch 38/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0641 - accuracy: 0.9818 - val_loss: 0.3186 - val_accuracy: 0.9036\n","Epoch 39/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0563 - accuracy: 0.9839 - val_loss: 0.3168 - val_accuracy: 0.9047\n","Epoch 40/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0572 - accuracy: 0.9821 - val_loss: 0.3566 - val_accuracy: 0.8897\n","Epoch 41/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0579 - accuracy: 0.9839 - val_loss: 0.3199 - val_accuracy: 0.8983\n","Epoch 42/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0538 - accuracy: 0.9847 - val_loss: 0.3431 - val_accuracy: 0.8908\n","Epoch 43/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0611 - accuracy: 0.9826 - val_loss: 0.3254 - val_accuracy: 0.8972\n","Epoch 44/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0502 - accuracy: 0.9869 - val_loss: 0.3457 - val_accuracy: 0.9004\n","Epoch 45/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0504 - accuracy: 0.9863 - val_loss: 0.3523 - val_accuracy: 0.8940\n","Epoch 46/100\n","30/30 [==============================] - 1s 33ms/step - loss: 0.0423 - accuracy: 0.9912 - val_loss: 0.3365 - val_accuracy: 0.8994\n","Epoch 47/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0455 - accuracy: 0.9890 - val_loss: 0.3375 - val_accuracy: 0.8972\n","Epoch 48/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.0495 - accuracy: 0.9874 - val_loss: 0.3801 - val_accuracy: 0.8940\n","Epoch 49/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0523 - accuracy: 0.9855 - val_loss: 0.3633 - val_accuracy: 0.9015\n","Epoch 50/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0609 - accuracy: 0.9815 - val_loss: 0.5247 - val_accuracy: 0.8715\n","Epoch 51/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0575 - accuracy: 0.9826 - val_loss: 0.3408 - val_accuracy: 0.8994\n","Epoch 52/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0461 - accuracy: 0.9898 - val_loss: 0.3676 - val_accuracy: 0.8972\n","Epoch 53/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0438 - accuracy: 0.9896 - val_loss: 0.3422 - val_accuracy: 0.8972\n","Epoch 54/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0397 - accuracy: 0.9922 - val_loss: 0.3875 - val_accuracy: 0.8961\n","Epoch 55/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0523 - accuracy: 0.9850 - val_loss: 0.4314 - val_accuracy: 0.8929\n","Epoch 56/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0558 - accuracy: 0.9858 - val_loss: 0.3429 - val_accuracy: 0.9004\n","Epoch 57/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0452 - accuracy: 0.9896 - val_loss: 0.3466 - val_accuracy: 0.8940\n","Epoch 58/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0468 - accuracy: 0.9877 - val_loss: 0.3601 - val_accuracy: 0.8983\n","Epoch 59/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0445 - accuracy: 0.9879 - val_loss: 0.3492 - val_accuracy: 0.8994\n","Epoch 60/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0445 - accuracy: 0.9879 - val_loss: 0.4406 - val_accuracy: 0.8929\n","Epoch 61/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0739 - accuracy: 0.9759 - val_loss: 0.4436 - val_accuracy: 0.8876\n","Epoch 62/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0482 - accuracy: 0.9871 - val_loss: 0.3709 - val_accuracy: 0.8983\n","Epoch 63/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0639 - accuracy: 0.9802 - val_loss: 0.3381 - val_accuracy: 0.9036\n","Epoch 64/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0462 - accuracy: 0.9882 - val_loss: 0.3749 - val_accuracy: 0.8961\n","Epoch 65/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0430 - accuracy: 0.9909 - val_loss: 0.3465 - val_accuracy: 0.8983\n","Epoch 66/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0411 - accuracy: 0.9906 - val_loss: 0.3541 - val_accuracy: 0.8961\n","Epoch 67/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0404 - accuracy: 0.9912 - val_loss: 0.3644 - val_accuracy: 0.9004\n","Epoch 68/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.0392 - accuracy: 0.9917 - val_loss: 0.3681 - val_accuracy: 0.8951\n","Epoch 69/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0343 - accuracy: 0.9933 - val_loss: 0.4155 - val_accuracy: 0.8983\n","Epoch 70/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0425 - accuracy: 0.9901 - val_loss: 0.3624 - val_accuracy: 0.8951\n","Epoch 71/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0379 - accuracy: 0.9914 - val_loss: 0.3768 - val_accuracy: 0.8940\n","Epoch 72/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0386 - accuracy: 0.9917 - val_loss: 0.3786 - val_accuracy: 0.8951\n","Epoch 73/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0385 - accuracy: 0.9914 - val_loss: 0.3798 - val_accuracy: 0.8951\n","Epoch 74/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0382 - accuracy: 0.9917 - val_loss: 0.3785 - val_accuracy: 0.8919\n","Epoch 75/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0454 - accuracy: 0.9874 - val_loss: 0.3809 - val_accuracy: 0.8929\n","Epoch 76/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0380 - accuracy: 0.9909 - val_loss: 0.3793 - val_accuracy: 0.8897\n","Epoch 77/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0396 - accuracy: 0.9898 - val_loss: 0.4249 - val_accuracy: 0.8994\n","Epoch 78/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0566 - accuracy: 0.9826 - val_loss: 0.3910 - val_accuracy: 0.8929\n","Epoch 79/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0656 - accuracy: 0.9794 - val_loss: 0.3909 - val_accuracy: 0.8887\n","Epoch 80/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0454 - accuracy: 0.9877 - val_loss: 0.3725 - val_accuracy: 0.9015\n","Epoch 81/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0387 - accuracy: 0.9912 - val_loss: 0.3797 - val_accuracy: 0.8908\n","Epoch 82/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0458 - accuracy: 0.9901 - val_loss: 0.4286 - val_accuracy: 0.8951\n","Epoch 83/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0438 - accuracy: 0.9879 - val_loss: 0.3676 - val_accuracy: 0.8972\n","Epoch 84/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0352 - accuracy: 0.9922 - val_loss: 0.3673 - val_accuracy: 0.8972\n","Epoch 85/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0345 - accuracy: 0.9933 - val_loss: 0.3699 - val_accuracy: 0.8961\n","Epoch 86/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0337 - accuracy: 0.9936 - val_loss: 0.3851 - val_accuracy: 0.8972\n","Epoch 87/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0336 - accuracy: 0.9933 - val_loss: 0.3709 - val_accuracy: 0.8983\n","Epoch 88/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0338 - accuracy: 0.9930 - val_loss: 0.3741 - val_accuracy: 0.9004\n","Epoch 89/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0360 - accuracy: 0.9917 - val_loss: 0.4153 - val_accuracy: 0.8940\n","Epoch 90/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0336 - accuracy: 0.9936 - val_loss: 0.3798 - val_accuracy: 0.8951\n","Epoch 91/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0383 - accuracy: 0.9909 - val_loss: 0.3973 - val_accuracy: 0.8876\n","Epoch 92/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.0372 - accuracy: 0.9914 - val_loss: 0.4047 - val_accuracy: 0.8951\n","Epoch 93/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0370 - accuracy: 0.9922 - val_loss: 0.3981 - val_accuracy: 0.8951\n","Epoch 94/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.0443 - accuracy: 0.9882 - val_loss: 0.3818 - val_accuracy: 0.8961\n","Epoch 95/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0370 - accuracy: 0.9912 - val_loss: 0.3861 - val_accuracy: 0.8994\n","Epoch 96/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0434 - accuracy: 0.9874 - val_loss: 0.3777 - val_accuracy: 0.8983\n","Epoch 97/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0360 - accuracy: 0.9920 - val_loss: 0.3828 - val_accuracy: 0.8961\n","Epoch 98/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0312 - accuracy: 0.9941 - val_loss: 0.4388 - val_accuracy: 0.8951\n","Epoch 99/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0355 - accuracy: 0.9912 - val_loss: 0.3971 - val_accuracy: 0.8908\n","Epoch 100/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0360 - accuracy: 0.9922 - val_loss: 0.3962 - val_accuracy: 0.8983\n","{'loss': [0.13698382675647736, 0.10213731974363327, 0.10172243416309357, 0.11329665780067444, 0.10388260334730148, 0.09277521073818207, 0.08944259583950043, 0.09227672219276428, 0.08692775666713715, 0.07492182403802872, 0.0763925239443779, 0.07526356726884842, 0.08010056614875793, 0.08419135212898254, 0.06837750226259232, 0.07225603610277176, 0.07824641466140747, 0.07724543660879135, 0.06689000129699707, 0.06635373085737228, 0.07886399328708649, 0.06371891498565674, 0.0681983157992363, 0.07164192199707031, 0.0599021390080452, 0.10533645004034042, 0.06871494650840759, 0.06396506726741791, 0.06435959041118622, 0.06212975084781647, 0.06497827917337418, 0.059816595166921616, 0.05589619278907776, 0.05262809246778488, 0.051949016749858856, 0.05877626687288284, 0.06059066951274872, 0.06414537131786346, 0.0563090480864048, 0.057156383991241455, 0.05792810395359993, 0.05375352129340172, 0.06114951893687248, 0.050235770642757416, 0.050395138561725616, 0.04234132170677185, 0.0455324649810791, 0.04945354908704758, 0.05229511857032776, 0.06090208888053894, 0.05747814103960991, 0.04606904089450836, 0.0437597930431366, 0.03971927613019943, 0.052266672253608704, 0.05584290996193886, 0.045159030705690384, 0.04682518169283867, 0.044517114758491516, 0.04445941001176834, 0.07385992258787155, 0.048205211758613586, 0.06385963410139084, 0.04621773958206177, 0.04296654835343361, 0.04114215448498726, 0.04042191430926323, 0.039203111082315445, 0.034267671406269073, 0.042507272213697433, 0.03786982223391533, 0.03857964277267456, 0.03845249488949776, 0.03817438706755638, 0.045384615659713745, 0.038034431636333466, 0.039622962474823, 0.056592635810375214, 0.06563211232423782, 0.045442089438438416, 0.038707833737134933, 0.04579503461718559, 0.04376916587352753, 0.035197578370571136, 0.034488603472709656, 0.033676519989967346, 0.03360374644398689, 0.03376295417547226, 0.036035895347595215, 0.03363041579723358, 0.03829262778162956, 0.03715911880135536, 0.03704790771007538, 0.044271230697631836, 0.036953914910554886, 0.043410081416368484, 0.036034129559993744, 0.031235333532094955, 0.035485103726387024, 0.03597013279795647], 'accuracy': [0.9515135288238525, 0.9670506119728088, 0.9697294235229492, 0.9590141773223877, 0.965711236000061, 0.972140371799469, 0.9708009362220764, 0.968122124671936, 0.9705330729484558, 0.9780337810516357, 0.9777658581733704, 0.9777658581733704, 0.9766943454742432, 0.9729440212249756, 0.9807125926017761, 0.9766943454742432, 0.9737476706504822, 0.9774979948997498, 0.9815161824226379, 0.978569507598877, 0.9724082350730896, 0.9804446697235107, 0.9788373708724976, 0.9793731570243835, 0.9833913445472717, 0.9638360738754272, 0.9788373708724976, 0.9825877547264099, 0.9817841053009033, 0.9812483191490173, 0.9796410202980042, 0.9823198318481445, 0.9855344295501709, 0.9882132411003113, 0.9852665662765503, 0.9852665662765503, 0.9849986433982849, 0.9817841053009033, 0.9839271306991577, 0.9820519685745239, 0.9839271306991577, 0.9847307801246643, 0.9825877547264099, 0.9868738055229187, 0.9863380789756775, 0.9911599159240723, 0.9890168905258179, 0.9874095916748047, 0.9855344295501709, 0.9815161824226379, 0.9825877547264099, 0.9898205399513245, 0.9895526170730591, 0.9922314286231995, 0.9849986433982849, 0.9858022928237915, 0.9895526170730591, 0.9876774549484253, 0.9879453778266907, 0.9879453778266907, 0.9758906960487366, 0.9871417284011841, 0.9801768064498901, 0.9882132411003113, 0.9908920526504517, 0.990624189376831, 0.9911599159240723, 0.9916957020759583, 0.9933030009269714, 0.9900884032249451, 0.9914277791976929, 0.9916957020759583, 0.9914277791976929, 0.9916957020759583, 0.9874095916748047, 0.9908920526504517, 0.9898205399513245, 0.9825877547264099, 0.9793731570243835, 0.9876774549484253, 0.9911599159240723, 0.9900884032249451, 0.9879453778266907, 0.9922314286231995, 0.9933030009269714, 0.993570864200592, 0.9933030009269714, 0.993035078048706, 0.9916957020759583, 0.993570864200592, 0.9908920526504517, 0.9914277791976929, 0.9922314286231995, 0.9882132411003113, 0.9911599159240723, 0.9874095916748047, 0.9919635653495789, 0.9941065907478333, 0.9911599159240723, 0.9922314286231995], 'val_loss': [0.6516863107681274, 0.6476832628250122, 0.6398094296455383, 0.6287620663642883, 0.619851291179657, 0.6058083176612854, 0.5904329419136047, 0.5698640942573547, 0.5505551695823669, 0.5241042971611023, 0.49407005310058594, 0.4706379175186157, 0.4316508173942566, 0.40161001682281494, 0.3693704605102539, 0.3408139944076538, 0.31993567943573, 0.30101561546325684, 0.281085342168808, 0.27621570229530334, 0.2721044719219208, 0.27673211693763733, 0.265796035528183, 0.275055468082428, 0.33968448638916016, 0.30448758602142334, 0.27915364503860474, 0.2938939929008484, 0.2888573110103607, 0.3280550539493561, 0.3133141100406647, 0.2973048686981201, 0.3044692575931549, 0.3116650879383087, 0.3035028874874115, 0.3084244132041931, 0.34906861186027527, 0.3185723125934601, 0.3168186545372009, 0.35664281249046326, 0.31992653012275696, 0.3430708944797516, 0.3253537714481354, 0.34570443630218506, 0.3522510528564453, 0.3364822566509247, 0.3375183343887329, 0.38014456629753113, 0.36327433586120605, 0.5247193574905396, 0.34081465005874634, 0.36758774518966675, 0.3421524465084076, 0.3875170946121216, 0.43144217133522034, 0.3428761661052704, 0.3466486930847168, 0.360061913728714, 0.34920811653137207, 0.4406003952026367, 0.4436088800430298, 0.3709259033203125, 0.33810049295425415, 0.3748681843280792, 0.34651848673820496, 0.35408955812454224, 0.3643697500228882, 0.36807772517204285, 0.4155246317386627, 0.3624284565448761, 0.3768334686756134, 0.37864774465560913, 0.37977850437164307, 0.3785012662410736, 0.38091814517974854, 0.3792612850666046, 0.4248518645763397, 0.3910091519355774, 0.390872985124588, 0.3725346326828003, 0.37967056035995483, 0.42858076095581055, 0.3675934970378876, 0.3673253655433655, 0.369933545589447, 0.38514357805252075, 0.3709407150745392, 0.3741123378276825, 0.4153202176094055, 0.3798111379146576, 0.3973177671432495, 0.4046914875507355, 0.3980556130409241, 0.38183802366256714, 0.386140376329422, 0.37767869234085083, 0.38279223442077637, 0.4388440251350403, 0.39709609746932983, 0.39624476432800293], 'val_accuracy': [0.7805139422416687, 0.7794432640075684, 0.783725917339325, 0.8051391839981079, 0.7890792489051819, 0.824411153793335, 0.7987151741981506, 0.8383297920227051, 0.8426124453544617, 0.8383297920227051, 0.840471088886261, 0.8019272089004517, 0.8426124453544617, 0.8522483706474304, 0.856531023979187, 0.8554604053497314, 0.8790149688720703, 0.8704496622085571, 0.8832976222038269, 0.8918629288673401, 0.8940042853355408, 0.8929336071014404, 0.900428295135498, 0.900428295135498, 0.8843683004379272, 0.897216260433197, 0.902569591999054, 0.900428295135498, 0.9057815670967102, 0.8982869386672974, 0.902569591999054, 0.9047109484672546, 0.8993576169013977, 0.900428295135498, 0.9014989137649536, 0.900428295135498, 0.900428295135498, 0.9036402702331543, 0.9047109484672546, 0.8897216320037842, 0.8982869386672974, 0.8907923102378845, 0.897216260433197, 0.900428295135498, 0.8940042853355408, 0.8993576169013977, 0.897216260433197, 0.8940042853355408, 0.9014989137649536, 0.8715203404426575, 0.8993576169013977, 0.897216260433197, 0.897216260433197, 0.8961455821990967, 0.8929336071014404, 0.900428295135498, 0.8940042853355408, 0.8982869386672974, 0.8993576169013977, 0.8929336071014404, 0.8875802755355835, 0.8982869386672974, 0.9036402702331543, 0.8961455821990967, 0.8982869386672974, 0.8961455821990967, 0.900428295135498, 0.8950749635696411, 0.8982869386672974, 0.8950749635696411, 0.8940042853355408, 0.8950749635696411, 0.8950749635696411, 0.8918629288673401, 0.8929336071014404, 0.8897216320037842, 0.8993576169013977, 0.8929336071014404, 0.8886509537696838, 0.9014989137649536, 0.8907923102378845, 0.8950749635696411, 0.897216260433197, 0.897216260433197, 0.8961455821990967, 0.897216260433197, 0.8982869386672974, 0.900428295135498, 0.8940042853355408, 0.8950749635696411, 0.8875802755355835, 0.8950749635696411, 0.8950749635696411, 0.8961455821990967, 0.8993576169013977, 0.8982869386672974, 0.8961455821990967, 0.8950749635696411, 0.8907923102378845, 0.8982869386672974]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 70ms/step - loss: 0.1426 - accuracy: 0.9523 - val_loss: 0.6541 - val_accuracy: 0.7591\n","Epoch 2/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.1216 - accuracy: 0.9566 - val_loss: 0.6469 - val_accuracy: 0.8105\n","Epoch 3/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1061 - accuracy: 0.9628 - val_loss: 0.6415 - val_accuracy: 0.8191\n","Epoch 4/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1035 - accuracy: 0.9676 - val_loss: 0.6311 - val_accuracy: 0.8244\n","Epoch 5/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0923 - accuracy: 0.9697 - val_loss: 0.6219 - val_accuracy: 0.8212\n","Epoch 6/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0940 - accuracy: 0.9737 - val_loss: 0.6085 - val_accuracy: 0.8137\n","Epoch 7/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0901 - accuracy: 0.9711 - val_loss: 0.5946 - val_accuracy: 0.8233\n","Epoch 8/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0843 - accuracy: 0.9735 - val_loss: 0.5756 - val_accuracy: 0.8137\n","Epoch 9/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0848 - accuracy: 0.9711 - val_loss: 0.5549 - val_accuracy: 0.8276\n","Epoch 10/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0888 - accuracy: 0.9697 - val_loss: 0.5343 - val_accuracy: 0.8276\n","Epoch 11/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0844 - accuracy: 0.9716 - val_loss: 0.5087 - val_accuracy: 0.8244\n","Epoch 12/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0769 - accuracy: 0.9756 - val_loss: 0.4823 - val_accuracy: 0.8319\n","Epoch 13/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0802 - accuracy: 0.9751 - val_loss: 0.4503 - val_accuracy: 0.8308\n","Epoch 14/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0935 - accuracy: 0.9662 - val_loss: 0.4256 - val_accuracy: 0.8319\n","Epoch 15/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0916 - accuracy: 0.9689 - val_loss: 0.3952 - val_accuracy: 0.8351\n","Epoch 16/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0776 - accuracy: 0.9762 - val_loss: 0.3700 - val_accuracy: 0.8501\n","Epoch 17/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0676 - accuracy: 0.9807 - val_loss: 0.3441 - val_accuracy: 0.8469\n","Epoch 18/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0685 - accuracy: 0.9812 - val_loss: 0.3350 - val_accuracy: 0.8576\n","Epoch 19/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0684 - accuracy: 0.9788 - val_loss: 0.3268 - val_accuracy: 0.8608\n","Epoch 20/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0799 - accuracy: 0.9735 - val_loss: 0.3368 - val_accuracy: 0.8694\n","Epoch 21/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0690 - accuracy: 0.9788 - val_loss: 0.3284 - val_accuracy: 0.8790\n","Epoch 22/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0665 - accuracy: 0.9823 - val_loss: 0.3582 - val_accuracy: 0.8726\n","Epoch 23/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0714 - accuracy: 0.9764 - val_loss: 0.3209 - val_accuracy: 0.8865\n","Epoch 24/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0691 - accuracy: 0.9783 - val_loss: 0.3882 - val_accuracy: 0.8662\n","Epoch 25/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0935 - accuracy: 0.9679 - val_loss: 0.3722 - val_accuracy: 0.8790\n","Epoch 26/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0749 - accuracy: 0.9735 - val_loss: 0.3403 - val_accuracy: 0.8844\n","Epoch 27/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0656 - accuracy: 0.9804 - val_loss: 0.3322 - val_accuracy: 0.8972\n","Epoch 28/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0640 - accuracy: 0.9796 - val_loss: 0.3421 - val_accuracy: 0.8919\n","Epoch 29/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0631 - accuracy: 0.9796 - val_loss: 0.3330 - val_accuracy: 0.8908\n","Epoch 30/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0572 - accuracy: 0.9855 - val_loss: 0.3951 - val_accuracy: 0.8833\n","Epoch 31/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0580 - accuracy: 0.9837 - val_loss: 0.3926 - val_accuracy: 0.8812\n","Epoch 32/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0627 - accuracy: 0.9791 - val_loss: 0.4003 - val_accuracy: 0.8801\n","Epoch 33/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0634 - accuracy: 0.9815 - val_loss: 0.3846 - val_accuracy: 0.8876\n","Epoch 34/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0562 - accuracy: 0.9839 - val_loss: 0.3633 - val_accuracy: 0.8940\n","Epoch 35/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0556 - accuracy: 0.9823 - val_loss: 0.3558 - val_accuracy: 0.8876\n","Epoch 36/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0578 - accuracy: 0.9821 - val_loss: 0.3892 - val_accuracy: 0.8854\n","Epoch 37/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0556 - accuracy: 0.9826 - val_loss: 0.3644 - val_accuracy: 0.8929\n","Epoch 38/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0494 - accuracy: 0.9861 - val_loss: 0.3850 - val_accuracy: 0.8887\n","Epoch 39/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0544 - accuracy: 0.9839 - val_loss: 0.3737 - val_accuracy: 0.8908\n","Epoch 40/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0573 - accuracy: 0.9807 - val_loss: 0.3874 - val_accuracy: 0.8951\n","Epoch 41/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0493 - accuracy: 0.9861 - val_loss: 0.3775 - val_accuracy: 0.8801\n","Epoch 42/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0508 - accuracy: 0.9855 - val_loss: 0.3776 - val_accuracy: 0.8854\n","Epoch 43/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0489 - accuracy: 0.9863 - val_loss: 0.3876 - val_accuracy: 0.8908\n","Epoch 44/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0568 - accuracy: 0.9826 - val_loss: 0.4519 - val_accuracy: 0.8822\n","Epoch 45/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0553 - accuracy: 0.9815 - val_loss: 0.5098 - val_accuracy: 0.8694\n","Epoch 46/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0779 - accuracy: 0.9732 - val_loss: 0.3915 - val_accuracy: 0.8876\n","Epoch 47/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0466 - accuracy: 0.9877 - val_loss: 0.3796 - val_accuracy: 0.8940\n","Epoch 48/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0461 - accuracy: 0.9871 - val_loss: 0.3866 - val_accuracy: 0.8876\n","Epoch 49/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0431 - accuracy: 0.9877 - val_loss: 0.3983 - val_accuracy: 0.8929\n","Epoch 50/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0432 - accuracy: 0.9887 - val_loss: 0.4173 - val_accuracy: 0.8887\n","Epoch 51/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0463 - accuracy: 0.9861 - val_loss: 0.4018 - val_accuracy: 0.8887\n","Epoch 52/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0472 - accuracy: 0.9863 - val_loss: 0.3928 - val_accuracy: 0.8844\n","Epoch 53/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0449 - accuracy: 0.9885 - val_loss: 0.3970 - val_accuracy: 0.8908\n","Epoch 54/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0401 - accuracy: 0.9887 - val_loss: 0.4101 - val_accuracy: 0.8865\n","Epoch 55/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0471 - accuracy: 0.9874 - val_loss: 0.4027 - val_accuracy: 0.8897\n","Epoch 56/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0378 - accuracy: 0.9914 - val_loss: 0.4443 - val_accuracy: 0.8854\n","Epoch 57/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0446 - accuracy: 0.9869 - val_loss: 0.4473 - val_accuracy: 0.8833\n","Epoch 58/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0430 - accuracy: 0.9882 - val_loss: 0.5532 - val_accuracy: 0.8694\n","Epoch 59/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0530 - accuracy: 0.9823 - val_loss: 0.4137 - val_accuracy: 0.8940\n","Epoch 60/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0516 - accuracy: 0.9850 - val_loss: 0.5374 - val_accuracy: 0.8522\n","Epoch 61/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0536 - accuracy: 0.9810 - val_loss: 0.4172 - val_accuracy: 0.8876\n","Epoch 62/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0454 - accuracy: 0.9871 - val_loss: 0.4810 - val_accuracy: 0.8822\n","Epoch 63/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0441 - accuracy: 0.9877 - val_loss: 0.4341 - val_accuracy: 0.8854\n","Epoch 64/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0582 - accuracy: 0.9799 - val_loss: 0.4739 - val_accuracy: 0.8747\n","Epoch 65/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0443 - accuracy: 0.9871 - val_loss: 0.4253 - val_accuracy: 0.8887\n","Epoch 66/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0361 - accuracy: 0.9901 - val_loss: 0.4497 - val_accuracy: 0.8833\n","Epoch 67/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0441 - accuracy: 0.9863 - val_loss: 0.4398 - val_accuracy: 0.8854\n","Epoch 68/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0378 - accuracy: 0.9896 - val_loss: 0.4326 - val_accuracy: 0.8844\n","Epoch 69/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.0366 - accuracy: 0.9890 - val_loss: 0.4372 - val_accuracy: 0.8865\n","Epoch 70/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0310 - accuracy: 0.9901 - val_loss: 0.5104 - val_accuracy: 0.8812\n","Epoch 71/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0347 - accuracy: 0.9917 - val_loss: 0.4374 - val_accuracy: 0.8865\n","Epoch 72/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0334 - accuracy: 0.9933 - val_loss: 0.4413 - val_accuracy: 0.8919\n","Epoch 73/100\n","30/30 [==============================] - 1s 32ms/step - loss: 0.0321 - accuracy: 0.9914 - val_loss: 0.4429 - val_accuracy: 0.8854\n","Epoch 74/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0306 - accuracy: 0.9922 - val_loss: 0.4577 - val_accuracy: 0.8822\n","Epoch 75/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0319 - accuracy: 0.9922 - val_loss: 0.4606 - val_accuracy: 0.8812\n","Epoch 76/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 0.4575 - val_accuracy: 0.8790\n","Epoch 77/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0342 - accuracy: 0.9914 - val_loss: 0.5326 - val_accuracy: 0.8790\n","Epoch 78/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0357 - accuracy: 0.9917 - val_loss: 0.4562 - val_accuracy: 0.8833\n","Epoch 79/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0348 - accuracy: 0.9904 - val_loss: 0.4908 - val_accuracy: 0.8683\n","Epoch 80/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0301 - accuracy: 0.9920 - val_loss: 0.4422 - val_accuracy: 0.8908\n","Epoch 81/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0283 - accuracy: 0.9933 - val_loss: 0.4779 - val_accuracy: 0.8822\n","Epoch 82/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0346 - accuracy: 0.9912 - val_loss: 0.4509 - val_accuracy: 0.8854\n","Epoch 83/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0327 - accuracy: 0.9914 - val_loss: 0.4755 - val_accuracy: 0.8854\n","Epoch 84/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0343 - accuracy: 0.9893 - val_loss: 0.4685 - val_accuracy: 0.8854\n","Epoch 85/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0285 - accuracy: 0.9941 - val_loss: 0.4582 - val_accuracy: 0.8876\n","Epoch 86/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0342 - accuracy: 0.9901 - val_loss: 0.4992 - val_accuracy: 0.8812\n","Epoch 87/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0296 - accuracy: 0.9946 - val_loss: 0.4702 - val_accuracy: 0.8854\n","Epoch 88/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0348 - accuracy: 0.9909 - val_loss: 0.4696 - val_accuracy: 0.8833\n","Epoch 89/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0281 - accuracy: 0.9936 - val_loss: 0.5773 - val_accuracy: 0.8726\n","Epoch 90/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0314 - accuracy: 0.9912 - val_loss: 0.4661 - val_accuracy: 0.8876\n","Epoch 91/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0320 - accuracy: 0.9922 - val_loss: 0.5482 - val_accuracy: 0.8662\n","Epoch 92/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0420 - accuracy: 0.9885 - val_loss: 0.4479 - val_accuracy: 0.8854\n","Epoch 93/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0295 - accuracy: 0.9928 - val_loss: 0.4701 - val_accuracy: 0.8844\n","Epoch 94/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0278 - accuracy: 0.9938 - val_loss: 0.4915 - val_accuracy: 0.8726\n","Epoch 95/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0534 - accuracy: 0.9837 - val_loss: 0.5794 - val_accuracy: 0.8833\n","Epoch 96/100\n","30/30 [==============================] - 1s 32ms/step - loss: 0.0418 - accuracy: 0.9869 - val_loss: 0.4697 - val_accuracy: 0.8801\n","Epoch 97/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0296 - accuracy: 0.9920 - val_loss: 0.4976 - val_accuracy: 0.8812\n","Epoch 98/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0268 - accuracy: 0.9944 - val_loss: 0.5368 - val_accuracy: 0.8801\n","Epoch 99/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0378 - accuracy: 0.9887 - val_loss: 0.5146 - val_accuracy: 0.8758\n","Epoch 100/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0349 - accuracy: 0.9887 - val_loss: 0.5148 - val_accuracy: 0.8801\n","{'loss': [0.1425529271364212, 0.12160339951515198, 0.10605117678642273, 0.10345160961151123, 0.0923038050532341, 0.09397175908088684, 0.09005828201770782, 0.0842735692858696, 0.08481144160032272, 0.08882372826337814, 0.08444694429636002, 0.07687440514564514, 0.08024217188358307, 0.09352989494800568, 0.09162020683288574, 0.077603280544281, 0.06759044528007507, 0.06852316856384277, 0.06844408810138702, 0.0798630490899086, 0.06900620460510254, 0.06647732853889465, 0.07140045613050461, 0.06912913173437119, 0.0934743657708168, 0.07491890341043472, 0.06559529900550842, 0.06395271420478821, 0.06307985633611679, 0.05719359964132309, 0.05799465626478195, 0.06273984163999557, 0.06338837742805481, 0.056213438510894775, 0.055611878633499146, 0.05777779594063759, 0.05562613159418106, 0.0493583120405674, 0.054444193840026855, 0.057254765182733536, 0.049338240176439285, 0.050756651908159256, 0.04894489794969559, 0.05677073821425438, 0.05527794361114502, 0.07786855101585388, 0.0466030016541481, 0.046143870800733566, 0.04312606900930405, 0.04319678992033005, 0.0463026724755764, 0.047249600291252136, 0.04488725587725639, 0.04012292996048927, 0.04710609093308449, 0.03776673227548599, 0.04463972896337509, 0.04299174249172211, 0.052958231419324875, 0.05164672061800957, 0.05356588587164879, 0.04538870230317116, 0.044070784002542496, 0.05817756429314613, 0.04434766620397568, 0.03614826872944832, 0.04409755766391754, 0.03779185190796852, 0.03655949980020523, 0.031013263389468193, 0.034687358886003494, 0.03341865539550781, 0.032126449048519135, 0.030626151710748672, 0.03187412768602371, 0.03361509367823601, 0.03417795151472092, 0.03573502600193024, 0.034773703664541245, 0.03014294244349003, 0.028259124606847763, 0.03455972298979759, 0.03265029564499855, 0.03433075174689293, 0.028469229117035866, 0.03418055549263954, 0.02959577925503254, 0.034818124026060104, 0.02808736078441143, 0.031406011432409286, 0.0319884717464447, 0.041984617710113525, 0.029475264251232147, 0.027795396745204926, 0.05338379368185997, 0.04178391024470329, 0.029576079919934273, 0.026831675320863724, 0.037755876779556274, 0.03490988165140152], 'accuracy': [0.9523171782493591, 0.9566032886505127, 0.9627645611763, 0.9675863981246948, 0.9697294235229492, 0.9737476706504822, 0.9710688591003418, 0.9734797477722168, 0.9710688591003418, 0.9697294235229492, 0.971604585647583, 0.975622832775116, 0.97508704662323, 0.9662469625473022, 0.9689257740974426, 0.9761585593223572, 0.9807125926017761, 0.9812483191490173, 0.9788373708724976, 0.9734797477722168, 0.9788373708724976, 0.9823198318481445, 0.9764264822006226, 0.9783016443252563, 0.9678542613983154, 0.9734797477722168, 0.9804446697235107, 0.9796410202980042, 0.9796410202980042, 0.9855344295501709, 0.9836592674255371, 0.9791052937507629, 0.9815161824226379, 0.9839271306991577, 0.9823198318481445, 0.9820519685745239, 0.9825877547264099, 0.9860701560974121, 0.9839271306991577, 0.9807125926017761, 0.9860701560974121, 0.9855344295501709, 0.9863380789756775, 0.9825877547264099, 0.9815161824226379, 0.9732118844985962, 0.9876774549484253, 0.9871417284011841, 0.9876774549484253, 0.9887489676475525, 0.9860701560974121, 0.9863380789756775, 0.9884811043739319, 0.9887489676475525, 0.9874095916748047, 0.9914277791976929, 0.9868738055229187, 0.9882132411003113, 0.9823198318481445, 0.9849986433982849, 0.9809804558753967, 0.9871417284011841, 0.9876774549484253, 0.9799089431762695, 0.9871417284011841, 0.9900884032249451, 0.9863380789756775, 0.9895526170730591, 0.9890168905258179, 0.9900884032249451, 0.9916957020759583, 0.9933030009269714, 0.9914277791976929, 0.9922314286231995, 0.9922314286231995, 0.9890168905258179, 0.9914277791976929, 0.9916957020759583, 0.9903562664985657, 0.9919635653495789, 0.9933030009269714, 0.9911599159240723, 0.9914277791976929, 0.9892847537994385, 0.9941065907478333, 0.9900884032249451, 0.9946423768997192, 0.9908920526504517, 0.993570864200592, 0.9911599159240723, 0.9922314286231995, 0.9884811043739319, 0.9927672147750854, 0.9938387274742126, 0.9836592674255371, 0.9868738055229187, 0.9919635653495789, 0.9943745136260986, 0.9887489676475525, 0.9887489676475525], 'val_loss': [0.6541314721107483, 0.6468631625175476, 0.6414716243743896, 0.631144106388092, 0.6219054460525513, 0.6085475087165833, 0.5945791602134705, 0.5755956768989563, 0.5549034476280212, 0.5342637300491333, 0.5087088942527771, 0.48226842284202576, 0.4503355920314789, 0.42558911442756653, 0.39522191882133484, 0.3700147569179535, 0.3440921902656555, 0.3349856734275818, 0.3268021047115326, 0.33678069710731506, 0.328433096408844, 0.35820597410202026, 0.32094940543174744, 0.3881504535675049, 0.3722303509712219, 0.34028360247612, 0.33219873905181885, 0.3421266973018646, 0.33302929997444153, 0.39508676528930664, 0.3925663232803345, 0.4002716839313507, 0.38460561633110046, 0.3633459210395813, 0.35578617453575134, 0.3892119526863098, 0.3644091486930847, 0.38500526547431946, 0.37365487217903137, 0.38735514879226685, 0.37746572494506836, 0.3775594234466553, 0.3875562250614166, 0.4519023001194, 0.5097569227218628, 0.3914950489997864, 0.37962251901626587, 0.3866291046142578, 0.3983033299446106, 0.41727563738822937, 0.4018220901489258, 0.39276450872421265, 0.39695125818252563, 0.41009044647216797, 0.40274226665496826, 0.4443031847476959, 0.44727131724357605, 0.5532263517379761, 0.41369935870170593, 0.5374026298522949, 0.4172064960002899, 0.4810370206832886, 0.4340746998786926, 0.4739043414592743, 0.42531219124794006, 0.44973641633987427, 0.4397751986980438, 0.432551771402359, 0.4372395873069763, 0.5104050040245056, 0.43743014335632324, 0.44132307171821594, 0.4429359436035156, 0.4576961100101471, 0.46062445640563965, 0.4575140178203583, 0.5326160788536072, 0.456228643655777, 0.49079635739326477, 0.4422171413898468, 0.4779147207736969, 0.45085588097572327, 0.4754849374294281, 0.4685122072696686, 0.45823508501052856, 0.4992061257362366, 0.47022515535354614, 0.46958109736442566, 0.5772911310195923, 0.4660704433917999, 0.5482085347175598, 0.44793397188186646, 0.4700511693954468, 0.4914971590042114, 0.5793740749359131, 0.4696798324584961, 0.49763163924217224, 0.5368465781211853, 0.5146123170852661, 0.5148239135742188], 'val_accuracy': [0.759100615978241, 0.8104925155639648, 0.819057822227478, 0.824411153793335, 0.8211991190910339, 0.8137044906616211, 0.8233404755592346, 0.8137044906616211, 0.8276231288909912, 0.8276231288909912, 0.824411153793335, 0.8319057822227478, 0.8308351039886475, 0.8319057822227478, 0.835117757320404, 0.8501070737838745, 0.8468950986862183, 0.8576017022132874, 0.8608136773109436, 0.8693790435791016, 0.8790149688720703, 0.8725910186767578, 0.8865096569061279, 0.8661670088768005, 0.8790149688720703, 0.8843683004379272, 0.897216260433197, 0.8918629288673401, 0.8907923102378845, 0.8832976222038269, 0.881156325340271, 0.8800856471061707, 0.8875802755355835, 0.8940042853355408, 0.8875802755355835, 0.8854389786720276, 0.8929336071014404, 0.8886509537696838, 0.8907923102378845, 0.8950749635696411, 0.8800856471061707, 0.8854389786720276, 0.8907923102378845, 0.8822270035743713, 0.8693790435791016, 0.8875802755355835, 0.8940042853355408, 0.8875802755355835, 0.8929336071014404, 0.8886509537696838, 0.8886509537696838, 0.8843683004379272, 0.8907923102378845, 0.8865096569061279, 0.8897216320037842, 0.8854389786720276, 0.8832976222038269, 0.8693790435791016, 0.8940042853355408, 0.8522483706474304, 0.8875802755355835, 0.8822270035743713, 0.8854389786720276, 0.8747323155403137, 0.8886509537696838, 0.8832976222038269, 0.8854389786720276, 0.8843683004379272, 0.8865096569061279, 0.881156325340271, 0.8865096569061279, 0.8918629288673401, 0.8854389786720276, 0.8822270035743713, 0.881156325340271, 0.8790149688720703, 0.8790149688720703, 0.8832976222038269, 0.8683083653450012, 0.8907923102378845, 0.8822270035743713, 0.8854389786720276, 0.8854389786720276, 0.8854389786720276, 0.8875802755355835, 0.881156325340271, 0.8854389786720276, 0.8832976222038269, 0.8725910186767578, 0.8875802755355835, 0.8661670088768005, 0.8854389786720276, 0.8843683004379272, 0.8725910186767578, 0.8832976222038269, 0.8800856471061707, 0.881156325340271, 0.8800856471061707, 0.8758029937744141, 0.8800856471061707]}\n","37/37 [==============================] - 1s 5ms/step\n"]}]},{"cell_type":"code","source":["\n","metrics_df.round(3)"],"metadata":{"id":"Ik5JoVP2NPvY","executionInfo":{"status":"ok","timestamp":1716482939588,"user_tz":-360,"elapsed":1538,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"colab":{"base_uri":"https://localhost:8080/","height":459},"outputId":"bafc3b04-8879-4d5a-e665-54fb1ed3050f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.813      0.865   0.744  0.800        0.744        0.883   \n","1        1     0.792      0.804   0.778  0.790        0.778        0.806   \n","2        2     0.805      0.813   0.795  0.803        0.795        0.816   \n","3        0     0.833      0.871   0.784  0.825        0.784        0.883   \n","4        1     0.812      0.815   0.813  0.814        0.813        0.811   \n","5        2     0.807      0.891   0.700  0.784        0.700        0.914   \n","6        0     0.812      0.749   0.942  0.835        0.942        0.681   \n","7        1     0.831      0.902   0.747  0.817        0.747        0.917   \n","8        2     0.845      0.822   0.880  0.850        0.880        0.810   \n","9        0     0.845      0.799   0.923  0.857        0.923        0.766   \n","10       1     0.871      0.868   0.879  0.874        0.879        0.863   \n","11       2     0.871      0.864   0.882  0.873        0.882        0.861   \n","12       0     0.901      0.897   0.908  0.903        0.908        0.895   \n","13       1     0.887      0.897   0.876  0.887        0.876        0.898   \n","14       2     0.897      0.926   0.863  0.894        0.863        0.931   \n","\n","    Kappa  \n","0   0.627  \n","1   0.584  \n","2   0.611  \n","3   0.666  \n","4   0.625  \n","5   0.614  \n","6   0.624  \n","7   0.663  \n","8   0.690  \n","9   0.690  \n","10  0.743  \n","11  0.743  \n","12  0.803  \n","13  0.774  \n","14  0.794  "],"text/html":["\n","  <div id=\"df-38d99554-cb2b-408d-941f-adc7937a5288\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.813</td>\n","      <td>0.865</td>\n","      <td>0.744</td>\n","      <td>0.800</td>\n","      <td>0.744</td>\n","      <td>0.883</td>\n","      <td>0.627</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.792</td>\n","      <td>0.804</td>\n","      <td>0.778</td>\n","      <td>0.790</td>\n","      <td>0.778</td>\n","      <td>0.806</td>\n","      <td>0.584</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.805</td>\n","      <td>0.813</td>\n","      <td>0.795</td>\n","      <td>0.803</td>\n","      <td>0.795</td>\n","      <td>0.816</td>\n","      <td>0.611</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.833</td>\n","      <td>0.871</td>\n","      <td>0.784</td>\n","      <td>0.825</td>\n","      <td>0.784</td>\n","      <td>0.883</td>\n","      <td>0.666</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.812</td>\n","      <td>0.815</td>\n","      <td>0.813</td>\n","      <td>0.814</td>\n","      <td>0.813</td>\n","      <td>0.811</td>\n","      <td>0.625</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.807</td>\n","      <td>0.891</td>\n","      <td>0.700</td>\n","      <td>0.784</td>\n","      <td>0.700</td>\n","      <td>0.914</td>\n","      <td>0.614</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.812</td>\n","      <td>0.749</td>\n","      <td>0.942</td>\n","      <td>0.835</td>\n","      <td>0.942</td>\n","      <td>0.681</td>\n","      <td>0.624</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.831</td>\n","      <td>0.902</td>\n","      <td>0.747</td>\n","      <td>0.817</td>\n","      <td>0.747</td>\n","      <td>0.917</td>\n","      <td>0.663</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.845</td>\n","      <td>0.822</td>\n","      <td>0.880</td>\n","      <td>0.850</td>\n","      <td>0.880</td>\n","      <td>0.810</td>\n","      <td>0.690</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.845</td>\n","      <td>0.799</td>\n","      <td>0.923</td>\n","      <td>0.857</td>\n","      <td>0.923</td>\n","      <td>0.766</td>\n","      <td>0.690</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.871</td>\n","      <td>0.868</td>\n","      <td>0.879</td>\n","      <td>0.874</td>\n","      <td>0.879</td>\n","      <td>0.863</td>\n","      <td>0.743</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.871</td>\n","      <td>0.864</td>\n","      <td>0.882</td>\n","      <td>0.873</td>\n","      <td>0.882</td>\n","      <td>0.861</td>\n","      <td>0.743</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.901</td>\n","      <td>0.897</td>\n","      <td>0.908</td>\n","      <td>0.903</td>\n","      <td>0.908</td>\n","      <td>0.895</td>\n","      <td>0.803</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.887</td>\n","      <td>0.897</td>\n","      <td>0.876</td>\n","      <td>0.887</td>\n","      <td>0.876</td>\n","      <td>0.898</td>\n","      <td>0.774</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.897</td>\n","      <td>0.926</td>\n","      <td>0.863</td>\n","      <td>0.894</td>\n","      <td>0.863</td>\n","      <td>0.931</td>\n","      <td>0.794</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38d99554-cb2b-408d-941f-adc7937a5288')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-38d99554-cb2b-408d-941f-adc7937a5288 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-38d99554-cb2b-408d-941f-adc7937a5288');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-612d057b-d203-4268-81a2-565b91c0d80c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-612d057b-d203-4268-81a2-565b91c0d80c')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-612d057b-d203-4268-81a2-565b91c0d80c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03601957139958113,\n        \"min\": 0.792,\n        \"max\": 0.901,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.887,\n          0.901,\n          0.813\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04927213063327846,\n        \"min\": 0.749,\n        \"max\": 0.926,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.799,\n          0.864,\n          0.865\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07335478041357503,\n        \"min\": 0.7,\n        \"max\": 0.942,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.923,\n          0.882,\n          0.744\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03944761444896618,\n        \"min\": 0.784,\n        \"max\": 0.903,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.857,\n          0.873,\n          0.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07335478041357503,\n        \"min\": 0.7,\n        \"max\": 0.942,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.923,\n          0.882,\n          0.744\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06748438972935042,\n        \"min\": 0.681,\n        \"max\": 0.931,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.863,\n          0.895,\n          0.883\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07206822164746798,\n        \"min\": 0.584,\n        \"max\": 0.803,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.774,\n          0.743,\n          0.627\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["# Frequency-domain"],"metadata":{"id":"QUuWzfMHSNmi"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split,KFold,StratifiedKFold\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM,Dropout, GRU\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from keras.optimizers import RMSprop, Adam\n","# from wandb.keras import WandbCallback\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', k_folds=5, stratified=False):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.k_folds = k_folds\n","        self.stratified = stratified\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle= True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        X = scaled_data_reshaped.reshape(self.X.shape)\n","        np.moveaxis(X, 1, 2)\n","        self.X = X\n","\n","    def create_partitions(self):\n","        if self.stratified:\n","            kf = StratifiedKFold(n_splits=self.k_folds, shuffle=True, random_state=42)\n","        else:\n","            kf = KFold(n_splits=self.k_folds, shuffle=True, random_state=42)\n","\n","        for train_index, test_index in kf.split(self.X, self.Y):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(LSTM(256, return_sequences=True))\n","    model.add(LSTM(256, return_sequences=True))\n","        # GRU layers\n","    # model.add(GRU(256, return_sequences=True))\n","    # model.add(GRU(128, return_sequences=False))\n","\n","    model.add(Flatten())\n","    # model.add(Dense(1024, activation='relu'))\n","    # model.add(Dense(512, activation='relu'))\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dense(32, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Evaluate client model\n","            y_pred = (client_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"8xrx_fxBSWGd","executionInfo":{"status":"ok","timestamp":1716484228237,"user_tz":-360,"elapsed":4,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["global_model, metrics_df = federated_learning(frequency_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H1TaNdIbSfkq","outputId":"22092c02-eb3c-42c3-eb61-5604e9a251d1","executionInfo":{"status":"ok","timestamp":1716485352368,"user_tz":-360,"elapsed":1116857,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4667, 19, 29), Test shape: (1167, 19, 29)\n","Train shape: (4667, 19, 29), Test shape: (1167, 19, 29)\n","Train shape: (4667, 19, 29), Test shape: (1167, 19, 29)\n","Train shape: (4667, 19, 29), Test shape: (1167, 19, 29)\n","Train shape: (4668, 19, 29), Test shape: (1166, 19, 29)\n","Train shape: (4667, 19, 29), Test shape: (1167, 19, 29)\n","Train shape: (4667, 19, 29), Test shape: (1167, 19, 29)\n","Train shape: (4667, 19, 29), Test shape: (1167, 19, 29)\n","Train shape: (4667, 19, 29), Test shape: (1167, 19, 29)\n","Train shape: (4668, 19, 29), Test shape: (1166, 19, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 18s 74ms/step - loss: 0.6929 - accuracy: 0.5893 - val_loss: 0.6931 - val_accuracy: 0.5054\n","Epoch 2/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.6919 - accuracy: 0.6459 - val_loss: 0.6930 - val_accuracy: 0.5032\n","Epoch 3/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.6893 - accuracy: 0.7107 - val_loss: 0.6927 - val_accuracy: 0.5054\n","Epoch 4/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.6836 - accuracy: 0.7284 - val_loss: 0.6919 - val_accuracy: 0.5385\n","Epoch 5/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.6720 - accuracy: 0.7244 - val_loss: 0.6899 - val_accuracy: 0.6627\n","Epoch 6/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.6496 - accuracy: 0.7278 - val_loss: 0.6861 - val_accuracy: 0.7002\n","Epoch 7/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.6127 - accuracy: 0.7286 - val_loss: 0.6785 - val_accuracy: 0.7248\n","Epoch 8/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.5748 - accuracy: 0.7281 - val_loss: 0.6665 - val_accuracy: 0.7302\n","Epoch 9/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.5449 - accuracy: 0.7372 - val_loss: 0.6547 - val_accuracy: 0.7398\n","Epoch 10/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.5321 - accuracy: 0.7345 - val_loss: 0.6411 - val_accuracy: 0.7398\n","Epoch 11/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.5249 - accuracy: 0.7431 - val_loss: 0.6294 - val_accuracy: 0.7484\n","Epoch 12/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.5189 - accuracy: 0.7442 - val_loss: 0.6187 - val_accuracy: 0.7441\n","Epoch 13/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.5101 - accuracy: 0.7541 - val_loss: 0.6048 - val_accuracy: 0.7441\n","Epoch 14/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.5080 - accuracy: 0.7509 - val_loss: 0.5916 - val_accuracy: 0.7484\n","Epoch 15/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.5037 - accuracy: 0.7565 - val_loss: 0.5778 - val_accuracy: 0.7463\n","Epoch 16/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4997 - accuracy: 0.7584 - val_loss: 0.5649 - val_accuracy: 0.7591\n","Epoch 17/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4939 - accuracy: 0.7629 - val_loss: 0.5506 - val_accuracy: 0.7580\n","Epoch 18/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4879 - accuracy: 0.7661 - val_loss: 0.5361 - val_accuracy: 0.7591\n","Epoch 19/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4879 - accuracy: 0.7715 - val_loss: 0.5257 - val_accuracy: 0.7645\n","Epoch 20/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4840 - accuracy: 0.7702 - val_loss: 0.5135 - val_accuracy: 0.7602\n","Epoch 21/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4803 - accuracy: 0.7702 - val_loss: 0.5059 - val_accuracy: 0.7634\n","Epoch 22/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4756 - accuracy: 0.7736 - val_loss: 0.5003 - val_accuracy: 0.7655\n","Epoch 23/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4687 - accuracy: 0.7852 - val_loss: 0.4965 - val_accuracy: 0.7687\n","Epoch 24/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4643 - accuracy: 0.7833 - val_loss: 0.4957 - val_accuracy: 0.7773\n","Epoch 25/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4600 - accuracy: 0.7854 - val_loss: 0.4936 - val_accuracy: 0.7602\n","Epoch 26/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4603 - accuracy: 0.7892 - val_loss: 0.4952 - val_accuracy: 0.7580\n","Epoch 27/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4565 - accuracy: 0.7860 - val_loss: 0.4933 - val_accuracy: 0.7730\n","Epoch 28/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4505 - accuracy: 0.7911 - val_loss: 0.4931 - val_accuracy: 0.7794\n","Epoch 29/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4464 - accuracy: 0.8023 - val_loss: 0.4974 - val_accuracy: 0.7666\n","Epoch 30/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4438 - accuracy: 0.7988 - val_loss: 0.4969 - val_accuracy: 0.7677\n","Epoch 31/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4472 - accuracy: 0.7953 - val_loss: 0.4971 - val_accuracy: 0.7655\n","Epoch 32/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.4375 - accuracy: 0.8026 - val_loss: 0.4966 - val_accuracy: 0.7741\n","Epoch 33/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4367 - accuracy: 0.8026 - val_loss: 0.4971 - val_accuracy: 0.7709\n","Epoch 34/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.4319 - accuracy: 0.8066 - val_loss: 0.4929 - val_accuracy: 0.7773\n","Epoch 35/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4291 - accuracy: 0.8058 - val_loss: 0.4928 - val_accuracy: 0.7730\n","Epoch 36/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4311 - accuracy: 0.8074 - val_loss: 0.4932 - val_accuracy: 0.7752\n","Epoch 37/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.4256 - accuracy: 0.8079 - val_loss: 0.4970 - val_accuracy: 0.7719\n","Epoch 38/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.4295 - accuracy: 0.8061 - val_loss: 0.4922 - val_accuracy: 0.7837\n","Epoch 39/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4203 - accuracy: 0.8077 - val_loss: 0.4947 - val_accuracy: 0.7687\n","Epoch 40/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4175 - accuracy: 0.8170 - val_loss: 0.4925 - val_accuracy: 0.7848\n","Epoch 41/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4174 - accuracy: 0.8103 - val_loss: 0.4910 - val_accuracy: 0.7837\n","Epoch 42/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4109 - accuracy: 0.8192 - val_loss: 0.4969 - val_accuracy: 0.7698\n","Epoch 43/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4137 - accuracy: 0.8178 - val_loss: 0.4877 - val_accuracy: 0.7859\n","Epoch 44/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4036 - accuracy: 0.8211 - val_loss: 0.4902 - val_accuracy: 0.7848\n","Epoch 45/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4108 - accuracy: 0.8197 - val_loss: 0.4863 - val_accuracy: 0.7848\n","Epoch 46/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4003 - accuracy: 0.8237 - val_loss: 0.4873 - val_accuracy: 0.7859\n","Epoch 47/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4006 - accuracy: 0.8237 - val_loss: 0.4869 - val_accuracy: 0.7901\n","Epoch 48/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3983 - accuracy: 0.8245 - val_loss: 0.4908 - val_accuracy: 0.7816\n","Epoch 49/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3937 - accuracy: 0.8299 - val_loss: 0.4860 - val_accuracy: 0.7848\n","Epoch 50/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3913 - accuracy: 0.8318 - val_loss: 0.4893 - val_accuracy: 0.7891\n","Epoch 51/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3898 - accuracy: 0.8347 - val_loss: 0.4937 - val_accuracy: 0.7805\n","Epoch 52/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3878 - accuracy: 0.8286 - val_loss: 0.4866 - val_accuracy: 0.7859\n","Epoch 53/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3833 - accuracy: 0.8323 - val_loss: 0.4895 - val_accuracy: 0.7869\n","Epoch 54/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3849 - accuracy: 0.8280 - val_loss: 0.4860 - val_accuracy: 0.7859\n","Epoch 55/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3856 - accuracy: 0.8358 - val_loss: 0.4895 - val_accuracy: 0.7837\n","Epoch 56/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3814 - accuracy: 0.8361 - val_loss: 0.4920 - val_accuracy: 0.7848\n","Epoch 57/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3773 - accuracy: 0.8307 - val_loss: 0.4862 - val_accuracy: 0.7901\n","Epoch 58/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3753 - accuracy: 0.8398 - val_loss: 0.4847 - val_accuracy: 0.7891\n","Epoch 59/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3713 - accuracy: 0.8374 - val_loss: 0.4839 - val_accuracy: 0.7880\n","Epoch 60/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3684 - accuracy: 0.8411 - val_loss: 0.4833 - val_accuracy: 0.7891\n","Epoch 61/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3628 - accuracy: 0.8433 - val_loss: 0.4859 - val_accuracy: 0.7955\n","Epoch 62/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3661 - accuracy: 0.8468 - val_loss: 0.4996 - val_accuracy: 0.7837\n","Epoch 63/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3638 - accuracy: 0.8414 - val_loss: 0.4850 - val_accuracy: 0.7944\n","Epoch 64/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.3622 - accuracy: 0.8444 - val_loss: 0.4881 - val_accuracy: 0.7859\n","Epoch 65/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3540 - accuracy: 0.8452 - val_loss: 0.4909 - val_accuracy: 0.7880\n","Epoch 66/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.3591 - accuracy: 0.8481 - val_loss: 0.4850 - val_accuracy: 0.7869\n","Epoch 67/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3510 - accuracy: 0.8527 - val_loss: 0.4843 - val_accuracy: 0.7901\n","Epoch 68/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3486 - accuracy: 0.8511 - val_loss: 0.4880 - val_accuracy: 0.7998\n","Epoch 69/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3466 - accuracy: 0.8553 - val_loss: 0.4847 - val_accuracy: 0.7891\n","Epoch 70/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3397 - accuracy: 0.8561 - val_loss: 0.4872 - val_accuracy: 0.7912\n","Epoch 71/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.3473 - accuracy: 0.8503 - val_loss: 0.4880 - val_accuracy: 0.7880\n","Epoch 72/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.3392 - accuracy: 0.8543 - val_loss: 0.4894 - val_accuracy: 0.7891\n","Epoch 73/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3368 - accuracy: 0.8612 - val_loss: 0.4879 - val_accuracy: 0.7923\n","Epoch 74/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3334 - accuracy: 0.8594 - val_loss: 0.4872 - val_accuracy: 0.7869\n","Epoch 75/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3299 - accuracy: 0.8588 - val_loss: 0.4894 - val_accuracy: 0.7934\n","Epoch 76/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3301 - accuracy: 0.8599 - val_loss: 0.4852 - val_accuracy: 0.7934\n","Epoch 77/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3318 - accuracy: 0.8602 - val_loss: 0.4959 - val_accuracy: 0.7912\n","Epoch 78/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3189 - accuracy: 0.8655 - val_loss: 0.5077 - val_accuracy: 0.7837\n","Epoch 79/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3187 - accuracy: 0.8653 - val_loss: 0.4897 - val_accuracy: 0.7891\n","Epoch 80/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3110 - accuracy: 0.8738 - val_loss: 0.4890 - val_accuracy: 0.7923\n","Epoch 81/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3104 - accuracy: 0.8687 - val_loss: 0.4936 - val_accuracy: 0.7891\n","Epoch 82/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3065 - accuracy: 0.8722 - val_loss: 0.4950 - val_accuracy: 0.7869\n","Epoch 83/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3034 - accuracy: 0.8722 - val_loss: 0.5068 - val_accuracy: 0.7901\n","Epoch 84/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3055 - accuracy: 0.8744 - val_loss: 0.5158 - val_accuracy: 0.7869\n","Epoch 85/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3086 - accuracy: 0.8720 - val_loss: 0.5058 - val_accuracy: 0.7923\n","Epoch 86/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3019 - accuracy: 0.8733 - val_loss: 0.4970 - val_accuracy: 0.7837\n","Epoch 87/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2964 - accuracy: 0.8819 - val_loss: 0.4974 - val_accuracy: 0.7859\n","Epoch 88/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.2915 - accuracy: 0.8848 - val_loss: 0.5017 - val_accuracy: 0.7848\n","Epoch 89/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2857 - accuracy: 0.8840 - val_loss: 0.5024 - val_accuracy: 0.7859\n","Epoch 90/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.2849 - accuracy: 0.8848 - val_loss: 0.5106 - val_accuracy: 0.7901\n","Epoch 91/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2885 - accuracy: 0.8811 - val_loss: 0.5055 - val_accuracy: 0.7816\n","Epoch 92/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2777 - accuracy: 0.8886 - val_loss: 0.5115 - val_accuracy: 0.7859\n","Epoch 93/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.2819 - accuracy: 0.8845 - val_loss: 0.5074 - val_accuracy: 0.7859\n","Epoch 94/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2724 - accuracy: 0.8870 - val_loss: 0.5128 - val_accuracy: 0.7848\n","Epoch 95/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2679 - accuracy: 0.8971 - val_loss: 0.5122 - val_accuracy: 0.7859\n","Epoch 96/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2674 - accuracy: 0.8904 - val_loss: 0.5158 - val_accuracy: 0.7827\n","Epoch 97/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2652 - accuracy: 0.8971 - val_loss: 0.5183 - val_accuracy: 0.7912\n","Epoch 98/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2608 - accuracy: 0.8950 - val_loss: 0.5223 - val_accuracy: 0.7859\n","Epoch 99/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2563 - accuracy: 0.9001 - val_loss: 0.5200 - val_accuracy: 0.7837\n","Epoch 100/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2558 - accuracy: 0.8990 - val_loss: 0.5222 - val_accuracy: 0.7880\n","{'loss': [0.6929363012313843, 0.6918536424636841, 0.6893030405044556, 0.683575451374054, 0.672035813331604, 0.6496294140815735, 0.6126605868339539, 0.5748409628868103, 0.5448658466339111, 0.5321305394172668, 0.5249021649360657, 0.5189171433448792, 0.5100786685943604, 0.508039653301239, 0.5037158131599426, 0.49972885847091675, 0.49390777945518494, 0.487867534160614, 0.487870991230011, 0.4839862585067749, 0.48028674721717834, 0.4755834937095642, 0.46872082352638245, 0.4643374979496002, 0.4599512815475464, 0.4602572023868561, 0.4565332531929016, 0.45049095153808594, 0.44638678431510925, 0.4437560439109802, 0.44721657037734985, 0.4375401437282562, 0.4367218315601349, 0.43193677067756653, 0.42906779050827026, 0.43110692501068115, 0.42563751339912415, 0.42945989966392517, 0.42033517360687256, 0.417516827583313, 0.41736820340156555, 0.4108525514602661, 0.4137011170387268, 0.403562992811203, 0.41081079840660095, 0.4003305733203888, 0.40059417486190796, 0.3983147144317627, 0.3937055468559265, 0.3912566006183624, 0.3898158669471741, 0.38776683807373047, 0.3833262622356415, 0.38493338227272034, 0.3855647146701813, 0.3813771605491638, 0.37734454870224, 0.37532544136047363, 0.37132760882377625, 0.3684465289115906, 0.3628407418727875, 0.366111159324646, 0.3638306260108948, 0.3621838092803955, 0.3540460467338562, 0.3590737283229828, 0.3509763777256012, 0.3485686779022217, 0.34659287333488464, 0.3397061824798584, 0.3472902774810791, 0.33915895223617554, 0.33676451444625854, 0.33339056372642517, 0.3299051523208618, 0.3301137685775757, 0.3318048417568207, 0.3189263343811035, 0.3187050521373749, 0.3110474944114685, 0.31037798523902893, 0.306512713432312, 0.3034478425979614, 0.3054954409599304, 0.30856022238731384, 0.30193600058555603, 0.29635751247406006, 0.29150068759918213, 0.28570184111595154, 0.2849114239215851, 0.28849461674690247, 0.27771005034446716, 0.28192833065986633, 0.2724226415157318, 0.26791107654571533, 0.2673625946044922, 0.26515114307403564, 0.26077353954315186, 0.25630083680152893, 0.25579604506492615], 'accuracy': [0.5893383622169495, 0.6458612084388733, 0.7106884717941284, 0.7283685803413391, 0.7243503928184509, 0.7278328537940979, 0.7286365032196045, 0.7281007170677185, 0.7372086644172668, 0.7345298528671265, 0.7431020736694336, 0.7441735863685608, 0.7540851831436157, 0.7508705854415894, 0.7564961314201355, 0.7583712935447693, 0.7629252672195435, 0.766139805316925, 0.7714974284172058, 0.770158052444458, 0.770158052444458, 0.773640513420105, 0.7851594090461731, 0.7832842469215393, 0.7854272723197937, 0.7891775965690613, 0.7859630584716797, 0.7910527586936951, 0.8023037910461426, 0.7988213300704956, 0.7953388690948486, 0.8025716543197632, 0.8025716543197632, 0.8065899014472961, 0.8057862520217896, 0.807393491268158, 0.807929277420044, 0.8060541152954102, 0.8076614141464233, 0.8170372247695923, 0.8103402256965637, 0.8191803097724915, 0.8178408741950989, 0.8210554718971252, 0.8197160363197327, 0.8237342834472656, 0.8237342834472656, 0.8245379328727722, 0.829895555973053, 0.8317707180976868, 0.8347173929214478, 0.8285561203956604, 0.832306444644928, 0.8280203342437744, 0.835788905620575, 0.8360567688941956, 0.8306991457939148, 0.8398071527481079, 0.8373962044715881, 0.8411465287208557, 0.8432895541191101, 0.8467720150947571, 0.8414143919944763, 0.8443611264228821, 0.8451647758483887, 0.8481114506721497, 0.8526654243469238, 0.8510581254959106, 0.8553442358970642, 0.8561478853225708, 0.850254476070404, 0.854272723197937, 0.8612375855445862, 0.8593624234199524, 0.8588266968727112, 0.8598982095718384, 0.860166072845459, 0.8655236959457397, 0.8652558326721191, 0.8738279938697815, 0.8687382936477661, 0.8722207546234131, 0.8722207546234131, 0.8743637800216675, 0.8719528317451477, 0.8732922673225403, 0.8818644285202026, 0.8848111629486084, 0.8840075135231018, 0.8848111629486084, 0.8810608386993408, 0.888561487197876, 0.884543240070343, 0.8869541883468628, 0.8971336483955383, 0.8904366493225098, 0.8971336483955383, 0.8949906229972839, 0.9000803828239441, 0.8990088105201721], 'val_loss': [0.6930825114250183, 0.6929565072059631, 0.69266676902771, 0.691897451877594, 0.6899228692054749, 0.686079740524292, 0.6785130500793457, 0.6664633750915527, 0.6546937227249146, 0.6411140561103821, 0.6293598413467407, 0.6186855435371399, 0.6047620177268982, 0.5916427373886108, 0.577799379825592, 0.5649192333221436, 0.5506423711776733, 0.5361422300338745, 0.525711178779602, 0.513468325138092, 0.5059360861778259, 0.5003284215927124, 0.4964556396007538, 0.49572810530662537, 0.49360182881355286, 0.4952406883239746, 0.49329060316085815, 0.49311140179634094, 0.4973702132701874, 0.4969373643398285, 0.4970722794532776, 0.49659019708633423, 0.49711623787879944, 0.49294593930244446, 0.49279817938804626, 0.49320077896118164, 0.4969819486141205, 0.4922124445438385, 0.4946739375591278, 0.4925045371055603, 0.49097687005996704, 0.4969214200973511, 0.487719863653183, 0.4901704788208008, 0.4863264262676239, 0.4872904121875763, 0.48694461584091187, 0.49079883098602295, 0.4859592020511627, 0.48929092288017273, 0.49373701214790344, 0.48661014437675476, 0.489511638879776, 0.4860385060310364, 0.4895411431789398, 0.49195557832717896, 0.48620325326919556, 0.4846622943878174, 0.4839266240596771, 0.48330986499786377, 0.4859195947647095, 0.4995889961719513, 0.4850365221500397, 0.4880654811859131, 0.490870863199234, 0.4850025773048401, 0.4842545688152313, 0.4879969656467438, 0.4846573770046234, 0.4872174859046936, 0.4880475103855133, 0.489425927400589, 0.4878690540790558, 0.487163245677948, 0.4893956184387207, 0.4851837158203125, 0.49591127038002014, 0.507656991481781, 0.48972994089126587, 0.4889781177043915, 0.49356937408447266, 0.49501028656959534, 0.5068343877792358, 0.5157541036605835, 0.5058076977729797, 0.4970393478870392, 0.4973660409450531, 0.5016707181930542, 0.5023946762084961, 0.5106415748596191, 0.5055391788482666, 0.5115416646003723, 0.5074037909507751, 0.5128055214881897, 0.5121626257896423, 0.5158010721206665, 0.5182771682739258, 0.5223192572593689, 0.5200388431549072, 0.5221705436706543], 'val_accuracy': [0.5053533315658569, 0.5032119750976562, 0.5053533315658569, 0.5385438799858093, 0.6627408862113953, 0.700214147567749, 0.7248393893241882, 0.7301927208900452, 0.7398287057876587, 0.7398287057876587, 0.7483940124511719, 0.7441113591194153, 0.7441113591194153, 0.7483940124511719, 0.7462526559829712, 0.759100615978241, 0.7580299973487854, 0.759100615978241, 0.7644539475440979, 0.7601712942123413, 0.7633832693099976, 0.7655246257781982, 0.7687366008758545, 0.7773019075393677, 0.7601712942123413, 0.7580299973487854, 0.7730192542076111, 0.7794432640075684, 0.7665953040122986, 0.7676659822463989, 0.7655246257781982, 0.7740899324417114, 0.7708779573440552, 0.7773019075393677, 0.7730192542076111, 0.7751606106758118, 0.7719486355781555, 0.783725917339325, 0.7687366008758545, 0.7847965955734253, 0.783725917339325, 0.7698072791099548, 0.7858672142028809, 0.7847965955734253, 0.7847965955734253, 0.7858672142028809, 0.7901498675346375, 0.7815845608711243, 0.7847965955734253, 0.7890792489051819, 0.7805139422416687, 0.7858672142028809, 0.7869378924369812, 0.7858672142028809, 0.783725917339325, 0.7847965955734253, 0.7901498675346375, 0.7890792489051819, 0.7880085706710815, 0.7890792489051819, 0.7955031991004944, 0.783725917339325, 0.794432520866394, 0.7858672142028809, 0.7880085706710815, 0.7869378924369812, 0.7901498675346375, 0.799785852432251, 0.7890792489051819, 0.7912205457687378, 0.7880085706710815, 0.7890792489051819, 0.7922912240028381, 0.7869378924369812, 0.7933619022369385, 0.7933619022369385, 0.7912205457687378, 0.783725917339325, 0.7890792489051819, 0.7922912240028381, 0.7890792489051819, 0.7869378924369812, 0.7901498675346375, 0.7869378924369812, 0.7922912240028381, 0.783725917339325, 0.7858672142028809, 0.7847965955734253, 0.7858672142028809, 0.7901498675346375, 0.7815845608711243, 0.7858672142028809, 0.7858672142028809, 0.7847965955734253, 0.7858672142028809, 0.7826552391052246, 0.7912205457687378, 0.7858672142028809, 0.783725917339325, 0.7880085706710815]}\n","37/37 [==============================] - 2s 9ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 7s 47ms/step - loss: 0.6929 - accuracy: 0.5636 - val_loss: 0.6931 - val_accuracy: 0.7345\n","Epoch 2/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.6917 - accuracy: 0.6692 - val_loss: 0.6929 - val_accuracy: 0.5203\n","Epoch 3/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.6892 - accuracy: 0.7120 - val_loss: 0.6925 - val_accuracy: 0.5396\n","Epoch 4/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.6835 - accuracy: 0.7219 - val_loss: 0.6916 - val_accuracy: 0.6274\n","Epoch 5/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.6708 - accuracy: 0.7268 - val_loss: 0.6893 - val_accuracy: 0.7248\n","Epoch 6/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.6459 - accuracy: 0.7305 - val_loss: 0.6845 - val_accuracy: 0.7409\n","Epoch 7/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.6056 - accuracy: 0.7329 - val_loss: 0.6745 - val_accuracy: 0.7591\n","Epoch 8/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.5616 - accuracy: 0.7402 - val_loss: 0.6601 - val_accuracy: 0.7677\n","Epoch 9/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.5378 - accuracy: 0.7418 - val_loss: 0.6460 - val_accuracy: 0.7677\n","Epoch 10/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.5247 - accuracy: 0.7450 - val_loss: 0.6344 - val_accuracy: 0.7655\n","Epoch 11/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.5168 - accuracy: 0.7493 - val_loss: 0.6207 - val_accuracy: 0.7698\n","Epoch 12/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.5118 - accuracy: 0.7506 - val_loss: 0.6079 - val_accuracy: 0.7719\n","Epoch 13/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.5072 - accuracy: 0.7485 - val_loss: 0.5941 - val_accuracy: 0.7730\n","Epoch 14/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.5028 - accuracy: 0.7568 - val_loss: 0.5797 - val_accuracy: 0.7762\n","Epoch 15/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4976 - accuracy: 0.7586 - val_loss: 0.5626 - val_accuracy: 0.7773\n","Epoch 16/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4967 - accuracy: 0.7594 - val_loss: 0.5487 - val_accuracy: 0.7794\n","Epoch 17/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4913 - accuracy: 0.7624 - val_loss: 0.5341 - val_accuracy: 0.7816\n","Epoch 18/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4859 - accuracy: 0.7667 - val_loss: 0.5228 - val_accuracy: 0.7805\n","Epoch 19/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4799 - accuracy: 0.7766 - val_loss: 0.5050 - val_accuracy: 0.7880\n","Epoch 20/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4824 - accuracy: 0.7712 - val_loss: 0.4937 - val_accuracy: 0.7869\n","Epoch 21/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4727 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7869\n","Epoch 22/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4678 - accuracy: 0.7790 - val_loss: 0.4731 - val_accuracy: 0.7891\n","Epoch 23/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4671 - accuracy: 0.7833 - val_loss: 0.4587 - val_accuracy: 0.8019\n","Epoch 24/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4629 - accuracy: 0.7884 - val_loss: 0.4532 - val_accuracy: 0.8009\n","Epoch 25/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4611 - accuracy: 0.7878 - val_loss: 0.4507 - val_accuracy: 0.7998\n","Epoch 26/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4590 - accuracy: 0.7876 - val_loss: 0.4474 - val_accuracy: 0.8019\n","Epoch 27/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4543 - accuracy: 0.7902 - val_loss: 0.4427 - val_accuracy: 0.8051\n","Epoch 28/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4509 - accuracy: 0.7951 - val_loss: 0.4407 - val_accuracy: 0.8062\n","Epoch 29/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4481 - accuracy: 0.7943 - val_loss: 0.4414 - val_accuracy: 0.8030\n","Epoch 30/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4455 - accuracy: 0.7959 - val_loss: 0.4388 - val_accuracy: 0.8041\n","Epoch 31/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4411 - accuracy: 0.8002 - val_loss: 0.4344 - val_accuracy: 0.8105\n","Epoch 32/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4379 - accuracy: 0.8007 - val_loss: 0.4336 - val_accuracy: 0.8105\n","Epoch 33/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4402 - accuracy: 0.7986 - val_loss: 0.4364 - val_accuracy: 0.8084\n","Epoch 34/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4304 - accuracy: 0.8055 - val_loss: 0.4297 - val_accuracy: 0.8137\n","Epoch 35/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4313 - accuracy: 0.8058 - val_loss: 0.4297 - val_accuracy: 0.8084\n","Epoch 36/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4254 - accuracy: 0.8111 - val_loss: 0.4269 - val_accuracy: 0.8137\n","Epoch 37/100\n","30/30 [==============================] - 1s 32ms/step - loss: 0.4268 - accuracy: 0.8069 - val_loss: 0.4252 - val_accuracy: 0.8169\n","Epoch 38/100\n","30/30 [==============================] - 1s 32ms/step - loss: 0.4236 - accuracy: 0.8144 - val_loss: 0.4242 - val_accuracy: 0.8158\n","Epoch 39/100\n","30/30 [==============================] - 1s 46ms/step - loss: 0.4156 - accuracy: 0.8216 - val_loss: 0.4254 - val_accuracy: 0.8191\n","Epoch 40/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4169 - accuracy: 0.8152 - val_loss: 0.4212 - val_accuracy: 0.8158\n","Epoch 41/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4187 - accuracy: 0.8111 - val_loss: 0.4206 - val_accuracy: 0.8191\n","Epoch 42/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4134 - accuracy: 0.8181 - val_loss: 0.4188 - val_accuracy: 0.8158\n","Epoch 43/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4119 - accuracy: 0.8178 - val_loss: 0.4174 - val_accuracy: 0.8158\n","Epoch 44/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4030 - accuracy: 0.8253 - val_loss: 0.4185 - val_accuracy: 0.8030\n","Epoch 45/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4066 - accuracy: 0.8181 - val_loss: 0.4172 - val_accuracy: 0.8201\n","Epoch 46/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4028 - accuracy: 0.8213 - val_loss: 0.4162 - val_accuracy: 0.8191\n","Epoch 47/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3961 - accuracy: 0.8272 - val_loss: 0.4147 - val_accuracy: 0.8116\n","Epoch 48/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3962 - accuracy: 0.8310 - val_loss: 0.4149 - val_accuracy: 0.8148\n","Epoch 49/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3995 - accuracy: 0.8261 - val_loss: 0.4129 - val_accuracy: 0.8084\n","Epoch 50/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3888 - accuracy: 0.8342 - val_loss: 0.4138 - val_accuracy: 0.8051\n","Epoch 51/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3905 - accuracy: 0.8256 - val_loss: 0.4113 - val_accuracy: 0.8126\n","Epoch 52/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3902 - accuracy: 0.8264 - val_loss: 0.4108 - val_accuracy: 0.8126\n","Epoch 53/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3961 - accuracy: 0.8232 - val_loss: 0.4135 - val_accuracy: 0.8180\n","Epoch 54/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3811 - accuracy: 0.8320 - val_loss: 0.4134 - val_accuracy: 0.8180\n","Epoch 55/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3754 - accuracy: 0.8353 - val_loss: 0.4121 - val_accuracy: 0.8191\n","Epoch 56/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3786 - accuracy: 0.8310 - val_loss: 0.4122 - val_accuracy: 0.8051\n","Epoch 57/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3773 - accuracy: 0.8390 - val_loss: 0.4291 - val_accuracy: 0.8116\n","Epoch 58/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3714 - accuracy: 0.8409 - val_loss: 0.4132 - val_accuracy: 0.8158\n","Epoch 59/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3693 - accuracy: 0.8411 - val_loss: 0.4091 - val_accuracy: 0.8191\n","Epoch 60/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3705 - accuracy: 0.8401 - val_loss: 0.4073 - val_accuracy: 0.8105\n","Epoch 61/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3666 - accuracy: 0.8438 - val_loss: 0.4065 - val_accuracy: 0.8148\n","Epoch 62/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3640 - accuracy: 0.8444 - val_loss: 0.4084 - val_accuracy: 0.8158\n","Epoch 63/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3558 - accuracy: 0.8476 - val_loss: 0.4054 - val_accuracy: 0.8191\n","Epoch 64/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3589 - accuracy: 0.8505 - val_loss: 0.4066 - val_accuracy: 0.8148\n","Epoch 65/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3571 - accuracy: 0.8511 - val_loss: 0.4055 - val_accuracy: 0.8191\n","Epoch 66/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3576 - accuracy: 0.8513 - val_loss: 0.4052 - val_accuracy: 0.8169\n","Epoch 67/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3529 - accuracy: 0.8508 - val_loss: 0.4050 - val_accuracy: 0.8116\n","Epoch 68/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3489 - accuracy: 0.8532 - val_loss: 0.4080 - val_accuracy: 0.8126\n","Epoch 69/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3469 - accuracy: 0.8545 - val_loss: 0.4074 - val_accuracy: 0.8191\n","Epoch 70/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3438 - accuracy: 0.8516 - val_loss: 0.4091 - val_accuracy: 0.8169\n","Epoch 71/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3417 - accuracy: 0.8548 - val_loss: 0.4055 - val_accuracy: 0.8148\n","Epoch 72/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3416 - accuracy: 0.8556 - val_loss: 0.4076 - val_accuracy: 0.8180\n","Epoch 73/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3385 - accuracy: 0.8556 - val_loss: 0.4035 - val_accuracy: 0.8169\n","Epoch 74/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3372 - accuracy: 0.8545 - val_loss: 0.4028 - val_accuracy: 0.8169\n","Epoch 75/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3332 - accuracy: 0.8604 - val_loss: 0.4031 - val_accuracy: 0.8169\n","Epoch 76/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3272 - accuracy: 0.8623 - val_loss: 0.4069 - val_accuracy: 0.8148\n","Epoch 77/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3240 - accuracy: 0.8647 - val_loss: 0.4012 - val_accuracy: 0.8212\n","Epoch 78/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3256 - accuracy: 0.8669 - val_loss: 0.4050 - val_accuracy: 0.8169\n","Epoch 79/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3240 - accuracy: 0.8636 - val_loss: 0.4021 - val_accuracy: 0.8255\n","Epoch 80/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3121 - accuracy: 0.8655 - val_loss: 0.4072 - val_accuracy: 0.8223\n","Epoch 81/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3124 - accuracy: 0.8661 - val_loss: 0.4044 - val_accuracy: 0.8201\n","Epoch 82/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3152 - accuracy: 0.8682 - val_loss: 0.4033 - val_accuracy: 0.8244\n","Epoch 83/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3069 - accuracy: 0.8722 - val_loss: 0.4046 - val_accuracy: 0.8233\n","Epoch 84/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3085 - accuracy: 0.8728 - val_loss: 0.4045 - val_accuracy: 0.8223\n","Epoch 85/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3015 - accuracy: 0.8784 - val_loss: 0.4047 - val_accuracy: 0.8255\n","Epoch 86/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3032 - accuracy: 0.8746 - val_loss: 0.4050 - val_accuracy: 0.8255\n","Epoch 87/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2948 - accuracy: 0.8784 - val_loss: 0.4172 - val_accuracy: 0.8201\n","Epoch 88/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2977 - accuracy: 0.8749 - val_loss: 0.4072 - val_accuracy: 0.8255\n","Epoch 89/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.2895 - accuracy: 0.8784 - val_loss: 0.4301 - val_accuracy: 0.8084\n","Epoch 90/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2907 - accuracy: 0.8803 - val_loss: 0.4104 - val_accuracy: 0.8244\n","Epoch 91/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2843 - accuracy: 0.8803 - val_loss: 0.4137 - val_accuracy: 0.8223\n","Epoch 92/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2775 - accuracy: 0.8920 - val_loss: 0.4110 - val_accuracy: 0.8255\n","Epoch 93/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2769 - accuracy: 0.8880 - val_loss: 0.4138 - val_accuracy: 0.8287\n","Epoch 94/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2729 - accuracy: 0.8902 - val_loss: 0.4123 - val_accuracy: 0.8255\n","Epoch 95/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2756 - accuracy: 0.8851 - val_loss: 0.4156 - val_accuracy: 0.8255\n","Epoch 96/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2707 - accuracy: 0.8912 - val_loss: 0.4119 - val_accuracy: 0.8287\n","Epoch 97/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2680 - accuracy: 0.8920 - val_loss: 0.4147 - val_accuracy: 0.8287\n","Epoch 98/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2700 - accuracy: 0.8904 - val_loss: 0.4125 - val_accuracy: 0.8298\n","Epoch 99/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2580 - accuracy: 0.8977 - val_loss: 0.4154 - val_accuracy: 0.8298\n","Epoch 100/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2503 - accuracy: 0.9068 - val_loss: 0.4233 - val_accuracy: 0.8276\n","{'loss': [0.6929235458374023, 0.6917227506637573, 0.6892250776290894, 0.683513879776001, 0.670805037021637, 0.6459349989891052, 0.6055927872657776, 0.5616108775138855, 0.53782057762146, 0.5246858596801758, 0.5168360471725464, 0.5118337869644165, 0.5072436332702637, 0.5028091073036194, 0.49759969115257263, 0.4967246353626251, 0.4912656843662262, 0.48588356375694275, 0.4798664450645447, 0.4823684096336365, 0.4726982116699219, 0.46783891320228577, 0.46712443232536316, 0.4628995656967163, 0.4610830843448639, 0.45895451307296753, 0.45433467626571655, 0.45087459683418274, 0.4480891525745392, 0.4455419182777405, 0.441074013710022, 0.43786630034446716, 0.4401748776435852, 0.4304026663303375, 0.4312944710254669, 0.4254075288772583, 0.4267975389957428, 0.4235856831073761, 0.4155898988246918, 0.41693273186683655, 0.41872167587280273, 0.41337209939956665, 0.41190141439437866, 0.40303727984428406, 0.4066046476364136, 0.40282142162323, 0.39608925580978394, 0.3962113857269287, 0.3995319902896881, 0.388814777135849, 0.3904712498188019, 0.3901602625846863, 0.39614954590797424, 0.38114693760871887, 0.37535735964775085, 0.3786022961139679, 0.37729623913764954, 0.3713843524456024, 0.36933088302612305, 0.37048089504241943, 0.36657828092575073, 0.36403688788414, 0.35584133863449097, 0.3588857352733612, 0.35713934898376465, 0.35762184858322144, 0.3528865873813629, 0.34887298941612244, 0.3469323515892029, 0.3438475728034973, 0.34166449308395386, 0.34160083532333374, 0.33848312497138977, 0.33716416358947754, 0.3332100212574005, 0.3272046446800232, 0.32404625415802, 0.3255729079246521, 0.32396405935287476, 0.31212207674980164, 0.31242409348487854, 0.31522971391677856, 0.3069044053554535, 0.30849358439445496, 0.3015038073062897, 0.30320507287979126, 0.2948363423347473, 0.2977156639099121, 0.28953781723976135, 0.29073813557624817, 0.2842694818973541, 0.2774764597415924, 0.2768753170967102, 0.2728888988494873, 0.2755625247955322, 0.2707306444644928, 0.2679882347583771, 0.26995107531547546, 0.25803402066230774, 0.25030070543289185], 'accuracy': [0.5636217594146729, 0.6691668629646301, 0.7120278477668762, 0.7219394445419312, 0.7267613410949707, 0.7305116653442383, 0.7329225540161133, 0.7401553988456726, 0.741762638092041, 0.7449772357940674, 0.749263346195221, 0.7506027221679688, 0.7484596967697144, 0.7567639946937561, 0.7586391568183899, 0.7594428062438965, 0.7623894810676575, 0.766675591468811, 0.776587188243866, 0.7712295651435852, 0.779533863067627, 0.7789981365203857, 0.7832842469215393, 0.7883739471435547, 0.7878382205963135, 0.7875702977180481, 0.7902491092681885, 0.795071005821228, 0.7942673563957214, 0.7958746552467346, 0.8001607060432434, 0.8006964921951294, 0.798553466796875, 0.8055183291435242, 0.8057862520217896, 0.8111438751220703, 0.8068577647209167, 0.8143584132194519, 0.8215911984443665, 0.8151620626449585, 0.8111438751220703, 0.8181087374687195, 0.8178408741950989, 0.825341522693634, 0.8181087374687195, 0.8213233351707458, 0.8272167444229126, 0.8309670686721802, 0.8261451721191406, 0.8341816067695618, 0.8256094455718994, 0.826413094997406, 0.8231984972953796, 0.8320385813713074, 0.835253119468689, 0.8309670686721802, 0.8390035033226013, 0.8408786654472351, 0.8411465287208557, 0.8400750160217285, 0.8438253402709961, 0.8443611264228821, 0.8475756645202637, 0.8505223393440247, 0.8510581254959106, 0.8513259887695312, 0.85079026222229, 0.853201150894165, 0.8545405864715576, 0.8515939116477966, 0.8548084497451782, 0.8556120991706848, 0.8556120991706848, 0.8545405864715576, 0.8604339957237244, 0.8623091578483582, 0.8647200465202332, 0.8668631315231323, 0.863648533821106, 0.8655236959457397, 0.8660594820976257, 0.8682025074958801, 0.8722207546234131, 0.8727564811706543, 0.8783820271492004, 0.8746316432952881, 0.8783820271492004, 0.8748995661735535, 0.8783820271492004, 0.8802571892738342, 0.8802571892738342, 0.892043948173523, 0.88802570104599, 0.8901687860488892, 0.885079026222229, 0.8912402987480164, 0.892043948173523, 0.8904366493225098, 0.8976694345474243, 0.9067773818969727], 'val_loss': [0.6930873990058899, 0.6929187178611755, 0.6925214529037476, 0.6915656924247742, 0.6892970204353333, 0.6845178604125977, 0.6745377779006958, 0.6600654721260071, 0.6460477709770203, 0.6343595385551453, 0.6207422614097595, 0.6079058647155762, 0.5940918922424316, 0.5797367691993713, 0.5626134872436523, 0.5486564040184021, 0.5341206789016724, 0.5227646231651306, 0.5049805045127869, 0.49372756481170654, 0.4891909956932068, 0.47311028838157654, 0.45873039960861206, 0.45316797494888306, 0.45065540075302124, 0.44744259119033813, 0.4427485764026642, 0.44071048498153687, 0.4414360821247101, 0.43876686692237854, 0.4343934953212738, 0.43359073996543884, 0.4363531172275543, 0.4296826124191284, 0.42968493700027466, 0.4269223213195801, 0.42518526315689087, 0.42423883080482483, 0.425356924533844, 0.42117297649383545, 0.42059651017189026, 0.4188140630722046, 0.41740477085113525, 0.4185156524181366, 0.4171554744243622, 0.4162468910217285, 0.4146629869937897, 0.4148668944835663, 0.41294950246810913, 0.41378623247146606, 0.4113246202468872, 0.41075196862220764, 0.4135231077671051, 0.41340842843055725, 0.4120592772960663, 0.41215062141418457, 0.4291391670703888, 0.41319727897644043, 0.4091460108757019, 0.4072761833667755, 0.4065089225769043, 0.40841370820999146, 0.4054144620895386, 0.4065586030483246, 0.40547308325767517, 0.40519648790359497, 0.40495651960372925, 0.4080185890197754, 0.40735769271850586, 0.4090847074985504, 0.4055042564868927, 0.40759220719337463, 0.40354159474372864, 0.40284019708633423, 0.40310728549957275, 0.4069373309612274, 0.40123313665390015, 0.40495193004608154, 0.4020852744579315, 0.4072290062904358, 0.4043692350387573, 0.4032523036003113, 0.4045672118663788, 0.404457688331604, 0.40473848581314087, 0.4050309658050537, 0.4171726107597351, 0.40719103813171387, 0.43013814091682434, 0.4103580117225647, 0.41367894411087036, 0.41103506088256836, 0.4137954115867615, 0.4122539162635803, 0.41564464569091797, 0.41193851828575134, 0.41467025876045227, 0.41247740387916565, 0.4153875708580017, 0.423343688249588], 'val_accuracy': [0.7344753742218018, 0.5203425884246826, 0.5396145582199097, 0.6274089813232422, 0.7248393893241882, 0.740899384021759, 0.759100615978241, 0.7676659822463989, 0.7676659822463989, 0.7655246257781982, 0.7698072791099548, 0.7719486355781555, 0.7730192542076111, 0.7762312889099121, 0.7773019075393677, 0.7794432640075684, 0.7815845608711243, 0.7805139422416687, 0.7880085706710815, 0.7869378924369812, 0.7869378924369812, 0.7890792489051819, 0.8019272089004517, 0.8008565306663513, 0.799785852432251, 0.8019272089004517, 0.8051391839981079, 0.8062098622322083, 0.802997887134552, 0.8040685057640076, 0.8104925155639648, 0.8104925155639648, 0.8083511590957642, 0.8137044906616211, 0.8083511590957642, 0.8137044906616211, 0.8169164657592773, 0.8158458471298218, 0.819057822227478, 0.8158458471298218, 0.819057822227478, 0.8158458471298218, 0.8158458471298218, 0.802997887134552, 0.8201285004615784, 0.819057822227478, 0.8115631937980652, 0.8147751688957214, 0.8083511590957642, 0.8051391839981079, 0.8126338124275208, 0.8126338124275208, 0.8179871439933777, 0.8179871439933777, 0.819057822227478, 0.8051391839981079, 0.8115631937980652, 0.8158458471298218, 0.819057822227478, 0.8104925155639648, 0.8147751688957214, 0.8158458471298218, 0.819057822227478, 0.8147751688957214, 0.819057822227478, 0.8169164657592773, 0.8115631937980652, 0.8126338124275208, 0.819057822227478, 0.8169164657592773, 0.8147751688957214, 0.8179871439933777, 0.8169164657592773, 0.8169164657592773, 0.8169164657592773, 0.8147751688957214, 0.8211991190910339, 0.8169164657592773, 0.8254817724227905, 0.8222697973251343, 0.8201285004615784, 0.824411153793335, 0.8233404755592346, 0.8222697973251343, 0.8254817724227905, 0.8254817724227905, 0.8201285004615784, 0.8254817724227905, 0.8083511590957642, 0.824411153793335, 0.8222697973251343, 0.8254817724227905, 0.8286938071250916, 0.8254817724227905, 0.8254817724227905, 0.8286938071250916, 0.8286938071250916, 0.8297644257545471, 0.8297644257545471, 0.8276231288909912]}\n","37/37 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 45ms/step - loss: 0.6929 - accuracy: 0.5757 - val_loss: 0.6931 - val_accuracy: 0.7152\n","Epoch 2/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.6918 - accuracy: 0.6477 - val_loss: 0.6930 - val_accuracy: 0.5086\n","Epoch 3/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.6893 - accuracy: 0.7021 - val_loss: 0.6926 - val_accuracy: 0.5289\n","Epoch 4/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.6836 - accuracy: 0.7203 - val_loss: 0.6917 - val_accuracy: 0.5964\n","Epoch 5/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.6711 - accuracy: 0.7273 - val_loss: 0.6897 - val_accuracy: 0.6842\n","Epoch 6/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.6467 - accuracy: 0.7308 - val_loss: 0.6853 - val_accuracy: 0.7184\n","Epoch 7/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.6087 - accuracy: 0.7340 - val_loss: 0.6761 - val_accuracy: 0.7270\n","Epoch 8/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.5675 - accuracy: 0.7375 - val_loss: 0.6634 - val_accuracy: 0.7366\n","Epoch 9/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.5419 - accuracy: 0.7380 - val_loss: 0.6496 - val_accuracy: 0.7388\n","Epoch 10/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.5281 - accuracy: 0.7402 - val_loss: 0.6358 - val_accuracy: 0.7409\n","Epoch 11/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.5218 - accuracy: 0.7450 - val_loss: 0.6235 - val_accuracy: 0.7484\n","Epoch 12/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.5163 - accuracy: 0.7527 - val_loss: 0.6110 - val_accuracy: 0.7409\n","Epoch 13/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.5112 - accuracy: 0.7560 - val_loss: 0.5976 - val_accuracy: 0.7452\n","Epoch 14/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.5062 - accuracy: 0.7592 - val_loss: 0.5837 - val_accuracy: 0.7548\n","Epoch 15/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.5041 - accuracy: 0.7581 - val_loss: 0.5704 - val_accuracy: 0.7602\n","Epoch 16/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.5025 - accuracy: 0.7562 - val_loss: 0.5576 - val_accuracy: 0.7623\n","Epoch 17/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4919 - accuracy: 0.7635 - val_loss: 0.5409 - val_accuracy: 0.7645\n","Epoch 18/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4927 - accuracy: 0.7688 - val_loss: 0.5278 - val_accuracy: 0.7666\n","Epoch 19/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4876 - accuracy: 0.7731 - val_loss: 0.5128 - val_accuracy: 0.7634\n","Epoch 20/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4856 - accuracy: 0.7680 - val_loss: 0.5019 - val_accuracy: 0.7634\n","Epoch 21/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4829 - accuracy: 0.7710 - val_loss: 0.4962 - val_accuracy: 0.7741\n","Epoch 22/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4779 - accuracy: 0.7758 - val_loss: 0.4917 - val_accuracy: 0.7741\n","Epoch 23/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4744 - accuracy: 0.7766 - val_loss: 0.4817 - val_accuracy: 0.7773\n","Epoch 24/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.4708 - accuracy: 0.7785 - val_loss: 0.4803 - val_accuracy: 0.7741\n","Epoch 25/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4677 - accuracy: 0.7755 - val_loss: 0.4734 - val_accuracy: 0.7773\n","Epoch 26/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.4611 - accuracy: 0.7838 - val_loss: 0.4700 - val_accuracy: 0.7784\n","Epoch 27/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4603 - accuracy: 0.7825 - val_loss: 0.4674 - val_accuracy: 0.7784\n","Epoch 28/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4591 - accuracy: 0.7862 - val_loss: 0.4686 - val_accuracy: 0.7816\n","Epoch 29/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4513 - accuracy: 0.7937 - val_loss: 0.4654 - val_accuracy: 0.7784\n","Epoch 30/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4515 - accuracy: 0.7932 - val_loss: 0.4632 - val_accuracy: 0.7848\n","Epoch 31/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4485 - accuracy: 0.7943 - val_loss: 0.4607 - val_accuracy: 0.7827\n","Epoch 32/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4458 - accuracy: 0.7956 - val_loss: 0.4642 - val_accuracy: 0.7816\n","Epoch 33/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4468 - accuracy: 0.7967 - val_loss: 0.4581 - val_accuracy: 0.7837\n","Epoch 34/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4380 - accuracy: 0.7991 - val_loss: 0.4580 - val_accuracy: 0.7869\n","Epoch 35/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4370 - accuracy: 0.8004 - val_loss: 0.4585 - val_accuracy: 0.7794\n","Epoch 36/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4327 - accuracy: 0.8069 - val_loss: 0.4538 - val_accuracy: 0.7827\n","Epoch 37/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4302 - accuracy: 0.8050 - val_loss: 0.4521 - val_accuracy: 0.7912\n","Epoch 38/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4262 - accuracy: 0.8106 - val_loss: 0.4523 - val_accuracy: 0.7912\n","Epoch 39/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4263 - accuracy: 0.8047 - val_loss: 0.4566 - val_accuracy: 0.7784\n","Epoch 40/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4198 - accuracy: 0.8168 - val_loss: 0.4498 - val_accuracy: 0.7934\n","Epoch 41/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4237 - accuracy: 0.8128 - val_loss: 0.4477 - val_accuracy: 0.7912\n","Epoch 42/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4168 - accuracy: 0.8173 - val_loss: 0.4468 - val_accuracy: 0.7923\n","Epoch 43/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4105 - accuracy: 0.8168 - val_loss: 0.4484 - val_accuracy: 0.7901\n","Epoch 44/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4102 - accuracy: 0.8160 - val_loss: 0.4430 - val_accuracy: 0.7923\n","Epoch 45/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4083 - accuracy: 0.8165 - val_loss: 0.4428 - val_accuracy: 0.7955\n","Epoch 46/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4018 - accuracy: 0.8229 - val_loss: 0.4443 - val_accuracy: 0.7912\n","Epoch 47/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4053 - accuracy: 0.8211 - val_loss: 0.4435 - val_accuracy: 0.7934\n","Epoch 48/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4030 - accuracy: 0.8211 - val_loss: 0.4468 - val_accuracy: 0.7955\n","Epoch 49/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4000 - accuracy: 0.8243 - val_loss: 0.4401 - val_accuracy: 0.7944\n","Epoch 50/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3958 - accuracy: 0.8275 - val_loss: 0.4386 - val_accuracy: 0.7955\n","Epoch 51/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3905 - accuracy: 0.8280 - val_loss: 0.4401 - val_accuracy: 0.7944\n","Epoch 52/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3929 - accuracy: 0.8243 - val_loss: 0.4378 - val_accuracy: 0.7944\n","Epoch 53/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3879 - accuracy: 0.8350 - val_loss: 0.4410 - val_accuracy: 0.7955\n","Epoch 54/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.3832 - accuracy: 0.8369 - val_loss: 0.4368 - val_accuracy: 0.7998\n","Epoch 55/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3828 - accuracy: 0.8286 - val_loss: 0.4340 - val_accuracy: 0.8019\n","Epoch 56/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.3773 - accuracy: 0.8406 - val_loss: 0.4356 - val_accuracy: 0.8019\n","Epoch 57/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3734 - accuracy: 0.8385 - val_loss: 0.4358 - val_accuracy: 0.8051\n","Epoch 58/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3704 - accuracy: 0.8382 - val_loss: 0.4368 - val_accuracy: 0.8041\n","Epoch 59/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3694 - accuracy: 0.8382 - val_loss: 0.4378 - val_accuracy: 0.8030\n","Epoch 60/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3678 - accuracy: 0.8401 - val_loss: 0.4363 - val_accuracy: 0.8073\n","Epoch 61/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3656 - accuracy: 0.8361 - val_loss: 0.4399 - val_accuracy: 0.8105\n","Epoch 62/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.3625 - accuracy: 0.8446 - val_loss: 0.4350 - val_accuracy: 0.8084\n","Epoch 63/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3640 - accuracy: 0.8441 - val_loss: 0.4394 - val_accuracy: 0.8094\n","Epoch 64/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3597 - accuracy: 0.8430 - val_loss: 0.4384 - val_accuracy: 0.8051\n","Epoch 65/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3506 - accuracy: 0.8500 - val_loss: 0.4405 - val_accuracy: 0.8105\n","Epoch 66/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3542 - accuracy: 0.8495 - val_loss: 0.4499 - val_accuracy: 0.8009\n","Epoch 67/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3490 - accuracy: 0.8508 - val_loss: 0.4354 - val_accuracy: 0.8126\n","Epoch 68/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3524 - accuracy: 0.8457 - val_loss: 0.4620 - val_accuracy: 0.8094\n","Epoch 69/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3459 - accuracy: 0.8564 - val_loss: 0.4341 - val_accuracy: 0.8158\n","Epoch 70/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3364 - accuracy: 0.8623 - val_loss: 0.4350 - val_accuracy: 0.8158\n","Epoch 71/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3342 - accuracy: 0.8626 - val_loss: 0.4371 - val_accuracy: 0.8201\n","Epoch 72/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3345 - accuracy: 0.8594 - val_loss: 0.4366 - val_accuracy: 0.8201\n","Epoch 73/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3269 - accuracy: 0.8663 - val_loss: 0.4406 - val_accuracy: 0.8062\n","Epoch 74/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3268 - accuracy: 0.8628 - val_loss: 0.4401 - val_accuracy: 0.8169\n","Epoch 75/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3238 - accuracy: 0.8645 - val_loss: 0.4442 - val_accuracy: 0.8094\n","Epoch 76/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3179 - accuracy: 0.8693 - val_loss: 0.4401 - val_accuracy: 0.8137\n","Epoch 77/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3167 - accuracy: 0.8744 - val_loss: 0.4416 - val_accuracy: 0.8158\n","Epoch 78/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3145 - accuracy: 0.8671 - val_loss: 0.4416 - val_accuracy: 0.8148\n","Epoch 79/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3097 - accuracy: 0.8725 - val_loss: 0.4439 - val_accuracy: 0.8126\n","Epoch 80/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3056 - accuracy: 0.8795 - val_loss: 0.4439 - val_accuracy: 0.8137\n","Epoch 81/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3052 - accuracy: 0.8768 - val_loss: 0.4449 - val_accuracy: 0.8158\n","Epoch 82/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2989 - accuracy: 0.8827 - val_loss: 0.4466 - val_accuracy: 0.8137\n","Epoch 83/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3043 - accuracy: 0.8717 - val_loss: 0.4671 - val_accuracy: 0.8116\n","Epoch 84/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2991 - accuracy: 0.8757 - val_loss: 0.4448 - val_accuracy: 0.8126\n","Epoch 85/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2979 - accuracy: 0.8803 - val_loss: 0.4438 - val_accuracy: 0.8180\n","Epoch 86/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2849 - accuracy: 0.8851 - val_loss: 0.4480 - val_accuracy: 0.8137\n","Epoch 87/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2845 - accuracy: 0.8870 - val_loss: 0.4499 - val_accuracy: 0.8148\n","Epoch 88/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2768 - accuracy: 0.8902 - val_loss: 0.4511 - val_accuracy: 0.8137\n","Epoch 89/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2790 - accuracy: 0.8819 - val_loss: 0.4492 - val_accuracy: 0.8169\n","Epoch 90/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2840 - accuracy: 0.8813 - val_loss: 0.4670 - val_accuracy: 0.8073\n","Epoch 91/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2708 - accuracy: 0.8894 - val_loss: 0.4488 - val_accuracy: 0.8201\n","Epoch 92/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2681 - accuracy: 0.8926 - val_loss: 0.4543 - val_accuracy: 0.8180\n","Epoch 93/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2644 - accuracy: 0.8950 - val_loss: 0.4561 - val_accuracy: 0.8158\n","Epoch 94/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2638 - accuracy: 0.8888 - val_loss: 0.4596 - val_accuracy: 0.8137\n","Epoch 95/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2605 - accuracy: 0.8977 - val_loss: 0.4731 - val_accuracy: 0.8223\n","Epoch 96/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2588 - accuracy: 0.8915 - val_loss: 0.4621 - val_accuracy: 0.8105\n","Epoch 97/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2480 - accuracy: 0.9062 - val_loss: 0.4627 - val_accuracy: 0.8137\n","Epoch 98/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2476 - accuracy: 0.8998 - val_loss: 0.4666 - val_accuracy: 0.8169\n","Epoch 99/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2493 - accuracy: 0.9012 - val_loss: 0.4683 - val_accuracy: 0.8169\n","Epoch 100/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2357 - accuracy: 0.9073 - val_loss: 0.5035 - val_accuracy: 0.8148\n","{'loss': [0.6929081082344055, 0.6918050050735474, 0.6892619729042053, 0.6836147308349609, 0.6711323857307434, 0.6466969847679138, 0.6087232232093811, 0.5675268769264221, 0.5419198870658875, 0.528112530708313, 0.5217682719230652, 0.5163145065307617, 0.5112015008926392, 0.506192147731781, 0.50407475233078, 0.5024574398994446, 0.4918866455554962, 0.49274447560310364, 0.4876239597797394, 0.4856201708316803, 0.48293304443359375, 0.4779098629951477, 0.4743918478488922, 0.4707711935043335, 0.4677368700504303, 0.46105626225471497, 0.4603477418422699, 0.4591444432735443, 0.4513199031352997, 0.4515245854854584, 0.4485355019569397, 0.4457866847515106, 0.4468032121658325, 0.4380474388599396, 0.43696239590644836, 0.43274208903312683, 0.4302302896976471, 0.4261625409126282, 0.4262997806072235, 0.4197677969932556, 0.423728883266449, 0.4167766571044922, 0.41045573353767395, 0.4101705849170685, 0.4082723557949066, 0.4017925262451172, 0.4053232967853546, 0.40296441316604614, 0.40000268816947937, 0.3957764804363251, 0.39052075147628784, 0.39286670088768005, 0.3879006803035736, 0.38317975401878357, 0.38284242153167725, 0.3773210644721985, 0.3733845055103302, 0.3704454004764557, 0.3694230020046234, 0.36780431866645813, 0.3656345307826996, 0.3624580502510071, 0.3640297055244446, 0.35966363549232483, 0.3505699038505554, 0.35417744517326355, 0.3490174412727356, 0.35241585969924927, 0.3458951413631439, 0.3363740146160126, 0.3341505825519562, 0.33452874422073364, 0.3268599212169647, 0.32679376006126404, 0.32375022768974304, 0.31789442896842957, 0.3166966140270233, 0.3145413398742676, 0.30967089533805847, 0.30559903383255005, 0.3052273392677307, 0.2989344298839569, 0.3043001592159271, 0.2991010844707489, 0.29791924357414246, 0.28491348028182983, 0.2845195233821869, 0.27676764130592346, 0.27899453043937683, 0.28403422236442566, 0.27080538868904114, 0.26811039447784424, 0.26441308856010437, 0.26378434896469116, 0.26050078868865967, 0.2587548792362213, 0.24796341359615326, 0.24757587909698486, 0.24929676949977875, 0.23573186993598938], 'accuracy': [0.5756763815879822, 0.6477364301681519, 0.7021162509918213, 0.720332145690918, 0.7272970676422119, 0.7307795286178589, 0.7339941263198853, 0.7374765872955322, 0.7380123138427734, 0.7401553988456726, 0.7449772357940674, 0.7527458071708679, 0.7559603452682495, 0.7591749429702759, 0.7581034302711487, 0.7562282085418701, 0.7634609937667847, 0.7688186168670654, 0.773104727268219, 0.7680150270462036, 0.7709617018699646, 0.7757835388183594, 0.776587188243866, 0.7784623503684998, 0.7755156755447388, 0.7838199734687805, 0.7824805974960327, 0.7862309217453003, 0.7937315702438354, 0.7931958436965942, 0.7942673563957214, 0.7956067323684692, 0.7966782450675964, 0.7990891933441162, 0.8004286289215088, 0.8068577647209167, 0.804982602596283, 0.8106080889701843, 0.8047146797180176, 0.8167693614959717, 0.8127511143684387, 0.8173050880432129, 0.8167693614959717, 0.8159657120704651, 0.8165014982223511, 0.822930634021759, 0.8210554718971252, 0.8210554718971252, 0.8242700099945068, 0.8274846076965332, 0.8280203342437744, 0.8242700099945068, 0.8349852561950684, 0.8368604183197021, 0.8285561203956604, 0.8406107425689697, 0.8384677171707153, 0.8381998538970947, 0.8381998538970947, 0.8400750160217285, 0.8360567688941956, 0.8446289896965027, 0.8440932035446167, 0.8430216908454895, 0.8499866127967834, 0.8494508266448975, 0.85079026222229, 0.8457005023956299, 0.8564157485961914, 0.8623091578483582, 0.8625770211219788, 0.8593624234199524, 0.8663273453712463, 0.8628448843955994, 0.8644521832466125, 0.8692740201950073, 0.8743637800216675, 0.8671309947967529, 0.8724886178970337, 0.8794535398483276, 0.8767747282981873, 0.8826680779457092, 0.8716849684715271, 0.8757032155990601, 0.8802571892738342, 0.885079026222229, 0.8869541883468628, 0.8901687860488892, 0.8818644285202026, 0.8813287019729614, 0.8893651366233826, 0.8925796747207642, 0.8949906229972839, 0.8888293504714966, 0.8976694345474243, 0.891508162021637, 0.9062416553497314, 0.8998124599456787, 0.9011518955230713, 0.9073131680488586], 'val_loss': [0.6930798888206482, 0.6929698586463928, 0.6926165819168091, 0.6917495727539062, 0.689687967300415, 0.6853435039520264, 0.676112174987793, 0.6633531451225281, 0.6496132612228394, 0.6358038187026978, 0.6234715580940247, 0.6110195517539978, 0.5976262092590332, 0.5836666226387024, 0.5704054832458496, 0.5576262474060059, 0.5408744215965271, 0.527790904045105, 0.512825608253479, 0.5019124150276184, 0.4962098002433777, 0.4916611909866333, 0.4817456007003784, 0.4803394675254822, 0.47335687279701233, 0.46998894214630127, 0.46735909581184387, 0.4686199426651001, 0.4653807282447815, 0.4631568491458893, 0.4606822729110718, 0.4641997814178467, 0.4581298828125, 0.45799893140792847, 0.4584865868091583, 0.4537947475910187, 0.452079176902771, 0.45232418179512024, 0.45663148164749146, 0.44977256655693054, 0.44769594073295593, 0.44682636857032776, 0.4484274685382843, 0.4429919421672821, 0.44279685616493225, 0.4443373382091522, 0.44345253705978394, 0.4468028247356415, 0.4401490092277527, 0.4386166036128998, 0.44009289145469666, 0.4377642273902893, 0.4409545063972473, 0.43682947754859924, 0.43395116925239563, 0.4355943202972412, 0.43584516644477844, 0.4368169605731964, 0.4378393590450287, 0.43634942173957825, 0.43989822268486023, 0.4349692165851593, 0.4393928349018097, 0.43842822313308716, 0.4404798150062561, 0.4498884379863739, 0.4354293644428253, 0.4619632959365845, 0.43409463763237, 0.43502965569496155, 0.43714800477027893, 0.4365919828414917, 0.44060295820236206, 0.44008079171180725, 0.4442426860332489, 0.4401094913482666, 0.44164222478866577, 0.44156479835510254, 0.4439031481742859, 0.44393178820610046, 0.4448856711387634, 0.44664517045021057, 0.4670921266078949, 0.4448150098323822, 0.44377586245536804, 0.4480050802230835, 0.4499207139015198, 0.4511012136936188, 0.4492216110229492, 0.46700242161750793, 0.44881659746170044, 0.454316109418869, 0.4561452567577362, 0.4595929980278015, 0.473117858171463, 0.4620748460292816, 0.46267035603523254, 0.4665878117084503, 0.46834471821784973, 0.5035398602485657], 'val_accuracy': [0.7152034044265747, 0.5085653066635132, 0.5289078950881958, 0.5963597297668457, 0.6841541528701782, 0.7184154391288757, 0.7269807457923889, 0.7366167306900024, 0.7387580275535583, 0.740899384021759, 0.7483940124511719, 0.740899384021759, 0.7451820373535156, 0.7548179626464844, 0.7601712942123413, 0.762312650680542, 0.7644539475440979, 0.7665953040122986, 0.7633832693099976, 0.7633832693099976, 0.7740899324417114, 0.7740899324417114, 0.7773019075393677, 0.7740899324417114, 0.7773019075393677, 0.778372585773468, 0.778372585773468, 0.7815845608711243, 0.778372585773468, 0.7847965955734253, 0.7826552391052246, 0.7815845608711243, 0.783725917339325, 0.7869378924369812, 0.7794432640075684, 0.7826552391052246, 0.7912205457687378, 0.7912205457687378, 0.778372585773468, 0.7933619022369385, 0.7912205457687378, 0.7922912240028381, 0.7901498675346375, 0.7922912240028381, 0.7955031991004944, 0.7912205457687378, 0.7933619022369385, 0.7955031991004944, 0.794432520866394, 0.7955031991004944, 0.794432520866394, 0.794432520866394, 0.7955031991004944, 0.799785852432251, 0.8019272089004517, 0.8019272089004517, 0.8051391839981079, 0.8040685057640076, 0.802997887134552, 0.8072805404663086, 0.8104925155639648, 0.8083511590957642, 0.8094218373298645, 0.8051391839981079, 0.8104925155639648, 0.8008565306663513, 0.8126338124275208, 0.8094218373298645, 0.8158458471298218, 0.8158458471298218, 0.8201285004615784, 0.8201285004615784, 0.8062098622322083, 0.8169164657592773, 0.8094218373298645, 0.8137044906616211, 0.8158458471298218, 0.8147751688957214, 0.8126338124275208, 0.8137044906616211, 0.8158458471298218, 0.8137044906616211, 0.8115631937980652, 0.8126338124275208, 0.8179871439933777, 0.8137044906616211, 0.8147751688957214, 0.8137044906616211, 0.8169164657592773, 0.8072805404663086, 0.8201285004615784, 0.8179871439933777, 0.8158458471298218, 0.8137044906616211, 0.8222697973251343, 0.8104925155639648, 0.8137044906616211, 0.8169164657592773, 0.8169164657592773, 0.8147751688957214]}\n","37/37 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 9s 81ms/step - loss: 0.3251 - accuracy: 0.8588 - val_loss: 0.6761 - val_accuracy: 0.5171\n","Epoch 2/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.3102 - accuracy: 0.8677 - val_loss: 0.6725 - val_accuracy: 0.5471\n","Epoch 3/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3127 - accuracy: 0.8733 - val_loss: 0.6689 - val_accuracy: 0.5525\n","Epoch 4/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3086 - accuracy: 0.8711 - val_loss: 0.6623 - val_accuracy: 0.6552\n","Epoch 5/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3045 - accuracy: 0.8682 - val_loss: 0.6576 - val_accuracy: 0.6403\n","Epoch 6/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3007 - accuracy: 0.8752 - val_loss: 0.6479 - val_accuracy: 0.7655\n","Epoch 7/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2975 - accuracy: 0.8773 - val_loss: 0.6402 - val_accuracy: 0.7891\n","Epoch 8/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2958 - accuracy: 0.8808 - val_loss: 0.6327 - val_accuracy: 0.7762\n","Epoch 9/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2869 - accuracy: 0.8856 - val_loss: 0.6197 - val_accuracy: 0.8084\n","Epoch 10/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2860 - accuracy: 0.8786 - val_loss: 0.6075 - val_accuracy: 0.8041\n","Epoch 11/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2774 - accuracy: 0.8862 - val_loss: 0.5900 - val_accuracy: 0.8169\n","Epoch 12/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2785 - accuracy: 0.8867 - val_loss: 0.5745 - val_accuracy: 0.8201\n","Epoch 13/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2746 - accuracy: 0.8931 - val_loss: 0.5549 - val_accuracy: 0.8223\n","Epoch 14/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2750 - accuracy: 0.8870 - val_loss: 0.5408 - val_accuracy: 0.8126\n","Epoch 15/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2684 - accuracy: 0.8915 - val_loss: 0.5154 - val_accuracy: 0.8201\n","Epoch 16/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2702 - accuracy: 0.8931 - val_loss: 0.4882 - val_accuracy: 0.8255\n","Epoch 17/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2665 - accuracy: 0.8920 - val_loss: 0.4648 - val_accuracy: 0.8201\n","Epoch 18/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2695 - accuracy: 0.8920 - val_loss: 0.4429 - val_accuracy: 0.8244\n","Epoch 19/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2578 - accuracy: 0.8974 - val_loss: 0.4242 - val_accuracy: 0.8180\n","Epoch 20/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2525 - accuracy: 0.8985 - val_loss: 0.4134 - val_accuracy: 0.8201\n","Epoch 21/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2499 - accuracy: 0.9049 - val_loss: 0.4087 - val_accuracy: 0.8244\n","Epoch 22/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2568 - accuracy: 0.8955 - val_loss: 0.4008 - val_accuracy: 0.8212\n","Epoch 23/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2454 - accuracy: 0.9006 - val_loss: 0.3939 - val_accuracy: 0.8191\n","Epoch 24/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2455 - accuracy: 0.9068 - val_loss: 0.3974 - val_accuracy: 0.8191\n","Epoch 25/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2453 - accuracy: 0.9036 - val_loss: 0.4008 - val_accuracy: 0.8244\n","Epoch 26/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2381 - accuracy: 0.9095 - val_loss: 0.4068 - val_accuracy: 0.8244\n","Epoch 27/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2379 - accuracy: 0.9049 - val_loss: 0.4126 - val_accuracy: 0.8212\n","Epoch 28/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2343 - accuracy: 0.9105 - val_loss: 0.4197 - val_accuracy: 0.8266\n","Epoch 29/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2239 - accuracy: 0.9151 - val_loss: 0.4283 - val_accuracy: 0.8191\n","Epoch 30/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2289 - accuracy: 0.9108 - val_loss: 0.4411 - val_accuracy: 0.8223\n","Epoch 31/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2299 - accuracy: 0.9121 - val_loss: 0.4280 - val_accuracy: 0.8212\n","Epoch 32/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2165 - accuracy: 0.9242 - val_loss: 0.4340 - val_accuracy: 0.8276\n","Epoch 33/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2143 - accuracy: 0.9180 - val_loss: 0.4363 - val_accuracy: 0.8255\n","Epoch 34/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2168 - accuracy: 0.9156 - val_loss: 0.4412 - val_accuracy: 0.8180\n","Epoch 35/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2065 - accuracy: 0.9202 - val_loss: 0.4494 - val_accuracy: 0.8137\n","Epoch 36/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2093 - accuracy: 0.9220 - val_loss: 0.4453 - val_accuracy: 0.8233\n","Epoch 37/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2109 - accuracy: 0.9220 - val_loss: 0.4500 - val_accuracy: 0.8212\n","Epoch 38/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1987 - accuracy: 0.9290 - val_loss: 0.4771 - val_accuracy: 0.8105\n","Epoch 39/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2143 - accuracy: 0.9143 - val_loss: 0.4557 - val_accuracy: 0.8116\n","Epoch 40/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2020 - accuracy: 0.9287 - val_loss: 0.4531 - val_accuracy: 0.8233\n","Epoch 41/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1902 - accuracy: 0.9336 - val_loss: 0.4576 - val_accuracy: 0.8276\n","Epoch 42/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1889 - accuracy: 0.9317 - val_loss: 0.4631 - val_accuracy: 0.8148\n","Epoch 43/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1885 - accuracy: 0.9320 - val_loss: 0.4866 - val_accuracy: 0.8180\n","Epoch 44/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1971 - accuracy: 0.9274 - val_loss: 0.4718 - val_accuracy: 0.8148\n","Epoch 45/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1806 - accuracy: 0.9349 - val_loss: 0.4671 - val_accuracy: 0.8180\n","Epoch 46/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1843 - accuracy: 0.9330 - val_loss: 0.4687 - val_accuracy: 0.8191\n","Epoch 47/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1825 - accuracy: 0.9352 - val_loss: 0.4721 - val_accuracy: 0.8191\n","Epoch 48/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1807 - accuracy: 0.9344 - val_loss: 0.4777 - val_accuracy: 0.8116\n","Epoch 49/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1723 - accuracy: 0.9403 - val_loss: 0.4817 - val_accuracy: 0.8137\n","Epoch 50/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1680 - accuracy: 0.9424 - val_loss: 0.4918 - val_accuracy: 0.8191\n","Epoch 51/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1705 - accuracy: 0.9357 - val_loss: 0.4891 - val_accuracy: 0.8276\n","Epoch 52/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1723 - accuracy: 0.9405 - val_loss: 0.4901 - val_accuracy: 0.8244\n","Epoch 53/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1650 - accuracy: 0.9454 - val_loss: 0.5009 - val_accuracy: 0.8244\n","Epoch 54/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1618 - accuracy: 0.9443 - val_loss: 0.4934 - val_accuracy: 0.8266\n","Epoch 55/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1606 - accuracy: 0.9419 - val_loss: 0.5050 - val_accuracy: 0.8191\n","Epoch 56/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1547 - accuracy: 0.9483 - val_loss: 0.5011 - val_accuracy: 0.8201\n","Epoch 57/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1561 - accuracy: 0.9454 - val_loss: 0.5136 - val_accuracy: 0.8169\n","Epoch 58/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1488 - accuracy: 0.9502 - val_loss: 0.5036 - val_accuracy: 0.8180\n","Epoch 59/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1494 - accuracy: 0.9520 - val_loss: 0.5089 - val_accuracy: 0.8169\n","Epoch 60/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1460 - accuracy: 0.9518 - val_loss: 0.5187 - val_accuracy: 0.8116\n","Epoch 61/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1421 - accuracy: 0.9518 - val_loss: 0.5170 - val_accuracy: 0.8148\n","Epoch 62/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1427 - accuracy: 0.9504 - val_loss: 0.5216 - val_accuracy: 0.8169\n","Epoch 63/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1406 - accuracy: 0.9499 - val_loss: 0.5316 - val_accuracy: 0.8148\n","Epoch 64/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1542 - accuracy: 0.9502 - val_loss: 0.5187 - val_accuracy: 0.8180\n","Epoch 65/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1377 - accuracy: 0.9550 - val_loss: 0.5334 - val_accuracy: 0.8180\n","Epoch 66/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1300 - accuracy: 0.9612 - val_loss: 0.5348 - val_accuracy: 0.8255\n","Epoch 67/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1367 - accuracy: 0.9563 - val_loss: 0.5436 - val_accuracy: 0.8158\n","Epoch 68/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1345 - accuracy: 0.9577 - val_loss: 0.5399 - val_accuracy: 0.8158\n","Epoch 69/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1318 - accuracy: 0.9539 - val_loss: 0.5652 - val_accuracy: 0.8041\n","Epoch 70/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1292 - accuracy: 0.9563 - val_loss: 0.5345 - val_accuracy: 0.8276\n","Epoch 71/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1231 - accuracy: 0.9609 - val_loss: 0.5414 - val_accuracy: 0.8169\n","Epoch 72/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1189 - accuracy: 0.9609 - val_loss: 0.5405 - val_accuracy: 0.8169\n","Epoch 73/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1189 - accuracy: 0.9638 - val_loss: 0.5477 - val_accuracy: 0.8180\n","Epoch 74/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1148 - accuracy: 0.9638 - val_loss: 0.5483 - val_accuracy: 0.8212\n","Epoch 75/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1126 - accuracy: 0.9652 - val_loss: 0.5515 - val_accuracy: 0.8180\n","Epoch 76/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1164 - accuracy: 0.9622 - val_loss: 0.5702 - val_accuracy: 0.8201\n","Epoch 77/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1202 - accuracy: 0.9601 - val_loss: 0.5817 - val_accuracy: 0.8266\n","Epoch 78/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1152 - accuracy: 0.9633 - val_loss: 0.5718 - val_accuracy: 0.8169\n","Epoch 79/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1127 - accuracy: 0.9630 - val_loss: 0.5764 - val_accuracy: 0.8212\n","Epoch 80/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1070 - accuracy: 0.9649 - val_loss: 0.5675 - val_accuracy: 0.8169\n","Epoch 81/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1121 - accuracy: 0.9657 - val_loss: 0.5742 - val_accuracy: 0.8180\n","Epoch 82/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1032 - accuracy: 0.9705 - val_loss: 0.5826 - val_accuracy: 0.8180\n","Epoch 83/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1145 - accuracy: 0.9612 - val_loss: 0.5809 - val_accuracy: 0.8212\n","Epoch 84/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1161 - accuracy: 0.9585 - val_loss: 0.5625 - val_accuracy: 0.8169\n","Epoch 85/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0947 - accuracy: 0.9727 - val_loss: 0.5736 - val_accuracy: 0.8116\n","Epoch 86/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1053 - accuracy: 0.9646 - val_loss: 0.5921 - val_accuracy: 0.8094\n","Epoch 87/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0981 - accuracy: 0.9711 - val_loss: 0.5849 - val_accuracy: 0.8116\n","Epoch 88/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0915 - accuracy: 0.9735 - val_loss: 0.6025 - val_accuracy: 0.8148\n","Epoch 89/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0892 - accuracy: 0.9729 - val_loss: 0.5982 - val_accuracy: 0.8180\n","Epoch 90/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0868 - accuracy: 0.9751 - val_loss: 0.5971 - val_accuracy: 0.8105\n","Epoch 91/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0826 - accuracy: 0.9788 - val_loss: 0.6076 - val_accuracy: 0.8223\n","Epoch 92/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0861 - accuracy: 0.9754 - val_loss: 0.6105 - val_accuracy: 0.8105\n","Epoch 93/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0803 - accuracy: 0.9799 - val_loss: 0.6166 - val_accuracy: 0.8148\n","Epoch 94/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0876 - accuracy: 0.9743 - val_loss: 0.6160 - val_accuracy: 0.8212\n","Epoch 95/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0899 - accuracy: 0.9719 - val_loss: 0.6267 - val_accuracy: 0.8137\n","Epoch 96/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0944 - accuracy: 0.9703 - val_loss: 0.6227 - val_accuracy: 0.8137\n","Epoch 97/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0795 - accuracy: 0.9783 - val_loss: 0.6206 - val_accuracy: 0.8191\n","Epoch 98/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0758 - accuracy: 0.9815 - val_loss: 0.6407 - val_accuracy: 0.8105\n","Epoch 99/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0796 - accuracy: 0.9778 - val_loss: 0.6750 - val_accuracy: 0.8180\n","Epoch 100/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0895 - accuracy: 0.9716 - val_loss: 0.6373 - val_accuracy: 0.8105\n","{'loss': [0.32507896423339844, 0.3101750314235687, 0.3127356171607971, 0.3086337745189667, 0.30454495549201965, 0.30065974593162537, 0.29753220081329346, 0.29579848051071167, 0.2869018316268921, 0.285995751619339, 0.27741506695747375, 0.27849552035331726, 0.2746056318283081, 0.2749978005886078, 0.2684137225151062, 0.27018988132476807, 0.2665313482284546, 0.2694934010505676, 0.25775521993637085, 0.25253427028656006, 0.24992457032203674, 0.2567512094974518, 0.2453533113002777, 0.24550779163837433, 0.2453378587961197, 0.23809689283370972, 0.23786020278930664, 0.23434589803218842, 0.22386468946933746, 0.22885656356811523, 0.22991187870502472, 0.21653494238853455, 0.21430319547653198, 0.21679827570915222, 0.2064766138792038, 0.20931600034236908, 0.2108771800994873, 0.1986728459596634, 0.21426184475421906, 0.20199967920780182, 0.19022057950496674, 0.18890467286109924, 0.18850116431713104, 0.19711697101593018, 0.18055227398872375, 0.18427570164203644, 0.1824687272310257, 0.18073506653308868, 0.17231671512126923, 0.16795143485069275, 0.17049089074134827, 0.1722961962223053, 0.16501197218894958, 0.1618386059999466, 0.16058605909347534, 0.15467312932014465, 0.15608389675617218, 0.14881056547164917, 0.1493784487247467, 0.14600655436515808, 0.14214643836021423, 0.14266382157802582, 0.14062714576721191, 0.15419384837150574, 0.13765017688274384, 0.12998762726783752, 0.13669177889823914, 0.13449107110500336, 0.1318240463733673, 0.12923641502857208, 0.123057521879673, 0.11894668638706207, 0.11886350065469742, 0.11475071310997009, 0.11259496212005615, 0.11638544499874115, 0.120242640376091, 0.11517015099525452, 0.11270908266305923, 0.10695243626832962, 0.112058624625206, 0.10320320725440979, 0.11445963382720947, 0.1161361038684845, 0.09465499967336655, 0.10533283650875092, 0.09805968403816223, 0.09153500944375992, 0.08924803882837296, 0.08683613687753677, 0.08260337263345718, 0.0860532820224762, 0.08029474318027496, 0.0876213014125824, 0.08986841887235641, 0.09439337253570557, 0.07953493297100067, 0.07581471651792526, 0.07956358790397644, 0.08953862637281418], 'accuracy': [0.8588266968727112, 0.8676667809486389, 0.8732922673225403, 0.8711491823196411, 0.8682025074958801, 0.8751674294471741, 0.8773104548454285, 0.8807929158210754, 0.885614812374115, 0.878649890422821, 0.8861505389213562, 0.8866863250732422, 0.8931154608726501, 0.8869541883468628, 0.891508162021637, 0.8931154608726501, 0.892043948173523, 0.892043948173523, 0.8974015712738037, 0.8984730839729309, 0.9049022197723389, 0.8955264091491699, 0.9006161093711853, 0.9067773818969727, 0.9035628437995911, 0.909456193447113, 0.9049022197723389, 0.9105277061462402, 0.9150816798210144, 0.9107956290245056, 0.9121350049972534, 0.9241896867752075, 0.9180284142494202, 0.9156174659729004, 0.9201714396476746, 0.9220466017723083, 0.9220466017723083, 0.9290115237236023, 0.9142780900001526, 0.9287436604499817, 0.9335654973983765, 0.9316903352737427, 0.9319581985473633, 0.9274042248725891, 0.9349048733711243, 0.9330297112464905, 0.9351727962493896, 0.9343691468238831, 0.940262496471405, 0.9424055814743042, 0.9357085227966309, 0.9405304193496704, 0.9453522562980652, 0.944280743598938, 0.9418697953224182, 0.9482989311218262, 0.9453522562980652, 0.95017409324646, 0.9520493149757385, 0.9517813920974731, 0.9517813920974731, 0.9504420161247253, 0.9499062299728394, 0.95017409324646, 0.9549959897994995, 0.9611572623252869, 0.9563353657722473, 0.9576748013496399, 0.9539244771003723, 0.9563353657722473, 0.9608893394470215, 0.9608893394470215, 0.9638360738754272, 0.9638360738754272, 0.965175449848175, 0.9622287750244141, 0.9600857496261597, 0.9633002877235413, 0.9630324244499207, 0.9649075865745544, 0.965711236000061, 0.9705330729484558, 0.9611572623252869, 0.9584784507751465, 0.972676157951355, 0.9646397233009338, 0.9710688591003418, 0.9734797477722168, 0.9729440212249756, 0.97508704662323, 0.9788373708724976, 0.9753549695014954, 0.9799089431762695, 0.9742833971977234, 0.9718725085258484, 0.9702652096748352, 0.9783016443252563, 0.9815161824226379, 0.9777658581733704, 0.971604585647583], 'val_loss': [0.6760523319244385, 0.6724773049354553, 0.6688663363456726, 0.6622554063796997, 0.657579779624939, 0.6479182839393616, 0.640210747718811, 0.6326719522476196, 0.6197044253349304, 0.6074811220169067, 0.5900392532348633, 0.5745285153388977, 0.5549295544624329, 0.5408157110214233, 0.5153844952583313, 0.4882272779941559, 0.46479541063308716, 0.442911833524704, 0.42420607805252075, 0.41344255208969116, 0.4087466895580292, 0.4008373022079468, 0.3938811421394348, 0.3974137604236603, 0.4007616639137268, 0.40683743357658386, 0.4125671088695526, 0.41967642307281494, 0.42833924293518066, 0.44114950299263, 0.42801108956336975, 0.4340183138847351, 0.4363480508327484, 0.4411774277687073, 0.4493960440158844, 0.4453481137752533, 0.4500213861465454, 0.47709208726882935, 0.45571649074554443, 0.45314908027648926, 0.45759961009025574, 0.4631066620349884, 0.4865786135196686, 0.47180119156837463, 0.46708956360816956, 0.46873512864112854, 0.47209441661834717, 0.4776594042778015, 0.4816567003726959, 0.49177512526512146, 0.4891365170478821, 0.4900790750980377, 0.5009359121322632, 0.49341532588005066, 0.5049833655357361, 0.501081109046936, 0.5135507583618164, 0.503614604473114, 0.5088669061660767, 0.5186986923217773, 0.5169724822044373, 0.5216049551963806, 0.5315669775009155, 0.5187424421310425, 0.5334227681159973, 0.5348334908485413, 0.5435910224914551, 0.5398677587509155, 0.5651768445968628, 0.5344597697257996, 0.541374683380127, 0.540542721748352, 0.547662615776062, 0.548332691192627, 0.5515327453613281, 0.5701743364334106, 0.5816670656204224, 0.5717563033103943, 0.576352059841156, 0.5675150752067566, 0.5742266178131104, 0.5825641751289368, 0.5809372663497925, 0.5624756217002869, 0.5736333727836609, 0.5921342968940735, 0.5849142670631409, 0.6025269031524658, 0.5982260704040527, 0.597122073173523, 0.6075606942176819, 0.6104519367218018, 0.6166124939918518, 0.6160481572151184, 0.62674880027771, 0.6226532459259033, 0.6205563545227051, 0.6406543850898743, 0.6750429272651672, 0.6372988820075989], 'val_accuracy': [0.5171306133270264, 0.5471091866493225, 0.5524625182151794, 0.6552462577819824, 0.640256941318512, 0.7655246257781982, 0.7890792489051819, 0.7762312889099121, 0.8083511590957642, 0.8040685057640076, 0.8169164657592773, 0.8201285004615784, 0.8222697973251343, 0.8126338124275208, 0.8201285004615784, 0.8254817724227905, 0.8201285004615784, 0.824411153793335, 0.8179871439933777, 0.8201285004615784, 0.824411153793335, 0.8211991190910339, 0.819057822227478, 0.819057822227478, 0.824411153793335, 0.824411153793335, 0.8211991190910339, 0.8265524506568909, 0.819057822227478, 0.8222697973251343, 0.8211991190910339, 0.8276231288909912, 0.8254817724227905, 0.8179871439933777, 0.8137044906616211, 0.8233404755592346, 0.8211991190910339, 0.8104925155639648, 0.8115631937980652, 0.8233404755592346, 0.8276231288909912, 0.8147751688957214, 0.8179871439933777, 0.8147751688957214, 0.8179871439933777, 0.819057822227478, 0.819057822227478, 0.8115631937980652, 0.8137044906616211, 0.819057822227478, 0.8276231288909912, 0.824411153793335, 0.824411153793335, 0.8265524506568909, 0.819057822227478, 0.8201285004615784, 0.8169164657592773, 0.8179871439933777, 0.8169164657592773, 0.8115631937980652, 0.8147751688957214, 0.8169164657592773, 0.8147751688957214, 0.8179871439933777, 0.8179871439933777, 0.8254817724227905, 0.8158458471298218, 0.8158458471298218, 0.8040685057640076, 0.8276231288909912, 0.8169164657592773, 0.8169164657592773, 0.8179871439933777, 0.8211991190910339, 0.8179871439933777, 0.8201285004615784, 0.8265524506568909, 0.8169164657592773, 0.8211991190910339, 0.8169164657592773, 0.8179871439933777, 0.8179871439933777, 0.8211991190910339, 0.8169164657592773, 0.8115631937980652, 0.8094218373298645, 0.8115631937980652, 0.8147751688957214, 0.8179871439933777, 0.8104925155639648, 0.8222697973251343, 0.8104925155639648, 0.8147751688957214, 0.8211991190910339, 0.8137044906616211, 0.8137044906616211, 0.819057822227478, 0.8104925155639648, 0.8179871439933777, 0.8104925155639648]}\n","37/37 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 46ms/step - loss: 0.3153 - accuracy: 0.8653 - val_loss: 0.6769 - val_accuracy: 0.4904\n","Epoch 2/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3150 - accuracy: 0.8738 - val_loss: 0.6722 - val_accuracy: 0.5075\n","Epoch 3/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3068 - accuracy: 0.8765 - val_loss: 0.6672 - val_accuracy: 0.5493\n","Epoch 4/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3046 - accuracy: 0.8725 - val_loss: 0.6628 - val_accuracy: 0.5482\n","Epoch 5/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2995 - accuracy: 0.8770 - val_loss: 0.6559 - val_accuracy: 0.6188\n","Epoch 6/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.2986 - accuracy: 0.8800 - val_loss: 0.6463 - val_accuracy: 0.7259\n","Epoch 7/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2934 - accuracy: 0.8792 - val_loss: 0.6382 - val_accuracy: 0.7495\n","Epoch 8/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2953 - accuracy: 0.8805 - val_loss: 0.6280 - val_accuracy: 0.7612\n","Epoch 9/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2880 - accuracy: 0.8808 - val_loss: 0.6116 - val_accuracy: 0.8405\n","Epoch 10/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2870 - accuracy: 0.8867 - val_loss: 0.6010 - val_accuracy: 0.8105\n","Epoch 11/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2827 - accuracy: 0.8827 - val_loss: 0.5813 - val_accuracy: 0.8415\n","Epoch 12/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2811 - accuracy: 0.8886 - val_loss: 0.5641 - val_accuracy: 0.8448\n","Epoch 13/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2749 - accuracy: 0.8875 - val_loss: 0.5416 - val_accuracy: 0.8469\n","Epoch 14/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2707 - accuracy: 0.8910 - val_loss: 0.5239 - val_accuracy: 0.8405\n","Epoch 15/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2734 - accuracy: 0.8902 - val_loss: 0.4903 - val_accuracy: 0.8512\n","Epoch 16/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2699 - accuracy: 0.8945 - val_loss: 0.4624 - val_accuracy: 0.8555\n","Epoch 17/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2636 - accuracy: 0.8920 - val_loss: 0.4383 - val_accuracy: 0.8448\n","Epoch 18/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2631 - accuracy: 0.8953 - val_loss: 0.4145 - val_accuracy: 0.8480\n","Epoch 19/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2525 - accuracy: 0.9012 - val_loss: 0.3845 - val_accuracy: 0.8587\n","Epoch 20/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2568 - accuracy: 0.8928 - val_loss: 0.3638 - val_accuracy: 0.8630\n","Epoch 21/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2494 - accuracy: 0.8979 - val_loss: 0.3497 - val_accuracy: 0.8555\n","Epoch 22/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2454 - accuracy: 0.9038 - val_loss: 0.3353 - val_accuracy: 0.8587\n","Epoch 23/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2409 - accuracy: 0.9054 - val_loss: 0.3287 - val_accuracy: 0.8565\n","Epoch 24/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2419 - accuracy: 0.9022 - val_loss: 0.3460 - val_accuracy: 0.8501\n","Epoch 25/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2537 - accuracy: 0.8958 - val_loss: 0.3268 - val_accuracy: 0.8565\n","Epoch 26/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2340 - accuracy: 0.9095 - val_loss: 0.3273 - val_accuracy: 0.8630\n","Epoch 27/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2353 - accuracy: 0.9081 - val_loss: 0.3281 - val_accuracy: 0.8597\n","Epoch 28/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2330 - accuracy: 0.9097 - val_loss: 0.3320 - val_accuracy: 0.8544\n","Epoch 29/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2211 - accuracy: 0.9108 - val_loss: 0.3333 - val_accuracy: 0.8555\n","Epoch 30/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.2193 - accuracy: 0.9156 - val_loss: 0.3367 - val_accuracy: 0.8576\n","Epoch 31/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2337 - accuracy: 0.9057 - val_loss: 0.3446 - val_accuracy: 0.8587\n","Epoch 32/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2092 - accuracy: 0.9239 - val_loss: 0.3405 - val_accuracy: 0.8555\n","Epoch 33/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2124 - accuracy: 0.9210 - val_loss: 0.3680 - val_accuracy: 0.8533\n","Epoch 34/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2287 - accuracy: 0.9116 - val_loss: 0.3406 - val_accuracy: 0.8587\n","Epoch 35/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2027 - accuracy: 0.9229 - val_loss: 0.3456 - val_accuracy: 0.8597\n","Epoch 36/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2052 - accuracy: 0.9237 - val_loss: 0.3508 - val_accuracy: 0.8587\n","Epoch 37/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2078 - accuracy: 0.9218 - val_loss: 0.3550 - val_accuracy: 0.8458\n","Epoch 38/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1992 - accuracy: 0.9266 - val_loss: 0.3476 - val_accuracy: 0.8522\n","Epoch 39/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1967 - accuracy: 0.9261 - val_loss: 0.3475 - val_accuracy: 0.8565\n","Epoch 40/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1993 - accuracy: 0.9242 - val_loss: 0.3531 - val_accuracy: 0.8608\n","Epoch 41/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1941 - accuracy: 0.9266 - val_loss: 0.3544 - val_accuracy: 0.8501\n","Epoch 42/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1945 - accuracy: 0.9263 - val_loss: 0.3659 - val_accuracy: 0.8555\n","Epoch 43/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1879 - accuracy: 0.9282 - val_loss: 0.3671 - val_accuracy: 0.8608\n","Epoch 44/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1859 - accuracy: 0.9295 - val_loss: 0.3576 - val_accuracy: 0.8565\n","Epoch 45/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1861 - accuracy: 0.9274 - val_loss: 0.3563 - val_accuracy: 0.8544\n","Epoch 46/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1763 - accuracy: 0.9376 - val_loss: 0.3585 - val_accuracy: 0.8576\n","Epoch 47/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1811 - accuracy: 0.9317 - val_loss: 0.3595 - val_accuracy: 0.8555\n","Epoch 48/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1724 - accuracy: 0.9408 - val_loss: 0.3667 - val_accuracy: 0.8651\n","Epoch 49/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1667 - accuracy: 0.9437 - val_loss: 0.3627 - val_accuracy: 0.8565\n","Epoch 50/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1609 - accuracy: 0.9413 - val_loss: 0.3631 - val_accuracy: 0.8490\n","Epoch 51/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1619 - accuracy: 0.9448 - val_loss: 0.3751 - val_accuracy: 0.8501\n","Epoch 52/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1704 - accuracy: 0.9370 - val_loss: 0.3876 - val_accuracy: 0.8512\n","Epoch 53/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1661 - accuracy: 0.9403 - val_loss: 0.3681 - val_accuracy: 0.8587\n","Epoch 54/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1556 - accuracy: 0.9480 - val_loss: 0.3673 - val_accuracy: 0.8608\n","Epoch 55/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1540 - accuracy: 0.9464 - val_loss: 0.3731 - val_accuracy: 0.8565\n","Epoch 56/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1556 - accuracy: 0.9459 - val_loss: 0.3818 - val_accuracy: 0.8608\n","Epoch 57/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1459 - accuracy: 0.9480 - val_loss: 0.3819 - val_accuracy: 0.8490\n","Epoch 58/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1484 - accuracy: 0.9475 - val_loss: 0.3778 - val_accuracy: 0.8640\n","Epoch 59/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1513 - accuracy: 0.9494 - val_loss: 0.3758 - val_accuracy: 0.8576\n","Epoch 60/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1374 - accuracy: 0.9545 - val_loss: 0.3783 - val_accuracy: 0.8619\n","Epoch 61/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1414 - accuracy: 0.9515 - val_loss: 0.3819 - val_accuracy: 0.8597\n","Epoch 62/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1340 - accuracy: 0.9547 - val_loss: 0.3853 - val_accuracy: 0.8533\n","Epoch 63/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.1325 - accuracy: 0.9585 - val_loss: 0.3830 - val_accuracy: 0.8597\n","Epoch 64/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1284 - accuracy: 0.9595 - val_loss: 0.3877 - val_accuracy: 0.8597\n","Epoch 65/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1299 - accuracy: 0.9561 - val_loss: 0.3923 - val_accuracy: 0.8630\n","Epoch 66/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1249 - accuracy: 0.9595 - val_loss: 0.3982 - val_accuracy: 0.8565\n","Epoch 67/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1228 - accuracy: 0.9566 - val_loss: 0.3956 - val_accuracy: 0.8630\n","Epoch 68/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1218 - accuracy: 0.9563 - val_loss: 0.3992 - val_accuracy: 0.8597\n","Epoch 69/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1213 - accuracy: 0.9590 - val_loss: 0.4117 - val_accuracy: 0.8587\n","Epoch 70/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1220 - accuracy: 0.9579 - val_loss: 0.4042 - val_accuracy: 0.8544\n","Epoch 71/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1167 - accuracy: 0.9622 - val_loss: 0.4175 - val_accuracy: 0.8469\n","Epoch 72/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1120 - accuracy: 0.9628 - val_loss: 0.4082 - val_accuracy: 0.8597\n","Epoch 73/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1142 - accuracy: 0.9638 - val_loss: 0.4207 - val_accuracy: 0.8672\n","Epoch 74/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1144 - accuracy: 0.9612 - val_loss: 0.4123 - val_accuracy: 0.8576\n","Epoch 75/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1092 - accuracy: 0.9665 - val_loss: 0.4130 - val_accuracy: 0.8576\n","Epoch 76/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1048 - accuracy: 0.9679 - val_loss: 0.4189 - val_accuracy: 0.8576\n","Epoch 77/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1069 - accuracy: 0.9649 - val_loss: 0.4194 - val_accuracy: 0.8587\n","Epoch 78/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1107 - accuracy: 0.9585 - val_loss: 0.4198 - val_accuracy: 0.8630\n","Epoch 79/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1011 - accuracy: 0.9695 - val_loss: 0.4226 - val_accuracy: 0.8608\n","Epoch 80/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1012 - accuracy: 0.9633 - val_loss: 0.4365 - val_accuracy: 0.8640\n","Epoch 81/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1030 - accuracy: 0.9671 - val_loss: 0.4296 - val_accuracy: 0.8544\n","Epoch 82/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0927 - accuracy: 0.9727 - val_loss: 0.4318 - val_accuracy: 0.8576\n","Epoch 83/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0900 - accuracy: 0.9732 - val_loss: 0.4559 - val_accuracy: 0.8576\n","Epoch 84/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0902 - accuracy: 0.9737 - val_loss: 0.4457 - val_accuracy: 0.8522\n","Epoch 85/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1025 - accuracy: 0.9649 - val_loss: 0.4548 - val_accuracy: 0.8480\n","Epoch 86/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0888 - accuracy: 0.9767 - val_loss: 0.4420 - val_accuracy: 0.8608\n","Epoch 87/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0878 - accuracy: 0.9711 - val_loss: 0.4454 - val_accuracy: 0.8619\n","Epoch 88/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0801 - accuracy: 0.9778 - val_loss: 0.4503 - val_accuracy: 0.8608\n","Epoch 89/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0876 - accuracy: 0.9735 - val_loss: 0.4521 - val_accuracy: 0.8576\n","Epoch 90/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0956 - accuracy: 0.9662 - val_loss: 0.4413 - val_accuracy: 0.8662\n","Epoch 91/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0807 - accuracy: 0.9770 - val_loss: 0.4440 - val_accuracy: 0.8608\n","Epoch 92/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0792 - accuracy: 0.9783 - val_loss: 0.4593 - val_accuracy: 0.8619\n","Epoch 93/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0800 - accuracy: 0.9759 - val_loss: 0.4580 - val_accuracy: 0.8619\n","Epoch 94/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0726 - accuracy: 0.9778 - val_loss: 0.4666 - val_accuracy: 0.8544\n","Epoch 95/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0787 - accuracy: 0.9775 - val_loss: 0.4932 - val_accuracy: 0.8587\n","Epoch 96/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0753 - accuracy: 0.9772 - val_loss: 0.4663 - val_accuracy: 0.8576\n","Epoch 97/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0717 - accuracy: 0.9794 - val_loss: 0.4944 - val_accuracy: 0.8576\n","Epoch 98/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0779 - accuracy: 0.9729 - val_loss: 0.4713 - val_accuracy: 0.8630\n","Epoch 99/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0662 - accuracy: 0.9821 - val_loss: 0.5004 - val_accuracy: 0.8405\n","Epoch 100/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0681 - accuracy: 0.9804 - val_loss: 0.4875 - val_accuracy: 0.8608\n","{'loss': [0.31534406542778015, 0.3150002062320709, 0.3068316876888275, 0.3046223223209381, 0.2995370030403137, 0.2985627353191376, 0.2934148609638214, 0.2952750325202942, 0.2879897952079773, 0.28696906566619873, 0.28266265988349915, 0.2810792922973633, 0.2748989760875702, 0.2706710994243622, 0.273396372795105, 0.26989349722862244, 0.26357465982437134, 0.2631286382675171, 0.25252121686935425, 0.25676822662353516, 0.24939677119255066, 0.24535168707370758, 0.24094019830226898, 0.24190457165241241, 0.25374162197113037, 0.23402704298496246, 0.23528634011745453, 0.2330448031425476, 0.22110475599765778, 0.2193320095539093, 0.23368950188159943, 0.20920361578464508, 0.2123752385377884, 0.22871102392673492, 0.2026740163564682, 0.2051747590303421, 0.20775170624256134, 0.19916129112243652, 0.19671832025051117, 0.1992644965648651, 0.19413822889328003, 0.19447678327560425, 0.1878529042005539, 0.18594256043434143, 0.18608342111110687, 0.17626813054084778, 0.18110814690589905, 0.17239563167095184, 0.1667429357767105, 0.16085965931415558, 0.161860853433609, 0.170430526137352, 0.16608740389347076, 0.15558716654777527, 0.1539774090051651, 0.15564607083797455, 0.14592565596103668, 0.1483508050441742, 0.15130984783172607, 0.13740144670009613, 0.14136461913585663, 0.13397164642810822, 0.13245326280593872, 0.12842223048210144, 0.1299283504486084, 0.12491884082555771, 0.12279196083545685, 0.12183623760938644, 0.1213473230600357, 0.12203022092580795, 0.11673452705144882, 0.11199580878019333, 0.11424568295478821, 0.11442697793245316, 0.10922744125127792, 0.10478834062814713, 0.10689383000135422, 0.11071514338254929, 0.10111617296934128, 0.10122489184141159, 0.10296404361724854, 0.09272410720586777, 0.09003500640392303, 0.09020291268825531, 0.10247483104467392, 0.08878422528505325, 0.08777306228876114, 0.08012526482343674, 0.08762914687395096, 0.09555896371603012, 0.0806628167629242, 0.07915911823511124, 0.08000371605157852, 0.07263999432325363, 0.0787149965763092, 0.07525850832462311, 0.07170963287353516, 0.07786548137664795, 0.06616318225860596, 0.06810858845710754], 'accuracy': [0.8652558326721191, 0.8738279938697815, 0.8765068054199219, 0.8724886178970337, 0.8770425915718079, 0.8799892663955688, 0.8791856169700623, 0.8805250525474548, 0.8807929158210754, 0.8866863250732422, 0.8826680779457092, 0.888561487197876, 0.8874899744987488, 0.8909724354743958, 0.8901687860488892, 0.894454836845398, 0.892043948173523, 0.8952584862709045, 0.9011518955230713, 0.8928475975990295, 0.8979372978210449, 0.9038307070732117, 0.9054380059242249, 0.9022234082221985, 0.8957942724227905, 0.909456193447113, 0.9081168174743652, 0.9097240567207336, 0.9107956290245056, 0.9156174659729004, 0.9057058691978455, 0.9239217638969421, 0.9209750890731812, 0.9115992784500122, 0.9228502511978149, 0.9236539006233215, 0.9217787384986877, 0.9266005754470825, 0.9260648488998413, 0.9241896867752075, 0.9266005754470825, 0.9263327121734619, 0.9282078742980957, 0.9295473098754883, 0.9274042248725891, 0.9375836849212646, 0.9316903352737427, 0.940798282623291, 0.943744957447052, 0.941334068775177, 0.944816529750824, 0.9370479583740234, 0.940262496471405, 0.9480310678482056, 0.9464237689971924, 0.9458880424499512, 0.9480310678482056, 0.9474953413009644, 0.9493705034255981, 0.9544602036476135, 0.9515135288238525, 0.9547281265258789, 0.9584784507751465, 0.9595499634742737, 0.9560675024986267, 0.9595499634742737, 0.9566032886505127, 0.9563353657722473, 0.9590141773223877, 0.9579426646232605, 0.9622287750244141, 0.9627645611763, 0.9638360738754272, 0.9611572623252869, 0.9665148854255676, 0.9678542613983154, 0.9649075865745544, 0.9584784507751465, 0.9694615602493286, 0.9633002877235413, 0.9670506119728088, 0.972676157951355, 0.9732118844985962, 0.9737476706504822, 0.9649075865745544, 0.9766943454742432, 0.9710688591003418, 0.9777658581733704, 0.9734797477722168, 0.9662469625473022, 0.9769622087478638, 0.9783016443252563, 0.9758906960487366, 0.9777658581733704, 0.9774979948997498, 0.9772301316261292, 0.9793731570243835, 0.9729440212249756, 0.9820519685745239, 0.9804446697235107], 'val_loss': [0.6769227385520935, 0.672161877155304, 0.6671964526176453, 0.6627750992774963, 0.655873715877533, 0.6463069319725037, 0.6382074356079102, 0.6279826760292053, 0.6116011738777161, 0.6009784936904907, 0.5812528729438782, 0.5641441345214844, 0.5416092872619629, 0.5238825678825378, 0.49032464623451233, 0.46240779757499695, 0.4383183419704437, 0.414528489112854, 0.3844747841358185, 0.3638322353363037, 0.34971144795417786, 0.33534398674964905, 0.3287128508090973, 0.3460313379764557, 0.3268265724182129, 0.3272760808467865, 0.3281092643737793, 0.3320345878601074, 0.3332567811012268, 0.33674517273902893, 0.3445969820022583, 0.34047314524650574, 0.3679533004760742, 0.34062233567237854, 0.3455970883369446, 0.35082361102104187, 0.3550092577934265, 0.3475726842880249, 0.34745949506759644, 0.35313159227371216, 0.354392409324646, 0.3659158945083618, 0.3671351671218872, 0.3575635254383087, 0.35634905099868774, 0.35854431986808777, 0.35946381092071533, 0.3667433559894562, 0.36272937059402466, 0.36308398842811584, 0.3751494288444519, 0.3875986635684967, 0.3680543899536133, 0.36727529764175415, 0.37308239936828613, 0.3817638158798218, 0.38189026713371277, 0.3777519166469574, 0.3757531940937042, 0.3782587945461273, 0.38188135623931885, 0.3853398263454437, 0.3829786777496338, 0.38767504692077637, 0.3923114538192749, 0.39819905161857605, 0.3955540359020233, 0.39915433526039124, 0.4117099642753601, 0.4041736423969269, 0.4174916744232178, 0.4082368314266205, 0.42074552178382874, 0.4122505486011505, 0.4130462408065796, 0.4188988208770752, 0.41935598850250244, 0.41976454854011536, 0.4226357042789459, 0.4364895224571228, 0.429644376039505, 0.4317554235458374, 0.455949991941452, 0.4456980526447296, 0.45478400588035583, 0.44204115867614746, 0.4454464018344879, 0.45029088854789734, 0.4521310031414032, 0.44134044647216797, 0.44404128193855286, 0.4593008756637573, 0.45799586176872253, 0.46662676334381104, 0.493196576833725, 0.4663003981113434, 0.49438270926475525, 0.4713263213634491, 0.5004250407218933, 0.48750069737434387], 'val_accuracy': [0.4903640151023865, 0.5074946284294128, 0.5492505431175232, 0.5481798648834229, 0.618843674659729, 0.7259100675582886, 0.7494646906852722, 0.7612419724464417, 0.840471088886261, 0.8104925155639648, 0.8415417671203613, 0.8447537422180176, 0.8468950986862183, 0.840471088886261, 0.8511777520179749, 0.8554604053497314, 0.8447537422180176, 0.8479657173156738, 0.8586723804473877, 0.8629550337791443, 0.8554604053497314, 0.8586723804473877, 0.856531023979187, 0.8501070737838745, 0.856531023979187, 0.8629550337791443, 0.859743058681488, 0.8543897271156311, 0.8554604053497314, 0.8576017022132874, 0.8586723804473877, 0.8554604053497314, 0.8533190488815308, 0.8586723804473877, 0.859743058681488, 0.8586723804473877, 0.8458244204521179, 0.8522483706474304, 0.856531023979187, 0.8608136773109436, 0.8501070737838745, 0.8554604053497314, 0.8608136773109436, 0.856531023979187, 0.8543897271156311, 0.8576017022132874, 0.8554604053497314, 0.8650963306427002, 0.856531023979187, 0.8490363955497742, 0.8501070737838745, 0.8511777520179749, 0.8586723804473877, 0.8608136773109436, 0.856531023979187, 0.8608136773109436, 0.8490363955497742, 0.8640257120132446, 0.8576017022132874, 0.861884355545044, 0.859743058681488, 0.8533190488815308, 0.859743058681488, 0.859743058681488, 0.8629550337791443, 0.856531023979187, 0.8629550337791443, 0.859743058681488, 0.8586723804473877, 0.8543897271156311, 0.8468950986862183, 0.859743058681488, 0.8672376871109009, 0.8576017022132874, 0.8576017022132874, 0.8576017022132874, 0.8586723804473877, 0.8629550337791443, 0.8608136773109436, 0.8640257120132446, 0.8543897271156311, 0.8576017022132874, 0.8576017022132874, 0.8522483706474304, 0.8479657173156738, 0.8608136773109436, 0.861884355545044, 0.8608136773109436, 0.8576017022132874, 0.8661670088768005, 0.8608136773109436, 0.861884355545044, 0.861884355545044, 0.8543897271156311, 0.8586723804473877, 0.8576017022132874, 0.8576017022132874, 0.8629550337791443, 0.840471088886261, 0.8608136773109436]}\n","37/37 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 65ms/step - loss: 0.3278 - accuracy: 0.8615 - val_loss: 0.6756 - val_accuracy: 0.5086\n","Epoch 2/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3161 - accuracy: 0.8709 - val_loss: 0.6704 - val_accuracy: 0.5621\n","Epoch 3/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3088 - accuracy: 0.8701 - val_loss: 0.6653 - val_accuracy: 0.5996\n","Epoch 4/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3058 - accuracy: 0.8714 - val_loss: 0.6596 - val_accuracy: 0.6692\n","Epoch 5/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3030 - accuracy: 0.8736 - val_loss: 0.6533 - val_accuracy: 0.7088\n","Epoch 6/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2966 - accuracy: 0.8786 - val_loss: 0.6439 - val_accuracy: 0.7955\n","Epoch 7/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2939 - accuracy: 0.8765 - val_loss: 0.6367 - val_accuracy: 0.7827\n","Epoch 8/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2916 - accuracy: 0.8789 - val_loss: 0.6264 - val_accuracy: 0.7859\n","Epoch 9/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.2852 - accuracy: 0.8832 - val_loss: 0.6122 - val_accuracy: 0.8287\n","Epoch 10/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2815 - accuracy: 0.8819 - val_loss: 0.5942 - val_accuracy: 0.8469\n","Epoch 11/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2793 - accuracy: 0.8902 - val_loss: 0.5800 - val_accuracy: 0.8448\n","Epoch 12/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2769 - accuracy: 0.8915 - val_loss: 0.5602 - val_accuracy: 0.8512\n","Epoch 13/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2663 - accuracy: 0.8920 - val_loss: 0.5326 - val_accuracy: 0.8373\n","Epoch 14/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2657 - accuracy: 0.8859 - val_loss: 0.5151 - val_accuracy: 0.8437\n","Epoch 15/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2589 - accuracy: 0.8963 - val_loss: 0.4875 - val_accuracy: 0.8426\n","Epoch 16/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2612 - accuracy: 0.8955 - val_loss: 0.4563 - val_accuracy: 0.8469\n","Epoch 17/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2544 - accuracy: 0.8955 - val_loss: 0.4332 - val_accuracy: 0.8501\n","Epoch 18/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2546 - accuracy: 0.8985 - val_loss: 0.4117 - val_accuracy: 0.8490\n","Epoch 19/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2551 - accuracy: 0.8979 - val_loss: 0.3877 - val_accuracy: 0.8480\n","Epoch 20/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2446 - accuracy: 0.9038 - val_loss: 0.3672 - val_accuracy: 0.8426\n","Epoch 21/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2484 - accuracy: 0.9022 - val_loss: 0.3557 - val_accuracy: 0.8480\n","Epoch 22/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2389 - accuracy: 0.9022 - val_loss: 0.3480 - val_accuracy: 0.8480\n","Epoch 23/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2347 - accuracy: 0.9078 - val_loss: 0.3454 - val_accuracy: 0.8512\n","Epoch 24/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2357 - accuracy: 0.9068 - val_loss: 0.3545 - val_accuracy: 0.8415\n","Epoch 25/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2294 - accuracy: 0.9095 - val_loss: 0.3473 - val_accuracy: 0.8490\n","Epoch 26/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2304 - accuracy: 0.9068 - val_loss: 0.3649 - val_accuracy: 0.8426\n","Epoch 27/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2292 - accuracy: 0.9073 - val_loss: 0.3606 - val_accuracy: 0.8490\n","Epoch 28/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2197 - accuracy: 0.9175 - val_loss: 0.3600 - val_accuracy: 0.8490\n","Epoch 29/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2191 - accuracy: 0.9156 - val_loss: 0.3673 - val_accuracy: 0.8469\n","Epoch 30/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2101 - accuracy: 0.9250 - val_loss: 0.3791 - val_accuracy: 0.8437\n","Epoch 31/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2142 - accuracy: 0.9113 - val_loss: 0.3746 - val_accuracy: 0.8458\n","Epoch 32/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2094 - accuracy: 0.9215 - val_loss: 0.3774 - val_accuracy: 0.8448\n","Epoch 33/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2071 - accuracy: 0.9164 - val_loss: 0.3839 - val_accuracy: 0.8480\n","Epoch 34/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2067 - accuracy: 0.9212 - val_loss: 0.3836 - val_accuracy: 0.8480\n","Epoch 35/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2049 - accuracy: 0.9186 - val_loss: 0.3964 - val_accuracy: 0.8458\n","Epoch 36/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1992 - accuracy: 0.9242 - val_loss: 0.4038 - val_accuracy: 0.8437\n","Epoch 37/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1980 - accuracy: 0.9207 - val_loss: 0.3872 - val_accuracy: 0.8501\n","Epoch 38/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2002 - accuracy: 0.9194 - val_loss: 0.3887 - val_accuracy: 0.8522\n","Epoch 39/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1929 - accuracy: 0.9258 - val_loss: 0.4292 - val_accuracy: 0.8308\n","Epoch 40/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1940 - accuracy: 0.9229 - val_loss: 0.3920 - val_accuracy: 0.8522\n","Epoch 41/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1953 - accuracy: 0.9223 - val_loss: 0.4220 - val_accuracy: 0.8533\n","Epoch 42/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1847 - accuracy: 0.9330 - val_loss: 0.3895 - val_accuracy: 0.8480\n","Epoch 43/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1769 - accuracy: 0.9330 - val_loss: 0.4045 - val_accuracy: 0.8480\n","Epoch 44/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1730 - accuracy: 0.9370 - val_loss: 0.3977 - val_accuracy: 0.8512\n","Epoch 45/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1725 - accuracy: 0.9320 - val_loss: 0.4380 - val_accuracy: 0.8501\n","Epoch 46/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1722 - accuracy: 0.9379 - val_loss: 0.4048 - val_accuracy: 0.8544\n","Epoch 47/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1648 - accuracy: 0.9360 - val_loss: 0.4050 - val_accuracy: 0.8576\n","Epoch 48/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1654 - accuracy: 0.9368 - val_loss: 0.4114 - val_accuracy: 0.8501\n","Epoch 49/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1633 - accuracy: 0.9387 - val_loss: 0.4193 - val_accuracy: 0.8512\n","Epoch 50/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1602 - accuracy: 0.9405 - val_loss: 0.4166 - val_accuracy: 0.8480\n","Epoch 51/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1554 - accuracy: 0.9443 - val_loss: 0.4158 - val_accuracy: 0.8512\n","Epoch 52/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1547 - accuracy: 0.9435 - val_loss: 0.4183 - val_accuracy: 0.8565\n","Epoch 53/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1502 - accuracy: 0.9464 - val_loss: 0.4352 - val_accuracy: 0.8533\n","Epoch 54/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1433 - accuracy: 0.9537 - val_loss: 0.4269 - val_accuracy: 0.8512\n","Epoch 55/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1505 - accuracy: 0.9411 - val_loss: 0.4306 - val_accuracy: 0.8522\n","Epoch 56/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1415 - accuracy: 0.9494 - val_loss: 0.4278 - val_accuracy: 0.8480\n","Epoch 57/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1400 - accuracy: 0.9486 - val_loss: 0.4503 - val_accuracy: 0.8501\n","Epoch 58/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1422 - accuracy: 0.9499 - val_loss: 0.4309 - val_accuracy: 0.8533\n","Epoch 59/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1364 - accuracy: 0.9526 - val_loss: 0.4394 - val_accuracy: 0.8565\n","Epoch 60/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1335 - accuracy: 0.9542 - val_loss: 0.4591 - val_accuracy: 0.8587\n","Epoch 61/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1322 - accuracy: 0.9537 - val_loss: 0.4423 - val_accuracy: 0.8544\n","Epoch 62/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1392 - accuracy: 0.9486 - val_loss: 0.4478 - val_accuracy: 0.8533\n","Epoch 63/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1253 - accuracy: 0.9595 - val_loss: 0.4428 - val_accuracy: 0.8544\n","Epoch 64/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1229 - accuracy: 0.9587 - val_loss: 0.4497 - val_accuracy: 0.8522\n","Epoch 65/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1144 - accuracy: 0.9628 - val_loss: 0.4746 - val_accuracy: 0.8522\n","Epoch 66/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1190 - accuracy: 0.9579 - val_loss: 0.4738 - val_accuracy: 0.8448\n","Epoch 67/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1173 - accuracy: 0.9609 - val_loss: 0.4678 - val_accuracy: 0.8533\n","Epoch 68/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1077 - accuracy: 0.9649 - val_loss: 0.4760 - val_accuracy: 0.8469\n","Epoch 69/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1147 - accuracy: 0.9585 - val_loss: 0.4772 - val_accuracy: 0.8490\n","Epoch 70/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1151 - accuracy: 0.9593 - val_loss: 0.4679 - val_accuracy: 0.8512\n","Epoch 71/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1094 - accuracy: 0.9636 - val_loss: 0.4688 - val_accuracy: 0.8597\n","Epoch 72/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1039 - accuracy: 0.9660 - val_loss: 0.4708 - val_accuracy: 0.8480\n","Epoch 73/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1147 - accuracy: 0.9561 - val_loss: 0.4848 - val_accuracy: 0.8490\n","Epoch 74/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1002 - accuracy: 0.9671 - val_loss: 0.4732 - val_accuracy: 0.8608\n","Epoch 75/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1015 - accuracy: 0.9671 - val_loss: 0.4932 - val_accuracy: 0.8490\n","Epoch 76/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1054 - accuracy: 0.9668 - val_loss: 0.5046 - val_accuracy: 0.8533\n","Epoch 77/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1061 - accuracy: 0.9636 - val_loss: 0.4900 - val_accuracy: 0.8522\n","Epoch 78/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0904 - accuracy: 0.9716 - val_loss: 0.5022 - val_accuracy: 0.8490\n","Epoch 79/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0939 - accuracy: 0.9681 - val_loss: 0.5150 - val_accuracy: 0.8480\n","Epoch 80/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0901 - accuracy: 0.9711 - val_loss: 0.5170 - val_accuracy: 0.8501\n","Epoch 81/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0959 - accuracy: 0.9673 - val_loss: 0.5426 - val_accuracy: 0.8490\n","Epoch 82/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1018 - accuracy: 0.9644 - val_loss: 0.5088 - val_accuracy: 0.8587\n","Epoch 83/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0864 - accuracy: 0.9705 - val_loss: 0.5064 - val_accuracy: 0.8501\n","Epoch 84/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0862 - accuracy: 0.9735 - val_loss: 0.5154 - val_accuracy: 0.8501\n","Epoch 85/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0815 - accuracy: 0.9746 - val_loss: 0.5263 - val_accuracy: 0.8490\n","Epoch 86/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0836 - accuracy: 0.9735 - val_loss: 0.5152 - val_accuracy: 0.8565\n","Epoch 87/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0760 - accuracy: 0.9764 - val_loss: 0.5279 - val_accuracy: 0.8544\n","Epoch 88/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0909 - accuracy: 0.9673 - val_loss: 0.5361 - val_accuracy: 0.8522\n","Epoch 89/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0786 - accuracy: 0.9751 - val_loss: 0.5474 - val_accuracy: 0.8501\n","Epoch 90/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0773 - accuracy: 0.9764 - val_loss: 0.5291 - val_accuracy: 0.8533\n","Epoch 91/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0737 - accuracy: 0.9786 - val_loss: 0.5361 - val_accuracy: 0.8501\n","Epoch 92/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0700 - accuracy: 0.9799 - val_loss: 0.5388 - val_accuracy: 0.8555\n","Epoch 93/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0635 - accuracy: 0.9839 - val_loss: 0.5430 - val_accuracy: 0.8555\n","Epoch 94/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0756 - accuracy: 0.9737 - val_loss: 0.5847 - val_accuracy: 0.8501\n","Epoch 95/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0813 - accuracy: 0.9697 - val_loss: 0.5488 - val_accuracy: 0.8512\n","Epoch 96/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0640 - accuracy: 0.9810 - val_loss: 0.5519 - val_accuracy: 0.8587\n","Epoch 97/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0605 - accuracy: 0.9815 - val_loss: 0.5500 - val_accuracy: 0.8512\n","Epoch 98/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0632 - accuracy: 0.9807 - val_loss: 0.5962 - val_accuracy: 0.8426\n","Epoch 99/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0741 - accuracy: 0.9754 - val_loss: 0.5587 - val_accuracy: 0.8512\n","Epoch 100/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0640 - accuracy: 0.9812 - val_loss: 0.5746 - val_accuracy: 0.8469\n","{'loss': [0.3277601897716522, 0.31613945960998535, 0.30879390239715576, 0.3058330714702606, 0.30295637249946594, 0.29662826657295227, 0.29389891028404236, 0.29163292050361633, 0.2851741313934326, 0.2814899682998657, 0.27930113673210144, 0.27689996361732483, 0.26625803112983704, 0.2657248079776764, 0.25886091589927673, 0.26124873757362366, 0.2544296979904175, 0.2545982897281647, 0.25507932901382446, 0.24459463357925415, 0.2484196424484253, 0.23888026177883148, 0.23466235399246216, 0.2356874644756317, 0.2293756604194641, 0.23043780028820038, 0.2291765809059143, 0.21970196068286896, 0.21908225119113922, 0.2101423591375351, 0.21418893337249756, 0.20943409204483032, 0.20710434019565582, 0.2067062109708786, 0.204900860786438, 0.19915840029716492, 0.197984978556633, 0.20015548169612885, 0.19291476905345917, 0.19404539465904236, 0.19532331824302673, 0.18469302356243134, 0.17689743638038635, 0.17302528023719788, 0.17252090573310852, 0.1722003072500229, 0.16476032137870789, 0.16540710628032684, 0.16328491270542145, 0.16017407178878784, 0.15543422102928162, 0.1547325849533081, 0.15024730563163757, 0.1433170884847641, 0.15052145719528198, 0.14149048924446106, 0.1400107741355896, 0.1421876847743988, 0.13641707599163055, 0.13347409665584564, 0.13221998512744904, 0.1391826570034027, 0.12525586783885956, 0.12294722348451614, 0.11440248042345047, 0.11898361146450043, 0.11725082248449326, 0.1077447310090065, 0.1147138774394989, 0.11510266363620758, 0.10943058878183365, 0.10388770699501038, 0.11471336334943771, 0.10018522292375565, 0.10154836624860764, 0.10544174164533615, 0.10610044747591019, 0.09038659930229187, 0.09392935782670975, 0.0901249498128891, 0.09589800983667374, 0.10178139805793762, 0.08635646104812622, 0.08619113266468048, 0.08148647844791412, 0.08360148966312408, 0.07604999840259552, 0.09088882058858871, 0.07861067354679108, 0.07728525251150131, 0.07372624427080154, 0.07002470642328262, 0.06353369355201721, 0.0755840390920639, 0.08134973794221878, 0.06395924091339111, 0.060499902814626694, 0.06320880353450775, 0.0740605890750885, 0.06403641402721405], 'accuracy': [0.8615055084228516, 0.8708813190460205, 0.8700776696205139, 0.8714171051979065, 0.8735601305961609, 0.878649890422821, 0.8765068054199219, 0.8789177536964417, 0.8832038640975952, 0.8818644285202026, 0.8901687860488892, 0.891508162021637, 0.892043948173523, 0.8858826756477356, 0.8963300585746765, 0.8955264091491699, 0.8955264091491699, 0.8984730839729309, 0.8979372978210449, 0.9038307070732117, 0.9022234082221985, 0.9022234082221985, 0.9078488945960999, 0.9067773818969727, 0.909456193447113, 0.9067773818969727, 0.9073131680488586, 0.9174926280975342, 0.9156174659729004, 0.9249932765960693, 0.9113313555717468, 0.9215108752250671, 0.916421115398407, 0.9212429523468018, 0.9185641407966614, 0.9241896867752075, 0.9207072257995605, 0.919367790222168, 0.9257969260215759, 0.9228502511978149, 0.922314465045929, 0.9330297112464905, 0.9330297112464905, 0.9370479583740234, 0.9319581985473633, 0.93785160779953, 0.9359764456748962, 0.9367800951004028, 0.9386552572250366, 0.9405304193496704, 0.944280743598938, 0.9434770941734314, 0.9464237689971924, 0.9536565542221069, 0.9410661458969116, 0.9493705034255981, 0.9485668540000916, 0.9499062299728394, 0.9525850415229797, 0.9541923403739929, 0.9536565542221069, 0.9485668540000916, 0.9595499634742737, 0.9587463140487671, 0.9627645611763, 0.9579426646232605, 0.9608893394470215, 0.9649075865745544, 0.9584784507751465, 0.9592821002006531, 0.9635681509971619, 0.9659790992736816, 0.9560675024986267, 0.9670506119728088, 0.9670506119728088, 0.9667827486991882, 0.9635681509971619, 0.971604585647583, 0.968122124671936, 0.9710688591003418, 0.9673185348510742, 0.9643718004226685, 0.9705330729484558, 0.9734797477722168, 0.9745513200759888, 0.9734797477722168, 0.9764264822006226, 0.9673185348510742, 0.97508704662323, 0.9764264822006226, 0.978569507598877, 0.9799089431762695, 0.9839271306991577, 0.9737476706504822, 0.9697294235229492, 0.9809804558753967, 0.9815161824226379, 0.9807125926017761, 0.9753549695014954, 0.9812483191490173], 'val_loss': [0.675568163394928, 0.6703800559043884, 0.6653016209602356, 0.6595732569694519, 0.6532673239707947, 0.6439026594161987, 0.6366590857505798, 0.6264128088951111, 0.6122350692749023, 0.5941534042358398, 0.5800211429595947, 0.5602443814277649, 0.5326194167137146, 0.5151321291923523, 0.48748964071273804, 0.45629748702049255, 0.433174192905426, 0.41167256236076355, 0.38774722814559937, 0.3671533167362213, 0.35568588972091675, 0.34799590706825256, 0.3454054594039917, 0.35448968410491943, 0.3473398685455322, 0.36488860845565796, 0.3605777323246002, 0.3599710166454315, 0.36730286478996277, 0.3790891170501709, 0.37464186549186707, 0.37738701701164246, 0.3839195668697357, 0.3836348354816437, 0.39643386006355286, 0.40383362770080566, 0.3872106671333313, 0.38872841000556946, 0.42916926741600037, 0.391966849565506, 0.42201459407806396, 0.3894789516925812, 0.4044725298881531, 0.3977397382259369, 0.4380464553833008, 0.40480583906173706, 0.404964417219162, 0.41139957308769226, 0.41925564408302307, 0.4165543019771576, 0.41575658321380615, 0.41826432943344116, 0.43515411019325256, 0.42688626050949097, 0.43063050508499146, 0.42776787281036377, 0.450252503156662, 0.43089938163757324, 0.4393789768218994, 0.4590727686882019, 0.4423091411590576, 0.4477813243865967, 0.44284558296203613, 0.44968411326408386, 0.47455894947052, 0.47383418679237366, 0.4677741527557373, 0.47595247626304626, 0.47715649008750916, 0.4678557813167572, 0.4687683880329132, 0.47079068422317505, 0.48479533195495605, 0.4732153117656708, 0.4932083487510681, 0.5046283006668091, 0.49004244804382324, 0.5021549463272095, 0.515007495880127, 0.5170414447784424, 0.5426371097564697, 0.508755624294281, 0.5064454078674316, 0.5153931379318237, 0.5262725949287415, 0.5151988863945007, 0.5278908610343933, 0.5361030697822571, 0.5473513603210449, 0.5291094183921814, 0.536098062992096, 0.5387543439865112, 0.543010950088501, 0.5846931338310242, 0.5488073825836182, 0.5518816113471985, 0.5500031113624573, 0.5961886644363403, 0.55872642993927, 0.5745797753334045], 'val_accuracy': [0.5085653066635132, 0.562098503112793, 0.599571704864502, 0.6691648960113525, 0.7087794542312622, 0.7955031991004944, 0.7826552391052246, 0.7858672142028809, 0.8286938071250916, 0.8468950986862183, 0.8447537422180176, 0.8511777520179749, 0.8372591137886047, 0.8436830639839172, 0.8426124453544617, 0.8468950986862183, 0.8501070737838745, 0.8490363955497742, 0.8479657173156738, 0.8426124453544617, 0.8479657173156738, 0.8479657173156738, 0.8511777520179749, 0.8415417671203613, 0.8490363955497742, 0.8426124453544617, 0.8490363955497742, 0.8490363955497742, 0.8468950986862183, 0.8436830639839172, 0.8458244204521179, 0.8447537422180176, 0.8479657173156738, 0.8479657173156738, 0.8458244204521179, 0.8436830639839172, 0.8501070737838745, 0.8522483706474304, 0.8308351039886475, 0.8522483706474304, 0.8533190488815308, 0.8479657173156738, 0.8479657173156738, 0.8511777520179749, 0.8501070737838745, 0.8543897271156311, 0.8576017022132874, 0.8501070737838745, 0.8511777520179749, 0.8479657173156738, 0.8511777520179749, 0.856531023979187, 0.8533190488815308, 0.8511777520179749, 0.8522483706474304, 0.8479657173156738, 0.8501070737838745, 0.8533190488815308, 0.856531023979187, 0.8586723804473877, 0.8543897271156311, 0.8533190488815308, 0.8543897271156311, 0.8522483706474304, 0.8522483706474304, 0.8447537422180176, 0.8533190488815308, 0.8468950986862183, 0.8490363955497742, 0.8511777520179749, 0.859743058681488, 0.8479657173156738, 0.8490363955497742, 0.8608136773109436, 0.8490363955497742, 0.8533190488815308, 0.8522483706474304, 0.8490363955497742, 0.8479657173156738, 0.8501070737838745, 0.8490363955497742, 0.8586723804473877, 0.8501070737838745, 0.8501070737838745, 0.8490363955497742, 0.856531023979187, 0.8543897271156311, 0.8522483706474304, 0.8501070737838745, 0.8533190488815308, 0.8501070737838745, 0.8554604053497314, 0.8554604053497314, 0.8501070737838745, 0.8511777520179749, 0.8586723804473877, 0.8511777520179749, 0.8426124453544617, 0.8511777520179749, 0.8468950986862183]}\n","37/37 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 9s 48ms/step - loss: 0.1494 - accuracy: 0.9459 - val_loss: 0.6691 - val_accuracy: 0.5107\n","Epoch 2/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1346 - accuracy: 0.9523 - val_loss: 0.6612 - val_accuracy: 0.5375\n","Epoch 3/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1353 - accuracy: 0.9504 - val_loss: 0.6509 - val_accuracy: 0.6103\n","Epoch 4/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1313 - accuracy: 0.9537 - val_loss: 0.6430 - val_accuracy: 0.6627\n","Epoch 5/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1299 - accuracy: 0.9550 - val_loss: 0.6355 - val_accuracy: 0.6745\n","Epoch 6/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1207 - accuracy: 0.9571 - val_loss: 0.6165 - val_accuracy: 0.8084\n","Epoch 7/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1207 - accuracy: 0.9606 - val_loss: 0.6088 - val_accuracy: 0.7602\n","Epoch 8/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1105 - accuracy: 0.9638 - val_loss: 0.5900 - val_accuracy: 0.8191\n","Epoch 9/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1080 - accuracy: 0.9630 - val_loss: 0.5736 - val_accuracy: 0.8244\n","Epoch 10/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1060 - accuracy: 0.9673 - val_loss: 0.5473 - val_accuracy: 0.8522\n","Epoch 11/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1041 - accuracy: 0.9665 - val_loss: 0.5287 - val_accuracy: 0.8394\n","Epoch 12/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1088 - accuracy: 0.9625 - val_loss: 0.4925 - val_accuracy: 0.8672\n","Epoch 13/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1018 - accuracy: 0.9665 - val_loss: 0.4645 - val_accuracy: 0.8694\n","Epoch 14/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1022 - accuracy: 0.9679 - val_loss: 0.4472 - val_accuracy: 0.8576\n","Epoch 15/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0996 - accuracy: 0.9665 - val_loss: 0.4137 - val_accuracy: 0.8640\n","Epoch 16/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0972 - accuracy: 0.9708 - val_loss: 0.3820 - val_accuracy: 0.8662\n","Epoch 17/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.0906 - accuracy: 0.9713 - val_loss: 0.3596 - val_accuracy: 0.8683\n","Epoch 18/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0960 - accuracy: 0.9684 - val_loss: 0.3380 - val_accuracy: 0.8587\n","Epoch 19/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0846 - accuracy: 0.9746 - val_loss: 0.3251 - val_accuracy: 0.8651\n","Epoch 20/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0955 - accuracy: 0.9687 - val_loss: 0.3180 - val_accuracy: 0.8683\n","Epoch 21/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0886 - accuracy: 0.9724 - val_loss: 0.3175 - val_accuracy: 0.8726\n","Epoch 22/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0802 - accuracy: 0.9756 - val_loss: 0.3260 - val_accuracy: 0.8640\n","Epoch 23/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0847 - accuracy: 0.9719 - val_loss: 0.3396 - val_accuracy: 0.8672\n","Epoch 24/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0769 - accuracy: 0.9770 - val_loss: 0.3488 - val_accuracy: 0.8630\n","Epoch 25/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0774 - accuracy: 0.9778 - val_loss: 0.3614 - val_accuracy: 0.8662\n","Epoch 26/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0797 - accuracy: 0.9770 - val_loss: 0.3921 - val_accuracy: 0.8576\n","Epoch 27/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0781 - accuracy: 0.9775 - val_loss: 0.4298 - val_accuracy: 0.8597\n","Epoch 28/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0772 - accuracy: 0.9756 - val_loss: 0.4424 - val_accuracy: 0.8544\n","Epoch 29/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0796 - accuracy: 0.9746 - val_loss: 0.4031 - val_accuracy: 0.8640\n","Epoch 30/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0785 - accuracy: 0.9762 - val_loss: 0.4229 - val_accuracy: 0.8630\n","Epoch 31/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0678 - accuracy: 0.9807 - val_loss: 0.4220 - val_accuracy: 0.8651\n","Epoch 32/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0681 - accuracy: 0.9799 - val_loss: 0.4443 - val_accuracy: 0.8630\n","Epoch 33/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0667 - accuracy: 0.9826 - val_loss: 0.4380 - val_accuracy: 0.8597\n","Epoch 34/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.0629 - accuracy: 0.9802 - val_loss: 0.4507 - val_accuracy: 0.8608\n","Epoch 35/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0628 - accuracy: 0.9826 - val_loss: 0.4647 - val_accuracy: 0.8630\n","Epoch 36/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0695 - accuracy: 0.9802 - val_loss: 0.4678 - val_accuracy: 0.8597\n","Epoch 37/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0606 - accuracy: 0.9845 - val_loss: 0.4705 - val_accuracy: 0.8662\n","Epoch 38/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0588 - accuracy: 0.9839 - val_loss: 0.4589 - val_accuracy: 0.8608\n","Epoch 39/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0587 - accuracy: 0.9839 - val_loss: 0.4700 - val_accuracy: 0.8640\n","Epoch 40/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0546 - accuracy: 0.9877 - val_loss: 0.4724 - val_accuracy: 0.8576\n","Epoch 41/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0574 - accuracy: 0.9839 - val_loss: 0.4815 - val_accuracy: 0.8597\n","Epoch 42/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0611 - accuracy: 0.9834 - val_loss: 0.4867 - val_accuracy: 0.8662\n","Epoch 43/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0584 - accuracy: 0.9821 - val_loss: 0.4838 - val_accuracy: 0.8704\n","Epoch 44/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0494 - accuracy: 0.9879 - val_loss: 0.4935 - val_accuracy: 0.8640\n","Epoch 45/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0526 - accuracy: 0.9866 - val_loss: 0.4978 - val_accuracy: 0.8630\n","Epoch 46/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0482 - accuracy: 0.9879 - val_loss: 0.5039 - val_accuracy: 0.8630\n","Epoch 47/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0589 - accuracy: 0.9834 - val_loss: 0.4922 - val_accuracy: 0.8630\n","Epoch 48/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0531 - accuracy: 0.9839 - val_loss: 0.5102 - val_accuracy: 0.8587\n","Epoch 49/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0592 - accuracy: 0.9812 - val_loss: 0.4884 - val_accuracy: 0.8630\n","Epoch 50/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0534 - accuracy: 0.9853 - val_loss: 0.5489 - val_accuracy: 0.8544\n","Epoch 51/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0516 - accuracy: 0.9842 - val_loss: 0.4934 - val_accuracy: 0.8630\n","Epoch 52/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0457 - accuracy: 0.9877 - val_loss: 0.5121 - val_accuracy: 0.8597\n","Epoch 53/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0468 - accuracy: 0.9874 - val_loss: 0.5432 - val_accuracy: 0.8597\n","Epoch 54/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0434 - accuracy: 0.9885 - val_loss: 0.5051 - val_accuracy: 0.8630\n","Epoch 55/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0503 - accuracy: 0.9837 - val_loss: 0.5172 - val_accuracy: 0.8555\n","Epoch 56/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0421 - accuracy: 0.9879 - val_loss: 0.5124 - val_accuracy: 0.8576\n","Epoch 57/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0475 - accuracy: 0.9877 - val_loss: 0.5144 - val_accuracy: 0.8704\n","Epoch 58/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0436 - accuracy: 0.9877 - val_loss: 0.5383 - val_accuracy: 0.8597\n","Epoch 59/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0481 - accuracy: 0.9839 - val_loss: 0.5250 - val_accuracy: 0.8608\n","Epoch 60/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0402 - accuracy: 0.9904 - val_loss: 0.5308 - val_accuracy: 0.8555\n","Epoch 61/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0381 - accuracy: 0.9893 - val_loss: 0.5270 - val_accuracy: 0.8630\n","Epoch 62/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0347 - accuracy: 0.9906 - val_loss: 0.5368 - val_accuracy: 0.8597\n","Epoch 63/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0359 - accuracy: 0.9901 - val_loss: 0.5420 - val_accuracy: 0.8608\n","Epoch 64/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0400 - accuracy: 0.9879 - val_loss: 0.5506 - val_accuracy: 0.8597\n","Epoch 65/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0360 - accuracy: 0.9896 - val_loss: 0.5462 - val_accuracy: 0.8597\n","Epoch 66/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0363 - accuracy: 0.9898 - val_loss: 0.5469 - val_accuracy: 0.8672\n","Epoch 67/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0401 - accuracy: 0.9882 - val_loss: 0.5477 - val_accuracy: 0.8662\n","Epoch 68/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0335 - accuracy: 0.9914 - val_loss: 0.5450 - val_accuracy: 0.8651\n","Epoch 69/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0323 - accuracy: 0.9906 - val_loss: 0.5864 - val_accuracy: 0.8576\n","Epoch 70/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0361 - accuracy: 0.9898 - val_loss: 0.5679 - val_accuracy: 0.8662\n","Epoch 71/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0269 - accuracy: 0.9938 - val_loss: 0.5767 - val_accuracy: 0.8587\n","Epoch 72/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0298 - accuracy: 0.9922 - val_loss: 0.5984 - val_accuracy: 0.8608\n","Epoch 73/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0308 - accuracy: 0.9930 - val_loss: 0.5833 - val_accuracy: 0.8597\n","Epoch 74/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0271 - accuracy: 0.9938 - val_loss: 0.6084 - val_accuracy: 0.8619\n","Epoch 75/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0275 - accuracy: 0.9925 - val_loss: 0.5760 - val_accuracy: 0.8651\n","Epoch 76/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0341 - accuracy: 0.9893 - val_loss: 0.5872 - val_accuracy: 0.8608\n","Epoch 77/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0285 - accuracy: 0.9922 - val_loss: 0.5943 - val_accuracy: 0.8608\n","Epoch 78/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0300 - accuracy: 0.9901 - val_loss: 0.6350 - val_accuracy: 0.8480\n","Epoch 79/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0276 - accuracy: 0.9922 - val_loss: 0.5859 - val_accuracy: 0.8619\n","Epoch 80/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0265 - accuracy: 0.9933 - val_loss: 0.5953 - val_accuracy: 0.8640\n","Epoch 81/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0248 - accuracy: 0.9925 - val_loss: 0.6554 - val_accuracy: 0.8522\n","Epoch 82/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.6242 - val_accuracy: 0.8608\n","Epoch 83/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0234 - accuracy: 0.9938 - val_loss: 0.6113 - val_accuracy: 0.8662\n","Epoch 84/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0212 - accuracy: 0.9946 - val_loss: 0.6187 - val_accuracy: 0.8587\n","Epoch 85/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0205 - accuracy: 0.9949 - val_loss: 0.6186 - val_accuracy: 0.8651\n","Epoch 86/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0199 - accuracy: 0.9949 - val_loss: 0.6259 - val_accuracy: 0.8630\n","Epoch 87/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0195 - accuracy: 0.9952 - val_loss: 0.6276 - val_accuracy: 0.8619\n","Epoch 88/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0188 - accuracy: 0.9954 - val_loss: 0.6832 - val_accuracy: 0.8555\n","Epoch 89/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 0.6652 - val_accuracy: 0.8587\n","Epoch 90/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0499 - accuracy: 0.9804 - val_loss: 0.6341 - val_accuracy: 0.8651\n","Epoch 91/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0228 - accuracy: 0.9936 - val_loss: 0.6489 - val_accuracy: 0.8608\n","Epoch 92/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0212 - accuracy: 0.9936 - val_loss: 0.6474 - val_accuracy: 0.8597\n","Epoch 93/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0187 - accuracy: 0.9938 - val_loss: 0.6574 - val_accuracy: 0.8565\n","Epoch 94/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0186 - accuracy: 0.9949 - val_loss: 0.6394 - val_accuracy: 0.8640\n","Epoch 95/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0171 - accuracy: 0.9962 - val_loss: 0.6526 - val_accuracy: 0.8630\n","Epoch 96/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0210 - accuracy: 0.9944 - val_loss: 0.7348 - val_accuracy: 0.8480\n","Epoch 97/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0312 - accuracy: 0.9874 - val_loss: 0.7104 - val_accuracy: 0.8565\n","Epoch 98/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0212 - accuracy: 0.9944 - val_loss: 0.6600 - val_accuracy: 0.8619\n","Epoch 99/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0197 - accuracy: 0.9928 - val_loss: 0.6694 - val_accuracy: 0.8608\n","Epoch 100/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.6565 - val_accuracy: 0.8672\n","{'loss': [0.149402916431427, 0.13459178805351257, 0.13531920313835144, 0.13131751120090485, 0.12991879880428314, 0.12069123238325119, 0.12066315859556198, 0.11052976548671722, 0.10798447579145432, 0.10602711886167526, 0.10405440628528595, 0.10877791792154312, 0.10182855278253555, 0.10223453491926193, 0.09955014288425446, 0.09721225500106812, 0.0906316265463829, 0.09595909714698792, 0.08456502109766006, 0.09551474452018738, 0.088561050593853, 0.08015500009059906, 0.08473803848028183, 0.07690440863370895, 0.07738593220710754, 0.07966878265142441, 0.07812337577342987, 0.07718861103057861, 0.07957368344068527, 0.07854047417640686, 0.06776624172925949, 0.06805692613124847, 0.06669211387634277, 0.06287875771522522, 0.06283844262361526, 0.06953800469636917, 0.060617540031671524, 0.05881648510694504, 0.05873292684555054, 0.05456669256091118, 0.05740465596318245, 0.061110831797122955, 0.058434437960386276, 0.04944881424307823, 0.052624981850385666, 0.048166003078222275, 0.05886360630393028, 0.05307492986321449, 0.05923740565776825, 0.053403936326503754, 0.05163439363241196, 0.045707330107688904, 0.046750325709581375, 0.04344979301095009, 0.05031117796897888, 0.042065732181072235, 0.04748532548546791, 0.04355364292860031, 0.048070959746837616, 0.04016180709004402, 0.038144566118717194, 0.03469444438815117, 0.03590749204158783, 0.04001608118414879, 0.03599119558930397, 0.03625573590397835, 0.04013562202453613, 0.033542025834321976, 0.0323496051132679, 0.03606691211462021, 0.026889093220233917, 0.029798325151205063, 0.030785316601395607, 0.02707352116703987, 0.02746495231986046, 0.0341242179274559, 0.028460437431931496, 0.030020592734217644, 0.027592821046710014, 0.026525072753429413, 0.024790363386273384, 0.029181215912103653, 0.023376276716589928, 0.021219398826360703, 0.020509928464889526, 0.019944846630096436, 0.019503150135278702, 0.01877521723508835, 0.02087739109992981, 0.049876004457473755, 0.02283124439418316, 0.021151484921574593, 0.018679717555642128, 0.018644366413354874, 0.01709860935807228, 0.020984191447496414, 0.031211812049150467, 0.021158795803785324, 0.019676245748996735, 0.01595376804471016], 'accuracy': [0.9458880424499512, 0.9523171782493591, 0.9504420161247253, 0.9536565542221069, 0.9549959897994995, 0.9571390151977539, 0.9606214761734009, 0.9638360738754272, 0.9630324244499207, 0.9673185348510742, 0.9665148854255676, 0.9624966382980347, 0.9665148854255676, 0.9678542613983154, 0.9665148854255676, 0.9708009362220764, 0.9713367223739624, 0.9683900475502014, 0.9745513200759888, 0.968657910823822, 0.9724082350730896, 0.975622832775116, 0.9718725085258484, 0.9769622087478638, 0.9777658581733704, 0.9769622087478638, 0.9774979948997498, 0.975622832775116, 0.9745513200759888, 0.9761585593223572, 0.9807125926017761, 0.9799089431762695, 0.9825877547264099, 0.9801768064498901, 0.9825877547264099, 0.9801768064498901, 0.9844629168510437, 0.9839271306991577, 0.9839271306991577, 0.9876774549484253, 0.9839271306991577, 0.9833913445472717, 0.9820519685745239, 0.9879453778266907, 0.9866059422492981, 0.9879453778266907, 0.9833913445472717, 0.9839271306991577, 0.9812483191490173, 0.9852665662765503, 0.9841949939727783, 0.9876774549484253, 0.9874095916748047, 0.9884811043739319, 0.9836592674255371, 0.9879453778266907, 0.9876774549484253, 0.9876774549484253, 0.9839271306991577, 0.9903562664985657, 0.9892847537994385, 0.990624189376831, 0.9900884032249451, 0.9879453778266907, 0.9895526170730591, 0.9898205399513245, 0.9882132411003113, 0.9914277791976929, 0.990624189376831, 0.9898205399513245, 0.9938387274742126, 0.9922314286231995, 0.993035078048706, 0.9938387274742126, 0.9924993515014648, 0.9892847537994385, 0.9922314286231995, 0.9900884032249451, 0.9922314286231995, 0.9933030009269714, 0.9924993515014648, 0.9911599159240723, 0.9938387274742126, 0.9946423768997192, 0.9949102401733398, 0.9949102401733398, 0.9951781630516052, 0.9954460263252258, 0.993570864200592, 0.9804446697235107, 0.993570864200592, 0.993570864200592, 0.9938387274742126, 0.9949102401733398, 0.9962496757507324, 0.9943745136260986, 0.9874095916748047, 0.9943745136260986, 0.9927672147750854, 0.9949102401733398], 'val_loss': [0.6690556406974792, 0.6612298488616943, 0.6509214639663696, 0.6429723501205444, 0.6355434060096741, 0.6164860725402832, 0.608793318271637, 0.5899648666381836, 0.5735812783241272, 0.5472671985626221, 0.528709888458252, 0.4925409257411957, 0.4644584357738495, 0.4472171664237976, 0.41369614005088806, 0.38196679949760437, 0.3596089780330658, 0.337956964969635, 0.32509684562683105, 0.31799134612083435, 0.3175400495529175, 0.32595735788345337, 0.33959341049194336, 0.3488224148750305, 0.36136990785598755, 0.39213162660598755, 0.42984694242477417, 0.44238609075546265, 0.4031215310096741, 0.42292699217796326, 0.4220254123210907, 0.44425517320632935, 0.43803393840789795, 0.45070797204971313, 0.46472370624542236, 0.46784088015556335, 0.4705251157283783, 0.4588635265827179, 0.46996593475341797, 0.47237688302993774, 0.48152586817741394, 0.4867076873779297, 0.48383820056915283, 0.4934725761413574, 0.4977611005306244, 0.5038870573043823, 0.4922062158584595, 0.5101510286331177, 0.48835065960884094, 0.5488951802253723, 0.493388295173645, 0.512096107006073, 0.5431641936302185, 0.5050908327102661, 0.5172188878059387, 0.5124344825744629, 0.5143876075744629, 0.5382975935935974, 0.5250314474105835, 0.5308395028114319, 0.5270252227783203, 0.5368163585662842, 0.5419967174530029, 0.5505828261375427, 0.5461880564689636, 0.5469114780426025, 0.5476970672607422, 0.545036792755127, 0.5863690972328186, 0.5678510069847107, 0.576665997505188, 0.5983814597129822, 0.5833384990692139, 0.6084476709365845, 0.5759766697883606, 0.5872045159339905, 0.5943331718444824, 0.6349692344665527, 0.5859470367431641, 0.5953218936920166, 0.6554099321365356, 0.624197781085968, 0.6112506985664368, 0.6186927556991577, 0.6185517907142639, 0.6258894801139832, 0.6276313066482544, 0.6831914782524109, 0.6652045845985413, 0.6340869665145874, 0.6489260196685791, 0.6474201679229736, 0.6574122905731201, 0.6394256949424744, 0.6526291370391846, 0.734815239906311, 0.7103703022003174, 0.6599832773208618, 0.6694026589393616, 0.6564509868621826], 'val_accuracy': [0.5107066631317139, 0.5374732613563538, 0.6102783679962158, 0.6627408862113953, 0.6745182275772095, 0.8083511590957642, 0.7601712942123413, 0.819057822227478, 0.824411153793335, 0.8522483706474304, 0.8394004106521606, 0.8672376871109009, 0.8693790435791016, 0.8576017022132874, 0.8640257120132446, 0.8661670088768005, 0.8683083653450012, 0.8586723804473877, 0.8650963306427002, 0.8683083653450012, 0.8725910186767578, 0.8640257120132446, 0.8672376871109009, 0.8629550337791443, 0.8661670088768005, 0.8576017022132874, 0.859743058681488, 0.8543897271156311, 0.8640257120132446, 0.8629550337791443, 0.8650963306427002, 0.8629550337791443, 0.859743058681488, 0.8608136773109436, 0.8629550337791443, 0.859743058681488, 0.8661670088768005, 0.8608136773109436, 0.8640257120132446, 0.8576017022132874, 0.859743058681488, 0.8661670088768005, 0.8704496622085571, 0.8640257120132446, 0.8629550337791443, 0.8629550337791443, 0.8629550337791443, 0.8586723804473877, 0.8629550337791443, 0.8543897271156311, 0.8629550337791443, 0.859743058681488, 0.859743058681488, 0.8629550337791443, 0.8554604053497314, 0.8576017022132874, 0.8704496622085571, 0.859743058681488, 0.8608136773109436, 0.8554604053497314, 0.8629550337791443, 0.859743058681488, 0.8608136773109436, 0.859743058681488, 0.859743058681488, 0.8672376871109009, 0.8661670088768005, 0.8650963306427002, 0.8576017022132874, 0.8661670088768005, 0.8586723804473877, 0.8608136773109436, 0.859743058681488, 0.861884355545044, 0.8650963306427002, 0.8608136773109436, 0.8608136773109436, 0.8479657173156738, 0.861884355545044, 0.8640257120132446, 0.8522483706474304, 0.8608136773109436, 0.8661670088768005, 0.8586723804473877, 0.8650963306427002, 0.8629550337791443, 0.861884355545044, 0.8554604053497314, 0.8586723804473877, 0.8650963306427002, 0.8608136773109436, 0.859743058681488, 0.856531023979187, 0.8640257120132446, 0.8629550337791443, 0.8479657173156738, 0.856531023979187, 0.861884355545044, 0.8608136773109436, 0.8672376871109009]}\n","37/37 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 65ms/step - loss: 0.1652 - accuracy: 0.9384 - val_loss: 0.6691 - val_accuracy: 0.4957\n","Epoch 2/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1398 - accuracy: 0.9470 - val_loss: 0.6578 - val_accuracy: 0.5589\n","Epoch 3/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1325 - accuracy: 0.9515 - val_loss: 0.6486 - val_accuracy: 0.6092\n","Epoch 4/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1239 - accuracy: 0.9577 - val_loss: 0.6375 - val_accuracy: 0.7056\n","Epoch 5/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1208 - accuracy: 0.9571 - val_loss: 0.6286 - val_accuracy: 0.7002\n","Epoch 6/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1188 - accuracy: 0.9574 - val_loss: 0.6176 - val_accuracy: 0.7259\n","Epoch 7/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1154 - accuracy: 0.9609 - val_loss: 0.5991 - val_accuracy: 0.8137\n","Epoch 8/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1137 - accuracy: 0.9590 - val_loss: 0.5806 - val_accuracy: 0.8394\n","Epoch 9/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1087 - accuracy: 0.9638 - val_loss: 0.5555 - val_accuracy: 0.8908\n","Epoch 10/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1041 - accuracy: 0.9673 - val_loss: 0.5373 - val_accuracy: 0.8683\n","Epoch 11/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0978 - accuracy: 0.9713 - val_loss: 0.5096 - val_accuracy: 0.8876\n","Epoch 12/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0946 - accuracy: 0.9692 - val_loss: 0.4836 - val_accuracy: 0.8833\n","Epoch 13/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1077 - accuracy: 0.9601 - val_loss: 0.4518 - val_accuracy: 0.8929\n","Epoch 14/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1045 - accuracy: 0.9644 - val_loss: 0.4072 - val_accuracy: 0.9058\n","Epoch 15/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0918 - accuracy: 0.9700 - val_loss: 0.3737 - val_accuracy: 0.8994\n","Epoch 16/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1040 - accuracy: 0.9665 - val_loss: 0.3462 - val_accuracy: 0.9015\n","Epoch 17/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0933 - accuracy: 0.9684 - val_loss: 0.3094 - val_accuracy: 0.8983\n","Epoch 18/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0885 - accuracy: 0.9703 - val_loss: 0.2881 - val_accuracy: 0.9036\n","Epoch 19/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0829 - accuracy: 0.9746 - val_loss: 0.2627 - val_accuracy: 0.8983\n","Epoch 20/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0866 - accuracy: 0.9697 - val_loss: 0.2562 - val_accuracy: 0.8961\n","Epoch 21/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0970 - accuracy: 0.9673 - val_loss: 0.2573 - val_accuracy: 0.8983\n","Epoch 22/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0809 - accuracy: 0.9743 - val_loss: 0.2449 - val_accuracy: 0.9058\n","Epoch 23/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0731 - accuracy: 0.9770 - val_loss: 0.2498 - val_accuracy: 0.9036\n","Epoch 24/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0835 - accuracy: 0.9721 - val_loss: 0.2585 - val_accuracy: 0.9015\n","Epoch 25/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0725 - accuracy: 0.9794 - val_loss: 0.2737 - val_accuracy: 0.8983\n","Epoch 26/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0759 - accuracy: 0.9767 - val_loss: 0.2736 - val_accuracy: 0.8994\n","Epoch 27/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0711 - accuracy: 0.9780 - val_loss: 0.2911 - val_accuracy: 0.8983\n","Epoch 28/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0689 - accuracy: 0.9796 - val_loss: 0.2848 - val_accuracy: 0.9058\n","Epoch 29/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0748 - accuracy: 0.9767 - val_loss: 0.3102 - val_accuracy: 0.8897\n","Epoch 30/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0692 - accuracy: 0.9764 - val_loss: 0.3018 - val_accuracy: 0.8961\n","Epoch 31/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0670 - accuracy: 0.9775 - val_loss: 0.3079 - val_accuracy: 0.8994\n","Epoch 32/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0627 - accuracy: 0.9812 - val_loss: 0.3125 - val_accuracy: 0.9004\n","Epoch 33/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0633 - accuracy: 0.9829 - val_loss: 0.3163 - val_accuracy: 0.9015\n","Epoch 34/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0649 - accuracy: 0.9818 - val_loss: 0.3208 - val_accuracy: 0.8940\n","Epoch 35/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0590 - accuracy: 0.9834 - val_loss: 0.3251 - val_accuracy: 0.9015\n","Epoch 36/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0610 - accuracy: 0.9812 - val_loss: 0.3302 - val_accuracy: 0.8972\n","Epoch 37/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0740 - accuracy: 0.9737 - val_loss: 0.3628 - val_accuracy: 0.8876\n","Epoch 38/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0641 - accuracy: 0.9799 - val_loss: 0.3733 - val_accuracy: 0.8887\n","Epoch 39/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0601 - accuracy: 0.9807 - val_loss: 0.3428 - val_accuracy: 0.8940\n","Epoch 40/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0549 - accuracy: 0.9847 - val_loss: 0.3385 - val_accuracy: 0.8919\n","Epoch 41/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0511 - accuracy: 0.9853 - val_loss: 0.3594 - val_accuracy: 0.8908\n","Epoch 42/100\n","30/30 [==============================] - 1s 16ms/step - loss: 0.0553 - accuracy: 0.9839 - val_loss: 0.3429 - val_accuracy: 0.9015\n","Epoch 43/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0592 - accuracy: 0.9829 - val_loss: 0.3695 - val_accuracy: 0.8897\n","Epoch 44/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0493 - accuracy: 0.9861 - val_loss: 0.3452 - val_accuracy: 0.8961\n","Epoch 45/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0502 - accuracy: 0.9847 - val_loss: 0.3567 - val_accuracy: 0.8994\n","Epoch 46/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0515 - accuracy: 0.9847 - val_loss: 0.3766 - val_accuracy: 0.8940\n","Epoch 47/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0510 - accuracy: 0.9866 - val_loss: 0.3543 - val_accuracy: 0.8961\n","Epoch 48/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0567 - accuracy: 0.9799 - val_loss: 0.3667 - val_accuracy: 0.8940\n","Epoch 49/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0461 - accuracy: 0.9879 - val_loss: 0.3551 - val_accuracy: 0.8961\n","Epoch 50/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0438 - accuracy: 0.9879 - val_loss: 0.3655 - val_accuracy: 0.8908\n","Epoch 51/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0382 - accuracy: 0.9901 - val_loss: 0.3640 - val_accuracy: 0.8951\n","Epoch 52/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0413 - accuracy: 0.9874 - val_loss: 0.3689 - val_accuracy: 0.8951\n","Epoch 53/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0452 - accuracy: 0.9871 - val_loss: 0.3673 - val_accuracy: 0.8972\n","Epoch 54/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0375 - accuracy: 0.9912 - val_loss: 0.3852 - val_accuracy: 0.8908\n","Epoch 55/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0391 - accuracy: 0.9885 - val_loss: 0.3861 - val_accuracy: 0.8897\n","Epoch 56/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0436 - accuracy: 0.9866 - val_loss: 0.3886 - val_accuracy: 0.8908\n","Epoch 57/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0413 - accuracy: 0.9896 - val_loss: 0.3882 - val_accuracy: 0.8929\n","Epoch 58/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0349 - accuracy: 0.9912 - val_loss: 0.4022 - val_accuracy: 0.8887\n","Epoch 59/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0374 - accuracy: 0.9890 - val_loss: 0.3892 - val_accuracy: 0.8919\n","Epoch 60/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0435 - accuracy: 0.9863 - val_loss: 0.4270 - val_accuracy: 0.8876\n","Epoch 61/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0348 - accuracy: 0.9906 - val_loss: 0.3942 - val_accuracy: 0.8940\n","Epoch 62/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0318 - accuracy: 0.9925 - val_loss: 0.3937 - val_accuracy: 0.8940\n","Epoch 63/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0346 - accuracy: 0.9906 - val_loss: 0.4393 - val_accuracy: 0.8887\n","Epoch 64/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0412 - accuracy: 0.9861 - val_loss: 0.4215 - val_accuracy: 0.8951\n","Epoch 65/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0359 - accuracy: 0.9901 - val_loss: 0.5065 - val_accuracy: 0.8758\n","Epoch 66/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0452 - accuracy: 0.9834 - val_loss: 0.4121 - val_accuracy: 0.8919\n","Epoch 67/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0329 - accuracy: 0.9906 - val_loss: 0.4081 - val_accuracy: 0.8919\n","Epoch 68/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0372 - accuracy: 0.9890 - val_loss: 0.4013 - val_accuracy: 0.8919\n","Epoch 69/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0363 - accuracy: 0.9898 - val_loss: 0.4061 - val_accuracy: 0.8919\n","Epoch 70/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0294 - accuracy: 0.9914 - val_loss: 0.4184 - val_accuracy: 0.8908\n","Epoch 71/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0346 - accuracy: 0.9893 - val_loss: 0.4551 - val_accuracy: 0.8854\n","Epoch 72/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0284 - accuracy: 0.9925 - val_loss: 0.4299 - val_accuracy: 0.8929\n","Epoch 73/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0267 - accuracy: 0.9936 - val_loss: 0.4309 - val_accuracy: 0.8876\n","Epoch 74/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0268 - accuracy: 0.9949 - val_loss: 0.4409 - val_accuracy: 0.8897\n","Epoch 75/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0268 - accuracy: 0.9920 - val_loss: 0.4256 - val_accuracy: 0.8940\n","Epoch 76/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.9949 - val_loss: 0.4306 - val_accuracy: 0.8897\n","Epoch 77/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0211 - accuracy: 0.9949 - val_loss: 0.4781 - val_accuracy: 0.8844\n","Epoch 78/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0258 - accuracy: 0.9920 - val_loss: 0.4358 - val_accuracy: 0.8908\n","Epoch 79/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0227 - accuracy: 0.9938 - val_loss: 0.4426 - val_accuracy: 0.8929\n","Epoch 80/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0225 - accuracy: 0.9917 - val_loss: 0.4494 - val_accuracy: 0.8908\n","Epoch 81/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0309 - accuracy: 0.9896 - val_loss: 0.4388 - val_accuracy: 0.8951\n","Epoch 82/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0258 - accuracy: 0.9917 - val_loss: 0.4812 - val_accuracy: 0.8897\n","Epoch 83/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0235 - accuracy: 0.9938 - val_loss: 0.4502 - val_accuracy: 0.8929\n","Epoch 84/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.4611 - val_accuracy: 0.8897\n","Epoch 85/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0254 - accuracy: 0.9906 - val_loss: 0.4887 - val_accuracy: 0.8865\n","Epoch 86/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0371 - accuracy: 0.9869 - val_loss: 0.4556 - val_accuracy: 0.8908\n","Epoch 87/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0251 - accuracy: 0.9928 - val_loss: 0.4486 - val_accuracy: 0.8897\n","Epoch 88/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0275 - accuracy: 0.9904 - val_loss: 0.5074 - val_accuracy: 0.8865\n","Epoch 89/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0605 - accuracy: 0.9770 - val_loss: 0.4702 - val_accuracy: 0.8833\n","Epoch 90/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0213 - accuracy: 0.9941 - val_loss: 0.4653 - val_accuracy: 0.8887\n","Epoch 91/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0196 - accuracy: 0.9938 - val_loss: 0.4540 - val_accuracy: 0.8844\n","Epoch 92/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0203 - accuracy: 0.9952 - val_loss: 0.4526 - val_accuracy: 0.8951\n","Epoch 93/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0190 - accuracy: 0.9957 - val_loss: 0.4602 - val_accuracy: 0.8951\n","Epoch 94/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0167 - accuracy: 0.9968 - val_loss: 0.4650 - val_accuracy: 0.8929\n","Epoch 95/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: 0.4597 - val_accuracy: 0.8908\n","Epoch 96/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0165 - accuracy: 0.9965 - val_loss: 0.4672 - val_accuracy: 0.8929\n","Epoch 97/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0163 - accuracy: 0.9968 - val_loss: 0.4807 - val_accuracy: 0.8919\n","Epoch 98/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0149 - accuracy: 0.9971 - val_loss: 0.4817 - val_accuracy: 0.8919\n","Epoch 99/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0170 - accuracy: 0.9960 - val_loss: 0.5073 - val_accuracy: 0.8908\n","Epoch 100/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0154 - accuracy: 0.9962 - val_loss: 0.4799 - val_accuracy: 0.8908\n","{'loss': [0.16521568596363068, 0.1398209184408188, 0.13248860836029053, 0.12387628853321075, 0.12082307785749435, 0.11879148334264755, 0.11540507525205612, 0.11372581124305725, 0.10868540406227112, 0.10413108766078949, 0.09776388108730316, 0.09463968127965927, 0.10770469903945923, 0.10452982038259506, 0.0917544960975647, 0.10400228947401047, 0.09331704676151276, 0.08848553150892258, 0.08288240432739258, 0.08657166361808777, 0.09698829799890518, 0.08094050735235214, 0.0731179341673851, 0.08351438492536545, 0.07245133817195892, 0.0759359821677208, 0.07110266387462616, 0.06885074824094772, 0.0748344212770462, 0.06920315325260162, 0.06701964884996414, 0.06267766654491425, 0.06333959847688675, 0.06493151932954788, 0.05896556004881859, 0.06104247644543648, 0.07397239655256271, 0.06406359374523163, 0.06010279059410095, 0.05491107702255249, 0.051052581518888474, 0.05527900531888008, 0.059153273701667786, 0.049251627177000046, 0.05022222548723221, 0.05151430889964104, 0.05099564790725708, 0.056657738983631134, 0.0461091622710228, 0.043790217489004135, 0.03824415057897568, 0.04129129275679588, 0.04521908983588219, 0.03747626021504402, 0.03909334912896156, 0.04358796030282974, 0.04131755232810974, 0.0349380187690258, 0.03740148991346359, 0.04348547011613846, 0.034767888486385345, 0.03178451210260391, 0.03460060432553291, 0.0411895290017128, 0.03591898828744888, 0.04517136886715889, 0.03289727494120598, 0.037189140915870667, 0.036257997155189514, 0.029436858370900154, 0.03459743782877922, 0.028386220335960388, 0.026663566008210182, 0.02679310366511345, 0.026824740692973137, 0.024060796946287155, 0.021059468388557434, 0.025824036449193954, 0.02267150953412056, 0.022547641769051552, 0.03094617649912834, 0.025800343602895737, 0.023506218567490578, 0.019324960187077522, 0.02535834163427353, 0.03706985339522362, 0.025097081437706947, 0.027484292164444923, 0.06051066890358925, 0.02134060673415661, 0.019565071910619736, 0.02033347822725773, 0.019045844674110413, 0.01670335792005062, 0.0173275675624609, 0.016508057713508606, 0.016254674643278122, 0.014877931214869022, 0.017037993296980858, 0.015379933640360832], 'accuracy': [0.9383873343467712, 0.9469595551490784, 0.9515135288238525, 0.9576748013496399, 0.9571390151977539, 0.9574069380760193, 0.9608893394470215, 0.9590141773223877, 0.9638360738754272, 0.9673185348510742, 0.9713367223739624, 0.969193696975708, 0.9600857496261597, 0.9643718004226685, 0.9699973464012146, 0.9665148854255676, 0.9683900475502014, 0.9702652096748352, 0.9745513200759888, 0.9697294235229492, 0.9673185348510742, 0.9742833971977234, 0.9769622087478638, 0.972140371799469, 0.9793731570243835, 0.9766943454742432, 0.9780337810516357, 0.9796410202980042, 0.9766943454742432, 0.9764264822006226, 0.9774979948997498, 0.9812483191490173, 0.9828556180000305, 0.9817841053009033, 0.9833913445472717, 0.9812483191490173, 0.9737476706504822, 0.9799089431762695, 0.9807125926017761, 0.9847307801246643, 0.9852665662765503, 0.9839271306991577, 0.9828556180000305, 0.9860701560974121, 0.9847307801246643, 0.9847307801246643, 0.9866059422492981, 0.9799089431762695, 0.9879453778266907, 0.9879453778266907, 0.9900884032249451, 0.9874095916748047, 0.9871417284011841, 0.9911599159240723, 0.9884811043739319, 0.9866059422492981, 0.9895526170730591, 0.9911599159240723, 0.9890168905258179, 0.9863380789756775, 0.990624189376831, 0.9924993515014648, 0.990624189376831, 0.9860701560974121, 0.9900884032249451, 0.9833913445472717, 0.990624189376831, 0.9890168905258179, 0.9898205399513245, 0.9914277791976929, 0.9892847537994385, 0.9924993515014648, 0.993570864200592, 0.9949102401733398, 0.9919635653495789, 0.9949102401733398, 0.9949102401733398, 0.9919635653495789, 0.9938387274742126, 0.9916957020759583, 0.9895526170730591, 0.9916957020759583, 0.9938387274742126, 0.993570864200592, 0.990624189376831, 0.9868738055229187, 0.9927672147750854, 0.9903562664985657, 0.9769622087478638, 0.9941065907478333, 0.9938387274742126, 0.9951781630516052, 0.9957138895988464, 0.9967854022979736, 0.9941065907478333, 0.996517539024353, 0.9967854022979736, 0.997053325176239, 0.9959818124771118, 0.9962496757507324], 'val_loss': [0.6690893173217773, 0.657758355140686, 0.6485660672187805, 0.6375351548194885, 0.6286172270774841, 0.6175997853279114, 0.5991313457489014, 0.5806152820587158, 0.5555380582809448, 0.5372718572616577, 0.509587824344635, 0.4835536777973175, 0.45177772641181946, 0.40719494223594666, 0.3736540377140045, 0.3462021052837372, 0.30936846137046814, 0.2881147861480713, 0.2627488374710083, 0.2562369108200073, 0.2573480010032654, 0.2449461817741394, 0.24975216388702393, 0.2584533989429474, 0.27370956540107727, 0.2736372947692871, 0.29109176993370056, 0.2848392724990845, 0.3101712465286255, 0.301778644323349, 0.30792367458343506, 0.31251654028892517, 0.3162960112094879, 0.32084906101226807, 0.32509326934814453, 0.33023592829704285, 0.3627657890319824, 0.37330183386802673, 0.3427785336971283, 0.3384609520435333, 0.3593876361846924, 0.34292879700660706, 0.36949414014816284, 0.3452412486076355, 0.3567013442516327, 0.3765532076358795, 0.3543449938297272, 0.3667202293872833, 0.35513725876808167, 0.3654577136039734, 0.3640483021736145, 0.36890295147895813, 0.36731573939323425, 0.38517749309539795, 0.3861057758331299, 0.3885602653026581, 0.38820722699165344, 0.4021751880645752, 0.3891734182834625, 0.42698273062705994, 0.3941999673843384, 0.3937147259712219, 0.43925637006759644, 0.42151346802711487, 0.5064730644226074, 0.4121491014957428, 0.40813910961151123, 0.40128183364868164, 0.40607842803001404, 0.4184037446975708, 0.45507946610450745, 0.42989152669906616, 0.430931955575943, 0.44087275862693787, 0.4256168007850647, 0.430611789226532, 0.4781339168548584, 0.43583032488822937, 0.442582905292511, 0.44936415553092957, 0.4388428032398224, 0.481244295835495, 0.4501747488975525, 0.46112293004989624, 0.4887242019176483, 0.45556336641311646, 0.4486313760280609, 0.5073898434638977, 0.4701789319515228, 0.4653328061103821, 0.4539547264575958, 0.4525582790374756, 0.4602236747741699, 0.464993953704834, 0.4597206115722656, 0.4671556353569031, 0.48066791892051697, 0.48168087005615234, 0.507264256477356, 0.4799000322818756], 'val_accuracy': [0.4957173466682434, 0.5588865280151367, 0.6092076897621155, 0.705567479133606, 0.700214147567749, 0.7259100675582886, 0.8137044906616211, 0.8394004106521606, 0.8907923102378845, 0.8683083653450012, 0.8875802755355835, 0.8832976222038269, 0.8929336071014404, 0.9057815670967102, 0.8993576169013977, 0.9014989137649536, 0.8982869386672974, 0.9036402702331543, 0.8982869386672974, 0.8961455821990967, 0.8982869386672974, 0.9057815670967102, 0.9036402702331543, 0.9014989137649536, 0.8982869386672974, 0.8993576169013977, 0.8982869386672974, 0.9057815670967102, 0.8897216320037842, 0.8961455821990967, 0.8993576169013977, 0.900428295135498, 0.9014989137649536, 0.8940042853355408, 0.9014989137649536, 0.897216260433197, 0.8875802755355835, 0.8886509537696838, 0.8940042853355408, 0.8918629288673401, 0.8907923102378845, 0.9014989137649536, 0.8897216320037842, 0.8961455821990967, 0.8993576169013977, 0.8940042853355408, 0.8961455821990967, 0.8940042853355408, 0.8961455821990967, 0.8907923102378845, 0.8950749635696411, 0.8950749635696411, 0.897216260433197, 0.8907923102378845, 0.8897216320037842, 0.8907923102378845, 0.8929336071014404, 0.8886509537696838, 0.8918629288673401, 0.8875802755355835, 0.8940042853355408, 0.8940042853355408, 0.8886509537696838, 0.8950749635696411, 0.8758029937744141, 0.8918629288673401, 0.8918629288673401, 0.8918629288673401, 0.8918629288673401, 0.8907923102378845, 0.8854389786720276, 0.8929336071014404, 0.8875802755355835, 0.8897216320037842, 0.8940042853355408, 0.8897216320037842, 0.8843683004379272, 0.8907923102378845, 0.8929336071014404, 0.8907923102378845, 0.8950749635696411, 0.8897216320037842, 0.8929336071014404, 0.8897216320037842, 0.8865096569061279, 0.8907923102378845, 0.8897216320037842, 0.8865096569061279, 0.8832976222038269, 0.8886509537696838, 0.8843683004379272, 0.8950749635696411, 0.8950749635696411, 0.8929336071014404, 0.8907923102378845, 0.8929336071014404, 0.8918629288673401, 0.8918629288673401, 0.8907923102378845, 0.8907923102378845]}\n","37/37 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 7s 46ms/step - loss: 0.1478 - accuracy: 0.9459 - val_loss: 0.6623 - val_accuracy: 0.5278\n","Epoch 2/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1359 - accuracy: 0.9491 - val_loss: 0.6553 - val_accuracy: 0.5803\n","Epoch 3/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1335 - accuracy: 0.9512 - val_loss: 0.6465 - val_accuracy: 0.6306\n","Epoch 4/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1222 - accuracy: 0.9537 - val_loss: 0.6405 - val_accuracy: 0.6231\n","Epoch 5/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1214 - accuracy: 0.9531 - val_loss: 0.6293 - val_accuracy: 0.6938\n","Epoch 6/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1156 - accuracy: 0.9582 - val_loss: 0.6151 - val_accuracy: 0.7420\n","Epoch 7/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1093 - accuracy: 0.9660 - val_loss: 0.6028 - val_accuracy: 0.7612\n","Epoch 8/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1100 - accuracy: 0.9636 - val_loss: 0.5797 - val_accuracy: 0.8351\n","Epoch 9/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1094 - accuracy: 0.9617 - val_loss: 0.5611 - val_accuracy: 0.8490\n","Epoch 10/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0978 - accuracy: 0.9681 - val_loss: 0.5357 - val_accuracy: 0.8726\n","Epoch 11/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0968 - accuracy: 0.9660 - val_loss: 0.5081 - val_accuracy: 0.8790\n","Epoch 12/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1012 - accuracy: 0.9676 - val_loss: 0.4767 - val_accuracy: 0.8865\n","Epoch 13/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0935 - accuracy: 0.9697 - val_loss: 0.4422 - val_accuracy: 0.8961\n","Epoch 14/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0913 - accuracy: 0.9689 - val_loss: 0.4178 - val_accuracy: 0.8801\n","Epoch 15/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0913 - accuracy: 0.9681 - val_loss: 0.3756 - val_accuracy: 0.8972\n","Epoch 16/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0897 - accuracy: 0.9692 - val_loss: 0.3615 - val_accuracy: 0.8779\n","Epoch 17/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0879 - accuracy: 0.9708 - val_loss: 0.3209 - val_accuracy: 0.8961\n","Epoch 18/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0846 - accuracy: 0.9711 - val_loss: 0.2985 - val_accuracy: 0.8972\n","Epoch 19/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0815 - accuracy: 0.9740 - val_loss: 0.2848 - val_accuracy: 0.8961\n","Epoch 20/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0785 - accuracy: 0.9762 - val_loss: 0.2782 - val_accuracy: 0.8951\n","Epoch 21/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0787 - accuracy: 0.9754 - val_loss: 0.2747 - val_accuracy: 0.8929\n","Epoch 22/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0768 - accuracy: 0.9762 - val_loss: 0.2828 - val_accuracy: 0.8961\n","Epoch 23/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0764 - accuracy: 0.9729 - val_loss: 0.3008 - val_accuracy: 0.8908\n","Epoch 24/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0784 - accuracy: 0.9746 - val_loss: 0.3045 - val_accuracy: 0.8961\n","Epoch 25/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0761 - accuracy: 0.9756 - val_loss: 0.3168 - val_accuracy: 0.8929\n","Epoch 26/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0709 - accuracy: 0.9815 - val_loss: 0.3365 - val_accuracy: 0.8919\n","Epoch 27/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0716 - accuracy: 0.9759 - val_loss: 0.3496 - val_accuracy: 0.8919\n","Epoch 28/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0779 - accuracy: 0.9729 - val_loss: 0.3479 - val_accuracy: 0.8887\n","Epoch 29/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0641 - accuracy: 0.9818 - val_loss: 0.3623 - val_accuracy: 0.8929\n","Epoch 30/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0604 - accuracy: 0.9821 - val_loss: 0.3605 - val_accuracy: 0.8919\n","Epoch 31/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0593 - accuracy: 0.9829 - val_loss: 0.3771 - val_accuracy: 0.8897\n","Epoch 32/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0601 - accuracy: 0.9818 - val_loss: 0.3999 - val_accuracy: 0.8865\n","Epoch 33/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0657 - accuracy: 0.9791 - val_loss: 0.3786 - val_accuracy: 0.8929\n","Epoch 34/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0644 - accuracy: 0.9783 - val_loss: 0.3882 - val_accuracy: 0.8940\n","Epoch 35/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0563 - accuracy: 0.9853 - val_loss: 0.3854 - val_accuracy: 0.8897\n","Epoch 36/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0549 - accuracy: 0.9863 - val_loss: 0.4026 - val_accuracy: 0.8833\n","Epoch 37/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0552 - accuracy: 0.9837 - val_loss: 0.4033 - val_accuracy: 0.8844\n","Epoch 38/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0530 - accuracy: 0.9863 - val_loss: 0.4011 - val_accuracy: 0.8951\n","Epoch 39/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0781 - accuracy: 0.9743 - val_loss: 0.4117 - val_accuracy: 0.8812\n","Epoch 40/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0536 - accuracy: 0.9853 - val_loss: 0.4130 - val_accuracy: 0.8887\n","Epoch 41/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0515 - accuracy: 0.9845 - val_loss: 0.4071 - val_accuracy: 0.8929\n","Epoch 42/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0502 - accuracy: 0.9874 - val_loss: 0.4181 - val_accuracy: 0.8876\n","Epoch 43/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0491 - accuracy: 0.9855 - val_loss: 0.4179 - val_accuracy: 0.8908\n","Epoch 44/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0495 - accuracy: 0.9847 - val_loss: 0.4201 - val_accuracy: 0.8887\n","Epoch 45/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0489 - accuracy: 0.9837 - val_loss: 0.4267 - val_accuracy: 0.8887\n","Epoch 46/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0444 - accuracy: 0.9871 - val_loss: 0.4365 - val_accuracy: 0.8822\n","Epoch 47/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0474 - accuracy: 0.9874 - val_loss: 0.4358 - val_accuracy: 0.8897\n","Epoch 48/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0428 - accuracy: 0.9887 - val_loss: 0.4340 - val_accuracy: 0.8865\n","Epoch 49/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0489 - accuracy: 0.9853 - val_loss: 0.4354 - val_accuracy: 0.8833\n","Epoch 50/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0437 - accuracy: 0.9874 - val_loss: 0.4353 - val_accuracy: 0.8865\n","Epoch 51/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0390 - accuracy: 0.9906 - val_loss: 0.4564 - val_accuracy: 0.8854\n","Epoch 52/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0409 - accuracy: 0.9882 - val_loss: 0.4449 - val_accuracy: 0.8844\n","Epoch 53/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0430 - accuracy: 0.9874 - val_loss: 0.4599 - val_accuracy: 0.8812\n","Epoch 54/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0367 - accuracy: 0.9893 - val_loss: 0.4510 - val_accuracy: 0.8887\n","Epoch 55/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0363 - accuracy: 0.9920 - val_loss: 0.4567 - val_accuracy: 0.8887\n","Epoch 56/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0365 - accuracy: 0.9914 - val_loss: 0.4608 - val_accuracy: 0.8822\n","Epoch 57/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0369 - accuracy: 0.9904 - val_loss: 0.4576 - val_accuracy: 0.8887\n","Epoch 58/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0356 - accuracy: 0.9893 - val_loss: 0.4707 - val_accuracy: 0.8876\n","Epoch 59/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0413 - accuracy: 0.9866 - val_loss: 0.4599 - val_accuracy: 0.8876\n","Epoch 60/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0393 - accuracy: 0.9877 - val_loss: 0.4642 - val_accuracy: 0.8887\n","Epoch 61/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0363 - accuracy: 0.9893 - val_loss: 0.5930 - val_accuracy: 0.8490\n","Epoch 62/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0506 - accuracy: 0.9839 - val_loss: 0.4816 - val_accuracy: 0.8876\n","Epoch 63/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0319 - accuracy: 0.9933 - val_loss: 0.4715 - val_accuracy: 0.8854\n","Epoch 64/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0327 - accuracy: 0.9904 - val_loss: 0.4736 - val_accuracy: 0.8929\n","Epoch 65/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0300 - accuracy: 0.9928 - val_loss: 0.5120 - val_accuracy: 0.8747\n","Epoch 66/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0331 - accuracy: 0.9901 - val_loss: 0.4928 - val_accuracy: 0.8876\n","Epoch 67/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0276 - accuracy: 0.9941 - val_loss: 0.5017 - val_accuracy: 0.8887\n","Epoch 68/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0302 - accuracy: 0.9917 - val_loss: 0.4816 - val_accuracy: 0.8908\n","Epoch 69/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0311 - accuracy: 0.9917 - val_loss: 0.5053 - val_accuracy: 0.8919\n","Epoch 70/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0327 - accuracy: 0.9912 - val_loss: 0.4910 - val_accuracy: 0.8854\n","Epoch 71/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0266 - accuracy: 0.9933 - val_loss: 0.4960 - val_accuracy: 0.8865\n","Epoch 72/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0306 - accuracy: 0.9914 - val_loss: 0.5160 - val_accuracy: 0.8854\n","Epoch 73/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0246 - accuracy: 0.9952 - val_loss: 0.5204 - val_accuracy: 0.8812\n","Epoch 74/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0263 - accuracy: 0.9941 - val_loss: 0.5195 - val_accuracy: 0.8790\n","Epoch 75/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0236 - accuracy: 0.9944 - val_loss: 0.5105 - val_accuracy: 0.8854\n","Epoch 76/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0263 - accuracy: 0.9930 - val_loss: 0.5046 - val_accuracy: 0.8833\n","Epoch 77/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 0.5176 - val_accuracy: 0.8887\n","Epoch 78/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0226 - accuracy: 0.9946 - val_loss: 0.5150 - val_accuracy: 0.8865\n","Epoch 79/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0200 - accuracy: 0.9952 - val_loss: 0.5163 - val_accuracy: 0.8929\n","Epoch 80/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.5178 - val_accuracy: 0.8876\n","Epoch 81/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 0.5473 - val_accuracy: 0.8876\n","Epoch 82/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.5212 - val_accuracy: 0.8919\n","Epoch 83/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0666 - accuracy: 0.9713 - val_loss: 0.5559 - val_accuracy: 0.8715\n","Epoch 84/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0338 - accuracy: 0.9896 - val_loss: 0.5128 - val_accuracy: 0.8854\n","Epoch 85/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0251 - accuracy: 0.9922 - val_loss: 0.5131 - val_accuracy: 0.8769\n","Epoch 86/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0388 - accuracy: 0.9858 - val_loss: 0.5086 - val_accuracy: 0.8897\n","Epoch 87/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.5097 - val_accuracy: 0.8897\n","Epoch 88/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0230 - accuracy: 0.9944 - val_loss: 0.5138 - val_accuracy: 0.8897\n","Epoch 89/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0182 - accuracy: 0.9954 - val_loss: 0.5250 - val_accuracy: 0.8865\n","Epoch 90/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0163 - accuracy: 0.9962 - val_loss: 0.5280 - val_accuracy: 0.8865\n","Epoch 91/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 0.5297 - val_accuracy: 0.8887\n","Epoch 92/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0194 - accuracy: 0.9952 - val_loss: 0.5286 - val_accuracy: 0.8919\n","Epoch 93/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0146 - accuracy: 0.9965 - val_loss: 0.5466 - val_accuracy: 0.8758\n","Epoch 94/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0155 - accuracy: 0.9962 - val_loss: 0.5680 - val_accuracy: 0.8747\n","Epoch 95/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0167 - accuracy: 0.9962 - val_loss: 0.5560 - val_accuracy: 0.8747\n","Epoch 96/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0190 - accuracy: 0.9946 - val_loss: 0.5360 - val_accuracy: 0.8897\n","Epoch 97/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0157 - accuracy: 0.9962 - val_loss: 0.5404 - val_accuracy: 0.8833\n","Epoch 98/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0178 - accuracy: 0.9952 - val_loss: 0.5591 - val_accuracy: 0.8833\n","Epoch 99/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.5634 - val_accuracy: 0.8876\n","Epoch 100/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.5632 - val_accuracy: 0.8812\n","{'loss': [0.14779284596443176, 0.1359415352344513, 0.1335214376449585, 0.12216676026582718, 0.1213807761669159, 0.1156006008386612, 0.10925602167844772, 0.11004176735877991, 0.10943049937486649, 0.09775518625974655, 0.09684889763593674, 0.10115230828523636, 0.09350250661373138, 0.09131492674350739, 0.09132584184408188, 0.08971680700778961, 0.08793997764587402, 0.0845574215054512, 0.08151296526193619, 0.07849878817796707, 0.07868257164955139, 0.0768231600522995, 0.07640250027179718, 0.07844726741313934, 0.07610306888818741, 0.07093369215726852, 0.07159551233053207, 0.07792338728904724, 0.06408268958330154, 0.06041164696216583, 0.05929775536060333, 0.060083817690610886, 0.06574844568967819, 0.0643724873661995, 0.056282997131347656, 0.05487566441297531, 0.055155906826257706, 0.052996959537267685, 0.07805460691452026, 0.053575895726680756, 0.0514959990978241, 0.050168368965387344, 0.049051497131586075, 0.04945506900548935, 0.04889168590307236, 0.044354286044836044, 0.047382790595293045, 0.04280102998018265, 0.04888911172747612, 0.04365912824869156, 0.039035677909851074, 0.040879786014556885, 0.042989425361156464, 0.03668997809290886, 0.036279674619436264, 0.03645822033286095, 0.036873068660497665, 0.03562614694237709, 0.041334208101034164, 0.03925089165568352, 0.03627697005867958, 0.050556641072034836, 0.03187272325158119, 0.032739099115133286, 0.02999977394938469, 0.0330684520304203, 0.027556154876947403, 0.030226880684494972, 0.031100789085030556, 0.03269978612661362, 0.026560336351394653, 0.030570093542337418, 0.024626780301332474, 0.02631523460149765, 0.023580385372042656, 0.026318179443478584, 0.024518756195902824, 0.02258984185755253, 0.01997457817196846, 0.02387276105582714, 0.023909516632556915, 0.0317736491560936, 0.06655247509479523, 0.0337836891412735, 0.025099359452724457, 0.038820598274469376, 0.02394810877740383, 0.02298203483223915, 0.018192168325185776, 0.01626213826239109, 0.0158989354968071, 0.01936902292072773, 0.014613536186516285, 0.015539153479039669, 0.016735978424549103, 0.019045663997530937, 0.015684662386775017, 0.01775383949279785, 0.015220538713037968, 0.016816910356283188], 'accuracy': [0.9458880424499512, 0.9491025805473328, 0.9512456655502319, 0.9536565542221069, 0.9531208276748657, 0.9582105278968811, 0.9659790992736816, 0.9635681509971619, 0.9616929888725281, 0.968122124671936, 0.9659790992736816, 0.9675863981246948, 0.9697294235229492, 0.9689257740974426, 0.968122124671936, 0.969193696975708, 0.9708009362220764, 0.9710688591003418, 0.9740155339241028, 0.9761585593223572, 0.9753549695014954, 0.9761585593223572, 0.9729440212249756, 0.9745513200759888, 0.975622832775116, 0.9815161824226379, 0.9758906960487366, 0.9729440212249756, 0.9817841053009033, 0.9820519685745239, 0.9828556180000305, 0.9817841053009033, 0.9791052937507629, 0.9783016443252563, 0.9852665662765503, 0.9863380789756775, 0.9836592674255371, 0.9863380789756775, 0.9742833971977234, 0.9852665662765503, 0.9844629168510437, 0.9874095916748047, 0.9855344295501709, 0.9847307801246643, 0.9836592674255371, 0.9871417284011841, 0.9874095916748047, 0.9887489676475525, 0.9852665662765503, 0.9874095916748047, 0.990624189376831, 0.9882132411003113, 0.9874095916748047, 0.9892847537994385, 0.9919635653495789, 0.9914277791976929, 0.9903562664985657, 0.9892847537994385, 0.9866059422492981, 0.9876774549484253, 0.9892847537994385, 0.9839271306991577, 0.9933030009269714, 0.9903562664985657, 0.9927672147750854, 0.9900884032249451, 0.9941065907478333, 0.9916957020759583, 0.9916957020759583, 0.9911599159240723, 0.9933030009269714, 0.9914277791976929, 0.9951781630516052, 0.9941065907478333, 0.9943745136260986, 0.993035078048706, 0.9933030009269714, 0.9946423768997192, 0.9951781630516052, 0.9933030009269714, 0.9927672147750854, 0.9895526170730591, 0.9713367223739624, 0.9895526170730591, 0.9922314286231995, 0.9858022928237915, 0.9933030009269714, 0.9943745136260986, 0.9954460263252258, 0.9962496757507324, 0.9946423768997192, 0.9951781630516052, 0.996517539024353, 0.9962496757507324, 0.9962496757507324, 0.9946423768997192, 0.9962496757507324, 0.9951781630516052, 0.9954460263252258, 0.9949102401733398], 'val_loss': [0.662283718585968, 0.65533846616745, 0.6465292572975159, 0.6405308842658997, 0.6293359398841858, 0.6150849461555481, 0.6027929186820984, 0.5797175168991089, 0.5610550045967102, 0.5356915593147278, 0.5080701112747192, 0.476654976606369, 0.44219687581062317, 0.41779232025146484, 0.3756067454814911, 0.3614668548107147, 0.32089465856552124, 0.2984827160835266, 0.2848462462425232, 0.2781657576560974, 0.27470308542251587, 0.28281956911087036, 0.30076703429222107, 0.30446434020996094, 0.3167845606803894, 0.3364841341972351, 0.34963884949684143, 0.3479388952255249, 0.3622779846191406, 0.36052197217941284, 0.3770851492881775, 0.3998607099056244, 0.37860018014907837, 0.3882443606853485, 0.385419636964798, 0.40255558490753174, 0.40326517820358276, 0.4010861814022064, 0.4117152988910675, 0.4130164384841919, 0.4070955514907837, 0.4181109666824341, 0.41787484288215637, 0.4201396107673645, 0.4267290532588959, 0.43647292256355286, 0.4358045756816864, 0.4340291917324066, 0.43539875745773315, 0.4353347420692444, 0.45639070868492126, 0.4448544383049011, 0.4599471390247345, 0.45101115107536316, 0.4567348062992096, 0.46078193187713623, 0.4575830101966858, 0.47067829966545105, 0.45993247628211975, 0.4642254114151001, 0.5929611325263977, 0.48160678148269653, 0.47149452567100525, 0.47360166907310486, 0.5120229721069336, 0.4928070604801178, 0.5016651749610901, 0.48158565163612366, 0.5052726864814758, 0.49096617102622986, 0.4960281550884247, 0.516035795211792, 0.5203787684440613, 0.5194584727287292, 0.510496973991394, 0.5046190619468689, 0.5175697207450867, 0.5149610042572021, 0.5162549018859863, 0.5178413987159729, 0.5473495721817017, 0.5212039947509766, 0.5559050440788269, 0.5127967596054077, 0.5130898952484131, 0.5085977911949158, 0.5096583962440491, 0.5138314366340637, 0.5250043869018555, 0.5279992818832397, 0.5297459959983826, 0.5285547971725464, 0.5465623140335083, 0.5679824948310852, 0.5560339689254761, 0.5360404849052429, 0.5404244065284729, 0.5591381192207336, 0.5633575916290283, 0.5632287263870239], 'val_accuracy': [0.5278372764587402, 0.5802997946739197, 0.6306209564208984, 0.6231263279914856, 0.6937901377677917, 0.7419700026512146, 0.7612419724464417, 0.835117757320404, 0.8490363955497742, 0.8725910186767578, 0.8790149688720703, 0.8865096569061279, 0.8961455821990967, 0.8800856471061707, 0.897216260433197, 0.8779443502426147, 0.8961455821990967, 0.897216260433197, 0.8961455821990967, 0.8950749635696411, 0.8929336071014404, 0.8961455821990967, 0.8907923102378845, 0.8961455821990967, 0.8929336071014404, 0.8918629288673401, 0.8918629288673401, 0.8886509537696838, 0.8929336071014404, 0.8918629288673401, 0.8897216320037842, 0.8865096569061279, 0.8929336071014404, 0.8940042853355408, 0.8897216320037842, 0.8832976222038269, 0.8843683004379272, 0.8950749635696411, 0.881156325340271, 0.8886509537696838, 0.8929336071014404, 0.8875802755355835, 0.8907923102378845, 0.8886509537696838, 0.8886509537696838, 0.8822270035743713, 0.8897216320037842, 0.8865096569061279, 0.8832976222038269, 0.8865096569061279, 0.8854389786720276, 0.8843683004379272, 0.881156325340271, 0.8886509537696838, 0.8886509537696838, 0.8822270035743713, 0.8886509537696838, 0.8875802755355835, 0.8875802755355835, 0.8886509537696838, 0.8490363955497742, 0.8875802755355835, 0.8854389786720276, 0.8929336071014404, 0.8747323155403137, 0.8875802755355835, 0.8886509537696838, 0.8907923102378845, 0.8918629288673401, 0.8854389786720276, 0.8865096569061279, 0.8854389786720276, 0.881156325340271, 0.8790149688720703, 0.8854389786720276, 0.8832976222038269, 0.8886509537696838, 0.8865096569061279, 0.8929336071014404, 0.8875802755355835, 0.8875802755355835, 0.8918629288673401, 0.8715203404426575, 0.8854389786720276, 0.8768736720085144, 0.8897216320037842, 0.8897216320037842, 0.8897216320037842, 0.8865096569061279, 0.8865096569061279, 0.8886509537696838, 0.8918629288673401, 0.8758029937744141, 0.8747323155403137, 0.8747323155403137, 0.8897216320037842, 0.8832976222038269, 0.8832976222038269, 0.8875802755355835, 0.881156325340271]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 7s 48ms/step - loss: 0.0936 - accuracy: 0.9700 - val_loss: 0.6538 - val_accuracy: 0.5310\n","Epoch 2/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0696 - accuracy: 0.9767 - val_loss: 0.6448 - val_accuracy: 0.5771\n","Epoch 3/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0621 - accuracy: 0.9807 - val_loss: 0.6382 - val_accuracy: 0.5974\n","Epoch 4/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0548 - accuracy: 0.9812 - val_loss: 0.6246 - val_accuracy: 0.6478\n","Epoch 5/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0535 - accuracy: 0.9829 - val_loss: 0.6052 - val_accuracy: 0.7120\n","Epoch 6/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0484 - accuracy: 0.9850 - val_loss: 0.5894 - val_accuracy: 0.7666\n","Epoch 7/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0515 - accuracy: 0.9861 - val_loss: 0.5722 - val_accuracy: 0.7752\n","Epoch 8/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0430 - accuracy: 0.9874 - val_loss: 0.5479 - val_accuracy: 0.8266\n","Epoch 9/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0467 - accuracy: 0.9842 - val_loss: 0.5160 - val_accuracy: 0.8758\n","Epoch 10/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0422 - accuracy: 0.9853 - val_loss: 0.4933 - val_accuracy: 0.8897\n","Epoch 11/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0383 - accuracy: 0.9879 - val_loss: 0.4682 - val_accuracy: 0.8672\n","Epoch 12/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0473 - accuracy: 0.9826 - val_loss: 0.4197 - val_accuracy: 0.9026\n","Epoch 13/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0373 - accuracy: 0.9885 - val_loss: 0.3938 - val_accuracy: 0.8994\n","Epoch 14/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0385 - accuracy: 0.9882 - val_loss: 0.3531 - val_accuracy: 0.9015\n","Epoch 15/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0345 - accuracy: 0.9904 - val_loss: 0.3246 - val_accuracy: 0.8929\n","Epoch 16/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0396 - accuracy: 0.9858 - val_loss: 0.2989 - val_accuracy: 0.9036\n","Epoch 17/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0296 - accuracy: 0.9920 - val_loss: 0.2755 - val_accuracy: 0.8972\n","Epoch 18/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0328 - accuracy: 0.9914 - val_loss: 0.2795 - val_accuracy: 0.8961\n","Epoch 19/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0320 - accuracy: 0.9914 - val_loss: 0.2592 - val_accuracy: 0.8929\n","Epoch 20/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0302 - accuracy: 0.9922 - val_loss: 0.2593 - val_accuracy: 0.8994\n","Epoch 21/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0313 - accuracy: 0.9898 - val_loss: 0.2881 - val_accuracy: 0.9004\n","Epoch 22/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0289 - accuracy: 0.9928 - val_loss: 0.2909 - val_accuracy: 0.9015\n","Epoch 23/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0342 - accuracy: 0.9885 - val_loss: 0.3156 - val_accuracy: 0.8972\n","Epoch 24/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0431 - accuracy: 0.9861 - val_loss: 0.3192 - val_accuracy: 0.8972\n","Epoch 25/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0313 - accuracy: 0.9904 - val_loss: 0.3613 - val_accuracy: 0.9004\n","Epoch 26/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0440 - accuracy: 0.9855 - val_loss: 0.3739 - val_accuracy: 0.8940\n","Epoch 27/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0302 - accuracy: 0.9912 - val_loss: 0.3927 - val_accuracy: 0.9036\n","Epoch 28/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0262 - accuracy: 0.9933 - val_loss: 0.3815 - val_accuracy: 0.8951\n","Epoch 29/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0314 - accuracy: 0.9887 - val_loss: 0.3907 - val_accuracy: 0.8919\n","Epoch 30/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0227 - accuracy: 0.9938 - val_loss: 0.4052 - val_accuracy: 0.9004\n","Epoch 31/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0269 - accuracy: 0.9922 - val_loss: 0.4104 - val_accuracy: 0.8919\n","Epoch 32/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0242 - accuracy: 0.9930 - val_loss: 0.3958 - val_accuracy: 0.8951\n","Epoch 33/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.0183 - accuracy: 0.9949 - val_loss: 0.4057 - val_accuracy: 0.8994\n","Epoch 34/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0246 - accuracy: 0.9914 - val_loss: 0.4173 - val_accuracy: 0.9015\n","Epoch 35/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0221 - accuracy: 0.9936 - val_loss: 0.4242 - val_accuracy: 0.8908\n","Epoch 36/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0227 - accuracy: 0.9930 - val_loss: 0.4707 - val_accuracy: 0.8994\n","Epoch 37/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.4954 - val_accuracy: 0.8951\n","Epoch 38/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0189 - accuracy: 0.9946 - val_loss: 0.4338 - val_accuracy: 0.8951\n","Epoch 39/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0159 - accuracy: 0.9971 - val_loss: 0.4224 - val_accuracy: 0.8972\n","Epoch 40/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0200 - accuracy: 0.9946 - val_loss: 0.4714 - val_accuracy: 0.9015\n","Epoch 41/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0155 - accuracy: 0.9957 - val_loss: 0.4453 - val_accuracy: 0.8951\n","Epoch 42/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0181 - accuracy: 0.9949 - val_loss: 0.4593 - val_accuracy: 0.8972\n","Epoch 43/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0203 - accuracy: 0.9928 - val_loss: 0.5122 - val_accuracy: 0.8919\n","Epoch 44/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0171 - accuracy: 0.9952 - val_loss: 0.4661 - val_accuracy: 0.8897\n","Epoch 45/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0182 - accuracy: 0.9936 - val_loss: 0.4795 - val_accuracy: 0.8919\n","Epoch 46/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0175 - accuracy: 0.9933 - val_loss: 0.4905 - val_accuracy: 0.8972\n","Epoch 47/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.4881 - val_accuracy: 0.8961\n","Epoch 48/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 0.4855 - val_accuracy: 0.8983\n","Epoch 49/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0161 - accuracy: 0.9960 - val_loss: 0.4851 - val_accuracy: 0.8940\n","Epoch 50/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0174 - accuracy: 0.9949 - val_loss: 0.4716 - val_accuracy: 0.8940\n","Epoch 51/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.0188 - accuracy: 0.9938 - val_loss: 0.5911 - val_accuracy: 0.8876\n","Epoch 52/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0199 - accuracy: 0.9938 - val_loss: 0.5513 - val_accuracy: 0.8908\n","Epoch 53/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.0203 - accuracy: 0.9941 - val_loss: 0.4974 - val_accuracy: 0.8897\n","Epoch 54/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 0.5096 - val_accuracy: 0.8972\n","Epoch 55/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0145 - accuracy: 0.9960 - val_loss: 0.4979 - val_accuracy: 0.8961\n","Epoch 56/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.5311 - val_accuracy: 0.8983\n","Epoch 57/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0375 - accuracy: 0.9863 - val_loss: 0.6565 - val_accuracy: 0.8704\n","Epoch 58/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0326 - accuracy: 0.9879 - val_loss: 0.5544 - val_accuracy: 0.8822\n","Epoch 59/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0142 - accuracy: 0.9965 - val_loss: 0.4897 - val_accuracy: 0.8972\n","Epoch 60/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0286 - accuracy: 0.9871 - val_loss: 0.5273 - val_accuracy: 0.8961\n","Epoch 61/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.4855 - val_accuracy: 0.8908\n","Epoch 62/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0109 - accuracy: 0.9971 - val_loss: 0.5588 - val_accuracy: 0.8940\n","Epoch 63/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.5459 - val_accuracy: 0.8929\n","Epoch 64/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0147 - accuracy: 0.9946 - val_loss: 0.5006 - val_accuracy: 0.8929\n","Epoch 65/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0086 - accuracy: 0.9984 - val_loss: 0.5118 - val_accuracy: 0.8929\n","Epoch 66/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0077 - accuracy: 0.9989 - val_loss: 0.5184 - val_accuracy: 0.8951\n","Epoch 67/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 0.5037 - val_accuracy: 0.8983\n","Epoch 68/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0093 - accuracy: 0.9981 - val_loss: 0.5086 - val_accuracy: 0.8951\n","Epoch 69/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.6030 - val_accuracy: 0.8844\n","Epoch 70/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0170 - accuracy: 0.9930 - val_loss: 0.6026 - val_accuracy: 0.8844\n","Epoch 71/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.5422 - val_accuracy: 0.8951\n","Epoch 72/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 0.5837 - val_accuracy: 0.8961\n","Epoch 73/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.6000 - val_accuracy: 0.8919\n","Epoch 74/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 0.5525 - val_accuracy: 0.8919\n","Epoch 75/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.5705 - val_accuracy: 0.8940\n","Epoch 76/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 0.5554 - val_accuracy: 0.8951\n","Epoch 77/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0064 - accuracy: 0.9992 - val_loss: 0.6030 - val_accuracy: 0.8940\n","Epoch 78/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0112 - accuracy: 0.9971 - val_loss: 0.5688 - val_accuracy: 0.8865\n","Epoch 79/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 0.5606 - val_accuracy: 0.8961\n","Epoch 80/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.6100 - val_accuracy: 0.8940\n","Epoch 81/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.5736 - val_accuracy: 0.8951\n","Epoch 82/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.5697 - val_accuracy: 0.8929\n","Epoch 83/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.5668 - val_accuracy: 0.8940\n","Epoch 84/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.5731 - val_accuracy: 0.8897\n","Epoch 85/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.5836 - val_accuracy: 0.8940\n","Epoch 86/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.5681 - val_accuracy: 0.8929\n","Epoch 87/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.6193 - val_accuracy: 0.8929\n","Epoch 88/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0079 - accuracy: 0.9971 - val_loss: 0.6040 - val_accuracy: 0.8940\n","Epoch 89/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0082 - accuracy: 0.9968 - val_loss: 0.5811 - val_accuracy: 0.8961\n","Epoch 90/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.5813 - val_accuracy: 0.8951\n","Epoch 91/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0109 - accuracy: 0.9954 - val_loss: 0.5954 - val_accuracy: 0.8972\n","Epoch 92/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0123 - accuracy: 0.9949 - val_loss: 0.6235 - val_accuracy: 0.8919\n","Epoch 93/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.6208 - val_accuracy: 0.8929\n","Epoch 94/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.5702 - val_accuracy: 0.8897\n","Epoch 95/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0069 - accuracy: 0.9973 - val_loss: 0.6025 - val_accuracy: 0.8865\n","Epoch 96/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.6234 - val_accuracy: 0.8897\n","Epoch 97/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.6117 - val_accuracy: 0.8865\n","Epoch 98/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0110 - accuracy: 0.9960 - val_loss: 0.5927 - val_accuracy: 0.8897\n","Epoch 99/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.6679 - val_accuracy: 0.8854\n","Epoch 100/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0099 - accuracy: 0.9962 - val_loss: 0.5736 - val_accuracy: 0.8854\n","{'loss': [0.09364238381385803, 0.06959398090839386, 0.06210477277636528, 0.05482657626271248, 0.05352334305644035, 0.048378895968198776, 0.051476847380399704, 0.0430297926068306, 0.04673100635409355, 0.042155671864748, 0.03827233240008354, 0.047280214726924896, 0.03731844574213028, 0.0385122112929821, 0.0344751812517643, 0.03963727131485939, 0.029568977653980255, 0.0328095518052578, 0.03201158717274666, 0.03019557148218155, 0.03130079060792923, 0.02893749810755253, 0.03420788422226906, 0.043069303035736084, 0.03131609037518501, 0.04400761052966118, 0.030196385458111763, 0.026198260486125946, 0.03144942596554756, 0.022739795967936516, 0.026889583095908165, 0.024243947118520737, 0.018331613391637802, 0.024644851684570312, 0.022068865597248077, 0.02272222563624382, 0.021223390474915504, 0.018877917900681496, 0.015945756807923317, 0.019956517964601517, 0.0154856126755476, 0.018059562891721725, 0.020254386588931084, 0.01706864684820175, 0.018223389983177185, 0.017495691776275635, 0.016302606090903282, 0.017669254913926125, 0.01612096279859543, 0.017397744581103325, 0.018832480534911156, 0.01989477500319481, 0.020321747288107872, 0.012798115611076355, 0.014508374966681004, 0.010974184609949589, 0.03751475736498833, 0.03257853537797928, 0.014211243949830532, 0.02862580679357052, 0.01739664003252983, 0.010851635597646236, 0.01254314836114645, 0.014737848192453384, 0.008567697368562222, 0.007689375430345535, 0.010329579934477806, 0.009310743771493435, 0.012073613703250885, 0.01699310727417469, 0.00948773231357336, 0.00807796511799097, 0.009974880144000053, 0.013763872906565666, 0.009944823570549488, 0.008335861377418041, 0.006352191790938377, 0.011192703619599342, 0.010408067144453526, 0.0067777675576508045, 0.011852871626615524, 0.007840657606720924, 0.005573544651269913, 0.006948812399059534, 0.006586685311049223, 0.007998732849955559, 0.010801669210195541, 0.0078865522518754, 0.00815588142722845, 0.008068078197538853, 0.01086670346558094, 0.012271312065422535, 0.010663327760994434, 0.005266009364277124, 0.006883958820253611, 0.008837023749947548, 0.009526112116873264, 0.01097117643803358, 0.005593802779912949, 0.009909408167004585], 'accuracy': [0.9699973464012146, 0.9766943454742432, 0.9807125926017761, 0.9812483191490173, 0.9828556180000305, 0.9849986433982849, 0.9860701560974121, 0.9874095916748047, 0.9841949939727783, 0.9852665662765503, 0.9879453778266907, 0.9825877547264099, 0.9884811043739319, 0.9882132411003113, 0.9903562664985657, 0.9858022928237915, 0.9919635653495789, 0.9914277791976929, 0.9914277791976929, 0.9922314286231995, 0.9898205399513245, 0.9927672147750854, 0.9884811043739319, 0.9860701560974121, 0.9903562664985657, 0.9855344295501709, 0.9911599159240723, 0.9933030009269714, 0.9887489676475525, 0.9938387274742126, 0.9922314286231995, 0.993035078048706, 0.9949102401733398, 0.9914277791976929, 0.993570864200592, 0.993035078048706, 0.9933030009269714, 0.9946423768997192, 0.997053325176239, 0.9946423768997192, 0.9957138895988464, 0.9949102401733398, 0.9927672147750854, 0.9951781630516052, 0.993570864200592, 0.9933030009269714, 0.9949102401733398, 0.9941065907478333, 0.9959818124771118, 0.9949102401733398, 0.9938387274742126, 0.9938387274742126, 0.9941065907478333, 0.9962496757507324, 0.9959818124771118, 0.9975890517234802, 0.9863380789756775, 0.9879453778266907, 0.996517539024353, 0.9871417284011841, 0.9946423768997192, 0.997053325176239, 0.9957138895988464, 0.9946423768997192, 0.9983927011489868, 0.9989284873008728, 0.9973211884498596, 0.9981248378753662, 0.9957138895988464, 0.993035078048706, 0.9975890517234802, 0.9981248378753662, 0.9967854022979736, 0.9959818124771118, 0.9975890517234802, 0.9981248378753662, 0.9991963505744934, 0.997053325176239, 0.9973211884498596, 0.9989284873008728, 0.9962496757507324, 0.9986606240272522, 0.9983927011489868, 0.9981248378753662, 0.9978569746017456, 0.9973211884498596, 0.996517539024353, 0.997053325176239, 0.9967854022979736, 0.9975890517234802, 0.9954460263252258, 0.9949102401733398, 0.996517539024353, 0.9989284873008728, 0.9973211884498596, 0.997053325176239, 0.9967854022979736, 0.9959818124771118, 0.9986606240272522, 0.9962496757507324], 'val_loss': [0.6537551879882812, 0.6447716951370239, 0.6382380127906799, 0.6245737075805664, 0.6052374839782715, 0.5893633365631104, 0.5722286105155945, 0.5479066967964172, 0.5160331130027771, 0.4933263957500458, 0.4682468771934509, 0.4197031557559967, 0.3937787115573883, 0.3530946969985962, 0.3245680332183838, 0.29890963435173035, 0.2754824757575989, 0.27945372462272644, 0.2591588497161865, 0.25932130217552185, 0.2880677580833435, 0.29090434312820435, 0.31558817625045776, 0.31920239329338074, 0.36126336455345154, 0.3738700747489929, 0.3927447199821472, 0.3814699947834015, 0.3906896412372589, 0.4052300751209259, 0.4104473292827606, 0.39578044414520264, 0.4056817591190338, 0.4173073172569275, 0.4241568446159363, 0.4706887900829315, 0.4953620731830597, 0.4338226616382599, 0.4224269688129425, 0.47142496705055237, 0.44526490569114685, 0.4592539370059967, 0.5122160911560059, 0.4660670757293701, 0.47953930497169495, 0.4904937148094177, 0.48805922269821167, 0.485493540763855, 0.4850862920284271, 0.4715714752674103, 0.5911096334457397, 0.5512592792510986, 0.4973762035369873, 0.509629487991333, 0.49789726734161377, 0.5311367511749268, 0.6564908623695374, 0.5544224381446838, 0.48971524834632874, 0.5272631049156189, 0.4854835271835327, 0.5587501525878906, 0.5459015965461731, 0.5005919337272644, 0.5117884278297424, 0.5184249877929688, 0.503714919090271, 0.5086120963096619, 0.6030084490776062, 0.6025699973106384, 0.5421563982963562, 0.5837216377258301, 0.600043535232544, 0.5525181889533997, 0.5705049633979797, 0.5554088354110718, 0.6030470728874207, 0.5688135623931885, 0.5606057047843933, 0.6099648475646973, 0.5736316442489624, 0.569694995880127, 0.5668025016784668, 0.5730787515640259, 0.5836237668991089, 0.5681183338165283, 0.6192876696586609, 0.6040201783180237, 0.5810927152633667, 0.5812854766845703, 0.5953803062438965, 0.6235222220420837, 0.6207560300827026, 0.5702213644981384, 0.6025352478027344, 0.6233866810798645, 0.6117339730262756, 0.5927141308784485, 0.6678546667098999, 0.5735839009284973], 'val_accuracy': [0.5310492515563965, 0.5770878195762634, 0.597430408000946, 0.6477516293525696, 0.7119914293289185, 0.7665953040122986, 0.7751606106758118, 0.8265524506568909, 0.8758029937744141, 0.8897216320037842, 0.8672376871109009, 0.902569591999054, 0.8993576169013977, 0.9014989137649536, 0.8929336071014404, 0.9036402702331543, 0.897216260433197, 0.8961455821990967, 0.8929336071014404, 0.8993576169013977, 0.900428295135498, 0.9014989137649536, 0.897216260433197, 0.897216260433197, 0.900428295135498, 0.8940042853355408, 0.9036402702331543, 0.8950749635696411, 0.8918629288673401, 0.900428295135498, 0.8918629288673401, 0.8950749635696411, 0.8993576169013977, 0.9014989137649536, 0.8907923102378845, 0.8993576169013977, 0.8950749635696411, 0.8950749635696411, 0.897216260433197, 0.9014989137649536, 0.8950749635696411, 0.897216260433197, 0.8918629288673401, 0.8897216320037842, 0.8918629288673401, 0.897216260433197, 0.8961455821990967, 0.8982869386672974, 0.8940042853355408, 0.8940042853355408, 0.8875802755355835, 0.8907923102378845, 0.8897216320037842, 0.897216260433197, 0.8961455821990967, 0.8982869386672974, 0.8704496622085571, 0.8822270035743713, 0.897216260433197, 0.8961455821990967, 0.8907923102378845, 0.8940042853355408, 0.8929336071014404, 0.8929336071014404, 0.8929336071014404, 0.8950749635696411, 0.8982869386672974, 0.8950749635696411, 0.8843683004379272, 0.8843683004379272, 0.8950749635696411, 0.8961455821990967, 0.8918629288673401, 0.8918629288673401, 0.8940042853355408, 0.8950749635696411, 0.8940042853355408, 0.8865096569061279, 0.8961455821990967, 0.8940042853355408, 0.8950749635696411, 0.8929336071014404, 0.8940042853355408, 0.8897216320037842, 0.8940042853355408, 0.8929336071014404, 0.8929336071014404, 0.8940042853355408, 0.8961455821990967, 0.8950749635696411, 0.897216260433197, 0.8918629288673401, 0.8929336071014404, 0.8897216320037842, 0.8865096569061279, 0.8897216320037842, 0.8865096569061279, 0.8897216320037842, 0.8854389786720276, 0.8854389786720276]}\n","37/37 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 7s 46ms/step - loss: 0.0794 - accuracy: 0.9746 - val_loss: 0.6507 - val_accuracy: 0.5268\n","Epoch 2/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0681 - accuracy: 0.9767 - val_loss: 0.6401 - val_accuracy: 0.5899\n","Epoch 3/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0564 - accuracy: 0.9804 - val_loss: 0.6292 - val_accuracy: 0.6274\n","Epoch 4/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0517 - accuracy: 0.9821 - val_loss: 0.6208 - val_accuracy: 0.6221\n","Epoch 5/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0476 - accuracy: 0.9847 - val_loss: 0.5979 - val_accuracy: 0.7548\n","Epoch 6/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0405 - accuracy: 0.9874 - val_loss: 0.5803 - val_accuracy: 0.7880\n","Epoch 7/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0404 - accuracy: 0.9853 - val_loss: 0.5485 - val_accuracy: 0.9026\n","Epoch 8/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0456 - accuracy: 0.9845 - val_loss: 0.5388 - val_accuracy: 0.8319\n","Epoch 9/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0342 - accuracy: 0.9882 - val_loss: 0.5072 - val_accuracy: 0.8812\n","Epoch 10/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0384 - accuracy: 0.9866 - val_loss: 0.4900 - val_accuracy: 0.8415\n","Epoch 11/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0752 - accuracy: 0.9713 - val_loss: 0.4520 - val_accuracy: 0.9058\n","Epoch 12/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0397 - accuracy: 0.9855 - val_loss: 0.4011 - val_accuracy: 0.9240\n","Epoch 13/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0373 - accuracy: 0.9874 - val_loss: 0.3650 - val_accuracy: 0.9272\n","Epoch 14/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0383 - accuracy: 0.9871 - val_loss: 0.3308 - val_accuracy: 0.9229\n","Epoch 15/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0289 - accuracy: 0.9912 - val_loss: 0.3041 - val_accuracy: 0.9197\n","Epoch 16/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0297 - accuracy: 0.9914 - val_loss: 0.2699 - val_accuracy: 0.9186\n","Epoch 17/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0298 - accuracy: 0.9912 - val_loss: 0.2313 - val_accuracy: 0.9208\n","Epoch 18/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 0.2134 - val_accuracy: 0.9261\n","Epoch 19/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0250 - accuracy: 0.9925 - val_loss: 0.2020 - val_accuracy: 0.9208\n","Epoch 20/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0219 - accuracy: 0.9941 - val_loss: 0.2017 - val_accuracy: 0.9176\n","Epoch 21/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0243 - accuracy: 0.9930 - val_loss: 0.2050 - val_accuracy: 0.9229\n","Epoch 22/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0254 - accuracy: 0.9928 - val_loss: 0.2098 - val_accuracy: 0.9218\n","Epoch 23/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0225 - accuracy: 0.9941 - val_loss: 0.2235 - val_accuracy: 0.9208\n","Epoch 24/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0256 - accuracy: 0.9914 - val_loss: 0.2364 - val_accuracy: 0.9186\n","Epoch 25/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0256 - accuracy: 0.9920 - val_loss: 0.2574 - val_accuracy: 0.9208\n","Epoch 26/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0253 - accuracy: 0.9920 - val_loss: 0.2576 - val_accuracy: 0.9176\n","Epoch 27/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0218 - accuracy: 0.9936 - val_loss: 0.2678 - val_accuracy: 0.9208\n","Epoch 28/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0205 - accuracy: 0.9949 - val_loss: 0.2728 - val_accuracy: 0.9165\n","Epoch 29/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0186 - accuracy: 0.9954 - val_loss: 0.2909 - val_accuracy: 0.9229\n","Epoch 30/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0223 - accuracy: 0.9928 - val_loss: 0.2900 - val_accuracy: 0.9229\n","Epoch 31/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0192 - accuracy: 0.9936 - val_loss: 0.2918 - val_accuracy: 0.9251\n","Epoch 32/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: 0.2991 - val_accuracy: 0.9229\n","Epoch 33/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0167 - accuracy: 0.9965 - val_loss: 0.3107 - val_accuracy: 0.9154\n","Epoch 34/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0183 - accuracy: 0.9952 - val_loss: 0.3211 - val_accuracy: 0.9218\n","Epoch 35/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0235 - accuracy: 0.9920 - val_loss: 0.3567 - val_accuracy: 0.9143\n","Epoch 36/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0224 - accuracy: 0.9928 - val_loss: 0.3160 - val_accuracy: 0.9165\n","Epoch 37/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0151 - accuracy: 0.9960 - val_loss: 0.3161 - val_accuracy: 0.9197\n","Epoch 38/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0190 - accuracy: 0.9957 - val_loss: 0.3220 - val_accuracy: 0.9176\n","Epoch 39/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.3336 - val_accuracy: 0.9154\n","Epoch 40/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0172 - accuracy: 0.9938 - val_loss: 0.3338 - val_accuracy: 0.9154\n","Epoch 41/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0249 - accuracy: 0.9909 - val_loss: 0.3897 - val_accuracy: 0.9165\n","Epoch 42/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.3349 - val_accuracy: 0.9165\n","Epoch 43/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0219 - accuracy: 0.9930 - val_loss: 0.3550 - val_accuracy: 0.9186\n","Epoch 44/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0195 - accuracy: 0.9930 - val_loss: 0.3326 - val_accuracy: 0.9122\n","Epoch 45/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.5278 - val_accuracy: 0.8887\n","Epoch 46/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0279 - accuracy: 0.9917 - val_loss: 0.3436 - val_accuracy: 0.9165\n","Epoch 47/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0127 - accuracy: 0.9971 - val_loss: 0.3418 - val_accuracy: 0.9122\n","Epoch 48/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0537 - accuracy: 0.9794 - val_loss: 0.3869 - val_accuracy: 0.9133\n","Epoch 49/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.3391 - val_accuracy: 0.9229\n","Epoch 50/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0149 - accuracy: 0.9960 - val_loss: 0.3413 - val_accuracy: 0.9208\n","Epoch 51/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0149 - accuracy: 0.9960 - val_loss: 0.3432 - val_accuracy: 0.9218\n","Epoch 52/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.0101 - accuracy: 0.9981 - val_loss: 0.3504 - val_accuracy: 0.9143\n","Epoch 53/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0141 - accuracy: 0.9952 - val_loss: 0.3580 - val_accuracy: 0.9122\n","Epoch 54/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0170 - accuracy: 0.9933 - val_loss: 0.3972 - val_accuracy: 0.9122\n","Epoch 55/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.3376 - val_accuracy: 0.9218\n","Epoch 56/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.3521 - val_accuracy: 0.9133\n","Epoch 57/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0385 - accuracy: 0.9869 - val_loss: 0.3848 - val_accuracy: 0.9133\n","Epoch 58/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.3802 - val_accuracy: 0.9176\n","Epoch 59/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0108 - accuracy: 0.9971 - val_loss: 0.3813 - val_accuracy: 0.9197\n","Epoch 60/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0129 - accuracy: 0.9968 - val_loss: 0.3541 - val_accuracy: 0.9176\n","Epoch 61/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.3554 - val_accuracy: 0.9133\n","Epoch 62/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.3625 - val_accuracy: 0.9186\n","Epoch 63/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 0.3641 - val_accuracy: 0.9197\n","Epoch 64/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.3546 - val_accuracy: 0.9133\n","Epoch 65/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0155 - accuracy: 0.9946 - val_loss: 0.3697 - val_accuracy: 0.9111\n","Epoch 66/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0182 - accuracy: 0.9928 - val_loss: 0.3850 - val_accuracy: 0.9165\n","Epoch 67/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.3706 - val_accuracy: 0.9186\n","Epoch 68/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0117 - accuracy: 0.9971 - val_loss: 0.3714 - val_accuracy: 0.9197\n","Epoch 69/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.3784 - val_accuracy: 0.9143\n","Epoch 70/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 0.3724 - val_accuracy: 0.9154\n","Epoch 71/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.3906 - val_accuracy: 0.9197\n","Epoch 72/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.3769 - val_accuracy: 0.9122\n","Epoch 73/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.3689 - val_accuracy: 0.9143\n","Epoch 74/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.3774 - val_accuracy: 0.9154\n","Epoch 75/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0192 - accuracy: 0.9925 - val_loss: 0.3944 - val_accuracy: 0.9122\n","Epoch 76/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0149 - accuracy: 0.9944 - val_loss: 0.4500 - val_accuracy: 0.9154\n","Epoch 77/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.4541 - val_accuracy: 0.9133\n","Epoch 78/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0234 - accuracy: 0.9912 - val_loss: 0.4427 - val_accuracy: 0.9133\n","Epoch 79/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.3715 - val_accuracy: 0.9176\n","Epoch 80/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.3829 - val_accuracy: 0.9122\n","Epoch 81/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.3807 - val_accuracy: 0.9122\n","Epoch 82/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.4219 - val_accuracy: 0.9154\n","Epoch 83/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0060 - accuracy: 0.9992 - val_loss: 0.3837 - val_accuracy: 0.9165\n","Epoch 84/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0048 - accuracy: 0.9997 - val_loss: 0.4288 - val_accuracy: 0.9165\n","Epoch 85/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0110 - accuracy: 0.9960 - val_loss: 0.4841 - val_accuracy: 0.9111\n","Epoch 86/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.4048 - val_accuracy: 0.9111\n","Epoch 87/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0074 - accuracy: 0.9984 - val_loss: 0.4055 - val_accuracy: 0.9143\n","Epoch 88/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.3983 - val_accuracy: 0.9133\n","Epoch 89/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.3974 - val_accuracy: 0.9143\n","Epoch 90/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.3939 - val_accuracy: 0.9165\n","Epoch 91/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.4050 - val_accuracy: 0.9143\n","Epoch 92/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.4425 - val_accuracy: 0.9122\n","Epoch 93/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.4143 - val_accuracy: 0.9176\n","Epoch 94/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0094 - accuracy: 0.9962 - val_loss: 0.4171 - val_accuracy: 0.9079\n","Epoch 95/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.4524 - val_accuracy: 0.9101\n","Epoch 96/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.4084 - val_accuracy: 0.9154\n","Epoch 97/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.4184 - val_accuracy: 0.9165\n","Epoch 98/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.4506 - val_accuracy: 0.9154\n","Epoch 99/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.4244 - val_accuracy: 0.9101\n","Epoch 100/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.4342 - val_accuracy: 0.9165\n","{'loss': [0.07943397760391235, 0.06806591153144836, 0.05644308403134346, 0.05172700434923172, 0.04761599004268646, 0.04048781469464302, 0.04035550728440285, 0.045608099550008774, 0.034150660037994385, 0.03843303397297859, 0.07518579065799713, 0.039728209376335144, 0.037348952144384384, 0.03834756463766098, 0.028880314901471138, 0.02973666787147522, 0.02979850582778454, 0.024161918088793755, 0.02497904933989048, 0.021870339289307594, 0.024258561432361603, 0.025444239377975464, 0.022549785673618317, 0.02562592178583145, 0.02559858188033104, 0.025319397449493408, 0.021759405732154846, 0.020549770444631577, 0.01858041249215603, 0.02226497419178486, 0.019185548648238182, 0.020615018904209137, 0.016694290563464165, 0.01832294464111328, 0.023495668545365334, 0.022354889661073685, 0.015139305032789707, 0.019037341699004173, 0.014903991483151913, 0.01720574125647545, 0.024947170168161392, 0.019620254635810852, 0.021879898384213448, 0.01948651857674122, 0.02021501399576664, 0.02793128974735737, 0.012698550708591938, 0.05370434373617172, 0.017770659178495407, 0.0148862823843956, 0.014894137158989906, 0.010094402357935905, 0.014052999205887318, 0.017011279240250587, 0.014879376627504826, 0.013923859223723412, 0.03851405158638954, 0.015208403579890728, 0.010821783915162086, 0.012897007167339325, 0.010261263698339462, 0.008239160291850567, 0.008090763352811337, 0.010801847092807293, 0.01551490742713213, 0.018244018778204918, 0.012054338119924068, 0.011670062318444252, 0.011062467470765114, 0.00887251552194357, 0.009320310316979885, 0.009356431663036346, 0.005335961934179068, 0.007403910160064697, 0.01924726366996765, 0.014858727343380451, 0.01405298337340355, 0.023416079580783844, 0.016974585130810738, 0.0065821134485304356, 0.006595707032829523, 0.0066779740154743195, 0.005990976467728615, 0.00478555029258132, 0.010967983864247799, 0.011062016710639, 0.007423514500260353, 0.007677675224840641, 0.00698805321007967, 0.0063628689385950565, 0.004848663229495287, 0.00678744912147522, 0.008887499570846558, 0.009383122436702251, 0.008960338309407234, 0.008737440221011639, 0.004628091584891081, 0.0052251629531383514, 0.007776442915201187, 0.0071595292538404465], 'accuracy': [0.9745513200759888, 0.9766943454742432, 0.9804446697235107, 0.9820519685745239, 0.9847307801246643, 0.9874095916748047, 0.9852665662765503, 0.9844629168510437, 0.9882132411003113, 0.9866059422492981, 0.9713367223739624, 0.9855344295501709, 0.9874095916748047, 0.9871417284011841, 0.9911599159240723, 0.9914277791976929, 0.9911599159240723, 0.9933030009269714, 0.9924993515014648, 0.9941065907478333, 0.993035078048706, 0.9927672147750854, 0.9941065907478333, 0.9914277791976929, 0.9919635653495789, 0.9919635653495789, 0.993570864200592, 0.9949102401733398, 0.9954460263252258, 0.9927672147750854, 0.993570864200592, 0.9941065907478333, 0.996517539024353, 0.9951781630516052, 0.9919635653495789, 0.9927672147750854, 0.9959818124771118, 0.9957138895988464, 0.9957138895988464, 0.9938387274742126, 0.9908920526504517, 0.9933030009269714, 0.993035078048706, 0.993035078048706, 0.9933030009269714, 0.9916957020759583, 0.997053325176239, 0.9793731570243835, 0.9943745136260986, 0.9959818124771118, 0.9959818124771118, 0.9981248378753662, 0.9951781630516052, 0.9933030009269714, 0.9954460263252258, 0.9957138895988464, 0.9868738055229187, 0.9957138895988464, 0.997053325176239, 0.9967854022979736, 0.9975890517234802, 0.9978569746017456, 0.9981248378753662, 0.9967854022979736, 0.9946423768997192, 0.9927672147750854, 0.9959818124771118, 0.997053325176239, 0.9967854022979736, 0.9981248378753662, 0.997053325176239, 0.9978569746017456, 0.9991963505744934, 0.9989284873008728, 0.9924993515014648, 0.9943745136260986, 0.9954460263252258, 0.9911599159240723, 0.9946423768997192, 0.9983927011489868, 0.9978569746017456, 0.9981248378753662, 0.9991963505744934, 0.9997321367263794, 0.9959818124771118, 0.9967854022979736, 0.9983927011489868, 0.9978569746017456, 0.9981248378753662, 0.9983927011489868, 0.9991963505744934, 0.9975890517234802, 0.9975890517234802, 0.9962496757507324, 0.997053325176239, 0.9973211884498596, 0.9991963505744934, 0.9989284873008728, 0.9986606240272522, 0.9975890517234802], 'val_loss': [0.6506870985031128, 0.6400572657585144, 0.6292225122451782, 0.6208112239837646, 0.5979079008102417, 0.5803094506263733, 0.5484517216682434, 0.5387794375419617, 0.5071507096290588, 0.4899691939353943, 0.4520365297794342, 0.40110641717910767, 0.3650447428226471, 0.3308207392692566, 0.3040880858898163, 0.2699398994445801, 0.23127810657024384, 0.21338753402233124, 0.2019539624452591, 0.20169295370578766, 0.20504409074783325, 0.20983141660690308, 0.2235291749238968, 0.23637260496616364, 0.257407546043396, 0.2576444447040558, 0.2677542269229889, 0.272785484790802, 0.2908855378627777, 0.29001230001449585, 0.2918199300765991, 0.2990807890892029, 0.31072482466697693, 0.3210788369178772, 0.356669157743454, 0.3160422146320343, 0.31606024503707886, 0.32196271419525146, 0.33360716700553894, 0.333829790353775, 0.38974902033805847, 0.3348847031593323, 0.3550287187099457, 0.3325951099395752, 0.5278358459472656, 0.3436080515384674, 0.3417636454105377, 0.3869451880455017, 0.33905652165412903, 0.341293066740036, 0.3431796431541443, 0.3503864109516144, 0.3580121397972107, 0.39721623063087463, 0.337609201669693, 0.35212019085884094, 0.3847997188568115, 0.3801754415035248, 0.3813314139842987, 0.35406678915023804, 0.3554144501686096, 0.3624732494354248, 0.36412277817726135, 0.35455265641212463, 0.3696659803390503, 0.3850085139274597, 0.37058570981025696, 0.3713626265525818, 0.3784322440624237, 0.37238043546676636, 0.3905964195728302, 0.3768600821495056, 0.36894676089286804, 0.3774277865886688, 0.3943715989589691, 0.44997525215148926, 0.4541330337524414, 0.4427092373371124, 0.37152299284935, 0.3829440474510193, 0.3807060420513153, 0.42194247245788574, 0.3836568593978882, 0.4287653863430023, 0.48410123586654663, 0.40483197569847107, 0.40549108386039734, 0.39826110005378723, 0.39741793274879456, 0.3939068913459778, 0.4049501419067383, 0.4424586594104767, 0.4143090546131134, 0.4171372354030609, 0.45237335562705994, 0.4083711802959442, 0.41836556792259216, 0.4506421685218811, 0.42435720562934875, 0.4342091381549835], 'val_accuracy': [0.5267665982246399, 0.5899357795715332, 0.6274089813232422, 0.6220556497573853, 0.7548179626464844, 0.7880085706710815, 0.902569591999054, 0.8319057822227478, 0.881156325340271, 0.8415417671203613, 0.9057815670967102, 0.9239828586578369, 0.9271948337554932, 0.9229121804237366, 0.9197002053260803, 0.91862952709198, 0.9207708835601807, 0.9261242151260376, 0.9207708835601807, 0.9175589084625244, 0.9229121804237366, 0.921841561794281, 0.9207708835601807, 0.91862952709198, 0.9207708835601807, 0.9175589084625244, 0.9207708835601807, 0.9164882302284241, 0.9229121804237366, 0.9229121804237366, 0.9250535368919373, 0.9229121804237366, 0.9154175519943237, 0.921841561794281, 0.9143468737602234, 0.9164882302284241, 0.9197002053260803, 0.9175589084625244, 0.9154175519943237, 0.9154175519943237, 0.9164882302284241, 0.9164882302284241, 0.91862952709198, 0.9122055768966675, 0.8886509537696838, 0.9164882302284241, 0.9122055768966675, 0.9132762551307678, 0.9229121804237366, 0.9207708835601807, 0.921841561794281, 0.9143468737602234, 0.9122055768966675, 0.9122055768966675, 0.921841561794281, 0.9132762551307678, 0.9132762551307678, 0.9175589084625244, 0.9197002053260803, 0.9175589084625244, 0.9132762551307678, 0.91862952709198, 0.9197002053260803, 0.9132762551307678, 0.9111348986625671, 0.9164882302284241, 0.91862952709198, 0.9197002053260803, 0.9143468737602234, 0.9154175519943237, 0.9197002053260803, 0.9122055768966675, 0.9143468737602234, 0.9154175519943237, 0.9122055768966675, 0.9154175519943237, 0.9132762551307678, 0.9132762551307678, 0.9175589084625244, 0.9122055768966675, 0.9122055768966675, 0.9154175519943237, 0.9164882302284241, 0.9164882302284241, 0.9111348986625671, 0.9111348986625671, 0.9143468737602234, 0.9132762551307678, 0.9143468737602234, 0.9164882302284241, 0.9143468737602234, 0.9122055768966675, 0.9175589084625244, 0.9079229235649109, 0.9100642204284668, 0.9154175519943237, 0.9164882302284241, 0.9154175519943237, 0.9100642204284668, 0.9164882302284241]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 7s 48ms/step - loss: 0.0865 - accuracy: 0.9713 - val_loss: 0.6495 - val_accuracy: 0.5385\n","Epoch 2/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0613 - accuracy: 0.9772 - val_loss: 0.6402 - val_accuracy: 0.5921\n","Epoch 3/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0583 - accuracy: 0.9799 - val_loss: 0.6291 - val_accuracy: 0.6210\n","Epoch 4/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0549 - accuracy: 0.9810 - val_loss: 0.6210 - val_accuracy: 0.6221\n","Epoch 5/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0451 - accuracy: 0.9871 - val_loss: 0.6009 - val_accuracy: 0.7131\n","Epoch 6/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0478 - accuracy: 0.9823 - val_loss: 0.5902 - val_accuracy: 0.7056\n","Epoch 7/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0508 - accuracy: 0.9839 - val_loss: 0.5672 - val_accuracy: 0.7559\n","Epoch 8/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0432 - accuracy: 0.9869 - val_loss: 0.5330 - val_accuracy: 0.8544\n","Epoch 9/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0384 - accuracy: 0.9866 - val_loss: 0.5066 - val_accuracy: 0.8822\n","Epoch 10/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0343 - accuracy: 0.9901 - val_loss: 0.4719 - val_accuracy: 0.9122\n","Epoch 11/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0391 - accuracy: 0.9890 - val_loss: 0.4461 - val_accuracy: 0.9079\n","Epoch 12/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0392 - accuracy: 0.9874 - val_loss: 0.4058 - val_accuracy: 0.9176\n","Epoch 13/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0331 - accuracy: 0.9890 - val_loss: 0.3718 - val_accuracy: 0.9176\n","Epoch 14/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0297 - accuracy: 0.9922 - val_loss: 0.3246 - val_accuracy: 0.9186\n","Epoch 15/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0303 - accuracy: 0.9901 - val_loss: 0.2970 - val_accuracy: 0.9251\n","Epoch 16/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0309 - accuracy: 0.9909 - val_loss: 0.2755 - val_accuracy: 0.9165\n","Epoch 17/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0339 - accuracy: 0.9882 - val_loss: 0.2405 - val_accuracy: 0.9208\n","Epoch 18/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0308 - accuracy: 0.9920 - val_loss: 0.2251 - val_accuracy: 0.9197\n","Epoch 19/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0246 - accuracy: 0.9925 - val_loss: 0.2222 - val_accuracy: 0.9208\n","Epoch 20/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0297 - accuracy: 0.9904 - val_loss: 0.2259 - val_accuracy: 0.9165\n","Epoch 21/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0258 - accuracy: 0.9922 - val_loss: 0.2318 - val_accuracy: 0.9165\n","Epoch 22/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0422 - accuracy: 0.9855 - val_loss: 0.2371 - val_accuracy: 0.9165\n","Epoch 23/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0302 - accuracy: 0.9885 - val_loss: 0.2611 - val_accuracy: 0.9176\n","Epoch 24/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0297 - accuracy: 0.9917 - val_loss: 0.2715 - val_accuracy: 0.9111\n","Epoch 25/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0225 - accuracy: 0.9944 - val_loss: 0.2829 - val_accuracy: 0.9218\n","Epoch 26/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0195 - accuracy: 0.9946 - val_loss: 0.2901 - val_accuracy: 0.9165\n","Epoch 27/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0202 - accuracy: 0.9960 - val_loss: 0.3038 - val_accuracy: 0.9176\n","Epoch 28/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 0.3187 - val_accuracy: 0.9208\n","Epoch 29/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.3344 - val_accuracy: 0.9186\n","Epoch 30/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0204 - accuracy: 0.9952 - val_loss: 0.3455 - val_accuracy: 0.9229\n","Epoch 31/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0404 - accuracy: 0.9847 - val_loss: 0.4051 - val_accuracy: 0.8876\n","Epoch 32/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0248 - accuracy: 0.9920 - val_loss: 0.3313 - val_accuracy: 0.9208\n","Epoch 33/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0148 - accuracy: 0.9973 - val_loss: 0.3435 - val_accuracy: 0.9251\n","Epoch 34/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0170 - accuracy: 0.9960 - val_loss: 0.3785 - val_accuracy: 0.9186\n","Epoch 35/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0195 - accuracy: 0.9946 - val_loss: 0.3663 - val_accuracy: 0.9208\n","Epoch 36/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.3605 - val_accuracy: 0.9186\n","Epoch 37/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0137 - accuracy: 0.9976 - val_loss: 0.3758 - val_accuracy: 0.9122\n","Epoch 38/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0167 - accuracy: 0.9954 - val_loss: 0.3745 - val_accuracy: 0.9186\n","Epoch 39/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0142 - accuracy: 0.9968 - val_loss: 0.3798 - val_accuracy: 0.9165\n","Epoch 40/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0146 - accuracy: 0.9968 - val_loss: 0.3941 - val_accuracy: 0.9176\n","Epoch 41/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0135 - accuracy: 0.9968 - val_loss: 0.3917 - val_accuracy: 0.9154\n","Epoch 42/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0178 - accuracy: 0.9954 - val_loss: 0.4281 - val_accuracy: 0.9111\n","Epoch 43/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0180 - accuracy: 0.9946 - val_loss: 0.3927 - val_accuracy: 0.9186\n","Epoch 44/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0140 - accuracy: 0.9965 - val_loss: 0.3950 - val_accuracy: 0.9186\n","Epoch 45/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0128 - accuracy: 0.9973 - val_loss: 0.4019 - val_accuracy: 0.9165\n","Epoch 46/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0143 - accuracy: 0.9962 - val_loss: 0.4005 - val_accuracy: 0.9143\n","Epoch 47/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.3953 - val_accuracy: 0.9176\n","Epoch 48/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.3973 - val_accuracy: 0.9176\n","Epoch 49/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.4168 - val_accuracy: 0.9154\n","Epoch 50/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.3942 - val_accuracy: 0.9218\n","Epoch 51/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0122 - accuracy: 0.9971 - val_loss: 0.4015 - val_accuracy: 0.9197\n","Epoch 52/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.4099 - val_accuracy: 0.9176\n","Epoch 53/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.4244 - val_accuracy: 0.9154\n","Epoch 54/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0131 - accuracy: 0.9968 - val_loss: 0.4233 - val_accuracy: 0.9133\n","Epoch 55/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0122 - accuracy: 0.9965 - val_loss: 0.4089 - val_accuracy: 0.9154\n","Epoch 56/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.4236 - val_accuracy: 0.9133\n","Epoch 57/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0184 - accuracy: 0.9930 - val_loss: 0.4190 - val_accuracy: 0.9176\n","Epoch 58/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0143 - accuracy: 0.9965 - val_loss: 0.4584 - val_accuracy: 0.9079\n","Epoch 59/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0153 - accuracy: 0.9946 - val_loss: 0.4239 - val_accuracy: 0.9176\n","Epoch 60/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.4554 - val_accuracy: 0.9111\n","Epoch 61/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0080 - accuracy: 0.9987 - val_loss: 0.4735 - val_accuracy: 0.9090\n","Epoch 62/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0109 - accuracy: 0.9957 - val_loss: 0.4291 - val_accuracy: 0.9176\n","Epoch 63/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.4352 - val_accuracy: 0.9176\n","Epoch 64/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.4706 - val_accuracy: 0.9143\n","Epoch 65/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.4241 - val_accuracy: 0.9101\n","Epoch 66/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0078 - accuracy: 0.9971 - val_loss: 0.4327 - val_accuracy: 0.9176\n","Epoch 67/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.4254 - val_accuracy: 0.9197\n","Epoch 68/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.4369 - val_accuracy: 0.9111\n","Epoch 69/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0083 - accuracy: 0.9984 - val_loss: 0.4318 - val_accuracy: 0.9165\n","Epoch 70/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0097 - accuracy: 0.9962 - val_loss: 0.4335 - val_accuracy: 0.9186\n","Epoch 71/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.4444 - val_accuracy: 0.9154\n","Epoch 72/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0303 - accuracy: 0.9887 - val_loss: 0.5097 - val_accuracy: 0.8961\n","Epoch 73/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0298 - accuracy: 0.9885 - val_loss: 0.4770 - val_accuracy: 0.9143\n","Epoch 74/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0119 - accuracy: 0.9971 - val_loss: 0.4465 - val_accuracy: 0.9090\n","Epoch 75/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0086 - accuracy: 0.9981 - val_loss: 0.4529 - val_accuracy: 0.9143\n","Epoch 76/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 0.4371 - val_accuracy: 0.9154\n","Epoch 77/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.4371 - val_accuracy: 0.9176\n","Epoch 78/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.4240 - val_accuracy: 0.9197\n","Epoch 79/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.4325 - val_accuracy: 0.9122\n","Epoch 80/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.4468 - val_accuracy: 0.9165\n","Epoch 81/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.4481 - val_accuracy: 0.9133\n","Epoch 82/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.4534 - val_accuracy: 0.9133\n","Epoch 83/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 0.4701 - val_accuracy: 0.9143\n","Epoch 84/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0098 - accuracy: 0.9957 - val_loss: 0.4602 - val_accuracy: 0.9154\n","Epoch 85/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.4827 - val_accuracy: 0.9079\n","Epoch 86/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.4686 - val_accuracy: 0.9154\n","Epoch 87/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.5181 - val_accuracy: 0.9069\n","Epoch 88/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0078 - accuracy: 0.9971 - val_loss: 0.4673 - val_accuracy: 0.9133\n","Epoch 89/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.4951 - val_accuracy: 0.9101\n","Epoch 90/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0036 - accuracy: 0.9997 - val_loss: 0.4694 - val_accuracy: 0.9143\n","Epoch 91/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.4829 - val_accuracy: 0.9197\n","Epoch 92/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.4959 - val_accuracy: 0.9133\n","Epoch 93/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.4895 - val_accuracy: 0.9069\n","Epoch 94/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.4895 - val_accuracy: 0.9069\n","Epoch 95/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.5128 - val_accuracy: 0.8972\n","Epoch 96/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.5010 - val_accuracy: 0.9176\n","Epoch 97/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.5193 - val_accuracy: 0.9111\n","Epoch 98/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0074 - accuracy: 0.9971 - val_loss: 0.5503 - val_accuracy: 0.9101\n","Epoch 99/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.5049 - val_accuracy: 0.9143\n","Epoch 100/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.5097 - val_accuracy: 0.9122\n","{'loss': [0.08645667135715485, 0.0613459050655365, 0.05834006518125534, 0.054887037724256516, 0.04512925073504448, 0.047816600650548935, 0.050779297947883606, 0.04323692247271538, 0.03843988850712776, 0.03428458794951439, 0.039139524102211, 0.03916555270552635, 0.03305840864777565, 0.02972150780260563, 0.03029673360288143, 0.030892159789800644, 0.033942997455596924, 0.030805477872490883, 0.024562634527683258, 0.029679879546165466, 0.025814032182097435, 0.04222916439175606, 0.030152034014463425, 0.02974811941385269, 0.022463252767920494, 0.019534340128302574, 0.020203562453389168, 0.020887626335024834, 0.022076433524489403, 0.02043064869940281, 0.040397848933935165, 0.024826737120747566, 0.014836492016911507, 0.01700693741440773, 0.01948702335357666, 0.015455052256584167, 0.0137395104393363, 0.016698874533176422, 0.014183878898620605, 0.01462747436016798, 0.01346318144351244, 0.017811603844165802, 0.018001899123191833, 0.014034580439329147, 0.012835848145186901, 0.014267085120081902, 0.014751892536878586, 0.01567845419049263, 0.01688462868332863, 0.013799183070659637, 0.012212526984512806, 0.01479070819914341, 0.01184410322457552, 0.01313177403062582, 0.012172459624707699, 0.015257167629897594, 0.01844056323170662, 0.014288917183876038, 0.015297748148441315, 0.009666534140706062, 0.008021727204322815, 0.01092740148305893, 0.009090684354305267, 0.011844559572637081, 0.006699575111269951, 0.007764010690152645, 0.006284908391535282, 0.008681866340339184, 0.008343920111656189, 0.009718324989080429, 0.008610647171735764, 0.030319979414343834, 0.029777629300951958, 0.011907124891877174, 0.008640323765575886, 0.0071614994667470455, 0.006033694837242365, 0.009446904063224792, 0.00629469845443964, 0.005447654519230127, 0.006515983026474714, 0.005420111585408449, 0.00824979692697525, 0.009753519669175148, 0.004427640233188868, 0.004668048582971096, 0.010017136111855507, 0.007842686958611012, 0.006174450274556875, 0.003599128918722272, 0.004555576480925083, 0.0042031751945614815, 0.003950194455683231, 0.005592504981905222, 0.006506859324872494, 0.00525709567591548, 0.004740013275295496, 0.007445965427905321, 0.005903299432247877, 0.0032891039736568928], 'accuracy': [0.9713367223739624, 0.9772301316261292, 0.9799089431762695, 0.9809804558753967, 0.9871417284011841, 0.9823198318481445, 0.9839271306991577, 0.9868738055229187, 0.9866059422492981, 0.9900884032249451, 0.9890168905258179, 0.9874095916748047, 0.9890168905258179, 0.9922314286231995, 0.9900884032249451, 0.9908920526504517, 0.9882132411003113, 0.9919635653495789, 0.9924993515014648, 0.9903562664985657, 0.9922314286231995, 0.9855344295501709, 0.9884811043739319, 0.9916957020759583, 0.9943745136260986, 0.9946423768997192, 0.9959818124771118, 0.993570864200592, 0.9933030009269714, 0.9951781630516052, 0.9847307801246643, 0.9919635653495789, 0.9973211884498596, 0.9959818124771118, 0.9946423768997192, 0.9954460263252258, 0.9975890517234802, 0.9954460263252258, 0.9967854022979736, 0.9967854022979736, 0.9967854022979736, 0.9954460263252258, 0.9946423768997192, 0.996517539024353, 0.9973211884498596, 0.9962496757507324, 0.9954460263252258, 0.9954460263252258, 0.9949102401733398, 0.9957138895988464, 0.997053325176239, 0.9951781630516052, 0.9967854022979736, 0.9967854022979736, 0.996517539024353, 0.9949102401733398, 0.993035078048706, 0.996517539024353, 0.9946423768997192, 0.997053325176239, 0.9986606240272522, 0.9957138895988464, 0.9973211884498596, 0.9954460263252258, 0.9978569746017456, 0.997053325176239, 0.9986606240272522, 0.9967854022979736, 0.9983927011489868, 0.9962496757507324, 0.9975890517234802, 0.9887489676475525, 0.9884811043739319, 0.997053325176239, 0.9981248378753662, 0.9981248378753662, 0.9983927011489868, 0.9978569746017456, 0.9983927011489868, 0.9991963505744934, 0.9978569746017456, 0.9991963505744934, 0.9981248378753662, 0.9957138895988464, 0.9991963505744934, 0.999464213848114, 0.997053325176239, 0.997053325176239, 0.9983927011489868, 0.9997321367263794, 0.9991963505744934, 0.9986606240272522, 0.9991963505744934, 0.9981248378753662, 0.9983927011489868, 0.9983927011489868, 0.9983927011489868, 0.997053325176239, 0.9983927011489868, 0.999464213848114], 'val_loss': [0.6494879126548767, 0.6401551365852356, 0.6290845274925232, 0.6209712028503418, 0.6008700132369995, 0.5901885628700256, 0.5672469735145569, 0.5329563021659851, 0.5066280364990234, 0.47190895676612854, 0.44613632559776306, 0.4057804048061371, 0.37176814675331116, 0.3245542049407959, 0.2970086634159088, 0.27551859617233276, 0.24052971601486206, 0.225101500749588, 0.22222574055194855, 0.2259395569562912, 0.2318023443222046, 0.23706422746181488, 0.2610666751861572, 0.27151376008987427, 0.2829316258430481, 0.29013514518737793, 0.30379968881607056, 0.3186663091182709, 0.3344334661960602, 0.3455338478088379, 0.40513700246810913, 0.3313288688659668, 0.34347206354141235, 0.3785357177257538, 0.3662811517715454, 0.3604627847671509, 0.37583285570144653, 0.3745177388191223, 0.3797578811645508, 0.39409348368644714, 0.3916744291782379, 0.4281148314476013, 0.3926694691181183, 0.39495131373405457, 0.4018949568271637, 0.4004889726638794, 0.39527374505996704, 0.39725369215011597, 0.4168291985988617, 0.3941652774810791, 0.401492714881897, 0.4099333584308624, 0.4244373142719269, 0.42329129576683044, 0.4089185893535614, 0.4236169457435608, 0.41903164982795715, 0.4583539664745331, 0.4238777756690979, 0.45538806915283203, 0.47351446747779846, 0.42905792593955994, 0.4351619780063629, 0.47061625123023987, 0.424084335565567, 0.43270424008369446, 0.42541393637657166, 0.4369394779205322, 0.43184521794319153, 0.43352580070495605, 0.44438111782073975, 0.509667694568634, 0.4770062565803528, 0.44646158814430237, 0.45293059945106506, 0.437107652425766, 0.43705618381500244, 0.42399755120277405, 0.4325487017631531, 0.44677630066871643, 0.44814378023147583, 0.4534098505973816, 0.4701322615146637, 0.4602256119251251, 0.4826827645301819, 0.4686044156551361, 0.5181103944778442, 0.4672905504703522, 0.4951436221599579, 0.4694380760192871, 0.4829385578632355, 0.495870977640152, 0.4895385801792145, 0.48954257369041443, 0.5128412246704102, 0.5010367035865784, 0.5192974209785461, 0.5503088235855103, 0.5048810243606567, 0.5096845030784607], 'val_accuracy': [0.5385438799858093, 0.5920770764350891, 0.6209850311279297, 0.6220556497573853, 0.7130621075630188, 0.705567479133606, 0.7558886408805847, 0.8543897271156311, 0.8822270035743713, 0.9122055768966675, 0.9079229235649109, 0.9175589084625244, 0.9175589084625244, 0.91862952709198, 0.9250535368919373, 0.9164882302284241, 0.9207708835601807, 0.9197002053260803, 0.9207708835601807, 0.9164882302284241, 0.9164882302284241, 0.9164882302284241, 0.9175589084625244, 0.9111348986625671, 0.921841561794281, 0.9164882302284241, 0.9175589084625244, 0.9207708835601807, 0.91862952709198, 0.9229121804237366, 0.8875802755355835, 0.9207708835601807, 0.9250535368919373, 0.91862952709198, 0.9207708835601807, 0.91862952709198, 0.9122055768966675, 0.91862952709198, 0.9164882302284241, 0.9175589084625244, 0.9154175519943237, 0.9111348986625671, 0.91862952709198, 0.91862952709198, 0.9164882302284241, 0.9143468737602234, 0.9175589084625244, 0.9175589084625244, 0.9154175519943237, 0.921841561794281, 0.9197002053260803, 0.9175589084625244, 0.9154175519943237, 0.9132762551307678, 0.9154175519943237, 0.9132762551307678, 0.9175589084625244, 0.9079229235649109, 0.9175589084625244, 0.9111348986625671, 0.9089936017990112, 0.9175589084625244, 0.9175589084625244, 0.9143468737602234, 0.9100642204284668, 0.9175589084625244, 0.9197002053260803, 0.9111348986625671, 0.9164882302284241, 0.91862952709198, 0.9154175519943237, 0.8961455821990967, 0.9143468737602234, 0.9089936017990112, 0.9143468737602234, 0.9154175519943237, 0.9175589084625244, 0.9197002053260803, 0.9122055768966675, 0.9164882302284241, 0.9132762551307678, 0.9132762551307678, 0.9143468737602234, 0.9154175519943237, 0.9079229235649109, 0.9154175519943237, 0.9068522453308105, 0.9132762551307678, 0.9100642204284668, 0.9143468737602234, 0.9197002053260803, 0.9132762551307678, 0.9068522453308105, 0.9068522453308105, 0.897216260433197, 0.9175589084625244, 0.9111348986625671, 0.9100642204284668, 0.9143468737602234, 0.9122055768966675]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 7s 45ms/step - loss: 0.0665 - accuracy: 0.9799 - val_loss: 0.6596 - val_accuracy: 0.5096\n","Epoch 2/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0340 - accuracy: 0.9890 - val_loss: 0.6441 - val_accuracy: 0.5375\n","Epoch 3/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0327 - accuracy: 0.9893 - val_loss: 0.6200 - val_accuracy: 0.6210\n","Epoch 4/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0295 - accuracy: 0.9920 - val_loss: 0.6034 - val_accuracy: 0.6713\n","Epoch 5/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0286 - accuracy: 0.9896 - val_loss: 0.5903 - val_accuracy: 0.6831\n","Epoch 6/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 0.5722 - val_accuracy: 0.7077\n","Epoch 7/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0197 - accuracy: 0.9930 - val_loss: 0.5368 - val_accuracy: 0.8094\n","Epoch 8/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0183 - accuracy: 0.9944 - val_loss: 0.5148 - val_accuracy: 0.8276\n","Epoch 9/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0204 - accuracy: 0.9922 - val_loss: 0.4974 - val_accuracy: 0.8009\n","Epoch 10/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0128 - accuracy: 0.9976 - val_loss: 0.4479 - val_accuracy: 0.8694\n","Epoch 11/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.4024 - val_accuracy: 0.9165\n","Epoch 12/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0252 - accuracy: 0.9914 - val_loss: 0.3865 - val_accuracy: 0.8801\n","Epoch 13/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0161 - accuracy: 0.9954 - val_loss: 0.3350 - val_accuracy: 0.9229\n","Epoch 14/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.2967 - val_accuracy: 0.9176\n","Epoch 15/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.2664 - val_accuracy: 0.9165\n","Epoch 16/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.2433 - val_accuracy: 0.9197\n","Epoch 17/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.0166 - accuracy: 0.9938 - val_loss: 0.2267 - val_accuracy: 0.9218\n","Epoch 18/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.2159 - val_accuracy: 0.9186\n","Epoch 19/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0145 - accuracy: 0.9960 - val_loss: 0.2134 - val_accuracy: 0.9261\n","Epoch 20/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 0.2223 - val_accuracy: 0.9229\n","Epoch 21/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.0122 - accuracy: 0.9971 - val_loss: 0.2372 - val_accuracy: 0.9197\n","Epoch 22/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.2360 - val_accuracy: 0.9240\n","Epoch 23/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.2468 - val_accuracy: 0.9293\n","Epoch 24/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0116 - accuracy: 0.9976 - val_loss: 0.3094 - val_accuracy: 0.9165\n","Epoch 25/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.3073 - val_accuracy: 0.9229\n","Epoch 26/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.3401 - val_accuracy: 0.9176\n","Epoch 27/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0169 - accuracy: 0.9936 - val_loss: 0.3659 - val_accuracy: 0.9090\n","Epoch 28/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0396 - accuracy: 0.9855 - val_loss: 0.3589 - val_accuracy: 0.9111\n","Epoch 29/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0169 - accuracy: 0.9952 - val_loss: 0.3543 - val_accuracy: 0.9186\n","Epoch 30/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.3668 - val_accuracy: 0.9154\n","Epoch 31/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.4159 - val_accuracy: 0.9069\n","Epoch 32/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0122 - accuracy: 0.9941 - val_loss: 0.3910 - val_accuracy: 0.9133\n","Epoch 33/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0122 - accuracy: 0.9979 - val_loss: 0.3513 - val_accuracy: 0.9251\n","Epoch 34/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0109 - accuracy: 0.9973 - val_loss: 0.3733 - val_accuracy: 0.9229\n","Epoch 35/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.3935 - val_accuracy: 0.9154\n","Epoch 36/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.3853 - val_accuracy: 0.9154\n","Epoch 37/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0124 - accuracy: 0.9954 - val_loss: 0.4099 - val_accuracy: 0.9186\n","Epoch 38/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0116 - accuracy: 0.9957 - val_loss: 0.3907 - val_accuracy: 0.9186\n","Epoch 39/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.3774 - val_accuracy: 0.9229\n","Epoch 40/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.4206 - val_accuracy: 0.9090\n","Epoch 41/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0135 - accuracy: 0.9946 - val_loss: 0.4479 - val_accuracy: 0.9058\n","Epoch 42/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0061 - accuracy: 0.9992 - val_loss: 0.4043 - val_accuracy: 0.9143\n","Epoch 43/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.4359 - val_accuracy: 0.9143\n","Epoch 44/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0095 - accuracy: 0.9965 - val_loss: 0.3844 - val_accuracy: 0.9208\n","Epoch 45/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.4154 - val_accuracy: 0.9176\n","Epoch 46/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.3913 - val_accuracy: 0.9261\n","Epoch 47/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.4101 - val_accuracy: 0.9197\n","Epoch 48/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 0.4226 - val_accuracy: 0.9186\n","Epoch 49/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0220 - accuracy: 0.9914 - val_loss: 0.5087 - val_accuracy: 0.8951\n","Epoch 50/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0128 - accuracy: 0.9949 - val_loss: 0.4738 - val_accuracy: 0.9101\n","Epoch 51/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.4256 - val_accuracy: 0.9208\n","Epoch 52/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.4942 - val_accuracy: 0.9101\n","Epoch 53/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.4493 - val_accuracy: 0.9154\n","Epoch 54/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0049 - accuracy: 0.9981 - val_loss: 0.4349 - val_accuracy: 0.9186\n","Epoch 55/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.4510 - val_accuracy: 0.9165\n","Epoch 56/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.4268 - val_accuracy: 0.9186\n","Epoch 57/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.4553 - val_accuracy: 0.9154\n","Epoch 58/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.4431 - val_accuracy: 0.9186\n","Epoch 59/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.4623 - val_accuracy: 0.9165\n","Epoch 60/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.4881 - val_accuracy: 0.9143\n","Epoch 61/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.4406 - val_accuracy: 0.9176\n","Epoch 62/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.4655 - val_accuracy: 0.9143\n","Epoch 63/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.4500 - val_accuracy: 0.9186\n","Epoch 64/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.5214 - val_accuracy: 0.9122\n","Epoch 65/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.4816 - val_accuracy: 0.9154\n","Epoch 66/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.4775 - val_accuracy: 0.9186\n","Epoch 67/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.4644 - val_accuracy: 0.9154\n","Epoch 68/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.4710 - val_accuracy: 0.9251\n","Epoch 69/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.4994 - val_accuracy: 0.9101\n","Epoch 70/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.5083 - val_accuracy: 0.9047\n","Epoch 71/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.5406 - val_accuracy: 0.8994\n","Epoch 72/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.4717 - val_accuracy: 0.9176\n","Epoch 73/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.0167 - accuracy: 0.9933 - val_loss: 0.4742 - val_accuracy: 0.9111\n","Epoch 74/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0112 - accuracy: 0.9957 - val_loss: 0.4650 - val_accuracy: 0.9133\n","Epoch 75/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.4495 - val_accuracy: 0.9229\n","Epoch 76/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.4680 - val_accuracy: 0.9176\n","Epoch 77/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.5000 - val_accuracy: 0.9111\n","Epoch 78/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.4485 - val_accuracy: 0.9186\n","Epoch 79/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0101 - accuracy: 0.9954 - val_loss: 0.4451 - val_accuracy: 0.9229\n","Epoch 80/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.4841 - val_accuracy: 0.9143\n","Epoch 81/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.5322 - val_accuracy: 0.9090\n","Epoch 82/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.4967 - val_accuracy: 0.9111\n","Epoch 83/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.5000 - val_accuracy: 0.9133\n","Epoch 84/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0071 - accuracy: 0.9973 - val_loss: 0.5343 - val_accuracy: 0.9047\n","Epoch 85/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.4889 - val_accuracy: 0.9143\n","Epoch 86/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.4722 - val_accuracy: 0.9154\n","Epoch 87/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.4860 - val_accuracy: 0.9101\n","Epoch 88/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0047 - accuracy: 0.9981 - val_loss: 0.4603 - val_accuracy: 0.9165\n","Epoch 89/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.5160 - val_accuracy: 0.9133\n","Epoch 90/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0230 - accuracy: 0.9922 - val_loss: 0.5513 - val_accuracy: 0.9101\n","Epoch 91/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0140 - accuracy: 0.9944 - val_loss: 0.4945 - val_accuracy: 0.9090\n","Epoch 92/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.4867 - val_accuracy: 0.9111\n","Epoch 93/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.5196 - val_accuracy: 0.9111\n","Epoch 94/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.5211 - val_accuracy: 0.9090\n","Epoch 95/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.5076 - val_accuracy: 0.9047\n","Epoch 96/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.4743 - val_accuracy: 0.9165\n","Epoch 97/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5116 - val_accuracy: 0.9079\n","Epoch 98/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0078 - accuracy: 0.9971 - val_loss: 0.5449 - val_accuracy: 0.9101\n","Epoch 99/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.4734 - val_accuracy: 0.9154\n","Epoch 100/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.4916 - val_accuracy: 0.9176\n","{'loss': [0.0664755180478096, 0.03395663946866989, 0.032661013305187225, 0.02947835624217987, 0.02858254313468933, 0.026015689596533775, 0.019709324464201927, 0.018333658576011658, 0.02041882649064064, 0.01279741432517767, 0.013964741490781307, 0.02519230544567108, 0.01607672870159149, 0.012105886824429035, 0.013181700371205807, 0.011844666674733162, 0.016557421535253525, 0.01248292624950409, 0.014460342936217785, 0.012813704088330269, 0.012158951722085476, 0.011298557743430138, 0.01583130471408367, 0.01161271333694458, 0.010988199152052402, 0.017483631148934364, 0.016894636675715446, 0.039649367332458496, 0.016928333789110184, 0.00921219028532505, 0.008579539135098457, 0.01221710816025734, 0.012162252329289913, 0.010928191244602203, 0.009318286553025246, 0.008556848391890526, 0.012427415698766708, 0.011642816476523876, 0.012688979506492615, 0.013028656132519245, 0.013475974090397358, 0.006096080411225557, 0.008387122303247452, 0.009547149762511253, 0.006023022346198559, 0.007875816896557808, 0.006923227105289698, 0.008068390190601349, 0.021954284980893135, 0.012796160764992237, 0.008901563473045826, 0.006162701174616814, 0.00647853733971715, 0.0049263178370893, 0.006440491881221533, 0.004687279462814331, 0.004805727396160364, 0.006081634201109409, 0.005892714951187372, 0.0067057982087135315, 0.005541766062378883, 0.005127946846187115, 0.005174925085157156, 0.00840530265122652, 0.004614387173205614, 0.004285313654690981, 0.003863731399178505, 0.0032194515224546194, 0.004116892348974943, 0.007319629658013582, 0.01504049077630043, 0.013212504796683788, 0.016681671142578125, 0.01123717799782753, 0.005537107586860657, 0.005347284954041243, 0.0043936436995863914, 0.005280870478600264, 0.010133507661521435, 0.005890571046620607, 0.006603114306926727, 0.011132044717669487, 0.009511002339422703, 0.007072694133967161, 0.003967424388974905, 0.008252633735537529, 0.006652513053268194, 0.004656354896724224, 0.0035124686546623707, 0.022980181500315666, 0.014047392643988132, 0.004365650005638599, 0.005794536788016558, 0.005366019904613495, 0.004859297536313534, 0.0053975870832800865, 0.0019709335174411535, 0.007821251638233662, 0.0029288840014487505, 0.003991175442934036], 'accuracy': [0.9799089431762695, 0.9890168905258179, 0.9892847537994385, 0.9919635653495789, 0.9895526170730591, 0.9916957020759583, 0.993035078048706, 0.9943745136260986, 0.9922314286231995, 0.9975890517234802, 0.9951781630516052, 0.9914277791976929, 0.9954460263252258, 0.9957138895988464, 0.9962496757507324, 0.9959818124771118, 0.9938387274742126, 0.9954460263252258, 0.9959818124771118, 0.996517539024353, 0.997053325176239, 0.996517539024353, 0.9951781630516052, 0.9975890517234802, 0.997053325176239, 0.9943745136260986, 0.993570864200592, 0.9855344295501709, 0.9951781630516052, 0.9973211884498596, 0.997053325176239, 0.9941065907478333, 0.9978569746017456, 0.9973211884498596, 0.997053325176239, 0.9973211884498596, 0.9954460263252258, 0.9957138895988464, 0.9957138895988464, 0.996517539024353, 0.9946423768997192, 0.9991963505744934, 0.9973211884498596, 0.996517539024353, 0.9986606240272522, 0.9975890517234802, 0.9983927011489868, 0.9981248378753662, 0.9914277791976929, 0.9949102401733398, 0.9973211884498596, 0.9986606240272522, 0.9986606240272522, 0.9981248378753662, 0.9978569746017456, 0.9991963505744934, 0.9989284873008728, 0.9986606240272522, 0.9986606240272522, 0.9975890517234802, 0.9978569746017456, 0.9989284873008728, 0.9983927011489868, 0.9975890517234802, 0.9991963505744934, 0.9989284873008728, 0.9989284873008728, 0.9991963505744934, 0.999464213848114, 0.9981248378753662, 0.9954460263252258, 0.9957138895988464, 0.9933030009269714, 0.9957138895988464, 0.9983927011489868, 0.9986606240272522, 0.9989284873008728, 0.9983927011489868, 0.9954460263252258, 0.9981248378753662, 0.9981248378753662, 0.9962496757507324, 0.9975890517234802, 0.9973211884498596, 0.9989284873008728, 0.9975890517234802, 0.9983927011489868, 0.9981248378753662, 0.9991963505744934, 0.9922314286231995, 0.9943745136260986, 0.9989284873008728, 0.9978569746017456, 0.9983927011489868, 0.9986606240272522, 0.9981248378753662, 1.0, 0.997053325176239, 0.9991963505744934, 0.9983927011489868], 'val_loss': [0.659619152545929, 0.64410400390625, 0.6199537515640259, 0.603351891040802, 0.5903444290161133, 0.5722196698188782, 0.5367820262908936, 0.5148332118988037, 0.4973856508731842, 0.4479491114616394, 0.40237241983413696, 0.3864800035953522, 0.3350124657154083, 0.29668989777565, 0.26635468006134033, 0.24329061806201935, 0.2266601026058197, 0.2159179151058197, 0.21335472166538239, 0.22231735289096832, 0.2371777594089508, 0.23603780567646027, 0.2468142807483673, 0.3093574047088623, 0.30729755759239197, 0.3401390612125397, 0.36594873666763306, 0.3588612377643585, 0.35427042841911316, 0.3668072819709778, 0.4159036874771118, 0.3909597396850586, 0.35128745436668396, 0.3732857406139374, 0.39346763491630554, 0.38531479239463806, 0.4099474847316742, 0.3906662166118622, 0.3774413764476776, 0.42055395245552063, 0.44793570041656494, 0.4042758643627167, 0.43590936064720154, 0.3844166100025177, 0.41543489694595337, 0.3912849426269531, 0.41009974479675293, 0.42256489396095276, 0.5087037682533264, 0.4738368093967438, 0.4256089925765991, 0.49416863918304443, 0.44934558868408203, 0.4348788261413574, 0.4509677588939667, 0.42683517932891846, 0.4552580416202545, 0.4431328773498535, 0.4622502028942108, 0.48811060190200806, 0.4406176805496216, 0.46553584933280945, 0.4500488042831421, 0.5213856101036072, 0.48158934712409973, 0.47753024101257324, 0.4644392728805542, 0.47099506855010986, 0.49939990043640137, 0.5083269476890564, 0.5406200289726257, 0.47174784541130066, 0.4741787612438202, 0.4649733603000641, 0.44953039288520813, 0.4679792821407318, 0.5000298619270325, 0.44845113158226013, 0.44509342312812805, 0.48413902521133423, 0.532188355922699, 0.49674132466316223, 0.5000457167625427, 0.5343295335769653, 0.4889209568500519, 0.47218072414398193, 0.4860445559024811, 0.4603302776813507, 0.5160356760025024, 0.5513114333152771, 0.4945175349712372, 0.486685574054718, 0.5196119546890259, 0.5210551619529724, 0.5075750350952148, 0.47429823875427246, 0.5115821361541748, 0.5449499487876892, 0.47344180941581726, 0.4916028082370758], 'val_accuracy': [0.5096359848976135, 0.5374732613563538, 0.6209850311279297, 0.6713061928749084, 0.6830835342407227, 0.7077087759971619, 0.8094218373298645, 0.8276231288909912, 0.8008565306663513, 0.8693790435791016, 0.9164882302284241, 0.8800856471061707, 0.9229121804237366, 0.9175589084625244, 0.9164882302284241, 0.9197002053260803, 0.921841561794281, 0.91862952709198, 0.9261242151260376, 0.9229121804237366, 0.9197002053260803, 0.9239828586578369, 0.9293361902236938, 0.9164882302284241, 0.9229121804237366, 0.9175589084625244, 0.9089936017990112, 0.9111348986625671, 0.91862952709198, 0.9154175519943237, 0.9068522453308105, 0.9132762551307678, 0.9250535368919373, 0.9229121804237366, 0.9154175519943237, 0.9154175519943237, 0.91862952709198, 0.91862952709198, 0.9229121804237366, 0.9089936017990112, 0.9057815670967102, 0.9143468737602234, 0.9143468737602234, 0.9207708835601807, 0.9175589084625244, 0.9261242151260376, 0.9197002053260803, 0.91862952709198, 0.8950749635696411, 0.9100642204284668, 0.9207708835601807, 0.9100642204284668, 0.9154175519943237, 0.91862952709198, 0.9164882302284241, 0.91862952709198, 0.9154175519943237, 0.91862952709198, 0.9164882302284241, 0.9143468737602234, 0.9175589084625244, 0.9143468737602234, 0.91862952709198, 0.9122055768966675, 0.9154175519943237, 0.91862952709198, 0.9154175519943237, 0.9250535368919373, 0.9100642204284668, 0.9047109484672546, 0.8993576169013977, 0.9175589084625244, 0.9111348986625671, 0.9132762551307678, 0.9229121804237366, 0.9175589084625244, 0.9111348986625671, 0.91862952709198, 0.9229121804237366, 0.9143468737602234, 0.9089936017990112, 0.9111348986625671, 0.9132762551307678, 0.9047109484672546, 0.9143468737602234, 0.9154175519943237, 0.9100642204284668, 0.9164882302284241, 0.9132762551307678, 0.9100642204284668, 0.9089936017990112, 0.9111348986625671, 0.9111348986625671, 0.9089936017990112, 0.9047109484672546, 0.9164882302284241, 0.9079229235649109, 0.9100642204284668, 0.9154175519943237, 0.9175589084625244]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 7s 47ms/step - loss: 0.0440 - accuracy: 0.9855 - val_loss: 0.6595 - val_accuracy: 0.4989\n","Epoch 2/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0343 - accuracy: 0.9893 - val_loss: 0.6289 - val_accuracy: 0.5835\n","Epoch 3/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.0271 - accuracy: 0.9922 - val_loss: 0.6234 - val_accuracy: 0.5728\n","Epoch 4/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0221 - accuracy: 0.9917 - val_loss: 0.6010 - val_accuracy: 0.6435\n","Epoch 5/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0167 - accuracy: 0.9941 - val_loss: 0.5853 - val_accuracy: 0.6809\n","Epoch 6/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: 0.5548 - val_accuracy: 0.7837\n","Epoch 7/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0209 - accuracy: 0.9941 - val_loss: 0.5292 - val_accuracy: 0.8191\n","Epoch 8/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.4944 - val_accuracy: 0.8737\n","Epoch 9/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.4621 - val_accuracy: 0.8854\n","Epoch 10/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.4227 - val_accuracy: 0.9101\n","Epoch 11/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 0.3934 - val_accuracy: 0.9079\n","Epoch 12/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0151 - accuracy: 0.9938 - val_loss: 0.3482 - val_accuracy: 0.9379\n","Epoch 13/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.3125 - val_accuracy: 0.9336\n","Epoch 14/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.2693 - val_accuracy: 0.9422\n","Epoch 15/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0205 - accuracy: 0.9925 - val_loss: 0.2338 - val_accuracy: 0.9454\n","Epoch 16/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0251 - accuracy: 0.9914 - val_loss: 0.2070 - val_accuracy: 0.9400\n","Epoch 17/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0178 - accuracy: 0.9941 - val_loss: 0.1854 - val_accuracy: 0.9411\n","Epoch 18/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0108 - accuracy: 0.9971 - val_loss: 0.1698 - val_accuracy: 0.9411\n","Epoch 19/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0109 - accuracy: 0.9973 - val_loss: 0.1613 - val_accuracy: 0.9454\n","Epoch 20/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0112 - accuracy: 0.9952 - val_loss: 0.1648 - val_accuracy: 0.9422\n","Epoch 21/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0094 - accuracy: 0.9981 - val_loss: 0.1806 - val_accuracy: 0.9390\n","Epoch 22/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.1732 - val_accuracy: 0.9454\n","Epoch 23/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.1949 - val_accuracy: 0.9443\n","Epoch 24/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.2028 - val_accuracy: 0.9368\n","Epoch 25/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.2048 - val_accuracy: 0.9465\n","Epoch 26/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0137 - accuracy: 0.9952 - val_loss: 0.2298 - val_accuracy: 0.9411\n","Epoch 27/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.2390 - val_accuracy: 0.9433\n","Epoch 28/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.2479 - val_accuracy: 0.9422\n","Epoch 29/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0080 - accuracy: 0.9981 - val_loss: 0.2452 - val_accuracy: 0.9454\n","Epoch 30/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.2658 - val_accuracy: 0.9400\n","Epoch 31/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.3360 - val_accuracy: 0.9283\n","Epoch 32/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.2742 - val_accuracy: 0.9379\n","Epoch 33/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.2966 - val_accuracy: 0.9390\n","Epoch 34/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0177 - accuracy: 0.9949 - val_loss: 0.3260 - val_accuracy: 0.9325\n","Epoch 35/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0077 - accuracy: 0.9984 - val_loss: 0.2802 - val_accuracy: 0.9390\n","Epoch 36/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.2607 - val_accuracy: 0.9422\n","Epoch 37/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0080 - accuracy: 0.9971 - val_loss: 0.2690 - val_accuracy: 0.9411\n","Epoch 38/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0220 - accuracy: 0.9928 - val_loss: 0.2878 - val_accuracy: 0.9368\n","Epoch 39/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 0.2851 - val_accuracy: 0.9433\n","Epoch 40/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.2731 - val_accuracy: 0.9400\n","Epoch 41/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.2778 - val_accuracy: 0.9411\n","Epoch 42/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0076 - accuracy: 0.9987 - val_loss: 0.2932 - val_accuracy: 0.9379\n","Epoch 43/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.3466 - val_accuracy: 0.9347\n","Epoch 44/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0106 - accuracy: 0.9962 - val_loss: 0.2802 - val_accuracy: 0.9465\n","Epoch 45/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.2839 - val_accuracy: 0.9433\n","Epoch 46/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.2957 - val_accuracy: 0.9358\n","Epoch 47/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.2991 - val_accuracy: 0.9368\n","Epoch 48/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.3182 - val_accuracy: 0.9358\n","Epoch 49/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.3170 - val_accuracy: 0.9358\n","Epoch 50/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.3014 - val_accuracy: 0.9379\n","Epoch 51/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 0.3108 - val_accuracy: 0.9390\n","Epoch 52/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.2983 - val_accuracy: 0.9358\n","Epoch 53/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.3053 - val_accuracy: 0.9379\n","Epoch 54/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.3076 - val_accuracy: 0.9390\n","Epoch 55/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.3543 - val_accuracy: 0.9325\n","Epoch 56/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.3003 - val_accuracy: 0.9379\n","Epoch 57/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.3470 - val_accuracy: 0.9347\n","Epoch 58/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0246 - accuracy: 0.9885 - val_loss: 0.3208 - val_accuracy: 0.9315\n","Epoch 59/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0267 - accuracy: 0.9901 - val_loss: 0.4305 - val_accuracy: 0.9133\n","Epoch 60/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0342 - accuracy: 0.9877 - val_loss: 0.3780 - val_accuracy: 0.9261\n","Epoch 61/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0290 - accuracy: 0.9896 - val_loss: 0.3042 - val_accuracy: 0.9293\n","Epoch 62/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0095 - accuracy: 0.9981 - val_loss: 0.3305 - val_accuracy: 0.9347\n","Epoch 63/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.3109 - val_accuracy: 0.9390\n","Epoch 64/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.3123 - val_accuracy: 0.9368\n","Epoch 65/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.3481 - val_accuracy: 0.9304\n","Epoch 66/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.3360 - val_accuracy: 0.9347\n","Epoch 67/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.3229 - val_accuracy: 0.9358\n","Epoch 68/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.3357 - val_accuracy: 0.9358\n","Epoch 69/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 0.3466 - val_accuracy: 0.9347\n","Epoch 70/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.3000 - val_accuracy: 0.9400\n","Epoch 71/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.3463 - val_accuracy: 0.9336\n","Epoch 72/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.3243 - val_accuracy: 0.9379\n","Epoch 73/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.3118 - val_accuracy: 0.9368\n","Epoch 74/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.3016 - val_accuracy: 0.9347\n","Epoch 75/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.3105 - val_accuracy: 0.9347\n","Epoch 76/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.3292 - val_accuracy: 0.9315\n","Epoch 77/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.3328 - val_accuracy: 0.9358\n","Epoch 78/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.4094 - val_accuracy: 0.9176\n","Epoch 79/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.3360 - val_accuracy: 0.9347\n","Epoch 80/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.3262 - val_accuracy: 0.9336\n","Epoch 81/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.3555 - val_accuracy: 0.9293\n","Epoch 82/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.3791 - val_accuracy: 0.9218\n","Epoch 83/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0178 - accuracy: 0.9936 - val_loss: 0.3498 - val_accuracy: 0.9368\n","Epoch 84/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.3603 - val_accuracy: 0.9368\n","Epoch 85/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.3534 - val_accuracy: 0.9325\n","Epoch 86/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.3638 - val_accuracy: 0.9304\n","Epoch 87/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.4141 - val_accuracy: 0.9251\n","Epoch 88/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.3653 - val_accuracy: 0.9358\n","Epoch 89/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.3514 - val_accuracy: 0.9304\n","Epoch 90/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.3494 - val_accuracy: 0.9325\n","Epoch 91/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.3770 - val_accuracy: 0.9325\n","Epoch 92/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.3552 - val_accuracy: 0.9315\n","Epoch 93/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.3747 - val_accuracy: 0.9261\n","Epoch 94/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.3851 - val_accuracy: 0.9272\n","Epoch 95/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.3444 - val_accuracy: 0.9315\n","Epoch 96/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.3561 - val_accuracy: 0.9283\n","Epoch 97/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.3325 - val_accuracy: 0.9347\n","Epoch 98/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.3708 - val_accuracy: 0.9240\n","Epoch 99/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.3570 - val_accuracy: 0.9347\n","Epoch 100/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.3643 - val_accuracy: 0.9283\n","{'loss': [0.04403412342071533, 0.034255675971508026, 0.02710258960723877, 0.022071251645684242, 0.016740184277296066, 0.024092013016343117, 0.020886646583676338, 0.013197760097682476, 0.011288848705589771, 0.018673671409487724, 0.020928220823407173, 0.015075527131557465, 0.01050390861928463, 0.016298534348607063, 0.020522315055131912, 0.025129036977887154, 0.017807455733418465, 0.010835285298526287, 0.010863409377634525, 0.011240910738706589, 0.009391723200678825, 0.009723828174173832, 0.011161873117089272, 0.010078009217977524, 0.008685498498380184, 0.013728002086281776, 0.009070676751434803, 0.008884838782250881, 0.008008993230760098, 0.007022492121905088, 0.008237836882472038, 0.01084117405116558, 0.0065873353742063046, 0.01767728291451931, 0.007732566446065903, 0.014897813089191914, 0.007986849173903465, 0.02195053920149803, 0.011073505505919456, 0.01074738148599863, 0.006578662432730198, 0.007574493531137705, 0.007818535901606083, 0.010624600574374199, 0.0050574238412082195, 0.006926874164491892, 0.009422688744962215, 0.009264237247407436, 0.005955533590167761, 0.004751021973788738, 0.007506353314965963, 0.005810838658362627, 0.004902559798210859, 0.0048425705172121525, 0.006152932066470385, 0.008418579585850239, 0.0048399255611002445, 0.024579748511314392, 0.02670639008283615, 0.034153152257204056, 0.028972359374165535, 0.009496768936514854, 0.005519059952348471, 0.004554553423076868, 0.005509808659553528, 0.004716136492788792, 0.0033743642270565033, 0.005829280707985163, 0.007416451349854469, 0.006251354236155748, 0.0052770813927054405, 0.005836210213601589, 0.006892066448926926, 0.007651256863027811, 0.004501232411712408, 0.0034727980382740498, 0.0036805751733481884, 0.0038434104062616825, 0.004679202567785978, 0.002909537171944976, 0.0042472411878407, 0.0028879072051495314, 0.017843691632151604, 0.008351217955350876, 0.0038429510314017534, 0.0034420080482959747, 0.003595049260184169, 0.007992898114025593, 0.0030247983522713184, 0.002691927831619978, 0.0025188096333295107, 0.006564683746546507, 0.007123210001736879, 0.006453284528106451, 0.005309559870511293, 0.003636989975348115, 0.0026941592805087566, 0.0026689062360674143, 0.001839512144215405, 0.0020927665755152702], 'accuracy': [0.9855344295501709, 0.9892847537994385, 0.9922314286231995, 0.9916957020759583, 0.9941065907478333, 0.9922314286231995, 0.9941065907478333, 0.9959818124771118, 0.997053325176239, 0.9933030009269714, 0.993570864200592, 0.9938387274742126, 0.997053325176239, 0.9949102401733398, 0.9924993515014648, 0.9914277791976929, 0.9941065907478333, 0.997053325176239, 0.9973211884498596, 0.9951781630516052, 0.9981248378753662, 0.997053325176239, 0.9967854022979736, 0.997053325176239, 0.997053325176239, 0.9951781630516052, 0.9973211884498596, 0.9975890517234802, 0.9981248378753662, 0.9981248378753662, 0.9978569746017456, 0.996517539024353, 0.9983927011489868, 0.9949102401733398, 0.9983927011489868, 0.9949102401733398, 0.997053325176239, 0.9927672147750854, 0.9959818124771118, 0.9962496757507324, 0.9986606240272522, 0.9986606240272522, 0.9978569746017456, 0.9962496757507324, 0.9989284873008728, 0.9978569746017456, 0.9975890517234802, 0.9973211884498596, 0.9986606240272522, 0.9983927011489868, 0.9981248378753662, 0.9983927011489868, 0.9983927011489868, 0.9991963505744934, 0.9978569746017456, 0.997053325176239, 0.9986606240272522, 0.9884811043739319, 0.9900884032249451, 0.9876774549484253, 0.9895526170730591, 0.9981248378753662, 0.9981248378753662, 0.9991963505744934, 0.9981248378753662, 0.9983927011489868, 0.9997321367263794, 0.9986606240272522, 0.9973211884498596, 0.9978569746017456, 0.9986606240272522, 0.9981248378753662, 0.9978569746017456, 0.9975890517234802, 0.9983927011489868, 0.999464213848114, 0.9989284873008728, 0.9991963505744934, 0.9986606240272522, 0.999464213848114, 0.9986606240272522, 0.999464213848114, 0.993570864200592, 0.9978569746017456, 0.999464213848114, 0.9989284873008728, 0.9986606240272522, 0.9973211884498596, 0.999464213848114, 0.9991963505744934, 0.999464213848114, 0.9983927011489868, 0.9975890517234802, 0.9983927011489868, 0.9983927011489868, 0.9989284873008728, 0.9989284873008728, 0.9989284873008728, 0.9997321367263794, 0.9997321367263794], 'val_loss': [0.6594880819320679, 0.6288704872131348, 0.6233862638473511, 0.6009528636932373, 0.5853450298309326, 0.5547894239425659, 0.5291733145713806, 0.4943516254425049, 0.4621364176273346, 0.4226923882961273, 0.3933587372303009, 0.3481520712375641, 0.3125033974647522, 0.269258975982666, 0.2337561398744583, 0.20699402689933777, 0.1853916198015213, 0.16975003480911255, 0.16128526628017426, 0.1648198366165161, 0.18060137331485748, 0.17316092550754547, 0.1949170082807541, 0.20278267562389374, 0.20475079119205475, 0.2297559529542923, 0.23897720873355865, 0.24791927635669708, 0.2452201098203659, 0.2657591700553894, 0.3359890878200531, 0.2741960287094116, 0.296578973531723, 0.3260049819946289, 0.28021541237831116, 0.2606789469718933, 0.269008994102478, 0.28777068853378296, 0.2851063907146454, 0.27310431003570557, 0.27778807282447815, 0.293163925409317, 0.3465777039527893, 0.28015679121017456, 0.2839241325855255, 0.2956712543964386, 0.2990933358669281, 0.31816011667251587, 0.316985160112381, 0.3014240562915802, 0.31082627177238464, 0.2983036935329437, 0.30526119470596313, 0.30764955282211304, 0.35429057478904724, 0.30025917291641235, 0.3470146954059601, 0.320841908454895, 0.43053439259529114, 0.3780471086502075, 0.3041929304599762, 0.33049386739730835, 0.31085386872291565, 0.3123444616794586, 0.34806084632873535, 0.33595922589302063, 0.3228764533996582, 0.3356698751449585, 0.3466435968875885, 0.29997146129608154, 0.34626996517181396, 0.3243124783039093, 0.3117519021034241, 0.30155280232429504, 0.31051504611968994, 0.3292424976825714, 0.33280137181282043, 0.40935271978378296, 0.3359549939632416, 0.32615190744400024, 0.35554492473602295, 0.3791073262691498, 0.3497946560382843, 0.3602989614009857, 0.3534180223941803, 0.36382269859313965, 0.4141160547733307, 0.3652738630771637, 0.3513972759246826, 0.34937775135040283, 0.3769935965538025, 0.3552014231681824, 0.3746803104877472, 0.38506001234054565, 0.3443537652492523, 0.3560566306114197, 0.33251798152923584, 0.37084656953811646, 0.35704824328422546, 0.3643151819705963], 'val_accuracy': [0.49892932176589966, 0.5835117697715759, 0.5728051662445068, 0.643468976020813, 0.680942177772522, 0.783725917339325, 0.819057822227478, 0.8736616969108582, 0.8854389786720276, 0.9100642204284668, 0.9079229235649109, 0.937901496887207, 0.9336188435554504, 0.9421841502189636, 0.9453961253166199, 0.9400428533554077, 0.9411134719848633, 0.9411134719848633, 0.9453961253166199, 0.9421841502189636, 0.9389721751213074, 0.9453961253166199, 0.9443255066871643, 0.9368308186531067, 0.9464668035507202, 0.9411134719848633, 0.943254828453064, 0.9421841502189636, 0.9453961253166199, 0.9400428533554077, 0.9282655119895935, 0.937901496887207, 0.9389721751213074, 0.9325481653213501, 0.9389721751213074, 0.9421841502189636, 0.9411134719848633, 0.9368308186531067, 0.943254828453064, 0.9400428533554077, 0.9411134719848633, 0.937901496887207, 0.9346895217895508, 0.9464668035507202, 0.943254828453064, 0.9357602000236511, 0.9368308186531067, 0.9357602000236511, 0.9357602000236511, 0.937901496887207, 0.9389721751213074, 0.9357602000236511, 0.937901496887207, 0.9389721751213074, 0.9325481653213501, 0.937901496887207, 0.9346895217895508, 0.9314774870872498, 0.9132762551307678, 0.9261242151260376, 0.9293361902236938, 0.9346895217895508, 0.9389721751213074, 0.9368308186531067, 0.9304068684577942, 0.9346895217895508, 0.9357602000236511, 0.9357602000236511, 0.9346895217895508, 0.9400428533554077, 0.9336188435554504, 0.937901496887207, 0.9368308186531067, 0.9346895217895508, 0.9346895217895508, 0.9314774870872498, 0.9357602000236511, 0.9175589084625244, 0.9346895217895508, 0.9336188435554504, 0.9293361902236938, 0.921841561794281, 0.9368308186531067, 0.9368308186531067, 0.9325481653213501, 0.9304068684577942, 0.9250535368919373, 0.9357602000236511, 0.9304068684577942, 0.9325481653213501, 0.9325481653213501, 0.9314774870872498, 0.9261242151260376, 0.9271948337554932, 0.9314774870872498, 0.9282655119895935, 0.9346895217895508, 0.9239828586578369, 0.9346895217895508, 0.9282655119895935]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 19, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 19, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 10, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 10, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 49ms/step - loss: 0.0564 - accuracy: 0.9826 - val_loss: 0.6466 - val_accuracy: 0.5300\n","Epoch 2/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0276 - accuracy: 0.9922 - val_loss: 0.6349 - val_accuracy: 0.5589\n","Epoch 3/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0321 - accuracy: 0.9904 - val_loss: 0.6216 - val_accuracy: 0.5760\n","Epoch 4/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0262 - accuracy: 0.9904 - val_loss: 0.6010 - val_accuracy: 0.6403\n","Epoch 5/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.5849 - val_accuracy: 0.6767\n","Epoch 6/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.5471 - val_accuracy: 0.8276\n","Epoch 7/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0202 - accuracy: 0.9941 - val_loss: 0.5210 - val_accuracy: 0.8694\n","Epoch 8/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0250 - accuracy: 0.9906 - val_loss: 0.5161 - val_accuracy: 0.7709\n","Epoch 9/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0239 - accuracy: 0.9912 - val_loss: 0.4769 - val_accuracy: 0.8330\n","Epoch 10/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0180 - accuracy: 0.9949 - val_loss: 0.4424 - val_accuracy: 0.8694\n","Epoch 11/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0150 - accuracy: 0.9962 - val_loss: 0.3963 - val_accuracy: 0.9154\n","Epoch 12/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0199 - accuracy: 0.9928 - val_loss: 0.3577 - val_accuracy: 0.9315\n","Epoch 13/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.3089 - val_accuracy: 0.9390\n","Epoch 14/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0154 - accuracy: 0.9944 - val_loss: 0.2686 - val_accuracy: 0.9358\n","Epoch 15/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 0.2377 - val_accuracy: 0.9379\n","Epoch 16/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0145 - accuracy: 0.9960 - val_loss: 0.2120 - val_accuracy: 0.9400\n","Epoch 17/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.1927 - val_accuracy: 0.9411\n","Epoch 18/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0252 - accuracy: 0.9909 - val_loss: 0.1913 - val_accuracy: 0.9315\n","Epoch 19/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.1809 - val_accuracy: 0.9390\n","Epoch 20/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0185 - accuracy: 0.9933 - val_loss: 0.1819 - val_accuracy: 0.9379\n","Epoch 21/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 0.1942 - val_accuracy: 0.9390\n","Epoch 22/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.2000 - val_accuracy: 0.9379\n","Epoch 23/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0078 - accuracy: 0.9989 - val_loss: 0.2133 - val_accuracy: 0.9433\n","Epoch 24/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 0.2292 - val_accuracy: 0.9411\n","Epoch 25/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.0148 - accuracy: 0.9944 - val_loss: 0.2612 - val_accuracy: 0.9358\n","Epoch 26/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.2530 - val_accuracy: 0.9358\n","Epoch 27/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.2778 - val_accuracy: 0.9368\n","Epoch 28/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.2842 - val_accuracy: 0.9368\n","Epoch 29/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.2948 - val_accuracy: 0.9347\n","Epoch 30/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.3147 - val_accuracy: 0.9390\n","Epoch 31/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 0.2967 - val_accuracy: 0.9390\n","Epoch 32/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.2945 - val_accuracy: 0.9379\n","Epoch 33/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0105 - accuracy: 0.9960 - val_loss: 0.3069 - val_accuracy: 0.9368\n","Epoch 34/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0151 - accuracy: 0.9954 - val_loss: 0.3376 - val_accuracy: 0.9304\n","Epoch 35/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.3069 - val_accuracy: 0.9368\n","Epoch 36/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0141 - accuracy: 0.9944 - val_loss: 0.3247 - val_accuracy: 0.9379\n","Epoch 37/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.3279 - val_accuracy: 0.9304\n","Epoch 38/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.3941 - val_accuracy: 0.9208\n","Epoch 39/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.3189 - val_accuracy: 0.9325\n","Epoch 40/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.3487 - val_accuracy: 0.9379\n","Epoch 41/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0104 - accuracy: 0.9976 - val_loss: 0.3258 - val_accuracy: 0.9379\n","Epoch 42/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0137 - accuracy: 0.9944 - val_loss: 0.3252 - val_accuracy: 0.9325\n","Epoch 43/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.3236 - val_accuracy: 0.9368\n","Epoch 44/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0149 - accuracy: 0.9944 - val_loss: 0.3384 - val_accuracy: 0.9293\n","Epoch 45/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.3960 - val_accuracy: 0.9261\n","Epoch 46/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 0.3221 - val_accuracy: 0.9325\n","Epoch 47/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.3211 - val_accuracy: 0.9400\n","Epoch 48/100\n","30/30 [==============================] - 1s 35ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.3472 - val_accuracy: 0.9368\n","Epoch 49/100\n","30/30 [==============================] - 1s 40ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.3874 - val_accuracy: 0.9251\n","Epoch 50/100\n","30/30 [==============================] - 1s 47ms/step - loss: 0.0132 - accuracy: 0.9965 - val_loss: 0.3797 - val_accuracy: 0.9293\n","Epoch 51/100\n","30/30 [==============================] - 1s 32ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.3681 - val_accuracy: 0.9283\n","Epoch 52/100\n","30/30 [==============================] - 1s 38ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 0.3424 - val_accuracy: 0.9390\n","Epoch 53/100\n","30/30 [==============================] - 1s 41ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.3623 - val_accuracy: 0.9304\n","Epoch 54/100\n","30/30 [==============================] - 1s 32ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.3578 - val_accuracy: 0.9368\n","Epoch 55/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.3558 - val_accuracy: 0.9390\n","Epoch 56/100\n","30/30 [==============================] - 1s 38ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.3902 - val_accuracy: 0.9325\n","Epoch 57/100\n","30/30 [==============================] - 1s 35ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.3781 - val_accuracy: 0.9293\n","Epoch 58/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.3939 - val_accuracy: 0.9283\n","Epoch 59/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.3665 - val_accuracy: 0.9368\n","Epoch 60/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.3482 - val_accuracy: 0.9358\n","Epoch 61/100\n","30/30 [==============================] - 1s 36ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.3577 - val_accuracy: 0.9411\n","Epoch 62/100\n","30/30 [==============================] - 1s 43ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.3612 - val_accuracy: 0.9390\n","Epoch 63/100\n","30/30 [==============================] - 1s 31ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.3577 - val_accuracy: 0.9347\n","Epoch 64/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.3635 - val_accuracy: 0.9315\n","Epoch 65/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.3720 - val_accuracy: 0.9304\n","Epoch 66/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.3848 - val_accuracy: 0.9368\n","Epoch 67/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.3786 - val_accuracy: 0.9347\n","Epoch 68/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.4214 - val_accuracy: 0.9325\n","Epoch 69/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0073 - accuracy: 0.9973 - val_loss: 0.3803 - val_accuracy: 0.9325\n","Epoch 70/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.3817 - val_accuracy: 0.9304\n","Epoch 71/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.4112 - val_accuracy: 0.9251\n","Epoch 72/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0081 - accuracy: 0.9968 - val_loss: 0.3995 - val_accuracy: 0.9272\n","Epoch 73/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.3760 - val_accuracy: 0.9368\n","Epoch 74/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.3750 - val_accuracy: 0.9411\n","Epoch 75/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.3842 - val_accuracy: 0.9347\n","Epoch 76/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.3956 - val_accuracy: 0.9336\n","Epoch 77/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0068 - accuracy: 0.9973 - val_loss: 0.4630 - val_accuracy: 0.9229\n","Epoch 78/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.3792 - val_accuracy: 0.9325\n","Epoch 79/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0184 - accuracy: 0.9936 - val_loss: 0.4981 - val_accuracy: 0.9154\n","Epoch 80/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0176 - accuracy: 0.9930 - val_loss: 0.4246 - val_accuracy: 0.9208\n","Epoch 81/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.4114 - val_accuracy: 0.9293\n","Epoch 82/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.4066 - val_accuracy: 0.9272\n","Epoch 83/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0047 - accuracy: 0.9981 - val_loss: 0.4151 - val_accuracy: 0.9218\n","Epoch 84/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.4126 - val_accuracy: 0.9218\n","Epoch 85/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0242 - accuracy: 0.9904 - val_loss: 0.4274 - val_accuracy: 0.9251\n","Epoch 86/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.4180 - val_accuracy: 0.9304\n","Epoch 87/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.4071 - val_accuracy: 0.9293\n","Epoch 88/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.4331 - val_accuracy: 0.9229\n","Epoch 89/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.4233 - val_accuracy: 0.9272\n","Epoch 90/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.4094 - val_accuracy: 0.9315\n","Epoch 91/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.4099 - val_accuracy: 0.9293\n","Epoch 92/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.4108 - val_accuracy: 0.9315\n","Epoch 93/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.4188 - val_accuracy: 0.9315\n","Epoch 94/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.4552 - val_accuracy: 0.9304\n","Epoch 95/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0047 - accuracy: 0.9981 - val_loss: 0.4366 - val_accuracy: 0.9261\n","Epoch 96/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.4017 - val_accuracy: 0.9293\n","Epoch 97/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 0.4190 - val_accuracy: 0.9261\n","Epoch 98/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.4044 - val_accuracy: 0.9261\n","Epoch 99/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.4384 - val_accuracy: 0.9218\n","Epoch 100/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.4047 - val_accuracy: 0.9315\n","{'loss': [0.0563543476164341, 0.027589865028858185, 0.032054685056209564, 0.0261512640863657, 0.01880427822470665, 0.018839707598090172, 0.020161764696240425, 0.024969078600406647, 0.02387804351747036, 0.01798766851425171, 0.014976154081523418, 0.019854312762618065, 0.015445022843778133, 0.015412603504955769, 0.013844085857272148, 0.014464553445577621, 0.014032546430826187, 0.025208143517374992, 0.014598244801163673, 0.018468962982296944, 0.008940251544117928, 0.013548278249800205, 0.007798331789672375, 0.011542703956365585, 0.014769185334444046, 0.008700997568666935, 0.006444279104471207, 0.008430209942162037, 0.005404663737863302, 0.009409035556018353, 0.0042812880128622055, 0.007165444549173117, 0.010451704263687134, 0.015101858414709568, 0.013128568418323994, 0.014109480194747448, 0.012231544591486454, 0.01135440543293953, 0.008175213821232319, 0.006296237464994192, 0.010384534485638142, 0.013731916435062885, 0.008766927756369114, 0.014919009990990162, 0.008614163845777512, 0.007093767635524273, 0.004481780342757702, 0.0074873752892017365, 0.013607490807771683, 0.013153444044291973, 0.007241871207952499, 0.007223720662295818, 0.004581444431096315, 0.004877287894487381, 0.006506526842713356, 0.005730585195124149, 0.00726923206821084, 0.005858056712895632, 0.0058816540986299515, 0.0037617399357259274, 0.0032292611431330442, 0.003710620803758502, 0.0029473730828613043, 0.004773690365254879, 0.004135133698582649, 0.003049710765480995, 0.0032585470471531153, 0.006868597585707903, 0.007295830640941858, 0.00958616565912962, 0.004371747840195894, 0.008112065494060516, 0.003596570109948516, 0.0033380312379449606, 0.0060849315486848354, 0.004790905863046646, 0.006830277387052774, 0.005207403562963009, 0.01835263893008232, 0.017565341666340828, 0.006563723552972078, 0.003702196292579174, 0.004675049800425768, 0.004432576708495617, 0.024219093844294548, 0.004060788080096245, 0.003822208847850561, 0.0023984971921890974, 0.003921342082321644, 0.0031941013876348734, 0.0032427378464490175, 0.0019212226616218686, 0.0014356302563101053, 0.004397842567414045, 0.004735899157822132, 0.006476588547229767, 0.003917165100574493, 0.007531007286161184, 0.006329709198325872, 0.0026507461443543434], 'accuracy': [0.9825877547264099, 0.9922314286231995, 0.9903562664985657, 0.9903562664985657, 0.9941065907478333, 0.9941065907478333, 0.9941065907478333, 0.990624189376831, 0.9911599159240723, 0.9949102401733398, 0.9962496757507324, 0.9927672147750854, 0.9954460263252258, 0.9943745136260986, 0.9959818124771118, 0.9959818124771118, 0.9957138895988464, 0.9908920526504517, 0.9957138895988464, 0.9933030009269714, 0.9981248378753662, 0.9957138895988464, 0.9989284873008728, 0.9962496757507324, 0.9943745136260986, 0.9978569746017456, 0.9981248378753662, 0.9978569746017456, 0.9989284873008728, 0.9973211884498596, 0.999464213848114, 0.9978569746017456, 0.9959818124771118, 0.9954460263252258, 0.9957138895988464, 0.9943745136260986, 0.9957138895988464, 0.9962496757507324, 0.9975890517234802, 0.9983927011489868, 0.9975890517234802, 0.9943745136260986, 0.9973211884498596, 0.9943745136260986, 0.9978569746017456, 0.9981248378753662, 0.9991963505744934, 0.9973211884498596, 0.9951781630516052, 0.996517539024353, 0.9978569746017456, 0.9981248378753662, 0.9991963505744934, 0.9989284873008728, 0.9981248378753662, 0.9983927011489868, 0.9983927011489868, 0.9981248378753662, 0.9989284873008728, 0.9989284873008728, 0.9991963505744934, 0.9991963505744934, 0.999464213848114, 0.9989284873008728, 0.999464213848114, 0.9989284873008728, 0.9991963505744934, 0.9983927011489868, 0.9973211884498596, 0.997053325176239, 0.9983927011489868, 0.9967854022979736, 0.9991963505744934, 0.999464213848114, 0.9983927011489868, 0.9986606240272522, 0.9973211884498596, 0.9983927011489868, 0.993570864200592, 0.993035078048706, 0.9981248378753662, 0.999464213848114, 0.9981248378753662, 0.9983927011489868, 0.9903562664985657, 0.999464213848114, 0.9991963505744934, 0.9997321367263794, 0.999464213848114, 0.9989284873008728, 0.9989284873008728, 0.999464213848114, 0.9997321367263794, 0.9983927011489868, 0.9981248378753662, 0.9978569746017456, 0.9983927011489868, 0.9973211884498596, 0.9978569746017456, 0.9991963505744934], 'val_loss': [0.6466037034988403, 0.6349073648452759, 0.6216230988502502, 0.6009668111801147, 0.5849443674087524, 0.5470955967903137, 0.5209913849830627, 0.5161393284797668, 0.47691231966018677, 0.4424125850200653, 0.3963066041469574, 0.35772937536239624, 0.30892565846443176, 0.26862311363220215, 0.23767204582691193, 0.2119886875152588, 0.19270731508731842, 0.19131898880004883, 0.18092212080955505, 0.1818614900112152, 0.1941891759634018, 0.19995228946208954, 0.21330127120018005, 0.22923505306243896, 0.2612006664276123, 0.2529987096786499, 0.277809202671051, 0.28417810797691345, 0.29476428031921387, 0.31467393040657043, 0.29667946696281433, 0.2944848835468292, 0.30692920088768005, 0.337577760219574, 0.306911826133728, 0.3246757686138153, 0.3278968036174774, 0.3941020965576172, 0.3188832104206085, 0.3486632704734802, 0.3257577419281006, 0.3251952528953552, 0.32357385754585266, 0.3384442925453186, 0.3960469663143158, 0.3221382796764374, 0.3210538625717163, 0.34716659784317017, 0.3874184787273407, 0.37968742847442627, 0.3680887222290039, 0.3424006402492523, 0.362304151058197, 0.35776129364967346, 0.35575738549232483, 0.3902474641799927, 0.378080278635025, 0.3939274549484253, 0.3665482997894287, 0.34821054339408875, 0.35773202776908875, 0.3612256348133087, 0.3576817214488983, 0.36351290345191956, 0.37197333574295044, 0.38477084040641785, 0.3786020874977112, 0.42136090993881226, 0.38027286529541016, 0.38171622157096863, 0.41121894121170044, 0.3994887173175812, 0.3760032057762146, 0.3750319480895996, 0.3842427134513855, 0.39557403326034546, 0.46299007534980774, 0.37921416759490967, 0.49805474281311035, 0.4245551526546478, 0.4114294946193695, 0.40659889578819275, 0.4151146709918976, 0.4125978648662567, 0.42740029096603394, 0.4179907739162445, 0.40708890557289124, 0.4330586791038513, 0.42333707213401794, 0.40943583846092224, 0.4098801016807556, 0.4107523560523987, 0.418826162815094, 0.45515385270118713, 0.43659132719039917, 0.40168496966362, 0.4190111756324768, 0.40443721413612366, 0.43835359811782837, 0.40469133853912354], 'val_accuracy': [0.5299785733222961, 0.5588865280151367, 0.5760171413421631, 0.640256941318512, 0.6766595244407654, 0.8276231288909912, 0.8693790435791016, 0.7708779573440552, 0.8329764604568481, 0.8693790435791016, 0.9154175519943237, 0.9314774870872498, 0.9389721751213074, 0.9357602000236511, 0.937901496887207, 0.9400428533554077, 0.9411134719848633, 0.9314774870872498, 0.9389721751213074, 0.937901496887207, 0.9389721751213074, 0.937901496887207, 0.943254828453064, 0.9411134719848633, 0.9357602000236511, 0.9357602000236511, 0.9368308186531067, 0.9368308186531067, 0.9346895217895508, 0.9389721751213074, 0.9389721751213074, 0.937901496887207, 0.9368308186531067, 0.9304068684577942, 0.9368308186531067, 0.937901496887207, 0.9304068684577942, 0.9207708835601807, 0.9325481653213501, 0.937901496887207, 0.937901496887207, 0.9325481653213501, 0.9368308186531067, 0.9293361902236938, 0.9261242151260376, 0.9325481653213501, 0.9400428533554077, 0.9368308186531067, 0.9250535368919373, 0.9293361902236938, 0.9282655119895935, 0.9389721751213074, 0.9304068684577942, 0.9368308186531067, 0.9389721751213074, 0.9325481653213501, 0.9293361902236938, 0.9282655119895935, 0.9368308186531067, 0.9357602000236511, 0.9411134719848633, 0.9389721751213074, 0.9346895217895508, 0.9314774870872498, 0.9304068684577942, 0.9368308186531067, 0.9346895217895508, 0.9325481653213501, 0.9325481653213501, 0.9304068684577942, 0.9250535368919373, 0.9271948337554932, 0.9368308186531067, 0.9411134719848633, 0.9346895217895508, 0.9336188435554504, 0.9229121804237366, 0.9325481653213501, 0.9154175519943237, 0.9207708835601807, 0.9293361902236938, 0.9271948337554932, 0.921841561794281, 0.921841561794281, 0.9250535368919373, 0.9304068684577942, 0.9293361902236938, 0.9229121804237366, 0.9271948337554932, 0.9314774870872498, 0.9293361902236938, 0.9314774870872498, 0.9314774870872498, 0.9304068684577942, 0.9261242151260376, 0.9293361902236938, 0.9261242151260376, 0.9261242151260376, 0.921841561794281, 0.9314774870872498]}\n","37/37 [==============================] - 1s 4ms/step\n"]}]},{"cell_type":"code","source":["metrics_df.round(3)"],"metadata":{"id":"y3RXIk-qZ7ts","colab":{"base_uri":"https://localhost:8080/","height":519},"executionInfo":{"status":"ok","timestamp":1716485352381,"user_tz":-360,"elapsed":36,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}},"outputId":"76e9944e-1b15-4341-b189-dfb909893e9a"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.818      0.814   0.828  0.821        0.828        0.809   \n","1        1     0.803      0.833   0.762  0.796        0.762        0.844   \n","2        2     0.805      0.873   0.716  0.786        0.716        0.895   \n","3        0     0.874      0.885   0.862  0.873        0.862        0.886   \n","4        1     0.841      0.863   0.815  0.838        0.815        0.869   \n","5        2     0.845      0.879   0.800  0.838        0.800        0.890   \n","6        0     0.919      0.910   0.932  0.921        0.932        0.907   \n","7        1     0.891      0.898   0.885  0.891        0.885        0.898   \n","8        2     0.891      0.883   0.902  0.892        0.902        0.880   \n","9        0     0.946      0.952   0.940  0.946        0.940        0.952   \n","10       1     0.917      0.921   0.913  0.917        0.913        0.920   \n","11       2     0.924      0.948   0.897  0.922        0.897        0.950   \n","12       0     0.963      0.949   0.980  0.964        0.980        0.947   \n","13       1     0.939      0.933   0.947  0.940        0.947        0.931   \n","14       2     0.938      0.937   0.940  0.938        0.940        0.937   \n","\n","    Kappa  \n","0   0.637  \n","1   0.606  \n","2   0.611  \n","3   0.748  \n","4   0.683  \n","5   0.690  \n","6   0.839  \n","7   0.782  \n","8   0.782  \n","9   0.892  \n","10  0.834  \n","11  0.847  \n","12  0.926  \n","13  0.878  \n","14  0.877  "],"text/html":["\n","  <div id=\"df-1ba27aa7-ede4-41cf-9548-f34281349906\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.818</td>\n","      <td>0.814</td>\n","      <td>0.828</td>\n","      <td>0.821</td>\n","      <td>0.828</td>\n","      <td>0.809</td>\n","      <td>0.637</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.803</td>\n","      <td>0.833</td>\n","      <td>0.762</td>\n","      <td>0.796</td>\n","      <td>0.762</td>\n","      <td>0.844</td>\n","      <td>0.606</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.805</td>\n","      <td>0.873</td>\n","      <td>0.716</td>\n","      <td>0.786</td>\n","      <td>0.716</td>\n","      <td>0.895</td>\n","      <td>0.611</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.874</td>\n","      <td>0.885</td>\n","      <td>0.862</td>\n","      <td>0.873</td>\n","      <td>0.862</td>\n","      <td>0.886</td>\n","      <td>0.748</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.841</td>\n","      <td>0.863</td>\n","      <td>0.815</td>\n","      <td>0.838</td>\n","      <td>0.815</td>\n","      <td>0.869</td>\n","      <td>0.683</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.845</td>\n","      <td>0.879</td>\n","      <td>0.800</td>\n","      <td>0.838</td>\n","      <td>0.800</td>\n","      <td>0.890</td>\n","      <td>0.690</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.919</td>\n","      <td>0.910</td>\n","      <td>0.932</td>\n","      <td>0.921</td>\n","      <td>0.932</td>\n","      <td>0.907</td>\n","      <td>0.839</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.891</td>\n","      <td>0.898</td>\n","      <td>0.885</td>\n","      <td>0.891</td>\n","      <td>0.885</td>\n","      <td>0.898</td>\n","      <td>0.782</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.891</td>\n","      <td>0.883</td>\n","      <td>0.902</td>\n","      <td>0.892</td>\n","      <td>0.902</td>\n","      <td>0.880</td>\n","      <td>0.782</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.946</td>\n","      <td>0.952</td>\n","      <td>0.940</td>\n","      <td>0.946</td>\n","      <td>0.940</td>\n","      <td>0.952</td>\n","      <td>0.892</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.917</td>\n","      <td>0.921</td>\n","      <td>0.913</td>\n","      <td>0.917</td>\n","      <td>0.913</td>\n","      <td>0.920</td>\n","      <td>0.834</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.924</td>\n","      <td>0.948</td>\n","      <td>0.897</td>\n","      <td>0.922</td>\n","      <td>0.897</td>\n","      <td>0.950</td>\n","      <td>0.847</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.963</td>\n","      <td>0.949</td>\n","      <td>0.980</td>\n","      <td>0.964</td>\n","      <td>0.980</td>\n","      <td>0.947</td>\n","      <td>0.926</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.939</td>\n","      <td>0.933</td>\n","      <td>0.947</td>\n","      <td>0.940</td>\n","      <td>0.947</td>\n","      <td>0.931</td>\n","      <td>0.878</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.938</td>\n","      <td>0.937</td>\n","      <td>0.940</td>\n","      <td>0.938</td>\n","      <td>0.940</td>\n","      <td>0.937</td>\n","      <td>0.877</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ba27aa7-ede4-41cf-9548-f34281349906')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1ba27aa7-ede4-41cf-9548-f34281349906 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1ba27aa7-ede4-41cf-9548-f34281349906');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-e8516b19-49ec-47f4-8fa6-c0e8d64d15da\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e8516b19-49ec-47f4-8fa6-c0e8d64d15da')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-e8516b19-49ec-47f4-8fa6-c0e8d64d15da button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05376642606151696,\n        \"min\": 0.803,\n        \"max\": 0.963,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.917,\n          0.963,\n          0.818\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04252539857320004,\n        \"min\": 0.814,\n        \"max\": 0.952,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.952,\n          0.948,\n          0.814\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07574185481904025,\n        \"min\": 0.716,\n        \"max\": 0.98,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.94,\n          0.897,\n          0.828\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05728732927304339,\n        \"min\": 0.786,\n        \"max\": 0.964,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.917,\n          0.964,\n          0.821\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07574185481904025,\n        \"min\": 0.716,\n        \"max\": 0.98,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.94,\n          0.897,\n          0.828\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04077814540727842,\n        \"min\": 0.809,\n        \"max\": 0.952,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.952,\n          0.95,\n          0.809\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10733050868806174,\n        \"min\": 0.606,\n        \"max\": 0.926,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.834,\n          0.926,\n          0.637\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":[],"metadata":{"id":"_iOLsKpkfzdG"},"execution_count":null,"outputs":[]}]}