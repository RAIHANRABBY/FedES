{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Mbfw8uvdftFM","executionInfo":{"status":"ok","timestamp":1716487493158,"user_tz":-360,"elapsed":1715,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sb"]},{"cell_type":"code","source":["from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"INiFJfLjgOkx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import ExtraTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score, cross_val_predict"],"metadata":{"id":"lYo2Uq77gQSH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPool1D, Flatten, Dropout,LSTM"],"metadata":{"id":"g66575_xgVzz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MOCNWlamfr3v","executionInfo":{"status":"ok","timestamp":1716479486891,"user_tz":-360,"elapsed":3569,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"72ab19ae-f08c-4b49-99e4-123c492f862a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Raw_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/only data/raw_data.npz'\n","\n","DWT_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/DWT/DWT.npz'\n","\n","Time_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/time domain /time_domain_data.npz'\n","\n","frequency_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/feature domain/frequency_domain_data.npz'\n","\n","# RAW = np.load(Raw_data, allow_pickle=True)  # Allow loading pickled object arrays\n","# X = RAW['X'].astype('float64')\n","# Y = RAW['Y'].astype('float64')\n","# group = RAW['Group'].astype('float64')"],"metadata":{"id":"iNy9eOGMf2qO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This is a good performing model"],"metadata":{"id":"PzeABzSyHgKg"}},{"cell_type":"code","source":["# import numpy as np\n","# from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n","# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","# from tensorflow.keras.models import Sequential\n","# from tensorflow.keras.layers import Conv1D, MaxPool1D, Flatten, Dense, BatchNormalization, LSTM,MaxPooling1D\n","# from tensorflow.keras.optimizers import Adam\n","# from tensorflow.keras.regularizers import l2\n","# from tensorflow.keras.backend import clear_session\n","\n","# class FederatedData:\n","#     def __init__(self, data_path, num_clients, scaler_type='MinMax'):\n","#         self.data_path = data_path\n","#         self.num_clients = num_clients\n","#         self.scaler_type = scaler_type\n","#         self.load_data()\n","#         self.scale_data()\n","#         self.partitions = []\n","\n","#     def load_data(self):\n","#         try:\n","#             data = np.load(self.data_path)\n","#             self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","#             self.Y = data['Y']\n","#         except KeyError as e:\n","#             raise ValueError(f\"Missing expected data field: {e}\")\n","#         except FileNotFoundError as e:\n","#             raise ValueError(f\"Data file not found: {e}\")\n","\n","#     def scale_data(self):\n","#         # Reshape data to 2D array for scaling\n","#         X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","#         # Select scaler based on input\n","#         if self.scaler_type == 'Standard':\n","#             scaler = StandardScaler()\n","#         elif self.scaler_type == 'MinMax':\n","#             scaler = MinMaxScaler(feature_range=(0, 1))\n","#         else:\n","#             raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","#         # Fit and transform the data\n","#         scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","#         # Reshape back to original shape\n","#         self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","#     def create_partitions(self):\n","#         sss = StratifiedShuffleSplit(n_splits=self.num_clients, test_size=0.2, random_state=42)\n","#         for train_idx, test_idx in sss.split(self.X, self.Y):\n","#             partition_X_train, partition_X_test = self.X[train_idx], self.X[test_idx]\n","#             partition_Y_train, partition_Y_test = self.Y[train_idx], self.Y[test_idx]\n","#             self.partitions.append((partition_X_train, partition_Y_train, partition_X_test, partition_Y_test))\n","\n","#     def get_training_and_validation_data(self, client_idx):\n","#         if client_idx < 0 or client_idx >= len(self.partitions):\n","#             raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","#         partition_X_train, partition_Y_train, _, _ = self.partitions[client_idx]\n","#         X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","#         return X_train, X_val, Y_train, Y_val\n","\n","#     def get_testing_data(self, client_idx):\n","#         if client_idx < 0 or client_idx >= len(self.partitions):\n","#             raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","#         _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","#         return partition_X_test, partition_Y_test\n","\n","# def build_sequential_model(input_shape):\n","#     clear_session()\n","#     model = Sequential()\n","\n","#     model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","#     model.add(BatchNormalization())\n","#     model.add(MaxPooling1D(2, padding=\"same\"))\n","#     model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","#     model.add(MaxPooling1D(2, padding=\"same\"))\n","#     model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","#     model.add(MaxPooling1D(2, padding=\"same\"))\n","#     model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","#     model.add(LSTM(256, return_sequences=True))\n","#     model.add(LSTM(256, return_sequences=False))\n","#     model.add(Flatten())\n","#     model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.001)))\n","#     model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.001)))\n","#     model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","#     opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","#     model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","#     model.summary()\n","#     return model\n","\n","# def federated_learning(data_path):\n","#     federated_data = FederatedData(data_path, num_clients=2, scaler_type='MinMax')\n","#     federated_data.create_partitions()\n","\n","#     # Get the input shape from the data\n","#     input_shape = federated_data.X.shape[1:]\n","#     global_model = build_sequential_model(input_shape)\n","\n","#     num_clients = 2\n","#     local_epochs = 20\n","#     global_optimizer = Adam()\n","\n","#     # Initialize m and v for Adam optimizer\n","#     m = [np.zeros_like(w) for w in global_model.get_weights()]\n","#     v = [np.zeros_like(w) for w in global_model.get_weights()]\n","#     beta1 = 0.9\n","#     beta2 = 0.999\n","#     epsilon = 1e-7\n","#     t = 0\n","\n","#     client_data = []\n","#     for client_idx in range(num_clients):\n","#         x_train, _, y_train, _ = federated_data.get_training_and_validation_data(client_idx)\n","#         client_data.append((x_train, y_train))\n","\n","#     for epoch in range(local_epochs):\n","#         client_models = []\n","\n","#         for client in range(num_clients):\n","#             x, y = client_data[client]\n","#             client_model = build_sequential_model(input_shape)\n","#             client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","#             client_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","#             history = client_model.fit(x, y, epochs=1, batch_size=64)\n","#             client_models.append(client_model)\n","\n","#             print(history.history)\n","\n","#         global_weights = global_model.get_weights()\n","#         for layer in range(len(global_model.layers)):\n","#             layer_weights = []\n","#             layer_biases = []\n","#             for i in range(num_clients):\n","#                 layer_weights.append(client_models[i].layers[layer].get_weights()[0])\n","#                 layer_biases.append(client_models[i].layers[layer].get_weights()[1])\n","#             averaged_layer_weights = np.mean(layer_weights, axis=0)\n","#             averaged_layer_biases = np.mean(layer_biases, axis=0)\n","#             global_weights[layer * 2] = averaged_layer_weights.reshape(global_weights[layer * 2].shape)\n","#             global_weights[layer * 2 + 1] = averaged_layer_biases.reshape(global_weights[layer * 2 + 1].shape)\n","\n","#         # Apply FedOpt (Adam) update to global weights\n","#         t += 1\n","#         for i in range(len(global_weights)):\n","#             g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","#             m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","#             v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","#             m_hat = m[i] / (1 - beta1 ** t)\n","#             v_hat = v[i] / (1 - beta2 ** t)\n","#             global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","#         global_model.set_weights(global_weights)\n","\n","#     return global_model\n"],"metadata":{"id":"6cLRGG8qDAWq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# DWT"],"metadata":{"id":"6DhAYwXUSE9z"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split,KFold,StratifiedKFold\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM,Dropout, GRU\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from keras.optimizers import RMSprop, Adam\n","# from wandb.keras import WandbCallback\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', k_folds=5, stratified=False):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.k_folds = k_folds\n","        self.stratified = stratified\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle= True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        X = scaled_data_reshaped.reshape(self.X.shape)\n","        np.moveaxis(X, 1, 2)\n","        self.X = X\n","\n","    def create_partitions(self):\n","        if self.stratified:\n","            kf = StratifiedKFold(n_splits=self.k_folds, shuffle=True, random_state=42)\n","        else:\n","            kf = KFold(n_splits=self.k_folds, shuffle=True, random_state=42)\n","\n","        for train_index, test_index in kf.split(self.X, self.Y):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(LSTM(256, return_sequences=True))\n","    model.add(LSTM(256, return_sequences=True))\n","        # GRU layers\n","    # model.add(GRU(256, return_sequences=True))\n","    # model.add(GRU(128, return_sequences=False))\n","\n","    model.add(Flatten())\n","    # model.add(Dense(1024, activation='relu'))\n","    # model.add(Dense(512, activation='relu'))\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dense(32, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Evaluate client model\n","            y_pred = (client_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"VvjC2xCQNHLP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["global_model, metrics_df = federated_learning(DWT_data)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVURUnmYNNNg","outputId":"919a25af-f080-480f-c168-364a5e10a2c4","executionInfo":{"status":"ok","timestamp":1716482933454,"user_tz":-360,"elapsed":163465,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4667, 52, 29), Test shape: (1167, 52, 29)\n","Train shape: (4667, 52, 29), Test shape: (1167, 52, 29)\n","Train shape: (4667, 52, 29), Test shape: (1167, 52, 29)\n","Train shape: (4667, 52, 29), Test shape: (1167, 52, 29)\n","Train shape: (4668, 52, 29), Test shape: (1166, 52, 29)\n","Train shape: (4667, 52, 29), Test shape: (1167, 52, 29)\n","Train shape: (4667, 52, 29), Test shape: (1167, 52, 29)\n","Train shape: (4667, 52, 29), Test shape: (1167, 52, 29)\n","Train shape: (4667, 52, 29), Test shape: (1167, 52, 29)\n","Train shape: (4668, 52, 29), Test shape: (1166, 52, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 9s 59ms/step - loss: 0.6928 - accuracy: 0.5031 - val_loss: 0.6930 - val_accuracy: 0.5525\n","Epoch 2/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.6886 - accuracy: 0.5660 - val_loss: 0.6925 - val_accuracy: 0.7216\n","Epoch 3/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.6806 - accuracy: 0.6885 - val_loss: 0.6916 - val_accuracy: 0.6328\n","Epoch 4/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.6663 - accuracy: 0.6962 - val_loss: 0.6897 - val_accuracy: 0.6253\n","Epoch 5/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.6436 - accuracy: 0.7118 - val_loss: 0.6861 - val_accuracy: 0.6435\n","Epoch 6/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.6134 - accuracy: 0.7289 - val_loss: 0.6796 - val_accuracy: 0.6777\n","Epoch 7/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.5806 - accuracy: 0.7292 - val_loss: 0.6697 - val_accuracy: 0.7141\n","Epoch 8/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.5591 - accuracy: 0.7268 - val_loss: 0.6588 - val_accuracy: 0.7056\n","Epoch 9/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.5477 - accuracy: 0.7257 - val_loss: 0.6486 - val_accuracy: 0.7355\n","Epoch 10/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.5415 - accuracy: 0.7348 - val_loss: 0.6368 - val_accuracy: 0.7281\n","Epoch 11/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.5321 - accuracy: 0.7442 - val_loss: 0.6270 - val_accuracy: 0.7313\n","Epoch 12/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.5271 - accuracy: 0.7385 - val_loss: 0.6156 - val_accuracy: 0.7334\n","Epoch 13/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.5223 - accuracy: 0.7477 - val_loss: 0.6054 - val_accuracy: 0.7409\n","Epoch 14/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.5129 - accuracy: 0.7533 - val_loss: 0.5924 - val_accuracy: 0.7409\n","Epoch 15/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.5106 - accuracy: 0.7576 - val_loss: 0.5789 - val_accuracy: 0.7409\n","Epoch 16/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.5023 - accuracy: 0.7653 - val_loss: 0.5627 - val_accuracy: 0.7495\n","Epoch 17/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4987 - accuracy: 0.7648 - val_loss: 0.5604 - val_accuracy: 0.7463\n","Epoch 18/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4954 - accuracy: 0.7664 - val_loss: 0.5412 - val_accuracy: 0.7516\n","Epoch 19/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4934 - accuracy: 0.7688 - val_loss: 0.5517 - val_accuracy: 0.7366\n","Epoch 20/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4919 - accuracy: 0.7704 - val_loss: 0.5301 - val_accuracy: 0.7505\n","Epoch 21/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4845 - accuracy: 0.7752 - val_loss: 0.5236 - val_accuracy: 0.7505\n","Epoch 22/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4858 - accuracy: 0.7777 - val_loss: 0.5282 - val_accuracy: 0.7505\n","Epoch 23/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4843 - accuracy: 0.7763 - val_loss: 0.5177 - val_accuracy: 0.7559\n","Epoch 24/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4796 - accuracy: 0.7809 - val_loss: 0.5346 - val_accuracy: 0.7463\n","Epoch 25/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4836 - accuracy: 0.7769 - val_loss: 0.5203 - val_accuracy: 0.7484\n","Epoch 26/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4774 - accuracy: 0.7819 - val_loss: 0.5244 - val_accuracy: 0.7505\n","Epoch 27/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4771 - accuracy: 0.7844 - val_loss: 0.5276 - val_accuracy: 0.7505\n","Epoch 28/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4763 - accuracy: 0.7798 - val_loss: 0.5217 - val_accuracy: 0.7548\n","Epoch 29/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4736 - accuracy: 0.7897 - val_loss: 0.5219 - val_accuracy: 0.7537\n","Epoch 30/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4731 - accuracy: 0.7862 - val_loss: 0.5246 - val_accuracy: 0.7527\n","Epoch 31/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4711 - accuracy: 0.7889 - val_loss: 0.5256 - val_accuracy: 0.7537\n","Epoch 32/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.5238 - val_accuracy: 0.7527\n","Epoch 33/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4691 - accuracy: 0.7873 - val_loss: 0.5393 - val_accuracy: 0.7473\n","Epoch 34/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4717 - accuracy: 0.7889 - val_loss: 0.5320 - val_accuracy: 0.7527\n","Epoch 35/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4711 - accuracy: 0.7833 - val_loss: 0.5277 - val_accuracy: 0.7537\n","Epoch 36/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4653 - accuracy: 0.7921 - val_loss: 0.5220 - val_accuracy: 0.7548\n","Epoch 37/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4670 - accuracy: 0.7908 - val_loss: 0.5233 - val_accuracy: 0.7548\n","Epoch 38/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4651 - accuracy: 0.7897 - val_loss: 0.5239 - val_accuracy: 0.7602\n","Epoch 39/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4650 - accuracy: 0.7881 - val_loss: 0.5275 - val_accuracy: 0.7559\n","Epoch 40/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.4591 - accuracy: 0.7921 - val_loss: 0.5241 - val_accuracy: 0.7612\n","Epoch 41/100\n","30/30 [==============================] - 1s 35ms/step - loss: 0.4610 - accuracy: 0.7972 - val_loss: 0.5255 - val_accuracy: 0.7537\n","Epoch 42/100\n","30/30 [==============================] - 1s 35ms/step - loss: 0.4579 - accuracy: 0.7956 - val_loss: 0.5268 - val_accuracy: 0.7580\n","Epoch 43/100\n","30/30 [==============================] - 1s 37ms/step - loss: 0.4594 - accuracy: 0.7892 - val_loss: 0.5248 - val_accuracy: 0.7559\n","Epoch 44/100\n","30/30 [==============================] - 1s 39ms/step - loss: 0.4552 - accuracy: 0.7956 - val_loss: 0.5243 - val_accuracy: 0.7537\n","Epoch 45/100\n","30/30 [==============================] - 1s 38ms/step - loss: 0.4557 - accuracy: 0.7961 - val_loss: 0.5253 - val_accuracy: 0.7548\n","Epoch 46/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.4545 - accuracy: 0.7956 - val_loss: 0.5273 - val_accuracy: 0.7559\n","Epoch 47/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.4519 - accuracy: 0.8002 - val_loss: 0.5232 - val_accuracy: 0.7580\n","Epoch 48/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.4507 - accuracy: 0.7961 - val_loss: 0.5228 - val_accuracy: 0.7612\n","Epoch 49/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.4495 - accuracy: 0.8028 - val_loss: 0.5234 - val_accuracy: 0.7655\n","Epoch 50/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.4479 - accuracy: 0.7986 - val_loss: 0.5305 - val_accuracy: 0.7527\n","Epoch 51/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.4506 - accuracy: 0.7986 - val_loss: 0.5220 - val_accuracy: 0.7634\n","Epoch 52/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.4442 - accuracy: 0.8063 - val_loss: 0.5203 - val_accuracy: 0.7580\n","Epoch 53/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4455 - accuracy: 0.8074 - val_loss: 0.5331 - val_accuracy: 0.7570\n","Epoch 54/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.4519 - accuracy: 0.7964 - val_loss: 0.5210 - val_accuracy: 0.7580\n","Epoch 55/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.4461 - accuracy: 0.8004 - val_loss: 0.5234 - val_accuracy: 0.7612\n","Epoch 56/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.4424 - accuracy: 0.8034 - val_loss: 0.5194 - val_accuracy: 0.7612\n","Epoch 57/100\n","30/30 [==============================] - 1s 33ms/step - loss: 0.4397 - accuracy: 0.8109 - val_loss: 0.5206 - val_accuracy: 0.7612\n","Epoch 58/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.4360 - accuracy: 0.8087 - val_loss: 0.5207 - val_accuracy: 0.7623\n","Epoch 59/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4385 - accuracy: 0.8069 - val_loss: 0.5196 - val_accuracy: 0.7623\n","Epoch 60/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4342 - accuracy: 0.8069 - val_loss: 0.5200 - val_accuracy: 0.7623\n","Epoch 61/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4351 - accuracy: 0.8069 - val_loss: 0.5189 - val_accuracy: 0.7634\n","Epoch 62/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4338 - accuracy: 0.8053 - val_loss: 0.5218 - val_accuracy: 0.7602\n","Epoch 63/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4398 - accuracy: 0.8066 - val_loss: 0.5164 - val_accuracy: 0.7623\n","Epoch 64/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4341 - accuracy: 0.8111 - val_loss: 0.5216 - val_accuracy: 0.7612\n","Epoch 65/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.4308 - accuracy: 0.8114 - val_loss: 0.5159 - val_accuracy: 0.7655\n","Epoch 66/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4323 - accuracy: 0.8154 - val_loss: 0.5118 - val_accuracy: 0.7655\n","Epoch 67/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4307 - accuracy: 0.8109 - val_loss: 0.5136 - val_accuracy: 0.7634\n","Epoch 68/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4269 - accuracy: 0.8141 - val_loss: 0.5168 - val_accuracy: 0.7634\n","Epoch 69/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4224 - accuracy: 0.8133 - val_loss: 0.5142 - val_accuracy: 0.7645\n","Epoch 70/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4235 - accuracy: 0.8138 - val_loss: 0.5116 - val_accuracy: 0.7645\n","Epoch 71/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4212 - accuracy: 0.8165 - val_loss: 0.5163 - val_accuracy: 0.7623\n","Epoch 72/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4241 - accuracy: 0.8117 - val_loss: 0.5078 - val_accuracy: 0.7698\n","Epoch 73/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4188 - accuracy: 0.8165 - val_loss: 0.5083 - val_accuracy: 0.7612\n","Epoch 74/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4166 - accuracy: 0.8146 - val_loss: 0.5178 - val_accuracy: 0.7612\n","Epoch 75/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4112 - accuracy: 0.8184 - val_loss: 0.5069 - val_accuracy: 0.7623\n","Epoch 76/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4093 - accuracy: 0.8205 - val_loss: 0.5122 - val_accuracy: 0.7612\n","Epoch 77/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4072 - accuracy: 0.8261 - val_loss: 0.5058 - val_accuracy: 0.7709\n","Epoch 78/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4096 - accuracy: 0.8237 - val_loss: 0.5005 - val_accuracy: 0.7762\n","Epoch 79/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4089 - accuracy: 0.8213 - val_loss: 0.5092 - val_accuracy: 0.7666\n","Epoch 80/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4061 - accuracy: 0.8296 - val_loss: 0.4994 - val_accuracy: 0.7709\n","Epoch 81/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4034 - accuracy: 0.8235 - val_loss: 0.4996 - val_accuracy: 0.7773\n","Epoch 82/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4028 - accuracy: 0.8267 - val_loss: 0.4957 - val_accuracy: 0.7816\n","Epoch 83/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3937 - accuracy: 0.8280 - val_loss: 0.4957 - val_accuracy: 0.7827\n","Epoch 84/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3966 - accuracy: 0.8240 - val_loss: 0.4984 - val_accuracy: 0.7827\n","Epoch 85/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3914 - accuracy: 0.8288 - val_loss: 0.4951 - val_accuracy: 0.7827\n","Epoch 86/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3933 - accuracy: 0.8339 - val_loss: 0.4939 - val_accuracy: 0.7859\n","Epoch 87/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3942 - accuracy: 0.8299 - val_loss: 0.4934 - val_accuracy: 0.7794\n","Epoch 88/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3888 - accuracy: 0.8326 - val_loss: 0.4956 - val_accuracy: 0.7848\n","Epoch 89/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3862 - accuracy: 0.8336 - val_loss: 0.4945 - val_accuracy: 0.7741\n","Epoch 90/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3840 - accuracy: 0.8350 - val_loss: 0.4900 - val_accuracy: 0.7816\n","Epoch 91/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3810 - accuracy: 0.8342 - val_loss: 0.4938 - val_accuracy: 0.7848\n","Epoch 92/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3746 - accuracy: 0.8390 - val_loss: 0.4900 - val_accuracy: 0.7891\n","Epoch 93/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3755 - accuracy: 0.8387 - val_loss: 0.4885 - val_accuracy: 0.7859\n","Epoch 94/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3731 - accuracy: 0.8382 - val_loss: 0.4884 - val_accuracy: 0.7805\n","Epoch 95/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3707 - accuracy: 0.8428 - val_loss: 0.5094 - val_accuracy: 0.7709\n","Epoch 96/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3697 - accuracy: 0.8470 - val_loss: 0.4848 - val_accuracy: 0.7859\n","Epoch 97/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3635 - accuracy: 0.8457 - val_loss: 0.4919 - val_accuracy: 0.7805\n","Epoch 98/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3622 - accuracy: 0.8513 - val_loss: 0.4943 - val_accuracy: 0.7794\n","Epoch 99/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3591 - accuracy: 0.8476 - val_loss: 0.4866 - val_accuracy: 0.7859\n","Epoch 100/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3551 - accuracy: 0.8489 - val_loss: 0.4979 - val_accuracy: 0.7816\n","{'loss': [0.6927823424339294, 0.6886005997657776, 0.6805983781814575, 0.6663342714309692, 0.6435669660568237, 0.6133990287780762, 0.5806451439857483, 0.5591051578521729, 0.5477378964424133, 0.5415157675743103, 0.5320699214935303, 0.5271093249320984, 0.5222705006599426, 0.5129191279411316, 0.5106022953987122, 0.5023308992385864, 0.4986805021762848, 0.4953937232494354, 0.4934157133102417, 0.49189305305480957, 0.48449015617370605, 0.48579540848731995, 0.48433926701545715, 0.4796038269996643, 0.4835614860057831, 0.4773975908756256, 0.47709813714027405, 0.4762794077396393, 0.47358039021492004, 0.4730650782585144, 0.4711058735847473, 0.47030627727508545, 0.46910199522972107, 0.4716934859752655, 0.4710817337036133, 0.46529388427734375, 0.4669560194015503, 0.4650746285915375, 0.4650290012359619, 0.45912137627601624, 0.4610045552253723, 0.4578617811203003, 0.4594079852104187, 0.45521923899650574, 0.4557279348373413, 0.4544711112976074, 0.4518980085849762, 0.4507191479206085, 0.4495472311973572, 0.44790950417518616, 0.45063483715057373, 0.4441784918308258, 0.445467084646225, 0.4519213140010834, 0.44610995054244995, 0.4423781633377075, 0.43970024585723877, 0.43596357107162476, 0.43845993280410767, 0.4342329800128937, 0.4351462423801422, 0.4337579011917114, 0.43978747725486755, 0.4340605139732361, 0.43077534437179565, 0.4322926700115204, 0.4307357966899872, 0.4269155263900757, 0.4223993122577667, 0.42345601320266724, 0.42118218541145325, 0.4241081178188324, 0.4188458025455475, 0.4166116416454315, 0.4112315773963928, 0.40932074189186096, 0.4072309136390686, 0.4096100628376007, 0.40890565514564514, 0.40613406896591187, 0.4034045934677124, 0.40275663137435913, 0.3936508595943451, 0.39656537771224976, 0.3913746476173401, 0.3932704031467438, 0.39417141675949097, 0.38878950476646423, 0.3862049877643585, 0.3839569687843323, 0.38095125555992126, 0.37456247210502625, 0.3755418062210083, 0.3730705678462982, 0.37068110704421997, 0.36973798274993896, 0.36349815130233765, 0.362235963344574, 0.3590857684612274, 0.3551118075847626], 'accuracy': [0.5030806064605713, 0.5660327076911926, 0.6884543299674988, 0.6962229013442993, 0.7117599844932556, 0.7289043664932251, 0.7291722297668457, 0.7267613410949707, 0.7256897687911987, 0.7347977757453918, 0.7441735863685608, 0.7385480999946594, 0.7476560473442078, 0.7532815337181091, 0.7575676441192627, 0.7653362154960632, 0.7648004293441772, 0.7664077281951904, 0.7688186168670654, 0.7704259157180786, 0.7752478122711182, 0.7776587009429932, 0.7763193249702454, 0.7808732986450195, 0.7768550515174866, 0.7819448113441467, 0.7843557596206665, 0.7798017859458923, 0.7897133827209473, 0.7862309217453003, 0.7889097332954407, 0.7840878367424011, 0.7873024344444275, 0.7889097332954407, 0.7832842469215393, 0.7921242713928223, 0.7907848954200745, 0.7897133827209473, 0.7881060838699341, 0.7921242713928223, 0.7972140312194824, 0.7956067323684692, 0.7891775965690613, 0.7956067323684692, 0.7961425185203552, 0.7956067323684692, 0.8001607060432434, 0.7961425185203552, 0.8028395175933838, 0.798553466796875, 0.798553466796875, 0.8063219785690308, 0.807393491268158, 0.7964103817939758, 0.8004286289215088, 0.8033753037452698, 0.8108759522438049, 0.8087329268455505, 0.8068577647209167, 0.8068577647209167, 0.8068577647209167, 0.8052504658699036, 0.8065899014472961, 0.8111438751220703, 0.8114117383956909, 0.8154299259185791, 0.8108759522438049, 0.8140905499458313, 0.8132869005203247, 0.8138226866722107, 0.8165014982223511, 0.8116796016693115, 0.8165014982223511, 0.8146262764930725, 0.8183766603469849, 0.8205196857452393, 0.8261451721191406, 0.8237342834472656, 0.8213233351707458, 0.8296276330947876, 0.8234663605690002, 0.8266809582710266, 0.8280203342437744, 0.8240021467208862, 0.828823983669281, 0.8339137434959412, 0.829895555973053, 0.8325743079185486, 0.8336458802223206, 0.8349852561950684, 0.8341816067695618, 0.8390035033226013, 0.8387355804443359, 0.8381998538970947, 0.8427538275718689, 0.8470399379730225, 0.8457005023956299, 0.8513259887695312, 0.8475756645202637, 0.8489151000976562], 'val_loss': [0.6930257678031921, 0.692512035369873, 0.6915682554244995, 0.689696729183197, 0.6860841512680054, 0.6795814037322998, 0.6697421669960022, 0.6588415503501892, 0.6485723257064819, 0.6367762088775635, 0.626980721950531, 0.6156149506568909, 0.6053827404975891, 0.5924158096313477, 0.578877866268158, 0.5626738667488098, 0.5603528618812561, 0.5411974191665649, 0.5516706109046936, 0.5300647020339966, 0.5236304998397827, 0.5282449126243591, 0.517733633518219, 0.5345781445503235, 0.5202656388282776, 0.5244258046150208, 0.5276456475257874, 0.5217265486717224, 0.521906852722168, 0.524567186832428, 0.5256215929985046, 0.5237559080123901, 0.5393413305282593, 0.5320441722869873, 0.5276936292648315, 0.5220170021057129, 0.5233281254768372, 0.5239307284355164, 0.5275086760520935, 0.5240817070007324, 0.5255195498466492, 0.5268409848213196, 0.5247739553451538, 0.5242884159088135, 0.5253310799598694, 0.5272919535636902, 0.5231995582580566, 0.5228191018104553, 0.5234141945838928, 0.5305101871490479, 0.5219766497612, 0.5202918648719788, 0.5331203937530518, 0.5210348963737488, 0.5234068036079407, 0.5194156169891357, 0.5205873250961304, 0.5207200050354004, 0.5195885300636292, 0.5199832916259766, 0.5188813209533691, 0.5217874050140381, 0.5164169073104858, 0.5216236114501953, 0.515929102897644, 0.511806845664978, 0.5136019587516785, 0.5167652368545532, 0.5141894221305847, 0.5115796327590942, 0.5162718296051025, 0.5078362822532654, 0.5082617998123169, 0.5177674889564514, 0.5069372653961182, 0.512216329574585, 0.5057549476623535, 0.5004818439483643, 0.5091829299926758, 0.499437153339386, 0.4995589554309845, 0.4957248568534851, 0.49567365646362305, 0.49843430519104004, 0.49513959884643555, 0.4938572943210602, 0.49344152212142944, 0.49560391902923584, 0.49449729919433594, 0.489993691444397, 0.4938456118106842, 0.48997101187705994, 0.4885443150997162, 0.4884372651576996, 0.5093756914138794, 0.4847569465637207, 0.49185338616371155, 0.4943380057811737, 0.48660773038864136, 0.4978793263435364], 'val_accuracy': [0.5524625182151794, 0.721627414226532, 0.6327623128890991, 0.6252676844596863, 0.643468976020813, 0.6777302026748657, 0.7141327857971191, 0.705567479133606, 0.7355460524559021, 0.7280513644218445, 0.7312633991241455, 0.7334046959877014, 0.740899384021759, 0.740899384021759, 0.740899384021759, 0.7494646906852722, 0.7462526559829712, 0.7516059875488281, 0.7366167306900024, 0.7505353093147278, 0.7505353093147278, 0.7505353093147278, 0.7558886408805847, 0.7462526559829712, 0.7483940124511719, 0.7505353093147278, 0.7505353093147278, 0.7548179626464844, 0.7537473440170288, 0.7526766657829285, 0.7537473440170288, 0.7526766657829285, 0.7473233342170715, 0.7526766657829285, 0.7537473440170288, 0.7548179626464844, 0.7548179626464844, 0.7601712942123413, 0.7558886408805847, 0.7612419724464417, 0.7537473440170288, 0.7580299973487854, 0.7558886408805847, 0.7537473440170288, 0.7548179626464844, 0.7558886408805847, 0.7580299973487854, 0.7612419724464417, 0.7655246257781982, 0.7526766657829285, 0.7633832693099976, 0.7580299973487854, 0.7569593191146851, 0.7580299973487854, 0.7612419724464417, 0.7612419724464417, 0.7612419724464417, 0.762312650680542, 0.762312650680542, 0.762312650680542, 0.7633832693099976, 0.7601712942123413, 0.762312650680542, 0.7612419724464417, 0.7655246257781982, 0.7655246257781982, 0.7633832693099976, 0.7633832693099976, 0.7644539475440979, 0.7644539475440979, 0.762312650680542, 0.7698072791099548, 0.7612419724464417, 0.7612419724464417, 0.762312650680542, 0.7612419724464417, 0.7708779573440552, 0.7762312889099121, 0.7665953040122986, 0.7708779573440552, 0.7773019075393677, 0.7815845608711243, 0.7826552391052246, 0.7826552391052246, 0.7826552391052246, 0.7858672142028809, 0.7794432640075684, 0.7847965955734253, 0.7740899324417114, 0.7815845608711243, 0.7847965955734253, 0.7890792489051819, 0.7858672142028809, 0.7805139422416687, 0.7708779573440552, 0.7858672142028809, 0.7805139422416687, 0.7794432640075684, 0.7858672142028809, 0.7815845608711243]}\n","37/37 [==============================] - 1s 6ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 9s 52ms/step - loss: 0.6928 - accuracy: 0.5020 - val_loss: 0.6930 - val_accuracy: 0.4861\n","Epoch 2/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.6889 - accuracy: 0.5526 - val_loss: 0.6926 - val_accuracy: 0.5139\n","Epoch 3/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.6810 - accuracy: 0.6501 - val_loss: 0.6916 - val_accuracy: 0.5921\n","Epoch 4/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.6649 - accuracy: 0.6919 - val_loss: 0.6897 - val_accuracy: 0.5664\n","Epoch 5/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.6399 - accuracy: 0.7168 - val_loss: 0.6852 - val_accuracy: 0.6210\n","Epoch 6/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.6072 - accuracy: 0.7177 - val_loss: 0.6767 - val_accuracy: 0.7270\n","Epoch 7/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.5749 - accuracy: 0.7262 - val_loss: 0.6677 - val_accuracy: 0.6809\n","Epoch 8/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.5536 - accuracy: 0.7302 - val_loss: 0.6538 - val_accuracy: 0.7495\n","Epoch 9/100\n","30/30 [==============================] - 1s 33ms/step - loss: 0.5423 - accuracy: 0.7329 - val_loss: 0.6423 - val_accuracy: 0.7398\n","Epoch 10/100\n","30/30 [==============================] - 1s 42ms/step - loss: 0.5384 - accuracy: 0.7343 - val_loss: 0.6314 - val_accuracy: 0.7409\n","Epoch 11/100\n","30/30 [==============================] - 1s 40ms/step - loss: 0.5359 - accuracy: 0.7383 - val_loss: 0.6202 - val_accuracy: 0.7634\n","Epoch 12/100\n","30/30 [==============================] - 1s 31ms/step - loss: 0.5280 - accuracy: 0.7418 - val_loss: 0.6064 - val_accuracy: 0.7687\n","Epoch 13/100\n","30/30 [==============================] - 1s 34ms/step - loss: 0.5238 - accuracy: 0.7442 - val_loss: 0.5907 - val_accuracy: 0.7655\n","Epoch 14/100\n","30/30 [==============================] - 1s 38ms/step - loss: 0.5190 - accuracy: 0.7498 - val_loss: 0.5772 - val_accuracy: 0.7677\n","Epoch 15/100\n","30/30 [==============================] - 1s 33ms/step - loss: 0.5168 - accuracy: 0.7501 - val_loss: 0.5602 - val_accuracy: 0.7677\n","Epoch 16/100\n","30/30 [==============================] - 1s 32ms/step - loss: 0.5115 - accuracy: 0.7527 - val_loss: 0.5476 - val_accuracy: 0.7773\n","Epoch 17/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.5088 - accuracy: 0.7586 - val_loss: 0.5321 - val_accuracy: 0.7784\n","Epoch 18/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.5075 - accuracy: 0.7592 - val_loss: 0.5162 - val_accuracy: 0.7762\n","Epoch 19/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.5048 - accuracy: 0.7619 - val_loss: 0.5257 - val_accuracy: 0.7741\n","Epoch 20/100\n","30/30 [==============================] - 1s 35ms/step - loss: 0.4999 - accuracy: 0.7613 - val_loss: 0.4918 - val_accuracy: 0.7912\n","Epoch 21/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.4968 - accuracy: 0.7688 - val_loss: 0.4822 - val_accuracy: 0.7912\n","Epoch 22/100\n","30/30 [==============================] - 1s 33ms/step - loss: 0.4938 - accuracy: 0.7683 - val_loss: 0.4753 - val_accuracy: 0.7934\n","Epoch 23/100\n","30/30 [==============================] - 1s 45ms/step - loss: 0.4896 - accuracy: 0.7739 - val_loss: 0.4706 - val_accuracy: 0.7944\n","Epoch 24/100\n","30/30 [==============================] - 1s 34ms/step - loss: 0.4877 - accuracy: 0.7736 - val_loss: 0.4647 - val_accuracy: 0.7891\n","Epoch 25/100\n","30/30 [==============================] - 1s 34ms/step - loss: 0.4814 - accuracy: 0.7785 - val_loss: 0.4594 - val_accuracy: 0.7955\n","Epoch 26/100\n","30/30 [==============================] - 1s 33ms/step - loss: 0.4819 - accuracy: 0.7787 - val_loss: 0.4660 - val_accuracy: 0.7998\n","Epoch 27/100\n","30/30 [==============================] - 1s 37ms/step - loss: 0.4801 - accuracy: 0.7793 - val_loss: 0.4568 - val_accuracy: 0.7923\n","Epoch 28/100\n","30/30 [==============================] - 1s 38ms/step - loss: 0.4831 - accuracy: 0.7750 - val_loss: 0.4530 - val_accuracy: 0.7966\n","Epoch 29/100\n","30/30 [==============================] - 1s 42ms/step - loss: 0.4791 - accuracy: 0.7852 - val_loss: 0.4522 - val_accuracy: 0.7944\n","Epoch 30/100\n","30/30 [==============================] - 1s 39ms/step - loss: 0.4773 - accuracy: 0.7814 - val_loss: 0.4533 - val_accuracy: 0.8019\n","Epoch 31/100\n","30/30 [==============================] - 1s 42ms/step - loss: 0.4772 - accuracy: 0.7819 - val_loss: 0.4536 - val_accuracy: 0.7944\n","Epoch 32/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4732 - accuracy: 0.7846 - val_loss: 0.4491 - val_accuracy: 0.8051\n","Epoch 33/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4698 - accuracy: 0.7876 - val_loss: 0.4495 - val_accuracy: 0.7966\n","Epoch 34/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4685 - accuracy: 0.7862 - val_loss: 0.4474 - val_accuracy: 0.8030\n","Epoch 35/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4655 - accuracy: 0.7884 - val_loss: 0.4624 - val_accuracy: 0.7901\n","Epoch 36/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4724 - accuracy: 0.7873 - val_loss: 0.4520 - val_accuracy: 0.8094\n","Epoch 37/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4671 - accuracy: 0.7852 - val_loss: 0.4443 - val_accuracy: 0.8019\n","Epoch 38/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4658 - accuracy: 0.7886 - val_loss: 0.4446 - val_accuracy: 0.8009\n","Epoch 39/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4667 - accuracy: 0.7900 - val_loss: 0.4428 - val_accuracy: 0.7987\n","Epoch 40/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4644 - accuracy: 0.7841 - val_loss: 0.4427 - val_accuracy: 0.8019\n","Epoch 41/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4621 - accuracy: 0.7927 - val_loss: 0.4435 - val_accuracy: 0.8030\n","Epoch 42/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4666 - accuracy: 0.7937 - val_loss: 0.4449 - val_accuracy: 0.7998\n","Epoch 43/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.4625 - accuracy: 0.7919 - val_loss: 0.4497 - val_accuracy: 0.7987\n","Epoch 44/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.4605 - accuracy: 0.7921 - val_loss: 0.4404 - val_accuracy: 0.8051\n","Epoch 45/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.4604 - accuracy: 0.7913 - val_loss: 0.4401 - val_accuracy: 0.8019\n","Epoch 46/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.4580 - accuracy: 0.7935 - val_loss: 0.4393 - val_accuracy: 0.8094\n","Epoch 47/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.4544 - accuracy: 0.7929 - val_loss: 0.4401 - val_accuracy: 0.8073\n","Epoch 48/100\n","30/30 [==============================] - 1s 31ms/step - loss: 0.4534 - accuracy: 0.7948 - val_loss: 0.4397 - val_accuracy: 0.8084\n","Epoch 49/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.4548 - accuracy: 0.8012 - val_loss: 0.4371 - val_accuracy: 0.8084\n","Epoch 50/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.4515 - accuracy: 0.7967 - val_loss: 0.4367 - val_accuracy: 0.8094\n","Epoch 51/100\n","30/30 [==============================] - 1s 39ms/step - loss: 0.4504 - accuracy: 0.8012 - val_loss: 0.4376 - val_accuracy: 0.8041\n","Epoch 52/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.4464 - accuracy: 0.7996 - val_loss: 0.4381 - val_accuracy: 0.8084\n","Epoch 53/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.4451 - accuracy: 0.8026 - val_loss: 0.4461 - val_accuracy: 0.7998\n","Epoch 54/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.4450 - accuracy: 0.7991 - val_loss: 0.4371 - val_accuracy: 0.8116\n","Epoch 55/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4480 - accuracy: 0.7916 - val_loss: 0.4374 - val_accuracy: 0.8105\n","Epoch 56/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.4415 - accuracy: 0.7986 - val_loss: 0.4320 - val_accuracy: 0.8073\n","Epoch 57/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.4405 - accuracy: 0.8044 - val_loss: 0.4332 - val_accuracy: 0.8137\n","Epoch 58/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.4400 - accuracy: 0.8020 - val_loss: 0.4316 - val_accuracy: 0.8116\n","Epoch 59/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.4367 - accuracy: 0.8082 - val_loss: 0.4300 - val_accuracy: 0.8116\n","Epoch 60/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.4385 - accuracy: 0.8106 - val_loss: 0.4354 - val_accuracy: 0.8105\n","Epoch 61/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4341 - accuracy: 0.8077 - val_loss: 0.4313 - val_accuracy: 0.8126\n","Epoch 62/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.4347 - accuracy: 0.8031 - val_loss: 0.4292 - val_accuracy: 0.8137\n","Epoch 63/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.4359 - accuracy: 0.8039 - val_loss: 0.4279 - val_accuracy: 0.8105\n","Epoch 64/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.4283 - accuracy: 0.8074 - val_loss: 0.4315 - val_accuracy: 0.8148\n","Epoch 65/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.4250 - accuracy: 0.8077 - val_loss: 0.4264 - val_accuracy: 0.8116\n","Epoch 66/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.4252 - accuracy: 0.8157 - val_loss: 0.4237 - val_accuracy: 0.8158\n","Epoch 67/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.4273 - accuracy: 0.8066 - val_loss: 0.4230 - val_accuracy: 0.8148\n","Epoch 68/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4197 - accuracy: 0.8122 - val_loss: 0.4401 - val_accuracy: 0.8009\n","Epoch 69/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.4244 - accuracy: 0.8111 - val_loss: 0.4328 - val_accuracy: 0.8094\n","Epoch 70/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.4202 - accuracy: 0.8111 - val_loss: 0.4199 - val_accuracy: 0.8126\n","Epoch 71/100\n","30/30 [==============================] - 1s 34ms/step - loss: 0.4185 - accuracy: 0.8157 - val_loss: 0.4276 - val_accuracy: 0.8148\n","Epoch 72/100\n","30/30 [==============================] - 1s 36ms/step - loss: 0.4188 - accuracy: 0.8119 - val_loss: 0.4287 - val_accuracy: 0.8094\n","Epoch 73/100\n","30/30 [==============================] - 1s 36ms/step - loss: 0.4154 - accuracy: 0.8170 - val_loss: 0.4244 - val_accuracy: 0.8126\n","Epoch 74/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4167 - accuracy: 0.8173 - val_loss: 0.4167 - val_accuracy: 0.8148\n","Epoch 75/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4086 - accuracy: 0.8197 - val_loss: 0.4207 - val_accuracy: 0.8169\n","Epoch 76/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4109 - accuracy: 0.8170 - val_loss: 0.4210 - val_accuracy: 0.8126\n","Epoch 77/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4108 - accuracy: 0.8181 - val_loss: 0.4148 - val_accuracy: 0.8212\n","Epoch 78/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4048 - accuracy: 0.8229 - val_loss: 0.4153 - val_accuracy: 0.8233\n","Epoch 79/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4006 - accuracy: 0.8205 - val_loss: 0.4135 - val_accuracy: 0.8223\n","Epoch 80/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4019 - accuracy: 0.8235 - val_loss: 0.4145 - val_accuracy: 0.8137\n","Epoch 81/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3993 - accuracy: 0.8264 - val_loss: 0.4135 - val_accuracy: 0.8212\n","Epoch 82/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3961 - accuracy: 0.8299 - val_loss: 0.4141 - val_accuracy: 0.8180\n","Epoch 83/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3940 - accuracy: 0.8275 - val_loss: 0.4241 - val_accuracy: 0.8105\n","Epoch 84/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3929 - accuracy: 0.8320 - val_loss: 0.4154 - val_accuracy: 0.8137\n","Epoch 85/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3944 - accuracy: 0.8296 - val_loss: 0.4094 - val_accuracy: 0.8276\n","Epoch 86/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3974 - accuracy: 0.8253 - val_loss: 0.4097 - val_accuracy: 0.8191\n","Epoch 87/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3843 - accuracy: 0.8328 - val_loss: 0.4072 - val_accuracy: 0.8266\n","Epoch 88/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3869 - accuracy: 0.8353 - val_loss: 0.4108 - val_accuracy: 0.8212\n","Epoch 89/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.3875 - accuracy: 0.8299 - val_loss: 0.4228 - val_accuracy: 0.8084\n","Epoch 90/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.3794 - accuracy: 0.8355 - val_loss: 0.4072 - val_accuracy: 0.8255\n","Epoch 91/100\n","30/30 [==============================] - 1s 44ms/step - loss: 0.3747 - accuracy: 0.8379 - val_loss: 0.4316 - val_accuracy: 0.8084\n","Epoch 92/100\n","30/30 [==============================] - 1s 32ms/step - loss: 0.3894 - accuracy: 0.8283 - val_loss: 0.4578 - val_accuracy: 0.7955\n","Epoch 93/100\n","30/30 [==============================] - 1s 32ms/step - loss: 0.3800 - accuracy: 0.8398 - val_loss: 0.4013 - val_accuracy: 0.8287\n","Epoch 94/100\n","30/30 [==============================] - 1s 31ms/step - loss: 0.3734 - accuracy: 0.8406 - val_loss: 0.4042 - val_accuracy: 0.8319\n","Epoch 95/100\n","30/30 [==============================] - 1s 41ms/step - loss: 0.3725 - accuracy: 0.8417 - val_loss: 0.4053 - val_accuracy: 0.8308\n","Epoch 96/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.3732 - accuracy: 0.8422 - val_loss: 0.4166 - val_accuracy: 0.8319\n","Epoch 97/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.3729 - accuracy: 0.8377 - val_loss: 0.4023 - val_accuracy: 0.8276\n","Epoch 98/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.3682 - accuracy: 0.8441 - val_loss: 0.4008 - val_accuracy: 0.8340\n","Epoch 99/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3616 - accuracy: 0.8489 - val_loss: 0.4026 - val_accuracy: 0.8276\n","Epoch 100/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3599 - accuracy: 0.8521 - val_loss: 0.4032 - val_accuracy: 0.8276\n","{'loss': [0.6928271055221558, 0.6889367699623108, 0.6810041069984436, 0.6648910641670227, 0.6398904919624329, 0.6071672439575195, 0.5749256610870361, 0.5535914301872253, 0.5422961711883545, 0.5384219884872437, 0.5358515381813049, 0.528007984161377, 0.5237798094749451, 0.5189822912216187, 0.5167726278305054, 0.5114736557006836, 0.5087522268295288, 0.5075087547302246, 0.5047604441642761, 0.4999046325683594, 0.4967779815196991, 0.49376824498176575, 0.48960140347480774, 0.48773065209388733, 0.48141905665397644, 0.48187488317489624, 0.4800560772418976, 0.4830561876296997, 0.47914204001426697, 0.4773496687412262, 0.4771675169467926, 0.4731592833995819, 0.46977493166923523, 0.4685283899307251, 0.4655008316040039, 0.47238293290138245, 0.46705374121665955, 0.46583354473114014, 0.46671804785728455, 0.46439340710639954, 0.46213939785957336, 0.4665907919406891, 0.46246978640556335, 0.4605160653591156, 0.4604167938232422, 0.45802125334739685, 0.45444798469543457, 0.45340457558631897, 0.45484909415245056, 0.45151063799858093, 0.45043572783470154, 0.4463728666305542, 0.44510456919670105, 0.44504043459892273, 0.4479852020740509, 0.441495805978775, 0.4405117332935333, 0.43995824456214905, 0.43665921688079834, 0.4384816288948059, 0.43411585688591003, 0.43472355604171753, 0.4359097182750702, 0.42825958132743835, 0.4250316321849823, 0.4251684546470642, 0.4273209571838379, 0.41965630650520325, 0.42442843317985535, 0.4201825261116028, 0.41852182149887085, 0.41875308752059937, 0.4153969883918762, 0.4166885316371918, 0.40859419107437134, 0.41094252467155457, 0.41077670454978943, 0.4047602117061615, 0.4006441831588745, 0.4019124507904053, 0.399260014295578, 0.39612385630607605, 0.3940008282661438, 0.39293548464775085, 0.39435192942619324, 0.39737048745155334, 0.3843350410461426, 0.386948823928833, 0.3874798119068146, 0.379366010427475, 0.37473511695861816, 0.38941478729248047, 0.3800346255302429, 0.37342405319213867, 0.37249335646629333, 0.3731716573238373, 0.37285900115966797, 0.3681623935699463, 0.3615628480911255, 0.359897643327713], 'accuracy': [0.5020090937614441, 0.5526386499404907, 0.6501473188400269, 0.6919367909431458, 0.7168497443199158, 0.7176533341407776, 0.7262255549430847, 0.7302437424659729, 0.7329225540161133, 0.7342619895935059, 0.738280177116394, 0.741762638092041, 0.7441735863685608, 0.7497990727424622, 0.7500669956207275, 0.7527458071708679, 0.7586391568183899, 0.7591749429702759, 0.7618537545204163, 0.7613179683685303, 0.7688186168670654, 0.7682828903198242, 0.7739083766937256, 0.773640513420105, 0.7784623503684998, 0.7787302732467651, 0.7792659997940063, 0.7749798893928528, 0.7851594090461731, 0.7814090251922607, 0.7819448113441467, 0.7846236228942871, 0.7875702977180481, 0.7862309217453003, 0.7883739471435547, 0.7873024344444275, 0.7851594090461731, 0.7886418700218201, 0.7899812459945679, 0.7840878367424011, 0.7926600575447083, 0.7937315702438354, 0.7918564081192017, 0.7921242713928223, 0.7913206815719604, 0.7934637069702148, 0.7929279208183289, 0.7948030829429626, 0.8012322783470154, 0.7966782450675964, 0.8012322783470154, 0.7996249794960022, 0.8025716543197632, 0.7990891933441162, 0.791588544845581, 0.798553466796875, 0.804446816444397, 0.8020358681678772, 0.8081971406936646, 0.8106080889701843, 0.8076614141464233, 0.8031074404716492, 0.8039110898971558, 0.807393491268158, 0.8076614141464233, 0.8156978487968445, 0.8065899014472961, 0.8122153878211975, 0.8111438751220703, 0.8111438751220703, 0.8156978487968445, 0.8119475245475769, 0.8170372247695923, 0.8173050880432129, 0.8197160363197327, 0.8170372247695923, 0.8181087374687195, 0.822930634021759, 0.8205196857452393, 0.8234663605690002, 0.826413094997406, 0.829895555973053, 0.8274846076965332, 0.8320385813713074, 0.8296276330947876, 0.825341522693634, 0.832842230796814, 0.835253119468689, 0.829895555973053, 0.8355210423469543, 0.8379319310188293, 0.8282882571220398, 0.8398071527481079, 0.8406107425689697, 0.8416823148727417, 0.8422180414199829, 0.8376640677452087, 0.8440932035446167, 0.8489151000976562, 0.8521296381950378], 'val_loss': [0.6930256485939026, 0.6926018595695496, 0.6916009783744812, 0.6896512508392334, 0.6851819753646851, 0.6767000555992126, 0.6676877737045288, 0.653755784034729, 0.6422650218009949, 0.6314170360565186, 0.6201766729354858, 0.6063935160636902, 0.5906680226325989, 0.5771536827087402, 0.5601807236671448, 0.5475562810897827, 0.5321398377418518, 0.5162116289138794, 0.5257327556610107, 0.4917798340320587, 0.4821516275405884, 0.4753391146659851, 0.47061654925346375, 0.46466314792633057, 0.45941364765167236, 0.46598947048187256, 0.4567503035068512, 0.4529813230037689, 0.4522364139556885, 0.45334580540657043, 0.4536489248275757, 0.4491034150123596, 0.44950422644615173, 0.44736865162849426, 0.4623548686504364, 0.4520055651664734, 0.4443134665489197, 0.4446435868740082, 0.44276759028434753, 0.44271227717399597, 0.44349682331085205, 0.4449182152748108, 0.4497198462486267, 0.4403643310070038, 0.4400658905506134, 0.4392739534378052, 0.44009724259376526, 0.43971267342567444, 0.43707287311553955, 0.43669378757476807, 0.4375545084476471, 0.43812501430511475, 0.44606971740722656, 0.43705350160598755, 0.4374326467514038, 0.4320419132709503, 0.4332316219806671, 0.4315713047981262, 0.4300065338611603, 0.43536877632141113, 0.4313049018383026, 0.42921182513237, 0.42793354392051697, 0.4314599335193634, 0.42643892765045166, 0.4237443804740906, 0.42295727133750916, 0.44008076190948486, 0.43280228972435, 0.4199466407299042, 0.4276030659675598, 0.4286573827266693, 0.4244140386581421, 0.4167002737522125, 0.42069998383522034, 0.42097246646881104, 0.41483524441719055, 0.41533327102661133, 0.41351598501205444, 0.41453006863594055, 0.413474977016449, 0.4141417145729065, 0.4241238534450531, 0.41542139649391174, 0.4093610644340515, 0.40973684191703796, 0.40718376636505127, 0.410778671503067, 0.42278429865837097, 0.4071710705757141, 0.4315840005874634, 0.4578109085559845, 0.40133941173553467, 0.4041670858860016, 0.4053387939929962, 0.4166339039802551, 0.4023445248603821, 0.40082433819770813, 0.40261128544807434, 0.4032342731952667], 'val_accuracy': [0.4860813617706299, 0.5139186382293701, 0.5920770764350891, 0.5663811564445496, 0.6209850311279297, 0.7269807457923889, 0.680942177772522, 0.7494646906852722, 0.7398287057876587, 0.740899384021759, 0.7633832693099976, 0.7687366008758545, 0.7655246257781982, 0.7676659822463989, 0.7676659822463989, 0.7773019075393677, 0.778372585773468, 0.7762312889099121, 0.7740899324417114, 0.7912205457687378, 0.7912205457687378, 0.7933619022369385, 0.794432520866394, 0.7890792489051819, 0.7955031991004944, 0.799785852432251, 0.7922912240028381, 0.7965738773345947, 0.794432520866394, 0.8019272089004517, 0.794432520866394, 0.8051391839981079, 0.7965738773345947, 0.802997887134552, 0.7901498675346375, 0.8094218373298645, 0.8019272089004517, 0.8008565306663513, 0.7987151741981506, 0.8019272089004517, 0.802997887134552, 0.799785852432251, 0.7987151741981506, 0.8051391839981079, 0.8019272089004517, 0.8094218373298645, 0.8072805404663086, 0.8083511590957642, 0.8083511590957642, 0.8094218373298645, 0.8040685057640076, 0.8083511590957642, 0.799785852432251, 0.8115631937980652, 0.8104925155639648, 0.8072805404663086, 0.8137044906616211, 0.8115631937980652, 0.8115631937980652, 0.8104925155639648, 0.8126338124275208, 0.8137044906616211, 0.8104925155639648, 0.8147751688957214, 0.8115631937980652, 0.8158458471298218, 0.8147751688957214, 0.8008565306663513, 0.8094218373298645, 0.8126338124275208, 0.8147751688957214, 0.8094218373298645, 0.8126338124275208, 0.8147751688957214, 0.8169164657592773, 0.8126338124275208, 0.8211991190910339, 0.8233404755592346, 0.8222697973251343, 0.8137044906616211, 0.8211991190910339, 0.8179871439933777, 0.8104925155639648, 0.8137044906616211, 0.8276231288909912, 0.819057822227478, 0.8265524506568909, 0.8211991190910339, 0.8083511590957642, 0.8254817724227905, 0.8083511590957642, 0.7955031991004944, 0.8286938071250916, 0.8319057822227478, 0.8308351039886475, 0.8319057822227478, 0.8276231288909912, 0.8340471386909485, 0.8276231288909912, 0.8276231288909912]}\n","37/37 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 9s 53ms/step - loss: 0.6930 - accuracy: 0.5050 - val_loss: 0.6931 - val_accuracy: 0.6895\n","Epoch 2/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.6901 - accuracy: 0.6086 - val_loss: 0.6927 - val_accuracy: 0.6713\n","Epoch 3/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.6837 - accuracy: 0.6418 - val_loss: 0.6918 - val_accuracy: 0.5428\n","Epoch 4/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.6705 - accuracy: 0.6818 - val_loss: 0.6898 - val_accuracy: 0.5996\n","Epoch 5/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.6454 - accuracy: 0.7115 - val_loss: 0.6852 - val_accuracy: 0.6210\n","Epoch 6/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.6109 - accuracy: 0.7284 - val_loss: 0.6774 - val_accuracy: 0.7013\n","Epoch 7/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.5805 - accuracy: 0.7214 - val_loss: 0.6678 - val_accuracy: 0.7109\n","Epoch 8/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.5581 - accuracy: 0.7305 - val_loss: 0.6555 - val_accuracy: 0.7259\n","Epoch 9/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.5484 - accuracy: 0.7265 - val_loss: 0.6444 - val_accuracy: 0.7291\n","Epoch 10/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.5391 - accuracy: 0.7359 - val_loss: 0.6347 - val_accuracy: 0.7420\n","Epoch 11/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.5369 - accuracy: 0.7340 - val_loss: 0.6227 - val_accuracy: 0.7420\n","Epoch 12/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.5319 - accuracy: 0.7383 - val_loss: 0.6107 - val_accuracy: 0.7463\n","Epoch 13/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.5271 - accuracy: 0.7463 - val_loss: 0.5969 - val_accuracy: 0.7484\n","Epoch 14/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.5288 - accuracy: 0.7477 - val_loss: 0.5870 - val_accuracy: 0.7452\n","Epoch 15/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.5189 - accuracy: 0.7471 - val_loss: 0.5734 - val_accuracy: 0.7473\n","Epoch 16/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.5128 - accuracy: 0.7586 - val_loss: 0.5709 - val_accuracy: 0.7463\n","Epoch 17/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.5135 - accuracy: 0.7565 - val_loss: 0.5499 - val_accuracy: 0.7420\n","Epoch 18/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.5069 - accuracy: 0.7635 - val_loss: 0.5378 - val_accuracy: 0.7484\n","Epoch 19/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.5025 - accuracy: 0.7664 - val_loss: 0.5310 - val_accuracy: 0.7527\n","Epoch 20/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.5015 - accuracy: 0.7702 - val_loss: 0.5189 - val_accuracy: 0.7591\n","Epoch 21/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4972 - accuracy: 0.7712 - val_loss: 0.5159 - val_accuracy: 0.7559\n","Epoch 22/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4983 - accuracy: 0.7669 - val_loss: 0.5009 - val_accuracy: 0.7548\n","Epoch 23/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4903 - accuracy: 0.7763 - val_loss: 0.5071 - val_accuracy: 0.7570\n","Epoch 24/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4909 - accuracy: 0.7750 - val_loss: 0.5133 - val_accuracy: 0.7602\n","Epoch 25/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4895 - accuracy: 0.7798 - val_loss: 0.4986 - val_accuracy: 0.7655\n","Epoch 26/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4881 - accuracy: 0.7715 - val_loss: 0.4958 - val_accuracy: 0.7645\n","Epoch 27/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4842 - accuracy: 0.7801 - val_loss: 0.4913 - val_accuracy: 0.7762\n","Epoch 28/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4861 - accuracy: 0.7755 - val_loss: 0.4886 - val_accuracy: 0.7655\n","Epoch 29/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4847 - accuracy: 0.7782 - val_loss: 0.4873 - val_accuracy: 0.7687\n","Epoch 30/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4832 - accuracy: 0.7803 - val_loss: 0.4869 - val_accuracy: 0.7677\n","Epoch 31/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4808 - accuracy: 0.7822 - val_loss: 0.4938 - val_accuracy: 0.7719\n","Epoch 32/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4817 - accuracy: 0.7795 - val_loss: 0.4872 - val_accuracy: 0.7730\n","Epoch 33/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4798 - accuracy: 0.7798 - val_loss: 0.4846 - val_accuracy: 0.7752\n","Epoch 34/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4728 - accuracy: 0.7873 - val_loss: 0.4851 - val_accuracy: 0.7752\n","Epoch 35/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4762 - accuracy: 0.7849 - val_loss: 0.4924 - val_accuracy: 0.7762\n","Epoch 36/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4741 - accuracy: 0.7841 - val_loss: 0.4834 - val_accuracy: 0.7741\n","Epoch 37/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4728 - accuracy: 0.7873 - val_loss: 0.4829 - val_accuracy: 0.7752\n","Epoch 38/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4723 - accuracy: 0.7878 - val_loss: 0.4902 - val_accuracy: 0.7762\n","Epoch 39/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4737 - accuracy: 0.7841 - val_loss: 0.4841 - val_accuracy: 0.7784\n","Epoch 40/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4733 - accuracy: 0.7884 - val_loss: 0.4811 - val_accuracy: 0.7741\n","Epoch 41/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4654 - accuracy: 0.7916 - val_loss: 0.4808 - val_accuracy: 0.7794\n","Epoch 42/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4699 - accuracy: 0.7889 - val_loss: 0.4805 - val_accuracy: 0.7794\n","Epoch 43/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4666 - accuracy: 0.7919 - val_loss: 0.4852 - val_accuracy: 0.7762\n","Epoch 44/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.4704 - accuracy: 0.7886 - val_loss: 0.4794 - val_accuracy: 0.7752\n","Epoch 45/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4651 - accuracy: 0.7905 - val_loss: 0.4821 - val_accuracy: 0.7837\n","Epoch 46/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4629 - accuracy: 0.7969 - val_loss: 0.4796 - val_accuracy: 0.7827\n","Epoch 47/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4674 - accuracy: 0.7900 - val_loss: 0.4808 - val_accuracy: 0.7827\n","Epoch 48/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4626 - accuracy: 0.7961 - val_loss: 0.4771 - val_accuracy: 0.7784\n","Epoch 49/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4623 - accuracy: 0.7916 - val_loss: 0.4766 - val_accuracy: 0.7880\n","Epoch 50/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4641 - accuracy: 0.7937 - val_loss: 0.4776 - val_accuracy: 0.7762\n","Epoch 51/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4611 - accuracy: 0.7932 - val_loss: 0.4811 - val_accuracy: 0.7773\n","Epoch 52/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4611 - accuracy: 0.7943 - val_loss: 0.4759 - val_accuracy: 0.7773\n","Epoch 53/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4577 - accuracy: 0.7948 - val_loss: 0.4761 - val_accuracy: 0.7848\n","Epoch 54/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4525 - accuracy: 0.7972 - val_loss: 0.4712 - val_accuracy: 0.7805\n","Epoch 55/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.4560 - accuracy: 0.7991 - val_loss: 0.4728 - val_accuracy: 0.7901\n","Epoch 56/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4562 - accuracy: 0.7953 - val_loss: 0.4728 - val_accuracy: 0.7912\n","Epoch 57/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4544 - accuracy: 0.7945 - val_loss: 0.4680 - val_accuracy: 0.7934\n","Epoch 58/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4509 - accuracy: 0.8026 - val_loss: 0.4700 - val_accuracy: 0.7934\n","Epoch 59/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4475 - accuracy: 0.8012 - val_loss: 0.4657 - val_accuracy: 0.7944\n","Epoch 60/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.4488 - accuracy: 0.8028 - val_loss: 0.4652 - val_accuracy: 0.7901\n","Epoch 61/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4458 - accuracy: 0.8036 - val_loss: 0.4721 - val_accuracy: 0.7848\n","Epoch 62/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4459 - accuracy: 0.8031 - val_loss: 0.4739 - val_accuracy: 0.7827\n","Epoch 63/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4442 - accuracy: 0.8028 - val_loss: 0.4633 - val_accuracy: 0.7976\n","Epoch 64/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.4426 - accuracy: 0.8007 - val_loss: 0.4632 - val_accuracy: 0.7966\n","Epoch 65/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4401 - accuracy: 0.8058 - val_loss: 0.4631 - val_accuracy: 0.7955\n","Epoch 66/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4435 - accuracy: 0.8020 - val_loss: 0.4617 - val_accuracy: 0.8030\n","Epoch 67/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.4383 - accuracy: 0.8077 - val_loss: 0.4675 - val_accuracy: 0.7891\n","Epoch 68/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4365 - accuracy: 0.8063 - val_loss: 0.4591 - val_accuracy: 0.8062\n","Epoch 69/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.4339 - accuracy: 0.8069 - val_loss: 0.4644 - val_accuracy: 0.7976\n","Epoch 70/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4299 - accuracy: 0.8119 - val_loss: 0.4595 - val_accuracy: 0.8062\n","Epoch 71/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4322 - accuracy: 0.8074 - val_loss: 0.4588 - val_accuracy: 0.7923\n","Epoch 72/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4325 - accuracy: 0.8069 - val_loss: 0.4632 - val_accuracy: 0.7998\n","Epoch 73/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4243 - accuracy: 0.8109 - val_loss: 0.4571 - val_accuracy: 0.7912\n","Epoch 74/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4223 - accuracy: 0.8130 - val_loss: 0.4574 - val_accuracy: 0.8019\n","Epoch 75/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4227 - accuracy: 0.8144 - val_loss: 0.4583 - val_accuracy: 0.8041\n","Epoch 76/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4165 - accuracy: 0.8173 - val_loss: 0.4571 - val_accuracy: 0.7912\n","Epoch 77/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4147 - accuracy: 0.8162 - val_loss: 0.4552 - val_accuracy: 0.8041\n","Epoch 78/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4169 - accuracy: 0.8133 - val_loss: 0.4536 - val_accuracy: 0.8062\n","Epoch 79/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4081 - accuracy: 0.8205 - val_loss: 0.4531 - val_accuracy: 0.8051\n","Epoch 80/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4135 - accuracy: 0.8205 - val_loss: 0.4506 - val_accuracy: 0.8062\n","Epoch 81/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4071 - accuracy: 0.8224 - val_loss: 0.4575 - val_accuracy: 0.7923\n","Epoch 82/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4033 - accuracy: 0.8208 - val_loss: 0.4683 - val_accuracy: 0.7901\n","Epoch 83/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4139 - accuracy: 0.8109 - val_loss: 0.4849 - val_accuracy: 0.7784\n","Epoch 84/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4087 - accuracy: 0.8186 - val_loss: 0.4572 - val_accuracy: 0.7934\n","Epoch 85/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4008 - accuracy: 0.8253 - val_loss: 0.4533 - val_accuracy: 0.7998\n","Epoch 86/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3974 - accuracy: 0.8259 - val_loss: 0.4507 - val_accuracy: 0.8009\n","Epoch 87/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3975 - accuracy: 0.8205 - val_loss: 0.4642 - val_accuracy: 0.7901\n","Epoch 88/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3976 - accuracy: 0.8288 - val_loss: 0.4443 - val_accuracy: 0.8073\n","Epoch 89/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3897 - accuracy: 0.8377 - val_loss: 0.4454 - val_accuracy: 0.8073\n","Epoch 90/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3859 - accuracy: 0.8318 - val_loss: 0.4466 - val_accuracy: 0.8116\n","Epoch 91/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3835 - accuracy: 0.8310 - val_loss: 0.4529 - val_accuracy: 0.8030\n","Epoch 92/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3803 - accuracy: 0.8353 - val_loss: 0.4480 - val_accuracy: 0.8051\n","Epoch 93/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3813 - accuracy: 0.8342 - val_loss: 0.4464 - val_accuracy: 0.8062\n","Epoch 94/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3779 - accuracy: 0.8358 - val_loss: 0.4442 - val_accuracy: 0.8137\n","Epoch 95/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3779 - accuracy: 0.8377 - val_loss: 0.4438 - val_accuracy: 0.8105\n","Epoch 96/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3781 - accuracy: 0.8355 - val_loss: 0.4489 - val_accuracy: 0.8051\n","Epoch 97/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3726 - accuracy: 0.8393 - val_loss: 0.4460 - val_accuracy: 0.8073\n","Epoch 98/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3720 - accuracy: 0.8401 - val_loss: 0.4575 - val_accuracy: 0.8041\n","Epoch 99/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3741 - accuracy: 0.8403 - val_loss: 0.4394 - val_accuracy: 0.8169\n","Epoch 100/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3709 - accuracy: 0.8422 - val_loss: 0.4404 - val_accuracy: 0.8158\n","{'loss': [0.6930481195449829, 0.6900927424430847, 0.6837303042411804, 0.6705176830291748, 0.6454123854637146, 0.6109458208084106, 0.5804518461227417, 0.55808424949646, 0.5483847260475159, 0.5391172170639038, 0.5369381308555603, 0.5318651795387268, 0.527105450630188, 0.5287812948226929, 0.5189163684844971, 0.512775182723999, 0.5135291814804077, 0.5068754553794861, 0.5025379061698914, 0.5014765858650208, 0.49720561504364014, 0.49833381175994873, 0.49028268456459045, 0.4909464120864868, 0.48954862356185913, 0.48808690905570984, 0.4842081069946289, 0.48606792092323303, 0.4847370982170105, 0.4832444489002228, 0.4808069169521332, 0.4816669225692749, 0.4798409044742584, 0.47277772426605225, 0.47622641921043396, 0.47405698895454407, 0.47281646728515625, 0.47230541706085205, 0.47366178035736084, 0.4733388125896454, 0.46537667512893677, 0.46989327669143677, 0.4666396379470825, 0.4704122543334961, 0.4650647044181824, 0.4628785252571106, 0.4673941433429718, 0.4625530242919922, 0.4623117446899414, 0.464099645614624, 0.4611136019229889, 0.4610948860645294, 0.4576896131038666, 0.4524829685688019, 0.4559640884399414, 0.4562136232852936, 0.4544219970703125, 0.4508548080921173, 0.4474669396877289, 0.4488091766834259, 0.4457683563232422, 0.44590601325035095, 0.4442327916622162, 0.44258353114128113, 0.44014325737953186, 0.4434540569782257, 0.43827709555625916, 0.43648311495780945, 0.4338946044445038, 0.42989927530288696, 0.4321635067462921, 0.432522714138031, 0.42431318759918213, 0.4222779870033264, 0.4226788282394409, 0.4164799451828003, 0.41469985246658325, 0.4169445037841797, 0.40813741087913513, 0.4135086238384247, 0.4070977568626404, 0.40325719118118286, 0.41394248604774475, 0.40871021151542664, 0.4007686972618103, 0.397434800863266, 0.39754554629325867, 0.3976312279701233, 0.3896978199481964, 0.3859483599662781, 0.38348904252052307, 0.38034895062446594, 0.3812880516052246, 0.37792497873306274, 0.37785768508911133, 0.3780865967273712, 0.3726253807544708, 0.3719797432422638, 0.3740762770175934, 0.3709343671798706], 'accuracy': [0.5049558281898499, 0.6086257696151733, 0.6418430209159851, 0.6817572712898254, 0.711492121219635, 0.7283685803413391, 0.7214037179946899, 0.7305116653442383, 0.7264934182167053, 0.735869288444519, 0.7339941263198853, 0.738280177116394, 0.7463166117668152, 0.7476560473442078, 0.7471202611923218, 0.7586391568183899, 0.7564961314201355, 0.7634609937667847, 0.7664077281951904, 0.770158052444458, 0.7712295651435852, 0.7669434547424316, 0.7763193249702454, 0.7749798893928528, 0.7798017859458923, 0.7714974284172058, 0.7800696492195129, 0.7755156755447388, 0.7781944870948792, 0.7803375124931335, 0.7822126746177673, 0.779533863067627, 0.7798017859458923, 0.7873024344444275, 0.7848914861679077, 0.7840878367424011, 0.7873024344444275, 0.7878382205963135, 0.7840878367424011, 0.7883739471435547, 0.791588544845581, 0.7889097332954407, 0.7918564081192017, 0.7886418700218201, 0.7905170321464539, 0.7969461679458618, 0.7899812459945679, 0.7961425185203552, 0.791588544845581, 0.7937315702438354, 0.7931958436965942, 0.7942673563957214, 0.7948030829429626, 0.7972140312194824, 0.7990891933441162, 0.7953388690948486, 0.794535219669342, 0.8025716543197632, 0.8012322783470154, 0.8028395175933838, 0.8036431670188904, 0.8031074404716492, 0.8028395175933838, 0.8006964921951294, 0.8057862520217896, 0.8020358681678772, 0.8076614141464233, 0.8063219785690308, 0.8068577647209167, 0.8119475245475769, 0.807393491268158, 0.8068577647209167, 0.8108759522438049, 0.8130190372467041, 0.8143584132194519, 0.8173050880432129, 0.8162335753440857, 0.8132869005203247, 0.8205196857452393, 0.8205196857452393, 0.822394847869873, 0.8207875490188599, 0.8108759522438049, 0.8186445236206055, 0.825341522693634, 0.82587730884552, 0.8205196857452393, 0.828823983669281, 0.8376640677452087, 0.8317707180976868, 0.8309670686721802, 0.835253119468689, 0.8341816067695618, 0.835788905620575, 0.8376640677452087, 0.8355210423469543, 0.8392713665962219, 0.8400750160217285, 0.8403428792953491, 0.8422180414199829], 'val_loss': [0.6930540800094604, 0.6926590204238892, 0.6918212175369263, 0.6897876262664795, 0.6852267980575562, 0.6774085760116577, 0.6678296327590942, 0.6555380821228027, 0.6444423198699951, 0.6346888542175293, 0.6226643919944763, 0.6107019782066345, 0.596863329410553, 0.586979329586029, 0.5733900666236877, 0.5708909630775452, 0.5498631596565247, 0.537830114364624, 0.5309711694717407, 0.518944263458252, 0.5158842206001282, 0.5009414553642273, 0.5070982575416565, 0.5133102536201477, 0.49861201643943787, 0.4958290457725525, 0.4912686347961426, 0.48861971497535706, 0.4872983396053314, 0.48691704869270325, 0.4938187599182129, 0.48716917634010315, 0.4846438765525818, 0.48514872789382935, 0.492420494556427, 0.4834328293800354, 0.48286741971969604, 0.4901827871799469, 0.48408693075180054, 0.4811146557331085, 0.4808414876461029, 0.48045676946640015, 0.48519259691238403, 0.47943738102912903, 0.4820890426635742, 0.4796167314052582, 0.48084232211112976, 0.47709327936172485, 0.4765687882900238, 0.4776310622692108, 0.48112595081329346, 0.47591632604599, 0.476062536239624, 0.47116076946258545, 0.47282564640045166, 0.4728439152240753, 0.4680376946926117, 0.47003278136253357, 0.46572673320770264, 0.46517834067344666, 0.4721188545227051, 0.473876953125, 0.46328386664390564, 0.46316155791282654, 0.46306896209716797, 0.4616559147834778, 0.46745073795318604, 0.4590959846973419, 0.4643896222114563, 0.4595367908477783, 0.4588117301464081, 0.4631761610507965, 0.4571492373943329, 0.45743632316589355, 0.45829275250434875, 0.45712971687316895, 0.4552142024040222, 0.4535512626171112, 0.4531278610229492, 0.4506245255470276, 0.45748215913772583, 0.4683030843734741, 0.48489272594451904, 0.457180917263031, 0.45325663685798645, 0.45068639516830444, 0.46421101689338684, 0.44432759284973145, 0.44540420174598694, 0.4466146230697632, 0.4528951644897461, 0.4479838013648987, 0.44644132256507874, 0.44421225786209106, 0.44377315044403076, 0.44889387488365173, 0.4459967017173767, 0.45751476287841797, 0.4393545389175415, 0.4403627812862396], 'val_accuracy': [0.6895074844360352, 0.6713061928749084, 0.5428265333175659, 0.599571704864502, 0.6209850311279297, 0.7012848258018494, 0.7109207510948181, 0.7259100675582886, 0.7291220426559448, 0.7419700026512146, 0.7419700026512146, 0.7462526559829712, 0.7483940124511719, 0.7451820373535156, 0.7473233342170715, 0.7462526559829712, 0.7419700026512146, 0.7483940124511719, 0.7526766657829285, 0.759100615978241, 0.7558886408805847, 0.7548179626464844, 0.7569593191146851, 0.7601712942123413, 0.7655246257781982, 0.7644539475440979, 0.7762312889099121, 0.7655246257781982, 0.7687366008758545, 0.7676659822463989, 0.7719486355781555, 0.7730192542076111, 0.7751606106758118, 0.7751606106758118, 0.7762312889099121, 0.7740899324417114, 0.7751606106758118, 0.7762312889099121, 0.778372585773468, 0.7740899324417114, 0.7794432640075684, 0.7794432640075684, 0.7762312889099121, 0.7751606106758118, 0.783725917339325, 0.7826552391052246, 0.7826552391052246, 0.778372585773468, 0.7880085706710815, 0.7762312889099121, 0.7773019075393677, 0.7773019075393677, 0.7847965955734253, 0.7805139422416687, 0.7901498675346375, 0.7912205457687378, 0.7933619022369385, 0.7933619022369385, 0.794432520866394, 0.7901498675346375, 0.7847965955734253, 0.7826552391052246, 0.7976445555686951, 0.7965738773345947, 0.7955031991004944, 0.802997887134552, 0.7890792489051819, 0.8062098622322083, 0.7976445555686951, 0.8062098622322083, 0.7922912240028381, 0.799785852432251, 0.7912205457687378, 0.8019272089004517, 0.8040685057640076, 0.7912205457687378, 0.8040685057640076, 0.8062098622322083, 0.8051391839981079, 0.8062098622322083, 0.7922912240028381, 0.7901498675346375, 0.778372585773468, 0.7933619022369385, 0.799785852432251, 0.8008565306663513, 0.7901498675346375, 0.8072805404663086, 0.8072805404663086, 0.8115631937980652, 0.802997887134552, 0.8051391839981079, 0.8062098622322083, 0.8137044906616211, 0.8104925155639648, 0.8051391839981079, 0.8072805404663086, 0.8040685057640076, 0.8169164657592773, 0.8158458471298218]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 54ms/step - loss: 0.4066 - accuracy: 0.8184 - val_loss: 0.6769 - val_accuracy: 0.7173\n","Epoch 2/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4038 - accuracy: 0.8227 - val_loss: 0.6735 - val_accuracy: 0.7291\n","Epoch 3/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4000 - accuracy: 0.8294 - val_loss: 0.6704 - val_accuracy: 0.6756\n","Epoch 4/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4055 - accuracy: 0.8221 - val_loss: 0.6646 - val_accuracy: 0.7516\n","Epoch 5/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3881 - accuracy: 0.8403 - val_loss: 0.6600 - val_accuracy: 0.7612\n","Epoch 6/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3901 - accuracy: 0.8318 - val_loss: 0.6531 - val_accuracy: 0.7570\n","Epoch 7/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3851 - accuracy: 0.8344 - val_loss: 0.6456 - val_accuracy: 0.7591\n","Epoch 8/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3824 - accuracy: 0.8326 - val_loss: 0.6383 - val_accuracy: 0.7548\n","Epoch 9/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3804 - accuracy: 0.8387 - val_loss: 0.6292 - val_accuracy: 0.7505\n","Epoch 10/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3794 - accuracy: 0.8387 - val_loss: 0.6143 - val_accuracy: 0.7677\n","Epoch 11/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3722 - accuracy: 0.8428 - val_loss: 0.5996 - val_accuracy: 0.7719\n","Epoch 12/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3727 - accuracy: 0.8406 - val_loss: 0.5853 - val_accuracy: 0.7741\n","Epoch 13/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3710 - accuracy: 0.8428 - val_loss: 0.5675 - val_accuracy: 0.7794\n","Epoch 14/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.3670 - accuracy: 0.8462 - val_loss: 0.5471 - val_accuracy: 0.7816\n","Epoch 15/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3692 - accuracy: 0.8428 - val_loss: 0.5311 - val_accuracy: 0.7816\n","Epoch 16/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3581 - accuracy: 0.8508 - val_loss: 0.5067 - val_accuracy: 0.7880\n","Epoch 17/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3617 - accuracy: 0.8500 - val_loss: 0.4934 - val_accuracy: 0.7816\n","Epoch 18/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3577 - accuracy: 0.8484 - val_loss: 0.4685 - val_accuracy: 0.7859\n","Epoch 19/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3616 - accuracy: 0.8486 - val_loss: 0.4604 - val_accuracy: 0.7869\n","Epoch 20/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3536 - accuracy: 0.8556 - val_loss: 0.4656 - val_accuracy: 0.7912\n","Epoch 21/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3500 - accuracy: 0.8545 - val_loss: 0.4386 - val_accuracy: 0.7966\n","Epoch 22/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3439 - accuracy: 0.8607 - val_loss: 0.4913 - val_accuracy: 0.7805\n","Epoch 23/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3533 - accuracy: 0.8521 - val_loss: 0.4416 - val_accuracy: 0.7901\n","Epoch 24/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3482 - accuracy: 0.8594 - val_loss: 0.4308 - val_accuracy: 0.7987\n","Epoch 25/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3482 - accuracy: 0.8556 - val_loss: 0.4532 - val_accuracy: 0.7891\n","Epoch 26/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3576 - accuracy: 0.8508 - val_loss: 0.4443 - val_accuracy: 0.7934\n","Epoch 27/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3355 - accuracy: 0.8610 - val_loss: 0.4377 - val_accuracy: 0.8019\n","Epoch 28/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3333 - accuracy: 0.8647 - val_loss: 0.4444 - val_accuracy: 0.7998\n","Epoch 29/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3308 - accuracy: 0.8674 - val_loss: 0.4506 - val_accuracy: 0.7944\n","Epoch 30/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3327 - accuracy: 0.8669 - val_loss: 0.4422 - val_accuracy: 0.8094\n","Epoch 31/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3267 - accuracy: 0.8706 - val_loss: 0.4435 - val_accuracy: 0.8105\n","Epoch 32/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3278 - accuracy: 0.8701 - val_loss: 0.4462 - val_accuracy: 0.8051\n","Epoch 33/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3367 - accuracy: 0.8615 - val_loss: 0.4694 - val_accuracy: 0.7944\n","Epoch 34/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3342 - accuracy: 0.8588 - val_loss: 0.4462 - val_accuracy: 0.8073\n","Epoch 35/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3315 - accuracy: 0.8647 - val_loss: 0.4462 - val_accuracy: 0.7998\n","Epoch 36/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3224 - accuracy: 0.8706 - val_loss: 0.4516 - val_accuracy: 0.8009\n","Epoch 37/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3219 - accuracy: 0.8687 - val_loss: 0.4458 - val_accuracy: 0.8084\n","Epoch 38/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3170 - accuracy: 0.8733 - val_loss: 0.4486 - val_accuracy: 0.8105\n","Epoch 39/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3169 - accuracy: 0.8722 - val_loss: 0.4646 - val_accuracy: 0.7966\n","Epoch 40/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3191 - accuracy: 0.8711 - val_loss: 0.4515 - val_accuracy: 0.8105\n","Epoch 41/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3149 - accuracy: 0.8728 - val_loss: 0.4478 - val_accuracy: 0.8084\n","Epoch 42/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3048 - accuracy: 0.8829 - val_loss: 0.4491 - val_accuracy: 0.8084\n","Epoch 43/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3055 - accuracy: 0.8762 - val_loss: 0.4602 - val_accuracy: 0.8030\n","Epoch 44/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3059 - accuracy: 0.8837 - val_loss: 0.4556 - val_accuracy: 0.8073\n","Epoch 45/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3046 - accuracy: 0.8768 - val_loss: 0.4485 - val_accuracy: 0.8094\n","Epoch 46/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3019 - accuracy: 0.8797 - val_loss: 0.4534 - val_accuracy: 0.8105\n","Epoch 47/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2951 - accuracy: 0.8845 - val_loss: 0.4540 - val_accuracy: 0.8084\n","Epoch 48/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3002 - accuracy: 0.8800 - val_loss: 0.4584 - val_accuracy: 0.8116\n","Epoch 49/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3054 - accuracy: 0.8848 - val_loss: 0.4507 - val_accuracy: 0.8137\n","Epoch 50/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2976 - accuracy: 0.8862 - val_loss: 0.4651 - val_accuracy: 0.7998\n","Epoch 51/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2934 - accuracy: 0.8878 - val_loss: 0.4530 - val_accuracy: 0.8137\n","Epoch 52/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2834 - accuracy: 0.8904 - val_loss: 0.4594 - val_accuracy: 0.8094\n","Epoch 53/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2819 - accuracy: 0.8894 - val_loss: 0.4636 - val_accuracy: 0.8073\n","Epoch 54/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2829 - accuracy: 0.8931 - val_loss: 0.4560 - val_accuracy: 0.8148\n","Epoch 55/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2808 - accuracy: 0.8896 - val_loss: 0.4670 - val_accuracy: 0.8051\n","Epoch 56/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2833 - accuracy: 0.8891 - val_loss: 0.4904 - val_accuracy: 0.7998\n","Epoch 57/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2851 - accuracy: 0.8888 - val_loss: 0.4674 - val_accuracy: 0.8062\n","Epoch 58/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2811 - accuracy: 0.8910 - val_loss: 0.4566 - val_accuracy: 0.8158\n","Epoch 59/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2830 - accuracy: 0.8939 - val_loss: 0.4749 - val_accuracy: 0.8084\n","Epoch 60/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2764 - accuracy: 0.8937 - val_loss: 0.4572 - val_accuracy: 0.8137\n","Epoch 61/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2681 - accuracy: 0.8987 - val_loss: 0.4615 - val_accuracy: 0.8126\n","Epoch 62/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2686 - accuracy: 0.8990 - val_loss: 0.4624 - val_accuracy: 0.8126\n","Epoch 63/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2669 - accuracy: 0.9001 - val_loss: 0.4627 - val_accuracy: 0.8126\n","Epoch 64/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2743 - accuracy: 0.8947 - val_loss: 0.4697 - val_accuracy: 0.8073\n","Epoch 65/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.2699 - accuracy: 0.8969 - val_loss: 0.4621 - val_accuracy: 0.8169\n","Epoch 66/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2577 - accuracy: 0.9054 - val_loss: 0.4635 - val_accuracy: 0.8148\n","Epoch 67/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2756 - accuracy: 0.8915 - val_loss: 0.4727 - val_accuracy: 0.8105\n","Epoch 68/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2583 - accuracy: 0.9028 - val_loss: 0.4639 - val_accuracy: 0.8148\n","Epoch 69/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2661 - accuracy: 0.9017 - val_loss: 0.4868 - val_accuracy: 0.7966\n","Epoch 70/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2628 - accuracy: 0.8974 - val_loss: 0.4671 - val_accuracy: 0.8073\n","Epoch 71/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2518 - accuracy: 0.9076 - val_loss: 0.4806 - val_accuracy: 0.8030\n","Epoch 72/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2536 - accuracy: 0.9062 - val_loss: 0.4789 - val_accuracy: 0.8094\n","Epoch 73/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2471 - accuracy: 0.9078 - val_loss: 0.4801 - val_accuracy: 0.8073\n","Epoch 74/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2466 - accuracy: 0.9095 - val_loss: 0.4721 - val_accuracy: 0.8191\n","Epoch 75/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2416 - accuracy: 0.9100 - val_loss: 0.4825 - val_accuracy: 0.8158\n","Epoch 76/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2442 - accuracy: 0.9076 - val_loss: 0.4864 - val_accuracy: 0.8051\n","Epoch 77/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2519 - accuracy: 0.9033 - val_loss: 0.4748 - val_accuracy: 0.8201\n","Epoch 78/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2380 - accuracy: 0.9121 - val_loss: 0.4911 - val_accuracy: 0.8084\n","Epoch 79/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2414 - accuracy: 0.9137 - val_loss: 0.4868 - val_accuracy: 0.8137\n","Epoch 80/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2415 - accuracy: 0.9100 - val_loss: 0.4896 - val_accuracy: 0.8137\n","Epoch 81/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2443 - accuracy: 0.9041 - val_loss: 0.4808 - val_accuracy: 0.8137\n","Epoch 82/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2398 - accuracy: 0.9121 - val_loss: 0.4862 - val_accuracy: 0.8073\n","Epoch 83/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2459 - accuracy: 0.9057 - val_loss: 0.4871 - val_accuracy: 0.8105\n","Epoch 84/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2307 - accuracy: 0.9167 - val_loss: 0.4815 - val_accuracy: 0.8180\n","Epoch 85/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2215 - accuracy: 0.9202 - val_loss: 0.4841 - val_accuracy: 0.8201\n","Epoch 86/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2216 - accuracy: 0.9223 - val_loss: 0.4893 - val_accuracy: 0.8201\n","Epoch 87/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2216 - accuracy: 0.9207 - val_loss: 0.4930 - val_accuracy: 0.8169\n","Epoch 88/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2220 - accuracy: 0.9191 - val_loss: 0.4920 - val_accuracy: 0.8169\n","Epoch 89/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2254 - accuracy: 0.9121 - val_loss: 0.5064 - val_accuracy: 0.8084\n","Epoch 90/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2178 - accuracy: 0.9210 - val_loss: 0.4931 - val_accuracy: 0.8137\n","Epoch 91/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2158 - accuracy: 0.9210 - val_loss: 0.5144 - val_accuracy: 0.8137\n","Epoch 92/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2166 - accuracy: 0.9234 - val_loss: 0.5109 - val_accuracy: 0.8126\n","Epoch 93/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2164 - accuracy: 0.9239 - val_loss: 0.5111 - val_accuracy: 0.8105\n","Epoch 94/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2129 - accuracy: 0.9245 - val_loss: 0.4976 - val_accuracy: 0.8148\n","Epoch 95/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2041 - accuracy: 0.9255 - val_loss: 0.5044 - val_accuracy: 0.8180\n","Epoch 96/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2059 - accuracy: 0.9271 - val_loss: 0.5083 - val_accuracy: 0.8169\n","Epoch 97/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2051 - accuracy: 0.9271 - val_loss: 0.5043 - val_accuracy: 0.8158\n","Epoch 98/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2001 - accuracy: 0.9269 - val_loss: 0.5100 - val_accuracy: 0.8158\n","Epoch 99/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2031 - accuracy: 0.9287 - val_loss: 0.5104 - val_accuracy: 0.8169\n","Epoch 100/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2078 - accuracy: 0.9207 - val_loss: 0.5179 - val_accuracy: 0.8191\n","{'loss': [0.4066285490989685, 0.4038103520870209, 0.399959534406662, 0.40546107292175293, 0.38810795545578003, 0.390089750289917, 0.38508203625679016, 0.3823767304420471, 0.38042929768562317, 0.37938350439071655, 0.37223488092422485, 0.3727371096611023, 0.3710464537143707, 0.3670045733451843, 0.36915746331214905, 0.3580586016178131, 0.36168771982192993, 0.3577234447002411, 0.3615812063217163, 0.3535747230052948, 0.3499833941459656, 0.34385019540786743, 0.3532547950744629, 0.3482336401939392, 0.3481542766094208, 0.35764676332473755, 0.33546698093414307, 0.3333263397216797, 0.33081063628196716, 0.3327109217643738, 0.326698899269104, 0.3277739882469177, 0.33672675490379333, 0.3341562747955322, 0.33149459958076477, 0.3224460780620575, 0.32192423939704895, 0.31703197956085205, 0.31691378355026245, 0.3191365897655487, 0.31486260890960693, 0.30477526783943176, 0.3055483400821686, 0.3059369921684265, 0.3045991361141205, 0.3019498586654663, 0.29506757855415344, 0.300222247838974, 0.30535832047462463, 0.2976211905479431, 0.29336386919021606, 0.28337937593460083, 0.28193676471710205, 0.28294214606285095, 0.2807520627975464, 0.2833154499530792, 0.28514084219932556, 0.28108081221580505, 0.2830273509025574, 0.27638566493988037, 0.26811671257019043, 0.2685677111148834, 0.266918808221817, 0.27431580424308777, 0.26986441016197205, 0.25765755772590637, 0.2755852937698364, 0.2582884728908539, 0.266117125749588, 0.26279160380363464, 0.2518391013145447, 0.2536439895629883, 0.24707816541194916, 0.24656857550144196, 0.24163903295993805, 0.2441844791173935, 0.25188684463500977, 0.23796814680099487, 0.2414175122976303, 0.24146775901317596, 0.24429771304130554, 0.23984895646572113, 0.24585317075252533, 0.23070165514945984, 0.22145842015743256, 0.22158238291740417, 0.2215890884399414, 0.22198373079299927, 0.22539545595645905, 0.21782062947750092, 0.21576698124408722, 0.2166300266981125, 0.21635417640209198, 0.21292421221733093, 0.20407548546791077, 0.2059364914894104, 0.20505309104919434, 0.2001078724861145, 0.20306776463985443, 0.20776289701461792], 'accuracy': [0.8183766603469849, 0.8226627111434937, 0.829359769821167, 0.8221269845962524, 0.8403428792953491, 0.8317707180976868, 0.8344495296478271, 0.8325743079185486, 0.8387355804443359, 0.8387355804443359, 0.8427538275718689, 0.8406107425689697, 0.8427538275718689, 0.8462362885475159, 0.8427538275718689, 0.85079026222229, 0.8499866127967834, 0.8483793139457703, 0.8486471772193909, 0.8556120991706848, 0.8545405864715576, 0.860701858997345, 0.8521296381950378, 0.8593624234199524, 0.8556120991706848, 0.85079026222229, 0.8609697222709656, 0.8647200465202332, 0.8673988580703735, 0.8668631315231323, 0.8706134557723999, 0.8700776696205139, 0.8615055084228516, 0.8588266968727112, 0.8647200465202332, 0.8706134557723999, 0.8687382936477661, 0.8732922673225403, 0.8722207546234131, 0.8711491823196411, 0.8727564811706543, 0.8829360008239746, 0.8762389421463013, 0.8837395906448364, 0.8767747282981873, 0.8797214031219482, 0.884543240070343, 0.8799892663955688, 0.8848111629486084, 0.8861505389213562, 0.8877578377723694, 0.8904366493225098, 0.8893651366233826, 0.8931154608726501, 0.8896329998970032, 0.8890972137451172, 0.8888293504714966, 0.8909724354743958, 0.8939191102981567, 0.8936512470245361, 0.8987409472465515, 0.8990088105201721, 0.9000803828239441, 0.8947227597236633, 0.8968657851219177, 0.9054380059242249, 0.891508162021637, 0.9027591943740845, 0.9016876220703125, 0.8974015712738037, 0.9075810313224792, 0.9062416553497314, 0.9078488945960999, 0.909456193447113, 0.909991979598999, 0.9075810313224792, 0.9032949209213257, 0.9121350049972534, 0.9137423038482666, 0.909991979598999, 0.9040985703468323, 0.9121350049972534, 0.9057058691978455, 0.9166889786720276, 0.9201714396476746, 0.922314465045929, 0.9207072257995605, 0.9190999269485474, 0.9121350049972534, 0.9209750890731812, 0.9209750890731812, 0.9233860373497009, 0.9239217638969421, 0.9244575500488281, 0.9255290627479553, 0.9271363615989685, 0.9271363615989685, 0.9268684983253479, 0.9287436604499817, 0.9207072257995605], 'val_loss': [0.6769341230392456, 0.6735410690307617, 0.6704497337341309, 0.6646003723144531, 0.6599732041358948, 0.6531215906143188, 0.6455869078636169, 0.6382641196250916, 0.6291922926902771, 0.6142854690551758, 0.5996152758598328, 0.5853287577629089, 0.5675433874130249, 0.547094464302063, 0.531052827835083, 0.5067375302314758, 0.493373841047287, 0.468495637178421, 0.46037623286247253, 0.465582937002182, 0.4386080503463745, 0.4912797510623932, 0.44163838028907776, 0.4307762086391449, 0.45321381092071533, 0.4443456530570984, 0.43772661685943604, 0.44437935948371887, 0.450551837682724, 0.4422077536582947, 0.44354692101478577, 0.4462282657623291, 0.46941423416137695, 0.4462223947048187, 0.44617345929145813, 0.4516356289386749, 0.4458167552947998, 0.44862738251686096, 0.4646317958831787, 0.4514547288417816, 0.4477847218513489, 0.44906654953956604, 0.4601878821849823, 0.4555545151233673, 0.4485102891921997, 0.4533655643463135, 0.4540158212184906, 0.45837637782096863, 0.45068830251693726, 0.4650534987449646, 0.45301753282546997, 0.4593743681907654, 0.46361419558525085, 0.45596012473106384, 0.46695274114608765, 0.49040529131889343, 0.4674444794654846, 0.4566403031349182, 0.4749376177787781, 0.4572015404701233, 0.4614697992801666, 0.46240347623825073, 0.4626561999320984, 0.4697338044643402, 0.4620981812477112, 0.4635305404663086, 0.4727417826652527, 0.4639228582382202, 0.4867810010910034, 0.46714770793914795, 0.4806247651576996, 0.478861004114151, 0.4800691604614258, 0.4720804691314697, 0.4825034737586975, 0.48640337586402893, 0.4747520387172699, 0.4910789430141449, 0.48677781224250793, 0.48959848284721375, 0.480773001909256, 0.48617517948150635, 0.48707109689712524, 0.48146113753318787, 0.48406723141670227, 0.48931750655174255, 0.4930420219898224, 0.491964727640152, 0.506415069103241, 0.4931236207485199, 0.5143651962280273, 0.510891318321228, 0.511128306388855, 0.4976351261138916, 0.5044326782226562, 0.5082775950431824, 0.5043496489524841, 0.5099794268608093, 0.5103633403778076, 0.5178878307342529], 'val_accuracy': [0.7173447608947754, 0.7291220426559448, 0.675588846206665, 0.7516059875488281, 0.7612419724464417, 0.7569593191146851, 0.759100615978241, 0.7548179626464844, 0.7505353093147278, 0.7676659822463989, 0.7719486355781555, 0.7740899324417114, 0.7794432640075684, 0.7815845608711243, 0.7815845608711243, 0.7880085706710815, 0.7815845608711243, 0.7858672142028809, 0.7869378924369812, 0.7912205457687378, 0.7965738773345947, 0.7805139422416687, 0.7901498675346375, 0.7987151741981506, 0.7890792489051819, 0.7933619022369385, 0.8019272089004517, 0.799785852432251, 0.794432520866394, 0.8094218373298645, 0.8104925155639648, 0.8051391839981079, 0.794432520866394, 0.8072805404663086, 0.799785852432251, 0.8008565306663513, 0.8083511590957642, 0.8104925155639648, 0.7965738773345947, 0.8104925155639648, 0.8083511590957642, 0.8083511590957642, 0.802997887134552, 0.8072805404663086, 0.8094218373298645, 0.8104925155639648, 0.8083511590957642, 0.8115631937980652, 0.8137044906616211, 0.799785852432251, 0.8137044906616211, 0.8094218373298645, 0.8072805404663086, 0.8147751688957214, 0.8051391839981079, 0.799785852432251, 0.8062098622322083, 0.8158458471298218, 0.8083511590957642, 0.8137044906616211, 0.8126338124275208, 0.8126338124275208, 0.8126338124275208, 0.8072805404663086, 0.8169164657592773, 0.8147751688957214, 0.8104925155639648, 0.8147751688957214, 0.7965738773345947, 0.8072805404663086, 0.802997887134552, 0.8094218373298645, 0.8072805404663086, 0.819057822227478, 0.8158458471298218, 0.8051391839981079, 0.8201285004615784, 0.8083511590957642, 0.8137044906616211, 0.8137044906616211, 0.8137044906616211, 0.8072805404663086, 0.8104925155639648, 0.8179871439933777, 0.8201285004615784, 0.8201285004615784, 0.8169164657592773, 0.8169164657592773, 0.8083511590957642, 0.8137044906616211, 0.8137044906616211, 0.8126338124275208, 0.8104925155639648, 0.8147751688957214, 0.8179871439933777, 0.8169164657592773, 0.8158458471298218, 0.8158458471298218, 0.8169164657592773, 0.819057822227478]}\n","37/37 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 9s 51ms/step - loss: 0.4073 - accuracy: 0.8216 - val_loss: 0.6757 - val_accuracy: 0.7505\n","Epoch 2/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4048 - accuracy: 0.8197 - val_loss: 0.6720 - val_accuracy: 0.7473\n","Epoch 3/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4039 - accuracy: 0.8224 - val_loss: 0.6692 - val_accuracy: 0.6713\n","Epoch 4/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3960 - accuracy: 0.8240 - val_loss: 0.6636 - val_accuracy: 0.7398\n","Epoch 5/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3892 - accuracy: 0.8288 - val_loss: 0.6575 - val_accuracy: 0.7752\n","Epoch 6/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3888 - accuracy: 0.8299 - val_loss: 0.6526 - val_accuracy: 0.7206\n","Epoch 7/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3883 - accuracy: 0.8291 - val_loss: 0.6433 - val_accuracy: 0.7794\n","Epoch 8/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3917 - accuracy: 0.8253 - val_loss: 0.6347 - val_accuracy: 0.7752\n","Epoch 9/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3932 - accuracy: 0.8328 - val_loss: 0.6222 - val_accuracy: 0.7944\n","Epoch 10/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3798 - accuracy: 0.8315 - val_loss: 0.6102 - val_accuracy: 0.7869\n","Epoch 11/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3803 - accuracy: 0.8312 - val_loss: 0.5958 - val_accuracy: 0.7987\n","Epoch 12/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3767 - accuracy: 0.8320 - val_loss: 0.5745 - val_accuracy: 0.8137\n","Epoch 13/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3750 - accuracy: 0.8411 - val_loss: 0.5551 - val_accuracy: 0.8169\n","Epoch 14/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3717 - accuracy: 0.8401 - val_loss: 0.5339 - val_accuracy: 0.8148\n","Epoch 15/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3724 - accuracy: 0.8409 - val_loss: 0.5114 - val_accuracy: 0.8062\n","Epoch 16/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3690 - accuracy: 0.8406 - val_loss: 0.4850 - val_accuracy: 0.8298\n","Epoch 17/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3700 - accuracy: 0.8414 - val_loss: 0.4645 - val_accuracy: 0.8266\n","Epoch 18/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3647 - accuracy: 0.8462 - val_loss: 0.4389 - val_accuracy: 0.8276\n","Epoch 19/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3604 - accuracy: 0.8495 - val_loss: 0.4190 - val_accuracy: 0.8319\n","Epoch 20/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3614 - accuracy: 0.8460 - val_loss: 0.4066 - val_accuracy: 0.8383\n","Epoch 21/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3593 - accuracy: 0.8497 - val_loss: 0.3913 - val_accuracy: 0.8287\n","Epoch 22/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3554 - accuracy: 0.8508 - val_loss: 0.3822 - val_accuracy: 0.8330\n","Epoch 23/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3536 - accuracy: 0.8508 - val_loss: 0.3767 - val_accuracy: 0.8340\n","Epoch 24/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3530 - accuracy: 0.8604 - val_loss: 0.3814 - val_accuracy: 0.8308\n","Epoch 25/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3516 - accuracy: 0.8545 - val_loss: 0.3743 - val_accuracy: 0.8373\n","Epoch 26/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3500 - accuracy: 0.8527 - val_loss: 0.3833 - val_accuracy: 0.8287\n","Epoch 27/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3482 - accuracy: 0.8532 - val_loss: 0.3724 - val_accuracy: 0.8426\n","Epoch 28/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3449 - accuracy: 0.8543 - val_loss: 0.3689 - val_accuracy: 0.8480\n","Epoch 29/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3409 - accuracy: 0.8586 - val_loss: 0.3671 - val_accuracy: 0.8533\n","Epoch 30/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3431 - accuracy: 0.8610 - val_loss: 0.3673 - val_accuracy: 0.8480\n","Epoch 31/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3377 - accuracy: 0.8551 - val_loss: 0.3757 - val_accuracy: 0.8469\n","Epoch 32/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3485 - accuracy: 0.8521 - val_loss: 0.3668 - val_accuracy: 0.8501\n","Epoch 33/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3309 - accuracy: 0.8639 - val_loss: 0.3817 - val_accuracy: 0.8426\n","Epoch 34/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3384 - accuracy: 0.8602 - val_loss: 0.3714 - val_accuracy: 0.8362\n","Epoch 35/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3348 - accuracy: 0.8602 - val_loss: 0.3719 - val_accuracy: 0.8340\n","Epoch 36/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3292 - accuracy: 0.8669 - val_loss: 0.3675 - val_accuracy: 0.8544\n","Epoch 37/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3289 - accuracy: 0.8645 - val_loss: 0.3708 - val_accuracy: 0.8383\n","Epoch 38/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3253 - accuracy: 0.8639 - val_loss: 0.3678 - val_accuracy: 0.8448\n","Epoch 39/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3205 - accuracy: 0.8677 - val_loss: 0.3758 - val_accuracy: 0.8512\n","Epoch 40/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3204 - accuracy: 0.8671 - val_loss: 0.3685 - val_accuracy: 0.8576\n","Epoch 41/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3159 - accuracy: 0.8760 - val_loss: 0.3728 - val_accuracy: 0.8383\n","Epoch 42/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3196 - accuracy: 0.8663 - val_loss: 0.3694 - val_accuracy: 0.8394\n","Epoch 43/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.3206 - accuracy: 0.8706 - val_loss: 0.3890 - val_accuracy: 0.8437\n","Epoch 44/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3135 - accuracy: 0.8728 - val_loss: 0.3692 - val_accuracy: 0.8448\n","Epoch 45/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3099 - accuracy: 0.8738 - val_loss: 0.3707 - val_accuracy: 0.8415\n","Epoch 46/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3089 - accuracy: 0.8722 - val_loss: 0.3680 - val_accuracy: 0.8501\n","Epoch 47/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3115 - accuracy: 0.8757 - val_loss: 0.3879 - val_accuracy: 0.8340\n","Epoch 48/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3077 - accuracy: 0.8781 - val_loss: 0.3682 - val_accuracy: 0.8501\n","Epoch 49/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3031 - accuracy: 0.8797 - val_loss: 0.3718 - val_accuracy: 0.8458\n","Epoch 50/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3028 - accuracy: 0.8773 - val_loss: 0.3707 - val_accuracy: 0.8426\n","Epoch 51/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2945 - accuracy: 0.8870 - val_loss: 0.3717 - val_accuracy: 0.8533\n","Epoch 52/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2979 - accuracy: 0.8827 - val_loss: 0.3747 - val_accuracy: 0.8565\n","Epoch 53/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2946 - accuracy: 0.8853 - val_loss: 0.3732 - val_accuracy: 0.8501\n","Epoch 54/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2992 - accuracy: 0.8789 - val_loss: 0.4313 - val_accuracy: 0.8137\n","Epoch 55/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2996 - accuracy: 0.8797 - val_loss: 0.3736 - val_accuracy: 0.8555\n","Epoch 56/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2839 - accuracy: 0.8878 - val_loss: 0.3739 - val_accuracy: 0.8522\n","Epoch 57/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2842 - accuracy: 0.8894 - val_loss: 0.3753 - val_accuracy: 0.8490\n","Epoch 58/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2876 - accuracy: 0.8878 - val_loss: 0.3800 - val_accuracy: 0.8501\n","Epoch 59/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2804 - accuracy: 0.8904 - val_loss: 0.3804 - val_accuracy: 0.8522\n","Epoch 60/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2919 - accuracy: 0.8776 - val_loss: 0.3925 - val_accuracy: 0.8298\n","Epoch 61/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2872 - accuracy: 0.8875 - val_loss: 0.3906 - val_accuracy: 0.8437\n","Epoch 62/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2837 - accuracy: 0.8888 - val_loss: 0.3861 - val_accuracy: 0.8340\n","Epoch 63/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2750 - accuracy: 0.8942 - val_loss: 0.3850 - val_accuracy: 0.8490\n","Epoch 64/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2736 - accuracy: 0.8953 - val_loss: 0.3786 - val_accuracy: 0.8512\n","Epoch 65/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2771 - accuracy: 0.8923 - val_loss: 0.3994 - val_accuracy: 0.8298\n","Epoch 66/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2725 - accuracy: 0.8958 - val_loss: 0.3832 - val_accuracy: 0.8448\n","Epoch 67/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2694 - accuracy: 0.8953 - val_loss: 0.3821 - val_accuracy: 0.8480\n","Epoch 68/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2670 - accuracy: 0.8971 - val_loss: 0.3807 - val_accuracy: 0.8512\n","Epoch 69/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2625 - accuracy: 0.8998 - val_loss: 0.4123 - val_accuracy: 0.8287\n","Epoch 70/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2633 - accuracy: 0.8955 - val_loss: 0.3887 - val_accuracy: 0.8458\n","Epoch 71/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2590 - accuracy: 0.9044 - val_loss: 0.4055 - val_accuracy: 0.8308\n","Epoch 72/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2594 - accuracy: 0.9014 - val_loss: 0.3849 - val_accuracy: 0.8480\n","Epoch 73/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2537 - accuracy: 0.9076 - val_loss: 0.4309 - val_accuracy: 0.8244\n","Epoch 74/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2628 - accuracy: 0.8979 - val_loss: 0.3883 - val_accuracy: 0.8501\n","Epoch 75/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2517 - accuracy: 0.9057 - val_loss: 0.3925 - val_accuracy: 0.8469\n","Epoch 76/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2536 - accuracy: 0.9060 - val_loss: 0.3926 - val_accuracy: 0.8448\n","Epoch 77/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2459 - accuracy: 0.9095 - val_loss: 0.3944 - val_accuracy: 0.8490\n","Epoch 78/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2421 - accuracy: 0.9097 - val_loss: 0.4443 - val_accuracy: 0.8233\n","Epoch 79/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2415 - accuracy: 0.9084 - val_loss: 0.4013 - val_accuracy: 0.8405\n","Epoch 80/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2460 - accuracy: 0.9113 - val_loss: 0.4024 - val_accuracy: 0.8383\n","Epoch 81/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2419 - accuracy: 0.9105 - val_loss: 0.3998 - val_accuracy: 0.8448\n","Epoch 82/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2470 - accuracy: 0.9073 - val_loss: 0.4127 - val_accuracy: 0.8383\n","Epoch 83/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2410 - accuracy: 0.9103 - val_loss: 0.4051 - val_accuracy: 0.8405\n","Epoch 84/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2453 - accuracy: 0.9049 - val_loss: 0.4349 - val_accuracy: 0.8244\n","Epoch 85/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2357 - accuracy: 0.9162 - val_loss: 0.4490 - val_accuracy: 0.8244\n","Epoch 86/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2448 - accuracy: 0.9052 - val_loss: 0.4905 - val_accuracy: 0.8105\n","Epoch 87/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2661 - accuracy: 0.8993 - val_loss: 0.3975 - val_accuracy: 0.8394\n","Epoch 88/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2401 - accuracy: 0.9121 - val_loss: 0.3999 - val_accuracy: 0.8405\n","Epoch 89/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2270 - accuracy: 0.9172 - val_loss: 0.4030 - val_accuracy: 0.8405\n","Epoch 90/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2213 - accuracy: 0.9191 - val_loss: 0.3960 - val_accuracy: 0.8480\n","Epoch 91/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.2236 - accuracy: 0.9196 - val_loss: 0.4010 - val_accuracy: 0.8490\n","Epoch 92/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2284 - accuracy: 0.9159 - val_loss: 0.4075 - val_accuracy: 0.8426\n","Epoch 93/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2213 - accuracy: 0.9186 - val_loss: 0.4060 - val_accuracy: 0.8394\n","Epoch 94/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2162 - accuracy: 0.9199 - val_loss: 0.4212 - val_accuracy: 0.8426\n","Epoch 95/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2162 - accuracy: 0.9183 - val_loss: 0.4170 - val_accuracy: 0.8448\n","Epoch 96/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2202 - accuracy: 0.9196 - val_loss: 0.4185 - val_accuracy: 0.8426\n","Epoch 97/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2117 - accuracy: 0.9250 - val_loss: 0.4117 - val_accuracy: 0.8448\n","Epoch 98/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2113 - accuracy: 0.9253 - val_loss: 0.4172 - val_accuracy: 0.8448\n","Epoch 99/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2098 - accuracy: 0.9261 - val_loss: 0.4170 - val_accuracy: 0.8458\n","Epoch 100/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2075 - accuracy: 0.9242 - val_loss: 0.4192 - val_accuracy: 0.8426\n","{'loss': [0.4072876572608948, 0.40476804971694946, 0.40389391779899597, 0.39598289132118225, 0.38919034600257874, 0.3888401687145233, 0.3883472681045532, 0.3916771113872528, 0.39322802424430847, 0.3798423409461975, 0.38031652569770813, 0.37673741579055786, 0.37504056096076965, 0.37171095609664917, 0.3724285662174225, 0.3689587116241455, 0.36996614933013916, 0.364709734916687, 0.3603871762752533, 0.36139819025993347, 0.35930225253105164, 0.3554193079471588, 0.3535861670970917, 0.35303419828414917, 0.35164833068847656, 0.3499608337879181, 0.34821200370788574, 0.3449054956436157, 0.34086647629737854, 0.3430960476398468, 0.3377036452293396, 0.34851008653640747, 0.3309493660926819, 0.338442862033844, 0.33479490876197815, 0.32916733622550964, 0.3288806676864624, 0.32532915472984314, 0.3205472230911255, 0.32037997245788574, 0.31594592332839966, 0.31959056854248047, 0.3205725848674774, 0.3135145604610443, 0.3099341094493866, 0.3088627755641937, 0.31154686212539673, 0.3077123463153839, 0.3031032681465149, 0.3028126358985901, 0.2944708466529846, 0.2978895902633667, 0.2946350872516632, 0.29917851090431213, 0.29955774545669556, 0.28385376930236816, 0.2841724753379822, 0.2875928282737732, 0.2804497182369232, 0.2918660044670105, 0.2872435450553894, 0.2836751341819763, 0.2750127613544464, 0.273550808429718, 0.2771056592464447, 0.2724991738796234, 0.2693820595741272, 0.26702454686164856, 0.2624981105327606, 0.2633066475391388, 0.25901538133621216, 0.25944265723228455, 0.2537406086921692, 0.26283887028694153, 0.2516743540763855, 0.25359001755714417, 0.2458585649728775, 0.24205835163593292, 0.24149936437606812, 0.24598334729671478, 0.24189171195030212, 0.24697747826576233, 0.24098855257034302, 0.2453029751777649, 0.23574107885360718, 0.24484536051750183, 0.2660852372646332, 0.2401181161403656, 0.22700829803943634, 0.22130349278450012, 0.22363604605197906, 0.22838963568210602, 0.22128278017044067, 0.21622928977012634, 0.21621723473072052, 0.22016967833042145, 0.2116849571466446, 0.21130181849002838, 0.2098422348499298, 0.20749728381633759], 'accuracy': [0.8215911984443665, 0.8197160363197327, 0.822394847869873, 0.8240021467208862, 0.828823983669281, 0.829895555973053, 0.8290919065475464, 0.825341522693634, 0.832842230796814, 0.8315027952194214, 0.8312349319458008, 0.8320385813713074, 0.8411465287208557, 0.8400750160217285, 0.8408786654472351, 0.8406107425689697, 0.8414143919944763, 0.8462362885475159, 0.8494508266448975, 0.8459683656692505, 0.8497187495231628, 0.85079026222229, 0.85079026222229, 0.8604339957237244, 0.8545405864715576, 0.8526654243469238, 0.853201150894165, 0.854272723197937, 0.8585587739944458, 0.8609697222709656, 0.8550763726234436, 0.8521296381950378, 0.8639163970947266, 0.860166072845459, 0.860166072845459, 0.8668631315231323, 0.8644521832466125, 0.8639163970947266, 0.8676667809486389, 0.8671309947967529, 0.8759710788726807, 0.8663273453712463, 0.8706134557723999, 0.8727564811706543, 0.8738279938697815, 0.8722207546234131, 0.8757032155990601, 0.8781141042709351, 0.8797214031219482, 0.8773104548454285, 0.8869541883468628, 0.8826680779457092, 0.8853468894958496, 0.8789177536964417, 0.8797214031219482, 0.8877578377723694, 0.8893651366233826, 0.8877578377723694, 0.8904366493225098, 0.8775783777236938, 0.8874899744987488, 0.8888293504714966, 0.8941869735717773, 0.8952584862709045, 0.8923118114471436, 0.8957942724227905, 0.8952584862709045, 0.8971336483955383, 0.8998124599456787, 0.8955264091491699, 0.9043664336204529, 0.9014197587966919, 0.9075810313224792, 0.8979372978210449, 0.9057058691978455, 0.9059737324714661, 0.909456193447113, 0.9097240567207336, 0.9083846807479858, 0.9113313555717468, 0.9105277061462402, 0.9073131680488586, 0.9102598428726196, 0.9049022197723389, 0.9161532521247864, 0.9051700830459595, 0.8992767333984375, 0.9121350049972534, 0.9172247648239136, 0.9190999269485474, 0.9196356534957886, 0.915885329246521, 0.9185641407966614, 0.919903576374054, 0.9182962775230408, 0.9196356534957886, 0.9249932765960693, 0.9252611994743347, 0.9260648488998413, 0.9241896867752075], 'val_loss': [0.6756899952888489, 0.6720072627067566, 0.6691561341285706, 0.6636374592781067, 0.6575252413749695, 0.6525960564613342, 0.6432558298110962, 0.6347209215164185, 0.6221645474433899, 0.6102336049079895, 0.5958122611045837, 0.5745334029197693, 0.5550529360771179, 0.5338822603225708, 0.5113958120346069, 0.4849541187286377, 0.46451812982559204, 0.4388638138771057, 0.4189518094062805, 0.40664389729499817, 0.39131414890289307, 0.38216862082481384, 0.3766755163669586, 0.3813669979572296, 0.3742755651473999, 0.38333162665367126, 0.3724175691604614, 0.36894190311431885, 0.3671329915523529, 0.3673165738582611, 0.37566938996315, 0.3667866289615631, 0.38170090317726135, 0.37136662006378174, 0.3718757629394531, 0.3675164580345154, 0.37076666951179504, 0.36776965856552124, 0.37582260370254517, 0.368549108505249, 0.37279385328292847, 0.3693774342536926, 0.38897374272346497, 0.3691778779029846, 0.3706762492656708, 0.36799997091293335, 0.3878856301307678, 0.36819520592689514, 0.3717629909515381, 0.37068504095077515, 0.3717253506183624, 0.37465399503707886, 0.37324514985084534, 0.43127870559692383, 0.37355440855026245, 0.37390485405921936, 0.37528014183044434, 0.3800400495529175, 0.3804025650024414, 0.3924619257450104, 0.39057520031929016, 0.38608524203300476, 0.3849867582321167, 0.378597229719162, 0.3993968069553375, 0.3831785023212433, 0.3821188509464264, 0.38068100810050964, 0.4123002588748932, 0.38866984844207764, 0.4054988622665405, 0.3849044442176819, 0.4308628737926483, 0.38831305503845215, 0.3925214409828186, 0.3926280438899994, 0.3944207429885864, 0.4443049430847168, 0.4013291001319885, 0.40241503715515137, 0.39977407455444336, 0.41270387172698975, 0.4050672948360443, 0.4349057078361511, 0.44899237155914307, 0.4904732406139374, 0.39751625061035156, 0.3998906910419464, 0.4029819965362549, 0.3959900736808777, 0.4010373055934906, 0.40745916962623596, 0.4059550166130066, 0.42124423384666443, 0.41702234745025635, 0.4185015559196472, 0.4116627275943756, 0.41720759868621826, 0.41700923442840576, 0.41921013593673706], 'val_accuracy': [0.7505353093147278, 0.7473233342170715, 0.6713061928749084, 0.7398287057876587, 0.7751606106758118, 0.7205567359924316, 0.7794432640075684, 0.7751606106758118, 0.794432520866394, 0.7869378924369812, 0.7987151741981506, 0.8137044906616211, 0.8169164657592773, 0.8147751688957214, 0.8062098622322083, 0.8297644257545471, 0.8265524506568909, 0.8276231288909912, 0.8319057822227478, 0.8383297920227051, 0.8286938071250916, 0.8329764604568481, 0.8340471386909485, 0.8308351039886475, 0.8372591137886047, 0.8286938071250916, 0.8426124453544617, 0.8479657173156738, 0.8533190488815308, 0.8479657173156738, 0.8468950986862183, 0.8501070737838745, 0.8426124453544617, 0.8361884355545044, 0.8340471386909485, 0.8543897271156311, 0.8383297920227051, 0.8447537422180176, 0.8511777520179749, 0.8576017022132874, 0.8383297920227051, 0.8394004106521606, 0.8436830639839172, 0.8447537422180176, 0.8415417671203613, 0.8501070737838745, 0.8340471386909485, 0.8501070737838745, 0.8458244204521179, 0.8426124453544617, 0.8533190488815308, 0.856531023979187, 0.8501070737838745, 0.8137044906616211, 0.8554604053497314, 0.8522483706474304, 0.8490363955497742, 0.8501070737838745, 0.8522483706474304, 0.8297644257545471, 0.8436830639839172, 0.8340471386909485, 0.8490363955497742, 0.8511777520179749, 0.8297644257545471, 0.8447537422180176, 0.8479657173156738, 0.8511777520179749, 0.8286938071250916, 0.8458244204521179, 0.8308351039886475, 0.8479657173156738, 0.824411153793335, 0.8501070737838745, 0.8468950986862183, 0.8447537422180176, 0.8490363955497742, 0.8233404755592346, 0.840471088886261, 0.8383297920227051, 0.8447537422180176, 0.8383297920227051, 0.840471088886261, 0.824411153793335, 0.824411153793335, 0.8104925155639648, 0.8394004106521606, 0.840471088886261, 0.840471088886261, 0.8479657173156738, 0.8490363955497742, 0.8426124453544617, 0.8394004106521606, 0.8426124453544617, 0.8447537422180176, 0.8426124453544617, 0.8447537422180176, 0.8447537422180176, 0.8458244204521179, 0.8426124453544617]}\n","37/37 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 54ms/step - loss: 0.4152 - accuracy: 0.8197 - val_loss: 0.6761 - val_accuracy: 0.7409\n","Epoch 2/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4070 - accuracy: 0.8245 - val_loss: 0.6726 - val_accuracy: 0.7495\n","Epoch 3/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4046 - accuracy: 0.8181 - val_loss: 0.6686 - val_accuracy: 0.7388\n","Epoch 4/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3990 - accuracy: 0.8259 - val_loss: 0.6647 - val_accuracy: 0.7291\n","Epoch 5/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3945 - accuracy: 0.8248 - val_loss: 0.6582 - val_accuracy: 0.7730\n","Epoch 6/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3919 - accuracy: 0.8280 - val_loss: 0.6513 - val_accuracy: 0.7934\n","Epoch 7/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3895 - accuracy: 0.8310 - val_loss: 0.6449 - val_accuracy: 0.7430\n","Epoch 8/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3887 - accuracy: 0.8328 - val_loss: 0.6362 - val_accuracy: 0.7452\n","Epoch 9/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3906 - accuracy: 0.8291 - val_loss: 0.6263 - val_accuracy: 0.7548\n","Epoch 10/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3914 - accuracy: 0.8213 - val_loss: 0.6124 - val_accuracy: 0.8019\n","Epoch 11/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3831 - accuracy: 0.8336 - val_loss: 0.5977 - val_accuracy: 0.7912\n","Epoch 12/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3947 - accuracy: 0.8259 - val_loss: 0.5816 - val_accuracy: 0.7998\n","Epoch 13/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3718 - accuracy: 0.8401 - val_loss: 0.5629 - val_accuracy: 0.8084\n","Epoch 14/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3710 - accuracy: 0.8433 - val_loss: 0.5390 - val_accuracy: 0.8137\n","Epoch 15/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3717 - accuracy: 0.8406 - val_loss: 0.5189 - val_accuracy: 0.8158\n","Epoch 16/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3708 - accuracy: 0.8385 - val_loss: 0.4962 - val_accuracy: 0.8116\n","Epoch 17/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3640 - accuracy: 0.8438 - val_loss: 0.4732 - val_accuracy: 0.8148\n","Epoch 18/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3717 - accuracy: 0.8371 - val_loss: 0.4541 - val_accuracy: 0.8094\n","Epoch 19/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3644 - accuracy: 0.8465 - val_loss: 0.4361 - val_accuracy: 0.8169\n","Epoch 20/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3594 - accuracy: 0.8476 - val_loss: 0.4229 - val_accuracy: 0.8191\n","Epoch 21/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3613 - accuracy: 0.8454 - val_loss: 0.4164 - val_accuracy: 0.8212\n","Epoch 22/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.3599 - accuracy: 0.8406 - val_loss: 0.4139 - val_accuracy: 0.8212\n","Epoch 23/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3538 - accuracy: 0.8473 - val_loss: 0.4026 - val_accuracy: 0.8212\n","Epoch 24/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3704 - accuracy: 0.8401 - val_loss: 0.4042 - val_accuracy: 0.8266\n","Epoch 25/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3627 - accuracy: 0.8449 - val_loss: 0.3988 - val_accuracy: 0.8308\n","Epoch 26/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3463 - accuracy: 0.8540 - val_loss: 0.4012 - val_accuracy: 0.8308\n","Epoch 27/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3461 - accuracy: 0.8551 - val_loss: 0.4008 - val_accuracy: 0.8298\n","Epoch 28/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3459 - accuracy: 0.8551 - val_loss: 0.3960 - val_accuracy: 0.8276\n","Epoch 29/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3391 - accuracy: 0.8548 - val_loss: 0.4020 - val_accuracy: 0.8319\n","Epoch 30/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3425 - accuracy: 0.8545 - val_loss: 0.4353 - val_accuracy: 0.8169\n","Epoch 31/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3506 - accuracy: 0.8508 - val_loss: 0.4016 - val_accuracy: 0.8298\n","Epoch 32/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3365 - accuracy: 0.8570 - val_loss: 0.4014 - val_accuracy: 0.8298\n","Epoch 33/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3345 - accuracy: 0.8631 - val_loss: 0.3967 - val_accuracy: 0.8308\n","Epoch 34/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3325 - accuracy: 0.8618 - val_loss: 0.4105 - val_accuracy: 0.8266\n","Epoch 35/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3323 - accuracy: 0.8634 - val_loss: 0.4003 - val_accuracy: 0.8330\n","Epoch 36/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3279 - accuracy: 0.8626 - val_loss: 0.3985 - val_accuracy: 0.8298\n","Epoch 37/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3225 - accuracy: 0.8650 - val_loss: 0.4057 - val_accuracy: 0.8276\n","Epoch 38/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3294 - accuracy: 0.8628 - val_loss: 0.4011 - val_accuracy: 0.8330\n","Epoch 39/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3285 - accuracy: 0.8623 - val_loss: 0.4051 - val_accuracy: 0.8266\n","Epoch 40/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.3246 - accuracy: 0.8653 - val_loss: 0.3982 - val_accuracy: 0.8340\n","Epoch 41/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.3261 - accuracy: 0.8626 - val_loss: 0.3976 - val_accuracy: 0.8351\n","Epoch 42/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.3211 - accuracy: 0.8645 - val_loss: 0.3991 - val_accuracy: 0.8319\n","Epoch 43/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3171 - accuracy: 0.8706 - val_loss: 0.3990 - val_accuracy: 0.8330\n","Epoch 44/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.3106 - accuracy: 0.8741 - val_loss: 0.4033 - val_accuracy: 0.8276\n","Epoch 45/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.3127 - accuracy: 0.8661 - val_loss: 0.4014 - val_accuracy: 0.8340\n","Epoch 46/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.3136 - accuracy: 0.8706 - val_loss: 0.3987 - val_accuracy: 0.8340\n","Epoch 47/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3080 - accuracy: 0.8714 - val_loss: 0.4201 - val_accuracy: 0.8266\n","Epoch 48/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3181 - accuracy: 0.8671 - val_loss: 0.4099 - val_accuracy: 0.8233\n","Epoch 49/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3136 - accuracy: 0.8720 - val_loss: 0.4348 - val_accuracy: 0.8191\n","Epoch 50/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3077 - accuracy: 0.8733 - val_loss: 0.4098 - val_accuracy: 0.8233\n","Epoch 51/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3021 - accuracy: 0.8778 - val_loss: 0.3986 - val_accuracy: 0.8351\n","Epoch 52/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3005 - accuracy: 0.8803 - val_loss: 0.4234 - val_accuracy: 0.8148\n","Epoch 53/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3054 - accuracy: 0.8690 - val_loss: 0.3964 - val_accuracy: 0.8351\n","Epoch 54/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2990 - accuracy: 0.8792 - val_loss: 0.4108 - val_accuracy: 0.8244\n","Epoch 55/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2932 - accuracy: 0.8853 - val_loss: 0.4061 - val_accuracy: 0.8276\n","Epoch 56/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2952 - accuracy: 0.8800 - val_loss: 0.4004 - val_accuracy: 0.8351\n","Epoch 57/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2838 - accuracy: 0.8896 - val_loss: 0.3995 - val_accuracy: 0.8351\n","Epoch 58/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2932 - accuracy: 0.8795 - val_loss: 0.3975 - val_accuracy: 0.8394\n","Epoch 59/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2896 - accuracy: 0.8816 - val_loss: 0.4008 - val_accuracy: 0.8308\n","Epoch 60/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2851 - accuracy: 0.8832 - val_loss: 0.3985 - val_accuracy: 0.8373\n","Epoch 61/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2813 - accuracy: 0.8843 - val_loss: 0.4017 - val_accuracy: 0.8351\n","Epoch 62/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2836 - accuracy: 0.8864 - val_loss: 0.4037 - val_accuracy: 0.8383\n","Epoch 63/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2811 - accuracy: 0.8848 - val_loss: 0.4094 - val_accuracy: 0.8308\n","Epoch 64/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2838 - accuracy: 0.8840 - val_loss: 0.4016 - val_accuracy: 0.8394\n","Epoch 65/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2760 - accuracy: 0.8883 - val_loss: 0.4861 - val_accuracy: 0.8019\n","Epoch 66/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2857 - accuracy: 0.8851 - val_loss: 0.3974 - val_accuracy: 0.8362\n","Epoch 67/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2696 - accuracy: 0.8969 - val_loss: 0.3986 - val_accuracy: 0.8383\n","Epoch 68/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.2662 - accuracy: 0.8942 - val_loss: 0.4005 - val_accuracy: 0.8415\n","Epoch 69/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2693 - accuracy: 0.9006 - val_loss: 0.3997 - val_accuracy: 0.8415\n","Epoch 70/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2630 - accuracy: 0.8945 - val_loss: 0.4088 - val_accuracy: 0.8319\n","Epoch 71/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2665 - accuracy: 0.8966 - val_loss: 0.4073 - val_accuracy: 0.8351\n","Epoch 72/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2679 - accuracy: 0.8945 - val_loss: 0.4199 - val_accuracy: 0.8180\n","Epoch 73/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2634 - accuracy: 0.8987 - val_loss: 0.4124 - val_accuracy: 0.8298\n","Epoch 74/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2590 - accuracy: 0.8947 - val_loss: 0.4232 - val_accuracy: 0.8255\n","Epoch 75/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2547 - accuracy: 0.9017 - val_loss: 0.4183 - val_accuracy: 0.8308\n","Epoch 76/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2539 - accuracy: 0.8953 - val_loss: 0.4044 - val_accuracy: 0.8415\n","Epoch 77/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2490 - accuracy: 0.9054 - val_loss: 0.4066 - val_accuracy: 0.8415\n","Epoch 78/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2536 - accuracy: 0.9060 - val_loss: 0.4106 - val_accuracy: 0.8383\n","Epoch 79/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2441 - accuracy: 0.9062 - val_loss: 0.4266 - val_accuracy: 0.8276\n","Epoch 80/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2506 - accuracy: 0.8987 - val_loss: 0.4078 - val_accuracy: 0.8415\n","Epoch 81/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2569 - accuracy: 0.8979 - val_loss: 0.4158 - val_accuracy: 0.8255\n","Epoch 82/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2459 - accuracy: 0.9073 - val_loss: 0.4277 - val_accuracy: 0.8255\n","Epoch 83/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2451 - accuracy: 0.9020 - val_loss: 0.4076 - val_accuracy: 0.8405\n","Epoch 84/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2517 - accuracy: 0.8995 - val_loss: 0.4761 - val_accuracy: 0.8084\n","Epoch 85/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2393 - accuracy: 0.9089 - val_loss: 0.4114 - val_accuracy: 0.8426\n","Epoch 86/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2394 - accuracy: 0.9097 - val_loss: 0.4125 - val_accuracy: 0.8437\n","Epoch 87/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2361 - accuracy: 0.9070 - val_loss: 0.4149 - val_accuracy: 0.8415\n","Epoch 88/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2336 - accuracy: 0.9178 - val_loss: 0.4190 - val_accuracy: 0.8415\n","Epoch 89/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2361 - accuracy: 0.9089 - val_loss: 0.4136 - val_accuracy: 0.8448\n","Epoch 90/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2262 - accuracy: 0.9135 - val_loss: 0.4169 - val_accuracy: 0.8490\n","Epoch 91/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2268 - accuracy: 0.9092 - val_loss: 0.4154 - val_accuracy: 0.8383\n","Epoch 92/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.2223 - accuracy: 0.9153 - val_loss: 0.4209 - val_accuracy: 0.8351\n","Epoch 93/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.2199 - accuracy: 0.9140 - val_loss: 0.4320 - val_accuracy: 0.8191\n","Epoch 94/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2280 - accuracy: 0.9121 - val_loss: 0.4846 - val_accuracy: 0.8126\n","Epoch 95/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2614 - accuracy: 0.8942 - val_loss: 0.4183 - val_accuracy: 0.8330\n","Epoch 96/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2268 - accuracy: 0.9143 - val_loss: 0.4164 - val_accuracy: 0.8415\n","Epoch 97/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2136 - accuracy: 0.9220 - val_loss: 0.4177 - val_accuracy: 0.8415\n","Epoch 98/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2135 - accuracy: 0.9170 - val_loss: 0.4237 - val_accuracy: 0.8340\n","Epoch 99/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2202 - accuracy: 0.9186 - val_loss: 0.4497 - val_accuracy: 0.8223\n","Epoch 100/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2222 - accuracy: 0.9132 - val_loss: 0.4839 - val_accuracy: 0.8094\n","{'loss': [0.415179967880249, 0.4069906771183014, 0.40463241934776306, 0.39895960688591003, 0.3944946527481079, 0.39186277985572815, 0.38951629400253296, 0.3887174129486084, 0.39058589935302734, 0.3913508951663971, 0.3830990195274353, 0.3947341740131378, 0.3718101382255554, 0.37104570865631104, 0.3716695010662079, 0.3707643151283264, 0.3639680743217468, 0.3717080056667328, 0.3643515408039093, 0.3593786060810089, 0.36125922203063965, 0.3598996102809906, 0.3538073003292084, 0.37043899297714233, 0.3626571595668793, 0.3462904095649719, 0.3461430072784424, 0.3458614647388458, 0.33910250663757324, 0.3424626886844635, 0.350629061460495, 0.33647528290748596, 0.3344820439815521, 0.33250150084495544, 0.33233019709587097, 0.32788899540901184, 0.3224812150001526, 0.3293509781360626, 0.32846343517303467, 0.32462555170059204, 0.3261066675186157, 0.3210979104042053, 0.31714633107185364, 0.3106021583080292, 0.312738299369812, 0.3135557174682617, 0.30802208185195923, 0.3180891275405884, 0.31358879804611206, 0.30765828490257263, 0.30209752917289734, 0.30047857761383057, 0.30537712574005127, 0.29895561933517456, 0.29324832558631897, 0.29516491293907166, 0.2838301658630371, 0.29316726326942444, 0.2895844280719757, 0.28512662649154663, 0.28133437037467957, 0.2835780382156372, 0.2811082899570465, 0.28376561403274536, 0.27596715092658997, 0.2856738269329071, 0.26956528425216675, 0.26622772216796875, 0.2693122923374176, 0.26297250390052795, 0.2664748728275299, 0.26791200041770935, 0.26335418224334717, 0.25904151797294617, 0.25473448634147644, 0.25388845801353455, 0.2490137368440628, 0.2536134123802185, 0.24412354826927185, 0.25062379240989685, 0.2569366991519928, 0.24587514996528625, 0.24509942531585693, 0.2516668736934662, 0.23934996128082275, 0.2394285947084427, 0.23613876104354858, 0.23355592787265778, 0.2360740751028061, 0.22621779143810272, 0.2267751544713974, 0.22232533991336823, 0.2198885977268219, 0.2279624491930008, 0.26136845350265503, 0.22676382958889008, 0.21357138454914093, 0.21350517868995667, 0.22016985714435577, 0.2221691906452179], 'accuracy': [0.8197160363197327, 0.8245379328727722, 0.8181087374687195, 0.82587730884552, 0.8248057961463928, 0.8280203342437744, 0.8309670686721802, 0.832842230796814, 0.8290919065475464, 0.8213233351707458, 0.8336458802223206, 0.82587730884552, 0.8400750160217285, 0.8432895541191101, 0.8406107425689697, 0.8384677171707153, 0.8438253402709961, 0.8371283411979675, 0.8465041518211365, 0.8475756645202637, 0.8454326391220093, 0.8406107425689697, 0.8473078012466431, 0.8400750160217285, 0.8448968529701233, 0.8540048003196716, 0.8550763726234436, 0.8550763726234436, 0.8548084497451782, 0.8545405864715576, 0.85079026222229, 0.8569515347480774, 0.8631128072738647, 0.8617733716964722, 0.8633806705474854, 0.8625770211219788, 0.8649879693984985, 0.8628448843955994, 0.8623091578483582, 0.8652558326721191, 0.8625770211219788, 0.8644521832466125, 0.8706134557723999, 0.8740959167480469, 0.8660594820976257, 0.8706134557723999, 0.8714171051979065, 0.8671309947967529, 0.8719528317451477, 0.8732922673225403, 0.8778462409973145, 0.8802571892738342, 0.8690061569213867, 0.8791856169700623, 0.8853468894958496, 0.8799892663955688, 0.8896329998970032, 0.8794535398483276, 0.881596565246582, 0.8832038640975952, 0.8842753767967224, 0.8864184021949768, 0.8848111629486084, 0.8840075135231018, 0.8882936239242554, 0.885079026222229, 0.8968657851219177, 0.8941869735717773, 0.9006161093711853, 0.894454836845398, 0.8965979218482971, 0.894454836845398, 0.8987409472465515, 0.8947227597236633, 0.9016876220703125, 0.8952584862709045, 0.9054380059242249, 0.9059737324714661, 0.9062416553497314, 0.8987409472465515, 0.8979372978210449, 0.9073131680488586, 0.9019555449485779, 0.8995445966720581, 0.9089204668998718, 0.9097240567207336, 0.9070452451705933, 0.9177604913711548, 0.9089204668998718, 0.913474440574646, 0.9091883301734924, 0.9153496026992798, 0.9140101671218872, 0.9121350049972534, 0.8941869735717773, 0.9142780900001526, 0.9220466017723083, 0.9169568419456482, 0.9185641407966614, 0.9132065176963806], 'val_loss': [0.6761084198951721, 0.6726400256156921, 0.6686388850212097, 0.6646855473518372, 0.658215343952179, 0.6512560248374939, 0.6449481844902039, 0.6361973881721497, 0.626258134841919, 0.6124494075775146, 0.5976741909980774, 0.5815708637237549, 0.5629012584686279, 0.5390306711196899, 0.5189199447631836, 0.49616938829421997, 0.47318121790885925, 0.4540632665157318, 0.43610963225364685, 0.42292946577072144, 0.4164096415042877, 0.4138801097869873, 0.4025926887989044, 0.40422895550727844, 0.39883953332901, 0.40119221806526184, 0.4008128046989441, 0.39598020911216736, 0.4020218253135681, 0.43527838587760925, 0.4015907645225525, 0.4013531804084778, 0.39666059613227844, 0.4104517102241516, 0.40030232071876526, 0.3984570801258087, 0.4057424068450928, 0.40109866857528687, 0.4050513505935669, 0.3982207477092743, 0.39759552478790283, 0.399109810590744, 0.39898231625556946, 0.403293251991272, 0.4013783633708954, 0.39865347743034363, 0.420112669467926, 0.4099499583244324, 0.43481042981147766, 0.4098169803619385, 0.3985683023929596, 0.4233957529067993, 0.3963572680950165, 0.4108303189277649, 0.4060945510864258, 0.4003557860851288, 0.3995124101638794, 0.3975397050380707, 0.40076860785484314, 0.3984987437725067, 0.4016736149787903, 0.40368932485580444, 0.40944600105285645, 0.40158721804618835, 0.48614832758903503, 0.39741456508636475, 0.39860203862190247, 0.4004918038845062, 0.3997077941894531, 0.4087686538696289, 0.4073408246040344, 0.41991111636161804, 0.41235587000846863, 0.4231770932674408, 0.41832202672958374, 0.40438196063041687, 0.4065735340118408, 0.41062065958976746, 0.42661306262016296, 0.40783435106277466, 0.41577431559562683, 0.42774805426597595, 0.40764012932777405, 0.4760759770870209, 0.41136375069618225, 0.4125067889690399, 0.41486093401908875, 0.4190397262573242, 0.4136059880256653, 0.4169488251209259, 0.415359228849411, 0.420868456363678, 0.43198442459106445, 0.4846348166465759, 0.4182787537574768, 0.4163622260093689, 0.41768524050712585, 0.42366495728492737, 0.4497029483318329, 0.4839347302913666], 'val_accuracy': [0.740899384021759, 0.7494646906852722, 0.7387580275535583, 0.7291220426559448, 0.7730192542076111, 0.7933619022369385, 0.7430406808853149, 0.7451820373535156, 0.7548179626464844, 0.8019272089004517, 0.7912205457687378, 0.799785852432251, 0.8083511590957642, 0.8137044906616211, 0.8158458471298218, 0.8115631937980652, 0.8147751688957214, 0.8094218373298645, 0.8169164657592773, 0.819057822227478, 0.8211991190910339, 0.8211991190910339, 0.8211991190910339, 0.8265524506568909, 0.8308351039886475, 0.8308351039886475, 0.8297644257545471, 0.8276231288909912, 0.8319057822227478, 0.8169164657592773, 0.8297644257545471, 0.8297644257545471, 0.8308351039886475, 0.8265524506568909, 0.8329764604568481, 0.8297644257545471, 0.8276231288909912, 0.8329764604568481, 0.8265524506568909, 0.8340471386909485, 0.835117757320404, 0.8319057822227478, 0.8329764604568481, 0.8276231288909912, 0.8340471386909485, 0.8340471386909485, 0.8265524506568909, 0.8233404755592346, 0.819057822227478, 0.8233404755592346, 0.835117757320404, 0.8147751688957214, 0.835117757320404, 0.824411153793335, 0.8276231288909912, 0.835117757320404, 0.835117757320404, 0.8394004106521606, 0.8308351039886475, 0.8372591137886047, 0.835117757320404, 0.8383297920227051, 0.8308351039886475, 0.8394004106521606, 0.8019272089004517, 0.8361884355545044, 0.8383297920227051, 0.8415417671203613, 0.8415417671203613, 0.8319057822227478, 0.835117757320404, 0.8179871439933777, 0.8297644257545471, 0.8254817724227905, 0.8308351039886475, 0.8415417671203613, 0.8415417671203613, 0.8383297920227051, 0.8276231288909912, 0.8415417671203613, 0.8254817724227905, 0.8254817724227905, 0.840471088886261, 0.8083511590957642, 0.8426124453544617, 0.8436830639839172, 0.8415417671203613, 0.8415417671203613, 0.8447537422180176, 0.8490363955497742, 0.8383297920227051, 0.835117757320404, 0.819057822227478, 0.8126338124275208, 0.8329764604568481, 0.8415417671203613, 0.8415417671203613, 0.8340471386909485, 0.8222697973251343, 0.8094218373298645]}\n","37/37 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 10s 55ms/step - loss: 0.2842 - accuracy: 0.8821 - val_loss: 0.6723 - val_accuracy: 0.7045\n","Epoch 2/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2566 - accuracy: 0.9054 - val_loss: 0.6670 - val_accuracy: 0.7869\n","Epoch 3/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2575 - accuracy: 0.8990 - val_loss: 0.6633 - val_accuracy: 0.7762\n","Epoch 4/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2516 - accuracy: 0.9012 - val_loss: 0.6583 - val_accuracy: 0.7719\n","Epoch 5/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2495 - accuracy: 0.9057 - val_loss: 0.6502 - val_accuracy: 0.8009\n","Epoch 6/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2557 - accuracy: 0.9041 - val_loss: 0.6437 - val_accuracy: 0.8062\n","Epoch 7/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2450 - accuracy: 0.9076 - val_loss: 0.6340 - val_accuracy: 0.8084\n","Epoch 8/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2390 - accuracy: 0.9153 - val_loss: 0.6234 - val_accuracy: 0.8105\n","Epoch 9/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2387 - accuracy: 0.9137 - val_loss: 0.6100 - val_accuracy: 0.7976\n","Epoch 10/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2341 - accuracy: 0.9188 - val_loss: 0.5928 - val_accuracy: 0.8041\n","Epoch 11/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2380 - accuracy: 0.9151 - val_loss: 0.5754 - val_accuracy: 0.8094\n","Epoch 12/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2367 - accuracy: 0.9060 - val_loss: 0.5588 - val_accuracy: 0.7987\n","Epoch 13/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2371 - accuracy: 0.9119 - val_loss: 0.5316 - val_accuracy: 0.8158\n","Epoch 14/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2300 - accuracy: 0.9127 - val_loss: 0.5079 - val_accuracy: 0.8137\n","Epoch 15/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.2317 - accuracy: 0.9137 - val_loss: 0.4801 - val_accuracy: 0.8191\n","Epoch 16/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.2292 - accuracy: 0.9167 - val_loss: 0.4685 - val_accuracy: 0.8116\n","Epoch 17/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2162 - accuracy: 0.9194 - val_loss: 0.4337 - val_accuracy: 0.8169\n","Epoch 18/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2102 - accuracy: 0.9245 - val_loss: 0.4169 - val_accuracy: 0.8244\n","Epoch 19/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.2284 - accuracy: 0.9140 - val_loss: 0.4073 - val_accuracy: 0.8233\n","Epoch 20/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2196 - accuracy: 0.9183 - val_loss: 0.4173 - val_accuracy: 0.8180\n","Epoch 21/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2274 - accuracy: 0.9119 - val_loss: 0.4132 - val_accuracy: 0.8201\n","Epoch 22/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2213 - accuracy: 0.9191 - val_loss: 0.3880 - val_accuracy: 0.8276\n","Epoch 23/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2346 - accuracy: 0.9121 - val_loss: 0.3843 - val_accuracy: 0.8330\n","Epoch 24/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2057 - accuracy: 0.9255 - val_loss: 0.3871 - val_accuracy: 0.8362\n","Epoch 25/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2112 - accuracy: 0.9223 - val_loss: 0.4014 - val_accuracy: 0.8362\n","Epoch 26/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2018 - accuracy: 0.9271 - val_loss: 0.3994 - val_accuracy: 0.8351\n","Epoch 27/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2070 - accuracy: 0.9258 - val_loss: 0.4070 - val_accuracy: 0.8340\n","Epoch 28/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2064 - accuracy: 0.9239 - val_loss: 0.4154 - val_accuracy: 0.8330\n","Epoch 29/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1953 - accuracy: 0.9293 - val_loss: 0.4351 - val_accuracy: 0.8266\n","Epoch 30/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2037 - accuracy: 0.9250 - val_loss: 0.4516 - val_accuracy: 0.8351\n","Epoch 31/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2023 - accuracy: 0.9290 - val_loss: 0.4410 - val_accuracy: 0.8330\n","Epoch 32/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2014 - accuracy: 0.9301 - val_loss: 0.4297 - val_accuracy: 0.8351\n","Epoch 33/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1985 - accuracy: 0.9317 - val_loss: 0.4435 - val_accuracy: 0.8244\n","Epoch 34/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1917 - accuracy: 0.9325 - val_loss: 0.4364 - val_accuracy: 0.8362\n","Epoch 35/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1933 - accuracy: 0.9304 - val_loss: 0.4354 - val_accuracy: 0.8351\n","Epoch 36/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1861 - accuracy: 0.9379 - val_loss: 0.4504 - val_accuracy: 0.8362\n","Epoch 37/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1844 - accuracy: 0.9389 - val_loss: 0.4439 - val_accuracy: 0.8308\n","Epoch 38/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1917 - accuracy: 0.9346 - val_loss: 0.4506 - val_accuracy: 0.8244\n","Epoch 39/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2018 - accuracy: 0.9239 - val_loss: 0.4480 - val_accuracy: 0.8330\n","Epoch 40/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.1936 - accuracy: 0.9317 - val_loss: 0.4488 - val_accuracy: 0.8319\n","Epoch 41/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1844 - accuracy: 0.9328 - val_loss: 0.4465 - val_accuracy: 0.8319\n","Epoch 42/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1729 - accuracy: 0.9411 - val_loss: 0.4556 - val_accuracy: 0.8319\n","Epoch 43/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1749 - accuracy: 0.9395 - val_loss: 0.4769 - val_accuracy: 0.8298\n","Epoch 44/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1732 - accuracy: 0.9389 - val_loss: 0.4618 - val_accuracy: 0.8287\n","Epoch 45/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1736 - accuracy: 0.9440 - val_loss: 0.4652 - val_accuracy: 0.8255\n","Epoch 46/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1726 - accuracy: 0.9440 - val_loss: 0.4639 - val_accuracy: 0.8276\n","Epoch 47/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1696 - accuracy: 0.9443 - val_loss: 0.4978 - val_accuracy: 0.8180\n","Epoch 48/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1717 - accuracy: 0.9421 - val_loss: 0.4854 - val_accuracy: 0.8201\n","Epoch 49/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1674 - accuracy: 0.9424 - val_loss: 0.4670 - val_accuracy: 0.8223\n","Epoch 50/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1730 - accuracy: 0.9365 - val_loss: 0.4721 - val_accuracy: 0.8319\n","Epoch 51/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1693 - accuracy: 0.9435 - val_loss: 0.4832 - val_accuracy: 0.8223\n","Epoch 52/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1576 - accuracy: 0.9467 - val_loss: 0.4770 - val_accuracy: 0.8244\n","Epoch 53/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1564 - accuracy: 0.9488 - val_loss: 0.4808 - val_accuracy: 0.8298\n","Epoch 54/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1640 - accuracy: 0.9464 - val_loss: 0.4780 - val_accuracy: 0.8308\n","Epoch 55/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1644 - accuracy: 0.9443 - val_loss: 0.4830 - val_accuracy: 0.8266\n","Epoch 56/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1515 - accuracy: 0.9518 - val_loss: 0.4859 - val_accuracy: 0.8266\n","Epoch 57/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1594 - accuracy: 0.9467 - val_loss: 0.5291 - val_accuracy: 0.8212\n","Epoch 58/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1614 - accuracy: 0.9451 - val_loss: 0.4953 - val_accuracy: 0.8223\n","Epoch 59/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1593 - accuracy: 0.9472 - val_loss: 0.4861 - val_accuracy: 0.8287\n","Epoch 60/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1525 - accuracy: 0.9520 - val_loss: 0.4878 - val_accuracy: 0.8276\n","Epoch 61/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1587 - accuracy: 0.9443 - val_loss: 0.4934 - val_accuracy: 0.8255\n","Epoch 62/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1549 - accuracy: 0.9448 - val_loss: 0.5027 - val_accuracy: 0.8169\n","Epoch 63/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1752 - accuracy: 0.9330 - val_loss: 0.5173 - val_accuracy: 0.8255\n","Epoch 64/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1450 - accuracy: 0.9553 - val_loss: 0.4873 - val_accuracy: 0.8276\n","Epoch 65/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1378 - accuracy: 0.9579 - val_loss: 0.5239 - val_accuracy: 0.8223\n","Epoch 66/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1349 - accuracy: 0.9545 - val_loss: 0.5657 - val_accuracy: 0.8180\n","Epoch 67/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1467 - accuracy: 0.9494 - val_loss: 0.5499 - val_accuracy: 0.8223\n","Epoch 68/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1403 - accuracy: 0.9558 - val_loss: 0.5497 - val_accuracy: 0.8223\n","Epoch 69/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1421 - accuracy: 0.9537 - val_loss: 0.5373 - val_accuracy: 0.8212\n","Epoch 70/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1386 - accuracy: 0.9545 - val_loss: 0.5314 - val_accuracy: 0.8244\n","Epoch 71/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1368 - accuracy: 0.9553 - val_loss: 0.5281 - val_accuracy: 0.8233\n","Epoch 72/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1286 - accuracy: 0.9601 - val_loss: 0.5683 - val_accuracy: 0.8158\n","Epoch 73/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1282 - accuracy: 0.9587 - val_loss: 0.5686 - val_accuracy: 0.8191\n","Epoch 74/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1559 - accuracy: 0.9462 - val_loss: 0.5814 - val_accuracy: 0.8212\n","Epoch 75/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1446 - accuracy: 0.9518 - val_loss: 0.5107 - val_accuracy: 0.8266\n","Epoch 76/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1265 - accuracy: 0.9609 - val_loss: 0.5150 - val_accuracy: 0.8223\n","Epoch 77/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1265 - accuracy: 0.9593 - val_loss: 0.5340 - val_accuracy: 0.8201\n","Epoch 78/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1266 - accuracy: 0.9555 - val_loss: 0.5282 - val_accuracy: 0.8298\n","Epoch 79/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1335 - accuracy: 0.9585 - val_loss: 0.5269 - val_accuracy: 0.8201\n","Epoch 80/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1280 - accuracy: 0.9566 - val_loss: 0.5279 - val_accuracy: 0.8180\n","Epoch 81/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1264 - accuracy: 0.9604 - val_loss: 0.5334 - val_accuracy: 0.8233\n","Epoch 82/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1356 - accuracy: 0.9529 - val_loss: 0.5276 - val_accuracy: 0.8201\n","Epoch 83/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1244 - accuracy: 0.9579 - val_loss: 0.5545 - val_accuracy: 0.8212\n","Epoch 84/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1195 - accuracy: 0.9625 - val_loss: 0.5687 - val_accuracy: 0.8244\n","Epoch 85/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1145 - accuracy: 0.9662 - val_loss: 0.5635 - val_accuracy: 0.8233\n","Epoch 86/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1232 - accuracy: 0.9604 - val_loss: 0.5948 - val_accuracy: 0.8233\n","Epoch 87/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1145 - accuracy: 0.9657 - val_loss: 0.5957 - val_accuracy: 0.8233\n","Epoch 88/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1157 - accuracy: 0.9625 - val_loss: 0.5598 - val_accuracy: 0.8233\n","Epoch 89/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1174 - accuracy: 0.9630 - val_loss: 0.5667 - val_accuracy: 0.8287\n","Epoch 90/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1090 - accuracy: 0.9662 - val_loss: 0.5682 - val_accuracy: 0.8255\n","Epoch 91/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1087 - accuracy: 0.9679 - val_loss: 0.5692 - val_accuracy: 0.8201\n","Epoch 92/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1075 - accuracy: 0.9665 - val_loss: 0.5631 - val_accuracy: 0.8191\n","Epoch 93/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1174 - accuracy: 0.9625 - val_loss: 0.5644 - val_accuracy: 0.8298\n","Epoch 94/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1225 - accuracy: 0.9612 - val_loss: 0.5630 - val_accuracy: 0.8223\n","Epoch 95/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1023 - accuracy: 0.9719 - val_loss: 0.5572 - val_accuracy: 0.8266\n","Epoch 96/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1067 - accuracy: 0.9684 - val_loss: 0.5643 - val_accuracy: 0.8233\n","Epoch 97/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1047 - accuracy: 0.9676 - val_loss: 0.5592 - val_accuracy: 0.8266\n","Epoch 98/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1076 - accuracy: 0.9649 - val_loss: 0.5768 - val_accuracy: 0.8212\n","Epoch 99/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1170 - accuracy: 0.9614 - val_loss: 0.5899 - val_accuracy: 0.8244\n","Epoch 100/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1094 - accuracy: 0.9654 - val_loss: 0.7647 - val_accuracy: 0.7912\n","{'loss': [0.28418585658073425, 0.25659725069999695, 0.2575030028820038, 0.2516458332538605, 0.2494608461856842, 0.2557145357131958, 0.24503766000270844, 0.2389940619468689, 0.23866038024425507, 0.23411856591701508, 0.2380191534757614, 0.23665952682495117, 0.2370753139257431, 0.2299787849187851, 0.2316574901342392, 0.22924481332302094, 0.21618671715259552, 0.21019038558006287, 0.22835151851177216, 0.21960337460041046, 0.22736407816410065, 0.22125175595283508, 0.23455524444580078, 0.2057047188282013, 0.21124665439128876, 0.2018364667892456, 0.20695838332176208, 0.20639657974243164, 0.19533342123031616, 0.20374968647956848, 0.20232342183589935, 0.2014336884021759, 0.19847045838832855, 0.19172373414039612, 0.19325348734855652, 0.18613053858280182, 0.1844141185283661, 0.19173097610473633, 0.2017642706632614, 0.19361530244350433, 0.18438293039798737, 0.17285531759262085, 0.17491421103477478, 0.1732286959886551, 0.17361615598201752, 0.17260606586933136, 0.16963735222816467, 0.17174217104911804, 0.1673857718706131, 0.17303195595741272, 0.1692628264427185, 0.15760178864002228, 0.1563551276922226, 0.1640259176492691, 0.16444732248783112, 0.15149250626564026, 0.1593974530696869, 0.16135655343532562, 0.15926086902618408, 0.15250499546527863, 0.15872642397880554, 0.15490420162677765, 0.17524537444114685, 0.14502257108688354, 0.13777261972427368, 0.13487395644187927, 0.14670084416866302, 0.1403341442346573, 0.14211392402648926, 0.13855589926242828, 0.13679812848567963, 0.12857253849506378, 0.12816882133483887, 0.15592992305755615, 0.14461380243301392, 0.1265106499195099, 0.12649857997894287, 0.12655599415302277, 0.13345882296562195, 0.1279868632555008, 0.12644989788532257, 0.13558033108711243, 0.12439727783203125, 0.11948760598897934, 0.11449019610881805, 0.12321678549051285, 0.11446956545114517, 0.11572617292404175, 0.11742542684078217, 0.10903174430131912, 0.10872843861579895, 0.10752930492162704, 0.11741837859153748, 0.12252494692802429, 0.10225366801023483, 0.10666429996490479, 0.10469323396682739, 0.10763110220432281, 0.11704065650701523, 0.10944376140832901], 'accuracy': [0.882132351398468, 0.9054380059242249, 0.8990088105201721, 0.9011518955230713, 0.9057058691978455, 0.9040985703468323, 0.9075810313224792, 0.9153496026992798, 0.9137423038482666, 0.9188320636749268, 0.9150816798210144, 0.9059737324714661, 0.9118671417236328, 0.9126707911491394, 0.9137423038482666, 0.9166889786720276, 0.919367790222168, 0.9244575500488281, 0.9140101671218872, 0.9182962775230408, 0.9118671417236328, 0.9190999269485474, 0.9121350049972534, 0.9255290627479553, 0.922314465045929, 0.9271363615989685, 0.9257969260215759, 0.9239217638969421, 0.9292793869972229, 0.9249932765960693, 0.9290115237236023, 0.9300830364227295, 0.9316903352737427, 0.9324939846992493, 0.9303508996963501, 0.93785160779953, 0.9389231204986572, 0.9346370100975037, 0.9239217638969421, 0.9316903352737427, 0.9327618479728699, 0.9410661458969116, 0.9394589066505432, 0.9389231204986572, 0.9440128803253174, 0.9440128803253174, 0.944280743598938, 0.9421377182006836, 0.9424055814743042, 0.9365121722221375, 0.9434770941734314, 0.9466916918754578, 0.9488347172737122, 0.9464237689971924, 0.944280743598938, 0.9517813920974731, 0.9466916918754578, 0.9450843930244446, 0.947227418422699, 0.9520493149757385, 0.944280743598938, 0.944816529750824, 0.9330297112464905, 0.9552638530731201, 0.9579426646232605, 0.9544602036476135, 0.9493705034255981, 0.9557996392250061, 0.9536565542221069, 0.9544602036476135, 0.9552638530731201, 0.9600857496261597, 0.9587463140487671, 0.9461559057235718, 0.9517813920974731, 0.9608893394470215, 0.9592821002006531, 0.9555317163467407, 0.9584784507751465, 0.9566032886505127, 0.9603536128997803, 0.9528529047966003, 0.9579426646232605, 0.9624966382980347, 0.9662469625473022, 0.9603536128997803, 0.965711236000061, 0.9624966382980347, 0.9630324244499207, 0.9662469625473022, 0.9678542613983154, 0.9665148854255676, 0.9624966382980347, 0.9611572623252869, 0.9718725085258484, 0.9683900475502014, 0.9675863981246948, 0.9649075865745544, 0.9614251255989075, 0.9654433727264404], 'val_loss': [0.6722986102104187, 0.6670364737510681, 0.6632549166679382, 0.6582537293434143, 0.6501889824867249, 0.6437179446220398, 0.633990466594696, 0.6234461665153503, 0.6099544167518616, 0.5928160548210144, 0.5753742456436157, 0.5587632656097412, 0.5316303968429565, 0.5078807473182678, 0.4800734221935272, 0.46845972537994385, 0.43374520540237427, 0.4169120788574219, 0.4072691798210144, 0.41733524203300476, 0.4132298231124878, 0.3880051374435425, 0.38427433371543884, 0.38711777329444885, 0.4014129340648651, 0.3993963599205017, 0.4070053696632385, 0.41539886593818665, 0.43513888120651245, 0.45160678029060364, 0.4410078525543213, 0.4297281801700592, 0.4435006380081177, 0.43642544746398926, 0.4353727400302887, 0.4504309892654419, 0.4439031183719635, 0.4505804181098938, 0.44799697399139404, 0.44876033067703247, 0.44647544622421265, 0.4556024372577667, 0.4768765866756439, 0.46184754371643066, 0.4652373790740967, 0.463876873254776, 0.4977985918521881, 0.4854114353656769, 0.46699053049087524, 0.4721195101737976, 0.483232319355011, 0.4769889712333679, 0.48076343536376953, 0.47803017497062683, 0.48296689987182617, 0.4859398603439331, 0.5291301012039185, 0.4952707886695862, 0.4861026704311371, 0.4877565801143646, 0.4933810532093048, 0.5026856064796448, 0.5172961354255676, 0.48734432458877563, 0.5239187479019165, 0.5657118558883667, 0.5498797297477722, 0.5497332215309143, 0.537288248538971, 0.531445324420929, 0.5281374454498291, 0.568274974822998, 0.568554699420929, 0.5813712477684021, 0.5106658935546875, 0.515036940574646, 0.5340424180030823, 0.5281701683998108, 0.5268587470054626, 0.5279362797737122, 0.5334336161613464, 0.5276191234588623, 0.5545043349266052, 0.5687222480773926, 0.5634667873382568, 0.594778835773468, 0.5956827402114868, 0.559830904006958, 0.5666998624801636, 0.5681746602058411, 0.5691879391670227, 0.5630561709403992, 0.5643838047981262, 0.5629966855049133, 0.5572100877761841, 0.564286470413208, 0.5592316389083862, 0.576819896697998, 0.5898860096931458, 0.764710009098053], 'val_accuracy': [0.7044968008995056, 0.7869378924369812, 0.7762312889099121, 0.7719486355781555, 0.8008565306663513, 0.8062098622322083, 0.8083511590957642, 0.8104925155639648, 0.7976445555686951, 0.8040685057640076, 0.8094218373298645, 0.7987151741981506, 0.8158458471298218, 0.8137044906616211, 0.819057822227478, 0.8115631937980652, 0.8169164657592773, 0.824411153793335, 0.8233404755592346, 0.8179871439933777, 0.8201285004615784, 0.8276231288909912, 0.8329764604568481, 0.8361884355545044, 0.8361884355545044, 0.835117757320404, 0.8340471386909485, 0.8329764604568481, 0.8265524506568909, 0.835117757320404, 0.8329764604568481, 0.835117757320404, 0.824411153793335, 0.8361884355545044, 0.835117757320404, 0.8361884355545044, 0.8308351039886475, 0.824411153793335, 0.8329764604568481, 0.8319057822227478, 0.8319057822227478, 0.8319057822227478, 0.8297644257545471, 0.8286938071250916, 0.8254817724227905, 0.8276231288909912, 0.8179871439933777, 0.8201285004615784, 0.8222697973251343, 0.8319057822227478, 0.8222697973251343, 0.824411153793335, 0.8297644257545471, 0.8308351039886475, 0.8265524506568909, 0.8265524506568909, 0.8211991190910339, 0.8222697973251343, 0.8286938071250916, 0.8276231288909912, 0.8254817724227905, 0.8169164657592773, 0.8254817724227905, 0.8276231288909912, 0.8222697973251343, 0.8179871439933777, 0.8222697973251343, 0.8222697973251343, 0.8211991190910339, 0.824411153793335, 0.8233404755592346, 0.8158458471298218, 0.819057822227478, 0.8211991190910339, 0.8265524506568909, 0.8222697973251343, 0.8201285004615784, 0.8297644257545471, 0.8201285004615784, 0.8179871439933777, 0.8233404755592346, 0.8201285004615784, 0.8211991190910339, 0.824411153793335, 0.8233404755592346, 0.8233404755592346, 0.8233404755592346, 0.8233404755592346, 0.8286938071250916, 0.8254817724227905, 0.8201285004615784, 0.819057822227478, 0.8297644257545471, 0.8222697973251343, 0.8265524506568909, 0.8233404755592346, 0.8265524506568909, 0.8211991190910339, 0.824411153793335, 0.7912205457687378]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 51ms/step - loss: 0.2740 - accuracy: 0.8910 - val_loss: 0.6716 - val_accuracy: 0.7238\n","Epoch 2/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2640 - accuracy: 0.8934 - val_loss: 0.6670 - val_accuracy: 0.7784\n","Epoch 3/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2624 - accuracy: 0.8955 - val_loss: 0.6631 - val_accuracy: 0.7859\n","Epoch 4/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2578 - accuracy: 0.9068 - val_loss: 0.6561 - val_accuracy: 0.7859\n","Epoch 5/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2546 - accuracy: 0.9022 - val_loss: 0.6500 - val_accuracy: 0.8084\n","Epoch 6/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2529 - accuracy: 0.9057 - val_loss: 0.6414 - val_accuracy: 0.8009\n","Epoch 7/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2500 - accuracy: 0.9038 - val_loss: 0.6295 - val_accuracy: 0.8340\n","Epoch 8/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2771 - accuracy: 0.8888 - val_loss: 0.6182 - val_accuracy: 0.8340\n","Epoch 9/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2425 - accuracy: 0.9097 - val_loss: 0.6063 - val_accuracy: 0.8201\n","Epoch 10/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2454 - accuracy: 0.9065 - val_loss: 0.5902 - val_accuracy: 0.8169\n","Epoch 11/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2475 - accuracy: 0.9020 - val_loss: 0.5692 - val_accuracy: 0.8405\n","Epoch 12/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2371 - accuracy: 0.9089 - val_loss: 0.5489 - val_accuracy: 0.8287\n","Epoch 13/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2439 - accuracy: 0.9076 - val_loss: 0.5185 - val_accuracy: 0.8394\n","Epoch 14/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2427 - accuracy: 0.9084 - val_loss: 0.4922 - val_accuracy: 0.8501\n","Epoch 15/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.2286 - accuracy: 0.9212 - val_loss: 0.4621 - val_accuracy: 0.8480\n","Epoch 16/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2258 - accuracy: 0.9178 - val_loss: 0.4283 - val_accuracy: 0.8533\n","Epoch 17/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.2271 - accuracy: 0.9196 - val_loss: 0.4050 - val_accuracy: 0.8576\n","Epoch 18/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.2199 - accuracy: 0.9231 - val_loss: 0.3728 - val_accuracy: 0.8619\n","Epoch 19/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2269 - accuracy: 0.9145 - val_loss: 0.3534 - val_accuracy: 0.8597\n","Epoch 20/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.2234 - accuracy: 0.9194 - val_loss: 0.3518 - val_accuracy: 0.8490\n","Epoch 21/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2285 - accuracy: 0.9129 - val_loss: 0.3372 - val_accuracy: 0.8565\n","Epoch 22/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2156 - accuracy: 0.9202 - val_loss: 0.3156 - val_accuracy: 0.8683\n","Epoch 23/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2198 - accuracy: 0.9210 - val_loss: 0.3142 - val_accuracy: 0.8683\n","Epoch 24/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2140 - accuracy: 0.9178 - val_loss: 0.4069 - val_accuracy: 0.8330\n","Epoch 25/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2671 - accuracy: 0.8979 - val_loss: 0.3411 - val_accuracy: 0.8533\n","Epoch 26/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2130 - accuracy: 0.9212 - val_loss: 0.3104 - val_accuracy: 0.8662\n","Epoch 27/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2068 - accuracy: 0.9245 - val_loss: 0.3150 - val_accuracy: 0.8683\n","Epoch 28/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2048 - accuracy: 0.9242 - val_loss: 0.3473 - val_accuracy: 0.8555\n","Epoch 29/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2111 - accuracy: 0.9207 - val_loss: 0.3230 - val_accuracy: 0.8608\n","Epoch 30/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2009 - accuracy: 0.9301 - val_loss: 0.3484 - val_accuracy: 0.8533\n","Epoch 31/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2033 - accuracy: 0.9247 - val_loss: 0.3251 - val_accuracy: 0.8672\n","Epoch 32/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2056 - accuracy: 0.9247 - val_loss: 0.3431 - val_accuracy: 0.8683\n","Epoch 33/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1987 - accuracy: 0.9325 - val_loss: 0.3297 - val_accuracy: 0.8662\n","Epoch 34/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1977 - accuracy: 0.9298 - val_loss: 0.3313 - val_accuracy: 0.8640\n","Epoch 35/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1944 - accuracy: 0.9336 - val_loss: 0.3393 - val_accuracy: 0.8576\n","Epoch 36/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1928 - accuracy: 0.9333 - val_loss: 0.3362 - val_accuracy: 0.8640\n","Epoch 37/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1879 - accuracy: 0.9349 - val_loss: 0.3348 - val_accuracy: 0.8608\n","Epoch 38/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1911 - accuracy: 0.9309 - val_loss: 0.3499 - val_accuracy: 0.8576\n","Epoch 39/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1965 - accuracy: 0.9287 - val_loss: 0.3386 - val_accuracy: 0.8683\n","Epoch 40/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.1900 - accuracy: 0.9330 - val_loss: 0.3387 - val_accuracy: 0.8630\n","Epoch 41/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1854 - accuracy: 0.9354 - val_loss: 0.3483 - val_accuracy: 0.8597\n","Epoch 42/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1869 - accuracy: 0.9346 - val_loss: 0.3426 - val_accuracy: 0.8640\n","Epoch 43/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1828 - accuracy: 0.9376 - val_loss: 0.3447 - val_accuracy: 0.8619\n","Epoch 44/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1811 - accuracy: 0.9360 - val_loss: 0.3511 - val_accuracy: 0.8597\n","Epoch 45/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1886 - accuracy: 0.9333 - val_loss: 0.3466 - val_accuracy: 0.8619\n","Epoch 46/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1782 - accuracy: 0.9373 - val_loss: 0.3617 - val_accuracy: 0.8565\n","Epoch 47/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1758 - accuracy: 0.9424 - val_loss: 0.3570 - val_accuracy: 0.8597\n","Epoch 48/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1722 - accuracy: 0.9400 - val_loss: 0.3523 - val_accuracy: 0.8630\n","Epoch 49/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1667 - accuracy: 0.9437 - val_loss: 0.3542 - val_accuracy: 0.8608\n","Epoch 50/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1731 - accuracy: 0.9360 - val_loss: 0.3578 - val_accuracy: 0.8597\n","Epoch 51/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1667 - accuracy: 0.9443 - val_loss: 0.3629 - val_accuracy: 0.8587\n","Epoch 52/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1671 - accuracy: 0.9413 - val_loss: 0.3579 - val_accuracy: 0.8597\n","Epoch 53/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1659 - accuracy: 0.9421 - val_loss: 0.3574 - val_accuracy: 0.8619\n","Epoch 54/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1689 - accuracy: 0.9419 - val_loss: 0.3640 - val_accuracy: 0.8576\n","Epoch 55/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1665 - accuracy: 0.9440 - val_loss: 0.4418 - val_accuracy: 0.8383\n","Epoch 56/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1827 - accuracy: 0.9295 - val_loss: 0.4412 - val_accuracy: 0.8448\n","Epoch 57/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1705 - accuracy: 0.9373 - val_loss: 0.3659 - val_accuracy: 0.8576\n","Epoch 58/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1600 - accuracy: 0.9470 - val_loss: 0.3736 - val_accuracy: 0.8565\n","Epoch 59/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1539 - accuracy: 0.9475 - val_loss: 0.3639 - val_accuracy: 0.8533\n","Epoch 60/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1598 - accuracy: 0.9419 - val_loss: 0.3636 - val_accuracy: 0.8565\n","Epoch 61/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1553 - accuracy: 0.9478 - val_loss: 0.4061 - val_accuracy: 0.8448\n","Epoch 62/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1639 - accuracy: 0.9445 - val_loss: 0.3738 - val_accuracy: 0.8597\n","Epoch 63/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1445 - accuracy: 0.9515 - val_loss: 0.3770 - val_accuracy: 0.8501\n","Epoch 64/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1472 - accuracy: 0.9526 - val_loss: 0.3715 - val_accuracy: 0.8576\n","Epoch 65/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1435 - accuracy: 0.9563 - val_loss: 0.3770 - val_accuracy: 0.8544\n","Epoch 66/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1471 - accuracy: 0.9502 - val_loss: 0.4109 - val_accuracy: 0.8437\n","Epoch 67/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1539 - accuracy: 0.9478 - val_loss: 0.3841 - val_accuracy: 0.8576\n","Epoch 68/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1469 - accuracy: 0.9478 - val_loss: 0.4465 - val_accuracy: 0.8469\n","Epoch 69/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1458 - accuracy: 0.9491 - val_loss: 0.3818 - val_accuracy: 0.8555\n","Epoch 70/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1379 - accuracy: 0.9563 - val_loss: 0.3825 - val_accuracy: 0.8555\n","Epoch 71/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1426 - accuracy: 0.9518 - val_loss: 0.4127 - val_accuracy: 0.8512\n","Epoch 72/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1420 - accuracy: 0.9520 - val_loss: 0.3892 - val_accuracy: 0.8544\n","Epoch 73/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1404 - accuracy: 0.9545 - val_loss: 0.3871 - val_accuracy: 0.8555\n","Epoch 74/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1275 - accuracy: 0.9598 - val_loss: 0.3935 - val_accuracy: 0.8533\n","Epoch 75/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1354 - accuracy: 0.9547 - val_loss: 0.3879 - val_accuracy: 0.8522\n","Epoch 76/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1298 - accuracy: 0.9590 - val_loss: 0.3861 - val_accuracy: 0.8512\n","Epoch 77/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1374 - accuracy: 0.9558 - val_loss: 0.3962 - val_accuracy: 0.8512\n","Epoch 78/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1181 - accuracy: 0.9636 - val_loss: 0.4013 - val_accuracy: 0.8544\n","Epoch 79/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1312 - accuracy: 0.9563 - val_loss: 0.4023 - val_accuracy: 0.8533\n","Epoch 80/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1283 - accuracy: 0.9601 - val_loss: 0.3968 - val_accuracy: 0.8512\n","Epoch 81/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1401 - accuracy: 0.9507 - val_loss: 0.4177 - val_accuracy: 0.8512\n","Epoch 82/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1252 - accuracy: 0.9590 - val_loss: 0.4061 - val_accuracy: 0.8533\n","Epoch 83/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1213 - accuracy: 0.9601 - val_loss: 0.3981 - val_accuracy: 0.8576\n","Epoch 84/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1266 - accuracy: 0.9593 - val_loss: 0.4137 - val_accuracy: 0.8555\n","Epoch 85/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1197 - accuracy: 0.9628 - val_loss: 0.4147 - val_accuracy: 0.8555\n","Epoch 86/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1192 - accuracy: 0.9641 - val_loss: 0.4185 - val_accuracy: 0.8533\n","Epoch 87/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1119 - accuracy: 0.9654 - val_loss: 0.4113 - val_accuracy: 0.8555\n","Epoch 88/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1149 - accuracy: 0.9636 - val_loss: 0.4135 - val_accuracy: 0.8544\n","Epoch 89/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1144 - accuracy: 0.9649 - val_loss: 0.4127 - val_accuracy: 0.8501\n","Epoch 90/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1143 - accuracy: 0.9628 - val_loss: 0.4335 - val_accuracy: 0.8512\n","Epoch 91/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1106 - accuracy: 0.9679 - val_loss: 0.4164 - val_accuracy: 0.8501\n","Epoch 92/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1168 - accuracy: 0.9609 - val_loss: 0.4395 - val_accuracy: 0.8544\n","Epoch 93/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1060 - accuracy: 0.9684 - val_loss: 0.4257 - val_accuracy: 0.8522\n","Epoch 94/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1068 - accuracy: 0.9665 - val_loss: 0.4226 - val_accuracy: 0.8565\n","Epoch 95/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1045 - accuracy: 0.9676 - val_loss: 0.4261 - val_accuracy: 0.8533\n","Epoch 96/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1116 - accuracy: 0.9654 - val_loss: 0.4244 - val_accuracy: 0.8512\n","Epoch 97/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1061 - accuracy: 0.9700 - val_loss: 0.4254 - val_accuracy: 0.8522\n","Epoch 98/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1008 - accuracy: 0.9695 - val_loss: 0.4304 - val_accuracy: 0.8512\n","Epoch 99/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1039 - accuracy: 0.9705 - val_loss: 0.4495 - val_accuracy: 0.8501\n","Epoch 100/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1011 - accuracy: 0.9692 - val_loss: 0.4622 - val_accuracy: 0.8512\n","{'loss': [0.27396321296691895, 0.26399940252304077, 0.2623828053474426, 0.257758766412735, 0.2545667886734009, 0.25289982557296753, 0.24995951354503632, 0.2770967185497284, 0.24250395596027374, 0.24536703526973724, 0.2475353628396988, 0.23706689476966858, 0.2438536137342453, 0.24265728890895844, 0.2285735309123993, 0.2257510870695114, 0.22708463668823242, 0.21990104019641876, 0.22691074013710022, 0.22340638935565948, 0.2284594625234604, 0.21555368602275848, 0.21981465816497803, 0.21395546197891235, 0.267091304063797, 0.21297508478164673, 0.20675455033779144, 0.20480303466320038, 0.2111327052116394, 0.20090991258621216, 0.20333243906497955, 0.20558059215545654, 0.19866082072257996, 0.19768022000789642, 0.19441697001457214, 0.1928359717130661, 0.18794377148151398, 0.1911485195159912, 0.1964629590511322, 0.19002175331115723, 0.18543434143066406, 0.1868939846754074, 0.1828494817018509, 0.181126669049263, 0.18856675922870636, 0.1782139390707016, 0.17583416402339935, 0.17218725383281708, 0.16674809157848358, 0.1730705350637436, 0.16666783392429352, 0.16710703074932098, 0.16585738956928253, 0.16889731585979462, 0.16648846864700317, 0.18269076943397522, 0.17050085961818695, 0.15999117493629456, 0.15392456948757172, 0.15979894995689392, 0.15530003607273102, 0.16389110684394836, 0.14452849328517914, 0.1471991389989853, 0.143485888838768, 0.1470910757780075, 0.1538579910993576, 0.14689099788665771, 0.1458457112312317, 0.13789290189743042, 0.14264552295207977, 0.1419840157032013, 0.1404428333044052, 0.12754635512828827, 0.1353815495967865, 0.12976287305355072, 0.13737887144088745, 0.11808369308710098, 0.1312008798122406, 0.12825925648212433, 0.14011098444461823, 0.12517181038856506, 0.12134970724582672, 0.12663355469703674, 0.11971182376146317, 0.11920059472322464, 0.11189161241054535, 0.11486632376909256, 0.11442852765321732, 0.11432363092899323, 0.11061399430036545, 0.11683395504951477, 0.10599740594625473, 0.10676930099725723, 0.10449466109275818, 0.11155489832162857, 0.10611224174499512, 0.10084262490272522, 0.10386452078819275, 0.10109858214855194], 'accuracy': [0.8909724354743958, 0.8933833241462708, 0.8955264091491699, 0.9067773818969727, 0.9022234082221985, 0.9057058691978455, 0.9038307070732117, 0.8888293504714966, 0.9097240567207336, 0.906509518623352, 0.9019555449485779, 0.9089204668998718, 0.9075810313224792, 0.9083846807479858, 0.9212429523468018, 0.9177604913711548, 0.9196356534957886, 0.9231181144714355, 0.9145459532737732, 0.919367790222168, 0.91293865442276, 0.9201714396476746, 0.9209750890731812, 0.9177604913711548, 0.8979372978210449, 0.9212429523468018, 0.9244575500488281, 0.9241896867752075, 0.9207072257995605, 0.9300830364227295, 0.9247254133224487, 0.9247254133224487, 0.9324939846992493, 0.9298151731491089, 0.9335654973983765, 0.9332976341247559, 0.9349048733711243, 0.9308866858482361, 0.9287436604499817, 0.9330297112464905, 0.9354406595230103, 0.9346370100975037, 0.9375836849212646, 0.9359764456748962, 0.9332976341247559, 0.937315821647644, 0.9424055814743042, 0.9399946331977844, 0.943744957447052, 0.9359764456748962, 0.944280743598938, 0.941334068775177, 0.9421377182006836, 0.9418697953224182, 0.9440128803253174, 0.9295473098754883, 0.937315821647644, 0.9469595551490784, 0.9474953413009644, 0.9418697953224182, 0.947763204574585, 0.9445486068725586, 0.9515135288238525, 0.9525850415229797, 0.9563353657722473, 0.95017409324646, 0.947763204574585, 0.947763204574585, 0.9491025805473328, 0.9563353657722473, 0.9517813920974731, 0.9520493149757385, 0.9544602036476135, 0.9598178267478943, 0.9547281265258789, 0.9590141773223877, 0.9557996392250061, 0.9635681509971619, 0.9563353657722473, 0.9600857496261597, 0.950709879398346, 0.9590141773223877, 0.9600857496261597, 0.9592821002006531, 0.9627645611763, 0.9641039371490479, 0.9654433727264404, 0.9635681509971619, 0.9649075865745544, 0.9627645611763, 0.9678542613983154, 0.9608893394470215, 0.9683900475502014, 0.9665148854255676, 0.9675863981246948, 0.9654433727264404, 0.9699973464012146, 0.9694615602493286, 0.9705330729484558, 0.969193696975708], 'val_loss': [0.6716097593307495, 0.6669698357582092, 0.6631067395210266, 0.6560876965522766, 0.6499788165092468, 0.6413500905036926, 0.6294597387313843, 0.618224024772644, 0.6062740087509155, 0.5902234315872192, 0.5692440867424011, 0.5489391684532166, 0.5185466408729553, 0.4921855330467224, 0.4621346890926361, 0.42834100127220154, 0.4050222337245941, 0.37278228998184204, 0.3534456491470337, 0.3518230617046356, 0.3372173011302948, 0.3155893087387085, 0.3141837418079376, 0.4069388210773468, 0.34107398986816406, 0.3103550970554352, 0.31501317024230957, 0.3473269045352936, 0.3230271637439728, 0.34844112396240234, 0.3251126706600189, 0.34309515357017517, 0.32969915866851807, 0.33127427101135254, 0.3393037021160126, 0.33624473214149475, 0.3347870409488678, 0.3499353528022766, 0.3385528028011322, 0.3387311100959778, 0.34826046228408813, 0.3425523340702057, 0.3447388708591461, 0.35107421875, 0.34662896394729614, 0.36167478561401367, 0.3569927215576172, 0.35231608152389526, 0.3542484939098358, 0.35776567459106445, 0.36285656690597534, 0.3578779399394989, 0.3574254512786865, 0.36399608850479126, 0.4418219327926636, 0.44116124510765076, 0.3658623993396759, 0.3735843896865845, 0.36394163966178894, 0.36360806226730347, 0.406074583530426, 0.37384963035583496, 0.3770468533039093, 0.37146300077438354, 0.37698638439178467, 0.4108502268791199, 0.38408002257347107, 0.4464949369430542, 0.381751149892807, 0.3825409412384033, 0.41271230578422546, 0.3891754150390625, 0.3870526850223541, 0.3935365080833435, 0.38792046904563904, 0.38607293367385864, 0.39619001746177673, 0.4013206362724304, 0.40230467915534973, 0.39684444665908813, 0.4176516830921173, 0.40611687302589417, 0.3981136083602905, 0.4137386679649353, 0.41471296548843384, 0.41845208406448364, 0.4112659990787506, 0.413504421710968, 0.41270390152931213, 0.433525025844574, 0.4163660407066345, 0.4394742250442505, 0.4257145822048187, 0.42258891463279724, 0.42610928416252136, 0.4244304597377777, 0.42535459995269775, 0.43037477135658264, 0.44945618510246277, 0.4622285068035126], 'val_accuracy': [0.7237687110900879, 0.778372585773468, 0.7858672142028809, 0.7858672142028809, 0.8083511590957642, 0.8008565306663513, 0.8340471386909485, 0.8340471386909485, 0.8201285004615784, 0.8169164657592773, 0.840471088886261, 0.8286938071250916, 0.8394004106521606, 0.8501070737838745, 0.8479657173156738, 0.8533190488815308, 0.8576017022132874, 0.861884355545044, 0.859743058681488, 0.8490363955497742, 0.856531023979187, 0.8683083653450012, 0.8683083653450012, 0.8329764604568481, 0.8533190488815308, 0.8661670088768005, 0.8683083653450012, 0.8554604053497314, 0.8608136773109436, 0.8533190488815308, 0.8672376871109009, 0.8683083653450012, 0.8661670088768005, 0.8640257120132446, 0.8576017022132874, 0.8640257120132446, 0.8608136773109436, 0.8576017022132874, 0.8683083653450012, 0.8629550337791443, 0.859743058681488, 0.8640257120132446, 0.861884355545044, 0.859743058681488, 0.861884355545044, 0.856531023979187, 0.859743058681488, 0.8629550337791443, 0.8608136773109436, 0.859743058681488, 0.8586723804473877, 0.859743058681488, 0.861884355545044, 0.8576017022132874, 0.8383297920227051, 0.8447537422180176, 0.8576017022132874, 0.856531023979187, 0.8533190488815308, 0.856531023979187, 0.8447537422180176, 0.859743058681488, 0.8501070737838745, 0.8576017022132874, 0.8543897271156311, 0.8436830639839172, 0.8576017022132874, 0.8468950986862183, 0.8554604053497314, 0.8554604053497314, 0.8511777520179749, 0.8543897271156311, 0.8554604053497314, 0.8533190488815308, 0.8522483706474304, 0.8511777520179749, 0.8511777520179749, 0.8543897271156311, 0.8533190488815308, 0.8511777520179749, 0.8511777520179749, 0.8533190488815308, 0.8576017022132874, 0.8554604053497314, 0.8554604053497314, 0.8533190488815308, 0.8554604053497314, 0.8543897271156311, 0.8501070737838745, 0.8511777520179749, 0.8501070737838745, 0.8543897271156311, 0.8522483706474304, 0.856531023979187, 0.8533190488815308, 0.8511777520179749, 0.8522483706474304, 0.8511777520179749, 0.8501070737838745, 0.8511777520179749]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 53ms/step - loss: 0.2794 - accuracy: 0.8856 - val_loss: 0.6707 - val_accuracy: 0.7687\n","Epoch 2/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2682 - accuracy: 0.8904 - val_loss: 0.6670 - val_accuracy: 0.7966\n","Epoch 3/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2621 - accuracy: 0.8937 - val_loss: 0.6625 - val_accuracy: 0.7869\n","Epoch 4/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2616 - accuracy: 0.8937 - val_loss: 0.6573 - val_accuracy: 0.7976\n","Epoch 5/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2607 - accuracy: 0.8961 - val_loss: 0.6506 - val_accuracy: 0.7891\n","Epoch 6/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2561 - accuracy: 0.8971 - val_loss: 0.6428 - val_accuracy: 0.8158\n","Epoch 7/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2498 - accuracy: 0.9009 - val_loss: 0.6322 - val_accuracy: 0.8137\n","Epoch 8/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2597 - accuracy: 0.8923 - val_loss: 0.6217 - val_accuracy: 0.7976\n","Epoch 9/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2462 - accuracy: 0.9052 - val_loss: 0.6076 - val_accuracy: 0.8223\n","Epoch 10/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2444 - accuracy: 0.9065 - val_loss: 0.5918 - val_accuracy: 0.8244\n","Epoch 11/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2395 - accuracy: 0.9054 - val_loss: 0.5732 - val_accuracy: 0.8212\n","Epoch 12/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.2436 - accuracy: 0.9057 - val_loss: 0.5528 - val_accuracy: 0.8298\n","Epoch 13/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.2328 - accuracy: 0.9087 - val_loss: 0.5319 - val_accuracy: 0.8212\n","Epoch 14/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2340 - accuracy: 0.9089 - val_loss: 0.4985 - val_accuracy: 0.8340\n","Epoch 15/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.2309 - accuracy: 0.9132 - val_loss: 0.4738 - val_accuracy: 0.8276\n","Epoch 16/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.2388 - accuracy: 0.9095 - val_loss: 0.4519 - val_accuracy: 0.8233\n","Epoch 17/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.2327 - accuracy: 0.9148 - val_loss: 0.4172 - val_accuracy: 0.8340\n","Epoch 18/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2227 - accuracy: 0.9153 - val_loss: 0.3952 - val_accuracy: 0.8383\n","Epoch 19/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2235 - accuracy: 0.9132 - val_loss: 0.3693 - val_accuracy: 0.8426\n","Epoch 20/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2292 - accuracy: 0.9100 - val_loss: 0.3680 - val_accuracy: 0.8469\n","Epoch 21/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2222 - accuracy: 0.9156 - val_loss: 0.4005 - val_accuracy: 0.8340\n","Epoch 22/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2331 - accuracy: 0.9070 - val_loss: 0.3479 - val_accuracy: 0.8501\n","Epoch 23/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2195 - accuracy: 0.9151 - val_loss: 0.3328 - val_accuracy: 0.8576\n","Epoch 24/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2211 - accuracy: 0.9119 - val_loss: 0.3424 - val_accuracy: 0.8555\n","Epoch 25/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2105 - accuracy: 0.9215 - val_loss: 0.3237 - val_accuracy: 0.8608\n","Epoch 26/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2054 - accuracy: 0.9269 - val_loss: 0.3298 - val_accuracy: 0.8630\n","Epoch 27/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2076 - accuracy: 0.9231 - val_loss: 0.3291 - val_accuracy: 0.8672\n","Epoch 28/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2050 - accuracy: 0.9226 - val_loss: 0.3446 - val_accuracy: 0.8619\n","Epoch 29/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2042 - accuracy: 0.9250 - val_loss: 0.3438 - val_accuracy: 0.8640\n","Epoch 30/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2003 - accuracy: 0.9261 - val_loss: 0.3356 - val_accuracy: 0.8726\n","Epoch 31/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1999 - accuracy: 0.9298 - val_loss: 0.4065 - val_accuracy: 0.8383\n","Epoch 32/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2128 - accuracy: 0.9167 - val_loss: 0.3407 - val_accuracy: 0.8672\n","Epoch 33/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1944 - accuracy: 0.9336 - val_loss: 0.3446 - val_accuracy: 0.8683\n","Epoch 34/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1990 - accuracy: 0.9258 - val_loss: 0.3451 - val_accuracy: 0.8715\n","Epoch 35/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1873 - accuracy: 0.9352 - val_loss: 0.3740 - val_accuracy: 0.8619\n","Epoch 36/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1913 - accuracy: 0.9285 - val_loss: 0.3907 - val_accuracy: 0.8448\n","Epoch 37/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1952 - accuracy: 0.9312 - val_loss: 0.3484 - val_accuracy: 0.8662\n","Epoch 38/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.1867 - accuracy: 0.9346 - val_loss: 0.3605 - val_accuracy: 0.8533\n","Epoch 39/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1997 - accuracy: 0.9237 - val_loss: 0.3620 - val_accuracy: 0.8640\n","Epoch 40/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1834 - accuracy: 0.9357 - val_loss: 0.4463 - val_accuracy: 0.8340\n","Epoch 41/100\n","30/30 [==============================] - 1s 31ms/step - loss: 0.2082 - accuracy: 0.9188 - val_loss: 0.3608 - val_accuracy: 0.8683\n","Epoch 42/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1851 - accuracy: 0.9312 - val_loss: 0.3593 - val_accuracy: 0.8597\n","Epoch 43/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1835 - accuracy: 0.9336 - val_loss: 0.3614 - val_accuracy: 0.8597\n","Epoch 44/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1754 - accuracy: 0.9360 - val_loss: 0.3643 - val_accuracy: 0.8576\n","Epoch 45/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1739 - accuracy: 0.9416 - val_loss: 0.3586 - val_accuracy: 0.8651\n","Epoch 46/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1809 - accuracy: 0.9333 - val_loss: 0.3678 - val_accuracy: 0.8587\n","Epoch 47/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1811 - accuracy: 0.9314 - val_loss: 0.3568 - val_accuracy: 0.8704\n","Epoch 48/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1704 - accuracy: 0.9387 - val_loss: 0.3901 - val_accuracy: 0.8597\n","Epoch 49/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1696 - accuracy: 0.9392 - val_loss: 0.3653 - val_accuracy: 0.8608\n","Epoch 50/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1722 - accuracy: 0.9379 - val_loss: 0.3848 - val_accuracy: 0.8512\n","Epoch 51/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1603 - accuracy: 0.9432 - val_loss: 0.3641 - val_accuracy: 0.8683\n","Epoch 52/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1641 - accuracy: 0.9459 - val_loss: 0.3680 - val_accuracy: 0.8683\n","Epoch 53/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1666 - accuracy: 0.9397 - val_loss: 0.3880 - val_accuracy: 0.8630\n","Epoch 54/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1752 - accuracy: 0.9389 - val_loss: 0.3683 - val_accuracy: 0.8683\n","Epoch 55/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1567 - accuracy: 0.9459 - val_loss: 0.3704 - val_accuracy: 0.8683\n","Epoch 56/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1615 - accuracy: 0.9437 - val_loss: 0.3725 - val_accuracy: 0.8630\n","Epoch 57/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1664 - accuracy: 0.9365 - val_loss: 0.3700 - val_accuracy: 0.8672\n","Epoch 58/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1502 - accuracy: 0.9510 - val_loss: 0.3861 - val_accuracy: 0.8555\n","Epoch 59/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1450 - accuracy: 0.9515 - val_loss: 0.3771 - val_accuracy: 0.8672\n","Epoch 60/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1566 - accuracy: 0.9440 - val_loss: 0.3818 - val_accuracy: 0.8576\n","Epoch 61/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1762 - accuracy: 0.9322 - val_loss: 0.3854 - val_accuracy: 0.8576\n","Epoch 62/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1690 - accuracy: 0.9384 - val_loss: 0.3951 - val_accuracy: 0.8608\n","Epoch 63/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1531 - accuracy: 0.9456 - val_loss: 0.3815 - val_accuracy: 0.8651\n","Epoch 64/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1472 - accuracy: 0.9507 - val_loss: 0.4002 - val_accuracy: 0.8597\n","Epoch 65/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1495 - accuracy: 0.9467 - val_loss: 0.4230 - val_accuracy: 0.8565\n","Epoch 66/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1472 - accuracy: 0.9478 - val_loss: 0.4662 - val_accuracy: 0.8394\n","Epoch 67/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1615 - accuracy: 0.9397 - val_loss: 0.3927 - val_accuracy: 0.8662\n","Epoch 68/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1427 - accuracy: 0.9529 - val_loss: 0.4096 - val_accuracy: 0.8512\n","Epoch 69/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1565 - accuracy: 0.9445 - val_loss: 0.3825 - val_accuracy: 0.8587\n","Epoch 70/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1574 - accuracy: 0.9443 - val_loss: 0.3982 - val_accuracy: 0.8480\n","Epoch 71/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1437 - accuracy: 0.9491 - val_loss: 0.3905 - val_accuracy: 0.8555\n","Epoch 72/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1384 - accuracy: 0.9531 - val_loss: 0.3873 - val_accuracy: 0.8640\n","Epoch 73/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1406 - accuracy: 0.9523 - val_loss: 0.3895 - val_accuracy: 0.8683\n","Epoch 74/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1329 - accuracy: 0.9561 - val_loss: 0.3923 - val_accuracy: 0.8683\n","Epoch 75/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1264 - accuracy: 0.9577 - val_loss: 0.3978 - val_accuracy: 0.8662\n","Epoch 76/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1264 - accuracy: 0.9590 - val_loss: 0.3977 - val_accuracy: 0.8672\n","Epoch 77/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1307 - accuracy: 0.9579 - val_loss: 0.3975 - val_accuracy: 0.8662\n","Epoch 78/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1253 - accuracy: 0.9617 - val_loss: 0.4202 - val_accuracy: 0.8512\n","Epoch 79/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1222 - accuracy: 0.9612 - val_loss: 0.4668 - val_accuracy: 0.8319\n","Epoch 80/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1315 - accuracy: 0.9542 - val_loss: 0.4191 - val_accuracy: 0.8544\n","Epoch 81/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1208 - accuracy: 0.9617 - val_loss: 0.4211 - val_accuracy: 0.8662\n","Epoch 82/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1167 - accuracy: 0.9644 - val_loss: 0.4198 - val_accuracy: 0.8651\n","Epoch 83/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1202 - accuracy: 0.9585 - val_loss: 0.4183 - val_accuracy: 0.8619\n","Epoch 84/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1176 - accuracy: 0.9622 - val_loss: 0.4698 - val_accuracy: 0.8522\n","Epoch 85/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1365 - accuracy: 0.9518 - val_loss: 0.4086 - val_accuracy: 0.8672\n","Epoch 86/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1144 - accuracy: 0.9633 - val_loss: 0.4293 - val_accuracy: 0.8533\n","Epoch 87/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1191 - accuracy: 0.9593 - val_loss: 0.4361 - val_accuracy: 0.8533\n","Epoch 88/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1134 - accuracy: 0.9633 - val_loss: 0.4248 - val_accuracy: 0.8672\n","Epoch 89/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1098 - accuracy: 0.9644 - val_loss: 0.4316 - val_accuracy: 0.8651\n","Epoch 90/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1116 - accuracy: 0.9638 - val_loss: 0.4335 - val_accuracy: 0.8565\n","Epoch 91/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1201 - accuracy: 0.9630 - val_loss: 0.4408 - val_accuracy: 0.8544\n","Epoch 92/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1087 - accuracy: 0.9654 - val_loss: 0.4376 - val_accuracy: 0.8490\n","Epoch 93/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1101 - accuracy: 0.9665 - val_loss: 0.4476 - val_accuracy: 0.8555\n","Epoch 94/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1081 - accuracy: 0.9684 - val_loss: 0.4353 - val_accuracy: 0.8651\n","Epoch 95/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0992 - accuracy: 0.9711 - val_loss: 0.4688 - val_accuracy: 0.8405\n","Epoch 96/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1050 - accuracy: 0.9700 - val_loss: 0.4435 - val_accuracy: 0.8587\n","Epoch 97/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1049 - accuracy: 0.9668 - val_loss: 0.4605 - val_accuracy: 0.8458\n","Epoch 98/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1035 - accuracy: 0.9673 - val_loss: 0.4392 - val_accuracy: 0.8662\n","Epoch 99/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0956 - accuracy: 0.9713 - val_loss: 0.4507 - val_accuracy: 0.8651\n","Epoch 100/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1059 - accuracy: 0.9654 - val_loss: 0.4893 - val_accuracy: 0.8330\n","{'loss': [0.27943944931030273, 0.26818472146987915, 0.26209625601768494, 0.26163822412490845, 0.2607246935367584, 0.256090372800827, 0.24981427192687988, 0.2597198188304901, 0.24621173739433289, 0.24440878629684448, 0.2394581139087677, 0.24358470737934113, 0.23284579813480377, 0.23397953808307648, 0.23087316751480103, 0.23876486718654633, 0.23267729580402374, 0.2227272242307663, 0.2234705239534378, 0.22919407486915588, 0.22217194736003876, 0.23309451341629028, 0.21952475607395172, 0.22113579511642456, 0.2104586660861969, 0.20541974902153015, 0.20762932300567627, 0.20504459738731384, 0.20424111187458038, 0.20033110678195953, 0.19992944598197937, 0.2127717137336731, 0.1944192349910736, 0.1990257054567337, 0.187334343791008, 0.19125309586524963, 0.1952359825372696, 0.18670210242271423, 0.1997126191854477, 0.18344253301620483, 0.20819590985774994, 0.1850605458021164, 0.1834707260131836, 0.1753574013710022, 0.17388390004634857, 0.18092772364616394, 0.18110129237174988, 0.1703711599111557, 0.16964833438396454, 0.17215406894683838, 0.1602931171655655, 0.16407477855682373, 0.16662131249904633, 0.17517229914665222, 0.15668180584907532, 0.16145353019237518, 0.16644629836082458, 0.15020973980426788, 0.14501260221004486, 0.1566237211227417, 0.17616717517375946, 0.1689601093530655, 0.15312089025974274, 0.14717625081539154, 0.14950387179851532, 0.14719480276107788, 0.1614898443222046, 0.14270254969596863, 0.15654009580612183, 0.15737003087997437, 0.14365357160568237, 0.1383666694164276, 0.14057600498199463, 0.132925882935524, 0.12641744315624237, 0.12635166943073273, 0.13071508705615997, 0.1253497451543808, 0.1221882626414299, 0.13154204189777374, 0.12075718492269516, 0.11672092974185944, 0.12021037191152573, 0.11755890399217606, 0.1365266591310501, 0.11436072736978531, 0.11912950128316879, 0.11337895691394806, 0.10984300076961517, 0.11163344979286194, 0.12006045877933502, 0.10869447141885757, 0.11014063656330109, 0.1081225797533989, 0.09917094558477402, 0.10500286519527435, 0.10494919121265411, 0.10348883271217346, 0.09559210389852524, 0.10589079558849335], 'accuracy': [0.885614812374115, 0.8904366493225098, 0.8936512470245361, 0.8936512470245361, 0.8960621356964111, 0.8971336483955383, 0.9008840322494507, 0.8923118114471436, 0.9051700830459595, 0.906509518623352, 0.9054380059242249, 0.9057058691978455, 0.9086525440216064, 0.9089204668998718, 0.9132065176963806, 0.909456193447113, 0.9148138165473938, 0.9153496026992798, 0.9132065176963806, 0.909991979598999, 0.9156174659729004, 0.9070452451705933, 0.9150816798210144, 0.9118671417236328, 0.9215108752250671, 0.9268684983253479, 0.9231181144714355, 0.9225823879241943, 0.9249932765960693, 0.9260648488998413, 0.9298151731491089, 0.9166889786720276, 0.9335654973983765, 0.9257969260215759, 0.9351727962493896, 0.9284757375717163, 0.9311545491218567, 0.9346370100975037, 0.9236539006233215, 0.9357085227966309, 0.9188320636749268, 0.9311545491218567, 0.9335654973983765, 0.9359764456748962, 0.9416019320487976, 0.9332976341247559, 0.9314224720001221, 0.9386552572250366, 0.9391909837722778, 0.93785160779953, 0.9432092308998108, 0.9458880424499512, 0.9397267699241638, 0.9389231204986572, 0.9458880424499512, 0.943744957447052, 0.9365121722221375, 0.9509777426719666, 0.9515135288238525, 0.9440128803253174, 0.9322260618209839, 0.9383873343467712, 0.9456201195716858, 0.950709879398346, 0.9466916918754578, 0.947763204574585, 0.9397267699241638, 0.9528529047966003, 0.9445486068725586, 0.944280743598938, 0.9491025805473328, 0.9531208276748657, 0.9523171782493591, 0.9560675024986267, 0.9576748013496399, 0.9590141773223877, 0.9579426646232605, 0.9616929888725281, 0.9611572623252869, 0.9541923403739929, 0.9616929888725281, 0.9643718004226685, 0.9584784507751465, 0.9622287750244141, 0.9517813920974731, 0.9633002877235413, 0.9592821002006531, 0.9633002877235413, 0.9643718004226685, 0.9638360738754272, 0.9630324244499207, 0.9654433727264404, 0.9665148854255676, 0.9683900475502014, 0.9710688591003418, 0.9699973464012146, 0.9667827486991882, 0.9673185348510742, 0.9713367223739624, 0.9654433727264404], 'val_loss': [0.6706938743591309, 0.6670395135879517, 0.6625291705131531, 0.6572598814964294, 0.6506473422050476, 0.6427700519561768, 0.6322392225265503, 0.6216596364974976, 0.6076045632362366, 0.5917862057685852, 0.573199987411499, 0.5527829527854919, 0.5319002866744995, 0.49850112199783325, 0.47377902269363403, 0.451861172914505, 0.4171724319458008, 0.3952212333679199, 0.36929529905319214, 0.3680361211299896, 0.40045350790023804, 0.3479360044002533, 0.3327920436859131, 0.34235522150993347, 0.3237307369709015, 0.32981234788894653, 0.32910996675491333, 0.34457603096961975, 0.3438114821910858, 0.3356151580810547, 0.406536728143692, 0.3406502306461334, 0.34463953971862793, 0.3450649380683899, 0.37397390604019165, 0.39074137806892395, 0.3483632504940033, 0.3605015277862549, 0.3619667589664459, 0.44626083970069885, 0.3607737421989441, 0.35927826166152954, 0.36141711473464966, 0.36427149176597595, 0.3585506081581116, 0.36775141954421997, 0.3568307161331177, 0.3901400864124298, 0.36525583267211914, 0.38478460907936096, 0.3641154170036316, 0.36802807450294495, 0.38803380727767944, 0.3683162331581116, 0.37041381001472473, 0.37245720624923706, 0.37000572681427, 0.3861013948917389, 0.3771446645259857, 0.3818461298942566, 0.3853510022163391, 0.39510872960090637, 0.3815440237522125, 0.4002113938331604, 0.4229593276977539, 0.466169148683548, 0.3926873505115509, 0.4096128046512604, 0.3825182020664215, 0.39824211597442627, 0.3905153274536133, 0.3872703015804291, 0.3895379900932312, 0.39226505160331726, 0.39784252643585205, 0.39767903089523315, 0.39747223258018494, 0.4201867878437042, 0.46675801277160645, 0.41907525062561035, 0.4211369454860687, 0.419800728559494, 0.4183000922203064, 0.4697956144809723, 0.40856829285621643, 0.42929351329803467, 0.4361189603805542, 0.42483755946159363, 0.4316141903400421, 0.4335373640060425, 0.4407748281955719, 0.4376223683357239, 0.44759100675582886, 0.43525686860084534, 0.4687969386577606, 0.4435420036315918, 0.4605138301849365, 0.43924009799957275, 0.45074471831321716, 0.4892910420894623], 'val_accuracy': [0.7687366008758545, 0.7965738773345947, 0.7869378924369812, 0.7976445555686951, 0.7890792489051819, 0.8158458471298218, 0.8137044906616211, 0.7976445555686951, 0.8222697973251343, 0.824411153793335, 0.8211991190910339, 0.8297644257545471, 0.8211991190910339, 0.8340471386909485, 0.8276231288909912, 0.8233404755592346, 0.8340471386909485, 0.8383297920227051, 0.8426124453544617, 0.8468950986862183, 0.8340471386909485, 0.8501070737838745, 0.8576017022132874, 0.8554604053497314, 0.8608136773109436, 0.8629550337791443, 0.8672376871109009, 0.861884355545044, 0.8640257120132446, 0.8725910186767578, 0.8383297920227051, 0.8672376871109009, 0.8683083653450012, 0.8715203404426575, 0.861884355545044, 0.8447537422180176, 0.8661670088768005, 0.8533190488815308, 0.8640257120132446, 0.8340471386909485, 0.8683083653450012, 0.859743058681488, 0.859743058681488, 0.8576017022132874, 0.8650963306427002, 0.8586723804473877, 0.8704496622085571, 0.859743058681488, 0.8608136773109436, 0.8511777520179749, 0.8683083653450012, 0.8683083653450012, 0.8629550337791443, 0.8683083653450012, 0.8683083653450012, 0.8629550337791443, 0.8672376871109009, 0.8554604053497314, 0.8672376871109009, 0.8576017022132874, 0.8576017022132874, 0.8608136773109436, 0.8650963306427002, 0.859743058681488, 0.856531023979187, 0.8394004106521606, 0.8661670088768005, 0.8511777520179749, 0.8586723804473877, 0.8479657173156738, 0.8554604053497314, 0.8640257120132446, 0.8683083653450012, 0.8683083653450012, 0.8661670088768005, 0.8672376871109009, 0.8661670088768005, 0.8511777520179749, 0.8319057822227478, 0.8543897271156311, 0.8661670088768005, 0.8650963306427002, 0.861884355545044, 0.8522483706474304, 0.8672376871109009, 0.8533190488815308, 0.8533190488815308, 0.8672376871109009, 0.8650963306427002, 0.856531023979187, 0.8543897271156311, 0.8490363955497742, 0.8554604053497314, 0.8650963306427002, 0.840471088886261, 0.8586723804473877, 0.8458244204521179, 0.8661670088768005, 0.8650963306427002, 0.8329764604568481]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 53ms/step - loss: 0.1845 - accuracy: 0.9330 - val_loss: 0.6632 - val_accuracy: 0.7901\n","Epoch 2/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1655 - accuracy: 0.9437 - val_loss: 0.6584 - val_accuracy: 0.8137\n","Epoch 3/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1750 - accuracy: 0.9346 - val_loss: 0.6517 - val_accuracy: 0.8073\n","Epoch 4/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1500 - accuracy: 0.9510 - val_loss: 0.6458 - val_accuracy: 0.8148\n","Epoch 5/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1390 - accuracy: 0.9545 - val_loss: 0.6366 - val_accuracy: 0.8126\n","Epoch 6/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1454 - accuracy: 0.9518 - val_loss: 0.6266 - val_accuracy: 0.8116\n","Epoch 7/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1494 - accuracy: 0.9486 - val_loss: 0.6137 - val_accuracy: 0.8137\n","Epoch 8/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1417 - accuracy: 0.9512 - val_loss: 0.6037 - val_accuracy: 0.8116\n","Epoch 9/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1479 - accuracy: 0.9456 - val_loss: 0.5847 - val_accuracy: 0.8148\n","Epoch 10/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1350 - accuracy: 0.9561 - val_loss: 0.5650 - val_accuracy: 0.8105\n","Epoch 11/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1631 - accuracy: 0.9392 - val_loss: 0.5493 - val_accuracy: 0.8051\n","Epoch 12/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1356 - accuracy: 0.9550 - val_loss: 0.5215 - val_accuracy: 0.8223\n","Epoch 13/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1299 - accuracy: 0.9550 - val_loss: 0.4963 - val_accuracy: 0.8169\n","Epoch 14/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1240 - accuracy: 0.9614 - val_loss: 0.4640 - val_accuracy: 0.8233\n","Epoch 15/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1371 - accuracy: 0.9531 - val_loss: 0.4647 - val_accuracy: 0.8073\n","Epoch 16/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.1622 - accuracy: 0.9384 - val_loss: 0.4382 - val_accuracy: 0.8094\n","Epoch 17/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1426 - accuracy: 0.9491 - val_loss: 0.3968 - val_accuracy: 0.8330\n","Epoch 18/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1240 - accuracy: 0.9595 - val_loss: 0.3783 - val_accuracy: 0.8405\n","Epoch 19/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1245 - accuracy: 0.9612 - val_loss: 0.3700 - val_accuracy: 0.8373\n","Epoch 20/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1217 - accuracy: 0.9622 - val_loss: 0.3793 - val_accuracy: 0.8448\n","Epoch 21/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1160 - accuracy: 0.9609 - val_loss: 0.3924 - val_accuracy: 0.8405\n","Epoch 22/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1207 - accuracy: 0.9598 - val_loss: 0.3712 - val_accuracy: 0.8426\n","Epoch 23/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1159 - accuracy: 0.9644 - val_loss: 0.3798 - val_accuracy: 0.8448\n","Epoch 24/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1129 - accuracy: 0.9665 - val_loss: 0.3867 - val_accuracy: 0.8458\n","Epoch 25/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1155 - accuracy: 0.9620 - val_loss: 0.3955 - val_accuracy: 0.8576\n","Epoch 26/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1119 - accuracy: 0.9649 - val_loss: 0.4031 - val_accuracy: 0.8544\n","Epoch 27/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1149 - accuracy: 0.9641 - val_loss: 0.4187 - val_accuracy: 0.8480\n","Epoch 28/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1120 - accuracy: 0.9652 - val_loss: 0.4297 - val_accuracy: 0.8480\n","Epoch 29/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1135 - accuracy: 0.9652 - val_loss: 0.4556 - val_accuracy: 0.8480\n","Epoch 30/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1078 - accuracy: 0.9668 - val_loss: 0.4361 - val_accuracy: 0.8448\n","Epoch 31/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1120 - accuracy: 0.9649 - val_loss: 0.4641 - val_accuracy: 0.8522\n","Epoch 32/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1278 - accuracy: 0.9574 - val_loss: 0.4506 - val_accuracy: 0.8533\n","Epoch 33/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1152 - accuracy: 0.9598 - val_loss: 0.4507 - val_accuracy: 0.8351\n","Epoch 34/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1032 - accuracy: 0.9700 - val_loss: 0.4478 - val_accuracy: 0.8458\n","Epoch 35/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0986 - accuracy: 0.9729 - val_loss: 0.4676 - val_accuracy: 0.8437\n","Epoch 36/100\n","30/30 [==============================] - 1s 31ms/step - loss: 0.0994 - accuracy: 0.9695 - val_loss: 0.4665 - val_accuracy: 0.8426\n","Epoch 37/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0963 - accuracy: 0.9713 - val_loss: 0.4852 - val_accuracy: 0.8426\n","Epoch 38/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0977 - accuracy: 0.9708 - val_loss: 0.4682 - val_accuracy: 0.8458\n","Epoch 39/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0948 - accuracy: 0.9719 - val_loss: 0.4621 - val_accuracy: 0.8448\n","Epoch 40/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0957 - accuracy: 0.9711 - val_loss: 0.4782 - val_accuracy: 0.8373\n","Epoch 41/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0926 - accuracy: 0.9711 - val_loss: 0.4821 - val_accuracy: 0.8501\n","Epoch 42/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0960 - accuracy: 0.9732 - val_loss: 0.4867 - val_accuracy: 0.8448\n","Epoch 43/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0975 - accuracy: 0.9689 - val_loss: 0.4820 - val_accuracy: 0.8448\n","Epoch 44/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0890 - accuracy: 0.9748 - val_loss: 0.4939 - val_accuracy: 0.8383\n","Epoch 45/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0938 - accuracy: 0.9737 - val_loss: 0.5005 - val_accuracy: 0.8362\n","Epoch 46/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0906 - accuracy: 0.9740 - val_loss: 0.4937 - val_accuracy: 0.8448\n","Epoch 47/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0890 - accuracy: 0.9737 - val_loss: 0.4959 - val_accuracy: 0.8469\n","Epoch 48/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0980 - accuracy: 0.9708 - val_loss: 0.5210 - val_accuracy: 0.8426\n","Epoch 49/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0946 - accuracy: 0.9708 - val_loss: 0.5696 - val_accuracy: 0.8394\n","Epoch 50/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0991 - accuracy: 0.9700 - val_loss: 0.4961 - val_accuracy: 0.8458\n","Epoch 51/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0903 - accuracy: 0.9754 - val_loss: 0.5554 - val_accuracy: 0.8437\n","Epoch 52/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0861 - accuracy: 0.9770 - val_loss: 0.4988 - val_accuracy: 0.8426\n","Epoch 53/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0808 - accuracy: 0.9786 - val_loss: 0.5048 - val_accuracy: 0.8448\n","Epoch 54/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0839 - accuracy: 0.9751 - val_loss: 0.5182 - val_accuracy: 0.8383\n","Epoch 55/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0750 - accuracy: 0.9807 - val_loss: 0.5100 - val_accuracy: 0.8448\n","Epoch 56/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0824 - accuracy: 0.9786 - val_loss: 0.5164 - val_accuracy: 0.8448\n","Epoch 57/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0834 - accuracy: 0.9764 - val_loss: 0.5483 - val_accuracy: 0.8415\n","Epoch 58/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0871 - accuracy: 0.9735 - val_loss: 0.5534 - val_accuracy: 0.8415\n","Epoch 59/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0808 - accuracy: 0.9783 - val_loss: 0.5173 - val_accuracy: 0.8415\n","Epoch 60/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0725 - accuracy: 0.9834 - val_loss: 0.5300 - val_accuracy: 0.8405\n","Epoch 61/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0789 - accuracy: 0.9772 - val_loss: 0.5302 - val_accuracy: 0.8415\n","Epoch 62/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0777 - accuracy: 0.9786 - val_loss: 0.5436 - val_accuracy: 0.8415\n","Epoch 63/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0804 - accuracy: 0.9791 - val_loss: 0.5627 - val_accuracy: 0.8340\n","Epoch 64/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0783 - accuracy: 0.9788 - val_loss: 0.5620 - val_accuracy: 0.8362\n","Epoch 65/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0996 - accuracy: 0.9681 - val_loss: 0.5398 - val_accuracy: 0.8394\n","Epoch 66/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0755 - accuracy: 0.9799 - val_loss: 0.5472 - val_accuracy: 0.8426\n","Epoch 67/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0771 - accuracy: 0.9778 - val_loss: 0.5320 - val_accuracy: 0.8512\n","Epoch 68/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0749 - accuracy: 0.9778 - val_loss: 0.5433 - val_accuracy: 0.8405\n","Epoch 69/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0986 - accuracy: 0.9684 - val_loss: 0.6286 - val_accuracy: 0.8223\n","Epoch 70/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1085 - accuracy: 0.9641 - val_loss: 0.5291 - val_accuracy: 0.8458\n","Epoch 71/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0801 - accuracy: 0.9772 - val_loss: 0.5295 - val_accuracy: 0.8469\n","Epoch 72/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0741 - accuracy: 0.9788 - val_loss: 0.5527 - val_accuracy: 0.8394\n","Epoch 73/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0652 - accuracy: 0.9831 - val_loss: 0.5441 - val_accuracy: 0.8437\n","Epoch 74/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0873 - accuracy: 0.9721 - val_loss: 0.5343 - val_accuracy: 0.8458\n","Epoch 75/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0641 - accuracy: 0.9845 - val_loss: 0.5562 - val_accuracy: 0.8437\n","Epoch 76/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0709 - accuracy: 0.9810 - val_loss: 0.5656 - val_accuracy: 0.8448\n","Epoch 77/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0669 - accuracy: 0.9829 - val_loss: 0.5593 - val_accuracy: 0.8426\n","Epoch 78/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1200 - accuracy: 0.9587 - val_loss: 0.5963 - val_accuracy: 0.8319\n","Epoch 79/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0863 - accuracy: 0.9724 - val_loss: 0.5632 - val_accuracy: 0.8362\n","Epoch 80/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0707 - accuracy: 0.9799 - val_loss: 0.5505 - val_accuracy: 0.8405\n","Epoch 81/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0648 - accuracy: 0.9823 - val_loss: 0.6019 - val_accuracy: 0.8383\n","Epoch 82/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0613 - accuracy: 0.9858 - val_loss: 0.5949 - val_accuracy: 0.8426\n","Epoch 83/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0573 - accuracy: 0.9866 - val_loss: 0.5917 - val_accuracy: 0.8362\n","Epoch 84/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0589 - accuracy: 0.9853 - val_loss: 0.5989 - val_accuracy: 0.8383\n","Epoch 85/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0579 - accuracy: 0.9847 - val_loss: 0.5721 - val_accuracy: 0.8415\n","Epoch 86/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0746 - accuracy: 0.9794 - val_loss: 0.5765 - val_accuracy: 0.8448\n","Epoch 87/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0633 - accuracy: 0.9837 - val_loss: 0.6040 - val_accuracy: 0.8362\n","Epoch 88/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0583 - accuracy: 0.9853 - val_loss: 0.5830 - val_accuracy: 0.8458\n","Epoch 89/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0548 - accuracy: 0.9861 - val_loss: 0.6850 - val_accuracy: 0.8287\n","Epoch 90/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0567 - accuracy: 0.9853 - val_loss: 0.6838 - val_accuracy: 0.8308\n","Epoch 91/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0564 - accuracy: 0.9853 - val_loss: 0.6283 - val_accuracy: 0.8373\n","Epoch 92/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0588 - accuracy: 0.9871 - val_loss: 0.5920 - val_accuracy: 0.8426\n","Epoch 93/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0564 - accuracy: 0.9861 - val_loss: 0.6081 - val_accuracy: 0.8394\n","Epoch 94/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0572 - accuracy: 0.9858 - val_loss: 0.7179 - val_accuracy: 0.8308\n","Epoch 95/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0600 - accuracy: 0.9842 - val_loss: 0.6403 - val_accuracy: 0.8373\n","Epoch 96/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0619 - accuracy: 0.9834 - val_loss: 0.5993 - val_accuracy: 0.8383\n","Epoch 97/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0571 - accuracy: 0.9850 - val_loss: 0.6076 - val_accuracy: 0.8415\n","Epoch 98/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0589 - accuracy: 0.9845 - val_loss: 0.6408 - val_accuracy: 0.8383\n","Epoch 99/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0589 - accuracy: 0.9837 - val_loss: 0.7462 - val_accuracy: 0.8308\n","Epoch 100/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0639 - accuracy: 0.9831 - val_loss: 0.7666 - val_accuracy: 0.8201\n","{'loss': [0.18450987339019775, 0.16546529531478882, 0.1749889850616455, 0.14995799958705902, 0.13903263211250305, 0.14539912343025208, 0.14939314126968384, 0.14173291623592377, 0.14792469143867493, 0.1350354701280594, 0.16311591863632202, 0.13563624024391174, 0.12987321615219116, 0.12400121241807938, 0.13713586330413818, 0.16216455399990082, 0.14255701005458832, 0.12404338270425797, 0.12453430145978928, 0.12170509994029999, 0.11598889529705048, 0.1207183450460434, 0.1158522218465805, 0.11291610449552536, 0.1154753565788269, 0.11186326295137405, 0.11486289650201797, 0.11203855276107788, 0.11346504092216492, 0.10777439922094345, 0.11201324313879013, 0.12780293822288513, 0.11521965265274048, 0.10323900729417801, 0.09860522300004959, 0.0994097962975502, 0.09632086753845215, 0.09769503027200699, 0.09483007341623306, 0.09570092707872391, 0.09262712299823761, 0.09603071212768555, 0.0975361242890358, 0.08898351341485977, 0.09382539242506027, 0.09056076407432556, 0.08897868543863297, 0.09795957803726196, 0.09460315853357315, 0.09912806004285812, 0.09030638635158539, 0.08613623678684235, 0.08079087734222412, 0.08385537564754486, 0.07502187043428421, 0.08237088471651077, 0.08335962891578674, 0.0871446505188942, 0.0808386504650116, 0.07254597544670105, 0.07893924415111542, 0.07770442962646484, 0.0803779810667038, 0.07834374904632568, 0.09959138184785843, 0.07545206695795059, 0.07705862820148468, 0.07485336810350418, 0.09858036786317825, 0.10846468806266785, 0.08014605194330215, 0.07410707324743271, 0.06515688449144363, 0.08731091022491455, 0.0641166940331459, 0.07088387757539749, 0.06693331897258759, 0.12004920840263367, 0.08630091696977615, 0.07065422832965851, 0.06482772529125214, 0.061300016939640045, 0.05732527747750282, 0.05885205790400505, 0.05790496990084648, 0.0745888277888298, 0.06326738744974136, 0.05828244984149933, 0.05477369576692581, 0.056731924414634705, 0.05642079561948776, 0.058803703635931015, 0.05636436119675636, 0.05721679702401161, 0.06003711745142937, 0.06189539656043053, 0.057064030319452286, 0.058939769864082336, 0.058934710919857025, 0.06391096115112305], 'accuracy': [0.9330297112464905, 0.943744957447052, 0.9346370100975037, 0.9509777426719666, 0.9544602036476135, 0.9517813920974731, 0.9485668540000916, 0.9512456655502319, 0.9456201195716858, 0.9560675024986267, 0.9391909837722778, 0.9549959897994995, 0.9549959897994995, 0.9614251255989075, 0.9531208276748657, 0.9383873343467712, 0.9491025805473328, 0.9595499634742737, 0.9611572623252869, 0.9622287750244141, 0.9608893394470215, 0.9598178267478943, 0.9643718004226685, 0.9665148854255676, 0.9619609117507935, 0.9649075865745544, 0.9641039371490479, 0.965175449848175, 0.965175449848175, 0.9667827486991882, 0.9649075865745544, 0.9574069380760193, 0.9598178267478943, 0.9699973464012146, 0.9729440212249756, 0.9694615602493286, 0.9713367223739624, 0.9708009362220764, 0.9718725085258484, 0.9710688591003418, 0.9710688591003418, 0.9732118844985962, 0.9689257740974426, 0.9748191833496094, 0.9737476706504822, 0.9740155339241028, 0.9737476706504822, 0.9708009362220764, 0.9708009362220764, 0.9699973464012146, 0.9753549695014954, 0.9769622087478638, 0.978569507598877, 0.97508704662323, 0.9807125926017761, 0.978569507598877, 0.9764264822006226, 0.9734797477722168, 0.9783016443252563, 0.9833913445472717, 0.9772301316261292, 0.978569507598877, 0.9791052937507629, 0.9788373708724976, 0.968122124671936, 0.9799089431762695, 0.9777658581733704, 0.9777658581733704, 0.9683900475502014, 0.9641039371490479, 0.9772301316261292, 0.9788373708724976, 0.9831234812736511, 0.972140371799469, 0.9844629168510437, 0.9809804558753967, 0.9828556180000305, 0.9587463140487671, 0.9724082350730896, 0.9799089431762695, 0.9823198318481445, 0.9858022928237915, 0.9866059422492981, 0.9852665662765503, 0.9847307801246643, 0.9793731570243835, 0.9836592674255371, 0.9852665662765503, 0.9860701560974121, 0.9852665662765503, 0.9852665662765503, 0.9871417284011841, 0.9860701560974121, 0.9858022928237915, 0.9841949939727783, 0.9833913445472717, 0.9849986433982849, 0.9844629168510437, 0.9836592674255371, 0.9831234812736511], 'val_loss': [0.6631971001625061, 0.6583841443061829, 0.6516945362091064, 0.645776629447937, 0.6366182565689087, 0.62664794921875, 0.6136799454689026, 0.6036757826805115, 0.5847389698028564, 0.5649535655975342, 0.5492687225341797, 0.5214714407920837, 0.49631041288375854, 0.46404409408569336, 0.4647368788719177, 0.43824148178100586, 0.3968469202518463, 0.37826505303382874, 0.36995649337768555, 0.37927618622779846, 0.39239707589149475, 0.3712148368358612, 0.3798235058784485, 0.386681467294693, 0.39545413851737976, 0.40310466289520264, 0.41865238547325134, 0.4297431707382202, 0.4555543065071106, 0.43612730503082275, 0.46412667632102966, 0.4506427049636841, 0.45069384574890137, 0.4477664828300476, 0.46755942702293396, 0.46652328968048096, 0.485232949256897, 0.46817171573638916, 0.46213969588279724, 0.47817137837409973, 0.48214495182037354, 0.4867253303527832, 0.48204585909843445, 0.4939104914665222, 0.5005378723144531, 0.49372756481170654, 0.4958663284778595, 0.520965039730072, 0.5695629119873047, 0.49607929587364197, 0.5553827881813049, 0.4988461136817932, 0.504767894744873, 0.5182005763053894, 0.5100401639938354, 0.516395092010498, 0.5482513904571533, 0.5533717274665833, 0.5173012614250183, 0.5299556255340576, 0.5302431583404541, 0.5436086654663086, 0.5627001523971558, 0.5619748830795288, 0.5397798418998718, 0.5472160577774048, 0.5319516062736511, 0.5433316826820374, 0.6286460757255554, 0.5290854573249817, 0.5295076966285706, 0.5527336597442627, 0.544144332408905, 0.5343085527420044, 0.5561714172363281, 0.5655719637870789, 0.5592753291130066, 0.5963401198387146, 0.5632416605949402, 0.550477921962738, 0.6018814444541931, 0.594932496547699, 0.5917297601699829, 0.5988767147064209, 0.5720972418785095, 0.5765233039855957, 0.6039547920227051, 0.5829627513885498, 0.6850482821464539, 0.6837995052337646, 0.6283015012741089, 0.5920000672340393, 0.6080926656723022, 0.7179180979728699, 0.6403490304946899, 0.5993098020553589, 0.6076346635818481, 0.6408268213272095, 0.7461650371551514, 0.7665912508964539], 'val_accuracy': [0.7901498675346375, 0.8137044906616211, 0.8072805404663086, 0.8147751688957214, 0.8126338124275208, 0.8115631937980652, 0.8137044906616211, 0.8115631937980652, 0.8147751688957214, 0.8104925155639648, 0.8051391839981079, 0.8222697973251343, 0.8169164657592773, 0.8233404755592346, 0.8072805404663086, 0.8094218373298645, 0.8329764604568481, 0.840471088886261, 0.8372591137886047, 0.8447537422180176, 0.840471088886261, 0.8426124453544617, 0.8447537422180176, 0.8458244204521179, 0.8576017022132874, 0.8543897271156311, 0.8479657173156738, 0.8479657173156738, 0.8479657173156738, 0.8447537422180176, 0.8522483706474304, 0.8533190488815308, 0.835117757320404, 0.8458244204521179, 0.8436830639839172, 0.8426124453544617, 0.8426124453544617, 0.8458244204521179, 0.8447537422180176, 0.8372591137886047, 0.8501070737838745, 0.8447537422180176, 0.8447537422180176, 0.8383297920227051, 0.8361884355545044, 0.8447537422180176, 0.8468950986862183, 0.8426124453544617, 0.8394004106521606, 0.8458244204521179, 0.8436830639839172, 0.8426124453544617, 0.8447537422180176, 0.8383297920227051, 0.8447537422180176, 0.8447537422180176, 0.8415417671203613, 0.8415417671203613, 0.8415417671203613, 0.840471088886261, 0.8415417671203613, 0.8415417671203613, 0.8340471386909485, 0.8361884355545044, 0.8394004106521606, 0.8426124453544617, 0.8511777520179749, 0.840471088886261, 0.8222697973251343, 0.8458244204521179, 0.8468950986862183, 0.8394004106521606, 0.8436830639839172, 0.8458244204521179, 0.8436830639839172, 0.8447537422180176, 0.8426124453544617, 0.8319057822227478, 0.8361884355545044, 0.840471088886261, 0.8383297920227051, 0.8426124453544617, 0.8361884355545044, 0.8383297920227051, 0.8415417671203613, 0.8447537422180176, 0.8361884355545044, 0.8458244204521179, 0.8286938071250916, 0.8308351039886475, 0.8372591137886047, 0.8426124453544617, 0.8394004106521606, 0.8308351039886475, 0.8372591137886047, 0.8383297920227051, 0.8415417671203613, 0.8383297920227051, 0.8308351039886475, 0.8201285004615784]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 55ms/step - loss: 0.1837 - accuracy: 0.9346 - val_loss: 0.6631 - val_accuracy: 0.7441\n","Epoch 2/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1768 - accuracy: 0.9365 - val_loss: 0.6581 - val_accuracy: 0.7859\n","Epoch 3/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1682 - accuracy: 0.9397 - val_loss: 0.6493 - val_accuracy: 0.8169\n","Epoch 4/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1671 - accuracy: 0.9411 - val_loss: 0.6446 - val_accuracy: 0.7987\n","Epoch 5/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1520 - accuracy: 0.9464 - val_loss: 0.6341 - val_accuracy: 0.8362\n","Epoch 6/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1537 - accuracy: 0.9456 - val_loss: 0.6249 - val_accuracy: 0.8276\n","Epoch 7/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1414 - accuracy: 0.9531 - val_loss: 0.6105 - val_accuracy: 0.8458\n","Epoch 8/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1484 - accuracy: 0.9478 - val_loss: 0.5959 - val_accuracy: 0.8394\n","Epoch 9/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1525 - accuracy: 0.9464 - val_loss: 0.5792 - val_accuracy: 0.8469\n","Epoch 10/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1624 - accuracy: 0.9435 - val_loss: 0.5582 - val_accuracy: 0.8394\n","Epoch 11/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1377 - accuracy: 0.9537 - val_loss: 0.5349 - val_accuracy: 0.8223\n","Epoch 12/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1404 - accuracy: 0.9518 - val_loss: 0.5077 - val_accuracy: 0.8469\n","Epoch 13/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1442 - accuracy: 0.9488 - val_loss: 0.4830 - val_accuracy: 0.8490\n","Epoch 14/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1438 - accuracy: 0.9470 - val_loss: 0.4409 - val_accuracy: 0.8437\n","Epoch 15/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1338 - accuracy: 0.9547 - val_loss: 0.4100 - val_accuracy: 0.8640\n","Epoch 16/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1254 - accuracy: 0.9569 - val_loss: 0.3822 - val_accuracy: 0.8308\n","Epoch 17/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1651 - accuracy: 0.9370 - val_loss: 0.3485 - val_accuracy: 0.8683\n","Epoch 18/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.1263 - accuracy: 0.9595 - val_loss: 0.3354 - val_accuracy: 0.8715\n","Epoch 19/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1266 - accuracy: 0.9598 - val_loss: 0.3099 - val_accuracy: 0.8683\n","Epoch 20/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1253 - accuracy: 0.9579 - val_loss: 0.2986 - val_accuracy: 0.8779\n","Epoch 21/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1175 - accuracy: 0.9628 - val_loss: 0.3086 - val_accuracy: 0.8737\n","Epoch 22/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1274 - accuracy: 0.9585 - val_loss: 0.3016 - val_accuracy: 0.8651\n","Epoch 23/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1282 - accuracy: 0.9579 - val_loss: 0.2811 - val_accuracy: 0.8897\n","Epoch 24/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1206 - accuracy: 0.9585 - val_loss: 0.2869 - val_accuracy: 0.8801\n","Epoch 25/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1095 - accuracy: 0.9646 - val_loss: 0.2823 - val_accuracy: 0.8865\n","Epoch 26/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1077 - accuracy: 0.9646 - val_loss: 0.2935 - val_accuracy: 0.8833\n","Epoch 27/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1125 - accuracy: 0.9636 - val_loss: 0.3058 - val_accuracy: 0.8779\n","Epoch 28/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1116 - accuracy: 0.9625 - val_loss: 0.2938 - val_accuracy: 0.8812\n","Epoch 29/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1273 - accuracy: 0.9558 - val_loss: 0.3154 - val_accuracy: 0.8822\n","Epoch 30/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1325 - accuracy: 0.9537 - val_loss: 0.2958 - val_accuracy: 0.8865\n","Epoch 31/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1018 - accuracy: 0.9671 - val_loss: 0.3042 - val_accuracy: 0.8844\n","Epoch 32/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1083 - accuracy: 0.9649 - val_loss: 0.3078 - val_accuracy: 0.8833\n","Epoch 33/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1103 - accuracy: 0.9657 - val_loss: 0.3120 - val_accuracy: 0.8876\n","Epoch 34/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1054 - accuracy: 0.9671 - val_loss: 0.3111 - val_accuracy: 0.8897\n","Epoch 35/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1085 - accuracy: 0.9654 - val_loss: 0.3156 - val_accuracy: 0.8812\n","Epoch 36/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1083 - accuracy: 0.9644 - val_loss: 0.3166 - val_accuracy: 0.8908\n","Epoch 37/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1054 - accuracy: 0.9620 - val_loss: 0.3116 - val_accuracy: 0.8854\n","Epoch 38/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1078 - accuracy: 0.9671 - val_loss: 0.3151 - val_accuracy: 0.8865\n","Epoch 39/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0999 - accuracy: 0.9695 - val_loss: 0.3437 - val_accuracy: 0.8737\n","Epoch 40/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0999 - accuracy: 0.9695 - val_loss: 0.3237 - val_accuracy: 0.8790\n","Epoch 41/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0959 - accuracy: 0.9721 - val_loss: 0.3256 - val_accuracy: 0.8929\n","Epoch 42/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0921 - accuracy: 0.9735 - val_loss: 0.3278 - val_accuracy: 0.8854\n","Epoch 43/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0893 - accuracy: 0.9735 - val_loss: 0.3375 - val_accuracy: 0.8919\n","Epoch 44/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1098 - accuracy: 0.9638 - val_loss: 0.3674 - val_accuracy: 0.8801\n","Epoch 45/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0974 - accuracy: 0.9695 - val_loss: 0.3318 - val_accuracy: 0.8822\n","Epoch 46/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0854 - accuracy: 0.9756 - val_loss: 0.3389 - val_accuracy: 0.8897\n","Epoch 47/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0861 - accuracy: 0.9735 - val_loss: 0.3633 - val_accuracy: 0.8812\n","Epoch 48/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0974 - accuracy: 0.9697 - val_loss: 0.3396 - val_accuracy: 0.8897\n","Epoch 49/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0824 - accuracy: 0.9791 - val_loss: 0.3524 - val_accuracy: 0.8908\n","Epoch 50/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0883 - accuracy: 0.9748 - val_loss: 0.3481 - val_accuracy: 0.8929\n","Epoch 51/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0894 - accuracy: 0.9746 - val_loss: 0.3745 - val_accuracy: 0.8747\n","Epoch 52/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1142 - accuracy: 0.9606 - val_loss: 0.3455 - val_accuracy: 0.8854\n","Epoch 53/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0854 - accuracy: 0.9748 - val_loss: 0.3399 - val_accuracy: 0.8854\n","Epoch 54/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0897 - accuracy: 0.9727 - val_loss: 0.3445 - val_accuracy: 0.8844\n","Epoch 55/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0774 - accuracy: 0.9780 - val_loss: 0.3457 - val_accuracy: 0.8801\n","Epoch 56/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0782 - accuracy: 0.9764 - val_loss: 0.3608 - val_accuracy: 0.8865\n","Epoch 57/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0814 - accuracy: 0.9767 - val_loss: 0.3575 - val_accuracy: 0.8897\n","Epoch 58/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0796 - accuracy: 0.9767 - val_loss: 0.3850 - val_accuracy: 0.8812\n","Epoch 59/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0796 - accuracy: 0.9764 - val_loss: 0.3560 - val_accuracy: 0.8801\n","Epoch 60/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0777 - accuracy: 0.9778 - val_loss: 0.3663 - val_accuracy: 0.8865\n","Epoch 61/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0739 - accuracy: 0.9794 - val_loss: 0.3871 - val_accuracy: 0.8865\n","Epoch 62/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0863 - accuracy: 0.9746 - val_loss: 0.3772 - val_accuracy: 0.8726\n","Epoch 63/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0878 - accuracy: 0.9719 - val_loss: 0.3676 - val_accuracy: 0.8865\n","Epoch 64/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0831 - accuracy: 0.9735 - val_loss: 0.3635 - val_accuracy: 0.8790\n","Epoch 65/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0752 - accuracy: 0.9775 - val_loss: 0.3571 - val_accuracy: 0.8833\n","Epoch 66/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.0690 - accuracy: 0.9818 - val_loss: 0.3624 - val_accuracy: 0.8854\n","Epoch 67/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0722 - accuracy: 0.9804 - val_loss: 0.4080 - val_accuracy: 0.8790\n","Epoch 68/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0727 - accuracy: 0.9786 - val_loss: 0.4132 - val_accuracy: 0.8769\n","Epoch 69/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0712 - accuracy: 0.9804 - val_loss: 0.3635 - val_accuracy: 0.8833\n","Epoch 70/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0704 - accuracy: 0.9796 - val_loss: 0.3697 - val_accuracy: 0.8822\n","Epoch 71/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0722 - accuracy: 0.9799 - val_loss: 0.4091 - val_accuracy: 0.8779\n","Epoch 72/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0838 - accuracy: 0.9740 - val_loss: 0.3689 - val_accuracy: 0.8876\n","Epoch 73/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0713 - accuracy: 0.9796 - val_loss: 0.3787 - val_accuracy: 0.8865\n","Epoch 74/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0706 - accuracy: 0.9794 - val_loss: 0.4631 - val_accuracy: 0.8694\n","Epoch 75/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0694 - accuracy: 0.9794 - val_loss: 0.3781 - val_accuracy: 0.8833\n","Epoch 76/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0707 - accuracy: 0.9804 - val_loss: 0.3975 - val_accuracy: 0.8737\n","Epoch 77/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0684 - accuracy: 0.9799 - val_loss: 0.3759 - val_accuracy: 0.8779\n","Epoch 78/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0678 - accuracy: 0.9802 - val_loss: 0.3755 - val_accuracy: 0.8822\n","Epoch 79/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0723 - accuracy: 0.9783 - val_loss: 0.4070 - val_accuracy: 0.8876\n","Epoch 80/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0647 - accuracy: 0.9823 - val_loss: 0.3797 - val_accuracy: 0.8769\n","Epoch 81/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0634 - accuracy: 0.9821 - val_loss: 0.3831 - val_accuracy: 0.8854\n","Epoch 82/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0556 - accuracy: 0.9871 - val_loss: 0.3897 - val_accuracy: 0.8844\n","Epoch 83/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0614 - accuracy: 0.9861 - val_loss: 0.3881 - val_accuracy: 0.8747\n","Epoch 84/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0652 - accuracy: 0.9823 - val_loss: 0.3900 - val_accuracy: 0.8854\n","Epoch 85/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0562 - accuracy: 0.9853 - val_loss: 0.3886 - val_accuracy: 0.8801\n","Epoch 86/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0541 - accuracy: 0.9874 - val_loss: 0.4299 - val_accuracy: 0.8812\n","Epoch 87/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0617 - accuracy: 0.9823 - val_loss: 0.4419 - val_accuracy: 0.8737\n","Epoch 88/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0606 - accuracy: 0.9834 - val_loss: 0.4285 - val_accuracy: 0.8844\n","Epoch 89/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0556 - accuracy: 0.9866 - val_loss: 0.4222 - val_accuracy: 0.8694\n","Epoch 90/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0907 - accuracy: 0.9705 - val_loss: 0.4825 - val_accuracy: 0.8640\n","Epoch 91/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0719 - accuracy: 0.9772 - val_loss: 0.3923 - val_accuracy: 0.8801\n","Epoch 92/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0593 - accuracy: 0.9842 - val_loss: 0.4008 - val_accuracy: 0.8854\n","Epoch 93/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0529 - accuracy: 0.9863 - val_loss: 0.4323 - val_accuracy: 0.8812\n","Epoch 94/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0481 - accuracy: 0.9890 - val_loss: 0.4119 - val_accuracy: 0.8876\n","Epoch 95/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0496 - accuracy: 0.9890 - val_loss: 0.4098 - val_accuracy: 0.8854\n","Epoch 96/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0555 - accuracy: 0.9847 - val_loss: 0.4698 - val_accuracy: 0.8737\n","Epoch 97/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0586 - accuracy: 0.9837 - val_loss: 0.4070 - val_accuracy: 0.8790\n","Epoch 98/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0483 - accuracy: 0.9893 - val_loss: 0.4719 - val_accuracy: 0.8779\n","Epoch 99/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0652 - accuracy: 0.9815 - val_loss: 0.4182 - val_accuracy: 0.8876\n","Epoch 100/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0492 - accuracy: 0.9898 - val_loss: 0.4364 - val_accuracy: 0.8833\n","{'loss': [0.183749720454216, 0.17681141197681427, 0.1682358831167221, 0.16708484292030334, 0.1519988626241684, 0.1537410467863083, 0.14137287437915802, 0.14843802154064178, 0.15247920155525208, 0.1624334156513214, 0.1377030909061432, 0.14036060869693756, 0.14422477781772614, 0.1437789648771286, 0.1337982565164566, 0.1253693401813507, 0.16508851945400238, 0.12626901268959045, 0.1266387701034546, 0.125348761677742, 0.1175338625907898, 0.12744885683059692, 0.12823492288589478, 0.12055860459804535, 0.109490767121315, 0.1077367439866066, 0.11245813965797424, 0.11162378638982773, 0.1273331493139267, 0.13251972198486328, 0.10183238238096237, 0.10833695530891418, 0.11030592769384384, 0.10539231449365616, 0.10848931968212128, 0.10830678045749664, 0.10542580485343933, 0.10776834189891815, 0.09987477958202362, 0.09991665929555893, 0.09587278962135315, 0.09213589876890182, 0.08927842229604721, 0.10984119772911072, 0.09743192046880722, 0.08539708703756332, 0.08611754328012466, 0.09737373888492584, 0.08236125856637955, 0.08829855918884277, 0.08941779285669327, 0.11422602832317352, 0.08544357866048813, 0.08968912065029144, 0.07741443067789078, 0.07824350148439407, 0.08138509094715118, 0.07956848293542862, 0.07958303391933441, 0.07768835127353668, 0.07388030737638474, 0.08628527075052261, 0.08780543506145477, 0.0830751359462738, 0.07515405118465424, 0.0689777210354805, 0.0722464770078659, 0.07271982729434967, 0.0712345540523529, 0.07036829739809036, 0.07223808020353317, 0.08380559086799622, 0.07134901732206345, 0.07064805179834366, 0.06943172961473465, 0.07068460434675217, 0.06844274699687958, 0.06784822046756744, 0.07227293401956558, 0.06468698382377625, 0.06339698284864426, 0.05562802776694298, 0.061372872442007065, 0.06522925198078156, 0.05618002638220787, 0.054148297756910324, 0.06168251112103462, 0.060568589717149734, 0.05562477558851242, 0.09071889519691467, 0.0719163715839386, 0.05934099853038788, 0.05286622792482376, 0.04811101034283638, 0.04957014322280884, 0.055460795760154724, 0.05864670127630234, 0.048256997019052505, 0.06522111594676971, 0.04920501261949539], 'accuracy': [0.9346370100975037, 0.9365121722221375, 0.9397267699241638, 0.9410661458969116, 0.9464237689971924, 0.9456201195716858, 0.9531208276748657, 0.947763204574585, 0.9464237689971924, 0.9434770941734314, 0.9536565542221069, 0.9517813920974731, 0.9488347172737122, 0.9469595551490784, 0.9547281265258789, 0.9568711519241333, 0.9370479583740234, 0.9595499634742737, 0.9598178267478943, 0.9579426646232605, 0.9627645611763, 0.9584784507751465, 0.9579426646232605, 0.9584784507751465, 0.9646397233009338, 0.9646397233009338, 0.9635681509971619, 0.9624966382980347, 0.9557996392250061, 0.9536565542221069, 0.9670506119728088, 0.9649075865745544, 0.965711236000061, 0.9670506119728088, 0.9654433727264404, 0.9643718004226685, 0.9619609117507935, 0.9670506119728088, 0.9694615602493286, 0.9694615602493286, 0.972140371799469, 0.9734797477722168, 0.9734797477722168, 0.9638360738754272, 0.9694615602493286, 0.975622832775116, 0.9734797477722168, 0.9697294235229492, 0.9791052937507629, 0.9748191833496094, 0.9745513200759888, 0.9606214761734009, 0.9748191833496094, 0.972676157951355, 0.9780337810516357, 0.9764264822006226, 0.9766943454742432, 0.9766943454742432, 0.9764264822006226, 0.9777658581733704, 0.9793731570243835, 0.9745513200759888, 0.9718725085258484, 0.9734797477722168, 0.9774979948997498, 0.9817841053009033, 0.9804446697235107, 0.978569507598877, 0.9804446697235107, 0.9796410202980042, 0.9799089431762695, 0.9740155339241028, 0.9796410202980042, 0.9793731570243835, 0.9793731570243835, 0.9804446697235107, 0.9799089431762695, 0.9801768064498901, 0.9783016443252563, 0.9823198318481445, 0.9820519685745239, 0.9871417284011841, 0.9860701560974121, 0.9823198318481445, 0.9852665662765503, 0.9874095916748047, 0.9823198318481445, 0.9833913445472717, 0.9866059422492981, 0.9705330729484558, 0.9772301316261292, 0.9841949939727783, 0.9863380789756775, 0.9890168905258179, 0.9890168905258179, 0.9847307801246643, 0.9836592674255371, 0.9892847537994385, 0.9815161824226379, 0.9898205399513245], 'val_loss': [0.6630986928939819, 0.6581323146820068, 0.6492765545845032, 0.6445565223693848, 0.6341450214385986, 0.6248903274536133, 0.6104576587677002, 0.5959041118621826, 0.5792173147201538, 0.558204174041748, 0.5349072217941284, 0.50773024559021, 0.4829869866371155, 0.44093552231788635, 0.4100036919116974, 0.38220879435539246, 0.3485242426395416, 0.33535197377204895, 0.3098759055137634, 0.2986024022102356, 0.30861082673072815, 0.3016156852245331, 0.2811390459537506, 0.28690460324287415, 0.2822703421115875, 0.2935134172439575, 0.3057674467563629, 0.2938450276851654, 0.3154495060443878, 0.29583027958869934, 0.3042219281196594, 0.3078136444091797, 0.31198424100875854, 0.31111735105514526, 0.315594345331192, 0.3166205585002899, 0.3115522265434265, 0.3150833547115326, 0.3436906635761261, 0.3236633539199829, 0.32560354471206665, 0.3277866244316101, 0.3374897241592407, 0.36741605401039124, 0.33181291818618774, 0.33887526392936707, 0.3632742166519165, 0.3395930230617523, 0.35240986943244934, 0.3480587899684906, 0.37449297308921814, 0.3455091118812561, 0.3398677706718445, 0.3445037603378296, 0.3457441031932831, 0.360796719789505, 0.35752028226852417, 0.38500604033470154, 0.355986088514328, 0.36634311079978943, 0.38709625601768494, 0.37723466753959656, 0.367642343044281, 0.36353009939193726, 0.35711878538131714, 0.3623883128166199, 0.40795522928237915, 0.4132448732852936, 0.3635265529155731, 0.36967363953590393, 0.4090770184993744, 0.3688862919807434, 0.37870973348617554, 0.4630536437034607, 0.37805381417274475, 0.3975473940372467, 0.3758604824542999, 0.3754573166370392, 0.40702351927757263, 0.3796956241130829, 0.3831240236759186, 0.38969388604164124, 0.38807201385498047, 0.39004942774772644, 0.38864338397979736, 0.4298998713493347, 0.44194942712783813, 0.42851293087005615, 0.42215707898139954, 0.4825373888015747, 0.3923269510269165, 0.4007534682750702, 0.43230706453323364, 0.41186368465423584, 0.40976929664611816, 0.4697502553462982, 0.4070180654525757, 0.4718901216983795, 0.4182094633579254, 0.4364250600337982], 'val_accuracy': [0.7441113591194153, 0.7858672142028809, 0.8169164657592773, 0.7987151741981506, 0.8361884355545044, 0.8276231288909912, 0.8458244204521179, 0.8394004106521606, 0.8468950986862183, 0.8394004106521606, 0.8222697973251343, 0.8468950986862183, 0.8490363955497742, 0.8436830639839172, 0.8640257120132446, 0.8308351039886475, 0.8683083653450012, 0.8715203404426575, 0.8683083653450012, 0.8779443502426147, 0.8736616969108582, 0.8650963306427002, 0.8897216320037842, 0.8800856471061707, 0.8865096569061279, 0.8832976222038269, 0.8779443502426147, 0.881156325340271, 0.8822270035743713, 0.8865096569061279, 0.8843683004379272, 0.8832976222038269, 0.8875802755355835, 0.8897216320037842, 0.881156325340271, 0.8907923102378845, 0.8854389786720276, 0.8865096569061279, 0.8736616969108582, 0.8790149688720703, 0.8929336071014404, 0.8854389786720276, 0.8918629288673401, 0.8800856471061707, 0.8822270035743713, 0.8897216320037842, 0.881156325340271, 0.8897216320037842, 0.8907923102378845, 0.8929336071014404, 0.8747323155403137, 0.8854389786720276, 0.8854389786720276, 0.8843683004379272, 0.8800856471061707, 0.8865096569061279, 0.8897216320037842, 0.881156325340271, 0.8800856471061707, 0.8865096569061279, 0.8865096569061279, 0.8725910186767578, 0.8865096569061279, 0.8790149688720703, 0.8832976222038269, 0.8854389786720276, 0.8790149688720703, 0.8768736720085144, 0.8832976222038269, 0.8822270035743713, 0.8779443502426147, 0.8875802755355835, 0.8865096569061279, 0.8693790435791016, 0.8832976222038269, 0.8736616969108582, 0.8779443502426147, 0.8822270035743713, 0.8875802755355835, 0.8768736720085144, 0.8854389786720276, 0.8843683004379272, 0.8747323155403137, 0.8854389786720276, 0.8800856471061707, 0.881156325340271, 0.8736616969108582, 0.8843683004379272, 0.8693790435791016, 0.8640257120132446, 0.8800856471061707, 0.8854389786720276, 0.881156325340271, 0.8875802755355835, 0.8854389786720276, 0.8736616969108582, 0.8790149688720703, 0.8779443502426147, 0.8875802755355835, 0.8832976222038269]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 10s 53ms/step - loss: 0.2034 - accuracy: 0.9258 - val_loss: 0.6619 - val_accuracy: 0.7944\n","Epoch 2/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1777 - accuracy: 0.9349 - val_loss: 0.6578 - val_accuracy: 0.8041\n","Epoch 3/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1583 - accuracy: 0.9429 - val_loss: 0.6516 - val_accuracy: 0.8009\n","Epoch 4/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1616 - accuracy: 0.9432 - val_loss: 0.6436 - val_accuracy: 0.8212\n","Epoch 5/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1663 - accuracy: 0.9341 - val_loss: 0.6361 - val_accuracy: 0.8233\n","Epoch 6/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1476 - accuracy: 0.9451 - val_loss: 0.6266 - val_accuracy: 0.8158\n","Epoch 7/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1423 - accuracy: 0.9480 - val_loss: 0.6128 - val_accuracy: 0.8201\n","Epoch 8/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1421 - accuracy: 0.9507 - val_loss: 0.5972 - val_accuracy: 0.8212\n","Epoch 9/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1435 - accuracy: 0.9512 - val_loss: 0.5788 - val_accuracy: 0.8255\n","Epoch 10/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1457 - accuracy: 0.9488 - val_loss: 0.5612 - val_accuracy: 0.8223\n","Epoch 11/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1445 - accuracy: 0.9510 - val_loss: 0.5399 - val_accuracy: 0.8287\n","Epoch 12/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1365 - accuracy: 0.9542 - val_loss: 0.5164 - val_accuracy: 0.8266\n","Epoch 13/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1349 - accuracy: 0.9539 - val_loss: 0.4822 - val_accuracy: 0.8308\n","Epoch 14/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1363 - accuracy: 0.9523 - val_loss: 0.4590 - val_accuracy: 0.8383\n","Epoch 15/100\n","30/30 [==============================] - 1s 31ms/step - loss: 0.1357 - accuracy: 0.9545 - val_loss: 0.4196 - val_accuracy: 0.8448\n","Epoch 16/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1287 - accuracy: 0.9571 - val_loss: 0.3891 - val_accuracy: 0.8458\n","Epoch 17/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.1369 - accuracy: 0.9515 - val_loss: 0.3646 - val_accuracy: 0.8373\n","Epoch 18/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.1320 - accuracy: 0.9515 - val_loss: 0.3494 - val_accuracy: 0.8576\n","Epoch 19/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1245 - accuracy: 0.9566 - val_loss: 0.3392 - val_accuracy: 0.8587\n","Epoch 20/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1260 - accuracy: 0.9571 - val_loss: 0.3262 - val_accuracy: 0.8597\n","Epoch 21/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1226 - accuracy: 0.9555 - val_loss: 0.3170 - val_accuracy: 0.8630\n","Epoch 22/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1284 - accuracy: 0.9526 - val_loss: 0.3503 - val_accuracy: 0.8565\n","Epoch 23/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1195 - accuracy: 0.9622 - val_loss: 0.3158 - val_accuracy: 0.8715\n","Epoch 24/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1179 - accuracy: 0.9577 - val_loss: 0.3040 - val_accuracy: 0.8812\n","Epoch 25/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1298 - accuracy: 0.9542 - val_loss: 0.3687 - val_accuracy: 0.8651\n","Epoch 26/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1251 - accuracy: 0.9561 - val_loss: 0.3332 - val_accuracy: 0.8812\n","Epoch 27/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1128 - accuracy: 0.9628 - val_loss: 0.3243 - val_accuracy: 0.8801\n","Epoch 28/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1081 - accuracy: 0.9649 - val_loss: 0.3254 - val_accuracy: 0.8801\n","Epoch 29/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1144 - accuracy: 0.9593 - val_loss: 0.3260 - val_accuracy: 0.8790\n","Epoch 30/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1106 - accuracy: 0.9617 - val_loss: 0.3344 - val_accuracy: 0.8779\n","Epoch 31/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1047 - accuracy: 0.9673 - val_loss: 0.3391 - val_accuracy: 0.8790\n","Epoch 32/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1091 - accuracy: 0.9668 - val_loss: 0.3437 - val_accuracy: 0.8865\n","Epoch 33/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1093 - accuracy: 0.9620 - val_loss: 0.4019 - val_accuracy: 0.8694\n","Epoch 34/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1007 - accuracy: 0.9689 - val_loss: 0.3606 - val_accuracy: 0.8790\n","Epoch 35/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1127 - accuracy: 0.9614 - val_loss: 0.3595 - val_accuracy: 0.8737\n","Epoch 36/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1003 - accuracy: 0.9689 - val_loss: 0.3523 - val_accuracy: 0.8801\n","Epoch 37/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1010 - accuracy: 0.9684 - val_loss: 0.3668 - val_accuracy: 0.8758\n","Epoch 38/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.1072 - accuracy: 0.9628 - val_loss: 0.3590 - val_accuracy: 0.8822\n","Epoch 39/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0992 - accuracy: 0.9676 - val_loss: 0.3658 - val_accuracy: 0.8747\n","Epoch 40/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0978 - accuracy: 0.9711 - val_loss: 0.3882 - val_accuracy: 0.8672\n","Epoch 41/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0969 - accuracy: 0.9697 - val_loss: 0.3625 - val_accuracy: 0.8769\n","Epoch 42/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0967 - accuracy: 0.9687 - val_loss: 0.3668 - val_accuracy: 0.8769\n","Epoch 43/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0943 - accuracy: 0.9703 - val_loss: 0.3848 - val_accuracy: 0.8715\n","Epoch 44/100\n","30/30 [==============================] - 1s 31ms/step - loss: 0.0958 - accuracy: 0.9700 - val_loss: 0.3838 - val_accuracy: 0.8769\n","Epoch 45/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0914 - accuracy: 0.9708 - val_loss: 0.3755 - val_accuracy: 0.8790\n","Epoch 46/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0928 - accuracy: 0.9673 - val_loss: 0.3777 - val_accuracy: 0.8812\n","Epoch 47/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0878 - accuracy: 0.9751 - val_loss: 0.3805 - val_accuracy: 0.8833\n","Epoch 48/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0824 - accuracy: 0.9751 - val_loss: 0.3787 - val_accuracy: 0.8812\n","Epoch 49/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0818 - accuracy: 0.9732 - val_loss: 0.3988 - val_accuracy: 0.8715\n","Epoch 50/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1080 - accuracy: 0.9638 - val_loss: 0.3796 - val_accuracy: 0.8769\n","Epoch 51/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0890 - accuracy: 0.9721 - val_loss: 0.4047 - val_accuracy: 0.8662\n","Epoch 52/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0814 - accuracy: 0.9754 - val_loss: 0.3900 - val_accuracy: 0.8779\n","Epoch 53/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0783 - accuracy: 0.9786 - val_loss: 0.4116 - val_accuracy: 0.8726\n","Epoch 54/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0818 - accuracy: 0.9764 - val_loss: 0.4169 - val_accuracy: 0.8758\n","Epoch 55/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0876 - accuracy: 0.9711 - val_loss: 0.3963 - val_accuracy: 0.8747\n","Epoch 56/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0768 - accuracy: 0.9775 - val_loss: 0.4199 - val_accuracy: 0.8672\n","Epoch 57/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0918 - accuracy: 0.9724 - val_loss: 0.3933 - val_accuracy: 0.8779\n","Epoch 58/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0714 - accuracy: 0.9815 - val_loss: 0.4038 - val_accuracy: 0.8758\n","Epoch 59/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0817 - accuracy: 0.9729 - val_loss: 0.4178 - val_accuracy: 0.8747\n","Epoch 60/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0670 - accuracy: 0.9815 - val_loss: 0.4083 - val_accuracy: 0.8769\n","Epoch 61/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0917 - accuracy: 0.9700 - val_loss: 0.5700 - val_accuracy: 0.8405\n","Epoch 62/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0853 - accuracy: 0.9700 - val_loss: 0.4105 - val_accuracy: 0.8779\n","Epoch 63/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0702 - accuracy: 0.9791 - val_loss: 0.4227 - val_accuracy: 0.8715\n","Epoch 64/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0751 - accuracy: 0.9762 - val_loss: 0.4108 - val_accuracy: 0.8747\n","Epoch 65/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0692 - accuracy: 0.9818 - val_loss: 0.4219 - val_accuracy: 0.8758\n","Epoch 66/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0689 - accuracy: 0.9815 - val_loss: 0.4109 - val_accuracy: 0.8801\n","Epoch 67/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0688 - accuracy: 0.9794 - val_loss: 0.4195 - val_accuracy: 0.8747\n","Epoch 68/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0721 - accuracy: 0.9786 - val_loss: 0.4576 - val_accuracy: 0.8694\n","Epoch 69/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0741 - accuracy: 0.9775 - val_loss: 0.4193 - val_accuracy: 0.8779\n","Epoch 70/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0637 - accuracy: 0.9812 - val_loss: 0.4288 - val_accuracy: 0.8769\n","Epoch 71/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0648 - accuracy: 0.9829 - val_loss: 0.4206 - val_accuracy: 0.8726\n","Epoch 72/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0649 - accuracy: 0.9837 - val_loss: 0.4619 - val_accuracy: 0.8672\n","Epoch 73/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0710 - accuracy: 0.9802 - val_loss: 0.4255 - val_accuracy: 0.8769\n","Epoch 74/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0685 - accuracy: 0.9802 - val_loss: 0.4379 - val_accuracy: 0.8726\n","Epoch 75/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0844 - accuracy: 0.9721 - val_loss: 0.4429 - val_accuracy: 0.8715\n","Epoch 76/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0679 - accuracy: 0.9791 - val_loss: 0.4421 - val_accuracy: 0.8704\n","Epoch 77/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0697 - accuracy: 0.9778 - val_loss: 0.4448 - val_accuracy: 0.8704\n","Epoch 78/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0575 - accuracy: 0.9861 - val_loss: 0.4519 - val_accuracy: 0.8683\n","Epoch 79/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0532 - accuracy: 0.9869 - val_loss: 0.4383 - val_accuracy: 0.8715\n","Epoch 80/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0655 - accuracy: 0.9791 - val_loss: 0.5024 - val_accuracy: 0.8597\n","Epoch 81/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0661 - accuracy: 0.9796 - val_loss: 0.4591 - val_accuracy: 0.8737\n","Epoch 82/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0571 - accuracy: 0.9829 - val_loss: 0.4493 - val_accuracy: 0.8758\n","Epoch 83/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0565 - accuracy: 0.9850 - val_loss: 0.4749 - val_accuracy: 0.8651\n","Epoch 84/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0667 - accuracy: 0.9810 - val_loss: 0.4553 - val_accuracy: 0.8769\n","Epoch 85/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0520 - accuracy: 0.9869 - val_loss: 0.4544 - val_accuracy: 0.8704\n","Epoch 86/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0530 - accuracy: 0.9853 - val_loss: 0.4551 - val_accuracy: 0.8758\n","Epoch 87/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0667 - accuracy: 0.9775 - val_loss: 0.4548 - val_accuracy: 0.8737\n","Epoch 88/100\n","30/30 [==============================] - 1s 31ms/step - loss: 0.0572 - accuracy: 0.9855 - val_loss: 0.4444 - val_accuracy: 0.8747\n","Epoch 89/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0479 - accuracy: 0.9898 - val_loss: 0.4572 - val_accuracy: 0.8737\n","Epoch 90/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0520 - accuracy: 0.9879 - val_loss: 0.4576 - val_accuracy: 0.8747\n","Epoch 91/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0652 - accuracy: 0.9775 - val_loss: 0.4702 - val_accuracy: 0.8662\n","Epoch 92/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0525 - accuracy: 0.9866 - val_loss: 0.4570 - val_accuracy: 0.8790\n","Epoch 93/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0520 - accuracy: 0.9871 - val_loss: 0.4643 - val_accuracy: 0.8758\n","Epoch 94/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0492 - accuracy: 0.9855 - val_loss: 0.4959 - val_accuracy: 0.8651\n","Epoch 95/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0470 - accuracy: 0.9871 - val_loss: 0.4817 - val_accuracy: 0.8694\n","Epoch 96/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0480 - accuracy: 0.9855 - val_loss: 0.4807 - val_accuracy: 0.8715\n","Epoch 97/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0447 - accuracy: 0.9877 - val_loss: 0.4827 - val_accuracy: 0.8715\n","Epoch 98/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0447 - accuracy: 0.9890 - val_loss: 0.4867 - val_accuracy: 0.8662\n","Epoch 99/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0537 - accuracy: 0.9842 - val_loss: 0.5268 - val_accuracy: 0.8544\n","Epoch 100/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0696 - accuracy: 0.9770 - val_loss: 0.4923 - val_accuracy: 0.8630\n","{'loss': [0.20341439545154572, 0.17770951986312866, 0.1582697331905365, 0.16159462928771973, 0.16627630591392517, 0.1475919932126999, 0.14233942329883575, 0.14211289584636688, 0.14348909258842468, 0.14574213325977325, 0.1444912850856781, 0.1364782750606537, 0.13487572968006134, 0.13632415235042572, 0.13568894565105438, 0.128662571310997, 0.1368970274925232, 0.13200059533119202, 0.12446577847003937, 0.12601283192634583, 0.12261577695608139, 0.1283644139766693, 0.11949405074119568, 0.11789508908987045, 0.1297609508037567, 0.12514877319335938, 0.11282803863286972, 0.10808790475130081, 0.11440631002187729, 0.11055313050746918, 0.10473577678203583, 0.10905825346708298, 0.10928235203027725, 0.10071074962615967, 0.11266805231571198, 0.10030921548604965, 0.10095743089914322, 0.10715589672327042, 0.0992332473397255, 0.09778479486703873, 0.09692762047052383, 0.09668388217687607, 0.09428655356168747, 0.09583152830600739, 0.09136394411325455, 0.09275394678115845, 0.08782309293746948, 0.08242078125476837, 0.08176751434803009, 0.10803430527448654, 0.08900334686040878, 0.08144587278366089, 0.07826525717973709, 0.08175425231456757, 0.08757235109806061, 0.07678108662366867, 0.09184808284044266, 0.0713915228843689, 0.0816994458436966, 0.06698857247829437, 0.09167134016752243, 0.08526728302240372, 0.07023611664772034, 0.07514280080795288, 0.069155752658844, 0.06892435252666473, 0.06884653121232986, 0.07212129980325699, 0.07408413290977478, 0.06370586156845093, 0.06482494622468948, 0.0648738294839859, 0.07102063298225403, 0.06848260760307312, 0.08437909185886383, 0.0679178237915039, 0.06965503096580505, 0.05753316730260849, 0.053184133023023605, 0.06554180383682251, 0.06607236713171005, 0.05707211419939995, 0.05651864409446716, 0.066733717918396, 0.05198673531413078, 0.05298295617103577, 0.06672240793704987, 0.057203296571969986, 0.04792618751525879, 0.05203510448336601, 0.06523551046848297, 0.052474722266197205, 0.05199720337986946, 0.04915398359298706, 0.047024838626384735, 0.048017825931310654, 0.044687628746032715, 0.04472806677222252, 0.05372489616274834, 0.0696268230676651], 'accuracy': [0.9257969260215759, 0.9349048733711243, 0.9429413080215454, 0.9432092308998108, 0.9341012835502625, 0.9450843930244446, 0.9480310678482056, 0.950709879398346, 0.9512456655502319, 0.9488347172737122, 0.9509777426719666, 0.9541923403739929, 0.9539244771003723, 0.9523171782493591, 0.9544602036476135, 0.9571390151977539, 0.9515135288238525, 0.9515135288238525, 0.9566032886505127, 0.9571390151977539, 0.9555317163467407, 0.9525850415229797, 0.9622287750244141, 0.9576748013496399, 0.9541923403739929, 0.9560675024986267, 0.9627645611763, 0.9649075865745544, 0.9592821002006531, 0.9616929888725281, 0.9673185348510742, 0.9667827486991882, 0.9619609117507935, 0.9689257740974426, 0.9614251255989075, 0.9689257740974426, 0.9683900475502014, 0.9627645611763, 0.9675863981246948, 0.9710688591003418, 0.9697294235229492, 0.968657910823822, 0.9702652096748352, 0.9699973464012146, 0.9708009362220764, 0.9673185348510742, 0.97508704662323, 0.97508704662323, 0.9732118844985962, 0.9638360738754272, 0.972140371799469, 0.9753549695014954, 0.978569507598877, 0.9764264822006226, 0.9710688591003418, 0.9774979948997498, 0.9724082350730896, 0.9815161824226379, 0.9729440212249756, 0.9815161824226379, 0.9699973464012146, 0.9699973464012146, 0.9791052937507629, 0.9761585593223572, 0.9817841053009033, 0.9815161824226379, 0.9793731570243835, 0.978569507598877, 0.9774979948997498, 0.9812483191490173, 0.9828556180000305, 0.9836592674255371, 0.9801768064498901, 0.9801768064498901, 0.972140371799469, 0.9791052937507629, 0.9777658581733704, 0.9860701560974121, 0.9868738055229187, 0.9791052937507629, 0.9796410202980042, 0.9828556180000305, 0.9849986433982849, 0.9809804558753967, 0.9868738055229187, 0.9852665662765503, 0.9774979948997498, 0.9855344295501709, 0.9898205399513245, 0.9879453778266907, 0.9774979948997498, 0.9866059422492981, 0.9871417284011841, 0.9855344295501709, 0.9871417284011841, 0.9855344295501709, 0.9876774549484253, 0.9890168905258179, 0.9841949939727783, 0.9769622087478638], 'val_loss': [0.6619253754615784, 0.657772958278656, 0.6516091227531433, 0.6435957551002502, 0.6361344456672668, 0.6265684962272644, 0.6127853393554688, 0.597197949886322, 0.5787827968597412, 0.5611634850502014, 0.5398945808410645, 0.5164218544960022, 0.4821677505970001, 0.4590094983577728, 0.41963016986846924, 0.389137864112854, 0.36455702781677246, 0.3493524193763733, 0.3392272889614105, 0.32623380422592163, 0.3170367181301117, 0.35033512115478516, 0.31578290462493896, 0.30398833751678467, 0.36866816878318787, 0.33318817615509033, 0.3243039846420288, 0.3253501355648041, 0.326022744178772, 0.3343619108200073, 0.3391250967979431, 0.3436952829360962, 0.4018994867801666, 0.36056897044181824, 0.35948437452316284, 0.35226577520370483, 0.36676883697509766, 0.3590329885482788, 0.3657729923725128, 0.3881824314594269, 0.36246800422668457, 0.36683568358421326, 0.3847852051258087, 0.38376879692077637, 0.3755042850971222, 0.37770339846611023, 0.380485475063324, 0.3786517381668091, 0.39881566166877747, 0.379554808139801, 0.404692679643631, 0.3899838328361511, 0.4116448163986206, 0.41693559288978577, 0.39633089303970337, 0.41989606618881226, 0.39331352710723877, 0.40383675694465637, 0.4178030788898468, 0.408349871635437, 0.5699613690376282, 0.4105261564254761, 0.4227004647254944, 0.4107570946216583, 0.4218868911266327, 0.4108818471431732, 0.4195459187030792, 0.4575917422771454, 0.419303297996521, 0.4288141131401062, 0.4206174314022064, 0.46190571784973145, 0.4254639148712158, 0.43787747621536255, 0.44285494089126587, 0.44209009408950806, 0.44478920102119446, 0.4519038200378418, 0.4383167624473572, 0.5024107098579407, 0.45908206701278687, 0.4493486285209656, 0.4748968780040741, 0.4552750587463379, 0.4543614089488983, 0.45505431294441223, 0.45480021834373474, 0.4443979859352112, 0.45723390579223633, 0.45762088894844055, 0.47024115920066833, 0.45695066452026367, 0.4642801582813263, 0.49586138129234314, 0.4816856384277344, 0.48074132204055786, 0.482684463262558, 0.48667946457862854, 0.5268373489379883, 0.4923132061958313], 'val_accuracy': [0.794432520866394, 0.8040685057640076, 0.8008565306663513, 0.8211991190910339, 0.8233404755592346, 0.8158458471298218, 0.8201285004615784, 0.8211991190910339, 0.8254817724227905, 0.8222697973251343, 0.8286938071250916, 0.8265524506568909, 0.8308351039886475, 0.8383297920227051, 0.8447537422180176, 0.8458244204521179, 0.8372591137886047, 0.8576017022132874, 0.8586723804473877, 0.859743058681488, 0.8629550337791443, 0.856531023979187, 0.8715203404426575, 0.881156325340271, 0.8650963306427002, 0.881156325340271, 0.8800856471061707, 0.8800856471061707, 0.8790149688720703, 0.8779443502426147, 0.8790149688720703, 0.8865096569061279, 0.8693790435791016, 0.8790149688720703, 0.8736616969108582, 0.8800856471061707, 0.8758029937744141, 0.8822270035743713, 0.8747323155403137, 0.8672376871109009, 0.8768736720085144, 0.8768736720085144, 0.8715203404426575, 0.8768736720085144, 0.8790149688720703, 0.881156325340271, 0.8832976222038269, 0.881156325340271, 0.8715203404426575, 0.8768736720085144, 0.8661670088768005, 0.8779443502426147, 0.8725910186767578, 0.8758029937744141, 0.8747323155403137, 0.8672376871109009, 0.8779443502426147, 0.8758029937744141, 0.8747323155403137, 0.8768736720085144, 0.840471088886261, 0.8779443502426147, 0.8715203404426575, 0.8747323155403137, 0.8758029937744141, 0.8800856471061707, 0.8747323155403137, 0.8693790435791016, 0.8779443502426147, 0.8768736720085144, 0.8725910186767578, 0.8672376871109009, 0.8768736720085144, 0.8725910186767578, 0.8715203404426575, 0.8704496622085571, 0.8704496622085571, 0.8683083653450012, 0.8715203404426575, 0.859743058681488, 0.8736616969108582, 0.8758029937744141, 0.8650963306427002, 0.8768736720085144, 0.8704496622085571, 0.8758029937744141, 0.8736616969108582, 0.8747323155403137, 0.8736616969108582, 0.8747323155403137, 0.8661670088768005, 0.8790149688720703, 0.8758029937744141, 0.8650963306427002, 0.8693790435791016, 0.8715203404426575, 0.8715203404426575, 0.8661670088768005, 0.8543897271156311, 0.8629550337791443]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 9s 53ms/step - loss: 0.1299 - accuracy: 0.9569 - val_loss: 0.6557 - val_accuracy: 0.8009\n","Epoch 2/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1298 - accuracy: 0.9561 - val_loss: 0.6495 - val_accuracy: 0.7623\n","Epoch 3/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1017 - accuracy: 0.9697 - val_loss: 0.6430 - val_accuracy: 0.8158\n","Epoch 4/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0984 - accuracy: 0.9684 - val_loss: 0.6337 - val_accuracy: 0.7976\n","Epoch 5/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0910 - accuracy: 0.9705 - val_loss: 0.6245 - val_accuracy: 0.7784\n","Epoch 6/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0905 - accuracy: 0.9713 - val_loss: 0.6137 - val_accuracy: 0.8148\n","Epoch 7/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0831 - accuracy: 0.9743 - val_loss: 0.5972 - val_accuracy: 0.7976\n","Epoch 8/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0815 - accuracy: 0.9767 - val_loss: 0.5788 - val_accuracy: 0.8073\n","Epoch 9/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0849 - accuracy: 0.9759 - val_loss: 0.5593 - val_accuracy: 0.7955\n","Epoch 10/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0846 - accuracy: 0.9751 - val_loss: 0.5385 - val_accuracy: 0.8116\n","Epoch 11/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0852 - accuracy: 0.9700 - val_loss: 0.5151 - val_accuracy: 0.7987\n","Epoch 12/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0802 - accuracy: 0.9770 - val_loss: 0.4876 - val_accuracy: 0.8158\n","Epoch 13/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0965 - accuracy: 0.9673 - val_loss: 0.4642 - val_accuracy: 0.8266\n","Epoch 14/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0980 - accuracy: 0.9673 - val_loss: 0.4312 - val_accuracy: 0.8255\n","Epoch 15/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0767 - accuracy: 0.9778 - val_loss: 0.4103 - val_accuracy: 0.8319\n","Epoch 16/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0767 - accuracy: 0.9783 - val_loss: 0.3844 - val_accuracy: 0.8330\n","Epoch 17/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0698 - accuracy: 0.9818 - val_loss: 0.3712 - val_accuracy: 0.8287\n","Epoch 18/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.0733 - accuracy: 0.9794 - val_loss: 0.3673 - val_accuracy: 0.8287\n","Epoch 19/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0879 - accuracy: 0.9746 - val_loss: 0.3688 - val_accuracy: 0.8351\n","Epoch 20/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0713 - accuracy: 0.9810 - val_loss: 0.3639 - val_accuracy: 0.8469\n","Epoch 21/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0691 - accuracy: 0.9802 - val_loss: 0.3708 - val_accuracy: 0.8555\n","Epoch 22/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0901 - accuracy: 0.9716 - val_loss: 0.3897 - val_accuracy: 0.8565\n","Epoch 23/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0730 - accuracy: 0.9812 - val_loss: 0.3933 - val_accuracy: 0.8555\n","Epoch 24/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0772 - accuracy: 0.9783 - val_loss: 0.4420 - val_accuracy: 0.8522\n","Epoch 25/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0799 - accuracy: 0.9770 - val_loss: 0.4391 - val_accuracy: 0.8576\n","Epoch 26/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0872 - accuracy: 0.9724 - val_loss: 0.4052 - val_accuracy: 0.8608\n","Epoch 27/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0695 - accuracy: 0.9807 - val_loss: 0.4247 - val_accuracy: 0.8619\n","Epoch 28/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0630 - accuracy: 0.9839 - val_loss: 0.4202 - val_accuracy: 0.8630\n","Epoch 29/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0613 - accuracy: 0.9826 - val_loss: 0.4270 - val_accuracy: 0.8662\n","Epoch 30/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0625 - accuracy: 0.9842 - val_loss: 0.4761 - val_accuracy: 0.8544\n","Epoch 31/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0663 - accuracy: 0.9818 - val_loss: 0.4731 - val_accuracy: 0.8587\n","Epoch 32/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0672 - accuracy: 0.9815 - val_loss: 0.4854 - val_accuracy: 0.8565\n","Epoch 33/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0696 - accuracy: 0.9796 - val_loss: 0.4891 - val_accuracy: 0.8608\n","Epoch 34/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0718 - accuracy: 0.9804 - val_loss: 0.5003 - val_accuracy: 0.8597\n","Epoch 35/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0836 - accuracy: 0.9748 - val_loss: 0.4846 - val_accuracy: 0.8662\n","Epoch 36/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0633 - accuracy: 0.9812 - val_loss: 0.4684 - val_accuracy: 0.8672\n","Epoch 37/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0596 - accuracy: 0.9853 - val_loss: 0.4566 - val_accuracy: 0.8630\n","Epoch 38/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0651 - accuracy: 0.9823 - val_loss: 0.5032 - val_accuracy: 0.8587\n","Epoch 39/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0568 - accuracy: 0.9861 - val_loss: 0.4641 - val_accuracy: 0.8672\n","Epoch 40/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0526 - accuracy: 0.9855 - val_loss: 0.4765 - val_accuracy: 0.8630\n","Epoch 41/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0677 - accuracy: 0.9804 - val_loss: 0.4867 - val_accuracy: 0.8640\n","Epoch 42/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0641 - accuracy: 0.9829 - val_loss: 0.4710 - val_accuracy: 0.8672\n","Epoch 43/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0702 - accuracy: 0.9799 - val_loss: 0.4749 - val_accuracy: 0.8683\n","Epoch 44/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0647 - accuracy: 0.9812 - val_loss: 0.4791 - val_accuracy: 0.8662\n","Epoch 45/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0559 - accuracy: 0.9853 - val_loss: 0.4966 - val_accuracy: 0.8630\n","Epoch 46/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0564 - accuracy: 0.9847 - val_loss: 0.4864 - val_accuracy: 0.8672\n","Epoch 47/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0580 - accuracy: 0.9839 - val_loss: 0.4940 - val_accuracy: 0.8630\n","Epoch 48/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0701 - accuracy: 0.9775 - val_loss: 0.4989 - val_accuracy: 0.8576\n","Epoch 49/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0579 - accuracy: 0.9834 - val_loss: 0.4945 - val_accuracy: 0.8608\n","Epoch 50/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0667 - accuracy: 0.9794 - val_loss: 0.4927 - val_accuracy: 0.8608\n","Epoch 51/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0627 - accuracy: 0.9807 - val_loss: 0.4922 - val_accuracy: 0.8662\n","Epoch 52/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0501 - accuracy: 0.9879 - val_loss: 0.4968 - val_accuracy: 0.8651\n","Epoch 53/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0590 - accuracy: 0.9845 - val_loss: 0.5248 - val_accuracy: 0.8630\n","Epoch 54/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0486 - accuracy: 0.9858 - val_loss: 0.5018 - val_accuracy: 0.8672\n","Epoch 55/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0475 - accuracy: 0.9887 - val_loss: 0.4955 - val_accuracy: 0.8694\n","Epoch 56/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0532 - accuracy: 0.9866 - val_loss: 0.5448 - val_accuracy: 0.8597\n","Epoch 57/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0672 - accuracy: 0.9810 - val_loss: 0.5485 - val_accuracy: 0.8662\n","Epoch 58/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0591 - accuracy: 0.9829 - val_loss: 0.5042 - val_accuracy: 0.8597\n","Epoch 59/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0605 - accuracy: 0.9847 - val_loss: 0.5638 - val_accuracy: 0.8565\n","Epoch 60/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0467 - accuracy: 0.9877 - val_loss: 0.5500 - val_accuracy: 0.8576\n","Epoch 61/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0509 - accuracy: 0.9879 - val_loss: 0.5446 - val_accuracy: 0.8608\n","Epoch 62/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0493 - accuracy: 0.9882 - val_loss: 0.5393 - val_accuracy: 0.8640\n","Epoch 63/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0617 - accuracy: 0.9818 - val_loss: 0.6371 - val_accuracy: 0.8533\n","Epoch 64/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0587 - accuracy: 0.9855 - val_loss: 0.5246 - val_accuracy: 0.8544\n","Epoch 65/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0853 - accuracy: 0.9735 - val_loss: 0.5319 - val_accuracy: 0.8480\n","Epoch 66/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0705 - accuracy: 0.9788 - val_loss: 0.5088 - val_accuracy: 0.8630\n","Epoch 67/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0490 - accuracy: 0.9882 - val_loss: 0.5422 - val_accuracy: 0.8608\n","Epoch 68/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0461 - accuracy: 0.9893 - val_loss: 0.5134 - val_accuracy: 0.8651\n","Epoch 69/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0454 - accuracy: 0.9896 - val_loss: 0.5538 - val_accuracy: 0.8608\n","Epoch 70/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0433 - accuracy: 0.9917 - val_loss: 0.5282 - val_accuracy: 0.8597\n","Epoch 71/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0449 - accuracy: 0.9887 - val_loss: 0.5340 - val_accuracy: 0.8597\n","Epoch 72/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0489 - accuracy: 0.9871 - val_loss: 0.5290 - val_accuracy: 0.8619\n","Epoch 73/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0532 - accuracy: 0.9858 - val_loss: 0.5288 - val_accuracy: 0.8608\n","Epoch 74/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0520 - accuracy: 0.9866 - val_loss: 0.5367 - val_accuracy: 0.8619\n","Epoch 75/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0419 - accuracy: 0.9914 - val_loss: 0.5617 - val_accuracy: 0.8619\n","Epoch 76/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0456 - accuracy: 0.9898 - val_loss: 0.5419 - val_accuracy: 0.8608\n","Epoch 77/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0420 - accuracy: 0.9912 - val_loss: 0.5574 - val_accuracy: 0.8576\n","Epoch 78/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0432 - accuracy: 0.9890 - val_loss: 0.5495 - val_accuracy: 0.8608\n","Epoch 79/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0544 - accuracy: 0.9850 - val_loss: 0.6743 - val_accuracy: 0.8448\n","Epoch 80/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0535 - accuracy: 0.9847 - val_loss: 0.6317 - val_accuracy: 0.8555\n","Epoch 81/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0487 - accuracy: 0.9877 - val_loss: 0.5734 - val_accuracy: 0.8597\n","Epoch 82/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0492 - accuracy: 0.9861 - val_loss: 0.5481 - val_accuracy: 0.8587\n","Epoch 83/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0449 - accuracy: 0.9896 - val_loss: 0.5625 - val_accuracy: 0.8608\n","Epoch 84/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0503 - accuracy: 0.9879 - val_loss: 0.6344 - val_accuracy: 0.8480\n","Epoch 85/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0476 - accuracy: 0.9877 - val_loss: 0.5431 - val_accuracy: 0.8662\n","Epoch 86/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0474 - accuracy: 0.9893 - val_loss: 0.5964 - val_accuracy: 0.8555\n","Epoch 87/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0417 - accuracy: 0.9914 - val_loss: 0.6242 - val_accuracy: 0.8544\n","Epoch 88/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0433 - accuracy: 0.9893 - val_loss: 0.5873 - val_accuracy: 0.8608\n","Epoch 89/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0404 - accuracy: 0.9917 - val_loss: 0.6314 - val_accuracy: 0.8587\n","Epoch 90/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0427 - accuracy: 0.9909 - val_loss: 0.6136 - val_accuracy: 0.8533\n","Epoch 91/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0407 - accuracy: 0.9914 - val_loss: 0.5843 - val_accuracy: 0.8544\n","Epoch 92/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0373 - accuracy: 0.9922 - val_loss: 0.5734 - val_accuracy: 0.8640\n","Epoch 93/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0365 - accuracy: 0.9928 - val_loss: 0.5951 - val_accuracy: 0.8555\n","Epoch 94/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0383 - accuracy: 0.9920 - val_loss: 0.6099 - val_accuracy: 0.8565\n","Epoch 95/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0627 - accuracy: 0.9804 - val_loss: 0.6131 - val_accuracy: 0.8437\n","Epoch 96/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0526 - accuracy: 0.9855 - val_loss: 0.5783 - val_accuracy: 0.8565\n","Epoch 97/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0413 - accuracy: 0.9906 - val_loss: 0.6966 - val_accuracy: 0.8426\n","Epoch 98/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0425 - accuracy: 0.9901 - val_loss: 0.5644 - val_accuracy: 0.8619\n","Epoch 99/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0412 - accuracy: 0.9901 - val_loss: 0.6565 - val_accuracy: 0.8490\n","Epoch 100/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0394 - accuracy: 0.9920 - val_loss: 0.6149 - val_accuracy: 0.8544\n","{'loss': [0.12991763651371002, 0.12976796925067902, 0.10172021389007568, 0.09835854172706604, 0.09102251380681992, 0.09051453322172165, 0.08309178799390793, 0.08146078139543533, 0.08488278836011887, 0.08462943881750107, 0.08518711477518082, 0.08020854741334915, 0.09654552489519119, 0.09797661006450653, 0.07668479532003403, 0.07667084038257599, 0.0698167160153389, 0.07327700406312943, 0.08793876320123672, 0.0713268592953682, 0.0690939798951149, 0.09007006883621216, 0.07302113622426987, 0.07721910625696182, 0.07986107468605042, 0.08716435730457306, 0.06950952112674713, 0.06303325295448303, 0.061333708465099335, 0.06252480298280716, 0.06632158905267715, 0.06721676141023636, 0.06957834959030151, 0.07177095115184784, 0.08360055834054947, 0.06329365074634552, 0.059598103165626526, 0.06505431979894638, 0.05678458884358406, 0.05258627235889435, 0.06772508472204208, 0.064053475856781, 0.07021541893482208, 0.06466594338417053, 0.05587540939450264, 0.056419819593429565, 0.05797242000699043, 0.07012572884559631, 0.057929206639528275, 0.06673269718885422, 0.06265424191951752, 0.05007566139101982, 0.05900324881076813, 0.04861340671777725, 0.04750867933034897, 0.05317316949367523, 0.06722033023834229, 0.059111449867486954, 0.06047091260552406, 0.04671385511755943, 0.05092201754450798, 0.04933888837695122, 0.0617196261882782, 0.05868588387966156, 0.0852503851056099, 0.07048545032739639, 0.04899162799119949, 0.04614788666367531, 0.04540875181555748, 0.0432649627327919, 0.04487410932779312, 0.04889465123414993, 0.05318339914083481, 0.05203135311603546, 0.041867539286613464, 0.0455828495323658, 0.041952766478061676, 0.043203260749578476, 0.054418448358774185, 0.05349915102124214, 0.04871802031993866, 0.04920553043484688, 0.04491099715232849, 0.050260044634342194, 0.04764844477176666, 0.047430381178855896, 0.041736628860235214, 0.04326537996530533, 0.040387216955423355, 0.04272647574543953, 0.040682271122932434, 0.03731899708509445, 0.036516398191452026, 0.03833260014653206, 0.06269925087690353, 0.05263928696513176, 0.041279617697000504, 0.042456015944480896, 0.04117263853549957, 0.039350345730781555], 'accuracy': [0.9568711519241333, 0.9560675024986267, 0.9697294235229492, 0.9683900475502014, 0.9705330729484558, 0.9713367223739624, 0.9742833971977234, 0.9766943454742432, 0.9758906960487366, 0.97508704662323, 0.9699973464012146, 0.9769622087478638, 0.9673185348510742, 0.9673185348510742, 0.9777658581733704, 0.9783016443252563, 0.9817841053009033, 0.9793731570243835, 0.9745513200759888, 0.9809804558753967, 0.9801768064498901, 0.971604585647583, 0.9812483191490173, 0.9783016443252563, 0.9769622087478638, 0.9724082350730896, 0.9807125926017761, 0.9839271306991577, 0.9825877547264099, 0.9841949939727783, 0.9817841053009033, 0.9815161824226379, 0.9796410202980042, 0.9804446697235107, 0.9748191833496094, 0.9812483191490173, 0.9852665662765503, 0.9823198318481445, 0.9860701560974121, 0.9855344295501709, 0.9804446697235107, 0.9828556180000305, 0.9799089431762695, 0.9812483191490173, 0.9852665662765503, 0.9847307801246643, 0.9839271306991577, 0.9774979948997498, 0.9833913445472717, 0.9793731570243835, 0.9807125926017761, 0.9879453778266907, 0.9844629168510437, 0.9858022928237915, 0.9887489676475525, 0.9866059422492981, 0.9809804558753967, 0.9828556180000305, 0.9847307801246643, 0.9876774549484253, 0.9879453778266907, 0.9882132411003113, 0.9817841053009033, 0.9855344295501709, 0.9734797477722168, 0.9788373708724976, 0.9882132411003113, 0.9892847537994385, 0.9895526170730591, 0.9916957020759583, 0.9887489676475525, 0.9871417284011841, 0.9858022928237915, 0.9866059422492981, 0.9914277791976929, 0.9898205399513245, 0.9911599159240723, 0.9890168905258179, 0.9849986433982849, 0.9847307801246643, 0.9876774549484253, 0.9860701560974121, 0.9895526170730591, 0.9879453778266907, 0.9876774549484253, 0.9892847537994385, 0.9914277791976929, 0.9892847537994385, 0.9916957020759583, 0.9908920526504517, 0.9914277791976929, 0.9922314286231995, 0.9927672147750854, 0.9919635653495789, 0.9804446697235107, 0.9855344295501709, 0.990624189376831, 0.9900884032249451, 0.9900884032249451, 0.9919635653495789], 'val_loss': [0.6556721925735474, 0.6495050191879272, 0.642959475517273, 0.6336504817008972, 0.6245169043540955, 0.6136637330055237, 0.597203254699707, 0.5788173675537109, 0.5592562556266785, 0.5385122299194336, 0.5151157379150391, 0.4875963628292084, 0.4642331302165985, 0.4312317669391632, 0.4102940559387207, 0.3844200074672699, 0.3712497353553772, 0.36734580993652344, 0.36880552768707275, 0.3639078140258789, 0.37084999680519104, 0.38974377512931824, 0.3933057487010956, 0.44203704595565796, 0.43907615542411804, 0.40520355105400085, 0.4246751070022583, 0.4202461838722229, 0.4269520342350006, 0.47606226801872253, 0.4730713963508606, 0.4853827953338623, 0.48908382654190063, 0.5002856254577637, 0.4846137464046478, 0.4683643579483032, 0.45664846897125244, 0.503240168094635, 0.4640759229660034, 0.47654280066490173, 0.4866660535335541, 0.4710170030593872, 0.47489818930625916, 0.4790708124637604, 0.4965934455394745, 0.4864269495010376, 0.49398505687713623, 0.49886608123779297, 0.49449145793914795, 0.49274107813835144, 0.49217525124549866, 0.4967963397502899, 0.5248286128044128, 0.5018360614776611, 0.4955170452594757, 0.5448377132415771, 0.5484951734542847, 0.5041795372962952, 0.5638182163238525, 0.549966037273407, 0.544633686542511, 0.5392535924911499, 0.6371466517448425, 0.5245875716209412, 0.5318685173988342, 0.5088267922401428, 0.5422082543373108, 0.5133937001228333, 0.5538430213928223, 0.5282049179077148, 0.5339965224266052, 0.5290402173995972, 0.5288394093513489, 0.5367090106010437, 0.5616694092750549, 0.5419338941574097, 0.5574421286582947, 0.5495221018791199, 0.6743447780609131, 0.63173508644104, 0.5734457969665527, 0.5481018424034119, 0.562513530254364, 0.6344138979911804, 0.543097972869873, 0.5963853597640991, 0.6242361068725586, 0.5873287320137024, 0.6313684582710266, 0.6135988831520081, 0.5843054056167603, 0.5733999013900757, 0.5950785279273987, 0.6099333763122559, 0.6131449937820435, 0.5783496499061584, 0.6965603828430176, 0.5644494295120239, 0.65653395652771, 0.6148741245269775], 'val_accuracy': [0.8008565306663513, 0.762312650680542, 0.8158458471298218, 0.7976445555686951, 0.778372585773468, 0.8147751688957214, 0.7976445555686951, 0.8072805404663086, 0.7955031991004944, 0.8115631937980652, 0.7987151741981506, 0.8158458471298218, 0.8265524506568909, 0.8254817724227905, 0.8319057822227478, 0.8329764604568481, 0.8286938071250916, 0.8286938071250916, 0.835117757320404, 0.8468950986862183, 0.8554604053497314, 0.856531023979187, 0.8554604053497314, 0.8522483706474304, 0.8576017022132874, 0.8608136773109436, 0.861884355545044, 0.8629550337791443, 0.8661670088768005, 0.8543897271156311, 0.8586723804473877, 0.856531023979187, 0.8608136773109436, 0.859743058681488, 0.8661670088768005, 0.8672376871109009, 0.8629550337791443, 0.8586723804473877, 0.8672376871109009, 0.8629550337791443, 0.8640257120132446, 0.8672376871109009, 0.8683083653450012, 0.8661670088768005, 0.8629550337791443, 0.8672376871109009, 0.8629550337791443, 0.8576017022132874, 0.8608136773109436, 0.8608136773109436, 0.8661670088768005, 0.8650963306427002, 0.8629550337791443, 0.8672376871109009, 0.8693790435791016, 0.859743058681488, 0.8661670088768005, 0.859743058681488, 0.856531023979187, 0.8576017022132874, 0.8608136773109436, 0.8640257120132446, 0.8533190488815308, 0.8543897271156311, 0.8479657173156738, 0.8629550337791443, 0.8608136773109436, 0.8650963306427002, 0.8608136773109436, 0.859743058681488, 0.859743058681488, 0.861884355545044, 0.8608136773109436, 0.861884355545044, 0.861884355545044, 0.8608136773109436, 0.8576017022132874, 0.8608136773109436, 0.8447537422180176, 0.8554604053497314, 0.859743058681488, 0.8586723804473877, 0.8608136773109436, 0.8479657173156738, 0.8661670088768005, 0.8554604053497314, 0.8543897271156311, 0.8608136773109436, 0.8586723804473877, 0.8533190488815308, 0.8543897271156311, 0.8640257120132446, 0.8554604053497314, 0.856531023979187, 0.8436830639839172, 0.856531023979187, 0.8426124453544617, 0.861884355545044, 0.8490363955497742, 0.8543897271156311]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 71ms/step - loss: 0.1370 - accuracy: 0.9515 - val_loss: 0.6517 - val_accuracy: 0.7805\n","Epoch 2/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.1021 - accuracy: 0.9671 - val_loss: 0.6477 - val_accuracy: 0.7794\n","Epoch 3/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.1017 - accuracy: 0.9697 - val_loss: 0.6398 - val_accuracy: 0.7837\n","Epoch 4/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1133 - accuracy: 0.9590 - val_loss: 0.6288 - val_accuracy: 0.8051\n","Epoch 5/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1039 - accuracy: 0.9657 - val_loss: 0.6199 - val_accuracy: 0.7891\n","Epoch 6/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0928 - accuracy: 0.9721 - val_loss: 0.6058 - val_accuracy: 0.8244\n","Epoch 7/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0894 - accuracy: 0.9708 - val_loss: 0.5904 - val_accuracy: 0.7987\n","Epoch 8/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0923 - accuracy: 0.9681 - val_loss: 0.5699 - val_accuracy: 0.8383\n","Epoch 9/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0869 - accuracy: 0.9705 - val_loss: 0.5506 - val_accuracy: 0.8426\n","Epoch 10/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0749 - accuracy: 0.9780 - val_loss: 0.5241 - val_accuracy: 0.8383\n","Epoch 11/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0764 - accuracy: 0.9778 - val_loss: 0.4941 - val_accuracy: 0.8405\n","Epoch 12/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0753 - accuracy: 0.9778 - val_loss: 0.4706 - val_accuracy: 0.8019\n","Epoch 13/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0801 - accuracy: 0.9767 - val_loss: 0.4317 - val_accuracy: 0.8426\n","Epoch 14/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0842 - accuracy: 0.9729 - val_loss: 0.4016 - val_accuracy: 0.8522\n","Epoch 15/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0684 - accuracy: 0.9807 - val_loss: 0.3694 - val_accuracy: 0.8565\n","Epoch 16/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0723 - accuracy: 0.9767 - val_loss: 0.3408 - val_accuracy: 0.8555\n","Epoch 17/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0782 - accuracy: 0.9737 - val_loss: 0.3199 - val_accuracy: 0.8790\n","Epoch 18/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0772 - accuracy: 0.9775 - val_loss: 0.3010 - val_accuracy: 0.8704\n","Epoch 19/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0669 - accuracy: 0.9815 - val_loss: 0.2811 - val_accuracy: 0.8833\n","Epoch 20/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0664 - accuracy: 0.9786 - val_loss: 0.2762 - val_accuracy: 0.8919\n","Epoch 21/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0789 - accuracy: 0.9724 - val_loss: 0.2721 - val_accuracy: 0.8940\n","Epoch 22/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0637 - accuracy: 0.9804 - val_loss: 0.2767 - val_accuracy: 0.8929\n","Epoch 23/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0682 - accuracy: 0.9788 - val_loss: 0.2658 - val_accuracy: 0.9004\n","Epoch 24/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0716 - accuracy: 0.9794 - val_loss: 0.2751 - val_accuracy: 0.9004\n","Epoch 25/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0599 - accuracy: 0.9834 - val_loss: 0.3397 - val_accuracy: 0.8844\n","Epoch 26/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1053 - accuracy: 0.9638 - val_loss: 0.3045 - val_accuracy: 0.8972\n","Epoch 27/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0687 - accuracy: 0.9788 - val_loss: 0.2792 - val_accuracy: 0.9026\n","Epoch 28/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0640 - accuracy: 0.9826 - val_loss: 0.2939 - val_accuracy: 0.9004\n","Epoch 29/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0644 - accuracy: 0.9818 - val_loss: 0.2889 - val_accuracy: 0.9058\n","Epoch 30/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0621 - accuracy: 0.9812 - val_loss: 0.3281 - val_accuracy: 0.8983\n","Epoch 31/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0650 - accuracy: 0.9796 - val_loss: 0.3133 - val_accuracy: 0.9026\n","Epoch 32/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0598 - accuracy: 0.9823 - val_loss: 0.2973 - val_accuracy: 0.9047\n","Epoch 33/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0559 - accuracy: 0.9855 - val_loss: 0.3045 - val_accuracy: 0.8994\n","Epoch 34/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0526 - accuracy: 0.9882 - val_loss: 0.3117 - val_accuracy: 0.9004\n","Epoch 35/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0519 - accuracy: 0.9853 - val_loss: 0.3035 - val_accuracy: 0.9015\n","Epoch 36/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0588 - accuracy: 0.9853 - val_loss: 0.3084 - val_accuracy: 0.9004\n","Epoch 37/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0606 - accuracy: 0.9850 - val_loss: 0.3491 - val_accuracy: 0.9004\n","Epoch 38/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0641 - accuracy: 0.9818 - val_loss: 0.3186 - val_accuracy: 0.9036\n","Epoch 39/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0563 - accuracy: 0.9839 - val_loss: 0.3168 - val_accuracy: 0.9047\n","Epoch 40/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0572 - accuracy: 0.9821 - val_loss: 0.3566 - val_accuracy: 0.8897\n","Epoch 41/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0579 - accuracy: 0.9839 - val_loss: 0.3199 - val_accuracy: 0.8983\n","Epoch 42/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0538 - accuracy: 0.9847 - val_loss: 0.3431 - val_accuracy: 0.8908\n","Epoch 43/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0611 - accuracy: 0.9826 - val_loss: 0.3254 - val_accuracy: 0.8972\n","Epoch 44/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0502 - accuracy: 0.9869 - val_loss: 0.3457 - val_accuracy: 0.9004\n","Epoch 45/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0504 - accuracy: 0.9863 - val_loss: 0.3523 - val_accuracy: 0.8940\n","Epoch 46/100\n","30/30 [==============================] - 1s 33ms/step - loss: 0.0423 - accuracy: 0.9912 - val_loss: 0.3365 - val_accuracy: 0.8994\n","Epoch 47/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0455 - accuracy: 0.9890 - val_loss: 0.3375 - val_accuracy: 0.8972\n","Epoch 48/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.0495 - accuracy: 0.9874 - val_loss: 0.3801 - val_accuracy: 0.8940\n","Epoch 49/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0523 - accuracy: 0.9855 - val_loss: 0.3633 - val_accuracy: 0.9015\n","Epoch 50/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0609 - accuracy: 0.9815 - val_loss: 0.5247 - val_accuracy: 0.8715\n","Epoch 51/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0575 - accuracy: 0.9826 - val_loss: 0.3408 - val_accuracy: 0.8994\n","Epoch 52/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0461 - accuracy: 0.9898 - val_loss: 0.3676 - val_accuracy: 0.8972\n","Epoch 53/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0438 - accuracy: 0.9896 - val_loss: 0.3422 - val_accuracy: 0.8972\n","Epoch 54/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0397 - accuracy: 0.9922 - val_loss: 0.3875 - val_accuracy: 0.8961\n","Epoch 55/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0523 - accuracy: 0.9850 - val_loss: 0.4314 - val_accuracy: 0.8929\n","Epoch 56/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0558 - accuracy: 0.9858 - val_loss: 0.3429 - val_accuracy: 0.9004\n","Epoch 57/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0452 - accuracy: 0.9896 - val_loss: 0.3466 - val_accuracy: 0.8940\n","Epoch 58/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0468 - accuracy: 0.9877 - val_loss: 0.3601 - val_accuracy: 0.8983\n","Epoch 59/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0445 - accuracy: 0.9879 - val_loss: 0.3492 - val_accuracy: 0.8994\n","Epoch 60/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0445 - accuracy: 0.9879 - val_loss: 0.4406 - val_accuracy: 0.8929\n","Epoch 61/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0739 - accuracy: 0.9759 - val_loss: 0.4436 - val_accuracy: 0.8876\n","Epoch 62/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0482 - accuracy: 0.9871 - val_loss: 0.3709 - val_accuracy: 0.8983\n","Epoch 63/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0639 - accuracy: 0.9802 - val_loss: 0.3381 - val_accuracy: 0.9036\n","Epoch 64/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0462 - accuracy: 0.9882 - val_loss: 0.3749 - val_accuracy: 0.8961\n","Epoch 65/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0430 - accuracy: 0.9909 - val_loss: 0.3465 - val_accuracy: 0.8983\n","Epoch 66/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0411 - accuracy: 0.9906 - val_loss: 0.3541 - val_accuracy: 0.8961\n","Epoch 67/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0404 - accuracy: 0.9912 - val_loss: 0.3644 - val_accuracy: 0.9004\n","Epoch 68/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.0392 - accuracy: 0.9917 - val_loss: 0.3681 - val_accuracy: 0.8951\n","Epoch 69/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0343 - accuracy: 0.9933 - val_loss: 0.4155 - val_accuracy: 0.8983\n","Epoch 70/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0425 - accuracy: 0.9901 - val_loss: 0.3624 - val_accuracy: 0.8951\n","Epoch 71/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0379 - accuracy: 0.9914 - val_loss: 0.3768 - val_accuracy: 0.8940\n","Epoch 72/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0386 - accuracy: 0.9917 - val_loss: 0.3786 - val_accuracy: 0.8951\n","Epoch 73/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0385 - accuracy: 0.9914 - val_loss: 0.3798 - val_accuracy: 0.8951\n","Epoch 74/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0382 - accuracy: 0.9917 - val_loss: 0.3785 - val_accuracy: 0.8919\n","Epoch 75/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0454 - accuracy: 0.9874 - val_loss: 0.3809 - val_accuracy: 0.8929\n","Epoch 76/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0380 - accuracy: 0.9909 - val_loss: 0.3793 - val_accuracy: 0.8897\n","Epoch 77/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0396 - accuracy: 0.9898 - val_loss: 0.4249 - val_accuracy: 0.8994\n","Epoch 78/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0566 - accuracy: 0.9826 - val_loss: 0.3910 - val_accuracy: 0.8929\n","Epoch 79/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0656 - accuracy: 0.9794 - val_loss: 0.3909 - val_accuracy: 0.8887\n","Epoch 80/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0454 - accuracy: 0.9877 - val_loss: 0.3725 - val_accuracy: 0.9015\n","Epoch 81/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0387 - accuracy: 0.9912 - val_loss: 0.3797 - val_accuracy: 0.8908\n","Epoch 82/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0458 - accuracy: 0.9901 - val_loss: 0.4286 - val_accuracy: 0.8951\n","Epoch 83/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0438 - accuracy: 0.9879 - val_loss: 0.3676 - val_accuracy: 0.8972\n","Epoch 84/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0352 - accuracy: 0.9922 - val_loss: 0.3673 - val_accuracy: 0.8972\n","Epoch 85/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0345 - accuracy: 0.9933 - val_loss: 0.3699 - val_accuracy: 0.8961\n","Epoch 86/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0337 - accuracy: 0.9936 - val_loss: 0.3851 - val_accuracy: 0.8972\n","Epoch 87/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0336 - accuracy: 0.9933 - val_loss: 0.3709 - val_accuracy: 0.8983\n","Epoch 88/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0338 - accuracy: 0.9930 - val_loss: 0.3741 - val_accuracy: 0.9004\n","Epoch 89/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0360 - accuracy: 0.9917 - val_loss: 0.4153 - val_accuracy: 0.8940\n","Epoch 90/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0336 - accuracy: 0.9936 - val_loss: 0.3798 - val_accuracy: 0.8951\n","Epoch 91/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0383 - accuracy: 0.9909 - val_loss: 0.3973 - val_accuracy: 0.8876\n","Epoch 92/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.0372 - accuracy: 0.9914 - val_loss: 0.4047 - val_accuracy: 0.8951\n","Epoch 93/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0370 - accuracy: 0.9922 - val_loss: 0.3981 - val_accuracy: 0.8951\n","Epoch 94/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.0443 - accuracy: 0.9882 - val_loss: 0.3818 - val_accuracy: 0.8961\n","Epoch 95/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0370 - accuracy: 0.9912 - val_loss: 0.3861 - val_accuracy: 0.8994\n","Epoch 96/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0434 - accuracy: 0.9874 - val_loss: 0.3777 - val_accuracy: 0.8983\n","Epoch 97/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0360 - accuracy: 0.9920 - val_loss: 0.3828 - val_accuracy: 0.8961\n","Epoch 98/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0312 - accuracy: 0.9941 - val_loss: 0.4388 - val_accuracy: 0.8951\n","Epoch 99/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0355 - accuracy: 0.9912 - val_loss: 0.3971 - val_accuracy: 0.8908\n","Epoch 100/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0360 - accuracy: 0.9922 - val_loss: 0.3962 - val_accuracy: 0.8983\n","{'loss': [0.13698382675647736, 0.10213731974363327, 0.10172243416309357, 0.11329665780067444, 0.10388260334730148, 0.09277521073818207, 0.08944259583950043, 0.09227672219276428, 0.08692775666713715, 0.07492182403802872, 0.0763925239443779, 0.07526356726884842, 0.08010056614875793, 0.08419135212898254, 0.06837750226259232, 0.07225603610277176, 0.07824641466140747, 0.07724543660879135, 0.06689000129699707, 0.06635373085737228, 0.07886399328708649, 0.06371891498565674, 0.0681983157992363, 0.07164192199707031, 0.0599021390080452, 0.10533645004034042, 0.06871494650840759, 0.06396506726741791, 0.06435959041118622, 0.06212975084781647, 0.06497827917337418, 0.059816595166921616, 0.05589619278907776, 0.05262809246778488, 0.051949016749858856, 0.05877626687288284, 0.06059066951274872, 0.06414537131786346, 0.0563090480864048, 0.057156383991241455, 0.05792810395359993, 0.05375352129340172, 0.06114951893687248, 0.050235770642757416, 0.050395138561725616, 0.04234132170677185, 0.0455324649810791, 0.04945354908704758, 0.05229511857032776, 0.06090208888053894, 0.05747814103960991, 0.04606904089450836, 0.0437597930431366, 0.03971927613019943, 0.052266672253608704, 0.05584290996193886, 0.045159030705690384, 0.04682518169283867, 0.044517114758491516, 0.04445941001176834, 0.07385992258787155, 0.048205211758613586, 0.06385963410139084, 0.04621773958206177, 0.04296654835343361, 0.04114215448498726, 0.04042191430926323, 0.039203111082315445, 0.034267671406269073, 0.042507272213697433, 0.03786982223391533, 0.03857964277267456, 0.03845249488949776, 0.03817438706755638, 0.045384615659713745, 0.038034431636333466, 0.039622962474823, 0.056592635810375214, 0.06563211232423782, 0.045442089438438416, 0.038707833737134933, 0.04579503461718559, 0.04376916587352753, 0.035197578370571136, 0.034488603472709656, 0.033676519989967346, 0.03360374644398689, 0.03376295417547226, 0.036035895347595215, 0.03363041579723358, 0.03829262778162956, 0.03715911880135536, 0.03704790771007538, 0.044271230697631836, 0.036953914910554886, 0.043410081416368484, 0.036034129559993744, 0.031235333532094955, 0.035485103726387024, 0.03597013279795647], 'accuracy': [0.9515135288238525, 0.9670506119728088, 0.9697294235229492, 0.9590141773223877, 0.965711236000061, 0.972140371799469, 0.9708009362220764, 0.968122124671936, 0.9705330729484558, 0.9780337810516357, 0.9777658581733704, 0.9777658581733704, 0.9766943454742432, 0.9729440212249756, 0.9807125926017761, 0.9766943454742432, 0.9737476706504822, 0.9774979948997498, 0.9815161824226379, 0.978569507598877, 0.9724082350730896, 0.9804446697235107, 0.9788373708724976, 0.9793731570243835, 0.9833913445472717, 0.9638360738754272, 0.9788373708724976, 0.9825877547264099, 0.9817841053009033, 0.9812483191490173, 0.9796410202980042, 0.9823198318481445, 0.9855344295501709, 0.9882132411003113, 0.9852665662765503, 0.9852665662765503, 0.9849986433982849, 0.9817841053009033, 0.9839271306991577, 0.9820519685745239, 0.9839271306991577, 0.9847307801246643, 0.9825877547264099, 0.9868738055229187, 0.9863380789756775, 0.9911599159240723, 0.9890168905258179, 0.9874095916748047, 0.9855344295501709, 0.9815161824226379, 0.9825877547264099, 0.9898205399513245, 0.9895526170730591, 0.9922314286231995, 0.9849986433982849, 0.9858022928237915, 0.9895526170730591, 0.9876774549484253, 0.9879453778266907, 0.9879453778266907, 0.9758906960487366, 0.9871417284011841, 0.9801768064498901, 0.9882132411003113, 0.9908920526504517, 0.990624189376831, 0.9911599159240723, 0.9916957020759583, 0.9933030009269714, 0.9900884032249451, 0.9914277791976929, 0.9916957020759583, 0.9914277791976929, 0.9916957020759583, 0.9874095916748047, 0.9908920526504517, 0.9898205399513245, 0.9825877547264099, 0.9793731570243835, 0.9876774549484253, 0.9911599159240723, 0.9900884032249451, 0.9879453778266907, 0.9922314286231995, 0.9933030009269714, 0.993570864200592, 0.9933030009269714, 0.993035078048706, 0.9916957020759583, 0.993570864200592, 0.9908920526504517, 0.9914277791976929, 0.9922314286231995, 0.9882132411003113, 0.9911599159240723, 0.9874095916748047, 0.9919635653495789, 0.9941065907478333, 0.9911599159240723, 0.9922314286231995], 'val_loss': [0.6516863107681274, 0.6476832628250122, 0.6398094296455383, 0.6287620663642883, 0.619851291179657, 0.6058083176612854, 0.5904329419136047, 0.5698640942573547, 0.5505551695823669, 0.5241042971611023, 0.49407005310058594, 0.4706379175186157, 0.4316508173942566, 0.40161001682281494, 0.3693704605102539, 0.3408139944076538, 0.31993567943573, 0.30101561546325684, 0.281085342168808, 0.27621570229530334, 0.2721044719219208, 0.27673211693763733, 0.265796035528183, 0.275055468082428, 0.33968448638916016, 0.30448758602142334, 0.27915364503860474, 0.2938939929008484, 0.2888573110103607, 0.3280550539493561, 0.3133141100406647, 0.2973048686981201, 0.3044692575931549, 0.3116650879383087, 0.3035028874874115, 0.3084244132041931, 0.34906861186027527, 0.3185723125934601, 0.3168186545372009, 0.35664281249046326, 0.31992653012275696, 0.3430708944797516, 0.3253537714481354, 0.34570443630218506, 0.3522510528564453, 0.3364822566509247, 0.3375183343887329, 0.38014456629753113, 0.36327433586120605, 0.5247193574905396, 0.34081465005874634, 0.36758774518966675, 0.3421524465084076, 0.3875170946121216, 0.43144217133522034, 0.3428761661052704, 0.3466486930847168, 0.360061913728714, 0.34920811653137207, 0.4406003952026367, 0.4436088800430298, 0.3709259033203125, 0.33810049295425415, 0.3748681843280792, 0.34651848673820496, 0.35408955812454224, 0.3643697500228882, 0.36807772517204285, 0.4155246317386627, 0.3624284565448761, 0.3768334686756134, 0.37864774465560913, 0.37977850437164307, 0.3785012662410736, 0.38091814517974854, 0.3792612850666046, 0.4248518645763397, 0.3910091519355774, 0.390872985124588, 0.3725346326828003, 0.37967056035995483, 0.42858076095581055, 0.3675934970378876, 0.3673253655433655, 0.369933545589447, 0.38514357805252075, 0.3709407150745392, 0.3741123378276825, 0.4153202176094055, 0.3798111379146576, 0.3973177671432495, 0.4046914875507355, 0.3980556130409241, 0.38183802366256714, 0.386140376329422, 0.37767869234085083, 0.38279223442077637, 0.4388440251350403, 0.39709609746932983, 0.39624476432800293], 'val_accuracy': [0.7805139422416687, 0.7794432640075684, 0.783725917339325, 0.8051391839981079, 0.7890792489051819, 0.824411153793335, 0.7987151741981506, 0.8383297920227051, 0.8426124453544617, 0.8383297920227051, 0.840471088886261, 0.8019272089004517, 0.8426124453544617, 0.8522483706474304, 0.856531023979187, 0.8554604053497314, 0.8790149688720703, 0.8704496622085571, 0.8832976222038269, 0.8918629288673401, 0.8940042853355408, 0.8929336071014404, 0.900428295135498, 0.900428295135498, 0.8843683004379272, 0.897216260433197, 0.902569591999054, 0.900428295135498, 0.9057815670967102, 0.8982869386672974, 0.902569591999054, 0.9047109484672546, 0.8993576169013977, 0.900428295135498, 0.9014989137649536, 0.900428295135498, 0.900428295135498, 0.9036402702331543, 0.9047109484672546, 0.8897216320037842, 0.8982869386672974, 0.8907923102378845, 0.897216260433197, 0.900428295135498, 0.8940042853355408, 0.8993576169013977, 0.897216260433197, 0.8940042853355408, 0.9014989137649536, 0.8715203404426575, 0.8993576169013977, 0.897216260433197, 0.897216260433197, 0.8961455821990967, 0.8929336071014404, 0.900428295135498, 0.8940042853355408, 0.8982869386672974, 0.8993576169013977, 0.8929336071014404, 0.8875802755355835, 0.8982869386672974, 0.9036402702331543, 0.8961455821990967, 0.8982869386672974, 0.8961455821990967, 0.900428295135498, 0.8950749635696411, 0.8982869386672974, 0.8950749635696411, 0.8940042853355408, 0.8950749635696411, 0.8950749635696411, 0.8918629288673401, 0.8929336071014404, 0.8897216320037842, 0.8993576169013977, 0.8929336071014404, 0.8886509537696838, 0.9014989137649536, 0.8907923102378845, 0.8950749635696411, 0.897216260433197, 0.897216260433197, 0.8961455821990967, 0.897216260433197, 0.8982869386672974, 0.900428295135498, 0.8940042853355408, 0.8950749635696411, 0.8875802755355835, 0.8950749635696411, 0.8950749635696411, 0.8961455821990967, 0.8993576169013977, 0.8982869386672974, 0.8961455821990967, 0.8950749635696411, 0.8907923102378845, 0.8982869386672974]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 70ms/step - loss: 0.1426 - accuracy: 0.9523 - val_loss: 0.6541 - val_accuracy: 0.7591\n","Epoch 2/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.1216 - accuracy: 0.9566 - val_loss: 0.6469 - val_accuracy: 0.8105\n","Epoch 3/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1061 - accuracy: 0.9628 - val_loss: 0.6415 - val_accuracy: 0.8191\n","Epoch 4/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1035 - accuracy: 0.9676 - val_loss: 0.6311 - val_accuracy: 0.8244\n","Epoch 5/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0923 - accuracy: 0.9697 - val_loss: 0.6219 - val_accuracy: 0.8212\n","Epoch 6/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0940 - accuracy: 0.9737 - val_loss: 0.6085 - val_accuracy: 0.8137\n","Epoch 7/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0901 - accuracy: 0.9711 - val_loss: 0.5946 - val_accuracy: 0.8233\n","Epoch 8/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0843 - accuracy: 0.9735 - val_loss: 0.5756 - val_accuracy: 0.8137\n","Epoch 9/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0848 - accuracy: 0.9711 - val_loss: 0.5549 - val_accuracy: 0.8276\n","Epoch 10/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0888 - accuracy: 0.9697 - val_loss: 0.5343 - val_accuracy: 0.8276\n","Epoch 11/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0844 - accuracy: 0.9716 - val_loss: 0.5087 - val_accuracy: 0.8244\n","Epoch 12/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0769 - accuracy: 0.9756 - val_loss: 0.4823 - val_accuracy: 0.8319\n","Epoch 13/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0802 - accuracy: 0.9751 - val_loss: 0.4503 - val_accuracy: 0.8308\n","Epoch 14/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0935 - accuracy: 0.9662 - val_loss: 0.4256 - val_accuracy: 0.8319\n","Epoch 15/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0916 - accuracy: 0.9689 - val_loss: 0.3952 - val_accuracy: 0.8351\n","Epoch 16/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0776 - accuracy: 0.9762 - val_loss: 0.3700 - val_accuracy: 0.8501\n","Epoch 17/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0676 - accuracy: 0.9807 - val_loss: 0.3441 - val_accuracy: 0.8469\n","Epoch 18/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0685 - accuracy: 0.9812 - val_loss: 0.3350 - val_accuracy: 0.8576\n","Epoch 19/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0684 - accuracy: 0.9788 - val_loss: 0.3268 - val_accuracy: 0.8608\n","Epoch 20/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0799 - accuracy: 0.9735 - val_loss: 0.3368 - val_accuracy: 0.8694\n","Epoch 21/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0690 - accuracy: 0.9788 - val_loss: 0.3284 - val_accuracy: 0.8790\n","Epoch 22/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0665 - accuracy: 0.9823 - val_loss: 0.3582 - val_accuracy: 0.8726\n","Epoch 23/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0714 - accuracy: 0.9764 - val_loss: 0.3209 - val_accuracy: 0.8865\n","Epoch 24/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0691 - accuracy: 0.9783 - val_loss: 0.3882 - val_accuracy: 0.8662\n","Epoch 25/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0935 - accuracy: 0.9679 - val_loss: 0.3722 - val_accuracy: 0.8790\n","Epoch 26/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0749 - accuracy: 0.9735 - val_loss: 0.3403 - val_accuracy: 0.8844\n","Epoch 27/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0656 - accuracy: 0.9804 - val_loss: 0.3322 - val_accuracy: 0.8972\n","Epoch 28/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0640 - accuracy: 0.9796 - val_loss: 0.3421 - val_accuracy: 0.8919\n","Epoch 29/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0631 - accuracy: 0.9796 - val_loss: 0.3330 - val_accuracy: 0.8908\n","Epoch 30/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0572 - accuracy: 0.9855 - val_loss: 0.3951 - val_accuracy: 0.8833\n","Epoch 31/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0580 - accuracy: 0.9837 - val_loss: 0.3926 - val_accuracy: 0.8812\n","Epoch 32/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0627 - accuracy: 0.9791 - val_loss: 0.4003 - val_accuracy: 0.8801\n","Epoch 33/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0634 - accuracy: 0.9815 - val_loss: 0.3846 - val_accuracy: 0.8876\n","Epoch 34/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0562 - accuracy: 0.9839 - val_loss: 0.3633 - val_accuracy: 0.8940\n","Epoch 35/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0556 - accuracy: 0.9823 - val_loss: 0.3558 - val_accuracy: 0.8876\n","Epoch 36/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0578 - accuracy: 0.9821 - val_loss: 0.3892 - val_accuracy: 0.8854\n","Epoch 37/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0556 - accuracy: 0.9826 - val_loss: 0.3644 - val_accuracy: 0.8929\n","Epoch 38/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0494 - accuracy: 0.9861 - val_loss: 0.3850 - val_accuracy: 0.8887\n","Epoch 39/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0544 - accuracy: 0.9839 - val_loss: 0.3737 - val_accuracy: 0.8908\n","Epoch 40/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0573 - accuracy: 0.9807 - val_loss: 0.3874 - val_accuracy: 0.8951\n","Epoch 41/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0493 - accuracy: 0.9861 - val_loss: 0.3775 - val_accuracy: 0.8801\n","Epoch 42/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0508 - accuracy: 0.9855 - val_loss: 0.3776 - val_accuracy: 0.8854\n","Epoch 43/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0489 - accuracy: 0.9863 - val_loss: 0.3876 - val_accuracy: 0.8908\n","Epoch 44/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0568 - accuracy: 0.9826 - val_loss: 0.4519 - val_accuracy: 0.8822\n","Epoch 45/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0553 - accuracy: 0.9815 - val_loss: 0.5098 - val_accuracy: 0.8694\n","Epoch 46/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0779 - accuracy: 0.9732 - val_loss: 0.3915 - val_accuracy: 0.8876\n","Epoch 47/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0466 - accuracy: 0.9877 - val_loss: 0.3796 - val_accuracy: 0.8940\n","Epoch 48/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0461 - accuracy: 0.9871 - val_loss: 0.3866 - val_accuracy: 0.8876\n","Epoch 49/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0431 - accuracy: 0.9877 - val_loss: 0.3983 - val_accuracy: 0.8929\n","Epoch 50/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0432 - accuracy: 0.9887 - val_loss: 0.4173 - val_accuracy: 0.8887\n","Epoch 51/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0463 - accuracy: 0.9861 - val_loss: 0.4018 - val_accuracy: 0.8887\n","Epoch 52/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0472 - accuracy: 0.9863 - val_loss: 0.3928 - val_accuracy: 0.8844\n","Epoch 53/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0449 - accuracy: 0.9885 - val_loss: 0.3970 - val_accuracy: 0.8908\n","Epoch 54/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0401 - accuracy: 0.9887 - val_loss: 0.4101 - val_accuracy: 0.8865\n","Epoch 55/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0471 - accuracy: 0.9874 - val_loss: 0.4027 - val_accuracy: 0.8897\n","Epoch 56/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0378 - accuracy: 0.9914 - val_loss: 0.4443 - val_accuracy: 0.8854\n","Epoch 57/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0446 - accuracy: 0.9869 - val_loss: 0.4473 - val_accuracy: 0.8833\n","Epoch 58/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0430 - accuracy: 0.9882 - val_loss: 0.5532 - val_accuracy: 0.8694\n","Epoch 59/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0530 - accuracy: 0.9823 - val_loss: 0.4137 - val_accuracy: 0.8940\n","Epoch 60/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0516 - accuracy: 0.9850 - val_loss: 0.5374 - val_accuracy: 0.8522\n","Epoch 61/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0536 - accuracy: 0.9810 - val_loss: 0.4172 - val_accuracy: 0.8876\n","Epoch 62/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0454 - accuracy: 0.9871 - val_loss: 0.4810 - val_accuracy: 0.8822\n","Epoch 63/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0441 - accuracy: 0.9877 - val_loss: 0.4341 - val_accuracy: 0.8854\n","Epoch 64/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0582 - accuracy: 0.9799 - val_loss: 0.4739 - val_accuracy: 0.8747\n","Epoch 65/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0443 - accuracy: 0.9871 - val_loss: 0.4253 - val_accuracy: 0.8887\n","Epoch 66/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0361 - accuracy: 0.9901 - val_loss: 0.4497 - val_accuracy: 0.8833\n","Epoch 67/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0441 - accuracy: 0.9863 - val_loss: 0.4398 - val_accuracy: 0.8854\n","Epoch 68/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0378 - accuracy: 0.9896 - val_loss: 0.4326 - val_accuracy: 0.8844\n","Epoch 69/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.0366 - accuracy: 0.9890 - val_loss: 0.4372 - val_accuracy: 0.8865\n","Epoch 70/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0310 - accuracy: 0.9901 - val_loss: 0.5104 - val_accuracy: 0.8812\n","Epoch 71/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0347 - accuracy: 0.9917 - val_loss: 0.4374 - val_accuracy: 0.8865\n","Epoch 72/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0334 - accuracy: 0.9933 - val_loss: 0.4413 - val_accuracy: 0.8919\n","Epoch 73/100\n","30/30 [==============================] - 1s 32ms/step - loss: 0.0321 - accuracy: 0.9914 - val_loss: 0.4429 - val_accuracy: 0.8854\n","Epoch 74/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0306 - accuracy: 0.9922 - val_loss: 0.4577 - val_accuracy: 0.8822\n","Epoch 75/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0319 - accuracy: 0.9922 - val_loss: 0.4606 - val_accuracy: 0.8812\n","Epoch 76/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 0.4575 - val_accuracy: 0.8790\n","Epoch 77/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0342 - accuracy: 0.9914 - val_loss: 0.5326 - val_accuracy: 0.8790\n","Epoch 78/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0357 - accuracy: 0.9917 - val_loss: 0.4562 - val_accuracy: 0.8833\n","Epoch 79/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0348 - accuracy: 0.9904 - val_loss: 0.4908 - val_accuracy: 0.8683\n","Epoch 80/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0301 - accuracy: 0.9920 - val_loss: 0.4422 - val_accuracy: 0.8908\n","Epoch 81/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0283 - accuracy: 0.9933 - val_loss: 0.4779 - val_accuracy: 0.8822\n","Epoch 82/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0346 - accuracy: 0.9912 - val_loss: 0.4509 - val_accuracy: 0.8854\n","Epoch 83/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0327 - accuracy: 0.9914 - val_loss: 0.4755 - val_accuracy: 0.8854\n","Epoch 84/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0343 - accuracy: 0.9893 - val_loss: 0.4685 - val_accuracy: 0.8854\n","Epoch 85/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0285 - accuracy: 0.9941 - val_loss: 0.4582 - val_accuracy: 0.8876\n","Epoch 86/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0342 - accuracy: 0.9901 - val_loss: 0.4992 - val_accuracy: 0.8812\n","Epoch 87/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0296 - accuracy: 0.9946 - val_loss: 0.4702 - val_accuracy: 0.8854\n","Epoch 88/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0348 - accuracy: 0.9909 - val_loss: 0.4696 - val_accuracy: 0.8833\n","Epoch 89/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0281 - accuracy: 0.9936 - val_loss: 0.5773 - val_accuracy: 0.8726\n","Epoch 90/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0314 - accuracy: 0.9912 - val_loss: 0.4661 - val_accuracy: 0.8876\n","Epoch 91/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0320 - accuracy: 0.9922 - val_loss: 0.5482 - val_accuracy: 0.8662\n","Epoch 92/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0420 - accuracy: 0.9885 - val_loss: 0.4479 - val_accuracy: 0.8854\n","Epoch 93/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0295 - accuracy: 0.9928 - val_loss: 0.4701 - val_accuracy: 0.8844\n","Epoch 94/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0278 - accuracy: 0.9938 - val_loss: 0.4915 - val_accuracy: 0.8726\n","Epoch 95/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0534 - accuracy: 0.9837 - val_loss: 0.5794 - val_accuracy: 0.8833\n","Epoch 96/100\n","30/30 [==============================] - 1s 32ms/step - loss: 0.0418 - accuracy: 0.9869 - val_loss: 0.4697 - val_accuracy: 0.8801\n","Epoch 97/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0296 - accuracy: 0.9920 - val_loss: 0.4976 - val_accuracy: 0.8812\n","Epoch 98/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0268 - accuracy: 0.9944 - val_loss: 0.5368 - val_accuracy: 0.8801\n","Epoch 99/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0378 - accuracy: 0.9887 - val_loss: 0.5146 - val_accuracy: 0.8758\n","Epoch 100/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0349 - accuracy: 0.9887 - val_loss: 0.5148 - val_accuracy: 0.8801\n","{'loss': [0.1425529271364212, 0.12160339951515198, 0.10605117678642273, 0.10345160961151123, 0.0923038050532341, 0.09397175908088684, 0.09005828201770782, 0.0842735692858696, 0.08481144160032272, 0.08882372826337814, 0.08444694429636002, 0.07687440514564514, 0.08024217188358307, 0.09352989494800568, 0.09162020683288574, 0.077603280544281, 0.06759044528007507, 0.06852316856384277, 0.06844408810138702, 0.0798630490899086, 0.06900620460510254, 0.06647732853889465, 0.07140045613050461, 0.06912913173437119, 0.0934743657708168, 0.07491890341043472, 0.06559529900550842, 0.06395271420478821, 0.06307985633611679, 0.05719359964132309, 0.05799465626478195, 0.06273984163999557, 0.06338837742805481, 0.056213438510894775, 0.055611878633499146, 0.05777779594063759, 0.05562613159418106, 0.0493583120405674, 0.054444193840026855, 0.057254765182733536, 0.049338240176439285, 0.050756651908159256, 0.04894489794969559, 0.05677073821425438, 0.05527794361114502, 0.07786855101585388, 0.0466030016541481, 0.046143870800733566, 0.04312606900930405, 0.04319678992033005, 0.0463026724755764, 0.047249600291252136, 0.04488725587725639, 0.04012292996048927, 0.04710609093308449, 0.03776673227548599, 0.04463972896337509, 0.04299174249172211, 0.052958231419324875, 0.05164672061800957, 0.05356588587164879, 0.04538870230317116, 0.044070784002542496, 0.05817756429314613, 0.04434766620397568, 0.03614826872944832, 0.04409755766391754, 0.03779185190796852, 0.03655949980020523, 0.031013263389468193, 0.034687358886003494, 0.03341865539550781, 0.032126449048519135, 0.030626151710748672, 0.03187412768602371, 0.03361509367823601, 0.03417795151472092, 0.03573502600193024, 0.034773703664541245, 0.03014294244349003, 0.028259124606847763, 0.03455972298979759, 0.03265029564499855, 0.03433075174689293, 0.028469229117035866, 0.03418055549263954, 0.02959577925503254, 0.034818124026060104, 0.02808736078441143, 0.031406011432409286, 0.0319884717464447, 0.041984617710113525, 0.029475264251232147, 0.027795396745204926, 0.05338379368185997, 0.04178391024470329, 0.029576079919934273, 0.026831675320863724, 0.037755876779556274, 0.03490988165140152], 'accuracy': [0.9523171782493591, 0.9566032886505127, 0.9627645611763, 0.9675863981246948, 0.9697294235229492, 0.9737476706504822, 0.9710688591003418, 0.9734797477722168, 0.9710688591003418, 0.9697294235229492, 0.971604585647583, 0.975622832775116, 0.97508704662323, 0.9662469625473022, 0.9689257740974426, 0.9761585593223572, 0.9807125926017761, 0.9812483191490173, 0.9788373708724976, 0.9734797477722168, 0.9788373708724976, 0.9823198318481445, 0.9764264822006226, 0.9783016443252563, 0.9678542613983154, 0.9734797477722168, 0.9804446697235107, 0.9796410202980042, 0.9796410202980042, 0.9855344295501709, 0.9836592674255371, 0.9791052937507629, 0.9815161824226379, 0.9839271306991577, 0.9823198318481445, 0.9820519685745239, 0.9825877547264099, 0.9860701560974121, 0.9839271306991577, 0.9807125926017761, 0.9860701560974121, 0.9855344295501709, 0.9863380789756775, 0.9825877547264099, 0.9815161824226379, 0.9732118844985962, 0.9876774549484253, 0.9871417284011841, 0.9876774549484253, 0.9887489676475525, 0.9860701560974121, 0.9863380789756775, 0.9884811043739319, 0.9887489676475525, 0.9874095916748047, 0.9914277791976929, 0.9868738055229187, 0.9882132411003113, 0.9823198318481445, 0.9849986433982849, 0.9809804558753967, 0.9871417284011841, 0.9876774549484253, 0.9799089431762695, 0.9871417284011841, 0.9900884032249451, 0.9863380789756775, 0.9895526170730591, 0.9890168905258179, 0.9900884032249451, 0.9916957020759583, 0.9933030009269714, 0.9914277791976929, 0.9922314286231995, 0.9922314286231995, 0.9890168905258179, 0.9914277791976929, 0.9916957020759583, 0.9903562664985657, 0.9919635653495789, 0.9933030009269714, 0.9911599159240723, 0.9914277791976929, 0.9892847537994385, 0.9941065907478333, 0.9900884032249451, 0.9946423768997192, 0.9908920526504517, 0.993570864200592, 0.9911599159240723, 0.9922314286231995, 0.9884811043739319, 0.9927672147750854, 0.9938387274742126, 0.9836592674255371, 0.9868738055229187, 0.9919635653495789, 0.9943745136260986, 0.9887489676475525, 0.9887489676475525], 'val_loss': [0.6541314721107483, 0.6468631625175476, 0.6414716243743896, 0.631144106388092, 0.6219054460525513, 0.6085475087165833, 0.5945791602134705, 0.5755956768989563, 0.5549034476280212, 0.5342637300491333, 0.5087088942527771, 0.48226842284202576, 0.4503355920314789, 0.42558911442756653, 0.39522191882133484, 0.3700147569179535, 0.3440921902656555, 0.3349856734275818, 0.3268021047115326, 0.33678069710731506, 0.328433096408844, 0.35820597410202026, 0.32094940543174744, 0.3881504535675049, 0.3722303509712219, 0.34028360247612, 0.33219873905181885, 0.3421266973018646, 0.33302929997444153, 0.39508676528930664, 0.3925663232803345, 0.4002716839313507, 0.38460561633110046, 0.3633459210395813, 0.35578617453575134, 0.3892119526863098, 0.3644091486930847, 0.38500526547431946, 0.37365487217903137, 0.38735514879226685, 0.37746572494506836, 0.3775594234466553, 0.3875562250614166, 0.4519023001194, 0.5097569227218628, 0.3914950489997864, 0.37962251901626587, 0.3866291046142578, 0.3983033299446106, 0.41727563738822937, 0.4018220901489258, 0.39276450872421265, 0.39695125818252563, 0.41009044647216797, 0.40274226665496826, 0.4443031847476959, 0.44727131724357605, 0.5532263517379761, 0.41369935870170593, 0.5374026298522949, 0.4172064960002899, 0.4810370206832886, 0.4340746998786926, 0.4739043414592743, 0.42531219124794006, 0.44973641633987427, 0.4397751986980438, 0.432551771402359, 0.4372395873069763, 0.5104050040245056, 0.43743014335632324, 0.44132307171821594, 0.4429359436035156, 0.4576961100101471, 0.46062445640563965, 0.4575140178203583, 0.5326160788536072, 0.456228643655777, 0.49079635739326477, 0.4422171413898468, 0.4779147207736969, 0.45085588097572327, 0.4754849374294281, 0.4685122072696686, 0.45823508501052856, 0.4992061257362366, 0.47022515535354614, 0.46958109736442566, 0.5772911310195923, 0.4660704433917999, 0.5482085347175598, 0.44793397188186646, 0.4700511693954468, 0.4914971590042114, 0.5793740749359131, 0.4696798324584961, 0.49763163924217224, 0.5368465781211853, 0.5146123170852661, 0.5148239135742188], 'val_accuracy': [0.759100615978241, 0.8104925155639648, 0.819057822227478, 0.824411153793335, 0.8211991190910339, 0.8137044906616211, 0.8233404755592346, 0.8137044906616211, 0.8276231288909912, 0.8276231288909912, 0.824411153793335, 0.8319057822227478, 0.8308351039886475, 0.8319057822227478, 0.835117757320404, 0.8501070737838745, 0.8468950986862183, 0.8576017022132874, 0.8608136773109436, 0.8693790435791016, 0.8790149688720703, 0.8725910186767578, 0.8865096569061279, 0.8661670088768005, 0.8790149688720703, 0.8843683004379272, 0.897216260433197, 0.8918629288673401, 0.8907923102378845, 0.8832976222038269, 0.881156325340271, 0.8800856471061707, 0.8875802755355835, 0.8940042853355408, 0.8875802755355835, 0.8854389786720276, 0.8929336071014404, 0.8886509537696838, 0.8907923102378845, 0.8950749635696411, 0.8800856471061707, 0.8854389786720276, 0.8907923102378845, 0.8822270035743713, 0.8693790435791016, 0.8875802755355835, 0.8940042853355408, 0.8875802755355835, 0.8929336071014404, 0.8886509537696838, 0.8886509537696838, 0.8843683004379272, 0.8907923102378845, 0.8865096569061279, 0.8897216320037842, 0.8854389786720276, 0.8832976222038269, 0.8693790435791016, 0.8940042853355408, 0.8522483706474304, 0.8875802755355835, 0.8822270035743713, 0.8854389786720276, 0.8747323155403137, 0.8886509537696838, 0.8832976222038269, 0.8854389786720276, 0.8843683004379272, 0.8865096569061279, 0.881156325340271, 0.8865096569061279, 0.8918629288673401, 0.8854389786720276, 0.8822270035743713, 0.881156325340271, 0.8790149688720703, 0.8790149688720703, 0.8832976222038269, 0.8683083653450012, 0.8907923102378845, 0.8822270035743713, 0.8854389786720276, 0.8854389786720276, 0.8854389786720276, 0.8875802755355835, 0.881156325340271, 0.8854389786720276, 0.8832976222038269, 0.8725910186767578, 0.8875802755355835, 0.8661670088768005, 0.8854389786720276, 0.8843683004379272, 0.8725910186767578, 0.8832976222038269, 0.8800856471061707, 0.881156325340271, 0.8800856471061707, 0.8758029937744141, 0.8800856471061707]}\n","37/37 [==============================] - 1s 5ms/step\n"]}]},{"cell_type":"code","source":["\n","metrics_df.round(3)"],"metadata":{"id":"Ik5JoVP2NPvY","executionInfo":{"status":"ok","timestamp":1716482939588,"user_tz":-360,"elapsed":1538,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"colab":{"base_uri":"https://localhost:8080/","height":459},"outputId":"bafc3b04-8879-4d5a-e665-54fb1ed3050f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.813      0.865   0.744  0.800        0.744        0.883   \n","1        1     0.792      0.804   0.778  0.790        0.778        0.806   \n","2        2     0.805      0.813   0.795  0.803        0.795        0.816   \n","3        0     0.833      0.871   0.784  0.825        0.784        0.883   \n","4        1     0.812      0.815   0.813  0.814        0.813        0.811   \n","5        2     0.807      0.891   0.700  0.784        0.700        0.914   \n","6        0     0.812      0.749   0.942  0.835        0.942        0.681   \n","7        1     0.831      0.902   0.747  0.817        0.747        0.917   \n","8        2     0.845      0.822   0.880  0.850        0.880        0.810   \n","9        0     0.845      0.799   0.923  0.857        0.923        0.766   \n","10       1     0.871      0.868   0.879  0.874        0.879        0.863   \n","11       2     0.871      0.864   0.882  0.873        0.882        0.861   \n","12       0     0.901      0.897   0.908  0.903        0.908        0.895   \n","13       1     0.887      0.897   0.876  0.887        0.876        0.898   \n","14       2     0.897      0.926   0.863  0.894        0.863        0.931   \n","\n","    Kappa  \n","0   0.627  \n","1   0.584  \n","2   0.611  \n","3   0.666  \n","4   0.625  \n","5   0.614  \n","6   0.624  \n","7   0.663  \n","8   0.690  \n","9   0.690  \n","10  0.743  \n","11  0.743  \n","12  0.803  \n","13  0.774  \n","14  0.794  "],"text/html":["\n","  <div id=\"df-38d99554-cb2b-408d-941f-adc7937a5288\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.813</td>\n","      <td>0.865</td>\n","      <td>0.744</td>\n","      <td>0.800</td>\n","      <td>0.744</td>\n","      <td>0.883</td>\n","      <td>0.627</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.792</td>\n","      <td>0.804</td>\n","      <td>0.778</td>\n","      <td>0.790</td>\n","      <td>0.778</td>\n","      <td>0.806</td>\n","      <td>0.584</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.805</td>\n","      <td>0.813</td>\n","      <td>0.795</td>\n","      <td>0.803</td>\n","      <td>0.795</td>\n","      <td>0.816</td>\n","      <td>0.611</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.833</td>\n","      <td>0.871</td>\n","      <td>0.784</td>\n","      <td>0.825</td>\n","      <td>0.784</td>\n","      <td>0.883</td>\n","      <td>0.666</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.812</td>\n","      <td>0.815</td>\n","      <td>0.813</td>\n","      <td>0.814</td>\n","      <td>0.813</td>\n","      <td>0.811</td>\n","      <td>0.625</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.807</td>\n","      <td>0.891</td>\n","      <td>0.700</td>\n","      <td>0.784</td>\n","      <td>0.700</td>\n","      <td>0.914</td>\n","      <td>0.614</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.812</td>\n","      <td>0.749</td>\n","      <td>0.942</td>\n","      <td>0.835</td>\n","      <td>0.942</td>\n","      <td>0.681</td>\n","      <td>0.624</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.831</td>\n","      <td>0.902</td>\n","      <td>0.747</td>\n","      <td>0.817</td>\n","      <td>0.747</td>\n","      <td>0.917</td>\n","      <td>0.663</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.845</td>\n","      <td>0.822</td>\n","      <td>0.880</td>\n","      <td>0.850</td>\n","      <td>0.880</td>\n","      <td>0.810</td>\n","      <td>0.690</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.845</td>\n","      <td>0.799</td>\n","      <td>0.923</td>\n","      <td>0.857</td>\n","      <td>0.923</td>\n","      <td>0.766</td>\n","      <td>0.690</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.871</td>\n","      <td>0.868</td>\n","      <td>0.879</td>\n","      <td>0.874</td>\n","      <td>0.879</td>\n","      <td>0.863</td>\n","      <td>0.743</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.871</td>\n","      <td>0.864</td>\n","      <td>0.882</td>\n","      <td>0.873</td>\n","      <td>0.882</td>\n","      <td>0.861</td>\n","      <td>0.743</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.901</td>\n","      <td>0.897</td>\n","      <td>0.908</td>\n","      <td>0.903</td>\n","      <td>0.908</td>\n","      <td>0.895</td>\n","      <td>0.803</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.887</td>\n","      <td>0.897</td>\n","      <td>0.876</td>\n","      <td>0.887</td>\n","      <td>0.876</td>\n","      <td>0.898</td>\n","      <td>0.774</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.897</td>\n","      <td>0.926</td>\n","      <td>0.863</td>\n","      <td>0.894</td>\n","      <td>0.863</td>\n","      <td>0.931</td>\n","      <td>0.794</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38d99554-cb2b-408d-941f-adc7937a5288')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-38d99554-cb2b-408d-941f-adc7937a5288 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-38d99554-cb2b-408d-941f-adc7937a5288');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-612d057b-d203-4268-81a2-565b91c0d80c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-612d057b-d203-4268-81a2-565b91c0d80c')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-612d057b-d203-4268-81a2-565b91c0d80c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03601957139958113,\n        \"min\": 0.792,\n        \"max\": 0.901,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.887,\n          0.901,\n          0.813\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04927213063327846,\n        \"min\": 0.749,\n        \"max\": 0.926,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.799,\n          0.864,\n          0.865\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07335478041357503,\n        \"min\": 0.7,\n        \"max\": 0.942,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.923,\n          0.882,\n          0.744\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03944761444896618,\n        \"min\": 0.784,\n        \"max\": 0.903,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.857,\n          0.873,\n          0.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07335478041357503,\n        \"min\": 0.7,\n        \"max\": 0.942,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.923,\n          0.882,\n          0.744\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06748438972935042,\n        \"min\": 0.681,\n        \"max\": 0.931,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.863,\n          0.895,\n          0.883\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07206822164746798,\n        \"min\": 0.584,\n        \"max\": 0.803,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.774,\n          0.743,\n          0.627\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["# Time-domain"],"metadata":{"id":"QUuWzfMHSNmi"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split,KFold,StratifiedKFold\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM,Dropout, GRU\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from keras.optimizers import RMSprop, Adam\n","# from wandb.keras import WandbCallback\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', k_folds=5, stratified=False):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.k_folds = k_folds\n","        self.stratified = stratified\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle= True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        X = scaled_data_reshaped.reshape(self.X.shape)\n","        np.moveaxis(X, 1, 2)\n","        self.X = X\n","\n","    def create_partitions(self):\n","        if self.stratified:\n","            kf = StratifiedKFold(n_splits=self.k_folds, shuffle=True, random_state=42)\n","        else:\n","            kf = KFold(n_splits=self.k_folds, shuffle=True, random_state=42)\n","\n","        for train_index, test_index in kf.split(self.X, self.Y):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(LSTM(256, return_sequences=True))\n","    model.add(LSTM(256, return_sequences=True))\n","        # GRU layers\n","    # model.add(GRU(256, return_sequences=True))\n","    # model.add(GRU(128, return_sequences=False))\n","\n","    model.add(Flatten())\n","    # model.add(Dense(1024, activation='relu'))\n","    # model.add(Dense(512, activation='relu'))\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dense(32, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Evaluate client model\n","            y_pred = (client_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"8xrx_fxBSWGd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["global_model, metrics_df = federated_learning(Time_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H1TaNdIbSfkq","executionInfo":{"status":"ok","timestamp":1716484994401,"user_tz":-360,"elapsed":106311,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"a99a3f08-8b8e-4ded-b46a-840fb3c159d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4667, 18, 29), Test shape: (1167, 18, 29)\n","Train shape: (4667, 18, 29), Test shape: (1167, 18, 29)\n","Train shape: (4667, 18, 29), Test shape: (1167, 18, 29)\n","Train shape: (4667, 18, 29), Test shape: (1167, 18, 29)\n","Train shape: (4668, 18, 29), Test shape: (1166, 18, 29)\n","Train shape: (4667, 18, 29), Test shape: (1167, 18, 29)\n","Train shape: (4667, 18, 29), Test shape: (1167, 18, 29)\n","Train shape: (4667, 18, 29), Test shape: (1167, 18, 29)\n","Train shape: (4667, 18, 29), Test shape: (1167, 18, 29)\n","Train shape: (4668, 18, 29), Test shape: (1166, 18, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 10s 57ms/step - loss: 0.6929 - accuracy: 0.5475 - val_loss: 0.6931 - val_accuracy: 0.5953\n","Epoch 2/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.6918 - accuracy: 0.6325 - val_loss: 0.6930 - val_accuracy: 0.6831\n","Epoch 3/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.6889 - accuracy: 0.6831 - val_loss: 0.6926 - val_accuracy: 0.6103\n","Epoch 4/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.6830 - accuracy: 0.6901 - val_loss: 0.6918 - val_accuracy: 0.6253\n","Epoch 5/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.6716 - accuracy: 0.7032 - val_loss: 0.6901 - val_accuracy: 0.6039\n","Epoch 6/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.6528 - accuracy: 0.7056 - val_loss: 0.6862 - val_accuracy: 0.6756\n","Epoch 7/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.6264 - accuracy: 0.7099 - val_loss: 0.6799 - val_accuracy: 0.6906\n","Epoch 8/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.6005 - accuracy: 0.7126 - val_loss: 0.6705 - val_accuracy: 0.6938\n","Epoch 9/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.5746 - accuracy: 0.7246 - val_loss: 0.6602 - val_accuracy: 0.7099\n","Epoch 10/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.5556 - accuracy: 0.7340 - val_loss: 0.6471 - val_accuracy: 0.7195\n","Epoch 11/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.5388 - accuracy: 0.7377 - val_loss: 0.6345 - val_accuracy: 0.7206\n","Epoch 12/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.5305 - accuracy: 0.7434 - val_loss: 0.6205 - val_accuracy: 0.7409\n","Epoch 13/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.5237 - accuracy: 0.7527 - val_loss: 0.6053 - val_accuracy: 0.7323\n","Epoch 14/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.5050 - accuracy: 0.7578 - val_loss: 0.5874 - val_accuracy: 0.7355\n","Epoch 15/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4954 - accuracy: 0.7656 - val_loss: 0.5719 - val_accuracy: 0.7420\n","Epoch 16/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4861 - accuracy: 0.7710 - val_loss: 0.5613 - val_accuracy: 0.7323\n","Epoch 17/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.4833 - accuracy: 0.7766 - val_loss: 0.5300 - val_accuracy: 0.7505\n","Epoch 18/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4775 - accuracy: 0.7720 - val_loss: 0.5445 - val_accuracy: 0.7302\n","Epoch 19/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4691 - accuracy: 0.7827 - val_loss: 0.5107 - val_accuracy: 0.7527\n","Epoch 20/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4665 - accuracy: 0.7854 - val_loss: 0.5004 - val_accuracy: 0.7612\n","Epoch 21/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4563 - accuracy: 0.7900 - val_loss: 0.5069 - val_accuracy: 0.7548\n","Epoch 22/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4603 - accuracy: 0.7876 - val_loss: 0.5252 - val_accuracy: 0.7516\n","Epoch 23/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4557 - accuracy: 0.7892 - val_loss: 0.5055 - val_accuracy: 0.7602\n","Epoch 24/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4533 - accuracy: 0.7905 - val_loss: 0.4892 - val_accuracy: 0.7677\n","Epoch 25/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.4476 - accuracy: 0.7975 - val_loss: 0.4970 - val_accuracy: 0.7677\n","Epoch 26/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4481 - accuracy: 0.7969 - val_loss: 0.5008 - val_accuracy: 0.7677\n","Epoch 27/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4454 - accuracy: 0.7943 - val_loss: 0.4946 - val_accuracy: 0.7687\n","Epoch 28/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.4431 - accuracy: 0.8028 - val_loss: 0.4920 - val_accuracy: 0.7709\n","Epoch 29/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4405 - accuracy: 0.7988 - val_loss: 0.5042 - val_accuracy: 0.7698\n","Epoch 30/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4407 - accuracy: 0.8004 - val_loss: 0.4901 - val_accuracy: 0.7698\n","Epoch 31/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4390 - accuracy: 0.8004 - val_loss: 0.4907 - val_accuracy: 0.7752\n","Epoch 32/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4344 - accuracy: 0.8055 - val_loss: 0.4958 - val_accuracy: 0.7709\n","Epoch 33/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4316 - accuracy: 0.8071 - val_loss: 0.4953 - val_accuracy: 0.7730\n","Epoch 34/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4253 - accuracy: 0.8149 - val_loss: 0.4940 - val_accuracy: 0.7741\n","Epoch 35/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4294 - accuracy: 0.8002 - val_loss: 0.4917 - val_accuracy: 0.7762\n","Epoch 36/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4246 - accuracy: 0.8090 - val_loss: 0.4932 - val_accuracy: 0.7709\n","Epoch 37/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4178 - accuracy: 0.8184 - val_loss: 0.4913 - val_accuracy: 0.7730\n","Epoch 38/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4222 - accuracy: 0.8117 - val_loss: 0.4957 - val_accuracy: 0.7698\n","Epoch 39/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4239 - accuracy: 0.8111 - val_loss: 0.4914 - val_accuracy: 0.7719\n","Epoch 40/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.4205 - accuracy: 0.8077 - val_loss: 0.4962 - val_accuracy: 0.7837\n","Epoch 41/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4152 - accuracy: 0.8114 - val_loss: 0.4933 - val_accuracy: 0.7805\n","Epoch 42/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4138 - accuracy: 0.8162 - val_loss: 0.4913 - val_accuracy: 0.7773\n","Epoch 43/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4142 - accuracy: 0.8160 - val_loss: 0.4925 - val_accuracy: 0.7719\n","Epoch 44/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4085 - accuracy: 0.8144 - val_loss: 0.4945 - val_accuracy: 0.7741\n","Epoch 45/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.4083 - accuracy: 0.8168 - val_loss: 0.4873 - val_accuracy: 0.7773\n","Epoch 46/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4116 - accuracy: 0.8227 - val_loss: 0.4884 - val_accuracy: 0.7794\n","Epoch 47/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4079 - accuracy: 0.8240 - val_loss: 0.4828 - val_accuracy: 0.7794\n","Epoch 48/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4033 - accuracy: 0.8237 - val_loss: 0.4852 - val_accuracy: 0.7784\n","Epoch 49/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4018 - accuracy: 0.8278 - val_loss: 0.4852 - val_accuracy: 0.7730\n","Epoch 50/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4009 - accuracy: 0.8221 - val_loss: 0.4832 - val_accuracy: 0.7837\n","Epoch 51/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3913 - accuracy: 0.8294 - val_loss: 0.4904 - val_accuracy: 0.7730\n","Epoch 52/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3954 - accuracy: 0.8248 - val_loss: 0.4897 - val_accuracy: 0.7912\n","Epoch 53/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3990 - accuracy: 0.8200 - val_loss: 0.4844 - val_accuracy: 0.7816\n","Epoch 54/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3959 - accuracy: 0.8261 - val_loss: 0.4884 - val_accuracy: 0.7912\n","Epoch 55/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3934 - accuracy: 0.8261 - val_loss: 0.4859 - val_accuracy: 0.7773\n","Epoch 56/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3864 - accuracy: 0.8315 - val_loss: 0.4809 - val_accuracy: 0.7805\n","Epoch 57/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3890 - accuracy: 0.8310 - val_loss: 0.4995 - val_accuracy: 0.7912\n","Epoch 58/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3928 - accuracy: 0.8310 - val_loss: 0.4813 - val_accuracy: 0.7891\n","Epoch 59/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3906 - accuracy: 0.8296 - val_loss: 0.4805 - val_accuracy: 0.7794\n","Epoch 60/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3859 - accuracy: 0.8334 - val_loss: 0.4764 - val_accuracy: 0.7794\n","Epoch 61/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3804 - accuracy: 0.8334 - val_loss: 0.4771 - val_accuracy: 0.7837\n","Epoch 62/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3784 - accuracy: 0.8361 - val_loss: 0.4825 - val_accuracy: 0.7805\n","Epoch 63/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3764 - accuracy: 0.8371 - val_loss: 0.4878 - val_accuracy: 0.7923\n","Epoch 64/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3794 - accuracy: 0.8366 - val_loss: 0.4788 - val_accuracy: 0.7891\n","Epoch 65/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3772 - accuracy: 0.8347 - val_loss: 0.4868 - val_accuracy: 0.7934\n","Epoch 66/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3761 - accuracy: 0.8366 - val_loss: 0.4751 - val_accuracy: 0.7912\n","Epoch 67/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3782 - accuracy: 0.8344 - val_loss: 0.4724 - val_accuracy: 0.7901\n","Epoch 68/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3772 - accuracy: 0.8382 - val_loss: 0.4792 - val_accuracy: 0.7837\n","Epoch 69/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3701 - accuracy: 0.8420 - val_loss: 0.4773 - val_accuracy: 0.7901\n","Epoch 70/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3704 - accuracy: 0.8361 - val_loss: 0.4829 - val_accuracy: 0.7955\n","Epoch 71/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3713 - accuracy: 0.8393 - val_loss: 0.4745 - val_accuracy: 0.7955\n","Epoch 72/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3692 - accuracy: 0.8441 - val_loss: 0.4757 - val_accuracy: 0.7912\n","Epoch 73/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3682 - accuracy: 0.8430 - val_loss: 0.4906 - val_accuracy: 0.7816\n","Epoch 74/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3714 - accuracy: 0.8377 - val_loss: 0.4728 - val_accuracy: 0.7966\n","Epoch 75/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3596 - accuracy: 0.8438 - val_loss: 0.4700 - val_accuracy: 0.7923\n","Epoch 76/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3596 - accuracy: 0.8473 - val_loss: 0.4672 - val_accuracy: 0.7944\n","Epoch 77/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3564 - accuracy: 0.8497 - val_loss: 0.4748 - val_accuracy: 0.7966\n","Epoch 78/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3570 - accuracy: 0.8495 - val_loss: 0.4644 - val_accuracy: 0.7966\n","Epoch 79/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.3500 - accuracy: 0.8511 - val_loss: 0.4744 - val_accuracy: 0.7987\n","Epoch 80/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3551 - accuracy: 0.8457 - val_loss: 0.4724 - val_accuracy: 0.7955\n","Epoch 81/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.3523 - accuracy: 0.8513 - val_loss: 0.4843 - val_accuracy: 0.7998\n","Epoch 82/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3504 - accuracy: 0.8452 - val_loss: 0.4681 - val_accuracy: 0.7966\n","Epoch 83/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3517 - accuracy: 0.8543 - val_loss: 0.4689 - val_accuracy: 0.8009\n","Epoch 84/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3525 - accuracy: 0.8516 - val_loss: 0.4748 - val_accuracy: 0.7944\n","Epoch 85/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3488 - accuracy: 0.8535 - val_loss: 0.4683 - val_accuracy: 0.8041\n","Epoch 86/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3437 - accuracy: 0.8553 - val_loss: 0.4732 - val_accuracy: 0.8030\n","Epoch 87/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3474 - accuracy: 0.8548 - val_loss: 0.5046 - val_accuracy: 0.7869\n","Epoch 88/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3528 - accuracy: 0.8505 - val_loss: 0.4769 - val_accuracy: 0.7955\n","Epoch 89/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3447 - accuracy: 0.8588 - val_loss: 0.4709 - val_accuracy: 0.8019\n","Epoch 90/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3361 - accuracy: 0.8655 - val_loss: 0.4692 - val_accuracy: 0.8030\n","Epoch 91/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3401 - accuracy: 0.8578 - val_loss: 0.4736 - val_accuracy: 0.8019\n","Epoch 92/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3484 - accuracy: 0.8529 - val_loss: 0.4923 - val_accuracy: 0.7944\n","Epoch 93/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3434 - accuracy: 0.8588 - val_loss: 0.4636 - val_accuracy: 0.8084\n","Epoch 94/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3349 - accuracy: 0.8599 - val_loss: 0.4715 - val_accuracy: 0.8030\n","Epoch 95/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3437 - accuracy: 0.8540 - val_loss: 0.4623 - val_accuracy: 0.8030\n","Epoch 96/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3291 - accuracy: 0.8650 - val_loss: 0.4687 - val_accuracy: 0.8041\n","Epoch 97/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3247 - accuracy: 0.8674 - val_loss: 0.4713 - val_accuracy: 0.8041\n","Epoch 98/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3226 - accuracy: 0.8687 - val_loss: 0.4640 - val_accuracy: 0.8137\n","Epoch 99/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3267 - accuracy: 0.8682 - val_loss: 0.4686 - val_accuracy: 0.8084\n","Epoch 100/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3264 - accuracy: 0.8607 - val_loss: 0.4688 - val_accuracy: 0.8073\n","{'loss': [0.6928682923316956, 0.6917954087257385, 0.6888549327850342, 0.6829521059989929, 0.6715694069862366, 0.6528223156929016, 0.6264487504959106, 0.6004654169082642, 0.5746394991874695, 0.5556073784828186, 0.5387857556343079, 0.5304739475250244, 0.5236829519271851, 0.5050045847892761, 0.49538248777389526, 0.4861150085926056, 0.4833241403102875, 0.4774753749370575, 0.46914270520210266, 0.4664941430091858, 0.4562875032424927, 0.4603061079978943, 0.45570892095565796, 0.4532766044139862, 0.4476240277290344, 0.4481109082698822, 0.44544902443885803, 0.44311073422431946, 0.4404548704624176, 0.44067248702049255, 0.43902960419654846, 0.434374064207077, 0.4316292107105255, 0.42532214522361755, 0.42943617701530457, 0.42458462715148926, 0.4178491532802582, 0.42216792702674866, 0.42392516136169434, 0.4205222427845001, 0.41519275307655334, 0.4137895107269287, 0.4141758382320404, 0.40853986144065857, 0.4083266854286194, 0.4116052985191345, 0.4078713059425354, 0.4032737910747528, 0.40183499455451965, 0.40092402696609497, 0.3913396894931793, 0.39537370204925537, 0.3989793360233307, 0.3958584666252136, 0.3933749198913574, 0.3863559365272522, 0.38897061347961426, 0.3927909731864929, 0.39061760902404785, 0.3859036862850189, 0.3803706765174866, 0.378410667181015, 0.376352995634079, 0.37944531440734863, 0.377163290977478, 0.3760785758495331, 0.37819141149520874, 0.37722310423851013, 0.37013810873031616, 0.37035083770751953, 0.37130504846572876, 0.36923035979270935, 0.3681502044200897, 0.37143486738204956, 0.35957008600234985, 0.35963374376296997, 0.3564174473285675, 0.35703200101852417, 0.35000529885292053, 0.3550751507282257, 0.35225576162338257, 0.3504232168197632, 0.35170844197273254, 0.35248857736587524, 0.3488110303878784, 0.34372031688690186, 0.34742164611816406, 0.3528105914592743, 0.3447021245956421, 0.33610543608665466, 0.34011632204055786, 0.34838631749153137, 0.3434044122695923, 0.3349401652812958, 0.343678742647171, 0.3290739357471466, 0.3246897757053375, 0.3226228952407837, 0.32671067118644714, 0.3263849914073944], 'accuracy': [0.5475488901138306, 0.6324672102928162, 0.683096706867218, 0.690061628818512, 0.7031877636909485, 0.7055987119674683, 0.7098848223686218, 0.7125636339187622, 0.7246182560920715, 0.7339941263198853, 0.7377444505691528, 0.7433699369430542, 0.7527458071708679, 0.7578355073928833, 0.7656040787696838, 0.7709617018699646, 0.776587188243866, 0.7720332145690918, 0.7827484607696533, 0.7854272723197937, 0.7899812459945679, 0.7875702977180481, 0.7891775965690613, 0.7905170321464539, 0.797481894493103, 0.7969461679458618, 0.7942673563957214, 0.8028395175933838, 0.7988213300704956, 0.8004286289215088, 0.8004286289215088, 0.8055183291435242, 0.8071256279945374, 0.8148941993713379, 0.8001607060432434, 0.8090007901191711, 0.8183766603469849, 0.8116796016693115, 0.8111438751220703, 0.8076614141464233, 0.8114117383956909, 0.8162335753440857, 0.8159657120704651, 0.8143584132194519, 0.8167693614959717, 0.8226627111434937, 0.8240021467208862, 0.8237342834472656, 0.8277524709701538, 0.8221269845962524, 0.829359769821167, 0.8248057961463928, 0.8199838995933533, 0.8261451721191406, 0.8261451721191406, 0.8315027952194214, 0.8309670686721802, 0.8309670686721802, 0.8296276330947876, 0.8333779573440552, 0.8333779573440552, 0.8360567688941956, 0.8371283411979675, 0.8365925550460815, 0.8347173929214478, 0.8365925550460815, 0.8344495296478271, 0.8381998538970947, 0.8419501781463623, 0.8360567688941956, 0.8392713665962219, 0.8440932035446167, 0.8430216908454895, 0.8376640677452087, 0.8438253402709961, 0.8473078012466431, 0.8497187495231628, 0.8494508266448975, 0.8510581254959106, 0.8457005023956299, 0.8513259887695312, 0.8451647758483887, 0.854272723197937, 0.8515939116477966, 0.8534690737724304, 0.8553442358970642, 0.8548084497451782, 0.8505223393440247, 0.8588266968727112, 0.8655236959457397, 0.857755184173584, 0.8529332876205444, 0.8588266968727112, 0.8598982095718384, 0.8540048003196716, 0.8649879693984985, 0.8673988580703735, 0.8687382936477661, 0.8682025074958801, 0.860701858997345], 'val_loss': [0.6931130886077881, 0.6929818987846375, 0.692624032497406, 0.6917730569839478, 0.6900636553764343, 0.6862367987632751, 0.6799167990684509, 0.670458972454071, 0.6602075099945068, 0.6470836400985718, 0.6345440745353699, 0.6205414533615112, 0.605262279510498, 0.5873639583587646, 0.5718809366226196, 0.561274528503418, 0.5299712419509888, 0.5444794297218323, 0.5106985569000244, 0.5004015564918518, 0.5069489479064941, 0.52519291639328, 0.5055190324783325, 0.48915597796440125, 0.4969533681869507, 0.5007908344268799, 0.4946279525756836, 0.4920009970664978, 0.5041994452476501, 0.4900699555873871, 0.49070796370506287, 0.49580302834510803, 0.4952774941921234, 0.4939858615398407, 0.4916878938674927, 0.493152916431427, 0.4912986159324646, 0.49565690755844116, 0.4914012551307678, 0.49617111682891846, 0.49332302808761597, 0.4913107454776764, 0.49245673418045044, 0.4944540858268738, 0.4873404800891876, 0.48842182755470276, 0.48279356956481934, 0.4851613938808441, 0.4851682484149933, 0.4831743538379669, 0.4903603196144104, 0.4897006154060364, 0.48438864946365356, 0.488381952047348, 0.485898494720459, 0.48091262578964233, 0.49945440888404846, 0.4812816381454468, 0.4804760813713074, 0.47640201449394226, 0.477070689201355, 0.48250702023506165, 0.48783233761787415, 0.4788379967212677, 0.48680779337882996, 0.4751095473766327, 0.4724043011665344, 0.4791904091835022, 0.4773407578468323, 0.48287445306777954, 0.47447115182876587, 0.4756782352924347, 0.4906159043312073, 0.472773015499115, 0.4700130522251129, 0.46721574664115906, 0.4747638702392578, 0.4644303023815155, 0.47438251972198486, 0.4723905622959137, 0.48428353667259216, 0.4680509567260742, 0.4688725471496582, 0.4748375117778778, 0.4683319926261902, 0.4732113182544708, 0.5045507550239563, 0.47694700956344604, 0.4708840847015381, 0.46918678283691406, 0.47361913323402405, 0.49225878715515137, 0.46359992027282715, 0.47152701020240784, 0.4622650742530823, 0.46874845027923584, 0.4712646007537842, 0.4640205204486847, 0.46856802701950073, 0.4688286781311035], 'val_accuracy': [0.5952890515327454, 0.6830835342407227, 0.6102783679962158, 0.6252676844596863, 0.6038544178009033, 0.675588846206665, 0.6905781626701355, 0.6937901377677917, 0.7098501324653625, 0.7194860577583313, 0.7205567359924316, 0.740899384021759, 0.7323340177536011, 0.7355460524559021, 0.7419700026512146, 0.7323340177536011, 0.7505353093147278, 0.7301927208900452, 0.7526766657829285, 0.7612419724464417, 0.7548179626464844, 0.7516059875488281, 0.7601712942123413, 0.7676659822463989, 0.7676659822463989, 0.7676659822463989, 0.7687366008758545, 0.7708779573440552, 0.7698072791099548, 0.7698072791099548, 0.7751606106758118, 0.7708779573440552, 0.7730192542076111, 0.7740899324417114, 0.7762312889099121, 0.7708779573440552, 0.7730192542076111, 0.7698072791099548, 0.7719486355781555, 0.783725917339325, 0.7805139422416687, 0.7773019075393677, 0.7719486355781555, 0.7740899324417114, 0.7773019075393677, 0.7794432640075684, 0.7794432640075684, 0.778372585773468, 0.7730192542076111, 0.783725917339325, 0.7730192542076111, 0.7912205457687378, 0.7815845608711243, 0.7912205457687378, 0.7773019075393677, 0.7805139422416687, 0.7912205457687378, 0.7890792489051819, 0.7794432640075684, 0.7794432640075684, 0.783725917339325, 0.7805139422416687, 0.7922912240028381, 0.7890792489051819, 0.7933619022369385, 0.7912205457687378, 0.7901498675346375, 0.783725917339325, 0.7901498675346375, 0.7955031991004944, 0.7955031991004944, 0.7912205457687378, 0.7815845608711243, 0.7965738773345947, 0.7922912240028381, 0.794432520866394, 0.7965738773345947, 0.7965738773345947, 0.7987151741981506, 0.7955031991004944, 0.799785852432251, 0.7965738773345947, 0.8008565306663513, 0.794432520866394, 0.8040685057640076, 0.802997887134552, 0.7869378924369812, 0.7955031991004944, 0.8019272089004517, 0.802997887134552, 0.8019272089004517, 0.794432520866394, 0.8083511590957642, 0.802997887134552, 0.802997887134552, 0.8040685057640076, 0.8040685057640076, 0.8137044906616211, 0.8083511590957642, 0.8072805404663086]}\n","37/37 [==============================] - 1s 7ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 9s 45ms/step - loss: 0.6929 - accuracy: 0.5422 - val_loss: 0.6931 - val_accuracy: 0.6959\n","Epoch 2/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.6917 - accuracy: 0.6290 - val_loss: 0.6930 - val_accuracy: 0.6274\n","Epoch 3/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.6890 - accuracy: 0.6866 - val_loss: 0.6926 - val_accuracy: 0.6328\n","Epoch 4/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.6829 - accuracy: 0.7002 - val_loss: 0.6916 - val_accuracy: 0.6349\n","Epoch 5/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.6715 - accuracy: 0.7037 - val_loss: 0.6897 - val_accuracy: 0.6660\n","Epoch 6/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.6530 - accuracy: 0.7104 - val_loss: 0.6858 - val_accuracy: 0.6820\n","Epoch 7/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.6258 - accuracy: 0.7096 - val_loss: 0.6787 - val_accuracy: 0.7099\n","Epoch 8/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.5966 - accuracy: 0.7195 - val_loss: 0.6681 - val_accuracy: 0.7227\n","Epoch 9/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.5721 - accuracy: 0.7244 - val_loss: 0.6549 - val_accuracy: 0.7345\n","Epoch 10/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.5513 - accuracy: 0.7313 - val_loss: 0.6414 - val_accuracy: 0.7398\n","Epoch 11/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.5365 - accuracy: 0.7426 - val_loss: 0.6290 - val_accuracy: 0.7355\n","Epoch 12/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.5258 - accuracy: 0.7557 - val_loss: 0.6133 - val_accuracy: 0.7580\n","Epoch 13/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.5100 - accuracy: 0.7619 - val_loss: 0.5960 - val_accuracy: 0.7537\n","Epoch 14/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4997 - accuracy: 0.7659 - val_loss: 0.5775 - val_accuracy: 0.7570\n","Epoch 15/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4866 - accuracy: 0.7752 - val_loss: 0.5558 - val_accuracy: 0.7655\n","Epoch 16/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4866 - accuracy: 0.7755 - val_loss: 0.5457 - val_accuracy: 0.7548\n","Epoch 17/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4817 - accuracy: 0.7739 - val_loss: 0.5267 - val_accuracy: 0.7677\n","Epoch 18/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4755 - accuracy: 0.7787 - val_loss: 0.5227 - val_accuracy: 0.7570\n","Epoch 19/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4687 - accuracy: 0.7844 - val_loss: 0.5113 - val_accuracy: 0.7623\n","Epoch 20/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.4638 - accuracy: 0.7844 - val_loss: 0.4940 - val_accuracy: 0.7741\n","Epoch 21/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.4618 - accuracy: 0.7862 - val_loss: 0.4789 - val_accuracy: 0.7816\n","Epoch 22/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4598 - accuracy: 0.7836 - val_loss: 0.4721 - val_accuracy: 0.7816\n","Epoch 23/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4574 - accuracy: 0.7862 - val_loss: 0.4665 - val_accuracy: 0.7784\n","Epoch 24/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4605 - accuracy: 0.7811 - val_loss: 0.4523 - val_accuracy: 0.7976\n","Epoch 25/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4591 - accuracy: 0.7894 - val_loss: 0.4538 - val_accuracy: 0.7923\n","Epoch 26/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.4460 - accuracy: 0.7969 - val_loss: 0.4477 - val_accuracy: 0.7987\n","Epoch 27/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4473 - accuracy: 0.7900 - val_loss: 0.4651 - val_accuracy: 0.7837\n","Epoch 28/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4465 - accuracy: 0.7932 - val_loss: 0.4453 - val_accuracy: 0.8030\n","Epoch 29/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4382 - accuracy: 0.7980 - val_loss: 0.4444 - val_accuracy: 0.8019\n","Epoch 30/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4384 - accuracy: 0.8015 - val_loss: 0.4446 - val_accuracy: 0.7987\n","Epoch 31/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4370 - accuracy: 0.7986 - val_loss: 0.4458 - val_accuracy: 0.7998\n","Epoch 32/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4360 - accuracy: 0.8026 - val_loss: 0.4398 - val_accuracy: 0.8051\n","Epoch 33/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4344 - accuracy: 0.8018 - val_loss: 0.4509 - val_accuracy: 0.7966\n","Epoch 34/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4311 - accuracy: 0.8004 - val_loss: 0.4372 - val_accuracy: 0.8084\n","Epoch 35/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4284 - accuracy: 0.8042 - val_loss: 0.4364 - val_accuracy: 0.8084\n","Epoch 36/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.4284 - accuracy: 0.8023 - val_loss: 0.4338 - val_accuracy: 0.8094\n","Epoch 37/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4235 - accuracy: 0.8050 - val_loss: 0.4342 - val_accuracy: 0.8105\n","Epoch 38/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4223 - accuracy: 0.8071 - val_loss: 0.4340 - val_accuracy: 0.8116\n","Epoch 39/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4211 - accuracy: 0.8061 - val_loss: 0.4335 - val_accuracy: 0.8137\n","Epoch 40/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4200 - accuracy: 0.8069 - val_loss: 0.4308 - val_accuracy: 0.8116\n","Epoch 41/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4200 - accuracy: 0.8085 - val_loss: 0.4319 - val_accuracy: 0.8094\n","Epoch 42/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.4180 - accuracy: 0.8125 - val_loss: 0.4281 - val_accuracy: 0.8116\n","Epoch 43/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4131 - accuracy: 0.8138 - val_loss: 0.4241 - val_accuracy: 0.8158\n","Epoch 44/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4098 - accuracy: 0.8168 - val_loss: 0.4230 - val_accuracy: 0.8158\n","Epoch 45/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4096 - accuracy: 0.8109 - val_loss: 0.4202 - val_accuracy: 0.8148\n","Epoch 46/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4080 - accuracy: 0.8173 - val_loss: 0.4230 - val_accuracy: 0.8191\n","Epoch 47/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4040 - accuracy: 0.8170 - val_loss: 0.4213 - val_accuracy: 0.8255\n","Epoch 48/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4070 - accuracy: 0.8119 - val_loss: 0.4155 - val_accuracy: 0.8169\n","Epoch 49/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4051 - accuracy: 0.8168 - val_loss: 0.4150 - val_accuracy: 0.8201\n","Epoch 50/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3986 - accuracy: 0.8197 - val_loss: 0.4156 - val_accuracy: 0.8298\n","Epoch 51/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4013 - accuracy: 0.8173 - val_loss: 0.4135 - val_accuracy: 0.8244\n","Epoch 52/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3918 - accuracy: 0.8286 - val_loss: 0.4114 - val_accuracy: 0.8223\n","Epoch 53/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3896 - accuracy: 0.8286 - val_loss: 0.4112 - val_accuracy: 0.8223\n","Epoch 54/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3877 - accuracy: 0.8267 - val_loss: 0.4122 - val_accuracy: 0.8244\n","Epoch 55/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3883 - accuracy: 0.8296 - val_loss: 0.4143 - val_accuracy: 0.8244\n","Epoch 56/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3884 - accuracy: 0.8240 - val_loss: 0.4079 - val_accuracy: 0.8276\n","Epoch 57/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3845 - accuracy: 0.8272 - val_loss: 0.4091 - val_accuracy: 0.8276\n","Epoch 58/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3845 - accuracy: 0.8269 - val_loss: 0.4056 - val_accuracy: 0.8330\n","Epoch 59/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3818 - accuracy: 0.8326 - val_loss: 0.4070 - val_accuracy: 0.8287\n","Epoch 60/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3799 - accuracy: 0.8318 - val_loss: 0.4055 - val_accuracy: 0.8362\n","Epoch 61/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3792 - accuracy: 0.8272 - val_loss: 0.4055 - val_accuracy: 0.8340\n","Epoch 62/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3761 - accuracy: 0.8342 - val_loss: 0.4041 - val_accuracy: 0.8373\n","Epoch 63/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3741 - accuracy: 0.8344 - val_loss: 0.4028 - val_accuracy: 0.8373\n","Epoch 64/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3697 - accuracy: 0.8358 - val_loss: 0.4041 - val_accuracy: 0.8340\n","Epoch 65/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3755 - accuracy: 0.8347 - val_loss: 0.4069 - val_accuracy: 0.8298\n","Epoch 66/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3680 - accuracy: 0.8411 - val_loss: 0.3990 - val_accuracy: 0.8383\n","Epoch 67/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3660 - accuracy: 0.8425 - val_loss: 0.4014 - val_accuracy: 0.8448\n","Epoch 68/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3651 - accuracy: 0.8446 - val_loss: 0.4104 - val_accuracy: 0.8330\n","Epoch 69/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3665 - accuracy: 0.8420 - val_loss: 0.4305 - val_accuracy: 0.8276\n","Epoch 70/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3752 - accuracy: 0.8361 - val_loss: 0.3981 - val_accuracy: 0.8426\n","Epoch 71/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3589 - accuracy: 0.8468 - val_loss: 0.4039 - val_accuracy: 0.8373\n","Epoch 72/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3591 - accuracy: 0.8489 - val_loss: 0.4049 - val_accuracy: 0.8266\n","Epoch 73/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3585 - accuracy: 0.8444 - val_loss: 0.3983 - val_accuracy: 0.8469\n","Epoch 74/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3526 - accuracy: 0.8478 - val_loss: 0.3954 - val_accuracy: 0.8437\n","Epoch 75/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3585 - accuracy: 0.8495 - val_loss: 0.4020 - val_accuracy: 0.8394\n","Epoch 76/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3534 - accuracy: 0.8508 - val_loss: 0.3974 - val_accuracy: 0.8448\n","Epoch 77/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.3482 - accuracy: 0.8519 - val_loss: 0.4000 - val_accuracy: 0.8426\n","Epoch 78/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.3541 - accuracy: 0.8495 - val_loss: 0.3959 - val_accuracy: 0.8469\n","Epoch 79/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3504 - accuracy: 0.8516 - val_loss: 0.3958 - val_accuracy: 0.8415\n","Epoch 80/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3485 - accuracy: 0.8503 - val_loss: 0.3957 - val_accuracy: 0.8415\n","Epoch 81/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3468 - accuracy: 0.8524 - val_loss: 0.3982 - val_accuracy: 0.8415\n","Epoch 82/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3450 - accuracy: 0.8532 - val_loss: 0.3977 - val_accuracy: 0.8415\n","Epoch 83/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.3411 - accuracy: 0.8540 - val_loss: 0.3973 - val_accuracy: 0.8298\n","Epoch 84/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3375 - accuracy: 0.8575 - val_loss: 0.3933 - val_accuracy: 0.8437\n","Epoch 85/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3450 - accuracy: 0.8537 - val_loss: 0.3942 - val_accuracy: 0.8437\n","Epoch 86/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3340 - accuracy: 0.8588 - val_loss: 0.3934 - val_accuracy: 0.8501\n","Epoch 87/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3377 - accuracy: 0.8575 - val_loss: 0.3909 - val_accuracy: 0.8458\n","Epoch 88/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3487 - accuracy: 0.8529 - val_loss: 0.4016 - val_accuracy: 0.8437\n","Epoch 89/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3388 - accuracy: 0.8596 - val_loss: 0.3908 - val_accuracy: 0.8415\n","Epoch 90/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3342 - accuracy: 0.8583 - val_loss: 0.3968 - val_accuracy: 0.8426\n","Epoch 91/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3313 - accuracy: 0.8594 - val_loss: 0.4002 - val_accuracy: 0.8383\n","Epoch 92/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3309 - accuracy: 0.8626 - val_loss: 0.4008 - val_accuracy: 0.8287\n","Epoch 93/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3328 - accuracy: 0.8655 - val_loss: 0.3920 - val_accuracy: 0.8437\n","Epoch 94/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3243 - accuracy: 0.8661 - val_loss: 0.3907 - val_accuracy: 0.8448\n","Epoch 95/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3289 - accuracy: 0.8615 - val_loss: 0.3957 - val_accuracy: 0.8437\n","Epoch 96/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3433 - accuracy: 0.8599 - val_loss: 0.3908 - val_accuracy: 0.8469\n","Epoch 97/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.3216 - accuracy: 0.8669 - val_loss: 0.3987 - val_accuracy: 0.8426\n","Epoch 98/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3225 - accuracy: 0.8714 - val_loss: 0.4001 - val_accuracy: 0.8426\n","Epoch 99/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3267 - accuracy: 0.8620 - val_loss: 0.4017 - val_accuracy: 0.8426\n","Epoch 100/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3174 - accuracy: 0.8701 - val_loss: 0.3881 - val_accuracy: 0.8437\n","{'loss': [0.6928673386573792, 0.6917145848274231, 0.6889830827713013, 0.6828557252883911, 0.6715341210365295, 0.6530061960220337, 0.6257621645927429, 0.596636176109314, 0.5720973014831543, 0.5512781143188477, 0.5365172028541565, 0.5258213877677917, 0.509976327419281, 0.49971121549606323, 0.48661288619041443, 0.4866042733192444, 0.48168209195137024, 0.4755284786224365, 0.46873852610588074, 0.4638284742832184, 0.4617586135864258, 0.4598359167575836, 0.4573644697666168, 0.4604562819004059, 0.45912396907806396, 0.4459962546825409, 0.4472917914390564, 0.44654908776283264, 0.4382113516330719, 0.4383566379547119, 0.4369816780090332, 0.43598225712776184, 0.4344484508037567, 0.4310553967952728, 0.42844468355178833, 0.4284284710884094, 0.42345279455184937, 0.4223315715789795, 0.42112377285957336, 0.41999903321266174, 0.4200482964515686, 0.41801318526268005, 0.41309624910354614, 0.4098452925682068, 0.4096142053604126, 0.4080168902873993, 0.4039953649044037, 0.4069589376449585, 0.40507686138153076, 0.39861446619033813, 0.40129896998405457, 0.39183345437049866, 0.3896328806877136, 0.3876974582672119, 0.38833537697792053, 0.38842612504959106, 0.3844589293003082, 0.3844849467277527, 0.3817918300628662, 0.37994086742401123, 0.37915194034576416, 0.37606245279312134, 0.37409427762031555, 0.36973193287849426, 0.3755326271057129, 0.3679914176464081, 0.36595606803894043, 0.3651280403137207, 0.3664923310279846, 0.37523847818374634, 0.35887789726257324, 0.35905754566192627, 0.35846370458602905, 0.3526197075843811, 0.35852640867233276, 0.35338470339775085, 0.34816616773605347, 0.3540710508823395, 0.3503834903240204, 0.34846487641334534, 0.346804678440094, 0.34502655267715454, 0.34111496806144714, 0.33751705288887024, 0.34496060013771057, 0.3340475261211395, 0.3377028703689575, 0.348688006401062, 0.33884143829345703, 0.33415573835372925, 0.3312540650367737, 0.33091211318969727, 0.3327719271183014, 0.3242630064487457, 0.3289174735546112, 0.3433282971382141, 0.32158467173576355, 0.322464257478714, 0.326651394367218, 0.3173966705799103], 'accuracy': [0.5421912670135498, 0.6289847493171692, 0.686579167842865, 0.7002410888671875, 0.7037235498428345, 0.710420548915863, 0.7096169590950012, 0.7195285558700562, 0.7243503928184509, 0.7313153147697449, 0.7425662875175476, 0.7556924819946289, 0.7618537545204163, 0.7658719420433044, 0.7752478122711182, 0.7755156755447388, 0.7739083766937256, 0.7787302732467651, 0.7843557596206665, 0.7843557596206665, 0.7862309217453003, 0.7835521101951599, 0.7862309217453003, 0.7811411619186401, 0.7894454598426819, 0.7969461679458618, 0.7899812459945679, 0.7931958436965942, 0.798017680644989, 0.801500141620636, 0.798553466796875, 0.8025716543197632, 0.8017680048942566, 0.8004286289215088, 0.8041789531707764, 0.8023037910461426, 0.804982602596283, 0.8071256279945374, 0.8060541152954102, 0.8068577647209167, 0.8084650635719299, 0.8124832510948181, 0.8138226866722107, 0.8167693614959717, 0.8108759522438049, 0.8173050880432129, 0.8170372247695923, 0.8119475245475769, 0.8167693614959717, 0.8197160363197327, 0.8173050880432129, 0.8285561203956604, 0.8285561203956604, 0.8266809582710266, 0.8296276330947876, 0.8240021467208862, 0.8272167444229126, 0.8269488215446472, 0.8325743079185486, 0.8317707180976868, 0.8272167444229126, 0.8341816067695618, 0.8344495296478271, 0.835788905620575, 0.8347173929214478, 0.8411465287208557, 0.8424859642982483, 0.8446289896965027, 0.8419501781463623, 0.8360567688941956, 0.8467720150947571, 0.8489151000976562, 0.8443611264228821, 0.8478435277938843, 0.8494508266448975, 0.85079026222229, 0.8518617749214172, 0.8494508266448975, 0.8515939116477966, 0.850254476070404, 0.8523975610733032, 0.853201150894165, 0.8540048003196716, 0.8574872612953186, 0.853736937046051, 0.8588266968727112, 0.8574872612953186, 0.8529332876205444, 0.8596303462982178, 0.8582909107208252, 0.8593624234199524, 0.8625770211219788, 0.8655236959457397, 0.8660594820976257, 0.8615055084228516, 0.8598982095718384, 0.8668631315231323, 0.8714171051979065, 0.8620412349700928, 0.8700776696205139], 'val_loss': [0.6931124329566956, 0.6929699778556824, 0.6925569772720337, 0.6916402578353882, 0.6896563768386841, 0.685836911201477, 0.6786606907844543, 0.6680874824523926, 0.6548563241958618, 0.641380786895752, 0.6289987564086914, 0.6132869124412537, 0.5959917306900024, 0.577534556388855, 0.5558139681816101, 0.545741856098175, 0.5267216563224792, 0.5227283239364624, 0.5112982988357544, 0.4939691424369812, 0.47891274094581604, 0.47209879755973816, 0.4665023386478424, 0.45226943492889404, 0.4538424611091614, 0.44766470789909363, 0.465072900056839, 0.4453463852405548, 0.44436806440353394, 0.44457077980041504, 0.4458049237728119, 0.43976229429244995, 0.4508938789367676, 0.43723344802856445, 0.4364405572414398, 0.4338008761405945, 0.4342093765735626, 0.43404024839401245, 0.43346714973449707, 0.4308090806007385, 0.4319295585155487, 0.428102046251297, 0.42412129044532776, 0.42304447293281555, 0.4201540946960449, 0.4229946732521057, 0.4213447570800781, 0.41545990109443665, 0.4149508476257324, 0.4155564308166504, 0.4134708642959595, 0.41135141253471375, 0.41116681694984436, 0.4121587872505188, 0.4142550528049469, 0.40793463587760925, 0.4090558886528015, 0.40564751625061035, 0.40700051188468933, 0.40553489327430725, 0.4055396616458893, 0.40414509177207947, 0.40278926491737366, 0.4041040539741516, 0.4068944454193115, 0.39895230531692505, 0.4013805091381073, 0.41038617491722107, 0.43049776554107666, 0.39813897013664246, 0.4038780927658081, 0.4049447476863861, 0.3983042240142822, 0.39535510540008545, 0.40204566717147827, 0.3974110186100006, 0.400020569562912, 0.3959447741508484, 0.3957953453063965, 0.3957013487815857, 0.3981688320636749, 0.39774638414382935, 0.3972807824611664, 0.393329918384552, 0.39421212673187256, 0.39339566230773926, 0.3908894956111908, 0.4016299843788147, 0.39082837104797363, 0.39682114124298096, 0.4001598358154297, 0.40081271529197693, 0.3920331597328186, 0.39068642258644104, 0.3956576883792877, 0.390796035528183, 0.39868250489234924, 0.4000662565231323, 0.40165436267852783, 0.38808348774909973], 'val_accuracy': [0.6959314942359924, 0.6274089813232422, 0.6327623128890991, 0.6349036693572998, 0.6659528613090515, 0.6820128560066223, 0.7098501324653625, 0.7226980924606323, 0.7344753742218018, 0.7398287057876587, 0.7355460524559021, 0.7580299973487854, 0.7537473440170288, 0.7569593191146851, 0.7655246257781982, 0.7548179626464844, 0.7676659822463989, 0.7569593191146851, 0.762312650680542, 0.7740899324417114, 0.7815845608711243, 0.7815845608711243, 0.778372585773468, 0.7976445555686951, 0.7922912240028381, 0.7987151741981506, 0.783725917339325, 0.802997887134552, 0.8019272089004517, 0.7987151741981506, 0.799785852432251, 0.8051391839981079, 0.7965738773345947, 0.8083511590957642, 0.8083511590957642, 0.8094218373298645, 0.8104925155639648, 0.8115631937980652, 0.8137044906616211, 0.8115631937980652, 0.8094218373298645, 0.8115631937980652, 0.8158458471298218, 0.8158458471298218, 0.8147751688957214, 0.819057822227478, 0.8254817724227905, 0.8169164657592773, 0.8201285004615784, 0.8297644257545471, 0.824411153793335, 0.8222697973251343, 0.8222697973251343, 0.824411153793335, 0.824411153793335, 0.8276231288909912, 0.8276231288909912, 0.8329764604568481, 0.8286938071250916, 0.8361884355545044, 0.8340471386909485, 0.8372591137886047, 0.8372591137886047, 0.8340471386909485, 0.8297644257545471, 0.8383297920227051, 0.8447537422180176, 0.8329764604568481, 0.8276231288909912, 0.8426124453544617, 0.8372591137886047, 0.8265524506568909, 0.8468950986862183, 0.8436830639839172, 0.8394004106521606, 0.8447537422180176, 0.8426124453544617, 0.8468950986862183, 0.8415417671203613, 0.8415417671203613, 0.8415417671203613, 0.8415417671203613, 0.8297644257545471, 0.8436830639839172, 0.8436830639839172, 0.8501070737838745, 0.8458244204521179, 0.8436830639839172, 0.8415417671203613, 0.8426124453544617, 0.8383297920227051, 0.8286938071250916, 0.8436830639839172, 0.8447537422180176, 0.8436830639839172, 0.8468950986862183, 0.8426124453544617, 0.8426124453544617, 0.8426124453544617, 0.8436830639839172]}\n","37/37 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 11s 108ms/step - loss: 0.6929 - accuracy: 0.5446 - val_loss: 0.6931 - val_accuracy: 0.5021\n","Epoch 2/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.6919 - accuracy: 0.6343 - val_loss: 0.6930 - val_accuracy: 0.6660\n","Epoch 3/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.6891 - accuracy: 0.6903 - val_loss: 0.6926 - val_accuracy: 0.6135\n","Epoch 4/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.6836 - accuracy: 0.7016 - val_loss: 0.6918 - val_accuracy: 0.6852\n","Epoch 5/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.6734 - accuracy: 0.7061 - val_loss: 0.6900 - val_accuracy: 0.6884\n","Epoch 6/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.6555 - accuracy: 0.7067 - val_loss: 0.6863 - val_accuracy: 0.6895\n","Epoch 7/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.6292 - accuracy: 0.7126 - val_loss: 0.6788 - val_accuracy: 0.7088\n","Epoch 8/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.6011 - accuracy: 0.7198 - val_loss: 0.6686 - val_accuracy: 0.7152\n","Epoch 9/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.5784 - accuracy: 0.7219 - val_loss: 0.6559 - val_accuracy: 0.7248\n","Epoch 10/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.5584 - accuracy: 0.7364 - val_loss: 0.6429 - val_accuracy: 0.7366\n","Epoch 11/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.5465 - accuracy: 0.7423 - val_loss: 0.6302 - val_accuracy: 0.7313\n","Epoch 12/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.5293 - accuracy: 0.7525 - val_loss: 0.6110 - val_accuracy: 0.7687\n","Epoch 13/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.5226 - accuracy: 0.7562 - val_loss: 0.5983 - val_accuracy: 0.7452\n","Epoch 14/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.5101 - accuracy: 0.7648 - val_loss: 0.5749 - val_accuracy: 0.7570\n","Epoch 15/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.4998 - accuracy: 0.7710 - val_loss: 0.5557 - val_accuracy: 0.7537\n","Epoch 16/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4937 - accuracy: 0.7718 - val_loss: 0.5291 - val_accuracy: 0.7837\n","Epoch 17/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4895 - accuracy: 0.7651 - val_loss: 0.5211 - val_accuracy: 0.7645\n","Epoch 18/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4824 - accuracy: 0.7755 - val_loss: 0.5013 - val_accuracy: 0.7773\n","Epoch 19/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4755 - accuracy: 0.7825 - val_loss: 0.4932 - val_accuracy: 0.7762\n","Epoch 20/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.4758 - accuracy: 0.7819 - val_loss: 0.4688 - val_accuracy: 0.7912\n","Epoch 21/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4707 - accuracy: 0.7785 - val_loss: 0.4854 - val_accuracy: 0.7719\n","Epoch 22/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4702 - accuracy: 0.7801 - val_loss: 0.4553 - val_accuracy: 0.7923\n","Epoch 23/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4648 - accuracy: 0.7852 - val_loss: 0.4586 - val_accuracy: 0.7934\n","Epoch 24/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4633 - accuracy: 0.7870 - val_loss: 0.4502 - val_accuracy: 0.7966\n","Epoch 25/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4665 - accuracy: 0.7763 - val_loss: 0.4671 - val_accuracy: 0.7869\n","Epoch 26/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4562 - accuracy: 0.7862 - val_loss: 0.4433 - val_accuracy: 0.8009\n","Epoch 27/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4540 - accuracy: 0.7935 - val_loss: 0.4430 - val_accuracy: 0.7987\n","Epoch 28/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4522 - accuracy: 0.7937 - val_loss: 0.4453 - val_accuracy: 0.7987\n","Epoch 29/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4491 - accuracy: 0.7902 - val_loss: 0.4410 - val_accuracy: 0.8019\n","Epoch 30/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4518 - accuracy: 0.7894 - val_loss: 0.4392 - val_accuracy: 0.8019\n","Epoch 31/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4475 - accuracy: 0.7929 - val_loss: 0.4363 - val_accuracy: 0.8062\n","Epoch 32/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4462 - accuracy: 0.7967 - val_loss: 0.4355 - val_accuracy: 0.8084\n","Epoch 33/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4403 - accuracy: 0.7964 - val_loss: 0.4354 - val_accuracy: 0.8084\n","Epoch 34/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4503 - accuracy: 0.7894 - val_loss: 0.4367 - val_accuracy: 0.8148\n","Epoch 35/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4407 - accuracy: 0.7969 - val_loss: 0.4306 - val_accuracy: 0.8084\n","Epoch 36/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.4330 - accuracy: 0.8039 - val_loss: 0.4319 - val_accuracy: 0.8094\n","Epoch 37/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4396 - accuracy: 0.7996 - val_loss: 0.4312 - val_accuracy: 0.8116\n","Epoch 38/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4388 - accuracy: 0.7980 - val_loss: 0.4290 - val_accuracy: 0.8137\n","Epoch 39/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.4336 - accuracy: 0.7977 - val_loss: 0.4273 - val_accuracy: 0.8073\n","Epoch 40/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4340 - accuracy: 0.8026 - val_loss: 0.4262 - val_accuracy: 0.8105\n","Epoch 41/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4265 - accuracy: 0.8061 - val_loss: 0.4252 - val_accuracy: 0.8084\n","Epoch 42/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4273 - accuracy: 0.8050 - val_loss: 0.4246 - val_accuracy: 0.8116\n","Epoch 43/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4245 - accuracy: 0.8042 - val_loss: 0.4234 - val_accuracy: 0.8201\n","Epoch 44/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4183 - accuracy: 0.8093 - val_loss: 0.4225 - val_accuracy: 0.8116\n","Epoch 45/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4259 - accuracy: 0.8082 - val_loss: 0.4230 - val_accuracy: 0.8116\n","Epoch 46/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.4205 - accuracy: 0.8141 - val_loss: 0.4208 - val_accuracy: 0.8137\n","Epoch 47/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4228 - accuracy: 0.8082 - val_loss: 0.4198 - val_accuracy: 0.8212\n","Epoch 48/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4172 - accuracy: 0.8061 - val_loss: 0.4193 - val_accuracy: 0.8148\n","Epoch 49/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.4131 - accuracy: 0.8095 - val_loss: 0.4205 - val_accuracy: 0.8137\n","Epoch 50/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.4132 - accuracy: 0.8090 - val_loss: 0.4219 - val_accuracy: 0.8148\n","Epoch 51/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.4120 - accuracy: 0.8141 - val_loss: 0.4186 - val_accuracy: 0.8201\n","Epoch 52/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4096 - accuracy: 0.8138 - val_loss: 0.4162 - val_accuracy: 0.8158\n","Epoch 53/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4089 - accuracy: 0.8149 - val_loss: 0.4218 - val_accuracy: 0.8158\n","Epoch 54/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.4098 - accuracy: 0.8178 - val_loss: 0.4130 - val_accuracy: 0.8180\n","Epoch 55/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4093 - accuracy: 0.8176 - val_loss: 0.4127 - val_accuracy: 0.8169\n","Epoch 56/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.4084 - accuracy: 0.8165 - val_loss: 0.4434 - val_accuracy: 0.8051\n","Epoch 57/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4054 - accuracy: 0.8219 - val_loss: 0.4128 - val_accuracy: 0.8180\n","Epoch 58/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.4009 - accuracy: 0.8200 - val_loss: 0.4102 - val_accuracy: 0.8212\n","Epoch 59/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3979 - accuracy: 0.8170 - val_loss: 0.4090 - val_accuracy: 0.8169\n","Epoch 60/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3969 - accuracy: 0.8200 - val_loss: 0.4095 - val_accuracy: 0.8191\n","Epoch 61/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3940 - accuracy: 0.8267 - val_loss: 0.4130 - val_accuracy: 0.8201\n","Epoch 62/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3961 - accuracy: 0.8272 - val_loss: 0.4072 - val_accuracy: 0.8223\n","Epoch 63/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3913 - accuracy: 0.8240 - val_loss: 0.4058 - val_accuracy: 0.8255\n","Epoch 64/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3910 - accuracy: 0.8299 - val_loss: 0.4076 - val_accuracy: 0.8244\n","Epoch 65/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3903 - accuracy: 0.8296 - val_loss: 0.4052 - val_accuracy: 0.8201\n","Epoch 66/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3926 - accuracy: 0.8243 - val_loss: 0.4034 - val_accuracy: 0.8233\n","Epoch 67/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3874 - accuracy: 0.8253 - val_loss: 0.4049 - val_accuracy: 0.8180\n","Epoch 68/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3823 - accuracy: 0.8326 - val_loss: 0.4023 - val_accuracy: 0.8266\n","Epoch 69/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3815 - accuracy: 0.8304 - val_loss: 0.4037 - val_accuracy: 0.8233\n","Epoch 70/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3844 - accuracy: 0.8320 - val_loss: 0.4011 - val_accuracy: 0.8244\n","Epoch 71/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3772 - accuracy: 0.8366 - val_loss: 0.4008 - val_accuracy: 0.8266\n","Epoch 72/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3790 - accuracy: 0.8326 - val_loss: 0.4004 - val_accuracy: 0.8233\n","Epoch 73/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3738 - accuracy: 0.8436 - val_loss: 0.4009 - val_accuracy: 0.8201\n","Epoch 74/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3709 - accuracy: 0.8374 - val_loss: 0.4007 - val_accuracy: 0.8212\n","Epoch 75/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3719 - accuracy: 0.8398 - val_loss: 0.4059 - val_accuracy: 0.8169\n","Epoch 76/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3763 - accuracy: 0.8371 - val_loss: 0.4016 - val_accuracy: 0.8201\n","Epoch 77/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3672 - accuracy: 0.8387 - val_loss: 0.4003 - val_accuracy: 0.8266\n","Epoch 78/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3651 - accuracy: 0.8428 - val_loss: 0.4005 - val_accuracy: 0.8276\n","Epoch 79/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3697 - accuracy: 0.8409 - val_loss: 0.4026 - val_accuracy: 0.8266\n","Epoch 80/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3690 - accuracy: 0.8382 - val_loss: 0.3984 - val_accuracy: 0.8223\n","Epoch 81/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3600 - accuracy: 0.8457 - val_loss: 0.4168 - val_accuracy: 0.8191\n","Epoch 82/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3610 - accuracy: 0.8476 - val_loss: 0.3968 - val_accuracy: 0.8266\n","Epoch 83/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3600 - accuracy: 0.8486 - val_loss: 0.3985 - val_accuracy: 0.8255\n","Epoch 84/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3608 - accuracy: 0.8465 - val_loss: 0.3964 - val_accuracy: 0.8287\n","Epoch 85/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3532 - accuracy: 0.8497 - val_loss: 0.4013 - val_accuracy: 0.8330\n","Epoch 86/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3487 - accuracy: 0.8543 - val_loss: 0.4056 - val_accuracy: 0.8201\n","Epoch 87/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3594 - accuracy: 0.8425 - val_loss: 0.4245 - val_accuracy: 0.8191\n","Epoch 88/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3597 - accuracy: 0.8425 - val_loss: 0.4001 - val_accuracy: 0.8330\n","Epoch 89/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3530 - accuracy: 0.8497 - val_loss: 0.3987 - val_accuracy: 0.8244\n","Epoch 90/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3468 - accuracy: 0.8548 - val_loss: 0.4002 - val_accuracy: 0.8255\n","Epoch 91/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3454 - accuracy: 0.8513 - val_loss: 0.3978 - val_accuracy: 0.8308\n","Epoch 92/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3577 - accuracy: 0.8500 - val_loss: 0.4078 - val_accuracy: 0.8255\n","Epoch 93/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3457 - accuracy: 0.8527 - val_loss: 0.3976 - val_accuracy: 0.8319\n","Epoch 94/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3440 - accuracy: 0.8513 - val_loss: 0.4059 - val_accuracy: 0.8266\n","Epoch 95/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3433 - accuracy: 0.8537 - val_loss: 0.3961 - val_accuracy: 0.8287\n","Epoch 96/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3490 - accuracy: 0.8492 - val_loss: 0.4165 - val_accuracy: 0.8244\n","Epoch 97/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3450 - accuracy: 0.8521 - val_loss: 0.3942 - val_accuracy: 0.8351\n","Epoch 98/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3376 - accuracy: 0.8535 - val_loss: 0.3943 - val_accuracy: 0.8340\n","Epoch 99/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3364 - accuracy: 0.8572 - val_loss: 0.4127 - val_accuracy: 0.8223\n","Epoch 100/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3436 - accuracy: 0.8548 - val_loss: 0.4366 - val_accuracy: 0.8094\n","{'loss': [0.6929404735565186, 0.6918897032737732, 0.6891496777534485, 0.683604896068573, 0.6734179258346558, 0.6554868817329407, 0.6291940212249756, 0.6010589003562927, 0.5784129500389099, 0.5583873391151428, 0.5465028882026672, 0.5292977690696716, 0.522564709186554, 0.5100936889648438, 0.49980172514915466, 0.4937179386615753, 0.4894898235797882, 0.48238521814346313, 0.4755176305770874, 0.47580280900001526, 0.4706832468509674, 0.47018134593963623, 0.4647555947303772, 0.4633435010910034, 0.4665253758430481, 0.4561662971973419, 0.4540458023548126, 0.45217365026474, 0.4491453170776367, 0.45183926820755005, 0.4475358724594116, 0.4461650252342224, 0.44025561213493347, 0.4503091275691986, 0.44074171781539917, 0.43299540877342224, 0.43955060839653015, 0.43879467248916626, 0.43362152576446533, 0.4340059757232666, 0.4265236258506775, 0.42730778455734253, 0.42450037598609924, 0.41827213764190674, 0.42592543363571167, 0.42054206132888794, 0.4228173792362213, 0.417210191488266, 0.41307350993156433, 0.4132079780101776, 0.41203922033309937, 0.4095776379108429, 0.40894490480422974, 0.4097858667373657, 0.4093019962310791, 0.40840399265289307, 0.4053642749786377, 0.40089666843414307, 0.3979133665561676, 0.3969094157218933, 0.39400190114974976, 0.3961094915866852, 0.3913497030735016, 0.39104998111724854, 0.3903105556964874, 0.39255425333976746, 0.38739100098609924, 0.3822624385356903, 0.3814655840396881, 0.384439080953598, 0.37720662355422974, 0.3789502680301666, 0.37384557723999023, 0.37085944414138794, 0.37188124656677246, 0.3763248920440674, 0.3672408163547516, 0.3650762438774109, 0.36965858936309814, 0.36897987127304077, 0.36002498865127563, 0.36096903681755066, 0.3600468039512634, 0.36082398891448975, 0.35318997502326965, 0.3487444818019867, 0.3593887984752655, 0.35973164439201355, 0.35299602150917053, 0.3468112647533417, 0.34539732336997986, 0.35771000385284424, 0.3457106649875641, 0.3440132737159729, 0.34327855706214905, 0.3490249514579773, 0.3450339138507843, 0.3375993072986603, 0.3363836407661438, 0.3435703217983246], 'accuracy': [0.5446022152900696, 0.63434237241745, 0.6903294920921326, 0.7015805244445801, 0.7061344981193542, 0.7066702246665955, 0.7125636339187622, 0.7197964191436768, 0.7219394445419312, 0.7364050149917603, 0.742298424243927, 0.7524778842926025, 0.7562282085418701, 0.7648004293441772, 0.7709617018699646, 0.7717653512954712, 0.7650682926177979, 0.7755156755447388, 0.7824805974960327, 0.7819448113441467, 0.7784623503684998, 0.7800696492195129, 0.7851594090461731, 0.7870345711708069, 0.7763193249702454, 0.7862309217453003, 0.7934637069702148, 0.7937315702438354, 0.7902491092681885, 0.7894454598426819, 0.7929279208183289, 0.7966782450675964, 0.7964103817939758, 0.7894454598426819, 0.7969461679458618, 0.8039110898971558, 0.7996249794960022, 0.798017680644989, 0.7977498173713684, 0.8025716543197632, 0.8060541152954102, 0.804982602596283, 0.8041789531707764, 0.8092687129974365, 0.8081971406936646, 0.8140905499458313, 0.8081971406936646, 0.8060541152954102, 0.8095365762710571, 0.8090007901191711, 0.8140905499458313, 0.8138226866722107, 0.8148941993713379, 0.8178408741950989, 0.8175730109214783, 0.8165014982223511, 0.8218591213226318, 0.8199838995933533, 0.8170372247695923, 0.8199838995933533, 0.8266809582710266, 0.8272167444229126, 0.8240021467208862, 0.829895555973053, 0.8296276330947876, 0.8242700099945068, 0.825341522693634, 0.8325743079185486, 0.8304312825202942, 0.8320385813713074, 0.8365925550460815, 0.8325743079185486, 0.8435574769973755, 0.8373962044715881, 0.8398071527481079, 0.8371283411979675, 0.8387355804443359, 0.8427538275718689, 0.8408786654472351, 0.8381998538970947, 0.8457005023956299, 0.8475756645202637, 0.8486471772193909, 0.8465041518211365, 0.8497187495231628, 0.854272723197937, 0.8424859642982483, 0.8424859642982483, 0.8497187495231628, 0.8548084497451782, 0.8513259887695312, 0.8499866127967834, 0.8526654243469238, 0.8513259887695312, 0.853736937046051, 0.8491829633712769, 0.8521296381950378, 0.8534690737724304, 0.857219398021698, 0.8548084497451782], 'val_loss': [0.6931231021881104, 0.6929787993431091, 0.6926330924034119, 0.6917744278907776, 0.6899576783180237, 0.6863201856613159, 0.6787683963775635, 0.6685783267021179, 0.6558851003646851, 0.6428982019424438, 0.6302173733711243, 0.6110180616378784, 0.5982946157455444, 0.574878990650177, 0.5557278394699097, 0.5290699005126953, 0.5211394429206848, 0.5012978911399841, 0.4932357966899872, 0.4688102602958679, 0.48542866110801697, 0.45534324645996094, 0.4586459696292877, 0.4501630365848541, 0.4670749008655548, 0.44326910376548767, 0.44298142194747925, 0.4453229606151581, 0.44103288650512695, 0.43921658396720886, 0.4363410472869873, 0.43548887968063354, 0.43538230657577515, 0.43674036860466003, 0.43062910437583923, 0.4318958520889282, 0.4312427341938019, 0.42903849482536316, 0.4272695779800415, 0.4261524975299835, 0.4252202808856964, 0.4246295690536499, 0.4234221577644348, 0.4225319027900696, 0.4230272173881531, 0.42082008719444275, 0.41977837681770325, 0.4193408787250519, 0.4204913079738617, 0.421908438205719, 0.41862931847572327, 0.4161820411682129, 0.4217604100704193, 0.4129849970340729, 0.4126870334148407, 0.4434269964694977, 0.41283658146858215, 0.4102383255958557, 0.4089505672454834, 0.40946659445762634, 0.4129610061645508, 0.4071546494960785, 0.40579819679260254, 0.4076283276081085, 0.40516725182533264, 0.40338465571403503, 0.4048547148704529, 0.40227988362312317, 0.40366241335868835, 0.401077002286911, 0.40082886815071106, 0.4004164934158325, 0.4009336531162262, 0.4007113575935364, 0.405915230512619, 0.4016115665435791, 0.40031054615974426, 0.4005463719367981, 0.40255290269851685, 0.3983665108680725, 0.41683652997016907, 0.39675408601760864, 0.3985127806663513, 0.3963843584060669, 0.4013480544090271, 0.40559035539627075, 0.42447328567504883, 0.4001215100288391, 0.39870789647102356, 0.4001799523830414, 0.39778080582618713, 0.4077892005443573, 0.3976224362850189, 0.4059212803840637, 0.3961142897605896, 0.41650786995887756, 0.39421287178993225, 0.39425158500671387, 0.41270777583122253, 0.4365783631801605], 'val_accuracy': [0.5021413564682007, 0.6659528613090515, 0.6134903430938721, 0.6852248311042786, 0.6884368062019348, 0.6895074844360352, 0.7087794542312622, 0.7152034044265747, 0.7248393893241882, 0.7366167306900024, 0.7312633991241455, 0.7687366008758545, 0.7451820373535156, 0.7569593191146851, 0.7537473440170288, 0.783725917339325, 0.7644539475440979, 0.7773019075393677, 0.7762312889099121, 0.7912205457687378, 0.7719486355781555, 0.7922912240028381, 0.7933619022369385, 0.7965738773345947, 0.7869378924369812, 0.8008565306663513, 0.7987151741981506, 0.7987151741981506, 0.8019272089004517, 0.8019272089004517, 0.8062098622322083, 0.8083511590957642, 0.8083511590957642, 0.8147751688957214, 0.8083511590957642, 0.8094218373298645, 0.8115631937980652, 0.8137044906616211, 0.8072805404663086, 0.8104925155639648, 0.8083511590957642, 0.8115631937980652, 0.8201285004615784, 0.8115631937980652, 0.8115631937980652, 0.8137044906616211, 0.8211991190910339, 0.8147751688957214, 0.8137044906616211, 0.8147751688957214, 0.8201285004615784, 0.8158458471298218, 0.8158458471298218, 0.8179871439933777, 0.8169164657592773, 0.8051391839981079, 0.8179871439933777, 0.8211991190910339, 0.8169164657592773, 0.819057822227478, 0.8201285004615784, 0.8222697973251343, 0.8254817724227905, 0.824411153793335, 0.8201285004615784, 0.8233404755592346, 0.8179871439933777, 0.8265524506568909, 0.8233404755592346, 0.824411153793335, 0.8265524506568909, 0.8233404755592346, 0.8201285004615784, 0.8211991190910339, 0.8169164657592773, 0.8201285004615784, 0.8265524506568909, 0.8276231288909912, 0.8265524506568909, 0.8222697973251343, 0.819057822227478, 0.8265524506568909, 0.8254817724227905, 0.8286938071250916, 0.8329764604568481, 0.8201285004615784, 0.819057822227478, 0.8329764604568481, 0.824411153793335, 0.8254817724227905, 0.8308351039886475, 0.8254817724227905, 0.8319057822227478, 0.8265524506568909, 0.8286938071250916, 0.824411153793335, 0.835117757320404, 0.8340471386909485, 0.8222697973251343, 0.8094218373298645]}\n","37/37 [==============================] - 1s 6ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 7s 50ms/step - loss: 0.3693 - accuracy: 0.8406 - val_loss: 0.6800 - val_accuracy: 0.4989\n","Epoch 2/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3679 - accuracy: 0.8409 - val_loss: 0.6753 - val_accuracy: 0.5118\n","Epoch 3/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3613 - accuracy: 0.8465 - val_loss: 0.6700 - val_accuracy: 0.6617\n","Epoch 4/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3586 - accuracy: 0.8478 - val_loss: 0.6645 - val_accuracy: 0.7570\n","Epoch 5/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3580 - accuracy: 0.8497 - val_loss: 0.6575 - val_accuracy: 0.8030\n","Epoch 6/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3521 - accuracy: 0.8524 - val_loss: 0.6502 - val_accuracy: 0.8116\n","Epoch 7/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3470 - accuracy: 0.8551 - val_loss: 0.6426 - val_accuracy: 0.8126\n","Epoch 8/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3471 - accuracy: 0.8588 - val_loss: 0.6318 - val_accuracy: 0.8041\n","Epoch 9/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3475 - accuracy: 0.8505 - val_loss: 0.6220 - val_accuracy: 0.8062\n","Epoch 10/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3570 - accuracy: 0.8484 - val_loss: 0.6087 - val_accuracy: 0.8094\n","Epoch 11/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3492 - accuracy: 0.8478 - val_loss: 0.5937 - val_accuracy: 0.8062\n","Epoch 12/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3452 - accuracy: 0.8561 - val_loss: 0.5737 - val_accuracy: 0.7944\n","Epoch 13/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3418 - accuracy: 0.8599 - val_loss: 0.5582 - val_accuracy: 0.7923\n","Epoch 14/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3359 - accuracy: 0.8623 - val_loss: 0.5356 - val_accuracy: 0.7805\n","Epoch 15/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3345 - accuracy: 0.8623 - val_loss: 0.5168 - val_accuracy: 0.7869\n","Epoch 16/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3357 - accuracy: 0.8618 - val_loss: 0.4910 - val_accuracy: 0.7912\n","Epoch 17/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3323 - accuracy: 0.8575 - val_loss: 0.4690 - val_accuracy: 0.8051\n","Epoch 18/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3269 - accuracy: 0.8650 - val_loss: 0.4631 - val_accuracy: 0.7805\n","Epoch 19/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3374 - accuracy: 0.8578 - val_loss: 0.4606 - val_accuracy: 0.7805\n","Epoch 20/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3335 - accuracy: 0.8618 - val_loss: 0.4292 - val_accuracy: 0.8051\n","Epoch 21/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3272 - accuracy: 0.8636 - val_loss: 0.4266 - val_accuracy: 0.8062\n","Epoch 22/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3245 - accuracy: 0.8679 - val_loss: 0.4256 - val_accuracy: 0.8062\n","Epoch 23/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3148 - accuracy: 0.8706 - val_loss: 0.4253 - val_accuracy: 0.8094\n","Epoch 24/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3198 - accuracy: 0.8701 - val_loss: 0.4186 - val_accuracy: 0.8169\n","Epoch 25/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3214 - accuracy: 0.8661 - val_loss: 0.4261 - val_accuracy: 0.8191\n","Epoch 26/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3200 - accuracy: 0.8720 - val_loss: 0.4346 - val_accuracy: 0.8084\n","Epoch 27/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3144 - accuracy: 0.8709 - val_loss: 0.4328 - val_accuracy: 0.8212\n","Epoch 28/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3161 - accuracy: 0.8725 - val_loss: 0.4454 - val_accuracy: 0.8084\n","Epoch 29/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3138 - accuracy: 0.8703 - val_loss: 0.4380 - val_accuracy: 0.8201\n","Epoch 30/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3066 - accuracy: 0.8752 - val_loss: 0.4509 - val_accuracy: 0.8094\n","Epoch 31/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3134 - accuracy: 0.8733 - val_loss: 0.4354 - val_accuracy: 0.8126\n","Epoch 32/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3143 - accuracy: 0.8752 - val_loss: 0.4411 - val_accuracy: 0.8137\n","Epoch 33/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3076 - accuracy: 0.8733 - val_loss: 0.4455 - val_accuracy: 0.8148\n","Epoch 34/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3206 - accuracy: 0.8690 - val_loss: 0.4542 - val_accuracy: 0.8051\n","Epoch 35/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3064 - accuracy: 0.8720 - val_loss: 0.4378 - val_accuracy: 0.8212\n","Epoch 36/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3002 - accuracy: 0.8744 - val_loss: 0.4408 - val_accuracy: 0.8116\n","Epoch 37/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3040 - accuracy: 0.8744 - val_loss: 0.4529 - val_accuracy: 0.8180\n","Epoch 38/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3017 - accuracy: 0.8781 - val_loss: 0.4451 - val_accuracy: 0.8223\n","Epoch 39/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2995 - accuracy: 0.8770 - val_loss: 0.4577 - val_accuracy: 0.8126\n","Epoch 40/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3059 - accuracy: 0.8722 - val_loss: 0.4420 - val_accuracy: 0.8244\n","Epoch 41/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2951 - accuracy: 0.8853 - val_loss: 0.4401 - val_accuracy: 0.8255\n","Epoch 42/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2966 - accuracy: 0.8813 - val_loss: 0.4432 - val_accuracy: 0.8223\n","Epoch 43/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2920 - accuracy: 0.8845 - val_loss: 0.4523 - val_accuracy: 0.8266\n","Epoch 44/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2917 - accuracy: 0.8840 - val_loss: 0.4515 - val_accuracy: 0.8148\n","Epoch 45/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2879 - accuracy: 0.8853 - val_loss: 0.4375 - val_accuracy: 0.8266\n","Epoch 46/100\n","30/30 [==============================] - 0s 13ms/step - loss: 0.2900 - accuracy: 0.8832 - val_loss: 0.4462 - val_accuracy: 0.8201\n","Epoch 47/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2890 - accuracy: 0.8864 - val_loss: 0.4448 - val_accuracy: 0.8233\n","Epoch 48/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2881 - accuracy: 0.8851 - val_loss: 0.4628 - val_accuracy: 0.8126\n","Epoch 49/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2838 - accuracy: 0.8896 - val_loss: 0.4482 - val_accuracy: 0.8233\n","Epoch 50/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2876 - accuracy: 0.8872 - val_loss: 0.4491 - val_accuracy: 0.8191\n","Epoch 51/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2906 - accuracy: 0.8829 - val_loss: 0.4486 - val_accuracy: 0.8212\n","Epoch 52/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2810 - accuracy: 0.8872 - val_loss: 0.4379 - val_accuracy: 0.8255\n","Epoch 53/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2840 - accuracy: 0.8862 - val_loss: 0.4952 - val_accuracy: 0.8051\n","Epoch 54/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2848 - accuracy: 0.8910 - val_loss: 0.4481 - val_accuracy: 0.8223\n","Epoch 55/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2740 - accuracy: 0.8950 - val_loss: 0.4551 - val_accuracy: 0.8233\n","Epoch 56/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2759 - accuracy: 0.8888 - val_loss: 0.4639 - val_accuracy: 0.8148\n","Epoch 57/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2773 - accuracy: 0.8851 - val_loss: 0.4584 - val_accuracy: 0.8180\n","Epoch 58/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2754 - accuracy: 0.8880 - val_loss: 0.4922 - val_accuracy: 0.8084\n","Epoch 59/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2823 - accuracy: 0.8837 - val_loss: 0.4690 - val_accuracy: 0.8126\n","Epoch 60/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2711 - accuracy: 0.8939 - val_loss: 0.4408 - val_accuracy: 0.8233\n","Epoch 61/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2634 - accuracy: 0.8993 - val_loss: 0.4465 - val_accuracy: 0.8255\n","Epoch 62/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2715 - accuracy: 0.8843 - val_loss: 0.4749 - val_accuracy: 0.8201\n","Epoch 63/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2623 - accuracy: 0.9025 - val_loss: 0.4491 - val_accuracy: 0.8233\n","Epoch 64/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2589 - accuracy: 0.9003 - val_loss: 0.4519 - val_accuracy: 0.8287\n","Epoch 65/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2660 - accuracy: 0.8979 - val_loss: 0.4427 - val_accuracy: 0.8298\n","Epoch 66/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2607 - accuracy: 0.8974 - val_loss: 0.4480 - val_accuracy: 0.8255\n","Epoch 67/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2547 - accuracy: 0.8998 - val_loss: 0.5718 - val_accuracy: 0.7762\n","Epoch 68/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2926 - accuracy: 0.8832 - val_loss: 0.4589 - val_accuracy: 0.8191\n","Epoch 69/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2607 - accuracy: 0.8985 - val_loss: 0.4701 - val_accuracy: 0.8180\n","Epoch 70/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2859 - accuracy: 0.8845 - val_loss: 0.4491 - val_accuracy: 0.8298\n","Epoch 71/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2803 - accuracy: 0.8859 - val_loss: 0.4419 - val_accuracy: 0.8255\n","Epoch 72/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2539 - accuracy: 0.9046 - val_loss: 0.4387 - val_accuracy: 0.8244\n","Epoch 73/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2548 - accuracy: 0.8985 - val_loss: 0.4433 - val_accuracy: 0.8244\n","Epoch 74/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2449 - accuracy: 0.9036 - val_loss: 0.4464 - val_accuracy: 0.8266\n","Epoch 75/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2507 - accuracy: 0.9062 - val_loss: 0.4516 - val_accuracy: 0.8276\n","Epoch 76/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2508 - accuracy: 0.9052 - val_loss: 0.4683 - val_accuracy: 0.8201\n","Epoch 77/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2487 - accuracy: 0.9006 - val_loss: 0.5469 - val_accuracy: 0.7794\n","Epoch 78/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2687 - accuracy: 0.8880 - val_loss: 0.4579 - val_accuracy: 0.8287\n","Epoch 79/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2463 - accuracy: 0.9070 - val_loss: 0.4520 - val_accuracy: 0.8244\n","Epoch 80/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2449 - accuracy: 0.9012 - val_loss: 0.4518 - val_accuracy: 0.8255\n","Epoch 81/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2385 - accuracy: 0.9084 - val_loss: 0.4635 - val_accuracy: 0.8255\n","Epoch 82/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2388 - accuracy: 0.9062 - val_loss: 0.4516 - val_accuracy: 0.8233\n","Epoch 83/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2475 - accuracy: 0.9065 - val_loss: 0.4805 - val_accuracy: 0.8233\n","Epoch 84/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2443 - accuracy: 0.9073 - val_loss: 0.4487 - val_accuracy: 0.8308\n","Epoch 85/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2350 - accuracy: 0.9081 - val_loss: 0.4503 - val_accuracy: 0.8362\n","Epoch 86/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2309 - accuracy: 0.9095 - val_loss: 0.4534 - val_accuracy: 0.8276\n","Epoch 87/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2277 - accuracy: 0.9113 - val_loss: 0.4633 - val_accuracy: 0.8276\n","Epoch 88/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2270 - accuracy: 0.9121 - val_loss: 0.4763 - val_accuracy: 0.8244\n","Epoch 89/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2442 - accuracy: 0.9044 - val_loss: 0.4605 - val_accuracy: 0.8308\n","Epoch 90/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2298 - accuracy: 0.9070 - val_loss: 0.4572 - val_accuracy: 0.8276\n","Epoch 91/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2413 - accuracy: 0.8998 - val_loss: 0.4555 - val_accuracy: 0.8298\n","Epoch 92/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2316 - accuracy: 0.9076 - val_loss: 0.4467 - val_accuracy: 0.8383\n","Epoch 93/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2218 - accuracy: 0.9132 - val_loss: 0.4537 - val_accuracy: 0.8373\n","Epoch 94/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2237 - accuracy: 0.9156 - val_loss: 0.4707 - val_accuracy: 0.8330\n","Epoch 95/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2222 - accuracy: 0.9119 - val_loss: 0.4846 - val_accuracy: 0.8266\n","Epoch 96/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2139 - accuracy: 0.9135 - val_loss: 0.4593 - val_accuracy: 0.8276\n","Epoch 97/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2162 - accuracy: 0.9148 - val_loss: 0.4747 - val_accuracy: 0.8330\n","Epoch 98/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2273 - accuracy: 0.9087 - val_loss: 0.4661 - val_accuracy: 0.8319\n","Epoch 99/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2143 - accuracy: 0.9199 - val_loss: 0.4670 - val_accuracy: 0.8212\n","Epoch 100/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2161 - accuracy: 0.9132 - val_loss: 0.4573 - val_accuracy: 0.8373\n","{'loss': [0.3692573606967926, 0.36791545152664185, 0.3612973988056183, 0.3585761785507202, 0.35803887248039246, 0.3520856499671936, 0.3469841480255127, 0.34714341163635254, 0.3474547564983368, 0.3570191264152527, 0.34915411472320557, 0.34515804052352905, 0.34176337718963623, 0.33590754866600037, 0.334506630897522, 0.3356654942035675, 0.33225515484809875, 0.3269104063510895, 0.3373924791812897, 0.33351150155067444, 0.32722049951553345, 0.32452481985092163, 0.3148082494735718, 0.3198380768299103, 0.3213804364204407, 0.32004469633102417, 0.31444448232650757, 0.3160519003868103, 0.3137654960155487, 0.3065921664237976, 0.31342288851737976, 0.31425541639328003, 0.3075826168060303, 0.3206460475921631, 0.3063777685165405, 0.3001747131347656, 0.3040047585964203, 0.3017288148403168, 0.2995404303073883, 0.30592575669288635, 0.29508453607559204, 0.29659685492515564, 0.29195332527160645, 0.2917019724845886, 0.2878846228122711, 0.2899688184261322, 0.28896114230155945, 0.2881474196910858, 0.2837684750556946, 0.2875760495662689, 0.29057034850120544, 0.28097718954086304, 0.28397732973098755, 0.2848038375377655, 0.2740101218223572, 0.275936096906662, 0.2773052155971527, 0.27538833022117615, 0.28231188654899597, 0.2710712254047394, 0.2633712589740753, 0.2714526653289795, 0.26233604550361633, 0.2589251697063446, 0.2660134732723236, 0.2607041001319885, 0.2547209560871124, 0.2926263213157654, 0.26066020131111145, 0.28589844703674316, 0.2803056240081787, 0.2538784146308899, 0.2547934055328369, 0.24490028619766235, 0.25065892934799194, 0.25079235434532166, 0.24871526658535004, 0.26870885491371155, 0.24630960822105408, 0.24490761756896973, 0.23849539458751678, 0.23884648084640503, 0.24751868844032288, 0.24425414204597473, 0.23495106399059296, 0.2308901697397232, 0.22773118317127228, 0.22703836858272552, 0.24416041374206543, 0.2298348844051361, 0.24130874872207642, 0.2315523475408554, 0.22178247570991516, 0.22373628616333008, 0.22217102348804474, 0.2138901799917221, 0.21623745560646057, 0.22734268009662628, 0.2143058478832245, 0.21606437861919403], 'accuracy': [0.8406107425689697, 0.8408786654472351, 0.8465041518211365, 0.8478435277938843, 0.8497187495231628, 0.8523975610733032, 0.8550763726234436, 0.8588266968727112, 0.8505223393440247, 0.8483793139457703, 0.8478435277938843, 0.8561478853225708, 0.8598982095718384, 0.8623091578483582, 0.8623091578483582, 0.8617733716964722, 0.8574872612953186, 0.8649879693984985, 0.857755184173584, 0.8617733716964722, 0.863648533821106, 0.8679346442222595, 0.8706134557723999, 0.8700776696205139, 0.8660594820976257, 0.8719528317451477, 0.8708813190460205, 0.8724886178970337, 0.8703455924987793, 0.8751674294471741, 0.8732922673225403, 0.8751674294471741, 0.8732922673225403, 0.8690061569213867, 0.8719528317451477, 0.8743637800216675, 0.8743637800216675, 0.8781141042709351, 0.8770425915718079, 0.8722207546234131, 0.8853468894958496, 0.8813287019729614, 0.884543240070343, 0.8840075135231018, 0.8853468894958496, 0.8832038640975952, 0.8864184021949768, 0.885079026222229, 0.8896329998970032, 0.8872220516204834, 0.8829360008239746, 0.8872220516204834, 0.8861505389213562, 0.8909724354743958, 0.8949906229972839, 0.8888293504714966, 0.885079026222229, 0.88802570104599, 0.8837395906448364, 0.8939191102981567, 0.8992767333984375, 0.8842753767967224, 0.9024912714958191, 0.9003482460975647, 0.8979372978210449, 0.8974015712738037, 0.8998124599456787, 0.8832038640975952, 0.8984730839729309, 0.884543240070343, 0.8858826756477356, 0.9046343564987183, 0.8984730839729309, 0.9035628437995911, 0.9062416553497314, 0.9051700830459595, 0.9006161093711853, 0.88802570104599, 0.9070452451705933, 0.9011518955230713, 0.9083846807479858, 0.9062416553497314, 0.906509518623352, 0.9073131680488586, 0.9081168174743652, 0.909456193447113, 0.9113313555717468, 0.9121350049972534, 0.9043664336204529, 0.9070452451705933, 0.8998124599456787, 0.9075810313224792, 0.9132065176963806, 0.9156174659729004, 0.9118671417236328, 0.913474440574646, 0.9148138165473938, 0.9086525440216064, 0.919903576374054, 0.9132065176963806], 'val_loss': [0.6800360679626465, 0.675287127494812, 0.6700109243392944, 0.664514422416687, 0.6575283408164978, 0.6502172946929932, 0.6425890922546387, 0.6318130493164062, 0.621970534324646, 0.6087002754211426, 0.5936504602432251, 0.5736922025680542, 0.5581560730934143, 0.5356290340423584, 0.51678466796875, 0.4909697473049164, 0.46897974610328674, 0.4631006717681885, 0.46062618494033813, 0.4292306900024414, 0.4266451299190521, 0.42564284801483154, 0.42529603838920593, 0.4186001718044281, 0.42605727910995483, 0.4345865845680237, 0.43278267979621887, 0.44542890787124634, 0.4379946291446686, 0.4508567452430725, 0.43540483713150024, 0.4411403238773346, 0.44551822543144226, 0.4542487859725952, 0.43784022331237793, 0.44078028202056885, 0.45291808247566223, 0.4450768232345581, 0.4576757848262787, 0.4419865608215332, 0.4400717616081238, 0.4431702494621277, 0.4522660970687866, 0.45149531960487366, 0.4374711215496063, 0.446162611246109, 0.44483426213264465, 0.46282005310058594, 0.44821012020111084, 0.4490884840488434, 0.4485979974269867, 0.43785014748573303, 0.4951770603656769, 0.4480803608894348, 0.4550797641277313, 0.46385300159454346, 0.45842817425727844, 0.4922240972518921, 0.46896228194236755, 0.4407961666584015, 0.4465414583683014, 0.47489696741104126, 0.4491179883480072, 0.45192569494247437, 0.4426902234554291, 0.4480004608631134, 0.5717766284942627, 0.45893576741218567, 0.47014951705932617, 0.4490600824356079, 0.44194096326828003, 0.4387410581111908, 0.4433440864086151, 0.44639140367507935, 0.4516370892524719, 0.46833524107933044, 0.5469247102737427, 0.45791095495224, 0.4519689381122589, 0.4517769515514374, 0.46353021264076233, 0.4515587389469147, 0.4805348217487335, 0.4487473666667938, 0.45029327273368835, 0.45344123244285583, 0.46329814195632935, 0.4763091504573822, 0.4604942798614502, 0.45724114775657654, 0.4554861783981323, 0.4467194080352783, 0.45370951294898987, 0.47074201703071594, 0.48457738757133484, 0.45933523774147034, 0.4746854603290558, 0.46606093645095825, 0.4670442044734955, 0.4573182165622711], 'val_accuracy': [0.49892932176589966, 0.5117772817611694, 0.6616702079772949, 0.7569593191146851, 0.802997887134552, 0.8115631937980652, 0.8126338124275208, 0.8040685057640076, 0.8062098622322083, 0.8094218373298645, 0.8062098622322083, 0.794432520866394, 0.7922912240028381, 0.7805139422416687, 0.7869378924369812, 0.7912205457687378, 0.8051391839981079, 0.7805139422416687, 0.7805139422416687, 0.8051391839981079, 0.8062098622322083, 0.8062098622322083, 0.8094218373298645, 0.8169164657592773, 0.819057822227478, 0.8083511590957642, 0.8211991190910339, 0.8083511590957642, 0.8201285004615784, 0.8094218373298645, 0.8126338124275208, 0.8137044906616211, 0.8147751688957214, 0.8051391839981079, 0.8211991190910339, 0.8115631937980652, 0.8179871439933777, 0.8222697973251343, 0.8126338124275208, 0.824411153793335, 0.8254817724227905, 0.8222697973251343, 0.8265524506568909, 0.8147751688957214, 0.8265524506568909, 0.8201285004615784, 0.8233404755592346, 0.8126338124275208, 0.8233404755592346, 0.819057822227478, 0.8211991190910339, 0.8254817724227905, 0.8051391839981079, 0.8222697973251343, 0.8233404755592346, 0.8147751688957214, 0.8179871439933777, 0.8083511590957642, 0.8126338124275208, 0.8233404755592346, 0.8254817724227905, 0.8201285004615784, 0.8233404755592346, 0.8286938071250916, 0.8297644257545471, 0.8254817724227905, 0.7762312889099121, 0.819057822227478, 0.8179871439933777, 0.8297644257545471, 0.8254817724227905, 0.824411153793335, 0.824411153793335, 0.8265524506568909, 0.8276231288909912, 0.8201285004615784, 0.7794432640075684, 0.8286938071250916, 0.824411153793335, 0.8254817724227905, 0.8254817724227905, 0.8233404755592346, 0.8233404755592346, 0.8308351039886475, 0.8361884355545044, 0.8276231288909912, 0.8276231288909912, 0.824411153793335, 0.8308351039886475, 0.8276231288909912, 0.8297644257545471, 0.8383297920227051, 0.8372591137886047, 0.8329764604568481, 0.8265524506568909, 0.8276231288909912, 0.8329764604568481, 0.8319057822227478, 0.8211991190910339, 0.8372591137886047]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 7s 50ms/step - loss: 0.3678 - accuracy: 0.8425 - val_loss: 0.6807 - val_accuracy: 0.4872\n","Epoch 2/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.3606 - accuracy: 0.8422 - val_loss: 0.6754 - val_accuracy: 0.5236\n","Epoch 3/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3604 - accuracy: 0.8428 - val_loss: 0.6702 - val_accuracy: 0.6809\n","Epoch 4/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3668 - accuracy: 0.8411 - val_loss: 0.6651 - val_accuracy: 0.6403\n","Epoch 5/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3581 - accuracy: 0.8425 - val_loss: 0.6577 - val_accuracy: 0.8448\n","Epoch 6/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3521 - accuracy: 0.8540 - val_loss: 0.6493 - val_accuracy: 0.8426\n","Epoch 7/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3447 - accuracy: 0.8570 - val_loss: 0.6413 - val_accuracy: 0.8415\n","Epoch 8/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3428 - accuracy: 0.8511 - val_loss: 0.6308 - val_accuracy: 0.8383\n","Epoch 9/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3559 - accuracy: 0.8468 - val_loss: 0.6191 - val_accuracy: 0.8330\n","Epoch 10/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3406 - accuracy: 0.8599 - val_loss: 0.6059 - val_accuracy: 0.8458\n","Epoch 11/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3458 - accuracy: 0.8529 - val_loss: 0.5893 - val_accuracy: 0.8351\n","Epoch 12/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3433 - accuracy: 0.8505 - val_loss: 0.5756 - val_accuracy: 0.7987\n","Epoch 13/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3399 - accuracy: 0.8521 - val_loss: 0.5513 - val_accuracy: 0.8126\n","Epoch 14/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3368 - accuracy: 0.8620 - val_loss: 0.5300 - val_accuracy: 0.8062\n","Epoch 15/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3346 - accuracy: 0.8596 - val_loss: 0.5067 - val_accuracy: 0.8009\n","Epoch 16/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3330 - accuracy: 0.8623 - val_loss: 0.4725 - val_accuracy: 0.8394\n","Epoch 17/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3355 - accuracy: 0.8586 - val_loss: 0.4483 - val_accuracy: 0.8458\n","Epoch 18/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3271 - accuracy: 0.8650 - val_loss: 0.4590 - val_accuracy: 0.7944\n","Epoch 19/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3285 - accuracy: 0.8612 - val_loss: 0.4156 - val_accuracy: 0.8351\n","Epoch 20/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.3234 - accuracy: 0.8685 - val_loss: 0.4019 - val_accuracy: 0.8362\n","Epoch 21/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3257 - accuracy: 0.8636 - val_loss: 0.3892 - val_accuracy: 0.8415\n","Epoch 22/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3270 - accuracy: 0.8650 - val_loss: 0.3719 - val_accuracy: 0.8458\n","Epoch 23/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3215 - accuracy: 0.8655 - val_loss: 0.3665 - val_accuracy: 0.8522\n","Epoch 24/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3204 - accuracy: 0.8703 - val_loss: 0.4006 - val_accuracy: 0.8330\n","Epoch 25/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3157 - accuracy: 0.8733 - val_loss: 0.3536 - val_accuracy: 0.8608\n","Epoch 26/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3184 - accuracy: 0.8679 - val_loss: 0.3544 - val_accuracy: 0.8608\n","Epoch 27/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3103 - accuracy: 0.8738 - val_loss: 0.3596 - val_accuracy: 0.8565\n","Epoch 28/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3246 - accuracy: 0.8647 - val_loss: 0.3616 - val_accuracy: 0.8512\n","Epoch 29/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3104 - accuracy: 0.8695 - val_loss: 0.3621 - val_accuracy: 0.8555\n","Epoch 30/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.3086 - accuracy: 0.8770 - val_loss: 0.3546 - val_accuracy: 0.8587\n","Epoch 31/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.3058 - accuracy: 0.8786 - val_loss: 0.3551 - val_accuracy: 0.8608\n","Epoch 32/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.3082 - accuracy: 0.8687 - val_loss: 0.3806 - val_accuracy: 0.8458\n","Epoch 33/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3115 - accuracy: 0.8655 - val_loss: 0.3556 - val_accuracy: 0.8587\n","Epoch 34/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3057 - accuracy: 0.8717 - val_loss: 0.3593 - val_accuracy: 0.8576\n","Epoch 35/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3031 - accuracy: 0.8706 - val_loss: 0.3542 - val_accuracy: 0.8662\n","Epoch 36/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3063 - accuracy: 0.8744 - val_loss: 0.3563 - val_accuracy: 0.8640\n","Epoch 37/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2941 - accuracy: 0.8811 - val_loss: 0.3556 - val_accuracy: 0.8565\n","Epoch 38/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2979 - accuracy: 0.8805 - val_loss: 0.3607 - val_accuracy: 0.8587\n","Epoch 39/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2960 - accuracy: 0.8776 - val_loss: 0.3565 - val_accuracy: 0.8608\n","Epoch 40/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3005 - accuracy: 0.8792 - val_loss: 0.3565 - val_accuracy: 0.8619\n","Epoch 41/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2940 - accuracy: 0.8770 - val_loss: 0.3573 - val_accuracy: 0.8704\n","Epoch 42/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3081 - accuracy: 0.8720 - val_loss: 0.3600 - val_accuracy: 0.8587\n","Epoch 43/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2942 - accuracy: 0.8803 - val_loss: 0.3672 - val_accuracy: 0.8490\n","Epoch 44/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2942 - accuracy: 0.8835 - val_loss: 0.3520 - val_accuracy: 0.8672\n","Epoch 45/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2867 - accuracy: 0.8832 - val_loss: 0.3663 - val_accuracy: 0.8555\n","Epoch 46/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2861 - accuracy: 0.8872 - val_loss: 0.3527 - val_accuracy: 0.8672\n","Epoch 47/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2836 - accuracy: 0.8915 - val_loss: 0.3520 - val_accuracy: 0.8672\n","Epoch 48/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2885 - accuracy: 0.8845 - val_loss: 0.3742 - val_accuracy: 0.8458\n","Epoch 49/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3127 - accuracy: 0.8682 - val_loss: 0.3498 - val_accuracy: 0.8619\n","Epoch 50/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2885 - accuracy: 0.8773 - val_loss: 0.3829 - val_accuracy: 0.8469\n","Epoch 51/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2902 - accuracy: 0.8789 - val_loss: 0.3541 - val_accuracy: 0.8651\n","Epoch 52/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2753 - accuracy: 0.8870 - val_loss: 0.3592 - val_accuracy: 0.8597\n","Epoch 53/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2780 - accuracy: 0.8915 - val_loss: 0.3603 - val_accuracy: 0.8565\n","Epoch 54/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2778 - accuracy: 0.8894 - val_loss: 0.3529 - val_accuracy: 0.8651\n","Epoch 55/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2784 - accuracy: 0.8915 - val_loss: 0.3486 - val_accuracy: 0.8619\n","Epoch 56/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2721 - accuracy: 0.8899 - val_loss: 0.3484 - val_accuracy: 0.8662\n","Epoch 57/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2775 - accuracy: 0.8904 - val_loss: 0.3509 - val_accuracy: 0.8726\n","Epoch 58/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2743 - accuracy: 0.8923 - val_loss: 0.3526 - val_accuracy: 0.8704\n","Epoch 59/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2688 - accuracy: 0.8947 - val_loss: 0.3502 - val_accuracy: 0.8694\n","Epoch 60/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2691 - accuracy: 0.8947 - val_loss: 0.3680 - val_accuracy: 0.8544\n","Epoch 61/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2674 - accuracy: 0.8958 - val_loss: 0.3672 - val_accuracy: 0.8533\n","Epoch 62/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2645 - accuracy: 0.8961 - val_loss: 0.3825 - val_accuracy: 0.8426\n","Epoch 63/100\n","30/30 [==============================] - 1s 16ms/step - loss: 0.2714 - accuracy: 0.8902 - val_loss: 0.3692 - val_accuracy: 0.8544\n","Epoch 64/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2641 - accuracy: 0.8923 - val_loss: 0.3537 - val_accuracy: 0.8715\n","Epoch 65/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2706 - accuracy: 0.8939 - val_loss: 0.3567 - val_accuracy: 0.8619\n","Epoch 66/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2658 - accuracy: 0.8947 - val_loss: 0.3476 - val_accuracy: 0.8662\n","Epoch 67/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2573 - accuracy: 0.8987 - val_loss: 0.3580 - val_accuracy: 0.8726\n","Epoch 68/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.2492 - accuracy: 0.9030 - val_loss: 0.3508 - val_accuracy: 0.8683\n","Epoch 69/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2545 - accuracy: 0.9009 - val_loss: 0.3798 - val_accuracy: 0.8533\n","Epoch 70/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2617 - accuracy: 0.8937 - val_loss: 0.3526 - val_accuracy: 0.8662\n","Epoch 71/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2509 - accuracy: 0.9020 - val_loss: 0.3662 - val_accuracy: 0.8587\n","Epoch 72/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2571 - accuracy: 0.8969 - val_loss: 0.3595 - val_accuracy: 0.8630\n","Epoch 73/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2505 - accuracy: 0.9038 - val_loss: 0.3505 - val_accuracy: 0.8672\n","Epoch 74/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2433 - accuracy: 0.9078 - val_loss: 0.3774 - val_accuracy: 0.8448\n","Epoch 75/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2551 - accuracy: 0.9038 - val_loss: 0.3589 - val_accuracy: 0.8662\n","Epoch 76/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2471 - accuracy: 0.9054 - val_loss: 0.3539 - val_accuracy: 0.8747\n","Epoch 77/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2399 - accuracy: 0.9081 - val_loss: 0.3687 - val_accuracy: 0.8597\n","Epoch 78/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2460 - accuracy: 0.8977 - val_loss: 0.3505 - val_accuracy: 0.8683\n","Epoch 79/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2436 - accuracy: 0.9017 - val_loss: 0.3906 - val_accuracy: 0.8522\n","Epoch 80/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2557 - accuracy: 0.8987 - val_loss: 0.4201 - val_accuracy: 0.8287\n","Epoch 81/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2526 - accuracy: 0.8977 - val_loss: 0.3493 - val_accuracy: 0.8715\n","Epoch 82/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2405 - accuracy: 0.9062 - val_loss: 0.3541 - val_accuracy: 0.8640\n","Epoch 83/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2445 - accuracy: 0.9025 - val_loss: 0.3492 - val_accuracy: 0.8704\n","Epoch 84/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2316 - accuracy: 0.9089 - val_loss: 0.3524 - val_accuracy: 0.8704\n","Epoch 85/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2323 - accuracy: 0.9078 - val_loss: 0.3578 - val_accuracy: 0.8683\n","Epoch 86/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2352 - accuracy: 0.9129 - val_loss: 0.3620 - val_accuracy: 0.8651\n","Epoch 87/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2327 - accuracy: 0.9097 - val_loss: 0.3629 - val_accuracy: 0.8683\n","Epoch 88/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2319 - accuracy: 0.9108 - val_loss: 0.3570 - val_accuracy: 0.8651\n","Epoch 89/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2256 - accuracy: 0.9143 - val_loss: 0.3500 - val_accuracy: 0.8672\n","Epoch 90/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2185 - accuracy: 0.9175 - val_loss: 0.3502 - val_accuracy: 0.8672\n","Epoch 91/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2203 - accuracy: 0.9140 - val_loss: 0.3575 - val_accuracy: 0.8683\n","Epoch 92/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2296 - accuracy: 0.9119 - val_loss: 0.3616 - val_accuracy: 0.8651\n","Epoch 93/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.2202 - accuracy: 0.9159 - val_loss: 0.3567 - val_accuracy: 0.8726\n","Epoch 94/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2247 - accuracy: 0.9111 - val_loss: 0.3728 - val_accuracy: 0.8662\n","Epoch 95/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2216 - accuracy: 0.9162 - val_loss: 0.3731 - val_accuracy: 0.8608\n","Epoch 96/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2316 - accuracy: 0.9097 - val_loss: 0.3475 - val_accuracy: 0.8694\n","Epoch 97/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2175 - accuracy: 0.9167 - val_loss: 0.3542 - val_accuracy: 0.8694\n","Epoch 98/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2131 - accuracy: 0.9194 - val_loss: 0.3608 - val_accuracy: 0.8694\n","Epoch 99/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2261 - accuracy: 0.9140 - val_loss: 0.3558 - val_accuracy: 0.8694\n","Epoch 100/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2187 - accuracy: 0.9180 - val_loss: 0.3457 - val_accuracy: 0.8683\n","{'loss': [0.3677709698677063, 0.3606172800064087, 0.360389769077301, 0.3667505383491516, 0.3581088185310364, 0.352139413356781, 0.34472301602363586, 0.3428118824958801, 0.35590434074401855, 0.34060579538345337, 0.34576985239982605, 0.34332984685897827, 0.33992254734039307, 0.33678755164146423, 0.33464697003364563, 0.3330477178096771, 0.33553099632263184, 0.32713252305984497, 0.3284912407398224, 0.3234092593193054, 0.3256876468658447, 0.32704633474349976, 0.32148149609565735, 0.3204338848590851, 0.31565776467323303, 0.318404883146286, 0.3102508783340454, 0.32458072900772095, 0.31036776304244995, 0.30858758091926575, 0.30580759048461914, 0.30815091729164124, 0.3114641010761261, 0.3056633770465851, 0.3031019866466522, 0.30626216530799866, 0.2941202223300934, 0.2979077398777008, 0.29604512453079224, 0.30048754811286926, 0.2939540445804596, 0.30811697244644165, 0.29418906569480896, 0.2941560447216034, 0.28669044375419617, 0.2861343026161194, 0.28359031677246094, 0.2884504795074463, 0.31271398067474365, 0.2884778082370758, 0.290219247341156, 0.2752505838871002, 0.27795422077178955, 0.2777939438819885, 0.2783602178096771, 0.2721041142940521, 0.2774937152862549, 0.27425119280815125, 0.26876500248908997, 0.26911044120788574, 0.2674320936203003, 0.2645033001899719, 0.27136722207069397, 0.2641455829143524, 0.2706035077571869, 0.2658109962940216, 0.2573131322860718, 0.2491702288389206, 0.25453808903694153, 0.26166608929634094, 0.25085529685020447, 0.25706982612609863, 0.2504868805408478, 0.2433243989944458, 0.25511783361434937, 0.24714355170726776, 0.23993036150932312, 0.2460005283355713, 0.24361152946949005, 0.2556762099266052, 0.252610981464386, 0.24051865935325623, 0.24445274472236633, 0.23159842193126678, 0.2323150634765625, 0.23521435260772705, 0.23267537355422974, 0.23193857073783875, 0.22559335827827454, 0.21845796704292297, 0.22026988863945007, 0.229575052857399, 0.22019818425178528, 0.22469989955425262, 0.2215615212917328, 0.23160329461097717, 0.2175484001636505, 0.21314647793769836, 0.22607079148292542, 0.21867148578166962], 'accuracy': [0.8424859642982483, 0.8422180414199829, 0.8427538275718689, 0.8411465287208557, 0.8424859642982483, 0.8540048003196716, 0.8569515347480774, 0.8510581254959106, 0.8467720150947571, 0.8598982095718384, 0.8529332876205444, 0.8505223393440247, 0.8521296381950378, 0.8620412349700928, 0.8596303462982178, 0.8623091578483582, 0.8585587739944458, 0.8649879693984985, 0.8612375855445862, 0.8684703707695007, 0.863648533821106, 0.8649879693984985, 0.8655236959457397, 0.8703455924987793, 0.8732922673225403, 0.8679346442222595, 0.8738279938697815, 0.8647200465202332, 0.8695419430732727, 0.8770425915718079, 0.878649890422821, 0.8687382936477661, 0.8655236959457397, 0.8716849684715271, 0.8706134557723999, 0.8743637800216675, 0.8810608386993408, 0.8805250525474548, 0.8775783777236938, 0.8791856169700623, 0.8770425915718079, 0.8719528317451477, 0.8802571892738342, 0.8834717273712158, 0.8832038640975952, 0.8872220516204834, 0.891508162021637, 0.884543240070343, 0.8682025074958801, 0.8773104548454285, 0.8789177536964417, 0.8869541883468628, 0.891508162021637, 0.8893651366233826, 0.891508162021637, 0.8899008631706238, 0.8904366493225098, 0.8923118114471436, 0.8947227597236633, 0.8947227597236633, 0.8957942724227905, 0.8960621356964111, 0.8901687860488892, 0.8923118114471436, 0.8939191102981567, 0.8947227597236633, 0.8987409472465515, 0.9030270576477051, 0.9008840322494507, 0.8936512470245361, 0.9019555449485779, 0.8968657851219177, 0.9038307070732117, 0.9078488945960999, 0.9038307070732117, 0.9054380059242249, 0.9081168174743652, 0.8976694345474243, 0.9016876220703125, 0.8987409472465515, 0.8976694345474243, 0.9062416553497314, 0.9024912714958191, 0.9089204668998718, 0.9078488945960999, 0.91293865442276, 0.9097240567207336, 0.9107956290245056, 0.9142780900001526, 0.9174926280975342, 0.9140101671218872, 0.9118671417236328, 0.915885329246521, 0.9110634922981262, 0.9161532521247864, 0.9097240567207336, 0.9166889786720276, 0.919367790222168, 0.9140101671218872, 0.9180284142494202], 'val_loss': [0.6806771755218506, 0.6754323840141296, 0.6701812148094177, 0.6650967001914978, 0.6576715111732483, 0.6493381261825562, 0.6412815451622009, 0.6308039426803589, 0.6191346645355225, 0.6058588624000549, 0.5893163084983826, 0.57563316822052, 0.5512738823890686, 0.5299779176712036, 0.506717324256897, 0.4724869728088379, 0.448326051235199, 0.4590190052986145, 0.4155791103839874, 0.40188419818878174, 0.38923895359039307, 0.3718755543231964, 0.3665216863155365, 0.4006047248840332, 0.3535503149032593, 0.35443180799484253, 0.3596011698246002, 0.3616158068180084, 0.36208710074424744, 0.35459673404693604, 0.3551062345504761, 0.380578875541687, 0.35561108589172363, 0.35926538705825806, 0.3541877567768097, 0.3563157916069031, 0.355599969625473, 0.36071449518203735, 0.3564545810222626, 0.35653185844421387, 0.35726895928382874, 0.36000820994377136, 0.3672211468219757, 0.35199570655822754, 0.3663236200809479, 0.35273662209510803, 0.35201820731163025, 0.3741524815559387, 0.3497612476348877, 0.3828528821468353, 0.35413214564323425, 0.359178364276886, 0.3602631986141205, 0.3529387414455414, 0.34856435656547546, 0.3484276533126831, 0.3509039580821991, 0.35257139801979065, 0.35024839639663696, 0.3680412471294403, 0.36718249320983887, 0.3824957609176636, 0.3691796660423279, 0.3536529839038849, 0.35669392347335815, 0.3475537896156311, 0.35802704095840454, 0.35079267621040344, 0.3797672688961029, 0.35263633728027344, 0.3662278950214386, 0.35947462916374207, 0.3505302667617798, 0.37742239236831665, 0.3589317202568054, 0.3538728952407837, 0.3687441945075989, 0.3504658639431, 0.3906300365924835, 0.4201090931892395, 0.3492562472820282, 0.3540632426738739, 0.34915387630462646, 0.35238662362098694, 0.35783764719963074, 0.36204761266708374, 0.3628880977630615, 0.356987863779068, 0.34999826550483704, 0.350227952003479, 0.35754910111427307, 0.3616084158420563, 0.35669249296188354, 0.372780442237854, 0.37306833267211914, 0.3474912643432617, 0.35418468713760376, 0.3607982397079468, 0.35580143332481384, 0.3457068204879761], 'val_accuracy': [0.4871520400047302, 0.5235546231269836, 0.680942177772522, 0.640256941318512, 0.8447537422180176, 0.8426124453544617, 0.8415417671203613, 0.8383297920227051, 0.8329764604568481, 0.8458244204521179, 0.835117757320404, 0.7987151741981506, 0.8126338124275208, 0.8062098622322083, 0.8008565306663513, 0.8394004106521606, 0.8458244204521179, 0.794432520866394, 0.835117757320404, 0.8361884355545044, 0.8415417671203613, 0.8458244204521179, 0.8522483706474304, 0.8329764604568481, 0.8608136773109436, 0.8608136773109436, 0.856531023979187, 0.8511777520179749, 0.8554604053497314, 0.8586723804473877, 0.8608136773109436, 0.8458244204521179, 0.8586723804473877, 0.8576017022132874, 0.8661670088768005, 0.8640257120132446, 0.856531023979187, 0.8586723804473877, 0.8608136773109436, 0.861884355545044, 0.8704496622085571, 0.8586723804473877, 0.8490363955497742, 0.8672376871109009, 0.8554604053497314, 0.8672376871109009, 0.8672376871109009, 0.8458244204521179, 0.861884355545044, 0.8468950986862183, 0.8650963306427002, 0.859743058681488, 0.856531023979187, 0.8650963306427002, 0.861884355545044, 0.8661670088768005, 0.8725910186767578, 0.8704496622085571, 0.8693790435791016, 0.8543897271156311, 0.8533190488815308, 0.8426124453544617, 0.8543897271156311, 0.8715203404426575, 0.861884355545044, 0.8661670088768005, 0.8725910186767578, 0.8683083653450012, 0.8533190488815308, 0.8661670088768005, 0.8586723804473877, 0.8629550337791443, 0.8672376871109009, 0.8447537422180176, 0.8661670088768005, 0.8747323155403137, 0.859743058681488, 0.8683083653450012, 0.8522483706474304, 0.8286938071250916, 0.8715203404426575, 0.8640257120132446, 0.8704496622085571, 0.8704496622085571, 0.8683083653450012, 0.8650963306427002, 0.8683083653450012, 0.8650963306427002, 0.8672376871109009, 0.8672376871109009, 0.8683083653450012, 0.8650963306427002, 0.8725910186767578, 0.8661670088768005, 0.8608136773109436, 0.8693790435791016, 0.8693790435791016, 0.8693790435791016, 0.8693790435791016, 0.8683083653450012]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 7s 50ms/step - loss: 0.3832 - accuracy: 0.8369 - val_loss: 0.6792 - val_accuracy: 0.5043\n","Epoch 2/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.3741 - accuracy: 0.8387 - val_loss: 0.6746 - val_accuracy: 0.5278\n","Epoch 3/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3702 - accuracy: 0.8406 - val_loss: 0.6699 - val_accuracy: 0.6745\n","Epoch 4/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3636 - accuracy: 0.8478 - val_loss: 0.6639 - val_accuracy: 0.7805\n","Epoch 5/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3638 - accuracy: 0.8473 - val_loss: 0.6571 - val_accuracy: 0.8351\n","Epoch 6/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3633 - accuracy: 0.8438 - val_loss: 0.6491 - val_accuracy: 0.8373\n","Epoch 7/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3604 - accuracy: 0.8422 - val_loss: 0.6427 - val_accuracy: 0.8405\n","Epoch 8/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3577 - accuracy: 0.8468 - val_loss: 0.6340 - val_accuracy: 0.8105\n","Epoch 9/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3575 - accuracy: 0.8449 - val_loss: 0.6234 - val_accuracy: 0.7580\n","Epoch 10/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.3568 - accuracy: 0.8481 - val_loss: 0.6092 - val_accuracy: 0.8062\n","Epoch 11/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3497 - accuracy: 0.8535 - val_loss: 0.5936 - val_accuracy: 0.8308\n","Epoch 12/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.3459 - accuracy: 0.8545 - val_loss: 0.5740 - val_accuracy: 0.8405\n","Epoch 13/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3472 - accuracy: 0.8516 - val_loss: 0.5546 - val_accuracy: 0.8126\n","Epoch 14/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3519 - accuracy: 0.8484 - val_loss: 0.5316 - val_accuracy: 0.8009\n","Epoch 15/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3485 - accuracy: 0.8516 - val_loss: 0.5069 - val_accuracy: 0.8116\n","Epoch 16/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3434 - accuracy: 0.8529 - val_loss: 0.4849 - val_accuracy: 0.8266\n","Epoch 17/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3437 - accuracy: 0.8545 - val_loss: 0.4553 - val_accuracy: 0.8340\n","Epoch 18/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3375 - accuracy: 0.8551 - val_loss: 0.4591 - val_accuracy: 0.7955\n","Epoch 19/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3346 - accuracy: 0.8636 - val_loss: 0.4389 - val_accuracy: 0.8105\n","Epoch 20/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3380 - accuracy: 0.8575 - val_loss: 0.4187 - val_accuracy: 0.8212\n","Epoch 21/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3350 - accuracy: 0.8545 - val_loss: 0.4013 - val_accuracy: 0.8340\n","Epoch 22/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3378 - accuracy: 0.8578 - val_loss: 0.3831 - val_accuracy: 0.8362\n","Epoch 23/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3286 - accuracy: 0.8653 - val_loss: 0.3745 - val_accuracy: 0.8469\n","Epoch 24/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3213 - accuracy: 0.8687 - val_loss: 0.3768 - val_accuracy: 0.8426\n","Epoch 25/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3318 - accuracy: 0.8628 - val_loss: 0.3791 - val_accuracy: 0.8426\n","Epoch 26/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.3234 - accuracy: 0.8671 - val_loss: 0.3936 - val_accuracy: 0.8308\n","Epoch 27/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3207 - accuracy: 0.8655 - val_loss: 0.3867 - val_accuracy: 0.8437\n","Epoch 28/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3244 - accuracy: 0.8669 - val_loss: 0.3815 - val_accuracy: 0.8448\n","Epoch 29/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3217 - accuracy: 0.8669 - val_loss: 0.3709 - val_accuracy: 0.8576\n","Epoch 30/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3206 - accuracy: 0.8658 - val_loss: 0.3785 - val_accuracy: 0.8544\n","Epoch 31/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3124 - accuracy: 0.8765 - val_loss: 0.3686 - val_accuracy: 0.8544\n","Epoch 32/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.3131 - accuracy: 0.8728 - val_loss: 0.3976 - val_accuracy: 0.8351\n","Epoch 33/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3218 - accuracy: 0.8658 - val_loss: 0.4161 - val_accuracy: 0.8073\n","Epoch 34/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.3206 - accuracy: 0.8620 - val_loss: 0.3746 - val_accuracy: 0.8415\n","Epoch 35/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.3153 - accuracy: 0.8706 - val_loss: 0.3962 - val_accuracy: 0.8426\n","Epoch 36/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3100 - accuracy: 0.8682 - val_loss: 0.3737 - val_accuracy: 0.8522\n","Epoch 37/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3142 - accuracy: 0.8703 - val_loss: 0.3930 - val_accuracy: 0.8340\n","Epoch 38/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3107 - accuracy: 0.8698 - val_loss: 0.3712 - val_accuracy: 0.8576\n","Epoch 39/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3162 - accuracy: 0.8669 - val_loss: 0.3705 - val_accuracy: 0.8576\n","Epoch 40/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.3053 - accuracy: 0.8776 - val_loss: 0.3785 - val_accuracy: 0.8522\n","Epoch 41/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.3053 - accuracy: 0.8741 - val_loss: 0.3685 - val_accuracy: 0.8587\n","Epoch 42/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2985 - accuracy: 0.8725 - val_loss: 0.3712 - val_accuracy: 0.8544\n","Epoch 43/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2967 - accuracy: 0.8762 - val_loss: 0.3725 - val_accuracy: 0.8490\n","Epoch 44/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2935 - accuracy: 0.8843 - val_loss: 0.3789 - val_accuracy: 0.8458\n","Epoch 45/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.2983 - accuracy: 0.8736 - val_loss: 0.3766 - val_accuracy: 0.8555\n","Epoch 46/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.3011 - accuracy: 0.8800 - val_loss: 0.3847 - val_accuracy: 0.8405\n","Epoch 47/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2939 - accuracy: 0.8770 - val_loss: 0.3726 - val_accuracy: 0.8555\n","Epoch 48/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2913 - accuracy: 0.8811 - val_loss: 0.3928 - val_accuracy: 0.8351\n","Epoch 49/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2928 - accuracy: 0.8816 - val_loss: 0.3746 - val_accuracy: 0.8565\n","Epoch 50/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2888 - accuracy: 0.8797 - val_loss: 0.3798 - val_accuracy: 0.8512\n","Epoch 51/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2911 - accuracy: 0.8803 - val_loss: 0.3793 - val_accuracy: 0.8565\n","Epoch 52/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2867 - accuracy: 0.8829 - val_loss: 0.3970 - val_accuracy: 0.8276\n","Epoch 53/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2877 - accuracy: 0.8757 - val_loss: 0.4063 - val_accuracy: 0.8244\n","Epoch 54/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2971 - accuracy: 0.8773 - val_loss: 0.4425 - val_accuracy: 0.8287\n","Epoch 55/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2851 - accuracy: 0.8808 - val_loss: 0.3773 - val_accuracy: 0.8555\n","Epoch 56/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2844 - accuracy: 0.8800 - val_loss: 0.3829 - val_accuracy: 0.8469\n","Epoch 57/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2754 - accuracy: 0.8864 - val_loss: 0.3853 - val_accuracy: 0.8415\n","Epoch 58/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2755 - accuracy: 0.8870 - val_loss: 0.3797 - val_accuracy: 0.8544\n","Epoch 59/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2690 - accuracy: 0.8891 - val_loss: 0.3803 - val_accuracy: 0.8512\n","Epoch 60/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2692 - accuracy: 0.8918 - val_loss: 0.3827 - val_accuracy: 0.8522\n","Epoch 61/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2677 - accuracy: 0.8880 - val_loss: 0.3826 - val_accuracy: 0.8501\n","Epoch 62/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2673 - accuracy: 0.8950 - val_loss: 0.4066 - val_accuracy: 0.8448\n","Epoch 63/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2753 - accuracy: 0.8840 - val_loss: 0.4213 - val_accuracy: 0.8169\n","Epoch 64/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2665 - accuracy: 0.8899 - val_loss: 0.3863 - val_accuracy: 0.8522\n","Epoch 65/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2625 - accuracy: 0.8880 - val_loss: 0.3866 - val_accuracy: 0.8533\n","Epoch 66/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2561 - accuracy: 0.8982 - val_loss: 0.3858 - val_accuracy: 0.8501\n","Epoch 67/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2534 - accuracy: 0.8969 - val_loss: 0.3911 - val_accuracy: 0.8415\n","Epoch 68/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2573 - accuracy: 0.8947 - val_loss: 0.3864 - val_accuracy: 0.8512\n","Epoch 69/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2541 - accuracy: 0.8963 - val_loss: 0.3918 - val_accuracy: 0.8512\n","Epoch 70/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.2472 - accuracy: 0.9001 - val_loss: 0.3962 - val_accuracy: 0.8544\n","Epoch 71/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.2532 - accuracy: 0.8990 - val_loss: 0.3935 - val_accuracy: 0.8512\n","Epoch 72/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2624 - accuracy: 0.8880 - val_loss: 0.3913 - val_accuracy: 0.8544\n","Epoch 73/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2619 - accuracy: 0.8958 - val_loss: 0.4203 - val_accuracy: 0.8180\n","Epoch 74/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2476 - accuracy: 0.8987 - val_loss: 0.3859 - val_accuracy: 0.8544\n","Epoch 75/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2486 - accuracy: 0.9041 - val_loss: 0.3924 - val_accuracy: 0.8480\n","Epoch 76/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2447 - accuracy: 0.8998 - val_loss: 0.3918 - val_accuracy: 0.8501\n","Epoch 77/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2462 - accuracy: 0.9001 - val_loss: 0.4007 - val_accuracy: 0.8533\n","Epoch 78/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2376 - accuracy: 0.9038 - val_loss: 0.4140 - val_accuracy: 0.8512\n","Epoch 79/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2439 - accuracy: 0.9054 - val_loss: 0.4036 - val_accuracy: 0.8522\n","Epoch 80/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2409 - accuracy: 0.9014 - val_loss: 0.3942 - val_accuracy: 0.8501\n","Epoch 81/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2380 - accuracy: 0.9038 - val_loss: 0.3983 - val_accuracy: 0.8458\n","Epoch 82/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2388 - accuracy: 0.9022 - val_loss: 0.3962 - val_accuracy: 0.8501\n","Epoch 83/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2302 - accuracy: 0.9028 - val_loss: 0.3942 - val_accuracy: 0.8522\n","Epoch 84/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2287 - accuracy: 0.9081 - val_loss: 0.3986 - val_accuracy: 0.8544\n","Epoch 85/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2305 - accuracy: 0.9070 - val_loss: 0.4301 - val_accuracy: 0.8266\n","Epoch 86/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2388 - accuracy: 0.8990 - val_loss: 0.4174 - val_accuracy: 0.8533\n","Epoch 87/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2335 - accuracy: 0.9033 - val_loss: 0.3992 - val_accuracy: 0.8512\n","Epoch 88/100\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2323 - accuracy: 0.9062 - val_loss: 0.3956 - val_accuracy: 0.8544\n","Epoch 89/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2318 - accuracy: 0.9049 - val_loss: 0.3960 - val_accuracy: 0.8555\n","Epoch 90/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2201 - accuracy: 0.9129 - val_loss: 0.4222 - val_accuracy: 0.8319\n","Epoch 91/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2227 - accuracy: 0.9105 - val_loss: 0.4243 - val_accuracy: 0.8522\n","Epoch 92/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2162 - accuracy: 0.9143 - val_loss: 0.4061 - val_accuracy: 0.8458\n","Epoch 93/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2128 - accuracy: 0.9207 - val_loss: 0.4112 - val_accuracy: 0.8533\n","Epoch 94/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2166 - accuracy: 0.9145 - val_loss: 0.4732 - val_accuracy: 0.8094\n","Epoch 95/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2239 - accuracy: 0.9135 - val_loss: 0.4071 - val_accuracy: 0.8501\n","Epoch 96/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2201 - accuracy: 0.9116 - val_loss: 0.4211 - val_accuracy: 0.8490\n","Epoch 97/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2096 - accuracy: 0.9156 - val_loss: 0.4099 - val_accuracy: 0.8512\n","Epoch 98/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2091 - accuracy: 0.9207 - val_loss: 0.4105 - val_accuracy: 0.8533\n","Epoch 99/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2095 - accuracy: 0.9159 - val_loss: 0.4088 - val_accuracy: 0.8512\n","Epoch 100/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2090 - accuracy: 0.9196 - val_loss: 0.4472 - val_accuracy: 0.8469\n","{'loss': [0.38320139050483704, 0.3741495609283447, 0.3701632618904114, 0.3635912239551544, 0.36383962631225586, 0.36330273747444153, 0.3603946566581726, 0.3576507568359375, 0.3574710786342621, 0.35682645440101624, 0.3497146964073181, 0.34587886929512024, 0.3471527099609375, 0.35185131430625916, 0.34849756956100464, 0.3433561623096466, 0.34370288252830505, 0.33745476603507996, 0.33463045954704285, 0.33796101808547974, 0.33495697379112244, 0.3378216028213501, 0.3285785913467407, 0.3212994635105133, 0.3317812979221344, 0.3234122395515442, 0.32066109776496887, 0.324370414018631, 0.32174304127693176, 0.3206181824207306, 0.3124416768550873, 0.3130798935890198, 0.3217819929122925, 0.3206402659416199, 0.3152984082698822, 0.310017466545105, 0.3141689598560333, 0.3107422888278961, 0.3161872625350952, 0.3052850663661957, 0.3053075671195984, 0.2984682321548462, 0.2967213988304138, 0.2934943735599518, 0.2982986271381378, 0.3011332154273987, 0.2938928008079529, 0.2912767231464386, 0.2927922308444977, 0.288847953081131, 0.2910802960395813, 0.2867306172847748, 0.2877083420753479, 0.29714277386665344, 0.28508260846138, 0.2844217121601105, 0.2754262387752533, 0.27550530433654785, 0.2690458297729492, 0.2692090570926666, 0.2677464187145233, 0.26729294657707214, 0.2753438949584961, 0.2664662301540375, 0.26246559619903564, 0.25612470507621765, 0.2533782720565796, 0.2572852373123169, 0.2541145086288452, 0.24722100794315338, 0.25322529673576355, 0.26244065165519714, 0.26185160875320435, 0.247605562210083, 0.24858634173870087, 0.24471545219421387, 0.24623800814151764, 0.23759660124778748, 0.24392017722129822, 0.24094094336032867, 0.23801009356975555, 0.23877111077308655, 0.23018653690814972, 0.228681281208992, 0.23048880696296692, 0.2388302981853485, 0.23347187042236328, 0.23229214549064636, 0.2318309098482132, 0.22006481885910034, 0.22270523011684418, 0.21622101962566376, 0.21275632083415985, 0.21655963361263275, 0.22392047941684723, 0.22014738619327545, 0.20955806970596313, 0.20908430218696594, 0.20946508646011353, 0.20895837247371674], 'accuracy': [0.8368604183197021, 0.8387355804443359, 0.8406107425689697, 0.8478435277938843, 0.8473078012466431, 0.8438253402709961, 0.8422180414199829, 0.8467720150947571, 0.8448968529701233, 0.8481114506721497, 0.8534690737724304, 0.8545405864715576, 0.8515939116477966, 0.8483793139457703, 0.8515939116477966, 0.8529332876205444, 0.8545405864715576, 0.8550763726234436, 0.863648533821106, 0.8574872612953186, 0.8545405864715576, 0.857755184173584, 0.8652558326721191, 0.8687382936477661, 0.8628448843955994, 0.8671309947967529, 0.8655236959457397, 0.8668631315231323, 0.8668631315231323, 0.8657915592193604, 0.8765068054199219, 0.8727564811706543, 0.8657915592193604, 0.8620412349700928, 0.8706134557723999, 0.8682025074958801, 0.8703455924987793, 0.8698098063468933, 0.8668631315231323, 0.8775783777236938, 0.8740959167480469, 0.8724886178970337, 0.8762389421463013, 0.8842753767967224, 0.8735601305961609, 0.8799892663955688, 0.8770425915718079, 0.8810608386993408, 0.881596565246582, 0.8797214031219482, 0.8802571892738342, 0.8829360008239746, 0.8757032155990601, 0.8773104548454285, 0.8807929158210754, 0.8799892663955688, 0.8864184021949768, 0.8869541883468628, 0.8890972137451172, 0.8917760252952576, 0.88802570104599, 0.8949906229972839, 0.8840075135231018, 0.8899008631706238, 0.88802570104599, 0.8982052206993103, 0.8968657851219177, 0.8947227597236633, 0.8963300585746765, 0.9000803828239441, 0.8990088105201721, 0.88802570104599, 0.8957942724227905, 0.8987409472465515, 0.9040985703468323, 0.8998124599456787, 0.9000803828239441, 0.9038307070732117, 0.9054380059242249, 0.9014197587966919, 0.9038307070732117, 0.9022234082221985, 0.9027591943740845, 0.9081168174743652, 0.9070452451705933, 0.8990088105201721, 0.9032949209213257, 0.9062416553497314, 0.9049022197723389, 0.91293865442276, 0.9105277061462402, 0.9142780900001526, 0.9207072257995605, 0.9145459532737732, 0.913474440574646, 0.9115992784500122, 0.9156174659729004, 0.9207072257995605, 0.915885329246521, 0.9196356534957886], 'val_loss': [0.6792001724243164, 0.6746111512184143, 0.6698917746543884, 0.6639442443847656, 0.6570734977722168, 0.6491474509239197, 0.6426994800567627, 0.6339755058288574, 0.6234268546104431, 0.6091872453689575, 0.5935840606689453, 0.5739662051200867, 0.5545559525489807, 0.5316068530082703, 0.5069129467010498, 0.48488301038742065, 0.4552988111972809, 0.4590640962123871, 0.4388570189476013, 0.4187375605106354, 0.40133923292160034, 0.38311341404914856, 0.3744848668575287, 0.3767643868923187, 0.3791411519050598, 0.39355024695396423, 0.38671785593032837, 0.38153448700904846, 0.3709491789340973, 0.3785220980644226, 0.3685634732246399, 0.39759907126426697, 0.4161387085914612, 0.37463465332984924, 0.39617449045181274, 0.3736823797225952, 0.39300820231437683, 0.3711523711681366, 0.3705118000507355, 0.37854981422424316, 0.3684585392475128, 0.3712165057659149, 0.37254610657691956, 0.3788934350013733, 0.37663084268569946, 0.38466617465019226, 0.37259015440940857, 0.3927791118621826, 0.37462368607521057, 0.3798408806324005, 0.3793213367462158, 0.3970278203487396, 0.4063238799571991, 0.44245967268943787, 0.3772772550582886, 0.3828941881656647, 0.38528478145599365, 0.3797386884689331, 0.3802863657474518, 0.3827253580093384, 0.3825770914554596, 0.4065767228603363, 0.42129752039909363, 0.3863341808319092, 0.38657641410827637, 0.38582876324653625, 0.39107438921928406, 0.3864029347896576, 0.39175283908843994, 0.39616623520851135, 0.3935132324695587, 0.3913273513317108, 0.42027562856674194, 0.38585230708122253, 0.39236265420913696, 0.39181292057037354, 0.40070196986198425, 0.41396668553352356, 0.40355369448661804, 0.39423537254333496, 0.39826300740242004, 0.396160751581192, 0.3941609859466553, 0.39857131242752075, 0.4300815463066101, 0.4173791706562042, 0.3992197811603546, 0.39564698934555054, 0.3959936499595642, 0.42217931151390076, 0.42431753873825073, 0.406146764755249, 0.41122737526893616, 0.47318315505981445, 0.4071410894393921, 0.4210936725139618, 0.4098770320415497, 0.41049590706825256, 0.40881773829460144, 0.4472043216228485], 'val_accuracy': [0.5042826533317566, 0.5278372764587402, 0.6745182275772095, 0.7805139422416687, 0.835117757320404, 0.8372591137886047, 0.840471088886261, 0.8104925155639648, 0.7580299973487854, 0.8062098622322083, 0.8308351039886475, 0.840471088886261, 0.8126338124275208, 0.8008565306663513, 0.8115631937980652, 0.8265524506568909, 0.8340471386909485, 0.7955031991004944, 0.8104925155639648, 0.8211991190910339, 0.8340471386909485, 0.8361884355545044, 0.8468950986862183, 0.8426124453544617, 0.8426124453544617, 0.8308351039886475, 0.8436830639839172, 0.8447537422180176, 0.8576017022132874, 0.8543897271156311, 0.8543897271156311, 0.835117757320404, 0.8072805404663086, 0.8415417671203613, 0.8426124453544617, 0.8522483706474304, 0.8340471386909485, 0.8576017022132874, 0.8576017022132874, 0.8522483706474304, 0.8586723804473877, 0.8543897271156311, 0.8490363955497742, 0.8458244204521179, 0.8554604053497314, 0.840471088886261, 0.8554604053497314, 0.835117757320404, 0.856531023979187, 0.8511777520179749, 0.856531023979187, 0.8276231288909912, 0.824411153793335, 0.8286938071250916, 0.8554604053497314, 0.8468950986862183, 0.8415417671203613, 0.8543897271156311, 0.8511777520179749, 0.8522483706474304, 0.8501070737838745, 0.8447537422180176, 0.8169164657592773, 0.8522483706474304, 0.8533190488815308, 0.8501070737838745, 0.8415417671203613, 0.8511777520179749, 0.8511777520179749, 0.8543897271156311, 0.8511777520179749, 0.8543897271156311, 0.8179871439933777, 0.8543897271156311, 0.8479657173156738, 0.8501070737838745, 0.8533190488815308, 0.8511777520179749, 0.8522483706474304, 0.8501070737838745, 0.8458244204521179, 0.8501070737838745, 0.8522483706474304, 0.8543897271156311, 0.8265524506568909, 0.8533190488815308, 0.8511777520179749, 0.8543897271156311, 0.8554604053497314, 0.8319057822227478, 0.8522483706474304, 0.8458244204521179, 0.8533190488815308, 0.8094218373298645, 0.8501070737838745, 0.8490363955497742, 0.8511777520179749, 0.8533190488815308, 0.8511777520179749, 0.8468950986862183]}\n","37/37 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 61ms/step - loss: 0.2773 - accuracy: 0.8891 - val_loss: 0.6708 - val_accuracy: 0.5610\n","Epoch 2/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2570 - accuracy: 0.8974 - val_loss: 0.6650 - val_accuracy: 0.7934\n","Epoch 3/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2460 - accuracy: 0.8998 - val_loss: 0.6596 - val_accuracy: 0.8158\n","Epoch 4/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2441 - accuracy: 0.9006 - val_loss: 0.6524 - val_accuracy: 0.8094\n","Epoch 5/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2392 - accuracy: 0.9095 - val_loss: 0.6437 - val_accuracy: 0.7923\n","Epoch 6/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2360 - accuracy: 0.9092 - val_loss: 0.6327 - val_accuracy: 0.8009\n","Epoch 7/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2408 - accuracy: 0.9076 - val_loss: 0.6242 - val_accuracy: 0.8148\n","Epoch 8/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2437 - accuracy: 0.9001 - val_loss: 0.6104 - val_accuracy: 0.7976\n","Epoch 9/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2394 - accuracy: 0.9033 - val_loss: 0.5986 - val_accuracy: 0.8126\n","Epoch 10/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2437 - accuracy: 0.9012 - val_loss: 0.5802 - val_accuracy: 0.8084\n","Epoch 11/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2319 - accuracy: 0.9070 - val_loss: 0.5580 - val_accuracy: 0.8094\n","Epoch 12/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2264 - accuracy: 0.9153 - val_loss: 0.5339 - val_accuracy: 0.8148\n","Epoch 13/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2472 - accuracy: 0.9020 - val_loss: 0.5169 - val_accuracy: 0.8169\n","Epoch 14/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2213 - accuracy: 0.9143 - val_loss: 0.4923 - val_accuracy: 0.7944\n","Epoch 15/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2216 - accuracy: 0.9116 - val_loss: 0.4654 - val_accuracy: 0.8255\n","Epoch 16/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2223 - accuracy: 0.9116 - val_loss: 0.4467 - val_accuracy: 0.8084\n","Epoch 17/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2216 - accuracy: 0.9145 - val_loss: 0.4265 - val_accuracy: 0.8126\n","Epoch 18/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2180 - accuracy: 0.9162 - val_loss: 0.4296 - val_accuracy: 0.7966\n","Epoch 19/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2118 - accuracy: 0.9167 - val_loss: 0.4078 - val_accuracy: 0.8191\n","Epoch 20/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2093 - accuracy: 0.9215 - val_loss: 0.3970 - val_accuracy: 0.8255\n","Epoch 21/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2168 - accuracy: 0.9162 - val_loss: 0.4551 - val_accuracy: 0.7976\n","Epoch 22/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2190 - accuracy: 0.9153 - val_loss: 0.3989 - val_accuracy: 0.8276\n","Epoch 23/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2135 - accuracy: 0.9175 - val_loss: 0.4032 - val_accuracy: 0.8351\n","Epoch 24/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2097 - accuracy: 0.9199 - val_loss: 0.3820 - val_accuracy: 0.8544\n","Epoch 25/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2033 - accuracy: 0.9210 - val_loss: 0.3998 - val_accuracy: 0.8490\n","Epoch 26/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2078 - accuracy: 0.9186 - val_loss: 0.3872 - val_accuracy: 0.8576\n","Epoch 27/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2030 - accuracy: 0.9245 - val_loss: 0.3947 - val_accuracy: 0.8576\n","Epoch 28/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2126 - accuracy: 0.9135 - val_loss: 0.4089 - val_accuracy: 0.8480\n","Epoch 29/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2074 - accuracy: 0.9202 - val_loss: 0.4037 - val_accuracy: 0.8522\n","Epoch 30/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1970 - accuracy: 0.9271 - val_loss: 0.4053 - val_accuracy: 0.8587\n","Epoch 31/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1938 - accuracy: 0.9298 - val_loss: 0.4160 - val_accuracy: 0.8597\n","Epoch 32/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1973 - accuracy: 0.9242 - val_loss: 0.4085 - val_accuracy: 0.8587\n","Epoch 33/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2004 - accuracy: 0.9250 - val_loss: 0.4101 - val_accuracy: 0.8597\n","Epoch 34/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1920 - accuracy: 0.9239 - val_loss: 0.4131 - val_accuracy: 0.8608\n","Epoch 35/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1967 - accuracy: 0.9269 - val_loss: 0.4210 - val_accuracy: 0.8597\n","Epoch 36/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1921 - accuracy: 0.9282 - val_loss: 0.4025 - val_accuracy: 0.8608\n","Epoch 37/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1914 - accuracy: 0.9285 - val_loss: 0.4307 - val_accuracy: 0.8490\n","Epoch 38/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1892 - accuracy: 0.9271 - val_loss: 0.4178 - val_accuracy: 0.8565\n","Epoch 39/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1884 - accuracy: 0.9279 - val_loss: 0.4173 - val_accuracy: 0.8544\n","Epoch 40/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1851 - accuracy: 0.9287 - val_loss: 0.4453 - val_accuracy: 0.8533\n","Epoch 41/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1875 - accuracy: 0.9295 - val_loss: 0.4210 - val_accuracy: 0.8565\n","Epoch 42/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2018 - accuracy: 0.9175 - val_loss: 0.4133 - val_accuracy: 0.8587\n","Epoch 43/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1924 - accuracy: 0.9274 - val_loss: 0.4187 - val_accuracy: 0.8576\n","Epoch 44/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1757 - accuracy: 0.9362 - val_loss: 0.4415 - val_accuracy: 0.8522\n","Epoch 45/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1933 - accuracy: 0.9269 - val_loss: 0.4742 - val_accuracy: 0.8490\n","Epoch 46/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1840 - accuracy: 0.9304 - val_loss: 0.4411 - val_accuracy: 0.8555\n","Epoch 47/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1847 - accuracy: 0.9290 - val_loss: 0.4541 - val_accuracy: 0.8458\n","Epoch 48/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1785 - accuracy: 0.9349 - val_loss: 0.4289 - val_accuracy: 0.8597\n","Epoch 49/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1744 - accuracy: 0.9336 - val_loss: 0.4183 - val_accuracy: 0.8608\n","Epoch 50/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1687 - accuracy: 0.9389 - val_loss: 0.4504 - val_accuracy: 0.8522\n","Epoch 51/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1763 - accuracy: 0.9309 - val_loss: 0.4565 - val_accuracy: 0.8490\n","Epoch 52/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1658 - accuracy: 0.9392 - val_loss: 0.4496 - val_accuracy: 0.8512\n","Epoch 53/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1895 - accuracy: 0.9253 - val_loss: 0.4199 - val_accuracy: 0.8587\n","Epoch 54/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1675 - accuracy: 0.9389 - val_loss: 0.4275 - val_accuracy: 0.8544\n","Epoch 55/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1691 - accuracy: 0.9373 - val_loss: 0.4179 - val_accuracy: 0.8576\n","Epoch 56/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1597 - accuracy: 0.9421 - val_loss: 0.4295 - val_accuracy: 0.8555\n","Epoch 57/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.1592 - accuracy: 0.9429 - val_loss: 0.4447 - val_accuracy: 0.8576\n","Epoch 58/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1576 - accuracy: 0.9456 - val_loss: 0.4307 - val_accuracy: 0.8587\n","Epoch 59/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1512 - accuracy: 0.9504 - val_loss: 0.4375 - val_accuracy: 0.8608\n","Epoch 60/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1585 - accuracy: 0.9443 - val_loss: 0.4853 - val_accuracy: 0.8426\n","Epoch 61/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1602 - accuracy: 0.9405 - val_loss: 0.4430 - val_accuracy: 0.8576\n","Epoch 62/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1592 - accuracy: 0.9432 - val_loss: 0.4486 - val_accuracy: 0.8565\n","Epoch 63/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1536 - accuracy: 0.9451 - val_loss: 0.4474 - val_accuracy: 0.8576\n","Epoch 64/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1516 - accuracy: 0.9445 - val_loss: 0.4424 - val_accuracy: 0.8565\n","Epoch 65/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1471 - accuracy: 0.9456 - val_loss: 0.4507 - val_accuracy: 0.8565\n","Epoch 66/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1532 - accuracy: 0.9435 - val_loss: 0.4344 - val_accuracy: 0.8576\n","Epoch 67/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1540 - accuracy: 0.9400 - val_loss: 0.4523 - val_accuracy: 0.8576\n","Epoch 68/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1622 - accuracy: 0.9411 - val_loss: 0.4485 - val_accuracy: 0.8587\n","Epoch 69/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1551 - accuracy: 0.9435 - val_loss: 0.4760 - val_accuracy: 0.8576\n","Epoch 70/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1593 - accuracy: 0.9432 - val_loss: 0.4437 - val_accuracy: 0.8619\n","Epoch 71/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1460 - accuracy: 0.9435 - val_loss: 0.4513 - val_accuracy: 0.8597\n","Epoch 72/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1505 - accuracy: 0.9478 - val_loss: 0.4524 - val_accuracy: 0.8565\n","Epoch 73/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1450 - accuracy: 0.9464 - val_loss: 0.4557 - val_accuracy: 0.8587\n","Epoch 74/100\n","30/30 [==============================] - 1s 16ms/step - loss: 0.1562 - accuracy: 0.9451 - val_loss: 0.5023 - val_accuracy: 0.8351\n","Epoch 75/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1540 - accuracy: 0.9440 - val_loss: 0.4386 - val_accuracy: 0.8630\n","Epoch 76/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1344 - accuracy: 0.9534 - val_loss: 0.4513 - val_accuracy: 0.8565\n","Epoch 77/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1289 - accuracy: 0.9566 - val_loss: 0.5077 - val_accuracy: 0.8287\n","Epoch 78/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1370 - accuracy: 0.9488 - val_loss: 0.4634 - val_accuracy: 0.8630\n","Epoch 79/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1375 - accuracy: 0.9531 - val_loss: 0.4593 - val_accuracy: 0.8608\n","Epoch 80/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1371 - accuracy: 0.9507 - val_loss: 0.5342 - val_accuracy: 0.8244\n","Epoch 81/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1396 - accuracy: 0.9499 - val_loss: 0.4521 - val_accuracy: 0.8555\n","Epoch 82/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1315 - accuracy: 0.9569 - val_loss: 0.4505 - val_accuracy: 0.8587\n","Epoch 83/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1415 - accuracy: 0.9512 - val_loss: 0.4555 - val_accuracy: 0.8597\n","Epoch 84/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1240 - accuracy: 0.9614 - val_loss: 0.4688 - val_accuracy: 0.8608\n","Epoch 85/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1214 - accuracy: 0.9601 - val_loss: 0.4694 - val_accuracy: 0.8608\n","Epoch 86/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1215 - accuracy: 0.9590 - val_loss: 0.4737 - val_accuracy: 0.8651\n","Epoch 87/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1281 - accuracy: 0.9545 - val_loss: 0.4845 - val_accuracy: 0.8565\n","Epoch 88/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1195 - accuracy: 0.9609 - val_loss: 0.4783 - val_accuracy: 0.8565\n","Epoch 89/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1270 - accuracy: 0.9545 - val_loss: 0.4884 - val_accuracy: 0.8630\n","Epoch 90/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1283 - accuracy: 0.9539 - val_loss: 0.5028 - val_accuracy: 0.8587\n","Epoch 91/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1174 - accuracy: 0.9604 - val_loss: 0.4770 - val_accuracy: 0.8576\n","Epoch 92/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1101 - accuracy: 0.9657 - val_loss: 0.4808 - val_accuracy: 0.8555\n","Epoch 93/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1129 - accuracy: 0.9622 - val_loss: 0.4873 - val_accuracy: 0.8587\n","Epoch 94/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1183 - accuracy: 0.9593 - val_loss: 0.5062 - val_accuracy: 0.8630\n","Epoch 95/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1152 - accuracy: 0.9577 - val_loss: 0.5039 - val_accuracy: 0.8587\n","Epoch 96/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1080 - accuracy: 0.9625 - val_loss: 0.4687 - val_accuracy: 0.8630\n","Epoch 97/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1162 - accuracy: 0.9577 - val_loss: 0.4870 - val_accuracy: 0.8630\n","Epoch 98/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1116 - accuracy: 0.9646 - val_loss: 0.4874 - val_accuracy: 0.8587\n","Epoch 99/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1129 - accuracy: 0.9649 - val_loss: 0.4815 - val_accuracy: 0.8587\n","Epoch 100/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1075 - accuracy: 0.9652 - val_loss: 0.5300 - val_accuracy: 0.8565\n","{'loss': [0.27726513147354126, 0.2569926083087921, 0.24598455429077148, 0.24407030642032623, 0.2391967922449112, 0.2360319197177887, 0.24084293842315674, 0.24369493126869202, 0.23941408097743988, 0.24371877312660217, 0.2318885773420334, 0.22635295987129211, 0.2472103387117386, 0.22128690779209137, 0.22163240611553192, 0.22225172817707062, 0.22160549461841583, 0.21796219050884247, 0.2118135243654251, 0.2093188762664795, 0.21684205532073975, 0.21903802454471588, 0.21352294087409973, 0.2097005397081375, 0.20330756902694702, 0.20784373581409454, 0.20301321148872375, 0.21264579892158508, 0.20738990604877472, 0.19695693254470825, 0.19377237558364868, 0.19727268815040588, 0.20042167603969574, 0.19203010201454163, 0.1966935098171234, 0.19209405779838562, 0.1913764923810959, 0.18915791809558868, 0.18840327858924866, 0.18509861826896667, 0.18751513957977295, 0.20176979899406433, 0.19240820407867432, 0.17568252980709076, 0.19331897795200348, 0.1840171068906784, 0.18474969267845154, 0.1785118579864502, 0.1743614673614502, 0.168685182929039, 0.17632730305194855, 0.1657605618238449, 0.18945780396461487, 0.16750600934028625, 0.16910003125667572, 0.15965144336223602, 0.15916305780410767, 0.15763214230537415, 0.15122957527637482, 0.15851280093193054, 0.1601843386888504, 0.15919291973114014, 0.15357615053653717, 0.15161609649658203, 0.1471443623304367, 0.1532166302204132, 0.1539773792028427, 0.16218064725399017, 0.1550767570734024, 0.15929821133613586, 0.14596369862556458, 0.15049012005329132, 0.14496652781963348, 0.15620285272598267, 0.15404610335826874, 0.13437220454216003, 0.1288725882768631, 0.137014701962471, 0.13752959668636322, 0.13709649443626404, 0.13956201076507568, 0.13154564797878265, 0.14149796962738037, 0.12399686872959137, 0.12144412100315094, 0.1214849129319191, 0.12814652919769287, 0.1195068433880806, 0.12695662677288055, 0.12829461693763733, 0.11740075796842575, 0.11012018471956253, 0.11287351697683334, 0.11831704527139664, 0.11517094820737839, 0.10800091922283173, 0.11621725559234619, 0.11161422729492188, 0.11288239061832428, 0.10749144852161407], 'accuracy': [0.8890972137451172, 0.8974015712738037, 0.8998124599456787, 0.9006161093711853, 0.909456193447113, 0.9091883301734924, 0.9075810313224792, 0.9000803828239441, 0.9032949209213257, 0.9011518955230713, 0.9070452451705933, 0.9153496026992798, 0.9019555449485779, 0.9142780900001526, 0.9115992784500122, 0.9115992784500122, 0.9145459532737732, 0.9161532521247864, 0.9166889786720276, 0.9215108752250671, 0.9161532521247864, 0.9153496026992798, 0.9174926280975342, 0.919903576374054, 0.9209750890731812, 0.9185641407966614, 0.9244575500488281, 0.913474440574646, 0.9201714396476746, 0.9271363615989685, 0.9298151731491089, 0.9241896867752075, 0.9249932765960693, 0.9239217638969421, 0.9268684983253479, 0.9282078742980957, 0.9284757375717163, 0.9271363615989685, 0.9279400110244751, 0.9287436604499817, 0.9295473098754883, 0.9174926280975342, 0.9274042248725891, 0.9362443089485168, 0.9268684983253479, 0.9303508996963501, 0.9290115237236023, 0.9349048733711243, 0.9335654973983765, 0.9389231204986572, 0.9308866858482361, 0.9391909837722778, 0.9252611994743347, 0.9389231204986572, 0.937315821647644, 0.9421377182006836, 0.9429413080215454, 0.9456201195716858, 0.9504420161247253, 0.944280743598938, 0.9405304193496704, 0.9432092308998108, 0.9450843930244446, 0.9445486068725586, 0.9456201195716858, 0.9434770941734314, 0.9399946331977844, 0.9410661458969116, 0.9434770941734314, 0.9432092308998108, 0.9434770941734314, 0.947763204574585, 0.9464237689971924, 0.9450843930244446, 0.9440128803253174, 0.9533886909484863, 0.9566032886505127, 0.9488347172737122, 0.9531208276748657, 0.950709879398346, 0.9499062299728394, 0.9568711519241333, 0.9512456655502319, 0.9614251255989075, 0.9600857496261597, 0.9590141773223877, 0.9544602036476135, 0.9608893394470215, 0.9544602036476135, 0.9539244771003723, 0.9603536128997803, 0.965711236000061, 0.9622287750244141, 0.9592821002006531, 0.9576748013496399, 0.9624966382980347, 0.9576748013496399, 0.9646397233009338, 0.9649075865745544, 0.965175449848175], 'val_loss': [0.6707769632339478, 0.6649814248085022, 0.6595996022224426, 0.6523876190185547, 0.6437325477600098, 0.6327435970306396, 0.62420654296875, 0.6104451417922974, 0.59855055809021, 0.5801859498023987, 0.5579745769500732, 0.5339334607124329, 0.5169137716293335, 0.4922594130039215, 0.4653705358505249, 0.44668808579444885, 0.4265372157096863, 0.42955484986305237, 0.4077918827533722, 0.39698052406311035, 0.4550834596157074, 0.39887213706970215, 0.4031812846660614, 0.38198211789131165, 0.3998335003852844, 0.38723668456077576, 0.3947224020957947, 0.4089493453502655, 0.40373918414115906, 0.4053419828414917, 0.4160182774066925, 0.4085214138031006, 0.4101449251174927, 0.41307052969932556, 0.4210023880004883, 0.40251830220222473, 0.43069231510162354, 0.41784554719924927, 0.41731297969818115, 0.44526955485343933, 0.4210430383682251, 0.4133029878139496, 0.4187457263469696, 0.44151419401168823, 0.4741889536380768, 0.44114774465560913, 0.4540945291519165, 0.42889437079429626, 0.4183095395565033, 0.45040518045425415, 0.4564811885356903, 0.44957855343818665, 0.4199124872684479, 0.42753851413726807, 0.41792750358581543, 0.4294971227645874, 0.44474318623542786, 0.4306949973106384, 0.4374595284461975, 0.4853155314922333, 0.4430347681045532, 0.4485839009284973, 0.4473987817764282, 0.44243842363357544, 0.4506679177284241, 0.4343664348125458, 0.4522841274738312, 0.44846296310424805, 0.47600406408309937, 0.4437088966369629, 0.4513486623764038, 0.4523601233959198, 0.4556827247142792, 0.5023435354232788, 0.4385555684566498, 0.4513072371482849, 0.5077092051506042, 0.4633727967739105, 0.4593287408351898, 0.5341796875, 0.45214223861694336, 0.4505161643028259, 0.45551690459251404, 0.4688042402267456, 0.4693908095359802, 0.4736778438091278, 0.4845368266105652, 0.4782976806163788, 0.48840537667274475, 0.5028462409973145, 0.4770137369632721, 0.4807978868484497, 0.48733338713645935, 0.5062314867973328, 0.5038774609565735, 0.4687206447124481, 0.4870143532752991, 0.4873788058757782, 0.4814578592777252, 0.5299715399742126], 'val_accuracy': [0.5610278248786926, 0.7933619022369385, 0.8158458471298218, 0.8094218373298645, 0.7922912240028381, 0.8008565306663513, 0.8147751688957214, 0.7976445555686951, 0.8126338124275208, 0.8083511590957642, 0.8094218373298645, 0.8147751688957214, 0.8169164657592773, 0.794432520866394, 0.8254817724227905, 0.8083511590957642, 0.8126338124275208, 0.7965738773345947, 0.819057822227478, 0.8254817724227905, 0.7976445555686951, 0.8276231288909912, 0.835117757320404, 0.8543897271156311, 0.8490363955497742, 0.8576017022132874, 0.8576017022132874, 0.8479657173156738, 0.8522483706474304, 0.8586723804473877, 0.859743058681488, 0.8586723804473877, 0.859743058681488, 0.8608136773109436, 0.859743058681488, 0.8608136773109436, 0.8490363955497742, 0.856531023979187, 0.8543897271156311, 0.8533190488815308, 0.856531023979187, 0.8586723804473877, 0.8576017022132874, 0.8522483706474304, 0.8490363955497742, 0.8554604053497314, 0.8458244204521179, 0.859743058681488, 0.8608136773109436, 0.8522483706474304, 0.8490363955497742, 0.8511777520179749, 0.8586723804473877, 0.8543897271156311, 0.8576017022132874, 0.8554604053497314, 0.8576017022132874, 0.8586723804473877, 0.8608136773109436, 0.8426124453544617, 0.8576017022132874, 0.856531023979187, 0.8576017022132874, 0.856531023979187, 0.856531023979187, 0.8576017022132874, 0.8576017022132874, 0.8586723804473877, 0.8576017022132874, 0.861884355545044, 0.859743058681488, 0.856531023979187, 0.8586723804473877, 0.835117757320404, 0.8629550337791443, 0.856531023979187, 0.8286938071250916, 0.8629550337791443, 0.8608136773109436, 0.824411153793335, 0.8554604053497314, 0.8586723804473877, 0.859743058681488, 0.8608136773109436, 0.8608136773109436, 0.8650963306427002, 0.856531023979187, 0.856531023979187, 0.8629550337791443, 0.8586723804473877, 0.8576017022132874, 0.8554604053497314, 0.8586723804473877, 0.8629550337791443, 0.8586723804473877, 0.8629550337791443, 0.8629550337791443, 0.8586723804473877, 0.8586723804473877, 0.856531023979187]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 7s 46ms/step - loss: 0.2706 - accuracy: 0.8961 - val_loss: 0.6703 - val_accuracy: 0.5942\n","Epoch 2/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2528 - accuracy: 0.8993 - val_loss: 0.6642 - val_accuracy: 0.8126\n","Epoch 3/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2516 - accuracy: 0.9057 - val_loss: 0.6581 - val_accuracy: 0.8437\n","Epoch 4/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2449 - accuracy: 0.9062 - val_loss: 0.6513 - val_accuracy: 0.8351\n","Epoch 5/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2405 - accuracy: 0.9076 - val_loss: 0.6407 - val_accuracy: 0.8362\n","Epoch 6/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.2444 - accuracy: 0.9012 - val_loss: 0.6320 - val_accuracy: 0.7901\n","Epoch 7/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2484 - accuracy: 0.9028 - val_loss: 0.6197 - val_accuracy: 0.8383\n","Epoch 8/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.2415 - accuracy: 0.9036 - val_loss: 0.6077 - val_accuracy: 0.8223\n","Epoch 9/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2378 - accuracy: 0.9084 - val_loss: 0.5937 - val_accuracy: 0.8255\n","Epoch 10/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2354 - accuracy: 0.9049 - val_loss: 0.5736 - val_accuracy: 0.8587\n","Epoch 11/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2320 - accuracy: 0.9076 - val_loss: 0.5564 - val_accuracy: 0.7976\n","Epoch 12/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2301 - accuracy: 0.9070 - val_loss: 0.5347 - val_accuracy: 0.8308\n","Epoch 13/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2252 - accuracy: 0.9164 - val_loss: 0.5061 - val_accuracy: 0.8340\n","Epoch 14/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.2356 - accuracy: 0.9073 - val_loss: 0.4778 - val_accuracy: 0.8223\n","Epoch 15/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2260 - accuracy: 0.9143 - val_loss: 0.4598 - val_accuracy: 0.8030\n","Epoch 16/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2352 - accuracy: 0.9068 - val_loss: 0.4491 - val_accuracy: 0.7912\n","Epoch 17/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2289 - accuracy: 0.9127 - val_loss: 0.3935 - val_accuracy: 0.8426\n","Epoch 18/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2185 - accuracy: 0.9164 - val_loss: 0.3973 - val_accuracy: 0.8180\n","Epoch 19/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2190 - accuracy: 0.9162 - val_loss: 0.3614 - val_accuracy: 0.8437\n","Epoch 20/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2168 - accuracy: 0.9220 - val_loss: 0.3675 - val_accuracy: 0.8319\n","Epoch 21/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2131 - accuracy: 0.9218 - val_loss: 0.3389 - val_accuracy: 0.8565\n","Epoch 22/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2075 - accuracy: 0.9223 - val_loss: 0.3271 - val_accuracy: 0.8597\n","Epoch 23/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2109 - accuracy: 0.9202 - val_loss: 0.3213 - val_accuracy: 0.8608\n","Epoch 24/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2076 - accuracy: 0.9207 - val_loss: 0.2966 - val_accuracy: 0.8844\n","Epoch 25/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2179 - accuracy: 0.9167 - val_loss: 0.3334 - val_accuracy: 0.8662\n","Epoch 26/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2060 - accuracy: 0.9215 - val_loss: 0.3478 - val_accuracy: 0.8587\n","Epoch 27/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2004 - accuracy: 0.9279 - val_loss: 0.3036 - val_accuracy: 0.8833\n","Epoch 28/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2057 - accuracy: 0.9215 - val_loss: 0.3201 - val_accuracy: 0.8822\n","Epoch 29/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2056 - accuracy: 0.9269 - val_loss: 0.3562 - val_accuracy: 0.8683\n","Epoch 30/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2078 - accuracy: 0.9212 - val_loss: 0.2998 - val_accuracy: 0.8865\n","Epoch 31/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2157 - accuracy: 0.9143 - val_loss: 0.2962 - val_accuracy: 0.8801\n","Epoch 32/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2018 - accuracy: 0.9269 - val_loss: 0.2958 - val_accuracy: 0.8833\n","Epoch 33/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1902 - accuracy: 0.9312 - val_loss: 0.3057 - val_accuracy: 0.8790\n","Epoch 34/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2075 - accuracy: 0.9167 - val_loss: 0.2985 - val_accuracy: 0.8876\n","Epoch 35/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1948 - accuracy: 0.9320 - val_loss: 0.3004 - val_accuracy: 0.8812\n","Epoch 36/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2000 - accuracy: 0.9226 - val_loss: 0.3032 - val_accuracy: 0.8801\n","Epoch 37/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1928 - accuracy: 0.9269 - val_loss: 0.3058 - val_accuracy: 0.8822\n","Epoch 38/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1989 - accuracy: 0.9258 - val_loss: 0.3393 - val_accuracy: 0.8597\n","Epoch 39/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1857 - accuracy: 0.9317 - val_loss: 0.3167 - val_accuracy: 0.8726\n","Epoch 40/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1880 - accuracy: 0.9290 - val_loss: 0.3034 - val_accuracy: 0.8833\n","Epoch 41/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1802 - accuracy: 0.9346 - val_loss: 0.3226 - val_accuracy: 0.8683\n","Epoch 42/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1869 - accuracy: 0.9312 - val_loss: 0.3979 - val_accuracy: 0.8437\n","Epoch 43/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1871 - accuracy: 0.9320 - val_loss: 0.3114 - val_accuracy: 0.8790\n","Epoch 44/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1804 - accuracy: 0.9360 - val_loss: 0.3100 - val_accuracy: 0.8854\n","Epoch 45/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1780 - accuracy: 0.9344 - val_loss: 0.3071 - val_accuracy: 0.8865\n","Epoch 46/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1752 - accuracy: 0.9373 - val_loss: 0.3206 - val_accuracy: 0.8758\n","Epoch 47/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1838 - accuracy: 0.9293 - val_loss: 0.3077 - val_accuracy: 0.8865\n","Epoch 48/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1747 - accuracy: 0.9354 - val_loss: 0.3178 - val_accuracy: 0.8822\n","Epoch 49/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1869 - accuracy: 0.9301 - val_loss: 0.3242 - val_accuracy: 0.8812\n","Epoch 50/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1785 - accuracy: 0.9349 - val_loss: 0.3103 - val_accuracy: 0.8833\n","Epoch 51/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1756 - accuracy: 0.9336 - val_loss: 0.3328 - val_accuracy: 0.8619\n","Epoch 52/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1750 - accuracy: 0.9389 - val_loss: 0.3266 - val_accuracy: 0.8790\n","Epoch 53/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1728 - accuracy: 0.9389 - val_loss: 0.3230 - val_accuracy: 0.8769\n","Epoch 54/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1746 - accuracy: 0.9317 - val_loss: 0.3075 - val_accuracy: 0.8790\n","Epoch 55/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1638 - accuracy: 0.9400 - val_loss: 0.3372 - val_accuracy: 0.8737\n","Epoch 56/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1699 - accuracy: 0.9392 - val_loss: 0.3233 - val_accuracy: 0.8769\n","Epoch 57/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1724 - accuracy: 0.9325 - val_loss: 0.3221 - val_accuracy: 0.8779\n","Epoch 58/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1860 - accuracy: 0.9269 - val_loss: 0.3251 - val_accuracy: 0.8822\n","Epoch 59/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1696 - accuracy: 0.9395 - val_loss: 0.3148 - val_accuracy: 0.8822\n","Epoch 60/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.1589 - accuracy: 0.9435 - val_loss: 0.3518 - val_accuracy: 0.8597\n","Epoch 61/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1711 - accuracy: 0.9349 - val_loss: 0.3241 - val_accuracy: 0.8769\n","Epoch 62/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1595 - accuracy: 0.9403 - val_loss: 0.3220 - val_accuracy: 0.8822\n","Epoch 63/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1634 - accuracy: 0.9389 - val_loss: 0.3177 - val_accuracy: 0.8844\n","Epoch 64/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1532 - accuracy: 0.9459 - val_loss: 0.3142 - val_accuracy: 0.8812\n","Epoch 65/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1583 - accuracy: 0.9435 - val_loss: 0.3304 - val_accuracy: 0.8694\n","Epoch 66/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1639 - accuracy: 0.9381 - val_loss: 0.3226 - val_accuracy: 0.8769\n","Epoch 67/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1671 - accuracy: 0.9354 - val_loss: 0.3475 - val_accuracy: 0.8587\n","Epoch 68/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1559 - accuracy: 0.9427 - val_loss: 0.3700 - val_accuracy: 0.8458\n","Epoch 69/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1703 - accuracy: 0.9336 - val_loss: 0.3190 - val_accuracy: 0.8801\n","Epoch 70/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1520 - accuracy: 0.9467 - val_loss: 0.3166 - val_accuracy: 0.8833\n","Epoch 71/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1494 - accuracy: 0.9467 - val_loss: 0.3216 - val_accuracy: 0.8737\n","Epoch 72/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1452 - accuracy: 0.9496 - val_loss: 0.3278 - val_accuracy: 0.8747\n","Epoch 73/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1461 - accuracy: 0.9483 - val_loss: 0.3619 - val_accuracy: 0.8854\n","Epoch 74/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1535 - accuracy: 0.9413 - val_loss: 0.3403 - val_accuracy: 0.8630\n","Epoch 75/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1544 - accuracy: 0.9416 - val_loss: 0.3316 - val_accuracy: 0.8747\n","Epoch 76/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1386 - accuracy: 0.9507 - val_loss: 0.3350 - val_accuracy: 0.8854\n","Epoch 77/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1495 - accuracy: 0.9478 - val_loss: 0.3329 - val_accuracy: 0.8769\n","Epoch 78/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1439 - accuracy: 0.9502 - val_loss: 0.3421 - val_accuracy: 0.8662\n","Epoch 79/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.1377 - accuracy: 0.9502 - val_loss: 0.3249 - val_accuracy: 0.8876\n","Epoch 80/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1380 - accuracy: 0.9510 - val_loss: 0.3338 - val_accuracy: 0.8844\n","Epoch 81/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1325 - accuracy: 0.9553 - val_loss: 0.3706 - val_accuracy: 0.8844\n","Epoch 82/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1509 - accuracy: 0.9459 - val_loss: 0.4042 - val_accuracy: 0.8458\n","Epoch 83/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1690 - accuracy: 0.9322 - val_loss: 0.3299 - val_accuracy: 0.8833\n","Epoch 84/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1356 - accuracy: 0.9526 - val_loss: 0.3439 - val_accuracy: 0.8662\n","Epoch 85/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1361 - accuracy: 0.9491 - val_loss: 0.3404 - val_accuracy: 0.8747\n","Epoch 86/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1278 - accuracy: 0.9558 - val_loss: 0.3428 - val_accuracy: 0.8844\n","Epoch 87/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1522 - accuracy: 0.9432 - val_loss: 0.3421 - val_accuracy: 0.8844\n","Epoch 88/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1381 - accuracy: 0.9488 - val_loss: 0.3590 - val_accuracy: 0.8587\n","Epoch 89/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1566 - accuracy: 0.9419 - val_loss: 0.3919 - val_accuracy: 0.8458\n","Epoch 90/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1307 - accuracy: 0.9563 - val_loss: 0.3371 - val_accuracy: 0.8683\n","Epoch 91/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1289 - accuracy: 0.9566 - val_loss: 0.3452 - val_accuracy: 0.8801\n","Epoch 92/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1313 - accuracy: 0.9545 - val_loss: 0.3438 - val_accuracy: 0.8887\n","Epoch 93/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1236 - accuracy: 0.9590 - val_loss: 0.3351 - val_accuracy: 0.8822\n","Epoch 94/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1217 - accuracy: 0.9593 - val_loss: 0.3435 - val_accuracy: 0.8790\n","Epoch 95/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1230 - accuracy: 0.9593 - val_loss: 0.3604 - val_accuracy: 0.8630\n","Epoch 96/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1202 - accuracy: 0.9577 - val_loss: 0.3487 - val_accuracy: 0.8833\n","Epoch 97/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1233 - accuracy: 0.9569 - val_loss: 0.4534 - val_accuracy: 0.8308\n","Epoch 98/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1331 - accuracy: 0.9496 - val_loss: 0.4117 - val_accuracy: 0.8469\n","Epoch 99/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1373 - accuracy: 0.9488 - val_loss: 0.3709 - val_accuracy: 0.8704\n","Epoch 100/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1325 - accuracy: 0.9537 - val_loss: 0.3425 - val_accuracy: 0.8833\n","{'loss': [0.2706054151058197, 0.252824604511261, 0.2515797019004822, 0.24489961564540863, 0.24045781791210175, 0.24435657262802124, 0.24842098355293274, 0.24152706563472748, 0.2377549409866333, 0.2353508472442627, 0.23197533190250397, 0.23013535141944885, 0.22516366839408875, 0.23558543622493744, 0.22595804929733276, 0.23521654307842255, 0.22886832058429718, 0.2185494750738144, 0.21901509165763855, 0.216762974858284, 0.21307560801506042, 0.20751644670963287, 0.21091613173484802, 0.2076483517885208, 0.21788926422595978, 0.2060195654630661, 0.20036529004573822, 0.20572789013385773, 0.20561583340168, 0.20784319937229156, 0.21566914021968842, 0.20181448757648468, 0.1902083158493042, 0.20754368603229523, 0.19478195905685425, 0.19996601343154907, 0.1927875429391861, 0.1989491879940033, 0.18567882478237152, 0.18802130222320557, 0.18017108738422394, 0.1868966817855835, 0.1870611608028412, 0.18044531345367432, 0.17803120613098145, 0.17515622079372406, 0.1837773472070694, 0.1747477948665619, 0.1868848204612732, 0.17846815288066864, 0.17559869587421417, 0.1749895215034485, 0.17275398969650269, 0.17455807328224182, 0.16375772655010223, 0.16986611485481262, 0.17235659062862396, 0.18596556782722473, 0.1695789098739624, 0.15892112255096436, 0.17109602689743042, 0.15948691964149475, 0.16341687738895416, 0.1531798541545868, 0.15834477543830872, 0.16390733420848846, 0.1671455204486847, 0.15586046874523163, 0.17034132778644562, 0.15195885300636292, 0.14941133558750153, 0.14515982568264008, 0.14607010781764984, 0.1534944772720337, 0.15439894795417786, 0.13864080607891083, 0.14950664341449738, 0.1438705325126648, 0.13772863149642944, 0.1380113661289215, 0.13254323601722717, 0.1508878916501999, 0.16896659135818481, 0.1356375813484192, 0.13610129058361053, 0.12777619063854218, 0.1521839052438736, 0.13810260593891144, 0.15664158761501312, 0.1307365596294403, 0.1289156824350357, 0.1313045769929886, 0.12356769293546677, 0.1217297688126564, 0.1230139434337616, 0.12019496411085129, 0.1233302429318428, 0.13314075767993927, 0.13730907440185547, 0.13245166838169098], 'accuracy': [0.8960621356964111, 0.8992767333984375, 0.9057058691978455, 0.9062416553497314, 0.9075810313224792, 0.9011518955230713, 0.9027591943740845, 0.9035628437995911, 0.9083846807479858, 0.9049022197723389, 0.9075810313224792, 0.9070452451705933, 0.916421115398407, 0.9073131680488586, 0.9142780900001526, 0.9067773818969727, 0.9126707911491394, 0.916421115398407, 0.9161532521247864, 0.9220466017723083, 0.9217787384986877, 0.922314465045929, 0.9201714396476746, 0.9207072257995605, 0.9166889786720276, 0.9215108752250671, 0.9279400110244751, 0.9215108752250671, 0.9268684983253479, 0.9212429523468018, 0.9142780900001526, 0.9268684983253479, 0.9311545491218567, 0.9166889786720276, 0.9319581985473633, 0.9225823879241943, 0.9268684983253479, 0.9257969260215759, 0.9316903352737427, 0.9290115237236023, 0.9346370100975037, 0.9311545491218567, 0.9319581985473633, 0.9359764456748962, 0.9343691468238831, 0.937315821647644, 0.9292793869972229, 0.9354406595230103, 0.9300830364227295, 0.9349048733711243, 0.9335654973983765, 0.9389231204986572, 0.9389231204986572, 0.9316903352737427, 0.9399946331977844, 0.9391909837722778, 0.9324939846992493, 0.9268684983253479, 0.9394589066505432, 0.9434770941734314, 0.9349048733711243, 0.940262496471405, 0.9389231204986572, 0.9458880424499512, 0.9434770941734314, 0.9381194710731506, 0.9354406595230103, 0.9426734447479248, 0.9335654973983765, 0.9466916918754578, 0.9466916918754578, 0.9496383666992188, 0.9482989311218262, 0.941334068775177, 0.9416019320487976, 0.950709879398346, 0.947763204574585, 0.95017409324646, 0.95017409324646, 0.9509777426719666, 0.9552638530731201, 0.9458880424499512, 0.9322260618209839, 0.9525850415229797, 0.9491025805473328, 0.9557996392250061, 0.9432092308998108, 0.9488347172737122, 0.9418697953224182, 0.9563353657722473, 0.9566032886505127, 0.9544602036476135, 0.9590141773223877, 0.9592821002006531, 0.9592821002006531, 0.9576748013496399, 0.9568711519241333, 0.9496383666992188, 0.9488347172737122, 0.9536565542221069], 'val_loss': [0.6702865958213806, 0.6642048358917236, 0.6580897569656372, 0.6512770652770996, 0.6407447457313538, 0.6320285201072693, 0.6197249889373779, 0.6076992750167847, 0.5936525464057922, 0.5736099481582642, 0.5563854575157166, 0.5346874594688416, 0.5061003565788269, 0.4777560234069824, 0.45975643396377563, 0.4490564167499542, 0.39350852370262146, 0.3973425328731537, 0.36137571930885315, 0.3674815595149994, 0.3389316201210022, 0.3270736038684845, 0.32132700085639954, 0.2965555191040039, 0.33340948820114136, 0.34784549474716187, 0.30357232689857483, 0.3201381266117096, 0.35621464252471924, 0.29980728030204773, 0.29623743891716003, 0.29577094316482544, 0.3057420253753662, 0.29847458004951477, 0.30041834712028503, 0.30319905281066895, 0.30578213930130005, 0.33933135867118835, 0.3167310655117035, 0.3034130036830902, 0.32259371876716614, 0.3979136347770691, 0.3114275336265564, 0.31001096963882446, 0.307088166475296, 0.3205742835998535, 0.30772385001182556, 0.3177996277809143, 0.32418614625930786, 0.3102675974369049, 0.3327505588531494, 0.3266080617904663, 0.3230268359184265, 0.3074924349784851, 0.33716845512390137, 0.32332295179367065, 0.32213345170021057, 0.32507723569869995, 0.3148149847984314, 0.35180169343948364, 0.32405146956443787, 0.321950227022171, 0.3177470564842224, 0.3141731023788452, 0.33043232560157776, 0.32261043787002563, 0.3474562466144562, 0.37003737688064575, 0.3189815878868103, 0.31659483909606934, 0.32161447405815125, 0.3277980387210846, 0.36185717582702637, 0.3403320014476776, 0.33160775899887085, 0.33498188853263855, 0.33292847871780396, 0.3420804738998413, 0.3249177038669586, 0.33381152153015137, 0.3705994486808777, 0.40417778491973877, 0.3298690617084503, 0.3439023196697235, 0.34043213725090027, 0.34276050329208374, 0.3420862555503845, 0.3589763343334198, 0.39188408851623535, 0.3371041417121887, 0.34522324800491333, 0.34378716349601746, 0.33510127663612366, 0.34347712993621826, 0.3604232370853424, 0.3486829996109009, 0.45340391993522644, 0.41168808937072754, 0.3709312379360199, 0.34253889322280884], 'val_accuracy': [0.5942184329032898, 0.8126338124275208, 0.8436830639839172, 0.835117757320404, 0.8361884355545044, 0.7901498675346375, 0.8383297920227051, 0.8222697973251343, 0.8254817724227905, 0.8586723804473877, 0.7976445555686951, 0.8308351039886475, 0.8340471386909485, 0.8222697973251343, 0.802997887134552, 0.7912205457687378, 0.8426124453544617, 0.8179871439933777, 0.8436830639839172, 0.8319057822227478, 0.856531023979187, 0.859743058681488, 0.8608136773109436, 0.8843683004379272, 0.8661670088768005, 0.8586723804473877, 0.8832976222038269, 0.8822270035743713, 0.8683083653450012, 0.8865096569061279, 0.8800856471061707, 0.8832976222038269, 0.8790149688720703, 0.8875802755355835, 0.881156325340271, 0.8800856471061707, 0.8822270035743713, 0.859743058681488, 0.8725910186767578, 0.8832976222038269, 0.8683083653450012, 0.8436830639839172, 0.8790149688720703, 0.8854389786720276, 0.8865096569061279, 0.8758029937744141, 0.8865096569061279, 0.8822270035743713, 0.881156325340271, 0.8832976222038269, 0.861884355545044, 0.8790149688720703, 0.8768736720085144, 0.8790149688720703, 0.8736616969108582, 0.8768736720085144, 0.8779443502426147, 0.8822270035743713, 0.8822270035743713, 0.859743058681488, 0.8768736720085144, 0.8822270035743713, 0.8843683004379272, 0.881156325340271, 0.8693790435791016, 0.8768736720085144, 0.8586723804473877, 0.8458244204521179, 0.8800856471061707, 0.8832976222038269, 0.8736616969108582, 0.8747323155403137, 0.8854389786720276, 0.8629550337791443, 0.8747323155403137, 0.8854389786720276, 0.8768736720085144, 0.8661670088768005, 0.8875802755355835, 0.8843683004379272, 0.8843683004379272, 0.8458244204521179, 0.8832976222038269, 0.8661670088768005, 0.8747323155403137, 0.8843683004379272, 0.8843683004379272, 0.8586723804473877, 0.8458244204521179, 0.8683083653450012, 0.8800856471061707, 0.8886509537696838, 0.8822270035743713, 0.8790149688720703, 0.8629550337791443, 0.8832976222038269, 0.8308351039886475, 0.8468950986862183, 0.8704496622085571, 0.8832976222038269]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 53ms/step - loss: 0.2761 - accuracy: 0.8864 - val_loss: 0.6687 - val_accuracy: 0.5675\n","Epoch 2/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2576 - accuracy: 0.8971 - val_loss: 0.6640 - val_accuracy: 0.8030\n","Epoch 3/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.2564 - accuracy: 0.8982 - val_loss: 0.6588 - val_accuracy: 0.8458\n","Epoch 4/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2487 - accuracy: 0.8995 - val_loss: 0.6521 - val_accuracy: 0.8330\n","Epoch 5/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2502 - accuracy: 0.8995 - val_loss: 0.6439 - val_accuracy: 0.8009\n","Epoch 6/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2446 - accuracy: 0.9006 - val_loss: 0.6351 - val_accuracy: 0.8212\n","Epoch 7/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2451 - accuracy: 0.9003 - val_loss: 0.6241 - val_accuracy: 0.8426\n","Epoch 8/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2385 - accuracy: 0.9078 - val_loss: 0.6098 - val_accuracy: 0.7891\n","Epoch 9/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2395 - accuracy: 0.9049 - val_loss: 0.5948 - val_accuracy: 0.8351\n","Epoch 10/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2401 - accuracy: 0.9014 - val_loss: 0.5788 - val_accuracy: 0.8448\n","Epoch 11/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2461 - accuracy: 0.8998 - val_loss: 0.5604 - val_accuracy: 0.7901\n","Epoch 12/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2335 - accuracy: 0.9076 - val_loss: 0.5467 - val_accuracy: 0.7987\n","Epoch 13/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2265 - accuracy: 0.9103 - val_loss: 0.5116 - val_accuracy: 0.8287\n","Epoch 14/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2241 - accuracy: 0.9078 - val_loss: 0.4964 - val_accuracy: 0.7827\n","Epoch 15/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.2360 - accuracy: 0.9052 - val_loss: 0.4520 - val_accuracy: 0.8405\n","Epoch 16/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2252 - accuracy: 0.9127 - val_loss: 0.4382 - val_accuracy: 0.8223\n","Epoch 17/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2201 - accuracy: 0.9124 - val_loss: 0.4185 - val_accuracy: 0.8287\n","Epoch 18/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2258 - accuracy: 0.9105 - val_loss: 0.3930 - val_accuracy: 0.8426\n","Epoch 19/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.2188 - accuracy: 0.9183 - val_loss: 0.3928 - val_accuracy: 0.8373\n","Epoch 20/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.2192 - accuracy: 0.9159 - val_loss: 0.3910 - val_accuracy: 0.8319\n","Epoch 21/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2301 - accuracy: 0.9084 - val_loss: 0.3441 - val_accuracy: 0.8683\n","Epoch 22/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2202 - accuracy: 0.9148 - val_loss: 0.3512 - val_accuracy: 0.8576\n","Epoch 23/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2234 - accuracy: 0.9159 - val_loss: 0.4591 - val_accuracy: 0.8191\n","Epoch 24/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2110 - accuracy: 0.9170 - val_loss: 0.3405 - val_accuracy: 0.8672\n","Epoch 25/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2222 - accuracy: 0.9119 - val_loss: 0.3460 - val_accuracy: 0.8694\n","Epoch 26/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2089 - accuracy: 0.9180 - val_loss: 0.3493 - val_accuracy: 0.8640\n","Epoch 27/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2072 - accuracy: 0.9215 - val_loss: 0.3534 - val_accuracy: 0.8683\n","Epoch 28/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1968 - accuracy: 0.9210 - val_loss: 0.3790 - val_accuracy: 0.8587\n","Epoch 29/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.2003 - accuracy: 0.9188 - val_loss: 0.3567 - val_accuracy: 0.8704\n","Epoch 30/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1989 - accuracy: 0.9207 - val_loss: 0.3656 - val_accuracy: 0.8587\n","Epoch 31/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2010 - accuracy: 0.9170 - val_loss: 0.3973 - val_accuracy: 0.8490\n","Epoch 32/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2046 - accuracy: 0.9159 - val_loss: 0.3850 - val_accuracy: 0.8608\n","Epoch 33/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1930 - accuracy: 0.9239 - val_loss: 0.3873 - val_accuracy: 0.8608\n","Epoch 34/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.1971 - accuracy: 0.9247 - val_loss: 0.3669 - val_accuracy: 0.8662\n","Epoch 35/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1998 - accuracy: 0.9199 - val_loss: 0.3633 - val_accuracy: 0.8704\n","Epoch 36/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1927 - accuracy: 0.9250 - val_loss: 0.3724 - val_accuracy: 0.8619\n","Epoch 37/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1922 - accuracy: 0.9271 - val_loss: 0.3747 - val_accuracy: 0.8587\n","Epoch 38/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1858 - accuracy: 0.9258 - val_loss: 0.3837 - val_accuracy: 0.8544\n","Epoch 39/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1836 - accuracy: 0.9279 - val_loss: 0.3852 - val_accuracy: 0.8576\n","Epoch 40/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1827 - accuracy: 0.9295 - val_loss: 0.4047 - val_accuracy: 0.8426\n","Epoch 41/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1979 - accuracy: 0.9223 - val_loss: 0.3811 - val_accuracy: 0.8544\n","Epoch 42/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1871 - accuracy: 0.9261 - val_loss: 0.4005 - val_accuracy: 0.8437\n","Epoch 43/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1826 - accuracy: 0.9282 - val_loss: 0.3915 - val_accuracy: 0.8704\n","Epoch 44/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1744 - accuracy: 0.9328 - val_loss: 0.4150 - val_accuracy: 0.8415\n","Epoch 45/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1843 - accuracy: 0.9295 - val_loss: 0.3880 - val_accuracy: 0.8747\n","Epoch 46/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1831 - accuracy: 0.9274 - val_loss: 0.3772 - val_accuracy: 0.8737\n","Epoch 47/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1875 - accuracy: 0.9234 - val_loss: 0.3750 - val_accuracy: 0.8662\n","Epoch 48/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1795 - accuracy: 0.9298 - val_loss: 0.3854 - val_accuracy: 0.8576\n","Epoch 49/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1689 - accuracy: 0.9325 - val_loss: 0.3826 - val_accuracy: 0.8597\n","Epoch 50/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1723 - accuracy: 0.9295 - val_loss: 0.3812 - val_accuracy: 0.8619\n","Epoch 51/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1659 - accuracy: 0.9376 - val_loss: 0.3845 - val_accuracy: 0.8597\n","Epoch 52/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1728 - accuracy: 0.9338 - val_loss: 0.3893 - val_accuracy: 0.8672\n","Epoch 53/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1607 - accuracy: 0.9419 - val_loss: 0.3939 - val_accuracy: 0.8619\n","Epoch 54/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1624 - accuracy: 0.9400 - val_loss: 0.3913 - val_accuracy: 0.8747\n","Epoch 55/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1571 - accuracy: 0.9411 - val_loss: 0.3976 - val_accuracy: 0.8555\n","Epoch 56/100\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1579 - accuracy: 0.9435 - val_loss: 0.3955 - val_accuracy: 0.8555\n","Epoch 57/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1671 - accuracy: 0.9357 - val_loss: 0.3921 - val_accuracy: 0.8640\n","Epoch 58/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1585 - accuracy: 0.9421 - val_loss: 0.4009 - val_accuracy: 0.8522\n","Epoch 59/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1548 - accuracy: 0.9424 - val_loss: 0.3951 - val_accuracy: 0.8619\n","Epoch 60/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1585 - accuracy: 0.9368 - val_loss: 0.4142 - val_accuracy: 0.8533\n","Epoch 61/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1761 - accuracy: 0.9309 - val_loss: 0.3956 - val_accuracy: 0.8651\n","Epoch 62/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1600 - accuracy: 0.9357 - val_loss: 0.3981 - val_accuracy: 0.8694\n","Epoch 63/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1500 - accuracy: 0.9443 - val_loss: 0.4083 - val_accuracy: 0.8544\n","Epoch 64/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1467 - accuracy: 0.9467 - val_loss: 0.4203 - val_accuracy: 0.8651\n","Epoch 65/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1591 - accuracy: 0.9357 - val_loss: 0.4307 - val_accuracy: 0.8608\n","Epoch 66/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1473 - accuracy: 0.9478 - val_loss: 0.4183 - val_accuracy: 0.8501\n","Epoch 67/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1414 - accuracy: 0.9470 - val_loss: 0.4192 - val_accuracy: 0.8662\n","Epoch 68/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1427 - accuracy: 0.9454 - val_loss: 0.4033 - val_accuracy: 0.8662\n","Epoch 69/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1462 - accuracy: 0.9432 - val_loss: 0.4116 - val_accuracy: 0.8715\n","Epoch 70/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1345 - accuracy: 0.9502 - val_loss: 0.4093 - val_accuracy: 0.8683\n","Epoch 71/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1377 - accuracy: 0.9475 - val_loss: 0.4315 - val_accuracy: 0.8726\n","Epoch 72/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1653 - accuracy: 0.9309 - val_loss: 0.4062 - val_accuracy: 0.8715\n","Epoch 73/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.1426 - accuracy: 0.9494 - val_loss: 0.4066 - val_accuracy: 0.8672\n","Epoch 74/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1347 - accuracy: 0.9529 - val_loss: 0.4091 - val_accuracy: 0.8576\n","Epoch 75/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1286 - accuracy: 0.9515 - val_loss: 0.4168 - val_accuracy: 0.8630\n","Epoch 76/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1478 - accuracy: 0.9384 - val_loss: 0.4208 - val_accuracy: 0.8522\n","Epoch 77/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1376 - accuracy: 0.9499 - val_loss: 0.4294 - val_accuracy: 0.8512\n","Epoch 78/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1370 - accuracy: 0.9486 - val_loss: 0.4877 - val_accuracy: 0.8340\n","Epoch 79/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1456 - accuracy: 0.9440 - val_loss: 0.4201 - val_accuracy: 0.8565\n","Epoch 80/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1324 - accuracy: 0.9502 - val_loss: 0.4250 - val_accuracy: 0.8522\n","Epoch 81/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1305 - accuracy: 0.9512 - val_loss: 0.4177 - val_accuracy: 0.8694\n","Epoch 82/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1414 - accuracy: 0.9454 - val_loss: 0.4150 - val_accuracy: 0.8737\n","Epoch 83/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1434 - accuracy: 0.9475 - val_loss: 0.4166 - val_accuracy: 0.8640\n","Epoch 84/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1274 - accuracy: 0.9534 - val_loss: 0.4319 - val_accuracy: 0.8565\n","Epoch 85/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1291 - accuracy: 0.9550 - val_loss: 0.4241 - val_accuracy: 0.8715\n","Epoch 86/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1329 - accuracy: 0.9499 - val_loss: 0.4483 - val_accuracy: 0.8704\n","Epoch 87/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1394 - accuracy: 0.9478 - val_loss: 0.4642 - val_accuracy: 0.8405\n","Epoch 88/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1193 - accuracy: 0.9571 - val_loss: 0.4237 - val_accuracy: 0.8651\n","Epoch 89/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1117 - accuracy: 0.9628 - val_loss: 0.4369 - val_accuracy: 0.8715\n","Epoch 90/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1146 - accuracy: 0.9601 - val_loss: 0.4416 - val_accuracy: 0.8769\n","Epoch 91/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1145 - accuracy: 0.9566 - val_loss: 0.4412 - val_accuracy: 0.8715\n","Epoch 92/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1376 - accuracy: 0.9464 - val_loss: 0.4697 - val_accuracy: 0.8437\n","Epoch 93/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1582 - accuracy: 0.9376 - val_loss: 0.4679 - val_accuracy: 0.8373\n","Epoch 94/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1340 - accuracy: 0.9502 - val_loss: 0.5022 - val_accuracy: 0.8298\n","Epoch 95/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1164 - accuracy: 0.9555 - val_loss: 0.4507 - val_accuracy: 0.8501\n","Epoch 96/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1108 - accuracy: 0.9614 - val_loss: 0.4630 - val_accuracy: 0.8448\n","Epoch 97/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1119 - accuracy: 0.9601 - val_loss: 0.4388 - val_accuracy: 0.8683\n","Epoch 98/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1126 - accuracy: 0.9593 - val_loss: 0.5107 - val_accuracy: 0.8405\n","Epoch 99/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1258 - accuracy: 0.9512 - val_loss: 0.4713 - val_accuracy: 0.8490\n","Epoch 100/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1090 - accuracy: 0.9571 - val_loss: 0.4504 - val_accuracy: 0.8501\n","{'loss': [0.27612870931625366, 0.2575744688510895, 0.256428062915802, 0.24867814779281616, 0.2502080500125885, 0.2445845603942871, 0.24511335790157318, 0.23850882053375244, 0.2395075559616089, 0.24011653661727905, 0.24607008695602417, 0.23346726596355438, 0.22650891542434692, 0.2241326868534088, 0.23603956401348114, 0.22519142925739288, 0.22014948725700378, 0.22584745287895203, 0.2187507301568985, 0.2191794514656067, 0.2300548553466797, 0.22016161680221558, 0.2234078198671341, 0.2110278308391571, 0.22220972180366516, 0.20886445045471191, 0.2071647047996521, 0.19683702290058136, 0.20027987658977509, 0.1988990753889084, 0.20095093548297882, 0.2045908272266388, 0.19297973811626434, 0.1970893144607544, 0.1998201608657837, 0.19268524646759033, 0.1922372281551361, 0.18583402037620544, 0.18363161385059357, 0.18265320360660553, 0.1979246288537979, 0.18712253868579865, 0.18264508247375488, 0.17444580793380737, 0.18434250354766846, 0.1831260770559311, 0.18745212256908417, 0.17945918440818787, 0.1689198613166809, 0.1722903549671173, 0.1658616065979004, 0.17283190786838531, 0.16066409647464752, 0.1623765528202057, 0.1571269929409027, 0.1578952819108963, 0.16709397733211517, 0.1584591120481491, 0.15476617217063904, 0.15851624310016632, 0.17606601119041443, 0.16003583371639252, 0.1499812752008438, 0.1466997265815735, 0.1591240018606186, 0.14731040596961975, 0.14139316976070404, 0.14271771907806396, 0.14619366824626923, 0.13454569876194, 0.1377149373292923, 0.16532327234745026, 0.14260649681091309, 0.1346621960401535, 0.12856876850128174, 0.14775416254997253, 0.1376088559627533, 0.13702917098999023, 0.1455545872449875, 0.1324222832918167, 0.13049335777759552, 0.1413542926311493, 0.14338980615139008, 0.12741003930568695, 0.12907542288303375, 0.13288001716136932, 0.13935741782188416, 0.11929791420698166, 0.11165665835142136, 0.11463741213083267, 0.11447765678167343, 0.13763374090194702, 0.1581927090883255, 0.1340268850326538, 0.11637213081121445, 0.11084243655204773, 0.11190401017665863, 0.11257953941822052, 0.1257791668176651, 0.10898251086473465], 'accuracy': [0.8864184021949768, 0.8971336483955383, 0.8982052206993103, 0.8995445966720581, 0.8995445966720581, 0.9006161093711853, 0.9003482460975647, 0.9078488945960999, 0.9049022197723389, 0.9014197587966919, 0.8998124599456787, 0.9075810313224792, 0.9102598428726196, 0.9078488945960999, 0.9051700830459595, 0.9126707911491394, 0.912402868270874, 0.9105277061462402, 0.9182962775230408, 0.915885329246521, 0.9083846807479858, 0.9148138165473938, 0.915885329246521, 0.9169568419456482, 0.9118671417236328, 0.9180284142494202, 0.9215108752250671, 0.9209750890731812, 0.9188320636749268, 0.9207072257995605, 0.9169568419456482, 0.915885329246521, 0.9239217638969421, 0.9247254133224487, 0.919903576374054, 0.9249932765960693, 0.9271363615989685, 0.9257969260215759, 0.9279400110244751, 0.9295473098754883, 0.922314465045929, 0.9260648488998413, 0.9282078742980957, 0.9327618479728699, 0.9295473098754883, 0.9274042248725891, 0.9233860373497009, 0.9298151731491089, 0.9324939846992493, 0.9295473098754883, 0.9375836849212646, 0.9338333606719971, 0.9418697953224182, 0.9399946331977844, 0.9410661458969116, 0.9434770941734314, 0.9357085227966309, 0.9421377182006836, 0.9424055814743042, 0.9367800951004028, 0.9308866858482361, 0.9357085227966309, 0.944280743598938, 0.9466916918754578, 0.9357085227966309, 0.947763204574585, 0.9469595551490784, 0.9453522562980652, 0.9432092308998108, 0.95017409324646, 0.9474953413009644, 0.9308866858482361, 0.9493705034255981, 0.9528529047966003, 0.9515135288238525, 0.9383873343467712, 0.9499062299728394, 0.9485668540000916, 0.9440128803253174, 0.95017409324646, 0.9512456655502319, 0.9453522562980652, 0.9474953413009644, 0.9533886909484863, 0.9549959897994995, 0.9499062299728394, 0.947763204574585, 0.9571390151977539, 0.9627645611763, 0.9600857496261597, 0.9566032886505127, 0.9464237689971924, 0.9375836849212646, 0.95017409324646, 0.9555317163467407, 0.9614251255989075, 0.9600857496261597, 0.9592821002006531, 0.9512456655502319, 0.9571390151977539], 'val_loss': [0.6687162518501282, 0.6640218496322632, 0.6588439345359802, 0.6520655751228333, 0.6438862085342407, 0.6351295113563538, 0.6241353154182434, 0.6097973585128784, 0.5947611927986145, 0.5787840485572815, 0.5603781342506409, 0.546669065952301, 0.5115843415260315, 0.49637946486473083, 0.4520063102245331, 0.43823254108428955, 0.4185107350349426, 0.3930160701274872, 0.39275842905044556, 0.39101484417915344, 0.34407472610473633, 0.35116803646087646, 0.459141343832016, 0.3405050039291382, 0.34600624442100525, 0.3492538630962372, 0.35342633724212646, 0.3790181875228882, 0.3567209541797638, 0.36562463641166687, 0.3973291218280792, 0.3849940896034241, 0.3873474597930908, 0.3669452667236328, 0.3632873594760895, 0.37239503860473633, 0.3746553659439087, 0.3837333619594574, 0.38516178727149963, 0.4046907424926758, 0.3810528814792633, 0.4004574716091156, 0.3914615213871002, 0.41503816843032837, 0.38801470398902893, 0.3771621286869049, 0.3749975562095642, 0.38542380928993225, 0.3825528621673584, 0.3811597526073456, 0.3844988942146301, 0.3892791271209717, 0.3939468562602997, 0.3913467228412628, 0.39759358763694763, 0.39545753598213196, 0.3920646607875824, 0.40094292163848877, 0.39510223269462585, 0.41422635316848755, 0.3955681622028351, 0.39810505509376526, 0.4082846939563751, 0.42030423879623413, 0.43069109320640564, 0.41826826333999634, 0.4192270040512085, 0.4033142924308777, 0.41160327196121216, 0.4093201756477356, 0.431512713432312, 0.40621984004974365, 0.40655097365379333, 0.4091099202632904, 0.416761577129364, 0.4208407402038574, 0.42937973141670227, 0.4877180755138397, 0.4201115667819977, 0.42496567964553833, 0.4176577925682068, 0.4150485694408417, 0.4166284203529358, 0.43185955286026, 0.42414969205856323, 0.44825270771980286, 0.4642009139060974, 0.42367565631866455, 0.4368700087070465, 0.4416213035583496, 0.4411892592906952, 0.4696560502052307, 0.4678788185119629, 0.5022391676902771, 0.4506935775279999, 0.4630371034145355, 0.4387853443622589, 0.510711133480072, 0.47128477692604065, 0.45037534832954407], 'val_accuracy': [0.5674518346786499, 0.802997887134552, 0.8458244204521179, 0.8329764604568481, 0.8008565306663513, 0.8211991190910339, 0.8426124453544617, 0.7890792489051819, 0.835117757320404, 0.8447537422180176, 0.7901498675346375, 0.7987151741981506, 0.8286938071250916, 0.7826552391052246, 0.840471088886261, 0.8222697973251343, 0.8286938071250916, 0.8426124453544617, 0.8372591137886047, 0.8319057822227478, 0.8683083653450012, 0.8576017022132874, 0.819057822227478, 0.8672376871109009, 0.8693790435791016, 0.8640257120132446, 0.8683083653450012, 0.8586723804473877, 0.8704496622085571, 0.8586723804473877, 0.8490363955497742, 0.8608136773109436, 0.8608136773109436, 0.8661670088768005, 0.8704496622085571, 0.861884355545044, 0.8586723804473877, 0.8543897271156311, 0.8576017022132874, 0.8426124453544617, 0.8543897271156311, 0.8436830639839172, 0.8704496622085571, 0.8415417671203613, 0.8747323155403137, 0.8736616969108582, 0.8661670088768005, 0.8576017022132874, 0.859743058681488, 0.861884355545044, 0.859743058681488, 0.8672376871109009, 0.861884355545044, 0.8747323155403137, 0.8554604053497314, 0.8554604053497314, 0.8640257120132446, 0.8522483706474304, 0.861884355545044, 0.8533190488815308, 0.8650963306427002, 0.8693790435791016, 0.8543897271156311, 0.8650963306427002, 0.8608136773109436, 0.8501070737838745, 0.8661670088768005, 0.8661670088768005, 0.8715203404426575, 0.8683083653450012, 0.8725910186767578, 0.8715203404426575, 0.8672376871109009, 0.8576017022132874, 0.8629550337791443, 0.8522483706474304, 0.8511777520179749, 0.8340471386909485, 0.856531023979187, 0.8522483706474304, 0.8693790435791016, 0.8736616969108582, 0.8640257120132446, 0.856531023979187, 0.8715203404426575, 0.8704496622085571, 0.840471088886261, 0.8650963306427002, 0.8715203404426575, 0.8768736720085144, 0.8715203404426575, 0.8436830639839172, 0.8372591137886047, 0.8297644257545471, 0.8501070737838745, 0.8447537422180176, 0.8683083653450012, 0.840471088886261, 0.8490363955497742, 0.8501070737838745]}\n","37/37 [==============================] - 1s 6ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 7s 50ms/step - loss: 0.1844 - accuracy: 0.9253 - val_loss: 0.6581 - val_accuracy: 0.6681\n","Epoch 2/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1612 - accuracy: 0.9387 - val_loss: 0.6518 - val_accuracy: 0.7955\n","Epoch 3/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1584 - accuracy: 0.9389 - val_loss: 0.6432 - val_accuracy: 0.7677\n","Epoch 4/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1475 - accuracy: 0.9413 - val_loss: 0.6323 - val_accuracy: 0.7687\n","Epoch 5/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1559 - accuracy: 0.9416 - val_loss: 0.6238 - val_accuracy: 0.7473\n","Epoch 6/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1452 - accuracy: 0.9448 - val_loss: 0.6071 - val_accuracy: 0.7730\n","Epoch 7/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1460 - accuracy: 0.9448 - val_loss: 0.5993 - val_accuracy: 0.7141\n","Epoch 8/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1420 - accuracy: 0.9478 - val_loss: 0.5824 - val_accuracy: 0.7495\n","Epoch 9/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1462 - accuracy: 0.9416 - val_loss: 0.5649 - val_accuracy: 0.7559\n","Epoch 10/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1336 - accuracy: 0.9520 - val_loss: 0.5477 - val_accuracy: 0.7559\n","Epoch 11/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1368 - accuracy: 0.9518 - val_loss: 0.5184 - val_accuracy: 0.7891\n","Epoch 12/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1398 - accuracy: 0.9462 - val_loss: 0.4989 - val_accuracy: 0.7837\n","Epoch 13/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1304 - accuracy: 0.9542 - val_loss: 0.4806 - val_accuracy: 0.7784\n","Epoch 14/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1372 - accuracy: 0.9475 - val_loss: 0.4576 - val_accuracy: 0.7901\n","Epoch 15/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1540 - accuracy: 0.9408 - val_loss: 0.4684 - val_accuracy: 0.7602\n","Epoch 16/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1340 - accuracy: 0.9534 - val_loss: 0.4319 - val_accuracy: 0.7987\n","Epoch 17/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1272 - accuracy: 0.9542 - val_loss: 0.4787 - val_accuracy: 0.7752\n","Epoch 18/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1208 - accuracy: 0.9604 - val_loss: 0.4781 - val_accuracy: 0.7869\n","Epoch 19/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1315 - accuracy: 0.9542 - val_loss: 0.5649 - val_accuracy: 0.7655\n","Epoch 20/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1382 - accuracy: 0.9499 - val_loss: 0.4174 - val_accuracy: 0.8266\n","Epoch 21/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1321 - accuracy: 0.9523 - val_loss: 0.3888 - val_accuracy: 0.8405\n","Epoch 22/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1502 - accuracy: 0.9397 - val_loss: 0.3596 - val_accuracy: 0.8651\n","Epoch 23/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1665 - accuracy: 0.9352 - val_loss: 0.3776 - val_accuracy: 0.8619\n","Epoch 24/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1342 - accuracy: 0.9518 - val_loss: 0.3477 - val_accuracy: 0.8694\n","Epoch 25/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1299 - accuracy: 0.9547 - val_loss: 0.3874 - val_accuracy: 0.8640\n","Epoch 26/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1101 - accuracy: 0.9676 - val_loss: 0.3755 - val_accuracy: 0.8726\n","Epoch 27/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1126 - accuracy: 0.9614 - val_loss: 0.3784 - val_accuracy: 0.8790\n","Epoch 28/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1093 - accuracy: 0.9609 - val_loss: 0.3683 - val_accuracy: 0.8779\n","Epoch 29/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1158 - accuracy: 0.9577 - val_loss: 0.3917 - val_accuracy: 0.8758\n","Epoch 30/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1106 - accuracy: 0.9630 - val_loss: 0.3863 - val_accuracy: 0.8822\n","Epoch 31/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1106 - accuracy: 0.9641 - val_loss: 0.4066 - val_accuracy: 0.8790\n","Epoch 32/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1073 - accuracy: 0.9644 - val_loss: 0.4105 - val_accuracy: 0.8812\n","Epoch 33/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1185 - accuracy: 0.9574 - val_loss: 0.4200 - val_accuracy: 0.8769\n","Epoch 34/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1175 - accuracy: 0.9595 - val_loss: 0.4678 - val_accuracy: 0.8480\n","Epoch 35/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1137 - accuracy: 0.9609 - val_loss: 0.4019 - val_accuracy: 0.8844\n","Epoch 36/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1069 - accuracy: 0.9620 - val_loss: 0.4507 - val_accuracy: 0.8597\n","Epoch 37/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1163 - accuracy: 0.9617 - val_loss: 0.3934 - val_accuracy: 0.8812\n","Epoch 38/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1010 - accuracy: 0.9665 - val_loss: 0.4004 - val_accuracy: 0.8779\n","Epoch 39/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1097 - accuracy: 0.9590 - val_loss: 0.4059 - val_accuracy: 0.8801\n","Epoch 40/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0967 - accuracy: 0.9711 - val_loss: 0.4306 - val_accuracy: 0.8704\n","Epoch 41/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1053 - accuracy: 0.9662 - val_loss: 0.4369 - val_accuracy: 0.8715\n","Epoch 42/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1120 - accuracy: 0.9614 - val_loss: 0.4512 - val_accuracy: 0.8662\n","Epoch 43/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1048 - accuracy: 0.9630 - val_loss: 0.4327 - val_accuracy: 0.8737\n","Epoch 44/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1149 - accuracy: 0.9545 - val_loss: 0.4241 - val_accuracy: 0.8790\n","Epoch 45/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0970 - accuracy: 0.9695 - val_loss: 0.4248 - val_accuracy: 0.8747\n","Epoch 46/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0940 - accuracy: 0.9684 - val_loss: 0.4362 - val_accuracy: 0.8704\n","Epoch 47/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0928 - accuracy: 0.9705 - val_loss: 0.4409 - val_accuracy: 0.8801\n","Epoch 48/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0954 - accuracy: 0.9671 - val_loss: 0.4156 - val_accuracy: 0.8801\n","Epoch 49/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0864 - accuracy: 0.9732 - val_loss: 0.4423 - val_accuracy: 0.8769\n","Epoch 50/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0889 - accuracy: 0.9713 - val_loss: 0.4567 - val_accuracy: 0.8737\n","Epoch 51/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0897 - accuracy: 0.9732 - val_loss: 0.4682 - val_accuracy: 0.8694\n","Epoch 52/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1039 - accuracy: 0.9671 - val_loss: 0.4347 - val_accuracy: 0.8779\n","Epoch 53/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1098 - accuracy: 0.9617 - val_loss: 0.4612 - val_accuracy: 0.8576\n","Epoch 54/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0948 - accuracy: 0.9681 - val_loss: 0.4522 - val_accuracy: 0.8747\n","Epoch 55/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0850 - accuracy: 0.9748 - val_loss: 0.4336 - val_accuracy: 0.8790\n","Epoch 56/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0851 - accuracy: 0.9727 - val_loss: 0.4825 - val_accuracy: 0.8576\n","Epoch 57/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0878 - accuracy: 0.9713 - val_loss: 0.4628 - val_accuracy: 0.8704\n","Epoch 58/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1012 - accuracy: 0.9633 - val_loss: 0.4582 - val_accuracy: 0.8747\n","Epoch 59/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0838 - accuracy: 0.9727 - val_loss: 0.4443 - val_accuracy: 0.8790\n","Epoch 60/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0792 - accuracy: 0.9746 - val_loss: 0.4844 - val_accuracy: 0.8597\n","Epoch 61/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0775 - accuracy: 0.9748 - val_loss: 0.4473 - val_accuracy: 0.8801\n","Epoch 62/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0815 - accuracy: 0.9740 - val_loss: 0.4524 - val_accuracy: 0.8801\n","Epoch 63/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0906 - accuracy: 0.9700 - val_loss: 0.4629 - val_accuracy: 0.8758\n","Epoch 64/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0789 - accuracy: 0.9735 - val_loss: 0.4457 - val_accuracy: 0.8822\n","Epoch 65/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0839 - accuracy: 0.9713 - val_loss: 0.4542 - val_accuracy: 0.8779\n","Epoch 66/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0843 - accuracy: 0.9727 - val_loss: 0.4514 - val_accuracy: 0.8801\n","Epoch 67/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0819 - accuracy: 0.9705 - val_loss: 0.4726 - val_accuracy: 0.8694\n","Epoch 68/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0737 - accuracy: 0.9775 - val_loss: 0.5021 - val_accuracy: 0.8597\n","Epoch 69/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0752 - accuracy: 0.9754 - val_loss: 0.4596 - val_accuracy: 0.8758\n","Epoch 70/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0756 - accuracy: 0.9796 - val_loss: 0.4461 - val_accuracy: 0.8812\n","Epoch 71/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0845 - accuracy: 0.9695 - val_loss: 0.4748 - val_accuracy: 0.8758\n","Epoch 72/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0757 - accuracy: 0.9770 - val_loss: 0.4774 - val_accuracy: 0.8672\n","Epoch 73/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0642 - accuracy: 0.9837 - val_loss: 0.4571 - val_accuracy: 0.8790\n","Epoch 74/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0735 - accuracy: 0.9748 - val_loss: 0.4797 - val_accuracy: 0.8715\n","Epoch 75/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0760 - accuracy: 0.9772 - val_loss: 0.4749 - val_accuracy: 0.8715\n","Epoch 76/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0743 - accuracy: 0.9762 - val_loss: 0.5601 - val_accuracy: 0.8426\n","Epoch 77/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0678 - accuracy: 0.9804 - val_loss: 0.4814 - val_accuracy: 0.8779\n","Epoch 78/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0717 - accuracy: 0.9772 - val_loss: 0.5003 - val_accuracy: 0.8737\n","Epoch 79/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0719 - accuracy: 0.9772 - val_loss: 0.4760 - val_accuracy: 0.8715\n","Epoch 80/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0703 - accuracy: 0.9775 - val_loss: 0.4697 - val_accuracy: 0.8769\n","Epoch 81/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0658 - accuracy: 0.9821 - val_loss: 0.4997 - val_accuracy: 0.8576\n","Epoch 82/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0687 - accuracy: 0.9799 - val_loss: 0.4888 - val_accuracy: 0.8790\n","Epoch 83/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0631 - accuracy: 0.9831 - val_loss: 0.4738 - val_accuracy: 0.8758\n","Epoch 84/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0689 - accuracy: 0.9772 - val_loss: 0.4900 - val_accuracy: 0.8769\n","Epoch 85/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0589 - accuracy: 0.9837 - val_loss: 0.4766 - val_accuracy: 0.8801\n","Epoch 86/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0595 - accuracy: 0.9826 - val_loss: 0.5160 - val_accuracy: 0.8737\n","Epoch 87/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0651 - accuracy: 0.9799 - val_loss: 0.4821 - val_accuracy: 0.8812\n","Epoch 88/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0556 - accuracy: 0.9834 - val_loss: 0.5028 - val_accuracy: 0.8747\n","Epoch 89/100\n","30/30 [==============================] - 1s 16ms/step - loss: 0.0570 - accuracy: 0.9845 - val_loss: 0.4934 - val_accuracy: 0.8779\n","Epoch 90/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0556 - accuracy: 0.9839 - val_loss: 0.4855 - val_accuracy: 0.8747\n","Epoch 91/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0560 - accuracy: 0.9842 - val_loss: 0.5158 - val_accuracy: 0.8737\n","Epoch 92/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0573 - accuracy: 0.9839 - val_loss: 0.5133 - val_accuracy: 0.8747\n","Epoch 93/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0759 - accuracy: 0.9743 - val_loss: 0.5250 - val_accuracy: 0.8704\n","Epoch 94/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0563 - accuracy: 0.9837 - val_loss: 0.5390 - val_accuracy: 0.8555\n","Epoch 95/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0605 - accuracy: 0.9796 - val_loss: 0.4961 - val_accuracy: 0.8747\n","Epoch 96/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0587 - accuracy: 0.9821 - val_loss: 0.5066 - val_accuracy: 0.8790\n","Epoch 97/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0665 - accuracy: 0.9786 - val_loss: 0.6774 - val_accuracy: 0.8180\n","Epoch 98/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0769 - accuracy: 0.9713 - val_loss: 0.4727 - val_accuracy: 0.8812\n","Epoch 99/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0539 - accuracy: 0.9861 - val_loss: 0.4910 - val_accuracy: 0.8812\n","Epoch 100/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0602 - accuracy: 0.9804 - val_loss: 0.4783 - val_accuracy: 0.8769\n","{'loss': [0.18435883522033691, 0.1611870527267456, 0.15841832756996155, 0.14753417670726776, 0.15591835975646973, 0.14524470269680023, 0.1459646075963974, 0.141972616314888, 0.14616726338863373, 0.13362275063991547, 0.13683339953422546, 0.13982613384723663, 0.1304381638765335, 0.13720758259296417, 0.15396203100681305, 0.13396930694580078, 0.1272316724061966, 0.12083017826080322, 0.13152338564395905, 0.13818806409835815, 0.13208550214767456, 0.15015296638011932, 0.16647173464298248, 0.1341710388660431, 0.1299315094947815, 0.11014087498188019, 0.1126493290066719, 0.10926317423582077, 0.11584889888763428, 0.11056406050920486, 0.11060384660959244, 0.107330322265625, 0.11854632943868637, 0.11754973977804184, 0.11374420672655106, 0.10688628256320953, 0.11625848710536957, 0.10101217776536942, 0.10969796776771545, 0.09667588025331497, 0.10530474036931992, 0.1120201051235199, 0.10483740270137787, 0.11493474245071411, 0.09697169810533524, 0.09403540194034576, 0.09278131276369095, 0.09543034434318542, 0.08644183725118637, 0.08888830989599228, 0.08968933671712875, 0.1038939505815506, 0.10977122187614441, 0.09482555091381073, 0.08498701453208923, 0.08507654070854187, 0.08777594566345215, 0.10116676241159439, 0.08376043289899826, 0.07924695312976837, 0.07746598869562149, 0.08154136687517166, 0.09062111377716064, 0.07889421284198761, 0.08389654010534286, 0.08431028574705124, 0.08186362683773041, 0.07368988543748856, 0.07515540719032288, 0.07563769072294235, 0.08450636267662048, 0.07573028653860092, 0.06421098113059998, 0.07353002578020096, 0.0759655088186264, 0.07427963614463806, 0.0677919089794159, 0.07174433022737503, 0.07190339267253876, 0.07028140127658844, 0.0658419281244278, 0.06868595629930496, 0.06305614113807678, 0.06889773905277252, 0.05885046720504761, 0.05951160565018654, 0.0650622770190239, 0.055630724877119064, 0.056998804211616516, 0.055597975850105286, 0.055990591645240784, 0.057300109416246414, 0.0758562684059143, 0.056319355964660645, 0.06049472466111183, 0.05869235098361969, 0.06646925210952759, 0.07690206170082092, 0.05387221649289131, 0.060153160244226456], 'accuracy': [0.9252611994743347, 0.9386552572250366, 0.9389231204986572, 0.941334068775177, 0.9416019320487976, 0.944816529750824, 0.944816529750824, 0.947763204574585, 0.9416019320487976, 0.9520493149757385, 0.9517813920974731, 0.9461559057235718, 0.9541923403739929, 0.9474953413009644, 0.940798282623291, 0.9533886909484863, 0.9541923403739929, 0.9603536128997803, 0.9541923403739929, 0.9499062299728394, 0.9523171782493591, 0.9397267699241638, 0.9351727962493896, 0.9517813920974731, 0.9547281265258789, 0.9675863981246948, 0.9614251255989075, 0.9608893394470215, 0.9576748013496399, 0.9630324244499207, 0.9641039371490479, 0.9643718004226685, 0.9574069380760193, 0.9595499634742737, 0.9608893394470215, 0.9619609117507935, 0.9616929888725281, 0.9665148854255676, 0.9590141773223877, 0.9710688591003418, 0.9662469625473022, 0.9614251255989075, 0.9630324244499207, 0.9544602036476135, 0.9694615602493286, 0.9683900475502014, 0.9705330729484558, 0.9670506119728088, 0.9732118844985962, 0.9713367223739624, 0.9732118844985962, 0.9670506119728088, 0.9616929888725281, 0.968122124671936, 0.9748191833496094, 0.972676157951355, 0.9713367223739624, 0.9633002877235413, 0.972676157951355, 0.9745513200759888, 0.9748191833496094, 0.9740155339241028, 0.9699973464012146, 0.9734797477722168, 0.9713367223739624, 0.972676157951355, 0.9705330729484558, 0.9774979948997498, 0.9753549695014954, 0.9796410202980042, 0.9694615602493286, 0.9769622087478638, 0.9836592674255371, 0.9748191833496094, 0.9772301316261292, 0.9761585593223572, 0.9804446697235107, 0.9772301316261292, 0.9772301316261292, 0.9774979948997498, 0.9820519685745239, 0.9799089431762695, 0.9831234812736511, 0.9772301316261292, 0.9836592674255371, 0.9825877547264099, 0.9799089431762695, 0.9833913445472717, 0.9844629168510437, 0.9839271306991577, 0.9841949939727783, 0.9839271306991577, 0.9742833971977234, 0.9836592674255371, 0.9796410202980042, 0.9820519685745239, 0.978569507598877, 0.9713367223739624, 0.9860701560974121, 0.9804446697235107], 'val_loss': [0.658060610294342, 0.6517950892448425, 0.6432048678398132, 0.6323280334472656, 0.6237916350364685, 0.6071325540542603, 0.5993120670318604, 0.5824266672134399, 0.5649121403694153, 0.5477395057678223, 0.5183798670768738, 0.4988817870616913, 0.48058873414993286, 0.45761752128601074, 0.4683944880962372, 0.4319043457508087, 0.4787146747112274, 0.47805026173591614, 0.564879834651947, 0.4173944294452667, 0.3888031542301178, 0.3595995306968689, 0.3776036202907562, 0.3476702868938446, 0.3874059319496155, 0.37551018595695496, 0.3784118592739105, 0.3682866096496582, 0.39168456196784973, 0.386308878660202, 0.4066058099269867, 0.41049766540527344, 0.42004337906837463, 0.4678102731704712, 0.4018774628639221, 0.4507004916667938, 0.39342209696769714, 0.4003913998603821, 0.4059065580368042, 0.4305662214756012, 0.436940997838974, 0.45116421580314636, 0.43265020847320557, 0.4241221249103546, 0.424780935049057, 0.43619802594184875, 0.4409359395503998, 0.41556161642074585, 0.44225260615348816, 0.45672500133514404, 0.46821027994155884, 0.4347200393676758, 0.46117302775382996, 0.4522211253643036, 0.4335586726665497, 0.48249194025993347, 0.4627770781517029, 0.45815762877464294, 0.44428104162216187, 0.48441746830940247, 0.44726720452308655, 0.4523647129535675, 0.4629300832748413, 0.4457172453403473, 0.4541786313056946, 0.45142677426338196, 0.47263285517692566, 0.5020690560340881, 0.45958852767944336, 0.44614264369010925, 0.47483065724372864, 0.4774421751499176, 0.4570566713809967, 0.4796944856643677, 0.47488728165626526, 0.5600578784942627, 0.48136019706726074, 0.5002957582473755, 0.47604870796203613, 0.469715416431427, 0.4997102916240692, 0.48878762125968933, 0.4737834930419922, 0.48997625708580017, 0.4765722155570984, 0.5159589648246765, 0.4821198880672455, 0.502769410610199, 0.49339017271995544, 0.4855459928512573, 0.5158306360244751, 0.5132765769958496, 0.5250340700149536, 0.5389764904975891, 0.4961070716381073, 0.5065668225288391, 0.6774469017982483, 0.47274652123451233, 0.4910011291503906, 0.47831055521965027], 'val_accuracy': [0.6680942177772522, 0.7955031991004944, 0.7676659822463989, 0.7687366008758545, 0.7473233342170715, 0.7730192542076111, 0.7141327857971191, 0.7494646906852722, 0.7558886408805847, 0.7558886408805847, 0.7890792489051819, 0.783725917339325, 0.778372585773468, 0.7901498675346375, 0.7601712942123413, 0.7987151741981506, 0.7751606106758118, 0.7869378924369812, 0.7655246257781982, 0.8265524506568909, 0.840471088886261, 0.8650963306427002, 0.861884355545044, 0.8693790435791016, 0.8640257120132446, 0.8725910186767578, 0.8790149688720703, 0.8779443502426147, 0.8758029937744141, 0.8822270035743713, 0.8790149688720703, 0.881156325340271, 0.8768736720085144, 0.8479657173156738, 0.8843683004379272, 0.859743058681488, 0.881156325340271, 0.8779443502426147, 0.8800856471061707, 0.8704496622085571, 0.8715203404426575, 0.8661670088768005, 0.8736616969108582, 0.8790149688720703, 0.8747323155403137, 0.8704496622085571, 0.8800856471061707, 0.8800856471061707, 0.8768736720085144, 0.8736616969108582, 0.8693790435791016, 0.8779443502426147, 0.8576017022132874, 0.8747323155403137, 0.8790149688720703, 0.8576017022132874, 0.8704496622085571, 0.8747323155403137, 0.8790149688720703, 0.859743058681488, 0.8800856471061707, 0.8800856471061707, 0.8758029937744141, 0.8822270035743713, 0.8779443502426147, 0.8800856471061707, 0.8693790435791016, 0.859743058681488, 0.8758029937744141, 0.881156325340271, 0.8758029937744141, 0.8672376871109009, 0.8790149688720703, 0.8715203404426575, 0.8715203404426575, 0.8426124453544617, 0.8779443502426147, 0.8736616969108582, 0.8715203404426575, 0.8768736720085144, 0.8576017022132874, 0.8790149688720703, 0.8758029937744141, 0.8768736720085144, 0.8800856471061707, 0.8736616969108582, 0.881156325340271, 0.8747323155403137, 0.8779443502426147, 0.8747323155403137, 0.8736616969108582, 0.8747323155403137, 0.8704496622085571, 0.8554604053497314, 0.8747323155403137, 0.8790149688720703, 0.8179871439933777, 0.881156325340271, 0.881156325340271, 0.8768736720085144]}\n","37/37 [==============================] - 3s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 73ms/step - loss: 0.1889 - accuracy: 0.9282 - val_loss: 0.6572 - val_accuracy: 0.7741\n","Epoch 2/100\n","30/30 [==============================] - 1s 30ms/step - loss: 0.1626 - accuracy: 0.9421 - val_loss: 0.6499 - val_accuracy: 0.8287\n","Epoch 3/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1717 - accuracy: 0.9379 - val_loss: 0.6420 - val_accuracy: 0.7484\n","Epoch 4/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1560 - accuracy: 0.9448 - val_loss: 0.6340 - val_accuracy: 0.7291\n","Epoch 5/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1562 - accuracy: 0.9435 - val_loss: 0.6218 - val_accuracy: 0.7987\n","Epoch 6/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1613 - accuracy: 0.9392 - val_loss: 0.6085 - val_accuracy: 0.7901\n","Epoch 7/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1535 - accuracy: 0.9435 - val_loss: 0.5985 - val_accuracy: 0.7955\n","Epoch 8/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1546 - accuracy: 0.9454 - val_loss: 0.5847 - val_accuracy: 0.8041\n","Epoch 9/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1578 - accuracy: 0.9421 - val_loss: 0.5664 - val_accuracy: 0.7762\n","Epoch 10/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1493 - accuracy: 0.9459 - val_loss: 0.5380 - val_accuracy: 0.8255\n","Epoch 11/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1465 - accuracy: 0.9459 - val_loss: 0.5331 - val_accuracy: 0.7463\n","Epoch 12/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1459 - accuracy: 0.9443 - val_loss: 0.4989 - val_accuracy: 0.7848\n","Epoch 13/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1402 - accuracy: 0.9486 - val_loss: 0.4545 - val_accuracy: 0.8287\n","Epoch 14/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1507 - accuracy: 0.9432 - val_loss: 0.4494 - val_accuracy: 0.8030\n","Epoch 15/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1351 - accuracy: 0.9491 - val_loss: 0.4190 - val_accuracy: 0.8105\n","Epoch 16/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1332 - accuracy: 0.9550 - val_loss: 0.4321 - val_accuracy: 0.7966\n","Epoch 17/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1372 - accuracy: 0.9520 - val_loss: 0.4266 - val_accuracy: 0.7987\n","Epoch 18/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1306 - accuracy: 0.9534 - val_loss: 0.4341 - val_accuracy: 0.7966\n","Epoch 19/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1377 - accuracy: 0.9526 - val_loss: 0.3602 - val_accuracy: 0.8426\n","Epoch 20/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1326 - accuracy: 0.9547 - val_loss: 0.4028 - val_accuracy: 0.8330\n","Epoch 21/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1281 - accuracy: 0.9550 - val_loss: 0.3215 - val_accuracy: 0.8662\n","Epoch 22/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1361 - accuracy: 0.9486 - val_loss: 0.4587 - val_accuracy: 0.8298\n","Epoch 23/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1460 - accuracy: 0.9435 - val_loss: 0.2993 - val_accuracy: 0.8769\n","Epoch 24/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1295 - accuracy: 0.9512 - val_loss: 0.3091 - val_accuracy: 0.8833\n","Epoch 25/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1303 - accuracy: 0.9553 - val_loss: 0.3104 - val_accuracy: 0.8897\n","Epoch 26/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1327 - accuracy: 0.9537 - val_loss: 0.2570 - val_accuracy: 0.9004\n","Epoch 27/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1374 - accuracy: 0.9515 - val_loss: 0.3251 - val_accuracy: 0.8844\n","Epoch 28/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1243 - accuracy: 0.9547 - val_loss: 0.2647 - val_accuracy: 0.9015\n","Epoch 29/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1187 - accuracy: 0.9593 - val_loss: 0.2834 - val_accuracy: 0.8983\n","Epoch 30/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.1229 - accuracy: 0.9577 - val_loss: 0.3337 - val_accuracy: 0.8887\n","Epoch 31/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1440 - accuracy: 0.9459 - val_loss: 0.2829 - val_accuracy: 0.8854\n","Epoch 32/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1295 - accuracy: 0.9529 - val_loss: 0.2717 - val_accuracy: 0.8876\n","Epoch 33/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1184 - accuracy: 0.9585 - val_loss: 0.2699 - val_accuracy: 0.9015\n","Epoch 34/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1154 - accuracy: 0.9598 - val_loss: 0.2820 - val_accuracy: 0.8994\n","Epoch 35/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1345 - accuracy: 0.9561 - val_loss: 0.3128 - val_accuracy: 0.8790\n","Epoch 36/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1187 - accuracy: 0.9571 - val_loss: 0.2756 - val_accuracy: 0.9026\n","Epoch 37/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1099 - accuracy: 0.9628 - val_loss: 0.2653 - val_accuracy: 0.8994\n","Epoch 38/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1048 - accuracy: 0.9652 - val_loss: 0.2885 - val_accuracy: 0.8972\n","Epoch 39/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1155 - accuracy: 0.9587 - val_loss: 0.2673 - val_accuracy: 0.9036\n","Epoch 40/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1170 - accuracy: 0.9579 - val_loss: 0.3443 - val_accuracy: 0.8715\n","Epoch 41/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.1153 - accuracy: 0.9595 - val_loss: 0.3091 - val_accuracy: 0.8779\n","Epoch 42/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1106 - accuracy: 0.9638 - val_loss: 0.3058 - val_accuracy: 0.8844\n","Epoch 43/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1188 - accuracy: 0.9561 - val_loss: 0.2819 - val_accuracy: 0.8940\n","Epoch 44/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1031 - accuracy: 0.9644 - val_loss: 0.2892 - val_accuracy: 0.9015\n","Epoch 45/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1035 - accuracy: 0.9638 - val_loss: 0.2811 - val_accuracy: 0.8994\n","Epoch 46/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1226 - accuracy: 0.9547 - val_loss: 0.2884 - val_accuracy: 0.9047\n","Epoch 47/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1011 - accuracy: 0.9703 - val_loss: 0.3042 - val_accuracy: 0.8769\n","Epoch 48/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1149 - accuracy: 0.9601 - val_loss: 0.2737 - val_accuracy: 0.9015\n","Epoch 49/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1064 - accuracy: 0.9620 - val_loss: 0.2853 - val_accuracy: 0.9015\n","Epoch 50/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0994 - accuracy: 0.9646 - val_loss: 0.2858 - val_accuracy: 0.9015\n","Epoch 51/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0973 - accuracy: 0.9689 - val_loss: 0.2934 - val_accuracy: 0.8833\n","Epoch 52/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0976 - accuracy: 0.9662 - val_loss: 0.2952 - val_accuracy: 0.8983\n","Epoch 53/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0974 - accuracy: 0.9671 - val_loss: 0.3319 - val_accuracy: 0.8715\n","Epoch 54/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0913 - accuracy: 0.9708 - val_loss: 0.3239 - val_accuracy: 0.9004\n","Epoch 55/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0945 - accuracy: 0.9689 - val_loss: 0.2831 - val_accuracy: 0.9047\n","Epoch 56/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0918 - accuracy: 0.9679 - val_loss: 0.2817 - val_accuracy: 0.8961\n","Epoch 57/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0894 - accuracy: 0.9676 - val_loss: 0.2845 - val_accuracy: 0.8929\n","Epoch 58/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0957 - accuracy: 0.9695 - val_loss: 0.3383 - val_accuracy: 0.8961\n","Epoch 59/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0913 - accuracy: 0.9695 - val_loss: 0.2915 - val_accuracy: 0.9015\n","Epoch 60/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0914 - accuracy: 0.9697 - val_loss: 0.2906 - val_accuracy: 0.9004\n","Epoch 61/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0830 - accuracy: 0.9732 - val_loss: 0.3402 - val_accuracy: 0.8704\n","Epoch 62/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1060 - accuracy: 0.9625 - val_loss: 0.2936 - val_accuracy: 0.9026\n","Epoch 63/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0944 - accuracy: 0.9668 - val_loss: 0.2979 - val_accuracy: 0.8929\n","Epoch 64/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0928 - accuracy: 0.9673 - val_loss: 0.2923 - val_accuracy: 0.9015\n","Epoch 65/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0837 - accuracy: 0.9708 - val_loss: 0.2924 - val_accuracy: 0.9026\n","Epoch 66/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0899 - accuracy: 0.9700 - val_loss: 0.2894 - val_accuracy: 0.9004\n","Epoch 67/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0900 - accuracy: 0.9727 - val_loss: 0.2950 - val_accuracy: 0.8983\n","Epoch 68/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0843 - accuracy: 0.9748 - val_loss: 0.3010 - val_accuracy: 0.8961\n","Epoch 69/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0800 - accuracy: 0.9737 - val_loss: 0.3255 - val_accuracy: 0.8887\n","Epoch 70/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0766 - accuracy: 0.9762 - val_loss: 0.3057 - val_accuracy: 0.8940\n","Epoch 71/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0740 - accuracy: 0.9759 - val_loss: 0.3221 - val_accuracy: 0.9004\n","Epoch 72/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1116 - accuracy: 0.9598 - val_loss: 0.3161 - val_accuracy: 0.8854\n","Epoch 73/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0797 - accuracy: 0.9756 - val_loss: 0.2909 - val_accuracy: 0.9004\n","Epoch 74/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0770 - accuracy: 0.9767 - val_loss: 0.3017 - val_accuracy: 0.8994\n","Epoch 75/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0790 - accuracy: 0.9737 - val_loss: 0.3018 - val_accuracy: 0.9036\n","Epoch 76/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0753 - accuracy: 0.9764 - val_loss: 0.4103 - val_accuracy: 0.8908\n","Epoch 77/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1321 - accuracy: 0.9475 - val_loss: 0.3378 - val_accuracy: 0.8801\n","Epoch 78/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0870 - accuracy: 0.9713 - val_loss: 0.2998 - val_accuracy: 0.9015\n","Epoch 79/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0782 - accuracy: 0.9764 - val_loss: 0.3362 - val_accuracy: 0.8726\n","Epoch 80/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0906 - accuracy: 0.9703 - val_loss: 0.3269 - val_accuracy: 0.8876\n","Epoch 81/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0795 - accuracy: 0.9740 - val_loss: 0.3043 - val_accuracy: 0.8983\n","Epoch 82/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0756 - accuracy: 0.9754 - val_loss: 0.3644 - val_accuracy: 0.8715\n","Epoch 83/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0789 - accuracy: 0.9735 - val_loss: 0.3017 - val_accuracy: 0.8972\n","Epoch 84/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0777 - accuracy: 0.9767 - val_loss: 0.3106 - val_accuracy: 0.8994\n","Epoch 85/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0821 - accuracy: 0.9724 - val_loss: 0.3268 - val_accuracy: 0.8887\n","Epoch 86/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0717 - accuracy: 0.9756 - val_loss: 0.3751 - val_accuracy: 0.8662\n","Epoch 87/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0738 - accuracy: 0.9770 - val_loss: 0.3095 - val_accuracy: 0.8940\n","Epoch 88/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0667 - accuracy: 0.9837 - val_loss: 0.3197 - val_accuracy: 0.8908\n","Epoch 89/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0694 - accuracy: 0.9754 - val_loss: 0.3191 - val_accuracy: 0.8897\n","Epoch 90/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0669 - accuracy: 0.9772 - val_loss: 0.3503 - val_accuracy: 0.8833\n","Epoch 91/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0611 - accuracy: 0.9810 - val_loss: 0.3358 - val_accuracy: 0.8929\n","Epoch 92/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0624 - accuracy: 0.9802 - val_loss: 0.3239 - val_accuracy: 0.8951\n","Epoch 93/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0558 - accuracy: 0.9839 - val_loss: 0.3363 - val_accuracy: 0.8951\n","Epoch 94/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0553 - accuracy: 0.9842 - val_loss: 0.3734 - val_accuracy: 0.8779\n","Epoch 95/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0671 - accuracy: 0.9780 - val_loss: 0.3672 - val_accuracy: 0.8833\n","Epoch 96/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0661 - accuracy: 0.9764 - val_loss: 0.3287 - val_accuracy: 0.8994\n","Epoch 97/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0636 - accuracy: 0.9791 - val_loss: 0.3413 - val_accuracy: 0.8951\n","Epoch 98/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0658 - accuracy: 0.9775 - val_loss: 0.3686 - val_accuracy: 0.8854\n","Epoch 99/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0617 - accuracy: 0.9794 - val_loss: 0.3452 - val_accuracy: 0.8929\n","Epoch 100/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0566 - accuracy: 0.9829 - val_loss: 0.3562 - val_accuracy: 0.8876\n","{'loss': [0.18889465928077698, 0.1625603586435318, 0.17174991965293884, 0.155998095870018, 0.15621568262577057, 0.16126950085163116, 0.15348458290100098, 0.1546114683151245, 0.15782569348812103, 0.1493024230003357, 0.14648304879665375, 0.14594294130802155, 0.1402493566274643, 0.15068601071834564, 0.1351366490125656, 0.13321104645729065, 0.13721062242984772, 0.13057391345500946, 0.1377284675836563, 0.1325577199459076, 0.12805677950382233, 0.13606508076190948, 0.14595645666122437, 0.12945470213890076, 0.13029615581035614, 0.1327221691608429, 0.13735421001911163, 0.12426112592220306, 0.11869253218173981, 0.12288421392440796, 0.1440260261297226, 0.12951108813285828, 0.11841877549886703, 0.11540676653385162, 0.13450315594673157, 0.11870637536048889, 0.1098509207367897, 0.10481225699186325, 0.11547499895095825, 0.11697153747081757, 0.11534225195646286, 0.11064739525318146, 0.11884573847055435, 0.10313572734594345, 0.10347490012645721, 0.12261804938316345, 0.1010952740907669, 0.11488886177539825, 0.1063796803355217, 0.09942183643579483, 0.09730575978755951, 0.09764529019594193, 0.09742002189159393, 0.09130607545375824, 0.0945097953081131, 0.09184180200099945, 0.08938261866569519, 0.0957385003566742, 0.09129703789949417, 0.0913858562707901, 0.08295442163944244, 0.10601921379566193, 0.09438622742891312, 0.09282583743333817, 0.08371825516223907, 0.08990758657455444, 0.09003482013940811, 0.08434673398733139, 0.07997839897871017, 0.07660816609859467, 0.07400242239236832, 0.11159954220056534, 0.07970814406871796, 0.07703303545713425, 0.07903162389993668, 0.07532520592212677, 0.1321311742067337, 0.08699116855859756, 0.0782255232334137, 0.09061294794082642, 0.07952835410833359, 0.07557559013366699, 0.07887867093086243, 0.07774680107831955, 0.08206731081008911, 0.07174557447433472, 0.07384263724088669, 0.06670037657022476, 0.06939568370580673, 0.06690813601016998, 0.06107435002923012, 0.06240121275186539, 0.055752407759428024, 0.05532444640994072, 0.06712953001260757, 0.06609950214624405, 0.06362194567918777, 0.06584685295820236, 0.06171206757426262, 0.056595899164676666], 'accuracy': [0.9282078742980957, 0.9421377182006836, 0.93785160779953, 0.944816529750824, 0.9434770941734314, 0.9391909837722778, 0.9434770941734314, 0.9453522562980652, 0.9421377182006836, 0.9458880424499512, 0.9458880424499512, 0.944280743598938, 0.9485668540000916, 0.9432092308998108, 0.9491025805473328, 0.9549959897994995, 0.9520493149757385, 0.9533886909484863, 0.9525850415229797, 0.9547281265258789, 0.9549959897994995, 0.9485668540000916, 0.9434770941734314, 0.9512456655502319, 0.9552638530731201, 0.9536565542221069, 0.9515135288238525, 0.9547281265258789, 0.9592821002006531, 0.9576748013496399, 0.9458880424499512, 0.9528529047966003, 0.9584784507751465, 0.9598178267478943, 0.9560675024986267, 0.9571390151977539, 0.9627645611763, 0.965175449848175, 0.9587463140487671, 0.9579426646232605, 0.9595499634742737, 0.9638360738754272, 0.9560675024986267, 0.9643718004226685, 0.9638360738754272, 0.9547281265258789, 0.9702652096748352, 0.9600857496261597, 0.9619609117507935, 0.9646397233009338, 0.9689257740974426, 0.9662469625473022, 0.9670506119728088, 0.9708009362220764, 0.9689257740974426, 0.9678542613983154, 0.9675863981246948, 0.9694615602493286, 0.9694615602493286, 0.9697294235229492, 0.9732118844985962, 0.9624966382980347, 0.9667827486991882, 0.9673185348510742, 0.9708009362220764, 0.9699973464012146, 0.972676157951355, 0.9748191833496094, 0.9737476706504822, 0.9761585593223572, 0.9758906960487366, 0.9598178267478943, 0.975622832775116, 0.9766943454742432, 0.9737476706504822, 0.9764264822006226, 0.9474953413009644, 0.9713367223739624, 0.9764264822006226, 0.9702652096748352, 0.9740155339241028, 0.9753549695014954, 0.9734797477722168, 0.9766943454742432, 0.9724082350730896, 0.975622832775116, 0.9769622087478638, 0.9836592674255371, 0.9753549695014954, 0.9772301316261292, 0.9809804558753967, 0.9801768064498901, 0.9839271306991577, 0.9841949939727783, 0.9780337810516357, 0.9764264822006226, 0.9791052937507629, 0.9774979948997498, 0.9793731570243835, 0.9828556180000305], 'val_loss': [0.6571775078773499, 0.6499407291412354, 0.6420010328292847, 0.6339926719665527, 0.6218053102493286, 0.6085209846496582, 0.5985493063926697, 0.5846697688102722, 0.5663861036300659, 0.5379977226257324, 0.5331063270568848, 0.4989017844200134, 0.4545215964317322, 0.4494408071041107, 0.41901591420173645, 0.4320943355560303, 0.42661765217781067, 0.4340914487838745, 0.36021485924720764, 0.4027854800224304, 0.32153815031051636, 0.4587368965148926, 0.2992624342441559, 0.30914586782455444, 0.3103778660297394, 0.2569842040538788, 0.3251052498817444, 0.26466935873031616, 0.2833734452724457, 0.33366742730140686, 0.2829226851463318, 0.27167025208473206, 0.26985788345336914, 0.2819552421569824, 0.3127598762512207, 0.2756064832210541, 0.2653402090072632, 0.2885224521160126, 0.26729005575180054, 0.34433311223983765, 0.3091127872467041, 0.30576038360595703, 0.2818931043148041, 0.28916794061660767, 0.2811056673526764, 0.28842639923095703, 0.3041621446609497, 0.27368879318237305, 0.28528520464897156, 0.28580084443092346, 0.293355792760849, 0.29520606994628906, 0.3318603038787842, 0.32388734817504883, 0.28313741087913513, 0.2817479074001312, 0.2844706177711487, 0.3382796049118042, 0.29151028394699097, 0.29064375162124634, 0.3401682376861572, 0.293623149394989, 0.29791709780693054, 0.2923419177532196, 0.2923567295074463, 0.28939762711524963, 0.2950262129306793, 0.30102190375328064, 0.3254631459712982, 0.30572211742401123, 0.32206228375434875, 0.3161155879497528, 0.2909356653690338, 0.3017449378967285, 0.30181407928466797, 0.41030797362327576, 0.33776459097862244, 0.2997994124889374, 0.33621227741241455, 0.32686948776245117, 0.30433833599090576, 0.3644135892391205, 0.30174097418785095, 0.3106388449668884, 0.326781690120697, 0.37506744265556335, 0.30946218967437744, 0.31967437267303467, 0.31912198662757874, 0.3503406345844269, 0.3358447849750519, 0.32386624813079834, 0.33634063601493835, 0.3734046518802643, 0.36718887090682983, 0.3286779820919037, 0.3413439393043518, 0.3686099350452423, 0.3451515734195709, 0.3562195301055908], 'val_accuracy': [0.7740899324417114, 0.8286938071250916, 0.7483940124511719, 0.7291220426559448, 0.7987151741981506, 0.7901498675346375, 0.7955031991004944, 0.8040685057640076, 0.7762312889099121, 0.8254817724227905, 0.7462526559829712, 0.7847965955734253, 0.8286938071250916, 0.802997887134552, 0.8104925155639648, 0.7965738773345947, 0.7987151741981506, 0.7965738773345947, 0.8426124453544617, 0.8329764604568481, 0.8661670088768005, 0.8297644257545471, 0.8768736720085144, 0.8832976222038269, 0.8897216320037842, 0.900428295135498, 0.8843683004379272, 0.9014989137649536, 0.8982869386672974, 0.8886509537696838, 0.8854389786720276, 0.8875802755355835, 0.9014989137649536, 0.8993576169013977, 0.8790149688720703, 0.902569591999054, 0.8993576169013977, 0.897216260433197, 0.9036402702331543, 0.8715203404426575, 0.8779443502426147, 0.8843683004379272, 0.8940042853355408, 0.9014989137649536, 0.8993576169013977, 0.9047109484672546, 0.8768736720085144, 0.9014989137649536, 0.9014989137649536, 0.9014989137649536, 0.8832976222038269, 0.8982869386672974, 0.8715203404426575, 0.900428295135498, 0.9047109484672546, 0.8961455821990967, 0.8929336071014404, 0.8961455821990967, 0.9014989137649536, 0.900428295135498, 0.8704496622085571, 0.902569591999054, 0.8929336071014404, 0.9014989137649536, 0.902569591999054, 0.900428295135498, 0.8982869386672974, 0.8961455821990967, 0.8886509537696838, 0.8940042853355408, 0.900428295135498, 0.8854389786720276, 0.900428295135498, 0.8993576169013977, 0.9036402702331543, 0.8907923102378845, 0.8800856471061707, 0.9014989137649536, 0.8725910186767578, 0.8875802755355835, 0.8982869386672974, 0.8715203404426575, 0.897216260433197, 0.8993576169013977, 0.8886509537696838, 0.8661670088768005, 0.8940042853355408, 0.8907923102378845, 0.8897216320037842, 0.8832976222038269, 0.8929336071014404, 0.8950749635696411, 0.8950749635696411, 0.8779443502426147, 0.8832976222038269, 0.8993576169013977, 0.8950749635696411, 0.8854389786720276, 0.8929336071014404, 0.8875802755355835]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 7s 51ms/step - loss: 0.1825 - accuracy: 0.9309 - val_loss: 0.6566 - val_accuracy: 0.7441\n","Epoch 2/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1596 - accuracy: 0.9429 - val_loss: 0.6506 - val_accuracy: 0.7934\n","Epoch 3/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1622 - accuracy: 0.9384 - val_loss: 0.6438 - val_accuracy: 0.7463\n","Epoch 4/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1518 - accuracy: 0.9416 - val_loss: 0.6337 - val_accuracy: 0.7184\n","Epoch 5/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1475 - accuracy: 0.9408 - val_loss: 0.6234 - val_accuracy: 0.7323\n","Epoch 6/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1504 - accuracy: 0.9405 - val_loss: 0.6120 - val_accuracy: 0.7398\n","Epoch 7/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1425 - accuracy: 0.9445 - val_loss: 0.5943 - val_accuracy: 0.7805\n","Epoch 8/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.1634 - accuracy: 0.9365 - val_loss: 0.5871 - val_accuracy: 0.7377\n","Epoch 9/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1419 - accuracy: 0.9483 - val_loss: 0.5747 - val_accuracy: 0.7206\n","Epoch 10/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1430 - accuracy: 0.9456 - val_loss: 0.5496 - val_accuracy: 0.7291\n","Epoch 11/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.1378 - accuracy: 0.9483 - val_loss: 0.5235 - val_accuracy: 0.7687\n","Epoch 12/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.1440 - accuracy: 0.9462 - val_loss: 0.5278 - val_accuracy: 0.7131\n","Epoch 13/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1548 - accuracy: 0.9357 - val_loss: 0.5057 - val_accuracy: 0.7345\n","Epoch 14/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1421 - accuracy: 0.9435 - val_loss: 0.4829 - val_accuracy: 0.7570\n","Epoch 15/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1363 - accuracy: 0.9504 - val_loss: 0.4694 - val_accuracy: 0.7719\n","Epoch 16/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1280 - accuracy: 0.9504 - val_loss: 0.4700 - val_accuracy: 0.7709\n","Epoch 17/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1292 - accuracy: 0.9553 - val_loss: 0.4988 - val_accuracy: 0.7537\n","Epoch 18/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1368 - accuracy: 0.9470 - val_loss: 0.4477 - val_accuracy: 0.8009\n","Epoch 19/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1235 - accuracy: 0.9566 - val_loss: 0.3848 - val_accuracy: 0.8415\n","Epoch 20/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1493 - accuracy: 0.9424 - val_loss: 0.4016 - val_accuracy: 0.8405\n","Epoch 21/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1271 - accuracy: 0.9515 - val_loss: 0.4566 - val_accuracy: 0.8287\n","Epoch 22/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1143 - accuracy: 0.9561 - val_loss: 0.4619 - val_accuracy: 0.8415\n","Epoch 23/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1184 - accuracy: 0.9590 - val_loss: 0.4611 - val_accuracy: 0.8448\n","Epoch 24/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1139 - accuracy: 0.9577 - val_loss: 0.4271 - val_accuracy: 0.8576\n","Epoch 25/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1185 - accuracy: 0.9563 - val_loss: 0.3525 - val_accuracy: 0.8865\n","Epoch 26/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1235 - accuracy: 0.9515 - val_loss: 0.3765 - val_accuracy: 0.8812\n","Epoch 27/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1056 - accuracy: 0.9622 - val_loss: 0.3940 - val_accuracy: 0.8812\n","Epoch 28/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1128 - accuracy: 0.9574 - val_loss: 0.3569 - val_accuracy: 0.8854\n","Epoch 29/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1136 - accuracy: 0.9593 - val_loss: 0.3511 - val_accuracy: 0.8887\n","Epoch 30/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1219 - accuracy: 0.9531 - val_loss: 0.3519 - val_accuracy: 0.8887\n","Epoch 31/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1175 - accuracy: 0.9569 - val_loss: 0.4024 - val_accuracy: 0.8801\n","Epoch 32/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1104 - accuracy: 0.9601 - val_loss: 0.3863 - val_accuracy: 0.8619\n","Epoch 33/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1210 - accuracy: 0.9561 - val_loss: 0.3625 - val_accuracy: 0.8887\n","Epoch 34/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1065 - accuracy: 0.9654 - val_loss: 0.3563 - val_accuracy: 0.8854\n","Epoch 35/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.1252 - accuracy: 0.9518 - val_loss: 0.4334 - val_accuracy: 0.8812\n","Epoch 36/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1224 - accuracy: 0.9539 - val_loss: 0.3550 - val_accuracy: 0.8812\n","Epoch 37/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.1009 - accuracy: 0.9633 - val_loss: 0.3616 - val_accuracy: 0.8833\n","Epoch 38/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0972 - accuracy: 0.9633 - val_loss: 0.3707 - val_accuracy: 0.8758\n","Epoch 39/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0966 - accuracy: 0.9630 - val_loss: 0.3770 - val_accuracy: 0.8812\n","Epoch 40/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0933 - accuracy: 0.9665 - val_loss: 0.3876 - val_accuracy: 0.8897\n","Epoch 41/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0997 - accuracy: 0.9622 - val_loss: 0.3934 - val_accuracy: 0.8908\n","Epoch 42/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.1009 - accuracy: 0.9636 - val_loss: 0.3967 - val_accuracy: 0.8854\n","Epoch 43/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0962 - accuracy: 0.9641 - val_loss: 0.3953 - val_accuracy: 0.8747\n","Epoch 44/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1077 - accuracy: 0.9582 - val_loss: 0.3782 - val_accuracy: 0.8833\n","Epoch 45/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0968 - accuracy: 0.9671 - val_loss: 0.3825 - val_accuracy: 0.8790\n","Epoch 46/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1017 - accuracy: 0.9612 - val_loss: 0.3926 - val_accuracy: 0.8897\n","Epoch 47/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0933 - accuracy: 0.9676 - val_loss: 0.3793 - val_accuracy: 0.8844\n","Epoch 48/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0910 - accuracy: 0.9681 - val_loss: 0.3838 - val_accuracy: 0.8908\n","Epoch 49/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0873 - accuracy: 0.9711 - val_loss: 0.3804 - val_accuracy: 0.8844\n","Epoch 50/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0860 - accuracy: 0.9703 - val_loss: 0.3940 - val_accuracy: 0.8865\n","Epoch 51/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0973 - accuracy: 0.9630 - val_loss: 0.4792 - val_accuracy: 0.8769\n","Epoch 52/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0994 - accuracy: 0.9622 - val_loss: 0.3929 - val_accuracy: 0.8833\n","Epoch 53/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0821 - accuracy: 0.9708 - val_loss: 0.3958 - val_accuracy: 0.8844\n","Epoch 54/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0800 - accuracy: 0.9716 - val_loss: 0.4053 - val_accuracy: 0.8854\n","Epoch 55/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0763 - accuracy: 0.9721 - val_loss: 0.4068 - val_accuracy: 0.8769\n","Epoch 56/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.0833 - accuracy: 0.9737 - val_loss: 0.4204 - val_accuracy: 0.8651\n","Epoch 57/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0816 - accuracy: 0.9708 - val_loss: 0.4078 - val_accuracy: 0.8929\n","Epoch 58/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0863 - accuracy: 0.9673 - val_loss: 0.4019 - val_accuracy: 0.8790\n","Epoch 59/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0945 - accuracy: 0.9614 - val_loss: 0.3962 - val_accuracy: 0.8854\n","Epoch 60/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0773 - accuracy: 0.9735 - val_loss: 0.4265 - val_accuracy: 0.8854\n","Epoch 61/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0814 - accuracy: 0.9705 - val_loss: 0.4159 - val_accuracy: 0.8747\n","Epoch 62/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0892 - accuracy: 0.9681 - val_loss: 0.4113 - val_accuracy: 0.8833\n","Epoch 63/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0782 - accuracy: 0.9689 - val_loss: 0.4041 - val_accuracy: 0.8833\n","Epoch 64/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0770 - accuracy: 0.9743 - val_loss: 0.4038 - val_accuracy: 0.8865\n","Epoch 65/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0807 - accuracy: 0.9708 - val_loss: 0.4355 - val_accuracy: 0.8822\n","Epoch 66/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0885 - accuracy: 0.9684 - val_loss: 0.3978 - val_accuracy: 0.8822\n","Epoch 67/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0801 - accuracy: 0.9703 - val_loss: 0.4634 - val_accuracy: 0.8822\n","Epoch 68/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0957 - accuracy: 0.9652 - val_loss: 0.4151 - val_accuracy: 0.8887\n","Epoch 69/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0752 - accuracy: 0.9737 - val_loss: 0.4214 - val_accuracy: 0.8726\n","Epoch 70/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0777 - accuracy: 0.9746 - val_loss: 0.4480 - val_accuracy: 0.8833\n","Epoch 71/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0781 - accuracy: 0.9705 - val_loss: 0.4252 - val_accuracy: 0.8833\n","Epoch 72/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0681 - accuracy: 0.9762 - val_loss: 0.4240 - val_accuracy: 0.8854\n","Epoch 73/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0670 - accuracy: 0.9754 - val_loss: 0.4251 - val_accuracy: 0.8790\n","Epoch 74/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0647 - accuracy: 0.9794 - val_loss: 0.4426 - val_accuracy: 0.8897\n","Epoch 75/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0735 - accuracy: 0.9756 - val_loss: 0.4269 - val_accuracy: 0.8854\n","Epoch 76/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0689 - accuracy: 0.9767 - val_loss: 0.4440 - val_accuracy: 0.8887\n","Epoch 77/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0621 - accuracy: 0.9794 - val_loss: 0.4361 - val_accuracy: 0.8747\n","Epoch 78/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0720 - accuracy: 0.9762 - val_loss: 0.4614 - val_accuracy: 0.8833\n","Epoch 79/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0915 - accuracy: 0.9646 - val_loss: 0.4639 - val_accuracy: 0.8683\n","Epoch 80/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0665 - accuracy: 0.9799 - val_loss: 0.4509 - val_accuracy: 0.8865\n","Epoch 81/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0650 - accuracy: 0.9780 - val_loss: 0.4351 - val_accuracy: 0.8844\n","Epoch 82/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0631 - accuracy: 0.9794 - val_loss: 0.4410 - val_accuracy: 0.8747\n","Epoch 83/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0635 - accuracy: 0.9804 - val_loss: 0.4510 - val_accuracy: 0.8747\n","Epoch 84/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0658 - accuracy: 0.9791 - val_loss: 0.4942 - val_accuracy: 0.8522\n","Epoch 85/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0586 - accuracy: 0.9818 - val_loss: 0.5192 - val_accuracy: 0.8822\n","Epoch 86/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0799 - accuracy: 0.9705 - val_loss: 0.4421 - val_accuracy: 0.8801\n","Epoch 87/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0590 - accuracy: 0.9796 - val_loss: 0.4437 - val_accuracy: 0.8833\n","Epoch 88/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0585 - accuracy: 0.9812 - val_loss: 0.4595 - val_accuracy: 0.8726\n","Epoch 89/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0533 - accuracy: 0.9831 - val_loss: 0.4538 - val_accuracy: 0.8769\n","Epoch 90/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0703 - accuracy: 0.9746 - val_loss: 0.4504 - val_accuracy: 0.8854\n","Epoch 91/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0700 - accuracy: 0.9743 - val_loss: 0.4986 - val_accuracy: 0.8555\n","Epoch 92/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0664 - accuracy: 0.9780 - val_loss: 0.4739 - val_accuracy: 0.8854\n","Epoch 93/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0622 - accuracy: 0.9778 - val_loss: 0.5121 - val_accuracy: 0.8576\n","Epoch 94/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0569 - accuracy: 0.9812 - val_loss: 0.4857 - val_accuracy: 0.8876\n","Epoch 95/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0696 - accuracy: 0.9732 - val_loss: 0.4825 - val_accuracy: 0.8640\n","Epoch 96/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0498 - accuracy: 0.9834 - val_loss: 0.4589 - val_accuracy: 0.8790\n","Epoch 97/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0629 - accuracy: 0.9759 - val_loss: 0.4872 - val_accuracy: 0.8865\n","Epoch 98/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0536 - accuracy: 0.9815 - val_loss: 0.5002 - val_accuracy: 0.8640\n","Epoch 99/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0545 - accuracy: 0.9829 - val_loss: 0.4687 - val_accuracy: 0.8779\n","Epoch 100/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0702 - accuracy: 0.9740 - val_loss: 0.5716 - val_accuracy: 0.8394\n","{'loss': [0.1824527531862259, 0.15963655710220337, 0.16219110786914825, 0.1518402397632599, 0.14746089279651642, 0.15043491125106812, 0.14252814650535583, 0.16344749927520752, 0.1419159173965454, 0.14295533299446106, 0.13783563673496246, 0.14398127794265747, 0.15481656789779663, 0.14210446178913116, 0.13632532954216003, 0.12803316116333008, 0.12919962406158447, 0.1368347406387329, 0.1234680563211441, 0.1492910534143448, 0.1270759403705597, 0.11426982283592224, 0.11839582026004791, 0.11394089460372925, 0.11849696934223175, 0.12348484992980957, 0.10559029877185822, 0.11278753727674484, 0.1135842502117157, 0.12188365310430527, 0.11751312762498856, 0.11043243855237961, 0.12103067338466644, 0.10648199915885925, 0.12518304586410522, 0.12241464108228683, 0.10086572915315628, 0.09716857224702835, 0.09659840166568756, 0.09334050118923187, 0.09965197741985321, 0.10091561079025269, 0.0961519256234169, 0.10765745490789413, 0.09682776778936386, 0.10166266560554504, 0.09325447678565979, 0.09101244807243347, 0.08734634518623352, 0.08597640693187714, 0.09725254029035568, 0.09937025606632233, 0.08206581324338913, 0.08002869784832001, 0.07626008242368698, 0.08332478255033493, 0.08163610845804214, 0.08633514493703842, 0.09451790899038315, 0.07728224247694016, 0.0813935250043869, 0.089248426258564, 0.07817850261926651, 0.07695157825946808, 0.08065308630466461, 0.08853244036436081, 0.08010648190975189, 0.09571655839681625, 0.07517825812101364, 0.07770276069641113, 0.07806332409381866, 0.06814028322696686, 0.06696522235870361, 0.06473774462938309, 0.07346811145544052, 0.06886404752731323, 0.06210143119096756, 0.07199286669492722, 0.09148616343736649, 0.06651481240987778, 0.06499478220939636, 0.06311158090829849, 0.06350700557231903, 0.0657815933227539, 0.05856867879629135, 0.0798933282494545, 0.05897980183362961, 0.058505769819021225, 0.05333753302693367, 0.07030565291643143, 0.06996487826108932, 0.06638537347316742, 0.06220953166484833, 0.05690837651491165, 0.06963485479354858, 0.04983162507414818, 0.06289364397525787, 0.05361805483698845, 0.05448918417096138, 0.07021806389093399], 'accuracy': [0.9308866858482361, 0.9429413080215454, 0.9383873343467712, 0.9416019320487976, 0.940798282623291, 0.9405304193496704, 0.9445486068725586, 0.9365121722221375, 0.9482989311218262, 0.9456201195716858, 0.9482989311218262, 0.9461559057235718, 0.9357085227966309, 0.9434770941734314, 0.9504420161247253, 0.9504420161247253, 0.9552638530731201, 0.9469595551490784, 0.9566032886505127, 0.9424055814743042, 0.9515135288238525, 0.9560675024986267, 0.9590141773223877, 0.9576748013496399, 0.9563353657722473, 0.9515135288238525, 0.9622287750244141, 0.9574069380760193, 0.9592821002006531, 0.9531208276748657, 0.9568711519241333, 0.9600857496261597, 0.9560675024986267, 0.9654433727264404, 0.9517813920974731, 0.9539244771003723, 0.9633002877235413, 0.9633002877235413, 0.9630324244499207, 0.9665148854255676, 0.9622287750244141, 0.9635681509971619, 0.9641039371490479, 0.9582105278968811, 0.9670506119728088, 0.9611572623252869, 0.9675863981246948, 0.968122124671936, 0.9710688591003418, 0.9702652096748352, 0.9630324244499207, 0.9622287750244141, 0.9708009362220764, 0.971604585647583, 0.972140371799469, 0.9737476706504822, 0.9708009362220764, 0.9673185348510742, 0.9614251255989075, 0.9734797477722168, 0.9705330729484558, 0.968122124671936, 0.9689257740974426, 0.9742833971977234, 0.9708009362220764, 0.9683900475502014, 0.9702652096748352, 0.965175449848175, 0.9737476706504822, 0.9745513200759888, 0.9705330729484558, 0.9761585593223572, 0.9753549695014954, 0.9793731570243835, 0.975622832775116, 0.9766943454742432, 0.9793731570243835, 0.9761585593223572, 0.9646397233009338, 0.9799089431762695, 0.9780337810516357, 0.9793731570243835, 0.9804446697235107, 0.9791052937507629, 0.9817841053009033, 0.9705330729484558, 0.9796410202980042, 0.9812483191490173, 0.9831234812736511, 0.9745513200759888, 0.9742833971977234, 0.9780337810516357, 0.9777658581733704, 0.9812483191490173, 0.9732118844985962, 0.9833913445472717, 0.9758906960487366, 0.9815161824226379, 0.9828556180000305, 0.9740155339241028], 'val_loss': [0.6565631031990051, 0.6506122350692749, 0.6437850594520569, 0.6336536407470703, 0.6234400868415833, 0.6120020151138306, 0.594260573387146, 0.5870746374130249, 0.5747495889663696, 0.5495560169219971, 0.5235047340393066, 0.5277756452560425, 0.5056888461112976, 0.48292914032936096, 0.4693928360939026, 0.4700391888618469, 0.4988153874874115, 0.4476745128631592, 0.3848167657852173, 0.40157240629196167, 0.456594854593277, 0.4618896245956421, 0.46113595366477966, 0.4270648956298828, 0.3524974584579468, 0.37645602226257324, 0.39404040575027466, 0.3569123446941376, 0.3510606288909912, 0.3518548011779785, 0.40241870284080505, 0.38630127906799316, 0.3625290095806122, 0.35632970929145813, 0.43336400389671326, 0.35503533482551575, 0.36157500743865967, 0.37071362137794495, 0.37696173787117004, 0.38764849305152893, 0.39340782165527344, 0.39665260910987854, 0.3952656686306, 0.3781723976135254, 0.3825069069862366, 0.39255112409591675, 0.3792574107646942, 0.38375887274742126, 0.38037076592445374, 0.3940281867980957, 0.47923409938812256, 0.39292678236961365, 0.39584609866142273, 0.4052501320838928, 0.40680041909217834, 0.42043375968933105, 0.4078485369682312, 0.40191885828971863, 0.39622628688812256, 0.42648524045944214, 0.41590073704719543, 0.4112502634525299, 0.40405285358428955, 0.403809517621994, 0.4354795217514038, 0.3978217542171478, 0.4634227752685547, 0.41508471965789795, 0.421424925327301, 0.44799166917800903, 0.4252464175224304, 0.4239758551120758, 0.4251400828361511, 0.4425909221172333, 0.42691272497177124, 0.44404059648513794, 0.43608731031417847, 0.46139833331108093, 0.4639222025871277, 0.45085111260414124, 0.435086190700531, 0.4410117566585541, 0.4509662985801697, 0.49418798089027405, 0.5191932320594788, 0.442058801651001, 0.4437021315097809, 0.4595127999782562, 0.45381686091423035, 0.4503830373287201, 0.4985537528991699, 0.47385483980178833, 0.5120591521263123, 0.48574116826057434, 0.4824649691581726, 0.4589304029941559, 0.4871726632118225, 0.5001556277275085, 0.46868932247161865, 0.5715688467025757], 'val_accuracy': [0.7441113591194153, 0.7933619022369385, 0.7462526559829712, 0.7184154391288757, 0.7323340177536011, 0.7398287057876587, 0.7805139422416687, 0.737687349319458, 0.7205567359924316, 0.7291220426559448, 0.7687366008758545, 0.7130621075630188, 0.7344753742218018, 0.7569593191146851, 0.7719486355781555, 0.7708779573440552, 0.7537473440170288, 0.8008565306663513, 0.8415417671203613, 0.840471088886261, 0.8286938071250916, 0.8415417671203613, 0.8447537422180176, 0.8576017022132874, 0.8865096569061279, 0.881156325340271, 0.881156325340271, 0.8854389786720276, 0.8886509537696838, 0.8886509537696838, 0.8800856471061707, 0.861884355545044, 0.8886509537696838, 0.8854389786720276, 0.881156325340271, 0.881156325340271, 0.8832976222038269, 0.8758029937744141, 0.881156325340271, 0.8897216320037842, 0.8907923102378845, 0.8854389786720276, 0.8747323155403137, 0.8832976222038269, 0.8790149688720703, 0.8897216320037842, 0.8843683004379272, 0.8907923102378845, 0.8843683004379272, 0.8865096569061279, 0.8768736720085144, 0.8832976222038269, 0.8843683004379272, 0.8854389786720276, 0.8768736720085144, 0.8650963306427002, 0.8929336071014404, 0.8790149688720703, 0.8854389786720276, 0.8854389786720276, 0.8747323155403137, 0.8832976222038269, 0.8832976222038269, 0.8865096569061279, 0.8822270035743713, 0.8822270035743713, 0.8822270035743713, 0.8886509537696838, 0.8725910186767578, 0.8832976222038269, 0.8832976222038269, 0.8854389786720276, 0.8790149688720703, 0.8897216320037842, 0.8854389786720276, 0.8886509537696838, 0.8747323155403137, 0.8832976222038269, 0.8683083653450012, 0.8865096569061279, 0.8843683004379272, 0.8747323155403137, 0.8747323155403137, 0.8522483706474304, 0.8822270035743713, 0.8800856471061707, 0.8832976222038269, 0.8725910186767578, 0.8768736720085144, 0.8854389786720276, 0.8554604053497314, 0.8854389786720276, 0.8576017022132874, 0.8875802755355835, 0.8640257120132446, 0.8790149688720703, 0.8865096569061279, 0.8640257120132446, 0.8779443502426147, 0.8394004106521606]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 9s 64ms/step - loss: 0.1430 - accuracy: 0.9475 - val_loss: 0.6469 - val_accuracy: 0.6874\n","Epoch 2/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1123 - accuracy: 0.9590 - val_loss: 0.6371 - val_accuracy: 0.7923\n","Epoch 3/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0963 - accuracy: 0.9660 - val_loss: 0.6277 - val_accuracy: 0.7537\n","Epoch 4/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0957 - accuracy: 0.9673 - val_loss: 0.6149 - val_accuracy: 0.7302\n","Epoch 5/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0881 - accuracy: 0.9708 - val_loss: 0.6027 - val_accuracy: 0.7570\n","Epoch 6/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0959 - accuracy: 0.9625 - val_loss: 0.5883 - val_accuracy: 0.7505\n","Epoch 7/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0880 - accuracy: 0.9681 - val_loss: 0.5726 - val_accuracy: 0.7612\n","Epoch 8/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0882 - accuracy: 0.9705 - val_loss: 0.5585 - val_accuracy: 0.7430\n","Epoch 9/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1000 - accuracy: 0.9630 - val_loss: 0.5428 - val_accuracy: 0.7559\n","Epoch 10/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0916 - accuracy: 0.9676 - val_loss: 0.5189 - val_accuracy: 0.7698\n","Epoch 11/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0760 - accuracy: 0.9762 - val_loss: 0.5242 - val_accuracy: 0.7281\n","Epoch 12/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0770 - accuracy: 0.9746 - val_loss: 0.5151 - val_accuracy: 0.7281\n","Epoch 13/100\n","30/30 [==============================] - 0s 17ms/step - loss: 0.0821 - accuracy: 0.9727 - val_loss: 0.4677 - val_accuracy: 0.7645\n","Epoch 14/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0720 - accuracy: 0.9778 - val_loss: 0.4901 - val_accuracy: 0.7452\n","Epoch 15/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0686 - accuracy: 0.9796 - val_loss: 0.4891 - val_accuracy: 0.7548\n","Epoch 16/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0670 - accuracy: 0.9783 - val_loss: 0.5443 - val_accuracy: 0.7409\n","Epoch 17/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0729 - accuracy: 0.9754 - val_loss: 0.5886 - val_accuracy: 0.7441\n","Epoch 18/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0751 - accuracy: 0.9746 - val_loss: 0.6134 - val_accuracy: 0.7548\n","Epoch 19/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0761 - accuracy: 0.9764 - val_loss: 0.4106 - val_accuracy: 0.8426\n","Epoch 20/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1528 - accuracy: 0.9416 - val_loss: 0.6803 - val_accuracy: 0.7687\n","Epoch 21/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0771 - accuracy: 0.9727 - val_loss: 0.5843 - val_accuracy: 0.8009\n","Epoch 22/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0650 - accuracy: 0.9802 - val_loss: 0.4846 - val_accuracy: 0.8415\n","Epoch 23/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0769 - accuracy: 0.9719 - val_loss: 0.4165 - val_accuracy: 0.8587\n","Epoch 24/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0961 - accuracy: 0.9625 - val_loss: 0.3960 - val_accuracy: 0.8672\n","Epoch 25/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0648 - accuracy: 0.9791 - val_loss: 0.3806 - val_accuracy: 0.8779\n","Epoch 26/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0573 - accuracy: 0.9837 - val_loss: 0.3722 - val_accuracy: 0.8844\n","Epoch 27/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0634 - accuracy: 0.9804 - val_loss: 0.3529 - val_accuracy: 0.8940\n","Epoch 28/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0590 - accuracy: 0.9839 - val_loss: 0.3521 - val_accuracy: 0.8972\n","Epoch 29/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0746 - accuracy: 0.9729 - val_loss: 0.4380 - val_accuracy: 0.8779\n","Epoch 30/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0638 - accuracy: 0.9794 - val_loss: 0.3780 - val_accuracy: 0.8983\n","Epoch 31/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0566 - accuracy: 0.9850 - val_loss: 0.3814 - val_accuracy: 0.8919\n","Epoch 32/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0572 - accuracy: 0.9834 - val_loss: 0.3808 - val_accuracy: 0.8951\n","Epoch 33/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0559 - accuracy: 0.9829 - val_loss: 0.4054 - val_accuracy: 0.8940\n","Epoch 34/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0692 - accuracy: 0.9748 - val_loss: 0.4106 - val_accuracy: 0.8961\n","Epoch 35/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0667 - accuracy: 0.9762 - val_loss: 0.3989 - val_accuracy: 0.8961\n","Epoch 36/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0588 - accuracy: 0.9810 - val_loss: 0.4007 - val_accuracy: 0.8908\n","Epoch 37/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0567 - accuracy: 0.9845 - val_loss: 0.3854 - val_accuracy: 0.8929\n","Epoch 38/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0550 - accuracy: 0.9815 - val_loss: 0.4040 - val_accuracy: 0.8887\n","Epoch 39/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0573 - accuracy: 0.9818 - val_loss: 0.4039 - val_accuracy: 0.8951\n","Epoch 40/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0502 - accuracy: 0.9847 - val_loss: 0.4187 - val_accuracy: 0.8972\n","Epoch 41/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0515 - accuracy: 0.9853 - val_loss: 0.4440 - val_accuracy: 0.8812\n","Epoch 42/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0536 - accuracy: 0.9842 - val_loss: 0.4869 - val_accuracy: 0.8630\n","Epoch 43/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0549 - accuracy: 0.9823 - val_loss: 0.3950 - val_accuracy: 0.8983\n","Epoch 44/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0613 - accuracy: 0.9812 - val_loss: 0.4484 - val_accuracy: 0.8790\n","Epoch 45/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0491 - accuracy: 0.9839 - val_loss: 0.4355 - val_accuracy: 0.8833\n","Epoch 46/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0503 - accuracy: 0.9850 - val_loss: 0.4264 - val_accuracy: 0.8822\n","Epoch 47/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0483 - accuracy: 0.9850 - val_loss: 0.4048 - val_accuracy: 0.9036\n","Epoch 48/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0495 - accuracy: 0.9853 - val_loss: 0.4479 - val_accuracy: 0.8897\n","Epoch 49/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0468 - accuracy: 0.9853 - val_loss: 0.4376 - val_accuracy: 0.8865\n","Epoch 50/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0479 - accuracy: 0.9871 - val_loss: 0.4481 - val_accuracy: 0.8940\n","Epoch 51/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0491 - accuracy: 0.9869 - val_loss: 0.4511 - val_accuracy: 0.8876\n","Epoch 52/100\n","30/30 [==============================] - 1s 27ms/step - loss: 0.0508 - accuracy: 0.9855 - val_loss: 0.4604 - val_accuracy: 0.8833\n","Epoch 53/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0485 - accuracy: 0.9863 - val_loss: 0.4400 - val_accuracy: 0.8972\n","Epoch 54/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0492 - accuracy: 0.9847 - val_loss: 0.4168 - val_accuracy: 0.8919\n","Epoch 55/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0481 - accuracy: 0.9863 - val_loss: 0.4470 - val_accuracy: 0.8919\n","Epoch 56/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0494 - accuracy: 0.9829 - val_loss: 0.4381 - val_accuracy: 0.8940\n","Epoch 57/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0459 - accuracy: 0.9879 - val_loss: 0.4464 - val_accuracy: 0.8929\n","Epoch 58/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0404 - accuracy: 0.9879 - val_loss: 0.4534 - val_accuracy: 0.8940\n","Epoch 59/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0453 - accuracy: 0.9863 - val_loss: 0.4598 - val_accuracy: 0.8940\n","Epoch 60/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0528 - accuracy: 0.9837 - val_loss: 0.5677 - val_accuracy: 0.8747\n","Epoch 61/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0674 - accuracy: 0.9754 - val_loss: 0.4827 - val_accuracy: 0.8715\n","Epoch 62/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0488 - accuracy: 0.9863 - val_loss: 0.4746 - val_accuracy: 0.8951\n","Epoch 63/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0520 - accuracy: 0.9829 - val_loss: 0.4468 - val_accuracy: 0.9004\n","Epoch 64/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0510 - accuracy: 0.9837 - val_loss: 0.4535 - val_accuracy: 0.8844\n","Epoch 65/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0542 - accuracy: 0.9810 - val_loss: 0.4727 - val_accuracy: 0.8865\n","Epoch 66/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0495 - accuracy: 0.9839 - val_loss: 0.4945 - val_accuracy: 0.8812\n","Epoch 67/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0381 - accuracy: 0.9893 - val_loss: 0.4627 - val_accuracy: 0.8887\n","Epoch 68/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0389 - accuracy: 0.9890 - val_loss: 0.4769 - val_accuracy: 0.8929\n","Epoch 69/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0407 - accuracy: 0.9879 - val_loss: 0.4530 - val_accuracy: 0.8961\n","Epoch 70/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0456 - accuracy: 0.9847 - val_loss: 0.4455 - val_accuracy: 0.8940\n","Epoch 71/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0773 - accuracy: 0.9711 - val_loss: 0.4948 - val_accuracy: 0.8758\n","Epoch 72/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0735 - accuracy: 0.9724 - val_loss: 0.4261 - val_accuracy: 0.8887\n","Epoch 73/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0408 - accuracy: 0.9896 - val_loss: 0.4533 - val_accuracy: 0.8908\n","Epoch 74/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0364 - accuracy: 0.9901 - val_loss: 0.4493 - val_accuracy: 0.8940\n","Epoch 75/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0444 - accuracy: 0.9855 - val_loss: 0.4839 - val_accuracy: 0.8865\n","Epoch 76/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0433 - accuracy: 0.9869 - val_loss: 0.4425 - val_accuracy: 0.8940\n","Epoch 77/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0365 - accuracy: 0.9906 - val_loss: 0.4523 - val_accuracy: 0.8940\n","Epoch 78/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0359 - accuracy: 0.9904 - val_loss: 0.4606 - val_accuracy: 0.8887\n","Epoch 79/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0289 - accuracy: 0.9938 - val_loss: 0.5393 - val_accuracy: 0.8640\n","Epoch 80/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0403 - accuracy: 0.9877 - val_loss: 0.5940 - val_accuracy: 0.8544\n","Epoch 81/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0485 - accuracy: 0.9847 - val_loss: 0.5154 - val_accuracy: 0.8790\n","Epoch 82/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0389 - accuracy: 0.9882 - val_loss: 0.4700 - val_accuracy: 0.8961\n","Epoch 83/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0342 - accuracy: 0.9909 - val_loss: 0.4711 - val_accuracy: 0.8897\n","Epoch 84/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0358 - accuracy: 0.9890 - val_loss: 0.6279 - val_accuracy: 0.8437\n","Epoch 85/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0452 - accuracy: 0.9861 - val_loss: 0.5143 - val_accuracy: 0.8769\n","Epoch 86/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0383 - accuracy: 0.9890 - val_loss: 0.4786 - val_accuracy: 0.8876\n","Epoch 87/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0611 - accuracy: 0.9794 - val_loss: 0.4753 - val_accuracy: 0.8994\n","Epoch 88/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0322 - accuracy: 0.9928 - val_loss: 0.4770 - val_accuracy: 0.8844\n","Epoch 89/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0335 - accuracy: 0.9898 - val_loss: 0.5133 - val_accuracy: 0.8812\n","Epoch 90/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0453 - accuracy: 0.9837 - val_loss: 0.4780 - val_accuracy: 0.8887\n","Epoch 91/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0459 - accuracy: 0.9831 - val_loss: 0.5655 - val_accuracy: 0.8630\n","Epoch 92/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0350 - accuracy: 0.9901 - val_loss: 0.4683 - val_accuracy: 0.8887\n","Epoch 93/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0270 - accuracy: 0.9949 - val_loss: 0.5130 - val_accuracy: 0.8854\n","Epoch 94/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0331 - accuracy: 0.9914 - val_loss: 0.4867 - val_accuracy: 0.8919\n","Epoch 95/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0314 - accuracy: 0.9920 - val_loss: 0.4908 - val_accuracy: 0.8887\n","Epoch 96/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0343 - accuracy: 0.9887 - val_loss: 0.4826 - val_accuracy: 0.8897\n","Epoch 97/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0274 - accuracy: 0.9930 - val_loss: 0.5012 - val_accuracy: 0.8929\n","Epoch 98/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0389 - accuracy: 0.9861 - val_loss: 0.5112 - val_accuracy: 0.8876\n","Epoch 99/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0281 - accuracy: 0.9925 - val_loss: 0.4978 - val_accuracy: 0.8887\n","Epoch 100/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0376 - accuracy: 0.9885 - val_loss: 0.4942 - val_accuracy: 0.8919\n","{'loss': [0.14301139116287231, 0.112294040620327, 0.09626654535531998, 0.09570583701133728, 0.08812221139669418, 0.09594205021858215, 0.08797980844974518, 0.08822738379240036, 0.09995073825120926, 0.09160809963941574, 0.07603108882904053, 0.07696335017681122, 0.08211507648229599, 0.07196395099163055, 0.06861938536167145, 0.06701449304819107, 0.07292906194925308, 0.07507842779159546, 0.0761331096291542, 0.1527661681175232, 0.07707083970308304, 0.06501249223947525, 0.0768766924738884, 0.0961432084441185, 0.06481301784515381, 0.057347189635038376, 0.06344632059335709, 0.05898592621088028, 0.0746007040143013, 0.06382647901773453, 0.056560199707746506, 0.05722320079803467, 0.05585837364196777, 0.06920672208070755, 0.06670214235782623, 0.05878797918558121, 0.05670706555247307, 0.055011339485645294, 0.05725548416376114, 0.05018067732453346, 0.05153515562415123, 0.053560659289360046, 0.05494304373860359, 0.061280056834220886, 0.049090899527072906, 0.05033639818429947, 0.048306096345186234, 0.049545373767614365, 0.04675693437457085, 0.04789434373378754, 0.049120932817459106, 0.05084295570850372, 0.04850069433450699, 0.049192722886800766, 0.048131924122571945, 0.04942460358142853, 0.04590488597750664, 0.040371574461460114, 0.04530724138021469, 0.052839960902929306, 0.06735663115978241, 0.04884669929742813, 0.05199267342686653, 0.05096081271767616, 0.05418677628040314, 0.049505043774843216, 0.03809000924229622, 0.03888191282749176, 0.04065490886569023, 0.04558531567454338, 0.07729925960302353, 0.07353527098894119, 0.04078126698732376, 0.036401282995939255, 0.04439355060458183, 0.04329550638794899, 0.03648240491747856, 0.03588138520717621, 0.028899939730763435, 0.040261100977659225, 0.04854318127036095, 0.038873665034770966, 0.034193187952041626, 0.035817477852106094, 0.04519067332148552, 0.038283657282590866, 0.06108328327536583, 0.0321999117732048, 0.033489394932985306, 0.04534589499235153, 0.04594743251800537, 0.035037752240896225, 0.026978041976690292, 0.03314027190208435, 0.031395550817251205, 0.034319162368774414, 0.027386413887143135, 0.03885309398174286, 0.028146466240286827, 0.03755888715386391], 'accuracy': [0.9474953413009644, 0.9590141773223877, 0.9659790992736816, 0.9673185348510742, 0.9708009362220764, 0.9624966382980347, 0.968122124671936, 0.9705330729484558, 0.9630324244499207, 0.9675863981246948, 0.9761585593223572, 0.9745513200759888, 0.972676157951355, 0.9777658581733704, 0.9796410202980042, 0.9783016443252563, 0.9753549695014954, 0.9745513200759888, 0.9764264822006226, 0.9416019320487976, 0.972676157951355, 0.9801768064498901, 0.9718725085258484, 0.9624966382980347, 0.9791052937507629, 0.9836592674255371, 0.9804446697235107, 0.9839271306991577, 0.9729440212249756, 0.9793731570243835, 0.9849986433982849, 0.9833913445472717, 0.9828556180000305, 0.9748191833496094, 0.9761585593223572, 0.9809804558753967, 0.9844629168510437, 0.9815161824226379, 0.9817841053009033, 0.9847307801246643, 0.9852665662765503, 0.9841949939727783, 0.9823198318481445, 0.9812483191490173, 0.9839271306991577, 0.9849986433982849, 0.9849986433982849, 0.9852665662765503, 0.9852665662765503, 0.9871417284011841, 0.9868738055229187, 0.9855344295501709, 0.9863380789756775, 0.9847307801246643, 0.9863380789756775, 0.9828556180000305, 0.9879453778266907, 0.9879453778266907, 0.9863380789756775, 0.9836592674255371, 0.9753549695014954, 0.9863380789756775, 0.9828556180000305, 0.9836592674255371, 0.9809804558753967, 0.9839271306991577, 0.9892847537994385, 0.9890168905258179, 0.9879453778266907, 0.9847307801246643, 0.9710688591003418, 0.9724082350730896, 0.9895526170730591, 0.9900884032249451, 0.9855344295501709, 0.9868738055229187, 0.990624189376831, 0.9903562664985657, 0.9938387274742126, 0.9876774549484253, 0.9847307801246643, 0.9882132411003113, 0.9908920526504517, 0.9890168905258179, 0.9860701560974121, 0.9890168905258179, 0.9793731570243835, 0.9927672147750854, 0.9898205399513245, 0.9836592674255371, 0.9831234812736511, 0.9900884032249451, 0.9949102401733398, 0.9914277791976929, 0.9919635653495789, 0.9887489676475525, 0.993035078048706, 0.9860701560974121, 0.9924993515014648, 0.9884811043739319], 'val_loss': [0.646862268447876, 0.6370572447776794, 0.6276938319206238, 0.6149237751960754, 0.6027474999427795, 0.5882824063301086, 0.5725999474525452, 0.5585315227508545, 0.5427769422531128, 0.5189301371574402, 0.5241726040840149, 0.5151262879371643, 0.4676903784275055, 0.49012190103530884, 0.48906874656677246, 0.5443257093429565, 0.5885629653930664, 0.6133954524993896, 0.4106168746948242, 0.6802728772163391, 0.5842649340629578, 0.48457545042037964, 0.4165082573890686, 0.3959534466266632, 0.3806345760822296, 0.37215399742126465, 0.3529128432273865, 0.35210704803466797, 0.4380154013633728, 0.3780163526535034, 0.3813997805118561, 0.3808457553386688, 0.40535348653793335, 0.41056081652641296, 0.3988977372646332, 0.4006631374359131, 0.3853658437728882, 0.40404772758483887, 0.4038873016834259, 0.41870853304862976, 0.44399672746658325, 0.48691651225090027, 0.39498502016067505, 0.448357492685318, 0.4355289041996002, 0.426448792219162, 0.40478625893592834, 0.44793570041656494, 0.4375624358654022, 0.4481491446495056, 0.45105651021003723, 0.4604075253009796, 0.4400074779987335, 0.4167696237564087, 0.4470047950744629, 0.43807676434516907, 0.44636020064353943, 0.4533982276916504, 0.45978760719299316, 0.5676565766334534, 0.4827336370944977, 0.47458043694496155, 0.44681453704833984, 0.45345377922058105, 0.47267571091651917, 0.4945046007633209, 0.46265077590942383, 0.47689053416252136, 0.4529918432235718, 0.4454590380191803, 0.49480634927749634, 0.4261086583137512, 0.45332443714141846, 0.4493483304977417, 0.4839363396167755, 0.44250354170799255, 0.45231592655181885, 0.46060216426849365, 0.5392508506774902, 0.5940178632736206, 0.515436589717865, 0.4699612855911255, 0.4711166024208069, 0.627945065498352, 0.5143117308616638, 0.4786292612552643, 0.47532978653907776, 0.4769569933414459, 0.5133494734764099, 0.47797030210494995, 0.5654645562171936, 0.4682881832122803, 0.5130035877227783, 0.486707478761673, 0.49077358841896057, 0.4826064705848694, 0.5012282729148865, 0.5112478733062744, 0.49777546525001526, 0.49419182538986206], 'val_accuracy': [0.6873661875724792, 0.7922912240028381, 0.7537473440170288, 0.7301927208900452, 0.7569593191146851, 0.7505353093147278, 0.7612419724464417, 0.7430406808853149, 0.7558886408805847, 0.7698072791099548, 0.7280513644218445, 0.7280513644218445, 0.7644539475440979, 0.7451820373535156, 0.7548179626464844, 0.740899384021759, 0.7441113591194153, 0.7548179626464844, 0.8426124453544617, 0.7687366008758545, 0.8008565306663513, 0.8415417671203613, 0.8586723804473877, 0.8672376871109009, 0.8779443502426147, 0.8843683004379272, 0.8940042853355408, 0.897216260433197, 0.8779443502426147, 0.8982869386672974, 0.8918629288673401, 0.8950749635696411, 0.8940042853355408, 0.8961455821990967, 0.8961455821990967, 0.8907923102378845, 0.8929336071014404, 0.8886509537696838, 0.8950749635696411, 0.897216260433197, 0.881156325340271, 0.8629550337791443, 0.8982869386672974, 0.8790149688720703, 0.8832976222038269, 0.8822270035743713, 0.9036402702331543, 0.8897216320037842, 0.8865096569061279, 0.8940042853355408, 0.8875802755355835, 0.8832976222038269, 0.897216260433197, 0.8918629288673401, 0.8918629288673401, 0.8940042853355408, 0.8929336071014404, 0.8940042853355408, 0.8940042853355408, 0.8747323155403137, 0.8715203404426575, 0.8950749635696411, 0.900428295135498, 0.8843683004379272, 0.8865096569061279, 0.881156325340271, 0.8886509537696838, 0.8929336071014404, 0.8961455821990967, 0.8940042853355408, 0.8758029937744141, 0.8886509537696838, 0.8907923102378845, 0.8940042853355408, 0.8865096569061279, 0.8940042853355408, 0.8940042853355408, 0.8886509537696838, 0.8640257120132446, 0.8543897271156311, 0.8790149688720703, 0.8961455821990967, 0.8897216320037842, 0.8436830639839172, 0.8768736720085144, 0.8875802755355835, 0.8993576169013977, 0.8843683004379272, 0.881156325340271, 0.8886509537696838, 0.8629550337791443, 0.8886509537696838, 0.8854389786720276, 0.8918629288673401, 0.8886509537696838, 0.8897216320037842, 0.8929336071014404, 0.8875802755355835, 0.8886509537696838, 0.8918629288673401]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 76ms/step - loss: 0.1567 - accuracy: 0.9429 - val_loss: 0.6463 - val_accuracy: 0.7473\n","Epoch 2/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.1072 - accuracy: 0.9622 - val_loss: 0.6360 - val_accuracy: 0.8137\n","Epoch 3/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.1150 - accuracy: 0.9638 - val_loss: 0.6265 - val_accuracy: 0.7484\n","Epoch 4/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0965 - accuracy: 0.9676 - val_loss: 0.6138 - val_accuracy: 0.7420\n","Epoch 5/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0934 - accuracy: 0.9692 - val_loss: 0.6036 - val_accuracy: 0.7163\n","Epoch 6/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0924 - accuracy: 0.9695 - val_loss: 0.5854 - val_accuracy: 0.7537\n","Epoch 7/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0921 - accuracy: 0.9719 - val_loss: 0.5803 - val_accuracy: 0.7152\n","Epoch 8/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0946 - accuracy: 0.9676 - val_loss: 0.5545 - val_accuracy: 0.7591\n","Epoch 9/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0871 - accuracy: 0.9700 - val_loss: 0.5331 - val_accuracy: 0.7655\n","Epoch 10/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0929 - accuracy: 0.9684 - val_loss: 0.5227 - val_accuracy: 0.7441\n","Epoch 11/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0874 - accuracy: 0.9695 - val_loss: 0.4976 - val_accuracy: 0.7666\n","Epoch 12/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0873 - accuracy: 0.9756 - val_loss: 0.4881 - val_accuracy: 0.7527\n","Epoch 13/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0784 - accuracy: 0.9746 - val_loss: 0.4837 - val_accuracy: 0.7505\n","Epoch 14/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0772 - accuracy: 0.9775 - val_loss: 0.4966 - val_accuracy: 0.7420\n","Epoch 15/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0954 - accuracy: 0.9654 - val_loss: 0.4475 - val_accuracy: 0.7859\n","Epoch 16/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1057 - accuracy: 0.9612 - val_loss: 0.4054 - val_accuracy: 0.8148\n","Epoch 17/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0804 - accuracy: 0.9751 - val_loss: 0.4849 - val_accuracy: 0.7837\n","Epoch 18/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0769 - accuracy: 0.9759 - val_loss: 0.4147 - val_accuracy: 0.8287\n","Epoch 19/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0778 - accuracy: 0.9748 - val_loss: 0.6344 - val_accuracy: 0.7591\n","Epoch 20/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0912 - accuracy: 0.9697 - val_loss: 0.4729 - val_accuracy: 0.8255\n","Epoch 21/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0842 - accuracy: 0.9703 - val_loss: 0.4475 - val_accuracy: 0.8405\n","Epoch 22/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0860 - accuracy: 0.9697 - val_loss: 0.3524 - val_accuracy: 0.8704\n","Epoch 23/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0767 - accuracy: 0.9770 - val_loss: 0.4514 - val_accuracy: 0.8544\n","Epoch 24/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0711 - accuracy: 0.9772 - val_loss: 0.4191 - val_accuracy: 0.8683\n","Epoch 25/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0751 - accuracy: 0.9762 - val_loss: 0.3116 - val_accuracy: 0.8919\n","Epoch 26/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0667 - accuracy: 0.9783 - val_loss: 0.2969 - val_accuracy: 0.9004\n","Epoch 27/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0771 - accuracy: 0.9746 - val_loss: 0.4700 - val_accuracy: 0.8672\n","Epoch 28/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.1132 - accuracy: 0.9545 - val_loss: 0.2486 - val_accuracy: 0.9165\n","Epoch 29/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0834 - accuracy: 0.9695 - val_loss: 0.2297 - val_accuracy: 0.9165\n","Epoch 30/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0645 - accuracy: 0.9802 - val_loss: 0.2335 - val_accuracy: 0.9251\n","Epoch 31/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0737 - accuracy: 0.9754 - val_loss: 0.2378 - val_accuracy: 0.9154\n","Epoch 32/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0630 - accuracy: 0.9812 - val_loss: 0.2357 - val_accuracy: 0.9197\n","Epoch 33/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0601 - accuracy: 0.9821 - val_loss: 0.2517 - val_accuracy: 0.9218\n","Epoch 34/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0728 - accuracy: 0.9737 - val_loss: 0.2564 - val_accuracy: 0.9218\n","Epoch 35/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0573 - accuracy: 0.9815 - val_loss: 0.2403 - val_accuracy: 0.9240\n","Epoch 36/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0673 - accuracy: 0.9770 - val_loss: 0.2987 - val_accuracy: 0.9111\n","Epoch 37/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0576 - accuracy: 0.9821 - val_loss: 0.2441 - val_accuracy: 0.9165\n","Epoch 38/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0697 - accuracy: 0.9746 - val_loss: 0.2635 - val_accuracy: 0.9111\n","Epoch 39/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0694 - accuracy: 0.9756 - val_loss: 0.2538 - val_accuracy: 0.9090\n","Epoch 40/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0563 - accuracy: 0.9810 - val_loss: 0.2481 - val_accuracy: 0.9251\n","Epoch 41/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0654 - accuracy: 0.9780 - val_loss: 0.2493 - val_accuracy: 0.9122\n","Epoch 42/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0584 - accuracy: 0.9826 - val_loss: 0.2642 - val_accuracy: 0.9133\n","Epoch 43/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0543 - accuracy: 0.9829 - val_loss: 0.2799 - val_accuracy: 0.9090\n","Epoch 44/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0526 - accuracy: 0.9869 - val_loss: 0.2667 - val_accuracy: 0.9165\n","Epoch 45/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0533 - accuracy: 0.9804 - val_loss: 0.2621 - val_accuracy: 0.9133\n","Epoch 46/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0535 - accuracy: 0.9818 - val_loss: 0.4323 - val_accuracy: 0.8769\n","Epoch 47/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0685 - accuracy: 0.9740 - val_loss: 0.2581 - val_accuracy: 0.9111\n","Epoch 48/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0535 - accuracy: 0.9831 - val_loss: 0.2571 - val_accuracy: 0.9208\n","Epoch 49/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0485 - accuracy: 0.9850 - val_loss: 0.2770 - val_accuracy: 0.9090\n","Epoch 50/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0547 - accuracy: 0.9807 - val_loss: 0.2729 - val_accuracy: 0.9133\n","Epoch 51/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0604 - accuracy: 0.9772 - val_loss: 0.5355 - val_accuracy: 0.8480\n","Epoch 52/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0636 - accuracy: 0.9775 - val_loss: 0.3117 - val_accuracy: 0.9069\n","Epoch 53/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0540 - accuracy: 0.9834 - val_loss: 0.2704 - val_accuracy: 0.9090\n","Epoch 54/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0424 - accuracy: 0.9898 - val_loss: 0.2890 - val_accuracy: 0.9090\n","Epoch 55/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0465 - accuracy: 0.9879 - val_loss: 0.2676 - val_accuracy: 0.9133\n","Epoch 56/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0604 - accuracy: 0.9807 - val_loss: 0.2795 - val_accuracy: 0.9176\n","Epoch 57/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0528 - accuracy: 0.9837 - val_loss: 0.2852 - val_accuracy: 0.9133\n","Epoch 58/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0623 - accuracy: 0.9775 - val_loss: 0.2668 - val_accuracy: 0.9176\n","Epoch 59/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0498 - accuracy: 0.9818 - val_loss: 0.2759 - val_accuracy: 0.9101\n","Epoch 60/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0466 - accuracy: 0.9871 - val_loss: 0.2765 - val_accuracy: 0.9143\n","Epoch 61/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0477 - accuracy: 0.9831 - val_loss: 0.3019 - val_accuracy: 0.9111\n","Epoch 62/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0638 - accuracy: 0.9756 - val_loss: 0.3527 - val_accuracy: 0.9079\n","Epoch 63/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0482 - accuracy: 0.9845 - val_loss: 0.3156 - val_accuracy: 0.9026\n","Epoch 64/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0417 - accuracy: 0.9871 - val_loss: 0.2977 - val_accuracy: 0.9069\n","Epoch 65/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0561 - accuracy: 0.9802 - val_loss: 0.3163 - val_accuracy: 0.9122\n","Epoch 66/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0513 - accuracy: 0.9826 - val_loss: 0.2784 - val_accuracy: 0.9197\n","Epoch 67/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0461 - accuracy: 0.9850 - val_loss: 0.3648 - val_accuracy: 0.8887\n","Epoch 68/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0539 - accuracy: 0.9810 - val_loss: 0.2877 - val_accuracy: 0.9069\n","Epoch 69/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0572 - accuracy: 0.9802 - val_loss: 0.2910 - val_accuracy: 0.9079\n","Epoch 70/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0480 - accuracy: 0.9845 - val_loss: 0.3280 - val_accuracy: 0.9111\n","Epoch 71/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0377 - accuracy: 0.9912 - val_loss: 0.2944 - val_accuracy: 0.9090\n","Epoch 72/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0438 - accuracy: 0.9866 - val_loss: 0.3417 - val_accuracy: 0.9026\n","Epoch 73/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0447 - accuracy: 0.9842 - val_loss: 0.3009 - val_accuracy: 0.9047\n","Epoch 74/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0465 - accuracy: 0.9842 - val_loss: 0.2984 - val_accuracy: 0.9079\n","Epoch 75/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0470 - accuracy: 0.9850 - val_loss: 0.2939 - val_accuracy: 0.9122\n","Epoch 76/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0548 - accuracy: 0.9818 - val_loss: 0.2917 - val_accuracy: 0.9090\n","Epoch 77/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0560 - accuracy: 0.9815 - val_loss: 0.3003 - val_accuracy: 0.9069\n","Epoch 78/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0525 - accuracy: 0.9815 - val_loss: 0.2872 - val_accuracy: 0.9111\n","Epoch 79/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0386 - accuracy: 0.9890 - val_loss: 0.3016 - val_accuracy: 0.9058\n","Epoch 80/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0317 - accuracy: 0.9917 - val_loss: 0.3322 - val_accuracy: 0.8972\n","Epoch 81/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0411 - accuracy: 0.9879 - val_loss: 0.3342 - val_accuracy: 0.9004\n","Epoch 82/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0422 - accuracy: 0.9845 - val_loss: 0.2908 - val_accuracy: 0.9069\n","Epoch 83/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0403 - accuracy: 0.9858 - val_loss: 0.3394 - val_accuracy: 0.9058\n","Epoch 84/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0343 - accuracy: 0.9906 - val_loss: 0.3528 - val_accuracy: 0.8951\n","Epoch 85/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0518 - accuracy: 0.9804 - val_loss: 0.3595 - val_accuracy: 0.9101\n","Epoch 86/100\n","30/30 [==============================] - 1s 28ms/step - loss: 0.0364 - accuracy: 0.9901 - val_loss: 0.3963 - val_accuracy: 0.8951\n","Epoch 87/100\n","30/30 [==============================] - 1s 29ms/step - loss: 0.0448 - accuracy: 0.9845 - val_loss: 0.3024 - val_accuracy: 0.9047\n","Epoch 88/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0311 - accuracy: 0.9912 - val_loss: 0.3425 - val_accuracy: 0.9015\n","Epoch 89/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0417 - accuracy: 0.9837 - val_loss: 0.3151 - val_accuracy: 0.9036\n","Epoch 90/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0334 - accuracy: 0.9893 - val_loss: 0.3827 - val_accuracy: 0.8940\n","Epoch 91/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0377 - accuracy: 0.9869 - val_loss: 0.3227 - val_accuracy: 0.9111\n","Epoch 92/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0361 - accuracy: 0.9896 - val_loss: 0.3598 - val_accuracy: 0.8983\n","Epoch 93/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0327 - accuracy: 0.9890 - val_loss: 0.3065 - val_accuracy: 0.9058\n","Epoch 94/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0292 - accuracy: 0.9909 - val_loss: 0.3175 - val_accuracy: 0.9047\n","Epoch 95/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0251 - accuracy: 0.9933 - val_loss: 0.3116 - val_accuracy: 0.9111\n","Epoch 96/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0236 - accuracy: 0.9941 - val_loss: 0.3367 - val_accuracy: 0.9036\n","Epoch 97/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0233 - accuracy: 0.9949 - val_loss: 0.3612 - val_accuracy: 0.9015\n","Epoch 98/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0288 - accuracy: 0.9912 - val_loss: 0.3205 - val_accuracy: 0.9090\n","Epoch 99/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0320 - accuracy: 0.9896 - val_loss: 0.3694 - val_accuracy: 0.8994\n","Epoch 100/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0666 - accuracy: 0.9756 - val_loss: 0.4127 - val_accuracy: 0.8972\n","{'loss': [0.15673458576202393, 0.10716953128576279, 0.11496313661336899, 0.09645429998636246, 0.09343474358320236, 0.09241756796836853, 0.09210091084241867, 0.09463541209697723, 0.08707007765769958, 0.09289098531007767, 0.08737596869468689, 0.08726004511117935, 0.07835698127746582, 0.07717550545930862, 0.09540148079395294, 0.10574173182249069, 0.0803651213645935, 0.07687631994485855, 0.07777538895606995, 0.09116125106811523, 0.08422420173883438, 0.08601198345422745, 0.07669629901647568, 0.07113640755414963, 0.07512050122022629, 0.06673498451709747, 0.07712768018245697, 0.11321098357439041, 0.08337142318487167, 0.06450232118368149, 0.07371629774570465, 0.0629739910364151, 0.060124028474092484, 0.07281024008989334, 0.05729043856263161, 0.06734097748994827, 0.05755744129419327, 0.06966543197631836, 0.06936037540435791, 0.05629006028175354, 0.06539613008499146, 0.058361005038022995, 0.05431942641735077, 0.05258376896381378, 0.0532665029168129, 0.05351819097995758, 0.06849071383476257, 0.05351928249001503, 0.048531342297792435, 0.054691266268491745, 0.06039714440703392, 0.06357936561107635, 0.05401495471596718, 0.04238279536366463, 0.046467043459415436, 0.0604093037545681, 0.052751023322343826, 0.062311574816703796, 0.049838099628686905, 0.04660024121403694, 0.04766030237078667, 0.06382954120635986, 0.04822095111012459, 0.04170631617307663, 0.056059859693050385, 0.051325052976608276, 0.04610208794474602, 0.05386964604258537, 0.05715838074684143, 0.0480160191655159, 0.037676852196455, 0.043828967958688736, 0.0447002574801445, 0.046499162912368774, 0.046952638775110245, 0.05483614653348923, 0.05598363280296326, 0.05252331495285034, 0.038600098341703415, 0.03168226405978203, 0.04111610725522041, 0.04219311103224754, 0.040329787880182266, 0.03425102308392525, 0.051841795444488525, 0.03637687489390373, 0.044754508882761, 0.031144678592681885, 0.04166749119758606, 0.03335825353860855, 0.037664804607629776, 0.03609475493431091, 0.03266875818371773, 0.02918991819024086, 0.02510477602481842, 0.023628761991858482, 0.02325931191444397, 0.028825342655181885, 0.03200698271393776, 0.06661974638700485], 'accuracy': [0.9429413080215454, 0.9622287750244141, 0.9638360738754272, 0.9675863981246948, 0.969193696975708, 0.9694615602493286, 0.9718725085258484, 0.9675863981246948, 0.9699973464012146, 0.9683900475502014, 0.9694615602493286, 0.975622832775116, 0.9745513200759888, 0.9774979948997498, 0.9654433727264404, 0.9611572623252869, 0.97508704662323, 0.9758906960487366, 0.9748191833496094, 0.9697294235229492, 0.9702652096748352, 0.9697294235229492, 0.9769622087478638, 0.9772301316261292, 0.9761585593223572, 0.9783016443252563, 0.9745513200759888, 0.9544602036476135, 0.9694615602493286, 0.9801768064498901, 0.9753549695014954, 0.9812483191490173, 0.9820519685745239, 0.9737476706504822, 0.9815161824226379, 0.9769622087478638, 0.9820519685745239, 0.9745513200759888, 0.975622832775116, 0.9809804558753967, 0.9780337810516357, 0.9825877547264099, 0.9828556180000305, 0.9868738055229187, 0.9804446697235107, 0.9817841053009033, 0.9740155339241028, 0.9831234812736511, 0.9849986433982849, 0.9807125926017761, 0.9772301316261292, 0.9774979948997498, 0.9833913445472717, 0.9898205399513245, 0.9879453778266907, 0.9807125926017761, 0.9836592674255371, 0.9774979948997498, 0.9817841053009033, 0.9871417284011841, 0.9831234812736511, 0.975622832775116, 0.9844629168510437, 0.9871417284011841, 0.9801768064498901, 0.9825877547264099, 0.9849986433982849, 0.9809804558753967, 0.9801768064498901, 0.9844629168510437, 0.9911599159240723, 0.9866059422492981, 0.9841949939727783, 0.9841949939727783, 0.9849986433982849, 0.9817841053009033, 0.9815161824226379, 0.9815161824226379, 0.9890168905258179, 0.9916957020759583, 0.9879453778266907, 0.9844629168510437, 0.9858022928237915, 0.990624189376831, 0.9804446697235107, 0.9900884032249451, 0.9844629168510437, 0.9911599159240723, 0.9836592674255371, 0.9892847537994385, 0.9868738055229187, 0.9895526170730591, 0.9890168905258179, 0.9908920526504517, 0.9933030009269714, 0.9941065907478333, 0.9949102401733398, 0.9911599159240723, 0.9895526170730591, 0.975622832775116], 'val_loss': [0.6462973356246948, 0.6359987854957581, 0.6265197396278381, 0.6138208508491516, 0.6035757660865784, 0.5853739976882935, 0.5802657008171082, 0.5544632077217102, 0.5331122875213623, 0.5226798057556152, 0.4976419508457184, 0.4880763292312622, 0.4837252199649811, 0.4966247081756592, 0.4474777579307556, 0.40541183948516846, 0.4848741292953491, 0.4146853983402252, 0.6344016790390015, 0.4729190170764923, 0.4475487172603607, 0.3523549735546112, 0.4514046013355255, 0.4190576672554016, 0.311576247215271, 0.2968911826610565, 0.4700249135494232, 0.24863719940185547, 0.22966738045215607, 0.23350976407527924, 0.23781231045722961, 0.23572741448879242, 0.25171810388565063, 0.25644785165786743, 0.24025237560272217, 0.2986910045146942, 0.24407583475112915, 0.2634720504283905, 0.2537515163421631, 0.2481260746717453, 0.2493087649345398, 0.264244019985199, 0.2798953652381897, 0.26669541001319885, 0.26214730739593506, 0.4322751760482788, 0.2580687999725342, 0.257085382938385, 0.2770218253135681, 0.2729257643222809, 0.5354771018028259, 0.3116966187953949, 0.2704390585422516, 0.28901514410972595, 0.2676022946834564, 0.27951571345329285, 0.28518420457839966, 0.26684296131134033, 0.2758629620075226, 0.2764718532562256, 0.30189529061317444, 0.3527442514896393, 0.31564071774482727, 0.2977007031440735, 0.3162532150745392, 0.27839645743370056, 0.3648131191730499, 0.2876821756362915, 0.29098838567733765, 0.32801470160484314, 0.29443517327308655, 0.34172698855400085, 0.30093541741371155, 0.29844316840171814, 0.2939481735229492, 0.2917249798774719, 0.3003424406051636, 0.28721582889556885, 0.30161911249160767, 0.3322429060935974, 0.3341507613658905, 0.2908393442630768, 0.33939650654792786, 0.3528028428554535, 0.3594684898853302, 0.39634889364242554, 0.3024441599845886, 0.34250468015670776, 0.31511056423187256, 0.3826551139354706, 0.32274582982063293, 0.3597698211669922, 0.3064996600151062, 0.3174666464328766, 0.3116050660610199, 0.3367331922054291, 0.3611951172351837, 0.32046011090278625, 0.36935189366340637, 0.41265934705734253], 'val_accuracy': [0.7473233342170715, 0.8137044906616211, 0.7483940124511719, 0.7419700026512146, 0.716274082660675, 0.7537473440170288, 0.7152034044265747, 0.759100615978241, 0.7655246257781982, 0.7441113591194153, 0.7665953040122986, 0.7526766657829285, 0.7505353093147278, 0.7419700026512146, 0.7858672142028809, 0.8147751688957214, 0.783725917339325, 0.8286938071250916, 0.759100615978241, 0.8254817724227905, 0.840471088886261, 0.8704496622085571, 0.8543897271156311, 0.8683083653450012, 0.8918629288673401, 0.900428295135498, 0.8672376871109009, 0.9164882302284241, 0.9164882302284241, 0.9250535368919373, 0.9154175519943237, 0.9197002053260803, 0.921841561794281, 0.921841561794281, 0.9239828586578369, 0.9111348986625671, 0.9164882302284241, 0.9111348986625671, 0.9089936017990112, 0.9250535368919373, 0.9122055768966675, 0.9132762551307678, 0.9089936017990112, 0.9164882302284241, 0.9132762551307678, 0.8768736720085144, 0.9111348986625671, 0.9207708835601807, 0.9089936017990112, 0.9132762551307678, 0.8479657173156738, 0.9068522453308105, 0.9089936017990112, 0.9089936017990112, 0.9132762551307678, 0.9175589084625244, 0.9132762551307678, 0.9175589084625244, 0.9100642204284668, 0.9143468737602234, 0.9111348986625671, 0.9079229235649109, 0.902569591999054, 0.9068522453308105, 0.9122055768966675, 0.9197002053260803, 0.8886509537696838, 0.9068522453308105, 0.9079229235649109, 0.9111348986625671, 0.9089936017990112, 0.902569591999054, 0.9047109484672546, 0.9079229235649109, 0.9122055768966675, 0.9089936017990112, 0.9068522453308105, 0.9111348986625671, 0.9057815670967102, 0.897216260433197, 0.900428295135498, 0.9068522453308105, 0.9057815670967102, 0.8950749635696411, 0.9100642204284668, 0.8950749635696411, 0.9047109484672546, 0.9014989137649536, 0.9036402702331543, 0.8940042853355408, 0.9111348986625671, 0.8982869386672974, 0.9057815670967102, 0.9047109484672546, 0.9111348986625671, 0.9036402702331543, 0.9014989137649536, 0.9089936017990112, 0.8993576169013977, 0.897216260433197]}\n","37/37 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/30 [==============================] - 8s 47ms/step - loss: 0.1279 - accuracy: 0.9555 - val_loss: 0.6452 - val_accuracy: 0.6938\n","Epoch 2/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1184 - accuracy: 0.9542 - val_loss: 0.6355 - val_accuracy: 0.7816\n","Epoch 3/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0953 - accuracy: 0.9644 - val_loss: 0.6252 - val_accuracy: 0.7527\n","Epoch 4/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0879 - accuracy: 0.9732 - val_loss: 0.6176 - val_accuracy: 0.7195\n","Epoch 5/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0828 - accuracy: 0.9713 - val_loss: 0.6025 - val_accuracy: 0.7238\n","Epoch 6/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0827 - accuracy: 0.9705 - val_loss: 0.5843 - val_accuracy: 0.7612\n","Epoch 7/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0917 - accuracy: 0.9641 - val_loss: 0.5726 - val_accuracy: 0.7355\n","Epoch 8/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0845 - accuracy: 0.9671 - val_loss: 0.5771 - val_accuracy: 0.6874\n","Epoch 9/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0940 - accuracy: 0.9652 - val_loss: 0.5516 - val_accuracy: 0.7259\n","Epoch 10/100\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0785 - accuracy: 0.9748 - val_loss: 0.5286 - val_accuracy: 0.7323\n","Epoch 11/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0877 - accuracy: 0.9671 - val_loss: 0.5458 - val_accuracy: 0.6927\n","Epoch 12/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0976 - accuracy: 0.9625 - val_loss: 0.5104 - val_accuracy: 0.7302\n","Epoch 13/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0847 - accuracy: 0.9687 - val_loss: 0.4605 - val_accuracy: 0.7848\n","Epoch 14/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0716 - accuracy: 0.9764 - val_loss: 0.4588 - val_accuracy: 0.7848\n","Epoch 15/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0684 - accuracy: 0.9778 - val_loss: 0.5104 - val_accuracy: 0.7559\n","Epoch 16/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0690 - accuracy: 0.9751 - val_loss: 0.4767 - val_accuracy: 0.7752\n","Epoch 17/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0696 - accuracy: 0.9759 - val_loss: 0.5474 - val_accuracy: 0.7655\n","Epoch 18/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0745 - accuracy: 0.9711 - val_loss: 0.6577 - val_accuracy: 0.7495\n","Epoch 19/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0709 - accuracy: 0.9764 - val_loss: 0.4772 - val_accuracy: 0.8244\n","Epoch 20/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0809 - accuracy: 0.9703 - val_loss: 0.6362 - val_accuracy: 0.7837\n","Epoch 21/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0604 - accuracy: 0.9807 - val_loss: 0.5917 - val_accuracy: 0.8116\n","Epoch 22/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0590 - accuracy: 0.9821 - val_loss: 0.5875 - val_accuracy: 0.8255\n","Epoch 23/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0650 - accuracy: 0.9759 - val_loss: 0.4559 - val_accuracy: 0.8683\n","Epoch 24/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0677 - accuracy: 0.9764 - val_loss: 0.4379 - val_accuracy: 0.8769\n","Epoch 25/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0546 - accuracy: 0.9839 - val_loss: 0.3795 - val_accuracy: 0.8897\n","Epoch 26/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0582 - accuracy: 0.9810 - val_loss: 0.4432 - val_accuracy: 0.8822\n","Epoch 27/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0638 - accuracy: 0.9770 - val_loss: 0.3439 - val_accuracy: 0.9026\n","Epoch 28/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0642 - accuracy: 0.9780 - val_loss: 0.3382 - val_accuracy: 0.9026\n","Epoch 29/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0703 - accuracy: 0.9727 - val_loss: 0.3773 - val_accuracy: 0.9058\n","Epoch 30/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0613 - accuracy: 0.9780 - val_loss: 0.3981 - val_accuracy: 0.9004\n","Epoch 31/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0648 - accuracy: 0.9756 - val_loss: 0.4033 - val_accuracy: 0.8983\n","Epoch 32/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0617 - accuracy: 0.9778 - val_loss: 0.3401 - val_accuracy: 0.9058\n","Epoch 33/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0566 - accuracy: 0.9807 - val_loss: 0.4298 - val_accuracy: 0.8747\n","Epoch 34/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0732 - accuracy: 0.9756 - val_loss: 0.3549 - val_accuracy: 0.8929\n","Epoch 35/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0539 - accuracy: 0.9831 - val_loss: 0.3547 - val_accuracy: 0.9036\n","Epoch 36/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0497 - accuracy: 0.9858 - val_loss: 0.3635 - val_accuracy: 0.9047\n","Epoch 37/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0544 - accuracy: 0.9812 - val_loss: 0.3912 - val_accuracy: 0.8887\n","Epoch 38/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0650 - accuracy: 0.9762 - val_loss: 0.3781 - val_accuracy: 0.8994\n","Epoch 39/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0615 - accuracy: 0.9775 - val_loss: 0.4235 - val_accuracy: 0.8790\n","Epoch 40/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0702 - accuracy: 0.9748 - val_loss: 0.3542 - val_accuracy: 0.9015\n","Epoch 41/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0563 - accuracy: 0.9807 - val_loss: 0.3734 - val_accuracy: 0.9047\n","Epoch 42/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0479 - accuracy: 0.9847 - val_loss: 0.3922 - val_accuracy: 0.8833\n","Epoch 43/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0625 - accuracy: 0.9788 - val_loss: 0.5164 - val_accuracy: 0.8876\n","Epoch 44/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0825 - accuracy: 0.9676 - val_loss: 0.4007 - val_accuracy: 0.8876\n","Epoch 45/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0609 - accuracy: 0.9770 - val_loss: 0.4041 - val_accuracy: 0.9026\n","Epoch 46/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0562 - accuracy: 0.9794 - val_loss: 0.3596 - val_accuracy: 0.8972\n","Epoch 47/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0470 - accuracy: 0.9842 - val_loss: 0.3717 - val_accuracy: 0.8972\n","Epoch 48/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0545 - accuracy: 0.9845 - val_loss: 0.3804 - val_accuracy: 0.9047\n","Epoch 49/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0379 - accuracy: 0.9890 - val_loss: 0.3829 - val_accuracy: 0.9036\n","Epoch 50/100\n","30/30 [==============================] - 1s 26ms/step - loss: 0.0507 - accuracy: 0.9831 - val_loss: 0.3917 - val_accuracy: 0.8951\n","Epoch 51/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0604 - accuracy: 0.9780 - val_loss: 0.3835 - val_accuracy: 0.9004\n","Epoch 52/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0446 - accuracy: 0.9871 - val_loss: 0.3834 - val_accuracy: 0.9047\n","Epoch 53/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0488 - accuracy: 0.9810 - val_loss: 0.4339 - val_accuracy: 0.9004\n","Epoch 54/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0586 - accuracy: 0.9799 - val_loss: 0.4298 - val_accuracy: 0.8844\n","Epoch 55/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0451 - accuracy: 0.9853 - val_loss: 0.3888 - val_accuracy: 0.9079\n","Epoch 56/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0540 - accuracy: 0.9807 - val_loss: 0.4436 - val_accuracy: 0.8747\n","Epoch 57/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0664 - accuracy: 0.9770 - val_loss: 0.3739 - val_accuracy: 0.9058\n","Epoch 58/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0577 - accuracy: 0.9778 - val_loss: 0.4174 - val_accuracy: 0.8897\n","Epoch 59/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0480 - accuracy: 0.9831 - val_loss: 0.3814 - val_accuracy: 0.9026\n","Epoch 60/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0452 - accuracy: 0.9861 - val_loss: 0.4122 - val_accuracy: 0.8994\n","Epoch 61/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0457 - accuracy: 0.9839 - val_loss: 0.4335 - val_accuracy: 0.8876\n","Epoch 62/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0399 - accuracy: 0.9877 - val_loss: 0.3870 - val_accuracy: 0.8983\n","Epoch 63/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0368 - accuracy: 0.9890 - val_loss: 0.4316 - val_accuracy: 0.8822\n","Epoch 64/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0520 - accuracy: 0.9815 - val_loss: 0.4234 - val_accuracy: 0.8865\n","Epoch 65/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0415 - accuracy: 0.9874 - val_loss: 0.4340 - val_accuracy: 0.8983\n","Epoch 66/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0499 - accuracy: 0.9837 - val_loss: 0.4034 - val_accuracy: 0.9036\n","Epoch 67/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0387 - accuracy: 0.9874 - val_loss: 0.4042 - val_accuracy: 0.9047\n","Epoch 68/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0424 - accuracy: 0.9861 - val_loss: 0.4258 - val_accuracy: 0.9090\n","Epoch 69/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0349 - accuracy: 0.9901 - val_loss: 0.4183 - val_accuracy: 0.9047\n","Epoch 70/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0334 - accuracy: 0.9901 - val_loss: 0.4495 - val_accuracy: 0.9026\n","Epoch 71/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0404 - accuracy: 0.9879 - val_loss: 0.4206 - val_accuracy: 0.8961\n","Epoch 72/100\n","30/30 [==============================] - 1s 22ms/step - loss: 0.0542 - accuracy: 0.9815 - val_loss: 0.4102 - val_accuracy: 0.8961\n","Epoch 73/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0448 - accuracy: 0.9863 - val_loss: 0.5126 - val_accuracy: 0.8662\n","Epoch 74/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0514 - accuracy: 0.9826 - val_loss: 0.4805 - val_accuracy: 0.8908\n","Epoch 75/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0445 - accuracy: 0.9850 - val_loss: 0.4368 - val_accuracy: 0.8940\n","Epoch 76/100\n","30/30 [==============================] - 1s 23ms/step - loss: 0.0357 - accuracy: 0.9885 - val_loss: 0.4568 - val_accuracy: 0.8833\n","Epoch 77/100\n","30/30 [==============================] - 1s 25ms/step - loss: 0.0564 - accuracy: 0.9762 - val_loss: 0.4661 - val_accuracy: 0.8983\n","Epoch 78/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0411 - accuracy: 0.9882 - val_loss: 0.4284 - val_accuracy: 0.8929\n","Epoch 79/100\n","30/30 [==============================] - 1s 20ms/step - loss: 0.0466 - accuracy: 0.9842 - val_loss: 0.4055 - val_accuracy: 0.8961\n","Epoch 80/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0423 - accuracy: 0.9858 - val_loss: 0.4158 - val_accuracy: 0.8994\n","Epoch 81/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0384 - accuracy: 0.9866 - val_loss: 0.4246 - val_accuracy: 0.9036\n","Epoch 82/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0359 - accuracy: 0.9896 - val_loss: 0.4689 - val_accuracy: 0.8769\n","Epoch 83/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0367 - accuracy: 0.9871 - val_loss: 0.4283 - val_accuracy: 0.8994\n","Epoch 84/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0493 - accuracy: 0.9839 - val_loss: 0.4256 - val_accuracy: 0.8983\n","Epoch 85/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0373 - accuracy: 0.9885 - val_loss: 0.4314 - val_accuracy: 0.8972\n","Epoch 86/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0411 - accuracy: 0.9869 - val_loss: 0.4346 - val_accuracy: 0.8940\n","Epoch 87/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0324 - accuracy: 0.9896 - val_loss: 0.4214 - val_accuracy: 0.9015\n","Epoch 88/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0338 - accuracy: 0.9896 - val_loss: 0.4158 - val_accuracy: 0.8983\n","Epoch 89/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0299 - accuracy: 0.9920 - val_loss: 0.4236 - val_accuracy: 0.8983\n","Epoch 90/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0263 - accuracy: 0.9925 - val_loss: 0.4859 - val_accuracy: 0.8833\n","Epoch 91/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0395 - accuracy: 0.9871 - val_loss: 0.4501 - val_accuracy: 0.8951\n","Epoch 92/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0413 - accuracy: 0.9869 - val_loss: 0.4485 - val_accuracy: 0.9004\n","Epoch 93/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0290 - accuracy: 0.9920 - val_loss: 0.4373 - val_accuracy: 0.8961\n","Epoch 94/100\n","30/30 [==============================] - 1s 18ms/step - loss: 0.0262 - accuracy: 0.9925 - val_loss: 0.4549 - val_accuracy: 0.8897\n","Epoch 95/100\n","30/30 [==============================] - 1s 17ms/step - loss: 0.0526 - accuracy: 0.9799 - val_loss: 0.4844 - val_accuracy: 0.8972\n","Epoch 96/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0358 - accuracy: 0.9890 - val_loss: 0.4687 - val_accuracy: 0.9004\n","Epoch 97/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0320 - accuracy: 0.9904 - val_loss: 0.4367 - val_accuracy: 0.8972\n","Epoch 98/100\n","30/30 [==============================] - 1s 19ms/step - loss: 0.0325 - accuracy: 0.9909 - val_loss: 0.4681 - val_accuracy: 0.8865\n","Epoch 99/100\n","30/30 [==============================] - 1s 21ms/step - loss: 0.0370 - accuracy: 0.9887 - val_loss: 0.4730 - val_accuracy: 0.8854\n","Epoch 100/100\n","30/30 [==============================] - 1s 24ms/step - loss: 0.0317 - accuracy: 0.9914 - val_loss: 0.4413 - val_accuracy: 0.8983\n","{'loss': [0.1278616040945053, 0.11835721880197525, 0.09528457373380661, 0.0878688395023346, 0.08279606699943542, 0.08274763077497482, 0.0917169600725174, 0.08452503383159637, 0.0940442755818367, 0.07853545993566513, 0.08773264288902283, 0.09760651737451553, 0.08474121242761612, 0.07155518233776093, 0.06837010383605957, 0.06896378844976425, 0.06964312493801117, 0.07452572137117386, 0.07094813138246536, 0.080874964594841, 0.06043358892202377, 0.05897779390215874, 0.06501259654760361, 0.06773845851421356, 0.05459737032651901, 0.05818120762705803, 0.06377455592155457, 0.06424655020236969, 0.07031644880771637, 0.0613383911550045, 0.06479213386774063, 0.061655763536691666, 0.05662684887647629, 0.07321522384881973, 0.053898319602012634, 0.04973561316728592, 0.05441640689969063, 0.06499868631362915, 0.0615183562040329, 0.07019279897212982, 0.05629725381731987, 0.047897424548864365, 0.06248002499341965, 0.08245638757944107, 0.06094633415341377, 0.056185558438301086, 0.046963829547166824, 0.054490089416503906, 0.03794068098068237, 0.05068859085440636, 0.06044043228030205, 0.04464186728000641, 0.04879862442612648, 0.05859459936618805, 0.04508812725543976, 0.05400720238685608, 0.06642402708530426, 0.05772184953093529, 0.047952331602573395, 0.045227717608213425, 0.04574665054678917, 0.03991440311074257, 0.036816224455833435, 0.05202564597129822, 0.04152702912688255, 0.049868032336235046, 0.03870423138141632, 0.042443253099918365, 0.03488532826304436, 0.033397480845451355, 0.04036328196525574, 0.05418653041124344, 0.044790931046009064, 0.05138365551829338, 0.044528283178806305, 0.035745274275541306, 0.05641857907176018, 0.0411016047000885, 0.04661998152732849, 0.04233812540769577, 0.0384378507733345, 0.03588743880391121, 0.0366659015417099, 0.04932248592376709, 0.037331126630306244, 0.04105573147535324, 0.03238343819975853, 0.033829204738140106, 0.02986227534711361, 0.02629583515226841, 0.039534345269203186, 0.04125385358929634, 0.029008110985159874, 0.026210878044366837, 0.052570562809705734, 0.03579508513212204, 0.03203665092587471, 0.03250685706734657, 0.036961521953344345, 0.031666599214076996], 'accuracy': [0.9555317163467407, 0.9541923403739929, 0.9643718004226685, 0.9732118844985962, 0.9713367223739624, 0.9705330729484558, 0.9641039371490479, 0.9670506119728088, 0.965175449848175, 0.9748191833496094, 0.9670506119728088, 0.9624966382980347, 0.968657910823822, 0.9764264822006226, 0.9777658581733704, 0.97508704662323, 0.9758906960487366, 0.9710688591003418, 0.9764264822006226, 0.9702652096748352, 0.9807125926017761, 0.9820519685745239, 0.9758906960487366, 0.9764264822006226, 0.9839271306991577, 0.9809804558753967, 0.9769622087478638, 0.9780337810516357, 0.972676157951355, 0.9780337810516357, 0.975622832775116, 0.9777658581733704, 0.9807125926017761, 0.975622832775116, 0.9831234812736511, 0.9858022928237915, 0.9812483191490173, 0.9761585593223572, 0.9774979948997498, 0.9748191833496094, 0.9807125926017761, 0.9847307801246643, 0.9788373708724976, 0.9675863981246948, 0.9769622087478638, 0.9793731570243835, 0.9841949939727783, 0.9844629168510437, 0.9890168905258179, 0.9831234812736511, 0.9780337810516357, 0.9871417284011841, 0.9809804558753967, 0.9799089431762695, 0.9852665662765503, 0.9807125926017761, 0.9769622087478638, 0.9777658581733704, 0.9831234812736511, 0.9860701560974121, 0.9839271306991577, 0.9876774549484253, 0.9890168905258179, 0.9815161824226379, 0.9874095916748047, 0.9836592674255371, 0.9874095916748047, 0.9860701560974121, 0.9900884032249451, 0.9900884032249451, 0.9879453778266907, 0.9815161824226379, 0.9863380789756775, 0.9825877547264099, 0.9849986433982849, 0.9884811043739319, 0.9761585593223572, 0.9882132411003113, 0.9841949939727783, 0.9858022928237915, 0.9866059422492981, 0.9895526170730591, 0.9871417284011841, 0.9839271306991577, 0.9884811043739319, 0.9868738055229187, 0.9895526170730591, 0.9895526170730591, 0.9919635653495789, 0.9924993515014648, 0.9871417284011841, 0.9868738055229187, 0.9919635653495789, 0.9924993515014648, 0.9799089431762695, 0.9890168905258179, 0.9903562664985657, 0.9908920526504517, 0.9887489676475525, 0.9914277791976929], 'val_loss': [0.6451898217201233, 0.6354667544364929, 0.6252177953720093, 0.6175503730773926, 0.6024579405784607, 0.5843052268028259, 0.5725561380386353, 0.5771172642707825, 0.5516183972358704, 0.5285637378692627, 0.5458185076713562, 0.5103728175163269, 0.46054112911224365, 0.45880335569381714, 0.5103933215141296, 0.47672533988952637, 0.5473648309707642, 0.6576918363571167, 0.4771620035171509, 0.6361852288246155, 0.5916688442230225, 0.5875108242034912, 0.45594489574432373, 0.4379274547100067, 0.37949860095977783, 0.44323134422302246, 0.3439498245716095, 0.3382459878921509, 0.3772519826889038, 0.3981087803840637, 0.40330299735069275, 0.34006166458129883, 0.42979690432548523, 0.3549008071422577, 0.3547488749027252, 0.36346274614334106, 0.3911840617656708, 0.3780549168586731, 0.4234607517719269, 0.3542022109031677, 0.3734241724014282, 0.3921973407268524, 0.516403079032898, 0.4006768763065338, 0.4040762484073639, 0.3596077561378479, 0.37171471118927, 0.3803773820400238, 0.3828624486923218, 0.3917407989501953, 0.38345593214035034, 0.3834146559238434, 0.43391624093055725, 0.4297892451286316, 0.3887888789176941, 0.44360190629959106, 0.37391549348831177, 0.4174197018146515, 0.381398469209671, 0.41217389702796936, 0.4335331618785858, 0.3870468735694885, 0.4315889775753021, 0.42344415187835693, 0.4340216815471649, 0.40338027477264404, 0.40416219830513, 0.4257611930370331, 0.41828933358192444, 0.4495128393173218, 0.4206312298774719, 0.4102191925048828, 0.512636125087738, 0.48052552342414856, 0.4367542862892151, 0.4567791223526001, 0.4660804867744446, 0.42843738198280334, 0.4055326282978058, 0.4158083498477936, 0.4245983064174652, 0.46891120076179504, 0.4283488094806671, 0.4255848228931427, 0.431386262178421, 0.43458545207977295, 0.4214363694190979, 0.4158072769641876, 0.4236471354961395, 0.48593538999557495, 0.4501372277736664, 0.448537677526474, 0.437288373708725, 0.45493990182876587, 0.4843935966491699, 0.46874767541885376, 0.4367336928844452, 0.4681277871131897, 0.4730404317378998, 0.4412999749183655], 'val_accuracy': [0.6937901377677917, 0.7815845608711243, 0.7526766657829285, 0.7194860577583313, 0.7237687110900879, 0.7612419724464417, 0.7355460524559021, 0.6873661875724792, 0.7259100675582886, 0.7323340177536011, 0.6927194595336914, 0.7301927208900452, 0.7847965955734253, 0.7847965955734253, 0.7558886408805847, 0.7751606106758118, 0.7655246257781982, 0.7494646906852722, 0.824411153793335, 0.783725917339325, 0.8115631937980652, 0.8254817724227905, 0.8683083653450012, 0.8768736720085144, 0.8897216320037842, 0.8822270035743713, 0.902569591999054, 0.902569591999054, 0.9057815670967102, 0.900428295135498, 0.8982869386672974, 0.9057815670967102, 0.8747323155403137, 0.8929336071014404, 0.9036402702331543, 0.9047109484672546, 0.8886509537696838, 0.8993576169013977, 0.8790149688720703, 0.9014989137649536, 0.9047109484672546, 0.8832976222038269, 0.8875802755355835, 0.8875802755355835, 0.902569591999054, 0.897216260433197, 0.897216260433197, 0.9047109484672546, 0.9036402702331543, 0.8950749635696411, 0.900428295135498, 0.9047109484672546, 0.900428295135498, 0.8843683004379272, 0.9079229235649109, 0.8747323155403137, 0.9057815670967102, 0.8897216320037842, 0.902569591999054, 0.8993576169013977, 0.8875802755355835, 0.8982869386672974, 0.8822270035743713, 0.8865096569061279, 0.8982869386672974, 0.9036402702331543, 0.9047109484672546, 0.9089936017990112, 0.9047109484672546, 0.902569591999054, 0.8961455821990967, 0.8961455821990967, 0.8661670088768005, 0.8907923102378845, 0.8940042853355408, 0.8832976222038269, 0.8982869386672974, 0.8929336071014404, 0.8961455821990967, 0.8993576169013977, 0.9036402702331543, 0.8768736720085144, 0.8993576169013977, 0.8982869386672974, 0.897216260433197, 0.8940042853355408, 0.9014989137649536, 0.8982869386672974, 0.8982869386672974, 0.8832976222038269, 0.8950749635696411, 0.900428295135498, 0.8961455821990967, 0.8897216320037842, 0.897216260433197, 0.900428295135498, 0.897216260433197, 0.8865096569061279, 0.8854389786720276, 0.8982869386672974]}\n","37/37 [==============================] - 1s 6ms/step\n"]}]},{"cell_type":"code","source":["metrics_df.round(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":459},"id":"y3RXIk-qZ7ts","executionInfo":{"status":"ok","timestamp":1716485046596,"user_tz":-360,"elapsed":457,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"b6dfc108-4573-42bb-b045-9b9c203d8c28"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.839      0.841   0.838  0.840        0.838        0.840   \n","1        1     0.810      0.831   0.783  0.806        0.783        0.837   \n","2        2     0.799      0.768   0.856  0.810        0.856        0.741   \n","3        0     0.871      0.877   0.864  0.870        0.864        0.878   \n","4        1     0.841      0.863   0.813  0.837        0.813        0.869   \n","5        2     0.853      0.936   0.757  0.837        0.757        0.949   \n","6        0     0.873      0.844   0.918  0.879        0.918        0.828   \n","7        1     0.861      0.893   0.823  0.857        0.823        0.900   \n","8        2     0.872      0.868   0.878  0.873        0.878        0.866   \n","9        0     0.901      0.889   0.917  0.903        0.917        0.884   \n","10       1     0.874      0.861   0.895  0.878        0.895        0.853   \n","11       2     0.871      0.827   0.938  0.879        0.938        0.803   \n","12       0     0.925      0.929   0.920  0.925        0.920        0.929   \n","13       1     0.883      0.967   0.796  0.873        0.796        0.972   \n","14       2     0.919      0.939   0.897  0.918        0.897        0.942   \n","\n","    Kappa  \n","0   0.678  \n","1   0.620  \n","2   0.597  \n","3   0.741  \n","4   0.681  \n","5   0.705  \n","6   0.746  \n","7   0.723  \n","8   0.745  \n","9   0.801  \n","10  0.748  \n","11  0.741  \n","12  0.849  \n","13  0.767  \n","14  0.839  "],"text/html":["\n","  <div id=\"df-97ee2673-8cc5-4524-816d-1c7e750b2f3f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.839</td>\n","      <td>0.841</td>\n","      <td>0.838</td>\n","      <td>0.840</td>\n","      <td>0.838</td>\n","      <td>0.840</td>\n","      <td>0.678</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.810</td>\n","      <td>0.831</td>\n","      <td>0.783</td>\n","      <td>0.806</td>\n","      <td>0.783</td>\n","      <td>0.837</td>\n","      <td>0.620</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.799</td>\n","      <td>0.768</td>\n","      <td>0.856</td>\n","      <td>0.810</td>\n","      <td>0.856</td>\n","      <td>0.741</td>\n","      <td>0.597</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.871</td>\n","      <td>0.877</td>\n","      <td>0.864</td>\n","      <td>0.870</td>\n","      <td>0.864</td>\n","      <td>0.878</td>\n","      <td>0.741</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.841</td>\n","      <td>0.863</td>\n","      <td>0.813</td>\n","      <td>0.837</td>\n","      <td>0.813</td>\n","      <td>0.869</td>\n","      <td>0.681</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.853</td>\n","      <td>0.936</td>\n","      <td>0.757</td>\n","      <td>0.837</td>\n","      <td>0.757</td>\n","      <td>0.949</td>\n","      <td>0.705</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.873</td>\n","      <td>0.844</td>\n","      <td>0.918</td>\n","      <td>0.879</td>\n","      <td>0.918</td>\n","      <td>0.828</td>\n","      <td>0.746</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.861</td>\n","      <td>0.893</td>\n","      <td>0.823</td>\n","      <td>0.857</td>\n","      <td>0.823</td>\n","      <td>0.900</td>\n","      <td>0.723</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.872</td>\n","      <td>0.868</td>\n","      <td>0.878</td>\n","      <td>0.873</td>\n","      <td>0.878</td>\n","      <td>0.866</td>\n","      <td>0.745</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.901</td>\n","      <td>0.889</td>\n","      <td>0.917</td>\n","      <td>0.903</td>\n","      <td>0.917</td>\n","      <td>0.884</td>\n","      <td>0.801</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.874</td>\n","      <td>0.861</td>\n","      <td>0.895</td>\n","      <td>0.878</td>\n","      <td>0.895</td>\n","      <td>0.853</td>\n","      <td>0.748</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.871</td>\n","      <td>0.827</td>\n","      <td>0.938</td>\n","      <td>0.879</td>\n","      <td>0.938</td>\n","      <td>0.803</td>\n","      <td>0.741</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.925</td>\n","      <td>0.929</td>\n","      <td>0.920</td>\n","      <td>0.925</td>\n","      <td>0.920</td>\n","      <td>0.929</td>\n","      <td>0.849</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.883</td>\n","      <td>0.967</td>\n","      <td>0.796</td>\n","      <td>0.873</td>\n","      <td>0.796</td>\n","      <td>0.972</td>\n","      <td>0.767</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.919</td>\n","      <td>0.939</td>\n","      <td>0.897</td>\n","      <td>0.918</td>\n","      <td>0.897</td>\n","      <td>0.942</td>\n","      <td>0.839</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97ee2673-8cc5-4524-816d-1c7e750b2f3f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-97ee2673-8cc5-4524-816d-1c7e750b2f3f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-97ee2673-8cc5-4524-816d-1c7e750b2f3f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-2a16c3d9-ba3a-4ceb-8e86-1197b24bb2a0\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2a16c3d9-ba3a-4ceb-8e86-1197b24bb2a0')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-2a16c3d9-ba3a-4ceb-8e86-1197b24bb2a0 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03502624866065585,\n        \"min\": 0.799,\n        \"max\": 0.925,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.901,\n          0.925,\n          0.839\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05203826430984178,\n        \"min\": 0.768,\n        \"max\": 0.967,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.889,\n          0.827,\n          0.841\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.056022784480534174,\n        \"min\": 0.757,\n        \"max\": 0.938,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.917,\n          0.938,\n          0.838\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03517642608880204,\n        \"min\": 0.806,\n        \"max\": 0.925,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.925,\n          0.878,\n          0.84\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.056022784480534174,\n        \"min\": 0.757,\n        \"max\": 0.938,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.917,\n          0.938,\n          0.838\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06067885801103881,\n        \"min\": 0.741,\n        \"max\": 0.972,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.884,\n          0.803,\n          0.84\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07020527724025417,\n        \"min\": 0.597,\n        \"max\": 0.849,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.801,\n          0.849,\n          0.678\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":[],"metadata":{"id":"AwRC33o2cDdM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Time-frequency Domain"],"metadata":{"id":"3K49pzDIgfaU"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split,KFold,StratifiedKFold\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM,Dropout, GRU\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from keras.optimizers import RMSprop, Adam\n","# from wandb.keras import WandbCallback\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', k_folds=5, stratified=False):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.k_folds = k_folds\n","        self.stratified = stratified\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle= True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        X = scaled_data_reshaped.reshape(self.X.shape)\n","        np.moveaxis(X, 1, 2)\n","        self.X = X\n","\n","    def create_partitions(self):\n","        if self.stratified:\n","            kf = StratifiedKFold(n_splits=self.k_folds, shuffle=True, random_state=42)\n","        else:\n","            kf = KFold(n_splits=self.k_folds, shuffle=True, random_state=42)\n","\n","        for train_index, test_index in kf.split(self.X, self.Y):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(LSTM(256, return_sequences=True))\n","    model.add(LSTM(256, return_sequences=True))\n","        # GRU layers\n","    # model.add(GRU(256, return_sequences=True))\n","    # model.add(GRU(128, return_sequences=False))\n","\n","    model.add(Flatten())\n","    # model.add(Dense(1024, activation='relu'))\n","    # model.add(Dense(512, activation='relu'))\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dense(32, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Evaluate client model\n","            y_pred = (client_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"uG4uMguAg-gr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["global_model, metrics_df = federated_learning(Time_data)"],"metadata":{"id":"0BXlcEhBnobF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["metrics_df.round(3)"],"metadata":{"id":"CRFZagKtnfrN"},"execution_count":null,"outputs":[]}]}