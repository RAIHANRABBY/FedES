{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Mbfw8uvdftFM","executionInfo":{"status":"ok","timestamp":1717496689947,"user_tz":-360,"elapsed":8,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sb"]},{"cell_type":"code","source":["from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"INiFJfLjgOkx","executionInfo":{"status":"ok","timestamp":1717496691209,"user_tz":-360,"elapsed":1268,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import ExtraTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score, cross_val_predict"],"metadata":{"id":"lYo2Uq77gQSH","executionInfo":{"status":"ok","timestamp":1717496693886,"user_tz":-360,"elapsed":2682,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPool1D, Flatten, Dropout,LSTM"],"metadata":{"id":"g66575_xgVzz","executionInfo":{"status":"ok","timestamp":1717496697442,"user_tz":-360,"elapsed":3562,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MOCNWlamfr3v","executionInfo":{"status":"ok","timestamp":1717496725284,"user_tz":-360,"elapsed":27848,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"2ee0744c-579b-435f-be17-88a40dcc6983"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Raw_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/only data/raw_data.npz'\n","\n","Theta_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/time domain /RAW/Alpha_time.npz'\n","\n","\n","\n","# RAW = np.load(Raw_data, allow_pickle=True)  # Allow loading pickled object arrays\n","# X = RAW['X'].astype('float64')\n","# Y = RAW['Y'].astype('float64')\n","# group = RAW['Group'].astype('float64')"],"metadata":{"id":"iNy9eOGMf2qO","executionInfo":{"status":"ok","timestamp":1717496725284,"user_tz":-360,"elapsed":8,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# CNN-LSTM"],"metadata":{"id":"6DhAYwXUSE9z"}},{"cell_type":"code","source":["%%capture\n","!pip install tensorflow_addons"],"metadata":{"id":"MjbPbUkSy2tp","executionInfo":{"status":"ok","timestamp":1717496945565,"user_tz":-360,"elapsed":9620,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(LSTM(256, return_sequences=True))\n","    model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Alpha/CNN_LSTM/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Alpha/CNN_LSTM/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"VvjC2xCQNHLP","executionInfo":{"status":"ok","timestamp":1717496945565,"user_tz":-360,"elapsed":8,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e4a7fc6b-1644-45f2-9996-c7002f4996d5"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["global_model, metrics_df = federated_learning(Theta_data)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVURUnmYNNNg","outputId":"1c891218-dabe-4f8f-faf5-e3f512fa514a","executionInfo":{"status":"ok","timestamp":1717498187797,"user_tz":-360,"elapsed":1242237,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 1.4077 - accuracy: 0.5051"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 25s 167ms/step - loss: 1.4047 - accuracy: 0.5035 - val_loss: 1.3741 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.3469 - accuracy: 0.5054 - val_loss: 1.3188 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 31ms/step - loss: 1.2937 - accuracy: 0.5038 - val_loss: 1.2676 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 34ms/step - loss: 1.2445 - accuracy: 0.5078 - val_loss: 1.2204 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 48ms/step - loss: 1.1991 - accuracy: 0.5005 - val_loss: 1.1769 - val_accuracy: 0.5151\n","Epoch 6/100\n","29/29 [==============================] - 1s 36ms/step - loss: 1.1570 - accuracy: 0.5035 - val_loss: 1.1368 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 36ms/step - loss: 1.1179 - accuracy: 0.5256 - val_loss: 1.0997 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.0818 - accuracy: 0.5242 - val_loss: 1.0654 - val_accuracy: 0.5097\n","Epoch 9/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.0475 - accuracy: 0.5388 - val_loss: 1.0341 - val_accuracy: 0.5162\n","Epoch 10/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.0166 - accuracy: 0.5388 - val_loss: 1.0053 - val_accuracy: 0.5162\n","Epoch 11/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.9848 - accuracy: 0.5536 - val_loss: 0.9793 - val_accuracy: 0.5162\n","Epoch 12/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.9553 - accuracy: 0.5741 - val_loss: 0.9509 - val_accuracy: 0.5819\n","Epoch 13/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.9302 - accuracy: 0.5768 - val_loss: 0.9282 - val_accuracy: 0.5679\n","Epoch 14/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.9168 - accuracy: 0.5515 - val_loss: 0.9096 - val_accuracy: 0.5679\n","Epoch 15/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8890 - accuracy: 0.5814 - val_loss: 0.8935 - val_accuracy: 0.5312\n","Epoch 16/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.8732 - accuracy: 0.5698 - val_loss: 0.8778 - val_accuracy: 0.5226\n","Epoch 17/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.8517 - accuracy: 0.5911 - val_loss: 0.8513 - val_accuracy: 0.5862\n","Epoch 18/100\n","29/29 [==============================] - 1s 35ms/step - loss: 0.8282 - accuracy: 0.5956 - val_loss: 0.8326 - val_accuracy: 0.5884\n","Epoch 19/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8061 - accuracy: 0.6134 - val_loss: 0.8145 - val_accuracy: 0.5851\n","Epoch 20/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.8058 - accuracy: 0.5827 - val_loss: 0.8118 - val_accuracy: 0.5603\n","Epoch 21/100\n","29/29 [==============================] - 1s 51ms/step - loss: 0.7799 - accuracy: 0.6258 - val_loss: 0.7856 - val_accuracy: 0.6110\n","Epoch 22/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.7657 - accuracy: 0.6261 - val_loss: 0.7754 - val_accuracy: 0.6002\n","Epoch 23/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.7594 - accuracy: 0.6212 - val_loss: 0.7756 - val_accuracy: 0.5862\n","Epoch 24/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.7415 - accuracy: 0.6288 - val_loss: 0.7654 - val_accuracy: 0.6024\n","Epoch 25/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.7253 - accuracy: 0.6474 - val_loss: 0.7684 - val_accuracy: 0.5841\n","Epoch 26/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.7131 - accuracy: 0.6498 - val_loss: 0.7487 - val_accuracy: 0.5873\n","Epoch 27/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.7088 - accuracy: 0.6452 - val_loss: 0.7450 - val_accuracy: 0.5927\n","Epoch 28/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.6951 - accuracy: 0.6538 - val_loss: 0.7277 - val_accuracy: 0.6088\n","Epoch 29/100\n","29/29 [==============================] - 1s 38ms/step - loss: 0.6791 - accuracy: 0.6668 - val_loss: 0.7237 - val_accuracy: 0.6121\n","Epoch 30/100\n","29/29 [==============================] - 1s 38ms/step - loss: 0.6684 - accuracy: 0.6670 - val_loss: 0.7165 - val_accuracy: 0.6153\n","Epoch 31/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6566 - accuracy: 0.6716 - val_loss: 0.7492 - val_accuracy: 0.5916\n","Epoch 32/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.6541 - accuracy: 0.6783 - val_loss: 0.7048 - val_accuracy: 0.6185\n","Epoch 33/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6369 - accuracy: 0.6940 - val_loss: 0.7178 - val_accuracy: 0.5916\n","Epoch 34/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6221 - accuracy: 0.7015 - val_loss: 0.7377 - val_accuracy: 0.5959\n","Epoch 35/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6271 - accuracy: 0.6929 - val_loss: 0.7140 - val_accuracy: 0.5938\n","Epoch 36/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5952 - accuracy: 0.7136 - val_loss: 0.7215 - val_accuracy: 0.5916\n","Epoch 37/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.5737 - accuracy: 0.7290 - val_loss: 0.6957 - val_accuracy: 0.6196\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5589 - accuracy: 0.7390 - val_loss: 0.8053 - val_accuracy: 0.5571\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5838 - accuracy: 0.7150 - val_loss: 0.7181 - val_accuracy: 0.6024\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5370 - accuracy: 0.7557 - val_loss: 0.7388 - val_accuracy: 0.6153\n","Epoch 41/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5216 - accuracy: 0.7610 - val_loss: 0.7276 - val_accuracy: 0.6293\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5011 - accuracy: 0.7751 - val_loss: 0.7651 - val_accuracy: 0.6239\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4662 - accuracy: 0.8012 - val_loss: 0.7623 - val_accuracy: 0.6239\n","Epoch 44/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4763 - accuracy: 0.7815 - val_loss: 0.7949 - val_accuracy: 0.6121\n","Epoch 45/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4199 - accuracy: 0.8322 - val_loss: 0.8855 - val_accuracy: 0.5830\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4012 - accuracy: 0.8332 - val_loss: 0.8744 - val_accuracy: 0.6110\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3967 - accuracy: 0.8351 - val_loss: 0.9076 - val_accuracy: 0.6088\n","Epoch 48/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3929 - accuracy: 0.8354 - val_loss: 0.8559 - val_accuracy: 0.5916\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3574 - accuracy: 0.8526 - val_loss: 0.9741 - val_accuracy: 0.6045\n","Epoch 50/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3021 - accuracy: 0.8798 - val_loss: 1.0602 - val_accuracy: 0.6121\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3126 - accuracy: 0.8782 - val_loss: 1.1069 - val_accuracy: 0.6024\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2770 - accuracy: 0.8906 - val_loss: 1.2338 - val_accuracy: 0.5991\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2821 - accuracy: 0.8925 - val_loss: 1.2104 - val_accuracy: 0.6034\n","Epoch 54/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2568 - accuracy: 0.9014 - val_loss: 1.1788 - val_accuracy: 0.6078\n","Epoch 55/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2529 - accuracy: 0.8998 - val_loss: 1.1835 - val_accuracy: 0.5970\n","Epoch 56/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2297 - accuracy: 0.9178 - val_loss: 1.3525 - val_accuracy: 0.6067\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1903 - accuracy: 0.9289 - val_loss: 1.4317 - val_accuracy: 0.6067\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1673 - accuracy: 0.9375 - val_loss: 1.4282 - val_accuracy: 0.6088\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2120 - accuracy: 0.9246 - val_loss: 1.2356 - val_accuracy: 0.5991\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1802 - accuracy: 0.9353 - val_loss: 1.5445 - val_accuracy: 0.6024\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1456 - accuracy: 0.9523 - val_loss: 1.6796 - val_accuracy: 0.6088\n","Epoch 62/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1321 - accuracy: 0.9609 - val_loss: 1.8620 - val_accuracy: 0.5948\n","Epoch 63/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1341 - accuracy: 0.9585 - val_loss: 1.9900 - val_accuracy: 0.5873\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1317 - accuracy: 0.9558 - val_loss: 1.7788 - val_accuracy: 0.6088\n","Epoch 65/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1413 - accuracy: 0.9526 - val_loss: 1.7710 - val_accuracy: 0.6067\n","Epoch 66/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1533 - accuracy: 0.9510 - val_loss: 1.7392 - val_accuracy: 0.6045\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1164 - accuracy: 0.9655 - val_loss: 1.9618 - val_accuracy: 0.6067\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0880 - accuracy: 0.9763 - val_loss: 1.9318 - val_accuracy: 0.6078\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1148 - accuracy: 0.9658 - val_loss: 1.8427 - val_accuracy: 0.6207\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1034 - accuracy: 0.9688 - val_loss: 1.9348 - val_accuracy: 0.5916\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0788 - accuracy: 0.9806 - val_loss: 2.1270 - val_accuracy: 0.6121\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0668 - accuracy: 0.9860 - val_loss: 2.3735 - val_accuracy: 0.5970\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0951 - accuracy: 0.9712 - val_loss: 2.2432 - val_accuracy: 0.5948\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1011 - accuracy: 0.9709 - val_loss: 1.9606 - val_accuracy: 0.5959\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1009 - accuracy: 0.9696 - val_loss: 1.9430 - val_accuracy: 0.5927\n","Epoch 76/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0907 - accuracy: 0.9728 - val_loss: 2.2612 - val_accuracy: 0.6185\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0879 - accuracy: 0.9758 - val_loss: 2.1360 - val_accuracy: 0.5981\n","Epoch 78/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0909 - accuracy: 0.9725 - val_loss: 2.0415 - val_accuracy: 0.6078\n","Epoch 79/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1257 - accuracy: 0.9588 - val_loss: 1.8215 - val_accuracy: 0.6164\n","Epoch 80/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0932 - accuracy: 0.9739 - val_loss: 1.9468 - val_accuracy: 0.6261\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0656 - accuracy: 0.9855 - val_loss: 2.1581 - val_accuracy: 0.6131\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0562 - accuracy: 0.9892 - val_loss: 2.2154 - val_accuracy: 0.6153\n","Epoch 83/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0494 - accuracy: 0.9919 - val_loss: 2.4067 - val_accuracy: 0.6045\n","Epoch 84/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0529 - accuracy: 0.9873 - val_loss: 2.4095 - val_accuracy: 0.5991\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0561 - accuracy: 0.9879 - val_loss: 2.4449 - val_accuracy: 0.5991\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0758 - accuracy: 0.9830 - val_loss: 2.3949 - val_accuracy: 0.6153\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0916 - accuracy: 0.9709 - val_loss: 2.1719 - val_accuracy: 0.6013\n","Epoch 88/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0813 - accuracy: 0.9793 - val_loss: 2.0491 - val_accuracy: 0.6142\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0726 - accuracy: 0.9793 - val_loss: 2.1971 - val_accuracy: 0.6131\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0576 - accuracy: 0.9876 - val_loss: 2.1232 - val_accuracy: 0.6131\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0491 - accuracy: 0.9903 - val_loss: 2.3719 - val_accuracy: 0.6207\n","Epoch 92/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0533 - accuracy: 0.9895 - val_loss: 2.3753 - val_accuracy: 0.6045\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0775 - accuracy: 0.9790 - val_loss: 2.0763 - val_accuracy: 0.6164\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0617 - accuracy: 0.9868 - val_loss: 2.2864 - val_accuracy: 0.6078\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0582 - accuracy: 0.9849 - val_loss: 2.2461 - val_accuracy: 0.6131\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1204 - accuracy: 0.9569 - val_loss: 1.8890 - val_accuracy: 0.5948\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0821 - accuracy: 0.9782 - val_loss: 2.0815 - val_accuracy: 0.6175\n","Epoch 98/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0444 - accuracy: 0.9916 - val_loss: 2.3845 - val_accuracy: 0.6078\n","Epoch 99/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0385 - accuracy: 0.9938 - val_loss: 2.2827 - val_accuracy: 0.6056\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0360 - accuracy: 0.9938 - val_loss: 2.3636 - val_accuracy: 0.6207\n","{'loss': [1.4047081470489502, 1.3468797206878662, 1.293684482574463, 1.244463324546814, 1.1990500688552856, 1.1570289134979248, 1.1179096698760986, 1.0818368196487427, 1.0475244522094727, 1.016627550125122, 0.9847798347473145, 0.9553331732749939, 0.9302039742469788, 0.9168318510055542, 0.8889666795730591, 0.8732497692108154, 0.8517086505889893, 0.8281733989715576, 0.8060621023178101, 0.8057894110679626, 0.779945969581604, 0.7657083868980408, 0.7593638896942139, 0.7415098547935486, 0.7253010869026184, 0.713103711605072, 0.7087769508361816, 0.6951124668121338, 0.679145872592926, 0.6683979630470276, 0.6566360592842102, 0.6540709137916565, 0.6368884444236755, 0.6220571994781494, 0.6270612478256226, 0.5951833128929138, 0.5736509561538696, 0.5588654279708862, 0.5838396549224854, 0.5369916558265686, 0.5215901136398315, 0.5011445879936218, 0.4662151038646698, 0.47627493739128113, 0.41990211606025696, 0.40121990442276, 0.39669981598854065, 0.39292269945144653, 0.35738885402679443, 0.3020801246166229, 0.31264492869377136, 0.27698439359664917, 0.2821398377418518, 0.2567693293094635, 0.252880722284317, 0.2296900451183319, 0.19025562703609467, 0.16733507812023163, 0.21203118562698364, 0.18024487793445587, 0.14561571180820465, 0.1321258246898651, 0.13411584496498108, 0.13169504702091217, 0.14132820069789886, 0.15325622260570526, 0.1164257600903511, 0.08804048597812653, 0.1147652193903923, 0.10342122614383698, 0.0787707045674324, 0.0668259710073471, 0.09512808173894882, 0.10108916461467743, 0.1009337455034256, 0.09074221551418304, 0.08786757290363312, 0.09094208478927612, 0.12569592893123627, 0.09322371333837509, 0.06559475511312485, 0.05619203299283981, 0.04940761253237724, 0.052899010479450226, 0.05614006519317627, 0.07582458853721619, 0.09159429371356964, 0.08127681910991669, 0.07256168127059937, 0.057575661689043045, 0.049134522676467896, 0.053338631987571716, 0.07752011716365814, 0.06165606528520584, 0.05819153040647507, 0.12044599652290344, 0.08205849677324295, 0.044433094561100006, 0.03851904720067978, 0.03596965968608856], 'accuracy': [0.5035021305084229, 0.5053879022598267, 0.5037715435028076, 0.5078125, 0.5005387663841248, 0.5035021305084229, 0.5255926847457886, 0.5242456793785095, 0.5387930870056152, 0.5387930870056152, 0.5536099076271057, 0.5740840435028076, 0.576777994632721, 0.5514547228813171, 0.5813577771186829, 0.5697737336158752, 0.5910560488700867, 0.5956357717514038, 0.6134159564971924, 0.5827047228813171, 0.6258081793785095, 0.6260775923728943, 0.6212284564971924, 0.6287715435028076, 0.6473599076271057, 0.649784505367279, 0.6452047228813171, 0.6538254022598267, 0.6667564511299133, 0.6670258641242981, 0.6716055870056152, 0.678340494632721, 0.693965494632721, 0.701508641242981, 0.6928879022598267, 0.7136314511299133, 0.7289870977401733, 0.7389547228813171, 0.7149784564971924, 0.7556573152542114, 0.7610452771186829, 0.775053858757019, 0.8011853694915771, 0.7815194129943848, 0.8321659564971924, 0.8332435488700867, 0.8351293206214905, 0.8353987336158752, 0.8526400923728943, 0.8798491358757019, 0.8782327771186829, 0.890625, 0.8925107717514038, 0.9014008641242981, 0.899784505367279, 0.9178340435028076, 0.9288793206214905, 0.9375, 0.9245689511299133, 0.9353448152542114, 0.9523168206214905, 0.9609375, 0.9585129022598267, 0.9558189511299133, 0.9525862336158752, 0.9509698152542114, 0.9655172228813171, 0.9762930870056152, 0.9657866358757019, 0.96875, 0.9806034564971924, 0.985991358757019, 0.9711745977401733, 0.9709051847457886, 0.9695581793785095, 0.9727909564971924, 0.9757543206214905, 0.9725215435028076, 0.9587823152542114, 0.9738685488700867, 0.9854525923728943, 0.9892241358757019, 0.9919180870056152, 0.9873383641242981, 0.9878771305084229, 0.983027994632721, 0.9709051847457886, 0.9792564511299133, 0.9792564511299133, 0.9876077771186829, 0.9903017282485962, 0.9894935488700867, 0.9789870977401733, 0.9867995977401733, 0.9849137663841248, 0.9568965435028076, 0.978178858757019, 0.9916487336158752, 0.993803858757019, 0.993803858757019], 'val_loss': [1.374147653579712, 1.3187506198883057, 1.2676212787628174, 1.2204383611679077, 1.1768958568572998, 1.136755347251892, 1.0997275114059448, 1.0653780698776245, 1.034118413925171, 1.0052891969680786, 0.9792669415473938, 0.9508965015411377, 0.9282304644584656, 0.9096449613571167, 0.8935233354568481, 0.8778300881385803, 0.851349413394928, 0.8326115012168884, 0.8144720196723938, 0.8117555975914001, 0.7855576872825623, 0.7754343152046204, 0.7755953073501587, 0.7653712630271912, 0.7684358954429626, 0.7486525177955627, 0.7449500560760498, 0.7277435660362244, 0.7237281203269958, 0.7164520025253296, 0.7492179870605469, 0.7047556638717651, 0.7177693843841553, 0.7376990914344788, 0.7139778137207031, 0.7215370535850525, 0.6957430839538574, 0.8053485155105591, 0.7181009650230408, 0.738822340965271, 0.7276169061660767, 0.765100359916687, 0.7623419761657715, 0.7949052453041077, 0.8854573369026184, 0.8744407296180725, 0.9075526595115662, 0.8558693528175354, 0.9740604162216187, 1.060154914855957, 1.1069269180297852, 1.2337536811828613, 1.2103996276855469, 1.1788192987442017, 1.183497667312622, 1.3525007963180542, 1.4316664934158325, 1.4281654357910156, 1.2355552911758423, 1.5444591045379639, 1.6795514822006226, 1.8619803190231323, 1.990039348602295, 1.7788258790969849, 1.7709555625915527, 1.739152431488037, 1.9617869853973389, 1.9318467378616333, 1.8427395820617676, 1.9347732067108154, 2.1270413398742676, 2.373544931411743, 2.243218421936035, 1.9605712890625, 1.9430077075958252, 2.261216878890991, 2.1359848976135254, 2.0415282249450684, 1.8214774131774902, 1.94678795337677, 2.158052682876587, 2.215394973754883, 2.406705379486084, 2.4094653129577637, 2.4449172019958496, 2.394911050796509, 2.1719210147857666, 2.049083709716797, 2.1970865726470947, 2.123227119445801, 2.3718719482421875, 2.3752572536468506, 2.076333522796631, 2.2863805294036865, 2.246093511581421, 1.8889521360397339, 2.0814905166625977, 2.384478807449341, 2.282668113708496, 2.3636348247528076], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.5150862336158752, 0.48491379618644714, 0.48491379618644714, 0.5096982717514038, 0.5161637663841248, 0.5161637663841248, 0.5161637663841248, 0.5818965435028076, 0.5678879022598267, 0.5678879022598267, 0.53125, 0.5226293206214905, 0.5862069129943848, 0.5883620977401733, 0.5851293206214905, 0.5603448152542114, 0.610991358757019, 0.600215494632721, 0.5862069129943848, 0.6023706793785095, 0.5840517282485962, 0.587284505367279, 0.5926724076271057, 0.6088362336158752, 0.6120689511299133, 0.6153017282485962, 0.5915948152542114, 0.618534505367279, 0.5915948152542114, 0.5959051847457886, 0.59375, 0.5915948152542114, 0.6196120977401733, 0.5571120977401733, 0.6023706793785095, 0.6153017282485962, 0.6293103694915771, 0.6239224076271057, 0.6239224076271057, 0.6120689511299133, 0.5829741358757019, 0.610991358757019, 0.6088362336158752, 0.5915948152542114, 0.6045258641242981, 0.6120689511299133, 0.6023706793785095, 0.5991379022598267, 0.6034482717514038, 0.607758641242981, 0.5969827771186829, 0.6066810488700867, 0.6066810488700867, 0.6088362336158752, 0.5991379022598267, 0.6023706793785095, 0.6088362336158752, 0.5948275923728943, 0.587284505367279, 0.6088362336158752, 0.6066810488700867, 0.6045258641242981, 0.6066810488700867, 0.607758641242981, 0.6206896305084229, 0.5915948152542114, 0.6120689511299133, 0.5969827771186829, 0.5948275923728943, 0.5959051847457886, 0.5926724076271057, 0.618534505367279, 0.5980603694915771, 0.607758641242981, 0.6163793206214905, 0.6260775923728943, 0.6131465435028076, 0.6153017282485962, 0.6045258641242981, 0.5991379022598267, 0.5991379022598267, 0.6153017282485962, 0.6012930870056152, 0.6142241358757019, 0.6131465435028076, 0.6131465435028076, 0.6206896305084229, 0.6045258641242981, 0.6163793206214905, 0.607758641242981, 0.6131465435028076, 0.5948275923728943, 0.6174569129943848, 0.607758641242981, 0.6056034564971924, 0.6206896305084229]}\n","38/38 [==============================] - 1s 9ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 1.4057 - accuracy: 0.4929"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 9s 78ms/step - loss: 1.4057 - accuracy: 0.4929 - val_loss: 1.3755 - val_accuracy: 0.5045\n","Epoch 2/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3496 - accuracy: 0.5014 - val_loss: 1.3218 - val_accuracy: 0.5045\n","Epoch 3/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2982 - accuracy: 0.4992 - val_loss: 1.2723 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2503 - accuracy: 0.4853 - val_loss: 1.2264 - val_accuracy: 0.5045\n","Epoch 5/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2059 - accuracy: 0.4935 - val_loss: 1.1838 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1647 - accuracy: 0.5011 - val_loss: 1.1443 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1265 - accuracy: 0.5113 - val_loss: 1.1076 - val_accuracy: 0.5045\n","Epoch 8/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0912 - accuracy: 0.5071 - val_loss: 1.0737 - val_accuracy: 0.5045\n","Epoch 9/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.0584 - accuracy: 0.5130 - val_loss: 1.0423 - val_accuracy: 0.5170\n","Epoch 10/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0279 - accuracy: 0.5280 - val_loss: 1.0135 - val_accuracy: 0.4955\n","Epoch 11/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.0005 - accuracy: 0.5011 - val_loss: 0.9865 - val_accuracy: 0.5328\n","Epoch 12/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9745 - accuracy: 0.5170 - val_loss: 0.9617 - val_accuracy: 0.5045\n","Epoch 13/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9499 - accuracy: 0.5594 - val_loss: 0.9385 - val_accuracy: 0.5566\n","Epoch 14/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9281 - accuracy: 0.5133 - val_loss: 0.9176 - val_accuracy: 0.5215\n","Epoch 15/100\n","28/28 [==============================] - 1s 42ms/step - loss: 0.9050 - accuracy: 0.5535 - val_loss: 0.8960 - val_accuracy: 0.5803\n","Epoch 16/100\n","28/28 [==============================] - 1s 17ms/step - loss: 0.8839 - accuracy: 0.5566 - val_loss: 0.8829 - val_accuracy: 0.5045\n","Epoch 17/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.8752 - accuracy: 0.4997 - val_loss: 0.8654 - val_accuracy: 0.5045\n","Epoch 18/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8583 - accuracy: 0.4989 - val_loss: 0.8504 - val_accuracy: 0.5045\n","Epoch 19/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8438 - accuracy: 0.4989 - val_loss: 0.8366 - val_accuracy: 0.5045\n","Epoch 20/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8305 - accuracy: 0.4989 - val_loss: 0.8240 - val_accuracy: 0.5045\n","Epoch 21/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8184 - accuracy: 0.4989 - val_loss: 0.8123 - val_accuracy: 0.5045\n","Epoch 22/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8072 - accuracy: 0.4992 - val_loss: 0.8017 - val_accuracy: 0.5045\n","Epoch 23/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7970 - accuracy: 0.4963 - val_loss: 0.7919 - val_accuracy: 0.5057\n","Epoch 24/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7876 - accuracy: 0.4938 - val_loss: 0.7829 - val_accuracy: 0.5034\n","Epoch 25/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7790 - accuracy: 0.4997 - val_loss: 0.7746 - val_accuracy: 0.5226\n","Epoch 26/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7710 - accuracy: 0.5088 - val_loss: 0.7671 - val_accuracy: 0.5045\n","Epoch 27/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7638 - accuracy: 0.4986 - val_loss: 0.7602 - val_accuracy: 0.5045\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7572 - accuracy: 0.5082 - val_loss: 0.7539 - val_accuracy: 0.5351\n","Epoch 29/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7511 - accuracy: 0.5325 - val_loss: 0.7481 - val_accuracy: 0.5600\n","Epoch 30/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7456 - accuracy: 0.5433 - val_loss: 0.7426 - val_accuracy: 0.5611\n","Epoch 31/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7404 - accuracy: 0.5331 - val_loss: 0.7382 - val_accuracy: 0.5045\n","Epoch 32/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7355 - accuracy: 0.5422 - val_loss: 0.7331 - val_accuracy: 0.5407\n","Epoch 33/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7303 - accuracy: 0.5594 - val_loss: 0.7302 - val_accuracy: 0.5102\n","Epoch 34/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7244 - accuracy: 0.5532 - val_loss: 0.7371 - val_accuracy: 0.5000\n","Epoch 35/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.7250 - accuracy: 0.5340 - val_loss: 0.7181 - val_accuracy: 0.5747\n","Epoch 36/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7162 - accuracy: 0.5640 - val_loss: 0.7141 - val_accuracy: 0.5554\n","Epoch 37/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.7076 - accuracy: 0.5798 - val_loss: 0.7288 - val_accuracy: 0.5271\n","Epoch 38/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.7058 - accuracy: 0.5750 - val_loss: 0.7263 - val_accuracy: 0.5260\n","Epoch 39/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.7030 - accuracy: 0.5685 - val_loss: 0.7029 - val_accuracy: 0.5622\n","Epoch 40/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.6938 - accuracy: 0.5840 - val_loss: 0.7468 - val_accuracy: 0.5181\n","Epoch 41/100\n","28/28 [==============================] - 3s 98ms/step - loss: 0.6858 - accuracy: 0.6022 - val_loss: 0.6786 - val_accuracy: 0.6188\n","Epoch 42/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.6885 - accuracy: 0.5894 - val_loss: 0.6908 - val_accuracy: 0.5905\n","Epoch 43/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.6767 - accuracy: 0.6070 - val_loss: 0.6739 - val_accuracy: 0.6176\n","Epoch 44/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6635 - accuracy: 0.6299 - val_loss: 0.6772 - val_accuracy: 0.6131\n","Epoch 45/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6580 - accuracy: 0.6310 - val_loss: 0.7233 - val_accuracy: 0.5679\n","Epoch 46/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6500 - accuracy: 0.6415 - val_loss: 0.6723 - val_accuracy: 0.5995\n","Epoch 47/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6449 - accuracy: 0.6449 - val_loss: 0.6720 - val_accuracy: 0.6324\n","Epoch 48/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6387 - accuracy: 0.6452 - val_loss: 0.7645 - val_accuracy: 0.5271\n","Epoch 49/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6462 - accuracy: 0.6336 - val_loss: 0.6655 - val_accuracy: 0.5939\n","Epoch 50/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6286 - accuracy: 0.6621 - val_loss: 0.6738 - val_accuracy: 0.5814\n","Epoch 51/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6239 - accuracy: 0.6689 - val_loss: 0.7435 - val_accuracy: 0.5486\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6143 - accuracy: 0.6650 - val_loss: 0.6681 - val_accuracy: 0.6052\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6103 - accuracy: 0.6729 - val_loss: 0.6605 - val_accuracy: 0.5984\n","Epoch 54/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5955 - accuracy: 0.6927 - val_loss: 0.6840 - val_accuracy: 0.6176\n","Epoch 55/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5777 - accuracy: 0.7046 - val_loss: 0.6789 - val_accuracy: 0.6075\n","Epoch 56/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5672 - accuracy: 0.7148 - val_loss: 0.8097 - val_accuracy: 0.5351\n","Epoch 57/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5622 - accuracy: 0.7145 - val_loss: 0.7017 - val_accuracy: 0.6143\n","Epoch 58/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5525 - accuracy: 0.7204 - val_loss: 0.6929 - val_accuracy: 0.6256\n","Epoch 59/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5309 - accuracy: 0.7411 - val_loss: 0.6852 - val_accuracy: 0.6267\n","Epoch 60/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5414 - accuracy: 0.7227 - val_loss: 0.7184 - val_accuracy: 0.6199\n","Epoch 61/100\n","28/28 [==============================] - 1s 42ms/step - loss: 0.5062 - accuracy: 0.7595 - val_loss: 0.6865 - val_accuracy: 0.6109\n","Epoch 62/100\n","28/28 [==============================] - 1s 37ms/step - loss: 0.5140 - accuracy: 0.7476 - val_loss: 0.7140 - val_accuracy: 0.6199\n","Epoch 63/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4923 - accuracy: 0.7572 - val_loss: 0.7017 - val_accuracy: 0.6075\n","Epoch 64/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4753 - accuracy: 0.7759 - val_loss: 0.7961 - val_accuracy: 0.6041\n","Epoch 65/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4413 - accuracy: 0.7999 - val_loss: 0.7576 - val_accuracy: 0.6244\n","Epoch 66/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4451 - accuracy: 0.7994 - val_loss: 0.7863 - val_accuracy: 0.6188\n","Epoch 67/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.4135 - accuracy: 0.8107 - val_loss: 0.8449 - val_accuracy: 0.6086\n","Epoch 68/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3937 - accuracy: 0.8246 - val_loss: 0.8642 - val_accuracy: 0.6097\n","Epoch 69/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3754 - accuracy: 0.8398 - val_loss: 0.8570 - val_accuracy: 0.5973\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3627 - accuracy: 0.8452 - val_loss: 0.9183 - val_accuracy: 0.6063\n","Epoch 71/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3337 - accuracy: 0.8622 - val_loss: 1.0381 - val_accuracy: 0.5860\n","Epoch 72/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3169 - accuracy: 0.8628 - val_loss: 1.1348 - val_accuracy: 0.6018\n","Epoch 73/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3013 - accuracy: 0.8772 - val_loss: 1.0956 - val_accuracy: 0.6063\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2998 - accuracy: 0.8687 - val_loss: 1.0192 - val_accuracy: 0.5735\n","Epoch 75/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2792 - accuracy: 0.8868 - val_loss: 1.1730 - val_accuracy: 0.5995\n","Epoch 76/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2292 - accuracy: 0.9080 - val_loss: 1.1686 - val_accuracy: 0.6109\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2165 - accuracy: 0.9162 - val_loss: 1.8890 - val_accuracy: 0.5475\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2392 - accuracy: 0.9041 - val_loss: 1.3653 - val_accuracy: 0.5973\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1761 - accuracy: 0.9315 - val_loss: 1.3183 - val_accuracy: 0.5860\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1714 - accuracy: 0.9375 - val_loss: 1.3416 - val_accuracy: 0.5894\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1984 - accuracy: 0.9264 - val_loss: 1.4711 - val_accuracy: 0.5905\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1828 - accuracy: 0.9284 - val_loss: 1.4392 - val_accuracy: 0.6097\n","Epoch 83/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1561 - accuracy: 0.9426 - val_loss: 1.4201 - val_accuracy: 0.6097\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1434 - accuracy: 0.9505 - val_loss: 1.8092 - val_accuracy: 0.5848\n","Epoch 85/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1169 - accuracy: 0.9601 - val_loss: 1.7750 - val_accuracy: 0.5701\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1882 - accuracy: 0.9293 - val_loss: 1.3551 - val_accuracy: 0.6222\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1263 - accuracy: 0.9561 - val_loss: 1.8146 - val_accuracy: 0.5792\n","Epoch 88/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1098 - accuracy: 0.9621 - val_loss: 1.9770 - val_accuracy: 0.5905\n","Epoch 89/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0817 - accuracy: 0.9757 - val_loss: 1.8745 - val_accuracy: 0.5882\n","Epoch 90/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0713 - accuracy: 0.9827 - val_loss: 2.2247 - val_accuracy: 0.5769\n","Epoch 91/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0664 - accuracy: 0.9785 - val_loss: 2.0344 - val_accuracy: 0.6052\n","Epoch 92/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.1094 - accuracy: 0.9624 - val_loss: 1.8316 - val_accuracy: 0.5973\n","Epoch 93/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0774 - accuracy: 0.9759 - val_loss: 2.0763 - val_accuracy: 0.6131\n","Epoch 94/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0787 - accuracy: 0.9765 - val_loss: 2.1760 - val_accuracy: 0.5905\n","Epoch 95/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0661 - accuracy: 0.9796 - val_loss: 2.0890 - val_accuracy: 0.6154\n","Epoch 96/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0608 - accuracy: 0.9836 - val_loss: 2.0993 - val_accuracy: 0.6188\n","Epoch 97/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0671 - accuracy: 0.9796 - val_loss: 2.7739 - val_accuracy: 0.5656\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1619 - accuracy: 0.9440 - val_loss: 1.3935 - val_accuracy: 0.6041\n","Epoch 99/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0827 - accuracy: 0.9740 - val_loss: 1.8415 - val_accuracy: 0.6233\n","Epoch 100/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0483 - accuracy: 0.9873 - val_loss: 2.3573 - val_accuracy: 0.5871\n","{'loss': [1.4057320356369019, 1.3496347665786743, 1.2981773614883423, 1.250307559967041, 1.2059346437454224, 1.1647394895553589, 1.1264896392822266, 1.0911788940429688, 1.0583614110946655, 1.0279120206832886, 1.0004780292510986, 0.9745326042175293, 0.9499132633209229, 0.9281205534934998, 0.9050317406654358, 0.8839406967163086, 0.8751878142356873, 0.8582784533500671, 0.8437938094139099, 0.8305433392524719, 0.8184277415275574, 0.8071956634521484, 0.7969794273376465, 0.7875531911849976, 0.7789698839187622, 0.7710150480270386, 0.7637936472892761, 0.7572041749954224, 0.7511391639709473, 0.7456127405166626, 0.74043208360672, 0.7354939579963684, 0.7303242683410645, 0.724415123462677, 0.7249533534049988, 0.7161637544631958, 0.7076429724693298, 0.7057797908782959, 0.7030442953109741, 0.6937553882598877, 0.6858236193656921, 0.6884947419166565, 0.6766756176948547, 0.6634898781776428, 0.6579642295837402, 0.6499653458595276, 0.6448925137519836, 0.6386694312095642, 0.6462362408638, 0.6286320090293884, 0.6239319443702698, 0.6143348813056946, 0.6102602481842041, 0.5954737663269043, 0.5776649713516235, 0.5671517848968506, 0.5622072815895081, 0.5524588227272034, 0.5308688879013062, 0.5414103865623474, 0.5061622858047485, 0.5139667391777039, 0.49225202202796936, 0.47528886795043945, 0.4413161873817444, 0.44514986872673035, 0.4135097861289978, 0.3936932384967804, 0.3754230737686157, 0.36269626021385193, 0.3336697816848755, 0.3168632388114929, 0.30127114057540894, 0.2997512221336365, 0.2792268395423889, 0.22915998101234436, 0.21652692556381226, 0.23922570049762726, 0.17613740265369415, 0.17135031521320343, 0.19842934608459473, 0.18279993534088135, 0.15608155727386475, 0.14342434704303741, 0.1168619841337204, 0.18820808827877045, 0.1262773722410202, 0.10978712886571884, 0.08170880377292633, 0.07130833715200424, 0.06640896946191788, 0.10942692309617996, 0.07739930599927902, 0.07870438694953918, 0.06611614674329758, 0.060757946223020554, 0.06705629080533981, 0.16190439462661743, 0.0826898142695427, 0.04834429919719696], 'accuracy': [0.49292585253715515, 0.5014148354530334, 0.4991511106491089, 0.48528578877449036, 0.4934917986392975, 0.5011318325996399, 0.5113186240196228, 0.5070741176605225, 0.513016402721405, 0.5280135869979858, 0.5011318325996399, 0.5169779062271118, 0.5594227313995361, 0.5132994055747986, 0.5534804463386536, 0.556593120098114, 0.49971702694892883, 0.4988681375980377, 0.4988681375980377, 0.4988681375980377, 0.4988681375980377, 0.4991511106491089, 0.496321439743042, 0.49377477169036865, 0.49971702694892883, 0.5087719559669495, 0.49858516454696655, 0.5082060098648071, 0.532541036605835, 0.5432937145233154, 0.5331069827079773, 0.5421618819236755, 0.5594227313995361, 0.5531975030899048, 0.5339558720588684, 0.5639501810073853, 0.5797962546348572, 0.5749858617782593, 0.5684776306152344, 0.5840407609939575, 0.602150559425354, 0.5894170999526978, 0.6069609522819519, 0.6298811435699463, 0.631013035774231, 0.6414827108383179, 0.6448783278465271, 0.6451612710952759, 0.6335597038269043, 0.6621392369270325, 0.6689304113388062, 0.6649688482284546, 0.6728919148445129, 0.6926994919776917, 0.7045840620994568, 0.7147707939147949, 0.7144878506660461, 0.7204301357269287, 0.7410866022109985, 0.7226938605308533, 0.7594793438911438, 0.7475947737693787, 0.7572156190872192, 0.7758913636207581, 0.7999433875083923, 0.7993775010108948, 0.8106960654258728, 0.8245614171028137, 0.8398415446281433, 0.8452178835868835, 0.8621957898139954, 0.8627617359161377, 0.8771929740905762, 0.8687040209770203, 0.8868138194084167, 0.9080362319946289, 0.916242241859436, 0.9040747284889221, 0.9315223693847656, 0.9374646544456482, 0.9264289736747742, 0.92840975522995, 0.9425579905509949, 0.9504810571670532, 0.960101842880249, 0.9292586445808411, 0.9561403393745422, 0.9620826244354248, 0.9756649732589722, 0.9827390909194946, 0.9784946441650391, 0.9623655676841736, 0.975947916507721, 0.9765138626098633, 0.979626476764679, 0.9835879802703857, 0.979626476764679, 0.9439728260040283, 0.9739671945571899, 0.9872665405273438], 'val_loss': [1.3754664659500122, 1.3218040466308594, 1.2723054885864258, 1.226382851600647, 1.1837824583053589, 1.1442564725875854, 1.1076133251190186, 1.0736932754516602, 1.0422757863998413, 1.0134618282318115, 0.9864819049835205, 0.9617352485656738, 0.9385411739349365, 0.9175615310668945, 0.896031379699707, 0.8829116225242615, 0.865388810634613, 0.8503631949424744, 0.8366265892982483, 0.8239856362342834, 0.8123278617858887, 0.8016635179519653, 0.7918543219566345, 0.7828734517097473, 0.7746415734291077, 0.7670799493789673, 0.7601708173751831, 0.7538649439811707, 0.7480620741844177, 0.7426486015319824, 0.7382150888442993, 0.7331352829933167, 0.7302113771438599, 0.7370868921279907, 0.7180776000022888, 0.7140554189682007, 0.7288143634796143, 0.7262603044509888, 0.702915370464325, 0.746826171875, 0.6785789132118225, 0.6907758712768555, 0.6738594770431519, 0.6772304773330688, 0.7232914566993713, 0.6723000407218933, 0.6720421314239502, 0.7645189166069031, 0.6655095815658569, 0.6738207936286926, 0.7435334324836731, 0.6681437492370605, 0.6604558825492859, 0.6839644908905029, 0.6788976788520813, 0.809719979763031, 0.7017425298690796, 0.6929082870483398, 0.6852206587791443, 0.7183850407600403, 0.6864729523658752, 0.7139779329299927, 0.7016942501068115, 0.7960700392723083, 0.7575564980506897, 0.7863029837608337, 0.8449445366859436, 0.8642286062240601, 0.8569818735122681, 0.9183284640312195, 1.038140892982483, 1.1347836256027222, 1.0956003665924072, 1.0192139148712158, 1.1729953289031982, 1.168586254119873, 1.888973593711853, 1.3652780055999756, 1.318345069885254, 1.341640830039978, 1.4711076021194458, 1.4392489194869995, 1.4201099872589111, 1.8091551065444946, 1.7750329971313477, 1.3551398515701294, 1.8145959377288818, 1.9770352840423584, 1.8745101690292358, 2.224724531173706, 2.0344321727752686, 1.8316460847854614, 2.076329231262207, 2.176002025604248, 2.089045763015747, 2.099270820617676, 2.7738523483276367, 1.393465518951416, 1.8415262699127197, 2.3572802543640137], 'val_accuracy': [0.5045248866081238, 0.5045248866081238, 0.4954751133918762, 0.5045248866081238, 0.4954751133918762, 0.4954751133918762, 0.5045248866081238, 0.5045248866081238, 0.516968309879303, 0.4954751133918762, 0.5328054428100586, 0.5045248866081238, 0.5565611124038696, 0.5214931964874268, 0.5803167223930359, 0.5045248866081238, 0.5045248866081238, 0.5045248866081238, 0.5045248866081238, 0.5045248866081238, 0.5045248866081238, 0.5045248866081238, 0.5056561231613159, 0.5033936500549316, 0.5226244330406189, 0.5045248866081238, 0.5045248866081238, 0.5350678563117981, 0.5599547624588013, 0.5610859990119934, 0.5045248866081238, 0.540723979473114, 0.5101810097694397, 0.5, 0.5746606588363647, 0.5554298758506775, 0.5271493196487427, 0.5260180830955505, 0.5622171759605408, 0.5180995464324951, 0.6187782883644104, 0.5904977321624756, 0.6176470518112183, 0.6131221652030945, 0.5678732991218567, 0.5995475053787231, 0.6323529481887817, 0.5271493196487427, 0.5938913822174072, 0.581447958946228, 0.5486425161361694, 0.6052036285400391, 0.598416268825531, 0.6176470518112183, 0.6074660420417786, 0.5350678563117981, 0.6142534017562866, 0.6255655884742737, 0.6266968250274658, 0.6199095249176025, 0.610859751701355, 0.6199095249176025, 0.6074660420417786, 0.6040723919868469, 0.6244344115257263, 0.6187782883644104, 0.6085972785949707, 0.6097285151481628, 0.5972850918769836, 0.6063348650932312, 0.5859728455543518, 0.6018099784851074, 0.6063348650932312, 0.5735294222831726, 0.5995475053787231, 0.610859751701355, 0.5475113391876221, 0.5972850918769836, 0.5859728455543518, 0.5893664956092834, 0.5904977321624756, 0.6097285151481628, 0.6097285151481628, 0.5848416090011597, 0.570135772228241, 0.622171938419342, 0.5791855454444885, 0.5904977321624756, 0.5882353186607361, 0.5769230723381042, 0.6052036285400391, 0.5972850918769836, 0.6131221652030945, 0.5904977321624756, 0.6153846383094788, 0.6187782883644104, 0.5656108856201172, 0.6040723919868469, 0.6233031749725342, 0.587104082107544]}\n","45/45 [==============================] - 1s 9ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 1.4032 - accuracy: 0.5044"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 69ms/step - loss: 1.4032 - accuracy: 0.5044 - val_loss: 1.3698 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3416 - accuracy: 0.5000 - val_loss: 1.3109 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2851 - accuracy: 0.5018 - val_loss: 1.2571 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2333 - accuracy: 0.5018 - val_loss: 1.2075 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1857 - accuracy: 0.5008 - val_loss: 1.1621 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1419 - accuracy: 0.5028 - val_loss: 1.1204 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1018 - accuracy: 0.5016 - val_loss: 1.0819 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.0647 - accuracy: 0.5093 - val_loss: 1.0466 - val_accuracy: 0.4876\n","Epoch 9/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0309 - accuracy: 0.5158 - val_loss: 1.0145 - val_accuracy: 0.4855\n","Epoch 10/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0000 - accuracy: 0.5036 - val_loss: 0.9848 - val_accuracy: 0.4855\n","Epoch 11/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9711 - accuracy: 0.5357 - val_loss: 0.9579 - val_accuracy: 0.4855\n","Epoch 12/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9448 - accuracy: 0.5222 - val_loss: 0.9328 - val_accuracy: 0.4855\n","Epoch 13/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.9190 - accuracy: 0.5395 - val_loss: 0.9100 - val_accuracy: 0.5155\n","Epoch 14/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9009 - accuracy: 0.4966 - val_loss: 0.8896 - val_accuracy: 0.5145\n","Epoch 15/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8808 - accuracy: 0.4920 - val_loss: 0.8709 - val_accuracy: 0.5145\n","Epoch 16/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8627 - accuracy: 0.5010 - val_loss: 0.8537 - val_accuracy: 0.4855\n","Epoch 17/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8462 - accuracy: 0.5044 - val_loss: 0.8380 - val_accuracy: 0.4855\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8311 - accuracy: 0.4979 - val_loss: 0.8237 - val_accuracy: 0.5155\n","Epoch 19/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8174 - accuracy: 0.4956 - val_loss: 0.8107 - val_accuracy: 0.4855\n","Epoch 20/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8050 - accuracy: 0.5036 - val_loss: 0.7990 - val_accuracy: 0.4855\n","Epoch 21/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7937 - accuracy: 0.5036 - val_loss: 0.7882 - val_accuracy: 0.4855\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7835 - accuracy: 0.5039 - val_loss: 0.7785 - val_accuracy: 0.4855\n","Epoch 23/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7742 - accuracy: 0.5036 - val_loss: 0.7697 - val_accuracy: 0.4855\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7658 - accuracy: 0.5036 - val_loss: 0.7618 - val_accuracy: 0.4855\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7582 - accuracy: 0.5036 - val_loss: 0.7547 - val_accuracy: 0.4855\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7513 - accuracy: 0.5036 - val_loss: 0.7482 - val_accuracy: 0.4855\n","Epoch 27/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7451 - accuracy: 0.5036 - val_loss: 0.7423 - val_accuracy: 0.4855\n","Epoch 28/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7395 - accuracy: 0.5036 - val_loss: 0.7369 - val_accuracy: 0.5424\n","Epoch 29/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7342 - accuracy: 0.5320 - val_loss: 0.7323 - val_accuracy: 0.4917\n","Epoch 30/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7287 - accuracy: 0.5571 - val_loss: 0.7278 - val_accuracy: 0.5155\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7218 - accuracy: 0.5475 - val_loss: 0.7244 - val_accuracy: 0.5424\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7209 - accuracy: 0.5178 - val_loss: 0.7221 - val_accuracy: 0.5145\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7211 - accuracy: 0.4964 - val_loss: 0.7190 - val_accuracy: 0.5145\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7178 - accuracy: 0.4984 - val_loss: 0.7163 - val_accuracy: 0.4855\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7150 - accuracy: 0.5036 - val_loss: 0.7139 - val_accuracy: 0.4855\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7126 - accuracy: 0.5036 - val_loss: 0.7115 - val_accuracy: 0.4855\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7105 - accuracy: 0.5036 - val_loss: 0.7096 - val_accuracy: 0.4855\n","Epoch 38/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7085 - accuracy: 0.5036 - val_loss: 0.7079 - val_accuracy: 0.4855\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7069 - accuracy: 0.5036 - val_loss: 0.7063 - val_accuracy: 0.4855\n","Epoch 40/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7054 - accuracy: 0.5036 - val_loss: 0.7048 - val_accuracy: 0.4855\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7041 - accuracy: 0.5036 - val_loss: 0.7036 - val_accuracy: 0.4855\n","Epoch 42/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7028 - accuracy: 0.5036 - val_loss: 0.7023 - val_accuracy: 0.4855\n","Epoch 43/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7014 - accuracy: 0.5109 - val_loss: 0.7017 - val_accuracy: 0.4845\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6975 - accuracy: 0.5447 - val_loss: 0.7142 - val_accuracy: 0.5134\n","Epoch 45/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6948 - accuracy: 0.5380 - val_loss: 0.7009 - val_accuracy: 0.5145\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7010 - accuracy: 0.4964 - val_loss: 0.7000 - val_accuracy: 0.5145\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7000 - accuracy: 0.4966 - val_loss: 0.6994 - val_accuracy: 0.5145\n","Epoch 48/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6991 - accuracy: 0.4886 - val_loss: 0.6988 - val_accuracy: 0.4855\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6985 - accuracy: 0.5034 - val_loss: 0.6983 - val_accuracy: 0.4855\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6980 - accuracy: 0.5036 - val_loss: 0.6978 - val_accuracy: 0.4855\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6975 - accuracy: 0.5036 - val_loss: 0.6975 - val_accuracy: 0.4855\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6971 - accuracy: 0.5036 - val_loss: 0.6972 - val_accuracy: 0.4855\n","Epoch 53/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6968 - accuracy: 0.5036 - val_loss: 0.6970 - val_accuracy: 0.4855\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6964 - accuracy: 0.5036 - val_loss: 0.6966 - val_accuracy: 0.4855\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6962 - accuracy: 0.5036 - val_loss: 0.6964 - val_accuracy: 0.4855\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6959 - accuracy: 0.5036 - val_loss: 0.6961 - val_accuracy: 0.4855\n","Epoch 57/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6957 - accuracy: 0.5036 - val_loss: 0.6959 - val_accuracy: 0.4855\n","Epoch 58/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6955 - accuracy: 0.5036 - val_loss: 0.6958 - val_accuracy: 0.4855\n","Epoch 59/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6953 - accuracy: 0.5036 - val_loss: 0.6956 - val_accuracy: 0.4855\n","Epoch 60/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6952 - accuracy: 0.5036 - val_loss: 0.6955 - val_accuracy: 0.4855\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6950 - accuracy: 0.5036 - val_loss: 0.6953 - val_accuracy: 0.4855\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6949 - accuracy: 0.5036 - val_loss: 0.6952 - val_accuracy: 0.4855\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6948 - accuracy: 0.5036 - val_loss: 0.6951 - val_accuracy: 0.4855\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6947 - accuracy: 0.5036 - val_loss: 0.6950 - val_accuracy: 0.4855\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6946 - accuracy: 0.5036 - val_loss: 0.6949 - val_accuracy: 0.4855\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6945 - accuracy: 0.5036 - val_loss: 0.6948 - val_accuracy: 0.4855\n","Epoch 67/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6944 - accuracy: 0.5036 - val_loss: 0.6947 - val_accuracy: 0.4855\n","Epoch 68/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6944 - accuracy: 0.5036 - val_loss: 0.6947 - val_accuracy: 0.4855\n","Epoch 69/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6943 - accuracy: 0.5036 - val_loss: 0.6946 - val_accuracy: 0.4855\n","Epoch 70/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6943 - accuracy: 0.5036 - val_loss: 0.6946 - val_accuracy: 0.4855\n","Epoch 71/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6942 - accuracy: 0.5036 - val_loss: 0.6944 - val_accuracy: 0.4855\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6942 - accuracy: 0.5036 - val_loss: 0.6944 - val_accuracy: 0.4855\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6941 - accuracy: 0.5036 - val_loss: 0.6943 - val_accuracy: 0.4855\n","Epoch 74/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6941 - accuracy: 0.5036 - val_loss: 0.6943 - val_accuracy: 0.4855\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6940 - accuracy: 0.5036 - val_loss: 0.6943 - val_accuracy: 0.4855\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6940 - accuracy: 0.5036 - val_loss: 0.6942 - val_accuracy: 0.4855\n","Epoch 77/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6940 - accuracy: 0.5036 - val_loss: 0.6942 - val_accuracy: 0.4855\n","Epoch 78/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6939 - accuracy: 0.5036 - val_loss: 0.6942 - val_accuracy: 0.4855\n","Epoch 79/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6939 - accuracy: 0.5036 - val_loss: 0.6941 - val_accuracy: 0.4855\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6939 - accuracy: 0.5036 - val_loss: 0.6941 - val_accuracy: 0.4855\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6939 - accuracy: 0.5036 - val_loss: 0.6941 - val_accuracy: 0.4855\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6938 - accuracy: 0.5036 - val_loss: 0.6940 - val_accuracy: 0.4855\n","Epoch 83/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6938 - accuracy: 0.5036 - val_loss: 0.6940 - val_accuracy: 0.4855\n","Epoch 84/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6938 - accuracy: 0.5036 - val_loss: 0.6940 - val_accuracy: 0.4855\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6938 - accuracy: 0.5036 - val_loss: 0.6940 - val_accuracy: 0.4855\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6938 - accuracy: 0.5036 - val_loss: 0.6940 - val_accuracy: 0.4855\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6937 - accuracy: 0.5036 - val_loss: 0.6940 - val_accuracy: 0.4855\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6937 - accuracy: 0.5036 - val_loss: 0.6939 - val_accuracy: 0.4855\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6937 - accuracy: 0.5036 - val_loss: 0.6939 - val_accuracy: 0.4855\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6937 - accuracy: 0.5036 - val_loss: 0.6939 - val_accuracy: 0.4855\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6937 - accuracy: 0.5036 - val_loss: 0.6939 - val_accuracy: 0.4855\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6937 - accuracy: 0.5036 - val_loss: 0.6939 - val_accuracy: 0.4855\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6937 - accuracy: 0.5036 - val_loss: 0.6938 - val_accuracy: 0.4855\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6936 - accuracy: 0.5036 - val_loss: 0.6938 - val_accuracy: 0.4855\n","Epoch 95/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6936 - accuracy: 0.5036 - val_loss: 0.6938 - val_accuracy: 0.4855\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6936 - accuracy: 0.5036 - val_loss: 0.6938 - val_accuracy: 0.4855\n","Epoch 97/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6936 - accuracy: 0.5036 - val_loss: 0.6938 - val_accuracy: 0.4855\n","Epoch 98/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6936 - accuracy: 0.5036 - val_loss: 0.6938 - val_accuracy: 0.4855\n","Epoch 99/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6936 - accuracy: 0.5036 - val_loss: 0.6938 - val_accuracy: 0.4855\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6936 - accuracy: 0.5036 - val_loss: 0.6938 - val_accuracy: 0.4855\n","{'loss': [1.4031727313995361, 1.3415722846984863, 1.2850944995880127, 1.2332912683486938, 1.1856688261032104, 1.1419471502304077, 1.1017524003982544, 1.064726710319519, 1.0309139490127563, 1.0000193119049072, 0.971079409122467, 0.9448341131210327, 0.9189900755882263, 0.900921106338501, 0.8808411955833435, 0.8626758456230164, 0.8461589217185974, 0.831148087978363, 0.8174465298652649, 0.8049920797348022, 0.7937129735946655, 0.7834820747375488, 0.7741773724555969, 0.7658023238182068, 0.7581886649131775, 0.7513449192047119, 0.7451388239860535, 0.73952716588974, 0.7342322468757629, 0.7287153005599976, 0.7217978835105896, 0.720860481262207, 0.7211357355117798, 0.7177931666374207, 0.7150219678878784, 0.7126035094261169, 0.7104830741882324, 0.7085443735122681, 0.7068871259689331, 0.7054149508476257, 0.7040597796440125, 0.7028114795684814, 0.7014317512512207, 0.6974517703056335, 0.6947948336601257, 0.7009875774383545, 0.6999868750572205, 0.6991070508956909, 0.6984918713569641, 0.6979597806930542, 0.6974698305130005, 0.6971266865730286, 0.6967573165893555, 0.6964216232299805, 0.6961575150489807, 0.6958968639373779, 0.6957037448883057, 0.6955054998397827, 0.6953260898590088, 0.6951785683631897, 0.6950467228889465, 0.6949188709259033, 0.694830596446991, 0.6947058439254761, 0.6946170330047607, 0.6945206522941589, 0.6944464445114136, 0.6943762302398682, 0.6943185329437256, 0.6942840218544006, 0.6942060589790344, 0.6941529512405396, 0.694108247756958, 0.6940699815750122, 0.6940377950668335, 0.6939951777458191, 0.6939685940742493, 0.6939375996589661, 0.6939073801040649, 0.6938811540603638, 0.6938582062721252, 0.6938349008560181, 0.693818986415863, 0.6937944889068604, 0.6937742829322815, 0.693757176399231, 0.6937469840049744, 0.6937261819839478, 0.6937093734741211, 0.6936945915222168, 0.6936802268028259, 0.6936672925949097, 0.6936617493629456, 0.6936436295509338, 0.6936299204826355, 0.6936235427856445, 0.6936067938804626, 0.6935999989509583, 0.6935912370681763, 0.6935800909996033], 'accuracy': [0.5043927431106567, 0.5, 0.501808762550354, 0.501808762550354, 0.5007752180099487, 0.502842366695404, 0.5015503764152527, 0.5093023180961609, 0.5157622694969177, 0.5036175847053528, 0.5356588959693909, 0.5222222208976746, 0.539534866809845, 0.4966408312320709, 0.4919896721839905, 0.50103360414505, 0.5043927431106567, 0.4979328215122223, 0.4956072270870209, 0.5036175847053528, 0.5036175847053528, 0.5038759708404541, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5320413708686829, 0.5571059584617615, 0.5475451946258545, 0.5178294777870178, 0.4963824152946472, 0.4984496235847473, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5108526945114136, 0.5447028279304504, 0.5379844903945923, 0.4963824152946472, 0.4966408312320709, 0.4886305034160614, 0.5033591985702515, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528], 'val_loss': [1.3697859048843384, 1.3109080791473389, 1.257092833518982, 1.2075046300888062, 1.1620832681655884, 1.1203571557998657, 1.081856608390808, 1.0465965270996094, 1.0145015716552734, 0.9847998023033142, 0.9578689336776733, 0.9327797889709473, 0.9100407958030701, 0.8896462321281433, 0.870926022529602, 0.85371333360672, 0.8380461931228638, 0.8236762881278992, 0.810743510723114, 0.7989585995674133, 0.7882038950920105, 0.7785027623176575, 0.7697269320487976, 0.7617608904838562, 0.7546902894973755, 0.7481801509857178, 0.7422581315040588, 0.7369034290313721, 0.7323373556137085, 0.7277741432189941, 0.724372148513794, 0.7221395373344421, 0.7189880609512329, 0.7162710428237915, 0.7139201164245605, 0.7115272283554077, 0.7095675468444824, 0.7078864574432373, 0.7063305377960205, 0.704774796962738, 0.7035701274871826, 0.7022662162780762, 0.7016785144805908, 0.7141873240470886, 0.7008793950080872, 0.7000259757041931, 0.6993971467018127, 0.698809802532196, 0.6982986330986023, 0.6977972388267517, 0.6974849104881287, 0.6971966624259949, 0.6969645619392395, 0.6965942978858948, 0.6963521242141724, 0.6961158514022827, 0.6958909034729004, 0.6957966089248657, 0.6956160068511963, 0.695480465888977, 0.6953175067901611, 0.695214033126831, 0.695133626461029, 0.6949920058250427, 0.6949033737182617, 0.694774866104126, 0.6947280168533325, 0.6946548819541931, 0.6945624351501465, 0.694571316242218, 0.6944433450698853, 0.6943864822387695, 0.6943468451499939, 0.6943072080612183, 0.6942537426948547, 0.6942291259765625, 0.6941913962364197, 0.6941658854484558, 0.6941455602645874, 0.6941097378730774, 0.694069504737854, 0.6940397024154663, 0.694000244140625, 0.6939982175827026, 0.6939776539802551, 0.6939758062362671, 0.6939646005630493, 0.6939156651496887, 0.6939098238945007, 0.6938987970352173, 0.6939154863357544, 0.6938908100128174, 0.693848729133606, 0.6938463449478149, 0.693838894367218, 0.6938456892967224, 0.6938151121139526, 0.693807065486908, 0.6937984228134155, 0.6937928199768066], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.4876033067703247, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.5154958963394165, 0.5144628286361694, 0.5144628286361694, 0.48553720116615295, 0.48553720116615295, 0.5154958963394165, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.5423553586006165, 0.4917355477809906, 0.5154958963394165, 0.5423553586006165, 0.5144628286361694, 0.5144628286361694, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.4845041334629059, 0.5134297609329224, 0.5144628286361694, 0.5144628286361694, 0.5144628286361694, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295]}\n","32/32 [==============================] - 1s 9ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.6768 - accuracy: 0.6106"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 52ms/step - loss: 0.6767 - accuracy: 0.6088 - val_loss: 0.6989 - val_accuracy: 0.4828\n","Epoch 2/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6429 - accuracy: 0.6352 - val_loss: 0.6995 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6198 - accuracy: 0.6525 - val_loss: 0.6999 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5837 - accuracy: 0.6937 - val_loss: 0.6996 - val_accuracy: 0.6034\n","Epoch 5/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.5687 - accuracy: 0.7066 - val_loss: 0.6999 - val_accuracy: 0.6218\n","Epoch 6/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5184 - accuracy: 0.7462 - val_loss: 0.6991 - val_accuracy: 0.5550\n","Epoch 7/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4934 - accuracy: 0.7675 - val_loss: 0.6987 - val_accuracy: 0.5463\n","Epoch 8/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.4893 - accuracy: 0.7635 - val_loss: 0.6976 - val_accuracy: 0.6110\n","Epoch 9/100\n","29/29 [==============================] - 1s 39ms/step - loss: 0.4233 - accuracy: 0.8103 - val_loss: 0.6952 - val_accuracy: 0.5528\n","Epoch 10/100\n","29/29 [==============================] - 1s 39ms/step - loss: 0.3990 - accuracy: 0.8238 - val_loss: 0.6923 - val_accuracy: 0.5948\n","Epoch 11/100\n","29/29 [==============================] - 1s 50ms/step - loss: 0.3476 - accuracy: 0.8537 - val_loss: 0.6887 - val_accuracy: 0.5614\n","Epoch 12/100\n","29/29 [==============================] - 2s 57ms/step - loss: 0.3494 - accuracy: 0.8416 - val_loss: 0.6847 - val_accuracy: 0.5765\n","Epoch 13/100\n","29/29 [==============================] - 1s 37ms/step - loss: 0.2722 - accuracy: 0.8952 - val_loss: 0.6757 - val_accuracy: 0.6056\n","Epoch 14/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2637 - accuracy: 0.8949 - val_loss: 0.6772 - val_accuracy: 0.5841\n","Epoch 15/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2064 - accuracy: 0.9259 - val_loss: 0.7042 - val_accuracy: 0.5744\n","Epoch 16/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1858 - accuracy: 0.9313 - val_loss: 0.6774 - val_accuracy: 0.6056\n","Epoch 17/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.1880 - accuracy: 0.9337 - val_loss: 0.6784 - val_accuracy: 0.6056\n","Epoch 18/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1937 - accuracy: 0.9318 - val_loss: 0.7075 - val_accuracy: 0.6175\n","Epoch 19/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1542 - accuracy: 0.9477 - val_loss: 0.7206 - val_accuracy: 0.6142\n","Epoch 20/100\n","29/29 [==============================] - 2s 79ms/step - loss: 0.1195 - accuracy: 0.9650 - val_loss: 0.7830 - val_accuracy: 0.6250\n","Epoch 21/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1429 - accuracy: 0.9529 - val_loss: 0.8715 - val_accuracy: 0.6056\n","Epoch 22/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2085 - accuracy: 0.9205 - val_loss: 0.7865 - val_accuracy: 0.6175\n","Epoch 23/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1088 - accuracy: 0.9674 - val_loss: 1.0147 - val_accuracy: 0.6207\n","Epoch 24/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0948 - accuracy: 0.9685 - val_loss: 1.2980 - val_accuracy: 0.6024\n","Epoch 25/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1135 - accuracy: 0.9615 - val_loss: 1.2360 - val_accuracy: 0.6336\n","Epoch 26/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1066 - accuracy: 0.9636 - val_loss: 1.2607 - val_accuracy: 0.6207\n","Epoch 27/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0931 - accuracy: 0.9723 - val_loss: 1.4547 - val_accuracy: 0.6218\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1205 - accuracy: 0.9601 - val_loss: 1.3716 - val_accuracy: 0.6282\n","Epoch 29/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0938 - accuracy: 0.9717 - val_loss: 1.4487 - val_accuracy: 0.6153\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0772 - accuracy: 0.9803 - val_loss: 1.5730 - val_accuracy: 0.6142\n","Epoch 31/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1849 - accuracy: 0.9337 - val_loss: 1.1643 - val_accuracy: 0.6196\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0920 - accuracy: 0.9776 - val_loss: 1.5168 - val_accuracy: 0.6088\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0580 - accuracy: 0.9876 - val_loss: 1.7122 - val_accuracy: 0.6088\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0571 - accuracy: 0.9841 - val_loss: 1.8265 - val_accuracy: 0.6121\n","Epoch 35/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0570 - accuracy: 0.9890 - val_loss: 1.8238 - val_accuracy: 0.6196\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0642 - accuracy: 0.9817 - val_loss: 1.8046 - val_accuracy: 0.6228\n","Epoch 37/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0574 - accuracy: 0.9871 - val_loss: 1.9164 - val_accuracy: 0.6228\n","Epoch 38/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0515 - accuracy: 0.9881 - val_loss: 1.9258 - val_accuracy: 0.6282\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0729 - accuracy: 0.9779 - val_loss: 1.9524 - val_accuracy: 0.6088\n","Epoch 40/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0819 - accuracy: 0.9776 - val_loss: 1.7329 - val_accuracy: 0.6056\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0601 - accuracy: 0.9863 - val_loss: 1.8628 - val_accuracy: 0.6272\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0617 - accuracy: 0.9844 - val_loss: 2.0144 - val_accuracy: 0.6207\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0594 - accuracy: 0.9863 - val_loss: 1.8184 - val_accuracy: 0.6131\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0637 - accuracy: 0.9828 - val_loss: 1.9069 - val_accuracy: 0.6131\n","Epoch 45/100\n","29/29 [==============================] - 3s 104ms/step - loss: 0.0546 - accuracy: 0.9860 - val_loss: 1.8990 - val_accuracy: 0.6347\n","Epoch 46/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1030 - accuracy: 0.9647 - val_loss: 1.5757 - val_accuracy: 0.6336\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0935 - accuracy: 0.9725 - val_loss: 1.6218 - val_accuracy: 0.6153\n","Epoch 48/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0523 - accuracy: 0.9879 - val_loss: 1.8689 - val_accuracy: 0.6142\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0432 - accuracy: 0.9919 - val_loss: 1.8903 - val_accuracy: 0.6239\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0339 - accuracy: 0.9949 - val_loss: 2.0712 - val_accuracy: 0.6175\n","Epoch 51/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0380 - accuracy: 0.9919 - val_loss: 2.1072 - val_accuracy: 0.6164\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0417 - accuracy: 0.9911 - val_loss: 1.9978 - val_accuracy: 0.6067\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0338 - accuracy: 0.9938 - val_loss: 2.0996 - val_accuracy: 0.6207\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0445 - accuracy: 0.9887 - val_loss: 2.1647 - val_accuracy: 0.6218\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0461 - accuracy: 0.9876 - val_loss: 2.1530 - val_accuracy: 0.6013\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0437 - accuracy: 0.9906 - val_loss: 2.0915 - val_accuracy: 0.6315\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0764 - accuracy: 0.9784 - val_loss: 1.9476 - val_accuracy: 0.6272\n","Epoch 58/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0649 - accuracy: 0.9806 - val_loss: 1.8737 - val_accuracy: 0.6282\n","Epoch 59/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0685 - accuracy: 0.9798 - val_loss: 1.8480 - val_accuracy: 0.6088\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0553 - accuracy: 0.9849 - val_loss: 1.9265 - val_accuracy: 0.5981\n","Epoch 61/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0466 - accuracy: 0.9865 - val_loss: 1.9139 - val_accuracy: 0.6336\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0423 - accuracy: 0.9914 - val_loss: 1.9803 - val_accuracy: 0.6142\n","Epoch 63/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0341 - accuracy: 0.9954 - val_loss: 2.1090 - val_accuracy: 0.6196\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0488 - accuracy: 0.9863 - val_loss: 2.2923 - val_accuracy: 0.6185\n","Epoch 65/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0894 - accuracy: 0.9717 - val_loss: 1.6927 - val_accuracy: 0.6261\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0661 - accuracy: 0.9809 - val_loss: 1.9090 - val_accuracy: 0.6067\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0444 - accuracy: 0.9906 - val_loss: 1.9744 - val_accuracy: 0.6164\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0322 - accuracy: 0.9949 - val_loss: 2.2069 - val_accuracy: 0.6185\n","Epoch 69/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0361 - accuracy: 0.9927 - val_loss: 2.0549 - val_accuracy: 0.6185\n","Epoch 70/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0382 - accuracy: 0.9911 - val_loss: 2.1698 - val_accuracy: 0.6304\n","Epoch 71/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0373 - accuracy: 0.9898 - val_loss: 2.0996 - val_accuracy: 0.6325\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0276 - accuracy: 0.9965 - val_loss: 2.2084 - val_accuracy: 0.6293\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0258 - accuracy: 0.9962 - val_loss: 2.3014 - val_accuracy: 0.6218\n","Epoch 74/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0303 - accuracy: 0.9938 - val_loss: 2.1108 - val_accuracy: 0.6282\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0530 - accuracy: 0.9876 - val_loss: 2.0837 - val_accuracy: 0.6164\n","Epoch 76/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0472 - accuracy: 0.9873 - val_loss: 2.0167 - val_accuracy: 0.6175\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0504 - accuracy: 0.9868 - val_loss: 2.2347 - val_accuracy: 0.6024\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0764 - accuracy: 0.9763 - val_loss: 1.9792 - val_accuracy: 0.6067\n","Epoch 79/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0450 - accuracy: 0.9892 - val_loss: 1.9060 - val_accuracy: 0.6304\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0298 - accuracy: 0.9930 - val_loss: 2.0116 - val_accuracy: 0.6153\n","Epoch 81/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0254 - accuracy: 0.9965 - val_loss: 2.2054 - val_accuracy: 0.6315\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0254 - accuracy: 0.9957 - val_loss: 2.2547 - val_accuracy: 0.6293\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0276 - accuracy: 0.9941 - val_loss: 2.2771 - val_accuracy: 0.6196\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0246 - accuracy: 0.9949 - val_loss: 2.2381 - val_accuracy: 0.6207\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0212 - accuracy: 0.9981 - val_loss: 2.1864 - val_accuracy: 0.6272\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0247 - accuracy: 0.9968 - val_loss: 2.2326 - val_accuracy: 0.6131\n","Epoch 87/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0353 - accuracy: 0.9930 - val_loss: 2.1625 - val_accuracy: 0.6164\n","Epoch 88/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0495 - accuracy: 0.9873 - val_loss: 2.0989 - val_accuracy: 0.6185\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0461 - accuracy: 0.9898 - val_loss: 2.1163 - val_accuracy: 0.6175\n","Epoch 90/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0336 - accuracy: 0.9946 - val_loss: 2.2320 - val_accuracy: 0.6239\n","Epoch 91/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0331 - accuracy: 0.9919 - val_loss: 2.0840 - val_accuracy: 0.6315\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0296 - accuracy: 0.9946 - val_loss: 2.1731 - val_accuracy: 0.6153\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0314 - accuracy: 0.9935 - val_loss: 2.2724 - val_accuracy: 0.6261\n","Epoch 94/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0495 - accuracy: 0.9868 - val_loss: 2.0388 - val_accuracy: 0.6325\n","Epoch 95/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0497 - accuracy: 0.9863 - val_loss: 1.9446 - val_accuracy: 0.6304\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0515 - accuracy: 0.9849 - val_loss: 2.1125 - val_accuracy: 0.6164\n","Epoch 97/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0464 - accuracy: 0.9879 - val_loss: 1.8931 - val_accuracy: 0.6336\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0456 - accuracy: 0.9881 - val_loss: 1.7942 - val_accuracy: 0.6325\n","Epoch 99/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0324 - accuracy: 0.9946 - val_loss: 1.9734 - val_accuracy: 0.6293\n","Epoch 100/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0313 - accuracy: 0.9927 - val_loss: 2.0080 - val_accuracy: 0.6315\n","{'loss': [0.6767411231994629, 0.6429200172424316, 0.6197999119758606, 0.5836620330810547, 0.5687453150749207, 0.5183984041213989, 0.4933528006076813, 0.4893477261066437, 0.42334023118019104, 0.3989664614200592, 0.3476078510284424, 0.34941285848617554, 0.2722211480140686, 0.2637423872947693, 0.20640289783477783, 0.1857624650001526, 0.18801037967205048, 0.19371385872364044, 0.15417039394378662, 0.11951589584350586, 0.14289678633213043, 0.20851632952690125, 0.10875208675861359, 0.09484339505434036, 0.11348646879196167, 0.10662965476512909, 0.09310352057218552, 0.12049209326505661, 0.09381193667650223, 0.07715574651956558, 0.18490499258041382, 0.09196958690881729, 0.05802762135863304, 0.05709691718220711, 0.05702140927314758, 0.06421596556901932, 0.057416316121816635, 0.05153074860572815, 0.07286842912435532, 0.08185771107673645, 0.06014155223965645, 0.061654914170503616, 0.05939454212784767, 0.063686802983284, 0.05462023243308067, 0.10300440341234207, 0.09346432238817215, 0.05234406888484955, 0.04315587505698204, 0.03389795124530792, 0.03796294704079628, 0.04165748879313469, 0.03375590965151787, 0.04450167715549469, 0.046123478561639786, 0.04366040229797363, 0.07638899981975555, 0.06488465517759323, 0.06848474591970444, 0.05529965087771416, 0.046637166291475296, 0.04230585694313049, 0.03408477082848549, 0.048809852451086044, 0.08935866504907608, 0.06606163829565048, 0.04435856640338898, 0.03219088166952133, 0.03611936420202255, 0.03815393149852753, 0.0373065322637558, 0.027559176087379456, 0.025785962119698524, 0.030333321541547775, 0.05301419273018837, 0.04717304930090904, 0.05044296756386757, 0.07640711218118668, 0.045042358338832855, 0.02979380637407303, 0.02542111650109291, 0.02540622651576996, 0.02758978307247162, 0.024624358862638474, 0.021188469603657722, 0.02470165491104126, 0.03525860235095024, 0.04953395202755928, 0.046082958579063416, 0.033580709248781204, 0.03310466185212135, 0.029637357220053673, 0.031357429921627045, 0.04951221123337746, 0.049723222851753235, 0.05148287117481232, 0.04644649103283882, 0.04559512436389923, 0.032406553626060486, 0.03131028637290001], 'accuracy': [0.6088362336158752, 0.6352370977401733, 0.6524784564971924, 0.693696141242981, 0.7066271305084229, 0.7462284564971924, 0.7675107717514038, 0.7634698152542114, 0.8103448152542114, 0.8238146305084229, 0.8537176847457886, 0.8415948152542114, 0.8952047228813171, 0.8949353694915771, 0.9259159564971924, 0.931303858757019, 0.9337284564971924, 0.9318426847457886, 0.9477370977401733, 0.9649784564971924, 0.9528555870056152, 0.920527994632721, 0.967402994632721, 0.9684805870056152, 0.9614762663841248, 0.9636314511299133, 0.9722521305084229, 0.9601293206214905, 0.9717133641242981, 0.9803340435028076, 0.9337284564971924, 0.9776400923728943, 0.9876077771186829, 0.9841055870056152, 0.9889547228813171, 0.9816810488700867, 0.9870689511299133, 0.9881465435028076, 0.977909505367279, 0.9776400923728943, 0.9862607717514038, 0.984375, 0.9862607717514038, 0.982758641242981, 0.985991358757019, 0.9647090435028076, 0.9725215435028076, 0.9878771305084229, 0.9919180870056152, 0.9948814511299133, 0.9919180870056152, 0.9911099076271057, 0.993803858757019, 0.9886853694915771, 0.9876077771186829, 0.990571141242981, 0.9784482717514038, 0.9806034564971924, 0.9797952771186829, 0.9849137663841248, 0.9865301847457886, 0.9913793206214905, 0.9954202771186829, 0.9862607717514038, 0.9717133641242981, 0.9808728694915771, 0.990571141242981, 0.9948814511299133, 0.9927262663841248, 0.9911099076271057, 0.9897629022598267, 0.9964978694915771, 0.9962284564971924, 0.993803858757019, 0.9876077771186829, 0.9873383641242981, 0.9867995977401733, 0.9762930870056152, 0.9892241358757019, 0.9929956793785095, 0.9964978694915771, 0.9956896305084229, 0.9940732717514038, 0.9948814511299133, 0.9981142282485962, 0.9967672228813171, 0.9929956793785095, 0.9873383641242981, 0.9897629022598267, 0.9946120977401733, 0.9919180870056152, 0.9946120977401733, 0.993534505367279, 0.9867995977401733, 0.9862607717514038, 0.9849137663841248, 0.9878771305084229, 0.9881465435028076, 0.9946120977401733, 0.9927262663841248], 'val_loss': [0.6989365220069885, 0.699513852596283, 0.6999346613883972, 0.6995651721954346, 0.6998710632324219, 0.6990855932235718, 0.6987470984458923, 0.6975693106651306, 0.6952289342880249, 0.6922609806060791, 0.6886938810348511, 0.684688150882721, 0.6757258176803589, 0.6772443056106567, 0.7041686773300171, 0.6774129271507263, 0.6784065961837769, 0.7075405716896057, 0.720632791519165, 0.7830224633216858, 0.8715329170227051, 0.7865489721298218, 1.0147368907928467, 1.2980396747589111, 1.2360100746154785, 1.2606819868087769, 1.4546879529953003, 1.371580958366394, 1.448682427406311, 1.5729875564575195, 1.1642552614212036, 1.5167732238769531, 1.7122015953063965, 1.826524257659912, 1.8238062858581543, 1.8046205043792725, 1.9164328575134277, 1.9257711172103882, 1.9524401426315308, 1.732930064201355, 1.8628476858139038, 2.0144410133361816, 1.818402647972107, 1.906886339187622, 1.8990275859832764, 1.5757380723953247, 1.6217955350875854, 1.8689430952072144, 1.8903311491012573, 2.071150302886963, 2.1072182655334473, 1.9978240728378296, 2.0996203422546387, 2.164705276489258, 2.1529762744903564, 2.091508150100708, 1.9475743770599365, 1.8737001419067383, 1.8479944467544556, 1.9264845848083496, 1.913933277130127, 1.9802906513214111, 2.1090238094329834, 2.2922606468200684, 1.6926769018173218, 1.90903639793396, 1.974401831626892, 2.206888437271118, 2.054936408996582, 2.1697568893432617, 2.099593162536621, 2.2084341049194336, 2.3013579845428467, 2.110847234725952, 2.0837104320526123, 2.0166618824005127, 2.2346630096435547, 1.9792191982269287, 1.9060057401657104, 2.0116114616394043, 2.2054247856140137, 2.2546868324279785, 2.2771334648132324, 2.2380762100219727, 2.1863715648651123, 2.2325570583343506, 2.1624889373779297, 2.0988709926605225, 2.116250514984131, 2.231966018676758, 2.0839765071868896, 2.1731176376342773, 2.2723963260650635, 2.038827657699585, 1.944606065750122, 2.112514019012451, 1.893127679824829, 1.7941654920578003, 1.9733726978302002, 2.0079843997955322], 'val_accuracy': [0.48275861144065857, 0.48491379618644714, 0.48491379618644714, 0.6034482717514038, 0.6217672228813171, 0.5549569129943848, 0.5463362336158752, 0.610991358757019, 0.5528017282485962, 0.5948275923728943, 0.5614224076271057, 0.576508641242981, 0.6056034564971924, 0.5840517282485962, 0.5743534564971924, 0.6056034564971924, 0.6056034564971924, 0.6174569129943848, 0.6142241358757019, 0.625, 0.6056034564971924, 0.6174569129943848, 0.6206896305084229, 0.6023706793785095, 0.6336206793785095, 0.6206896305084229, 0.6217672228813171, 0.6282327771186829, 0.6153017282485962, 0.6142241358757019, 0.6196120977401733, 0.6088362336158752, 0.6088362336158752, 0.6120689511299133, 0.6196120977401733, 0.6228448152542114, 0.6228448152542114, 0.6282327771186829, 0.6088362336158752, 0.6056034564971924, 0.6271551847457886, 0.6206896305084229, 0.6131465435028076, 0.6131465435028076, 0.6346982717514038, 0.6336206793785095, 0.6153017282485962, 0.6142241358757019, 0.6239224076271057, 0.6174569129943848, 0.6163793206214905, 0.6066810488700867, 0.6206896305084229, 0.6217672228813171, 0.6012930870056152, 0.631465494632721, 0.6271551847457886, 0.6282327771186829, 0.6088362336158752, 0.5980603694915771, 0.6336206793785095, 0.6142241358757019, 0.6196120977401733, 0.618534505367279, 0.6260775923728943, 0.6066810488700867, 0.6163793206214905, 0.618534505367279, 0.618534505367279, 0.6303879022598267, 0.6325430870056152, 0.6293103694915771, 0.6217672228813171, 0.6282327771186829, 0.6163793206214905, 0.6174569129943848, 0.6023706793785095, 0.6066810488700867, 0.6303879022598267, 0.6153017282485962, 0.631465494632721, 0.6293103694915771, 0.6196120977401733, 0.6206896305084229, 0.6271551847457886, 0.6131465435028076, 0.6163793206214905, 0.618534505367279, 0.6174569129943848, 0.6239224076271057, 0.631465494632721, 0.6153017282485962, 0.6260775923728943, 0.6325430870056152, 0.6303879022598267, 0.6163793206214905, 0.6336206793785095, 0.6325430870056152, 0.6293103694915771, 0.631465494632721]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.6801 - accuracy: 0.5872"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 9s 60ms/step - loss: 0.6801 - accuracy: 0.5872 - val_loss: 0.6987 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6394 - accuracy: 0.6452 - val_loss: 0.6994 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6082 - accuracy: 0.6797 - val_loss: 0.6998 - val_accuracy: 0.6007\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5769 - accuracy: 0.7066 - val_loss: 0.6999 - val_accuracy: 0.6199\n","Epoch 5/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5500 - accuracy: 0.7269 - val_loss: 0.6999 - val_accuracy: 0.5317\n","Epoch 6/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5187 - accuracy: 0.7499 - val_loss: 0.6993 - val_accuracy: 0.5464\n","Epoch 7/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4737 - accuracy: 0.7847 - val_loss: 0.6990 - val_accuracy: 0.5486\n","Epoch 8/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4645 - accuracy: 0.7835 - val_loss: 0.6982 - val_accuracy: 0.5373\n","Epoch 9/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4074 - accuracy: 0.8192 - val_loss: 0.6957 - val_accuracy: 0.5577\n","Epoch 10/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3818 - accuracy: 0.8328 - val_loss: 0.6941 - val_accuracy: 0.5452\n","Epoch 11/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3700 - accuracy: 0.8435 - val_loss: 0.6914 - val_accuracy: 0.5735\n","Epoch 12/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3175 - accuracy: 0.8718 - val_loss: 0.6925 - val_accuracy: 0.5464\n","Epoch 13/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3072 - accuracy: 0.8763 - val_loss: 0.6856 - val_accuracy: 0.5701\n","Epoch 14/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2718 - accuracy: 0.8964 - val_loss: 0.7054 - val_accuracy: 0.5520\n","Epoch 15/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2581 - accuracy: 0.8967 - val_loss: 0.7012 - val_accuracy: 0.5633\n","Epoch 16/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2031 - accuracy: 0.9259 - val_loss: 0.7081 - val_accuracy: 0.5690\n","Epoch 17/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1917 - accuracy: 0.9312 - val_loss: 0.7766 - val_accuracy: 0.5622\n","Epoch 18/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1775 - accuracy: 0.9394 - val_loss: 0.7497 - val_accuracy: 0.5848\n","Epoch 19/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1660 - accuracy: 0.9414 - val_loss: 0.7692 - val_accuracy: 0.6018\n","Epoch 20/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1562 - accuracy: 0.9454 - val_loss: 0.7648 - val_accuracy: 0.6120\n","Epoch 21/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1380 - accuracy: 0.9539 - val_loss: 0.8353 - val_accuracy: 0.6075\n","Epoch 22/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1424 - accuracy: 0.9502 - val_loss: 0.8877 - val_accuracy: 0.6029\n","Epoch 23/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1327 - accuracy: 0.9556 - val_loss: 0.9881 - val_accuracy: 0.5905\n","Epoch 24/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1402 - accuracy: 0.9516 - val_loss: 0.9791 - val_accuracy: 0.6199\n","Epoch 25/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1221 - accuracy: 0.9626 - val_loss: 1.0566 - val_accuracy: 0.6199\n","Epoch 26/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0916 - accuracy: 0.9743 - val_loss: 1.2170 - val_accuracy: 0.6063\n","Epoch 27/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.0998 - accuracy: 0.9686 - val_loss: 1.2940 - val_accuracy: 0.6233\n","Epoch 28/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.1318 - accuracy: 0.9567 - val_loss: 1.3775 - val_accuracy: 0.6301\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1061 - accuracy: 0.9675 - val_loss: 1.4311 - val_accuracy: 0.6029\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1110 - accuracy: 0.9658 - val_loss: 1.4266 - val_accuracy: 0.6256\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0715 - accuracy: 0.9813 - val_loss: 1.6586 - val_accuracy: 0.6120\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1036 - accuracy: 0.9646 - val_loss: 1.5698 - val_accuracy: 0.6007\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1243 - accuracy: 0.9559 - val_loss: 1.4961 - val_accuracy: 0.6029\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0826 - accuracy: 0.9791 - val_loss: 1.5994 - val_accuracy: 0.6063\n","Epoch 35/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0691 - accuracy: 0.9825 - val_loss: 1.7699 - val_accuracy: 0.6324\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0688 - accuracy: 0.9802 - val_loss: 1.6848 - val_accuracy: 0.6131\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0598 - accuracy: 0.9827 - val_loss: 1.8969 - val_accuracy: 0.6210\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0604 - accuracy: 0.9870 - val_loss: 1.8966 - val_accuracy: 0.6075\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0836 - accuracy: 0.9765 - val_loss: 1.7111 - val_accuracy: 0.6301\n","Epoch 40/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0661 - accuracy: 0.9822 - val_loss: 1.8456 - val_accuracy: 0.6210\n","Epoch 41/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0508 - accuracy: 0.9875 - val_loss: 1.7883 - val_accuracy: 0.6154\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0430 - accuracy: 0.9912 - val_loss: 2.0016 - val_accuracy: 0.6109\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0347 - accuracy: 0.9943 - val_loss: 2.0704 - val_accuracy: 0.6278\n","Epoch 44/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0501 - accuracy: 0.9892 - val_loss: 2.0984 - val_accuracy: 0.6063\n","Epoch 45/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0772 - accuracy: 0.9782 - val_loss: 1.8255 - val_accuracy: 0.6335\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0969 - accuracy: 0.9686 - val_loss: 1.6250 - val_accuracy: 0.6097\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0667 - accuracy: 0.9813 - val_loss: 1.6064 - val_accuracy: 0.6244\n","Epoch 48/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0574 - accuracy: 0.9853 - val_loss: 1.9926 - val_accuracy: 0.6391\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0733 - accuracy: 0.9771 - val_loss: 1.6918 - val_accuracy: 0.6244\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0470 - accuracy: 0.9878 - val_loss: 1.9027 - val_accuracy: 0.6312\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0382 - accuracy: 0.9924 - val_loss: 1.9954 - val_accuracy: 0.6278\n","Epoch 52/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0304 - accuracy: 0.9958 - val_loss: 2.0999 - val_accuracy: 0.6244\n","Epoch 53/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0243 - accuracy: 0.9980 - val_loss: 2.1554 - val_accuracy: 0.6131\n","Epoch 54/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0248 - accuracy: 0.9972 - val_loss: 2.1710 - val_accuracy: 0.6131\n","Epoch 55/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0290 - accuracy: 0.9955 - val_loss: 2.1140 - val_accuracy: 0.6143\n","Epoch 56/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0400 - accuracy: 0.9921 - val_loss: 2.2229 - val_accuracy: 0.5995\n","Epoch 57/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0496 - accuracy: 0.9878 - val_loss: 2.1723 - val_accuracy: 0.5916\n","Epoch 58/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1519 - accuracy: 0.9465 - val_loss: 1.3788 - val_accuracy: 0.6109\n","Epoch 59/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0693 - accuracy: 0.9805 - val_loss: 1.7434 - val_accuracy: 0.6154\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0310 - accuracy: 0.9966 - val_loss: 1.9117 - val_accuracy: 0.6244\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0331 - accuracy: 0.9946 - val_loss: 1.9783 - val_accuracy: 0.6086\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0420 - accuracy: 0.9887 - val_loss: 1.9248 - val_accuracy: 0.6301\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0391 - accuracy: 0.9912 - val_loss: 1.9745 - val_accuracy: 0.6210\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0313 - accuracy: 0.9952 - val_loss: 2.0590 - val_accuracy: 0.6120\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0528 - accuracy: 0.9864 - val_loss: 2.0436 - val_accuracy: 0.6086\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0403 - accuracy: 0.9926 - val_loss: 1.9523 - val_accuracy: 0.6063\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0411 - accuracy: 0.9904 - val_loss: 1.9813 - val_accuracy: 0.6357\n","Epoch 68/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0336 - accuracy: 0.9960 - val_loss: 2.0254 - val_accuracy: 0.6109\n","Epoch 69/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0278 - accuracy: 0.9955 - val_loss: 2.2130 - val_accuracy: 0.5928\n","Epoch 70/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0272 - accuracy: 0.9955 - val_loss: 2.0724 - val_accuracy: 0.6120\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0223 - accuracy: 0.9980 - val_loss: 2.0736 - val_accuracy: 0.6086\n","Epoch 72/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0233 - accuracy: 0.9977 - val_loss: 2.3663 - val_accuracy: 0.6063\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0225 - accuracy: 0.9986 - val_loss: 2.2336 - val_accuracy: 0.6380\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0292 - accuracy: 0.9952 - val_loss: 2.4171 - val_accuracy: 0.6109\n","Epoch 75/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0246 - accuracy: 0.9960 - val_loss: 2.2814 - val_accuracy: 0.6063\n","Epoch 76/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0343 - accuracy: 0.9929 - val_loss: 2.1557 - val_accuracy: 0.5962\n","Epoch 77/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0527 - accuracy: 0.9859 - val_loss: 1.9782 - val_accuracy: 0.6041\n","Epoch 78/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0484 - accuracy: 0.9864 - val_loss: 1.9290 - val_accuracy: 0.6120\n","Epoch 79/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0488 - accuracy: 0.9861 - val_loss: 1.9824 - val_accuracy: 0.6154\n","Epoch 80/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0716 - accuracy: 0.9774 - val_loss: 2.0766 - val_accuracy: 0.5995\n","Epoch 81/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0394 - accuracy: 0.9918 - val_loss: 1.9682 - val_accuracy: 0.6086\n","Epoch 82/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0247 - accuracy: 0.9958 - val_loss: 2.0622 - val_accuracy: 0.6097\n","Epoch 83/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0195 - accuracy: 0.9986 - val_loss: 2.1672 - val_accuracy: 0.6041\n","Epoch 84/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0189 - accuracy: 0.9989 - val_loss: 2.2260 - val_accuracy: 0.6165\n","Epoch 85/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0190 - accuracy: 0.9986 - val_loss: 2.1587 - val_accuracy: 0.6335\n","Epoch 86/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0187 - accuracy: 0.9989 - val_loss: 2.1510 - val_accuracy: 0.6312\n","Epoch 87/100\n","28/28 [==============================] - 1s 39ms/step - loss: 0.0164 - accuracy: 0.9994 - val_loss: 2.1777 - val_accuracy: 0.6188\n","Epoch 88/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0153 - accuracy: 0.9997 - val_loss: 2.2051 - val_accuracy: 0.6165\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0187 - accuracy: 0.9986 - val_loss: 2.1652 - val_accuracy: 0.6165\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0160 - accuracy: 0.9997 - val_loss: 2.1601 - val_accuracy: 0.6165\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0150 - accuracy: 0.9997 - val_loss: 2.1460 - val_accuracy: 0.6222\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0163 - accuracy: 0.9992 - val_loss: 2.0758 - val_accuracy: 0.6199\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0185 - accuracy: 0.9977 - val_loss: 2.2040 - val_accuracy: 0.6165\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0327 - accuracy: 0.9926 - val_loss: 2.1332 - val_accuracy: 0.6097\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0330 - accuracy: 0.9935 - val_loss: 2.0977 - val_accuracy: 0.6097\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0364 - accuracy: 0.9912 - val_loss: 2.1787 - val_accuracy: 0.6007\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0410 - accuracy: 0.9901 - val_loss: 2.1834 - val_accuracy: 0.5995\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0719 - accuracy: 0.9793 - val_loss: 1.8241 - val_accuracy: 0.6097\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0750 - accuracy: 0.9751 - val_loss: 1.5263 - val_accuracy: 0.6222\n","Epoch 100/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0352 - accuracy: 0.9921 - val_loss: 1.8426 - val_accuracy: 0.6086\n","{'loss': [0.6801192164421082, 0.6393501162528992, 0.6081901788711548, 0.57685786485672, 0.5500165820121765, 0.5187254548072815, 0.4736514687538147, 0.4645290672779083, 0.4074036478996277, 0.38178780674934387, 0.37003326416015625, 0.31748509407043457, 0.30719274282455444, 0.27182087302207947, 0.25813236832618713, 0.2030908316373825, 0.19165225327014923, 0.17753173410892487, 0.16595961153507233, 0.15619462728500366, 0.1380382925271988, 0.14240214228630066, 0.13267356157302856, 0.14019377529621124, 0.12209413200616837, 0.09159490466117859, 0.09979168325662613, 0.1318328082561493, 0.10612107813358307, 0.1110449731349945, 0.07148556411266327, 0.10360325127840042, 0.12427954375743866, 0.08263901621103287, 0.06905034929513931, 0.06879101693630219, 0.05980866774916649, 0.06044706329703331, 0.08357517421245575, 0.06606513261795044, 0.050814107060432434, 0.04302683100104332, 0.03471314162015915, 0.05010784789919853, 0.07722365111112595, 0.09692467749118805, 0.06673634052276611, 0.0574343316257, 0.07330462336540222, 0.04695018753409386, 0.038238465785980225, 0.030372316017746925, 0.024328110739588737, 0.02481154166162014, 0.029035402461886406, 0.040044717490673065, 0.04958372563123703, 0.1519402712583542, 0.06933999806642532, 0.030994074419140816, 0.033121973276138306, 0.041971705853939056, 0.03913373872637749, 0.031342536211013794, 0.05278113856911659, 0.04025055840611458, 0.04113972932100296, 0.03361484408378601, 0.027799496427178383, 0.027201570570468903, 0.022262241691350937, 0.023290522396564484, 0.02246059477329254, 0.029169509187340736, 0.024559268727898598, 0.034302663058042526, 0.05267177149653435, 0.04835923761129379, 0.048805054277181625, 0.07155236601829529, 0.03939542919397354, 0.024673456326127052, 0.01950889267027378, 0.018894849345088005, 0.019023537635803223, 0.018663207069039345, 0.0163635965436697, 0.015320813283324242, 0.018744079396128654, 0.01604059524834156, 0.015040903352200985, 0.01633775420486927, 0.018507661297917366, 0.03269317373633385, 0.0330289825797081, 0.03636763244867325, 0.04100719839334488, 0.0719461739063263, 0.07495832443237305, 0.035163551568984985], 'accuracy': [0.5871533751487732, 0.6451612710952759, 0.6796830892562866, 0.7065647840499878, 0.7269383072853088, 0.7498584985733032, 0.7846632599830627, 0.7835314273834229, 0.8191850781440735, 0.8327674269676208, 0.8435201048851013, 0.8718166351318359, 0.8763440847396851, 0.8964346647262573, 0.8967176079750061, 0.9258630275726318, 0.9312393665313721, 0.9394453763961792, 0.941426157951355, 0.9453876614570618, 0.9538766145706177, 0.9501980543136597, 0.9555743932723999, 0.9516128897666931, 0.9626485705375671, 0.9742501378059387, 0.9685908555984497, 0.9567062854766846, 0.967458963394165, 0.9657611846923828, 0.9813242554664612, 0.9646292924880981, 0.9558573961257935, 0.9790605306625366, 0.9824561476707458, 0.9801924228668213, 0.9827390909194946, 0.986983597278595, 0.9765138626098633, 0.9821732044219971, 0.9875495433807373, 0.9912280440330505, 0.994340717792511, 0.9892473220825195, 0.9782116413116455, 0.9685908555984497, 0.9813242554664612, 0.9852858185768127, 0.9770798087120056, 0.9878324866294861, 0.9923599362373352, 0.9957554936408997, 0.9980192184448242, 0.9971703290939331, 0.9954725503921509, 0.9920769929885864, 0.9878324866294861, 0.9465195536613464, 0.9804753661155701, 0.9966044425964355, 0.9946236610412598, 0.9886813759803772, 0.9912280440330505, 0.9951896071434021, 0.9864176511764526, 0.992642879486084, 0.9903791546821594, 0.9960384964942932, 0.9954725503921509, 0.9954725503921509, 0.9980192184448242, 0.9977362751960754, 0.9985851645469666, 0.9951896071434021, 0.9960384964942932, 0.9929258823394775, 0.9858517050743103, 0.9864176511764526, 0.9861347079277039, 0.9773627519607544, 0.9917939901351929, 0.9957554936408997, 0.9985851645469666, 0.9988681674003601, 0.9985851645469666, 0.9988681674003601, 0.9994340538978577, 0.9997170567512512, 0.9985851645469666, 0.9997170567512512, 0.9997170567512512, 0.9991511106491089, 0.9977362751960754, 0.992642879486084, 0.9934917688369751, 0.9912280440330505, 0.9900962114334106, 0.9793435335159302, 0.9750990271568298, 0.9920769929885864], 'val_loss': [0.6987236738204956, 0.6993910074234009, 0.6997948288917542, 0.6998623609542847, 0.699853777885437, 0.6993407011032104, 0.6990364789962769, 0.6982203125953674, 0.6956673264503479, 0.6940597891807556, 0.6913631558418274, 0.6924564838409424, 0.6855831742286682, 0.7053987383842468, 0.7012218236923218, 0.7080692052841187, 0.776619017124176, 0.7496758103370667, 0.7691668272018433, 0.7647510766983032, 0.8353061676025391, 0.887719452381134, 0.9880537390708923, 0.9790750741958618, 1.0566273927688599, 1.217036485671997, 1.2940291166305542, 1.3775228261947632, 1.4310994148254395, 1.4266456365585327, 1.658602237701416, 1.5697927474975586, 1.496111512184143, 1.5994129180908203, 1.7698723077774048, 1.6847935914993286, 1.8968520164489746, 1.8965882062911987, 1.7110716104507446, 1.8455917835235596, 1.7883028984069824, 2.001577138900757, 2.0704033374786377, 2.0983669757843018, 1.8254766464233398, 1.6250079870224, 1.606366753578186, 1.9925780296325684, 1.6918176412582397, 1.902747392654419, 1.995436668395996, 2.099928140640259, 2.155383586883545, 2.1710360050201416, 2.11397123336792, 2.222943067550659, 2.1723411083221436, 1.3787562847137451, 1.7433565855026245, 1.9117285013198853, 1.9783262014389038, 1.92478609085083, 1.9745397567749023, 2.0589654445648193, 2.0435895919799805, 1.9522855281829834, 1.9812595844268799, 2.0253522396087646, 2.213015556335449, 2.0724494457244873, 2.0735714435577393, 2.366328477859497, 2.2335948944091797, 2.4170515537261963, 2.2813880443573, 2.155674457550049, 1.9781991243362427, 1.9289870262145996, 1.9824053049087524, 2.0765762329101562, 1.9681761264801025, 2.062161922454834, 2.167207717895508, 2.226029634475708, 2.158712863922119, 2.150956869125366, 2.177701473236084, 2.205146074295044, 2.1652450561523438, 2.160109519958496, 2.145995616912842, 2.0758087635040283, 2.2039918899536133, 2.133232593536377, 2.0976743698120117, 2.1787445545196533, 2.183408737182617, 1.824054479598999, 1.5262560844421387, 1.8426107168197632], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.6006787419319153, 0.6199095249176025, 0.5316742062568665, 0.5463801026344299, 0.5486425161361694, 0.5373303294181824, 0.557692289352417, 0.5452488660812378, 0.5735294222831726, 0.5463801026344299, 0.570135772228241, 0.5520362257957458, 0.5633484125137329, 0.5690045356750488, 0.5622171759605408, 0.5848416090011597, 0.6018099784851074, 0.6119909286499023, 0.6074660420417786, 0.6029411554336548, 0.5904977321624756, 0.6199095249176025, 0.6199095249176025, 0.6063348650932312, 0.6233031749725342, 0.6300904750823975, 0.6029411554336548, 0.6255655884742737, 0.6119909286499023, 0.6006787419319153, 0.6029411554336548, 0.6063348650932312, 0.6323529481887817, 0.6131221652030945, 0.6210407018661499, 0.6074660420417786, 0.6300904750823975, 0.6210407018661499, 0.6153846383094788, 0.610859751701355, 0.627828061580658, 0.6063348650932312, 0.6334841847419739, 0.6097285151481628, 0.6244344115257263, 0.639140248298645, 0.6244344115257263, 0.6312217116355896, 0.627828061580658, 0.6244344115257263, 0.6131221652030945, 0.6131221652030945, 0.6142534017562866, 0.5995475053787231, 0.5916289687156677, 0.610859751701355, 0.6153846383094788, 0.6244344115257263, 0.6085972785949707, 0.6300904750823975, 0.6210407018661499, 0.6119909286499023, 0.6085972785949707, 0.6063348650932312, 0.6357465982437134, 0.610859751701355, 0.5927602052688599, 0.6119909286499023, 0.6085972785949707, 0.6063348650932312, 0.6380090713500977, 0.610859751701355, 0.6063348650932312, 0.5961538553237915, 0.6040723919868469, 0.6119909286499023, 0.6153846383094788, 0.5995475053787231, 0.6085972785949707, 0.6097285151481628, 0.6040723919868469, 0.6165158152580261, 0.6334841847419739, 0.6312217116355896, 0.6187782883644104, 0.6165158152580261, 0.6165158152580261, 0.6165158152580261, 0.622171938419342, 0.6199095249176025, 0.6165158152580261, 0.6097285151481628, 0.6097285151481628, 0.6006787419319153, 0.5995475053787231, 0.6097285151481628, 0.622171938419342, 0.6085972785949707]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 8s 50ms/step - loss: 0.6852 - accuracy: 0.5765 - val_loss: 0.6989 - val_accuracy: 0.4855\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6528 - accuracy: 0.6271 - val_loss: 0.6995 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6324 - accuracy: 0.6463 - val_loss: 0.6995 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6157 - accuracy: 0.6654 - val_loss: 0.6992 - val_accuracy: 0.4928\n","Epoch 5/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6097 - accuracy: 0.6718 - val_loss: 0.6990 - val_accuracy: 0.5021\n","Epoch 6/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5842 - accuracy: 0.6977 - val_loss: 0.6972 - val_accuracy: 0.5950\n","Epoch 7/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5682 - accuracy: 0.7062 - val_loss: 0.6968 - val_accuracy: 0.6074\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5507 - accuracy: 0.7191 - val_loss: 0.6948 - val_accuracy: 0.6033\n","Epoch 9/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5070 - accuracy: 0.7514 - val_loss: 0.6919 - val_accuracy: 0.5930\n","Epoch 10/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4953 - accuracy: 0.7628 - val_loss: 0.6908 - val_accuracy: 0.5651\n","Epoch 11/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4572 - accuracy: 0.7850 - val_loss: 0.6856 - val_accuracy: 0.5548\n","Epoch 12/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4380 - accuracy: 0.7977 - val_loss: 0.6831 - val_accuracy: 0.5744\n","Epoch 13/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4054 - accuracy: 0.8158 - val_loss: 0.6746 - val_accuracy: 0.5992\n","Epoch 14/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3717 - accuracy: 0.8413 - val_loss: 0.6568 - val_accuracy: 0.6426\n","Epoch 15/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3921 - accuracy: 0.8227 - val_loss: 0.6580 - val_accuracy: 0.6198\n","Epoch 16/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3195 - accuracy: 0.8669 - val_loss: 0.7194 - val_accuracy: 0.5496\n","Epoch 17/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3317 - accuracy: 0.8656 - val_loss: 0.6402 - val_accuracy: 0.6446\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2608 - accuracy: 0.8992 - val_loss: 0.6832 - val_accuracy: 0.6002\n","Epoch 19/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2631 - accuracy: 0.8920 - val_loss: 0.6952 - val_accuracy: 0.6167\n","Epoch 20/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2625 - accuracy: 0.8964 - val_loss: 0.6641 - val_accuracy: 0.6560\n","Epoch 21/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2322 - accuracy: 0.9083 - val_loss: 0.8027 - val_accuracy: 0.6095\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2941 - accuracy: 0.8749 - val_loss: 0.6862 - val_accuracy: 0.6415\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1841 - accuracy: 0.9315 - val_loss: 0.8080 - val_accuracy: 0.6446\n","Epoch 24/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1599 - accuracy: 0.9406 - val_loss: 1.0263 - val_accuracy: 0.6333\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1935 - accuracy: 0.9274 - val_loss: 0.9453 - val_accuracy: 0.6384\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1696 - accuracy: 0.9364 - val_loss: 0.9994 - val_accuracy: 0.6498\n","Epoch 27/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1369 - accuracy: 0.9481 - val_loss: 1.2275 - val_accuracy: 0.6198\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1151 - accuracy: 0.9638 - val_loss: 1.1684 - val_accuracy: 0.6508\n","Epoch 29/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1421 - accuracy: 0.9514 - val_loss: 1.1550 - val_accuracy: 0.6570\n","Epoch 30/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2303 - accuracy: 0.9049 - val_loss: 1.0006 - val_accuracy: 0.6519\n","Epoch 31/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1358 - accuracy: 0.9519 - val_loss: 1.1634 - val_accuracy: 0.6653\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1364 - accuracy: 0.9517 - val_loss: 1.1530 - val_accuracy: 0.6612\n","Epoch 33/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.1047 - accuracy: 0.9638 - val_loss: 1.2939 - val_accuracy: 0.6725\n","Epoch 34/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1110 - accuracy: 0.9599 - val_loss: 1.3484 - val_accuracy: 0.6488\n","Epoch 35/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0876 - accuracy: 0.9736 - val_loss: 1.7895 - val_accuracy: 0.6302\n","Epoch 36/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1058 - accuracy: 0.9641 - val_loss: 1.3336 - val_accuracy: 0.6498\n","Epoch 37/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1093 - accuracy: 0.9636 - val_loss: 1.3675 - val_accuracy: 0.6663\n","Epoch 38/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0934 - accuracy: 0.9682 - val_loss: 1.4551 - val_accuracy: 0.6570\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0865 - accuracy: 0.9742 - val_loss: 1.5370 - val_accuracy: 0.6529\n","Epoch 40/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0714 - accuracy: 0.9778 - val_loss: 1.6759 - val_accuracy: 0.6508\n","Epoch 41/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0682 - accuracy: 0.9801 - val_loss: 1.7531 - val_accuracy: 0.6467\n","Epoch 42/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1084 - accuracy: 0.9654 - val_loss: 1.4530 - val_accuracy: 0.6622\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1732 - accuracy: 0.9336 - val_loss: 1.1795 - val_accuracy: 0.6560\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0928 - accuracy: 0.9693 - val_loss: 1.4797 - val_accuracy: 0.6570\n","Epoch 45/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0597 - accuracy: 0.9827 - val_loss: 1.6663 - val_accuracy: 0.6529\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0586 - accuracy: 0.9829 - val_loss: 1.6357 - val_accuracy: 0.6508\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0598 - accuracy: 0.9858 - val_loss: 1.7126 - val_accuracy: 0.6519\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0609 - accuracy: 0.9819 - val_loss: 1.6394 - val_accuracy: 0.6601\n","Epoch 49/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0771 - accuracy: 0.9747 - val_loss: 2.2199 - val_accuracy: 0.6043\n","Epoch 50/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1108 - accuracy: 0.9610 - val_loss: 1.4128 - val_accuracy: 0.6674\n","Epoch 51/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0581 - accuracy: 0.9835 - val_loss: 1.5786 - val_accuracy: 0.6622\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0460 - accuracy: 0.9891 - val_loss: 1.6682 - val_accuracy: 0.6725\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0444 - accuracy: 0.9904 - val_loss: 1.6380 - val_accuracy: 0.6684\n","Epoch 54/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0602 - accuracy: 0.9827 - val_loss: 1.7295 - val_accuracy: 0.6684\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0834 - accuracy: 0.9718 - val_loss: 1.5005 - val_accuracy: 0.6601\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0566 - accuracy: 0.9845 - val_loss: 1.6351 - val_accuracy: 0.6643\n","Epoch 57/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0447 - accuracy: 0.9894 - val_loss: 1.6826 - val_accuracy: 0.6632\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0441 - accuracy: 0.9894 - val_loss: 1.8182 - val_accuracy: 0.6560\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0838 - accuracy: 0.9734 - val_loss: 1.9338 - val_accuracy: 0.6364\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1306 - accuracy: 0.9537 - val_loss: 1.4396 - val_accuracy: 0.6250\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1407 - accuracy: 0.9499 - val_loss: 1.1563 - val_accuracy: 0.6684\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0642 - accuracy: 0.9806 - val_loss: 1.5473 - val_accuracy: 0.6570\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0432 - accuracy: 0.9917 - val_loss: 1.8828 - val_accuracy: 0.6374\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0427 - accuracy: 0.9876 - val_loss: 1.6563 - val_accuracy: 0.6684\n","Epoch 65/100\n","31/31 [==============================] - 2s 56ms/step - loss: 0.0335 - accuracy: 0.9935 - val_loss: 1.7404 - val_accuracy: 0.6787\n","Epoch 66/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0383 - accuracy: 0.9910 - val_loss: 1.9885 - val_accuracy: 0.6488\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0554 - accuracy: 0.9860 - val_loss: 1.5303 - val_accuracy: 0.6632\n","Epoch 68/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0482 - accuracy: 0.9884 - val_loss: 1.7403 - val_accuracy: 0.6715\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0493 - accuracy: 0.9868 - val_loss: 1.9089 - val_accuracy: 0.6477\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1038 - accuracy: 0.9682 - val_loss: 1.4912 - val_accuracy: 0.6384\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0483 - accuracy: 0.9873 - val_loss: 1.6756 - val_accuracy: 0.6653\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0365 - accuracy: 0.9917 - val_loss: 1.7799 - val_accuracy: 0.6560\n","Epoch 73/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0479 - accuracy: 0.9868 - val_loss: 2.0035 - val_accuracy: 0.6426\n","Epoch 74/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0553 - accuracy: 0.9824 - val_loss: 1.8386 - val_accuracy: 0.6591\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0509 - accuracy: 0.9871 - val_loss: 1.6570 - val_accuracy: 0.6612\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0633 - accuracy: 0.9804 - val_loss: 1.6109 - val_accuracy: 0.6643\n","Epoch 77/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0415 - accuracy: 0.9902 - val_loss: 1.6431 - val_accuracy: 0.6643\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0377 - accuracy: 0.9907 - val_loss: 1.8221 - val_accuracy: 0.6591\n","Epoch 79/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0271 - accuracy: 0.9964 - val_loss: 1.7706 - val_accuracy: 0.6653\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0243 - accuracy: 0.9964 - val_loss: 1.8274 - val_accuracy: 0.6694\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0222 - accuracy: 0.9979 - val_loss: 1.8918 - val_accuracy: 0.6684\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0211 - accuracy: 0.9987 - val_loss: 1.9567 - val_accuracy: 0.6529\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0227 - accuracy: 0.9969 - val_loss: 1.9046 - val_accuracy: 0.6725\n","Epoch 84/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0271 - accuracy: 0.9956 - val_loss: 2.2047 - val_accuracy: 0.6395\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0355 - accuracy: 0.9922 - val_loss: 1.7561 - val_accuracy: 0.6694\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0361 - accuracy: 0.9912 - val_loss: 1.9376 - val_accuracy: 0.6508\n","Epoch 87/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0514 - accuracy: 0.9848 - val_loss: 1.7349 - val_accuracy: 0.6736\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0471 - accuracy: 0.9871 - val_loss: 1.6932 - val_accuracy: 0.6612\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0509 - accuracy: 0.9835 - val_loss: 1.5665 - val_accuracy: 0.6653\n","Epoch 90/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0511 - accuracy: 0.9863 - val_loss: 1.6391 - val_accuracy: 0.6457\n","Epoch 91/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0343 - accuracy: 0.9920 - val_loss: 1.6529 - val_accuracy: 0.6560\n","Epoch 92/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0274 - accuracy: 0.9951 - val_loss: 1.7640 - val_accuracy: 0.6612\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0226 - accuracy: 0.9972 - val_loss: 1.8383 - val_accuracy: 0.6488\n","Epoch 94/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0196 - accuracy: 0.9984 - val_loss: 1.8874 - val_accuracy: 0.6674\n","Epoch 95/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0216 - accuracy: 0.9966 - val_loss: 1.9314 - val_accuracy: 0.6612\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0246 - accuracy: 0.9953 - val_loss: 1.9063 - val_accuracy: 0.6653\n","Epoch 97/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0813 - accuracy: 0.9749 - val_loss: 1.6928 - val_accuracy: 0.6467\n","Epoch 98/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0934 - accuracy: 0.9698 - val_loss: 1.4890 - val_accuracy: 0.6405\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0573 - accuracy: 0.9824 - val_loss: 1.6391 - val_accuracy: 0.6446\n","Epoch 100/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0606 - accuracy: 0.9827 - val_loss: 1.4361 - val_accuracy: 0.6508\n","{'loss': [0.6852356195449829, 0.6528080701828003, 0.6323961019515991, 0.6156706809997559, 0.6097238659858704, 0.5842359066009521, 0.5681995153427124, 0.5506746172904968, 0.5069891810417175, 0.4952615797519684, 0.4571700692176819, 0.4379807114601135, 0.40543922781944275, 0.371654212474823, 0.39211124181747437, 0.3194868862628937, 0.331662654876709, 0.2608218193054199, 0.263060063123703, 0.26248109340667725, 0.23218226432800293, 0.2940734028816223, 0.18414099514484406, 0.15989528596401215, 0.19350215792655945, 0.16955064237117767, 0.13686026632785797, 0.11511917412281036, 0.1420840620994568, 0.2302962690591812, 0.1358007937669754, 0.1363857090473175, 0.10470264405012131, 0.1109902560710907, 0.0875861644744873, 0.10578269511461258, 0.10930585861206055, 0.09343075752258301, 0.08654530346393585, 0.07143136858940125, 0.06823821365833282, 0.10841395705938339, 0.1732017993927002, 0.09279435873031616, 0.05967876315116882, 0.05861378461122513, 0.059782665222883224, 0.060867905616760254, 0.0770881325006485, 0.1108405664563179, 0.05812476575374603, 0.046026069670915604, 0.04439746215939522, 0.060161489993333817, 0.08340039849281311, 0.05655091255903244, 0.04470181092619896, 0.04411047697067261, 0.08378537744283676, 0.13057857751846313, 0.14066831767559052, 0.06424614787101746, 0.043233081698417664, 0.04268930107355118, 0.033498313277959824, 0.03825270012021065, 0.05541202798485756, 0.04820000380277634, 0.049263447523117065, 0.10378985852003098, 0.04833192750811577, 0.03648397698998451, 0.04789438098669052, 0.05534374341368675, 0.05087237060070038, 0.06329372525215149, 0.04150089621543884, 0.037706490606069565, 0.02707679755985737, 0.0242646224796772, 0.022177647799253464, 0.02106766402721405, 0.022716807201504707, 0.027141738682985306, 0.035476744174957275, 0.03612922877073288, 0.05137376859784126, 0.047086071223020554, 0.05090594291687012, 0.051118042320013046, 0.034330230206251144, 0.027444474399089813, 0.022635169327259064, 0.01964147388935089, 0.02157476544380188, 0.024584444239735603, 0.0813324823975563, 0.09336724132299423, 0.05731107294559479, 0.06063961982727051], 'accuracy': [0.576485812664032, 0.6271317601203918, 0.646253228187561, 0.6653746962547302, 0.6718346476554871, 0.6976743936538696, 0.7062015533447266, 0.7191214561462402, 0.7514212131500244, 0.7627906799316406, 0.7850129008293152, 0.7976744174957275, 0.8157622814178467, 0.8413436412811279, 0.8227390050888062, 0.866925060749054, 0.8656330704689026, 0.8992248177528381, 0.8919896483421326, 0.8963824510574341, 0.9082687497138977, 0.8749353885650635, 0.9315245747566223, 0.9405684471130371, 0.9273901581764221, 0.9364340901374817, 0.948062002658844, 0.9638242721557617, 0.9514212012290955, 0.9049095511436462, 0.9519379734992981, 0.9516795873641968, 0.9638242721557617, 0.9599483013153076, 0.97364342212677, 0.964082658290863, 0.9635658860206604, 0.9682170748710632, 0.9741601943969727, 0.9777777791023254, 0.9801033735275269, 0.9653746485710144, 0.9335917234420776, 0.9692506194114685, 0.9826873540878296, 0.9829457402229309, 0.985788106918335, 0.9819121360778809, 0.9746770262718201, 0.9609819054603577, 0.9834625124931335, 0.9891473054885864, 0.9904392957687378, 0.9826873540878296, 0.9718345999717712, 0.9844961166381836, 0.9894056916236877, 0.9894056916236877, 0.9733850359916687, 0.9537467956542969, 0.9498708248138428, 0.9806201457977295, 0.9917312860488892, 0.987596869468689, 0.9935400485992432, 0.9909560680389404, 0.9860464930534363, 0.9883720874786377, 0.986821711063385, 0.9682170748710632, 0.9873384833335876, 0.9917312860488892, 0.986821711063385, 0.9824289679527283, 0.9870800971984863, 0.9803617596626282, 0.9901808500289917, 0.9906976819038391, 0.9963824152946472, 0.9963824152946472, 0.9979327917098999, 0.9987080097198486, 0.9968992471694946, 0.9956072568893433, 0.9922480583190918, 0.9912144541740417, 0.9847545027732849, 0.9870800971984863, 0.9834625124931335, 0.9863049387931824, 0.9919896721839905, 0.9950904250144958, 0.997157633304596, 0.9984496235847473, 0.9966408014297485, 0.9953488111495972, 0.9749354124069214, 0.9697674512863159, 0.9824289679527283, 0.9826873540878296], 'val_loss': [0.6988924145698547, 0.6995053291320801, 0.6995001435279846, 0.6991544365882874, 0.6990408301353455, 0.6972434520721436, 0.6968250274658203, 0.694819986820221, 0.6918964385986328, 0.6907783150672913, 0.685565173625946, 0.6831467747688293, 0.6745524406433105, 0.6567535400390625, 0.6580316424369812, 0.7193580269813538, 0.640182375907898, 0.6832347512245178, 0.6952078342437744, 0.664088249206543, 0.8026915192604065, 0.686185896396637, 0.807971179485321, 1.0262739658355713, 0.9453180432319641, 0.9993957281112671, 1.2274889945983887, 1.1683835983276367, 1.154966115951538, 1.0005673170089722, 1.1633552312850952, 1.1530447006225586, 1.2939083576202393, 1.3483799695968628, 1.7894740104675293, 1.3336085081100464, 1.3674930334091187, 1.4550929069519043, 1.5369508266448975, 1.6758936643600464, 1.7531355619430542, 1.4530162811279297, 1.179510235786438, 1.4797158241271973, 1.6662522554397583, 1.6357228755950928, 1.7126331329345703, 1.6394375562667847, 2.2198703289031982, 1.4128137826919556, 1.5785942077636719, 1.6681543588638306, 1.6380094289779663, 1.729502558708191, 1.500527024269104, 1.6351125240325928, 1.682570457458496, 1.8182040452957153, 1.9337735176086426, 1.4395771026611328, 1.1563156843185425, 1.5473209619522095, 1.8827885389328003, 1.6563334465026855, 1.7404197454452515, 1.9885271787643433, 1.5302804708480835, 1.7403452396392822, 1.9088575839996338, 1.4912128448486328, 1.6755753755569458, 1.7799135446548462, 2.003459930419922, 1.8386379480361938, 1.657017469406128, 1.6109200716018677, 1.643092155456543, 1.8220787048339844, 1.7705641984939575, 1.8273910284042358, 1.8917955160140991, 1.956735610961914, 1.904563307762146, 2.2046689987182617, 1.7560847997665405, 1.9375892877578735, 1.734945297241211, 1.693239450454712, 1.566462755203247, 1.639087200164795, 1.6528542041778564, 1.764048457145691, 1.8383464813232422, 1.887434482574463, 1.9314028024673462, 1.906269907951355, 1.6927872896194458, 1.4889905452728271, 1.6391240358352661, 1.436120629310608], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.4927685856819153, 0.5020661354064941, 0.5950413346290588, 0.6074380278587341, 0.6033057570457458, 0.5929751992225647, 0.5650826692581177, 0.5547520518302917, 0.5743801593780518, 0.5991735458374023, 0.6425619721412659, 0.6198347210884094, 0.5495867729187012, 0.64462810754776, 0.6002066135406494, 0.6167355179786682, 0.6559917330741882, 0.6095041036605835, 0.6415289044380188, 0.64462810754776, 0.6332644820213318, 0.6384297609329224, 0.6497933864593506, 0.6198347210884094, 0.6508264541625977, 0.6570248007774353, 0.6518595218658447, 0.6652892827987671, 0.6611570119857788, 0.672520637512207, 0.6487603187561035, 0.6301652789115906, 0.6497933864593506, 0.6663222908973694, 0.6570248007774353, 0.6528925895690918, 0.6508264541625977, 0.6466942429542542, 0.6621900796890259, 0.6559917330741882, 0.6570248007774353, 0.6528925895690918, 0.6508264541625977, 0.6518595218658447, 0.6601239442825317, 0.6043388247489929, 0.6673553586006165, 0.6621900796890259, 0.672520637512207, 0.6683884263038635, 0.6683884263038635, 0.6601239442825317, 0.66425621509552, 0.663223147392273, 0.6559917330741882, 0.6363636255264282, 0.625, 0.6683884263038635, 0.6570248007774353, 0.6373966932296753, 0.6683884263038635, 0.6787189841270447, 0.6487603187561035, 0.663223147392273, 0.6714876294136047, 0.6477272510528564, 0.6384297609329224, 0.6652892827987671, 0.6559917330741882, 0.6425619721412659, 0.6590909361839294, 0.6611570119857788, 0.66425621509552, 0.66425621509552, 0.6590909361839294, 0.6652892827987671, 0.6694214940071106, 0.6683884263038635, 0.6528925895690918, 0.672520637512207, 0.6394628286361694, 0.6694214940071106, 0.6508264541625977, 0.6735537052154541, 0.6611570119857788, 0.6652892827987671, 0.6456611752510071, 0.6559917330741882, 0.6611570119857788, 0.6487603187561035, 0.6673553586006165, 0.6611570119857788, 0.6652892827987671, 0.6466942429542542, 0.6404958963394165, 0.64462810754776, 0.6508264541625977]}\n","32/32 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/29 [========================>.....] - ETA: 0s - loss: 0.2518 - accuracy: 0.9119"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 53ms/step - loss: 0.2383 - accuracy: 0.9170 - val_loss: 0.7019 - val_accuracy: 0.5151\n","Epoch 2/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0966 - accuracy: 0.9723 - val_loss: 0.7013 - val_accuracy: 0.5183\n","Epoch 3/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0669 - accuracy: 0.9790 - val_loss: 0.7006 - val_accuracy: 0.5162\n","Epoch 4/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0582 - accuracy: 0.9795 - val_loss: 0.6960 - val_accuracy: 0.5280\n","Epoch 5/100\n","29/29 [==============================] - 1s 41ms/step - loss: 0.0645 - accuracy: 0.9803 - val_loss: 0.6937 - val_accuracy: 0.5463\n","Epoch 6/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0862 - accuracy: 0.9706 - val_loss: 0.6882 - val_accuracy: 0.5787\n","Epoch 7/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0839 - accuracy: 0.9739 - val_loss: 0.6832 - val_accuracy: 0.5894\n","Epoch 8/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0532 - accuracy: 0.9860 - val_loss: 0.6710 - val_accuracy: 0.6153\n","Epoch 9/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0759 - accuracy: 0.9766 - val_loss: 0.6667 - val_accuracy: 0.6228\n","Epoch 10/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0647 - accuracy: 0.9811 - val_loss: 0.6523 - val_accuracy: 0.6315\n","Epoch 11/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0608 - accuracy: 0.9822 - val_loss: 0.6490 - val_accuracy: 0.6433\n","Epoch 12/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0583 - accuracy: 0.9825 - val_loss: 0.6340 - val_accuracy: 0.6444\n","Epoch 13/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0510 - accuracy: 0.9860 - val_loss: 0.6241 - val_accuracy: 0.6476\n","Epoch 14/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0482 - accuracy: 0.9871 - val_loss: 0.6257 - val_accuracy: 0.6595\n","Epoch 15/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0379 - accuracy: 0.9903 - val_loss: 0.6409 - val_accuracy: 0.6897\n","Epoch 16/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0493 - accuracy: 0.9852 - val_loss: 0.6604 - val_accuracy: 0.6681\n","Epoch 17/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0571 - accuracy: 0.9846 - val_loss: 0.6702 - val_accuracy: 0.6864\n","Epoch 18/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0635 - accuracy: 0.9809 - val_loss: 0.7019 - val_accuracy: 0.6886\n","Epoch 19/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0554 - accuracy: 0.9838 - val_loss: 0.7534 - val_accuracy: 0.6735\n","Epoch 20/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0365 - accuracy: 0.9922 - val_loss: 0.9380 - val_accuracy: 0.6703\n","Epoch 21/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0298 - accuracy: 0.9933 - val_loss: 0.9727 - val_accuracy: 0.6983\n","Epoch 22/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0298 - accuracy: 0.9922 - val_loss: 0.9725 - val_accuracy: 0.7220\n","Epoch 23/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0394 - accuracy: 0.9895 - val_loss: 1.0871 - val_accuracy: 0.7144\n","Epoch 24/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0518 - accuracy: 0.9852 - val_loss: 1.0984 - val_accuracy: 0.7166\n","Epoch 25/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0663 - accuracy: 0.9801 - val_loss: 1.1666 - val_accuracy: 0.7015\n","Epoch 26/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0524 - accuracy: 0.9844 - val_loss: 1.1806 - val_accuracy: 0.7058\n","Epoch 27/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0369 - accuracy: 0.9922 - val_loss: 1.1943 - val_accuracy: 0.7080\n","Epoch 28/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0335 - accuracy: 0.9919 - val_loss: 1.2024 - val_accuracy: 0.7274\n","Epoch 29/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0363 - accuracy: 0.9892 - val_loss: 1.3705 - val_accuracy: 0.7026\n","Epoch 30/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0444 - accuracy: 0.9876 - val_loss: 1.2781 - val_accuracy: 0.7338\n","Epoch 31/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0525 - accuracy: 0.9836 - val_loss: 1.2152 - val_accuracy: 0.7231\n","Epoch 32/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0635 - accuracy: 0.9806 - val_loss: 1.1586 - val_accuracy: 0.7177\n","Epoch 33/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0398 - accuracy: 0.9876 - val_loss: 1.3934 - val_accuracy: 0.6864\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0429 - accuracy: 0.9892 - val_loss: 1.3435 - val_accuracy: 0.7112\n","Epoch 35/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0267 - accuracy: 0.9941 - val_loss: 1.3553 - val_accuracy: 0.7231\n","Epoch 36/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0251 - accuracy: 0.9946 - val_loss: 1.4776 - val_accuracy: 0.7069\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0476 - accuracy: 0.9873 - val_loss: 1.3125 - val_accuracy: 0.7134\n","Epoch 38/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0351 - accuracy: 0.9906 - val_loss: 1.5509 - val_accuracy: 0.6972\n","Epoch 39/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0546 - accuracy: 0.9849 - val_loss: 1.3684 - val_accuracy: 0.7166\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0708 - accuracy: 0.9787 - val_loss: 1.0986 - val_accuracy: 0.7166\n","Epoch 41/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0347 - accuracy: 0.9930 - val_loss: 1.3414 - val_accuracy: 0.7155\n","Epoch 42/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0217 - accuracy: 0.9976 - val_loss: 1.3101 - val_accuracy: 0.7435\n","Epoch 43/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0241 - accuracy: 0.9957 - val_loss: 1.3778 - val_accuracy: 0.7166\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 0.9968 - val_loss: 1.3537 - val_accuracy: 0.7306\n","Epoch 45/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0228 - accuracy: 0.9965 - val_loss: 1.4190 - val_accuracy: 0.7263\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0295 - accuracy: 0.9925 - val_loss: 1.4844 - val_accuracy: 0.7188\n","Epoch 47/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1185 - accuracy: 0.9647 - val_loss: 1.5683 - val_accuracy: 0.6509\n","Epoch 48/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1001 - accuracy: 0.9671 - val_loss: 0.9280 - val_accuracy: 0.7198\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0282 - accuracy: 0.9957 - val_loss: 1.1861 - val_accuracy: 0.7188\n","Epoch 50/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0168 - accuracy: 0.9995 - val_loss: 1.2604 - val_accuracy: 0.7155\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0152 - accuracy: 0.9995 - val_loss: 1.3368 - val_accuracy: 0.7231\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0143 - accuracy: 0.9989 - val_loss: 1.3649 - val_accuracy: 0.7166\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.3675 - val_accuracy: 0.7220\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0127 - accuracy: 0.9997 - val_loss: 1.3914 - val_accuracy: 0.7177\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.4039 - val_accuracy: 0.7188\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.4063 - val_accuracy: 0.7209\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.4022 - val_accuracy: 0.7198\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.3965 - val_accuracy: 0.7241\n","Epoch 59/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.3942 - val_accuracy: 0.7198\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.3982 - val_accuracy: 0.7188\n","Epoch 61/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0126 - accuracy: 0.9995 - val_loss: 1.4098 - val_accuracy: 0.7144\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0133 - accuracy: 0.9992 - val_loss: 1.4798 - val_accuracy: 0.7091\n","Epoch 63/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.4002 - val_accuracy: 0.7112\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0120 - accuracy: 0.9997 - val_loss: 1.3960 - val_accuracy: 0.7198\n","Epoch 65/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.4055 - val_accuracy: 0.7101\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.3973 - val_accuracy: 0.7134\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.3963 - val_accuracy: 0.7144\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.3831 - val_accuracy: 0.7123\n","Epoch 69/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.3739 - val_accuracy: 0.7112\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.3622 - val_accuracy: 0.7177\n","Epoch 71/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.3752 - val_accuracy: 0.7188\n","Epoch 72/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.3521 - val_accuracy: 0.7188\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.3563 - val_accuracy: 0.7231\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.3453 - val_accuracy: 0.7188\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.3425 - val_accuracy: 0.7198\n","Epoch 76/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.3371 - val_accuracy: 0.7209\n","Epoch 77/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.3276 - val_accuracy: 0.7198\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.3413 - val_accuracy: 0.7177\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.3280 - val_accuracy: 0.7198\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.3283 - val_accuracy: 0.7241\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.3236 - val_accuracy: 0.7241\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.3256 - val_accuracy: 0.7241\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.3230 - val_accuracy: 0.7295\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.3171 - val_accuracy: 0.7252\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.3155 - val_accuracy: 0.7274\n","Epoch 86/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.3133 - val_accuracy: 0.7284\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0129 - accuracy: 0.9992 - val_loss: 1.2929 - val_accuracy: 0.7263\n","Epoch 88/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0133 - accuracy: 0.9989 - val_loss: 1.3636 - val_accuracy: 0.7166\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0186 - accuracy: 0.9976 - val_loss: 1.3526 - val_accuracy: 0.7155\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0806 - accuracy: 0.9717 - val_loss: 1.5973 - val_accuracy: 0.6336\n","Epoch 91/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1138 - accuracy: 0.9609 - val_loss: 1.0672 - val_accuracy: 0.6983\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0490 - accuracy: 0.9855 - val_loss: 1.2818 - val_accuracy: 0.6994\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1030 - accuracy: 0.9636 - val_loss: 1.0871 - val_accuracy: 0.6961\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0986 - accuracy: 0.9652 - val_loss: 1.1837 - val_accuracy: 0.6864\n","Epoch 95/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0287 - accuracy: 0.9954 - val_loss: 1.3304 - val_accuracy: 0.7047\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0311 - accuracy: 0.9914 - val_loss: 1.4659 - val_accuracy: 0.6950\n","Epoch 97/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0299 - accuracy: 0.9906 - val_loss: 1.5039 - val_accuracy: 0.7026\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0598 - accuracy: 0.9790 - val_loss: 1.4241 - val_accuracy: 0.6907\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0405 - accuracy: 0.9900 - val_loss: 1.4613 - val_accuracy: 0.6756\n","Epoch 100/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0421 - accuracy: 0.9895 - val_loss: 1.3782 - val_accuracy: 0.6972\n","{'loss': [0.23831263184547424, 0.0965656116604805, 0.06686694920063019, 0.05821879953145981, 0.0645328015089035, 0.0861678421497345, 0.08389638364315033, 0.053198542445898056, 0.07590918242931366, 0.06470699608325958, 0.06083614379167557, 0.05829404294490814, 0.0509679801762104, 0.04824009910225868, 0.03792037069797516, 0.04931986331939697, 0.05713251605629921, 0.06354610621929169, 0.05542290583252907, 0.03651395067572594, 0.02984301559627056, 0.029781274497509003, 0.039444949477910995, 0.05184585601091385, 0.06625169515609741, 0.052355166524648666, 0.03685147687792778, 0.03345474600791931, 0.036261461675167084, 0.04437417536973953, 0.052537787705659866, 0.06347348541021347, 0.03980344906449318, 0.042854927480220795, 0.026725465431809425, 0.025136150419712067, 0.04756820946931839, 0.035106610506772995, 0.05460793152451515, 0.0708220899105072, 0.034706179052591324, 0.021667681634426117, 0.024119501933455467, 0.020213359966874123, 0.022753654047846794, 0.029454577714204788, 0.11852217465639114, 0.1001131534576416, 0.028195777907967567, 0.0167829766869545, 0.015237799845635891, 0.014260281808674335, 0.012880764901638031, 0.012717326171696186, 0.012271272018551826, 0.012017553672194481, 0.011796063743531704, 0.011628816835582256, 0.011540507897734642, 0.01170489750802517, 0.012609245255589485, 0.013291137292981148, 0.012213232927024364, 0.01197306253015995, 0.011224809102714062, 0.011127346195280552, 0.010964757762849331, 0.010858666151762009, 0.010775568895041943, 0.010724691674113274, 0.010667072609066963, 0.010644069872796535, 0.010571044869720936, 0.010441524907946587, 0.010360276326537132, 0.010277830995619297, 0.010363439098000526, 0.010272972285747528, 0.010237514972686768, 0.010203993879258633, 0.010147006250917912, 0.010112835094332695, 0.010087698698043823, 0.009969069622457027, 0.009913978166878223, 0.009862596169114113, 0.012940796092152596, 0.013329469598829746, 0.018579239025712013, 0.08064308762550354, 0.11382728070020676, 0.04900394380092621, 0.10300752520561218, 0.09863264858722687, 0.028749920427799225, 0.031100207939743996, 0.029879070818424225, 0.059762269258499146, 0.04048984497785568, 0.04205276817083359], 'accuracy': [0.9170258641242981, 0.9722521305084229, 0.9789870977401733, 0.9795258641242981, 0.9803340435028076, 0.9706357717514038, 0.9738685488700867, 0.985991358757019, 0.9765625, 0.9811422228813171, 0.9822198152542114, 0.9824892282485962, 0.985991358757019, 0.9870689511299133, 0.9903017282485962, 0.9851831793785095, 0.9846444129943848, 0.9808728694915771, 0.9838362336158752, 0.9921875, 0.9932650923728943, 0.9921875, 0.9894935488700867, 0.9851831793785095, 0.9800646305084229, 0.984375, 0.9921875, 0.9919180870056152, 0.9892241358757019, 0.9876077771186829, 0.9835668206214905, 0.9806034564971924, 0.9876077771186829, 0.9892241358757019, 0.9940732717514038, 0.9946120977401733, 0.9873383641242981, 0.990571141242981, 0.9849137663841248, 0.9787176847457886, 0.9929956793785095, 0.9975754022598267, 0.9956896305084229, 0.9967672228813171, 0.9964978694915771, 0.9924569129943848, 0.9647090435028076, 0.967133641242981, 0.9956896305084229, 0.9994612336158752, 0.9994612336158752, 0.9989224076271057, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9994612336158752, 0.9991918206214905, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9991918206214905, 0.9989224076271057, 0.9975754022598267, 0.9717133641242981, 0.9609375, 0.9854525923728943, 0.9636314511299133, 0.9652478694915771, 0.9954202771186829, 0.9913793206214905, 0.990571141242981, 0.9789870977401733, 0.9900323152542114, 0.9894935488700867], 'val_loss': [0.7018855810165405, 0.7013197541236877, 0.7005614638328552, 0.696036159992218, 0.6937320828437805, 0.6881914734840393, 0.6832083463668823, 0.6709936261177063, 0.6667320728302002, 0.6523361206054688, 0.6490388512611389, 0.6340291500091553, 0.6240651607513428, 0.6256734728813171, 0.6409473419189453, 0.6603748798370361, 0.6702190637588501, 0.7019308805465698, 0.7534007430076599, 0.9379729628562927, 0.9727241396903992, 0.9725403189659119, 1.0870637893676758, 1.0984022617340088, 1.1665925979614258, 1.1805988550186157, 1.1942859888076782, 1.2024470567703247, 1.370483160018921, 1.2781463861465454, 1.2151981592178345, 1.1586408615112305, 1.3933663368225098, 1.3434579372406006, 1.3552547693252563, 1.4775949716567993, 1.3125016689300537, 1.550926923751831, 1.3683563470840454, 1.09859037399292, 1.3413833379745483, 1.3101046085357666, 1.3777588605880737, 1.3537282943725586, 1.418951153755188, 1.4844247102737427, 1.568316102027893, 0.9280339479446411, 1.186105489730835, 1.2603633403778076, 1.33675217628479, 1.3648595809936523, 1.367450475692749, 1.391404628753662, 1.4039385318756104, 1.4063341617584229, 1.4021787643432617, 1.3965195417404175, 1.3941762447357178, 1.3982489109039307, 1.409847378730774, 1.4798483848571777, 1.4001681804656982, 1.3959970474243164, 1.4054858684539795, 1.3972587585449219, 1.3963191509246826, 1.3831393718719482, 1.3739420175552368, 1.3622386455535889, 1.3752049207687378, 1.3520866632461548, 1.3563082218170166, 1.3453153371810913, 1.3424935340881348, 1.3371402025222778, 1.3275519609451294, 1.3412538766860962, 1.328001618385315, 1.3283276557922363, 1.3236334323883057, 1.3256300687789917, 1.323001503944397, 1.3170936107635498, 1.315473198890686, 1.31327223777771, 1.2928675413131714, 1.3636319637298584, 1.3525505065917969, 1.5973331928253174, 1.0672496557235718, 1.2818289995193481, 1.0871481895446777, 1.1836715936660767, 1.3303669691085815, 1.4659242630004883, 1.5038834810256958, 1.4241024255752563, 1.4612691402435303, 1.3781638145446777], 'val_accuracy': [0.5150862336158752, 0.5183189511299133, 0.5161637663841248, 0.5280172228813171, 0.5463362336158752, 0.5786637663841248, 0.5894396305084229, 0.6153017282485962, 0.6228448152542114, 0.631465494632721, 0.6433189511299133, 0.6443965435028076, 0.6476293206214905, 0.6594827771186829, 0.6896551847457886, 0.6681034564971924, 0.6864224076271057, 0.6885775923728943, 0.673491358757019, 0.670258641242981, 0.6982758641242981, 0.7219827771186829, 0.7144396305084229, 0.7165948152542114, 0.701508641242981, 0.7058189511299133, 0.7079741358757019, 0.7273706793785095, 0.7025862336158752, 0.7338362336158752, 0.7230603694915771, 0.7176724076271057, 0.6864224076271057, 0.7112069129943848, 0.7230603694915771, 0.7068965435028076, 0.7133620977401733, 0.6971982717514038, 0.7165948152542114, 0.7165948152542114, 0.7155172228813171, 0.743534505367279, 0.7165948152542114, 0.7306034564971924, 0.7262930870056152, 0.71875, 0.6508620977401733, 0.7198275923728943, 0.71875, 0.7155172228813171, 0.7230603694915771, 0.7165948152542114, 0.7219827771186829, 0.7176724076271057, 0.71875, 0.7209051847457886, 0.7198275923728943, 0.7241379022598267, 0.7198275923728943, 0.71875, 0.7144396305084229, 0.7090517282485962, 0.7112069129943848, 0.7198275923728943, 0.7101293206214905, 0.7133620977401733, 0.7144396305084229, 0.712284505367279, 0.7112069129943848, 0.7176724076271057, 0.71875, 0.71875, 0.7230603694915771, 0.71875, 0.7198275923728943, 0.7209051847457886, 0.7198275923728943, 0.7176724076271057, 0.7198275923728943, 0.7241379022598267, 0.7241379022598267, 0.7241379022598267, 0.7295258641242981, 0.725215494632721, 0.7273706793785095, 0.7284482717514038, 0.7262930870056152, 0.7165948152542114, 0.7155172228813171, 0.6336206793785095, 0.6982758641242981, 0.6993534564971924, 0.6961206793785095, 0.6864224076271057, 0.704741358757019, 0.6950430870056152, 0.7025862336158752, 0.6907327771186829, 0.6756465435028076, 0.6971982717514038]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.3547 - accuracy: 0.8765"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 9s 56ms/step - loss: 0.3448 - accuracy: 0.8797 - val_loss: 0.7029 - val_accuracy: 0.5057\n","Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.1278 - accuracy: 0.9643 - val_loss: 0.7017 - val_accuracy: 0.5102\n","Epoch 3/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0749 - accuracy: 0.9816 - val_loss: 0.7007 - val_accuracy: 0.5260\n","Epoch 4/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0666 - accuracy: 0.9785 - val_loss: 0.6991 - val_accuracy: 0.5226\n","Epoch 5/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.1008 - accuracy: 0.9655 - val_loss: 0.6957 - val_accuracy: 0.5588\n","Epoch 6/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0922 - accuracy: 0.9703 - val_loss: 0.6949 - val_accuracy: 0.5396\n","Epoch 7/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0695 - accuracy: 0.9793 - val_loss: 0.6885 - val_accuracy: 0.5826\n","Epoch 8/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0398 - accuracy: 0.9918 - val_loss: 0.6796 - val_accuracy: 0.5962\n","Epoch 9/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0306 - accuracy: 0.9949 - val_loss: 0.6742 - val_accuracy: 0.5995\n","Epoch 10/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0235 - accuracy: 0.9980 - val_loss: 0.6593 - val_accuracy: 0.6109\n","Epoch 11/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0210 - accuracy: 0.9986 - val_loss: 0.6539 - val_accuracy: 0.6244\n","Epoch 12/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0214 - accuracy: 0.9983 - val_loss: 0.6549 - val_accuracy: 0.6346\n","Epoch 13/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0463 - accuracy: 0.9890 - val_loss: 0.6348 - val_accuracy: 0.6346\n","Epoch 14/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0868 - accuracy: 0.9709 - val_loss: 0.6598 - val_accuracy: 0.6233\n","Epoch 15/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1018 - accuracy: 0.9666 - val_loss: 0.6951 - val_accuracy: 0.6109\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1022 - accuracy: 0.9646 - val_loss: 0.7267 - val_accuracy: 0.5882\n","Epoch 17/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0559 - accuracy: 0.9870 - val_loss: 0.6975 - val_accuracy: 0.6335\n","Epoch 18/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0311 - accuracy: 0.9946 - val_loss: 0.7011 - val_accuracy: 0.6765\n","Epoch 19/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0264 - accuracy: 0.9952 - val_loss: 0.6704 - val_accuracy: 0.7048\n","Epoch 20/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0264 - accuracy: 0.9949 - val_loss: 0.7714 - val_accuracy: 0.6946\n","Epoch 21/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.0258 - accuracy: 0.9958 - val_loss: 0.8080 - val_accuracy: 0.7127\n","Epoch 22/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0283 - accuracy: 0.9946 - val_loss: 0.8784 - val_accuracy: 0.7217\n","Epoch 23/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0398 - accuracy: 0.9904 - val_loss: 0.8616 - val_accuracy: 0.7376\n","Epoch 24/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0788 - accuracy: 0.9745 - val_loss: 0.9954 - val_accuracy: 0.6855\n","Epoch 25/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0559 - accuracy: 0.9853 - val_loss: 0.8710 - val_accuracy: 0.7262\n","Epoch 26/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0353 - accuracy: 0.9926 - val_loss: 1.1126 - val_accuracy: 0.7070\n","Epoch 27/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0467 - accuracy: 0.9892 - val_loss: 0.9546 - val_accuracy: 0.7466\n","Epoch 28/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0340 - accuracy: 0.9929 - val_loss: 1.0347 - val_accuracy: 0.7579\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0418 - accuracy: 0.9901 - val_loss: 1.1592 - val_accuracy: 0.7104\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1262 - accuracy: 0.9598 - val_loss: 0.9740 - val_accuracy: 0.7364\n","Epoch 31/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1039 - accuracy: 0.9612 - val_loss: 0.8016 - val_accuracy: 0.7477\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0393 - accuracy: 0.9929 - val_loss: 0.8740 - val_accuracy: 0.7455\n","Epoch 33/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0204 - accuracy: 0.9986 - val_loss: 0.9712 - val_accuracy: 0.7647\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0170 - accuracy: 0.9997 - val_loss: 1.1008 - val_accuracy: 0.7455\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0158 - accuracy: 0.9986 - val_loss: 1.0857 - val_accuracy: 0.7534\n","Epoch 36/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0192 - accuracy: 0.9977 - val_loss: 1.2582 - val_accuracy: 0.7376\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0174 - accuracy: 0.9983 - val_loss: 1.1233 - val_accuracy: 0.7568\n","Epoch 38/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0187 - accuracy: 0.9986 - val_loss: 1.1682 - val_accuracy: 0.7466\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0160 - accuracy: 0.9992 - val_loss: 1.1414 - val_accuracy: 0.7636\n","Epoch 40/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0146 - accuracy: 0.9994 - val_loss: 1.1284 - val_accuracy: 0.7613\n","Epoch 41/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0141 - accuracy: 0.9997 - val_loss: 1.1725 - val_accuracy: 0.7579\n","Epoch 42/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0180 - accuracy: 0.9977 - val_loss: 1.1957 - val_accuracy: 0.7602\n","Epoch 43/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.1959 - val_accuracy: 0.7466\n","Epoch 44/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0133 - accuracy: 0.9997 - val_loss: 1.1720 - val_accuracy: 0.7692\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.1591 - val_accuracy: 0.7647\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.1683 - val_accuracy: 0.7590\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0132 - accuracy: 0.9997 - val_loss: 1.1895 - val_accuracy: 0.7489\n","Epoch 48/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.1621 - val_accuracy: 0.7568\n","Epoch 49/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.1649 - val_accuracy: 0.7568\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.1512 - val_accuracy: 0.7568\n","Epoch 51/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.1561 - val_accuracy: 0.7523\n","Epoch 52/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.1430 - val_accuracy: 0.7579\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.1616 - val_accuracy: 0.7545\n","Epoch 54/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.1381 - val_accuracy: 0.7500\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.1276 - val_accuracy: 0.7477\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.1204 - val_accuracy: 0.7534\n","Epoch 57/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.1139 - val_accuracy: 0.7523\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.1104 - val_accuracy: 0.7636\n","Epoch 59/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.1083 - val_accuracy: 0.7545\n","Epoch 60/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.1050 - val_accuracy: 0.7602\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.0975 - val_accuracy: 0.7579\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.1008 - val_accuracy: 0.7557\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.1039 - val_accuracy: 0.7568\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.0990 - val_accuracy: 0.7511\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.0955 - val_accuracy: 0.7523\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.0855 - val_accuracy: 0.7568\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.0879 - val_accuracy: 0.7489\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.0793 - val_accuracy: 0.7534\n","Epoch 69/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.0789 - val_accuracy: 0.7500\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.0806 - val_accuracy: 0.7523\n","Epoch 71/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.0835 - val_accuracy: 0.7489\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.0811 - val_accuracy: 0.7477\n","Epoch 73/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.0752 - val_accuracy: 0.7500\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.0775 - val_accuracy: 0.7511\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.0831 - val_accuracy: 0.7545\n","Epoch 76/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.0735 - val_accuracy: 0.7511\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.0694 - val_accuracy: 0.7602\n","Epoch 78/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.0718 - val_accuracy: 0.7545\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.0680 - val_accuracy: 0.7534\n","Epoch 80/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.0606 - val_accuracy: 0.7590\n","Epoch 81/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.0649 - val_accuracy: 0.7557\n","Epoch 82/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.0638 - val_accuracy: 0.7500\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.0622 - val_accuracy: 0.7511\n","Epoch 84/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.0663 - val_accuracy: 0.7489\n","Epoch 85/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.0553 - val_accuracy: 0.7489\n","Epoch 86/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.0569 - val_accuracy: 0.7500\n","Epoch 87/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.0612 - val_accuracy: 0.7523\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.0648 - val_accuracy: 0.7466\n","Epoch 89/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.0612 - val_accuracy: 0.7466\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.0641 - val_accuracy: 0.7443\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.0678 - val_accuracy: 0.7477\n","Epoch 92/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.0686 - val_accuracy: 0.7500\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.0610 - val_accuracy: 0.7500\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.0581 - val_accuracy: 0.7534\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.0613 - val_accuracy: 0.7466\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.0604 - val_accuracy: 0.7590\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.0678 - val_accuracy: 0.7579\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.0815 - val_accuracy: 0.7489\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.0793 - val_accuracy: 0.7489\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.0752 - val_accuracy: 0.7557\n","{'loss': [0.34478679299354553, 0.1277802735567093, 0.0749111995100975, 0.0665767714381218, 0.1008288711309433, 0.0922473669052124, 0.06954653561115265, 0.03978743776679039, 0.030607614666223526, 0.023537548258900642, 0.02102275937795639, 0.021369419991970062, 0.04625497758388519, 0.086801677942276, 0.10180199146270752, 0.10223305970430374, 0.05588674545288086, 0.03106873109936714, 0.02638058550655842, 0.02644929103553295, 0.025832396000623703, 0.028282491490244865, 0.03980274125933647, 0.07879801839590073, 0.05589979141950607, 0.03533226251602173, 0.04672570526599884, 0.03397878631949425, 0.041788361966609955, 0.12617415189743042, 0.10394739359617233, 0.03928937390446663, 0.020376959815621376, 0.01699223928153515, 0.015823179855942726, 0.019167039543390274, 0.01743650808930397, 0.018660828471183777, 0.015971645712852478, 0.014642597176134586, 0.014053099788725376, 0.018006229773163795, 0.01450754702091217, 0.013288036920130253, 0.012872966006398201, 0.012658498249948025, 0.01322958804666996, 0.0124189592897892, 0.01218621525913477, 0.011965105310082436, 0.011762003414332867, 0.011620980687439442, 0.011567579582333565, 0.011530382558703423, 0.01139456033706665, 0.011322415433824062, 0.011165207251906395, 0.01113232970237732, 0.011103262193500996, 0.011118772439658642, 0.01100160088390112, 0.010934037156403065, 0.010847730562090874, 0.010766655206680298, 0.010769087821245193, 0.010652903467416763, 0.010593517683446407, 0.010550608858466148, 0.010484087280929089, 0.010552700608968735, 0.01043230015784502, 0.010398373939096928, 0.010330546647310257, 0.010386302135884762, 0.010354941710829735, 0.010186843574047089, 0.010108500719070435, 0.010076070204377174, 0.010032099671661854, 0.009998873807489872, 0.009930632077157497, 0.009866340085864067, 0.009842823259532452, 0.009820855222642422, 0.009775788523256779, 0.009751638397574425, 0.009764665737748146, 0.009701162576675415, 0.0096480967476964, 0.009622444398701191, 0.009628821164369583, 0.009546353481709957, 0.009493840858340263, 0.009520033374428749, 0.009442644193768501, 0.009415039792656898, 0.009530538693070412, 0.009375766851007938, 0.00935454573482275, 0.009293437004089355], 'accuracy': [0.8797396421432495, 0.9643463492393494, 0.9816072583198547, 0.9784946441650391, 0.965478241443634, 0.9702886343002319, 0.9793435335159302, 0.9917939901351929, 0.9949066042900085, 0.9980192184448242, 0.9985851645469666, 0.9983022212982178, 0.988964319229126, 0.9708545804023743, 0.9666100740432739, 0.9646292924880981, 0.986983597278595, 0.9946236610412598, 0.9951896071434021, 0.9949066042900085, 0.9957554936408997, 0.9946236610412598, 0.9903791546821594, 0.9745330810546875, 0.9852858185768127, 0.992642879486084, 0.9892473220825195, 0.9929258823394775, 0.9900962114334106, 0.9598188996315002, 0.9612337350845337, 0.9929258823394775, 0.9985851645469666, 0.9997170567512512, 0.9985851645469666, 0.9977362751960754, 0.9983022212982178, 0.9985851645469666, 0.9991511106491089, 0.9994340538978577, 0.9997170567512512, 0.9977362751960754, 1.0, 0.9997170567512512, 1.0, 1.0, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.7029027938842773, 0.7017264366149902, 0.7006543874740601, 0.6990678906440735, 0.6956722140312195, 0.6948809623718262, 0.6885424256324768, 0.6796243786811829, 0.6742077469825745, 0.6593088507652283, 0.6538649797439575, 0.6549302935600281, 0.634767472743988, 0.659820020198822, 0.6951320767402649, 0.7266770601272583, 0.6975049376487732, 0.7010608911514282, 0.6704425811767578, 0.7713665962219238, 0.8079624176025391, 0.8783782720565796, 0.8615537881851196, 0.9954261183738708, 0.8709701895713806, 1.1125600337982178, 0.9546411633491516, 1.0347003936767578, 1.1591999530792236, 0.9740490913391113, 0.801645815372467, 0.8740246891975403, 0.9712216258049011, 1.1008248329162598, 1.0857354402542114, 1.2581859827041626, 1.1232624053955078, 1.1681673526763916, 1.1414228677749634, 1.128411889076233, 1.1724708080291748, 1.1957099437713623, 1.1958565711975098, 1.1719833612442017, 1.1591495275497437, 1.1683402061462402, 1.189520239830017, 1.1621191501617432, 1.164929747581482, 1.1511889696121216, 1.1561275720596313, 1.14296293258667, 1.1616054773330688, 1.1380587816238403, 1.1275568008422852, 1.120357871055603, 1.1139397621154785, 1.1104024648666382, 1.108283281326294, 1.1049808263778687, 1.0974767208099365, 1.1007897853851318, 1.1039488315582275, 1.0989789962768555, 1.095534086227417, 1.0855177640914917, 1.0879307985305786, 1.0793148279190063, 1.0788931846618652, 1.0806326866149902, 1.0834870338439941, 1.0810675621032715, 1.075161099433899, 1.077504277229309, 1.0830737352371216, 1.0735292434692383, 1.0694458484649658, 1.0717517137527466, 1.0679543018341064, 1.0605827569961548, 1.0648823976516724, 1.063755989074707, 1.062157154083252, 1.0663044452667236, 1.055267095565796, 1.056872010231018, 1.061230182647705, 1.0647711753845215, 1.061221718788147, 1.0640748739242554, 1.0678112506866455, 1.0686250925064087, 1.0609514713287354, 1.0580917596817017, 1.0612845420837402, 1.0603704452514648, 1.0678211450576782, 1.0815095901489258, 1.0792927742004395, 1.0751935243606567], 'val_accuracy': [0.5056561231613159, 0.5101810097694397, 0.5260180830955505, 0.5226244330406189, 0.5588235259056091, 0.5395927429199219, 0.5825791954994202, 0.5961538553237915, 0.5995475053787231, 0.610859751701355, 0.6244344115257263, 0.6346153616905212, 0.6346153616905212, 0.6233031749725342, 0.610859751701355, 0.5882353186607361, 0.6334841847419739, 0.6764705777168274, 0.7047511339187622, 0.6945701241493225, 0.7126696705818176, 0.7217194437980652, 0.7375565767288208, 0.685520350933075, 0.726244330406189, 0.7070135474205017, 0.7466063499450684, 0.7579185366630554, 0.7104072570800781, 0.7364253401756287, 0.7477375268936157, 0.7454751133918762, 0.7647058963775635, 0.7454751133918762, 0.7533936500549316, 0.7375565767288208, 0.7567873597145081, 0.7466063499450684, 0.7635746598243713, 0.7613122463226318, 0.7579185366630554, 0.7601810097694397, 0.7466063499450684, 0.7692307829856873, 0.7647058963775635, 0.7590497732162476, 0.7488687634468079, 0.7567873597145081, 0.7567873597145081, 0.7567873597145081, 0.7522624731063843, 0.7579185366630554, 0.7545248866081238, 0.75, 0.7477375268936157, 0.7533936500549316, 0.7522624731063843, 0.7635746598243713, 0.7545248866081238, 0.7601810097694397, 0.7579185366630554, 0.7556561231613159, 0.7567873597145081, 0.7511312365531921, 0.7522624731063843, 0.7567873597145081, 0.7488687634468079, 0.7533936500549316, 0.75, 0.7522624731063843, 0.7488687634468079, 0.7477375268936157, 0.75, 0.7511312365531921, 0.7545248866081238, 0.7511312365531921, 0.7601810097694397, 0.7545248866081238, 0.7533936500549316, 0.7590497732162476, 0.7556561231613159, 0.75, 0.7511312365531921, 0.7488687634468079, 0.7488687634468079, 0.75, 0.7522624731063843, 0.7466063499450684, 0.7466063499450684, 0.7443438768386841, 0.7477375268936157, 0.75, 0.75, 0.7533936500549316, 0.7466063499450684, 0.7590497732162476, 0.7579185366630554, 0.7488687634468079, 0.7488687634468079, 0.7556561231613159]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 9s 53ms/step - loss: 0.3019 - accuracy: 0.8938 - val_loss: 0.7019 - val_accuracy: 0.5155\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1692 - accuracy: 0.9372 - val_loss: 0.7011 - val_accuracy: 0.5176\n","Epoch 3/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1133 - accuracy: 0.9612 - val_loss: 0.6998 - val_accuracy: 0.5248\n","Epoch 4/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.1339 - accuracy: 0.9494 - val_loss: 0.6961 - val_accuracy: 0.5310\n","Epoch 5/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0936 - accuracy: 0.9724 - val_loss: 0.6942 - val_accuracy: 0.5279\n","Epoch 6/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0719 - accuracy: 0.9798 - val_loss: 0.6861 - val_accuracy: 0.5795\n","Epoch 7/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1041 - accuracy: 0.9636 - val_loss: 0.6810 - val_accuracy: 0.5909\n","Epoch 8/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.1069 - accuracy: 0.9628 - val_loss: 0.6815 - val_accuracy: 0.5610\n","Epoch 9/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0778 - accuracy: 0.9726 - val_loss: 0.6597 - val_accuracy: 0.6550\n","Epoch 10/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0557 - accuracy: 0.9829 - val_loss: 0.6534 - val_accuracy: 0.6405\n","Epoch 11/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0576 - accuracy: 0.9832 - val_loss: 0.6398 - val_accuracy: 0.6426\n","Epoch 12/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0706 - accuracy: 0.9775 - val_loss: 0.7029 - val_accuracy: 0.5930\n","Epoch 13/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0915 - accuracy: 0.9685 - val_loss: 0.6302 - val_accuracy: 0.6570\n","Epoch 14/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0637 - accuracy: 0.9806 - val_loss: 0.6571 - val_accuracy: 0.6581\n","Epoch 15/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0512 - accuracy: 0.9876 - val_loss: 0.6340 - val_accuracy: 0.6994\n","Epoch 16/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0580 - accuracy: 0.9827 - val_loss: 0.6647 - val_accuracy: 0.6901\n","Epoch 17/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0963 - accuracy: 0.9628 - val_loss: 0.6312 - val_accuracy: 0.7128\n","Epoch 18/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1458 - accuracy: 0.9473 - val_loss: 0.6292 - val_accuracy: 0.6890\n","Epoch 19/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0789 - accuracy: 0.9765 - val_loss: 0.7106 - val_accuracy: 0.6952\n","Epoch 20/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0445 - accuracy: 0.9881 - val_loss: 0.7572 - val_accuracy: 0.7118\n","Epoch 21/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0295 - accuracy: 0.9946 - val_loss: 0.7547 - val_accuracy: 0.7521\n","Epoch 22/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0232 - accuracy: 0.9974 - val_loss: 0.8200 - val_accuracy: 0.7676\n","Epoch 23/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0245 - accuracy: 0.9964 - val_loss: 0.9468 - val_accuracy: 0.7583\n","Epoch 24/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0253 - accuracy: 0.9951 - val_loss: 1.0558 - val_accuracy: 0.7428\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0387 - accuracy: 0.9912 - val_loss: 1.0972 - val_accuracy: 0.7366\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0492 - accuracy: 0.9858 - val_loss: 1.1533 - val_accuracy: 0.7345\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0496 - accuracy: 0.9860 - val_loss: 0.9994 - val_accuracy: 0.7655\n","Epoch 28/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1301 - accuracy: 0.9527 - val_loss: 1.4266 - val_accuracy: 0.6488\n","Epoch 29/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.1082 - accuracy: 0.9633 - val_loss: 0.8210 - val_accuracy: 0.7438\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0372 - accuracy: 0.9915 - val_loss: 0.9090 - val_accuracy: 0.7614\n","Epoch 31/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0256 - accuracy: 0.9964 - val_loss: 1.0103 - val_accuracy: 0.7717\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0220 - accuracy: 0.9972 - val_loss: 1.0835 - val_accuracy: 0.7634\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0243 - accuracy: 0.9959 - val_loss: 1.1323 - val_accuracy: 0.7655\n","Epoch 34/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0238 - accuracy: 0.9956 - val_loss: 1.1355 - val_accuracy: 0.7572\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0347 - accuracy: 0.9915 - val_loss: 1.2674 - val_accuracy: 0.7459\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0373 - accuracy: 0.9915 - val_loss: 1.1914 - val_accuracy: 0.7459\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0345 - accuracy: 0.9915 - val_loss: 1.2047 - val_accuracy: 0.7469\n","Epoch 38/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0367 - accuracy: 0.9899 - val_loss: 1.2690 - val_accuracy: 0.7448\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0470 - accuracy: 0.9884 - val_loss: 1.1206 - val_accuracy: 0.7438\n","Epoch 40/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0578 - accuracy: 0.9819 - val_loss: 1.2475 - val_accuracy: 0.7355\n","Epoch 41/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0780 - accuracy: 0.9757 - val_loss: 1.1484 - val_accuracy: 0.7283\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0574 - accuracy: 0.9829 - val_loss: 0.9447 - val_accuracy: 0.7583\n","Epoch 43/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0374 - accuracy: 0.9907 - val_loss: 1.1388 - val_accuracy: 0.7324\n","Epoch 44/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0683 - accuracy: 0.9801 - val_loss: 1.1632 - val_accuracy: 0.7355\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0667 - accuracy: 0.9780 - val_loss: 1.0366 - val_accuracy: 0.7366\n","Epoch 46/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0411 - accuracy: 0.9886 - val_loss: 1.2194 - val_accuracy: 0.7314\n","Epoch 47/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0267 - accuracy: 0.9951 - val_loss: 1.2933 - val_accuracy: 0.7355\n","Epoch 48/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0298 - accuracy: 0.9938 - val_loss: 1.5525 - val_accuracy: 0.7190\n","Epoch 49/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0905 - accuracy: 0.9693 - val_loss: 1.4538 - val_accuracy: 0.6746\n","Epoch 50/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0606 - accuracy: 0.9798 - val_loss: 1.1160 - val_accuracy: 0.7407\n","Epoch 51/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0298 - accuracy: 0.9943 - val_loss: 1.1841 - val_accuracy: 0.7417\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0237 - accuracy: 0.9966 - val_loss: 1.2905 - val_accuracy: 0.7428\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0282 - accuracy: 0.9935 - val_loss: 1.2183 - val_accuracy: 0.7438\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0250 - accuracy: 0.9951 - val_loss: 1.2228 - val_accuracy: 0.7459\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0277 - accuracy: 0.9938 - val_loss: 1.3202 - val_accuracy: 0.7397\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0215 - accuracy: 0.9964 - val_loss: 1.4941 - val_accuracy: 0.7252\n","Epoch 57/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0266 - accuracy: 0.9938 - val_loss: 1.4516 - val_accuracy: 0.7159\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0288 - accuracy: 0.9925 - val_loss: 1.3341 - val_accuracy: 0.7386\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0251 - accuracy: 0.9953 - val_loss: 1.2174 - val_accuracy: 0.7448\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0189 - accuracy: 0.9979 - val_loss: 1.2482 - val_accuracy: 0.7448\n","Epoch 61/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0170 - accuracy: 0.9984 - val_loss: 1.2459 - val_accuracy: 0.7500\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0212 - accuracy: 0.9961 - val_loss: 1.2712 - val_accuracy: 0.7510\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0327 - accuracy: 0.9922 - val_loss: 1.6720 - val_accuracy: 0.6890\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0434 - accuracy: 0.9876 - val_loss: 1.3072 - val_accuracy: 0.7262\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0711 - accuracy: 0.9786 - val_loss: 1.1785 - val_accuracy: 0.7159\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0617 - accuracy: 0.9824 - val_loss: 0.9741 - val_accuracy: 0.7490\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0266 - accuracy: 0.9953 - val_loss: 1.1933 - val_accuracy: 0.7283\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0167 - accuracy: 0.9984 - val_loss: 1.2548 - val_accuracy: 0.7355\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0147 - accuracy: 0.9992 - val_loss: 1.3156 - val_accuracy: 0.7386\n","Epoch 70/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0171 - accuracy: 0.9982 - val_loss: 1.2740 - val_accuracy: 0.7397\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0169 - accuracy: 0.9982 - val_loss: 1.3704 - val_accuracy: 0.7304\n","Epoch 72/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0170 - accuracy: 0.9979 - val_loss: 1.2968 - val_accuracy: 0.7603\n","Epoch 73/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0157 - accuracy: 0.9987 - val_loss: 1.5695 - val_accuracy: 0.7273\n","Epoch 74/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0181 - accuracy: 0.9977 - val_loss: 1.4198 - val_accuracy: 0.7273\n","Epoch 75/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0253 - accuracy: 0.9961 - val_loss: 1.4542 - val_accuracy: 0.7076\n","Epoch 76/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0886 - accuracy: 0.9716 - val_loss: 1.2503 - val_accuracy: 0.6952\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0603 - accuracy: 0.9811 - val_loss: 1.0995 - val_accuracy: 0.7304\n","Epoch 78/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0631 - accuracy: 0.9773 - val_loss: 1.2308 - val_accuracy: 0.7066\n","Epoch 79/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0689 - accuracy: 0.9760 - val_loss: 1.1560 - val_accuracy: 0.7066\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0391 - accuracy: 0.9889 - val_loss: 1.1258 - val_accuracy: 0.7190\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0207 - accuracy: 0.9974 - val_loss: 1.2221 - val_accuracy: 0.7262\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0201 - accuracy: 0.9966 - val_loss: 1.2719 - val_accuracy: 0.7324\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0186 - accuracy: 0.9974 - val_loss: 1.3017 - val_accuracy: 0.7355\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0435 - accuracy: 0.9886 - val_loss: 1.2851 - val_accuracy: 0.7159\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0673 - accuracy: 0.9801 - val_loss: 1.2871 - val_accuracy: 0.6901\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0419 - accuracy: 0.9889 - val_loss: 1.1835 - val_accuracy: 0.7314\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0340 - accuracy: 0.9920 - val_loss: 1.4061 - val_accuracy: 0.7087\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0469 - accuracy: 0.9868 - val_loss: 1.0656 - val_accuracy: 0.7366\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0285 - accuracy: 0.9935 - val_loss: 1.2108 - val_accuracy: 0.7324\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0172 - accuracy: 0.9979 - val_loss: 1.4133 - val_accuracy: 0.7252\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0157 - accuracy: 0.9987 - val_loss: 1.3542 - val_accuracy: 0.7376\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0208 - accuracy: 0.9964 - val_loss: 1.2990 - val_accuracy: 0.7500\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0218 - accuracy: 0.9948 - val_loss: 1.3547 - val_accuracy: 0.7314\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0431 - accuracy: 0.9866 - val_loss: 1.3921 - val_accuracy: 0.7159\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1010 - accuracy: 0.9685 - val_loss: 1.0306 - val_accuracy: 0.7004\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0375 - accuracy: 0.9907 - val_loss: 1.2316 - val_accuracy: 0.7045\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0445 - accuracy: 0.9868 - val_loss: 1.3603 - val_accuracy: 0.7087\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0281 - accuracy: 0.9951 - val_loss: 1.3833 - val_accuracy: 0.6983\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0224 - accuracy: 0.9964 - val_loss: 1.3970 - val_accuracy: 0.7014\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0190 - accuracy: 0.9956 - val_loss: 1.3412 - val_accuracy: 0.7293\n","{'loss': [0.3019196093082428, 0.16918028891086578, 0.11325235664844513, 0.13393168151378632, 0.0936138778924942, 0.07187215983867645, 0.10407786071300507, 0.10688503831624985, 0.07780482620000839, 0.055685315281152725, 0.057555899024009705, 0.07060150057077408, 0.09146463871002197, 0.06367317587137222, 0.05118037760257721, 0.05804911255836487, 0.0963025614619255, 0.14576609432697296, 0.0789293646812439, 0.04446077719330788, 0.029474083334207535, 0.023187657818198204, 0.024466732516884804, 0.025288358330726624, 0.038657788187265396, 0.04924020171165466, 0.04956991225481033, 0.1301422119140625, 0.10821984708309174, 0.037173036485910416, 0.025574125349521637, 0.021974729374051094, 0.024278728291392326, 0.023776914924383163, 0.034745953977108, 0.03729930892586708, 0.03446822240948677, 0.03669178858399391, 0.046970803290605545, 0.057795844972133636, 0.07796155661344528, 0.05739748477935791, 0.037434544414281845, 0.0683000236749649, 0.06665719300508499, 0.04114444553852081, 0.026689475402235985, 0.029756639152765274, 0.09054366499185562, 0.060574594885110855, 0.029753075912594795, 0.023737668991088867, 0.02820383757352829, 0.02496056817471981, 0.027693215757608414, 0.02154749073088169, 0.02658158354461193, 0.02884875051677227, 0.025089560076594353, 0.018864097073674202, 0.016969015821814537, 0.02124609611928463, 0.03267228603363037, 0.04338780418038368, 0.07107170671224594, 0.06167702004313469, 0.026561643928289413, 0.016736458986997604, 0.014683757908642292, 0.017079314216971397, 0.016919391229748726, 0.017003655433654785, 0.015664076432585716, 0.01809418946504593, 0.025307537987828255, 0.08859346807003021, 0.06028580665588379, 0.06305777281522751, 0.0688558891415596, 0.039144665002822876, 0.02065376564860344, 0.02009345404803753, 0.018635481595993042, 0.04346367344260216, 0.06733054667711258, 0.04185672104358673, 0.03397275507450104, 0.04694950208067894, 0.028470471501350403, 0.017156794667243958, 0.01572364941239357, 0.020750489085912704, 0.021810876205563545, 0.04313233494758606, 0.10104247182607651, 0.03745323047041893, 0.04451797157526016, 0.028116928413510323, 0.02244061790406704, 0.019040793180465698], 'accuracy': [0.8937984704971313, 0.9372093081474304, 0.961240291595459, 0.9493539929389954, 0.9723514318466187, 0.9798449873924255, 0.9635658860206604, 0.9627906680107117, 0.97260981798172, 0.9829457402229309, 0.9832041263580322, 0.9775193929672241, 0.9684754610061646, 0.9806201457977295, 0.987596869468689, 0.9826873540878296, 0.9627906680107117, 0.94728684425354, 0.9764857888221741, 0.9881137013435364, 0.9945736527442932, 0.9974160194396973, 0.9963824152946472, 0.9950904250144958, 0.9912144541740417, 0.985788106918335, 0.9860464930534363, 0.9527131915092468, 0.9633074998855591, 0.9914728403091431, 0.9963824152946472, 0.997157633304596, 0.9958656430244446, 0.9956072568893433, 0.9914728403091431, 0.9914728403091431, 0.9914728403091431, 0.9899224638938904, 0.9883720874786377, 0.9819121360778809, 0.9757105708122253, 0.9829457402229309, 0.9906976819038391, 0.9801033735275269, 0.9780361652374268, 0.988630473613739, 0.9950904250144958, 0.9937984347343445, 0.9692506194114685, 0.9798449873924255, 0.9943152666091919, 0.9966408014297485, 0.9935400485992432, 0.9950904250144958, 0.9937984347343445, 0.9963824152946472, 0.9937984347343445, 0.9925064444541931, 0.9953488111495972, 0.9979327917098999, 0.9984496235847473, 0.9961240291595459, 0.9922480583190918, 0.987596869468689, 0.9785529971122742, 0.9824289679527283, 0.9953488111495972, 0.9984496235847473, 0.9992247819900513, 0.998191237449646, 0.998191237449646, 0.9979327917098999, 0.9987080097198486, 0.9976744055747986, 0.9961240291595459, 0.9715762138366699, 0.9811369776725769, 0.9772610068321228, 0.9759690165519714, 0.9888888597488403, 0.9974160194396973, 0.9966408014297485, 0.9974160194396973, 0.988630473613739, 0.9801033735275269, 0.9888888597488403, 0.9919896721839905, 0.986821711063385, 0.9935400485992432, 0.9979327917098999, 0.9987080097198486, 0.9963824152946472, 0.9948320388793945, 0.9865633249282837, 0.9684754610061646, 0.9906976819038391, 0.986821711063385, 0.9950904250144958, 0.9963824152946472, 0.9956072568893433], 'val_loss': [0.7019013166427612, 0.7010616660118103, 0.6997616291046143, 0.6961003541946411, 0.6941684484481812, 0.6860523819923401, 0.6810053586959839, 0.6814711093902588, 0.6596672534942627, 0.6533932685852051, 0.6397992968559265, 0.7028653621673584, 0.6302405595779419, 0.6570709943771362, 0.6339961886405945, 0.6647095084190369, 0.6312091946601868, 0.6291830539703369, 0.7106291651725769, 0.7572413086891174, 0.7547260522842407, 0.8200034499168396, 0.9467958807945251, 1.0557528734207153, 1.0972317457199097, 1.153254508972168, 0.9994420409202576, 1.4266290664672852, 0.821005642414093, 0.9090170860290527, 1.0103392601013184, 1.0834845304489136, 1.1322791576385498, 1.1355048418045044, 1.2674299478530884, 1.191429853439331, 1.2047070264816284, 1.2689704895019531, 1.1205917596817017, 1.2474846839904785, 1.1483643054962158, 0.944723904132843, 1.138835072517395, 1.1631661653518677, 1.036558747291565, 1.2193957567214966, 1.293330192565918, 1.5525273084640503, 1.4538352489471436, 1.116045594215393, 1.1841233968734741, 1.2905397415161133, 1.2183270454406738, 1.2227823734283447, 1.3201876878738403, 1.4941105842590332, 1.4516148567199707, 1.3341023921966553, 1.2174478769302368, 1.2481508255004883, 1.245896816253662, 1.2712401151657104, 1.6719629764556885, 1.3072187900543213, 1.1785106658935547, 0.9740986824035645, 1.1933091878890991, 1.2548182010650635, 1.31562077999115, 1.27403724193573, 1.3704029321670532, 1.2968480587005615, 1.5694648027420044, 1.419767141342163, 1.4542368650436401, 1.2502760887145996, 1.0994608402252197, 1.2308242321014404, 1.1559520959854126, 1.1257718801498413, 1.2220807075500488, 1.2719407081604004, 1.3017451763153076, 1.2850995063781738, 1.287065863609314, 1.1835285425186157, 1.4061304330825806, 1.065623164176941, 1.2108471393585205, 1.4132778644561768, 1.3541911840438843, 1.2989979982376099, 1.3546946048736572, 1.3920949697494507, 1.030576229095459, 1.2316244840621948, 1.3602994680404663, 1.3833357095718384, 1.3970023393630981, 1.3412082195281982], 'val_accuracy': [0.5154958963394165, 0.5175619721412659, 0.5247933864593506, 0.5309917330741882, 0.5278925895690918, 0.5795454382896423, 0.5909090638160706, 0.5609503984451294, 0.6549586653709412, 0.6404958963394165, 0.6425619721412659, 0.5929751992225647, 0.6570248007774353, 0.6580578684806824, 0.6993801593780518, 0.6900826692581177, 0.7128099203109741, 0.6890496015548706, 0.6952479481697083, 0.711776852607727, 0.7520661354064941, 0.7675619721412659, 0.7582644820213318, 0.7427685856819153, 0.7365702390670776, 0.7345041036605835, 0.7654958963394165, 0.6487603187561035, 0.7438016533851624, 0.7613636255264282, 0.7716942429542542, 0.7634297609329224, 0.7654958963394165, 0.7572314143180847, 0.7458677887916565, 0.7458677887916565, 0.7469007968902588, 0.7448347210884094, 0.7438016533851624, 0.7355371713638306, 0.7283057570457458, 0.7582644820213318, 0.7324380278587341, 0.7355371713638306, 0.7365702390670776, 0.7314049601554871, 0.7355371713638306, 0.7190082669258118, 0.6745867729187012, 0.7407024502754211, 0.7417355179786682, 0.7427685856819153, 0.7438016533851624, 0.7458677887916565, 0.7396694421768188, 0.7252066135406494, 0.7159090638160706, 0.7386363744735718, 0.7448347210884094, 0.7448347210884094, 0.75, 0.7510330677032471, 0.6890496015548706, 0.7262396812438965, 0.7159090638160706, 0.7489669322967529, 0.7283057570457458, 0.7355371713638306, 0.7386363744735718, 0.7396694421768188, 0.73037189245224, 0.7603305578231812, 0.7272727489471436, 0.7272727489471436, 0.7076446413993835, 0.6952479481697083, 0.73037189245224, 0.7066115736961365, 0.7066115736961365, 0.7190082669258118, 0.7262396812438965, 0.7324380278587341, 0.7355371713638306, 0.7159090638160706, 0.6900826692581177, 0.7314049601554871, 0.7086777091026306, 0.7365702390670776, 0.7324380278587341, 0.7252066135406494, 0.7376033067703247, 0.75, 0.7314049601554871, 0.7159090638160706, 0.7004132270812988, 0.7045454382896423, 0.7086777091026306, 0.6983470916748047, 0.7014462947845459, 0.7293388247489929]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.0918 - accuracy: 0.9679"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 70ms/step - loss: 0.0923 - accuracy: 0.9685 - val_loss: 0.7000 - val_accuracy: 0.5151\n","Epoch 2/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0477 - accuracy: 0.9865 - val_loss: 0.6979 - val_accuracy: 0.5140\n","Epoch 3/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0310 - accuracy: 0.9930 - val_loss: 0.6934 - val_accuracy: 0.5453\n","Epoch 4/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.0311 - accuracy: 0.9916 - val_loss: 0.6872 - val_accuracy: 0.5517\n","Epoch 5/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0455 - accuracy: 0.9849 - val_loss: 0.6893 - val_accuracy: 0.5280\n","Epoch 6/100\n","29/29 [==============================] - 1s 37ms/step - loss: 0.0519 - accuracy: 0.9844 - val_loss: 0.6804 - val_accuracy: 0.6369\n","Epoch 7/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0317 - accuracy: 0.9916 - val_loss: 0.6700 - val_accuracy: 0.5873\n","Epoch 8/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0210 - accuracy: 0.9970 - val_loss: 0.6514 - val_accuracy: 0.6379\n","Epoch 9/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0200 - accuracy: 0.9949 - val_loss: 0.6412 - val_accuracy: 0.6325\n","Epoch 10/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0269 - accuracy: 0.9938 - val_loss: 0.6205 - val_accuracy: 0.6616\n","Epoch 11/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0408 - accuracy: 0.9871 - val_loss: 0.6061 - val_accuracy: 0.6875\n","Epoch 12/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0474 - accuracy: 0.9846 - val_loss: 0.6003 - val_accuracy: 0.6875\n","Epoch 13/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0470 - accuracy: 0.9857 - val_loss: 0.5926 - val_accuracy: 0.6821\n","Epoch 14/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0442 - accuracy: 0.9876 - val_loss: 0.6084 - val_accuracy: 0.6681\n","Epoch 15/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0429 - accuracy: 0.9879 - val_loss: 0.5845 - val_accuracy: 0.6821\n","Epoch 16/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0306 - accuracy: 0.9914 - val_loss: 0.6174 - val_accuracy: 0.6950\n","Epoch 17/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0257 - accuracy: 0.9954 - val_loss: 0.6541 - val_accuracy: 0.6972\n","Epoch 18/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0397 - accuracy: 0.9881 - val_loss: 0.6439 - val_accuracy: 0.7263\n","Epoch 19/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0494 - accuracy: 0.9860 - val_loss: 0.6333 - val_accuracy: 0.7263\n","Epoch 20/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0310 - accuracy: 0.9930 - val_loss: 0.7307 - val_accuracy: 0.7338\n","Epoch 21/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0420 - accuracy: 0.9887 - val_loss: 0.9840 - val_accuracy: 0.7069\n","Epoch 22/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0445 - accuracy: 0.9868 - val_loss: 0.8798 - val_accuracy: 0.7328\n","Epoch 23/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0304 - accuracy: 0.9925 - val_loss: 0.8466 - val_accuracy: 0.7619\n","Epoch 24/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0266 - accuracy: 0.9927 - val_loss: 0.8553 - val_accuracy: 0.7791\n","Epoch 25/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0368 - accuracy: 0.9911 - val_loss: 0.9113 - val_accuracy: 0.7694\n","Epoch 26/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0244 - accuracy: 0.9949 - val_loss: 0.8930 - val_accuracy: 0.7726\n","Epoch 27/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0183 - accuracy: 0.9976 - val_loss: 0.9570 - val_accuracy: 0.7672\n","Epoch 28/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0226 - accuracy: 0.9941 - val_loss: 0.9904 - val_accuracy: 0.7672\n","Epoch 29/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0235 - accuracy: 0.9938 - val_loss: 1.0198 - val_accuracy: 0.7877\n","Epoch 30/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0330 - accuracy: 0.9922 - val_loss: 1.1181 - val_accuracy: 0.7468\n","Epoch 31/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0410 - accuracy: 0.9892 - val_loss: 0.9096 - val_accuracy: 0.7877\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0286 - accuracy: 0.9938 - val_loss: 1.0312 - val_accuracy: 0.7716\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0257 - accuracy: 0.9949 - val_loss: 1.0631 - val_accuracy: 0.7651\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0219 - accuracy: 0.9954 - val_loss: 1.0722 - val_accuracy: 0.7662\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0286 - accuracy: 0.9927 - val_loss: 1.1590 - val_accuracy: 0.7597\n","Epoch 36/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0353 - accuracy: 0.9914 - val_loss: 1.2423 - val_accuracy: 0.7392\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0400 - accuracy: 0.9881 - val_loss: 1.0193 - val_accuracy: 0.7651\n","Epoch 38/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0343 - accuracy: 0.9919 - val_loss: 1.0033 - val_accuracy: 0.7672\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0244 - accuracy: 0.9952 - val_loss: 1.0531 - val_accuracy: 0.7629\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0168 - accuracy: 0.9973 - val_loss: 1.0890 - val_accuracy: 0.7748\n","Epoch 41/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0185 - accuracy: 0.9973 - val_loss: 1.1150 - val_accuracy: 0.7737\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0227 - accuracy: 0.9943 - val_loss: 1.0382 - val_accuracy: 0.7769\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0645 - accuracy: 0.9782 - val_loss: 1.1127 - val_accuracy: 0.7263\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0386 - accuracy: 0.9887 - val_loss: 1.0081 - val_accuracy: 0.7608\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0172 - accuracy: 0.9976 - val_loss: 1.1311 - val_accuracy: 0.7608\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0187 - accuracy: 0.9973 - val_loss: 1.2951 - val_accuracy: 0.7511\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0199 - accuracy: 0.9962 - val_loss: 1.0836 - val_accuracy: 0.7769\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0138 - accuracy: 0.9981 - val_loss: 1.0960 - val_accuracy: 0.7791\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0111 - accuracy: 0.9997 - val_loss: 1.0871 - val_accuracy: 0.7866\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0113 - accuracy: 0.9997 - val_loss: 1.2260 - val_accuracy: 0.7780\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0125 - accuracy: 0.9987 - val_loss: 1.1087 - val_accuracy: 0.7769\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0125 - accuracy: 0.9995 - val_loss: 1.1654 - val_accuracy: 0.7672\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0112 - accuracy: 0.9995 - val_loss: 1.1373 - val_accuracy: 0.7834\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0158 - accuracy: 0.9978 - val_loss: 1.1791 - val_accuracy: 0.7619\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0176 - accuracy: 0.9962 - val_loss: 1.3197 - val_accuracy: 0.7425\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0444 - accuracy: 0.9873 - val_loss: 1.1833 - val_accuracy: 0.7381\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0338 - accuracy: 0.9900 - val_loss: 0.9015 - val_accuracy: 0.7726\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0242 - accuracy: 0.9943 - val_loss: 1.0698 - val_accuracy: 0.7565\n","Epoch 59/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0248 - accuracy: 0.9941 - val_loss: 1.2268 - val_accuracy: 0.7489\n","Epoch 60/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0273 - accuracy: 0.9930 - val_loss: 1.1587 - val_accuracy: 0.7619\n","Epoch 61/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0211 - accuracy: 0.9952 - val_loss: 1.1037 - val_accuracy: 0.7672\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0302 - accuracy: 0.9925 - val_loss: 1.2074 - val_accuracy: 0.7489\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0312 - accuracy: 0.9922 - val_loss: 1.2285 - val_accuracy: 0.7252\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0270 - accuracy: 0.9938 - val_loss: 1.2255 - val_accuracy: 0.7371\n","Epoch 65/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0418 - accuracy: 0.9890 - val_loss: 1.1400 - val_accuracy: 0.7478\n","Epoch 66/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0229 - accuracy: 0.9960 - val_loss: 1.2296 - val_accuracy: 0.7597\n","Epoch 67/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0174 - accuracy: 0.9962 - val_loss: 1.2499 - val_accuracy: 0.7500\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0335 - accuracy: 0.9906 - val_loss: 1.1961 - val_accuracy: 0.7500\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0734 - accuracy: 0.9725 - val_loss: 1.1599 - val_accuracy: 0.6961\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0463 - accuracy: 0.9857 - val_loss: 1.0262 - val_accuracy: 0.7586\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0172 - accuracy: 0.9976 - val_loss: 1.1095 - val_accuracy: 0.7672\n","Epoch 72/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0124 - accuracy: 0.9989 - val_loss: 1.2574 - val_accuracy: 0.7575\n","Epoch 73/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0130 - accuracy: 0.9989 - val_loss: 1.3792 - val_accuracy: 0.7274\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0165 - accuracy: 0.9970 - val_loss: 1.3084 - val_accuracy: 0.7478\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0193 - accuracy: 0.9962 - val_loss: 1.2780 - val_accuracy: 0.7489\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0252 - accuracy: 0.9949 - val_loss: 1.2814 - val_accuracy: 0.7328\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0499 - accuracy: 0.9841 - val_loss: 1.4096 - val_accuracy: 0.6929\n","Epoch 78/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0682 - accuracy: 0.9779 - val_loss: 1.0321 - val_accuracy: 0.7134\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0217 - accuracy: 0.9952 - val_loss: 1.0193 - val_accuracy: 0.7651\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0134 - accuracy: 0.9984 - val_loss: 1.1441 - val_accuracy: 0.7672\n","Epoch 81/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0111 - accuracy: 0.9989 - val_loss: 1.1351 - val_accuracy: 0.7726\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0139 - accuracy: 0.9981 - val_loss: 1.4010 - val_accuracy: 0.7328\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0142 - accuracy: 0.9976 - val_loss: 1.2329 - val_accuracy: 0.7500\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0124 - accuracy: 0.9987 - val_loss: 1.2773 - val_accuracy: 0.7328\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0100 - accuracy: 0.9995 - val_loss: 1.2373 - val_accuracy: 0.7489\n","Epoch 86/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.2529 - val_accuracy: 0.7532\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0103 - accuracy: 0.9995 - val_loss: 1.2158 - val_accuracy: 0.7500\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0093 - accuracy: 0.9997 - val_loss: 1.1658 - val_accuracy: 0.7597\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0098 - accuracy: 0.9995 - val_loss: 1.1582 - val_accuracy: 0.7662\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0097 - accuracy: 0.9997 - val_loss: 1.2179 - val_accuracy: 0.7640\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0101 - accuracy: 0.9995 - val_loss: 1.2121 - val_accuracy: 0.7575\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.1577 - val_accuracy: 0.7662\n","Epoch 93/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.1391 - val_accuracy: 0.7694\n","Epoch 94/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.1335 - val_accuracy: 0.7737\n","Epoch 95/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.1239 - val_accuracy: 0.7737\n","Epoch 96/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.1185 - val_accuracy: 0.7726\n","Epoch 97/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.1134 - val_accuracy: 0.7737\n","Epoch 98/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.1092 - val_accuracy: 0.7780\n","Epoch 99/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.1066 - val_accuracy: 0.7769\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.1042 - val_accuracy: 0.7769\n","{'loss': [0.09227319061756134, 0.047653209418058395, 0.030977444723248482, 0.031144121661782265, 0.04545970633625984, 0.05187949910759926, 0.03165518119931221, 0.020978860557079315, 0.019979897886514664, 0.026859579607844353, 0.040810517966747284, 0.047395430505275726, 0.04696295037865639, 0.044233355671167374, 0.042894866317510605, 0.030639193952083588, 0.025732455775141716, 0.03966343775391579, 0.0494498535990715, 0.031031593680381775, 0.04199158027768135, 0.04449380189180374, 0.030367569997906685, 0.026595981791615486, 0.036792632192373276, 0.024353481829166412, 0.018250400200486183, 0.022602027282118797, 0.023538343608379364, 0.03298758715391159, 0.04095142334699631, 0.0285861287266016, 0.025708455592393875, 0.02193824015557766, 0.02856707200407982, 0.03530773147940636, 0.04004377871751785, 0.03425796329975128, 0.02436249330639839, 0.016775786876678467, 0.018510818481445312, 0.0227128267288208, 0.06451122462749481, 0.038577038794755936, 0.017236139625310898, 0.018741397187113762, 0.019928816705942154, 0.013813183642923832, 0.011076332069933414, 0.01127153355628252, 0.012526160106062889, 0.012527098879218102, 0.011174692772328854, 0.015752896666526794, 0.017597924917936325, 0.044442661106586456, 0.03383327275514603, 0.024198142811655998, 0.024769868701696396, 0.027264975011348724, 0.021061008796095848, 0.03022674471139908, 0.031221656128764153, 0.0269722081720829, 0.04184987396001816, 0.022881070151925087, 0.017402490600943565, 0.03349236398935318, 0.07339735329151154, 0.0462651252746582, 0.017242060974240303, 0.012423226609826088, 0.01296405028551817, 0.016455143690109253, 0.01933756098151207, 0.025242049247026443, 0.04993002489209175, 0.06822122633457184, 0.021655717864632607, 0.013424095697700977, 0.01109541766345501, 0.01385434065014124, 0.014206075109541416, 0.012418226338922977, 0.010032357648015022, 0.0094671081751585, 0.010258437134325504, 0.009322961792349815, 0.009828131645917892, 0.00973067432641983, 0.010133945383131504, 0.008703506551682949, 0.00849126372486353, 0.008407636545598507, 0.008383722975850105, 0.008298687636852264, 0.008251163177192211, 0.008205103687942028, 0.008188670501112938, 0.008149043656885624], 'accuracy': [0.9684805870056152, 0.9865301847457886, 0.9929956793785095, 0.9916487336158752, 0.9849137663841248, 0.984375, 0.9916487336158752, 0.9970366358757019, 0.9948814511299133, 0.993803858757019, 0.9870689511299133, 0.9846444129943848, 0.985722005367279, 0.9876077771186829, 0.9878771305084229, 0.9913793206214905, 0.9954202771186829, 0.9881465435028076, 0.985991358757019, 0.9929956793785095, 0.9886853694915771, 0.9867995977401733, 0.9924569129943848, 0.9927262663841248, 0.9911099076271057, 0.9948814511299133, 0.9975754022598267, 0.9940732717514038, 0.993803858757019, 0.9921875, 0.9892241358757019, 0.993803858757019, 0.9948814511299133, 0.9954202771186829, 0.9927262663841248, 0.9913793206214905, 0.9881465435028076, 0.9919180870056152, 0.9951508641242981, 0.9973060488700867, 0.9973060488700867, 0.9943426847457886, 0.978178858757019, 0.9886853694915771, 0.9975754022598267, 0.9973060488700867, 0.9962284564971924, 0.9981142282485962, 0.9997305870056152, 0.9997305870056152, 0.998652994632721, 0.9994612336158752, 0.9994612336158752, 0.9978448152542114, 0.9962284564971924, 0.9873383641242981, 0.9900323152542114, 0.9943426847457886, 0.9940732717514038, 0.9929956793785095, 0.9951508641242981, 0.9924569129943848, 0.9921875, 0.993803858757019, 0.9889547228813171, 0.9959590435028076, 0.9962284564971924, 0.990571141242981, 0.9725215435028076, 0.985722005367279, 0.9975754022598267, 0.9989224076271057, 0.9989224076271057, 0.9970366358757019, 0.9962284564971924, 0.9948814511299133, 0.9841055870056152, 0.977909505367279, 0.9951508641242981, 0.998383641242981, 0.9989224076271057, 0.9981142282485962, 0.9975754022598267, 0.998652994632721, 0.9994612336158752, 1.0, 0.9994612336158752, 0.9997305870056152, 0.9994612336158752, 0.9997305870056152, 0.9994612336158752, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.7000479698181152, 0.6978774070739746, 0.6934143304824829, 0.6871516704559326, 0.6892556548118591, 0.6804040670394897, 0.6700233221054077, 0.6514426469802856, 0.6411767601966858, 0.6204872131347656, 0.6060649752616882, 0.6002510190010071, 0.5925901532173157, 0.6084117293357849, 0.5844544172286987, 0.6174173951148987, 0.6541129946708679, 0.6438583135604858, 0.6332594752311707, 0.7307465076446533, 0.9839628338813782, 0.8797692656517029, 0.8465683460235596, 0.8552877306938171, 0.9113246202468872, 0.8930273652076721, 0.9569558501243591, 0.9904136657714844, 1.0197631120681763, 1.1180607080459595, 0.9096053838729858, 1.0311765670776367, 1.0631219148635864, 1.0721540451049805, 1.15898597240448, 1.2422878742218018, 1.0193179845809937, 1.0032737255096436, 1.053104043006897, 1.0889862775802612, 1.1149909496307373, 1.038171648979187, 1.1127362251281738, 1.0080629587173462, 1.131079077720642, 1.2950676679611206, 1.083555817604065, 1.095967411994934, 1.087096929550171, 1.2260478734970093, 1.108749508857727, 1.1653755903244019, 1.1373143196105957, 1.1791465282440186, 1.3197253942489624, 1.1832811832427979, 0.9015065431594849, 1.0697824954986572, 1.2268402576446533, 1.1586941480636597, 1.1037088632583618, 1.2073825597763062, 1.2284969091415405, 1.2255111932754517, 1.140044093132019, 1.2296408414840698, 1.249851942062378, 1.1961272954940796, 1.1598845720291138, 1.0261534452438354, 1.1094954013824463, 1.2573678493499756, 1.3791829347610474, 1.3083572387695312, 1.2779648303985596, 1.2814280986785889, 1.4095652103424072, 1.0321409702301025, 1.0193283557891846, 1.1440640687942505, 1.1350857019424438, 1.4009778499603271, 1.232940912246704, 1.2772891521453857, 1.2372578382492065, 1.2528560161590576, 1.2157875299453735, 1.1657979488372803, 1.1581560373306274, 1.217854619026184, 1.2120625972747803, 1.1576741933822632, 1.1391167640686035, 1.1334960460662842, 1.1239230632781982, 1.1184871196746826, 1.1134053468704224, 1.109194278717041, 1.1065864562988281, 1.1041719913482666], 'val_accuracy': [0.5150862336158752, 0.514008641242981, 0.545258641242981, 0.5517241358757019, 0.5280172228813171, 0.6368534564971924, 0.587284505367279, 0.6379310488700867, 0.6325430870056152, 0.6616379022598267, 0.6875, 0.6875, 0.6821120977401733, 0.6681034564971924, 0.6821120977401733, 0.6950430870056152, 0.6971982717514038, 0.7262930870056152, 0.7262930870056152, 0.7338362336158752, 0.7068965435028076, 0.732758641242981, 0.7618534564971924, 0.7790948152542114, 0.7693965435028076, 0.7726293206214905, 0.767241358757019, 0.767241358757019, 0.787715494632721, 0.7467672228813171, 0.787715494632721, 0.7715517282485962, 0.7650862336158752, 0.7661637663841248, 0.7596982717514038, 0.7392241358757019, 0.7650862336158752, 0.767241358757019, 0.7629310488700867, 0.774784505367279, 0.7737069129943848, 0.7769396305084229, 0.7262930870056152, 0.7607758641242981, 0.7607758641242981, 0.7510775923728943, 0.7769396305084229, 0.7790948152542114, 0.7866379022598267, 0.7780172228813171, 0.7769396305084229, 0.767241358757019, 0.7834051847457886, 0.7618534564971924, 0.7424569129943848, 0.7381465435028076, 0.7726293206214905, 0.756465494632721, 0.7489224076271057, 0.7618534564971924, 0.767241358757019, 0.7489224076271057, 0.725215494632721, 0.7370689511299133, 0.7478448152542114, 0.7596982717514038, 0.75, 0.75, 0.6961206793785095, 0.7586206793785095, 0.767241358757019, 0.7575430870056152, 0.7273706793785095, 0.7478448152542114, 0.7489224076271057, 0.732758641242981, 0.6928879022598267, 0.7133620977401733, 0.7650862336158752, 0.767241358757019, 0.7726293206214905, 0.732758641242981, 0.75, 0.732758641242981, 0.7489224076271057, 0.7532327771186829, 0.75, 0.7596982717514038, 0.7661637663841248, 0.764008641242981, 0.7575430870056152, 0.7661637663841248, 0.7693965435028076, 0.7737069129943848, 0.7737069129943848, 0.7726293206214905, 0.7737069129943848, 0.7780172228813171, 0.7769396305084229, 0.7769396305084229]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.1547 - accuracy: 0.9525"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 7s 58ms/step - loss: 0.1524 - accuracy: 0.9533 - val_loss: 0.7005 - val_accuracy: 0.5057\n","Epoch 2/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0444 - accuracy: 0.9901 - val_loss: 0.6992 - val_accuracy: 0.5090\n","Epoch 3/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0266 - accuracy: 0.9952 - val_loss: 0.6960 - val_accuracy: 0.5339\n","Epoch 4/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0186 - accuracy: 0.9977 - val_loss: 0.6921 - val_accuracy: 0.5532\n","Epoch 5/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0184 - accuracy: 0.9975 - val_loss: 0.6865 - val_accuracy: 0.5758\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0387 - accuracy: 0.9881 - val_loss: 0.6859 - val_accuracy: 0.5407\n","Epoch 7/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0665 - accuracy: 0.9748 - val_loss: 0.6733 - val_accuracy: 0.6403\n","Epoch 8/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.0497 - accuracy: 0.9844 - val_loss: 0.6631 - val_accuracy: 0.6459\n","Epoch 9/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0429 - accuracy: 0.9890 - val_loss: 0.6480 - val_accuracy: 0.6561\n","Epoch 10/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0316 - accuracy: 0.9912 - val_loss: 0.6415 - val_accuracy: 0.6312\n","Epoch 11/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0371 - accuracy: 0.9904 - val_loss: 0.6189 - val_accuracy: 0.6742\n","Epoch 12/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0213 - accuracy: 0.9969 - val_loss: 0.6056 - val_accuracy: 0.6697\n","Epoch 13/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0219 - accuracy: 0.9960 - val_loss: 0.5992 - val_accuracy: 0.6765\n","Epoch 14/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0295 - accuracy: 0.9926 - val_loss: 0.6156 - val_accuracy: 0.6697\n","Epoch 15/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0234 - accuracy: 0.9955 - val_loss: 0.6069 - val_accuracy: 0.6991\n","Epoch 16/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0454 - accuracy: 0.9859 - val_loss: 0.6000 - val_accuracy: 0.7002\n","Epoch 17/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0398 - accuracy: 0.9875 - val_loss: 0.5293 - val_accuracy: 0.7466\n","Epoch 18/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0417 - accuracy: 0.9884 - val_loss: 0.7108 - val_accuracy: 0.6900\n","Epoch 19/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0758 - accuracy: 0.9726 - val_loss: 0.6671 - val_accuracy: 0.7081\n","Epoch 20/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0644 - accuracy: 0.9785 - val_loss: 0.5615 - val_accuracy: 0.7613\n","Epoch 21/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0237 - accuracy: 0.9958 - val_loss: 0.5532 - val_accuracy: 0.7907\n","Epoch 22/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0195 - accuracy: 0.9972 - val_loss: 0.6067 - val_accuracy: 0.8122\n","Epoch 23/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0214 - accuracy: 0.9963 - val_loss: 0.6442 - val_accuracy: 0.7907\n","Epoch 24/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0270 - accuracy: 0.9935 - val_loss: 0.6144 - val_accuracy: 0.8100\n","Epoch 25/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0271 - accuracy: 0.9929 - val_loss: 0.6622 - val_accuracy: 0.8133\n","Epoch 26/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0215 - accuracy: 0.9969 - val_loss: 0.6532 - val_accuracy: 0.8145\n","Epoch 27/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0193 - accuracy: 0.9975 - val_loss: 0.6398 - val_accuracy: 0.8348\n","Epoch 28/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0170 - accuracy: 0.9977 - val_loss: 0.6739 - val_accuracy: 0.8247\n","Epoch 29/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0266 - accuracy: 0.9941 - val_loss: 0.8505 - val_accuracy: 0.7975\n","Epoch 30/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0391 - accuracy: 0.9901 - val_loss: 0.8166 - val_accuracy: 0.8167\n","Epoch 31/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0403 - accuracy: 0.9890 - val_loss: 0.6851 - val_accuracy: 0.8348\n","Epoch 32/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0291 - accuracy: 0.9926 - val_loss: 0.7312 - val_accuracy: 0.8100\n","Epoch 33/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0261 - accuracy: 0.9943 - val_loss: 0.7216 - val_accuracy: 0.8224\n","Epoch 34/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0203 - accuracy: 0.9955 - val_loss: 0.8392 - val_accuracy: 0.8020\n","Epoch 35/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0167 - accuracy: 0.9975 - val_loss: 0.7495 - val_accuracy: 0.8213\n","Epoch 36/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0155 - accuracy: 0.9980 - val_loss: 0.6995 - val_accuracy: 0.8462\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0464 - accuracy: 0.9864 - val_loss: 1.2914 - val_accuracy: 0.7398\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0710 - accuracy: 0.9768 - val_loss: 0.6406 - val_accuracy: 0.8043\n","Epoch 39/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0319 - accuracy: 0.9912 - val_loss: 1.0523 - val_accuracy: 0.7500\n","Epoch 40/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0311 - accuracy: 0.9929 - val_loss: 0.8298 - val_accuracy: 0.8145\n","Epoch 41/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0352 - accuracy: 0.9912 - val_loss: 0.7822 - val_accuracy: 0.8043\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0220 - accuracy: 0.9960 - val_loss: 0.9060 - val_accuracy: 0.7907\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0193 - accuracy: 0.9977 - val_loss: 0.9822 - val_accuracy: 0.7896\n","Epoch 44/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0168 - accuracy: 0.9977 - val_loss: 0.8566 - val_accuracy: 0.8190\n","Epoch 45/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0191 - accuracy: 0.9972 - val_loss: 0.8356 - val_accuracy: 0.8156\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0184 - accuracy: 0.9966 - val_loss: 0.8087 - val_accuracy: 0.8190\n","Epoch 47/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0228 - accuracy: 0.9960 - val_loss: 0.9543 - val_accuracy: 0.7941\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0455 - accuracy: 0.9864 - val_loss: 0.9432 - val_accuracy: 0.7726\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0828 - accuracy: 0.9709 - val_loss: 1.2333 - val_accuracy: 0.7342\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0774 - accuracy: 0.9734 - val_loss: 0.7179 - val_accuracy: 0.7817\n","Epoch 51/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0186 - accuracy: 0.9980 - val_loss: 0.8297 - val_accuracy: 0.8032\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0139 - accuracy: 0.9989 - val_loss: 0.8228 - val_accuracy: 0.8201\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0112 - accuracy: 0.9994 - val_loss: 0.8880 - val_accuracy: 0.8077\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.8291 - val_accuracy: 0.8224\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.8411 - val_accuracy: 0.8190\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.8390 - val_accuracy: 0.8156\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.8164 - val_accuracy: 0.8213\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.8031 - val_accuracy: 0.8224\n","Epoch 59/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.8053 - val_accuracy: 0.8258\n","Epoch 60/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.7984 - val_accuracy: 0.8258\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.7956 - val_accuracy: 0.8247\n","Epoch 62/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.7901 - val_accuracy: 0.8247\n","Epoch 63/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.7911 - val_accuracy: 0.8201\n","Epoch 64/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.7784 - val_accuracy: 0.8224\n","Epoch 65/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.7807 - val_accuracy: 0.8213\n","Epoch 66/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.7739 - val_accuracy: 0.8201\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.7779 - val_accuracy: 0.8167\n","Epoch 68/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.7710 - val_accuracy: 0.8213\n","Epoch 69/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.7740 - val_accuracy: 0.8213\n","Epoch 70/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.7778 - val_accuracy: 0.8179\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.7744 - val_accuracy: 0.8235\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.7693 - val_accuracy: 0.8247\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.7611 - val_accuracy: 0.8201\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.7632 - val_accuracy: 0.8247\n","Epoch 75/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.7585 - val_accuracy: 0.8201\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.7611 - val_accuracy: 0.8190\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.7605 - val_accuracy: 0.8190\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.7585 - val_accuracy: 0.8201\n","Epoch 79/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.7602 - val_accuracy: 0.8190\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.7559 - val_accuracy: 0.8213\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.7573 - val_accuracy: 0.8224\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.7581 - val_accuracy: 0.8213\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.7644 - val_accuracy: 0.8201\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.7628 - val_accuracy: 0.8235\n","Epoch 85/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.7608 - val_accuracy: 0.8235\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.7560 - val_accuracy: 0.8235\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.7586 - val_accuracy: 0.8190\n","Epoch 88/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.7534 - val_accuracy: 0.8235\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.7548 - val_accuracy: 0.8258\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.7548 - val_accuracy: 0.8224\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.7526 - val_accuracy: 0.8235\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.7525 - val_accuracy: 0.8235\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.7525 - val_accuracy: 0.8235\n","Epoch 94/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.7553 - val_accuracy: 0.8235\n","Epoch 95/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.7527 - val_accuracy: 0.8235\n","Epoch 96/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.7562 - val_accuracy: 0.8247\n","Epoch 97/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.7536 - val_accuracy: 0.8235\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.7583 - val_accuracy: 0.8224\n","Epoch 99/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.7525 - val_accuracy: 0.8247\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.7572 - val_accuracy: 0.8235\n","{'loss': [0.1523689329624176, 0.04439631104469299, 0.02659445069730282, 0.018598521128296852, 0.018428804352879524, 0.03868986293673515, 0.06648992002010345, 0.04966152086853981, 0.04287128150463104, 0.03158881515264511, 0.03707916662096977, 0.021334348246455193, 0.0219365693628788, 0.029544014483690262, 0.02342604659497738, 0.04543564096093178, 0.039819471538066864, 0.041684627532958984, 0.07578322291374207, 0.06444253772497177, 0.023682480677962303, 0.019480545073747635, 0.02139391377568245, 0.026975762099027634, 0.027136173099279404, 0.021502023562788963, 0.01934390887618065, 0.01702979765832424, 0.026599541306495667, 0.0391436330974102, 0.040314264595508575, 0.029105713590979576, 0.026083897799253464, 0.020292436704039574, 0.016725027933716774, 0.015525907278060913, 0.046387605369091034, 0.07101401686668396, 0.03190714120864868, 0.031062157824635506, 0.03522416204214096, 0.02199569344520569, 0.01926116831600666, 0.016812007874250412, 0.019132042303681374, 0.018416058272123337, 0.02278396300971508, 0.04549024626612663, 0.08282884955406189, 0.07736768573522568, 0.018561402335762978, 0.01386586669832468, 0.011221504770219326, 0.009941195137798786, 0.009629801847040653, 0.009459473192691803, 0.009433625265955925, 0.009388785809278488, 0.009302619844675064, 0.009250415489077568, 0.009169762954115868, 0.009096830151975155, 0.009057090617716312, 0.009011775255203247, 0.008963528089225292, 0.008928014896810055, 0.008883998729288578, 0.008886555209755898, 0.008834186010062695, 0.008813004940748215, 0.008764388039708138, 0.008746979758143425, 0.008678079582750797, 0.008656376972794533, 0.008639758452773094, 0.008596292696893215, 0.008580747991800308, 0.008575073443353176, 0.00852795410901308, 0.00851492304354906, 0.008481482975184917, 0.008501850999891758, 0.008442842401564121, 0.008421998471021652, 0.008406165987253189, 0.00837075337767601, 0.008353537879884243, 0.008316932246088982, 0.008304298855364323, 0.008297482505440712, 0.008279787376523018, 0.008236422203481197, 0.008222951553761959, 0.008212203159928322, 0.008190257474780083, 0.0081796795129776, 0.008159710094332695, 0.008136577904224396, 0.008117332123219967, 0.008106032386422157], 'accuracy': [0.9533106684684753, 0.9900962114334106, 0.9951896071434021, 0.9977362751960754, 0.9974533319473267, 0.9881154298782349, 0.974816083908081, 0.9844368696212769, 0.988964319229126, 0.9912280440330505, 0.9903791546821594, 0.9968873858451843, 0.9960384964942932, 0.992642879486084, 0.9954725503921509, 0.9858517050743103, 0.9875495433807373, 0.9883984327316284, 0.9725523591041565, 0.9784946441650391, 0.9957554936408997, 0.9971703290939331, 0.996321439743042, 0.9934917688369751, 0.9929258823394775, 0.9968873858451843, 0.9974533319473267, 0.9977362751960754, 0.9940577149391174, 0.9900962114334106, 0.988964319229126, 0.992642879486084, 0.994340717792511, 0.9954725503921509, 0.9974533319473267, 0.9980192184448242, 0.9864176511764526, 0.9767968058586121, 0.9912280440330505, 0.9929258823394775, 0.9912280440330505, 0.9960384964942932, 0.9977362751960754, 0.9977362751960754, 0.9971703290939331, 0.9966044425964355, 0.9960384964942932, 0.9864176511764526, 0.9708545804023743, 0.9734012484550476, 0.9980192184448242, 0.9988681674003601, 0.9994340538978577, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.7004837989807129, 0.6991576552391052, 0.6960003972053528, 0.6920522451400757, 0.6864781379699707, 0.6858539581298828, 0.6733284592628479, 0.6630605459213257, 0.6480472683906555, 0.6415427923202515, 0.6188677549362183, 0.605637788772583, 0.5992165207862854, 0.6155847907066345, 0.6068606972694397, 0.6000228524208069, 0.5293124914169312, 0.7108107209205627, 0.6671473979949951, 0.5615378618240356, 0.5532169938087463, 0.6067087650299072, 0.6441563367843628, 0.6144447922706604, 0.662204384803772, 0.6532003879547119, 0.6398277878761292, 0.6738912463188171, 0.8504508137702942, 0.8165650963783264, 0.6850916147232056, 0.7311844825744629, 0.7215775847434998, 0.8392456769943237, 0.7495366334915161, 0.6995355486869812, 1.2913808822631836, 0.6406006217002869, 1.0523015260696411, 0.8297787308692932, 0.7821915149688721, 0.9060015678405762, 0.9821908473968506, 0.8566242456436157, 0.8355575203895569, 0.8087432980537415, 0.9543110132217407, 0.9432142972946167, 1.2332879304885864, 0.7179468870162964, 0.8296564817428589, 0.8227846026420593, 0.8879722952842712, 0.8291144967079163, 0.8410707116127014, 0.8389700055122375, 0.8163501024246216, 0.8030557036399841, 0.8052998781204224, 0.7984238862991333, 0.7955554127693176, 0.7901480197906494, 0.7910641431808472, 0.7784162759780884, 0.7807363867759705, 0.773922860622406, 0.7779361009597778, 0.7709890604019165, 0.7739916443824768, 0.7778107523918152, 0.7744370698928833, 0.7693089246749878, 0.7611158490180969, 0.7631561160087585, 0.7584631443023682, 0.7611082196235657, 0.7605441212654114, 0.7585358619689941, 0.760233461856842, 0.7559024691581726, 0.7573124170303345, 0.7581424713134766, 0.7644173502922058, 0.762798547744751, 0.7607758641242981, 0.7559506297111511, 0.7585520148277283, 0.7534013986587524, 0.7548172473907471, 0.7548308968544006, 0.7526265978813171, 0.7524832487106323, 0.7525137066841125, 0.7552826404571533, 0.7527064681053162, 0.756172776222229, 0.7536162734031677, 0.7583118081092834, 0.7524927854537964, 0.7572142481803894], 'val_accuracy': [0.5056561231613159, 0.5090497732162476, 0.5339366793632507, 0.5531674027442932, 0.5757918357849121, 0.540723979473114, 0.6402714848518372, 0.6459276080131531, 0.6561086177825928, 0.6312217116355896, 0.6742081642150879, 0.6696832776069641, 0.6764705777168274, 0.6696832776069641, 0.6990950107574463, 0.7002262473106384, 0.7466063499450684, 0.6900452375411987, 0.7081447839736938, 0.7613122463226318, 0.790723979473114, 0.8122171759605408, 0.790723979473114, 0.8099547624588013, 0.8133484125137329, 0.814479649066925, 0.8348416090011597, 0.8246606588363647, 0.7975113391876221, 0.8167420625686646, 0.8348416090011597, 0.8099547624588013, 0.8223981857299805, 0.8020362257957458, 0.8212669491767883, 0.8461538553237915, 0.7398189902305603, 0.8042986392974854, 0.75, 0.814479649066925, 0.8042986392974854, 0.790723979473114, 0.7895927429199219, 0.8190045356750488, 0.8156108856201172, 0.8190045356750488, 0.7941176295280457, 0.7726244330406189, 0.7341628670692444, 0.7816742062568665, 0.8031674027442932, 0.820135772228241, 0.807692289352417, 0.8223981857299805, 0.8190045356750488, 0.8156108856201172, 0.8212669491767883, 0.8223981857299805, 0.8257918357849121, 0.8257918357849121, 0.8246606588363647, 0.8246606588363647, 0.820135772228241, 0.8223981857299805, 0.8212669491767883, 0.820135772228241, 0.8167420625686646, 0.8212669491767883, 0.8212669491767883, 0.8178732991218567, 0.8235294222831726, 0.8246606588363647, 0.820135772228241, 0.8246606588363647, 0.820135772228241, 0.8190045356750488, 0.8190045356750488, 0.820135772228241, 0.8190045356750488, 0.8212669491767883, 0.8223981857299805, 0.8212669491767883, 0.820135772228241, 0.8235294222831726, 0.8235294222831726, 0.8235294222831726, 0.8190045356750488, 0.8235294222831726, 0.8257918357849121, 0.8223981857299805, 0.8235294222831726, 0.8235294222831726, 0.8235294222831726, 0.8235294222831726, 0.8235294222831726, 0.8246606588363647, 0.8235294222831726, 0.8223981857299805, 0.8246606588363647, 0.8235294222831726]}\n","45/45 [==============================] - 2s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.1074 - accuracy: 0.9666"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 9s 57ms/step - loss: 0.1092 - accuracy: 0.9654 - val_loss: 0.6984 - val_accuracy: 0.5465\n","Epoch 2/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0620 - accuracy: 0.9796 - val_loss: 0.6970 - val_accuracy: 0.5186\n","Epoch 3/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0367 - accuracy: 0.9904 - val_loss: 0.6957 - val_accuracy: 0.5207\n","Epoch 4/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0336 - accuracy: 0.9915 - val_loss: 0.6902 - val_accuracy: 0.5362\n","Epoch 5/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0358 - accuracy: 0.9902 - val_loss: 0.6803 - val_accuracy: 0.5775\n","Epoch 6/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0548 - accuracy: 0.9824 - val_loss: 0.6770 - val_accuracy: 0.5692\n","Epoch 7/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1565 - accuracy: 0.9406 - val_loss: 0.6806 - val_accuracy: 0.5950\n","Epoch 8/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0474 - accuracy: 0.9886 - val_loss: 0.6658 - val_accuracy: 0.5868\n","Epoch 9/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0231 - accuracy: 0.9959 - val_loss: 0.6495 - val_accuracy: 0.6023\n","Epoch 10/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0183 - accuracy: 0.9969 - val_loss: 0.6312 - val_accuracy: 0.6446\n","Epoch 11/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0189 - accuracy: 0.9974 - val_loss: 0.6052 - val_accuracy: 0.6808\n","Epoch 12/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0189 - accuracy: 0.9974 - val_loss: 0.5832 - val_accuracy: 0.6973\n","Epoch 13/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0147 - accuracy: 0.9984 - val_loss: 0.5966 - val_accuracy: 0.6901\n","Epoch 14/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0171 - accuracy: 0.9972 - val_loss: 0.5828 - val_accuracy: 0.7262\n","Epoch 15/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0244 - accuracy: 0.9941 - val_loss: 0.7464 - val_accuracy: 0.6880\n","Epoch 16/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0878 - accuracy: 0.9705 - val_loss: 0.7187 - val_accuracy: 0.6622\n","Epoch 17/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0713 - accuracy: 0.9770 - val_loss: 0.5706 - val_accuracy: 0.7345\n","Epoch 18/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0340 - accuracy: 0.9897 - val_loss: 0.6608 - val_accuracy: 0.7376\n","Epoch 19/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0270 - accuracy: 0.9920 - val_loss: 0.6255 - val_accuracy: 0.7769\n","Epoch 20/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0226 - accuracy: 0.9961 - val_loss: 1.0317 - val_accuracy: 0.7066\n","Epoch 21/100\n","31/31 [==============================] - 1s 39ms/step - loss: 0.0381 - accuracy: 0.9881 - val_loss: 0.7608 - val_accuracy: 0.7944\n","Epoch 22/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0574 - accuracy: 0.9798 - val_loss: 0.7363 - val_accuracy: 0.7810\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0389 - accuracy: 0.9876 - val_loss: 0.7241 - val_accuracy: 0.7924\n","Epoch 24/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0626 - accuracy: 0.9801 - val_loss: 0.6974 - val_accuracy: 0.8017\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0419 - accuracy: 0.9886 - val_loss: 0.8234 - val_accuracy: 0.7800\n","Epoch 26/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0224 - accuracy: 0.9956 - val_loss: 0.8060 - val_accuracy: 0.8037\n","Epoch 27/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0160 - accuracy: 0.9987 - val_loss: 0.8534 - val_accuracy: 0.8120\n","Epoch 28/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0141 - accuracy: 0.9990 - val_loss: 0.8620 - val_accuracy: 0.8202\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0135 - accuracy: 0.9990 - val_loss: 0.9049 - val_accuracy: 0.8192\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0136 - accuracy: 0.9990 - val_loss: 0.8645 - val_accuracy: 0.8192\n","Epoch 31/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0124 - accuracy: 0.9992 - val_loss: 0.8732 - val_accuracy: 0.8161\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0124 - accuracy: 0.9995 - val_loss: 0.8878 - val_accuracy: 0.8192\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.9066 - val_accuracy: 0.8182\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0105 - accuracy: 0.9997 - val_loss: 0.9262 - val_accuracy: 0.8182\n","Epoch 35/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0107 - accuracy: 0.9995 - val_loss: 0.8781 - val_accuracy: 0.8254\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0123 - accuracy: 0.9992 - val_loss: 0.8904 - val_accuracy: 0.8161\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0112 - accuracy: 0.9997 - val_loss: 0.9304 - val_accuracy: 0.8120\n","Epoch 38/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.9075 - val_accuracy: 0.8213\n","Epoch 39/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.8969 - val_accuracy: 0.8244\n","Epoch 40/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.8921 - val_accuracy: 0.8182\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.8880 - val_accuracy: 0.8223\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.8899 - val_accuracy: 0.8233\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.8807 - val_accuracy: 0.8244\n","Epoch 44/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.8898 - val_accuracy: 0.8161\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.8800 - val_accuracy: 0.8202\n","Epoch 46/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.8766 - val_accuracy: 0.8192\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.8690 - val_accuracy: 0.8213\n","Epoch 48/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.8658 - val_accuracy: 0.8233\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.8677 - val_accuracy: 0.8161\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.8656 - val_accuracy: 0.8223\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.8617 - val_accuracy: 0.8233\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.8705 - val_accuracy: 0.8202\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0119 - accuracy: 0.9992 - val_loss: 0.8628 - val_accuracy: 0.8182\n","Epoch 54/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0123 - accuracy: 0.9992 - val_loss: 0.9010 - val_accuracy: 0.8048\n","Epoch 55/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0236 - accuracy: 0.9953 - val_loss: 1.2281 - val_accuracy: 0.7459\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1584 - accuracy: 0.9411 - val_loss: 0.6861 - val_accuracy: 0.7252\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0950 - accuracy: 0.9656 - val_loss: 1.4111 - val_accuracy: 0.6860\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0704 - accuracy: 0.9767 - val_loss: 1.2280 - val_accuracy: 0.7180\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1252 - accuracy: 0.9556 - val_loss: 0.6994 - val_accuracy: 0.7717\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.0567 - accuracy: 0.9822 - val_loss: 0.9099 - val_accuracy: 0.7800\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0432 - accuracy: 0.9866 - val_loss: 1.0494 - val_accuracy: 0.7562\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1071 - accuracy: 0.9636 - val_loss: 0.9233 - val_accuracy: 0.7159\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0442 - accuracy: 0.9879 - val_loss: 1.0988 - val_accuracy: 0.7273\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0315 - accuracy: 0.9904 - val_loss: 1.0625 - val_accuracy: 0.7562\n","Epoch 65/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0282 - accuracy: 0.9915 - val_loss: 0.9770 - val_accuracy: 0.7738\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0244 - accuracy: 0.9946 - val_loss: 1.0890 - val_accuracy: 0.7572\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0298 - accuracy: 0.9933 - val_loss: 1.1431 - val_accuracy: 0.7541\n","Epoch 68/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0370 - accuracy: 0.9868 - val_loss: 1.0669 - val_accuracy: 0.7655\n","Epoch 69/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1342 - accuracy: 0.9527 - val_loss: 0.7344 - val_accuracy: 0.7645\n","Epoch 70/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0417 - accuracy: 0.9886 - val_loss: 0.9841 - val_accuracy: 0.7593\n","Epoch 71/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0181 - accuracy: 0.9964 - val_loss: 1.1485 - val_accuracy: 0.7603\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0215 - accuracy: 0.9956 - val_loss: 1.1480 - val_accuracy: 0.7738\n","Epoch 73/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0506 - accuracy: 0.9832 - val_loss: 1.6574 - val_accuracy: 0.6808\n","Epoch 74/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0479 - accuracy: 0.9837 - val_loss: 0.9908 - val_accuracy: 0.7624\n","Epoch 75/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0251 - accuracy: 0.9933 - val_loss: 1.2127 - val_accuracy: 0.7386\n","Epoch 76/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0266 - accuracy: 0.9943 - val_loss: 1.2185 - val_accuracy: 0.7397\n","Epoch 77/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0301 - accuracy: 0.9915 - val_loss: 1.1259 - val_accuracy: 0.7583\n","Epoch 78/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0259 - accuracy: 0.9941 - val_loss: 1.1383 - val_accuracy: 0.7624\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0219 - accuracy: 0.9953 - val_loss: 1.1292 - val_accuracy: 0.7707\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0310 - accuracy: 0.9907 - val_loss: 1.1277 - val_accuracy: 0.7707\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0227 - accuracy: 0.9951 - val_loss: 1.0935 - val_accuracy: 0.7665\n","Epoch 82/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0192 - accuracy: 0.9961 - val_loss: 1.1199 - val_accuracy: 0.7696\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0133 - accuracy: 0.9995 - val_loss: 1.0610 - val_accuracy: 0.7800\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0106 - accuracy: 0.9995 - val_loss: 1.0933 - val_accuracy: 0.7893\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0124 - accuracy: 0.9984 - val_loss: 1.0710 - val_accuracy: 0.7955\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0135 - accuracy: 0.9984 - val_loss: 1.0787 - val_accuracy: 0.7800\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0138 - accuracy: 0.9987 - val_loss: 1.0520 - val_accuracy: 0.7820\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0118 - accuracy: 0.9992 - val_loss: 1.0414 - val_accuracy: 0.7831\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0104 - accuracy: 0.9992 - val_loss: 1.0742 - val_accuracy: 0.7841\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.0596 - val_accuracy: 0.7913\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.0488 - val_accuracy: 0.7913\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.0404 - val_accuracy: 0.7944\n","Epoch 93/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.0339 - val_accuracy: 0.7893\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.0251 - val_accuracy: 0.7903\n","Epoch 95/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.0206 - val_accuracy: 0.7924\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.0189 - val_accuracy: 0.7955\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.0201 - val_accuracy: 0.7934\n","Epoch 98/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.0074 - val_accuracy: 0.7944\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.0062 - val_accuracy: 0.7903\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.0025 - val_accuracy: 0.7934\n","{'loss': [0.10920348763465881, 0.06204022839665413, 0.0366944782435894, 0.033572740852832794, 0.035837892442941666, 0.054795488715171814, 0.15654799342155457, 0.04741029068827629, 0.023116320371627808, 0.01829376444220543, 0.018928108736872673, 0.0189410038292408, 0.01471965853124857, 0.01709653064608574, 0.024431070312857628, 0.08776248246431351, 0.0712938979268074, 0.03397773206233978, 0.027040626853704453, 0.022648580372333527, 0.0380776971578598, 0.05739833787083626, 0.038901399821043015, 0.06259559094905853, 0.04191332310438156, 0.022367224097251892, 0.015955334529280663, 0.01410708948969841, 0.013459633104503155, 0.01358200516551733, 0.012440509162843227, 0.01244436390697956, 0.010877690277993679, 0.010542439296841621, 0.01071249321103096, 0.012331414967775345, 0.011155436746776104, 0.010172480717301369, 0.009772936813533306, 0.009618251584470272, 0.009531102143228054, 0.009575989097356796, 0.00961480662226677, 0.00950979720801115, 0.009466847404837608, 0.009200087748467922, 0.009182772599160671, 0.009174102917313576, 0.009139971807599068, 0.009101379662752151, 0.00897800363600254, 0.009047766216099262, 0.011870035901665688, 0.012301393784582615, 0.023580847308039665, 0.15839718282222748, 0.09495231509208679, 0.07040324062108994, 0.12521259486675262, 0.05674286559224129, 0.043213389813899994, 0.10712502896785736, 0.04422680661082268, 0.03151659294962883, 0.028221307322382927, 0.02436390519142151, 0.029781784862279892, 0.036955177783966064, 0.13415680825710297, 0.04165215417742729, 0.018051430583000183, 0.021494342014193535, 0.05055324360728264, 0.04792865738272667, 0.025138599798083305, 0.02664795331656933, 0.03009435161948204, 0.02590308152139187, 0.021924078464508057, 0.030977824702858925, 0.02266157604753971, 0.019173908978700638, 0.013254785910248756, 0.010561740025877953, 0.012424718588590622, 0.0135386623442173, 0.013841900043189526, 0.011758905835449696, 0.010404055938124657, 0.00940533448010683, 0.00908694975078106, 0.008885830640792847, 0.008801694959402084, 0.008707273751497269, 0.008671911433339119, 0.008619747124612331, 0.008617212995886803, 0.008528194390237331, 0.008490361273288727, 0.00842701829969883], 'accuracy': [0.9653746485710144, 0.9795865416526794, 0.9904392957687378, 0.9914728403091431, 0.9901808500289917, 0.9824289679527283, 0.9405684471130371, 0.988630473613739, 0.9958656430244446, 0.9968992471694946, 0.9974160194396973, 0.9974160194396973, 0.9984496235847473, 0.997157633304596, 0.9940568208694458, 0.9705426096916199, 0.9770025610923767, 0.9896640777587891, 0.9919896721839905, 0.9961240291595459, 0.9881137013435364, 0.9798449873924255, 0.987596869468689, 0.9801033735275269, 0.988630473613739, 0.9956072568893433, 0.9987080097198486, 0.99896639585495, 0.99896639585495, 0.99896639585495, 0.9992247819900513, 0.9994832277297974, 1.0, 0.9997416138648987, 0.9994832277297974, 0.9992247819900513, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9992247819900513, 0.9992247819900513, 0.9953488111495972, 0.9410852789878845, 0.9656330943107605, 0.9767441749572754, 0.9555555582046509, 0.9821705222129822, 0.9865633249282837, 0.9635658860206604, 0.9878553152084351, 0.9904392957687378, 0.9914728403091431, 0.9945736527442932, 0.9932816624641418, 0.986821711063385, 0.9527131915092468, 0.988630473613739, 0.9963824152946472, 0.9956072568893433, 0.9832041263580322, 0.9837209582328796, 0.9932816624641418, 0.9943152666091919, 0.9914728403091431, 0.9940568208694458, 0.9953488111495972, 0.9906976819038391, 0.9950904250144958, 0.9961240291595459, 0.9994832277297974, 0.9994832277297974, 0.9984496235847473, 0.9984496235847473, 0.9987080097198486, 0.9992247819900513, 0.9992247819900513, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.6983692049980164, 0.6970067024230957, 0.6956830024719238, 0.6901938915252686, 0.6803295612335205, 0.6770114898681641, 0.6806193590164185, 0.6657792329788208, 0.6495161056518555, 0.631247878074646, 0.6051748394966125, 0.5831942558288574, 0.5966050624847412, 0.5827992558479309, 0.7464286088943481, 0.7186629772186279, 0.5706208944320679, 0.6607691645622253, 0.6255491375923157, 1.03171706199646, 0.7607736587524414, 0.7362522482872009, 0.7240666747093201, 0.6973738670349121, 0.8234241604804993, 0.8059680461883545, 0.8533609509468079, 0.8619672656059265, 0.9048529863357544, 0.8645474314689636, 0.8731780052185059, 0.8878254890441895, 0.9065942764282227, 0.9261569976806641, 0.8780791759490967, 0.8903505802154541, 0.9303727746009827, 0.9075325131416321, 0.896879255771637, 0.8920777440071106, 0.8880274891853333, 0.8898993134498596, 0.8806682229042053, 0.8898393511772156, 0.8799844980239868, 0.8765836358070374, 0.868962824344635, 0.8657968640327454, 0.8676885962486267, 0.8655682802200317, 0.8616843819618225, 0.8705301284790039, 0.8627998232841492, 0.9009679555892944, 1.228057622909546, 0.6861234307289124, 1.411105990409851, 1.2279579639434814, 0.699393093585968, 0.9098605513572693, 1.049446702003479, 0.9233089685440063, 1.0988408327102661, 1.0625020265579224, 0.9769793152809143, 1.0890169143676758, 1.1430673599243164, 1.0668931007385254, 0.7343921661376953, 0.9840633273124695, 1.1485182046890259, 1.1480060815811157, 1.6574485301971436, 0.9907745122909546, 1.2126586437225342, 1.21849524974823, 1.1259374618530273, 1.1383477449417114, 1.1291618347167969, 1.127720832824707, 1.09346342086792, 1.1199300289154053, 1.061015009880066, 1.093264102935791, 1.0709532499313354, 1.0786612033843994, 1.0519760847091675, 1.0413931608200073, 1.0741524696350098, 1.0595592260360718, 1.048815369606018, 1.0403767824172974, 1.0338603258132935, 1.02506685256958, 1.0205698013305664, 1.0189212560653687, 1.0200557708740234, 1.007407307624817, 1.0062206983566284, 1.0025242567062378], 'val_accuracy': [0.5464876294136047, 0.5185950398445129, 0.5206611752510071, 0.5361570119857788, 0.577479362487793, 0.5692148804664612, 0.5950413346290588, 0.586776852607727, 0.6022727489471436, 0.64462810754776, 0.6807851195335388, 0.6973140239715576, 0.6900826692581177, 0.7262396812438965, 0.6880165338516235, 0.6621900796890259, 0.7345041036605835, 0.7376033067703247, 0.7768595218658447, 0.7066115736961365, 0.7944214940071106, 0.7809917330741882, 0.7923553586006165, 0.8016529083251953, 0.7799586653709412, 0.8037189841270447, 0.8119834661483765, 0.8202479481697083, 0.8192148804664612, 0.8192148804664612, 0.81611567735672, 0.8192148804664612, 0.8181818127632141, 0.8181818127632141, 0.8254132270812988, 0.81611567735672, 0.8119834661483765, 0.8212810158729553, 0.8243801593780518, 0.8181818127632141, 0.8223140239715576, 0.8233470916748047, 0.8243801593780518, 0.81611567735672, 0.8202479481697083, 0.8192148804664612, 0.8212810158729553, 0.8233470916748047, 0.81611567735672, 0.8223140239715576, 0.8233470916748047, 0.8202479481697083, 0.8181818127632141, 0.8047520518302917, 0.7458677887916565, 0.7252066135406494, 0.6859503984451294, 0.7179751992225647, 0.7716942429542542, 0.7799586653709412, 0.7561983466148376, 0.7159090638160706, 0.7272727489471436, 0.7561983466148376, 0.7737603187561035, 0.7572314143180847, 0.7541322112083435, 0.7654958963394165, 0.7644628286361694, 0.7592975497245789, 0.7603305578231812, 0.7737603187561035, 0.6807851195335388, 0.7623966932296753, 0.7386363744735718, 0.7396694421768188, 0.7582644820213318, 0.7623966932296753, 0.7706611752510071, 0.7706611752510071, 0.7665289044380188, 0.76962810754776, 0.7799586653709412, 0.78925621509552, 0.7954545617103577, 0.7799586653709412, 0.7820248007774353, 0.7830578684806824, 0.7840909361839294, 0.7913222908973694, 0.7913222908973694, 0.7944214940071106, 0.78925621509552, 0.7902892827987671, 0.7923553586006165, 0.7954545617103577, 0.7933884263038635, 0.7944214940071106, 0.7902892827987671, 0.7933884263038635]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/29 [========================>.....] - ETA: 0s - loss: 0.0632 - accuracy: 0.9825"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 53ms/step - loss: 0.0615 - accuracy: 0.9822 - val_loss: 0.6975 - val_accuracy: 0.5151\n","Epoch 2/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0321 - accuracy: 0.9925 - val_loss: 0.6946 - val_accuracy: 0.5205\n","Epoch 3/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0182 - accuracy: 0.9962 - val_loss: 0.6906 - val_accuracy: 0.5237\n","Epoch 4/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0170 - accuracy: 0.9970 - val_loss: 0.6822 - val_accuracy: 0.6056\n","Epoch 5/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0275 - accuracy: 0.9930 - val_loss: 0.6781 - val_accuracy: 0.5851\n","Epoch 6/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0396 - accuracy: 0.9895 - val_loss: 0.6711 - val_accuracy: 0.6099\n","Epoch 7/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0331 - accuracy: 0.9914 - val_loss: 0.6665 - val_accuracy: 0.6034\n","Epoch 8/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0213 - accuracy: 0.9965 - val_loss: 0.6535 - val_accuracy: 0.6325\n","Epoch 9/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0229 - accuracy: 0.9952 - val_loss: 0.6380 - val_accuracy: 0.6336\n","Epoch 10/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0380 - accuracy: 0.9892 - val_loss: 0.6325 - val_accuracy: 0.6272\n","Epoch 11/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0543 - accuracy: 0.9836 - val_loss: 0.6064 - val_accuracy: 0.6853\n","Epoch 12/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0248 - accuracy: 0.9930 - val_loss: 0.5890 - val_accuracy: 0.6897\n","Epoch 13/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0173 - accuracy: 0.9970 - val_loss: 0.5497 - val_accuracy: 0.7231\n","Epoch 14/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0170 - accuracy: 0.9968 - val_loss: 0.6568 - val_accuracy: 0.6886\n","Epoch 15/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0163 - accuracy: 0.9978 - val_loss: 0.5443 - val_accuracy: 0.7414\n","Epoch 16/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0106 - accuracy: 0.9995 - val_loss: 0.6317 - val_accuracy: 0.7328\n","Epoch 17/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0135 - accuracy: 0.9981 - val_loss: 0.6065 - val_accuracy: 0.7619\n","Epoch 18/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0181 - accuracy: 0.9957 - val_loss: 0.7393 - val_accuracy: 0.7532\n","Epoch 19/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0264 - accuracy: 0.9930 - val_loss: 0.6329 - val_accuracy: 0.7651\n","Epoch 20/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0299 - accuracy: 0.9916 - val_loss: 0.9296 - val_accuracy: 0.7284\n","Epoch 21/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0629 - accuracy: 0.9787 - val_loss: 0.6265 - val_accuracy: 0.7748\n","Epoch 22/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0316 - accuracy: 0.9916 - val_loss: 0.7020 - val_accuracy: 0.7899\n","Epoch 23/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0305 - accuracy: 0.9900 - val_loss: 0.7298 - val_accuracy: 0.7909\n","Epoch 24/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.0300 - accuracy: 0.9914 - val_loss: 0.6468 - val_accuracy: 0.8060\n","Epoch 25/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0331 - accuracy: 0.9898 - val_loss: 0.9018 - val_accuracy: 0.7791\n","Epoch 26/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0393 - accuracy: 0.9911 - val_loss: 0.6549 - val_accuracy: 0.8265\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0184 - accuracy: 0.9954 - val_loss: 0.7988 - val_accuracy: 0.8125\n","Epoch 28/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0145 - accuracy: 0.9976 - val_loss: 0.7315 - val_accuracy: 0.8297\n","Epoch 29/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0161 - accuracy: 0.9973 - val_loss: 0.8389 - val_accuracy: 0.8082\n","Epoch 30/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0171 - accuracy: 0.9976 - val_loss: 0.7845 - val_accuracy: 0.8362\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0191 - accuracy: 0.9970 - val_loss: 0.7843 - val_accuracy: 0.8200\n","Epoch 32/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0173 - accuracy: 0.9965 - val_loss: 0.8303 - val_accuracy: 0.8222\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0234 - accuracy: 0.9938 - val_loss: 0.9777 - val_accuracy: 0.7963\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0286 - accuracy: 0.9935 - val_loss: 1.1747 - val_accuracy: 0.7662\n","Epoch 35/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0312 - accuracy: 0.9925 - val_loss: 0.8894 - val_accuracy: 0.7909\n","Epoch 36/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0253 - accuracy: 0.9927 - val_loss: 0.8171 - val_accuracy: 0.8179\n","Epoch 37/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 0.8236 - val_accuracy: 0.8082\n","Epoch 38/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0199 - accuracy: 0.9952 - val_loss: 0.9539 - val_accuracy: 0.8006\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0296 - accuracy: 0.9914 - val_loss: 0.8728 - val_accuracy: 0.8060\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0372 - accuracy: 0.9892 - val_loss: 0.8464 - val_accuracy: 0.7942\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 0.9957 - val_loss: 1.2610 - val_accuracy: 0.7392\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0301 - accuracy: 0.9911 - val_loss: 1.0675 - val_accuracy: 0.7748\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0245 - accuracy: 0.9946 - val_loss: 1.1295 - val_accuracy: 0.7726\n","Epoch 44/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0310 - accuracy: 0.9911 - val_loss: 0.9643 - val_accuracy: 0.7716\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0306 - accuracy: 0.9922 - val_loss: 0.8079 - val_accuracy: 0.8179\n","Epoch 46/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0271 - accuracy: 0.9922 - val_loss: 1.0879 - val_accuracy: 0.7640\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0515 - accuracy: 0.9844 - val_loss: 0.8861 - val_accuracy: 0.7780\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0189 - accuracy: 0.9960 - val_loss: 0.8888 - val_accuracy: 0.8028\n","Epoch 49/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0143 - accuracy: 0.9981 - val_loss: 0.9711 - val_accuracy: 0.7974\n","Epoch 50/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0126 - accuracy: 0.9987 - val_loss: 0.8830 - val_accuracy: 0.8136\n","Epoch 51/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0195 - accuracy: 0.9949 - val_loss: 0.9243 - val_accuracy: 0.7996\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0260 - accuracy: 0.9935 - val_loss: 0.8975 - val_accuracy: 0.8082\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0189 - accuracy: 0.9962 - val_loss: 0.8977 - val_accuracy: 0.8103\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0190 - accuracy: 0.9954 - val_loss: 0.8835 - val_accuracy: 0.8125\n","Epoch 55/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0277 - accuracy: 0.9933 - val_loss: 1.0702 - val_accuracy: 0.7726\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0448 - accuracy: 0.9860 - val_loss: 1.0343 - val_accuracy: 0.7597\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0163 - accuracy: 0.9973 - val_loss: 0.9632 - val_accuracy: 0.7866\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0138 - accuracy: 0.9981 - val_loss: 0.9726 - val_accuracy: 0.7953\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0171 - accuracy: 0.9970 - val_loss: 0.9531 - val_accuracy: 0.7920\n","Epoch 60/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0153 - accuracy: 0.9968 - val_loss: 0.9659 - val_accuracy: 0.7888\n","Epoch 61/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0154 - accuracy: 0.9973 - val_loss: 0.8962 - val_accuracy: 0.8157\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0204 - accuracy: 0.9968 - val_loss: 0.9077 - val_accuracy: 0.7985\n","Epoch 63/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0127 - accuracy: 0.9984 - val_loss: 0.9923 - val_accuracy: 0.8006\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9976 - val_loss: 0.9459 - val_accuracy: 0.8050\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0100 - accuracy: 0.9997 - val_loss: 0.9841 - val_accuracy: 0.8103\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0145 - accuracy: 0.9973 - val_loss: 0.9442 - val_accuracy: 0.8006\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0146 - accuracy: 0.9976 - val_loss: 0.9926 - val_accuracy: 0.7909\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0178 - accuracy: 0.9968 - val_loss: 0.9907 - val_accuracy: 0.7909\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0512 - accuracy: 0.9838 - val_loss: 0.9758 - val_accuracy: 0.7565\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 0.9052 - val_accuracy: 0.7963\n","Epoch 71/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0125 - accuracy: 0.9984 - val_loss: 0.9690 - val_accuracy: 0.8017\n","Epoch 72/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0112 - accuracy: 0.9987 - val_loss: 1.0410 - val_accuracy: 0.7931\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0163 - accuracy: 0.9965 - val_loss: 0.9039 - val_accuracy: 0.8147\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0121 - accuracy: 0.9981 - val_loss: 1.0557 - val_accuracy: 0.7899\n","Epoch 75/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.0070 - val_accuracy: 0.7996\n","Epoch 76/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0094 - accuracy: 0.9995 - val_loss: 0.9498 - val_accuracy: 0.8179\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.9997 - val_loss: 0.9152 - val_accuracy: 0.8254\n","Epoch 78/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.9176 - val_accuracy: 0.8233\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.9100 - val_accuracy: 0.8233\n","Epoch 80/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.9057 - val_accuracy: 0.8254\n","Epoch 81/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.9061 - val_accuracy: 0.8244\n","Epoch 82/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.9022 - val_accuracy: 0.8265\n","Epoch 83/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.9019 - val_accuracy: 0.8276\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.8991 - val_accuracy: 0.8287\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.8970 - val_accuracy: 0.8276\n","Epoch 86/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.8954 - val_accuracy: 0.8276\n","Epoch 87/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.8960 - val_accuracy: 0.8297\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.8951 - val_accuracy: 0.8276\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.8949 - val_accuracy: 0.8265\n","Epoch 90/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.8943 - val_accuracy: 0.8233\n","Epoch 91/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.8980 - val_accuracy: 0.8233\n","Epoch 92/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.8970 - val_accuracy: 0.8254\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.8985 - val_accuracy: 0.8254\n","Epoch 94/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.8979 - val_accuracy: 0.8211\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.8969 - val_accuracy: 0.8244\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.8973 - val_accuracy: 0.8211\n","Epoch 97/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.8977 - val_accuracy: 0.8211\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.9003 - val_accuracy: 0.8222\n","Epoch 99/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.8998 - val_accuracy: 0.8200\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.8998 - val_accuracy: 0.8211\n","{'loss': [0.06153051555156708, 0.03214418143033981, 0.018217114731669426, 0.017038727179169655, 0.027469057589769363, 0.039644382894039154, 0.033080216497182846, 0.021303832530975342, 0.022892015054821968, 0.038019176572561264, 0.05432506278157234, 0.024826176464557648, 0.017312066629529, 0.017009716480970383, 0.0162587258964777, 0.010582834482192993, 0.01349273044615984, 0.01805051416158676, 0.026368465274572372, 0.029881544411182404, 0.06286071985960007, 0.03157026693224907, 0.03048434481024742, 0.029962126165628433, 0.03314285725355148, 0.03930230438709259, 0.01842796802520752, 0.014534628950059414, 0.01612670347094536, 0.01712735928595066, 0.01908407174050808, 0.01727841980755329, 0.02338278293609619, 0.02858990803360939, 0.031220728531479836, 0.025318311527371407, 0.025157295167446136, 0.019863413646817207, 0.029621796682476997, 0.03721773251891136, 0.02051566168665886, 0.03011586330831051, 0.024544790387153625, 0.031026137992739677, 0.030595049262046814, 0.02708590403199196, 0.05153031274676323, 0.018933415412902832, 0.014265142381191254, 0.012619724497199059, 0.01950244791805744, 0.026021555066108704, 0.01887204684317112, 0.018996432423591614, 0.027737999334931374, 0.04476216435432434, 0.01630215160548687, 0.013847344554960728, 0.017146095633506775, 0.01526609156280756, 0.01537022553384304, 0.020358765497803688, 0.012722520157694817, 0.014599411748349667, 0.009989784099161625, 0.014535383321344852, 0.014556090347468853, 0.017804257571697235, 0.051234692335128784, 0.025181645527482033, 0.012475394643843174, 0.011168161407113075, 0.016290215775370598, 0.012107636779546738, 0.008756921626627445, 0.00940609909594059, 0.008627314120531082, 0.00799093209207058, 0.007826829329133034, 0.007809042930603027, 0.007738695479929447, 0.0076997363939881325, 0.007694386411458254, 0.0076382458209991455, 0.007613901048898697, 0.007606972940266132, 0.00757416570559144, 0.007549739442765713, 0.007538411766290665, 0.00751871895045042, 0.007518753409385681, 0.007488117087632418, 0.00747668044641614, 0.007448240648955107, 0.00744283152744174, 0.007430668454617262, 0.007417869288474321, 0.007405862677842379, 0.007385554723441601, 0.007369580678641796], 'accuracy': [0.9822198152542114, 0.9924569129943848, 0.9962284564971924, 0.9970366358757019, 0.9929956793785095, 0.9894935488700867, 0.9913793206214905, 0.9964978694915771, 0.9951508641242981, 0.9892241358757019, 0.9835668206214905, 0.9929956793785095, 0.9970366358757019, 0.9967672228813171, 0.9978448152542114, 0.9994612336158752, 0.9981142282485962, 0.9956896305084229, 0.9929956793785095, 0.9916487336158752, 0.9787176847457886, 0.9916487336158752, 0.9900323152542114, 0.9913793206214905, 0.9897629022598267, 0.9911099076271057, 0.9954202771186829, 0.9975754022598267, 0.9973060488700867, 0.9975754022598267, 0.9970366358757019, 0.9964978694915771, 0.993803858757019, 0.993534505367279, 0.9924569129943848, 0.9927262663841248, 0.9932650923728943, 0.9951508641242981, 0.9913793206214905, 0.9892241358757019, 0.9956896305084229, 0.9911099076271057, 0.9946120977401733, 0.9911099076271057, 0.9921875, 0.9921875, 0.984375, 0.9959590435028076, 0.9981142282485962, 0.998652994632721, 0.9948814511299133, 0.993534505367279, 0.9962284564971924, 0.9954202771186829, 0.9932650923728943, 0.985991358757019, 0.9973060488700867, 0.9981142282485962, 0.9970366358757019, 0.9967672228813171, 0.9973060488700867, 0.9967672228813171, 0.998383641242981, 0.9975754022598267, 0.9997305870056152, 0.9973060488700867, 0.9975754022598267, 0.9967672228813171, 0.9838362336158752, 0.9932650923728943, 0.998383641242981, 0.998652994632721, 0.9964978694915771, 0.9981142282485962, 1.0, 0.9994612336158752, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.6975178718566895, 0.6945821046829224, 0.6906245946884155, 0.6821843385696411, 0.6781208515167236, 0.6711129546165466, 0.6665154695510864, 0.653451144695282, 0.6379638910293579, 0.6324703097343445, 0.6064057350158691, 0.5889931917190552, 0.549720287322998, 0.6567903161048889, 0.5443423986434937, 0.6317166686058044, 0.6064914464950562, 0.7393301129341125, 0.6329333186149597, 0.9296332597732544, 0.6264644861221313, 0.7019909620285034, 0.7298213839530945, 0.6467640995979309, 0.901828408241272, 0.6549217104911804, 0.7988309264183044, 0.7314763069152832, 0.8388893008232117, 0.7844948768615723, 0.7842687368392944, 0.8303404450416565, 0.9776884317398071, 1.1747217178344727, 0.8894124031066895, 0.817110538482666, 0.8235649466514587, 0.953886091709137, 0.8727630972862244, 0.8463501334190369, 1.260991096496582, 1.0674861669540405, 1.1294673681259155, 0.9642605781555176, 0.8079341650009155, 1.0878506898880005, 0.8861215710639954, 0.8887512683868408, 0.971102774143219, 0.8829578161239624, 0.9243410229682922, 0.8975262641906738, 0.8977157473564148, 0.8835002779960632, 1.0702335834503174, 1.034263253211975, 0.9632322192192078, 0.9726094007492065, 0.9530904293060303, 0.965934157371521, 0.8962349891662598, 0.9077262878417969, 0.9922916889190674, 0.945929765701294, 0.9841431975364685, 0.9442171454429626, 0.9926425218582153, 0.990725040435791, 0.9758290648460388, 0.9052420854568481, 0.9689872860908508, 1.0410293340682983, 0.9039108753204346, 1.0557209253311157, 1.0070207118988037, 0.9497585296630859, 0.9151911735534668, 0.9176064133644104, 0.9100200533866882, 0.9056746363639832, 0.9061468839645386, 0.9022322297096252, 0.9018596410751343, 0.8991413712501526, 0.8970146775245667, 0.8953720331192017, 0.8960217237472534, 0.8951141238212585, 0.8949449062347412, 0.8943383693695068, 0.898012101650238, 0.8969695568084717, 0.8985017538070679, 0.8978887796401978, 0.8969190716743469, 0.8973197937011719, 0.8977335691452026, 0.9002554416656494, 0.899823009967804, 0.8997984528541565], 'val_accuracy': [0.5150862336158752, 0.5204741358757019, 0.5237069129943848, 0.6056034564971924, 0.5851293206214905, 0.6099137663841248, 0.6034482717514038, 0.6325430870056152, 0.6336206793785095, 0.6271551847457886, 0.6853448152542114, 0.6896551847457886, 0.7230603694915771, 0.6885775923728943, 0.7413793206214905, 0.732758641242981, 0.7618534564971924, 0.7532327771186829, 0.7650862336158752, 0.7284482717514038, 0.774784505367279, 0.7898706793785095, 0.7909482717514038, 0.806034505367279, 0.7790948152542114, 0.826508641242981, 0.8125, 0.829741358757019, 0.8081896305084229, 0.8362069129943848, 0.8200430870056152, 0.8221982717514038, 0.7963362336158752, 0.7661637663841248, 0.7909482717514038, 0.8178879022598267, 0.8081896305084229, 0.8006465435028076, 0.806034505367279, 0.7941810488700867, 0.7392241358757019, 0.774784505367279, 0.7726293206214905, 0.7715517282485962, 0.8178879022598267, 0.764008641242981, 0.7780172228813171, 0.8028017282485962, 0.7974137663841248, 0.8135775923728943, 0.7995689511299133, 0.8081896305084229, 0.8103448152542114, 0.8125, 0.7726293206214905, 0.7596982717514038, 0.7866379022598267, 0.795258641242981, 0.7920258641242981, 0.7887930870056152, 0.8157327771186829, 0.798491358757019, 0.8006465435028076, 0.8049569129943848, 0.8103448152542114, 0.8006465435028076, 0.7909482717514038, 0.7909482717514038, 0.756465494632721, 0.7963362336158752, 0.8017241358757019, 0.7931034564971924, 0.8146551847457886, 0.7898706793785095, 0.7995689511299133, 0.8178879022598267, 0.8254310488700867, 0.8232758641242981, 0.8232758641242981, 0.8254310488700867, 0.8243534564971924, 0.826508641242981, 0.8275862336158752, 0.8286637663841248, 0.8275862336158752, 0.8275862336158752, 0.829741358757019, 0.8275862336158752, 0.826508641242981, 0.8232758641242981, 0.8232758641242981, 0.8254310488700867, 0.8254310488700867, 0.8211206793785095, 0.8243534564971924, 0.8211206793785095, 0.8211206793785095, 0.8221982717514038, 0.8200430870056152, 0.8211206793785095]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.0798 - accuracy: 0.9757"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 58ms/step - loss: 0.0805 - accuracy: 0.9751 - val_loss: 0.6976 - val_accuracy: 0.5057\n","Epoch 2/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0460 - accuracy: 0.9864 - val_loss: 0.6969 - val_accuracy: 0.5057\n","Epoch 3/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0158 - accuracy: 0.9980 - val_loss: 0.6944 - val_accuracy: 0.5283\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0166 - accuracy: 0.9972 - val_loss: 0.6897 - val_accuracy: 0.5543\n","Epoch 5/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0203 - accuracy: 0.9955 - val_loss: 0.6813 - val_accuracy: 0.5656\n","Epoch 6/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0361 - accuracy: 0.9895 - val_loss: 0.6747 - val_accuracy: 0.6063\n","Epoch 7/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0782 - accuracy: 0.9740 - val_loss: 0.6742 - val_accuracy: 0.6222\n","Epoch 8/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0347 - accuracy: 0.9924 - val_loss: 0.6571 - val_accuracy: 0.6437\n","Epoch 9/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0151 - accuracy: 0.9983 - val_loss: 0.6281 - val_accuracy: 0.6742\n","Epoch 10/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0148 - accuracy: 0.9980 - val_loss: 0.6131 - val_accuracy: 0.6934\n","Epoch 11/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0160 - accuracy: 0.9966 - val_loss: 0.6042 - val_accuracy: 0.6652\n","Epoch 12/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0206 - accuracy: 0.9952 - val_loss: 0.5955 - val_accuracy: 0.6799\n","Epoch 13/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0303 - accuracy: 0.9924 - val_loss: 0.5409 - val_accuracy: 0.7330\n","Epoch 14/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0484 - accuracy: 0.9864 - val_loss: 0.5582 - val_accuracy: 0.7161\n","Epoch 15/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0378 - accuracy: 0.9895 - val_loss: 0.5291 - val_accuracy: 0.7432\n","Epoch 16/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0220 - accuracy: 0.9952 - val_loss: 0.5368 - val_accuracy: 0.7353\n","Epoch 17/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0181 - accuracy: 0.9958 - val_loss: 0.4970 - val_accuracy: 0.7726\n","Epoch 18/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0226 - accuracy: 0.9955 - val_loss: 0.5336 - val_accuracy: 0.7794\n","Epoch 19/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0391 - accuracy: 0.9895 - val_loss: 0.5005 - val_accuracy: 0.8100\n","Epoch 20/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0253 - accuracy: 0.9926 - val_loss: 0.5049 - val_accuracy: 0.8201\n","Epoch 21/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0207 - accuracy: 0.9955 - val_loss: 0.5151 - val_accuracy: 0.8281\n","Epoch 22/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0224 - accuracy: 0.9941 - val_loss: 0.5700 - val_accuracy: 0.8314\n","Epoch 23/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0190 - accuracy: 0.9955 - val_loss: 0.5638 - val_accuracy: 0.8450\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0163 - accuracy: 0.9963 - val_loss: 0.5499 - val_accuracy: 0.8450\n","Epoch 25/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0416 - accuracy: 0.9884 - val_loss: 0.4455 - val_accuracy: 0.8586\n","Epoch 26/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0551 - accuracy: 0.9813 - val_loss: 0.7461 - val_accuracy: 0.7749\n","Epoch 27/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0364 - accuracy: 0.9884 - val_loss: 0.5310 - val_accuracy: 0.8405\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0167 - accuracy: 0.9966 - val_loss: 0.6182 - val_accuracy: 0.8303\n","Epoch 29/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0126 - accuracy: 0.9989 - val_loss: 0.5299 - val_accuracy: 0.8665\n","Epoch 30/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0117 - accuracy: 0.9992 - val_loss: 0.6019 - val_accuracy: 0.8654\n","Epoch 31/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0135 - accuracy: 0.9972 - val_loss: 0.8210 - val_accuracy: 0.8292\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0231 - accuracy: 0.9938 - val_loss: 0.6843 - val_accuracy: 0.8428\n","Epoch 33/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0354 - accuracy: 0.9892 - val_loss: 0.5521 - val_accuracy: 0.8597\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0396 - accuracy: 0.9907 - val_loss: 0.7348 - val_accuracy: 0.8122\n","Epoch 35/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0264 - accuracy: 0.9929 - val_loss: 0.5649 - val_accuracy: 0.8563\n","Epoch 36/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0229 - accuracy: 0.9935 - val_loss: 0.6540 - val_accuracy: 0.8428\n","Epoch 37/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0281 - accuracy: 0.9932 - val_loss: 0.6144 - val_accuracy: 0.8518\n","Epoch 38/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0298 - accuracy: 0.9909 - val_loss: 0.7211 - val_accuracy: 0.8337\n","Epoch 39/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0288 - accuracy: 0.9932 - val_loss: 0.7104 - val_accuracy: 0.8258\n","Epoch 40/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0307 - accuracy: 0.9921 - val_loss: 0.6394 - val_accuracy: 0.8462\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0223 - accuracy: 0.9955 - val_loss: 0.6392 - val_accuracy: 0.8541\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0261 - accuracy: 0.9924 - val_loss: 0.6424 - val_accuracy: 0.8439\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0269 - accuracy: 0.9909 - val_loss: 0.7034 - val_accuracy: 0.8450\n","Epoch 44/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0227 - accuracy: 0.9946 - val_loss: 0.7543 - val_accuracy: 0.8269\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0135 - accuracy: 0.9986 - val_loss: 0.6919 - val_accuracy: 0.8495\n","Epoch 46/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0195 - accuracy: 0.9960 - val_loss: 0.6678 - val_accuracy: 0.8405\n","Epoch 47/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0133 - accuracy: 0.9983 - val_loss: 0.6174 - val_accuracy: 0.8507\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0145 - accuracy: 0.9983 - val_loss: 0.8074 - val_accuracy: 0.8247\n","Epoch 49/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0107 - accuracy: 0.9994 - val_loss: 0.7886 - val_accuracy: 0.8382\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0134 - accuracy: 0.9989 - val_loss: 0.7887 - val_accuracy: 0.8416\n","Epoch 51/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0121 - accuracy: 0.9983 - val_loss: 0.7501 - val_accuracy: 0.8450\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0102 - accuracy: 0.9994 - val_loss: 0.7761 - val_accuracy: 0.8428\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0186 - accuracy: 0.9955 - val_loss: 0.8449 - val_accuracy: 0.8360\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0849 - accuracy: 0.9734 - val_loss: 0.5709 - val_accuracy: 0.8281\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0662 - accuracy: 0.9779 - val_loss: 0.6351 - val_accuracy: 0.8281\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0187 - accuracy: 0.9966 - val_loss: 0.6253 - val_accuracy: 0.8360\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0266 - accuracy: 0.9932 - val_loss: 0.7208 - val_accuracy: 0.8360\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0217 - accuracy: 0.9952 - val_loss: 0.8370 - val_accuracy: 0.8224\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0216 - accuracy: 0.9952 - val_loss: 0.6899 - val_accuracy: 0.8462\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0135 - accuracy: 0.9986 - val_loss: 0.7945 - val_accuracy: 0.8247\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0139 - accuracy: 0.9986 - val_loss: 0.7698 - val_accuracy: 0.8247\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0193 - accuracy: 0.9960 - val_loss: 1.1772 - val_accuracy: 0.7715\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0193 - accuracy: 0.9958 - val_loss: 0.7831 - val_accuracy: 0.8201\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0170 - accuracy: 0.9955 - val_loss: 0.6906 - val_accuracy: 0.8371\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0420 - accuracy: 0.9875 - val_loss: 0.6260 - val_accuracy: 0.8360\n","Epoch 66/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0227 - accuracy: 0.9958 - val_loss: 0.7210 - val_accuracy: 0.8258\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0114 - accuracy: 0.9997 - val_loss: 0.7212 - val_accuracy: 0.8428\n","Epoch 68/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0090 - accuracy: 0.9997 - val_loss: 0.7506 - val_accuracy: 0.8405\n","Epoch 69/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.6638 - val_accuracy: 0.8518\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.6479 - val_accuracy: 0.8473\n","Epoch 71/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.6354 - val_accuracy: 0.8518\n","Epoch 72/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.6268 - val_accuracy: 0.8495\n","Epoch 73/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.6216 - val_accuracy: 0.8507\n","Epoch 74/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.6169 - val_accuracy: 0.8518\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.6148 - val_accuracy: 0.8507\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.6118 - val_accuracy: 0.8484\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.6108 - val_accuracy: 0.8495\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.6095 - val_accuracy: 0.8495\n","Epoch 79/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.6068 - val_accuracy: 0.8507\n","Epoch 80/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.6053 - val_accuracy: 0.8541\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.6059 - val_accuracy: 0.8518\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.6053 - val_accuracy: 0.8518\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.6038 - val_accuracy: 0.8518\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.6029 - val_accuracy: 0.8529\n","Epoch 85/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.6016 - val_accuracy: 0.8563\n","Epoch 86/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.6010 - val_accuracy: 0.8552\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.6009 - val_accuracy: 0.8541\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.6003 - val_accuracy: 0.8575\n","Epoch 89/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.6004 - val_accuracy: 0.8575\n","Epoch 90/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.6007 - val_accuracy: 0.8575\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.6003 - val_accuracy: 0.8575\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.6009 - val_accuracy: 0.8563\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.6010 - val_accuracy: 0.8563\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.6005 - val_accuracy: 0.8575\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.6015 - val_accuracy: 0.8563\n","Epoch 96/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.6019 - val_accuracy: 0.8575\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.6014 - val_accuracy: 0.8586\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.6015 - val_accuracy: 0.8586\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.6013 - val_accuracy: 0.8586\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.5999 - val_accuracy: 0.8575\n","{'loss': [0.08052948862314224, 0.046015653759241104, 0.01583726890385151, 0.016605442389845848, 0.0203059334307909, 0.036078616976737976, 0.07820641249418259, 0.0347447544336319, 0.015094039030373096, 0.014779901131987572, 0.015978345647454262, 0.02055331878364086, 0.030259110033512115, 0.04839105159044266, 0.03778982535004616, 0.021950410678982735, 0.018081024289131165, 0.022586697712540627, 0.03905689716339111, 0.025280166417360306, 0.020700721070170403, 0.02238195575773716, 0.01899438165128231, 0.016325300559401512, 0.041555631905794144, 0.05505289137363434, 0.03639256954193115, 0.016681285575032234, 0.012586863711476326, 0.01174286101013422, 0.013482237234711647, 0.02306113950908184, 0.03543082997202873, 0.03957716375589371, 0.026438461616635323, 0.022869957610964775, 0.028142336755990982, 0.029788533225655556, 0.02882351167500019, 0.0307385865598917, 0.022331785410642624, 0.02607698179781437, 0.0269171129912138, 0.022748040035367012, 0.01348184421658516, 0.019453899934887886, 0.013324776664376259, 0.014465760439634323, 0.010668326169252396, 0.013385099358856678, 0.012143938802182674, 0.010189034044742584, 0.018583498895168304, 0.08489883691072464, 0.06622793525457382, 0.01871403306722641, 0.0266451183706522, 0.02165578305721283, 0.02156808413565159, 0.013503266498446465, 0.01394854299724102, 0.019291475415229797, 0.019262144342064857, 0.017033671960234642, 0.04195072501897812, 0.02269471064209938, 0.011356351897120476, 0.008972694166004658, 0.008486973121762276, 0.008166220039129257, 0.008031927049160004, 0.00799784529954195, 0.007924549281597137, 0.007887789979577065, 0.007853825576603413, 0.00783938355743885, 0.007812305819243193, 0.007794939447194338, 0.007765492424368858, 0.007750446908175945, 0.007728429976850748, 0.007689429447054863, 0.007677961606532335, 0.007666400633752346, 0.007664268370717764, 0.007633160799741745, 0.007614963687956333, 0.007602602243423462, 0.007585462182760239, 0.007576783653348684, 0.007563353516161442, 0.007547324523329735, 0.0075286198407411575, 0.007520533632487059, 0.00750896567478776, 0.007505557965487242, 0.007484246976673603, 0.007470289710909128, 0.007465665228664875, 0.007446322590112686], 'accuracy': [0.9750990271568298, 0.9864176511764526, 0.9980192184448242, 0.9971703290939331, 0.9954725503921509, 0.9895302653312683, 0.9739671945571899, 0.9923599362373352, 0.9983022212982178, 0.9980192184448242, 0.9966044425964355, 0.9951896071434021, 0.9923599362373352, 0.9864176511764526, 0.9895302653312683, 0.9951896071434021, 0.9957554936408997, 0.9954725503921509, 0.9895302653312683, 0.992642879486084, 0.9954725503921509, 0.9940577149391174, 0.9954725503921509, 0.996321439743042, 0.9883984327316284, 0.9813242554664612, 0.9883984327316284, 0.9966044425964355, 0.9988681674003601, 0.9991511106491089, 0.9971703290939331, 0.9937747716903687, 0.9892473220825195, 0.990662157535553, 0.9929258823394775, 0.9934917688369751, 0.9932088255882263, 0.9909451007843018, 0.9932088255882263, 0.9920769929885864, 0.9954725503921509, 0.9923599362373352, 0.9909451007843018, 0.9946236610412598, 0.9985851645469666, 0.9960384964942932, 0.9983022212982178, 0.9983022212982178, 0.9994340538978577, 0.9988681674003601, 0.9983022212982178, 0.9994340538978577, 0.9954725503921509, 0.9734012484550476, 0.9779286980628967, 0.9966044425964355, 0.9932088255882263, 0.9951896071434021, 0.9951896071434021, 0.9985851645469666, 0.9985851645469666, 0.9960384964942932, 0.9957554936408997, 0.9954725503921509, 0.9875495433807373, 0.9957554936408997, 0.9997170567512512, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.6975838541984558, 0.6969150900840759, 0.6943768262863159, 0.6896680593490601, 0.6813156604766846, 0.6746551394462585, 0.6742166876792908, 0.6570625901222229, 0.6280984282493591, 0.6130537986755371, 0.6042269468307495, 0.5955007076263428, 0.5408918857574463, 0.5581768155097961, 0.5290676951408386, 0.5367763638496399, 0.4970066547393799, 0.5335636734962463, 0.5004886984825134, 0.5049260258674622, 0.5151355266571045, 0.5700036287307739, 0.5637669563293457, 0.5498688817024231, 0.44554704427719116, 0.7461130619049072, 0.5309935212135315, 0.6182258129119873, 0.5298649072647095, 0.6018871665000916, 0.8210480809211731, 0.6842698454856873, 0.5520991683006287, 0.7347984910011292, 0.5648543238639832, 0.6540305614471436, 0.6144229173660278, 0.7211045026779175, 0.7103554606437683, 0.6394139528274536, 0.6392020583152771, 0.6424237489700317, 0.7033910751342773, 0.7542680501937866, 0.6918981075286865, 0.6677733063697815, 0.6174114346504211, 0.8073557019233704, 0.7886353731155396, 0.7886719703674316, 0.7501067519187927, 0.7761038541793823, 0.8449270725250244, 0.5708923935890198, 0.6350740194320679, 0.6253407597541809, 0.7207828164100647, 0.836980402469635, 0.6899394989013672, 0.794470489025116, 0.7698174118995667, 1.177162528038025, 0.783123254776001, 0.6906205415725708, 0.6260276436805725, 0.721042275428772, 0.7211682200431824, 0.7505626678466797, 0.6638113260269165, 0.6479161381721497, 0.6354406476020813, 0.6268032789230347, 0.6215667128562927, 0.6168718934059143, 0.6147911548614502, 0.6117562651634216, 0.6107666492462158, 0.6094614863395691, 0.6067946553230286, 0.6052926778793335, 0.6058605909347534, 0.6053308248519897, 0.6038329005241394, 0.6028570532798767, 0.6016061305999756, 0.6009981036186218, 0.6009383201599121, 0.6003202795982361, 0.6004433631896973, 0.6006731390953064, 0.6003321409225464, 0.6009474992752075, 0.6009555459022522, 0.6005443930625916, 0.6014667749404907, 0.6019114255905151, 0.6013510823249817, 0.6015307307243347, 0.6012821197509766, 0.599879801273346], 'val_accuracy': [0.5056561231613159, 0.5056561231613159, 0.5282805562019348, 0.5542986392974854, 0.5656108856201172, 0.6063348650932312, 0.622171938419342, 0.6436651349067688, 0.6742081642150879, 0.6934388875961304, 0.6651583909988403, 0.679864227771759, 0.733031690120697, 0.7160633206367493, 0.7432126402854919, 0.7352941036224365, 0.7726244330406189, 0.779411792755127, 0.8099547624588013, 0.820135772228241, 0.8280543088912964, 0.831447958946228, 0.8450226187705994, 0.8450226187705994, 0.8585972785949707, 0.7748869061470032, 0.8404977321624756, 0.8303167223930359, 0.8665158152580261, 0.8653846383094788, 0.8291855454444885, 0.8427602052688599, 0.8597285151481628, 0.8122171759605408, 0.8563348650932312, 0.8427602052688599, 0.8518099784851074, 0.8337104320526123, 0.8257918357849121, 0.8461538553237915, 0.8540723919868469, 0.8438913822174072, 0.8450226187705994, 0.8269230723381042, 0.8495475053787231, 0.8404977321624756, 0.8506787419319153, 0.8246606588363647, 0.8382353186607361, 0.8416289687156677, 0.8450226187705994, 0.8427602052688599, 0.8359728455543518, 0.8280543088912964, 0.8280543088912964, 0.8359728455543518, 0.8359728455543518, 0.8223981857299805, 0.8461538553237915, 0.8246606588363647, 0.8246606588363647, 0.7714931964874268, 0.820135772228241, 0.837104082107544, 0.8359728455543518, 0.8257918357849121, 0.8427602052688599, 0.8404977321624756, 0.8518099784851074, 0.8472850918769836, 0.8518099784851074, 0.8495475053787231, 0.8506787419319153, 0.8518099784851074, 0.8506787419319153, 0.848416268825531, 0.8495475053787231, 0.8495475053787231, 0.8506787419319153, 0.8540723919868469, 0.8518099784851074, 0.8518099784851074, 0.8518099784851074, 0.8529411554336548, 0.8563348650932312, 0.8552036285400391, 0.8540723919868469, 0.8574660420417786, 0.8574660420417786, 0.8574660420417786, 0.8574660420417786, 0.8563348650932312, 0.8563348650932312, 0.8574660420417786, 0.8563348650932312, 0.8574660420417786, 0.8585972785949707, 0.8585972785949707, 0.8585972785949707, 0.8574660420417786]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 1, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4296257 (16.39 MB)\n","Trainable params: 4295745 (16.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.1088 - accuracy: 0.9646"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 9s 72ms/step - loss: 0.1035 - accuracy: 0.9661 - val_loss: 0.6971 - val_accuracy: 0.5155\n","Epoch 2/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0262 - accuracy: 0.9951 - val_loss: 0.6945 - val_accuracy: 0.5207\n","Epoch 3/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0147 - accuracy: 0.9979 - val_loss: 0.6903 - val_accuracy: 0.5372\n","Epoch 4/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0157 - accuracy: 0.9974 - val_loss: 0.6843 - val_accuracy: 0.5661\n","Epoch 5/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0128 - accuracy: 0.9984 - val_loss: 0.6755 - val_accuracy: 0.5961\n","Epoch 6/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0108 - accuracy: 0.9992 - val_loss: 0.6616 - val_accuracy: 0.6209\n","Epoch 7/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0110 - accuracy: 0.9992 - val_loss: 0.6467 - val_accuracy: 0.6271\n","Epoch 8/100\n","31/31 [==============================] - 1s 41ms/step - loss: 0.0226 - accuracy: 0.9956 - val_loss: 0.6301 - val_accuracy: 0.6787\n","Epoch 9/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0396 - accuracy: 0.9894 - val_loss: 0.6273 - val_accuracy: 0.6787\n","Epoch 10/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0369 - accuracy: 0.9910 - val_loss: 0.6107 - val_accuracy: 0.6849\n","Epoch 11/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0670 - accuracy: 0.9791 - val_loss: 0.6191 - val_accuracy: 0.6446\n","Epoch 12/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0377 - accuracy: 0.9886 - val_loss: 0.5551 - val_accuracy: 0.7097\n","Epoch 13/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0319 - accuracy: 0.9902 - val_loss: 0.5393 - val_accuracy: 0.7252\n","Epoch 14/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0428 - accuracy: 0.9855 - val_loss: 0.6131 - val_accuracy: 0.6870\n","Epoch 15/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0478 - accuracy: 0.9842 - val_loss: 0.5297 - val_accuracy: 0.7407\n","Epoch 16/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.0403 - accuracy: 0.9876 - val_loss: 0.5596 - val_accuracy: 0.7583\n","Epoch 17/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0488 - accuracy: 0.9827 - val_loss: 0.6027 - val_accuracy: 0.7583\n","Epoch 18/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0777 - accuracy: 0.9734 - val_loss: 0.4782 - val_accuracy: 0.7862\n","Epoch 19/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0260 - accuracy: 0.9956 - val_loss: 0.6397 - val_accuracy: 0.7789\n","Epoch 20/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0142 - accuracy: 0.9982 - val_loss: 0.5981 - val_accuracy: 0.8140\n","Epoch 21/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0138 - accuracy: 0.9984 - val_loss: 0.7663 - val_accuracy: 0.7913\n","Epoch 22/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0296 - accuracy: 0.9917 - val_loss: 0.7015 - val_accuracy: 0.8233\n","Epoch 23/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0669 - accuracy: 0.9775 - val_loss: 0.5788 - val_accuracy: 0.8151\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0384 - accuracy: 0.9902 - val_loss: 0.6641 - val_accuracy: 0.8089\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0183 - accuracy: 0.9956 - val_loss: 0.7124 - val_accuracy: 0.8213\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0176 - accuracy: 0.9964 - val_loss: 0.7936 - val_accuracy: 0.8161\n","Epoch 27/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0141 - accuracy: 0.9984 - val_loss: 0.7779 - val_accuracy: 0.8409\n","Epoch 28/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0168 - accuracy: 0.9969 - val_loss: 1.0027 - val_accuracy: 0.7975\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0687 - accuracy: 0.9786 - val_loss: 0.6913 - val_accuracy: 0.8140\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0294 - accuracy: 0.9935 - val_loss: 0.7124 - val_accuracy: 0.8161\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0128 - accuracy: 0.9992 - val_loss: 0.7723 - val_accuracy: 0.8306\n","Epoch 32/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0101 - accuracy: 0.9997 - val_loss: 0.7732 - val_accuracy: 0.8347\n","Epoch 33/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.7659 - val_accuracy: 0.8512\n","Epoch 34/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0093 - accuracy: 0.9997 - val_loss: 0.7613 - val_accuracy: 0.8574\n","Epoch 35/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.7509 - val_accuracy: 0.8481\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.7430 - val_accuracy: 0.8512\n","Epoch 37/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.7431 - val_accuracy: 0.8461\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.7363 - val_accuracy: 0.8502\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.7435 - val_accuracy: 0.8512\n","Epoch 40/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.7553 - val_accuracy: 0.8533\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.7359 - val_accuracy: 0.8512\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.7296 - val_accuracy: 0.8512\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.7251 - val_accuracy: 0.8543\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.7222 - val_accuracy: 0.8574\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.7244 - val_accuracy: 0.8554\n","Epoch 46/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.7273 - val_accuracy: 0.8585\n","Epoch 47/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.7232 - val_accuracy: 0.8585\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.7192 - val_accuracy: 0.8533\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0087 - accuracy: 0.9997 - val_loss: 0.7842 - val_accuracy: 0.8481\n","Epoch 50/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0301 - accuracy: 0.9917 - val_loss: 0.8226 - val_accuracy: 0.8130\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0708 - accuracy: 0.9747 - val_loss: 0.8589 - val_accuracy: 0.7521\n","Epoch 52/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0601 - accuracy: 0.9796 - val_loss: 0.8580 - val_accuracy: 0.8017\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0655 - accuracy: 0.9747 - val_loss: 0.7798 - val_accuracy: 0.7882\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0438 - accuracy: 0.9871 - val_loss: 0.9631 - val_accuracy: 0.7841\n","Epoch 55/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0755 - accuracy: 0.9742 - val_loss: 0.7163 - val_accuracy: 0.7965\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0570 - accuracy: 0.9832 - val_loss: 0.7725 - val_accuracy: 0.7944\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0292 - accuracy: 0.9922 - val_loss: 0.8692 - val_accuracy: 0.8006\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0532 - accuracy: 0.9835 - val_loss: 0.9304 - val_accuracy: 0.7665\n","Epoch 59/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0366 - accuracy: 0.9894 - val_loss: 0.8544 - val_accuracy: 0.7893\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0154 - accuracy: 0.9966 - val_loss: 0.9414 - val_accuracy: 0.7996\n","Epoch 61/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0147 - accuracy: 0.9974 - val_loss: 1.1829 - val_accuracy: 0.7624\n","Epoch 62/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0543 - accuracy: 0.9822 - val_loss: 0.8253 - val_accuracy: 0.7810\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0830 - accuracy: 0.9718 - val_loss: 0.7642 - val_accuracy: 0.7779\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0293 - accuracy: 0.9920 - val_loss: 1.0042 - val_accuracy: 0.7779\n","Epoch 65/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0506 - accuracy: 0.9845 - val_loss: 0.8909 - val_accuracy: 0.7800\n","Epoch 66/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0377 - accuracy: 0.9871 - val_loss: 0.8481 - val_accuracy: 0.8068\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0179 - accuracy: 0.9969 - val_loss: 0.9188 - val_accuracy: 0.8161\n","Epoch 68/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0144 - accuracy: 0.9979 - val_loss: 0.9486 - val_accuracy: 0.8006\n","Epoch 69/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0142 - accuracy: 0.9977 - val_loss: 0.9320 - val_accuracy: 0.8130\n","Epoch 70/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0150 - accuracy: 0.9982 - val_loss: 1.0970 - val_accuracy: 0.7810\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0136 - accuracy: 0.9977 - val_loss: 1.0363 - val_accuracy: 0.8058\n","Epoch 72/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0541 - accuracy: 0.9853 - val_loss: 0.9328 - val_accuracy: 0.7820\n","Epoch 73/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0786 - accuracy: 0.9749 - val_loss: 0.9936 - val_accuracy: 0.7262\n","Epoch 74/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0261 - accuracy: 0.9935 - val_loss: 0.8884 - val_accuracy: 0.7975\n","Epoch 75/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0144 - accuracy: 0.9974 - val_loss: 0.9697 - val_accuracy: 0.8099\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0113 - accuracy: 0.9987 - val_loss: 0.9044 - val_accuracy: 0.8110\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0110 - accuracy: 0.9987 - val_loss: 0.9298 - val_accuracy: 0.8223\n","Epoch 78/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0107 - accuracy: 0.9992 - val_loss: 0.9085 - val_accuracy: 0.8182\n","Epoch 79/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0093 - accuracy: 0.9997 - val_loss: 0.9597 - val_accuracy: 0.8068\n","Epoch 80/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0094 - accuracy: 0.9997 - val_loss: 0.9800 - val_accuracy: 0.8110\n","Epoch 81/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0099 - accuracy: 0.9995 - val_loss: 0.9807 - val_accuracy: 0.8068\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.9479 - val_accuracy: 0.8068\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.9319 - val_accuracy: 0.8120\n","Epoch 84/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.9221 - val_accuracy: 0.8140\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.9164 - val_accuracy: 0.8120\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.9137 - val_accuracy: 0.8110\n","Epoch 87/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.9089 - val_accuracy: 0.8130\n","Epoch 88/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.9063 - val_accuracy: 0.8120\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.9052 - val_accuracy: 0.8140\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 0.9995 - val_loss: 0.9012 - val_accuracy: 0.8182\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.8920 - val_accuracy: 0.8130\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.8977 - val_accuracy: 0.8182\n","Epoch 93/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.8866 - val_accuracy: 0.8161\n","Epoch 94/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.8852 - val_accuracy: 0.8151\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.8860 - val_accuracy: 0.8161\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.8860 - val_accuracy: 0.8140\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.8854 - val_accuracy: 0.8110\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.8907 - val_accuracy: 0.8171\n","Epoch 99/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.8860 - val_accuracy: 0.8120\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.8844 - val_accuracy: 0.8120\n","{'loss': [0.10348136723041534, 0.02616746909916401, 0.014688163995742798, 0.015674689784646034, 0.012818190269172192, 0.01083996333181858, 0.011029683984816074, 0.0226434413343668, 0.03964284807443619, 0.03693189099431038, 0.06704279780387878, 0.037671614438295364, 0.03189311921596527, 0.0428440235555172, 0.04776172339916229, 0.04027468338608742, 0.048767611384391785, 0.07770995795726776, 0.02604249306023121, 0.014199241064488888, 0.013847479596734047, 0.029609058052301407, 0.06688803434371948, 0.038448598235845566, 0.018327200785279274, 0.01761826127767563, 0.0141243115067482, 0.016843684017658234, 0.06870130449533463, 0.02943100780248642, 0.01277721393853426, 0.010104255750775337, 0.009320121258497238, 0.009277303703129292, 0.00891308393329382, 0.008631273172795773, 0.008585270494222641, 0.008830207400023937, 0.008644779212772846, 0.008437232114374638, 0.00836302898824215, 0.00823582150042057, 0.008242655545473099, 0.00815260224044323, 0.008167769759893417, 0.008100979030132294, 0.008072666823863983, 0.008116506971418858, 0.008713201619684696, 0.030093315988779068, 0.07084456086158752, 0.06014867126941681, 0.06550398468971252, 0.04383604973554611, 0.07545702904462814, 0.057044051587581635, 0.029155345633625984, 0.05318865552544594, 0.03657892718911171, 0.015398703515529633, 0.014664403162896633, 0.05431526154279709, 0.08298563957214355, 0.029302217066287994, 0.05059583857655525, 0.0377151295542717, 0.017937999218702316, 0.014410920441150665, 0.014185809530317783, 0.015006300061941147, 0.013564197346568108, 0.05414027348160744, 0.07860265672206879, 0.026085255667567253, 0.01435804646462202, 0.011316535994410515, 0.010987553745508194, 0.01070115901529789, 0.009252317249774933, 0.009364331141114235, 0.009859340265393257, 0.008312921971082687, 0.008114605210721493, 0.008090600371360779, 0.00794283114373684, 0.007850704714655876, 0.007884024642407894, 0.007800655905157328, 0.007873005233705044, 0.00857536867260933, 0.007876835763454437, 0.007806440815329552, 0.007722702343016863, 0.007684006821364164, 0.007650707382708788, 0.007625289727002382, 0.007594187278300524, 0.007592807058244944, 0.00755373714491725, 0.007547232788056135], 'accuracy': [0.9661498665809631, 0.9950904250144958, 0.9979327917098999, 0.9974160194396973, 0.9984496235847473, 0.9992247819900513, 0.9992247819900513, 0.9956072568893433, 0.9894056916236877, 0.9909560680389404, 0.9790697693824768, 0.988630473613739, 0.9901808500289917, 0.9855297207832336, 0.9842377305030823, 0.987596869468689, 0.9826873540878296, 0.9733850359916687, 0.9956072568893433, 0.998191237449646, 0.9984496235847473, 0.9917312860488892, 0.9775193929672241, 0.9901808500289917, 0.9956072568893433, 0.9963824152946472, 0.9984496235847473, 0.9968992471694946, 0.9785529971122742, 0.9935400485992432, 0.9992247819900513, 0.9997416138648987, 1.0, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997416138648987, 0.9917312860488892, 0.9746770262718201, 0.9795865416526794, 0.9746770262718201, 0.9870800971984863, 0.9741601943969727, 0.9832041263580322, 0.9922480583190918, 0.9834625124931335, 0.9894056916236877, 0.9966408014297485, 0.9974160194396973, 0.9821705222129822, 0.9718345999717712, 0.9919896721839905, 0.9844961166381836, 0.9870800971984863, 0.9968992471694946, 0.9979327917098999, 0.9976744055747986, 0.998191237449646, 0.9976744055747986, 0.9852713346481323, 0.9749354124069214, 0.9935400485992432, 0.9974160194396973, 0.9987080097198486, 0.9987080097198486, 0.9992247819900513, 0.9997416138648987, 0.9997416138648987, 0.9994832277297974, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9994832277297974, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.6971378326416016, 0.694544792175293, 0.6903374195098877, 0.6843351125717163, 0.675481379032135, 0.6616190671920776, 0.6466578245162964, 0.6300911903381348, 0.6273204684257507, 0.610657811164856, 0.6191480755805969, 0.5551212430000305, 0.539313018321991, 0.6131367087364197, 0.5296770930290222, 0.5596019625663757, 0.6026508808135986, 0.4781688451766968, 0.63968425989151, 0.5980738401412964, 0.7663243412971497, 0.7014521360397339, 0.5787710547447205, 0.6641417741775513, 0.7123634815216064, 0.7936164140701294, 0.7778514623641968, 1.0026576519012451, 0.6913474798202515, 0.7124258875846863, 0.7722817659378052, 0.7732234001159668, 0.765866756439209, 0.7613017559051514, 0.7509300708770752, 0.7430194020271301, 0.7430734038352966, 0.7363097667694092, 0.7434778809547424, 0.7553310990333557, 0.7359305024147034, 0.7295753359794617, 0.7250842452049255, 0.7222166657447815, 0.7244086265563965, 0.7272636890411377, 0.7232003808021545, 0.7192369103431702, 0.7841672897338867, 0.8226361870765686, 0.858879566192627, 0.858027458190918, 0.779761791229248, 0.9631032347679138, 0.7162575125694275, 0.7724587321281433, 0.8692192435264587, 0.9304113388061523, 0.8544278740882874, 0.9413812160491943, 1.1829208135604858, 0.8253088593482971, 0.7641931772232056, 1.004166841506958, 0.8908717632293701, 0.8480644822120667, 0.9188322424888611, 0.9486345648765564, 0.9320486187934875, 1.0970076322555542, 1.0362929105758667, 0.9328013062477112, 0.9936483502388, 0.8883869051933289, 0.9696571230888367, 0.9043672680854797, 0.9298378229141235, 0.9085174798965454, 0.9596632122993469, 0.9799919724464417, 0.9807217717170715, 0.9479286074638367, 0.9319438338279724, 0.9221434593200684, 0.9164440035820007, 0.9136976599693298, 0.9088659882545471, 0.9063164591789246, 0.9052361845970154, 0.9012396931648254, 0.8920130729675293, 0.8977267146110535, 0.8866257667541504, 0.8851795196533203, 0.8860495090484619, 0.885960042476654, 0.8853561878204346, 0.8907190561294556, 0.8859517574310303, 0.8843616843223572], 'val_accuracy': [0.5154958963394165, 0.5206611752510071, 0.5371900796890259, 0.56611567735672, 0.5960744023323059, 0.6208677887916565, 0.6270661354064941, 0.6787189841270447, 0.6787189841270447, 0.6849173307418823, 0.64462810754776, 0.7097107172012329, 0.7252066135406494, 0.6869834661483765, 0.7407024502754211, 0.7582644820213318, 0.7582644820213318, 0.7861570119857788, 0.7789255976676941, 0.8140496015548706, 0.7913222908973694, 0.8233470916748047, 0.8150826692581177, 0.80888432264328, 0.8212810158729553, 0.81611567735672, 0.8409090638160706, 0.797520637512207, 0.8140496015548706, 0.81611567735672, 0.8305785059928894, 0.8347107172012329, 0.8512396812438965, 0.8574380278587341, 0.8481404781341553, 0.8512396812438965, 0.8460744023323059, 0.8502066135406494, 0.8512396812438965, 0.8533057570457458, 0.8512396812438965, 0.8512396812438965, 0.8543388247489929, 0.8574380278587341, 0.85537189245224, 0.8584710955619812, 0.8584710955619812, 0.8533057570457458, 0.8481404781341553, 0.8130165338516235, 0.7520661354064941, 0.8016529083251953, 0.788223147392273, 0.7840909361839294, 0.7964876294136047, 0.7944214940071106, 0.8006198406219482, 0.7665289044380188, 0.78925621509552, 0.7995867729187012, 0.7623966932296753, 0.7809917330741882, 0.7778925895690918, 0.7778925895690918, 0.7799586653709412, 0.8068181872367859, 0.81611567735672, 0.8006198406219482, 0.8130165338516235, 0.7809917330741882, 0.8057851195335388, 0.7820248007774353, 0.7262396812438965, 0.797520637512207, 0.8099173307418823, 0.8109503984451294, 0.8223140239715576, 0.8181818127632141, 0.8068181872367859, 0.8109503984451294, 0.8068181872367859, 0.8068181872367859, 0.8119834661483765, 0.8140496015548706, 0.8119834661483765, 0.8109503984451294, 0.8130165338516235, 0.8119834661483765, 0.8140496015548706, 0.8181818127632141, 0.8130165338516235, 0.8181818127632141, 0.81611567735672, 0.8150826692581177, 0.81611567735672, 0.8140496015548706, 0.8109503984451294, 0.817148745059967, 0.8119834661483765, 0.8119834661483765]}\n","32/32 [==============================] - 1s 4ms/step\n"]}]},{"cell_type":"code","source":["\n","metrics_df.round(3)"],"metadata":{"id":"Ik5JoVP2NPvY","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1717498187797,"user_tz":-360,"elapsed":48,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"f01b85c9-32ef-4e7b-da7a-137b3e12b26f"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.554      0.574   0.422  0.486        0.422        0.687   \n","1        1     0.545      0.554   0.460  0.503        0.460        0.630   \n","2        2     0.519      0.516   0.604  0.557        0.604        0.434   \n","3        0     0.566      0.594   0.417  0.490        0.417        0.715   \n","4        1     0.597      0.649   0.425  0.514        0.425        0.770   \n","5        2     0.658      0.641   0.715  0.676        0.715        0.600   \n","6        0     0.698      0.710   0.668  0.689        0.668        0.727   \n","7        1     0.737      0.707   0.809  0.754        0.809        0.664   \n","8        2     0.775      0.763   0.797  0.780        0.797        0.753   \n","9        0     0.744      0.727   0.781  0.753        0.781        0.707   \n","10       1     0.787      0.757   0.847  0.799        0.847        0.727   \n","11       2     0.833      0.817   0.859  0.838        0.859        0.807   \n","12       0     0.808      0.823   0.786  0.804        0.786        0.831   \n","13       1     0.838      0.826   0.857  0.841        0.857        0.819   \n","14       2     0.857      0.845   0.876  0.860        0.876        0.839   \n","\n","    Kappa  \n","0   0.109  \n","1   0.090  \n","2   0.038  \n","3   0.132  \n","4   0.195  \n","5   0.315  \n","6   0.395  \n","7   0.473  \n","8   0.550  \n","9   0.487  \n","10  0.575  \n","11  0.667  \n","12  0.616  \n","13  0.677  \n","14  0.715  "],"text/html":["\n","  <div id=\"df-efb568f0-66e7-4c82-ad72-3ca2e1449982\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.554</td>\n","      <td>0.574</td>\n","      <td>0.422</td>\n","      <td>0.486</td>\n","      <td>0.422</td>\n","      <td>0.687</td>\n","      <td>0.109</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.545</td>\n","      <td>0.554</td>\n","      <td>0.460</td>\n","      <td>0.503</td>\n","      <td>0.460</td>\n","      <td>0.630</td>\n","      <td>0.090</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.519</td>\n","      <td>0.516</td>\n","      <td>0.604</td>\n","      <td>0.557</td>\n","      <td>0.604</td>\n","      <td>0.434</td>\n","      <td>0.038</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.566</td>\n","      <td>0.594</td>\n","      <td>0.417</td>\n","      <td>0.490</td>\n","      <td>0.417</td>\n","      <td>0.715</td>\n","      <td>0.132</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.597</td>\n","      <td>0.649</td>\n","      <td>0.425</td>\n","      <td>0.514</td>\n","      <td>0.425</td>\n","      <td>0.770</td>\n","      <td>0.195</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.658</td>\n","      <td>0.641</td>\n","      <td>0.715</td>\n","      <td>0.676</td>\n","      <td>0.715</td>\n","      <td>0.600</td>\n","      <td>0.315</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.698</td>\n","      <td>0.710</td>\n","      <td>0.668</td>\n","      <td>0.689</td>\n","      <td>0.668</td>\n","      <td>0.727</td>\n","      <td>0.395</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.737</td>\n","      <td>0.707</td>\n","      <td>0.809</td>\n","      <td>0.754</td>\n","      <td>0.809</td>\n","      <td>0.664</td>\n","      <td>0.473</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.775</td>\n","      <td>0.763</td>\n","      <td>0.797</td>\n","      <td>0.780</td>\n","      <td>0.797</td>\n","      <td>0.753</td>\n","      <td>0.550</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.744</td>\n","      <td>0.727</td>\n","      <td>0.781</td>\n","      <td>0.753</td>\n","      <td>0.781</td>\n","      <td>0.707</td>\n","      <td>0.487</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.787</td>\n","      <td>0.757</td>\n","      <td>0.847</td>\n","      <td>0.799</td>\n","      <td>0.847</td>\n","      <td>0.727</td>\n","      <td>0.575</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.833</td>\n","      <td>0.817</td>\n","      <td>0.859</td>\n","      <td>0.838</td>\n","      <td>0.859</td>\n","      <td>0.807</td>\n","      <td>0.667</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.808</td>\n","      <td>0.823</td>\n","      <td>0.786</td>\n","      <td>0.804</td>\n","      <td>0.786</td>\n","      <td>0.831</td>\n","      <td>0.616</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.838</td>\n","      <td>0.826</td>\n","      <td>0.857</td>\n","      <td>0.841</td>\n","      <td>0.857</td>\n","      <td>0.819</td>\n","      <td>0.677</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.857</td>\n","      <td>0.845</td>\n","      <td>0.876</td>\n","      <td>0.860</td>\n","      <td>0.876</td>\n","      <td>0.839</td>\n","      <td>0.715</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-efb568f0-66e7-4c82-ad72-3ca2e1449982')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-efb568f0-66e7-4c82-ad72-3ca2e1449982 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-efb568f0-66e7-4c82-ad72-3ca2e1449982');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b299fd68-3a53-4a14-a2e5-0fbeee57ef99\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b299fd68-3a53-4a14-a2e5-0fbeee57ef99')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b299fd68-3a53-4a14-a2e5-0fbeee57ef99 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11891261297191952,\n        \"min\": 0.519,\n        \"max\": 0.857,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.744,\n          0.833,\n          0.554\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10763045240875968,\n        \"min\": 0.516,\n        \"max\": 0.845,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.727,\n          0.817,\n          0.574\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17662235742639476,\n        \"min\": 0.417,\n        \"max\": 0.876,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.781,\n          0.859,\n          0.422\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14144448683898167,\n        \"min\": 0.486,\n        \"max\": 0.86,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.753,\n          0.838,\n          0.486\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17662235742639476,\n        \"min\": 0.417,\n        \"max\": 0.876,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.781,\n          0.859,\n          0.422\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1054629251036997,\n        \"min\": 0.434,\n        \"max\": 0.839,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.707,\n          0.831,\n          0.687\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23796292228192273,\n        \"min\": 0.038,\n        \"max\": 0.715,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.487,\n          0.667,\n          0.109\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["metrics_df.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Time Domain/CNN_LSTM/Alpha_CNN_LSTM.csv', index = False)"],"metadata":{"id":"Ncf_cMAQF6g4","executionInfo":{"status":"ok","timestamp":1717498187799,"user_tz":-360,"elapsed":35,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# CNN"],"metadata":{"id":"QUuWzfMHSNmi"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    # model.add(Dropout(0.5))\n","    # model.add(LSTM(256, return_sequences=True))\n","    # model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Alpha/CNN/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Alpha/CNN/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"8xrx_fxBSWGd","executionInfo":{"status":"ok","timestamp":1717498293274,"user_tz":-360,"elapsed":9,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["global_model_CNN, metrics_df_CNN = federated_learning(Theta_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H1TaNdIbSfkq","outputId":"85678cbd-b1ca-4b2e-fe8a-b3d8c9d4bec9","executionInfo":{"status":"ok","timestamp":1717499131346,"user_tz":-360,"elapsed":835745,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 29ms/step - loss: 1.7746 - accuracy: 0.5038 - val_loss: 1.7697 - val_accuracy: 0.5054\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 1.7655 - accuracy: 0.5547"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 17ms/step - loss: 1.7629 - accuracy: 0.5458 - val_loss: 1.7603 - val_accuracy: 0.5409\n","Epoch 3/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.7522 - accuracy: 0.5477 - val_loss: 1.7511 - val_accuracy: 0.5496\n","Epoch 4/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.7419 - accuracy: 0.5568 - val_loss: 1.7419 - val_accuracy: 0.5345\n","Epoch 5/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.7313 - accuracy: 0.5471 - val_loss: 1.7328 - val_accuracy: 0.5582\n","Epoch 6/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.7212 - accuracy: 0.5652 - val_loss: 1.7240 - val_accuracy: 0.5269\n","Epoch 7/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.7122 - accuracy: 0.5509 - val_loss: 1.7148 - val_accuracy: 0.5216\n","Epoch 8/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.7009 - accuracy: 0.5754 - val_loss: 1.7059 - val_accuracy: 0.5205\n","Epoch 9/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.6931 - accuracy: 0.5579 - val_loss: 1.6971 - val_accuracy: 0.5463\n","Epoch 10/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.6816 - accuracy: 0.5773 - val_loss: 1.6884 - val_accuracy: 0.5711\n","Epoch 11/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.6724 - accuracy: 0.5822 - val_loss: 1.6794 - val_accuracy: 0.5474\n","Epoch 12/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.6642 - accuracy: 0.5800 - val_loss: 1.6707 - val_accuracy: 0.5711\n","Epoch 13/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.6545 - accuracy: 0.5773 - val_loss: 1.6623 - val_accuracy: 0.5162\n","Epoch 14/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.6469 - accuracy: 0.5560 - val_loss: 1.6527 - val_accuracy: 0.5722\n","Epoch 15/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.6353 - accuracy: 0.5846 - val_loss: 1.6440 - val_accuracy: 0.5377\n","Epoch 16/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.6264 - accuracy: 0.5889 - val_loss: 1.6346 - val_accuracy: 0.5679\n","Epoch 17/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.6183 - accuracy: 0.5822 - val_loss: 1.6268 - val_accuracy: 0.5356\n","Epoch 18/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.6099 - accuracy: 0.5841 - val_loss: 1.6180 - val_accuracy: 0.5442\n","Epoch 19/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.6005 - accuracy: 0.5865 - val_loss: 1.6072 - val_accuracy: 0.5841\n","Epoch 20/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.5916 - accuracy: 0.5994 - val_loss: 1.5997 - val_accuracy: 0.5679\n","Epoch 21/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.5838 - accuracy: 0.5999 - val_loss: 1.5921 - val_accuracy: 0.5647\n","Epoch 22/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.5753 - accuracy: 0.5981 - val_loss: 1.5815 - val_accuracy: 0.5841\n","Epoch 23/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.5667 - accuracy: 0.5921 - val_loss: 1.5732 - val_accuracy: 0.5841\n","Epoch 24/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.5591 - accuracy: 0.5959 - val_loss: 1.5653 - val_accuracy: 0.5808\n","Epoch 25/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.5517 - accuracy: 0.5927 - val_loss: 1.5594 - val_accuracy: 0.5647\n","Epoch 26/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.5433 - accuracy: 0.5978 - val_loss: 1.5506 - val_accuracy: 0.5819\n","Epoch 27/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.5356 - accuracy: 0.6021 - val_loss: 1.5429 - val_accuracy: 0.5722\n","Epoch 28/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.5264 - accuracy: 0.6026 - val_loss: 1.5362 - val_accuracy: 0.5690\n","Epoch 29/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.5182 - accuracy: 0.6010 - val_loss: 1.5312 - val_accuracy: 0.5636\n","Epoch 30/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.5132 - accuracy: 0.5913 - val_loss: 1.5251 - val_accuracy: 0.5765\n","Epoch 31/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.5048 - accuracy: 0.5997 - val_loss: 1.5268 - val_accuracy: 0.5485\n","Epoch 32/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.4967 - accuracy: 0.6024 - val_loss: 1.5092 - val_accuracy: 0.5808\n","Epoch 33/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.4892 - accuracy: 0.6032 - val_loss: 1.5053 - val_accuracy: 0.5700\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4813 - accuracy: 0.6078 - val_loss: 1.5026 - val_accuracy: 0.5582\n","Epoch 35/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.4756 - accuracy: 0.6061 - val_loss: 1.4879 - val_accuracy: 0.5700\n","Epoch 36/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.4697 - accuracy: 0.6048 - val_loss: 1.4823 - val_accuracy: 0.5787\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.4585 - accuracy: 0.6172 - val_loss: 1.4788 - val_accuracy: 0.5711\n","Epoch 38/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.4515 - accuracy: 0.6072 - val_loss: 1.4687 - val_accuracy: 0.5733\n","Epoch 39/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.4442 - accuracy: 0.6129 - val_loss: 1.4601 - val_accuracy: 0.5754\n","Epoch 40/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.4383 - accuracy: 0.6099 - val_loss: 1.4537 - val_accuracy: 0.5765\n","Epoch 41/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.4304 - accuracy: 0.6161 - val_loss: 1.4490 - val_accuracy: 0.5744\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.4227 - accuracy: 0.6234 - val_loss: 1.4420 - val_accuracy: 0.5819\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.4162 - accuracy: 0.6140 - val_loss: 1.4351 - val_accuracy: 0.5797\n","Epoch 44/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.4086 - accuracy: 0.6255 - val_loss: 1.4342 - val_accuracy: 0.5765\n","Epoch 45/100\n","29/29 [==============================] - 2s 63ms/step - loss: 1.4058 - accuracy: 0.6223 - val_loss: 1.4253 - val_accuracy: 0.5862\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.3963 - accuracy: 0.6258 - val_loss: 1.4159 - val_accuracy: 0.5776\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3895 - accuracy: 0.6220 - val_loss: 1.4102 - val_accuracy: 0.5830\n","Epoch 48/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3804 - accuracy: 0.6395 - val_loss: 1.4048 - val_accuracy: 0.5862\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3763 - accuracy: 0.6210 - val_loss: 1.3983 - val_accuracy: 0.5884\n","Epoch 50/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.3661 - accuracy: 0.6395 - val_loss: 1.3924 - val_accuracy: 0.5830\n","Epoch 51/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3679 - accuracy: 0.6175 - val_loss: 1.3901 - val_accuracy: 0.5884\n","Epoch 52/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3587 - accuracy: 0.6272 - val_loss: 1.3814 - val_accuracy: 0.5948\n","Epoch 53/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.3483 - accuracy: 0.6355 - val_loss: 1.3753 - val_accuracy: 0.5873\n","Epoch 54/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3414 - accuracy: 0.6417 - val_loss: 1.3700 - val_accuracy: 0.5873\n","Epoch 55/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.3344 - accuracy: 0.6404 - val_loss: 1.3653 - val_accuracy: 0.5873\n","Epoch 56/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.3317 - accuracy: 0.6379 - val_loss: 1.3616 - val_accuracy: 0.5884\n","Epoch 57/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.3255 - accuracy: 0.6350 - val_loss: 1.3604 - val_accuracy: 0.6002\n","Epoch 58/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3197 - accuracy: 0.6412 - val_loss: 1.3481 - val_accuracy: 0.5894\n","Epoch 59/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.3086 - accuracy: 0.6511 - val_loss: 1.3428 - val_accuracy: 0.5970\n","Epoch 60/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3011 - accuracy: 0.6506 - val_loss: 1.3403 - val_accuracy: 0.5970\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3011 - accuracy: 0.6466 - val_loss: 1.3384 - val_accuracy: 0.5948\n","Epoch 62/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2915 - accuracy: 0.6581 - val_loss: 1.3313 - val_accuracy: 0.5841\n","Epoch 63/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.2862 - accuracy: 0.6546 - val_loss: 1.3376 - val_accuracy: 0.5938\n","Epoch 64/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2835 - accuracy: 0.6460 - val_loss: 1.3178 - val_accuracy: 0.5894\n","Epoch 65/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.2755 - accuracy: 0.6506 - val_loss: 1.3142 - val_accuracy: 0.5905\n","Epoch 66/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2656 - accuracy: 0.6598 - val_loss: 1.3107 - val_accuracy: 0.6034\n","Epoch 67/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2675 - accuracy: 0.6506 - val_loss: 1.3055 - val_accuracy: 0.6045\n","Epoch 68/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2577 - accuracy: 0.6511 - val_loss: 1.3025 - val_accuracy: 0.5808\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2503 - accuracy: 0.6608 - val_loss: 1.2931 - val_accuracy: 0.6013\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2458 - accuracy: 0.6665 - val_loss: 1.2877 - val_accuracy: 0.5959\n","Epoch 71/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.2370 - accuracy: 0.6654 - val_loss: 1.2859 - val_accuracy: 0.5916\n","Epoch 72/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2313 - accuracy: 0.6676 - val_loss: 1.2793 - val_accuracy: 0.5970\n","Epoch 73/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2269 - accuracy: 0.6673 - val_loss: 1.2759 - val_accuracy: 0.5981\n","Epoch 74/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2190 - accuracy: 0.6748 - val_loss: 1.2770 - val_accuracy: 0.5776\n","Epoch 75/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.2156 - accuracy: 0.6727 - val_loss: 1.2685 - val_accuracy: 0.5981\n","Epoch 76/100\n","29/29 [==============================] - 1s 35ms/step - loss: 1.2104 - accuracy: 0.6678 - val_loss: 1.2688 - val_accuracy: 0.6088\n","Epoch 77/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.2066 - accuracy: 0.6759 - val_loss: 1.2611 - val_accuracy: 0.5873\n","Epoch 78/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.1975 - accuracy: 0.6859 - val_loss: 1.2590 - val_accuracy: 0.5873\n","Epoch 79/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.1909 - accuracy: 0.6805 - val_loss: 1.2499 - val_accuracy: 0.6067\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1880 - accuracy: 0.6794 - val_loss: 1.2538 - val_accuracy: 0.6056\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1832 - accuracy: 0.6789 - val_loss: 1.2511 - val_accuracy: 0.5808\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1782 - accuracy: 0.6781 - val_loss: 1.2387 - val_accuracy: 0.5948\n","Epoch 83/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1712 - accuracy: 0.6835 - val_loss: 1.2346 - val_accuracy: 0.6099\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1680 - accuracy: 0.6870 - val_loss: 1.2326 - val_accuracy: 0.5905\n","Epoch 85/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1634 - accuracy: 0.6859 - val_loss: 1.2268 - val_accuracy: 0.6110\n","Epoch 86/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1562 - accuracy: 0.6897 - val_loss: 1.2240 - val_accuracy: 0.6045\n","Epoch 87/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.1504 - accuracy: 0.6907 - val_loss: 1.2204 - val_accuracy: 0.5948\n","Epoch 88/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.1456 - accuracy: 0.6902 - val_loss: 1.2193 - val_accuracy: 0.5894\n","Epoch 89/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.1390 - accuracy: 0.6961 - val_loss: 1.2150 - val_accuracy: 0.5916\n","Epoch 90/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1382 - accuracy: 0.6835 - val_loss: 1.2112 - val_accuracy: 0.6013\n","Epoch 91/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1322 - accuracy: 0.6940 - val_loss: 1.2122 - val_accuracy: 0.5894\n","Epoch 92/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1297 - accuracy: 0.6940 - val_loss: 1.2164 - val_accuracy: 0.6164\n","Epoch 93/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1220 - accuracy: 0.6875 - val_loss: 1.2000 - val_accuracy: 0.6078\n","Epoch 94/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1194 - accuracy: 0.6934 - val_loss: 1.2046 - val_accuracy: 0.6131\n","Epoch 95/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1184 - accuracy: 0.6905 - val_loss: 1.2011 - val_accuracy: 0.5948\n","Epoch 96/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1058 - accuracy: 0.7074 - val_loss: 1.1963 - val_accuracy: 0.5959\n","Epoch 97/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1023 - accuracy: 0.6999 - val_loss: 1.2073 - val_accuracy: 0.5733\n","Epoch 98/100\n","29/29 [==============================] - 0s 9ms/step - loss: 1.0977 - accuracy: 0.7002 - val_loss: 1.1880 - val_accuracy: 0.6088\n","Epoch 99/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0899 - accuracy: 0.7072 - val_loss: 1.1831 - val_accuracy: 0.5970\n","Epoch 100/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0939 - accuracy: 0.7031 - val_loss: 1.1824 - val_accuracy: 0.5916\n","{'loss': [1.7746392488479614, 1.76291823387146, 1.752161979675293, 1.7418559789657593, 1.731308102607727, 1.7212321758270264, 1.7122164964675903, 1.7009116411209106, 1.6931058168411255, 1.6816191673278809, 1.6724284887313843, 1.6642162799835205, 1.6544886827468872, 1.6468530893325806, 1.6353344917297363, 1.6263717412948608, 1.6183453798294067, 1.6098920106887817, 1.6004741191864014, 1.5916355848312378, 1.5838135480880737, 1.5753424167633057, 1.5667136907577515, 1.5590626001358032, 1.5516750812530518, 1.5433322191238403, 1.5355792045593262, 1.526440143585205, 1.5182477235794067, 1.513238549232483, 1.5047883987426758, 1.4967429637908936, 1.4892019033432007, 1.4813462495803833, 1.4756461381912231, 1.4697169065475464, 1.4585275650024414, 1.4515219926834106, 1.444185733795166, 1.4383171796798706, 1.430429220199585, 1.4226549863815308, 1.4162472486495972, 1.408642053604126, 1.405821442604065, 1.396323800086975, 1.3894867897033691, 1.3803820610046387, 1.3763175010681152, 1.366129755973816, 1.367910623550415, 1.3587497472763062, 1.3483200073242188, 1.3414357900619507, 1.3344285488128662, 1.3316959142684937, 1.3254948854446411, 1.3197059631347656, 1.3086140155792236, 1.3010623455047607, 1.301077127456665, 1.2915420532226562, 1.2861570119857788, 1.283478856086731, 1.2755160331726074, 1.265601396560669, 1.2674798965454102, 1.2577049732208252, 1.250251293182373, 1.2457985877990723, 1.2369686365127563, 1.2313309907913208, 1.2268884181976318, 1.2190337181091309, 1.2156388759613037, 1.2104016542434692, 1.2065534591674805, 1.1974741220474243, 1.1908823251724243, 1.1880004405975342, 1.183241367340088, 1.1781847476959229, 1.1711866855621338, 1.1680289506912231, 1.1633903980255127, 1.1561949253082275, 1.1504368782043457, 1.1455875635147095, 1.1389718055725098, 1.1382485628128052, 1.13224196434021, 1.1296640634536743, 1.121993064880371, 1.1194058656692505, 1.1184443235397339, 1.1057629585266113, 1.102299690246582, 1.0976824760437012, 1.0899144411087036, 1.0939134359359741], 'accuracy': [0.5037715435028076, 0.5457974076271057, 0.5476831793785095, 0.5568426847457886, 0.5471444129943848, 0.5651939511299133, 0.5509159564971924, 0.5754310488700867, 0.5579202771186829, 0.5773168206214905, 0.5821659564971924, 0.5800107717514038, 0.5773168206214905, 0.556034505367279, 0.584590494632721, 0.5889008641242981, 0.5821659564971924, 0.5840517282485962, 0.5864762663841248, 0.5994073152542114, 0.599946141242981, 0.5980603694915771, 0.592133641242981, 0.5959051847457886, 0.5926724076271057, 0.5977909564971924, 0.6021012663841248, 0.6026400923728943, 0.6010237336158752, 0.5913254022598267, 0.5996767282485962, 0.6023706793785095, 0.603178858757019, 0.607758641242981, 0.6061422228813171, 0.6047952771186829, 0.6171875, 0.6072198152542114, 0.6128771305084229, 0.6099137663841248, 0.6161099076271057, 0.623383641242981, 0.6139547228813171, 0.6255387663841248, 0.6223060488700867, 0.6258081793785095, 0.6220366358757019, 0.6395474076271057, 0.6209590435028076, 0.6395474076271057, 0.6174569129943848, 0.6271551847457886, 0.6355064511299133, 0.6417025923728943, 0.6403555870056152, 0.6379310488700867, 0.6349676847457886, 0.6411637663841248, 0.6511314511299133, 0.6505926847457886, 0.6465517282485962, 0.6581357717514038, 0.654633641242981, 0.6460129022598267, 0.6505926847457886, 0.6597521305084229, 0.6505926847457886, 0.6511314511299133, 0.6608297228813171, 0.6664870977401733, 0.665409505367279, 0.6675646305084229, 0.6672952771186829, 0.6748383641242981, 0.6726831793785095, 0.6678340435028076, 0.6759159564971924, 0.685883641242981, 0.6804956793785095, 0.6794180870056152, 0.6788793206214905, 0.678071141242981, 0.6834590435028076, 0.6869612336158752, 0.685883641242981, 0.6896551847457886, 0.6907327771186829, 0.6901939511299133, 0.6961206793785095, 0.6834590435028076, 0.693965494632721, 0.693965494632721, 0.6875, 0.6934267282485962, 0.6904633641242981, 0.7074353694915771, 0.6998922228813171, 0.7001616358757019, 0.7071659564971924, 0.703125], 'val_loss': [1.7696528434753418, 1.7603485584259033, 1.751121163368225, 1.7418888807296753, 1.7328499555587769, 1.7240043878555298, 1.7147886753082275, 1.705932378768921, 1.6971443891525269, 1.6884405612945557, 1.679445505142212, 1.670656442642212, 1.6623157262802124, 1.6526819467544556, 1.6440346240997314, 1.63463294506073, 1.6267588138580322, 1.6180033683776855, 1.6072289943695068, 1.5997143983840942, 1.592090129852295, 1.5815387964248657, 1.5731569528579712, 1.5653482675552368, 1.5594148635864258, 1.5505882501602173, 1.5428979396820068, 1.536161184310913, 1.531166434288025, 1.5250838994979858, 1.5268235206604004, 1.509207844734192, 1.5052525997161865, 1.5026103258132935, 1.487925410270691, 1.4822640419006348, 1.4788305759429932, 1.468666911125183, 1.4601494073867798, 1.4536617994308472, 1.4490275382995605, 1.4419777393341064, 1.435105800628662, 1.4342448711395264, 1.425303339958191, 1.4158604145050049, 1.4102176427841187, 1.4048246145248413, 1.3982555866241455, 1.392433524131775, 1.3900938034057617, 1.381362795829773, 1.3753321170806885, 1.3700388669967651, 1.3653157949447632, 1.3616490364074707, 1.3603893518447876, 1.348054051399231, 1.3428138494491577, 1.3402596712112427, 1.3384422063827515, 1.3313270807266235, 1.3375741243362427, 1.317825198173523, 1.3141897916793823, 1.3106745481491089, 1.3054732084274292, 1.3024734258651733, 1.2931222915649414, 1.287676215171814, 1.2859259843826294, 1.279326319694519, 1.27585768699646, 1.2770253419876099, 1.2685195207595825, 1.2687851190567017, 1.261125087738037, 1.2589516639709473, 1.2499034404754639, 1.2537509202957153, 1.2510833740234375, 1.2386683225631714, 1.234613299369812, 1.2325607538223267, 1.226847767829895, 1.2240326404571533, 1.2203984260559082, 1.2192760705947876, 1.2150297164916992, 1.211242914199829, 1.2122408151626587, 1.2164009809494019, 1.2000055313110352, 1.2045903205871582, 1.2011104822158813, 1.1963250637054443, 1.207262396812439, 1.1880176067352295, 1.1830745935440063, 1.1823875904083252], 'val_accuracy': [0.5053879022598267, 0.5409482717514038, 0.5495689511299133, 0.5344827771186829, 0.5581896305084229, 0.5269396305084229, 0.5215517282485962, 0.5204741358757019, 0.5463362336158752, 0.5711206793785095, 0.5474137663841248, 0.5711206793785095, 0.5161637663841248, 0.5721982717514038, 0.537715494632721, 0.5678879022598267, 0.5355603694915771, 0.5441810488700867, 0.5840517282485962, 0.5678879022598267, 0.5646551847457886, 0.5840517282485962, 0.5840517282485962, 0.5808189511299133, 0.5646551847457886, 0.5818965435028076, 0.5721982717514038, 0.568965494632721, 0.5635775923728943, 0.576508641242981, 0.548491358757019, 0.5808189511299133, 0.5700430870056152, 0.5581896305084229, 0.5700430870056152, 0.5786637663841248, 0.5711206793785095, 0.5732758641242981, 0.5754310488700867, 0.576508641242981, 0.5743534564971924, 0.5818965435028076, 0.579741358757019, 0.576508641242981, 0.5862069129943848, 0.5775862336158752, 0.5829741358757019, 0.5862069129943848, 0.5883620977401733, 0.5829741358757019, 0.5883620977401733, 0.5948275923728943, 0.587284505367279, 0.587284505367279, 0.587284505367279, 0.5883620977401733, 0.600215494632721, 0.5894396305084229, 0.5969827771186829, 0.5969827771186829, 0.5948275923728943, 0.5840517282485962, 0.59375, 0.5894396305084229, 0.5905172228813171, 0.6034482717514038, 0.6045258641242981, 0.5808189511299133, 0.6012930870056152, 0.5959051847457886, 0.5915948152542114, 0.5969827771186829, 0.5980603694915771, 0.5775862336158752, 0.5980603694915771, 0.6088362336158752, 0.587284505367279, 0.587284505367279, 0.6066810488700867, 0.6056034564971924, 0.5808189511299133, 0.5948275923728943, 0.6099137663841248, 0.5905172228813171, 0.610991358757019, 0.6045258641242981, 0.5948275923728943, 0.5894396305084229, 0.5915948152542114, 0.6012930870056152, 0.5894396305084229, 0.6163793206214905, 0.607758641242981, 0.6131465435028076, 0.5948275923728943, 0.5959051847457886, 0.5732758641242981, 0.6088362336158752, 0.5969827771186829, 0.5915948152542114]}\n","38/38 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 31ms/step - loss: 1.7744 - accuracy: 0.5218 - val_loss: 1.7700 - val_accuracy: 0.4932\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 1.7636 - accuracy: 0.5703"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 1s 18ms/step - loss: 1.7636 - accuracy: 0.5274 - val_loss: 1.7611 - val_accuracy: 0.5373\n","Epoch 3/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.7535 - accuracy: 0.5481 - val_loss: 1.7522 - val_accuracy: 0.5362\n","Epoch 4/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.7435 - accuracy: 0.5495 - val_loss: 1.7434 - val_accuracy: 0.5181\n","Epoch 5/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.7335 - accuracy: 0.5563 - val_loss: 1.7345 - val_accuracy: 0.5464\n","Epoch 6/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.7238 - accuracy: 0.5668 - val_loss: 1.7258 - val_accuracy: 0.5113\n","Epoch 7/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.7150 - accuracy: 0.5478 - val_loss: 1.7172 - val_accuracy: 0.4977\n","Epoch 8/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.7071 - accuracy: 0.5388 - val_loss: 1.7086 - val_accuracy: 0.5147\n","Epoch 9/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.6957 - accuracy: 0.5651 - val_loss: 1.7001 - val_accuracy: 0.5464\n","Epoch 10/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6871 - accuracy: 0.5557 - val_loss: 1.6917 - val_accuracy: 0.5373\n","Epoch 11/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.6775 - accuracy: 0.5739 - val_loss: 1.6832 - val_accuracy: 0.5713\n","Epoch 12/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.6689 - accuracy: 0.5679 - val_loss: 1.6745 - val_accuracy: 0.5656\n","Epoch 13/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6590 - accuracy: 0.5693 - val_loss: 1.6660 - val_accuracy: 0.5600\n","Epoch 14/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.6518 - accuracy: 0.5608 - val_loss: 1.6578 - val_accuracy: 0.5486\n","Epoch 15/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.6438 - accuracy: 0.5631 - val_loss: 1.6504 - val_accuracy: 0.5090\n","Epoch 16/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6343 - accuracy: 0.5722 - val_loss: 1.6408 - val_accuracy: 0.5645\n","Epoch 17/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6259 - accuracy: 0.5750 - val_loss: 1.6321 - val_accuracy: 0.5701\n","Epoch 18/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.6163 - accuracy: 0.5860 - val_loss: 1.6235 - val_accuracy: 0.5803\n","Epoch 19/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.6075 - accuracy: 0.5917 - val_loss: 1.6151 - val_accuracy: 0.5860\n","Epoch 20/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.6005 - accuracy: 0.5826 - val_loss: 1.6089 - val_accuracy: 0.5226\n","Epoch 21/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.5937 - accuracy: 0.5838 - val_loss: 1.5983 - val_accuracy: 0.5928\n","Epoch 22/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.5849 - accuracy: 0.5778 - val_loss: 1.5929 - val_accuracy: 0.5645\n","Epoch 23/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.5776 - accuracy: 0.5908 - val_loss: 1.5874 - val_accuracy: 0.5328\n","Epoch 24/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.5692 - accuracy: 0.5939 - val_loss: 1.5741 - val_accuracy: 0.5871\n","Epoch 25/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.5608 - accuracy: 0.5968 - val_loss: 1.5681 - val_accuracy: 0.5860\n","Epoch 26/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5549 - accuracy: 0.5905 - val_loss: 1.5600 - val_accuracy: 0.5679\n","Epoch 27/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.5452 - accuracy: 0.6038 - val_loss: 1.5523 - val_accuracy: 0.5747\n","Epoch 28/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5379 - accuracy: 0.6084 - val_loss: 1.5481 - val_accuracy: 0.5758\n","Epoch 29/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.5329 - accuracy: 0.5886 - val_loss: 1.5372 - val_accuracy: 0.5995\n","Epoch 30/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.5236 - accuracy: 0.6033 - val_loss: 1.5299 - val_accuracy: 0.5713\n","Epoch 31/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5181 - accuracy: 0.6005 - val_loss: 1.5258 - val_accuracy: 0.5848\n","Epoch 32/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.5134 - accuracy: 0.5900 - val_loss: 1.5213 - val_accuracy: 0.5724\n","Epoch 33/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.5020 - accuracy: 0.6084 - val_loss: 1.5114 - val_accuracy: 0.5656\n","Epoch 34/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4968 - accuracy: 0.6013 - val_loss: 1.5025 - val_accuracy: 0.5792\n","Epoch 35/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4882 - accuracy: 0.6075 - val_loss: 1.5035 - val_accuracy: 0.5679\n","Epoch 36/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4809 - accuracy: 0.6053 - val_loss: 1.4900 - val_accuracy: 0.5735\n","Epoch 37/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4721 - accuracy: 0.6188 - val_loss: 1.4827 - val_accuracy: 0.5769\n","Epoch 38/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4662 - accuracy: 0.6174 - val_loss: 1.4758 - val_accuracy: 0.5984\n","Epoch 39/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4587 - accuracy: 0.6222 - val_loss: 1.4695 - val_accuracy: 0.5973\n","Epoch 40/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4525 - accuracy: 0.6118 - val_loss: 1.4647 - val_accuracy: 0.5724\n","Epoch 41/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.4454 - accuracy: 0.6126 - val_loss: 1.4605 - val_accuracy: 0.5724\n","Epoch 42/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4436 - accuracy: 0.5999 - val_loss: 1.4648 - val_accuracy: 0.5860\n","Epoch 43/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4329 - accuracy: 0.6228 - val_loss: 1.4440 - val_accuracy: 0.5837\n","Epoch 44/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4237 - accuracy: 0.6259 - val_loss: 1.4372 - val_accuracy: 0.5962\n","Epoch 45/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4175 - accuracy: 0.6254 - val_loss: 1.4347 - val_accuracy: 0.5950\n","Epoch 46/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4149 - accuracy: 0.6183 - val_loss: 1.4273 - val_accuracy: 0.5735\n","Epoch 47/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4040 - accuracy: 0.6350 - val_loss: 1.4187 - val_accuracy: 0.5837\n","Epoch 48/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.4033 - accuracy: 0.6188 - val_loss: 1.4185 - val_accuracy: 0.5758\n","Epoch 49/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.3951 - accuracy: 0.6208 - val_loss: 1.4068 - val_accuracy: 0.6007\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3856 - accuracy: 0.6313 - val_loss: 1.4017 - val_accuracy: 0.6052\n","Epoch 51/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.3799 - accuracy: 0.6293 - val_loss: 1.3955 - val_accuracy: 0.5916\n","Epoch 52/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.3725 - accuracy: 0.6404 - val_loss: 1.3941 - val_accuracy: 0.5792\n","Epoch 53/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.3659 - accuracy: 0.6398 - val_loss: 1.3830 - val_accuracy: 0.5962\n","Epoch 54/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.3634 - accuracy: 0.6321 - val_loss: 1.3839 - val_accuracy: 0.6052\n","Epoch 55/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.3550 - accuracy: 0.6404 - val_loss: 1.3720 - val_accuracy: 0.6063\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3481 - accuracy: 0.6347 - val_loss: 1.3664 - val_accuracy: 0.5962\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3425 - accuracy: 0.6387 - val_loss: 1.3703 - val_accuracy: 0.6018\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3392 - accuracy: 0.6387 - val_loss: 1.3601 - val_accuracy: 0.6007\n","Epoch 59/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.3284 - accuracy: 0.6522 - val_loss: 1.3498 - val_accuracy: 0.6120\n","Epoch 60/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3210 - accuracy: 0.6565 - val_loss: 1.3442 - val_accuracy: 0.6041\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3174 - accuracy: 0.6542 - val_loss: 1.3420 - val_accuracy: 0.5837\n","Epoch 62/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.3140 - accuracy: 0.6457 - val_loss: 1.3335 - val_accuracy: 0.6143\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3036 - accuracy: 0.6528 - val_loss: 1.3297 - val_accuracy: 0.6029\n","Epoch 64/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.2963 - accuracy: 0.6590 - val_loss: 1.3242 - val_accuracy: 0.5984\n","Epoch 65/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2891 - accuracy: 0.6689 - val_loss: 1.3181 - val_accuracy: 0.6199\n","Epoch 66/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.2842 - accuracy: 0.6644 - val_loss: 1.3155 - val_accuracy: 0.6176\n","Epoch 67/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.2785 - accuracy: 0.6664 - val_loss: 1.3089 - val_accuracy: 0.6109\n","Epoch 68/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.2758 - accuracy: 0.6596 - val_loss: 1.3046 - val_accuracy: 0.6029\n","Epoch 69/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.2676 - accuracy: 0.6669 - val_loss: 1.2990 - val_accuracy: 0.6233\n","Epoch 70/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.2633 - accuracy: 0.6610 - val_loss: 1.2947 - val_accuracy: 0.6188\n","Epoch 71/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.2576 - accuracy: 0.6689 - val_loss: 1.2900 - val_accuracy: 0.6143\n","Epoch 72/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2488 - accuracy: 0.6735 - val_loss: 1.2943 - val_accuracy: 0.5916\n","Epoch 73/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.2464 - accuracy: 0.6681 - val_loss: 1.2853 - val_accuracy: 0.6233\n","Epoch 74/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2421 - accuracy: 0.6661 - val_loss: 1.2758 - val_accuracy: 0.6267\n","Epoch 75/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.2358 - accuracy: 0.6760 - val_loss: 1.2721 - val_accuracy: 0.6267\n","Epoch 76/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.2310 - accuracy: 0.6715 - val_loss: 1.2670 - val_accuracy: 0.6256\n","Epoch 77/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2212 - accuracy: 0.6814 - val_loss: 1.2649 - val_accuracy: 0.6029\n","Epoch 78/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.2186 - accuracy: 0.6797 - val_loss: 1.2582 - val_accuracy: 0.6176\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2112 - accuracy: 0.6808 - val_loss: 1.2651 - val_accuracy: 0.5916\n","Epoch 80/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.2086 - accuracy: 0.6817 - val_loss: 1.2500 - val_accuracy: 0.6244\n","Epoch 81/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.2049 - accuracy: 0.6672 - val_loss: 1.2499 - val_accuracy: 0.5995\n","Epoch 82/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1976 - accuracy: 0.6791 - val_loss: 1.2527 - val_accuracy: 0.5916\n","Epoch 83/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1932 - accuracy: 0.6887 - val_loss: 1.2382 - val_accuracy: 0.6176\n","Epoch 84/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1879 - accuracy: 0.6848 - val_loss: 1.2698 - val_accuracy: 0.5848\n","Epoch 85/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1830 - accuracy: 0.6836 - val_loss: 1.2317 - val_accuracy: 0.6176\n","Epoch 86/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1768 - accuracy: 0.6887 - val_loss: 1.2283 - val_accuracy: 0.6131\n","Epoch 87/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1736 - accuracy: 0.6879 - val_loss: 1.2327 - val_accuracy: 0.6256\n","Epoch 88/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1688 - accuracy: 0.6919 - val_loss: 1.2206 - val_accuracy: 0.6097\n","Epoch 89/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1608 - accuracy: 0.6916 - val_loss: 1.2164 - val_accuracy: 0.6109\n","Epoch 90/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1527 - accuracy: 0.6984 - val_loss: 1.2120 - val_accuracy: 0.6188\n","Epoch 91/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1584 - accuracy: 0.6865 - val_loss: 1.2153 - val_accuracy: 0.6029\n","Epoch 92/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1479 - accuracy: 0.6927 - val_loss: 1.2068 - val_accuracy: 0.6357\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1406 - accuracy: 0.6998 - val_loss: 1.2056 - val_accuracy: 0.6324\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1332 - accuracy: 0.6986 - val_loss: 1.1993 - val_accuracy: 0.6154\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1292 - accuracy: 0.6984 - val_loss: 1.1951 - val_accuracy: 0.6165\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1229 - accuracy: 0.7049 - val_loss: 1.1920 - val_accuracy: 0.6244\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1215 - accuracy: 0.7043 - val_loss: 1.1899 - val_accuracy: 0.6312\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1139 - accuracy: 0.7066 - val_loss: 1.1881 - val_accuracy: 0.6357\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1113 - accuracy: 0.7063 - val_loss: 1.2121 - val_accuracy: 0.5871\n","Epoch 100/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1095 - accuracy: 0.7077 - val_loss: 1.1848 - val_accuracy: 0.6041\n","{'loss': [1.7744139432907104, 1.7635902166366577, 1.753487467765808, 1.7435451745986938, 1.7334949970245361, 1.7237727642059326, 1.7149534225463867, 1.7070509195327759, 1.6957025527954102, 1.687126636505127, 1.6775153875350952, 1.6689128875732422, 1.659001350402832, 1.651849389076233, 1.6438117027282715, 1.6342822313308716, 1.6258589029312134, 1.6162728071212769, 1.6075366735458374, 1.600473165512085, 1.593708872795105, 1.5848803520202637, 1.577572226524353, 1.5692038536071777, 1.5608187913894653, 1.5549232959747314, 1.545162558555603, 1.5379271507263184, 1.5328933000564575, 1.5236291885375977, 1.5180739164352417, 1.5134289264678955, 1.5020294189453125, 1.4968175888061523, 1.4881776571273804, 1.4808506965637207, 1.4720855951309204, 1.46619713306427, 1.4587414264678955, 1.4524669647216797, 1.4453500509262085, 1.443606972694397, 1.43294358253479, 1.4236624240875244, 1.417516827583313, 1.4149487018585205, 1.404031753540039, 1.4033023118972778, 1.3951219320297241, 1.385632038116455, 1.3799033164978027, 1.3724586963653564, 1.365929126739502, 1.3634206056594849, 1.3549764156341553, 1.3481365442276, 1.3424770832061768, 1.3392109870910645, 1.3283789157867432, 1.3210035562515259, 1.3174326419830322, 1.3139989376068115, 1.303570032119751, 1.296293020248413, 1.289132833480835, 1.2842475175857544, 1.278460144996643, 1.2757773399353027, 1.2675656080245972, 1.2633087635040283, 1.2576429843902588, 1.2487709522247314, 1.24636971950531, 1.2421334981918335, 1.2358280420303345, 1.2309589385986328, 1.2212246656417847, 1.2185652256011963, 1.2112209796905518, 1.2086057662963867, 1.2048660516738892, 1.1976302862167358, 1.1931915283203125, 1.1879023313522339, 1.1830283403396606, 1.176775336265564, 1.1735684871673584, 1.16879403591156, 1.160813331604004, 1.1527019739151, 1.15835702419281, 1.1479034423828125, 1.140644907951355, 1.1332122087478638, 1.1291780471801758, 1.1228644847869873, 1.1214967966079712, 1.1138899326324463, 1.1113039255142212, 1.1094551086425781], 'accuracy': [0.5217883586883545, 0.5274476408958435, 0.5481041073799133, 0.5495189428329468, 0.5563101172447205, 0.5667798519134521, 0.5478211641311646, 0.5387662649154663, 0.5650820732116699, 0.5557441711425781, 0.5738539695739746, 0.5679117441177368, 0.5693265199661255, 0.5608375668525696, 0.5631012916564941, 0.5721561908721924, 0.5749858617782593, 0.5860214829444885, 0.5916808247566223, 0.5826259255409241, 0.583757758140564, 0.5778155326843262, 0.5908319354057312, 0.5939445495605469, 0.5967742204666138, 0.5905489325523376, 0.6038483381271362, 0.6083757877349854, 0.5885682106018066, 0.6032823920249939, 0.600452721118927, 0.5899830460548401, 0.6083757877349854, 0.6013016700744629, 0.6075268983840942, 0.6052631735801697, 0.618845522403717, 0.6174306869506836, 0.6222410798072815, 0.6117713451385498, 0.6126202344894409, 0.5998868346214294, 0.6228070259094238, 0.6259196400642395, 0.6253536939620972, 0.6182795763015747, 0.6349745392799377, 0.618845522403717, 0.620826244354248, 0.6312959790229797, 0.629315197467804, 0.640350878238678, 0.6397849321365356, 0.6321448683738708, 0.640350878238678, 0.634691596031189, 0.6386530995368958, 0.6386530995368958, 0.6522354483604431, 0.6564798951148987, 0.6542161703109741, 0.6457272171974182, 0.6528013348579407, 0.6590266227722168, 0.6689304113388062, 0.664402961730957, 0.666383683681488, 0.6595925092697144, 0.6669496297836304, 0.6610073447227478, 0.6689304113388062, 0.6734578609466553, 0.668081521987915, 0.6661007404327393, 0.6760045289993286, 0.6714770793914795, 0.6813808679580688, 0.6796830892562866, 0.6808149218559265, 0.6816638112068176, 0.6672325730323792, 0.6791171431541443, 0.6887379884719849, 0.6847764849662781, 0.6836445927619934, 0.6887379884719849, 0.6878890991210938, 0.6918506026268005, 0.691567599773407, 0.6983587741851807, 0.6864742636680603, 0.6926994919776917, 0.6997736096382141, 0.6986417770385742, 0.6983587741851807, 0.7048670053482056, 0.7043010592460632, 0.7065647840499878, 0.706281840801239, 0.7076966762542725], 'val_loss': [1.7700368165969849, 1.761081576347351, 1.7521989345550537, 1.7433587312698364, 1.734538197517395, 1.7258363962173462, 1.717233419418335, 1.7086443901062012, 1.700109839439392, 1.6916826963424683, 1.6831893920898438, 1.6745154857635498, 1.6659594774246216, 1.657792568206787, 1.650373101234436, 1.6407502889633179, 1.6321054697036743, 1.6234797239303589, 1.6150959730148315, 1.6088963747024536, 1.5983151197433472, 1.5928955078125, 1.58744215965271, 1.5740966796875, 1.5681145191192627, 1.56001615524292, 1.5522764921188354, 1.5480884313583374, 1.537227749824524, 1.529854655265808, 1.5258055925369263, 1.5212767124176025, 1.5113654136657715, 1.5024659633636475, 1.503504991531372, 1.4900259971618652, 1.4827147722244263, 1.4758317470550537, 1.4694503545761108, 1.464740514755249, 1.460510492324829, 1.4647841453552246, 1.443987488746643, 1.437159776687622, 1.4347444772720337, 1.4273481369018555, 1.4186619520187378, 1.4185222387313843, 1.4067926406860352, 1.4016987085342407, 1.3954963684082031, 1.3940860033035278, 1.3830240964889526, 1.383894681930542, 1.3720016479492188, 1.3664100170135498, 1.3703217506408691, 1.3600878715515137, 1.3498332500457764, 1.3441962003707886, 1.341964840888977, 1.3335257768630981, 1.3296750783920288, 1.324180245399475, 1.3181103467941284, 1.3155345916748047, 1.308891773223877, 1.3046355247497559, 1.2990097999572754, 1.2947312593460083, 1.2900099754333496, 1.2943239212036133, 1.2853257656097412, 1.275843858718872, 1.2720985412597656, 1.2670279741287231, 1.2648797035217285, 1.2581994533538818, 1.2650946378707886, 1.2499862909317017, 1.2498983144760132, 1.2526813745498657, 1.238178014755249, 1.2698441743850708, 1.2316845655441284, 1.2283189296722412, 1.2327466011047363, 1.2206335067749023, 1.2164063453674316, 1.21201491355896, 1.215272068977356, 1.2067946195602417, 1.2056406736373901, 1.1993328332901, 1.1950997114181519, 1.1920324563980103, 1.1898910999298096, 1.1880909204483032, 1.2120885848999023, 1.184808373451233], 'val_accuracy': [0.49321267008781433, 0.5373303294181824, 0.5361990928649902, 0.5180995464324951, 0.5463801026344299, 0.5113122463226318, 0.4977375566959381, 0.5147058963775635, 0.5463801026344299, 0.5373303294181824, 0.5712669491767883, 0.5656108856201172, 0.5599547624588013, 0.5486425161361694, 0.5090497732162476, 0.564479649066925, 0.570135772228241, 0.5803167223930359, 0.5859728455543518, 0.5226244330406189, 0.5927602052688599, 0.564479649066925, 0.5328054428100586, 0.587104082107544, 0.5859728455543518, 0.5678732991218567, 0.5746606588363647, 0.5757918357849121, 0.5995475053787231, 0.5712669491767883, 0.5848416090011597, 0.5723981857299805, 0.5656108856201172, 0.5791855454444885, 0.5678732991218567, 0.5735294222831726, 0.5769230723381042, 0.598416268825531, 0.5972850918769836, 0.5723981857299805, 0.5723981857299805, 0.5859728455543518, 0.5837104320526123, 0.5961538553237915, 0.5950226187705994, 0.5735294222831726, 0.5837104320526123, 0.5757918357849121, 0.6006787419319153, 0.6052036285400391, 0.5916289687156677, 0.5791855454444885, 0.5961538553237915, 0.6052036285400391, 0.6063348650932312, 0.5961538553237915, 0.6018099784851074, 0.6006787419319153, 0.6119909286499023, 0.6040723919868469, 0.5837104320526123, 0.6142534017562866, 0.6029411554336548, 0.598416268825531, 0.6199095249176025, 0.6176470518112183, 0.610859751701355, 0.6029411554336548, 0.6233031749725342, 0.6187782883644104, 0.6142534017562866, 0.5916289687156677, 0.6233031749725342, 0.6266968250274658, 0.6266968250274658, 0.6255655884742737, 0.6029411554336548, 0.6176470518112183, 0.5916289687156677, 0.6244344115257263, 0.5995475053787231, 0.5916289687156677, 0.6176470518112183, 0.5848416090011597, 0.6176470518112183, 0.6131221652030945, 0.6255655884742737, 0.6097285151481628, 0.610859751701355, 0.6187782883644104, 0.6029411554336548, 0.6357465982437134, 0.6323529481887817, 0.6153846383094788, 0.6165158152580261, 0.6244344115257263, 0.6312217116355896, 0.6357465982437134, 0.587104082107544, 0.6040723919868469]}\n","45/45 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 5s 39ms/step - loss: 1.7743 - accuracy: 0.5085 - val_loss: 1.7690 - val_accuracy: 0.5155\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 1.7705 - accuracy: 0.4844"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 1s 20ms/step - loss: 1.7631 - accuracy: 0.5150 - val_loss: 1.7592 - val_accuracy: 0.5186\n","Epoch 3/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.7519 - accuracy: 0.5186 - val_loss: 1.7497 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.7425 - accuracy: 0.5266 - val_loss: 1.7402 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.7307 - accuracy: 0.5475 - val_loss: 1.7309 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.7203 - accuracy: 0.5568 - val_loss: 1.7217 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.7081 - accuracy: 0.5514 - val_loss: 1.7116 - val_accuracy: 0.5351\n","Epoch 8/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.6993 - accuracy: 0.5496 - val_loss: 1.7037 - val_accuracy: 0.4855\n","Epoch 9/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.6895 - accuracy: 0.5473 - val_loss: 1.6949 - val_accuracy: 0.4855\n","Epoch 10/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.6783 - accuracy: 0.5698 - val_loss: 1.6872 - val_accuracy: 0.4855\n","Epoch 11/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.6688 - accuracy: 0.5682 - val_loss: 1.6772 - val_accuracy: 0.4855\n","Epoch 12/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.6585 - accuracy: 0.5664 - val_loss: 1.6679 - val_accuracy: 0.4845\n","Epoch 13/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.6496 - accuracy: 0.5661 - val_loss: 1.6618 - val_accuracy: 0.4855\n","Epoch 14/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.6399 - accuracy: 0.5703 - val_loss: 1.6495 - val_accuracy: 0.4917\n","Epoch 15/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.6306 - accuracy: 0.5708 - val_loss: 1.6465 - val_accuracy: 0.4845\n","Epoch 16/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.6212 - accuracy: 0.5734 - val_loss: 1.6413 - val_accuracy: 0.4855\n","Epoch 17/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.6139 - accuracy: 0.5641 - val_loss: 1.6236 - val_accuracy: 0.5207\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.6024 - accuracy: 0.5827 - val_loss: 1.6152 - val_accuracy: 0.5238\n","Epoch 19/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.5933 - accuracy: 0.5770 - val_loss: 1.6030 - val_accuracy: 0.5527\n","Epoch 20/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5843 - accuracy: 0.5829 - val_loss: 1.5964 - val_accuracy: 0.5331\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.5751 - accuracy: 0.5881 - val_loss: 1.5880 - val_accuracy: 0.5393\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.5664 - accuracy: 0.5902 - val_loss: 1.5777 - val_accuracy: 0.5496\n","Epoch 23/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5591 - accuracy: 0.5672 - val_loss: 1.5793 - val_accuracy: 0.5165\n","Epoch 24/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.5494 - accuracy: 0.5842 - val_loss: 1.5609 - val_accuracy: 0.5465\n","Epoch 25/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.5410 - accuracy: 0.5917 - val_loss: 1.5540 - val_accuracy: 0.5517\n","Epoch 26/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.5316 - accuracy: 0.5889 - val_loss: 1.5456 - val_accuracy: 0.5599\n","Epoch 27/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.5242 - accuracy: 0.5904 - val_loss: 1.5376 - val_accuracy: 0.5682\n","Epoch 28/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.5174 - accuracy: 0.5910 - val_loss: 1.5457 - val_accuracy: 0.5217\n","Epoch 29/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.5118 - accuracy: 0.5853 - val_loss: 1.5219 - val_accuracy: 0.5517\n","Epoch 30/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.5018 - accuracy: 0.5977 - val_loss: 1.5188 - val_accuracy: 0.5527\n","Epoch 31/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.4932 - accuracy: 0.6034 - val_loss: 1.5093 - val_accuracy: 0.5651\n","Epoch 32/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.4873 - accuracy: 0.5922 - val_loss: 1.5008 - val_accuracy: 0.5527\n","Epoch 33/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.4756 - accuracy: 0.6065 - val_loss: 1.4930 - val_accuracy: 0.5496\n","Epoch 34/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.4686 - accuracy: 0.6106 - val_loss: 1.4870 - val_accuracy: 0.5733\n","Epoch 35/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.4600 - accuracy: 0.6103 - val_loss: 1.4803 - val_accuracy: 0.5527\n","Epoch 36/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.4540 - accuracy: 0.6021 - val_loss: 1.4756 - val_accuracy: 0.5671\n","Epoch 37/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.4464 - accuracy: 0.6078 - val_loss: 1.4744 - val_accuracy: 0.5589\n","Epoch 38/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.4394 - accuracy: 0.6047 - val_loss: 1.4617 - val_accuracy: 0.5682\n","Epoch 39/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.4336 - accuracy: 0.6008 - val_loss: 1.4544 - val_accuracy: 0.5640\n","Epoch 40/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.4253 - accuracy: 0.6085 - val_loss: 1.4548 - val_accuracy: 0.5558\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.4194 - accuracy: 0.6047 - val_loss: 1.4370 - val_accuracy: 0.5826\n","Epoch 42/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.4072 - accuracy: 0.6181 - val_loss: 1.4607 - val_accuracy: 0.5382\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4051 - accuracy: 0.6106 - val_loss: 1.4260 - val_accuracy: 0.5950\n","Epoch 44/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.3974 - accuracy: 0.6124 - val_loss: 1.4287 - val_accuracy: 0.5630\n","Epoch 45/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.3998 - accuracy: 0.5943 - val_loss: 1.4105 - val_accuracy: 0.5775\n","Epoch 46/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.3837 - accuracy: 0.6251 - val_loss: 1.4119 - val_accuracy: 0.5713\n","Epoch 47/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3762 - accuracy: 0.6256 - val_loss: 1.3990 - val_accuracy: 0.6033\n","Epoch 48/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.3696 - accuracy: 0.6266 - val_loss: 1.3933 - val_accuracy: 0.6043\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3612 - accuracy: 0.6274 - val_loss: 1.3889 - val_accuracy: 0.5868\n","Epoch 50/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3554 - accuracy: 0.6225 - val_loss: 1.3801 - val_accuracy: 0.5847\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3475 - accuracy: 0.6279 - val_loss: 1.3740 - val_accuracy: 0.5981\n","Epoch 52/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.3424 - accuracy: 0.6248 - val_loss: 1.3680 - val_accuracy: 0.6054\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3343 - accuracy: 0.6320 - val_loss: 1.3623 - val_accuracy: 0.5899\n","Epoch 54/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3287 - accuracy: 0.6390 - val_loss: 1.3563 - val_accuracy: 0.5888\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3218 - accuracy: 0.6331 - val_loss: 1.3502 - val_accuracy: 0.6012\n","Epoch 56/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3141 - accuracy: 0.6424 - val_loss: 1.3496 - val_accuracy: 0.5940\n","Epoch 57/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.3114 - accuracy: 0.6323 - val_loss: 1.3386 - val_accuracy: 0.6023\n","Epoch 58/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.3054 - accuracy: 0.6382 - val_loss: 1.3456 - val_accuracy: 0.5651\n","Epoch 59/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2984 - accuracy: 0.6382 - val_loss: 1.3280 - val_accuracy: 0.5981\n","Epoch 60/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.2895 - accuracy: 0.6426 - val_loss: 1.3225 - val_accuracy: 0.6012\n","Epoch 61/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.2860 - accuracy: 0.6382 - val_loss: 1.3192 - val_accuracy: 0.5744\n","Epoch 62/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2775 - accuracy: 0.6432 - val_loss: 1.3147 - val_accuracy: 0.5682\n","Epoch 63/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.2761 - accuracy: 0.6439 - val_loss: 1.3095 - val_accuracy: 0.5754\n","Epoch 64/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2678 - accuracy: 0.6429 - val_loss: 1.3010 - val_accuracy: 0.6012\n","Epoch 65/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2604 - accuracy: 0.6553 - val_loss: 1.2966 - val_accuracy: 0.6033\n","Epoch 66/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2600 - accuracy: 0.6424 - val_loss: 1.3012 - val_accuracy: 0.5857\n","Epoch 67/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2497 - accuracy: 0.6486 - val_loss: 1.2865 - val_accuracy: 0.6054\n","Epoch 68/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2434 - accuracy: 0.6527 - val_loss: 1.2829 - val_accuracy: 0.5816\n","Epoch 69/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.2379 - accuracy: 0.6548 - val_loss: 1.2779 - val_accuracy: 0.6043\n","Epoch 70/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2338 - accuracy: 0.6486 - val_loss: 1.2759 - val_accuracy: 0.6085\n","Epoch 71/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2351 - accuracy: 0.6362 - val_loss: 1.2685 - val_accuracy: 0.5826\n","Epoch 72/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2210 - accuracy: 0.6553 - val_loss: 1.2741 - val_accuracy: 0.5795\n","Epoch 73/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2226 - accuracy: 0.6470 - val_loss: 1.2581 - val_accuracy: 0.6074\n","Epoch 74/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.2086 - accuracy: 0.6682 - val_loss: 1.2527 - val_accuracy: 0.6033\n","Epoch 75/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.2086 - accuracy: 0.6556 - val_loss: 1.2486 - val_accuracy: 0.6002\n","Epoch 76/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.2009 - accuracy: 0.6561 - val_loss: 1.2436 - val_accuracy: 0.6043\n","Epoch 77/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1938 - accuracy: 0.6643 - val_loss: 1.2397 - val_accuracy: 0.6012\n","Epoch 78/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.1872 - accuracy: 0.6705 - val_loss: 1.2366 - val_accuracy: 0.6126\n","Epoch 79/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1868 - accuracy: 0.6607 - val_loss: 1.2338 - val_accuracy: 0.6074\n","Epoch 80/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1776 - accuracy: 0.6716 - val_loss: 1.2271 - val_accuracy: 0.6095\n","Epoch 81/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1701 - accuracy: 0.6770 - val_loss: 1.2228 - val_accuracy: 0.6043\n","Epoch 82/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1717 - accuracy: 0.6659 - val_loss: 1.2301 - val_accuracy: 0.5837\n","Epoch 83/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1727 - accuracy: 0.6571 - val_loss: 1.2291 - val_accuracy: 0.5857\n","Epoch 84/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1676 - accuracy: 0.6584 - val_loss: 1.2111 - val_accuracy: 0.5940\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1551 - accuracy: 0.6773 - val_loss: 1.2189 - val_accuracy: 0.5888\n","Epoch 86/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1514 - accuracy: 0.6661 - val_loss: 1.2415 - val_accuracy: 0.5640\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1564 - accuracy: 0.6517 - val_loss: 1.1991 - val_accuracy: 0.5981\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1380 - accuracy: 0.6752 - val_loss: 1.2000 - val_accuracy: 0.5930\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1344 - accuracy: 0.6804 - val_loss: 1.1923 - val_accuracy: 0.6116\n","Epoch 90/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.1280 - accuracy: 0.6827 - val_loss: 1.1900 - val_accuracy: 0.6136\n","Epoch 91/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1203 - accuracy: 0.6848 - val_loss: 1.1850 - val_accuracy: 0.6012\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1205 - accuracy: 0.6832 - val_loss: 1.1829 - val_accuracy: 0.6012\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1196 - accuracy: 0.6724 - val_loss: 1.2002 - val_accuracy: 0.5816\n","Epoch 94/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1108 - accuracy: 0.6871 - val_loss: 1.1809 - val_accuracy: 0.6116\n","Epoch 95/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1042 - accuracy: 0.6904 - val_loss: 1.1741 - val_accuracy: 0.6064\n","Epoch 96/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1056 - accuracy: 0.6705 - val_loss: 1.1734 - val_accuracy: 0.5950\n","Epoch 97/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0943 - accuracy: 0.6868 - val_loss: 1.1652 - val_accuracy: 0.6085\n","Epoch 98/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0885 - accuracy: 0.6966 - val_loss: 1.1688 - val_accuracy: 0.6074\n","Epoch 99/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0867 - accuracy: 0.6935 - val_loss: 1.1605 - val_accuracy: 0.6064\n","Epoch 100/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0793 - accuracy: 0.6977 - val_loss: 1.1742 - val_accuracy: 0.6033\n","{'loss': [1.7743313312530518, 1.763104796409607, 1.751857042312622, 1.7425135374069214, 1.7307136058807373, 1.720315933227539, 1.7081087827682495, 1.6993260383605957, 1.6894594430923462, 1.6783159971237183, 1.668827772140503, 1.6585021018981934, 1.6496285200119019, 1.639891266822815, 1.6306486129760742, 1.6211665868759155, 1.6139016151428223, 1.602424144744873, 1.5933027267456055, 1.5842738151550293, 1.5751482248306274, 1.5663529634475708, 1.5591213703155518, 1.5493688583374023, 1.5409759283065796, 1.5315684080123901, 1.524171233177185, 1.517369270324707, 1.5118417739868164, 1.5017966032028198, 1.4931913614273071, 1.487300157546997, 1.4756156206130981, 1.4685829877853394, 1.459985375404358, 1.4539735317230225, 1.4464226961135864, 1.4394207000732422, 1.4335522651672363, 1.4252973794937134, 1.4193544387817383, 1.4072315692901611, 1.4050681591033936, 1.3974051475524902, 1.3998384475708008, 1.383711576461792, 1.3761885166168213, 1.3696200847625732, 1.361214518547058, 1.355443000793457, 1.3475241661071777, 1.3423871994018555, 1.3343344926834106, 1.3286983966827393, 1.3217623233795166, 1.3140895366668701, 1.3113555908203125, 1.305395245552063, 1.2983769178390503, 1.289530873298645, 1.286019206047058, 1.2774814367294312, 1.2760999202728271, 1.2677626609802246, 1.2604115009307861, 1.2600414752960205, 1.249650239944458, 1.2434214353561401, 1.2379279136657715, 1.233803153038025, 1.2350572347640991, 1.2210402488708496, 1.2225618362426758, 1.2085589170455933, 1.2086306810379028, 1.200924277305603, 1.1938194036483765, 1.1871874332427979, 1.1868425607681274, 1.1776351928710938, 1.1701446771621704, 1.1716769933700562, 1.172685146331787, 1.1676020622253418, 1.1551100015640259, 1.1514159440994263, 1.156422734260559, 1.138017177581787, 1.134437918663025, 1.1280174255371094, 1.1203330755233765, 1.1205127239227295, 1.1196445226669312, 1.1107925176620483, 1.1041988134384155, 1.1055957078933716, 1.0942552089691162, 1.0885266065597534, 1.0867303609848022, 1.079300880432129], 'accuracy': [0.5085271596908569, 0.514987051486969, 0.5186046361923218, 0.5266149640083313, 0.5475451946258545, 0.5568475723266602, 0.5514211654663086, 0.5496124029159546, 0.5472868084907532, 0.569767415523529, 0.5682170391082764, 0.5664082765579224, 0.566149890422821, 0.5702842473983765, 0.5708010196685791, 0.5733850002288818, 0.564082682132721, 0.5826873183250427, 0.5770025849342346, 0.5829457640647888, 0.5881136655807495, 0.5901808738708496, 0.5671834349632263, 0.5842377543449402, 0.5917312502861023, 0.5888888835906982, 0.5904392600059509, 0.5909560918807983, 0.5852712988853455, 0.5976744294166565, 0.6033591628074646, 0.5922480821609497, 0.6064599752426147, 0.6105943322181702, 0.6103359460830688, 0.6020671725273132, 0.6077519655227661, 0.604651153087616, 0.6007751822471619, 0.6085271239280701, 0.604651153087616, 0.6180878281593323, 0.6105943322181702, 0.6124030947685242, 0.594315230846405, 0.6250646114349365, 0.6255813837051392, 0.6266149878501892, 0.6273902058601379, 0.6224806308746338, 0.6279069781303406, 0.6248062252998352, 0.632041335105896, 0.6390180587768555, 0.633074939250946, 0.6423772573471069, 0.6322997212409973, 0.6382429003715515, 0.6382429003715515, 0.6426356434822083, 0.6382429003715515, 0.6431524753570557, 0.6439276337623596, 0.6428940296173096, 0.6552971601486206, 0.6423772573471069, 0.6485788226127625, 0.6527131795883179, 0.654780387878418, 0.6485788226127625, 0.6361756920814514, 0.6552971601486206, 0.6470284461975098, 0.6682170629501343, 0.6555555462837219, 0.6560723781585693, 0.6643410921096802, 0.6705426573753357, 0.6607235074043274, 0.671576201915741, 0.6770026087760925, 0.6658914685249329, 0.6571059226989746, 0.658397912979126, 0.6772609949111938, 0.6661498546600342, 0.6516795754432678, 0.6751937866210938, 0.6803617477416992, 0.6826873421669006, 0.6847545504570007, 0.6832041144371033, 0.6723514199256897, 0.6870800852775574, 0.6904392838478088, 0.6705426573753357, 0.686821699142456, 0.6966408491134644, 0.6935400366783142, 0.6976743936538696], 'val_loss': [1.76902174949646, 1.7592406272888184, 1.7497137784957886, 1.7402063608169556, 1.7309248447418213, 1.7217187881469727, 1.7115622758865356, 1.7036969661712646, 1.6949175596237183, 1.6872385740280151, 1.6771610975265503, 1.6678820848464966, 1.6618250608444214, 1.649532675743103, 1.6464624404907227, 1.641332983970642, 1.6236053705215454, 1.6152491569519043, 1.603035569190979, 1.5964429378509521, 1.587982177734375, 1.5776962041854858, 1.5793213844299316, 1.560925841331482, 1.5539647340774536, 1.545620083808899, 1.5376019477844238, 1.5457308292388916, 1.5219359397888184, 1.5188316106796265, 1.50927734375, 1.5008392333984375, 1.4929771423339844, 1.486985683441162, 1.4802929162979126, 1.475647211074829, 1.4743828773498535, 1.4616531133651733, 1.4543606042861938, 1.454819917678833, 1.4370381832122803, 1.4607329368591309, 1.4259787797927856, 1.4286634922027588, 1.4105018377304077, 1.4119154214859009, 1.3990235328674316, 1.3933161497116089, 1.3888591527938843, 1.3800785541534424, 1.3739662170410156, 1.3679819107055664, 1.3622663021087646, 1.3563166856765747, 1.3502445220947266, 1.349560022354126, 1.3386118412017822, 1.3456015586853027, 1.3279588222503662, 1.3225075006484985, 1.3192071914672852, 1.3146551847457886, 1.3094924688339233, 1.3010092973709106, 1.2965965270996094, 1.3011717796325684, 1.2864702939987183, 1.2828834056854248, 1.2778630256652832, 1.2758746147155762, 1.268458604812622, 1.2740918397903442, 1.2581459283828735, 1.2526934146881104, 1.248631477355957, 1.2435991764068604, 1.2397273778915405, 1.2366418838500977, 1.2338212728500366, 1.2270828485488892, 1.2228363752365112, 1.2300914525985718, 1.229144811630249, 1.2111035585403442, 1.218881368637085, 1.2415318489074707, 1.1991040706634521, 1.2000492811203003, 1.1922739744186401, 1.1900265216827393, 1.1850467920303345, 1.1828958988189697, 1.2002195119857788, 1.1808512210845947, 1.1741071939468384, 1.1733949184417725, 1.1652214527130127, 1.1687591075897217, 1.1604630947113037, 1.174249291419983], 'val_accuracy': [0.5154958963394165, 0.5185950398445129, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.5351239442825317, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.4845041334629059, 0.48553720116615295, 0.4917355477809906, 0.4845041334629059, 0.48553720116615295, 0.5206611752510071, 0.5237603187561035, 0.5526859760284424, 0.5330578684806824, 0.53925621509552, 0.5495867729187012, 0.5165289044380188, 0.5464876294136047, 0.5516529083251953, 0.5599173307418823, 0.5681818127632141, 0.5216942429542542, 0.5516529083251953, 0.5526859760284424, 0.5650826692581177, 0.5526859760284424, 0.5495867729187012, 0.5733470916748047, 0.5526859760284424, 0.567148745059967, 0.55888432264328, 0.5681818127632141, 0.5640496015548706, 0.5557851195335388, 0.5826446413993835, 0.538223147392273, 0.5950413346290588, 0.5630165338516235, 0.577479362487793, 0.5712810158729553, 0.6033057570457458, 0.6043388247489929, 0.586776852607727, 0.5847107172012329, 0.5981404781341553, 0.60537189245224, 0.5898760557174683, 0.5888429880142212, 0.6012396812438965, 0.5940082669258118, 0.6022727489471436, 0.5650826692581177, 0.5981404781341553, 0.6012396812438965, 0.5743801593780518, 0.5681818127632141, 0.5754132270812988, 0.6012396812438965, 0.6033057570457458, 0.58574378490448, 0.60537189245224, 0.5816115736961365, 0.6043388247489929, 0.6084710955619812, 0.5826446413993835, 0.5795454382896423, 0.6074380278587341, 0.6033057570457458, 0.6002066135406494, 0.6043388247489929, 0.6012396812438965, 0.6126033067703247, 0.6074380278587341, 0.6095041036605835, 0.6043388247489929, 0.5836777091026306, 0.58574378490448, 0.5940082669258118, 0.5888429880142212, 0.5640496015548706, 0.5981404781341553, 0.5929751992225647, 0.6115702390670776, 0.6136363744735718, 0.6012396812438965, 0.6012396812438965, 0.5816115736961365, 0.6115702390670776, 0.6064049601554871, 0.5950413346290588, 0.6084710955619812, 0.6074380278587341, 0.6064049601554871, 0.6033057570457458]}\n","32/32 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 28ms/step - loss: 1.1426 - accuracy: 0.6401 - val_loss: 1.2061 - val_accuracy: 0.4849\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 1.1332 - accuracy: 0.6016"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 12ms/step - loss: 1.1296 - accuracy: 0.6611 - val_loss: 1.2015 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1217 - accuracy: 0.6619 - val_loss: 1.1976 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.1186 - accuracy: 0.6554 - val_loss: 1.1934 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1102 - accuracy: 0.6638 - val_loss: 1.1877 - val_accuracy: 0.4860\n","Epoch 6/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1029 - accuracy: 0.6703 - val_loss: 1.1844 - val_accuracy: 0.4860\n","Epoch 7/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0985 - accuracy: 0.6673 - val_loss: 1.1794 - val_accuracy: 0.4892\n","Epoch 8/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0934 - accuracy: 0.6721 - val_loss: 1.1767 - val_accuracy: 0.4881\n","Epoch 9/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.0872 - accuracy: 0.6735 - val_loss: 1.1733 - val_accuracy: 0.4903\n","Epoch 10/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0846 - accuracy: 0.6743 - val_loss: 1.1639 - val_accuracy: 0.5194\n","Epoch 11/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0763 - accuracy: 0.6821 - val_loss: 1.1641 - val_accuracy: 0.4968\n","Epoch 12/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0706 - accuracy: 0.6778 - val_loss: 1.1526 - val_accuracy: 0.5539\n","Epoch 13/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.0689 - accuracy: 0.6775 - val_loss: 1.1448 - val_accuracy: 0.5668\n","Epoch 14/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.0632 - accuracy: 0.6837 - val_loss: 1.1374 - val_accuracy: 0.5841\n","Epoch 15/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0612 - accuracy: 0.6840 - val_loss: 1.1345 - val_accuracy: 0.5744\n","Epoch 16/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0641 - accuracy: 0.6719 - val_loss: 1.1222 - val_accuracy: 0.5948\n","Epoch 17/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.0485 - accuracy: 0.6835 - val_loss: 1.1162 - val_accuracy: 0.6024\n","Epoch 18/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0462 - accuracy: 0.6859 - val_loss: 1.1173 - val_accuracy: 0.5797\n","Epoch 19/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0378 - accuracy: 0.6953 - val_loss: 1.1028 - val_accuracy: 0.6067\n","Epoch 20/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0366 - accuracy: 0.6897 - val_loss: 1.0985 - val_accuracy: 0.6121\n","Epoch 21/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0306 - accuracy: 0.6940 - val_loss: 1.0995 - val_accuracy: 0.5959\n","Epoch 22/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0279 - accuracy: 0.6883 - val_loss: 1.0923 - val_accuracy: 0.6185\n","Epoch 23/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0263 - accuracy: 0.6827 - val_loss: 1.1004 - val_accuracy: 0.5647\n","Epoch 24/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0210 - accuracy: 0.6899 - val_loss: 1.0762 - val_accuracy: 0.6250\n","Epoch 25/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0156 - accuracy: 0.6959 - val_loss: 1.0786 - val_accuracy: 0.6142\n","Epoch 26/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0082 - accuracy: 0.6991 - val_loss: 1.0694 - val_accuracy: 0.6261\n","Epoch 27/100\n","29/29 [==============================] - 0s 10ms/step - loss: 1.0069 - accuracy: 0.6980 - val_loss: 1.0661 - val_accuracy: 0.6261\n","Epoch 28/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0035 - accuracy: 0.6948 - val_loss: 1.0641 - val_accuracy: 0.6347\n","Epoch 29/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9991 - accuracy: 0.7010 - val_loss: 1.0614 - val_accuracy: 0.6239\n","Epoch 30/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9935 - accuracy: 0.7018 - val_loss: 1.0583 - val_accuracy: 0.6358\n","Epoch 31/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9928 - accuracy: 0.7010 - val_loss: 1.0556 - val_accuracy: 0.6347\n","Epoch 32/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9862 - accuracy: 0.7074 - val_loss: 1.0614 - val_accuracy: 0.6282\n","Epoch 33/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9869 - accuracy: 0.7031 - val_loss: 1.0520 - val_accuracy: 0.6250\n","Epoch 34/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9791 - accuracy: 0.7093 - val_loss: 1.0535 - val_accuracy: 0.6293\n","Epoch 35/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9711 - accuracy: 0.7107 - val_loss: 1.0489 - val_accuracy: 0.6272\n","Epoch 36/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9724 - accuracy: 0.7117 - val_loss: 1.0464 - val_accuracy: 0.6315\n","Epoch 37/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9729 - accuracy: 0.7007 - val_loss: 1.0592 - val_accuracy: 0.6013\n","Epoch 38/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9632 - accuracy: 0.7134 - val_loss: 1.0443 - val_accuracy: 0.6325\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9625 - accuracy: 0.7150 - val_loss: 1.0434 - val_accuracy: 0.6293\n","Epoch 40/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9636 - accuracy: 0.7047 - val_loss: 1.0705 - val_accuracy: 0.6250\n","Epoch 41/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9644 - accuracy: 0.7039 - val_loss: 1.0387 - val_accuracy: 0.6315\n","Epoch 42/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.9529 - accuracy: 0.7131 - val_loss: 1.0395 - val_accuracy: 0.6261\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9443 - accuracy: 0.7239 - val_loss: 1.0341 - val_accuracy: 0.6336\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9418 - accuracy: 0.7260 - val_loss: 1.0315 - val_accuracy: 0.6401\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9424 - accuracy: 0.7155 - val_loss: 1.0406 - val_accuracy: 0.6121\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9364 - accuracy: 0.7196 - val_loss: 1.0304 - val_accuracy: 0.6315\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9282 - accuracy: 0.7287 - val_loss: 1.0284 - val_accuracy: 0.6175\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9290 - accuracy: 0.7301 - val_loss: 1.0249 - val_accuracy: 0.6401\n","Epoch 49/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9235 - accuracy: 0.7287 - val_loss: 1.0247 - val_accuracy: 0.6347\n","Epoch 50/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9220 - accuracy: 0.7298 - val_loss: 1.0267 - val_accuracy: 0.6239\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9160 - accuracy: 0.7373 - val_loss: 1.0219 - val_accuracy: 0.6272\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9140 - accuracy: 0.7381 - val_loss: 1.0233 - val_accuracy: 0.6239\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9085 - accuracy: 0.7379 - val_loss: 1.0375 - val_accuracy: 0.6013\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9061 - accuracy: 0.7411 - val_loss: 1.0212 - val_accuracy: 0.6293\n","Epoch 55/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9007 - accuracy: 0.7419 - val_loss: 1.0230 - val_accuracy: 0.6282\n","Epoch 56/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.9074 - accuracy: 0.7284 - val_loss: 1.0271 - val_accuracy: 0.6078\n","Epoch 57/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8951 - accuracy: 0.7430 - val_loss: 1.0153 - val_accuracy: 0.6347\n","Epoch 58/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8900 - accuracy: 0.7495 - val_loss: 1.0145 - val_accuracy: 0.6250\n","Epoch 59/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8944 - accuracy: 0.7398 - val_loss: 1.0122 - val_accuracy: 0.6379\n","Epoch 60/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8860 - accuracy: 0.7489 - val_loss: 1.0159 - val_accuracy: 0.6185\n","Epoch 61/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8810 - accuracy: 0.7532 - val_loss: 1.0106 - val_accuracy: 0.6390\n","Epoch 62/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.8842 - accuracy: 0.7384 - val_loss: 1.0171 - val_accuracy: 0.6250\n","Epoch 63/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8722 - accuracy: 0.7522 - val_loss: 1.0105 - val_accuracy: 0.6261\n","Epoch 64/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8711 - accuracy: 0.7548 - val_loss: 1.0105 - val_accuracy: 0.6250\n","Epoch 65/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8648 - accuracy: 0.7616 - val_loss: 1.0091 - val_accuracy: 0.6228\n","Epoch 66/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8633 - accuracy: 0.7624 - val_loss: 1.0059 - val_accuracy: 0.6336\n","Epoch 67/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8591 - accuracy: 0.7621 - val_loss: 1.0440 - val_accuracy: 0.5948\n","Epoch 68/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8586 - accuracy: 0.7619 - val_loss: 1.0048 - val_accuracy: 0.6347\n","Epoch 69/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8515 - accuracy: 0.7635 - val_loss: 1.0090 - val_accuracy: 0.6336\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8517 - accuracy: 0.7621 - val_loss: 1.0098 - val_accuracy: 0.6228\n","Epoch 71/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8548 - accuracy: 0.7548 - val_loss: 1.0201 - val_accuracy: 0.6131\n","Epoch 72/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8508 - accuracy: 0.7565 - val_loss: 1.0035 - val_accuracy: 0.6336\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8525 - accuracy: 0.7495 - val_loss: 1.0123 - val_accuracy: 0.6175\n","Epoch 74/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8379 - accuracy: 0.7672 - val_loss: 1.0011 - val_accuracy: 0.6325\n","Epoch 75/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8297 - accuracy: 0.7724 - val_loss: 1.0110 - val_accuracy: 0.6153\n","Epoch 76/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8273 - accuracy: 0.7732 - val_loss: 0.9991 - val_accuracy: 0.6325\n","Epoch 77/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8302 - accuracy: 0.7683 - val_loss: 1.0099 - val_accuracy: 0.6164\n","Epoch 78/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8417 - accuracy: 0.7513 - val_loss: 0.9996 - val_accuracy: 0.6336\n","Epoch 79/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8211 - accuracy: 0.7764 - val_loss: 0.9968 - val_accuracy: 0.6325\n","Epoch 80/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8201 - accuracy: 0.7748 - val_loss: 1.0013 - val_accuracy: 0.6315\n","Epoch 81/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8248 - accuracy: 0.7616 - val_loss: 1.0263 - val_accuracy: 0.6067\n","Epoch 82/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8196 - accuracy: 0.7702 - val_loss: 1.0226 - val_accuracy: 0.6056\n","Epoch 83/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8080 - accuracy: 0.7877 - val_loss: 0.9977 - val_accuracy: 0.6315\n","Epoch 84/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8093 - accuracy: 0.7769 - val_loss: 0.9976 - val_accuracy: 0.6325\n","Epoch 85/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8102 - accuracy: 0.7799 - val_loss: 0.9983 - val_accuracy: 0.6282\n","Epoch 86/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.8188 - accuracy: 0.7670 - val_loss: 1.0255 - val_accuracy: 0.6045\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8020 - accuracy: 0.7761 - val_loss: 0.9986 - val_accuracy: 0.6218\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7896 - accuracy: 0.7934 - val_loss: 1.0132 - val_accuracy: 0.6164\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7969 - accuracy: 0.7821 - val_loss: 1.0019 - val_accuracy: 0.6282\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7841 - accuracy: 0.7963 - val_loss: 0.9970 - val_accuracy: 0.6315\n","Epoch 91/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7976 - accuracy: 0.7710 - val_loss: 1.0302 - val_accuracy: 0.6045\n","Epoch 92/100\n","29/29 [==============================] - 2s 54ms/step - loss: 0.7825 - accuracy: 0.7963 - val_loss: 0.9952 - val_accuracy: 0.6412\n","Epoch 93/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7756 - accuracy: 0.7980 - val_loss: 0.9950 - val_accuracy: 0.6412\n","Epoch 94/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7730 - accuracy: 0.7945 - val_loss: 0.9942 - val_accuracy: 0.6401\n","Epoch 95/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7710 - accuracy: 0.7980 - val_loss: 0.9987 - val_accuracy: 0.6272\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7662 - accuracy: 0.8017 - val_loss: 0.9952 - val_accuracy: 0.6433\n","Epoch 97/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7651 - accuracy: 0.8028 - val_loss: 0.9943 - val_accuracy: 0.6401\n","Epoch 98/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7582 - accuracy: 0.8106 - val_loss: 1.0552 - val_accuracy: 0.6024\n","Epoch 99/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7610 - accuracy: 0.8001 - val_loss: 0.9993 - val_accuracy: 0.6207\n","Epoch 100/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7541 - accuracy: 0.8098 - val_loss: 0.9963 - val_accuracy: 0.6412\n","{'loss': [1.1425588130950928, 1.129586100578308, 1.121741771697998, 1.1186381578445435, 1.1101984977722168, 1.1028915643692017, 1.098525881767273, 1.0933598279953003, 1.0872488021850586, 1.0845773220062256, 1.0762529373168945, 1.0706114768981934, 1.0689361095428467, 1.0632150173187256, 1.0611835718154907, 1.0640878677368164, 1.048538327217102, 1.0462496280670166, 1.0378280878067017, 1.0366486310958862, 1.030596137046814, 1.0278983116149902, 1.0262811183929443, 1.0210407972335815, 1.015617847442627, 1.0081593990325928, 1.0068511962890625, 1.003528356552124, 0.9990946650505066, 0.9934533834457397, 0.9927521347999573, 0.9862359762191772, 0.9869142174720764, 0.9790539145469666, 0.9711121916770935, 0.9724215269088745, 0.9729041457176208, 0.9632239937782288, 0.962497353553772, 0.9635964035987854, 0.9644160866737366, 0.9528896808624268, 0.9442813992500305, 0.9417840838432312, 0.9423925280570984, 0.9363676905632019, 0.9281597137451172, 0.9290370941162109, 0.9234726428985596, 0.9219514727592468, 0.9159653782844543, 0.9140247106552124, 0.9084771275520325, 0.9060849547386169, 0.9006831645965576, 0.9073623418807983, 0.895088791847229, 0.889960765838623, 0.894372284412384, 0.8860431909561157, 0.8810476660728455, 0.8842253088951111, 0.8721514940261841, 0.8711053729057312, 0.8647760152816772, 0.8633113503456116, 0.8590894341468811, 0.8586192727088928, 0.8514692783355713, 0.8517155647277832, 0.8547617793083191, 0.8507829308509827, 0.8524571657180786, 0.8378886580467224, 0.8297420740127563, 0.8273224830627441, 0.830195963382721, 0.8417484164237976, 0.8210974335670471, 0.8200627565383911, 0.8247939944267273, 0.8196464776992798, 0.8079949021339417, 0.8092967867851257, 0.8101863861083984, 0.818756639957428, 0.8020299673080444, 0.7895541787147522, 0.7968729138374329, 0.7840940356254578, 0.7975745797157288, 0.7824815511703491, 0.7756485342979431, 0.7730287909507751, 0.7709515690803528, 0.7662080526351929, 0.7650983929634094, 0.7581660747528076, 0.7609520554542542, 0.7541077136993408], 'accuracy': [0.6400862336158752, 0.6610991358757019, 0.6619073152542114, 0.6554418206214905, 0.6637930870056152, 0.670258641242981, 0.6672952771186829, 0.6721444129943848, 0.673491358757019, 0.6742995977401733, 0.6821120977401733, 0.6778017282485962, 0.6775323152542114, 0.6837284564971924, 0.6839978694915771, 0.671875, 0.6834590435028076, 0.685883641242981, 0.6953125, 0.6896551847457886, 0.693965494632721, 0.6883081793785095, 0.6826508641242981, 0.6899245977401733, 0.6958512663841248, 0.6990840435028076, 0.6980064511299133, 0.6947737336158752, 0.7009698152542114, 0.701777994632721, 0.7009698152542114, 0.7074353694915771, 0.703125, 0.709321141242981, 0.7106680870056152, 0.7117456793785095, 0.7007004022598267, 0.7133620977401733, 0.7149784564971924, 0.704741358757019, 0.7039331793785095, 0.7130926847457886, 0.7238685488700867, 0.7260237336158752, 0.7155172228813171, 0.7195581793785095, 0.7287176847457886, 0.7300646305084229, 0.7287176847457886, 0.7297952771186829, 0.7373383641242981, 0.7381465435028076, 0.7378771305084229, 0.7411099076271057, 0.7419180870056152, 0.7284482717514038, 0.7429956793785095, 0.7494612336158752, 0.7397629022598267, 0.7489224076271057, 0.7532327771186829, 0.7384159564971924, 0.7521551847457886, 0.7548491358757019, 0.7615840435028076, 0.7623922228813171, 0.7621228694915771, 0.7618534564971924, 0.7634698152542114, 0.7621228694915771, 0.7548491358757019, 0.756465494632721, 0.7494612336158752, 0.767241358757019, 0.7723599076271057, 0.7731680870056152, 0.7683189511299133, 0.751347005367279, 0.7764008641242981, 0.774784505367279, 0.7615840435028076, 0.7702047228813171, 0.787715494632721, 0.7769396305084229, 0.779902994632721, 0.766972005367279, 0.7761314511299133, 0.7933728694915771, 0.7820581793785095, 0.7963362336158752, 0.7710129022598267, 0.7963362336158752, 0.7979525923728943, 0.7944504022598267, 0.7979525923728943, 0.8017241358757019, 0.8028017282485962, 0.8106142282485962, 0.8001077771186829, 0.8098060488700867], 'val_loss': [1.206055998802185, 1.2014539241790771, 1.1975915431976318, 1.1933965682983398, 1.1877028942108154, 1.1843680143356323, 1.1793514490127563, 1.1767460107803345, 1.1733094453811646, 1.1639153957366943, 1.1640650033950806, 1.1525570154190063, 1.1448159217834473, 1.1374320983886719, 1.1345397233963013, 1.1222445964813232, 1.1162030696868896, 1.1172646284103394, 1.1028242111206055, 1.0984768867492676, 1.0994982719421387, 1.0922815799713135, 1.1003633737564087, 1.0761988162994385, 1.078647255897522, 1.0693514347076416, 1.0660905838012695, 1.0640723705291748, 1.0613971948623657, 1.0583115816116333, 1.05564546585083, 1.061378836631775, 1.0519806146621704, 1.053526520729065, 1.04892897605896, 1.0464123487472534, 1.0591922998428345, 1.0443317890167236, 1.0434317588806152, 1.0705385208129883, 1.0387496948242188, 1.039525032043457, 1.0340783596038818, 1.0315006971359253, 1.0405919551849365, 1.030414342880249, 1.0284274816513062, 1.0249117612838745, 1.0247238874435425, 1.026708960533142, 1.0218894481658936, 1.0233012437820435, 1.0374830961227417, 1.0211793184280396, 1.0230153799057007, 1.0271433591842651, 1.0153417587280273, 1.0144706964492798, 1.0122380256652832, 1.015859842300415, 1.0105655193328857, 1.017107367515564, 1.0104886293411255, 1.0105422735214233, 1.0091407299041748, 1.0058802366256714, 1.0440421104431152, 1.0048418045043945, 1.008982539176941, 1.0097670555114746, 1.0201019048690796, 1.0035182237625122, 1.0123215913772583, 1.0010993480682373, 1.0109987258911133, 0.9991316199302673, 1.0098516941070557, 0.9996337890625, 0.9967935681343079, 1.0013470649719238, 1.0262962579727173, 1.0226048231124878, 0.9976844191551208, 0.9975858926773071, 0.9983304738998413, 1.025457739830017, 0.9985827803611755, 1.0132371187210083, 1.001910924911499, 0.996955394744873, 1.0302482843399048, 0.9951748847961426, 0.9950212240219116, 0.9942291378974915, 0.9986820816993713, 0.995173990726471, 0.9942943453788757, 1.0552176237106323, 0.9993191361427307, 0.9963317513465881], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.48599138855934143, 0.4892241358757019, 0.4881465435028076, 0.4903017282485962, 0.5193965435028076, 0.4967672526836395, 0.5538793206214905, 0.5668103694915771, 0.5840517282485962, 0.5743534564971924, 0.5948275923728943, 0.6023706793785095, 0.579741358757019, 0.6066810488700867, 0.6120689511299133, 0.5959051847457886, 0.618534505367279, 0.5646551847457886, 0.625, 0.6142241358757019, 0.6260775923728943, 0.6260775923728943, 0.6346982717514038, 0.6239224076271057, 0.6357758641242981, 0.6346982717514038, 0.6282327771186829, 0.625, 0.6293103694915771, 0.6271551847457886, 0.631465494632721, 0.6012930870056152, 0.6325430870056152, 0.6293103694915771, 0.625, 0.631465494632721, 0.6260775923728943, 0.6336206793785095, 0.6400862336158752, 0.6120689511299133, 0.631465494632721, 0.6174569129943848, 0.6400862336158752, 0.6346982717514038, 0.6239224076271057, 0.6271551847457886, 0.6239224076271057, 0.6012930870056152, 0.6293103694915771, 0.6282327771186829, 0.607758641242981, 0.6346982717514038, 0.625, 0.6379310488700867, 0.618534505367279, 0.639008641242981, 0.625, 0.6260775923728943, 0.625, 0.6228448152542114, 0.6336206793785095, 0.5948275923728943, 0.6346982717514038, 0.6336206793785095, 0.6228448152542114, 0.6131465435028076, 0.6336206793785095, 0.6174569129943848, 0.6325430870056152, 0.6153017282485962, 0.6325430870056152, 0.6163793206214905, 0.6336206793785095, 0.6325430870056152, 0.631465494632721, 0.6066810488700867, 0.6056034564971924, 0.631465494632721, 0.6325430870056152, 0.6282327771186829, 0.6045258641242981, 0.6217672228813171, 0.6163793206214905, 0.6282327771186829, 0.631465494632721, 0.6045258641242981, 0.6411637663841248, 0.6411637663841248, 0.6400862336158752, 0.6271551847457886, 0.6433189511299133, 0.6400862336158752, 0.6023706793785095, 0.6206896305084229, 0.6411637663841248]}\n","38/38 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 30ms/step - loss: 1.1453 - accuracy: 0.6395 - val_loss: 1.2049 - val_accuracy: 0.4955\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 1.1567 - accuracy: 0.6016"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 12ms/step - loss: 1.1326 - accuracy: 0.6522 - val_loss: 1.2016 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1267 - accuracy: 0.6638 - val_loss: 1.1974 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1220 - accuracy: 0.6616 - val_loss: 1.1925 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1126 - accuracy: 0.6723 - val_loss: 1.1892 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.1078 - accuracy: 0.6729 - val_loss: 1.1848 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1006 - accuracy: 0.6771 - val_loss: 1.1786 - val_accuracy: 0.4966\n","Epoch 8/100\n","28/28 [==============================] - 1s 17ms/step - loss: 1.0992 - accuracy: 0.6678 - val_loss: 1.1773 - val_accuracy: 0.4955\n","Epoch 9/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1001 - accuracy: 0.6587 - val_loss: 1.1735 - val_accuracy: 0.4955\n","Epoch 10/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.0854 - accuracy: 0.6882 - val_loss: 1.1651 - val_accuracy: 0.5068\n","Epoch 11/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0864 - accuracy: 0.6712 - val_loss: 1.1695 - val_accuracy: 0.4966\n","Epoch 12/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0808 - accuracy: 0.6831 - val_loss: 1.1746 - val_accuracy: 0.4955\n","Epoch 13/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.0825 - accuracy: 0.6653 - val_loss: 1.1529 - val_accuracy: 0.5204\n","Epoch 14/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0678 - accuracy: 0.6924 - val_loss: 1.1585 - val_accuracy: 0.4989\n","Epoch 15/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.0661 - accuracy: 0.6859 - val_loss: 1.1456 - val_accuracy: 0.5271\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0603 - accuracy: 0.6924 - val_loss: 1.1314 - val_accuracy: 0.5724\n","Epoch 17/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0554 - accuracy: 0.6927 - val_loss: 1.1220 - val_accuracy: 0.5882\n","Epoch 18/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0504 - accuracy: 0.6930 - val_loss: 1.1197 - val_accuracy: 0.5781\n","Epoch 19/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0470 - accuracy: 0.6969 - val_loss: 1.1167 - val_accuracy: 0.5735\n","Epoch 20/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0458 - accuracy: 0.6876 - val_loss: 1.0986 - val_accuracy: 0.6244\n","Epoch 21/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.0448 - accuracy: 0.6834 - val_loss: 1.0913 - val_accuracy: 0.6312\n","Epoch 22/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0339 - accuracy: 0.7001 - val_loss: 1.0865 - val_accuracy: 0.6233\n","Epoch 23/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.0322 - accuracy: 0.6865 - val_loss: 1.0789 - val_accuracy: 0.6448\n","Epoch 24/100\n","28/28 [==============================] - 0s 10ms/step - loss: 1.0302 - accuracy: 0.6916 - val_loss: 1.0807 - val_accuracy: 0.6188\n","Epoch 25/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.0216 - accuracy: 0.6986 - val_loss: 1.0691 - val_accuracy: 0.6471\n","Epoch 26/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0220 - accuracy: 0.6967 - val_loss: 1.0675 - val_accuracy: 0.6437\n","Epoch 27/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0135 - accuracy: 0.7088 - val_loss: 1.0604 - val_accuracy: 0.6516\n","Epoch 28/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0091 - accuracy: 0.7094 - val_loss: 1.0614 - val_accuracy: 0.6346\n","Epoch 29/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0113 - accuracy: 0.7020 - val_loss: 1.0602 - val_accuracy: 0.6312\n","Epoch 30/100\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0048 - accuracy: 0.7040 - val_loss: 1.0522 - val_accuracy: 0.6516\n","Epoch 31/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9975 - accuracy: 0.7156 - val_loss: 1.0488 - val_accuracy: 0.6505\n","Epoch 32/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9927 - accuracy: 0.7193 - val_loss: 1.0519 - val_accuracy: 0.6572\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9989 - accuracy: 0.6969 - val_loss: 1.0846 - val_accuracy: 0.5871\n","Epoch 34/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9919 - accuracy: 0.7066 - val_loss: 1.0433 - val_accuracy: 0.6527\n","Epoch 35/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9890 - accuracy: 0.7018 - val_loss: 1.0396 - val_accuracy: 0.6493\n","Epoch 36/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9871 - accuracy: 0.7006 - val_loss: 1.0495 - val_accuracy: 0.6493\n","Epoch 37/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9889 - accuracy: 0.6933 - val_loss: 1.0429 - val_accuracy: 0.6290\n","Epoch 38/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9721 - accuracy: 0.7235 - val_loss: 1.0335 - val_accuracy: 0.6493\n","Epoch 39/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9712 - accuracy: 0.7139 - val_loss: 1.0366 - val_accuracy: 0.6199\n","Epoch 40/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9670 - accuracy: 0.7216 - val_loss: 1.0300 - val_accuracy: 0.6527\n","Epoch 41/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9704 - accuracy: 0.7108 - val_loss: 1.0268 - val_accuracy: 0.6482\n","Epoch 42/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9580 - accuracy: 0.7269 - val_loss: 1.0276 - val_accuracy: 0.6312\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9573 - accuracy: 0.7278 - val_loss: 1.0315 - val_accuracy: 0.6527\n","Epoch 44/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9586 - accuracy: 0.7156 - val_loss: 1.0474 - val_accuracy: 0.6041\n","Epoch 45/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9508 - accuracy: 0.7235 - val_loss: 1.0189 - val_accuracy: 0.6561\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9464 - accuracy: 0.7292 - val_loss: 1.0239 - val_accuracy: 0.6278\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9397 - accuracy: 0.7329 - val_loss: 1.0174 - val_accuracy: 0.6425\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9371 - accuracy: 0.7329 - val_loss: 1.0187 - val_accuracy: 0.6369\n","Epoch 49/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9437 - accuracy: 0.7218 - val_loss: 1.0187 - val_accuracy: 0.6572\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9326 - accuracy: 0.7247 - val_loss: 1.0129 - val_accuracy: 0.6448\n","Epoch 51/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9291 - accuracy: 0.7357 - val_loss: 1.0098 - val_accuracy: 0.6437\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9263 - accuracy: 0.7346 - val_loss: 1.0108 - val_accuracy: 0.6561\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9320 - accuracy: 0.7218 - val_loss: 1.0200 - val_accuracy: 0.6482\n","Epoch 54/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9190 - accuracy: 0.7354 - val_loss: 1.0184 - val_accuracy: 0.6256\n","Epoch 55/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9197 - accuracy: 0.7323 - val_loss: 1.0094 - val_accuracy: 0.6335\n","Epoch 56/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9154 - accuracy: 0.7284 - val_loss: 1.0041 - val_accuracy: 0.6437\n","Epoch 57/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9085 - accuracy: 0.7411 - val_loss: 1.0124 - val_accuracy: 0.6301\n","Epoch 58/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.9024 - accuracy: 0.7484 - val_loss: 1.0001 - val_accuracy: 0.6448\n","Epoch 59/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9051 - accuracy: 0.7394 - val_loss: 1.0232 - val_accuracy: 0.6143\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9117 - accuracy: 0.7230 - val_loss: 0.9952 - val_accuracy: 0.6448\n","Epoch 61/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9084 - accuracy: 0.7255 - val_loss: 1.0102 - val_accuracy: 0.6505\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8917 - accuracy: 0.7490 - val_loss: 1.0087 - val_accuracy: 0.6527\n","Epoch 63/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8909 - accuracy: 0.7422 - val_loss: 1.0089 - val_accuracy: 0.6188\n","Epoch 64/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8880 - accuracy: 0.7428 - val_loss: 0.9939 - val_accuracy: 0.6459\n","Epoch 65/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8831 - accuracy: 0.7524 - val_loss: 0.9945 - val_accuracy: 0.6448\n","Epoch 66/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8800 - accuracy: 0.7555 - val_loss: 0.9918 - val_accuracy: 0.6369\n","Epoch 67/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8896 - accuracy: 0.7360 - val_loss: 0.9903 - val_accuracy: 0.6459\n","Epoch 68/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8795 - accuracy: 0.7501 - val_loss: 0.9913 - val_accuracy: 0.6425\n","Epoch 69/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8738 - accuracy: 0.7575 - val_loss: 0.9916 - val_accuracy: 0.6369\n","Epoch 70/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8648 - accuracy: 0.7629 - val_loss: 0.9879 - val_accuracy: 0.6403\n","Epoch 71/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8633 - accuracy: 0.7578 - val_loss: 0.9864 - val_accuracy: 0.6346\n","Epoch 72/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8609 - accuracy: 0.7632 - val_loss: 0.9903 - val_accuracy: 0.6425\n","Epoch 73/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8611 - accuracy: 0.7578 - val_loss: 0.9863 - val_accuracy: 0.6369\n","Epoch 74/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8529 - accuracy: 0.7683 - val_loss: 1.0000 - val_accuracy: 0.6188\n","Epoch 75/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8553 - accuracy: 0.7555 - val_loss: 1.0171 - val_accuracy: 0.6041\n","Epoch 76/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8572 - accuracy: 0.7518 - val_loss: 0.9980 - val_accuracy: 0.6222\n","Epoch 77/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8555 - accuracy: 0.7530 - val_loss: 0.9818 - val_accuracy: 0.6357\n","Epoch 78/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8453 - accuracy: 0.7671 - val_loss: 0.9801 - val_accuracy: 0.6369\n","Epoch 79/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8382 - accuracy: 0.7705 - val_loss: 0.9816 - val_accuracy: 0.6301\n","Epoch 80/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8371 - accuracy: 0.7719 - val_loss: 0.9783 - val_accuracy: 0.6278\n","Epoch 81/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8331 - accuracy: 0.7677 - val_loss: 0.9807 - val_accuracy: 0.6357\n","Epoch 82/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8288 - accuracy: 0.7779 - val_loss: 0.9843 - val_accuracy: 0.6403\n","Epoch 83/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8256 - accuracy: 0.7699 - val_loss: 0.9791 - val_accuracy: 0.6301\n","Epoch 84/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8215 - accuracy: 0.7765 - val_loss: 0.9888 - val_accuracy: 0.6312\n","Epoch 85/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8238 - accuracy: 0.7702 - val_loss: 0.9820 - val_accuracy: 0.6414\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8268 - accuracy: 0.7671 - val_loss: 0.9759 - val_accuracy: 0.6256\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8121 - accuracy: 0.7776 - val_loss: 0.9793 - val_accuracy: 0.6256\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8100 - accuracy: 0.7827 - val_loss: 0.9819 - val_accuracy: 0.6267\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8043 - accuracy: 0.7864 - val_loss: 0.9851 - val_accuracy: 0.6267\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8001 - accuracy: 0.7909 - val_loss: 0.9774 - val_accuracy: 0.6312\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8028 - accuracy: 0.7881 - val_loss: 0.9882 - val_accuracy: 0.6324\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7954 - accuracy: 0.7957 - val_loss: 0.9778 - val_accuracy: 0.6335\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8028 - accuracy: 0.7810 - val_loss: 0.9877 - val_accuracy: 0.6244\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7946 - accuracy: 0.7847 - val_loss: 0.9787 - val_accuracy: 0.6244\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7957 - accuracy: 0.7869 - val_loss: 0.9855 - val_accuracy: 0.6222\n","Epoch 96/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8005 - accuracy: 0.7787 - val_loss: 0.9787 - val_accuracy: 0.6369\n","Epoch 97/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7842 - accuracy: 0.7985 - val_loss: 0.9821 - val_accuracy: 0.6256\n","Epoch 98/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7843 - accuracy: 0.7960 - val_loss: 0.9799 - val_accuracy: 0.6244\n","Epoch 99/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7836 - accuracy: 0.7855 - val_loss: 0.9763 - val_accuracy: 0.6335\n","Epoch 100/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7703 - accuracy: 0.8065 - val_loss: 0.9841 - val_accuracy: 0.6244\n","{'loss': [1.1453235149383545, 1.1326451301574707, 1.1266831159591675, 1.1220306158065796, 1.1126034259796143, 1.1078429222106934, 1.100579023361206, 1.0991657972335815, 1.1001096963882446, 1.0854320526123047, 1.0864195823669434, 1.0807888507843018, 1.0825409889221191, 1.0677865743637085, 1.066055417060852, 1.0602798461914062, 1.0554184913635254, 1.0503991842269897, 1.0469919443130493, 1.0458426475524902, 1.0447670221328735, 1.0338776111602783, 1.0322363376617432, 1.030185341835022, 1.0215851068496704, 1.0220409631729126, 1.0135300159454346, 1.0090863704681396, 1.0113236904144287, 1.0047591924667358, 0.99747633934021, 0.9926905035972595, 0.9989051222801208, 0.9918883442878723, 0.9889978766441345, 0.9870641827583313, 0.9888571500778198, 0.9721125364303589, 0.9712230563163757, 0.9670236706733704, 0.9704090356826782, 0.9580060839653015, 0.9572740197181702, 0.9585943222045898, 0.9507910013198853, 0.9464238286018372, 0.939717173576355, 0.9371472597122192, 0.9436652660369873, 0.9326384663581848, 0.9290827512741089, 0.9262792468070984, 0.9320070147514343, 0.9189555644989014, 0.9196789860725403, 0.9154173135757446, 0.9085320830345154, 0.9023511409759521, 0.9050997495651245, 0.9117000102996826, 0.908380389213562, 0.8917044401168823, 0.890906810760498, 0.8879924416542053, 0.8831294775009155, 0.8800387382507324, 0.8895800709724426, 0.8795207738876343, 0.8738188147544861, 0.8647751808166504, 0.8632985949516296, 0.860877513885498, 0.8610600829124451, 0.8529118299484253, 0.8553466200828552, 0.8572330474853516, 0.8554977774620056, 0.8452675342559814, 0.8381875157356262, 0.8370882272720337, 0.8331043124198914, 0.8287639021873474, 0.8256272673606873, 0.8214516639709473, 0.8237839937210083, 0.8268364071846008, 0.812083899974823, 0.8100187182426453, 0.8042580485343933, 0.8000668883323669, 0.802764892578125, 0.7954084277153015, 0.8027684092521667, 0.7945669293403625, 0.7957366704940796, 0.8004757761955261, 0.7841677069664001, 0.7842925786972046, 0.7836448550224304, 0.7702955007553101], 'accuracy': [0.6395019888877869, 0.6522354483604431, 0.6638370156288147, 0.6615732908248901, 0.6723259687423706, 0.6728919148445129, 0.6771363615989685, 0.6677985191345215, 0.6587436199188232, 0.6881720423698425, 0.6711941361427307, 0.6830786466598511, 0.6652518510818481, 0.6924165487289429, 0.685908317565918, 0.6924165487289429, 0.6926994919776917, 0.6929824352264404, 0.696943998336792, 0.6876060962677002, 0.6833616495132446, 0.7000566124916077, 0.6864742636680603, 0.691567599773407, 0.6986417770385742, 0.6966609954833984, 0.7088285088539124, 0.7093944549560547, 0.7020373344421387, 0.7040181159973145, 0.715619683265686, 0.719298243522644, 0.696943998336792, 0.7065647840499878, 0.7017543911933899, 0.7006224989891052, 0.693265438079834, 0.7235427498817444, 0.7139219045639038, 0.7215619683265686, 0.7108092904090881, 0.7269383072853088, 0.7277871966362, 0.715619683265686, 0.7235427498817444, 0.7292020320892334, 0.7328805923461914, 0.7328805923461914, 0.7218449115753174, 0.7246745824813843, 0.7357102632522583, 0.7345783710479736, 0.7218449115753174, 0.7354272603988647, 0.7323146462440491, 0.7283531427383423, 0.7410866022109985, 0.7484436631202698, 0.7393888235092163, 0.722976803779602, 0.7255234718322754, 0.7490096092224121, 0.7422184348106384, 0.7427843809127808, 0.7524052262306213, 0.755517840385437, 0.7359932065010071, 0.7501415014266968, 0.757498562335968, 0.7628749012947083, 0.7577815651893616, 0.7631579041481018, 0.7577815651893616, 0.7682512998580933, 0.755517840385437, 0.751839280128479, 0.7529711127281189, 0.7671194076538086, 0.7705150246620178, 0.7719298005104065, 0.7676853537559509, 0.7778720855712891, 0.7699490785598755, 0.7764572501182556, 0.7702320218086243, 0.7671194076538086, 0.7775891423225403, 0.7826825380325317, 0.786361038684845, 0.7908884882926941, 0.788058876991272, 0.7956989407539368, 0.7809846997261047, 0.7846632599830627, 0.7869269847869873, 0.7787209749221802, 0.7985285520553589, 0.7959818840026855, 0.7855121493339539, 0.8064516186714172], 'val_loss': [1.2048635482788086, 1.2015621662139893, 1.1973708868026733, 1.1925336122512817, 1.189154863357544, 1.1848310232162476, 1.1785705089569092, 1.177260398864746, 1.1735081672668457, 1.1650581359863281, 1.169498085975647, 1.174572229385376, 1.1529449224472046, 1.1585439443588257, 1.1455578804016113, 1.131449580192566, 1.122008204460144, 1.1197144985198975, 1.1166568994522095, 1.0986037254333496, 1.0913130044937134, 1.0865261554718018, 1.078903079032898, 1.080735206604004, 1.069100260734558, 1.0675435066223145, 1.0603721141815186, 1.0613702535629272, 1.0601894855499268, 1.0522230863571167, 1.0488452911376953, 1.0518792867660522, 1.0846298933029175, 1.0433392524719238, 1.0396008491516113, 1.049516201019287, 1.0428961515426636, 1.0334585905075073, 1.0365636348724365, 1.0300143957138062, 1.0267653465270996, 1.0276379585266113, 1.0314607620239258, 1.0473785400390625, 1.0189306735992432, 1.0239219665527344, 1.017383337020874, 1.0186758041381836, 1.0187309980392456, 1.0128519535064697, 1.0098228454589844, 1.0108290910720825, 1.019995927810669, 1.0184060335159302, 1.009355902671814, 1.0040926933288574, 1.0124117136001587, 1.0001153945922852, 1.023237705230713, 0.9952144026756287, 1.0102401971817017, 1.0087260007858276, 1.0089051723480225, 0.9939013123512268, 0.9945307374000549, 0.9918169975280762, 0.9902803301811218, 0.9912899136543274, 0.9915775656700134, 0.987878680229187, 0.9863824844360352, 0.9903289675712585, 0.9862518310546875, 0.9999687671661377, 1.0171000957489014, 0.998009443283081, 0.981755793094635, 0.9801268577575684, 0.9816482067108154, 0.9783021807670593, 0.9806578159332275, 0.984318733215332, 0.9791252613067627, 0.9887744188308716, 0.9820106625556946, 0.9759223461151123, 0.9793153405189514, 0.9818685054779053, 0.9851087927818298, 0.9774004220962524, 0.9882171154022217, 0.977777361869812, 0.9877467751502991, 0.9786761999130249, 0.9854681491851807, 0.9787316918373108, 0.982119619846344, 0.9799294471740723, 0.9762513041496277, 0.9840908646583557], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.4954751133918762, 0.4954751133918762, 0.5067873597145081, 0.49660632014274597, 0.4954751133918762, 0.5203620195388794, 0.49886876344680786, 0.5271493196487427, 0.5723981857299805, 0.5882353186607361, 0.5780543088912964, 0.5735294222831726, 0.6244344115257263, 0.6312217116355896, 0.6233031749725342, 0.6447963714599609, 0.6187782883644104, 0.6470588445663452, 0.6436651349067688, 0.651583731174469, 0.6346153616905212, 0.6312217116355896, 0.651583731174469, 0.6504524946212769, 0.6572397947311401, 0.587104082107544, 0.6527149081230164, 0.6493212580680847, 0.6493212580680847, 0.6289592981338501, 0.6493212580680847, 0.6199095249176025, 0.6527149081230164, 0.6481900215148926, 0.6312217116355896, 0.6527149081230164, 0.6040723919868469, 0.6561086177825928, 0.627828061580658, 0.6425339579582214, 0.6368778347969055, 0.6572397947311401, 0.6447963714599609, 0.6436651349067688, 0.6561086177825928, 0.6481900215148926, 0.6255655884742737, 0.6334841847419739, 0.6436651349067688, 0.6300904750823975, 0.6447963714599609, 0.6142534017562866, 0.6447963714599609, 0.6504524946212769, 0.6527149081230164, 0.6187782883644104, 0.6459276080131531, 0.6447963714599609, 0.6368778347969055, 0.6459276080131531, 0.6425339579582214, 0.6368778347969055, 0.6402714848518372, 0.6346153616905212, 0.6425339579582214, 0.6368778347969055, 0.6187782883644104, 0.6040723919868469, 0.622171938419342, 0.6357465982437134, 0.6368778347969055, 0.6300904750823975, 0.627828061580658, 0.6357465982437134, 0.6402714848518372, 0.6300904750823975, 0.6312217116355896, 0.6414027214050293, 0.6255655884742737, 0.6255655884742737, 0.6266968250274658, 0.6266968250274658, 0.6312217116355896, 0.6323529481887817, 0.6334841847419739, 0.6244344115257263, 0.6244344115257263, 0.622171938419342, 0.6368778347969055, 0.6255655884742737, 0.6244344115257263, 0.6334841847419739, 0.6244344115257263]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 1.1467 - accuracy: 0.6387"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 4s 30ms/step - loss: 1.1472 - accuracy: 0.6370 - val_loss: 1.2060 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.1357 - accuracy: 0.6483 - val_loss: 1.2029 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1295 - accuracy: 0.6413 - val_loss: 1.1988 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1214 - accuracy: 0.6540 - val_loss: 1.1946 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1185 - accuracy: 0.6592 - val_loss: 1.1881 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1158 - accuracy: 0.6483 - val_loss: 1.1861 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1030 - accuracy: 0.6574 - val_loss: 1.1815 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0992 - accuracy: 0.6646 - val_loss: 1.1844 - val_accuracy: 0.4855\n","Epoch 9/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0955 - accuracy: 0.6620 - val_loss: 1.1737 - val_accuracy: 0.4876\n","Epoch 10/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0886 - accuracy: 0.6669 - val_loss: 1.1790 - val_accuracy: 0.4866\n","Epoch 11/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0842 - accuracy: 0.6641 - val_loss: 1.1703 - val_accuracy: 0.4917\n","Epoch 12/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0853 - accuracy: 0.6587 - val_loss: 1.1636 - val_accuracy: 0.4969\n","Epoch 13/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0770 - accuracy: 0.6633 - val_loss: 1.1682 - val_accuracy: 0.4959\n","Epoch 14/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0698 - accuracy: 0.6693 - val_loss: 1.1488 - val_accuracy: 0.5145\n","Epoch 15/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0717 - accuracy: 0.6649 - val_loss: 1.1423 - val_accuracy: 0.5258\n","Epoch 16/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0613 - accuracy: 0.6757 - val_loss: 1.1320 - val_accuracy: 0.5537\n","Epoch 17/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0570 - accuracy: 0.6718 - val_loss: 1.1122 - val_accuracy: 0.6188\n","Epoch 18/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0544 - accuracy: 0.6747 - val_loss: 1.1101 - val_accuracy: 0.6095\n","Epoch 19/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0494 - accuracy: 0.6775 - val_loss: 1.1036 - val_accuracy: 0.6105\n","Epoch 20/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0510 - accuracy: 0.6649 - val_loss: 1.0937 - val_accuracy: 0.6219\n","Epoch 21/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0418 - accuracy: 0.6749 - val_loss: 1.0879 - val_accuracy: 0.6312\n","Epoch 22/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0340 - accuracy: 0.6868 - val_loss: 1.0816 - val_accuracy: 0.6291\n","Epoch 23/100\n","31/31 [==============================] - 0s 10ms/step - loss: 1.0307 - accuracy: 0.6866 - val_loss: 1.0815 - val_accuracy: 0.6178\n","Epoch 24/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0249 - accuracy: 0.6899 - val_loss: 1.0752 - val_accuracy: 0.6240\n","Epoch 25/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0230 - accuracy: 0.6850 - val_loss: 1.0769 - val_accuracy: 0.6229\n","Epoch 26/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0188 - accuracy: 0.6853 - val_loss: 1.0794 - val_accuracy: 0.6105\n","Epoch 27/100\n","31/31 [==============================] - 0s 11ms/step - loss: 1.0166 - accuracy: 0.6904 - val_loss: 1.0926 - val_accuracy: 0.5940\n","Epoch 28/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0114 - accuracy: 0.6899 - val_loss: 1.0679 - val_accuracy: 0.6209\n","Epoch 29/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0077 - accuracy: 0.6925 - val_loss: 1.0612 - val_accuracy: 0.6343\n","Epoch 30/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.0018 - accuracy: 0.6951 - val_loss: 1.0611 - val_accuracy: 0.6178\n","Epoch 31/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9962 - accuracy: 0.6943 - val_loss: 1.0585 - val_accuracy: 0.6333\n","Epoch 32/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9972 - accuracy: 0.6930 - val_loss: 1.0674 - val_accuracy: 0.6167\n","Epoch 33/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0038 - accuracy: 0.6824 - val_loss: 1.0523 - val_accuracy: 0.6405\n","Epoch 34/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9881 - accuracy: 0.6899 - val_loss: 1.0529 - val_accuracy: 0.6343\n","Epoch 35/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9871 - accuracy: 0.6899 - val_loss: 1.0519 - val_accuracy: 0.6167\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9790 - accuracy: 0.6987 - val_loss: 1.0501 - val_accuracy: 0.6302\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9760 - accuracy: 0.7057 - val_loss: 1.0497 - val_accuracy: 0.6219\n","Epoch 38/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9762 - accuracy: 0.6979 - val_loss: 1.0469 - val_accuracy: 0.6136\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9678 - accuracy: 0.7103 - val_loss: 1.0535 - val_accuracy: 0.6136\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9635 - accuracy: 0.7059 - val_loss: 1.0499 - val_accuracy: 0.6178\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9629 - accuracy: 0.7036 - val_loss: 1.0403 - val_accuracy: 0.6302\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9569 - accuracy: 0.7093 - val_loss: 1.0411 - val_accuracy: 0.6043\n","Epoch 43/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9680 - accuracy: 0.6853 - val_loss: 1.0338 - val_accuracy: 0.6322\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9597 - accuracy: 0.7023 - val_loss: 1.0325 - val_accuracy: 0.6364\n","Epoch 45/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9464 - accuracy: 0.7207 - val_loss: 1.0328 - val_accuracy: 0.6395\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9430 - accuracy: 0.7217 - val_loss: 1.0326 - val_accuracy: 0.6178\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9398 - accuracy: 0.7178 - val_loss: 1.0364 - val_accuracy: 0.6219\n","Epoch 48/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9400 - accuracy: 0.7114 - val_loss: 1.0274 - val_accuracy: 0.6312\n","Epoch 49/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9378 - accuracy: 0.7140 - val_loss: 1.0257 - val_accuracy: 0.6333\n","Epoch 50/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9392 - accuracy: 0.7005 - val_loss: 1.0249 - val_accuracy: 0.6343\n","Epoch 51/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9274 - accuracy: 0.7238 - val_loss: 1.0212 - val_accuracy: 0.6384\n","Epoch 52/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9286 - accuracy: 0.7119 - val_loss: 1.0319 - val_accuracy: 0.6240\n","Epoch 53/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9281 - accuracy: 0.7137 - val_loss: 1.0228 - val_accuracy: 0.6229\n","Epoch 54/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9170 - accuracy: 0.7271 - val_loss: 1.0210 - val_accuracy: 0.6291\n","Epoch 55/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.9214 - accuracy: 0.7202 - val_loss: 1.0171 - val_accuracy: 0.6405\n","Epoch 56/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9219 - accuracy: 0.7155 - val_loss: 1.0199 - val_accuracy: 0.6374\n","Epoch 57/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.9123 - accuracy: 0.7207 - val_loss: 1.0176 - val_accuracy: 0.6219\n","Epoch 58/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9024 - accuracy: 0.7341 - val_loss: 1.0199 - val_accuracy: 0.6322\n","Epoch 59/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8997 - accuracy: 0.7313 - val_loss: 1.0439 - val_accuracy: 0.6054\n","Epoch 60/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9096 - accuracy: 0.7207 - val_loss: 1.0144 - val_accuracy: 0.6250\n","Epoch 61/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8954 - accuracy: 0.7362 - val_loss: 1.0178 - val_accuracy: 0.6105\n","Epoch 62/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8925 - accuracy: 0.7333 - val_loss: 1.0114 - val_accuracy: 0.6322\n","Epoch 63/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8983 - accuracy: 0.7233 - val_loss: 1.0100 - val_accuracy: 0.6343\n","Epoch 64/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.8838 - accuracy: 0.7411 - val_loss: 1.0072 - val_accuracy: 0.6322\n","Epoch 65/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8850 - accuracy: 0.7344 - val_loss: 1.0129 - val_accuracy: 0.6229\n","Epoch 66/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8809 - accuracy: 0.7388 - val_loss: 1.0067 - val_accuracy: 0.6312\n","Epoch 67/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8831 - accuracy: 0.7339 - val_loss: 1.0061 - val_accuracy: 0.6405\n","Epoch 68/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8715 - accuracy: 0.7437 - val_loss: 1.0204 - val_accuracy: 0.6209\n","Epoch 69/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8663 - accuracy: 0.7504 - val_loss: 1.0099 - val_accuracy: 0.6219\n","Epoch 70/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8723 - accuracy: 0.7398 - val_loss: 1.0037 - val_accuracy: 0.6322\n","Epoch 71/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8666 - accuracy: 0.7455 - val_loss: 1.0190 - val_accuracy: 0.6043\n","Epoch 72/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8662 - accuracy: 0.7406 - val_loss: 1.0048 - val_accuracy: 0.6271\n","Epoch 73/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8579 - accuracy: 0.7543 - val_loss: 1.0144 - val_accuracy: 0.6116\n","Epoch 74/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8582 - accuracy: 0.7406 - val_loss: 1.0084 - val_accuracy: 0.6157\n","Epoch 75/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8640 - accuracy: 0.7377 - val_loss: 1.0046 - val_accuracy: 0.6312\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8557 - accuracy: 0.7463 - val_loss: 1.0006 - val_accuracy: 0.6312\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8616 - accuracy: 0.7357 - val_loss: 1.0040 - val_accuracy: 0.6198\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8445 - accuracy: 0.7602 - val_loss: 1.0037 - val_accuracy: 0.6343\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8383 - accuracy: 0.7612 - val_loss: 0.9986 - val_accuracy: 0.6291\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8370 - accuracy: 0.7677 - val_loss: 1.0288 - val_accuracy: 0.6054\n","Epoch 81/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8491 - accuracy: 0.7478 - val_loss: 0.9983 - val_accuracy: 0.6333\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8320 - accuracy: 0.7680 - val_loss: 0.9981 - val_accuracy: 0.6333\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8259 - accuracy: 0.7674 - val_loss: 1.0220 - val_accuracy: 0.6136\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8259 - accuracy: 0.7664 - val_loss: 1.0051 - val_accuracy: 0.6229\n","Epoch 85/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8243 - accuracy: 0.7656 - val_loss: 0.9980 - val_accuracy: 0.6271\n","Epoch 86/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8208 - accuracy: 0.7659 - val_loss: 1.0416 - val_accuracy: 0.5971\n","Epoch 87/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8266 - accuracy: 0.7483 - val_loss: 1.0356 - val_accuracy: 0.6012\n","Epoch 88/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8142 - accuracy: 0.7716 - val_loss: 0.9981 - val_accuracy: 0.6333\n","Epoch 89/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8094 - accuracy: 0.7721 - val_loss: 1.0291 - val_accuracy: 0.6012\n","Epoch 90/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8195 - accuracy: 0.7566 - val_loss: 0.9982 - val_accuracy: 0.6333\n","Epoch 91/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8021 - accuracy: 0.7783 - val_loss: 1.0001 - val_accuracy: 0.6219\n","Epoch 92/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7987 - accuracy: 0.7840 - val_loss: 0.9972 - val_accuracy: 0.6364\n","Epoch 93/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7998 - accuracy: 0.7695 - val_loss: 0.9997 - val_accuracy: 0.6219\n","Epoch 94/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7921 - accuracy: 0.7850 - val_loss: 1.0018 - val_accuracy: 0.6291\n","Epoch 95/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7894 - accuracy: 0.7863 - val_loss: 1.0058 - val_accuracy: 0.6157\n","Epoch 96/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7943 - accuracy: 0.7729 - val_loss: 1.0009 - val_accuracy: 0.6229\n","Epoch 97/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7886 - accuracy: 0.7814 - val_loss: 1.0028 - val_accuracy: 0.6250\n","Epoch 98/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7866 - accuracy: 0.7811 - val_loss: 1.0001 - val_accuracy: 0.6302\n","Epoch 99/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7895 - accuracy: 0.7724 - val_loss: 1.0043 - val_accuracy: 0.6312\n","Epoch 100/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7762 - accuracy: 0.7835 - val_loss: 1.0078 - val_accuracy: 0.6229\n","{'loss': [1.1472485065460205, 1.1356983184814453, 1.1294924020767212, 1.1213560104370117, 1.118484616279602, 1.1158254146575928, 1.1029809713363647, 1.099231243133545, 1.0954649448394775, 1.0885870456695557, 1.0842432975769043, 1.0853387117385864, 1.0770471096038818, 1.069831132888794, 1.071689486503601, 1.0613350868225098, 1.0570249557495117, 1.054437279701233, 1.0493824481964111, 1.0510096549987793, 1.041792631149292, 1.0339572429656982, 1.0306751728057861, 1.0249004364013672, 1.022979736328125, 1.0188268423080444, 1.016598105430603, 1.0113886594772339, 1.0076948404312134, 1.0018202066421509, 0.9962294697761536, 0.9972137808799744, 1.0037702322006226, 0.9880535006523132, 0.9870898723602295, 0.9789970517158508, 0.9759676456451416, 0.976159930229187, 0.9678159952163696, 0.9635321497917175, 0.9628777503967285, 0.9568613767623901, 0.9679838418960571, 0.959729790687561, 0.9464240670204163, 0.9429935812950134, 0.9398321509361267, 0.9399734735488892, 0.9378480911254883, 0.939225435256958, 0.9274020791053772, 0.9286264181137085, 0.928111732006073, 0.9170021414756775, 0.921434223651886, 0.9219284057617188, 0.9122707843780518, 0.9023868441581726, 0.8997012972831726, 0.9096137881278992, 0.8953680396080017, 0.8924802541732788, 0.8982785940170288, 0.8837924599647522, 0.8849834203720093, 0.8808760046958923, 0.8831445574760437, 0.8715236186981201, 0.8662705421447754, 0.8723402619361877, 0.8665523529052734, 0.86618572473526, 0.857903778553009, 0.8582054376602173, 0.8640212416648865, 0.8557320237159729, 0.8615763783454895, 0.8445460796356201, 0.8382781744003296, 0.8369643688201904, 0.8491103053092957, 0.8319774866104126, 0.8258522152900696, 0.8258560299873352, 0.8243407607078552, 0.8208184838294983, 0.8265637159347534, 0.8142279386520386, 0.8093854188919067, 0.8195388317108154, 0.8021419644355774, 0.7987259030342102, 0.7998295426368713, 0.7921271920204163, 0.7894312739372253, 0.7943093776702881, 0.7886090278625488, 0.7866209745407104, 0.7894510626792908, 0.776175320148468], 'accuracy': [0.6369509100914001, 0.6483204364776611, 0.6413436532020569, 0.6540051698684692, 0.6591731309890747, 0.6483204364776611, 0.6573643684387207, 0.6645994782447815, 0.6620154976844788, 0.6669250726699829, 0.6640827059745789, 0.6586563587188721, 0.6633074879646301, 0.6692506670951843, 0.6648578643798828, 0.6757106184959412, 0.6718346476554871, 0.6746770143508911, 0.6775193810462952, 0.6648578643798828, 0.6749354004859924, 0.686821699142456, 0.6865633130073547, 0.6899224519729614, 0.685012936592102, 0.6852713227272034, 0.6904392838478088, 0.6899224519729614, 0.6925064325332642, 0.6950904130935669, 0.6943152546882629, 0.6930232644081116, 0.6824289560317993, 0.6899224519729614, 0.6899224519729614, 0.6987079977989197, 0.7056847810745239, 0.6979328393936157, 0.710335910320282, 0.7059431672096252, 0.7036175727844238, 0.7093023061752319, 0.6852713227272034, 0.7023255825042725, 0.7206718325614929, 0.721705436706543, 0.7178294658660889, 0.711369514465332, 0.7139534950256348, 0.7005168199539185, 0.7237725853919983, 0.7118862867355347, 0.7136951088905334, 0.7271317839622498, 0.7201550602912903, 0.7155038714408875, 0.7206718325614929, 0.7341085076332092, 0.7312661409378052, 0.7206718325614929, 0.7361757159233093, 0.7333333492279053, 0.7232558131217957, 0.7410852909088135, 0.7343669533729553, 0.7387596964836121, 0.7338501214981079, 0.7436692714691162, 0.7503876090049744, 0.7397933006286621, 0.7454780340194702, 0.7405684590339661, 0.7542635798454285, 0.7405684590339661, 0.737726092338562, 0.746253252029419, 0.7356589436531067, 0.7602066993713379, 0.7612403035163879, 0.7677002549171448, 0.7478036284446716, 0.7679586410522461, 0.7674418687820435, 0.7664082646369934, 0.7656330466270447, 0.7658914923667908, 0.7483204007148743, 0.7715762257575989, 0.7720929980278015, 0.7565891742706299, 0.778294563293457, 0.7839793562889099, 0.7695090174674988, 0.7850129008293152, 0.7863048911094666, 0.7728682160377502, 0.7813953757286072, 0.7811369299888611, 0.7723514437675476, 0.7834625244140625], 'val_loss': [1.2059768438339233, 1.2028591632843018, 1.1988482475280762, 1.1946319341659546, 1.1880757808685303, 1.1861363649368286, 1.1815143823623657, 1.1844468116760254, 1.1737184524536133, 1.1790204048156738, 1.1702914237976074, 1.1636258363723755, 1.1681534051895142, 1.1487674713134766, 1.1422804594039917, 1.1320405006408691, 1.1122181415557861, 1.11014986038208, 1.103554368019104, 1.0937477350234985, 1.08794105052948, 1.0815911293029785, 1.081469178199768, 1.0751945972442627, 1.0768641233444214, 1.07942795753479, 1.0925687551498413, 1.0678824186325073, 1.06117844581604, 1.0610694885253906, 1.0584938526153564, 1.067427396774292, 1.0522948503494263, 1.052920937538147, 1.0519435405731201, 1.050128698348999, 1.0497227907180786, 1.0468850135803223, 1.0534549951553345, 1.0499054193496704, 1.040339469909668, 1.0410802364349365, 1.0337588787078857, 1.0324524641036987, 1.0328288078308105, 1.0326147079467773, 1.0363610982894897, 1.0274485349655151, 1.025713324546814, 1.0249433517456055, 1.0211764574050903, 1.031948208808899, 1.022801399230957, 1.020959496498108, 1.0171207189559937, 1.0198537111282349, 1.0176210403442383, 1.0199004411697388, 1.043905258178711, 1.0144238471984863, 1.0177806615829468, 1.0113683938980103, 1.009969711303711, 1.0072277784347534, 1.0128669738769531, 1.0066922903060913, 1.0060877799987793, 1.0203711986541748, 1.0098873376846313, 1.0037392377853394, 1.0190306901931763, 1.0047776699066162, 1.0144048929214478, 1.0083630084991455, 1.0045593976974487, 1.0005674362182617, 1.0040291547775269, 1.0036687850952148, 0.9986434578895569, 1.0288456678390503, 0.9983136057853699, 0.9980906248092651, 1.0220074653625488, 1.0050547122955322, 0.9980206489562988, 1.0415652990341187, 1.0355677604675293, 0.9981257915496826, 1.0290778875350952, 0.9981833696365356, 1.000118374824524, 0.9971596598625183, 0.9996975064277649, 1.0017693042755127, 1.0058033466339111, 1.0009233951568604, 1.0028280019760132, 1.000099539756775, 1.0042667388916016, 1.0077537298202515], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.4876033067703247, 0.48657023906707764, 0.4917355477809906, 0.4969008266925812, 0.4958677589893341, 0.5144628286361694, 0.5258264541625977, 0.5537189841270447, 0.6188016533851624, 0.6095041036605835, 0.6105371713638306, 0.6219007968902588, 0.6311983466148376, 0.6291322112083435, 0.6177685856819153, 0.6239669322967529, 0.6229338645935059, 0.6105371713638306, 0.5940082669258118, 0.6208677887916565, 0.6342975497245789, 0.6177685856819153, 0.6332644820213318, 0.6167355179786682, 0.6404958963394165, 0.6342975497245789, 0.6167355179786682, 0.6301652789115906, 0.6219007968902588, 0.6136363744735718, 0.6136363744735718, 0.6177685856819153, 0.6301652789115906, 0.6043388247489929, 0.6322314143180847, 0.6363636255264282, 0.6394628286361694, 0.6177685856819153, 0.6219007968902588, 0.6311983466148376, 0.6332644820213318, 0.6342975497245789, 0.6384297609329224, 0.6239669322967529, 0.6229338645935059, 0.6291322112083435, 0.6404958963394165, 0.6373966932296753, 0.6219007968902588, 0.6322314143180847, 0.60537189245224, 0.625, 0.6105371713638306, 0.6322314143180847, 0.6342975497245789, 0.6322314143180847, 0.6229338645935059, 0.6311983466148376, 0.6404958963394165, 0.6208677887916565, 0.6219007968902588, 0.6322314143180847, 0.6043388247489929, 0.6270661354064941, 0.6115702390670776, 0.6157024502754211, 0.6311983466148376, 0.6311983466148376, 0.6198347210884094, 0.6342975497245789, 0.6291322112083435, 0.60537189245224, 0.6332644820213318, 0.6332644820213318, 0.6136363744735718, 0.6229338645935059, 0.6270661354064941, 0.5971074104309082, 0.6012396812438965, 0.6332644820213318, 0.6012396812438965, 0.6332644820213318, 0.6219007968902588, 0.6363636255264282, 0.6219007968902588, 0.6291322112083435, 0.6157024502754211, 0.6229338645935059, 0.625, 0.6301652789115906, 0.6311983466148376, 0.6229338645935059]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 28ms/step - loss: 0.8511 - accuracy: 0.7236 - val_loss: 1.0280 - val_accuracy: 0.4849\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.8312 - accuracy: 0.7266"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 11ms/step - loss: 0.8283 - accuracy: 0.7422 - val_loss: 1.0298 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8154 - accuracy: 0.7511 - val_loss: 1.0302 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.8101 - accuracy: 0.7635 - val_loss: 1.0317 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8052 - accuracy: 0.7656 - val_loss: 1.0363 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.8037 - accuracy: 0.7667 - val_loss: 1.0375 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8032 - accuracy: 0.7562 - val_loss: 1.0374 - val_accuracy: 0.4860\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7942 - accuracy: 0.7710 - val_loss: 1.0374 - val_accuracy: 0.4881\n","Epoch 9/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7878 - accuracy: 0.7751 - val_loss: 1.0438 - val_accuracy: 0.4881\n","Epoch 10/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7895 - accuracy: 0.7707 - val_loss: 1.0516 - val_accuracy: 0.4871\n","Epoch 11/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7903 - accuracy: 0.7713 - val_loss: 1.0550 - val_accuracy: 0.4892\n","Epoch 12/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7834 - accuracy: 0.7772 - val_loss: 1.0431 - val_accuracy: 0.4968\n","Epoch 13/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7809 - accuracy: 0.7794 - val_loss: 1.0293 - val_accuracy: 0.5022\n","Epoch 14/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7722 - accuracy: 0.7858 - val_loss: 1.0432 - val_accuracy: 0.5043\n","Epoch 15/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.7719 - accuracy: 0.7864 - val_loss: 1.0110 - val_accuracy: 0.5334\n","Epoch 16/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7658 - accuracy: 0.7888 - val_loss: 0.9914 - val_accuracy: 0.5614\n","Epoch 17/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7632 - accuracy: 0.7856 - val_loss: 0.9755 - val_accuracy: 0.5722\n","Epoch 18/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7638 - accuracy: 0.7861 - val_loss: 0.9955 - val_accuracy: 0.5668\n","Epoch 19/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.7642 - accuracy: 0.7821 - val_loss: 0.9425 - val_accuracy: 0.6196\n","Epoch 20/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7705 - accuracy: 0.7686 - val_loss: 0.9616 - val_accuracy: 0.5970\n","Epoch 21/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7706 - accuracy: 0.7664 - val_loss: 0.9448 - val_accuracy: 0.6185\n","Epoch 22/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7684 - accuracy: 0.7807 - val_loss: 0.9390 - val_accuracy: 0.6250\n","Epoch 23/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7527 - accuracy: 0.7920 - val_loss: 0.9342 - val_accuracy: 0.6358\n","Epoch 24/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7472 - accuracy: 0.7966 - val_loss: 0.9192 - val_accuracy: 0.6573\n","Epoch 25/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7389 - accuracy: 0.8020 - val_loss: 0.9391 - val_accuracy: 0.6379\n","Epoch 26/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7421 - accuracy: 0.8017 - val_loss: 0.9261 - val_accuracy: 0.6498\n","Epoch 27/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7380 - accuracy: 0.7934 - val_loss: 0.9393 - val_accuracy: 0.6487\n","Epoch 28/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7339 - accuracy: 0.8063 - val_loss: 0.9184 - val_accuracy: 0.6573\n","Epoch 29/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7458 - accuracy: 0.7891 - val_loss: 0.9410 - val_accuracy: 0.6390\n","Epoch 30/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7373 - accuracy: 0.7961 - val_loss: 0.9252 - val_accuracy: 0.6659\n","Epoch 31/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7547 - accuracy: 0.7783 - val_loss: 0.9512 - val_accuracy: 0.6379\n","Epoch 32/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7238 - accuracy: 0.8090 - val_loss: 0.9328 - val_accuracy: 0.6606\n","Epoch 33/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7282 - accuracy: 0.8063 - val_loss: 0.9307 - val_accuracy: 0.6595\n","Epoch 34/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7194 - accuracy: 0.8152 - val_loss: 0.9450 - val_accuracy: 0.6476\n","Epoch 35/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7201 - accuracy: 0.8109 - val_loss: 0.9314 - val_accuracy: 0.6552\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7142 - accuracy: 0.8133 - val_loss: 0.9349 - val_accuracy: 0.6584\n","Epoch 37/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.7198 - accuracy: 0.8103 - val_loss: 0.9454 - val_accuracy: 0.6455\n","Epoch 38/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7130 - accuracy: 0.8160 - val_loss: 0.9269 - val_accuracy: 0.6562\n","Epoch 39/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7090 - accuracy: 0.8144 - val_loss: 0.9295 - val_accuracy: 0.6606\n","Epoch 40/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7105 - accuracy: 0.8098 - val_loss: 0.9296 - val_accuracy: 0.6638\n","Epoch 41/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7043 - accuracy: 0.8160 - val_loss: 0.9278 - val_accuracy: 0.6638\n","Epoch 42/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.7088 - accuracy: 0.8071 - val_loss: 0.9600 - val_accuracy: 0.6304\n","Epoch 43/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6965 - accuracy: 0.8198 - val_loss: 0.9411 - val_accuracy: 0.6466\n","Epoch 44/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.7012 - accuracy: 0.8106 - val_loss: 0.9322 - val_accuracy: 0.6595\n","Epoch 45/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6948 - accuracy: 0.8217 - val_loss: 0.9311 - val_accuracy: 0.6530\n","Epoch 46/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6876 - accuracy: 0.8335 - val_loss: 0.9319 - val_accuracy: 0.6595\n","Epoch 47/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6882 - accuracy: 0.8260 - val_loss: 0.9549 - val_accuracy: 0.6498\n","Epoch 48/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6926 - accuracy: 0.8252 - val_loss: 0.9364 - val_accuracy: 0.6562\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6830 - accuracy: 0.8292 - val_loss: 0.9367 - val_accuracy: 0.6584\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6742 - accuracy: 0.8389 - val_loss: 0.9329 - val_accuracy: 0.6595\n","Epoch 51/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6723 - accuracy: 0.8378 - val_loss: 0.9350 - val_accuracy: 0.6767\n","Epoch 52/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6887 - accuracy: 0.8209 - val_loss: 0.9573 - val_accuracy: 0.6433\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6817 - accuracy: 0.8238 - val_loss: 0.9385 - val_accuracy: 0.6584\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6683 - accuracy: 0.8357 - val_loss: 0.9387 - val_accuracy: 0.6573\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6699 - accuracy: 0.8338 - val_loss: 0.9502 - val_accuracy: 0.6466\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6730 - accuracy: 0.8289 - val_loss: 0.9567 - val_accuracy: 0.6422\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6592 - accuracy: 0.8478 - val_loss: 0.9413 - val_accuracy: 0.6584\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6639 - accuracy: 0.8303 - val_loss: 0.9568 - val_accuracy: 0.6455\n","Epoch 59/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6599 - accuracy: 0.8367 - val_loss: 0.9420 - val_accuracy: 0.6649\n","Epoch 60/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6530 - accuracy: 0.8440 - val_loss: 0.9458 - val_accuracy: 0.6444\n","Epoch 61/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6516 - accuracy: 0.8427 - val_loss: 0.9390 - val_accuracy: 0.6703\n","Epoch 62/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6458 - accuracy: 0.8513 - val_loss: 0.9514 - val_accuracy: 0.6476\n","Epoch 63/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6583 - accuracy: 0.8341 - val_loss: 0.9668 - val_accuracy: 0.6401\n","Epoch 64/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6431 - accuracy: 0.8473 - val_loss: 0.9485 - val_accuracy: 0.6530\n","Epoch 65/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6384 - accuracy: 0.8537 - val_loss: 0.9458 - val_accuracy: 0.6606\n","Epoch 66/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6327 - accuracy: 0.8605 - val_loss: 0.9488 - val_accuracy: 0.6476\n","Epoch 67/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6346 - accuracy: 0.8621 - val_loss: 0.9496 - val_accuracy: 0.6670\n","Epoch 68/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6368 - accuracy: 0.8478 - val_loss: 0.9666 - val_accuracy: 0.6455\n","Epoch 69/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6358 - accuracy: 0.8537 - val_loss: 0.9557 - val_accuracy: 0.6552\n","Epoch 70/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6243 - accuracy: 0.8623 - val_loss: 0.9583 - val_accuracy: 0.6498\n","Epoch 71/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6351 - accuracy: 0.8464 - val_loss: 0.9910 - val_accuracy: 0.6487\n","Epoch 72/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6539 - accuracy: 0.8246 - val_loss: 0.9516 - val_accuracy: 0.6519\n","Epoch 73/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6207 - accuracy: 0.8656 - val_loss: 0.9542 - val_accuracy: 0.6627\n","Epoch 74/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6165 - accuracy: 0.8661 - val_loss: 0.9636 - val_accuracy: 0.6487\n","Epoch 75/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6103 - accuracy: 0.8707 - val_loss: 0.9581 - val_accuracy: 0.6487\n","Epoch 76/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6122 - accuracy: 0.8693 - val_loss: 0.9694 - val_accuracy: 0.6455\n","Epoch 77/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6055 - accuracy: 0.8782 - val_loss: 0.9654 - val_accuracy: 0.6541\n","Epoch 78/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.6047 - accuracy: 0.8745 - val_loss: 0.9629 - val_accuracy: 0.6412\n","Epoch 79/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6072 - accuracy: 0.8645 - val_loss: 1.0032 - val_accuracy: 0.6390\n","Epoch 80/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6087 - accuracy: 0.8629 - val_loss: 1.0064 - val_accuracy: 0.6476\n","Epoch 81/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5954 - accuracy: 0.8809 - val_loss: 0.9622 - val_accuracy: 0.6627\n","Epoch 82/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5957 - accuracy: 0.8780 - val_loss: 0.9685 - val_accuracy: 0.6562\n","Epoch 83/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5899 - accuracy: 0.8796 - val_loss: 0.9920 - val_accuracy: 0.6433\n","Epoch 84/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5986 - accuracy: 0.8704 - val_loss: 1.0659 - val_accuracy: 0.6250\n","Epoch 85/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.6023 - accuracy: 0.8650 - val_loss: 0.9818 - val_accuracy: 0.6401\n","Epoch 86/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5824 - accuracy: 0.8858 - val_loss: 0.9652 - val_accuracy: 0.6649\n","Epoch 87/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5856 - accuracy: 0.8790 - val_loss: 1.0085 - val_accuracy: 0.6401\n","Epoch 88/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5873 - accuracy: 0.8769 - val_loss: 0.9897 - val_accuracy: 0.6433\n","Epoch 89/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5868 - accuracy: 0.8809 - val_loss: 0.9765 - val_accuracy: 0.6562\n","Epoch 90/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5752 - accuracy: 0.8904 - val_loss: 0.9872 - val_accuracy: 0.6606\n","Epoch 91/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5737 - accuracy: 0.8874 - val_loss: 0.9785 - val_accuracy: 0.6595\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5650 - accuracy: 0.8947 - val_loss: 0.9834 - val_accuracy: 0.6627\n","Epoch 93/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5697 - accuracy: 0.8893 - val_loss: 0.9849 - val_accuracy: 0.6627\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5767 - accuracy: 0.8737 - val_loss: 0.9830 - val_accuracy: 0.6519\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5635 - accuracy: 0.8998 - val_loss: 0.9832 - val_accuracy: 0.6573\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5721 - accuracy: 0.8817 - val_loss: 1.0316 - val_accuracy: 0.6390\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5705 - accuracy: 0.8804 - val_loss: 0.9902 - val_accuracy: 0.6487\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5512 - accuracy: 0.9041 - val_loss: 0.9909 - val_accuracy: 0.6552\n","Epoch 99/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5497 - accuracy: 0.9027 - val_loss: 0.9894 - val_accuracy: 0.6573\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5590 - accuracy: 0.8904 - val_loss: 1.0195 - val_accuracy: 0.6466\n","{'loss': [0.8510591983795166, 0.8282913565635681, 0.8154358863830566, 0.8101245760917664, 0.805178701877594, 0.8037296533584595, 0.803221583366394, 0.7942039370536804, 0.7877838015556335, 0.7895292043685913, 0.7903475165367126, 0.7833574414253235, 0.7808519005775452, 0.7722424864768982, 0.7718912363052368, 0.7657741904258728, 0.7631933689117432, 0.7638253569602966, 0.7642425894737244, 0.7704638838768005, 0.7706160545349121, 0.7684047222137451, 0.7526707053184509, 0.7471664547920227, 0.7389279007911682, 0.742111325263977, 0.738030731678009, 0.7338954210281372, 0.7457654476165771, 0.7373005151748657, 0.7546579241752625, 0.7237551212310791, 0.7282118797302246, 0.7193790674209595, 0.7200773358345032, 0.7142452001571655, 0.7197944521903992, 0.7129765748977661, 0.7090380191802979, 0.710467517375946, 0.7043340802192688, 0.7087740898132324, 0.6964677572250366, 0.7012460827827454, 0.6948040723800659, 0.6875931024551392, 0.6881961822509766, 0.6925896406173706, 0.6830151677131653, 0.6742129325866699, 0.6723032593727112, 0.6886693835258484, 0.6817028522491455, 0.6683034300804138, 0.6699490547180176, 0.6730137467384338, 0.6591940522193909, 0.6638841032981873, 0.6599172949790955, 0.6530112624168396, 0.6515835523605347, 0.6458086967468262, 0.6583418846130371, 0.6431424617767334, 0.6383782029151917, 0.6326853632926941, 0.6345963478088379, 0.6367776393890381, 0.6358305215835571, 0.6242966055870056, 0.635101318359375, 0.6539141535758972, 0.6206997036933899, 0.6164857745170593, 0.6103150844573975, 0.6121529340744019, 0.6054506897926331, 0.6046895384788513, 0.6071848273277283, 0.60869300365448, 0.5953975915908813, 0.5956976413726807, 0.5899364948272705, 0.5985690951347351, 0.6023146510124207, 0.582410991191864, 0.5856233239173889, 0.587331235408783, 0.5868057012557983, 0.5752037167549133, 0.5737227201461792, 0.5649501085281372, 0.5696960687637329, 0.5766658782958984, 0.5634701251983643, 0.5720669031143188, 0.5705205202102661, 0.5512374043464661, 0.5496994256973267, 0.5589592456817627], 'accuracy': [0.7235991358757019, 0.7421875, 0.7510775923728943, 0.7634698152542114, 0.765625, 0.7667025923728943, 0.756196141242981, 0.7710129022598267, 0.775053858757019, 0.7707435488700867, 0.7712823152542114, 0.7772090435028076, 0.7793642282485962, 0.7858297228813171, 0.7863685488700867, 0.7887930870056152, 0.7855603694915771, 0.7860991358757019, 0.7820581793785095, 0.7685883641242981, 0.7664331793785095, 0.7807112336158752, 0.7920258641242981, 0.7966055870056152, 0.8019935488700867, 0.8017241358757019, 0.7933728694915771, 0.806303858757019, 0.7890625, 0.7960668206214905, 0.7782866358757019, 0.8089978694915771, 0.806303858757019, 0.8151939511299133, 0.810883641242981, 0.8133081793785095, 0.8103448152542114, 0.8160021305084229, 0.8143857717514038, 0.8098060488700867, 0.8160021305084229, 0.8071120977401733, 0.8197737336158752, 0.8106142282485962, 0.821659505367279, 0.8335129022598267, 0.8259698152542114, 0.8251616358757019, 0.8292025923728943, 0.8389008641242981, 0.8378232717514038, 0.8208512663841248, 0.8238146305084229, 0.8356680870056152, 0.8337823152542114, 0.8289331793785095, 0.8477909564971924, 0.8302801847457886, 0.8367456793785095, 0.8440194129943848, 0.8426724076271057, 0.8512930870056152, 0.8340517282485962, 0.8472521305084229, 0.8537176847457886, 0.8604525923728943, 0.8620689511299133, 0.8477909564971924, 0.8537176847457886, 0.8623383641242981, 0.8464439511299133, 0.8246228694915771, 0.865571141242981, 0.8661099076271057, 0.8706896305084229, 0.8693426847457886, 0.8782327771186829, 0.8744612336158752, 0.8644935488700867, 0.8628771305084229, 0.8809267282485962, 0.8779633641242981, 0.8795797228813171, 0.8704202771186829, 0.8650323152542114, 0.8857758641242981, 0.8790409564971924, 0.8768857717514038, 0.8809267282485962, 0.8903555870056152, 0.8873922228813171, 0.8946659564971924, 0.889277994632721, 0.873652994632721, 0.899784505367279, 0.8817349076271057, 0.8803879022598267, 0.9040948152542114, 0.9027478694915771, 0.8903555870056152], 'val_loss': [1.0279715061187744, 1.029844880104065, 1.030245304107666, 1.0317139625549316, 1.0363107919692993, 1.0374622344970703, 1.0374306440353394, 1.0374094247817993, 1.0438225269317627, 1.0515574216842651, 1.055012583732605, 1.0431411266326904, 1.0293364524841309, 1.0432175397872925, 1.0110198259353638, 0.9913881421089172, 0.9754869937896729, 0.9954560995101929, 0.9424517154693604, 0.961561381816864, 0.9448025226593018, 0.9389971494674683, 0.9341852068901062, 0.9192312955856323, 0.9390515685081482, 0.9261005520820618, 0.9392934441566467, 0.9184377789497375, 0.9410096406936646, 0.9252085089683533, 0.9511505365371704, 0.9327918887138367, 0.9306526184082031, 0.9450488686561584, 0.9314479231834412, 0.9349259734153748, 0.9454413056373596, 0.9268876910209656, 0.9295496940612793, 0.9296470880508423, 0.9277961850166321, 0.9600417017936707, 0.9410820007324219, 0.9321990013122559, 0.9311048984527588, 0.9319046139717102, 0.954926609992981, 0.9364408254623413, 0.9367389678955078, 0.9328507781028748, 0.9349660277366638, 0.957301914691925, 0.938461422920227, 0.9387087821960449, 0.9502310156822205, 0.9567465782165527, 0.9412869811058044, 0.9567774534225464, 0.9420177340507507, 0.9458012580871582, 0.9390208721160889, 0.9513972997665405, 0.9667506217956543, 0.9485450983047485, 0.9458144903182983, 0.9488072991371155, 0.9496191143989563, 0.9666261076927185, 0.9557174444198608, 0.958316445350647, 0.9910171627998352, 0.9516275525093079, 0.95421302318573, 0.9635897874832153, 0.9581018090248108, 0.9694365859031677, 0.9653557538986206, 0.9629294276237488, 1.0031996965408325, 1.0064481496810913, 0.9621537923812866, 0.9685122966766357, 0.9919905066490173, 1.0658575296401978, 0.9817801117897034, 0.9652302265167236, 1.0084874629974365, 0.9896845817565918, 0.9765457510948181, 0.9871513843536377, 0.9784970283508301, 0.9833701848983765, 0.9849435091018677, 0.9829689264297485, 0.9832020998001099, 1.0315771102905273, 0.9901675581932068, 0.9908922910690308, 0.9893767237663269, 1.019484519958496], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.4881465435028076, 0.4881465435028076, 0.48706895112991333, 0.4892241358757019, 0.4967672526836395, 0.5021551847457886, 0.5043103694915771, 0.5334051847457886, 0.5614224076271057, 0.5721982717514038, 0.5668103694915771, 0.6196120977401733, 0.5969827771186829, 0.618534505367279, 0.625, 0.6357758641242981, 0.6573275923728943, 0.6379310488700867, 0.649784505367279, 0.6487069129943848, 0.6573275923728943, 0.639008641242981, 0.6659482717514038, 0.6379310488700867, 0.6605603694915771, 0.6594827771186829, 0.6476293206214905, 0.6551724076271057, 0.6584051847457886, 0.6454741358757019, 0.65625, 0.6605603694915771, 0.6637930870056152, 0.6637930870056152, 0.6303879022598267, 0.6465517282485962, 0.6594827771186829, 0.6530172228813171, 0.6594827771186829, 0.649784505367279, 0.65625, 0.6584051847457886, 0.6594827771186829, 0.6767241358757019, 0.6433189511299133, 0.6584051847457886, 0.6573275923728943, 0.6465517282485962, 0.642241358757019, 0.6584051847457886, 0.6454741358757019, 0.6648706793785095, 0.6443965435028076, 0.670258641242981, 0.6476293206214905, 0.6400862336158752, 0.6530172228813171, 0.6605603694915771, 0.6476293206214905, 0.6670258641242981, 0.6454741358757019, 0.6551724076271057, 0.649784505367279, 0.6487069129943848, 0.6519396305084229, 0.662715494632721, 0.6487069129943848, 0.6487069129943848, 0.6454741358757019, 0.6540948152542114, 0.6411637663841248, 0.639008641242981, 0.6476293206214905, 0.662715494632721, 0.65625, 0.6433189511299133, 0.625, 0.6400862336158752, 0.6648706793785095, 0.6400862336158752, 0.6433189511299133, 0.65625, 0.6605603694915771, 0.6594827771186829, 0.662715494632721, 0.662715494632721, 0.6519396305084229, 0.6573275923728943, 0.639008641242981, 0.6487069129943848, 0.6551724076271057, 0.6573275923728943, 0.6465517282485962]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.8426 - accuracy: 0.7439"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 4s 39ms/step - loss: 0.8428 - accuracy: 0.7450 - val_loss: 1.0259 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8230 - accuracy: 0.7566 - val_loss: 1.0272 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8128 - accuracy: 0.7657 - val_loss: 1.0292 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8118 - accuracy: 0.7657 - val_loss: 1.0303 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8038 - accuracy: 0.7694 - val_loss: 1.0369 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.8038 - accuracy: 0.7649 - val_loss: 1.0373 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7962 - accuracy: 0.7765 - val_loss: 1.0420 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7945 - accuracy: 0.7796 - val_loss: 1.0474 - val_accuracy: 0.4955\n","Epoch 9/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7885 - accuracy: 0.7793 - val_loss: 1.0625 - val_accuracy: 0.4955\n","Epoch 10/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7913 - accuracy: 0.7756 - val_loss: 1.0614 - val_accuracy: 0.4966\n","Epoch 11/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7798 - accuracy: 0.7917 - val_loss: 1.0874 - val_accuracy: 0.4966\n","Epoch 12/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7850 - accuracy: 0.7779 - val_loss: 1.0493 - val_accuracy: 0.4955\n","Epoch 13/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7773 - accuracy: 0.7892 - val_loss: 1.0394 - val_accuracy: 0.5034\n","Epoch 14/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7817 - accuracy: 0.7838 - val_loss: 1.0737 - val_accuracy: 0.5000\n","Epoch 15/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.7729 - accuracy: 0.7926 - val_loss: 1.0266 - val_accuracy: 0.5249\n","Epoch 16/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7643 - accuracy: 0.8019 - val_loss: 1.0502 - val_accuracy: 0.5204\n","Epoch 17/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.7662 - accuracy: 0.7946 - val_loss: 1.0079 - val_accuracy: 0.5452\n","Epoch 18/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7584 - accuracy: 0.8011 - val_loss: 0.9820 - val_accuracy: 0.5645\n","Epoch 19/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.7576 - accuracy: 0.8025 - val_loss: 0.9564 - val_accuracy: 0.5973\n","Epoch 20/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7559 - accuracy: 0.7977 - val_loss: 0.9376 - val_accuracy: 0.6222\n","Epoch 21/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7608 - accuracy: 0.7920 - val_loss: 0.9710 - val_accuracy: 0.5837\n","Epoch 22/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.7567 - accuracy: 0.7999 - val_loss: 0.9125 - val_accuracy: 0.6606\n","Epoch 23/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7488 - accuracy: 0.7985 - val_loss: 0.9154 - val_accuracy: 0.6505\n","Epoch 24/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7434 - accuracy: 0.8067 - val_loss: 0.9129 - val_accuracy: 0.6482\n","Epoch 25/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7426 - accuracy: 0.8073 - val_loss: 0.9242 - val_accuracy: 0.6686\n","Epoch 26/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7595 - accuracy: 0.7750 - val_loss: 0.9037 - val_accuracy: 0.6505\n","Epoch 27/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7426 - accuracy: 0.8050 - val_loss: 0.9034 - val_accuracy: 0.6584\n","Epoch 28/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.7325 - accuracy: 0.8124 - val_loss: 0.8956 - val_accuracy: 0.6833\n","Epoch 29/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7296 - accuracy: 0.8147 - val_loss: 0.9073 - val_accuracy: 0.6459\n","Epoch 30/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7261 - accuracy: 0.8084 - val_loss: 0.8935 - val_accuracy: 0.6742\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7271 - accuracy: 0.8132 - val_loss: 0.8953 - val_accuracy: 0.6697\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7266 - accuracy: 0.8079 - val_loss: 0.8964 - val_accuracy: 0.6572\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7326 - accuracy: 0.8016 - val_loss: 0.8949 - val_accuracy: 0.6776\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7164 - accuracy: 0.8243 - val_loss: 0.8928 - val_accuracy: 0.6686\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7113 - accuracy: 0.8226 - val_loss: 0.9013 - val_accuracy: 0.6821\n","Epoch 36/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7094 - accuracy: 0.8178 - val_loss: 0.9045 - val_accuracy: 0.6844\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7200 - accuracy: 0.8081 - val_loss: 0.9043 - val_accuracy: 0.6505\n","Epoch 38/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7053 - accuracy: 0.8200 - val_loss: 0.8961 - val_accuracy: 0.6765\n","Epoch 39/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7054 - accuracy: 0.8206 - val_loss: 0.8992 - val_accuracy: 0.6606\n","Epoch 40/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6974 - accuracy: 0.8370 - val_loss: 0.8983 - val_accuracy: 0.6595\n","Epoch 41/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7031 - accuracy: 0.8209 - val_loss: 0.8944 - val_accuracy: 0.6686\n","Epoch 42/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6924 - accuracy: 0.8319 - val_loss: 0.9005 - val_accuracy: 0.6527\n","Epoch 43/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6911 - accuracy: 0.8316 - val_loss: 0.9092 - val_accuracy: 0.6505\n","Epoch 44/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6875 - accuracy: 0.8356 - val_loss: 0.9030 - val_accuracy: 0.6561\n","Epoch 45/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.8311 - val_loss: 0.9037 - val_accuracy: 0.6776\n","Epoch 46/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6812 - accuracy: 0.8353 - val_loss: 0.8980 - val_accuracy: 0.6618\n","Epoch 47/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6881 - accuracy: 0.8277 - val_loss: 0.9770 - val_accuracy: 0.6256\n","Epoch 48/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.7297 - accuracy: 0.7830 - val_loss: 0.9470 - val_accuracy: 0.6753\n","Epoch 49/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6878 - accuracy: 0.8257 - val_loss: 0.9251 - val_accuracy: 0.6482\n","Epoch 50/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6948 - accuracy: 0.8172 - val_loss: 0.9145 - val_accuracy: 0.6516\n","Epoch 51/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6796 - accuracy: 0.8314 - val_loss: 0.8985 - val_accuracy: 0.6606\n","Epoch 52/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6646 - accuracy: 0.8506 - val_loss: 0.9026 - val_accuracy: 0.6640\n","Epoch 53/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6643 - accuracy: 0.8463 - val_loss: 0.9103 - val_accuracy: 0.6561\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6718 - accuracy: 0.8376 - val_loss: 0.9512 - val_accuracy: 0.6674\n","Epoch 55/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6610 - accuracy: 0.8455 - val_loss: 0.9313 - val_accuracy: 0.6516\n","Epoch 56/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6631 - accuracy: 0.8430 - val_loss: 0.9063 - val_accuracy: 0.6538\n","Epoch 57/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6626 - accuracy: 0.8393 - val_loss: 0.9036 - val_accuracy: 0.6584\n","Epoch 58/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6502 - accuracy: 0.8554 - val_loss: 0.9046 - val_accuracy: 0.6538\n","Epoch 59/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6494 - accuracy: 0.8497 - val_loss: 0.9065 - val_accuracy: 0.6606\n","Epoch 60/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6479 - accuracy: 0.8523 - val_loss: 0.9096 - val_accuracy: 0.6606\n","Epoch 61/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6450 - accuracy: 0.8514 - val_loss: 0.9199 - val_accuracy: 0.6697\n","Epoch 62/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6362 - accuracy: 0.8630 - val_loss: 0.9280 - val_accuracy: 0.6482\n","Epoch 63/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6462 - accuracy: 0.8526 - val_loss: 0.9400 - val_accuracy: 0.6425\n","Epoch 64/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6344 - accuracy: 0.8630 - val_loss: 0.9158 - val_accuracy: 0.6595\n","Epoch 65/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6293 - accuracy: 0.8673 - val_loss: 0.9254 - val_accuracy: 0.6674\n","Epoch 66/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6303 - accuracy: 0.8599 - val_loss: 0.9112 - val_accuracy: 0.6550\n","Epoch 67/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6278 - accuracy: 0.8647 - val_loss: 0.9127 - val_accuracy: 0.6561\n","Epoch 68/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6321 - accuracy: 0.8537 - val_loss: 0.9304 - val_accuracy: 0.6471\n","Epoch 69/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6316 - accuracy: 0.8563 - val_loss: 0.9193 - val_accuracy: 0.6584\n","Epoch 70/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6230 - accuracy: 0.8662 - val_loss: 0.9183 - val_accuracy: 0.6550\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6242 - accuracy: 0.8574 - val_loss: 0.9417 - val_accuracy: 0.6380\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6320 - accuracy: 0.8591 - val_loss: 0.9183 - val_accuracy: 0.6606\n","Epoch 73/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6514 - accuracy: 0.8316 - val_loss: 0.9189 - val_accuracy: 0.6550\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6304 - accuracy: 0.8514 - val_loss: 0.9299 - val_accuracy: 0.6482\n","Epoch 75/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6094 - accuracy: 0.8704 - val_loss: 0.9270 - val_accuracy: 0.6640\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6132 - accuracy: 0.8625 - val_loss: 0.9771 - val_accuracy: 0.6403\n","Epoch 77/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6037 - accuracy: 0.8761 - val_loss: 0.9259 - val_accuracy: 0.6561\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5988 - accuracy: 0.8817 - val_loss: 0.9434 - val_accuracy: 0.6437\n","Epoch 79/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6009 - accuracy: 0.8718 - val_loss: 0.9270 - val_accuracy: 0.6516\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5929 - accuracy: 0.8831 - val_loss: 0.9537 - val_accuracy: 0.6686\n","Epoch 81/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5940 - accuracy: 0.8783 - val_loss: 0.9239 - val_accuracy: 0.6538\n","Epoch 82/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5835 - accuracy: 0.8882 - val_loss: 0.9365 - val_accuracy: 0.6561\n","Epoch 83/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5826 - accuracy: 0.8950 - val_loss: 0.9361 - val_accuracy: 0.6550\n","Epoch 84/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5805 - accuracy: 0.8911 - val_loss: 0.9337 - val_accuracy: 0.6584\n","Epoch 85/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6186 - accuracy: 0.8531 - val_loss: 0.9377 - val_accuracy: 0.6572\n","Epoch 86/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5835 - accuracy: 0.8812 - val_loss: 0.9754 - val_accuracy: 0.6640\n","Epoch 87/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5910 - accuracy: 0.8729 - val_loss: 0.9367 - val_accuracy: 0.6505\n","Epoch 88/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5691 - accuracy: 0.8942 - val_loss: 0.9451 - val_accuracy: 0.6448\n","Epoch 89/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5806 - accuracy: 0.8826 - val_loss: 0.9781 - val_accuracy: 0.6708\n","Epoch 90/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5807 - accuracy: 0.8806 - val_loss: 0.9480 - val_accuracy: 0.6448\n","Epoch 91/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5638 - accuracy: 0.8976 - val_loss: 0.9735 - val_accuracy: 0.6471\n","Epoch 92/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5644 - accuracy: 0.8962 - val_loss: 0.9509 - val_accuracy: 0.6538\n","Epoch 93/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5564 - accuracy: 0.9018 - val_loss: 0.9867 - val_accuracy: 0.6414\n","Epoch 94/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5683 - accuracy: 0.8888 - val_loss: 0.9568 - val_accuracy: 0.6527\n","Epoch 95/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5564 - accuracy: 0.9004 - val_loss: 0.9587 - val_accuracy: 0.6640\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5527 - accuracy: 0.9029 - val_loss: 1.0378 - val_accuracy: 0.6369\n","Epoch 97/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5563 - accuracy: 0.9004 - val_loss: 0.9547 - val_accuracy: 0.6572\n","Epoch 98/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5522 - accuracy: 0.8995 - val_loss: 0.9598 - val_accuracy: 0.6527\n","Epoch 99/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5407 - accuracy: 0.9092 - val_loss: 0.9653 - val_accuracy: 0.6516\n","Epoch 100/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5402 - accuracy: 0.9123 - val_loss: 0.9640 - val_accuracy: 0.6493\n","{'loss': [0.8427748680114746, 0.8230032324790955, 0.8127711415290833, 0.8117790222167969, 0.8037809133529663, 0.8037624955177307, 0.7961965799331665, 0.79451584815979, 0.788534939289093, 0.7913126945495605, 0.7797911763191223, 0.7850031852722168, 0.7773463726043701, 0.781686544418335, 0.7728723287582397, 0.7642797827720642, 0.7662408947944641, 0.7584345936775208, 0.7575774192810059, 0.7559124827384949, 0.7608477473258972, 0.7566968202590942, 0.7487804293632507, 0.7433987259864807, 0.7426440119743347, 0.7595316171646118, 0.7425764203071594, 0.732483983039856, 0.7295709252357483, 0.7260973453521729, 0.7270668148994446, 0.7266318202018738, 0.732649564743042, 0.7163760662078857, 0.7112755179405212, 0.7093544006347656, 0.7199580669403076, 0.7053200602531433, 0.705441415309906, 0.6974125504493713, 0.7030842900276184, 0.6924048662185669, 0.6910896897315979, 0.6875399947166443, 0.6890640258789062, 0.6812251806259155, 0.6881421208381653, 0.7296647429466248, 0.6878467798233032, 0.694821298122406, 0.6795955896377563, 0.6646179556846619, 0.6643204689025879, 0.6718263030052185, 0.6610252261161804, 0.6630871295928955, 0.6625933051109314, 0.650206446647644, 0.6493892073631287, 0.6478516459465027, 0.6449509263038635, 0.6362383365631104, 0.6462195515632629, 0.6344010233879089, 0.6293084621429443, 0.6303179264068604, 0.6278302073478699, 0.6321258544921875, 0.6316007971763611, 0.6230443120002747, 0.6241550445556641, 0.6320064067840576, 0.6514354944229126, 0.6303864121437073, 0.609355092048645, 0.613215982913971, 0.6036884188652039, 0.5987555980682373, 0.6009037494659424, 0.592932403087616, 0.5940085649490356, 0.583537220954895, 0.5825726985931396, 0.5804683566093445, 0.6185573935508728, 0.583486795425415, 0.5910042524337769, 0.5691455602645874, 0.5806427597999573, 0.5807205438613892, 0.563828706741333, 0.5644146800041199, 0.5564435720443726, 0.568251371383667, 0.5564070343971252, 0.552669882774353, 0.5562942624092102, 0.5522337555885315, 0.5407140254974365, 0.5402131080627441], 'accuracy': [0.7450481057167053, 0.7566496729850769, 0.7657045722007751, 0.7657045722007751, 0.7693831324577332, 0.764855682849884, 0.7764572501182556, 0.7795698642730713, 0.7792869210243225, 0.7756083607673645, 0.79173743724823, 0.7778720855712891, 0.7891907095909119, 0.7838143706321716, 0.7925863265991211, 0.8019241690635681, 0.7945670485496521, 0.801075279712677, 0.8024901151657104, 0.7976796627044678, 0.7920203804969788, 0.7999433875083923, 0.7985285520553589, 0.806734561920166, 0.8073005080223083, 0.7750424742698669, 0.8050367832183838, 0.8123939037322998, 0.8146576285362244, 0.808432400226593, 0.8132427930831909, 0.8078664541244507, 0.8016412258148193, 0.8242784142494202, 0.8225806355476379, 0.81777024269104, 0.8081493973731995, 0.8200339674949646, 0.8205999135971069, 0.8370118737220764, 0.8208828568458557, 0.831918478012085, 0.8316355347633362, 0.835597038269043, 0.8310695886611938, 0.8353140950202942, 0.8276740312576294, 0.7829654812812805, 0.8256932497024536, 0.8172042965888977, 0.8313525915145874, 0.8505942225456238, 0.8463497161865234, 0.8375778198242188, 0.8455008268356323, 0.842954158782959, 0.839275598526001, 0.8554046154022217, 0.8497453331947327, 0.852292001247406, 0.8514431118965149, 0.8630446791648865, 0.8525750041007996, 0.8630446791648865, 0.8672891855239868, 0.8599320650100708, 0.8647425174713135, 0.8537068367004395, 0.8562535643577576, 0.8661573529243469, 0.8573853969573975, 0.8590831756591797, 0.8316355347633362, 0.8514431118965149, 0.8704017996788025, 0.8624787926673889, 0.8760611414909363, 0.8817204236984253, 0.8718166351318359, 0.8831352591514587, 0.8783248662948608, 0.8882286548614502, 0.8950198292732239, 0.8910582661628723, 0.8531408905982971, 0.881154477596283, 0.8729485273361206, 0.8941709399223328, 0.8825693130493164, 0.8805885910987854, 0.8975664973258972, 0.8961516618728638, 0.9018110036849976, 0.8887945413589478, 0.9003961682319641, 0.9029428362846375, 0.9003961682319641, 0.899547278881073, 0.9091680645942688, 0.9122806787490845], 'val_loss': [1.0259393453598022, 1.0272412300109863, 1.029238224029541, 1.0303329229354858, 1.0368660688400269, 1.0373127460479736, 1.0419849157333374, 1.0474414825439453, 1.0624600648880005, 1.0614382028579712, 1.0873550176620483, 1.04926598072052, 1.0393548011779785, 1.0737212896347046, 1.0266108512878418, 1.0501760244369507, 1.0079196691513062, 0.982001006603241, 0.9563697576522827, 0.9375754594802856, 0.9710127115249634, 0.9124892354011536, 0.9153797030448914, 0.9128857851028442, 0.9241887331008911, 0.903679370880127, 0.9034435749053955, 0.8956467509269714, 0.9072747826576233, 0.8935320377349854, 0.8952683210372925, 0.8964369893074036, 0.8949252367019653, 0.8928290605545044, 0.901279091835022, 0.904495120048523, 0.9043196439743042, 0.8961268663406372, 0.8991883397102356, 0.898342490196228, 0.894356369972229, 0.9004704356193542, 0.9092143774032593, 0.902996838092804, 0.90366131067276, 0.8980451226234436, 0.9770358204841614, 0.9469549655914307, 0.9251343607902527, 0.9145194292068481, 0.8985013365745544, 0.9026150703430176, 0.910339891910553, 0.9511837959289551, 0.9312925934791565, 0.9063246846199036, 0.9035853147506714, 0.9045988917350769, 0.9065008163452148, 0.9095686078071594, 0.919888436794281, 0.9279729723930359, 0.9400097727775574, 0.9158313870429993, 0.9254290461540222, 0.9112334847450256, 0.912655770778656, 0.9303598403930664, 0.9192713499069214, 0.9183006286621094, 0.9416938424110413, 0.9183175563812256, 0.9188623428344727, 0.9298568367958069, 0.9270423650741577, 0.9770632982254028, 0.9258883595466614, 0.9433563947677612, 0.926993727684021, 0.9536803364753723, 0.9238983392715454, 0.9364845752716064, 0.9361255168914795, 0.9336588382720947, 0.9377025365829468, 0.9754001498222351, 0.9367475509643555, 0.9451102018356323, 0.9781302213668823, 0.9479714035987854, 0.9734527468681335, 0.9508659243583679, 0.9866783022880554, 0.9567508101463318, 0.9587438106536865, 1.0378352403640747, 0.9547176361083984, 0.9597561955451965, 0.9653205871582031, 0.9640284776687622], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.49660632014274597, 0.4954751133918762, 0.5033936500549316, 0.5, 0.5248869061470032, 0.5203620195388794, 0.5452488660812378, 0.564479649066925, 0.5972850918769836, 0.622171938419342, 0.5837104320526123, 0.6606335043907166, 0.6504524946212769, 0.6481900215148926, 0.668552041053772, 0.6504524946212769, 0.6583710312843323, 0.6832579374313354, 0.6459276080131531, 0.6742081642150879, 0.6696832776069641, 0.6572397947311401, 0.6776018142700195, 0.668552041053772, 0.6821267008781433, 0.6843891143798828, 0.6504524946212769, 0.6764705777168274, 0.6606335043907166, 0.6595022678375244, 0.668552041053772, 0.6527149081230164, 0.6504524946212769, 0.6561086177825928, 0.6776018142700195, 0.6617646813392639, 0.6255655884742737, 0.6753393411636353, 0.6481900215148926, 0.651583731174469, 0.6606335043907166, 0.6640271544456482, 0.6561086177825928, 0.6674208045005798, 0.651583731174469, 0.6538461446762085, 0.6583710312843323, 0.6538461446762085, 0.6606335043907166, 0.6606335043907166, 0.6696832776069641, 0.6481900215148926, 0.6425339579582214, 0.6595022678375244, 0.6674208045005798, 0.6549773812294006, 0.6561086177825928, 0.6470588445663452, 0.6583710312843323, 0.6549773812294006, 0.6380090713500977, 0.6606335043907166, 0.6549773812294006, 0.6481900215148926, 0.6640271544456482, 0.6402714848518372, 0.6561086177825928, 0.6436651349067688, 0.651583731174469, 0.668552041053772, 0.6538461446762085, 0.6561086177825928, 0.6549773812294006, 0.6583710312843323, 0.6572397947311401, 0.6640271544456482, 0.6504524946212769, 0.6447963714599609, 0.6708144545555115, 0.6447963714599609, 0.6470588445663452, 0.6538461446762085, 0.6414027214050293, 0.6527149081230164, 0.6640271544456482, 0.6368778347969055, 0.6572397947311401, 0.6527149081230164, 0.651583731174469, 0.6493212580680847]}\n","45/45 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 4s 30ms/step - loss: 0.8493 - accuracy: 0.7320 - val_loss: 1.0306 - val_accuracy: 0.4855\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.8086 - accuracy: 0.7500"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 12ms/step - loss: 0.8418 - accuracy: 0.7380 - val_loss: 1.0341 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8313 - accuracy: 0.7465 - val_loss: 1.0356 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8221 - accuracy: 0.7530 - val_loss: 1.0382 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8162 - accuracy: 0.7553 - val_loss: 1.0441 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8197 - accuracy: 0.7501 - val_loss: 1.0488 - val_accuracy: 0.4866\n","Epoch 7/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.8072 - accuracy: 0.7638 - val_loss: 1.0501 - val_accuracy: 0.4866\n","Epoch 8/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8082 - accuracy: 0.7643 - val_loss: 1.0546 - val_accuracy: 0.4866\n","Epoch 9/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8035 - accuracy: 0.7623 - val_loss: 1.0787 - val_accuracy: 0.4866\n","Epoch 10/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8037 - accuracy: 0.7630 - val_loss: 1.0655 - val_accuracy: 0.4886\n","Epoch 11/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7964 - accuracy: 0.7726 - val_loss: 1.0747 - val_accuracy: 0.4907\n","Epoch 12/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7909 - accuracy: 0.7762 - val_loss: 1.1133 - val_accuracy: 0.4886\n","Epoch 13/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7934 - accuracy: 0.7690 - val_loss: 1.0768 - val_accuracy: 0.4969\n","Epoch 14/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7855 - accuracy: 0.7796 - val_loss: 1.1116 - val_accuracy: 0.4959\n","Epoch 15/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7912 - accuracy: 0.7618 - val_loss: 1.0152 - val_accuracy: 0.5351\n","Epoch 16/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7844 - accuracy: 0.7711 - val_loss: 1.0248 - val_accuracy: 0.5372\n","Epoch 17/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7759 - accuracy: 0.7804 - val_loss: 0.9931 - val_accuracy: 0.5610\n","Epoch 18/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7719 - accuracy: 0.7811 - val_loss: 0.9580 - val_accuracy: 0.6136\n","Epoch 19/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7793 - accuracy: 0.7742 - val_loss: 0.9993 - val_accuracy: 0.5682\n","Epoch 20/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7702 - accuracy: 0.7876 - val_loss: 0.9389 - val_accuracy: 0.6384\n","Epoch 21/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7685 - accuracy: 0.7829 - val_loss: 0.9331 - val_accuracy: 0.6477\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7902 - accuracy: 0.7576 - val_loss: 0.9355 - val_accuracy: 0.6477\n","Epoch 23/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7615 - accuracy: 0.7889 - val_loss: 0.9272 - val_accuracy: 0.6612\n","Epoch 24/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7672 - accuracy: 0.7716 - val_loss: 0.9254 - val_accuracy: 0.6591\n","Epoch 25/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7578 - accuracy: 0.7907 - val_loss: 0.9266 - val_accuracy: 0.6663\n","Epoch 26/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7686 - accuracy: 0.7695 - val_loss: 0.9267 - val_accuracy: 0.6684\n","Epoch 27/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7649 - accuracy: 0.7780 - val_loss: 0.9315 - val_accuracy: 0.6705\n","Epoch 28/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7467 - accuracy: 0.7982 - val_loss: 0.9306 - val_accuracy: 0.6746\n","Epoch 29/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7449 - accuracy: 0.7966 - val_loss: 0.9332 - val_accuracy: 0.6622\n","Epoch 30/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7483 - accuracy: 0.7866 - val_loss: 0.9428 - val_accuracy: 0.6519\n","Epoch 31/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7471 - accuracy: 0.7866 - val_loss: 0.9484 - val_accuracy: 0.6570\n","Epoch 32/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7400 - accuracy: 0.7964 - val_loss: 0.9375 - val_accuracy: 0.6684\n","Epoch 33/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7369 - accuracy: 0.8013 - val_loss: 0.9349 - val_accuracy: 0.6694\n","Epoch 34/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7361 - accuracy: 0.8026 - val_loss: 0.9397 - val_accuracy: 0.6622\n","Epoch 35/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7468 - accuracy: 0.7837 - val_loss: 0.9776 - val_accuracy: 0.6260\n","Epoch 36/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7284 - accuracy: 0.8070 - val_loss: 0.9435 - val_accuracy: 0.6632\n","Epoch 37/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7231 - accuracy: 0.8106 - val_loss: 0.9733 - val_accuracy: 0.6405\n","Epoch 38/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7315 - accuracy: 0.7982 - val_loss: 0.9492 - val_accuracy: 0.6508\n","Epoch 39/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7204 - accuracy: 0.8109 - val_loss: 0.9408 - val_accuracy: 0.6570\n","Epoch 40/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7192 - accuracy: 0.8041 - val_loss: 0.9593 - val_accuracy: 0.6457\n","Epoch 41/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.7203 - accuracy: 0.8062 - val_loss: 0.9472 - val_accuracy: 0.6560\n","Epoch 42/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7146 - accuracy: 0.8085 - val_loss: 0.9870 - val_accuracy: 0.6281\n","Epoch 43/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7124 - accuracy: 0.8111 - val_loss: 0.9415 - val_accuracy: 0.6705\n","Epoch 44/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7095 - accuracy: 0.8088 - val_loss: 0.9416 - val_accuracy: 0.6612\n","Epoch 45/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.7019 - accuracy: 0.8225 - val_loss: 0.9546 - val_accuracy: 0.6477\n","Epoch 46/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7126 - accuracy: 0.8106 - val_loss: 0.9597 - val_accuracy: 0.6498\n","Epoch 47/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7128 - accuracy: 0.8023 - val_loss: 0.9683 - val_accuracy: 0.6550\n","Epoch 48/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7198 - accuracy: 0.7915 - val_loss: 0.9595 - val_accuracy: 0.6446\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6968 - accuracy: 0.8183 - val_loss: 0.9534 - val_accuracy: 0.6643\n","Epoch 50/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6914 - accuracy: 0.8245 - val_loss: 0.9715 - val_accuracy: 0.6457\n","Epoch 51/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6889 - accuracy: 0.8274 - val_loss: 0.9657 - val_accuracy: 0.6436\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6862 - accuracy: 0.8238 - val_loss: 0.9492 - val_accuracy: 0.6632\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6822 - accuracy: 0.8292 - val_loss: 0.9567 - val_accuracy: 0.6591\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6808 - accuracy: 0.8292 - val_loss: 0.9653 - val_accuracy: 0.6519\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6764 - accuracy: 0.8261 - val_loss: 0.9536 - val_accuracy: 0.6612\n","Epoch 56/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6790 - accuracy: 0.8310 - val_loss: 0.9666 - val_accuracy: 0.6601\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6743 - accuracy: 0.8341 - val_loss: 0.9651 - val_accuracy: 0.6550\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6696 - accuracy: 0.8375 - val_loss: 0.9604 - val_accuracy: 0.6529\n","Epoch 59/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6644 - accuracy: 0.8395 - val_loss: 0.9929 - val_accuracy: 0.6364\n","Epoch 60/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6678 - accuracy: 0.8339 - val_loss: 1.0298 - val_accuracy: 0.6167\n","Epoch 61/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6824 - accuracy: 0.8230 - val_loss: 0.9670 - val_accuracy: 0.6519\n","Epoch 62/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6623 - accuracy: 0.8393 - val_loss: 0.9674 - val_accuracy: 0.6498\n","Epoch 63/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6581 - accuracy: 0.8411 - val_loss: 0.9673 - val_accuracy: 0.6570\n","Epoch 64/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6645 - accuracy: 0.8307 - val_loss: 0.9630 - val_accuracy: 0.6581\n","Epoch 65/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6642 - accuracy: 0.8310 - val_loss: 0.9944 - val_accuracy: 0.6395\n","Epoch 66/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6515 - accuracy: 0.8460 - val_loss: 0.9695 - val_accuracy: 0.6591\n","Epoch 67/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6486 - accuracy: 0.8424 - val_loss: 0.9771 - val_accuracy: 0.6508\n","Epoch 68/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6492 - accuracy: 0.8429 - val_loss: 0.9649 - val_accuracy: 0.6622\n","Epoch 69/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6410 - accuracy: 0.8512 - val_loss: 0.9666 - val_accuracy: 0.6643\n","Epoch 70/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6362 - accuracy: 0.8628 - val_loss: 1.0085 - val_accuracy: 0.6364\n","Epoch 71/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6478 - accuracy: 0.8429 - val_loss: 0.9775 - val_accuracy: 0.6457\n","Epoch 72/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6294 - accuracy: 0.8566 - val_loss: 0.9722 - val_accuracy: 0.6550\n","Epoch 73/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6295 - accuracy: 0.8589 - val_loss: 0.9781 - val_accuracy: 0.6581\n","Epoch 74/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6385 - accuracy: 0.8434 - val_loss: 0.9733 - val_accuracy: 0.6581\n","Epoch 75/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6238 - accuracy: 0.8618 - val_loss: 0.9788 - val_accuracy: 0.6612\n","Epoch 76/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6203 - accuracy: 0.8625 - val_loss: 0.9786 - val_accuracy: 0.6581\n","Epoch 77/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6529 - accuracy: 0.8349 - val_loss: 1.0937 - val_accuracy: 0.6116\n","Epoch 78/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6413 - accuracy: 0.8432 - val_loss: 0.9783 - val_accuracy: 0.6570\n","Epoch 79/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6145 - accuracy: 0.8672 - val_loss: 1.0031 - val_accuracy: 0.6426\n","Epoch 80/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.6162 - accuracy: 0.8643 - val_loss: 1.0447 - val_accuracy: 0.6198\n","Epoch 81/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6154 - accuracy: 0.8618 - val_loss: 0.9896 - val_accuracy: 0.6508\n","Epoch 82/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6088 - accuracy: 0.8654 - val_loss: 0.9911 - val_accuracy: 0.6539\n","Epoch 83/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6017 - accuracy: 0.8705 - val_loss: 0.9884 - val_accuracy: 0.6519\n","Epoch 84/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6025 - accuracy: 0.8713 - val_loss: 0.9885 - val_accuracy: 0.6622\n","Epoch 85/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5972 - accuracy: 0.8775 - val_loss: 0.9877 - val_accuracy: 0.6612\n","Epoch 86/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5970 - accuracy: 0.8724 - val_loss: 1.0080 - val_accuracy: 0.6477\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5968 - accuracy: 0.8773 - val_loss: 1.0205 - val_accuracy: 0.6415\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5986 - accuracy: 0.8726 - val_loss: 0.9982 - val_accuracy: 0.6570\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5870 - accuracy: 0.8817 - val_loss: 0.9974 - val_accuracy: 0.6560\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5835 - accuracy: 0.8835 - val_loss: 1.0203 - val_accuracy: 0.6436\n","Epoch 91/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5879 - accuracy: 0.8731 - val_loss: 1.0033 - val_accuracy: 0.6488\n","Epoch 92/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5848 - accuracy: 0.8832 - val_loss: 1.1088 - val_accuracy: 0.6033\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5926 - accuracy: 0.8744 - val_loss: 1.0361 - val_accuracy: 0.6322\n","Epoch 94/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5789 - accuracy: 0.8801 - val_loss: 1.0316 - val_accuracy: 0.6374\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5695 - accuracy: 0.8964 - val_loss: 1.0529 - val_accuracy: 0.6353\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5945 - accuracy: 0.8615 - val_loss: 1.0267 - val_accuracy: 0.6550\n","Epoch 97/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5863 - accuracy: 0.8729 - val_loss: 1.0275 - val_accuracy: 0.6529\n","Epoch 98/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5631 - accuracy: 0.8974 - val_loss: 1.0177 - val_accuracy: 0.6498\n","Epoch 99/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5645 - accuracy: 0.8959 - val_loss: 1.0863 - val_accuracy: 0.6198\n","Epoch 100/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5742 - accuracy: 0.8786 - val_loss: 1.0250 - val_accuracy: 0.6488\n","{'loss': [0.849286675453186, 0.8418428897857666, 0.8313127756118774, 0.8221469521522522, 0.8161554932594299, 0.8197283744812012, 0.8071665167808533, 0.808219850063324, 0.8034919500350952, 0.8037270903587341, 0.7963623404502869, 0.7908626198768616, 0.7934399843215942, 0.7854837775230408, 0.7912238240242004, 0.784433901309967, 0.7759212851524353, 0.7719097137451172, 0.7792677879333496, 0.770215630531311, 0.7684813141822815, 0.7902448177337646, 0.7615330815315247, 0.7672244310379028, 0.7577871680259705, 0.7686425447463989, 0.76493239402771, 0.7466962933540344, 0.744910717010498, 0.7482953071594238, 0.7471219897270203, 0.7400314807891846, 0.7368869781494141, 0.7361354827880859, 0.746751606464386, 0.7284302711486816, 0.7231196761131287, 0.7314980030059814, 0.7203866243362427, 0.7191515564918518, 0.7202664613723755, 0.7146247029304504, 0.712361216545105, 0.709506630897522, 0.7018704414367676, 0.7126240730285645, 0.7128159403800964, 0.7198249697685242, 0.6967625617980957, 0.6914436221122742, 0.6888901591300964, 0.6861528158187866, 0.682219386100769, 0.6808063983917236, 0.6764137148857117, 0.6789554357528687, 0.6742995977401733, 0.6695516705513, 0.6644068360328674, 0.6678478717803955, 0.6823945641517639, 0.6622707843780518, 0.6581481695175171, 0.6645017862319946, 0.6641619801521301, 0.6514777541160583, 0.64860600233078, 0.6491549015045166, 0.6409503221511841, 0.6361598372459412, 0.6477810144424438, 0.6293515563011169, 0.6294516324996948, 0.6384641528129578, 0.623805582523346, 0.6202727556228638, 0.6529116630554199, 0.6412975192070007, 0.6145016551017761, 0.6162046194076538, 0.6154173612594604, 0.6088175773620605, 0.6016714572906494, 0.6025084853172302, 0.5972369909286499, 0.5970342755317688, 0.5968067049980164, 0.5985801219940186, 0.5870288014411926, 0.5834929943084717, 0.5879454016685486, 0.5848032832145691, 0.5926283597946167, 0.5788618922233582, 0.5695152282714844, 0.5945295095443726, 0.5862829089164734, 0.5631109476089478, 0.5644987225532532, 0.5741813778877258], 'accuracy': [0.7320413589477539, 0.7379844784736633, 0.7465116381645203, 0.7529715895652771, 0.7552971839904785, 0.750129222869873, 0.7638242840766907, 0.7643410563468933, 0.762273907661438, 0.7630490660667419, 0.7726098299026489, 0.7762274146080017, 0.7689922451972961, 0.7795865535736084, 0.7617571353912354, 0.7710594534873962, 0.7803617715835571, 0.7811369299888611, 0.7741602063179016, 0.7875968813896179, 0.7829457521438599, 0.7576227188110352, 0.7888888716697693, 0.7715762257575989, 0.7906976938247681, 0.7695090174674988, 0.7780361771583557, 0.7981911897659302, 0.7966408133506775, 0.7865633368492126, 0.7865633368492126, 0.7963824272155762, 0.8012920022010803, 0.8025839924812317, 0.7837209105491638, 0.8069767355918884, 0.8105943202972412, 0.7981911897659302, 0.8108527064323425, 0.8041343688964844, 0.8062015771865845, 0.8085271120071411, 0.8111110925674438, 0.8087855577468872, 0.8224806189537048, 0.8105943202972412, 0.8023256063461304, 0.791472852230072, 0.8183462619781494, 0.8245478272438049, 0.827390193939209, 0.8237726092338562, 0.829198956489563, 0.829198956489563, 0.8260982036590576, 0.8310077786445618, 0.8341085314750671, 0.8374677300453186, 0.8395348787307739, 0.8338501453399658, 0.8229973912239075, 0.8392764925956726, 0.8410852551460266, 0.8307493329048157, 0.8310077786445618, 0.8459948301315308, 0.842377245426178, 0.8428940773010254, 0.8511627912521362, 0.8627907037734985, 0.8428940773010254, 0.856589138507843, 0.8589147329330444, 0.843410849571228, 0.8617570996284485, 0.8625323176383972, 0.8348837494850159, 0.8431524634361267, 0.8671834468841553, 0.8643410801887512, 0.8617570996284485, 0.8653746843338013, 0.8705426454544067, 0.8713178038597107, 0.8775193691253662, 0.8723514080047607, 0.8772609829902649, 0.8726097941398621, 0.8816537261009216, 0.8834625482559204, 0.8731266260147095, 0.8832041621208191, 0.8744186162948608, 0.880103349685669, 0.8963824510574341, 0.8614987134933472, 0.8728682398796082, 0.8974159955978394, 0.8958656191825867, 0.8785529732704163], 'val_loss': [1.0306360721588135, 1.0341061353683472, 1.035637378692627, 1.0381659269332886, 1.04409658908844, 1.0488263368606567, 1.0500751733779907, 1.0546455383300781, 1.078741431236267, 1.0655261278152466, 1.0746639966964722, 1.1133155822753906, 1.076768159866333, 1.1115870475769043, 1.015230655670166, 1.0248486995697021, 0.9931098222732544, 0.9579986333847046, 0.9992841482162476, 0.9389494061470032, 0.9330570101737976, 0.9354745149612427, 0.927182137966156, 0.9253933429718018, 0.9265908598899841, 0.9266737103462219, 0.9314731955528259, 0.9306223392486572, 0.9331714510917664, 0.94279944896698, 0.9483740329742432, 0.9374614953994751, 0.9348989725112915, 0.9396741986274719, 0.9776367545127869, 0.9435008764266968, 0.9732916951179504, 0.94923996925354, 0.9407652616500854, 0.9592885971069336, 0.9471948742866516, 0.9870357513427734, 0.9415378570556641, 0.9415876269340515, 0.9546173810958862, 0.9596763253211975, 0.9683299660682678, 0.9594740271568298, 0.953427791595459, 0.9714539647102356, 0.9657365083694458, 0.9492026567459106, 0.9566959142684937, 0.9653074145317078, 0.9536247849464417, 0.9666105508804321, 0.9650817513465881, 0.9604160785675049, 0.9928961396217346, 1.029767394065857, 0.9669537544250488, 0.9673746824264526, 0.9672861695289612, 0.9630489349365234, 0.9943591952323914, 0.9695309996604919, 0.9770694375038147, 0.9649377465248108, 0.9666479229927063, 1.00849449634552, 0.9774787425994873, 0.9722430109977722, 0.9781440496444702, 0.9732903838157654, 0.9788220524787903, 0.978584349155426, 1.093713402748108, 0.9782501459121704, 1.0031062364578247, 1.0446579456329346, 0.9896335005760193, 0.9910714030265808, 0.9883685111999512, 0.988455057144165, 0.9877457022666931, 1.0079931020736694, 1.0205423831939697, 0.9982141256332397, 0.9974192380905151, 1.0203231573104858, 1.0033258199691772, 1.1088066101074219, 1.0361480712890625, 1.0315918922424316, 1.0528655052185059, 1.0266757011413574, 1.027503252029419, 1.0177453756332397, 1.0862596035003662, 1.0250250101089478], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.48657023906707764, 0.48657023906707764, 0.48657023906707764, 0.4886363744735718, 0.49070248007774353, 0.4886363744735718, 0.4969008266925812, 0.4958677589893341, 0.5351239442825317, 0.5371900796890259, 0.5609503984451294, 0.6136363744735718, 0.5681818127632141, 0.6384297609329224, 0.6477272510528564, 0.6477272510528564, 0.6611570119857788, 0.6590909361839294, 0.6663222908973694, 0.6683884263038635, 0.6704545617103577, 0.6745867729187012, 0.6621900796890259, 0.6518595218658447, 0.6570248007774353, 0.6683884263038635, 0.6694214940071106, 0.6621900796890259, 0.6260330677032471, 0.663223147392273, 0.6404958963394165, 0.6508264541625977, 0.6570248007774353, 0.6456611752510071, 0.6559917330741882, 0.6280992031097412, 0.6704545617103577, 0.6611570119857788, 0.6477272510528564, 0.6497933864593506, 0.6549586653709412, 0.64462810754776, 0.66425621509552, 0.6456611752510071, 0.6435950398445129, 0.663223147392273, 0.6590909361839294, 0.6518595218658447, 0.6611570119857788, 0.6601239442825317, 0.6549586653709412, 0.6528925895690918, 0.6363636255264282, 0.6167355179786682, 0.6518595218658447, 0.6497933864593506, 0.6570248007774353, 0.6580578684806824, 0.6394628286361694, 0.6590909361839294, 0.6508264541625977, 0.6621900796890259, 0.66425621509552, 0.6363636255264282, 0.6456611752510071, 0.6549586653709412, 0.6580578684806824, 0.6580578684806824, 0.6611570119857788, 0.6580578684806824, 0.6115702390670776, 0.6570248007774353, 0.6425619721412659, 0.6198347210884094, 0.6508264541625977, 0.6539255976676941, 0.6518595218658447, 0.6621900796890259, 0.6611570119857788, 0.6477272510528564, 0.6415289044380188, 0.6570248007774353, 0.6559917330741882, 0.6435950398445129, 0.6487603187561035, 0.6033057570457458, 0.6322314143180847, 0.6373966932296753, 0.6353305578231812, 0.6549586653709412, 0.6528925895690918, 0.6497933864593506, 0.6198347210884094, 0.6487603187561035]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 4s 35ms/step - loss: 0.6792 - accuracy: 0.8095 - val_loss: 1.0170 - val_accuracy: 0.4849\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 11ms/step - loss: 0.6257 - accuracy: 0.8540 - val_loss: 1.0195 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6412 - accuracy: 0.8384 - val_loss: 1.0272 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6491 - accuracy: 0.8295 - val_loss: 1.0411 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6134 - accuracy: 0.8510 - val_loss: 1.0469 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6120 - accuracy: 0.8634 - val_loss: 1.0670 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6017 - accuracy: 0.8648 - val_loss: 1.0786 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6085 - accuracy: 0.8578 - val_loss: 1.0980 - val_accuracy: 0.4871\n","Epoch 9/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.6018 - accuracy: 0.8613 - val_loss: 1.1105 - val_accuracy: 0.4871\n","Epoch 10/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.5933 - accuracy: 0.8763 - val_loss: 1.1625 - val_accuracy: 0.4871\n","Epoch 11/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5993 - accuracy: 0.8683 - val_loss: 1.1313 - val_accuracy: 0.4903\n","Epoch 12/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5860 - accuracy: 0.8723 - val_loss: 1.1676 - val_accuracy: 0.4935\n","Epoch 13/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5864 - accuracy: 0.8753 - val_loss: 1.1306 - val_accuracy: 0.5022\n","Epoch 14/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5907 - accuracy: 0.8669 - val_loss: 1.1144 - val_accuracy: 0.5086\n","Epoch 15/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5761 - accuracy: 0.8825 - val_loss: 1.2299 - val_accuracy: 0.5054\n","Epoch 16/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5823 - accuracy: 0.8761 - val_loss: 1.1253 - val_accuracy: 0.5302\n","Epoch 17/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5760 - accuracy: 0.8839 - val_loss: 1.1029 - val_accuracy: 0.5550\n","Epoch 18/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5704 - accuracy: 0.8852 - val_loss: 0.9932 - val_accuracy: 0.5862\n","Epoch 19/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5613 - accuracy: 0.8957 - val_loss: 1.0162 - val_accuracy: 0.5916\n","Epoch 20/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5639 - accuracy: 0.8960 - val_loss: 0.9429 - val_accuracy: 0.6315\n","Epoch 21/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5594 - accuracy: 0.8960 - val_loss: 0.9278 - val_accuracy: 0.6476\n","Epoch 22/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5556 - accuracy: 0.8966 - val_loss: 0.9274 - val_accuracy: 0.6606\n","Epoch 23/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5601 - accuracy: 0.8885 - val_loss: 0.8871 - val_accuracy: 0.6756\n","Epoch 24/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5524 - accuracy: 0.8979 - val_loss: 0.8945 - val_accuracy: 0.6810\n","Epoch 25/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5567 - accuracy: 0.8939 - val_loss: 0.8704 - val_accuracy: 0.7004\n","Epoch 26/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5481 - accuracy: 0.9019 - val_loss: 0.8697 - val_accuracy: 0.7134\n","Epoch 27/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5472 - accuracy: 0.9003 - val_loss: 0.8776 - val_accuracy: 0.7069\n","Epoch 28/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5617 - accuracy: 0.8852 - val_loss: 0.8686 - val_accuracy: 0.7112\n","Epoch 29/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5462 - accuracy: 0.8960 - val_loss: 0.8775 - val_accuracy: 0.6994\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5420 - accuracy: 0.9062 - val_loss: 0.8705 - val_accuracy: 0.7134\n","Epoch 31/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5391 - accuracy: 0.9025 - val_loss: 0.8740 - val_accuracy: 0.7177\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5470 - accuracy: 0.8909 - val_loss: 0.8802 - val_accuracy: 0.7101\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5312 - accuracy: 0.9084 - val_loss: 0.9253 - val_accuracy: 0.6724\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5455 - accuracy: 0.8914 - val_loss: 0.8936 - val_accuracy: 0.6983\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5325 - accuracy: 0.9030 - val_loss: 0.9120 - val_accuracy: 0.7026\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5226 - accuracy: 0.9114 - val_loss: 0.8908 - val_accuracy: 0.7123\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5192 - accuracy: 0.9186 - val_loss: 0.9022 - val_accuracy: 0.7026\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5307 - accuracy: 0.9054 - val_loss: 0.9268 - val_accuracy: 0.7080\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5229 - accuracy: 0.9103 - val_loss: 0.8889 - val_accuracy: 0.7069\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5135 - accuracy: 0.9168 - val_loss: 0.8933 - val_accuracy: 0.7177\n","Epoch 41/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5190 - accuracy: 0.9135 - val_loss: 0.8975 - val_accuracy: 0.7144\n","Epoch 42/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5116 - accuracy: 0.9176 - val_loss: 0.8971 - val_accuracy: 0.7047\n","Epoch 43/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5062 - accuracy: 0.9235 - val_loss: 0.9505 - val_accuracy: 0.6907\n","Epoch 44/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5152 - accuracy: 0.9103 - val_loss: 0.9129 - val_accuracy: 0.6929\n","Epoch 45/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4985 - accuracy: 0.9283 - val_loss: 0.9488 - val_accuracy: 0.6972\n","Epoch 46/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5119 - accuracy: 0.9154 - val_loss: 0.9019 - val_accuracy: 0.7134\n","Epoch 47/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5037 - accuracy: 0.9173 - val_loss: 0.9140 - val_accuracy: 0.6994\n","Epoch 48/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5196 - accuracy: 0.9022 - val_loss: 0.9332 - val_accuracy: 0.7004\n","Epoch 49/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4951 - accuracy: 0.9262 - val_loss: 0.9159 - val_accuracy: 0.7101\n","Epoch 50/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4985 - accuracy: 0.9224 - val_loss: 1.0347 - val_accuracy: 0.6498\n","Epoch 51/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.5227 - accuracy: 0.8979 - val_loss: 0.9083 - val_accuracy: 0.7144\n","Epoch 52/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5040 - accuracy: 0.9127 - val_loss: 0.9463 - val_accuracy: 0.6886\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5082 - accuracy: 0.9130 - val_loss: 0.9239 - val_accuracy: 0.6961\n","Epoch 54/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4770 - accuracy: 0.9421 - val_loss: 0.9153 - val_accuracy: 0.7123\n","Epoch 55/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4734 - accuracy: 0.9421 - val_loss: 0.9200 - val_accuracy: 0.7134\n","Epoch 56/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4710 - accuracy: 0.9380 - val_loss: 0.9619 - val_accuracy: 0.6756\n","Epoch 57/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4756 - accuracy: 0.9421 - val_loss: 0.9457 - val_accuracy: 0.7015\n","Epoch 58/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4872 - accuracy: 0.9240 - val_loss: 0.9305 - val_accuracy: 0.7069\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4648 - accuracy: 0.9472 - val_loss: 0.9357 - val_accuracy: 0.7058\n","Epoch 60/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4669 - accuracy: 0.9413 - val_loss: 0.9319 - val_accuracy: 0.7134\n","Epoch 61/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4667 - accuracy: 0.9364 - val_loss: 0.9216 - val_accuracy: 0.7144\n","Epoch 62/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4639 - accuracy: 0.9423 - val_loss: 0.9192 - val_accuracy: 0.7112\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4568 - accuracy: 0.9504 - val_loss: 0.9517 - val_accuracy: 0.6983\n","Epoch 64/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4576 - accuracy: 0.9488 - val_loss: 0.9273 - val_accuracy: 0.7037\n","Epoch 65/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4575 - accuracy: 0.9477 - val_loss: 0.9482 - val_accuracy: 0.7069\n","Epoch 66/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4578 - accuracy: 0.9437 - val_loss: 0.9305 - val_accuracy: 0.7134\n","Epoch 67/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4455 - accuracy: 0.9582 - val_loss: 0.9426 - val_accuracy: 0.7026\n","Epoch 68/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4646 - accuracy: 0.9348 - val_loss: 0.9372 - val_accuracy: 0.7080\n","Epoch 69/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4497 - accuracy: 0.9496 - val_loss: 0.9505 - val_accuracy: 0.7058\n","Epoch 70/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4550 - accuracy: 0.9421 - val_loss: 0.9614 - val_accuracy: 0.6940\n","Epoch 71/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.4539 - accuracy: 0.9364 - val_loss: 0.9399 - val_accuracy: 0.7047\n","Epoch 72/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4502 - accuracy: 0.9491 - val_loss: 0.9498 - val_accuracy: 0.7026\n","Epoch 73/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4394 - accuracy: 0.9496 - val_loss: 0.9437 - val_accuracy: 0.7123\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4343 - accuracy: 0.9564 - val_loss: 0.9623 - val_accuracy: 0.7112\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4405 - accuracy: 0.9558 - val_loss: 0.9639 - val_accuracy: 0.7058\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4414 - accuracy: 0.9499 - val_loss: 0.9557 - val_accuracy: 0.7123\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4318 - accuracy: 0.9572 - val_loss: 1.0047 - val_accuracy: 0.6756\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4296 - accuracy: 0.9574 - val_loss: 0.9544 - val_accuracy: 0.7091\n","Epoch 79/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4277 - accuracy: 0.9580 - val_loss: 0.9621 - val_accuracy: 0.7144\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4198 - accuracy: 0.9644 - val_loss: 0.9630 - val_accuracy: 0.7134\n","Epoch 81/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4214 - accuracy: 0.9628 - val_loss: 0.9633 - val_accuracy: 0.7058\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4192 - accuracy: 0.9650 - val_loss: 0.9665 - val_accuracy: 0.7091\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4362 - accuracy: 0.9464 - val_loss: 0.9754 - val_accuracy: 0.7047\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4217 - accuracy: 0.9599 - val_loss: 0.9664 - val_accuracy: 0.7015\n","Epoch 85/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4145 - accuracy: 0.9634 - val_loss: 0.9857 - val_accuracy: 0.7112\n","Epoch 86/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4164 - accuracy: 0.9609 - val_loss: 0.9854 - val_accuracy: 0.7026\n","Epoch 87/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4210 - accuracy: 0.9537 - val_loss: 0.9734 - val_accuracy: 0.7026\n","Epoch 88/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4095 - accuracy: 0.9658 - val_loss: 0.9840 - val_accuracy: 0.7037\n","Epoch 89/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4121 - accuracy: 0.9634 - val_loss: 0.9894 - val_accuracy: 0.7047\n","Epoch 90/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4110 - accuracy: 0.9617 - val_loss: 0.9908 - val_accuracy: 0.7091\n","Epoch 91/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4011 - accuracy: 0.9693 - val_loss: 0.9829 - val_accuracy: 0.7155\n","Epoch 92/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4012 - accuracy: 0.9704 - val_loss: 1.0087 - val_accuracy: 0.6875\n","Epoch 93/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3993 - accuracy: 0.9712 - val_loss: 0.9969 - val_accuracy: 0.7058\n","Epoch 94/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3952 - accuracy: 0.9725 - val_loss: 1.0172 - val_accuracy: 0.6994\n","Epoch 95/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3994 - accuracy: 0.9709 - val_loss: 1.0018 - val_accuracy: 0.7015\n","Epoch 96/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3908 - accuracy: 0.9723 - val_loss: 0.9922 - val_accuracy: 0.7058\n","Epoch 97/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3919 - accuracy: 0.9739 - val_loss: 1.0001 - val_accuracy: 0.7037\n","Epoch 98/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3927 - accuracy: 0.9706 - val_loss: 1.0153 - val_accuracy: 0.7037\n","Epoch 99/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3861 - accuracy: 0.9747 - val_loss: 1.0096 - val_accuracy: 0.7026\n","Epoch 100/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3849 - accuracy: 0.9747 - val_loss: 1.0259 - val_accuracy: 0.7080\n","{'loss': [0.6791803240776062, 0.6257189512252808, 0.6411871910095215, 0.6491275429725647, 0.6134257912635803, 0.6120043992996216, 0.601679265499115, 0.6085378527641296, 0.6017729640007019, 0.59326171875, 0.5992823243141174, 0.5859823822975159, 0.5863775610923767, 0.5907037854194641, 0.5761348009109497, 0.5823007225990295, 0.5759656429290771, 0.5703799724578857, 0.5612873435020447, 0.5638530254364014, 0.5594332218170166, 0.5556062459945679, 0.5601240992546082, 0.5524195432662964, 0.5566903352737427, 0.5480862855911255, 0.5472196936607361, 0.5617287158966064, 0.5461940765380859, 0.5420492887496948, 0.5390932559967041, 0.5469814538955688, 0.5312207937240601, 0.545495867729187, 0.5324539542198181, 0.522566556930542, 0.5191677808761597, 0.5306732654571533, 0.5229019522666931, 0.5135042667388916, 0.5189869999885559, 0.5115728974342346, 0.5061826705932617, 0.5151875019073486, 0.49851739406585693, 0.5119449496269226, 0.5036988854408264, 0.5195573568344116, 0.4951474070549011, 0.4984591007232666, 0.5227198004722595, 0.5039631128311157, 0.5081828832626343, 0.47697359323501587, 0.47341883182525635, 0.47097647190093994, 0.47559741139411926, 0.4871733486652374, 0.46481192111968994, 0.4669294059276581, 0.46672961115837097, 0.46385109424591064, 0.45675259828567505, 0.4576263725757599, 0.45751965045928955, 0.4578220844268799, 0.44548678398132324, 0.4645899534225464, 0.4497005343437195, 0.45495858788490295, 0.4539331793785095, 0.4502057135105133, 0.439434289932251, 0.4342534840106964, 0.44050875306129456, 0.44142359495162964, 0.4317570924758911, 0.4295917749404907, 0.4277200400829315, 0.41977375745773315, 0.4213757812976837, 0.41919249296188354, 0.4361572563648224, 0.42173925042152405, 0.41445380449295044, 0.41644150018692017, 0.42097240686416626, 0.40950095653533936, 0.4120948612689972, 0.41101711988449097, 0.40114840865135193, 0.4012106955051422, 0.3993203639984131, 0.39523065090179443, 0.3993740975856781, 0.3907756507396698, 0.3918958306312561, 0.39270877838134766, 0.386145681142807, 0.38491666316986084], 'accuracy': [0.8095366358757019, 0.8539870977401733, 0.8383620977401733, 0.829472005367279, 0.8510237336158752, 0.8634159564971924, 0.8647629022598267, 0.857758641242981, 0.8612607717514038, 0.876347005367279, 0.8682650923728943, 0.8723060488700867, 0.8752694129943848, 0.8669180870056152, 0.8825430870056152, 0.8760775923728943, 0.8838900923728943, 0.8852370977401733, 0.8957435488700867, 0.8960129022598267, 0.8960129022598267, 0.8965517282485962, 0.8884698152542114, 0.8978987336158752, 0.8938577771186829, 0.9019396305084229, 0.9003232717514038, 0.8852370977401733, 0.8960129022598267, 0.90625, 0.9024784564971924, 0.8908944129943848, 0.9084051847457886, 0.8914331793785095, 0.9030172228813171, 0.9113685488700867, 0.9186422228813171, 0.9054418206214905, 0.9102909564971924, 0.9167564511299133, 0.9135237336158752, 0.9175646305084229, 0.923491358757019, 0.9102909564971924, 0.928340494632721, 0.915409505367279, 0.9172952771186829, 0.9022090435028076, 0.9261853694915771, 0.9224137663841248, 0.8978987336158752, 0.912715494632721, 0.9129849076271057, 0.9420797228813171, 0.9420797228813171, 0.9380387663841248, 0.9420797228813171, 0.9240301847457886, 0.9471982717514038, 0.9412715435028076, 0.9364224076271057, 0.9423491358757019, 0.9504310488700867, 0.9488146305084229, 0.9477370977401733, 0.943696141242981, 0.9582435488700867, 0.9348060488700867, 0.9496228694915771, 0.9420797228813171, 0.9364224076271057, 0.9490840435028076, 0.9496228694915771, 0.9563577771186829, 0.9558189511299133, 0.9498922228813171, 0.9571659564971924, 0.9574353694915771, 0.9579741358757019, 0.9644396305084229, 0.9628232717514038, 0.9649784564971924, 0.9463900923728943, 0.9598599076271057, 0.9633620977401733, 0.9609375, 0.9536637663841248, 0.9657866358757019, 0.9633620977401733, 0.9617456793785095, 0.9692887663841248, 0.970366358757019, 0.9711745977401733, 0.9725215435028076, 0.9709051847457886, 0.9722521305084229, 0.9738685488700867, 0.9706357717514038, 0.9746767282485962, 0.9746767282485962], 'val_loss': [1.01699960231781, 1.0194926261901855, 1.0272183418273926, 1.0411148071289062, 1.0469224452972412, 1.0669567584991455, 1.0786430835723877, 1.0979615449905396, 1.1105393171310425, 1.1624517440795898, 1.1313053369522095, 1.1676310300827026, 1.1306116580963135, 1.1143879890441895, 1.229934573173523, 1.1252970695495605, 1.1029480695724487, 0.9931620955467224, 1.016176462173462, 0.9429347515106201, 0.9277934432029724, 0.9273620843887329, 0.8870702981948853, 0.8945299983024597, 0.8704254627227783, 0.8697152733802795, 0.8775999546051025, 0.8686331510543823, 0.8774676322937012, 0.8705418109893799, 0.8740277290344238, 0.880231499671936, 0.9252554178237915, 0.8935993313789368, 0.9120033383369446, 0.8908136487007141, 0.9022168517112732, 0.9267677068710327, 0.888853907585144, 0.8932825326919556, 0.8974802494049072, 0.8970839977264404, 0.9505186676979065, 0.912868857383728, 0.9488091468811035, 0.9019421339035034, 0.9140324592590332, 0.933218777179718, 0.9159324765205383, 1.0347464084625244, 0.9082664251327515, 0.9463333487510681, 0.9239242672920227, 0.9153403043746948, 0.9200443625450134, 0.9619408845901489, 0.945650577545166, 0.9305222034454346, 0.93567955493927, 0.9319320917129517, 0.9215722680091858, 0.9191733002662659, 0.9517269730567932, 0.9272924065589905, 0.9481785297393799, 0.9305434823036194, 0.9426451325416565, 0.9372196793556213, 0.9505197405815125, 0.9613649249076843, 0.939910888671875, 0.949764609336853, 0.9436736702919006, 0.9623208045959473, 0.9639125466346741, 0.9556964635848999, 1.0046924352645874, 0.9543558955192566, 0.9620801210403442, 0.9629785418510437, 0.9633171558380127, 0.9665102958679199, 0.975430965423584, 0.9664276838302612, 0.9857021570205688, 0.9854094386100769, 0.9733783602714539, 0.9840039014816284, 0.9893859624862671, 0.9908121824264526, 0.9829351902008057, 1.0087084770202637, 0.9969276785850525, 1.0171583890914917, 1.0017664432525635, 0.9922317266464233, 1.0001319646835327, 1.0152714252471924, 1.0096122026443481, 1.0259069204330444], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48706895112991333, 0.48706895112991333, 0.48706895112991333, 0.4903017282485962, 0.49353447556495667, 0.5021551847457886, 0.5086206793785095, 0.5053879022598267, 0.5301724076271057, 0.5549569129943848, 0.5862069129943848, 0.5915948152542114, 0.631465494632721, 0.6476293206214905, 0.6605603694915771, 0.6756465435028076, 0.681034505367279, 0.7004310488700867, 0.7133620977401733, 0.7068965435028076, 0.7112069129943848, 0.6993534564971924, 0.7133620977401733, 0.7176724076271057, 0.7101293206214905, 0.6724137663841248, 0.6982758641242981, 0.7025862336158752, 0.712284505367279, 0.7025862336158752, 0.7079741358757019, 0.7068965435028076, 0.7176724076271057, 0.7144396305084229, 0.704741358757019, 0.6907327771186829, 0.6928879022598267, 0.6971982717514038, 0.7133620977401733, 0.6993534564971924, 0.7004310488700867, 0.7101293206214905, 0.649784505367279, 0.7144396305084229, 0.6885775923728943, 0.6961206793785095, 0.712284505367279, 0.7133620977401733, 0.6756465435028076, 0.701508641242981, 0.7068965435028076, 0.7058189511299133, 0.7133620977401733, 0.7144396305084229, 0.7112069129943848, 0.6982758641242981, 0.7036637663841248, 0.7068965435028076, 0.7133620977401733, 0.7025862336158752, 0.7079741358757019, 0.7058189511299133, 0.693965494632721, 0.704741358757019, 0.7025862336158752, 0.712284505367279, 0.7112069129943848, 0.7058189511299133, 0.712284505367279, 0.6756465435028076, 0.7090517282485962, 0.7144396305084229, 0.7133620977401733, 0.7058189511299133, 0.7090517282485962, 0.704741358757019, 0.701508641242981, 0.7112069129943848, 0.7025862336158752, 0.7025862336158752, 0.7036637663841248, 0.704741358757019, 0.7090517282485962, 0.7155172228813171, 0.6875, 0.7058189511299133, 0.6993534564971924, 0.701508641242981, 0.7058189511299133, 0.7036637663841248, 0.7036637663841248, 0.7025862336158752, 0.7079741358757019]}\n","38/38 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 30ms/step - loss: 0.6726 - accuracy: 0.8186 - val_loss: 1.0111 - val_accuracy: 0.4955\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.6389 - accuracy: 0.8516"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 14ms/step - loss: 0.6274 - accuracy: 0.8517 - val_loss: 1.0156 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6174 - accuracy: 0.8548 - val_loss: 1.0197 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.6066 - accuracy: 0.8656 - val_loss: 1.0305 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.6029 - accuracy: 0.8664 - val_loss: 1.0401 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6005 - accuracy: 0.8664 - val_loss: 1.0487 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5977 - accuracy: 0.8693 - val_loss: 1.0710 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6023 - accuracy: 0.8647 - val_loss: 1.0880 - val_accuracy: 0.4966\n","Epoch 9/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5902 - accuracy: 0.8735 - val_loss: 1.1075 - val_accuracy: 0.4966\n","Epoch 10/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5835 - accuracy: 0.8843 - val_loss: 1.1528 - val_accuracy: 0.4966\n","Epoch 11/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5815 - accuracy: 0.8795 - val_loss: 1.1840 - val_accuracy: 0.4966\n","Epoch 12/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5742 - accuracy: 0.8894 - val_loss: 1.2262 - val_accuracy: 0.4966\n","Epoch 13/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5754 - accuracy: 0.8826 - val_loss: 1.2342 - val_accuracy: 0.4989\n","Epoch 14/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5751 - accuracy: 0.8857 - val_loss: 1.2107 - val_accuracy: 0.5000\n","Epoch 15/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5718 - accuracy: 0.8848 - val_loss: 1.1769 - val_accuracy: 0.5147\n","Epoch 16/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5947 - accuracy: 0.8656 - val_loss: 1.0856 - val_accuracy: 0.5385\n","Epoch 17/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5770 - accuracy: 0.8823 - val_loss: 1.1706 - val_accuracy: 0.5351\n","Epoch 18/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5593 - accuracy: 0.8939 - val_loss: 1.0383 - val_accuracy: 0.5656\n","Epoch 19/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5575 - accuracy: 0.8945 - val_loss: 0.9343 - val_accuracy: 0.6267\n","Epoch 20/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5603 - accuracy: 0.8911 - val_loss: 0.9460 - val_accuracy: 0.6244\n","Epoch 21/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.5616 - accuracy: 0.8834 - val_loss: 0.9915 - val_accuracy: 0.6029\n","Epoch 22/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5567 - accuracy: 0.8930 - val_loss: 0.9068 - val_accuracy: 0.6629\n","Epoch 23/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5443 - accuracy: 0.9035 - val_loss: 0.8813 - val_accuracy: 0.6708\n","Epoch 24/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5602 - accuracy: 0.8814 - val_loss: 0.9229 - val_accuracy: 0.6550\n","Epoch 25/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5684 - accuracy: 0.8834 - val_loss: 0.9080 - val_accuracy: 0.6505\n","Epoch 26/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5428 - accuracy: 0.9004 - val_loss: 0.8871 - val_accuracy: 0.6980\n","Epoch 27/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.5443 - accuracy: 0.8947 - val_loss: 0.8676 - val_accuracy: 0.7048\n","Epoch 28/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.5325 - accuracy: 0.9078 - val_loss: 0.8563 - val_accuracy: 0.6934\n","Epoch 29/100\n","28/28 [==============================] - 1s 38ms/step - loss: 0.5308 - accuracy: 0.9111 - val_loss: 0.8489 - val_accuracy: 0.7081\n","Epoch 30/100\n","28/28 [==============================] - 1s 39ms/step - loss: 0.5263 - accuracy: 0.9160 - val_loss: 0.8516 - val_accuracy: 0.7093\n","Epoch 31/100\n","28/28 [==============================] - 1s 38ms/step - loss: 0.5222 - accuracy: 0.9134 - val_loss: 0.8441 - val_accuracy: 0.7161\n","Epoch 32/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5236 - accuracy: 0.9114 - val_loss: 0.9028 - val_accuracy: 0.6799\n","Epoch 33/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5234 - accuracy: 0.9117 - val_loss: 0.8506 - val_accuracy: 0.7138\n","Epoch 34/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5359 - accuracy: 0.9058 - val_loss: 0.8757 - val_accuracy: 0.6980\n","Epoch 35/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5151 - accuracy: 0.9196 - val_loss: 0.8676 - val_accuracy: 0.6991\n","Epoch 36/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5203 - accuracy: 0.9100 - val_loss: 0.8654 - val_accuracy: 0.7093\n","Epoch 37/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5327 - accuracy: 0.9012 - val_loss: 0.8610 - val_accuracy: 0.7115\n","Epoch 38/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5049 - accuracy: 0.9270 - val_loss: 0.8619 - val_accuracy: 0.7115\n","Epoch 39/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5081 - accuracy: 0.9225 - val_loss: 0.8880 - val_accuracy: 0.6900\n","Epoch 40/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5006 - accuracy: 0.9312 - val_loss: 0.8687 - val_accuracy: 0.7070\n","Epoch 41/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5010 - accuracy: 0.9228 - val_loss: 0.9316 - val_accuracy: 0.6765\n","Epoch 42/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5063 - accuracy: 0.9199 - val_loss: 0.8830 - val_accuracy: 0.6946\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4931 - accuracy: 0.9321 - val_loss: 0.9035 - val_accuracy: 0.7093\n","Epoch 44/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.5047 - accuracy: 0.9199 - val_loss: 0.8654 - val_accuracy: 0.7070\n","Epoch 45/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4919 - accuracy: 0.9315 - val_loss: 0.8784 - val_accuracy: 0.7014\n","Epoch 46/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4958 - accuracy: 0.9253 - val_loss: 0.9277 - val_accuracy: 0.6821\n","Epoch 47/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4944 - accuracy: 0.9219 - val_loss: 0.8705 - val_accuracy: 0.7104\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4897 - accuracy: 0.9295 - val_loss: 0.8765 - val_accuracy: 0.7025\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4888 - accuracy: 0.9267 - val_loss: 0.8883 - val_accuracy: 0.7036\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4811 - accuracy: 0.9355 - val_loss: 0.8771 - val_accuracy: 0.7070\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4768 - accuracy: 0.9386 - val_loss: 0.9194 - val_accuracy: 0.6810\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4688 - accuracy: 0.9465 - val_loss: 0.8855 - val_accuracy: 0.7048\n","Epoch 53/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4714 - accuracy: 0.9465 - val_loss: 0.8885 - val_accuracy: 0.7115\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4672 - accuracy: 0.9434 - val_loss: 0.8919 - val_accuracy: 0.6980\n","Epoch 55/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4730 - accuracy: 0.9352 - val_loss: 0.8992 - val_accuracy: 0.6991\n","Epoch 56/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4605 - accuracy: 0.9496 - val_loss: 0.9048 - val_accuracy: 0.7070\n","Epoch 57/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4636 - accuracy: 0.9434 - val_loss: 0.9267 - val_accuracy: 0.6923\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4607 - accuracy: 0.9451 - val_loss: 0.8837 - val_accuracy: 0.6980\n","Epoch 59/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4574 - accuracy: 0.9428 - val_loss: 0.8924 - val_accuracy: 0.7093\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4716 - accuracy: 0.9312 - val_loss: 0.9020 - val_accuracy: 0.7070\n","Epoch 61/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4599 - accuracy: 0.9423 - val_loss: 0.8967 - val_accuracy: 0.7025\n","Epoch 62/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4481 - accuracy: 0.9516 - val_loss: 0.9024 - val_accuracy: 0.6980\n","Epoch 63/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4508 - accuracy: 0.9477 - val_loss: 0.9036 - val_accuracy: 0.7002\n","Epoch 64/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4591 - accuracy: 0.9383 - val_loss: 0.9116 - val_accuracy: 0.7036\n","Epoch 65/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4444 - accuracy: 0.9516 - val_loss: 1.0118 - val_accuracy: 0.6753\n","Epoch 66/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4588 - accuracy: 0.9377 - val_loss: 0.9039 - val_accuracy: 0.7048\n","Epoch 67/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4445 - accuracy: 0.9519 - val_loss: 0.9182 - val_accuracy: 0.7002\n","Epoch 68/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4357 - accuracy: 0.9556 - val_loss: 0.9379 - val_accuracy: 0.6855\n","Epoch 69/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4360 - accuracy: 0.9519 - val_loss: 0.9499 - val_accuracy: 0.6923\n","Epoch 70/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4395 - accuracy: 0.9485 - val_loss: 0.9287 - val_accuracy: 0.7104\n","Epoch 71/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4302 - accuracy: 0.9587 - val_loss: 0.9117 - val_accuracy: 0.7093\n","Epoch 72/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4410 - accuracy: 0.9437 - val_loss: 0.9137 - val_accuracy: 0.7036\n","Epoch 73/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4323 - accuracy: 0.9505 - val_loss: 1.0468 - val_accuracy: 0.6640\n","Epoch 74/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4594 - accuracy: 0.9341 - val_loss: 0.9227 - val_accuracy: 0.7093\n","Epoch 75/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4299 - accuracy: 0.9542 - val_loss: 0.9225 - val_accuracy: 0.7048\n","Epoch 76/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4187 - accuracy: 0.9686 - val_loss: 0.9290 - val_accuracy: 0.6980\n","Epoch 77/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4197 - accuracy: 0.9590 - val_loss: 0.9215 - val_accuracy: 0.7036\n","Epoch 78/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4229 - accuracy: 0.9550 - val_loss: 0.9426 - val_accuracy: 0.7036\n","Epoch 79/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4431 - accuracy: 0.9389 - val_loss: 0.9496 - val_accuracy: 0.6957\n","Epoch 80/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4158 - accuracy: 0.9618 - val_loss: 1.0045 - val_accuracy: 0.6765\n","Epoch 81/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4166 - accuracy: 0.9578 - val_loss: 0.9827 - val_accuracy: 0.6776\n","Epoch 82/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4057 - accuracy: 0.9703 - val_loss: 0.9336 - val_accuracy: 0.7014\n","Epoch 83/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4072 - accuracy: 0.9663 - val_loss: 0.9802 - val_accuracy: 0.6867\n","Epoch 84/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4020 - accuracy: 0.9717 - val_loss: 0.9500 - val_accuracy: 0.7081\n","Epoch 85/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4004 - accuracy: 0.9689 - val_loss: 1.0025 - val_accuracy: 0.6776\n","Epoch 86/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4307 - accuracy: 0.9434 - val_loss: 0.9862 - val_accuracy: 0.7081\n","Epoch 87/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4010 - accuracy: 0.9694 - val_loss: 0.9483 - val_accuracy: 0.7036\n","Epoch 88/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3965 - accuracy: 0.9706 - val_loss: 1.0652 - val_accuracy: 0.6686\n","Epoch 89/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4153 - accuracy: 0.9547 - val_loss: 0.9596 - val_accuracy: 0.7048\n","Epoch 90/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3978 - accuracy: 0.9692 - val_loss: 0.9535 - val_accuracy: 0.7081\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3878 - accuracy: 0.9754 - val_loss: 0.9627 - val_accuracy: 0.6946\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3894 - accuracy: 0.9745 - val_loss: 0.9585 - val_accuracy: 0.6900\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3908 - accuracy: 0.9714 - val_loss: 0.9679 - val_accuracy: 0.6923\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3891 - accuracy: 0.9717 - val_loss: 1.0042 - val_accuracy: 0.6821\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3854 - accuracy: 0.9717 - val_loss: 0.9616 - val_accuracy: 0.7070\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3897 - accuracy: 0.9717 - val_loss: 0.9983 - val_accuracy: 0.6923\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3778 - accuracy: 0.9774 - val_loss: 0.9717 - val_accuracy: 0.6980\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3789 - accuracy: 0.9779 - val_loss: 0.9809 - val_accuracy: 0.6934\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3738 - accuracy: 0.9793 - val_loss: 0.9801 - val_accuracy: 0.6957\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3717 - accuracy: 0.9810 - val_loss: 1.0435 - val_accuracy: 0.6833\n","{'loss': [0.6726313829421997, 0.6274131536483765, 0.6174381971359253, 0.6066291928291321, 0.6028969287872314, 0.600466787815094, 0.5977076292037964, 0.6022641658782959, 0.5902348160743713, 0.5834901928901672, 0.5815186500549316, 0.5741678476333618, 0.5754480361938477, 0.5750510692596436, 0.5718108415603638, 0.5947429537773132, 0.5769760608673096, 0.5592608451843262, 0.5574935674667358, 0.5602773427963257, 0.5615770220756531, 0.5567167401313782, 0.5442759990692139, 0.5602018237113953, 0.5683830380439758, 0.5428333878517151, 0.5442796945571899, 0.5325345396995544, 0.5307526588439941, 0.5263075828552246, 0.5221617221832275, 0.5235592126846313, 0.523359477519989, 0.5358763933181763, 0.5151451230049133, 0.5203257203102112, 0.5327212810516357, 0.5049074292182922, 0.5080937147140503, 0.5005682706832886, 0.5010033249855042, 0.506298840045929, 0.49312469363212585, 0.5046996474266052, 0.4919487237930298, 0.4957900047302246, 0.4944356083869934, 0.48967069387435913, 0.4887552559375763, 0.481070339679718, 0.47676748037338257, 0.46880993247032166, 0.4714127480983734, 0.4671750068664551, 0.47298914194107056, 0.46045783162117004, 0.46363914012908936, 0.4606671631336212, 0.4573782682418823, 0.47156310081481934, 0.45989903807640076, 0.44809240102767944, 0.4507961869239807, 0.45905783772468567, 0.4444389343261719, 0.45884624123573303, 0.44450289011001587, 0.4357440173625946, 0.4359866678714752, 0.4395124316215515, 0.4301835894584656, 0.4409794211387634, 0.43229812383651733, 0.4593682289123535, 0.4298969507217407, 0.41867056488990784, 0.4197259247303009, 0.42294684052467346, 0.4430611729621887, 0.41582879424095154, 0.4166063368320465, 0.4057460129261017, 0.40717625617980957, 0.4019627869129181, 0.4003768861293793, 0.43071120977401733, 0.4010310173034668, 0.3965282142162323, 0.41531944274902344, 0.3978172838687897, 0.38779452443122864, 0.3893919885158539, 0.39083945751190186, 0.3891376256942749, 0.385390967130661, 0.3897426128387451, 0.37781405448913574, 0.37887585163116455, 0.3738153874874115, 0.371746689081192], 'accuracy': [0.8186191320419312, 0.8517261147499084, 0.8548387289047241, 0.8655914068222046, 0.8664402961730957, 0.8664402961730957, 0.8692699670791626, 0.8647425174713135, 0.8735144138336182, 0.8842670917510986, 0.8794566988945007, 0.8893604874610901, 0.8825693130493164, 0.8856819272041321, 0.884833037853241, 0.8655914068222046, 0.8822863698005676, 0.8938879370689392, 0.8944538831710815, 0.8910582661628723, 0.8834182024002075, 0.8930390477180481, 0.9035087823867798, 0.8814374804496765, 0.8834182024002075, 0.9003961682319641, 0.8947368264198303, 0.9077532291412354, 0.9111488461494446, 0.9159592390060425, 0.9134125709533691, 0.9114317893981934, 0.9117147922515869, 0.9057725071907043, 0.9196377992630005, 0.9100169539451599, 0.9012450575828552, 0.9269949197769165, 0.9224674701690674, 0.9312393665313721, 0.9227504134178162, 0.9199207425117493, 0.9320882558822632, 0.9199207425117493, 0.9315223693847656, 0.9252971410751343, 0.921901524066925, 0.9295415878295898, 0.926711916923523, 0.9354838728904724, 0.9385964870452881, 0.9465195536613464, 0.9465195536613464, 0.943406879901886, 0.9352009296417236, 0.9496321678161621, 0.943406879901886, 0.945104718208313, 0.9428409934043884, 0.9312393665313721, 0.9422750473022461, 0.9516128897666931, 0.9476513862609863, 0.9383135437965393, 0.9516128897666931, 0.937747597694397, 0.9518958926200867, 0.9555743932723999, 0.9518958926200867, 0.9485002756118774, 0.9586870670318604, 0.9436898827552795, 0.9504810571670532, 0.934069037437439, 0.9541596174240112, 0.9685908555984497, 0.9589700102806091, 0.9550085067749023, 0.9388794302940369, 0.961799681186676, 0.9578381180763245, 0.9702886343002319, 0.9663271307945251, 0.9717034697532654, 0.9688737988471985, 0.943406879901886, 0.9694397449493408, 0.9705715775489807, 0.9547255039215088, 0.9691567420959473, 0.9753820300102234, 0.9745330810546875, 0.9714204668998718, 0.9717034697532654, 0.9717034697532654, 0.9717034697532654, 0.9773627519607544, 0.9779286980628967, 0.9793435335159302, 0.9810413122177124], 'val_loss': [1.0110985040664673, 1.0155833959579468, 1.0196568965911865, 1.0304545164108276, 1.0401312112808228, 1.0487184524536133, 1.0710302591323853, 1.0880321264266968, 1.1074683666229248, 1.152791976928711, 1.1840264797210693, 1.2262282371520996, 1.2342064380645752, 1.2106744050979614, 1.176859974861145, 1.0856295824050903, 1.1705689430236816, 1.0383473634719849, 0.9342686533927917, 0.9459938406944275, 0.9915034174919128, 0.9067575335502625, 0.881331205368042, 0.9229366183280945, 0.9080009460449219, 0.8870726823806763, 0.8676226139068604, 0.8563341498374939, 0.848933219909668, 0.8515918254852295, 0.8441115021705627, 0.9028147459030151, 0.8506049513816833, 0.8756860494613647, 0.8675516247749329, 0.8653609752655029, 0.860974133014679, 0.8619385957717896, 0.8879995942115784, 0.8687043786048889, 0.9315887093544006, 0.8829665780067444, 0.9034971594810486, 0.8653547763824463, 0.8783512115478516, 0.927722156047821, 0.8705012202262878, 0.8765050172805786, 0.8883139491081238, 0.8770627379417419, 0.919372022151947, 0.8854783177375793, 0.8885303139686584, 0.8919363617897034, 0.8991940021514893, 0.9048070311546326, 0.9267404675483704, 0.8837264180183411, 0.8924264907836914, 0.9019849896430969, 0.8966991901397705, 0.9023939967155457, 0.903557300567627, 0.9115586876869202, 1.0117895603179932, 0.903937816619873, 0.9181971549987793, 0.9378872513771057, 0.9499057531356812, 0.9286646842956543, 0.9117146730422974, 0.9136676788330078, 1.0467586517333984, 0.9227491021156311, 0.9224762320518494, 0.9290368556976318, 0.9215332269668579, 0.9425967931747437, 0.9495648145675659, 1.0045188665390015, 0.9827282428741455, 0.9336256384849548, 0.9801980257034302, 0.9499920010566711, 1.0024919509887695, 0.9862269163131714, 0.9482617378234863, 1.0651919841766357, 0.9596008062362671, 0.9535251259803772, 0.9626619219779968, 0.9585161209106445, 0.9679431915283203, 1.0041797161102295, 0.9615823030471802, 0.998321533203125, 0.9717442393302917, 0.9809092283248901, 0.9801173210144043, 1.0435357093811035], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.49660632014274597, 0.49660632014274597, 0.49660632014274597, 0.49660632014274597, 0.49886876344680786, 0.5, 0.5147058963775635, 0.5384615659713745, 0.5350678563117981, 0.5656108856201172, 0.6266968250274658, 0.6244344115257263, 0.6029411554336548, 0.662895917892456, 0.6708144545555115, 0.6549773812294006, 0.6504524946212769, 0.6979637742042542, 0.7047511339187622, 0.6934388875961304, 0.7081447839736938, 0.709276020526886, 0.7160633206367493, 0.679864227771759, 0.7138009071350098, 0.6979637742042542, 0.6990950107574463, 0.709276020526886, 0.7115384340286255, 0.7115384340286255, 0.6900452375411987, 0.7070135474205017, 0.6764705777168274, 0.6945701241493225, 0.709276020526886, 0.7070135474205017, 0.7013574838638306, 0.6821267008781433, 0.7104072570800781, 0.7024886608123779, 0.7036198973655701, 0.7070135474205017, 0.6809954643249512, 0.7047511339187622, 0.7115384340286255, 0.6979637742042542, 0.6990950107574463, 0.7070135474205017, 0.692307710647583, 0.6979637742042542, 0.709276020526886, 0.7070135474205017, 0.7024886608123779, 0.6979637742042542, 0.7002262473106384, 0.7036198973655701, 0.6753393411636353, 0.7047511339187622, 0.7002262473106384, 0.685520350933075, 0.692307710647583, 0.7104072570800781, 0.709276020526886, 0.7036198973655701, 0.6640271544456482, 0.709276020526886, 0.7047511339187622, 0.6979637742042542, 0.7036198973655701, 0.7036198973655701, 0.6957013607025146, 0.6764705777168274, 0.6776018142700195, 0.7013574838638306, 0.6866515874862671, 0.7081447839736938, 0.6776018142700195, 0.7081447839736938, 0.7036198973655701, 0.668552041053772, 0.7047511339187622, 0.7081447839736938, 0.6945701241493225, 0.6900452375411987, 0.692307710647583, 0.6821267008781433, 0.7070135474205017, 0.692307710647583, 0.6979637742042542, 0.6934388875961304, 0.6957013607025146, 0.6832579374313354]}\n","45/45 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 4s 28ms/step - loss: 0.7033 - accuracy: 0.7933 - val_loss: 1.0198 - val_accuracy: 0.4855\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.6006 - accuracy: 0.8750"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 12ms/step - loss: 0.6449 - accuracy: 0.8398 - val_loss: 1.0253 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6451 - accuracy: 0.8313 - val_loss: 1.0381 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.6362 - accuracy: 0.8413 - val_loss: 1.0498 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.6312 - accuracy: 0.8401 - val_loss: 1.0635 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6240 - accuracy: 0.8499 - val_loss: 1.0828 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6154 - accuracy: 0.8571 - val_loss: 1.0905 - val_accuracy: 0.4866\n","Epoch 8/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6227 - accuracy: 0.8450 - val_loss: 1.1285 - val_accuracy: 0.4866\n","Epoch 9/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6114 - accuracy: 0.8592 - val_loss: 1.1785 - val_accuracy: 0.4866\n","Epoch 10/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6171 - accuracy: 0.8543 - val_loss: 1.1800 - val_accuracy: 0.4866\n","Epoch 11/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6028 - accuracy: 0.8618 - val_loss: 1.2592 - val_accuracy: 0.4866\n","Epoch 12/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6251 - accuracy: 0.8470 - val_loss: 1.1964 - val_accuracy: 0.4928\n","Epoch 13/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6096 - accuracy: 0.8496 - val_loss: 1.2533 - val_accuracy: 0.4938\n","Epoch 14/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5961 - accuracy: 0.8690 - val_loss: 1.2431 - val_accuracy: 0.4959\n","Epoch 15/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5987 - accuracy: 0.8651 - val_loss: 1.1661 - val_accuracy: 0.5165\n","Epoch 16/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5862 - accuracy: 0.8724 - val_loss: 1.1049 - val_accuracy: 0.5506\n","Epoch 17/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5862 - accuracy: 0.8716 - val_loss: 1.0189 - val_accuracy: 0.5847\n","Epoch 18/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5903 - accuracy: 0.8654 - val_loss: 0.9249 - val_accuracy: 0.6436\n","Epoch 19/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5954 - accuracy: 0.8687 - val_loss: 0.9854 - val_accuracy: 0.6198\n","Epoch 20/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5847 - accuracy: 0.8804 - val_loss: 0.9956 - val_accuracy: 0.6209\n","Epoch 21/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5849 - accuracy: 0.8711 - val_loss: 0.8911 - val_accuracy: 0.6674\n","Epoch 22/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5991 - accuracy: 0.8597 - val_loss: 0.9202 - val_accuracy: 0.6591\n","Epoch 23/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5790 - accuracy: 0.8765 - val_loss: 0.9008 - val_accuracy: 0.6839\n","Epoch 24/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5951 - accuracy: 0.8628 - val_loss: 0.9139 - val_accuracy: 0.6911\n","Epoch 25/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5681 - accuracy: 0.8881 - val_loss: 0.8930 - val_accuracy: 0.6983\n","Epoch 26/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5686 - accuracy: 0.8845 - val_loss: 0.9567 - val_accuracy: 0.6705\n","Epoch 27/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5641 - accuracy: 0.8819 - val_loss: 0.9760 - val_accuracy: 0.6622\n","Epoch 28/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5851 - accuracy: 0.8716 - val_loss: 0.9035 - val_accuracy: 0.7035\n","Epoch 29/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5572 - accuracy: 0.8910 - val_loss: 0.9359 - val_accuracy: 0.6983\n","Epoch 30/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5906 - accuracy: 0.8574 - val_loss: 0.9269 - val_accuracy: 0.6932\n","Epoch 31/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5632 - accuracy: 0.8855 - val_loss: 0.9367 - val_accuracy: 0.6932\n","Epoch 32/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5671 - accuracy: 0.8773 - val_loss: 0.9288 - val_accuracy: 0.6983\n","Epoch 33/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5458 - accuracy: 0.9070 - val_loss: 0.9253 - val_accuracy: 0.6932\n","Epoch 34/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5497 - accuracy: 0.8930 - val_loss: 0.9218 - val_accuracy: 0.6973\n","Epoch 35/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5482 - accuracy: 0.8917 - val_loss: 0.9425 - val_accuracy: 0.7014\n","Epoch 36/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5484 - accuracy: 0.8925 - val_loss: 0.9565 - val_accuracy: 0.6911\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5386 - accuracy: 0.9008 - val_loss: 0.9492 - val_accuracy: 0.6911\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5390 - accuracy: 0.8956 - val_loss: 0.9496 - val_accuracy: 0.6932\n","Epoch 39/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5317 - accuracy: 0.9075 - val_loss: 0.9326 - val_accuracy: 0.6911\n","Epoch 40/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5297 - accuracy: 0.9028 - val_loss: 0.9758 - val_accuracy: 0.6870\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5327 - accuracy: 0.9023 - val_loss: 0.9787 - val_accuracy: 0.6921\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5376 - accuracy: 0.9008 - val_loss: 0.9816 - val_accuracy: 0.6829\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5308 - accuracy: 0.9021 - val_loss: 0.9692 - val_accuracy: 0.6818\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5259 - accuracy: 0.9098 - val_loss: 0.9491 - val_accuracy: 0.6942\n","Epoch 45/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5163 - accuracy: 0.9109 - val_loss: 0.9597 - val_accuracy: 0.6921\n","Epoch 46/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5184 - accuracy: 0.9103 - val_loss: 0.9509 - val_accuracy: 0.7025\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5139 - accuracy: 0.9165 - val_loss: 0.9537 - val_accuracy: 0.6994\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5122 - accuracy: 0.9178 - val_loss: 0.9474 - val_accuracy: 0.6963\n","Epoch 49/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5227 - accuracy: 0.9034 - val_loss: 0.9726 - val_accuracy: 0.6921\n","Epoch 50/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5195 - accuracy: 0.9070 - val_loss: 0.9686 - val_accuracy: 0.6994\n","Epoch 51/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5021 - accuracy: 0.9227 - val_loss: 0.9806 - val_accuracy: 0.6839\n","Epoch 52/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5017 - accuracy: 0.9238 - val_loss: 0.9595 - val_accuracy: 0.6932\n","Epoch 53/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5052 - accuracy: 0.9121 - val_loss: 1.0191 - val_accuracy: 0.6777\n","Epoch 54/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.5224 - accuracy: 0.8979 - val_loss: 0.9644 - val_accuracy: 0.6983\n","Epoch 55/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.5032 - accuracy: 0.9176 - val_loss: 0.9696 - val_accuracy: 0.6942\n","Epoch 56/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4895 - accuracy: 0.9284 - val_loss: 0.9864 - val_accuracy: 0.6829\n","Epoch 57/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4999 - accuracy: 0.9142 - val_loss: 0.9740 - val_accuracy: 0.6890\n","Epoch 58/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4941 - accuracy: 0.9222 - val_loss: 0.9722 - val_accuracy: 0.7004\n","Epoch 59/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4873 - accuracy: 0.9264 - val_loss: 0.9757 - val_accuracy: 0.6942\n","Epoch 60/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4820 - accuracy: 0.9326 - val_loss: 1.0092 - val_accuracy: 0.6890\n","Epoch 61/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5081 - accuracy: 0.9065 - val_loss: 0.9744 - val_accuracy: 0.6932\n","Epoch 62/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4832 - accuracy: 0.9248 - val_loss: 1.0114 - val_accuracy: 0.6870\n","Epoch 63/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4729 - accuracy: 0.9346 - val_loss: 0.9757 - val_accuracy: 0.6973\n","Epoch 64/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4781 - accuracy: 0.9310 - val_loss: 1.0369 - val_accuracy: 0.6756\n","Epoch 65/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4811 - accuracy: 0.9264 - val_loss: 0.9868 - val_accuracy: 0.6890\n","Epoch 66/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4687 - accuracy: 0.9372 - val_loss: 1.0246 - val_accuracy: 0.6808\n","Epoch 67/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4771 - accuracy: 0.9297 - val_loss: 0.9952 - val_accuracy: 0.6932\n","Epoch 68/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4770 - accuracy: 0.9256 - val_loss: 0.9863 - val_accuracy: 0.6901\n","Epoch 69/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4866 - accuracy: 0.9240 - val_loss: 0.9859 - val_accuracy: 0.6963\n","Epoch 70/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4601 - accuracy: 0.9406 - val_loss: 0.9933 - val_accuracy: 0.6921\n","Epoch 71/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4615 - accuracy: 0.9416 - val_loss: 1.0013 - val_accuracy: 0.6911\n","Epoch 72/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4559 - accuracy: 0.9463 - val_loss: 1.0049 - val_accuracy: 0.6963\n","Epoch 73/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4517 - accuracy: 0.9460 - val_loss: 1.0358 - val_accuracy: 0.6777\n","Epoch 74/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4777 - accuracy: 0.9225 - val_loss: 1.0405 - val_accuracy: 0.6798\n","Epoch 75/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4663 - accuracy: 0.9287 - val_loss: 1.0019 - val_accuracy: 0.6932\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4606 - accuracy: 0.9393 - val_loss: 1.0072 - val_accuracy: 0.6963\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4494 - accuracy: 0.9439 - val_loss: 1.0413 - val_accuracy: 0.6849\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4451 - accuracy: 0.9468 - val_loss: 1.0617 - val_accuracy: 0.6674\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4439 - accuracy: 0.9439 - val_loss: 1.0173 - val_accuracy: 0.6911\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4357 - accuracy: 0.9525 - val_loss: 1.0467 - val_accuracy: 0.6901\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4460 - accuracy: 0.9452 - val_loss: 1.0318 - val_accuracy: 0.6942\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4358 - accuracy: 0.9530 - val_loss: 1.0208 - val_accuracy: 0.6829\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4333 - accuracy: 0.9512 - val_loss: 1.0266 - val_accuracy: 0.6911\n","Epoch 84/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4391 - accuracy: 0.9434 - val_loss: 1.0420 - val_accuracy: 0.6870\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4336 - accuracy: 0.9522 - val_loss: 1.0473 - val_accuracy: 0.6870\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4342 - accuracy: 0.9491 - val_loss: 1.0712 - val_accuracy: 0.6808\n","Epoch 87/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4394 - accuracy: 0.9450 - val_loss: 1.0288 - val_accuracy: 0.6952\n","Epoch 88/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4297 - accuracy: 0.9496 - val_loss: 1.1270 - val_accuracy: 0.6632\n","Epoch 89/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4445 - accuracy: 0.9413 - val_loss: 1.0369 - val_accuracy: 0.6901\n","Epoch 90/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4292 - accuracy: 0.9532 - val_loss: 1.0472 - val_accuracy: 0.6829\n","Epoch 91/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4314 - accuracy: 0.9481 - val_loss: 1.0602 - val_accuracy: 0.6911\n","Epoch 92/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4188 - accuracy: 0.9605 - val_loss: 1.0502 - val_accuracy: 0.6942\n","Epoch 93/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4216 - accuracy: 0.9558 - val_loss: 1.0516 - val_accuracy: 0.6952\n","Epoch 94/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4162 - accuracy: 0.9620 - val_loss: 1.0614 - val_accuracy: 0.6860\n","Epoch 95/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4225 - accuracy: 0.9506 - val_loss: 1.0592 - val_accuracy: 0.6849\n","Epoch 96/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4097 - accuracy: 0.9620 - val_loss: 1.0725 - val_accuracy: 0.6860\n","Epoch 97/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4070 - accuracy: 0.9633 - val_loss: 1.0668 - val_accuracy: 0.6839\n","Epoch 98/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4058 - accuracy: 0.9672 - val_loss: 1.1035 - val_accuracy: 0.6818\n","Epoch 99/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4077 - accuracy: 0.9612 - val_loss: 1.0626 - val_accuracy: 0.6952\n","Epoch 100/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4028 - accuracy: 0.9685 - val_loss: 1.0652 - val_accuracy: 0.6952\n","{'loss': [0.7033085227012634, 0.6449277997016907, 0.6450979113578796, 0.6361558437347412, 0.6312400102615356, 0.6240078806877136, 0.6154321432113647, 0.6226800680160522, 0.6114024519920349, 0.6170974373817444, 0.6028285622596741, 0.6251176595687866, 0.6095882654190063, 0.59609055519104, 0.5987420678138733, 0.5862242579460144, 0.5861609578132629, 0.5902708768844604, 0.5954126715660095, 0.5846607685089111, 0.5848520398139954, 0.5991321802139282, 0.5790287256240845, 0.5950698852539062, 0.5680537223815918, 0.5685544610023499, 0.5640811920166016, 0.5850548148155212, 0.557228684425354, 0.5906355977058411, 0.5631937980651855, 0.5671047568321228, 0.5458138585090637, 0.5496662259101868, 0.548208475112915, 0.5483976006507874, 0.5386037230491638, 0.5389998555183411, 0.5317250490188599, 0.5296956300735474, 0.5326752662658691, 0.5375628471374512, 0.530826985836029, 0.5259302854537964, 0.5162968635559082, 0.5183912515640259, 0.5139314532279968, 0.5121915340423584, 0.5226889252662659, 0.5195387601852417, 0.5020752549171448, 0.5017247796058655, 0.5052241086959839, 0.5223937034606934, 0.5031958818435669, 0.48951655626296997, 0.49989524483680725, 0.4940668046474457, 0.4873313009738922, 0.4819633662700653, 0.5081390142440796, 0.48322999477386475, 0.4729122519493103, 0.4781395494937897, 0.481148898601532, 0.4686517119407654, 0.4770844876766205, 0.47701138257980347, 0.48658207058906555, 0.460073322057724, 0.46149367094039917, 0.4559440612792969, 0.4517403244972229, 0.47773605585098267, 0.4662528932094574, 0.46058887243270874, 0.44943273067474365, 0.4450986981391907, 0.4438968002796173, 0.4357309937477112, 0.4459589719772339, 0.43579211831092834, 0.4332634210586548, 0.4391423761844635, 0.43364080786705017, 0.4342356324195862, 0.43937307596206665, 0.4297229051589966, 0.4444865584373474, 0.4292018711566925, 0.4313637614250183, 0.41884657740592957, 0.4215695261955261, 0.416171133518219, 0.42253151535987854, 0.4096682071685791, 0.4070222079753876, 0.405758261680603, 0.40769249200820923, 0.4027995765209198], 'accuracy': [0.7932816743850708, 0.8397932648658752, 0.8312661647796631, 0.8413436412811279, 0.8400516510009766, 0.8498708009719849, 0.8571059703826904, 0.8449612259864807, 0.8591731190681458, 0.8542635440826416, 0.8617570996284485, 0.8470284342765808, 0.8496124148368835, 0.868992269039154, 0.8651162981987, 0.8723514080047607, 0.8715762495994568, 0.8653746843338013, 0.868733823299408, 0.8803617358207703, 0.8710594177246094, 0.8596899509429932, 0.8764857649803162, 0.8627907037734985, 0.8881136775016785, 0.8844961524009705, 0.8819121718406677, 0.8715762495994568, 0.8909560441970825, 0.8573643565177917, 0.8855296969413757, 0.8772609829902649, 0.9069767594337463, 0.8930232524871826, 0.8917312622070312, 0.89250648021698, 0.9007751941680908, 0.8956072330474854, 0.907493531703949, 0.9028424024581909, 0.9023255705833435, 0.9007751941680908, 0.9020671844482422, 0.9098191261291504, 0.9108527302742004, 0.910335898399353, 0.9165374636650085, 0.9178294539451599, 0.9033591747283936, 0.9069767594337463, 0.9227390289306641, 0.9237726330757141, 0.9121447205543518, 0.8979328274726868, 0.9175710678100586, 0.9284237623214722, 0.9142118692398071, 0.9222221970558167, 0.9263566136360168, 0.9325581192970276, 0.9064599275588989, 0.9248061776161194, 0.9346253275871277, 0.9310077428817749, 0.9263566136360168, 0.9372093081474304, 0.9297157526016235, 0.9255813956260681, 0.9240310192108154, 0.9405684471130371, 0.9416020512580872, 0.94625324010849, 0.9459948539733887, 0.9224806427955627, 0.9286821484565735, 0.9392764568328857, 0.9439276456832886, 0.9467700123786926, 0.9439276456832886, 0.9524548053741455, 0.9452196359634399, 0.9529715776443481, 0.9511628150939941, 0.9434108734130859, 0.9521963596343994, 0.949095606803894, 0.9449612498283386, 0.9496123790740967, 0.9413436651229858, 0.9532299637794495, 0.948062002658844, 0.960465133190155, 0.9558139443397522, 0.9620155096054077, 0.9506459832191467, 0.9620155096054077, 0.9633074998855591, 0.9671834707260132, 0.961240291595459, 0.9684754610061646], 'val_loss': [1.0197632312774658, 1.0253233909606934, 1.0380710363388062, 1.0497885942459106, 1.0634996891021729, 1.0828310251235962, 1.0904675722122192, 1.1284607648849487, 1.1785274744033813, 1.180004596710205, 1.2591617107391357, 1.1964049339294434, 1.2533087730407715, 1.24305260181427, 1.166069746017456, 1.10493004322052, 1.018889307975769, 0.9248617887496948, 0.9854027032852173, 0.9956231117248535, 0.8911428451538086, 0.9201826453208923, 0.9007691144943237, 0.9138818383216858, 0.8930040001869202, 0.9567255973815918, 0.9760223627090454, 0.9034895300865173, 0.9358596801757812, 0.9269233345985413, 0.9366518259048462, 0.9287939071655273, 0.925309419631958, 0.9218376874923706, 0.9424875974655151, 0.9565064907073975, 0.9491510391235352, 0.9496333599090576, 0.9326369762420654, 0.9758080840110779, 0.9787093997001648, 0.9816362857818604, 0.9691969752311707, 0.9490923881530762, 0.9596831202507019, 0.9509238600730896, 0.9537221193313599, 0.9474475383758545, 0.9725871682167053, 0.968590259552002, 0.9806421399116516, 0.9594941139221191, 1.0190984010696411, 0.9643908143043518, 0.9696140289306641, 0.9863508343696594, 0.9740039706230164, 0.9721774458885193, 0.9757131934165955, 1.0092180967330933, 0.9743930697441101, 1.0113649368286133, 0.9757099151611328, 1.0369296073913574, 0.9868482351303101, 1.0245617628097534, 0.9951877593994141, 0.9863132238388062, 0.9858542680740356, 0.9933188557624817, 1.0013209581375122, 1.0049291849136353, 1.035766839981079, 1.040515422821045, 1.0018516778945923, 1.0071691274642944, 1.041325330734253, 1.0617002248764038, 1.0173355340957642, 1.0466887950897217, 1.0318052768707275, 1.0207856893539429, 1.0265544652938843, 1.041953682899475, 1.0473307371139526, 1.0711841583251953, 1.0288052558898926, 1.1269774436950684, 1.0368999242782593, 1.0472047328948975, 1.0602091550827026, 1.050209879875183, 1.0516126155853271, 1.061375379562378, 1.0592200756072998, 1.072467565536499, 1.066802978515625, 1.1035195589065552, 1.0625929832458496, 1.065192461013794], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.48657023906707764, 0.48657023906707764, 0.48657023906707764, 0.48657023906707764, 0.4927685856819153, 0.49380165338516235, 0.4958677589893341, 0.5165289044380188, 0.5506198406219482, 0.5847107172012329, 0.6435950398445129, 0.6198347210884094, 0.6208677887916565, 0.6673553586006165, 0.6590909361839294, 0.68388432264328, 0.69111567735672, 0.6983470916748047, 0.6704545617103577, 0.6621900796890259, 0.7035123705863953, 0.6983470916748047, 0.6931818127632141, 0.6931818127632141, 0.6983470916748047, 0.6931818127632141, 0.6973140239715576, 0.7014462947845459, 0.69111567735672, 0.69111567735672, 0.6931818127632141, 0.69111567735672, 0.6869834661483765, 0.692148745059967, 0.682851254940033, 0.6818181872367859, 0.6942148804664612, 0.692148745059967, 0.702479362487793, 0.6993801593780518, 0.6962810158729553, 0.692148745059967, 0.6993801593780518, 0.68388432264328, 0.6931818127632141, 0.6776859760284424, 0.6983470916748047, 0.6942148804664612, 0.682851254940033, 0.6890496015548706, 0.7004132270812988, 0.6942148804664612, 0.6890496015548706, 0.6931818127632141, 0.6869834661483765, 0.6973140239715576, 0.6756198406219482, 0.6890496015548706, 0.6807851195335388, 0.6931818127632141, 0.6900826692581177, 0.6962810158729553, 0.692148745059967, 0.69111567735672, 0.6962810158729553, 0.6776859760284424, 0.6797520518302917, 0.6931818127632141, 0.6962810158729553, 0.6849173307418823, 0.6673553586006165, 0.69111567735672, 0.6900826692581177, 0.6942148804664612, 0.682851254940033, 0.69111567735672, 0.6869834661483765, 0.6869834661483765, 0.6807851195335388, 0.6952479481697083, 0.663223147392273, 0.6900826692581177, 0.682851254940033, 0.69111567735672, 0.6942148804664612, 0.6952479481697083, 0.6859503984451294, 0.6849173307418823, 0.6859503984451294, 0.68388432264328, 0.6818181872367859, 0.6952479481697083, 0.6952479481697083]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 5s 28ms/step - loss: 0.5271 - accuracy: 0.8860 - val_loss: 1.0596 - val_accuracy: 0.4849\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.4584 - accuracy: 0.9062"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 10ms/step - loss: 0.4797 - accuracy: 0.9165 - val_loss: 1.0698 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4747 - accuracy: 0.9227 - val_loss: 1.0814 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4718 - accuracy: 0.9189 - val_loss: 1.0960 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4682 - accuracy: 0.9316 - val_loss: 1.1173 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4519 - accuracy: 0.9375 - val_loss: 1.1665 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4423 - accuracy: 0.9472 - val_loss: 1.1734 - val_accuracy: 0.4860\n","Epoch 8/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4431 - accuracy: 0.9434 - val_loss: 1.2163 - val_accuracy: 0.4871\n","Epoch 9/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4382 - accuracy: 0.9456 - val_loss: 1.2744 - val_accuracy: 0.4871\n","Epoch 10/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4368 - accuracy: 0.9475 - val_loss: 1.3613 - val_accuracy: 0.4871\n","Epoch 11/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4766 - accuracy: 0.9138 - val_loss: 1.3844 - val_accuracy: 0.4903\n","Epoch 12/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.4509 - accuracy: 0.9353 - val_loss: 1.4469 - val_accuracy: 0.4903\n","Epoch 13/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4292 - accuracy: 0.9491 - val_loss: 1.3947 - val_accuracy: 0.5043\n","Epoch 14/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4305 - accuracy: 0.9539 - val_loss: 1.4304 - val_accuracy: 0.5065\n","Epoch 15/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4221 - accuracy: 0.9545 - val_loss: 1.3959 - val_accuracy: 0.5237\n","Epoch 16/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4178 - accuracy: 0.9620 - val_loss: 1.3641 - val_accuracy: 0.5431\n","Epoch 17/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4210 - accuracy: 0.9534 - val_loss: 1.2464 - val_accuracy: 0.5679\n","Epoch 18/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4157 - accuracy: 0.9599 - val_loss: 1.1949 - val_accuracy: 0.5894\n","Epoch 19/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4200 - accuracy: 0.9545 - val_loss: 1.1614 - val_accuracy: 0.6099\n","Epoch 20/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4097 - accuracy: 0.9623 - val_loss: 1.0664 - val_accuracy: 0.6422\n","Epoch 21/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4094 - accuracy: 0.9623 - val_loss: 0.9676 - val_accuracy: 0.6681\n","Epoch 22/100\n","29/29 [==============================] - 1s 37ms/step - loss: 0.4069 - accuracy: 0.9650 - val_loss: 0.9405 - val_accuracy: 0.6950\n","Epoch 23/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4087 - accuracy: 0.9582 - val_loss: 0.9676 - val_accuracy: 0.6950\n","Epoch 24/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4223 - accuracy: 0.9483 - val_loss: 0.8969 - val_accuracy: 0.7241\n","Epoch 25/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4050 - accuracy: 0.9634 - val_loss: 0.8634 - val_accuracy: 0.7392\n","Epoch 26/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3996 - accuracy: 0.9663 - val_loss: 0.8784 - val_accuracy: 0.7252\n","Epoch 27/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3926 - accuracy: 0.9728 - val_loss: 0.8501 - val_accuracy: 0.7446\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3973 - accuracy: 0.9671 - val_loss: 0.8463 - val_accuracy: 0.7403\n","Epoch 29/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3957 - accuracy: 0.9655 - val_loss: 0.8531 - val_accuracy: 0.7522\n","Epoch 30/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3974 - accuracy: 0.9650 - val_loss: 0.8764 - val_accuracy: 0.7629\n","Epoch 31/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3980 - accuracy: 0.9596 - val_loss: 0.9113 - val_accuracy: 0.7220\n","Epoch 32/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3997 - accuracy: 0.9615 - val_loss: 0.8782 - val_accuracy: 0.7543\n","Epoch 33/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3847 - accuracy: 0.9739 - val_loss: 0.8583 - val_accuracy: 0.7705\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3835 - accuracy: 0.9723 - val_loss: 0.9122 - val_accuracy: 0.7338\n","Epoch 35/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3835 - accuracy: 0.9731 - val_loss: 0.8878 - val_accuracy: 0.7672\n","Epoch 36/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3976 - accuracy: 0.9636 - val_loss: 0.8803 - val_accuracy: 0.7565\n","Epoch 37/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3984 - accuracy: 0.9601 - val_loss: 0.8798 - val_accuracy: 0.7629\n","Epoch 38/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3735 - accuracy: 0.9752 - val_loss: 0.8919 - val_accuracy: 0.7532\n","Epoch 39/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3744 - accuracy: 0.9741 - val_loss: 0.8946 - val_accuracy: 0.7575\n","Epoch 40/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3714 - accuracy: 0.9795 - val_loss: 0.8935 - val_accuracy: 0.7640\n","Epoch 41/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3769 - accuracy: 0.9731 - val_loss: 0.8960 - val_accuracy: 0.7662\n","Epoch 42/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3746 - accuracy: 0.9733 - val_loss: 0.8941 - val_accuracy: 0.7619\n","Epoch 43/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3715 - accuracy: 0.9771 - val_loss: 0.8852 - val_accuracy: 0.7662\n","Epoch 44/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3893 - accuracy: 0.9655 - val_loss: 0.9096 - val_accuracy: 0.7608\n","Epoch 45/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3769 - accuracy: 0.9688 - val_loss: 0.9135 - val_accuracy: 0.7532\n","Epoch 46/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3672 - accuracy: 0.9771 - val_loss: 0.9237 - val_accuracy: 0.7597\n","Epoch 47/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3638 - accuracy: 0.9793 - val_loss: 0.9022 - val_accuracy: 0.7619\n","Epoch 48/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3575 - accuracy: 0.9803 - val_loss: 0.9156 - val_accuracy: 0.7608\n","Epoch 49/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3623 - accuracy: 0.9809 - val_loss: 0.8989 - val_accuracy: 0.7640\n","Epoch 50/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3818 - accuracy: 0.9658 - val_loss: 0.9558 - val_accuracy: 0.7425\n","Epoch 51/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3597 - accuracy: 0.9787 - val_loss: 0.9410 - val_accuracy: 0.7511\n","Epoch 52/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3537 - accuracy: 0.9822 - val_loss: 0.9487 - val_accuracy: 0.7543\n","Epoch 53/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3574 - accuracy: 0.9787 - val_loss: 0.9155 - val_accuracy: 0.7543\n","Epoch 54/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3523 - accuracy: 0.9833 - val_loss: 0.9387 - val_accuracy: 0.7522\n","Epoch 55/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3497 - accuracy: 0.9846 - val_loss: 0.9287 - val_accuracy: 0.7619\n","Epoch 56/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3532 - accuracy: 0.9838 - val_loss: 0.9178 - val_accuracy: 0.7554\n","Epoch 57/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3473 - accuracy: 0.9841 - val_loss: 0.9397 - val_accuracy: 0.7511\n","Epoch 58/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3478 - accuracy: 0.9855 - val_loss: 0.9170 - val_accuracy: 0.7532\n","Epoch 59/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3432 - accuracy: 0.9868 - val_loss: 0.9255 - val_accuracy: 0.7629\n","Epoch 60/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3463 - accuracy: 0.9838 - val_loss: 0.9694 - val_accuracy: 0.7565\n","Epoch 61/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3471 - accuracy: 0.9836 - val_loss: 0.9303 - val_accuracy: 0.7619\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3456 - accuracy: 0.9852 - val_loss: 0.9345 - val_accuracy: 0.7575\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3521 - accuracy: 0.9803 - val_loss: 0.9395 - val_accuracy: 0.7522\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3444 - accuracy: 0.9846 - val_loss: 0.9337 - val_accuracy: 0.7554\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3432 - accuracy: 0.9855 - val_loss: 0.9330 - val_accuracy: 0.7597\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3447 - accuracy: 0.9855 - val_loss: 0.9327 - val_accuracy: 0.7554\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3543 - accuracy: 0.9736 - val_loss: 1.0404 - val_accuracy: 0.7468\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3406 - accuracy: 0.9830 - val_loss: 0.9398 - val_accuracy: 0.7522\n","Epoch 69/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3386 - accuracy: 0.9852 - val_loss: 1.0230 - val_accuracy: 0.7371\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3381 - accuracy: 0.9841 - val_loss: 1.0664 - val_accuracy: 0.7317\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3487 - accuracy: 0.9811 - val_loss: 0.9745 - val_accuracy: 0.7511\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3333 - accuracy: 0.9863 - val_loss: 0.9784 - val_accuracy: 0.7554\n","Epoch 73/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3332 - accuracy: 0.9876 - val_loss: 0.9584 - val_accuracy: 0.7575\n","Epoch 74/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3264 - accuracy: 0.9890 - val_loss: 0.9599 - val_accuracy: 0.7511\n","Epoch 75/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3260 - accuracy: 0.9908 - val_loss: 0.9601 - val_accuracy: 0.7575\n","Epoch 76/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3298 - accuracy: 0.9871 - val_loss: 0.9821 - val_accuracy: 0.7532\n","Epoch 77/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3253 - accuracy: 0.9906 - val_loss: 0.9708 - val_accuracy: 0.7511\n","Epoch 78/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3214 - accuracy: 0.9922 - val_loss: 0.9901 - val_accuracy: 0.7489\n","Epoch 79/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3295 - accuracy: 0.9887 - val_loss: 0.9998 - val_accuracy: 0.7522\n","Epoch 80/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3250 - accuracy: 0.9898 - val_loss: 0.9963 - val_accuracy: 0.7554\n","Epoch 81/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3291 - accuracy: 0.9871 - val_loss: 0.9844 - val_accuracy: 0.7511\n","Epoch 82/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3457 - accuracy: 0.9790 - val_loss: 1.1520 - val_accuracy: 0.7123\n","Epoch 83/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3453 - accuracy: 0.9760 - val_loss: 1.0894 - val_accuracy: 0.7306\n","Epoch 84/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3471 - accuracy: 0.9771 - val_loss: 1.0433 - val_accuracy: 0.7381\n","Epoch 85/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3278 - accuracy: 0.9860 - val_loss: 1.0661 - val_accuracy: 0.7457\n","Epoch 86/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3295 - accuracy: 0.9876 - val_loss: 0.9891 - val_accuracy: 0.7586\n","Epoch 87/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3241 - accuracy: 0.9876 - val_loss: 1.0401 - val_accuracy: 0.7468\n","Epoch 88/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3171 - accuracy: 0.9922 - val_loss: 0.9900 - val_accuracy: 0.7532\n","Epoch 89/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3189 - accuracy: 0.9900 - val_loss: 1.0064 - val_accuracy: 0.7575\n","Epoch 90/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3161 - accuracy: 0.9911 - val_loss: 1.0200 - val_accuracy: 0.7478\n","Epoch 91/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3187 - accuracy: 0.9887 - val_loss: 1.1041 - val_accuracy: 0.7198\n","Epoch 92/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3229 - accuracy: 0.9887 - val_loss: 1.0124 - val_accuracy: 0.7522\n","Epoch 93/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3158 - accuracy: 0.9922 - val_loss: 1.0077 - val_accuracy: 0.7543\n","Epoch 94/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3224 - accuracy: 0.9898 - val_loss: 1.0129 - val_accuracy: 0.7543\n","Epoch 95/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3150 - accuracy: 0.9895 - val_loss: 1.0331 - val_accuracy: 0.7478\n","Epoch 96/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3113 - accuracy: 0.9941 - val_loss: 1.0026 - val_accuracy: 0.7532\n","Epoch 97/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3189 - accuracy: 0.9879 - val_loss: 1.0022 - val_accuracy: 0.7511\n","Epoch 98/100\n","29/29 [==============================] - 0s 9ms/step - loss: 0.3069 - accuracy: 0.9938 - val_loss: 1.0123 - val_accuracy: 0.7532\n","Epoch 99/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3079 - accuracy: 0.9946 - val_loss: 1.0596 - val_accuracy: 0.7457\n","Epoch 100/100\n","29/29 [==============================] - 0s 10ms/step - loss: 0.3149 - accuracy: 0.9903 - val_loss: 1.0157 - val_accuracy: 0.7565\n","{'loss': [0.5271111130714417, 0.4796734154224396, 0.47470855712890625, 0.4717559814453125, 0.46815991401672363, 0.45185524225234985, 0.44230690598487854, 0.44310083985328674, 0.43823498487472534, 0.4367961883544922, 0.4765748977661133, 0.4508868157863617, 0.42922112345695496, 0.430489182472229, 0.42211687564849854, 0.41775888204574585, 0.4210216701030731, 0.41574448347091675, 0.41999220848083496, 0.4096578061580658, 0.40939369797706604, 0.4068673551082611, 0.4086907207965851, 0.42234399914741516, 0.40498656034469604, 0.39964354038238525, 0.39255446195602417, 0.39731746912002563, 0.3956978917121887, 0.39739659428596497, 0.3980455696582794, 0.3997254967689514, 0.3847252130508423, 0.38350817561149597, 0.3834795355796814, 0.3975994288921356, 0.39840516448020935, 0.37348854541778564, 0.37440866231918335, 0.3714122176170349, 0.37691113352775574, 0.37457045912742615, 0.3715028464794159, 0.3893243074417114, 0.37690281867980957, 0.36715543270111084, 0.3637900948524475, 0.35746341943740845, 0.3623496890068054, 0.3817797601222992, 0.3597104251384735, 0.3537445366382599, 0.35741254687309265, 0.3523368537425995, 0.349724143743515, 0.35324278473854065, 0.347343772649765, 0.3478263318538666, 0.34324827790260315, 0.346349835395813, 0.34713706374168396, 0.3456091284751892, 0.35205912590026855, 0.3443695306777954, 0.3431623578071594, 0.3446914851665497, 0.3543154001235962, 0.34058380126953125, 0.33856022357940674, 0.3380674421787262, 0.3486908972263336, 0.33334437012672424, 0.33319342136383057, 0.32642167806625366, 0.32601311802864075, 0.32979124784469604, 0.32527410984039307, 0.321389377117157, 0.329536110162735, 0.3249686062335968, 0.3291221261024475, 0.3456796109676361, 0.34528300166130066, 0.34710749983787537, 0.3277575373649597, 0.3294786512851715, 0.3240848481655121, 0.31706827878952026, 0.3189198672771454, 0.3161036968231201, 0.31871598958969116, 0.3228772282600403, 0.3157542049884796, 0.3224353492259979, 0.31497469544410706, 0.31131643056869507, 0.31894752383232117, 0.30686154961586, 0.3079133927822113, 0.31493768095970154], 'accuracy': [0.8860452771186829, 0.9164870977401733, 0.9226831793785095, 0.9189116358757019, 0.9315732717514038, 0.9375, 0.9471982717514038, 0.9434267282485962, 0.9455819129943848, 0.9474676847457886, 0.9137930870056152, 0.9353448152542114, 0.9490840435028076, 0.9539331793785095, 0.954472005367279, 0.9620150923728943, 0.9533944129943848, 0.9598599076271057, 0.954472005367279, 0.962284505367279, 0.962284505367279, 0.9649784564971924, 0.9582435488700867, 0.9482758641242981, 0.9633620977401733, 0.9663254022598267, 0.9727909564971924, 0.967133641242981, 0.9655172228813171, 0.9649784564971924, 0.959590494632721, 0.9614762663841248, 0.9738685488700867, 0.9722521305084229, 0.9730603694915771, 0.9636314511299133, 0.9601293206214905, 0.975215494632721, 0.9741379022598267, 0.9795258641242981, 0.9730603694915771, 0.9733297228813171, 0.9771012663841248, 0.9655172228813171, 0.96875, 0.9771012663841248, 0.9792564511299133, 0.9803340435028076, 0.9808728694915771, 0.9657866358757019, 0.9787176847457886, 0.9822198152542114, 0.9787176847457886, 0.9832974076271057, 0.9846444129943848, 0.9838362336158752, 0.9841055870056152, 0.9854525923728943, 0.9867995977401733, 0.9838362336158752, 0.9835668206214905, 0.9851831793785095, 0.9803340435028076, 0.9846444129943848, 0.9854525923728943, 0.9854525923728943, 0.9735991358757019, 0.983027994632721, 0.9851831793785095, 0.9841055870056152, 0.9811422228813171, 0.9862607717514038, 0.9876077771186829, 0.9889547228813171, 0.990840494632721, 0.9870689511299133, 0.990571141242981, 0.9921875, 0.9886853694915771, 0.9897629022598267, 0.9870689511299133, 0.9789870977401733, 0.9760237336158752, 0.9771012663841248, 0.985991358757019, 0.9876077771186829, 0.9876077771186829, 0.9921875, 0.9900323152542114, 0.9911099076271057, 0.9886853694915771, 0.9886853694915771, 0.9921875, 0.9897629022598267, 0.9894935488700867, 0.9940732717514038, 0.9878771305084229, 0.993803858757019, 0.9946120977401733, 0.9903017282485962], 'val_loss': [1.0596050024032593, 1.0698338747024536, 1.0813872814178467, 1.095991849899292, 1.117293119430542, 1.1665171384811401, 1.1733787059783936, 1.2162998914718628, 1.2744048833847046, 1.3612992763519287, 1.3844270706176758, 1.446895718574524, 1.3947407007217407, 1.43044912815094, 1.3958792686462402, 1.3640774488449097, 1.2463569641113281, 1.1949219703674316, 1.1614340543746948, 1.066429853439331, 0.967608630657196, 0.9404597282409668, 0.9676297903060913, 0.8969489932060242, 0.863381564617157, 0.8783516883850098, 0.85007643699646, 0.8463349342346191, 0.8531124591827393, 0.8763531446456909, 0.9112991094589233, 0.8782163858413696, 0.8582615256309509, 0.912204921245575, 0.8877576589584351, 0.8802653551101685, 0.8797926306724548, 0.8918678164482117, 0.8946412205696106, 0.8935447335243225, 0.8960140943527222, 0.8940818309783936, 0.885186493396759, 0.9095656275749207, 0.913455069065094, 0.9237390756607056, 0.9021809101104736, 0.9156145453453064, 0.8989315032958984, 0.9558156728744507, 0.9409583806991577, 0.9486651420593262, 0.9154598712921143, 0.9386583566665649, 0.9286675453186035, 0.9178390502929688, 0.939739465713501, 0.9169784188270569, 0.9255133867263794, 0.9693773984909058, 0.9303362369537354, 0.9344803094863892, 0.9395402073860168, 0.9336956739425659, 0.9330456256866455, 0.9326975345611572, 1.0404444932937622, 0.9397975206375122, 1.0230069160461426, 1.0664031505584717, 0.9744561910629272, 0.9784175753593445, 0.9583844542503357, 0.959905207157135, 0.9601070284843445, 0.9821053147315979, 0.9708371758460999, 0.9900874495506287, 0.9997649192810059, 0.9962958097457886, 0.984359085559845, 1.1520081758499146, 1.0894306898117065, 1.0433350801467896, 1.0661345720291138, 0.9890848398208618, 1.04013991355896, 0.9899700880050659, 1.006409764289856, 1.0199742317199707, 1.1040685176849365, 1.0123547315597534, 1.0077217817306519, 1.0128971338272095, 1.033067226409912, 1.0025593042373657, 1.0022104978561401, 1.0122740268707275, 1.0595811605453491, 1.0156617164611816], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.48706895112991333, 0.48706895112991333, 0.48706895112991333, 0.4903017282485962, 0.4903017282485962, 0.5043103694915771, 0.506465494632721, 0.5237069129943848, 0.5431034564971924, 0.5678879022598267, 0.5894396305084229, 0.6099137663841248, 0.642241358757019, 0.6681034564971924, 0.6950430870056152, 0.6950430870056152, 0.7241379022598267, 0.7392241358757019, 0.725215494632721, 0.7446120977401733, 0.7403017282485962, 0.7521551847457886, 0.7629310488700867, 0.7219827771186829, 0.7543103694915771, 0.7704741358757019, 0.7338362336158752, 0.767241358757019, 0.756465494632721, 0.7629310488700867, 0.7532327771186829, 0.7575430870056152, 0.764008641242981, 0.7661637663841248, 0.7618534564971924, 0.7661637663841248, 0.7607758641242981, 0.7532327771186829, 0.7596982717514038, 0.7618534564971924, 0.7607758641242981, 0.764008641242981, 0.7424569129943848, 0.7510775923728943, 0.7543103694915771, 0.7543103694915771, 0.7521551847457886, 0.7618534564971924, 0.7553879022598267, 0.7510775923728943, 0.7532327771186829, 0.7629310488700867, 0.756465494632721, 0.7618534564971924, 0.7575430870056152, 0.7521551847457886, 0.7553879022598267, 0.7596982717514038, 0.7553879022598267, 0.7467672228813171, 0.7521551847457886, 0.7370689511299133, 0.7316810488700867, 0.7510775923728943, 0.7553879022598267, 0.7575430870056152, 0.7510775923728943, 0.7575430870056152, 0.7532327771186829, 0.7510775923728943, 0.7489224076271057, 0.7521551847457886, 0.7553879022598267, 0.7510775923728943, 0.712284505367279, 0.7306034564971924, 0.7381465435028076, 0.7456896305084229, 0.7586206793785095, 0.7467672228813171, 0.7532327771186829, 0.7575430870056152, 0.7478448152542114, 0.7198275923728943, 0.7521551847457886, 0.7543103694915771, 0.7543103694915771, 0.7478448152542114, 0.7532327771186829, 0.7510775923728943, 0.7532327771186829, 0.7456896305084229, 0.756465494632721]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 29ms/step - loss: 0.5675 - accuracy: 0.8769 - val_loss: 1.0516 - val_accuracy: 0.4955\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.4765 - accuracy: 0.9219"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 11ms/step - loss: 0.4592 - accuracy: 0.9321 - val_loss: 1.0570 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4617 - accuracy: 0.9250 - val_loss: 1.0721 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4560 - accuracy: 0.9392 - val_loss: 1.0827 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4461 - accuracy: 0.9411 - val_loss: 1.1143 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.4530 - accuracy: 0.9335 - val_loss: 1.1354 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4456 - accuracy: 0.9403 - val_loss: 1.1704 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4400 - accuracy: 0.9440 - val_loss: 1.1794 - val_accuracy: 0.4966\n","Epoch 9/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4285 - accuracy: 0.9542 - val_loss: 1.2420 - val_accuracy: 0.4966\n","Epoch 10/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4386 - accuracy: 0.9411 - val_loss: 1.3133 - val_accuracy: 0.4966\n","Epoch 11/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4330 - accuracy: 0.9477 - val_loss: 1.3264 - val_accuracy: 0.5023\n","Epoch 12/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4293 - accuracy: 0.9457 - val_loss: 1.3372 - val_accuracy: 0.5011\n","Epoch 13/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4181 - accuracy: 0.9612 - val_loss: 1.3840 - val_accuracy: 0.5023\n","Epoch 14/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4189 - accuracy: 0.9544 - val_loss: 1.4147 - val_accuracy: 0.5034\n","Epoch 15/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4154 - accuracy: 0.9601 - val_loss: 1.3519 - val_accuracy: 0.5192\n","Epoch 16/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4080 - accuracy: 0.9638 - val_loss: 1.3125 - val_accuracy: 0.5396\n","Epoch 17/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.4112 - accuracy: 0.9598 - val_loss: 1.3258 - val_accuracy: 0.5475\n","Epoch 18/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4086 - accuracy: 0.9638 - val_loss: 1.1756 - val_accuracy: 0.5814\n","Epoch 19/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4099 - accuracy: 0.9641 - val_loss: 1.1964 - val_accuracy: 0.5837\n","Epoch 20/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4200 - accuracy: 0.9499 - val_loss: 1.1069 - val_accuracy: 0.6278\n","Epoch 21/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4058 - accuracy: 0.9612 - val_loss: 0.9978 - val_accuracy: 0.6493\n","Epoch 22/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4022 - accuracy: 0.9604 - val_loss: 1.0044 - val_accuracy: 0.6674\n","Epoch 23/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3950 - accuracy: 0.9683 - val_loss: 0.9611 - val_accuracy: 0.6912\n","Epoch 24/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4124 - accuracy: 0.9530 - val_loss: 1.0062 - val_accuracy: 0.6697\n","Epoch 25/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4050 - accuracy: 0.9598 - val_loss: 0.9218 - val_accuracy: 0.6946\n","Epoch 26/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3914 - accuracy: 0.9689 - val_loss: 0.8680 - val_accuracy: 0.7240\n","Epoch 27/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3971 - accuracy: 0.9660 - val_loss: 0.8956 - val_accuracy: 0.7172\n","Epoch 28/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3974 - accuracy: 0.9660 - val_loss: 0.8528 - val_accuracy: 0.7500\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3807 - accuracy: 0.9734 - val_loss: 0.8302 - val_accuracy: 0.7443\n","Epoch 30/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3787 - accuracy: 0.9762 - val_loss: 0.8374 - val_accuracy: 0.7421\n","Epoch 31/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3774 - accuracy: 0.9759 - val_loss: 0.9017 - val_accuracy: 0.7229\n","Epoch 32/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3865 - accuracy: 0.9692 - val_loss: 0.8497 - val_accuracy: 0.7534\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3732 - accuracy: 0.9762 - val_loss: 0.8283 - val_accuracy: 0.7511\n","Epoch 34/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3740 - accuracy: 0.9774 - val_loss: 0.8426 - val_accuracy: 0.7443\n","Epoch 35/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3705 - accuracy: 0.9793 - val_loss: 0.8706 - val_accuracy: 0.7511\n","Epoch 36/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3695 - accuracy: 0.9768 - val_loss: 0.8490 - val_accuracy: 0.7410\n","Epoch 37/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3752 - accuracy: 0.9737 - val_loss: 0.8792 - val_accuracy: 0.7353\n","Epoch 38/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3712 - accuracy: 0.9740 - val_loss: 0.8490 - val_accuracy: 0.7500\n","Epoch 39/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3684 - accuracy: 0.9771 - val_loss: 0.8444 - val_accuracy: 0.7421\n","Epoch 40/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3608 - accuracy: 0.9819 - val_loss: 0.8730 - val_accuracy: 0.7274\n","Epoch 41/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3653 - accuracy: 0.9765 - val_loss: 0.8467 - val_accuracy: 0.7466\n","Epoch 42/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3614 - accuracy: 0.9805 - val_loss: 0.8671 - val_accuracy: 0.7466\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3633 - accuracy: 0.9779 - val_loss: 0.8977 - val_accuracy: 0.7557\n","Epoch 44/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.4093 - accuracy: 0.9465 - val_loss: 0.8661 - val_accuracy: 0.7410\n","Epoch 45/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3624 - accuracy: 0.9793 - val_loss: 0.8576 - val_accuracy: 0.7477\n","Epoch 46/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3629 - accuracy: 0.9762 - val_loss: 0.9134 - val_accuracy: 0.7274\n","Epoch 47/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3607 - accuracy: 0.9788 - val_loss: 0.8696 - val_accuracy: 0.7376\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3686 - accuracy: 0.9728 - val_loss: 0.8753 - val_accuracy: 0.7455\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3557 - accuracy: 0.9799 - val_loss: 0.8722 - val_accuracy: 0.7387\n","Epoch 50/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3454 - accuracy: 0.9887 - val_loss: 0.8921 - val_accuracy: 0.7568\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3459 - accuracy: 0.9867 - val_loss: 0.8742 - val_accuracy: 0.7410\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3494 - accuracy: 0.9853 - val_loss: 0.9035 - val_accuracy: 0.7251\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3472 - accuracy: 0.9895 - val_loss: 0.9014 - val_accuracy: 0.7308\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3418 - accuracy: 0.9890 - val_loss: 0.8842 - val_accuracy: 0.7443\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3391 - accuracy: 0.9904 - val_loss: 0.8918 - val_accuracy: 0.7421\n","Epoch 56/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3391 - accuracy: 0.9912 - val_loss: 0.8953 - val_accuracy: 0.7443\n","Epoch 57/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3438 - accuracy: 0.9864 - val_loss: 0.9482 - val_accuracy: 0.7206\n","Epoch 58/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3531 - accuracy: 0.9802 - val_loss: 0.8862 - val_accuracy: 0.7523\n","Epoch 59/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3422 - accuracy: 0.9859 - val_loss: 0.9309 - val_accuracy: 0.7262\n","Epoch 60/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3363 - accuracy: 0.9892 - val_loss: 0.9515 - val_accuracy: 0.7206\n","Epoch 61/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3365 - accuracy: 0.9901 - val_loss: 0.9123 - val_accuracy: 0.7432\n","Epoch 62/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3388 - accuracy: 0.9884 - val_loss: 0.9464 - val_accuracy: 0.7274\n","Epoch 63/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3362 - accuracy: 0.9884 - val_loss: 0.9029 - val_accuracy: 0.7466\n","Epoch 64/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3267 - accuracy: 0.9938 - val_loss: 0.9221 - val_accuracy: 0.7398\n","Epoch 65/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3319 - accuracy: 0.9921 - val_loss: 0.9191 - val_accuracy: 0.7364\n","Epoch 66/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3346 - accuracy: 0.9884 - val_loss: 0.9044 - val_accuracy: 0.7443\n","Epoch 67/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3262 - accuracy: 0.9918 - val_loss: 0.9279 - val_accuracy: 0.7342\n","Epoch 68/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3234 - accuracy: 0.9941 - val_loss: 0.9447 - val_accuracy: 0.7161\n","Epoch 69/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3231 - accuracy: 0.9929 - val_loss: 0.9239 - val_accuracy: 0.7342\n","Epoch 70/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3267 - accuracy: 0.9901 - val_loss: 0.9386 - val_accuracy: 0.7262\n","Epoch 71/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3229 - accuracy: 0.9926 - val_loss: 0.9291 - val_accuracy: 0.7353\n","Epoch 72/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3204 - accuracy: 0.9952 - val_loss: 0.9231 - val_accuracy: 0.7455\n","Epoch 73/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3162 - accuracy: 0.9958 - val_loss: 1.0087 - val_accuracy: 0.7217\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3207 - accuracy: 0.9938 - val_loss: 0.9191 - val_accuracy: 0.7432\n","Epoch 75/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3203 - accuracy: 0.9941 - val_loss: 0.9263 - val_accuracy: 0.7387\n","Epoch 76/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3148 - accuracy: 0.9935 - val_loss: 0.9245 - val_accuracy: 0.7455\n","Epoch 77/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3212 - accuracy: 0.9921 - val_loss: 0.9376 - val_accuracy: 0.7296\n","Epoch 78/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3220 - accuracy: 0.9901 - val_loss: 0.9321 - val_accuracy: 0.7330\n","Epoch 79/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3190 - accuracy: 0.9932 - val_loss: 0.9544 - val_accuracy: 0.7364\n","Epoch 80/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3161 - accuracy: 0.9952 - val_loss: 0.9355 - val_accuracy: 0.7466\n","Epoch 81/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3094 - accuracy: 0.9975 - val_loss: 0.9416 - val_accuracy: 0.7353\n","Epoch 82/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3109 - accuracy: 0.9975 - val_loss: 0.9344 - val_accuracy: 0.7421\n","Epoch 83/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.3156 - accuracy: 0.9941 - val_loss: 1.0334 - val_accuracy: 0.7229\n","Epoch 84/100\n","28/28 [==============================] - 0s 10ms/step - loss: 0.3264 - accuracy: 0.9887 - val_loss: 0.9842 - val_accuracy: 0.7466\n","Epoch 85/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3160 - accuracy: 0.9938 - val_loss: 0.9762 - val_accuracy: 0.7364\n","Epoch 86/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3188 - accuracy: 0.9909 - val_loss: 0.9617 - val_accuracy: 0.7432\n","Epoch 87/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3061 - accuracy: 0.9963 - val_loss: 0.9681 - val_accuracy: 0.7398\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3091 - accuracy: 0.9969 - val_loss: 0.9608 - val_accuracy: 0.7455\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3152 - accuracy: 0.9929 - val_loss: 0.9552 - val_accuracy: 0.7376\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3221 - accuracy: 0.9870 - val_loss: 1.0096 - val_accuracy: 0.7262\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3169 - accuracy: 0.9912 - val_loss: 0.9589 - val_accuracy: 0.7364\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3024 - accuracy: 0.9969 - val_loss: 1.0024 - val_accuracy: 0.7274\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3032 - accuracy: 0.9958 - val_loss: 1.0239 - val_accuracy: 0.7319\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3220 - accuracy: 0.9887 - val_loss: 0.9623 - val_accuracy: 0.7466\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3234 - accuracy: 0.9861 - val_loss: 0.9838 - val_accuracy: 0.7308\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3006 - accuracy: 0.9966 - val_loss: 0.9786 - val_accuracy: 0.7376\n","Epoch 97/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2988 - accuracy: 0.9975 - val_loss: 1.0108 - val_accuracy: 0.7262\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3009 - accuracy: 0.9955 - val_loss: 0.9816 - val_accuracy: 0.7398\n","Epoch 99/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2959 - accuracy: 0.9983 - val_loss: 0.9725 - val_accuracy: 0.7455\n","Epoch 100/100\n","28/28 [==============================] - 0s 11ms/step - loss: 0.2972 - accuracy: 0.9977 - val_loss: 0.9792 - val_accuracy: 0.7398\n","{'loss': [0.5675159692764282, 0.45918184518814087, 0.46170687675476074, 0.45598283410072327, 0.44613099098205566, 0.4529970586299896, 0.44560906291007996, 0.44001051783561707, 0.4285249710083008, 0.4385695457458496, 0.43298494815826416, 0.4292587637901306, 0.41811299324035645, 0.4189221262931824, 0.4153636395931244, 0.40797901153564453, 0.41120144724845886, 0.4085558354854584, 0.40988025069236755, 0.4199850559234619, 0.40575477480888367, 0.40223392844200134, 0.3949540853500366, 0.41244226694107056, 0.40501710772514343, 0.39137065410614014, 0.3971436321735382, 0.39737674593925476, 0.3807465136051178, 0.3787460923194885, 0.377356618642807, 0.3865251839160919, 0.37317365407943726, 0.374021977186203, 0.3705470860004425, 0.36954572796821594, 0.37524035573005676, 0.37121328711509705, 0.3684171438217163, 0.36080968379974365, 0.3653489947319031, 0.36143556237220764, 0.3632957339286804, 0.40934762358665466, 0.3623661696910858, 0.3628789186477661, 0.3606853187084198, 0.3685886859893799, 0.3556773364543915, 0.3453892171382904, 0.3459411561489105, 0.3494403660297394, 0.3471772372722626, 0.3418082594871521, 0.3390674591064453, 0.3390919268131256, 0.343809574842453, 0.3530633747577667, 0.34216025471687317, 0.336328387260437, 0.33651572465896606, 0.33876627683639526, 0.33619117736816406, 0.3266978859901428, 0.33186253905296326, 0.3345659673213959, 0.3262161314487457, 0.3233598470687866, 0.3231348693370819, 0.3267214894294739, 0.3228995203971863, 0.32043635845184326, 0.31616339087486267, 0.3206988275051117, 0.32029858231544495, 0.31484857201576233, 0.32116755843162537, 0.3219604790210724, 0.3190261125564575, 0.31607863306999207, 0.30935174226760864, 0.3108670115470886, 0.3156382739543915, 0.32642707228660583, 0.3159615695476532, 0.31884241104125977, 0.30610784888267517, 0.30911174416542053, 0.3151915669441223, 0.32207340002059937, 0.3169178068637848, 0.3024246394634247, 0.30315813422203064, 0.3219973146915436, 0.3234250843524933, 0.30062609910964966, 0.29880189895629883, 0.30090877413749695, 0.29588407278060913, 0.2972220182418823], 'accuracy': [0.8769100308418274, 0.9320882558822632, 0.9250141382217407, 0.9391624331474304, 0.9411431550979614, 0.9335030913352966, 0.9402942657470703, 0.9439728260040283, 0.9541596174240112, 0.9411431550979614, 0.9476513862609863, 0.9456706047058105, 0.9612337350845337, 0.95444256067276, 0.960101842880249, 0.963780403137207, 0.9598188996315002, 0.963780403137207, 0.9640634059906006, 0.9499151110649109, 0.9612337350845337, 0.9603848457336426, 0.9683078527450562, 0.9530277252197266, 0.9598188996315002, 0.9688737988471985, 0.9660441279411316, 0.9660441279411316, 0.9734012484550476, 0.9762309193611145, 0.975947916507721, 0.9691567420959473, 0.9762309193611145, 0.9773627519607544, 0.9793435335159302, 0.9767968058586121, 0.9736841917037964, 0.9739671945571899, 0.9770798087120056, 0.9818902015686035, 0.9765138626098633, 0.9804753661155701, 0.9779286980628967, 0.9465195536613464, 0.9793435335159302, 0.9762309193611145, 0.9787775874137878, 0.9728353023529053, 0.9799094796180725, 0.9886813759803772, 0.9867005944252014, 0.9852858185768127, 0.9895302653312683, 0.988964319229126, 0.9903791546821594, 0.9912280440330505, 0.9864176511764526, 0.9801924228668213, 0.9858517050743103, 0.9892473220825195, 0.9900962114334106, 0.9883984327316284, 0.9883984327316284, 0.9937747716903687, 0.9920769929885864, 0.9883984327316284, 0.9917939901351929, 0.9940577149391174, 0.9929258823394775, 0.9900962114334106, 0.992642879486084, 0.9951896071434021, 0.9957554936408997, 0.9937747716903687, 0.9940577149391174, 0.9934917688369751, 0.9920769929885864, 0.9900962114334106, 0.9932088255882263, 0.9951896071434021, 0.9974533319473267, 0.9974533319473267, 0.9940577149391174, 0.9886813759803772, 0.9937747716903687, 0.9909451007843018, 0.996321439743042, 0.9968873858451843, 0.9929258823394775, 0.986983597278595, 0.9912280440330505, 0.9968873858451843, 0.9957554936408997, 0.9886813759803772, 0.9861347079277039, 0.9966044425964355, 0.9974533319473267, 0.9954725503921509, 0.9983022212982178, 0.9977362751960754], 'val_loss': [1.0515772104263306, 1.0569911003112793, 1.0721070766448975, 1.0826520919799805, 1.114342451095581, 1.1354230642318726, 1.1703885793685913, 1.179386854171753, 1.2420134544372559, 1.3133466243743896, 1.3264250755310059, 1.3371875286102295, 1.3840200901031494, 1.4147242307662964, 1.3518670797348022, 1.312476634979248, 1.3257992267608643, 1.175616979598999, 1.1964191198349, 1.106886863708496, 0.9978476762771606, 1.0043808221817017, 0.9611432552337646, 1.0061908960342407, 0.9218039512634277, 0.868044912815094, 0.8955744504928589, 0.8527939319610596, 0.8301565647125244, 0.8373554348945618, 0.9016911387443542, 0.8497028350830078, 0.8282516002655029, 0.8426024317741394, 0.8705801963806152, 0.8489720225334167, 0.879236102104187, 0.8490222096443176, 0.8444178104400635, 0.8729739785194397, 0.846747100353241, 0.8670845627784729, 0.8977472186088562, 0.8660820722579956, 0.8575557470321655, 0.9133755564689636, 0.8696109056472778, 0.875299334526062, 0.8722358345985413, 0.8920652866363525, 0.874242901802063, 0.9034982919692993, 0.9013768434524536, 0.8842061161994934, 0.8918359279632568, 0.8952612280845642, 0.9482037425041199, 0.8862048387527466, 0.9308843016624451, 0.9514653086662292, 0.9122764468193054, 0.9463605880737305, 0.9029070734977722, 0.9220821857452393, 0.9191445708274841, 0.9044389128684998, 0.9278599619865417, 0.9446693062782288, 0.9238672852516174, 0.9386348128318787, 0.9291045665740967, 0.9231407642364502, 1.008650302886963, 0.9191492795944214, 0.9263452887535095, 0.9244620203971863, 0.9376084804534912, 0.9320934414863586, 0.9544376134872437, 0.9354916214942932, 0.9416028261184692, 0.9344427585601807, 1.033375859260559, 0.9841786623001099, 0.9761847853660583, 0.961674153804779, 0.9681458473205566, 0.9607501029968262, 0.9551685452461243, 1.0095608234405518, 0.9588855504989624, 1.0024168491363525, 1.023883581161499, 0.9622887372970581, 0.9838395714759827, 0.978590190410614, 1.010788083076477, 0.9815525412559509, 0.9725396633148193, 0.9792273044586182], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.49660632014274597, 0.49660632014274597, 0.5022624731063843, 0.5011312365531921, 0.5022624731063843, 0.5033936500549316, 0.5192307829856873, 0.5395927429199219, 0.5475113391876221, 0.581447958946228, 0.5837104320526123, 0.627828061580658, 0.6493212580680847, 0.6674208045005798, 0.6911764740943909, 0.6696832776069641, 0.6945701241493225, 0.7239819169044495, 0.7171945571899414, 0.75, 0.7443438768386841, 0.7420814633369446, 0.7228506803512573, 0.7533936500549316, 0.7511312365531921, 0.7443438768386841, 0.7511312365531921, 0.7409502267837524, 0.7352941036224365, 0.75, 0.7420814633369446, 0.7273755669593811, 0.7466063499450684, 0.7466063499450684, 0.7556561231613159, 0.7409502267837524, 0.7477375268936157, 0.7273755669593811, 0.7375565767288208, 0.7454751133918762, 0.7386877536773682, 0.7567873597145081, 0.7409502267837524, 0.7251130938529968, 0.7307692170143127, 0.7443438768386841, 0.7420814633369446, 0.7443438768386841, 0.720588207244873, 0.7522624731063843, 0.726244330406189, 0.720588207244873, 0.7432126402854919, 0.7273755669593811, 0.7466063499450684, 0.7398189902305603, 0.7364253401756287, 0.7443438768386841, 0.7341628670692444, 0.7160633206367493, 0.7341628670692444, 0.726244330406189, 0.7352941036224365, 0.7454751133918762, 0.7217194437980652, 0.7432126402854919, 0.7386877536773682, 0.7454751133918762, 0.7296379804611206, 0.733031690120697, 0.7364253401756287, 0.7466063499450684, 0.7352941036224365, 0.7420814633369446, 0.7228506803512573, 0.7466063499450684, 0.7364253401756287, 0.7432126402854919, 0.7398189902305603, 0.7454751133918762, 0.7375565767288208, 0.726244330406189, 0.7364253401756287, 0.7273755669593811, 0.7319004535675049, 0.7466063499450684, 0.7307692170143127, 0.7375565767288208, 0.726244330406189, 0.7398189902305603, 0.7454751133918762, 0.7398189902305603]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               524800    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2852417 (10.88 MB)\n","Trainable params: 2851905 (10.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 4s 34ms/step - loss: 0.6266 - accuracy: 0.8486 - val_loss: 1.0697 - val_accuracy: 0.4855\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 16ms/step - loss: 0.5088 - accuracy: 0.9034 - val_loss: 1.0830 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4882 - accuracy: 0.9088 - val_loss: 1.0951 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4840 - accuracy: 0.9178 - val_loss: 1.1218 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4755 - accuracy: 0.9207 - val_loss: 1.1448 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4703 - accuracy: 0.9230 - val_loss: 1.1777 - val_accuracy: 0.4866\n","Epoch 7/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4682 - accuracy: 0.9235 - val_loss: 1.2184 - val_accuracy: 0.4866\n","Epoch 8/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4621 - accuracy: 0.9331 - val_loss: 1.2775 - val_accuracy: 0.4866\n","Epoch 9/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4646 - accuracy: 0.9292 - val_loss: 1.3568 - val_accuracy: 0.4866\n","Epoch 10/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4760 - accuracy: 0.9230 - val_loss: 1.3771 - val_accuracy: 0.4897\n","Epoch 11/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4500 - accuracy: 0.9354 - val_loss: 1.4722 - val_accuracy: 0.4897\n","Epoch 12/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4424 - accuracy: 0.9416 - val_loss: 1.4654 - val_accuracy: 0.4928\n","Epoch 13/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4412 - accuracy: 0.9452 - val_loss: 1.4641 - val_accuracy: 0.4948\n","Epoch 14/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4491 - accuracy: 0.9377 - val_loss: 1.4513 - val_accuracy: 0.5072\n","Epoch 15/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4436 - accuracy: 0.9390 - val_loss: 1.2323 - val_accuracy: 0.5413\n","Epoch 16/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4705 - accuracy: 0.9160 - val_loss: 1.1210 - val_accuracy: 0.5919\n","Epoch 17/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4594 - accuracy: 0.9282 - val_loss: 1.1690 - val_accuracy: 0.5909\n","Epoch 18/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4344 - accuracy: 0.9429 - val_loss: 1.0687 - val_accuracy: 0.6384\n","Epoch 19/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4390 - accuracy: 0.9434 - val_loss: 1.0363 - val_accuracy: 0.6477\n","Epoch 20/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4307 - accuracy: 0.9475 - val_loss: 0.9424 - val_accuracy: 0.6818\n","Epoch 21/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4401 - accuracy: 0.9351 - val_loss: 0.9236 - val_accuracy: 0.6983\n","Epoch 22/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4261 - accuracy: 0.9527 - val_loss: 0.8888 - val_accuracy: 0.7138\n","Epoch 23/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4304 - accuracy: 0.9455 - val_loss: 0.8839 - val_accuracy: 0.7149\n","Epoch 24/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4177 - accuracy: 0.9584 - val_loss: 0.8747 - val_accuracy: 0.7231\n","Epoch 25/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4317 - accuracy: 0.9419 - val_loss: 0.8701 - val_accuracy: 0.7355\n","Epoch 26/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.4208 - accuracy: 0.9486 - val_loss: 0.9923 - val_accuracy: 0.7004\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4596 - accuracy: 0.9245 - val_loss: 0.8891 - val_accuracy: 0.7376\n","Epoch 28/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.4266 - accuracy: 0.9455 - val_loss: 0.9099 - val_accuracy: 0.7169\n","Epoch 29/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4288 - accuracy: 0.9473 - val_loss: 0.8877 - val_accuracy: 0.7386\n","Epoch 30/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4088 - accuracy: 0.9605 - val_loss: 0.9069 - val_accuracy: 0.7428\n","Epoch 31/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4065 - accuracy: 0.9610 - val_loss: 0.9504 - val_accuracy: 0.7345\n","Epoch 32/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4112 - accuracy: 0.9594 - val_loss: 0.9505 - val_accuracy: 0.7242\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4077 - accuracy: 0.9615 - val_loss: 0.9192 - val_accuracy: 0.7407\n","Epoch 34/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4014 - accuracy: 0.9610 - val_loss: 0.9205 - val_accuracy: 0.7407\n","Epoch 35/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4000 - accuracy: 0.9625 - val_loss: 0.9643 - val_accuracy: 0.7242\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4007 - accuracy: 0.9612 - val_loss: 0.9907 - val_accuracy: 0.7169\n","Epoch 37/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4053 - accuracy: 0.9553 - val_loss: 0.9387 - val_accuracy: 0.7448\n","Epoch 38/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3971 - accuracy: 0.9625 - val_loss: 0.9600 - val_accuracy: 0.7304\n","Epoch 39/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4265 - accuracy: 0.9398 - val_loss: 0.9921 - val_accuracy: 0.7128\n","Epoch 40/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3981 - accuracy: 0.9630 - val_loss: 0.9505 - val_accuracy: 0.7314\n","Epoch 41/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3929 - accuracy: 0.9682 - val_loss: 0.9450 - val_accuracy: 0.7417\n","Epoch 42/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3860 - accuracy: 0.9703 - val_loss: 0.9513 - val_accuracy: 0.7366\n","Epoch 43/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3814 - accuracy: 0.9742 - val_loss: 0.9734 - val_accuracy: 0.7386\n","Epoch 44/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3843 - accuracy: 0.9731 - val_loss: 0.9690 - val_accuracy: 0.7500\n","Epoch 45/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3818 - accuracy: 0.9752 - val_loss: 0.9532 - val_accuracy: 0.7459\n","Epoch 46/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3931 - accuracy: 0.9643 - val_loss: 0.9617 - val_accuracy: 0.7335\n","Epoch 47/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4018 - accuracy: 0.9545 - val_loss: 1.0036 - val_accuracy: 0.7324\n","Epoch 48/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3960 - accuracy: 0.9574 - val_loss: 0.9689 - val_accuracy: 0.7438\n","Epoch 49/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3809 - accuracy: 0.9724 - val_loss: 0.9617 - val_accuracy: 0.7345\n","Epoch 50/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3773 - accuracy: 0.9726 - val_loss: 0.9628 - val_accuracy: 0.7479\n","Epoch 51/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3713 - accuracy: 0.9755 - val_loss: 0.9761 - val_accuracy: 0.7211\n","Epoch 52/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3925 - accuracy: 0.9597 - val_loss: 1.0255 - val_accuracy: 0.7180\n","Epoch 53/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3736 - accuracy: 0.9726 - val_loss: 0.9678 - val_accuracy: 0.7407\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3888 - accuracy: 0.9625 - val_loss: 1.0160 - val_accuracy: 0.7149\n","Epoch 55/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3804 - accuracy: 0.9674 - val_loss: 1.0857 - val_accuracy: 0.7097\n","Epoch 56/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3884 - accuracy: 0.9649 - val_loss: 1.0009 - val_accuracy: 0.7242\n","Epoch 57/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3775 - accuracy: 0.9703 - val_loss: 0.9924 - val_accuracy: 0.7428\n","Epoch 58/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3664 - accuracy: 0.9762 - val_loss: 0.9864 - val_accuracy: 0.7324\n","Epoch 59/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3661 - accuracy: 0.9773 - val_loss: 1.0204 - val_accuracy: 0.7190\n","Epoch 60/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3844 - accuracy: 0.9620 - val_loss: 1.0114 - val_accuracy: 0.7273\n","Epoch 61/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3628 - accuracy: 0.9752 - val_loss: 0.9981 - val_accuracy: 0.7324\n","Epoch 62/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3687 - accuracy: 0.9739 - val_loss: 1.0486 - val_accuracy: 0.7242\n","Epoch 63/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3681 - accuracy: 0.9708 - val_loss: 1.0028 - val_accuracy: 0.7324\n","Epoch 64/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3584 - accuracy: 0.9801 - val_loss: 0.9954 - val_accuracy: 0.7355\n","Epoch 65/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3683 - accuracy: 0.9705 - val_loss: 1.0010 - val_accuracy: 0.7366\n","Epoch 66/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3522 - accuracy: 0.9837 - val_loss: 1.0887 - val_accuracy: 0.7107\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3741 - accuracy: 0.9708 - val_loss: 1.0484 - val_accuracy: 0.7211\n","Epoch 68/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3534 - accuracy: 0.9829 - val_loss: 1.0326 - val_accuracy: 0.7231\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3561 - accuracy: 0.9778 - val_loss: 1.0179 - val_accuracy: 0.7376\n","Epoch 70/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3494 - accuracy: 0.9835 - val_loss: 1.0515 - val_accuracy: 0.7138\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3562 - accuracy: 0.9783 - val_loss: 1.0023 - val_accuracy: 0.7355\n","Epoch 72/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3423 - accuracy: 0.9863 - val_loss: 1.0230 - val_accuracy: 0.7469\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3426 - accuracy: 0.9845 - val_loss: 1.0284 - val_accuracy: 0.7314\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3418 - accuracy: 0.9842 - val_loss: 1.0616 - val_accuracy: 0.7190\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3542 - accuracy: 0.9788 - val_loss: 1.0298 - val_accuracy: 0.7397\n","Epoch 76/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3476 - accuracy: 0.9793 - val_loss: 1.1097 - val_accuracy: 0.6994\n","Epoch 77/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3496 - accuracy: 0.9765 - val_loss: 1.0401 - val_accuracy: 0.7242\n","Epoch 78/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3547 - accuracy: 0.9762 - val_loss: 1.1408 - val_accuracy: 0.7035\n","Epoch 79/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3489 - accuracy: 0.9796 - val_loss: 1.0866 - val_accuracy: 0.7138\n","Epoch 80/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3494 - accuracy: 0.9804 - val_loss: 1.0429 - val_accuracy: 0.7252\n","Epoch 81/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3352 - accuracy: 0.9881 - val_loss: 1.0335 - val_accuracy: 0.7345\n","Epoch 82/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3395 - accuracy: 0.9863 - val_loss: 1.0565 - val_accuracy: 0.7304\n","Epoch 83/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3348 - accuracy: 0.9866 - val_loss: 1.0819 - val_accuracy: 0.7169\n","Epoch 84/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3335 - accuracy: 0.9860 - val_loss: 1.0435 - val_accuracy: 0.7376\n","Epoch 85/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3305 - accuracy: 0.9889 - val_loss: 1.0448 - val_accuracy: 0.7386\n","Epoch 86/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3402 - accuracy: 0.9822 - val_loss: 1.1469 - val_accuracy: 0.7128\n","Epoch 87/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3378 - accuracy: 0.9845 - val_loss: 1.0721 - val_accuracy: 0.7097\n","Epoch 88/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3341 - accuracy: 0.9840 - val_loss: 1.0887 - val_accuracy: 0.7262\n","Epoch 89/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3374 - accuracy: 0.9827 - val_loss: 1.0570 - val_accuracy: 0.7417\n","Epoch 90/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3279 - accuracy: 0.9884 - val_loss: 1.0472 - val_accuracy: 0.7386\n","Epoch 91/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3270 - accuracy: 0.9876 - val_loss: 1.0810 - val_accuracy: 0.7190\n","Epoch 92/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3307 - accuracy: 0.9855 - val_loss: 1.0651 - val_accuracy: 0.7324\n","Epoch 93/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3254 - accuracy: 0.9884 - val_loss: 1.0714 - val_accuracy: 0.7386\n","Epoch 94/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3251 - accuracy: 0.9881 - val_loss: 1.0999 - val_accuracy: 0.7128\n","Epoch 95/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3263 - accuracy: 0.9879 - val_loss: 1.0877 - val_accuracy: 0.7304\n","Epoch 96/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3379 - accuracy: 0.9822 - val_loss: 1.2289 - val_accuracy: 0.6921\n","Epoch 97/100\n","31/31 [==============================] - 0s 10ms/step - loss: 0.3345 - accuracy: 0.9829 - val_loss: 1.0767 - val_accuracy: 0.7304\n","Epoch 98/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3228 - accuracy: 0.9884 - val_loss: 1.0826 - val_accuracy: 0.7345\n","Epoch 99/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3260 - accuracy: 0.9868 - val_loss: 1.0981 - val_accuracy: 0.7200\n","Epoch 100/100\n","31/31 [==============================] - 0s 11ms/step - loss: 0.3198 - accuracy: 0.9907 - val_loss: 1.0944 - val_accuracy: 0.7200\n","{'loss': [0.6266108751296997, 0.508770763874054, 0.4882281422615051, 0.48396795988082886, 0.47547200322151184, 0.47029951214790344, 0.468176007270813, 0.4620823860168457, 0.4646279215812683, 0.4760020077228546, 0.4499848186969757, 0.4424235224723816, 0.4411764442920685, 0.44914594292640686, 0.44364282488822937, 0.47046974301338196, 0.4594348073005676, 0.43439874053001404, 0.4390096068382263, 0.4307166635990143, 0.44010627269744873, 0.42606475949287415, 0.43042799830436707, 0.4177360534667969, 0.43173226714134216, 0.42077627778053284, 0.459612637758255, 0.4266175329685211, 0.4287585914134979, 0.4087921679019928, 0.40650779008865356, 0.41119858622550964, 0.40768179297447205, 0.40144944190979004, 0.40004128217697144, 0.40067899227142334, 0.40528208017349243, 0.3971223831176758, 0.42653828859329224, 0.3980705440044403, 0.39292317628860474, 0.3859659731388092, 0.38143986463546753, 0.38430696725845337, 0.3818162679672241, 0.39306512475013733, 0.40178588032722473, 0.3960122764110565, 0.3808988034725189, 0.37734171748161316, 0.3712714910507202, 0.39252808690071106, 0.373624712228775, 0.3888494372367859, 0.38044267892837524, 0.38843265175819397, 0.37746188044548035, 0.36639121174812317, 0.36614540219306946, 0.3844059705734253, 0.36275702714920044, 0.3686743378639221, 0.3681271970272064, 0.35841819643974304, 0.3683170974254608, 0.3522128760814667, 0.3740677833557129, 0.35340890288352966, 0.35607150197029114, 0.34937623143196106, 0.356160044670105, 0.342336505651474, 0.3426423668861389, 0.3418002724647522, 0.35423165559768677, 0.34757357835769653, 0.34956759214401245, 0.3547089695930481, 0.3489364683628082, 0.34944117069244385, 0.33520543575286865, 0.339460551738739, 0.3347568213939667, 0.3335164487361908, 0.3304697871208191, 0.3401777148246765, 0.3378084599971771, 0.33414196968078613, 0.3373826742172241, 0.32793208956718445, 0.3270459771156311, 0.3306530714035034, 0.3254495859146118, 0.3251201808452606, 0.32626137137413025, 0.3378753960132599, 0.3344847559928894, 0.3228347897529602, 0.32598283886909485, 0.319778710603714], 'accuracy': [0.8485788106918335, 0.9033591747283936, 0.9087855219841003, 0.9178294539451599, 0.920671820640564, 0.9229974150657654, 0.923514187335968, 0.933074951171875, 0.9291989803314209, 0.9229974150657654, 0.9354005455970764, 0.9416020512580872, 0.9452196359634399, 0.9377260804176331, 0.9390180706977844, 0.9160206913948059, 0.9281653761863708, 0.9428940415382385, 0.9434108734130859, 0.9475452303886414, 0.9351420998573303, 0.9527131915092468, 0.9454780220985413, 0.9583979249000549, 0.9418604373931885, 0.9485788345336914, 0.9245477914810181, 0.9454780220985413, 0.94728684425354, 0.960465133190155, 0.9609819054603577, 0.959431529045105, 0.9614987373352051, 0.9609819054603577, 0.9625322818756104, 0.961240291595459, 0.9552971720695496, 0.9625322818756104, 0.9397932887077332, 0.9630491137504578, 0.9682170748710632, 0.9702842235565186, 0.9741601943969727, 0.9731265902519226, 0.9751937985420227, 0.9643411040306091, 0.9545219540596008, 0.9573643207550049, 0.9723514318466187, 0.97260981798172, 0.975452184677124, 0.9596899151802063, 0.97260981798172, 0.9625322818756104, 0.9674418568611145, 0.9648578763008118, 0.9702842235565186, 0.9762274026870728, 0.9772610068321228, 0.9620155096054077, 0.9751937985420227, 0.9739018082618713, 0.970801055431366, 0.9801033735275269, 0.9705426096916199, 0.9837209582328796, 0.970801055431366, 0.9829457402229309, 0.9777777791023254, 0.9834625124931335, 0.9782945513725281, 0.9863049387931824, 0.9844961166381836, 0.9842377305030823, 0.9788113832473755, 0.9793281555175781, 0.9764857888221741, 0.9762274026870728, 0.9795865416526794, 0.9803617596626282, 0.9881137013435364, 0.9863049387931824, 0.9865633249282837, 0.9860464930534363, 0.9888888597488403, 0.9821705222129822, 0.9844961166381836, 0.983979344367981, 0.9826873540878296, 0.9883720874786377, 0.987596869468689, 0.9855297207832336, 0.9883720874786377, 0.9881137013435364, 0.9878553152084351, 0.9821705222129822, 0.9829457402229309, 0.9883720874786377, 0.986821711063385, 0.9906976819038391], 'val_loss': [1.0696810483932495, 1.082986831665039, 1.0951484441757202, 1.121828556060791, 1.1447991132736206, 1.1777421236038208, 1.2184123992919922, 1.2775100469589233, 1.3567957878112793, 1.3771203756332397, 1.4722208976745605, 1.4653761386871338, 1.4640907049179077, 1.4512521028518677, 1.232346773147583, 1.121022343635559, 1.1690047979354858, 1.068721890449524, 1.0362743139266968, 0.942413330078125, 0.9236236214637756, 0.8887899518013, 0.8838626742362976, 0.874697208404541, 0.8700858950614929, 0.9923157691955566, 0.8891113996505737, 0.9098697304725647, 0.8877102136611938, 0.9068722128868103, 0.9503814578056335, 0.9505183696746826, 0.9191908240318298, 0.9205073118209839, 0.9642901420593262, 0.9906531572341919, 0.9386520385742188, 0.9599608182907104, 0.9921265244483948, 0.9504634737968445, 0.9450450539588928, 0.9512718915939331, 0.9734450578689575, 0.9689844846725464, 0.9532427191734314, 0.9616733193397522, 1.0036424398422241, 0.9689369797706604, 0.9616751670837402, 0.9627790451049805, 0.9761132597923279, 1.0254994630813599, 0.9677571058273315, 1.0159506797790527, 1.085744023323059, 1.0008925199508667, 0.9923510551452637, 0.9863532185554504, 1.020379662513733, 1.0113800764083862, 0.9980748891830444, 1.048608660697937, 1.0027531385421753, 0.9954327940940857, 1.001039981842041, 1.0886998176574707, 1.0483782291412354, 1.0325775146484375, 1.0179117918014526, 1.0514709949493408, 1.002347469329834, 1.0229711532592773, 1.02839994430542, 1.0616472959518433, 1.0297600030899048, 1.109683632850647, 1.040092945098877, 1.1407746076583862, 1.0865942239761353, 1.0428862571716309, 1.0334571599960327, 1.0565367937088013, 1.081896185874939, 1.04351007938385, 1.0447582006454468, 1.1468791961669922, 1.0720834732055664, 1.0887157917022705, 1.0570417642593384, 1.0471720695495605, 1.0810410976409912, 1.0650897026062012, 1.0713611841201782, 1.0999493598937988, 1.087735652923584, 1.2289196252822876, 1.0766578912734985, 1.0825916528701782, 1.0981389284133911, 1.0944395065307617], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.48657023906707764, 0.48657023906707764, 0.48657023906707764, 0.48966941237449646, 0.48966941237449646, 0.4927685856819153, 0.4948347210884094, 0.5072314143180847, 0.5413222908973694, 0.5919421315193176, 0.5909090638160706, 0.6384297609329224, 0.6477272510528564, 0.6818181872367859, 0.6983470916748047, 0.7138429880142212, 0.7148760557174683, 0.7231404781341553, 0.7355371713638306, 0.7004132270812988, 0.7376033067703247, 0.7169421315193176, 0.7386363744735718, 0.7427685856819153, 0.7345041036605835, 0.7241735458374023, 0.7407024502754211, 0.7407024502754211, 0.7241735458374023, 0.7169421315193176, 0.7448347210884094, 0.73037189245224, 0.7128099203109741, 0.7314049601554871, 0.7417355179786682, 0.7365702390670776, 0.7386363744735718, 0.75, 0.7458677887916565, 0.7334710955619812, 0.7324380278587341, 0.7438016533851624, 0.7345041036605835, 0.7479338645935059, 0.7210744023323059, 0.7179751992225647, 0.7407024502754211, 0.7148760557174683, 0.7097107172012329, 0.7241735458374023, 0.7427685856819153, 0.7324380278587341, 0.7190082669258118, 0.7272727489471436, 0.7324380278587341, 0.7241735458374023, 0.7324380278587341, 0.7355371713638306, 0.7365702390670776, 0.71074378490448, 0.7210744023323059, 0.7231404781341553, 0.7376033067703247, 0.7138429880142212, 0.7355371713638306, 0.7469007968902588, 0.7314049601554871, 0.7190082669258118, 0.7396694421768188, 0.6993801593780518, 0.7241735458374023, 0.7035123705863953, 0.7138429880142212, 0.7252066135406494, 0.7345041036605835, 0.73037189245224, 0.7169421315193176, 0.7376033067703247, 0.7386363744735718, 0.7128099203109741, 0.7097107172012329, 0.7262396812438965, 0.7417355179786682, 0.7386363744735718, 0.7190082669258118, 0.7324380278587341, 0.7386363744735718, 0.7128099203109741, 0.73037189245224, 0.692148745059967, 0.73037189245224, 0.7345041036605835, 0.7200413346290588, 0.7200413346290588]}\n","32/32 [==============================] - 0s 3ms/step\n"]}]},{"cell_type":"code","source":["metrics_df_CNN.round(3)"],"metadata":{"id":"y3RXIk-qZ7ts","colab":{"base_uri":"https://localhost:8080/","height":519},"executionInfo":{"status":"ok","timestamp":1717499131349,"user_tz":-360,"elapsed":36,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"851af638-e094-4479-d2d1-4dc22fd06ba9"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.539      0.572   0.313  0.405        0.313        0.765   \n","1        1     0.550      0.556   0.494  0.524        0.494        0.606   \n","2        2     0.570      0.566   0.602  0.584        0.602        0.538   \n","3        0     0.575      0.582   0.528  0.554        0.528        0.621   \n","4        1     0.579      0.601   0.469  0.527        0.469        0.689   \n","5        2     0.624      0.632   0.596  0.614        0.596        0.653   \n","6        0     0.604      0.608   0.585  0.596        0.585        0.623   \n","7        1     0.631      0.670   0.516  0.583        0.516        0.746   \n","8        2     0.644      0.656   0.602  0.628        0.602        0.685   \n","9        0     0.673      0.661   0.710  0.685        0.710        0.637   \n","10       1     0.683      0.684   0.681  0.682        0.681        0.685   \n","11       2     0.700      0.681   0.753  0.715        0.753        0.647   \n","12       0     0.724      0.728   0.714  0.721        0.714        0.734   \n","13       1     0.721      0.764   0.640  0.696        0.640        0.802   \n","14       2     0.736      0.761   0.689  0.723        0.689        0.783   \n","\n","    Kappa  \n","0   0.079  \n","1   0.100  \n","2   0.141  \n","3   0.149  \n","4   0.158  \n","5   0.249  \n","6   0.208  \n","7   0.261  \n","8   0.287  \n","9   0.347  \n","10  0.366  \n","11  0.400  \n","12  0.447  \n","13  0.442  \n","14  0.472  "],"text/html":["\n","  <div id=\"df-015e40b1-d529-447f-a5d4-3c226c701120\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.539</td>\n","      <td>0.572</td>\n","      <td>0.313</td>\n","      <td>0.405</td>\n","      <td>0.313</td>\n","      <td>0.765</td>\n","      <td>0.079</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.550</td>\n","      <td>0.556</td>\n","      <td>0.494</td>\n","      <td>0.524</td>\n","      <td>0.494</td>\n","      <td>0.606</td>\n","      <td>0.100</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.570</td>\n","      <td>0.566</td>\n","      <td>0.602</td>\n","      <td>0.584</td>\n","      <td>0.602</td>\n","      <td>0.538</td>\n","      <td>0.141</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.575</td>\n","      <td>0.582</td>\n","      <td>0.528</td>\n","      <td>0.554</td>\n","      <td>0.528</td>\n","      <td>0.621</td>\n","      <td>0.149</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.579</td>\n","      <td>0.601</td>\n","      <td>0.469</td>\n","      <td>0.527</td>\n","      <td>0.469</td>\n","      <td>0.689</td>\n","      <td>0.158</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.624</td>\n","      <td>0.632</td>\n","      <td>0.596</td>\n","      <td>0.614</td>\n","      <td>0.596</td>\n","      <td>0.653</td>\n","      <td>0.249</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.604</td>\n","      <td>0.608</td>\n","      <td>0.585</td>\n","      <td>0.596</td>\n","      <td>0.585</td>\n","      <td>0.623</td>\n","      <td>0.208</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.631</td>\n","      <td>0.670</td>\n","      <td>0.516</td>\n","      <td>0.583</td>\n","      <td>0.516</td>\n","      <td>0.746</td>\n","      <td>0.261</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.644</td>\n","      <td>0.656</td>\n","      <td>0.602</td>\n","      <td>0.628</td>\n","      <td>0.602</td>\n","      <td>0.685</td>\n","      <td>0.287</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.673</td>\n","      <td>0.661</td>\n","      <td>0.710</td>\n","      <td>0.685</td>\n","      <td>0.710</td>\n","      <td>0.637</td>\n","      <td>0.347</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.683</td>\n","      <td>0.684</td>\n","      <td>0.681</td>\n","      <td>0.682</td>\n","      <td>0.681</td>\n","      <td>0.685</td>\n","      <td>0.366</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.700</td>\n","      <td>0.681</td>\n","      <td>0.753</td>\n","      <td>0.715</td>\n","      <td>0.753</td>\n","      <td>0.647</td>\n","      <td>0.400</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.724</td>\n","      <td>0.728</td>\n","      <td>0.714</td>\n","      <td>0.721</td>\n","      <td>0.714</td>\n","      <td>0.734</td>\n","      <td>0.447</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.721</td>\n","      <td>0.764</td>\n","      <td>0.640</td>\n","      <td>0.696</td>\n","      <td>0.640</td>\n","      <td>0.802</td>\n","      <td>0.442</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.736</td>\n","      <td>0.761</td>\n","      <td>0.689</td>\n","      <td>0.723</td>\n","      <td>0.689</td>\n","      <td>0.783</td>\n","      <td>0.472</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-015e40b1-d529-447f-a5d4-3c226c701120')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-015e40b1-d529-447f-a5d4-3c226c701120 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-015e40b1-d529-447f-a5d4-3c226c701120');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-2c7edf04-2580-4a9a-9e39-3efdf2fe890d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c7edf04-2580-4a9a-9e39-3efdf2fe890d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-2c7edf04-2580-4a9a-9e39-3efdf2fe890d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df_CNN\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06655810207916803,\n        \"min\": 0.539,\n        \"max\": 0.736,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.673,\n          0.7,\n          0.539\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06819705342049683,\n        \"min\": 0.556,\n        \"max\": 0.764,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.661,\n          0.681,\n          0.572\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11559300522584771,\n        \"min\": 0.313,\n        \"max\": 0.753,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.681,\n          0.714,\n          0.313\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09071241842847567,\n        \"min\": 0.405,\n        \"max\": 0.723,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.685,\n          0.715,\n          0.405\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11559300522584771,\n        \"min\": 0.313,\n        \"max\": 0.753,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.681,\n          0.714,\n          0.313\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07374905971959107,\n        \"min\": 0.538,\n        \"max\": 0.802,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.637,\n          0.734,\n          0.765\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1329379375426565,\n        \"min\": 0.079,\n        \"max\": 0.472,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.347,\n          0.4,\n          0.079\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["metrics_df_CNN.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Time Domain/CNN/Alpha_time_CNN.csv', index = False)"],"metadata":{"id":"_iOLsKpkfzdG","executionInfo":{"status":"ok","timestamp":1717499133018,"user_tz":-360,"elapsed":1681,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["# GRU"],"metadata":{"id":"GlmTFTtKzY0i"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout, GRU\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model_gru(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(GRU(256, return_sequences=True))\n","    model.add(GRU(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning_gru(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model_gru(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model_gru(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Alpha/CNN_GRU/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time_domain/Alpha/CNN_GRU/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"ieXSN-9PI4Dx","executionInfo":{"status":"ok","timestamp":1717499133018,"user_tz":-360,"elapsed":777,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["global_model_gru, metrics_df_gru = federated_learning_gru(Theta_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P-aLDvDmzfVZ","executionInfo":{"status":"ok","timestamp":1717500387320,"user_tz":-360,"elapsed":1255078,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"7b09ae1a-f970-47c3-f401-4d126ef82900"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Train shape: (4640, 18, 29), Test shape: (1194, 18, 29)\n","Train shape: (4418, 18, 29), Test shape: (1416, 18, 29)\n","Train shape: (4838, 18, 29), Test shape: (996, 18, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 1.4308 - accuracy: 0.5089"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 69ms/step - loss: 1.4307 - accuracy: 0.5116 - val_loss: 1.4285 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.4257 - accuracy: 0.5172 - val_loss: 1.4236 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.4207 - accuracy: 0.5210 - val_loss: 1.4189 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.4158 - accuracy: 0.5121 - val_loss: 1.4141 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.4107 - accuracy: 0.5307 - val_loss: 1.4093 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.4063 - accuracy: 0.5216 - val_loss: 1.4046 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.4013 - accuracy: 0.5242 - val_loss: 1.3999 - val_accuracy: 0.4871\n","Epoch 8/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.3963 - accuracy: 0.5267 - val_loss: 1.3952 - val_accuracy: 0.5453\n","Epoch 9/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.3915 - accuracy: 0.5321 - val_loss: 1.3907 - val_accuracy: 0.4860\n","Epoch 10/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.3871 - accuracy: 0.5283 - val_loss: 1.3859 - val_accuracy: 0.5366\n","Epoch 11/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.3821 - accuracy: 0.5423 - val_loss: 1.3812 - val_accuracy: 0.5560\n","Epoch 12/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.3772 - accuracy: 0.5256 - val_loss: 1.3766 - val_accuracy: 0.5453\n","Epoch 13/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.3718 - accuracy: 0.5477 - val_loss: 1.3719 - val_accuracy: 0.5636\n","Epoch 14/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3674 - accuracy: 0.5377 - val_loss: 1.3675 - val_accuracy: 0.5022\n","Epoch 15/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.3625 - accuracy: 0.5407 - val_loss: 1.3622 - val_accuracy: 0.5647\n","Epoch 16/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3571 - accuracy: 0.5577 - val_loss: 1.3569 - val_accuracy: 0.5636\n","Epoch 17/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3510 - accuracy: 0.5655 - val_loss: 1.3516 - val_accuracy: 0.5571\n","Epoch 18/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.3471 - accuracy: 0.5571 - val_loss: 1.3466 - val_accuracy: 0.5700\n","Epoch 19/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.3406 - accuracy: 0.5601 - val_loss: 1.3411 - val_accuracy: 0.5625\n","Epoch 20/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.3353 - accuracy: 0.5625 - val_loss: 1.3360 - val_accuracy: 0.5571\n","Epoch 21/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.3307 - accuracy: 0.5684 - val_loss: 1.3309 - val_accuracy: 0.5603\n","Epoch 22/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3242 - accuracy: 0.5760 - val_loss: 1.3261 - val_accuracy: 0.5528\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3210 - accuracy: 0.5630 - val_loss: 1.3204 - val_accuracy: 0.5614\n","Epoch 24/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.3155 - accuracy: 0.5668 - val_loss: 1.3158 - val_accuracy: 0.5636\n","Epoch 25/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.3112 - accuracy: 0.5754 - val_loss: 1.3105 - val_accuracy: 0.5733\n","Epoch 26/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.3058 - accuracy: 0.5768 - val_loss: 1.3060 - val_accuracy: 0.5776\n","Epoch 27/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2997 - accuracy: 0.5816 - val_loss: 1.3051 - val_accuracy: 0.5603\n","Epoch 28/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2964 - accuracy: 0.5770 - val_loss: 1.2974 - val_accuracy: 0.5765\n","Epoch 29/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2920 - accuracy: 0.5719 - val_loss: 1.2964 - val_accuracy: 0.5700\n","Epoch 30/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2861 - accuracy: 0.5773 - val_loss: 1.2894 - val_accuracy: 0.5700\n","Epoch 31/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2817 - accuracy: 0.5867 - val_loss: 1.2857 - val_accuracy: 0.5657\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2765 - accuracy: 0.5881 - val_loss: 1.2815 - val_accuracy: 0.5765\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2744 - accuracy: 0.5827 - val_loss: 1.2778 - val_accuracy: 0.5722\n","Epoch 34/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.2701 - accuracy: 0.5830 - val_loss: 1.2763 - val_accuracy: 0.5560\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2660 - accuracy: 0.5870 - val_loss: 1.2766 - val_accuracy: 0.5657\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2607 - accuracy: 0.5954 - val_loss: 1.2674 - val_accuracy: 0.5625\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2562 - accuracy: 0.5919 - val_loss: 1.2645 - val_accuracy: 0.5550\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2523 - accuracy: 0.5886 - val_loss: 1.2598 - val_accuracy: 0.5711\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2485 - accuracy: 0.5894 - val_loss: 1.2570 - val_accuracy: 0.5560\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2453 - accuracy: 0.5867 - val_loss: 1.2515 - val_accuracy: 0.5711\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2391 - accuracy: 0.6037 - val_loss: 1.2478 - val_accuracy: 0.5722\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2364 - accuracy: 0.5854 - val_loss: 1.2496 - val_accuracy: 0.5582\n","Epoch 43/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2324 - accuracy: 0.5956 - val_loss: 1.2415 - val_accuracy: 0.5679\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2271 - accuracy: 0.5962 - val_loss: 1.2369 - val_accuracy: 0.5744\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2235 - accuracy: 0.5913 - val_loss: 1.2341 - val_accuracy: 0.5668\n","Epoch 46/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.2209 - accuracy: 0.5897 - val_loss: 1.2294 - val_accuracy: 0.5873\n","Epoch 47/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.2151 - accuracy: 0.6010 - val_loss: 1.2273 - val_accuracy: 0.5700\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2118 - accuracy: 0.6008 - val_loss: 1.2250 - val_accuracy: 0.5636\n","Epoch 49/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.2078 - accuracy: 0.6048 - val_loss: 1.2192 - val_accuracy: 0.5754\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2035 - accuracy: 0.6008 - val_loss: 1.2155 - val_accuracy: 0.5754\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1969 - accuracy: 0.6080 - val_loss: 1.2131 - val_accuracy: 0.5841\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1976 - accuracy: 0.5991 - val_loss: 1.2186 - val_accuracy: 0.5593\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1901 - accuracy: 0.6067 - val_loss: 1.2055 - val_accuracy: 0.5797\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1864 - accuracy: 0.6029 - val_loss: 1.2051 - val_accuracy: 0.5733\n","Epoch 55/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1841 - accuracy: 0.6094 - val_loss: 1.2069 - val_accuracy: 0.5679\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1804 - accuracy: 0.6113 - val_loss: 1.1988 - val_accuracy: 0.5647\n","Epoch 57/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1755 - accuracy: 0.6037 - val_loss: 1.1926 - val_accuracy: 0.5765\n","Epoch 58/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1725 - accuracy: 0.6080 - val_loss: 1.1882 - val_accuracy: 0.5873\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1664 - accuracy: 0.6113 - val_loss: 1.1956 - val_accuracy: 0.5679\n","Epoch 60/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1666 - accuracy: 0.6032 - val_loss: 1.1799 - val_accuracy: 0.5819\n","Epoch 61/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1597 - accuracy: 0.6126 - val_loss: 1.1770 - val_accuracy: 0.5873\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1591 - accuracy: 0.6056 - val_loss: 1.1744 - val_accuracy: 0.5808\n","Epoch 63/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1489 - accuracy: 0.6258 - val_loss: 1.1844 - val_accuracy: 0.5603\n","Epoch 64/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.1496 - accuracy: 0.6118 - val_loss: 1.1681 - val_accuracy: 0.5916\n","Epoch 65/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.1449 - accuracy: 0.6204 - val_loss: 1.1659 - val_accuracy: 0.5981\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1426 - accuracy: 0.6218 - val_loss: 1.1596 - val_accuracy: 0.5819\n","Epoch 67/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1351 - accuracy: 0.6220 - val_loss: 1.1605 - val_accuracy: 0.5851\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1331 - accuracy: 0.6199 - val_loss: 1.1591 - val_accuracy: 0.5884\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1313 - accuracy: 0.6210 - val_loss: 1.1527 - val_accuracy: 0.5970\n","Epoch 70/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1238 - accuracy: 0.6242 - val_loss: 1.1479 - val_accuracy: 0.5851\n","Epoch 71/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1221 - accuracy: 0.6263 - val_loss: 1.1705 - val_accuracy: 0.5453\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1209 - accuracy: 0.6210 - val_loss: 1.1404 - val_accuracy: 0.5841\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1116 - accuracy: 0.6374 - val_loss: 1.1382 - val_accuracy: 0.5884\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1077 - accuracy: 0.6331 - val_loss: 1.1345 - val_accuracy: 0.5916\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1024 - accuracy: 0.6363 - val_loss: 1.1331 - val_accuracy: 0.5970\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0999 - accuracy: 0.6336 - val_loss: 1.1325 - val_accuracy: 0.5948\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0960 - accuracy: 0.6323 - val_loss: 1.1267 - val_accuracy: 0.5884\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0958 - accuracy: 0.6304 - val_loss: 1.1272 - val_accuracy: 0.5948\n","Epoch 79/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0910 - accuracy: 0.6374 - val_loss: 1.1196 - val_accuracy: 0.5873\n","Epoch 80/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0843 - accuracy: 0.6487 - val_loss: 1.1182 - val_accuracy: 0.6024\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0831 - accuracy: 0.6374 - val_loss: 1.1254 - val_accuracy: 0.5819\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0806 - accuracy: 0.6398 - val_loss: 1.1254 - val_accuracy: 0.5657\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0722 - accuracy: 0.6439 - val_loss: 1.1085 - val_accuracy: 0.5959\n","Epoch 84/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0714 - accuracy: 0.6501 - val_loss: 1.1063 - val_accuracy: 0.6034\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0671 - accuracy: 0.6506 - val_loss: 1.1082 - val_accuracy: 0.5991\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0652 - accuracy: 0.6457 - val_loss: 1.1009 - val_accuracy: 0.5970\n","Epoch 87/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.0632 - accuracy: 0.6420 - val_loss: 1.0973 - val_accuracy: 0.6045\n","Epoch 88/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0574 - accuracy: 0.6476 - val_loss: 1.1047 - val_accuracy: 0.5797\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0544 - accuracy: 0.6457 - val_loss: 1.1040 - val_accuracy: 0.5711\n","Epoch 90/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.0583 - accuracy: 0.6320 - val_loss: 1.0924 - val_accuracy: 0.6067\n","Epoch 91/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0459 - accuracy: 0.6511 - val_loss: 1.0927 - val_accuracy: 0.5894\n","Epoch 92/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0429 - accuracy: 0.6562 - val_loss: 1.0913 - val_accuracy: 0.5884\n","Epoch 93/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0419 - accuracy: 0.6536 - val_loss: 1.0957 - val_accuracy: 0.5981\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0373 - accuracy: 0.6600 - val_loss: 1.0799 - val_accuracy: 0.6034\n","Epoch 95/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0296 - accuracy: 0.6608 - val_loss: 1.0902 - val_accuracy: 0.5700\n","Epoch 96/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0271 - accuracy: 0.6633 - val_loss: 1.0784 - val_accuracy: 0.5959\n","Epoch 97/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.0203 - accuracy: 0.6657 - val_loss: 1.0744 - val_accuracy: 0.6078\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0184 - accuracy: 0.6692 - val_loss: 1.0734 - val_accuracy: 0.5970\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0165 - accuracy: 0.6643 - val_loss: 1.0772 - val_accuracy: 0.5873\n","Epoch 100/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0129 - accuracy: 0.6689 - val_loss: 1.0673 - val_accuracy: 0.6164\n","{'loss': [1.4306845664978027, 1.4256670475006104, 1.4207390546798706, 1.41584050655365, 1.4107383489608765, 1.4062848091125488, 1.4013383388519287, 1.3963152170181274, 1.3915268182754517, 1.3870912790298462, 1.3820518255233765, 1.377221703529358, 1.3717694282531738, 1.3673748970031738, 1.3624658584594727, 1.3570808172225952, 1.3510187864303589, 1.347082257270813, 1.3405932188034058, 1.335279107093811, 1.3307429552078247, 1.3242108821868896, 1.320992350578308, 1.3155428171157837, 1.3111646175384521, 1.30582857131958, 1.2997102737426758, 1.2964022159576416, 1.291975498199463, 1.286146640777588, 1.2816733121871948, 1.2765281200408936, 1.2743967771530151, 1.2700679302215576, 1.26595938205719, 1.2606518268585205, 1.256184697151184, 1.2523458003997803, 1.2484724521636963, 1.2453380823135376, 1.2391091585159302, 1.2363660335540771, 1.2323803901672363, 1.2270671129226685, 1.223512053489685, 1.2208776473999023, 1.2150524854660034, 1.2118343114852905, 1.2077620029449463, 1.2034837007522583, 1.1968690156936646, 1.1976349353790283, 1.190086007118225, 1.1863845586776733, 1.1840883493423462, 1.180419921875, 1.1754759550094604, 1.1724587678909302, 1.1663929224014282, 1.1665889024734497, 1.1597464084625244, 1.159063458442688, 1.1489185094833374, 1.1496316194534302, 1.1448588371276855, 1.142560601234436, 1.1350849866867065, 1.1331294775009155, 1.131299614906311, 1.1237802505493164, 1.122072696685791, 1.1209406852722168, 1.1115697622299194, 1.1077237129211426, 1.1023712158203125, 1.0999451875686646, 1.0959503650665283, 1.0958313941955566, 1.0909754037857056, 1.0843182802200317, 1.0831345319747925, 1.0805590152740479, 1.0722286701202393, 1.0714043378829956, 1.067138433456421, 1.065248727798462, 1.0631638765335083, 1.0574358701705933, 1.0543582439422607, 1.0583382844924927, 1.0458589792251587, 1.0428545475006104, 1.0418622493743896, 1.0372976064682007, 1.0296299457550049, 1.0271412134170532, 1.020326852798462, 1.0184228420257568, 1.0165472030639648, 1.0129375457763672], 'accuracy': [0.5115840435028076, 0.517241358757019, 0.5210129022598267, 0.5121228694915771, 0.5307112336158752, 0.5215517282485962, 0.5242456793785095, 0.5266702771186829, 0.5320581793785095, 0.5282866358757019, 0.5422952771186829, 0.5255926847457886, 0.5476831793785095, 0.537715494632721, 0.540678858757019, 0.5576508641242981, 0.5654633641242981, 0.5571120977401733, 0.5600754022598267, 0.5625, 0.5684267282485962, 0.5759698152542114, 0.5630387663841248, 0.5668103694915771, 0.5754310488700867, 0.576777994632721, 0.5816271305084229, 0.5770474076271057, 0.571928858757019, 0.5773168206214905, 0.5867456793785095, 0.5880926847457886, 0.5827047228813171, 0.5829741358757019, 0.5870150923728943, 0.595366358757019, 0.5918642282485962, 0.5886314511299133, 0.5894396305084229, 0.5867456793785095, 0.6037176847457886, 0.5853987336158752, 0.5956357717514038, 0.5961745977401733, 0.5913254022598267, 0.5897090435028076, 0.6010237336158752, 0.6007543206214905, 0.6047952771186829, 0.6007543206214905, 0.608027994632721, 0.5991379022598267, 0.6066810488700867, 0.602909505367279, 0.609375, 0.6112607717514038, 0.6037176847457886, 0.608027994632721, 0.6112607717514038, 0.603178858757019, 0.6126077771186829, 0.6056034564971924, 0.6258081793785095, 0.6117995977401733, 0.6204202771186829, 0.6217672228813171, 0.6220366358757019, 0.6198814511299133, 0.6209590435028076, 0.6241918206214905, 0.626347005367279, 0.6209590435028076, 0.6373922228813171, 0.6330819129943848, 0.6363146305084229, 0.6336206793785095, 0.6322737336158752, 0.6303879022598267, 0.6373922228813171, 0.6487069129943848, 0.6373922228813171, 0.6398168206214905, 0.6438577771186829, 0.650053858757019, 0.6505926847457886, 0.6457435488700867, 0.641972005367279, 0.6476293206214905, 0.6457435488700867, 0.6320043206214905, 0.6511314511299133, 0.65625, 0.6535560488700867, 0.6600215435028076, 0.6608297228813171, 0.6632543206214905, 0.665678858757019, 0.6691810488700867, 0.6643319129943848, 0.6689116358757019], 'val_loss': [1.4284881353378296, 1.423627495765686, 1.4188755750656128, 1.4141026735305786, 1.4093436002731323, 1.4046416282653809, 1.3999392986297607, 1.3952105045318604, 1.3906699419021606, 1.3859275579452515, 1.3812426328659058, 1.376562476158142, 1.3718693256378174, 1.3675066232681274, 1.3622093200683594, 1.3569098711013794, 1.3516312837600708, 1.3465992212295532, 1.3411200046539307, 1.336016058921814, 1.3309327363967896, 1.3260924816131592, 1.3204315900802612, 1.315813660621643, 1.310526967048645, 1.3059700727462769, 1.3051400184631348, 1.2974348068237305, 1.2963768243789673, 1.2894171476364136, 1.2856806516647339, 1.28152596950531, 1.2778282165527344, 1.2762776613235474, 1.276628017425537, 1.267388939857483, 1.264460563659668, 1.2597768306732178, 1.2569739818572998, 1.2515296936035156, 1.2478163242340088, 1.249638557434082, 1.2415012121200562, 1.2369204759597778, 1.234120488166809, 1.2294026613235474, 1.2272570133209229, 1.224991798400879, 1.2191675901412964, 1.2155438661575317, 1.2130566835403442, 1.2185609340667725, 1.205483317375183, 1.205079436302185, 1.2069387435913086, 1.1987836360931396, 1.1926298141479492, 1.188179850578308, 1.1956284046173096, 1.179868221282959, 1.1769672632217407, 1.1744052171707153, 1.184369683265686, 1.1681113243103027, 1.1659483909606934, 1.1596107482910156, 1.1604790687561035, 1.1590520143508911, 1.152674674987793, 1.1479449272155762, 1.1705081462860107, 1.1404306888580322, 1.1381762027740479, 1.1344927549362183, 1.1330962181091309, 1.132474422454834, 1.1266820430755615, 1.1271696090698242, 1.1196470260620117, 1.118208646774292, 1.1254318952560425, 1.1253831386566162, 1.1085455417633057, 1.1063172817230225, 1.1081719398498535, 1.1008625030517578, 1.0972764492034912, 1.1046595573425293, 1.1039692163467407, 1.0924475193023682, 1.0927447080612183, 1.0912976264953613, 1.0957257747650146, 1.0799049139022827, 1.0901566743850708, 1.0784177780151367, 1.0743762254714966, 1.0733586549758911, 1.0772167444229126, 1.067269206047058], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48706895112991333, 0.545258641242981, 0.48599138855934143, 0.5366379022598267, 0.556034505367279, 0.545258641242981, 0.5635775923728943, 0.5021551847457886, 0.5646551847457886, 0.5635775923728943, 0.5571120977401733, 0.5700430870056152, 0.5625, 0.5571120977401733, 0.5603448152542114, 0.5528017282485962, 0.5614224076271057, 0.5635775923728943, 0.5732758641242981, 0.5775862336158752, 0.5603448152542114, 0.576508641242981, 0.5700430870056152, 0.5700430870056152, 0.5657327771186829, 0.576508641242981, 0.5721982717514038, 0.556034505367279, 0.5657327771186829, 0.5625, 0.5549569129943848, 0.5711206793785095, 0.556034505367279, 0.5711206793785095, 0.5721982717514038, 0.5581896305084229, 0.5678879022598267, 0.5743534564971924, 0.5668103694915771, 0.587284505367279, 0.5700430870056152, 0.5635775923728943, 0.5754310488700867, 0.5754310488700867, 0.5840517282485962, 0.5592672228813171, 0.579741358757019, 0.5732758641242981, 0.5678879022598267, 0.5646551847457886, 0.576508641242981, 0.587284505367279, 0.5678879022598267, 0.5818965435028076, 0.587284505367279, 0.5808189511299133, 0.5603448152542114, 0.5915948152542114, 0.5980603694915771, 0.5818965435028076, 0.5851293206214905, 0.5883620977401733, 0.5969827771186829, 0.5851293206214905, 0.545258641242981, 0.5840517282485962, 0.5883620977401733, 0.5915948152542114, 0.5969827771186829, 0.5948275923728943, 0.5883620977401733, 0.5948275923728943, 0.587284505367279, 0.6023706793785095, 0.5818965435028076, 0.5657327771186829, 0.5959051847457886, 0.6034482717514038, 0.5991379022598267, 0.5969827771186829, 0.6045258641242981, 0.579741358757019, 0.5711206793785095, 0.6066810488700867, 0.5894396305084229, 0.5883620977401733, 0.5980603694915771, 0.6034482717514038, 0.5700430870056152, 0.5959051847457886, 0.607758641242981, 0.5969827771186829, 0.587284505367279, 0.6163793206214905]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 1.4316 - accuracy: 0.4887"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 72ms/step - loss: 1.4316 - accuracy: 0.4887 - val_loss: 1.4287 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4261 - accuracy: 0.5088 - val_loss: 1.4240 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4218 - accuracy: 0.5003 - val_loss: 1.4194 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4168 - accuracy: 0.5122 - val_loss: 1.4148 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.4121 - accuracy: 0.5105 - val_loss: 1.4102 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.4078 - accuracy: 0.5091 - val_loss: 1.4057 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.4031 - accuracy: 0.5181 - val_loss: 1.4011 - val_accuracy: 0.4943\n","Epoch 8/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3984 - accuracy: 0.5221 - val_loss: 1.3966 - val_accuracy: 0.4943\n","Epoch 9/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.3938 - accuracy: 0.5178 - val_loss: 1.3921 - val_accuracy: 0.5147\n","Epoch 10/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.3890 - accuracy: 0.5277 - val_loss: 1.3876 - val_accuracy: 0.5509\n","Epoch 11/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.3847 - accuracy: 0.5192 - val_loss: 1.3832 - val_accuracy: 0.5724\n","Epoch 12/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3804 - accuracy: 0.5224 - val_loss: 1.3787 - val_accuracy: 0.5622\n","Epoch 13/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3754 - accuracy: 0.5260 - val_loss: 1.3742 - val_accuracy: 0.5724\n","Epoch 14/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3706 - accuracy: 0.5297 - val_loss: 1.3696 - val_accuracy: 0.5600\n","Epoch 15/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3667 - accuracy: 0.5291 - val_loss: 1.3651 - val_accuracy: 0.5543\n","Epoch 16/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.3615 - accuracy: 0.5399 - val_loss: 1.3604 - val_accuracy: 0.5769\n","Epoch 17/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3578 - accuracy: 0.5407 - val_loss: 1.3561 - val_accuracy: 0.5226\n","Epoch 18/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3522 - accuracy: 0.5464 - val_loss: 1.3513 - val_accuracy: 0.5373\n","Epoch 19/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3478 - accuracy: 0.5529 - val_loss: 1.3464 - val_accuracy: 0.5566\n","Epoch 20/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3433 - accuracy: 0.5439 - val_loss: 1.3415 - val_accuracy: 0.5679\n","Epoch 21/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3380 - accuracy: 0.5518 - val_loss: 1.3366 - val_accuracy: 0.5645\n","Epoch 22/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.3335 - accuracy: 0.5603 - val_loss: 1.3313 - val_accuracy: 0.5860\n","Epoch 23/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3279 - accuracy: 0.5659 - val_loss: 1.3264 - val_accuracy: 0.5679\n","Epoch 24/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3238 - accuracy: 0.5577 - val_loss: 1.3223 - val_accuracy: 0.5520\n","Epoch 25/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3200 - accuracy: 0.5535 - val_loss: 1.3162 - val_accuracy: 0.5837\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3146 - accuracy: 0.5628 - val_loss: 1.3116 - val_accuracy: 0.5724\n","Epoch 27/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3103 - accuracy: 0.5555 - val_loss: 1.3077 - val_accuracy: 0.5690\n","Epoch 28/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3049 - accuracy: 0.5713 - val_loss: 1.3028 - val_accuracy: 0.5667\n","Epoch 29/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.2996 - accuracy: 0.5736 - val_loss: 1.2985 - val_accuracy: 0.5701\n","Epoch 30/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2940 - accuracy: 0.5733 - val_loss: 1.2937 - val_accuracy: 0.5701\n","Epoch 31/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2909 - accuracy: 0.5739 - val_loss: 1.2889 - val_accuracy: 0.5837\n","Epoch 32/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2877 - accuracy: 0.5628 - val_loss: 1.2850 - val_accuracy: 0.5803\n","Epoch 33/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2833 - accuracy: 0.5722 - val_loss: 1.2869 - val_accuracy: 0.5464\n","Epoch 34/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2785 - accuracy: 0.5688 - val_loss: 1.2774 - val_accuracy: 0.5758\n","Epoch 35/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2744 - accuracy: 0.5736 - val_loss: 1.2726 - val_accuracy: 0.5826\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2691 - accuracy: 0.5733 - val_loss: 1.2696 - val_accuracy: 0.5781\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2663 - accuracy: 0.5744 - val_loss: 1.2659 - val_accuracy: 0.5701\n","Epoch 38/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2622 - accuracy: 0.5775 - val_loss: 1.2615 - val_accuracy: 0.5769\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2577 - accuracy: 0.5781 - val_loss: 1.2573 - val_accuracy: 0.5826\n","Epoch 40/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2547 - accuracy: 0.5815 - val_loss: 1.2535 - val_accuracy: 0.5871\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2498 - accuracy: 0.5804 - val_loss: 1.2499 - val_accuracy: 0.5758\n","Epoch 42/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2452 - accuracy: 0.5846 - val_loss: 1.2471 - val_accuracy: 0.5622\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2427 - accuracy: 0.5789 - val_loss: 1.2435 - val_accuracy: 0.5656\n","Epoch 44/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2372 - accuracy: 0.5894 - val_loss: 1.2413 - val_accuracy: 0.5645\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2335 - accuracy: 0.5928 - val_loss: 1.2371 - val_accuracy: 0.5645\n","Epoch 46/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.2295 - accuracy: 0.5894 - val_loss: 1.2315 - val_accuracy: 0.5995\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2271 - accuracy: 0.5908 - val_loss: 1.2287 - val_accuracy: 0.5905\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2224 - accuracy: 0.5908 - val_loss: 1.2241 - val_accuracy: 0.5928\n","Epoch 49/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2178 - accuracy: 0.5897 - val_loss: 1.2216 - val_accuracy: 0.5928\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2127 - accuracy: 0.5886 - val_loss: 1.2188 - val_accuracy: 0.5724\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2083 - accuracy: 0.6013 - val_loss: 1.2137 - val_accuracy: 0.5701\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2083 - accuracy: 0.5911 - val_loss: 1.2113 - val_accuracy: 0.5939\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2024 - accuracy: 0.5971 - val_loss: 1.2102 - val_accuracy: 0.5611\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1969 - accuracy: 0.6005 - val_loss: 1.2048 - val_accuracy: 0.5713\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1977 - accuracy: 0.5917 - val_loss: 1.2043 - val_accuracy: 0.5645\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1900 - accuracy: 0.5863 - val_loss: 1.1943 - val_accuracy: 0.5814\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1845 - accuracy: 0.6092 - val_loss: 1.1953 - val_accuracy: 0.5679\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1809 - accuracy: 0.6095 - val_loss: 1.1879 - val_accuracy: 0.5962\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1794 - accuracy: 0.5979 - val_loss: 1.1830 - val_accuracy: 0.5882\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1756 - accuracy: 0.6089 - val_loss: 1.1805 - val_accuracy: 0.5950\n","Epoch 61/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1709 - accuracy: 0.6047 - val_loss: 1.1769 - val_accuracy: 0.5837\n","Epoch 62/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1660 - accuracy: 0.6022 - val_loss: 1.1759 - val_accuracy: 0.5837\n","Epoch 63/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1604 - accuracy: 0.6126 - val_loss: 1.1697 - val_accuracy: 0.5871\n","Epoch 64/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1601 - accuracy: 0.6064 - val_loss: 1.1660 - val_accuracy: 0.5984\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1555 - accuracy: 0.6183 - val_loss: 1.1635 - val_accuracy: 0.5894\n","Epoch 66/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1521 - accuracy: 0.6126 - val_loss: 1.1607 - val_accuracy: 0.5871\n","Epoch 67/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.1459 - accuracy: 0.6205 - val_loss: 1.1548 - val_accuracy: 0.6041\n","Epoch 68/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1406 - accuracy: 0.6180 - val_loss: 1.1659 - val_accuracy: 0.5860\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1395 - accuracy: 0.6180 - val_loss: 1.1487 - val_accuracy: 0.6041\n","Epoch 70/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1344 - accuracy: 0.6149 - val_loss: 1.1455 - val_accuracy: 0.5916\n","Epoch 71/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1326 - accuracy: 0.6293 - val_loss: 1.1416 - val_accuracy: 0.6086\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1262 - accuracy: 0.6285 - val_loss: 1.1469 - val_accuracy: 0.5871\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1225 - accuracy: 0.6310 - val_loss: 1.1348 - val_accuracy: 0.6029\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1165 - accuracy: 0.6404 - val_loss: 1.1338 - val_accuracy: 0.5894\n","Epoch 75/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1128 - accuracy: 0.6375 - val_loss: 1.1327 - val_accuracy: 0.5894\n","Epoch 76/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1097 - accuracy: 0.6310 - val_loss: 1.1247 - val_accuracy: 0.6029\n","Epoch 77/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1078 - accuracy: 0.6350 - val_loss: 1.1258 - val_accuracy: 0.6075\n","Epoch 78/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1007 - accuracy: 0.6440 - val_loss: 1.1286 - val_accuracy: 0.5826\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1031 - accuracy: 0.6344 - val_loss: 1.1201 - val_accuracy: 0.5962\n","Epoch 80/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.0948 - accuracy: 0.6327 - val_loss: 1.1134 - val_accuracy: 0.6165\n","Epoch 81/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0910 - accuracy: 0.6375 - val_loss: 1.1105 - val_accuracy: 0.6154\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0894 - accuracy: 0.6440 - val_loss: 1.1137 - val_accuracy: 0.5905\n","Epoch 83/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0813 - accuracy: 0.6494 - val_loss: 1.1081 - val_accuracy: 0.6063\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0811 - accuracy: 0.6395 - val_loss: 1.1083 - val_accuracy: 0.5962\n","Epoch 85/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.0763 - accuracy: 0.6534 - val_loss: 1.1036 - val_accuracy: 0.6176\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0699 - accuracy: 0.6508 - val_loss: 1.0956 - val_accuracy: 0.6143\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0643 - accuracy: 0.6644 - val_loss: 1.0934 - val_accuracy: 0.5995\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0659 - accuracy: 0.6463 - val_loss: 1.0925 - val_accuracy: 0.6029\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0634 - accuracy: 0.6505 - val_loss: 1.1106 - val_accuracy: 0.5792\n","Epoch 90/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0556 - accuracy: 0.6613 - val_loss: 1.0931 - val_accuracy: 0.5916\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0531 - accuracy: 0.6590 - val_loss: 1.0859 - val_accuracy: 0.6120\n","Epoch 92/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0484 - accuracy: 0.6565 - val_loss: 1.0920 - val_accuracy: 0.5916\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0467 - accuracy: 0.6585 - val_loss: 1.0863 - val_accuracy: 0.5973\n","Epoch 94/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0458 - accuracy: 0.6638 - val_loss: 1.0755 - val_accuracy: 0.6063\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0389 - accuracy: 0.6638 - val_loss: 1.0786 - val_accuracy: 0.6007\n","Epoch 96/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0309 - accuracy: 0.6678 - val_loss: 1.0733 - val_accuracy: 0.6086\n","Epoch 97/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0379 - accuracy: 0.6483 - val_loss: 1.0682 - val_accuracy: 0.6131\n","Epoch 98/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.0316 - accuracy: 0.6689 - val_loss: 1.0662 - val_accuracy: 0.6188\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0251 - accuracy: 0.6701 - val_loss: 1.0651 - val_accuracy: 0.6120\n","Epoch 100/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0221 - accuracy: 0.6718 - val_loss: 1.0614 - val_accuracy: 0.6188\n","{'loss': [1.4315892457962036, 1.4260966777801514, 1.421768307685852, 1.4167828559875488, 1.4121097326278687, 1.4077800512313843, 1.403052568435669, 1.398377537727356, 1.3938000202178955, 1.3889777660369873, 1.3847274780273438, 1.3803693056106567, 1.3754403591156006, 1.3706103563308716, 1.3667125701904297, 1.361542820930481, 1.3577589988708496, 1.3522155284881592, 1.3478403091430664, 1.3433315753936768, 1.3379703760147095, 1.333501935005188, 1.3278933763504028, 1.3237810134887695, 1.3199865818023682, 1.3145864009857178, 1.3102777004241943, 1.3048818111419678, 1.2996116876602173, 1.2939966917037964, 1.290944218635559, 1.2876949310302734, 1.2832907438278198, 1.278480887413025, 1.274398922920227, 1.2690832614898682, 1.2662757635116577, 1.2621833086013794, 1.2576980590820312, 1.2546690702438354, 1.249784231185913, 1.245221495628357, 1.2427079677581787, 1.2371718883514404, 1.2335469722747803, 1.2294774055480957, 1.2270745038986206, 1.2223588228225708, 1.2177518606185913, 1.212662696838379, 1.2082797288894653, 1.208287000656128, 1.2024387121200562, 1.1969448328018188, 1.1976591348648071, 1.1900118589401245, 1.184487223625183, 1.1808632612228394, 1.179399013519287, 1.1756428480148315, 1.1709233522415161, 1.1659907102584839, 1.1604201793670654, 1.1600631475448608, 1.1554889678955078, 1.1521180868148804, 1.1459259986877441, 1.140583872795105, 1.1395461559295654, 1.134427547454834, 1.1325881481170654, 1.126244306564331, 1.122510552406311, 1.1165025234222412, 1.1128339767456055, 1.1097171306610107, 1.1078379154205322, 1.1006525754928589, 1.1031030416488647, 1.0947649478912354, 1.09095299243927, 1.0894187688827515, 1.0812983512878418, 1.0810920000076294, 1.076345443725586, 1.0699235200881958, 1.0642926692962646, 1.0658971071243286, 1.0633504390716553, 1.0556046962738037, 1.0530723333358765, 1.048398733139038, 1.046663761138916, 1.0457688570022583, 1.0388675928115845, 1.030914068222046, 1.0379465818405151, 1.0316228866577148, 1.025108814239502, 1.0221346616744995], 'accuracy': [0.4886813759803772, 0.5087719559669495, 0.5002829432487488, 0.5121675133705139, 0.5104697346687317, 0.5090548992156982, 0.5181097984313965, 0.5220713019371033, 0.5178267955780029, 0.5277306437492371, 0.5192416310310364, 0.522354245185852, 0.5260328054428101, 0.5297113656997681, 0.5291454195976257, 0.539898157119751, 0.5407470464706421, 0.5464063286781311, 0.552914559841156, 0.5438596606254578, 0.5517826676368713, 0.5602716207504272, 0.565930962562561, 0.5577249526977539, 0.5534804463386536, 0.5628183484077454, 0.5554612278938293, 0.5713073015213013, 0.5735710263252258, 0.573288083076477, 0.5738539695739746, 0.5628183484077454, 0.5721561908721924, 0.5687606334686279, 0.5735710263252258, 0.573288083076477, 0.5744199156761169, 0.5775325298309326, 0.578098475933075, 0.5814940333366394, 0.5803622007369995, 0.5846067070960999, 0.5789473652839661, 0.5894170999526978, 0.5928126573562622, 0.5894170999526978, 0.5908319354057312, 0.5908319354057312, 0.5897000432014465, 0.5885682106018066, 0.6013016700744629, 0.59111487865448, 0.5970571637153625, 0.600452721118927, 0.5916808247566223, 0.5863044857978821, 0.6092246770858765, 0.6095076203346252, 0.5979060530662537, 0.6089417338371277, 0.6046972274780273, 0.602150559425354, 0.6126202344894409, 0.6063950061798096, 0.6182795763015747, 0.6126202344894409, 0.6205433011054993, 0.6179966330528259, 0.6179966330528259, 0.6148839592933655, 0.629315197467804, 0.6284663081169128, 0.631013035774231, 0.640350878238678, 0.6375212073326111, 0.631013035774231, 0.6349745392799377, 0.644029438495636, 0.6344085931777954, 0.6327108144760132, 0.6375212073326111, 0.644029438495636, 0.6494057774543762, 0.6395019888877869, 0.653367280960083, 0.6508206129074097, 0.664402961730957, 0.6462931632995605, 0.6505376100540161, 0.6612903475761414, 0.6590266227722168, 0.6564798951148987, 0.6584606766700745, 0.6638370156288147, 0.6638370156288147, 0.6677985191345215, 0.6482738852500916, 0.6689304113388062, 0.670062243938446, 0.6717600226402283], 'val_loss': [1.428666353225708, 1.42401921749115, 1.4194114208221436, 1.414815902709961, 1.410237193107605, 1.4056791067123413, 1.401138186454773, 1.3966336250305176, 1.3921362161636353, 1.3876267671585083, 1.3831502199172974, 1.37867271900177, 1.3741841316223145, 1.3696413040161133, 1.3651026487350464, 1.360425591468811, 1.356139063835144, 1.3513027429580688, 1.3463939428329468, 1.341474175453186, 1.3365819454193115, 1.3312841653823853, 1.3263540267944336, 1.322279930114746, 1.3161922693252563, 1.311609148979187, 1.3077061176300049, 1.3027526140213013, 1.2984555959701538, 1.2936900854110718, 1.2888721227645874, 1.284960150718689, 1.2868626117706299, 1.2774341106414795, 1.2726466655731201, 1.2695748805999756, 1.2658958435058594, 1.2614957094192505, 1.2573379278182983, 1.253488302230835, 1.249945044517517, 1.2471445798873901, 1.2434526681900024, 1.2412925958633423, 1.2370563745498657, 1.2314503192901611, 1.2286701202392578, 1.2241127490997314, 1.2216202020645142, 1.2187796831130981, 1.2137082815170288, 1.2112802267074585, 1.2102323770523071, 1.2048276662826538, 1.2042664289474487, 1.194298505783081, 1.195281744003296, 1.1879035234451294, 1.1829785108566284, 1.1805282831192017, 1.1768989562988281, 1.1759439706802368, 1.1696783304214478, 1.1659537553787231, 1.163536787033081, 1.1606721878051758, 1.1547976732254028, 1.1659430265426636, 1.148712158203125, 1.1455219984054565, 1.1416103839874268, 1.1468700170516968, 1.1347919702529907, 1.1338326930999756, 1.1326555013656616, 1.1246925592422485, 1.1257508993148804, 1.1285995244979858, 1.1201140880584717, 1.1134331226348877, 1.1105015277862549, 1.1137359142303467, 1.1081383228302002, 1.1083087921142578, 1.103556752204895, 1.0955933332443237, 1.093441367149353, 1.0924652814865112, 1.1105780601501465, 1.0931015014648438, 1.0858958959579468, 1.0919744968414307, 1.0862916707992554, 1.0754787921905518, 1.078570008277893, 1.0732800960540771, 1.068204641342163, 1.0662275552749634, 1.0651047229766846, 1.061380386352539], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4943438768386841, 0.4943438768386841, 0.5147058963775635, 0.5509049892425537, 0.5723981857299805, 0.5622171759605408, 0.5723981857299805, 0.5599547624588013, 0.5542986392974854, 0.5769230723381042, 0.5226244330406189, 0.5373303294181824, 0.5565611124038696, 0.5678732991218567, 0.564479649066925, 0.5859728455543518, 0.5678732991218567, 0.5520362257957458, 0.5837104320526123, 0.5723981857299805, 0.5690045356750488, 0.5667420625686646, 0.570135772228241, 0.570135772228241, 0.5837104320526123, 0.5803167223930359, 0.5463801026344299, 0.5757918357849121, 0.5825791954994202, 0.5780543088912964, 0.570135772228241, 0.5769230723381042, 0.5825791954994202, 0.587104082107544, 0.5757918357849121, 0.5622171759605408, 0.5656108856201172, 0.564479649066925, 0.564479649066925, 0.5995475053787231, 0.5904977321624756, 0.5927602052688599, 0.5927602052688599, 0.5723981857299805, 0.570135772228241, 0.5938913822174072, 0.5610859990119934, 0.5712669491767883, 0.564479649066925, 0.581447958946228, 0.5678732991218567, 0.5961538553237915, 0.5882353186607361, 0.5950226187705994, 0.5837104320526123, 0.5837104320526123, 0.587104082107544, 0.598416268825531, 0.5893664956092834, 0.587104082107544, 0.6040723919868469, 0.5859728455543518, 0.6040723919868469, 0.5916289687156677, 0.6085972785949707, 0.587104082107544, 0.6029411554336548, 0.5893664956092834, 0.5893664956092834, 0.6029411554336548, 0.6074660420417786, 0.5825791954994202, 0.5961538553237915, 0.6165158152580261, 0.6153846383094788, 0.5904977321624756, 0.6063348650932312, 0.5961538553237915, 0.6176470518112183, 0.6142534017562866, 0.5995475053787231, 0.6029411554336548, 0.5791855454444885, 0.5916289687156677, 0.6119909286499023, 0.5916289687156677, 0.5972850918769836, 0.6063348650932312, 0.6006787419319153, 0.6085972785949707, 0.6131221652030945, 0.6187782883644104, 0.6119909286499023, 0.6187782883644104]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 1.4313 - accuracy: 0.4914"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 9s 66ms/step - loss: 1.4313 - accuracy: 0.4922 - val_loss: 1.4282 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4257 - accuracy: 0.4969 - val_loss: 1.4231 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.4205 - accuracy: 0.5114 - val_loss: 1.4180 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.4154 - accuracy: 0.5152 - val_loss: 1.4130 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.4106 - accuracy: 0.4992 - val_loss: 1.4080 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.4053 - accuracy: 0.5098 - val_loss: 1.4031 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3998 - accuracy: 0.5258 - val_loss: 1.3982 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3955 - accuracy: 0.5137 - val_loss: 1.3933 - val_accuracy: 0.4855\n","Epoch 9/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3902 - accuracy: 0.5088 - val_loss: 1.3885 - val_accuracy: 0.4855\n","Epoch 10/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3854 - accuracy: 0.5129 - val_loss: 1.3837 - val_accuracy: 0.4855\n","Epoch 11/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3805 - accuracy: 0.5245 - val_loss: 1.3789 - val_accuracy: 0.4855\n","Epoch 12/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3757 - accuracy: 0.5121 - val_loss: 1.3742 - val_accuracy: 0.4855\n","Epoch 13/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.3699 - accuracy: 0.5447 - val_loss: 1.3692 - val_accuracy: 0.4866\n","Epoch 14/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.3658 - accuracy: 0.5160 - val_loss: 1.3645 - val_accuracy: 0.4897\n","Epoch 15/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3606 - accuracy: 0.5292 - val_loss: 1.3599 - val_accuracy: 0.4835\n","Epoch 16/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.3559 - accuracy: 0.5258 - val_loss: 1.3549 - val_accuracy: 0.5072\n","Epoch 17/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3506 - accuracy: 0.5230 - val_loss: 1.3503 - val_accuracy: 0.5000\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3462 - accuracy: 0.5339 - val_loss: 1.3461 - val_accuracy: 0.4917\n","Epoch 19/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.3401 - accuracy: 0.5478 - val_loss: 1.3401 - val_accuracy: 0.5134\n","Epoch 20/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.3369 - accuracy: 0.5406 - val_loss: 1.3363 - val_accuracy: 0.5186\n","Epoch 21/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.3315 - accuracy: 0.5393 - val_loss: 1.3306 - val_accuracy: 0.5258\n","Epoch 22/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.3262 - accuracy: 0.5499 - val_loss: 1.3264 - val_accuracy: 0.5300\n","Epoch 23/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.3211 - accuracy: 0.5597 - val_loss: 1.3222 - val_accuracy: 0.5186\n","Epoch 24/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.3158 - accuracy: 0.5465 - val_loss: 1.3164 - val_accuracy: 0.5455\n","Epoch 25/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.3112 - accuracy: 0.5576 - val_loss: 1.3119 - val_accuracy: 0.5444\n","Epoch 26/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3063 - accuracy: 0.5661 - val_loss: 1.3081 - val_accuracy: 0.5310\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3009 - accuracy: 0.5589 - val_loss: 1.3036 - val_accuracy: 0.5362\n","Epoch 28/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2950 - accuracy: 0.5726 - val_loss: 1.2982 - val_accuracy: 0.5424\n","Epoch 29/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.2912 - accuracy: 0.5540 - val_loss: 1.2938 - val_accuracy: 0.5548\n","Epoch 30/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2860 - accuracy: 0.5623 - val_loss: 1.2913 - val_accuracy: 0.5227\n","Epoch 31/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2804 - accuracy: 0.5677 - val_loss: 1.2880 - val_accuracy: 0.5227\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2767 - accuracy: 0.5579 - val_loss: 1.2820 - val_accuracy: 0.5372\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2709 - accuracy: 0.5641 - val_loss: 1.2782 - val_accuracy: 0.5393\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2665 - accuracy: 0.5633 - val_loss: 1.2728 - val_accuracy: 0.5517\n","Epoch 35/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2618 - accuracy: 0.5649 - val_loss: 1.2685 - val_accuracy: 0.5527\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2548 - accuracy: 0.5786 - val_loss: 1.2721 - val_accuracy: 0.5403\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2517 - accuracy: 0.5749 - val_loss: 1.2619 - val_accuracy: 0.5434\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2489 - accuracy: 0.5677 - val_loss: 1.2629 - val_accuracy: 0.5393\n","Epoch 39/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2453 - accuracy: 0.5597 - val_loss: 1.2520 - val_accuracy: 0.5610\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2386 - accuracy: 0.5703 - val_loss: 1.2502 - val_accuracy: 0.5403\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2322 - accuracy: 0.5819 - val_loss: 1.2446 - val_accuracy: 0.5558\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2276 - accuracy: 0.5806 - val_loss: 1.2414 - val_accuracy: 0.5486\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2236 - accuracy: 0.5897 - val_loss: 1.2362 - val_accuracy: 0.5568\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2179 - accuracy: 0.5845 - val_loss: 1.2323 - val_accuracy: 0.5568\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2132 - accuracy: 0.5956 - val_loss: 1.2298 - val_accuracy: 0.5506\n","Epoch 46/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2112 - accuracy: 0.5837 - val_loss: 1.2246 - val_accuracy: 0.5640\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2064 - accuracy: 0.5881 - val_loss: 1.2210 - val_accuracy: 0.5620\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2013 - accuracy: 0.5920 - val_loss: 1.2171 - val_accuracy: 0.5610\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1968 - accuracy: 0.5959 - val_loss: 1.2157 - val_accuracy: 0.5568\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1923 - accuracy: 0.5961 - val_loss: 1.2086 - val_accuracy: 0.5599\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1883 - accuracy: 0.5879 - val_loss: 1.2049 - val_accuracy: 0.5589\n","Epoch 52/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.1829 - accuracy: 0.5974 - val_loss: 1.2013 - val_accuracy: 0.5702\n","Epoch 53/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1801 - accuracy: 0.5948 - val_loss: 1.1993 - val_accuracy: 0.5506\n","Epoch 54/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1731 - accuracy: 0.6059 - val_loss: 1.1932 - val_accuracy: 0.5651\n","Epoch 55/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.1698 - accuracy: 0.6034 - val_loss: 1.1958 - val_accuracy: 0.5733\n","Epoch 56/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1657 - accuracy: 0.6049 - val_loss: 1.1855 - val_accuracy: 0.5630\n","Epoch 57/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.1593 - accuracy: 0.6103 - val_loss: 1.1846 - val_accuracy: 0.5847\n","Epoch 58/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.1563 - accuracy: 0.6098 - val_loss: 1.1856 - val_accuracy: 0.5888\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1532 - accuracy: 0.6098 - val_loss: 1.1739 - val_accuracy: 0.5713\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1500 - accuracy: 0.6163 - val_loss: 1.1717 - val_accuracy: 0.5558\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1474 - accuracy: 0.6137 - val_loss: 1.1676 - val_accuracy: 0.5816\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1408 - accuracy: 0.6137 - val_loss: 1.1631 - val_accuracy: 0.5640\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1343 - accuracy: 0.6202 - val_loss: 1.1600 - val_accuracy: 0.5620\n","Epoch 64/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1305 - accuracy: 0.6173 - val_loss: 1.1570 - val_accuracy: 0.5888\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1273 - accuracy: 0.6119 - val_loss: 1.1620 - val_accuracy: 0.5826\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1256 - accuracy: 0.6124 - val_loss: 1.1536 - val_accuracy: 0.5475\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1179 - accuracy: 0.6264 - val_loss: 1.1458 - val_accuracy: 0.5847\n","Epoch 68/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.1175 - accuracy: 0.6238 - val_loss: 1.1481 - val_accuracy: 0.5950\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1153 - accuracy: 0.6209 - val_loss: 1.1444 - val_accuracy: 0.5940\n","Epoch 70/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.1099 - accuracy: 0.6230 - val_loss: 1.1367 - val_accuracy: 0.5961\n","Epoch 71/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.1055 - accuracy: 0.6253 - val_loss: 1.1366 - val_accuracy: 0.5981\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1004 - accuracy: 0.6230 - val_loss: 1.1391 - val_accuracy: 0.5599\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1063 - accuracy: 0.6191 - val_loss: 1.1315 - val_accuracy: 0.5971\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0936 - accuracy: 0.6264 - val_loss: 1.1219 - val_accuracy: 0.5733\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0902 - accuracy: 0.6310 - val_loss: 1.1223 - val_accuracy: 0.5961\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0878 - accuracy: 0.6307 - val_loss: 1.1161 - val_accuracy: 0.5899\n","Epoch 77/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0819 - accuracy: 0.6318 - val_loss: 1.1146 - val_accuracy: 0.6033\n","Epoch 78/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0784 - accuracy: 0.6385 - val_loss: 1.1149 - val_accuracy: 0.6002\n","Epoch 79/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0729 - accuracy: 0.6341 - val_loss: 1.1071 - val_accuracy: 0.5806\n","Epoch 80/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0716 - accuracy: 0.6344 - val_loss: 1.1050 - val_accuracy: 0.5971\n","Epoch 81/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0665 - accuracy: 0.6408 - val_loss: 1.1032 - val_accuracy: 0.5702\n","Epoch 82/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0645 - accuracy: 0.6437 - val_loss: 1.1067 - val_accuracy: 0.5702\n","Epoch 83/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0662 - accuracy: 0.6333 - val_loss: 1.0965 - val_accuracy: 0.5733\n","Epoch 84/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0547 - accuracy: 0.6506 - val_loss: 1.0942 - val_accuracy: 0.5950\n","Epoch 85/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0524 - accuracy: 0.6426 - val_loss: 1.0919 - val_accuracy: 0.5702\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0481 - accuracy: 0.6460 - val_loss: 1.0941 - val_accuracy: 0.5971\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0486 - accuracy: 0.6442 - val_loss: 1.0847 - val_accuracy: 0.5930\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0432 - accuracy: 0.6468 - val_loss: 1.0911 - val_accuracy: 0.6002\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0425 - accuracy: 0.6452 - val_loss: 1.0819 - val_accuracy: 0.5744\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0371 - accuracy: 0.6444 - val_loss: 1.0847 - val_accuracy: 0.5723\n","Epoch 91/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0374 - accuracy: 0.6499 - val_loss: 1.0773 - val_accuracy: 0.5992\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0297 - accuracy: 0.6525 - val_loss: 1.0839 - val_accuracy: 0.6023\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0242 - accuracy: 0.6550 - val_loss: 1.0717 - val_accuracy: 0.5837\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0242 - accuracy: 0.6501 - val_loss: 1.0672 - val_accuracy: 0.5795\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0206 - accuracy: 0.6478 - val_loss: 1.0652 - val_accuracy: 0.5950\n","Epoch 96/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0138 - accuracy: 0.6620 - val_loss: 1.0645 - val_accuracy: 0.6054\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0159 - accuracy: 0.6494 - val_loss: 1.0620 - val_accuracy: 0.6023\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0081 - accuracy: 0.6571 - val_loss: 1.0588 - val_accuracy: 0.6054\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0049 - accuracy: 0.6607 - val_loss: 1.0553 - val_accuracy: 0.5816\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0045 - accuracy: 0.6612 - val_loss: 1.0509 - val_accuracy: 0.6054\n","{'loss': [1.431308627128601, 1.4256619215011597, 1.4204577207565308, 1.4154094457626343, 1.4105883836746216, 1.405334234237671, 1.3998491764068604, 1.3954664468765259, 1.3902037143707275, 1.3853679895401, 1.380504846572876, 1.3757212162017822, 1.3698556423187256, 1.3658428192138672, 1.3606265783309937, 1.3559155464172363, 1.3506449460983276, 1.3461841344833374, 1.340102195739746, 1.3369072675704956, 1.331483006477356, 1.3262419700622559, 1.3211437463760376, 1.315841555595398, 1.3111613988876343, 1.3063462972640991, 1.300925374031067, 1.2950176000595093, 1.2912077903747559, 1.2860124111175537, 1.280442714691162, 1.2767138481140137, 1.2708561420440674, 1.2664990425109863, 1.261757493019104, 1.2547622919082642, 1.2517287731170654, 1.2488888502120972, 1.2453193664550781, 1.2386168241500854, 1.2322481870651245, 1.227552056312561, 1.223568081855774, 1.2178961038589478, 1.213179349899292, 1.2111608982086182, 1.2063792943954468, 1.2012639045715332, 1.196779489517212, 1.1923185586929321, 1.1883395910263062, 1.1828527450561523, 1.1801481246948242, 1.1730512380599976, 1.1697709560394287, 1.1656956672668457, 1.1593035459518433, 1.1562573909759521, 1.153225064277649, 1.1500450372695923, 1.147434115409851, 1.1407866477966309, 1.1342601776123047, 1.13047456741333, 1.1272542476654053, 1.1255791187286377, 1.1178926229476929, 1.117460012435913, 1.1152511835098267, 1.1099494695663452, 1.1054590940475464, 1.100366234779358, 1.106285572052002, 1.093604326248169, 1.0901659727096558, 1.0878236293792725, 1.0818811655044556, 1.0783772468566895, 1.0729225873947144, 1.0716016292572021, 1.0665167570114136, 1.0644510984420776, 1.0662426948547363, 1.054682731628418, 1.0523650646209717, 1.0480507612228394, 1.0485905408859253, 1.0431650876998901, 1.042488932609558, 1.0370792150497437, 1.0373502969741821, 1.0297069549560547, 1.0242141485214233, 1.0242215394973755, 1.020603060722351, 1.0137776136398315, 1.0158977508544922, 1.0081303119659424, 1.0048611164093018, 1.0044715404510498], 'accuracy': [0.4922480583190918, 0.49689921736717224, 0.511369526386261, 0.5152454972267151, 0.49922481179237366, 0.5098191499710083, 0.5258398056030273, 0.5136950612068176, 0.5087855458259583, 0.5129199028015137, 0.524547815322876, 0.5121446847915649, 0.5447028279304504, 0.516020655632019, 0.529198944568634, 0.5258398056030273, 0.5229974389076233, 0.5338501334190369, 0.5478036403656006, 0.540568470954895, 0.5392764806747437, 0.5498707890510559, 0.5596899390220642, 0.5465116500854492, 0.5576227307319641, 0.566149890422821, 0.5589147210121155, 0.5726098418235779, 0.5540051460266113, 0.5622739195823669, 0.5677002668380737, 0.5578811168670654, 0.564082682132721, 0.5633074641227722, 0.5648579001426697, 0.5785529613494873, 0.5749353766441345, 0.5677002668380737, 0.5596899390220642, 0.5702842473983765, 0.5819121599197388, 0.5806201696395874, 0.589664101600647, 0.5844961404800415, 0.5956072211265564, 0.5837209224700928, 0.5881136655807495, 0.5919896364212036, 0.5958656072616577, 0.5961240530014038, 0.5878552794456482, 0.5974160432815552, 0.5948320627212524, 0.6059431433677673, 0.6033591628074646, 0.6049095392227173, 0.6103359460830688, 0.6098191142082214, 0.6098191142082214, 0.6162790656089783, 0.6136950850486755, 0.6136950850486755, 0.6201550364494324, 0.6173126697540283, 0.6118863224983215, 0.6124030947685242, 0.6263566017150879, 0.6237726211547852, 0.6209302544593811, 0.6229974031448364, 0.6253229975700378, 0.6229974031448364, 0.6191214323043823, 0.6263566017150879, 0.631007730960846, 0.6307493448257446, 0.6317829489707947, 0.6385012865066528, 0.6341085433959961, 0.6343669295310974, 0.6408268809318542, 0.6436692476272583, 0.6333333253860474, 0.6506459712982178, 0.6426356434822083, 0.6459948420524597, 0.6441860198974609, 0.6467700004577637, 0.645219624042511, 0.644444465637207, 0.6498708128929138, 0.6524547934532166, 0.6550387740135193, 0.6501291990280151, 0.6478036046028137, 0.6620154976844788, 0.6493539810180664, 0.6571059226989746, 0.6607235074043274, 0.6612403392791748], 'val_loss': [1.42818021774292, 1.4230643510818481, 1.4179811477661133, 1.4130088090896606, 1.4080332517623901, 1.403059959411621, 1.3982391357421875, 1.3933457136154175, 1.3885349035263062, 1.3836662769317627, 1.3788707256317139, 1.3742291927337646, 1.369179606437683, 1.3644942045211792, 1.3598893880844116, 1.3549128770828247, 1.3503437042236328, 1.3461371660232544, 1.3401480913162231, 1.3363475799560547, 1.3306337594985962, 1.3263764381408691, 1.3221728801727295, 1.3164420127868652, 1.3118871450424194, 1.3081227540969849, 1.3035916090011597, 1.298192024230957, 1.2937946319580078, 1.2912904024124146, 1.288000464439392, 1.2820473909378052, 1.278242826461792, 1.2728153467178345, 1.268543004989624, 1.2721266746520996, 1.2619011402130127, 1.2628843784332275, 1.2519941329956055, 1.2502341270446777, 1.2446390390396118, 1.2414228916168213, 1.2361841201782227, 1.2323484420776367, 1.2298041582107544, 1.2246001958847046, 1.2210315465927124, 1.2170518636703491, 1.2156790494918823, 1.2086293697357178, 1.204874873161316, 1.2013016939163208, 1.1993117332458496, 1.1932228803634644, 1.1957635879516602, 1.185465931892395, 1.1846275329589844, 1.1855928897857666, 1.17388916015625, 1.1717473268508911, 1.167616367340088, 1.1631064414978027, 1.1600080728530884, 1.15701162815094, 1.1619956493377686, 1.1536182165145874, 1.145752191543579, 1.148101806640625, 1.1443898677825928, 1.1366915702819824, 1.1366344690322876, 1.1390584707260132, 1.1315280199050903, 1.121908187866211, 1.1223474740982056, 1.11611807346344, 1.1146408319473267, 1.1149184703826904, 1.1071428060531616, 1.105039358139038, 1.1032315492630005, 1.1066584587097168, 1.0965335369110107, 1.094244122505188, 1.091857671737671, 1.0941402912139893, 1.0846697092056274, 1.091064214706421, 1.0819106101989746, 1.0847058296203613, 1.0772874355316162, 1.083913803100586, 1.0716686248779297, 1.0671929121017456, 1.0652042627334595, 1.0645085573196411, 1.061992883682251, 1.0587551593780518, 1.0552594661712646, 1.0509006977081299], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.48966941237449646, 0.4834710657596588, 0.5072314143180847, 0.5, 0.4917355477809906, 0.5134297609329224, 0.5185950398445129, 0.5258264541625977, 0.5299586653709412, 0.5185950398445129, 0.5454545617103577, 0.5444214940071106, 0.5309917330741882, 0.5361570119857788, 0.5423553586006165, 0.5547520518302917, 0.5227272510528564, 0.5227272510528564, 0.5371900796890259, 0.53925621509552, 0.5516529083251953, 0.5526859760284424, 0.5402892827987671, 0.5433884263038635, 0.53925621509552, 0.5609503984451294, 0.5402892827987671, 0.5557851195335388, 0.5485537052154541, 0.5568181872367859, 0.5568181872367859, 0.5506198406219482, 0.5640496015548706, 0.5619834661483765, 0.5609503984451294, 0.5568181872367859, 0.5599173307418823, 0.55888432264328, 0.5702479481697083, 0.5506198406219482, 0.5650826692581177, 0.5733470916748047, 0.5630165338516235, 0.5847107172012329, 0.5888429880142212, 0.5712810158729553, 0.5557851195335388, 0.5816115736961365, 0.5640496015548706, 0.5619834661483765, 0.5888429880142212, 0.5826446413993835, 0.547520637512207, 0.5847107172012329, 0.5950413346290588, 0.5940082669258118, 0.5960744023323059, 0.5981404781341553, 0.5599173307418823, 0.5971074104309082, 0.5733470916748047, 0.5960744023323059, 0.5898760557174683, 0.6033057570457458, 0.6002066135406494, 0.5805785059928894, 0.5971074104309082, 0.5702479481697083, 0.5702479481697083, 0.5733470916748047, 0.5950413346290588, 0.5702479481697083, 0.5971074104309082, 0.5929751992225647, 0.6002066135406494, 0.5743801593780518, 0.5723140239715576, 0.5991735458374023, 0.6022727489471436, 0.5836777091026306, 0.5795454382896423, 0.5950413346290588, 0.60537189245224, 0.6022727489471436, 0.60537189245224, 0.5816115736961365, 0.60537189245224]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 1.0471 - accuracy: 0.6259"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 67ms/step - loss: 1.0471 - accuracy: 0.6258 - val_loss: 1.0911 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0415 - accuracy: 0.6218 - val_loss: 1.0890 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.0387 - accuracy: 0.6274 - val_loss: 1.0845 - val_accuracy: 0.4968\n","Epoch 4/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.0300 - accuracy: 0.6269 - val_loss: 1.0814 - val_accuracy: 0.5011\n","Epoch 5/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.0257 - accuracy: 0.6269 - val_loss: 1.0778 - val_accuracy: 0.5334\n","Epoch 6/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.0239 - accuracy: 0.6317 - val_loss: 1.0742 - val_accuracy: 0.5765\n","Epoch 7/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0212 - accuracy: 0.6374 - val_loss: 1.0710 - val_accuracy: 0.5582\n","Epoch 8/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.0163 - accuracy: 0.6404 - val_loss: 1.0670 - val_accuracy: 0.5894\n","Epoch 9/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0068 - accuracy: 0.6387 - val_loss: 1.0633 - val_accuracy: 0.5894\n","Epoch 10/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0088 - accuracy: 0.6401 - val_loss: 1.0594 - val_accuracy: 0.5884\n","Epoch 11/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0061 - accuracy: 0.6449 - val_loss: 1.0566 - val_accuracy: 0.5571\n","Epoch 12/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0014 - accuracy: 0.6377 - val_loss: 1.0525 - val_accuracy: 0.5711\n","Epoch 13/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9968 - accuracy: 0.6474 - val_loss: 1.0486 - val_accuracy: 0.5722\n","Epoch 14/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9934 - accuracy: 0.6449 - val_loss: 1.0416 - val_accuracy: 0.5970\n","Epoch 15/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9864 - accuracy: 0.6509 - val_loss: 1.0421 - val_accuracy: 0.5754\n","Epoch 16/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9846 - accuracy: 0.6530 - val_loss: 1.0353 - val_accuracy: 0.5884\n","Epoch 17/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9798 - accuracy: 0.6511 - val_loss: 1.0269 - val_accuracy: 0.5970\n","Epoch 18/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.9791 - accuracy: 0.6568 - val_loss: 1.0248 - val_accuracy: 0.6024\n","Epoch 19/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.9756 - accuracy: 0.6624 - val_loss: 1.0158 - val_accuracy: 0.6078\n","Epoch 20/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.9670 - accuracy: 0.6619 - val_loss: 1.0134 - val_accuracy: 0.6099\n","Epoch 21/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9714 - accuracy: 0.6576 - val_loss: 1.0096 - val_accuracy: 0.6185\n","Epoch 22/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9657 - accuracy: 0.6581 - val_loss: 1.0035 - val_accuracy: 0.6153\n","Epoch 23/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9604 - accuracy: 0.6635 - val_loss: 1.0016 - val_accuracy: 0.6153\n","Epoch 24/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.9536 - accuracy: 0.6678 - val_loss: 0.9953 - val_accuracy: 0.6218\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9540 - accuracy: 0.6614 - val_loss: 0.9929 - val_accuracy: 0.6196\n","Epoch 26/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.9550 - accuracy: 0.6600 - val_loss: 0.9896 - val_accuracy: 0.6228\n","Epoch 27/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9518 - accuracy: 0.6654 - val_loss: 0.9917 - val_accuracy: 0.6164\n","Epoch 28/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9417 - accuracy: 0.6759 - val_loss: 0.9928 - val_accuracy: 0.6228\n","Epoch 29/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.9427 - accuracy: 0.6649 - val_loss: 0.9834 - val_accuracy: 0.6239\n","Epoch 30/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.9354 - accuracy: 0.6727 - val_loss: 0.9834 - val_accuracy: 0.6315\n","Epoch 31/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9381 - accuracy: 0.6735 - val_loss: 0.9818 - val_accuracy: 0.6218\n","Epoch 32/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9256 - accuracy: 0.6789 - val_loss: 0.9799 - val_accuracy: 0.6261\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9308 - accuracy: 0.6708 - val_loss: 0.9801 - val_accuracy: 0.6282\n","Epoch 34/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.9248 - accuracy: 0.6800 - val_loss: 0.9745 - val_accuracy: 0.6336\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9190 - accuracy: 0.6835 - val_loss: 0.9844 - val_accuracy: 0.6261\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9191 - accuracy: 0.6810 - val_loss: 0.9711 - val_accuracy: 0.6315\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9197 - accuracy: 0.6719 - val_loss: 1.0041 - val_accuracy: 0.6175\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9276 - accuracy: 0.6606 - val_loss: 0.9741 - val_accuracy: 0.6282\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9100 - accuracy: 0.6856 - val_loss: 0.9654 - val_accuracy: 0.6325\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9050 - accuracy: 0.6894 - val_loss: 0.9656 - val_accuracy: 0.6239\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9004 - accuracy: 0.6897 - val_loss: 0.9635 - val_accuracy: 0.6304\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8997 - accuracy: 0.6956 - val_loss: 0.9630 - val_accuracy: 0.6282\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9003 - accuracy: 0.6872 - val_loss: 0.9654 - val_accuracy: 0.6153\n","Epoch 44/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8885 - accuracy: 0.6985 - val_loss: 0.9597 - val_accuracy: 0.6369\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8933 - accuracy: 0.6918 - val_loss: 0.9672 - val_accuracy: 0.6013\n","Epoch 46/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8843 - accuracy: 0.6988 - val_loss: 0.9634 - val_accuracy: 0.6099\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8846 - accuracy: 0.6940 - val_loss: 0.9588 - val_accuracy: 0.6185\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8802 - accuracy: 0.6999 - val_loss: 0.9553 - val_accuracy: 0.6325\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8788 - accuracy: 0.6996 - val_loss: 0.9548 - val_accuracy: 0.6261\n","Epoch 50/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8709 - accuracy: 0.6991 - val_loss: 0.9508 - val_accuracy: 0.6336\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8725 - accuracy: 0.7010 - val_loss: 0.9566 - val_accuracy: 0.6131\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8647 - accuracy: 0.7104 - val_loss: 0.9509 - val_accuracy: 0.6336\n","Epoch 53/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8589 - accuracy: 0.7152 - val_loss: 0.9764 - val_accuracy: 0.5797\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8599 - accuracy: 0.7042 - val_loss: 0.9631 - val_accuracy: 0.6347\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8673 - accuracy: 0.7007 - val_loss: 0.9791 - val_accuracy: 0.5744\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8665 - accuracy: 0.6996 - val_loss: 0.9448 - val_accuracy: 0.6282\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8528 - accuracy: 0.7080 - val_loss: 0.9434 - val_accuracy: 0.6347\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8478 - accuracy: 0.7212 - val_loss: 0.9462 - val_accuracy: 0.6175\n","Epoch 59/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8451 - accuracy: 0.7196 - val_loss: 0.9461 - val_accuracy: 0.6207\n","Epoch 60/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8415 - accuracy: 0.7188 - val_loss: 0.9627 - val_accuracy: 0.5916\n","Epoch 61/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8402 - accuracy: 0.7128 - val_loss: 0.9395 - val_accuracy: 0.6261\n","Epoch 62/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8371 - accuracy: 0.7217 - val_loss: 0.9431 - val_accuracy: 0.6315\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8360 - accuracy: 0.7196 - val_loss: 0.9406 - val_accuracy: 0.6239\n","Epoch 64/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.8299 - accuracy: 0.7204 - val_loss: 0.9470 - val_accuracy: 0.6412\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8285 - accuracy: 0.7204 - val_loss: 0.9378 - val_accuracy: 0.6304\n","Epoch 66/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.8276 - accuracy: 0.7163 - val_loss: 0.9447 - val_accuracy: 0.6433\n","Epoch 67/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8287 - accuracy: 0.7225 - val_loss: 0.9372 - val_accuracy: 0.6282\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8252 - accuracy: 0.7204 - val_loss: 0.9550 - val_accuracy: 0.6379\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8246 - accuracy: 0.7196 - val_loss: 0.9572 - val_accuracy: 0.5851\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8108 - accuracy: 0.7303 - val_loss: 0.9417 - val_accuracy: 0.6056\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8118 - accuracy: 0.7225 - val_loss: 0.9409 - val_accuracy: 0.6121\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8032 - accuracy: 0.7325 - val_loss: 0.9384 - val_accuracy: 0.6196\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8060 - accuracy: 0.7390 - val_loss: 0.9380 - val_accuracy: 0.6196\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8037 - accuracy: 0.7346 - val_loss: 0.9354 - val_accuracy: 0.6293\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7962 - accuracy: 0.7419 - val_loss: 0.9404 - val_accuracy: 0.6110\n","Epoch 76/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8053 - accuracy: 0.7276 - val_loss: 1.0056 - val_accuracy: 0.6045\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8045 - accuracy: 0.7325 - val_loss: 0.9485 - val_accuracy: 0.6034\n","Epoch 78/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8047 - accuracy: 0.7247 - val_loss: 0.9440 - val_accuracy: 0.6401\n","Epoch 79/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7954 - accuracy: 0.7373 - val_loss: 0.9528 - val_accuracy: 0.5884\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7982 - accuracy: 0.7306 - val_loss: 0.9302 - val_accuracy: 0.6153\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7807 - accuracy: 0.7527 - val_loss: 0.9308 - val_accuracy: 0.6282\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7763 - accuracy: 0.7519 - val_loss: 0.9314 - val_accuracy: 0.6153\n","Epoch 83/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7759 - accuracy: 0.7497 - val_loss: 0.9346 - val_accuracy: 0.6282\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7706 - accuracy: 0.7460 - val_loss: 0.9415 - val_accuracy: 0.6099\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7710 - accuracy: 0.7403 - val_loss: 0.9473 - val_accuracy: 0.6024\n","Epoch 86/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7731 - accuracy: 0.7446 - val_loss: 0.9356 - val_accuracy: 0.6347\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7585 - accuracy: 0.7581 - val_loss: 0.9423 - val_accuracy: 0.6024\n","Epoch 88/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7640 - accuracy: 0.7557 - val_loss: 0.9390 - val_accuracy: 0.6390\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7563 - accuracy: 0.7632 - val_loss: 0.9381 - val_accuracy: 0.6282\n","Epoch 90/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7549 - accuracy: 0.7543 - val_loss: 0.9449 - val_accuracy: 0.6056\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7521 - accuracy: 0.7586 - val_loss: 0.9409 - val_accuracy: 0.6088\n","Epoch 92/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7470 - accuracy: 0.7648 - val_loss: 0.9342 - val_accuracy: 0.6218\n","Epoch 93/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7490 - accuracy: 0.7581 - val_loss: 0.9422 - val_accuracy: 0.6164\n","Epoch 94/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7400 - accuracy: 0.7613 - val_loss: 0.9480 - val_accuracy: 0.6078\n","Epoch 95/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7472 - accuracy: 0.7567 - val_loss: 0.9399 - val_accuracy: 0.6207\n","Epoch 96/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7342 - accuracy: 0.7724 - val_loss: 0.9394 - val_accuracy: 0.6131\n","Epoch 97/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7303 - accuracy: 0.7726 - val_loss: 0.9517 - val_accuracy: 0.6045\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7293 - accuracy: 0.7748 - val_loss: 0.9502 - val_accuracy: 0.6164\n","Epoch 99/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7241 - accuracy: 0.7737 - val_loss: 0.9517 - val_accuracy: 0.6336\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7328 - accuracy: 0.7659 - val_loss: 0.9387 - val_accuracy: 0.6207\n","{'loss': [1.047052025794983, 1.0415443181991577, 1.0387341976165771, 1.030043363571167, 1.0256869792938232, 1.0238966941833496, 1.021175742149353, 1.0163390636444092, 1.0068461894989014, 1.0087628364562988, 1.0060614347457886, 1.001372218132019, 0.9967952370643616, 0.9934049248695374, 0.9863728284835815, 0.9845542907714844, 0.9797757267951965, 0.9791175127029419, 0.9755504727363586, 0.9670482277870178, 0.9713611006736755, 0.9656620621681213, 0.9603835344314575, 0.9535633325576782, 0.9540360569953918, 0.9549527168273926, 0.9517590999603271, 0.94169682264328, 0.9427185654640198, 0.9354053735733032, 0.9381245374679565, 0.9256165623664856, 0.9307519793510437, 0.9248313307762146, 0.9190038442611694, 0.9191482067108154, 0.9196823835372925, 0.9276179075241089, 0.9099809527397156, 0.9050446152687073, 0.9004364013671875, 0.8997405767440796, 0.9003216028213501, 0.8885440230369568, 0.8933383822441101, 0.8842657804489136, 0.8845966458320618, 0.8801751136779785, 0.8787866234779358, 0.8708881735801697, 0.8724772930145264, 0.8646737933158875, 0.8589465022087097, 0.8598849773406982, 0.8673268556594849, 0.8664742708206177, 0.8528293967247009, 0.8478150367736816, 0.8451328873634338, 0.8415356278419495, 0.8401822447776794, 0.837109386920929, 0.8359798192977905, 0.8298652768135071, 0.8284963369369507, 0.8275652527809143, 0.8286837935447693, 0.8251750469207764, 0.8245811462402344, 0.8107897043228149, 0.8117584586143494, 0.8032024502754211, 0.8060035705566406, 0.803741455078125, 0.7961693406105042, 0.8052754998207092, 0.8044860363006592, 0.8047314286231995, 0.7954407930374146, 0.7981788516044617, 0.7807468175888062, 0.7763254642486572, 0.7759427428245544, 0.7706313729286194, 0.770983874797821, 0.7731437087059021, 0.7584807872772217, 0.7640251517295837, 0.7562537789344788, 0.7549262046813965, 0.752065122127533, 0.7470262050628662, 0.7489739060401917, 0.7399711012840271, 0.7472058534622192, 0.7342321276664734, 0.7302671670913696, 0.7292593717575073, 0.7241088151931763, 0.7327653765678406], 'accuracy': [0.6258081793785095, 0.6217672228813171, 0.6274245977401733, 0.6268857717514038, 0.6268857717514038, 0.6317349076271057, 0.6373922228813171, 0.6403555870056152, 0.6387392282485962, 0.6400862336158752, 0.6449353694915771, 0.6376616358757019, 0.6473599076271057, 0.6449353694915771, 0.6508620977401733, 0.6530172228813171, 0.6511314511299133, 0.6567887663841248, 0.662446141242981, 0.6619073152542114, 0.657597005367279, 0.6581357717514038, 0.6635237336158752, 0.6678340435028076, 0.6613685488700867, 0.6600215435028076, 0.665409505367279, 0.6759159564971924, 0.6648706793785095, 0.6726831793785095, 0.673491358757019, 0.6788793206214905, 0.6707974076271057, 0.6799569129943848, 0.6834590435028076, 0.681034505367279, 0.671875, 0.6605603694915771, 0.6856142282485962, 0.6893857717514038, 0.6896551847457886, 0.6955819129943848, 0.6872305870056152, 0.6985452771186829, 0.6918103694915771, 0.6988146305084229, 0.693965494632721, 0.6998922228813171, 0.6996228694915771, 0.6990840435028076, 0.7009698152542114, 0.7103987336158752, 0.7152478694915771, 0.7042025923728943, 0.7007004022598267, 0.6996228694915771, 0.7079741358757019, 0.7211745977401733, 0.7195581793785095, 0.71875, 0.7128232717514038, 0.7217133641242981, 0.7195581793785095, 0.720366358757019, 0.720366358757019, 0.7163254022598267, 0.7225215435028076, 0.720366358757019, 0.7195581793785095, 0.7303340435028076, 0.7225215435028076, 0.7324892282485962, 0.7389547228813171, 0.7346444129943848, 0.7419180870056152, 0.7276400923728943, 0.7324892282485962, 0.7246767282485962, 0.7373383641242981, 0.7306034564971924, 0.7526939511299133, 0.7518857717514038, 0.7497305870056152, 0.7459590435028076, 0.7403017282485962, 0.7446120977401733, 0.7580819129943848, 0.7556573152542114, 0.7632004022598267, 0.7543103694915771, 0.7586206793785095, 0.7648168206214905, 0.7580819129943848, 0.7613146305084229, 0.7567349076271057, 0.7723599076271057, 0.7726293206214905, 0.774784505367279, 0.7737069129943848, 0.7658944129943848], 'val_loss': [1.0911482572555542, 1.0889801979064941, 1.0844852924346924, 1.0813544988632202, 1.0778471231460571, 1.0741779804229736, 1.0710468292236328, 1.0669821500778198, 1.0632579326629639, 1.0594159364700317, 1.0566149950027466, 1.0524998903274536, 1.0486201047897339, 1.041605830192566, 1.0421382188796997, 1.0352970361709595, 1.0269442796707153, 1.024825930595398, 1.0157853364944458, 1.0133904218673706, 1.0096091032028198, 1.0034979581832886, 1.0016201734542847, 0.9953466057777405, 0.9928675889968872, 0.9896024465560913, 0.9916532039642334, 0.9928151965141296, 0.9834255576133728, 0.9833948612213135, 0.9818130135536194, 0.9798960089683533, 0.9801412224769592, 0.9745021462440491, 0.984359622001648, 0.9711365103721619, 1.0040830373764038, 0.9741097092628479, 0.9654065370559692, 0.9655721783638, 0.9634774327278137, 0.9629574418067932, 0.9653963446617126, 0.959700882434845, 0.9672156572341919, 0.963354766368866, 0.9587565660476685, 0.9553216695785522, 0.954848051071167, 0.9507853388786316, 0.9566314816474915, 0.950883150100708, 0.9764119386672974, 0.9631255865097046, 0.9791145324707031, 0.9448287487030029, 0.94340980052948, 0.9461617469787598, 0.9461262822151184, 0.9626843929290771, 0.9395438432693481, 0.9431083798408508, 0.9405694603919983, 0.9470378756523132, 0.9378466606140137, 0.9447248578071594, 0.9371739625930786, 0.9549648761749268, 0.9572411179542542, 0.9416705369949341, 0.9408878684043884, 0.9383736848831177, 0.9379801154136658, 0.9353923797607422, 0.9403758645057678, 1.0055935382843018, 0.9484997391700745, 0.9440498948097229, 0.9528068900108337, 0.9301959872245789, 0.9307645559310913, 0.9314262270927429, 0.9346438646316528, 0.9414912462234497, 0.9472695589065552, 0.9355912208557129, 0.9422639012336731, 0.9389591217041016, 0.938132643699646, 0.9449185729026794, 0.9409262537956238, 0.9341962933540344, 0.9422165155410767, 0.9479867219924927, 0.9398820400238037, 0.9394275546073914, 0.9517073035240173, 0.950164794921875, 0.9516819715499878, 0.9387416839599609], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.4967672526836395, 0.5010775923728943, 0.5334051847457886, 0.576508641242981, 0.5581896305084229, 0.5894396305084229, 0.5894396305084229, 0.5883620977401733, 0.5571120977401733, 0.5711206793785095, 0.5721982717514038, 0.5969827771186829, 0.5754310488700867, 0.5883620977401733, 0.5969827771186829, 0.6023706793785095, 0.607758641242981, 0.6099137663841248, 0.618534505367279, 0.6153017282485962, 0.6153017282485962, 0.6217672228813171, 0.6196120977401733, 0.6228448152542114, 0.6163793206214905, 0.6228448152542114, 0.6239224076271057, 0.631465494632721, 0.6217672228813171, 0.6260775923728943, 0.6282327771186829, 0.6336206793785095, 0.6260775923728943, 0.631465494632721, 0.6174569129943848, 0.6282327771186829, 0.6325430870056152, 0.6239224076271057, 0.6303879022598267, 0.6282327771186829, 0.6153017282485962, 0.6368534564971924, 0.6012930870056152, 0.6099137663841248, 0.618534505367279, 0.6325430870056152, 0.6260775923728943, 0.6336206793785095, 0.6131465435028076, 0.6336206793785095, 0.579741358757019, 0.6346982717514038, 0.5743534564971924, 0.6282327771186829, 0.6346982717514038, 0.6174569129943848, 0.6206896305084229, 0.5915948152542114, 0.6260775923728943, 0.631465494632721, 0.6239224076271057, 0.6411637663841248, 0.6303879022598267, 0.6433189511299133, 0.6282327771186829, 0.6379310488700867, 0.5851293206214905, 0.6056034564971924, 0.6120689511299133, 0.6196120977401733, 0.6196120977401733, 0.6293103694915771, 0.610991358757019, 0.6045258641242981, 0.6034482717514038, 0.6400862336158752, 0.5883620977401733, 0.6153017282485962, 0.6282327771186829, 0.6153017282485962, 0.6282327771186829, 0.6099137663841248, 0.6023706793785095, 0.6346982717514038, 0.6023706793785095, 0.639008641242981, 0.6282327771186829, 0.6056034564971924, 0.6088362336158752, 0.6217672228813171, 0.6163793206214905, 0.607758641242981, 0.6206896305084229, 0.6131465435028076, 0.6045258641242981, 0.6163793206214905, 0.6336206793785095, 0.6206896305084229]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 1.0442 - accuracy: 0.6314"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 7s 72ms/step - loss: 1.0452 - accuracy: 0.6290 - val_loss: 1.0901 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0403 - accuracy: 0.6319 - val_loss: 1.0868 - val_accuracy: 0.4943\n","Epoch 3/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.0404 - accuracy: 0.6271 - val_loss: 1.0834 - val_accuracy: 0.4966\n","Epoch 4/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.0309 - accuracy: 0.6333 - val_loss: 1.0798 - val_accuracy: 0.5079\n","Epoch 5/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.0256 - accuracy: 0.6387 - val_loss: 1.0762 - val_accuracy: 0.5667\n","Epoch 6/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.0258 - accuracy: 0.6350 - val_loss: 1.0727 - val_accuracy: 0.5735\n","Epoch 7/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.0179 - accuracy: 0.6426 - val_loss: 1.0692 - val_accuracy: 0.6233\n","Epoch 8/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.0133 - accuracy: 0.6480 - val_loss: 1.0654 - val_accuracy: 0.6312\n","Epoch 9/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0104 - accuracy: 0.6494 - val_loss: 1.0618 - val_accuracy: 0.6007\n","Epoch 10/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0055 - accuracy: 0.6514 - val_loss: 1.0578 - val_accuracy: 0.6109\n","Epoch 11/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0037 - accuracy: 0.6520 - val_loss: 1.0544 - val_accuracy: 0.5837\n","Epoch 12/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0003 - accuracy: 0.6474 - val_loss: 1.0499 - val_accuracy: 0.5995\n","Epoch 13/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9995 - accuracy: 0.6446 - val_loss: 1.0455 - val_accuracy: 0.5939\n","Epoch 14/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9929 - accuracy: 0.6607 - val_loss: 1.0385 - val_accuracy: 0.6312\n","Epoch 15/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9899 - accuracy: 0.6579 - val_loss: 1.0392 - val_accuracy: 0.5792\n","Epoch 16/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9872 - accuracy: 0.6568 - val_loss: 1.0372 - val_accuracy: 0.5814\n","Epoch 17/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9815 - accuracy: 0.6579 - val_loss: 1.0294 - val_accuracy: 0.5894\n","Epoch 18/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9783 - accuracy: 0.6619 - val_loss: 1.0190 - val_accuracy: 0.6154\n","Epoch 19/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9762 - accuracy: 0.6596 - val_loss: 1.0134 - val_accuracy: 0.6176\n","Epoch 20/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9774 - accuracy: 0.6587 - val_loss: 1.0250 - val_accuracy: 0.5939\n","Epoch 21/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9676 - accuracy: 0.6607 - val_loss: 0.9984 - val_accuracy: 0.6437\n","Epoch 22/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9682 - accuracy: 0.6644 - val_loss: 0.9945 - val_accuracy: 0.6369\n","Epoch 23/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9627 - accuracy: 0.6630 - val_loss: 0.9961 - val_accuracy: 0.6165\n","Epoch 24/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9604 - accuracy: 0.6582 - val_loss: 0.9894 - val_accuracy: 0.6301\n","Epoch 25/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9549 - accuracy: 0.6760 - val_loss: 0.9850 - val_accuracy: 0.6335\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9543 - accuracy: 0.6709 - val_loss: 0.9873 - val_accuracy: 0.6188\n","Epoch 27/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9471 - accuracy: 0.6786 - val_loss: 0.9774 - val_accuracy: 0.6278\n","Epoch 28/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9475 - accuracy: 0.6752 - val_loss: 0.9742 - val_accuracy: 0.6380\n","Epoch 29/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.9464 - accuracy: 0.6766 - val_loss: 0.9729 - val_accuracy: 0.6335\n","Epoch 30/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9381 - accuracy: 0.6814 - val_loss: 0.9766 - val_accuracy: 0.6301\n","Epoch 31/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9344 - accuracy: 0.6893 - val_loss: 0.9687 - val_accuracy: 0.6346\n","Epoch 32/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9316 - accuracy: 0.6746 - val_loss: 0.9804 - val_accuracy: 0.6188\n","Epoch 33/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.9305 - accuracy: 0.6774 - val_loss: 0.9734 - val_accuracy: 0.6290\n","Epoch 34/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9246 - accuracy: 0.6825 - val_loss: 0.9689 - val_accuracy: 0.6290\n","Epoch 35/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9240 - accuracy: 0.6817 - val_loss: 0.9611 - val_accuracy: 0.6380\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9198 - accuracy: 0.6876 - val_loss: 1.0107 - val_accuracy: 0.5860\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9239 - accuracy: 0.6794 - val_loss: 0.9632 - val_accuracy: 0.6369\n","Epoch 38/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9165 - accuracy: 0.6862 - val_loss: 0.9595 - val_accuracy: 0.6324\n","Epoch 39/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9113 - accuracy: 0.6859 - val_loss: 0.9596 - val_accuracy: 0.6335\n","Epoch 40/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9087 - accuracy: 0.6921 - val_loss: 0.9557 - val_accuracy: 0.6290\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9019 - accuracy: 0.7009 - val_loss: 0.9537 - val_accuracy: 0.6312\n","Epoch 42/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9018 - accuracy: 0.6862 - val_loss: 0.9735 - val_accuracy: 0.6007\n","Epoch 43/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9142 - accuracy: 0.6726 - val_loss: 0.9626 - val_accuracy: 0.6109\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8946 - accuracy: 0.6989 - val_loss: 0.9500 - val_accuracy: 0.6357\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9070 - accuracy: 0.6749 - val_loss: 0.9552 - val_accuracy: 0.6154\n","Epoch 46/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8929 - accuracy: 0.6933 - val_loss: 0.9515 - val_accuracy: 0.6324\n","Epoch 47/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.8831 - accuracy: 0.7040 - val_loss: 0.9442 - val_accuracy: 0.6459\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8887 - accuracy: 0.6950 - val_loss: 0.9440 - val_accuracy: 0.6369\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8778 - accuracy: 0.7057 - val_loss: 0.9430 - val_accuracy: 0.6391\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8814 - accuracy: 0.7054 - val_loss: 0.9483 - val_accuracy: 0.6222\n","Epoch 51/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8726 - accuracy: 0.7049 - val_loss: 0.9424 - val_accuracy: 0.6437\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8655 - accuracy: 0.7108 - val_loss: 0.9382 - val_accuracy: 0.6346\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8732 - accuracy: 0.7003 - val_loss: 0.9407 - val_accuracy: 0.6346\n","Epoch 54/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8677 - accuracy: 0.7100 - val_loss: 0.9384 - val_accuracy: 0.6290\n","Epoch 55/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.8634 - accuracy: 0.7190 - val_loss: 0.9354 - val_accuracy: 0.6471\n","Epoch 56/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.8594 - accuracy: 0.7184 - val_loss: 0.9360 - val_accuracy: 0.6482\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8533 - accuracy: 0.7148 - val_loss: 0.9410 - val_accuracy: 0.6233\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8638 - accuracy: 0.7012 - val_loss: 0.9491 - val_accuracy: 0.6267\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8527 - accuracy: 0.7145 - val_loss: 0.9445 - val_accuracy: 0.6244\n","Epoch 60/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8576 - accuracy: 0.7026 - val_loss: 0.9327 - val_accuracy: 0.6244\n","Epoch 61/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8455 - accuracy: 0.7108 - val_loss: 0.9362 - val_accuracy: 0.6233\n","Epoch 62/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.8445 - accuracy: 0.7190 - val_loss: 0.9309 - val_accuracy: 0.6448\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8364 - accuracy: 0.7179 - val_loss: 0.9289 - val_accuracy: 0.6391\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8346 - accuracy: 0.7235 - val_loss: 0.9289 - val_accuracy: 0.6335\n","Epoch 65/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8321 - accuracy: 0.7295 - val_loss: 0.9374 - val_accuracy: 0.6222\n","Epoch 66/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8353 - accuracy: 0.7207 - val_loss: 0.9558 - val_accuracy: 0.6267\n","Epoch 67/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8347 - accuracy: 0.7151 - val_loss: 0.9261 - val_accuracy: 0.6425\n","Epoch 68/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8205 - accuracy: 0.7346 - val_loss: 0.9266 - val_accuracy: 0.6425\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8207 - accuracy: 0.7303 - val_loss: 0.9277 - val_accuracy: 0.6425\n","Epoch 70/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8200 - accuracy: 0.7298 - val_loss: 0.9279 - val_accuracy: 0.6301\n","Epoch 71/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8200 - accuracy: 0.7218 - val_loss: 0.9648 - val_accuracy: 0.5984\n","Epoch 72/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8206 - accuracy: 0.7269 - val_loss: 0.9216 - val_accuracy: 0.6290\n","Epoch 73/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8103 - accuracy: 0.7397 - val_loss: 0.9584 - val_accuracy: 0.5995\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8132 - accuracy: 0.7354 - val_loss: 0.9272 - val_accuracy: 0.6233\n","Epoch 75/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8055 - accuracy: 0.7360 - val_loss: 0.9267 - val_accuracy: 0.6391\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8070 - accuracy: 0.7303 - val_loss: 0.9291 - val_accuracy: 0.6244\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7962 - accuracy: 0.7450 - val_loss: 0.9254 - val_accuracy: 0.6324\n","Epoch 78/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8056 - accuracy: 0.7247 - val_loss: 0.9318 - val_accuracy: 0.6154\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8004 - accuracy: 0.7286 - val_loss: 0.9269 - val_accuracy: 0.6391\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7907 - accuracy: 0.7470 - val_loss: 0.9200 - val_accuracy: 0.6369\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7877 - accuracy: 0.7459 - val_loss: 0.9211 - val_accuracy: 0.6357\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7795 - accuracy: 0.7516 - val_loss: 0.9247 - val_accuracy: 0.6301\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7816 - accuracy: 0.7467 - val_loss: 0.9192 - val_accuracy: 0.6335\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7811 - accuracy: 0.7462 - val_loss: 0.9210 - val_accuracy: 0.6301\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7789 - accuracy: 0.7467 - val_loss: 0.9153 - val_accuracy: 0.6335\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7766 - accuracy: 0.7467 - val_loss: 0.9199 - val_accuracy: 0.6357\n","Epoch 87/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7701 - accuracy: 0.7606 - val_loss: 0.9258 - val_accuracy: 0.6335\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7649 - accuracy: 0.7561 - val_loss: 0.9182 - val_accuracy: 0.6346\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7625 - accuracy: 0.7598 - val_loss: 0.9333 - val_accuracy: 0.6120\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7619 - accuracy: 0.7609 - val_loss: 0.9817 - val_accuracy: 0.6120\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7603 - accuracy: 0.7490 - val_loss: 0.9290 - val_accuracy: 0.6109\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7647 - accuracy: 0.7609 - val_loss: 0.9141 - val_accuracy: 0.6335\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7524 - accuracy: 0.7552 - val_loss: 0.9351 - val_accuracy: 0.6188\n","Epoch 94/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.7494 - accuracy: 0.7649 - val_loss: 0.9300 - val_accuracy: 0.6143\n","Epoch 95/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.7553 - accuracy: 0.7643 - val_loss: 0.9617 - val_accuracy: 0.6052\n","Epoch 96/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7491 - accuracy: 0.7620 - val_loss: 0.9280 - val_accuracy: 0.6335\n","Epoch 97/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7416 - accuracy: 0.7671 - val_loss: 0.9188 - val_accuracy: 0.6335\n","Epoch 98/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.7454 - accuracy: 0.7634 - val_loss: 0.9397 - val_accuracy: 0.6131\n","Epoch 99/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7385 - accuracy: 0.7705 - val_loss: 0.9194 - val_accuracy: 0.6290\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7318 - accuracy: 0.7832 - val_loss: 0.9292 - val_accuracy: 0.6120\n","{'loss': [1.0452474355697632, 1.0403239727020264, 1.0403560400009155, 1.0308696031570435, 1.025574803352356, 1.0258009433746338, 1.0178649425506592, 1.0133155584335327, 1.010387897491455, 1.0055296421051025, 1.0037379264831543, 1.0002734661102295, 0.9994839429855347, 0.9929097890853882, 0.989914059638977, 0.9872191548347473, 0.981509268283844, 0.9783318638801575, 0.9761992692947388, 0.9774029850959778, 0.9675567150115967, 0.9682273268699646, 0.9626725316047668, 0.9604243040084839, 0.954938530921936, 0.9542763233184814, 0.9470952749252319, 0.9475201368331909, 0.9464428424835205, 0.9381464123725891, 0.934380829334259, 0.9315834641456604, 0.9304956197738647, 0.9246034622192383, 0.9240286946296692, 0.9198065996170044, 0.9238998293876648, 0.9165209531784058, 0.9112715721130371, 0.9086592793464661, 0.9018875956535339, 0.9018341898918152, 0.9141955971717834, 0.8946355581283569, 0.907021164894104, 0.8929147720336914, 0.8830877542495728, 0.8886934518814087, 0.8777644634246826, 0.8814313411712646, 0.872599720954895, 0.8654792904853821, 0.8731657266616821, 0.867658257484436, 0.8633619546890259, 0.8593592643737793, 0.8532577157020569, 0.863845944404602, 0.8527326583862305, 0.8575681447982788, 0.8454820513725281, 0.8444997072219849, 0.8364009857177734, 0.8346107006072998, 0.8320592045783997, 0.8353372812271118, 0.8346716165542603, 0.8205154538154602, 0.8207213282585144, 0.8200458288192749, 0.8200392723083496, 0.8205513954162598, 0.8103300929069519, 0.8132199645042419, 0.8054725527763367, 0.8070212006568909, 0.7962275743484497, 0.8056062459945679, 0.8003656268119812, 0.7907060384750366, 0.7877066731452942, 0.7794719338417053, 0.7815781235694885, 0.7810689806938171, 0.7788886427879333, 0.7765819430351257, 0.7700876593589783, 0.7649221420288086, 0.7625377774238586, 0.761915922164917, 0.760342001914978, 0.7647028565406799, 0.7523752450942993, 0.749380886554718, 0.7552712559700012, 0.7491299510002136, 0.7416146397590637, 0.7454442381858826, 0.7384815216064453, 0.7317677736282349], 'accuracy': [0.6290322542190552, 0.6318619251251221, 0.6270514726638794, 0.6332767605781555, 0.6386530995368958, 0.6349745392799377, 0.6426146030426025, 0.6479909420013428, 0.6494057774543762, 0.651386559009552, 0.6519524455070496, 0.6474249958992004, 0.6445953845977783, 0.660724401473999, 0.6578947305679321, 0.6567628979682922, 0.6578947305679321, 0.6618562340736389, 0.6595925092697144, 0.6587436199188232, 0.660724401473999, 0.664402961730957, 0.6629881262779236, 0.6581776738166809, 0.6760045289993286, 0.6709111332893372, 0.678551197052002, 0.6751556396484375, 0.676570475101471, 0.6813808679580688, 0.6893039345741272, 0.6745896935462952, 0.6774193644523621, 0.6825127601623535, 0.6816638112068176, 0.6876060962677002, 0.6794000864028931, 0.6861912608146667, 0.685908317565918, 0.6921335458755493, 0.7009055018424988, 0.6861912608146667, 0.6726089119911194, 0.698924720287323, 0.674872636795044, 0.693265438079834, 0.7040181159973145, 0.6949632167816162, 0.7057158946990967, 0.7054329514503479, 0.7048670053482056, 0.7108092904090881, 0.7003395557403564, 0.709960401058197, 0.7190153002738953, 0.7184493541717529, 0.7147707939147949, 0.7011884450912476, 0.7144878506660461, 0.702603280544281, 0.7108092904090881, 0.7190153002738953, 0.7178834080696106, 0.7235427498817444, 0.7294849753379822, 0.7207130789756775, 0.7150537371635437, 0.7345783710479736, 0.7303339242935181, 0.7297679781913757, 0.7218449115753174, 0.7269383072853088, 0.7396717667579651, 0.7354272603988647, 0.7359932065010071, 0.7303339242935181, 0.7450481057167053, 0.7246745824813843, 0.7286360859870911, 0.7470288872718811, 0.7458969950675964, 0.7515563368797302, 0.7467458844184875, 0.7461799383163452, 0.7467458844184875, 0.7467458844184875, 0.7606111764907837, 0.7560837864875793, 0.7597622871398926, 0.7608941793441772, 0.7490096092224121, 0.7608941793441772, 0.7552348375320435, 0.764855682849884, 0.7642897367477417, 0.7620260119438171, 0.7671194076538086, 0.7634408473968506, 0.7705150246620178, 0.7832484245300293], 'val_loss': [1.0901408195495605, 1.0867513418197632, 1.0833699703216553, 1.07981538772583, 1.0762121677398682, 1.0727012157440186, 1.0691618919372559, 1.0653634071350098, 1.0617647171020508, 1.057846188545227, 1.0544377565383911, 1.049888014793396, 1.0455000400543213, 1.0384947061538696, 1.0391935110092163, 1.0372025966644287, 1.0294227600097656, 1.0189682245254517, 1.0133804082870483, 1.025007724761963, 0.9983716607093811, 0.9944984912872314, 0.9960994124412537, 0.9894482493400574, 0.9850418567657471, 0.9873107671737671, 0.9773892164230347, 0.9742415547370911, 0.9729454517364502, 0.9765591025352478, 0.9686964750289917, 0.9804369807243347, 0.9734026193618774, 0.9688903093338013, 0.9610744118690491, 1.0106697082519531, 0.9631652235984802, 0.9595389366149902, 0.9596021771430969, 0.9556902050971985, 0.9536951780319214, 0.9734766483306885, 0.9625941514968872, 0.9500300288200378, 0.9552062749862671, 0.9514743089675903, 0.9442388415336609, 0.9439746737480164, 0.9429872035980225, 0.9482517838478088, 0.9423524737358093, 0.938245415687561, 0.940724790096283, 0.9383728504180908, 0.935442328453064, 0.9359867572784424, 0.9410240054130554, 0.9491018056869507, 0.9444736242294312, 0.932747483253479, 0.9361863732337952, 0.9309294819831848, 0.9289422631263733, 0.9289392828941345, 0.9374257922172546, 0.9558247923851013, 0.926086962223053, 0.9266334772109985, 0.9276621341705322, 0.927872896194458, 0.9647669792175293, 0.9215611219406128, 0.95844566822052, 0.9272379875183105, 0.9266659021377563, 0.9290578961372375, 0.9253664612770081, 0.9317710399627686, 0.9269192814826965, 0.9199877977371216, 0.9210527539253235, 0.9246635437011719, 0.9192410707473755, 0.9209697842597961, 0.9153192639350891, 0.9199402928352356, 0.9257552623748779, 0.9182428121566772, 0.9333153367042542, 0.9816601872444153, 0.9290085434913635, 0.914061963558197, 0.935065507888794, 0.9300000071525574, 0.9616667628288269, 0.9279950857162476, 0.9188060760498047, 0.9397379755973816, 0.9194363951683044, 0.9291759729385376], 'val_accuracy': [0.4954751133918762, 0.4943438768386841, 0.49660632014274597, 0.5079185366630554, 0.5667420625686646, 0.5735294222831726, 0.6233031749725342, 0.6312217116355896, 0.6006787419319153, 0.610859751701355, 0.5837104320526123, 0.5995475053787231, 0.5938913822174072, 0.6312217116355896, 0.5791855454444885, 0.581447958946228, 0.5893664956092834, 0.6153846383094788, 0.6176470518112183, 0.5938913822174072, 0.6436651349067688, 0.6368778347969055, 0.6165158152580261, 0.6300904750823975, 0.6334841847419739, 0.6187782883644104, 0.627828061580658, 0.6380090713500977, 0.6334841847419739, 0.6300904750823975, 0.6346153616905212, 0.6187782883644104, 0.6289592981338501, 0.6289592981338501, 0.6380090713500977, 0.5859728455543518, 0.6368778347969055, 0.6323529481887817, 0.6334841847419739, 0.6289592981338501, 0.6312217116355896, 0.6006787419319153, 0.610859751701355, 0.6357465982437134, 0.6153846383094788, 0.6323529481887817, 0.6459276080131531, 0.6368778347969055, 0.639140248298645, 0.622171938419342, 0.6436651349067688, 0.6346153616905212, 0.6346153616905212, 0.6289592981338501, 0.6470588445663452, 0.6481900215148926, 0.6233031749725342, 0.6266968250274658, 0.6244344115257263, 0.6244344115257263, 0.6233031749725342, 0.6447963714599609, 0.639140248298645, 0.6334841847419739, 0.622171938419342, 0.6266968250274658, 0.6425339579582214, 0.6425339579582214, 0.6425339579582214, 0.6300904750823975, 0.598416268825531, 0.6289592981338501, 0.5995475053787231, 0.6233031749725342, 0.639140248298645, 0.6244344115257263, 0.6323529481887817, 0.6153846383094788, 0.639140248298645, 0.6368778347969055, 0.6357465982437134, 0.6300904750823975, 0.6334841847419739, 0.6300904750823975, 0.6334841847419739, 0.6357465982437134, 0.6334841847419739, 0.6346153616905212, 0.6119909286499023, 0.6119909286499023, 0.610859751701355, 0.6334841847419739, 0.6187782883644104, 0.6142534017562866, 0.6052036285400391, 0.6334841847419739, 0.6334841847419739, 0.6131221652030945, 0.6289592981338501, 0.6119909286499023]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 1.0507 - accuracy: 0.6110"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 61ms/step - loss: 1.0506 - accuracy: 0.6109 - val_loss: 1.0919 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0418 - accuracy: 0.6302 - val_loss: 1.0879 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0369 - accuracy: 0.6297 - val_loss: 1.0843 - val_accuracy: 0.4876\n","Epoch 4/100\n","31/31 [==============================] - 1s 29ms/step - loss: 1.0370 - accuracy: 0.6220 - val_loss: 1.0813 - val_accuracy: 0.4897\n","Epoch 5/100\n","31/31 [==============================] - 1s 29ms/step - loss: 1.0271 - accuracy: 0.6362 - val_loss: 1.0770 - val_accuracy: 0.5413\n","Epoch 6/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.0236 - accuracy: 0.6289 - val_loss: 1.0730 - val_accuracy: 0.5733\n","Epoch 7/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0183 - accuracy: 0.6395 - val_loss: 1.0699 - val_accuracy: 0.5548\n","Epoch 8/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0142 - accuracy: 0.6426 - val_loss: 1.0658 - val_accuracy: 0.5723\n","Epoch 9/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.0103 - accuracy: 0.6380 - val_loss: 1.0618 - val_accuracy: 0.5744\n","Epoch 10/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.0083 - accuracy: 0.6478 - val_loss: 1.0567 - val_accuracy: 0.5775\n","Epoch 11/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0078 - accuracy: 0.6377 - val_loss: 1.0526 - val_accuracy: 0.5950\n","Epoch 12/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0005 - accuracy: 0.6344 - val_loss: 1.0479 - val_accuracy: 0.5930\n","Epoch 13/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9965 - accuracy: 0.6388 - val_loss: 1.0430 - val_accuracy: 0.5847\n","Epoch 14/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9918 - accuracy: 0.6494 - val_loss: 1.0374 - val_accuracy: 0.5930\n","Epoch 15/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9908 - accuracy: 0.6496 - val_loss: 1.0323 - val_accuracy: 0.5940\n","Epoch 16/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9837 - accuracy: 0.6584 - val_loss: 1.0315 - val_accuracy: 0.5661\n","Epoch 17/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9841 - accuracy: 0.6496 - val_loss: 1.0275 - val_accuracy: 0.5702\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9836 - accuracy: 0.6437 - val_loss: 1.0174 - val_accuracy: 0.5909\n","Epoch 19/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9761 - accuracy: 0.6509 - val_loss: 1.0116 - val_accuracy: 0.6012\n","Epoch 20/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9699 - accuracy: 0.6571 - val_loss: 1.0110 - val_accuracy: 0.5961\n","Epoch 21/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9683 - accuracy: 0.6638 - val_loss: 1.0040 - val_accuracy: 0.6012\n","Epoch 22/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9673 - accuracy: 0.6550 - val_loss: 1.0263 - val_accuracy: 0.5754\n","Epoch 23/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9636 - accuracy: 0.6623 - val_loss: 1.0043 - val_accuracy: 0.6023\n","Epoch 24/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9618 - accuracy: 0.6527 - val_loss: 0.9935 - val_accuracy: 0.6136\n","Epoch 25/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9538 - accuracy: 0.6630 - val_loss: 0.9998 - val_accuracy: 0.6012\n","Epoch 26/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9544 - accuracy: 0.6646 - val_loss: 1.0012 - val_accuracy: 0.5981\n","Epoch 27/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9470 - accuracy: 0.6716 - val_loss: 0.9865 - val_accuracy: 0.6229\n","Epoch 28/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9504 - accuracy: 0.6514 - val_loss: 0.9845 - val_accuracy: 0.6188\n","Epoch 29/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.9432 - accuracy: 0.6682 - val_loss: 0.9821 - val_accuracy: 0.6271\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9430 - accuracy: 0.6589 - val_loss: 0.9857 - val_accuracy: 0.6033\n","Epoch 31/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9354 - accuracy: 0.6729 - val_loss: 0.9790 - val_accuracy: 0.6240\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9370 - accuracy: 0.6705 - val_loss: 0.9769 - val_accuracy: 0.6147\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9326 - accuracy: 0.6659 - val_loss: 0.9955 - val_accuracy: 0.5981\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9339 - accuracy: 0.6636 - val_loss: 0.9759 - val_accuracy: 0.6271\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9244 - accuracy: 0.6721 - val_loss: 0.9722 - val_accuracy: 0.6178\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9213 - accuracy: 0.6775 - val_loss: 0.9700 - val_accuracy: 0.6240\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9185 - accuracy: 0.6695 - val_loss: 0.9747 - val_accuracy: 0.6188\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9211 - accuracy: 0.6693 - val_loss: 0.9714 - val_accuracy: 0.6136\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9168 - accuracy: 0.6687 - val_loss: 0.9677 - val_accuracy: 0.6074\n","Epoch 40/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9126 - accuracy: 0.6687 - val_loss: 0.9640 - val_accuracy: 0.6281\n","Epoch 41/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9042 - accuracy: 0.6837 - val_loss: 0.9634 - val_accuracy: 0.6312\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9031 - accuracy: 0.6786 - val_loss: 0.9610 - val_accuracy: 0.6271\n","Epoch 43/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9000 - accuracy: 0.6806 - val_loss: 0.9598 - val_accuracy: 0.6178\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8967 - accuracy: 0.6917 - val_loss: 0.9680 - val_accuracy: 0.6054\n","Epoch 45/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8954 - accuracy: 0.6801 - val_loss: 0.9799 - val_accuracy: 0.5919\n","Epoch 46/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8924 - accuracy: 0.6990 - val_loss: 0.9562 - val_accuracy: 0.6229\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8922 - accuracy: 0.6788 - val_loss: 0.9693 - val_accuracy: 0.6074\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8926 - accuracy: 0.6824 - val_loss: 0.9576 - val_accuracy: 0.6198\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8867 - accuracy: 0.6850 - val_loss: 0.9517 - val_accuracy: 0.6271\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8825 - accuracy: 0.6941 - val_loss: 0.9505 - val_accuracy: 0.6271\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8757 - accuracy: 0.6943 - val_loss: 0.9478 - val_accuracy: 0.6209\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8777 - accuracy: 0.6915 - val_loss: 0.9583 - val_accuracy: 0.6209\n","Epoch 53/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8742 - accuracy: 0.6881 - val_loss: 0.9491 - val_accuracy: 0.6116\n","Epoch 54/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8827 - accuracy: 0.6806 - val_loss: 0.9820 - val_accuracy: 0.5981\n","Epoch 55/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8685 - accuracy: 0.6959 - val_loss: 0.9381 - val_accuracy: 0.6302\n","Epoch 56/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8664 - accuracy: 0.6904 - val_loss: 0.9369 - val_accuracy: 0.6281\n","Epoch 57/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8662 - accuracy: 0.7016 - val_loss: 0.9529 - val_accuracy: 0.6167\n","Epoch 58/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8639 - accuracy: 0.6884 - val_loss: 0.9406 - val_accuracy: 0.6157\n","Epoch 59/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8639 - accuracy: 0.6897 - val_loss: 0.9327 - val_accuracy: 0.6291\n","Epoch 60/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8579 - accuracy: 0.7078 - val_loss: 0.9311 - val_accuracy: 0.6209\n","Epoch 61/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8525 - accuracy: 0.7036 - val_loss: 0.9343 - val_accuracy: 0.6178\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8459 - accuracy: 0.7062 - val_loss: 0.9366 - val_accuracy: 0.6188\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8388 - accuracy: 0.7176 - val_loss: 0.9308 - val_accuracy: 0.6291\n","Epoch 64/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8442 - accuracy: 0.7054 - val_loss: 0.9277 - val_accuracy: 0.6302\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8367 - accuracy: 0.7165 - val_loss: 0.9274 - val_accuracy: 0.6302\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8451 - accuracy: 0.7028 - val_loss: 0.9251 - val_accuracy: 0.6281\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8360 - accuracy: 0.7096 - val_loss: 0.9254 - val_accuracy: 0.6271\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8286 - accuracy: 0.7171 - val_loss: 0.9244 - val_accuracy: 0.6312\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8281 - accuracy: 0.7212 - val_loss: 0.9568 - val_accuracy: 0.6002\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8388 - accuracy: 0.7018 - val_loss: 0.9515 - val_accuracy: 0.6105\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8367 - accuracy: 0.7010 - val_loss: 0.9327 - val_accuracy: 0.6126\n","Epoch 72/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8213 - accuracy: 0.7194 - val_loss: 0.9191 - val_accuracy: 0.6219\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8133 - accuracy: 0.7173 - val_loss: 0.9177 - val_accuracy: 0.6302\n","Epoch 74/100\n","31/31 [==============================] - 2s 58ms/step - loss: 0.8160 - accuracy: 0.7178 - val_loss: 0.9292 - val_accuracy: 0.6384\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8139 - accuracy: 0.7214 - val_loss: 0.9195 - val_accuracy: 0.6281\n","Epoch 76/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8110 - accuracy: 0.7222 - val_loss: 0.9181 - val_accuracy: 0.6395\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8034 - accuracy: 0.7382 - val_loss: 0.9263 - val_accuracy: 0.6188\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8072 - accuracy: 0.7258 - val_loss: 0.9146 - val_accuracy: 0.6260\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8043 - accuracy: 0.7245 - val_loss: 0.9142 - val_accuracy: 0.6260\n","Epoch 80/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7979 - accuracy: 0.7346 - val_loss: 0.9238 - val_accuracy: 0.6374\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7945 - accuracy: 0.7279 - val_loss: 0.9147 - val_accuracy: 0.6291\n","Epoch 82/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7915 - accuracy: 0.7339 - val_loss: 0.9501 - val_accuracy: 0.6126\n","Epoch 83/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7904 - accuracy: 0.7295 - val_loss: 0.9250 - val_accuracy: 0.6271\n","Epoch 84/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7898 - accuracy: 0.7256 - val_loss: 0.9171 - val_accuracy: 0.6333\n","Epoch 85/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7842 - accuracy: 0.7367 - val_loss: 0.9161 - val_accuracy: 0.6322\n","Epoch 86/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7812 - accuracy: 0.7382 - val_loss: 0.9119 - val_accuracy: 0.6281\n","Epoch 87/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7748 - accuracy: 0.7444 - val_loss: 0.9327 - val_accuracy: 0.6240\n","Epoch 88/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7815 - accuracy: 0.7359 - val_loss: 0.9195 - val_accuracy: 0.6415\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7747 - accuracy: 0.7413 - val_loss: 0.9286 - val_accuracy: 0.6188\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7689 - accuracy: 0.7403 - val_loss: 0.9459 - val_accuracy: 0.6105\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7822 - accuracy: 0.7251 - val_loss: 0.9121 - val_accuracy: 0.6302\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7722 - accuracy: 0.7380 - val_loss: 0.9132 - val_accuracy: 0.6333\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7599 - accuracy: 0.7501 - val_loss: 0.9132 - val_accuracy: 0.6281\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7577 - accuracy: 0.7535 - val_loss: 0.9234 - val_accuracy: 0.6281\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7572 - accuracy: 0.7439 - val_loss: 0.9130 - val_accuracy: 0.6250\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7526 - accuracy: 0.7460 - val_loss: 0.9308 - val_accuracy: 0.6229\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7591 - accuracy: 0.7403 - val_loss: 0.9307 - val_accuracy: 0.6322\n","Epoch 98/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7474 - accuracy: 0.7535 - val_loss: 0.9284 - val_accuracy: 0.6281\n","Epoch 99/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7530 - accuracy: 0.7421 - val_loss: 0.9520 - val_accuracy: 0.6023\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7482 - accuracy: 0.7494 - val_loss: 0.9142 - val_accuracy: 0.6281\n","{'loss': [1.050629734992981, 1.0418058633804321, 1.0369393825531006, 1.037003755569458, 1.0270915031433105, 1.0235657691955566, 1.01829993724823, 1.0141979455947876, 1.01033353805542, 1.0083158016204834, 1.007813811302185, 1.0005276203155518, 0.9965097308158875, 0.991754412651062, 0.9907587766647339, 0.9836553335189819, 0.9841283559799194, 0.9836390614509583, 0.9760991334915161, 0.9699429869651794, 0.9683241844177246, 0.967303991317749, 0.9635636210441589, 0.9617935419082642, 0.9537844061851501, 0.9544152021408081, 0.9470390677452087, 0.9504122734069824, 0.9432310461997986, 0.9429804682731628, 0.9353909492492676, 0.937003493309021, 0.9326035380363464, 0.9338706731796265, 0.9244030714035034, 0.921332836151123, 0.9184702634811401, 0.9211243987083435, 0.9168448448181152, 0.9126088619232178, 0.9041679501533508, 0.9031100869178772, 0.8999972343444824, 0.8966540098190308, 0.8954071998596191, 0.892368495464325, 0.8921555280685425, 0.8925667405128479, 0.8867029547691345, 0.8825168013572693, 0.8756851553916931, 0.8776743412017822, 0.8742139339447021, 0.8827466368675232, 0.8685349822044373, 0.8663543462753296, 0.8662210702896118, 0.8638594746589661, 0.8639492392539978, 0.8578773736953735, 0.8524773716926575, 0.8459461331367493, 0.8387725353240967, 0.8442398309707642, 0.836700975894928, 0.8451042175292969, 0.8360418081283569, 0.8285754323005676, 0.8281023502349854, 0.8388274312019348, 0.8366654515266418, 0.8212818503379822, 0.8133090138435364, 0.815986156463623, 0.8139100074768066, 0.8109571933746338, 0.8033753037452698, 0.8071994185447693, 0.8043450117111206, 0.7978762984275818, 0.7944673895835876, 0.7915118336677551, 0.7903818488121033, 0.7898499369621277, 0.7842357158660889, 0.7811923027038574, 0.7748036980628967, 0.7814522981643677, 0.7746979594230652, 0.7689173817634583, 0.7821890115737915, 0.7722325921058655, 0.7599376440048218, 0.7576897740364075, 0.7571685314178467, 0.7525830268859863, 0.759076714515686, 0.7474426031112671, 0.7529746890068054, 0.7481904029846191], 'accuracy': [0.6108527183532715, 0.630232572555542, 0.6297157406806946, 0.6219637989997864, 0.6361756920814514, 0.6289405822753906, 0.6395348906517029, 0.6426356434822083, 0.6379845142364502, 0.6478036046028137, 0.6377260684967041, 0.6343669295310974, 0.6387596726417542, 0.6493539810180664, 0.6496124267578125, 0.658397912979126, 0.6496124267578125, 0.6436692476272583, 0.6509044170379639, 0.6571059226989746, 0.6638242602348328, 0.6550387740135193, 0.6622738838195801, 0.6527131795883179, 0.6630491018295288, 0.6645994782447815, 0.671576201915741, 0.6514211893081665, 0.6682170629501343, 0.6589147448539734, 0.6728681921958923, 0.6705426573753357, 0.6658914685249329, 0.6635658740997314, 0.6720930337905884, 0.6775193810462952, 0.6695090532302856, 0.6692506670951843, 0.6687338352203369, 0.6687338352203369, 0.6837209463119507, 0.6785529851913452, 0.6806201338768005, 0.6917312741279602, 0.6801033616065979, 0.698966383934021, 0.6788113713264465, 0.6824289560317993, 0.685012936592102, 0.6940568685531616, 0.6943152546882629, 0.6914728879928589, 0.6881136894226074, 0.6806201338768005, 0.6958656311035156, 0.6904392838478088, 0.7015503644943237, 0.6883720755577087, 0.6896640658378601, 0.7077519297599792, 0.7036175727844238, 0.7062015533447266, 0.7175710797309875, 0.7054263353347778, 0.7165374755859375, 0.7028423547744751, 0.709560751914978, 0.7170542478561401, 0.7211886048316956, 0.7018088102340698, 0.7010335922241211, 0.7193798422813416, 0.7173126339912415, 0.7178294658660889, 0.7214470505714417, 0.7222222089767456, 0.7382428646087646, 0.7258397936820984, 0.724547803401947, 0.7346253395080566, 0.7279070019721985, 0.7338501214981079, 0.7294573783874512, 0.7255814075469971, 0.736692488193512, 0.7382428646087646, 0.7444444298744202, 0.735917329788208, 0.7413436770439148, 0.7403100728988647, 0.7250645756721497, 0.7379844784736633, 0.750129222869873, 0.7534883618354797, 0.7439276576042175, 0.7459948062896729, 0.7403100728988647, 0.7534883618354797, 0.7421188354492188, 0.7493540048599243], 'val_loss': [1.091893196105957, 1.087859869003296, 1.0843260288238525, 1.0812910795211792, 1.0769723653793335, 1.0730390548706055, 1.0699318647384644, 1.0658317804336548, 1.0618361234664917, 1.0567189455032349, 1.0525602102279663, 1.0478750467300415, 1.042999505996704, 1.0373889207839966, 1.0322833061218262, 1.0315309762954712, 1.0275216102600098, 1.0174180269241333, 1.0116207599639893, 1.0109951496124268, 1.0039938688278198, 1.026329517364502, 1.004251480102539, 0.9935485124588013, 0.9998233318328857, 1.0012112855911255, 0.9864919185638428, 0.9845424294471741, 0.9821244478225708, 0.9857187867164612, 0.9789513945579529, 0.9769056439399719, 0.9954757690429688, 0.9758543372154236, 0.9721967577934265, 0.9699554443359375, 0.9746662378311157, 0.9713910818099976, 0.9676797986030579, 0.9640330076217651, 0.9634276628494263, 0.9610047936439514, 0.9597997069358826, 0.9680272340774536, 0.9798798561096191, 0.9562177062034607, 0.9692676663398743, 0.9576109051704407, 0.951743483543396, 0.9505309462547302, 0.9478211998939514, 0.9582846164703369, 0.949059784412384, 0.9819718599319458, 0.9381238222122192, 0.9368652701377869, 0.9528802633285522, 0.9406149387359619, 0.9326626062393188, 0.9311316609382629, 0.9343012571334839, 0.9365519881248474, 0.9308198094367981, 0.9277329444885254, 0.927381157875061, 0.9250915050506592, 0.9254229664802551, 0.924423336982727, 0.9567513465881348, 0.9515253901481628, 0.9326668977737427, 0.9190663695335388, 0.9177237153053284, 0.9292227029800415, 0.9195001721382141, 0.9181209802627563, 0.9262773990631104, 0.9145583510398865, 0.9142318964004517, 0.9237579703330994, 0.914730966091156, 0.9501014351844788, 0.9249775409698486, 0.917072594165802, 0.9160824418067932, 0.9119263291358948, 0.932698130607605, 0.9194759726524353, 0.9286004900932312, 0.9459102749824524, 0.9121259450912476, 0.9131931662559509, 0.9131689071655273, 0.9234360456466675, 0.9129635095596313, 0.9307619333267212, 0.9306833744049072, 0.9284045696258545, 0.9519712924957275, 0.9141819477081299], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.4876033067703247, 0.48966941237449646, 0.5413222908973694, 0.5733470916748047, 0.5547520518302917, 0.5723140239715576, 0.5743801593780518, 0.577479362487793, 0.5950413346290588, 0.5929751992225647, 0.5847107172012329, 0.5929751992225647, 0.5940082669258118, 0.56611567735672, 0.5702479481697083, 0.5909090638160706, 0.6012396812438965, 0.5960744023323059, 0.6012396812438965, 0.5754132270812988, 0.6022727489471436, 0.6136363744735718, 0.6012396812438965, 0.5981404781341553, 0.6229338645935059, 0.6188016533851624, 0.6270661354064941, 0.6033057570457458, 0.6239669322967529, 0.6146694421768188, 0.5981404781341553, 0.6270661354064941, 0.6177685856819153, 0.6239669322967529, 0.6188016533851624, 0.6136363744735718, 0.6074380278587341, 0.6280992031097412, 0.6311983466148376, 0.6270661354064941, 0.6177685856819153, 0.60537189245224, 0.5919421315193176, 0.6229338645935059, 0.6074380278587341, 0.6198347210884094, 0.6270661354064941, 0.6270661354064941, 0.6208677887916565, 0.6208677887916565, 0.6115702390670776, 0.5981404781341553, 0.6301652789115906, 0.6280992031097412, 0.6167355179786682, 0.6157024502754211, 0.6291322112083435, 0.6208677887916565, 0.6177685856819153, 0.6188016533851624, 0.6291322112083435, 0.6301652789115906, 0.6301652789115906, 0.6280992031097412, 0.6270661354064941, 0.6311983466148376, 0.6002066135406494, 0.6105371713638306, 0.6126033067703247, 0.6219007968902588, 0.6301652789115906, 0.6384297609329224, 0.6280992031097412, 0.6394628286361694, 0.6188016533851624, 0.6260330677032471, 0.6260330677032471, 0.6373966932296753, 0.6291322112083435, 0.6126033067703247, 0.6270661354064941, 0.6332644820213318, 0.6322314143180847, 0.6280992031097412, 0.6239669322967529, 0.6415289044380188, 0.6188016533851624, 0.6105371713638306, 0.6301652789115906, 0.6332644820213318, 0.6280992031097412, 0.6280992031097412, 0.625, 0.6229338645935059, 0.6322314143180847, 0.6280992031097412, 0.6022727489471436, 0.6280992031097412]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.8001 - accuracy: 0.7049"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 53ms/step - loss: 0.7981 - accuracy: 0.7069 - val_loss: 0.9404 - val_accuracy: 0.4860\n","Epoch 2/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7806 - accuracy: 0.7287 - val_loss: 0.9359 - val_accuracy: 0.4935\n","Epoch 3/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.7769 - accuracy: 0.7293 - val_loss: 0.9326 - val_accuracy: 0.5119\n","Epoch 4/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.7700 - accuracy: 0.7381 - val_loss: 0.9287 - val_accuracy: 0.5366\n","Epoch 5/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7637 - accuracy: 0.7371 - val_loss: 0.9251 - val_accuracy: 0.5668\n","Epoch 6/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7626 - accuracy: 0.7376 - val_loss: 0.9218 - val_accuracy: 0.5916\n","Epoch 7/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7630 - accuracy: 0.7328 - val_loss: 0.9188 - val_accuracy: 0.5927\n","Epoch 8/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7563 - accuracy: 0.7481 - val_loss: 0.9182 - val_accuracy: 0.5711\n","Epoch 9/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7543 - accuracy: 0.7443 - val_loss: 0.9149 - val_accuracy: 0.5787\n","Epoch 10/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7494 - accuracy: 0.7484 - val_loss: 0.9168 - val_accuracy: 0.5690\n","Epoch 11/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7468 - accuracy: 0.7433 - val_loss: 0.9104 - val_accuracy: 0.5862\n","Epoch 12/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7484 - accuracy: 0.7460 - val_loss: 0.9320 - val_accuracy: 0.5496\n","Epoch 13/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7384 - accuracy: 0.7524 - val_loss: 0.9402 - val_accuracy: 0.5485\n","Epoch 14/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7328 - accuracy: 0.7559 - val_loss: 0.9244 - val_accuracy: 0.5711\n","Epoch 15/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7522 - accuracy: 0.7411 - val_loss: 0.9683 - val_accuracy: 0.5453\n","Epoch 16/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7380 - accuracy: 0.7508 - val_loss: 0.9199 - val_accuracy: 0.5884\n","Epoch 17/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7447 - accuracy: 0.7387 - val_loss: 0.9377 - val_accuracy: 0.5819\n","Epoch 18/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7260 - accuracy: 0.7497 - val_loss: 0.9556 - val_accuracy: 0.5776\n","Epoch 19/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7239 - accuracy: 0.7621 - val_loss: 0.9911 - val_accuracy: 0.5668\n","Epoch 20/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7183 - accuracy: 0.7616 - val_loss: 0.9909 - val_accuracy: 0.5776\n","Epoch 21/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7179 - accuracy: 0.7584 - val_loss: 0.9763 - val_accuracy: 0.5819\n","Epoch 22/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7326 - accuracy: 0.7449 - val_loss: 0.9576 - val_accuracy: 0.5927\n","Epoch 23/100\n","29/29 [==============================] - 1s 35ms/step - loss: 0.7163 - accuracy: 0.7608 - val_loss: 0.8740 - val_accuracy: 0.6455\n","Epoch 24/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7070 - accuracy: 0.7697 - val_loss: 0.9023 - val_accuracy: 0.6315\n","Epoch 25/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7059 - accuracy: 0.7672 - val_loss: 0.9042 - val_accuracy: 0.6315\n","Epoch 26/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.7030 - accuracy: 0.7753 - val_loss: 0.8445 - val_accuracy: 0.6541\n","Epoch 27/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6990 - accuracy: 0.7767 - val_loss: 0.8626 - val_accuracy: 0.6584\n","Epoch 28/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7091 - accuracy: 0.7594 - val_loss: 0.8505 - val_accuracy: 0.6681\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6977 - accuracy: 0.7680 - val_loss: 0.8475 - val_accuracy: 0.6498\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6986 - accuracy: 0.7745 - val_loss: 0.8525 - val_accuracy: 0.6595\n","Epoch 31/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6928 - accuracy: 0.7737 - val_loss: 0.8467 - val_accuracy: 0.6627\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6838 - accuracy: 0.7861 - val_loss: 0.8449 - val_accuracy: 0.6638\n","Epoch 33/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6761 - accuracy: 0.7856 - val_loss: 0.8514 - val_accuracy: 0.6638\n","Epoch 34/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6824 - accuracy: 0.7804 - val_loss: 0.8488 - val_accuracy: 0.6627\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6784 - accuracy: 0.7818 - val_loss: 0.8519 - val_accuracy: 0.6562\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6823 - accuracy: 0.7777 - val_loss: 0.9152 - val_accuracy: 0.6627\n","Epoch 37/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6981 - accuracy: 0.7645 - val_loss: 0.8945 - val_accuracy: 0.6724\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6812 - accuracy: 0.7780 - val_loss: 0.8587 - val_accuracy: 0.6595\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6655 - accuracy: 0.7920 - val_loss: 0.8569 - val_accuracy: 0.6573\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6644 - accuracy: 0.7961 - val_loss: 0.8668 - val_accuracy: 0.6681\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6712 - accuracy: 0.7839 - val_loss: 0.8706 - val_accuracy: 0.6595\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6662 - accuracy: 0.7866 - val_loss: 0.8586 - val_accuracy: 0.6649\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6560 - accuracy: 0.7963 - val_loss: 0.8717 - val_accuracy: 0.6422\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6881 - accuracy: 0.7699 - val_loss: 0.8877 - val_accuracy: 0.6670\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6724 - accuracy: 0.7710 - val_loss: 0.8549 - val_accuracy: 0.6487\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6486 - accuracy: 0.7998 - val_loss: 0.8561 - val_accuracy: 0.6627\n","Epoch 47/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6446 - accuracy: 0.8063 - val_loss: 0.8604 - val_accuracy: 0.6659\n","Epoch 48/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6476 - accuracy: 0.8028 - val_loss: 0.8576 - val_accuracy: 0.6606\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6422 - accuracy: 0.8039 - val_loss: 0.8692 - val_accuracy: 0.6595\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6357 - accuracy: 0.8001 - val_loss: 0.8661 - val_accuracy: 0.6713\n","Epoch 51/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6311 - accuracy: 0.8120 - val_loss: 0.8665 - val_accuracy: 0.6703\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6399 - accuracy: 0.8001 - val_loss: 0.8681 - val_accuracy: 0.6584\n","Epoch 53/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6457 - accuracy: 0.7961 - val_loss: 0.9173 - val_accuracy: 0.6250\n","Epoch 54/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6404 - accuracy: 0.8009 - val_loss: 0.8650 - val_accuracy: 0.6530\n","Epoch 55/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6267 - accuracy: 0.8117 - val_loss: 0.8631 - val_accuracy: 0.6584\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6355 - accuracy: 0.8009 - val_loss: 0.8815 - val_accuracy: 0.6681\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6361 - accuracy: 0.8031 - val_loss: 0.8873 - val_accuracy: 0.6627\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6262 - accuracy: 0.8079 - val_loss: 0.8650 - val_accuracy: 0.6692\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6215 - accuracy: 0.8047 - val_loss: 0.8695 - val_accuracy: 0.6703\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6271 - accuracy: 0.8055 - val_loss: 0.8658 - val_accuracy: 0.6659\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6057 - accuracy: 0.8211 - val_loss: 0.8736 - val_accuracy: 0.6713\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6050 - accuracy: 0.8168 - val_loss: 0.8882 - val_accuracy: 0.6595\n","Epoch 63/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6099 - accuracy: 0.8130 - val_loss: 0.8684 - val_accuracy: 0.6692\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5956 - accuracy: 0.8244 - val_loss: 0.8776 - val_accuracy: 0.6638\n","Epoch 65/100\n","29/29 [==============================] - 2s 66ms/step - loss: 0.5955 - accuracy: 0.8249 - val_loss: 0.8907 - val_accuracy: 0.6735\n","Epoch 66/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6148 - accuracy: 0.8066 - val_loss: 0.8852 - val_accuracy: 0.6562\n","Epoch 67/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5933 - accuracy: 0.8279 - val_loss: 0.8937 - val_accuracy: 0.6649\n","Epoch 68/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5906 - accuracy: 0.8182 - val_loss: 0.8915 - val_accuracy: 0.6519\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5865 - accuracy: 0.8270 - val_loss: 0.8848 - val_accuracy: 0.6713\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5936 - accuracy: 0.8163 - val_loss: 0.8999 - val_accuracy: 0.6595\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6008 - accuracy: 0.8171 - val_loss: 0.9501 - val_accuracy: 0.6218\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5867 - accuracy: 0.8254 - val_loss: 0.8803 - val_accuracy: 0.6573\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5791 - accuracy: 0.8346 - val_loss: 0.9174 - val_accuracy: 0.6681\n","Epoch 74/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5754 - accuracy: 0.8308 - val_loss: 0.8880 - val_accuracy: 0.6638\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5752 - accuracy: 0.8332 - val_loss: 0.9022 - val_accuracy: 0.6530\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5767 - accuracy: 0.8324 - val_loss: 0.8917 - val_accuracy: 0.6638\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5662 - accuracy: 0.8335 - val_loss: 0.8919 - val_accuracy: 0.6616\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5642 - accuracy: 0.8386 - val_loss: 0.9007 - val_accuracy: 0.6606\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5657 - accuracy: 0.8343 - val_loss: 0.8992 - val_accuracy: 0.6681\n","Epoch 80/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5608 - accuracy: 0.8386 - val_loss: 0.9106 - val_accuracy: 0.6746\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5575 - accuracy: 0.8400 - val_loss: 0.9289 - val_accuracy: 0.6476\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5597 - accuracy: 0.8416 - val_loss: 0.9076 - val_accuracy: 0.6562\n","Epoch 83/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5583 - accuracy: 0.8381 - val_loss: 0.9142 - val_accuracy: 0.6767\n","Epoch 84/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5614 - accuracy: 0.8362 - val_loss: 0.9378 - val_accuracy: 0.6627\n","Epoch 85/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5515 - accuracy: 0.8440 - val_loss: 0.9074 - val_accuracy: 0.6541\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5547 - accuracy: 0.8451 - val_loss: 0.9506 - val_accuracy: 0.6541\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5430 - accuracy: 0.8578 - val_loss: 0.9064 - val_accuracy: 0.6649\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5409 - accuracy: 0.8413 - val_loss: 0.9165 - val_accuracy: 0.6713\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5286 - accuracy: 0.8596 - val_loss: 0.9264 - val_accuracy: 0.6638\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5448 - accuracy: 0.8502 - val_loss: 0.9533 - val_accuracy: 0.6347\n","Epoch 91/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5229 - accuracy: 0.8599 - val_loss: 0.9243 - val_accuracy: 0.6552\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5270 - accuracy: 0.8481 - val_loss: 0.9544 - val_accuracy: 0.6649\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5241 - accuracy: 0.8599 - val_loss: 0.9244 - val_accuracy: 0.6552\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5190 - accuracy: 0.8618 - val_loss: 0.9239 - val_accuracy: 0.6681\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5278 - accuracy: 0.8534 - val_loss: 0.9357 - val_accuracy: 0.6530\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5213 - accuracy: 0.8572 - val_loss: 0.9242 - val_accuracy: 0.6724\n","Epoch 97/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5171 - accuracy: 0.8596 - val_loss: 0.9201 - val_accuracy: 0.6778\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5190 - accuracy: 0.8580 - val_loss: 0.9374 - val_accuracy: 0.6713\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5539 - accuracy: 0.8338 - val_loss: 0.9385 - val_accuracy: 0.6498\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5208 - accuracy: 0.8556 - val_loss: 0.9402 - val_accuracy: 0.6541\n","{'loss': [0.7980989813804626, 0.780627429485321, 0.7769347429275513, 0.7699970602989197, 0.7636860609054565, 0.7626217603683472, 0.7630400061607361, 0.7563124299049377, 0.7543364763259888, 0.7493578195571899, 0.7468076944351196, 0.7483934164047241, 0.7383723855018616, 0.732824444770813, 0.752204418182373, 0.7380301356315613, 0.7447089552879333, 0.72602778673172, 0.7239150404930115, 0.7182676792144775, 0.7178663611412048, 0.7326406836509705, 0.7162765264511108, 0.7070302367210388, 0.7058764100074768, 0.7030206322669983, 0.6989871859550476, 0.7091293931007385, 0.6977189183235168, 0.6986168026924133, 0.6927500367164612, 0.6837782263755798, 0.6761420965194702, 0.6823749542236328, 0.6783557534217834, 0.6823136806488037, 0.6981486678123474, 0.6811969876289368, 0.6655165553092957, 0.6643561720848083, 0.6712452173233032, 0.6661630272865295, 0.6560115814208984, 0.6881004571914673, 0.6724004149436951, 0.6485584378242493, 0.6446120142936707, 0.6476274728775024, 0.6422030329704285, 0.6356813311576843, 0.6310585737228394, 0.63994961977005, 0.6456869840621948, 0.6403988003730774, 0.6266822218894958, 0.6355275511741638, 0.6361460089683533, 0.6261759996414185, 0.6214677691459656, 0.6271017789840698, 0.6056625247001648, 0.6049708724021912, 0.6098962426185608, 0.5956167578697205, 0.5954946279525757, 0.614843487739563, 0.5932714343070984, 0.5905880928039551, 0.5865213871002197, 0.5936210751533508, 0.6008297204971313, 0.5867120027542114, 0.5791140198707581, 0.5753852128982544, 0.5751991868019104, 0.5766756534576416, 0.5662282109260559, 0.5642043948173523, 0.5656888484954834, 0.5608174800872803, 0.5574784278869629, 0.559739351272583, 0.558304488658905, 0.5614485740661621, 0.5514557361602783, 0.5547434687614441, 0.5430343151092529, 0.5409409403800964, 0.528578519821167, 0.5448240041732788, 0.5229423642158508, 0.5270015001296997, 0.5241184830665588, 0.518999457359314, 0.527787983417511, 0.521264910697937, 0.5171235203742981, 0.518974781036377, 0.55391526222229, 0.5207578539848328], 'accuracy': [0.7068965435028076, 0.7287176847457886, 0.7292564511299133, 0.7381465435028076, 0.7370689511299133, 0.7376077771186829, 0.732758641242981, 0.7481142282485962, 0.7443426847457886, 0.748383641242981, 0.7432650923728943, 0.7459590435028076, 0.7524245977401733, 0.7559267282485962, 0.7411099076271057, 0.7508081793785095, 0.7386853694915771, 0.7497305870056152, 0.7621228694915771, 0.7615840435028076, 0.7583512663841248, 0.7448814511299133, 0.7607758641242981, 0.7696659564971924, 0.767241358757019, 0.7753232717514038, 0.7766702771186829, 0.759428858757019, 0.7680495977401733, 0.7745150923728943, 0.7737069129943848, 0.7860991358757019, 0.7855603694915771, 0.7804418206214905, 0.7817887663841248, 0.7777478694915771, 0.7645474076271057, 0.7780172228813171, 0.7920258641242981, 0.7960668206214905, 0.7839439511299133, 0.7866379022598267, 0.7963362336158752, 0.7699353694915771, 0.7710129022598267, 0.7998383641242981, 0.806303858757019, 0.8028017282485962, 0.8038793206214905, 0.8001077771186829, 0.8119612336158752, 0.8001077771186829, 0.7960668206214905, 0.8009159564971924, 0.8116918206214905, 0.8009159564971924, 0.803071141242981, 0.8079202771186829, 0.8046875, 0.8054956793785095, 0.8211206793785095, 0.8168103694915771, 0.8130387663841248, 0.8243534564971924, 0.8248922228813171, 0.8065732717514038, 0.8278555870056152, 0.8181573152542114, 0.8270474076271057, 0.8162715435028076, 0.8170797228813171, 0.8254310488700867, 0.834590494632721, 0.8308189511299133, 0.8332435488700867, 0.8324353694915771, 0.8335129022598267, 0.8386314511299133, 0.834321141242981, 0.8386314511299133, 0.8399784564971924, 0.8415948152542114, 0.8380926847457886, 0.8362069129943848, 0.8440194129943848, 0.845097005367279, 0.857758641242981, 0.8413254022598267, 0.8596444129943848, 0.850215494632721, 0.8599137663841248, 0.8480603694915771, 0.8599137663841248, 0.8617995977401733, 0.8534482717514038, 0.8572198152542114, 0.8596444129943848, 0.858027994632721, 0.8337823152542114, 0.8556034564971924], 'val_loss': [0.9403916597366333, 0.9359156489372253, 0.9325829744338989, 0.9286563992500305, 0.925122082233429, 0.9217556118965149, 0.9188187122344971, 0.9181886911392212, 0.9149085879325867, 0.9168439507484436, 0.9104031920433044, 0.9320132732391357, 0.940241277217865, 0.9243860840797424, 0.9683240056037903, 0.9199020266532898, 0.9377020001411438, 0.9555839896202087, 0.9910520315170288, 0.9909476041793823, 0.9763128757476807, 0.9576267004013062, 0.8740245699882507, 0.9023411273956299, 0.9042206406593323, 0.8445324301719666, 0.8626126646995544, 0.8504714965820312, 0.8475373983383179, 0.852472186088562, 0.8466612100601196, 0.8449026942253113, 0.8513954281806946, 0.8488479256629944, 0.8518747687339783, 0.9151536226272583, 0.8945054411888123, 0.8586748242378235, 0.8568688035011292, 0.866820216178894, 0.8705772161483765, 0.8586024641990662, 0.8717136979103088, 0.8877385854721069, 0.8548910021781921, 0.8561140298843384, 0.8604117631912231, 0.8576313257217407, 0.8692055344581604, 0.8661117553710938, 0.8665117621421814, 0.8681216835975647, 0.9173184037208557, 0.8649550676345825, 0.8630588054656982, 0.881524920463562, 0.8872824907302856, 0.8650131821632385, 0.8695455193519592, 0.8658294677734375, 0.8736251592636108, 0.8882499933242798, 0.8683990836143494, 0.8776125907897949, 0.8907181024551392, 0.885213315486908, 0.8936959505081177, 0.8915247321128845, 0.8847599625587463, 0.8998656868934631, 0.9501176476478577, 0.8802695274353027, 0.9173898100852966, 0.8880359530448914, 0.9022060632705688, 0.8916804194450378, 0.8918951749801636, 0.900697648525238, 0.8992393016815186, 0.9106314182281494, 0.928870439529419, 0.9075900316238403, 0.9141654968261719, 0.9378132820129395, 0.9074409604072571, 0.9505712389945984, 0.9063808917999268, 0.9165037274360657, 0.9263896942138672, 0.9532736539840698, 0.9243155717849731, 0.9544452428817749, 0.924379825592041, 0.9239395260810852, 0.935693085193634, 0.9241526126861572, 0.9200796484947205, 0.9374301433563232, 0.9385285377502441, 0.9401878118515015], 'val_accuracy': [0.48599138855934143, 0.49353447556495667, 0.5118534564971924, 0.5366379022598267, 0.5668103694915771, 0.5915948152542114, 0.5926724076271057, 0.5711206793785095, 0.5786637663841248, 0.568965494632721, 0.5862069129943848, 0.5495689511299133, 0.548491358757019, 0.5711206793785095, 0.545258641242981, 0.5883620977401733, 0.5818965435028076, 0.5775862336158752, 0.5668103694915771, 0.5775862336158752, 0.5818965435028076, 0.5926724076271057, 0.6454741358757019, 0.631465494632721, 0.631465494632721, 0.6540948152542114, 0.6584051847457886, 0.6681034564971924, 0.649784505367279, 0.6594827771186829, 0.662715494632721, 0.6637930870056152, 0.6637930870056152, 0.662715494632721, 0.65625, 0.662715494632721, 0.6724137663841248, 0.6594827771186829, 0.6573275923728943, 0.6681034564971924, 0.6594827771186829, 0.6648706793785095, 0.642241358757019, 0.6670258641242981, 0.6487069129943848, 0.662715494632721, 0.6659482717514038, 0.6605603694915771, 0.6594827771186829, 0.6713362336158752, 0.670258641242981, 0.6584051847457886, 0.625, 0.6530172228813171, 0.6584051847457886, 0.6681034564971924, 0.662715494632721, 0.6691810488700867, 0.670258641242981, 0.6659482717514038, 0.6713362336158752, 0.6594827771186829, 0.6691810488700867, 0.6637930870056152, 0.673491358757019, 0.65625, 0.6648706793785095, 0.6519396305084229, 0.6713362336158752, 0.6594827771186829, 0.6217672228813171, 0.6573275923728943, 0.6681034564971924, 0.6637930870056152, 0.6530172228813171, 0.6637930870056152, 0.6616379022598267, 0.6605603694915771, 0.6681034564971924, 0.6745689511299133, 0.6476293206214905, 0.65625, 0.6767241358757019, 0.662715494632721, 0.6540948152542114, 0.6540948152542114, 0.6648706793785095, 0.6713362336158752, 0.6637930870056152, 0.6346982717514038, 0.6551724076271057, 0.6648706793785095, 0.6551724076271057, 0.6681034564971924, 0.6530172228813171, 0.6724137663841248, 0.6778017282485962, 0.6713362336158752, 0.649784505367279, 0.6540948152542114]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","24/28 [========================>.....] - ETA: 0s - loss: 0.7955 - accuracy: 0.7191"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 10s 56ms/step - loss: 0.7913 - accuracy: 0.7190 - val_loss: 0.9371 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7772 - accuracy: 0.7298 - val_loss: 0.9335 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7801 - accuracy: 0.7354 - val_loss: 0.9286 - val_accuracy: 0.5373\n","Epoch 4/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.7759 - accuracy: 0.7332 - val_loss: 0.9255 - val_accuracy: 0.5792\n","Epoch 5/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.7668 - accuracy: 0.7405 - val_loss: 0.9223 - val_accuracy: 0.6143\n","Epoch 6/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7623 - accuracy: 0.7366 - val_loss: 0.9195 - val_accuracy: 0.6007\n","Epoch 7/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7593 - accuracy: 0.7541 - val_loss: 0.9165 - val_accuracy: 0.6018\n","Epoch 8/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7457 - accuracy: 0.7615 - val_loss: 0.9140 - val_accuracy: 0.5894\n","Epoch 9/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7507 - accuracy: 0.7555 - val_loss: 0.9103 - val_accuracy: 0.5916\n","Epoch 10/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7478 - accuracy: 0.7459 - val_loss: 0.9080 - val_accuracy: 0.5995\n","Epoch 11/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7471 - accuracy: 0.7465 - val_loss: 0.9179 - val_accuracy: 0.5554\n","Epoch 12/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7515 - accuracy: 0.7470 - val_loss: 0.9017 - val_accuracy: 0.5962\n","Epoch 13/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7394 - accuracy: 0.7586 - val_loss: 0.9035 - val_accuracy: 0.5984\n","Epoch 14/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.7414 - accuracy: 0.7530 - val_loss: 0.9007 - val_accuracy: 0.5962\n","Epoch 15/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7370 - accuracy: 0.7541 - val_loss: 0.9238 - val_accuracy: 0.5611\n","Epoch 16/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7321 - accuracy: 0.7589 - val_loss: 0.9106 - val_accuracy: 0.5882\n","Epoch 17/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7287 - accuracy: 0.7637 - val_loss: 0.9582 - val_accuracy: 0.5554\n","Epoch 18/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7303 - accuracy: 0.7586 - val_loss: 0.9169 - val_accuracy: 0.5905\n","Epoch 19/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7245 - accuracy: 0.7671 - val_loss: 0.9316 - val_accuracy: 0.5882\n","Epoch 20/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7275 - accuracy: 0.7674 - val_loss: 0.9830 - val_accuracy: 0.5758\n","Epoch 21/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7242 - accuracy: 0.7629 - val_loss: 0.9266 - val_accuracy: 0.5962\n","Epoch 22/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7216 - accuracy: 0.7603 - val_loss: 0.8865 - val_accuracy: 0.6097\n","Epoch 23/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7149 - accuracy: 0.7651 - val_loss: 0.8912 - val_accuracy: 0.6199\n","Epoch 24/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7127 - accuracy: 0.7691 - val_loss: 0.8879 - val_accuracy: 0.6188\n","Epoch 25/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7083 - accuracy: 0.7801 - val_loss: 0.8628 - val_accuracy: 0.6425\n","Epoch 26/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7008 - accuracy: 0.7818 - val_loss: 0.8410 - val_accuracy: 0.6527\n","Epoch 27/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7061 - accuracy: 0.7765 - val_loss: 0.8383 - val_accuracy: 0.6606\n","Epoch 28/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6996 - accuracy: 0.7793 - val_loss: 0.8540 - val_accuracy: 0.6550\n","Epoch 29/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7027 - accuracy: 0.7708 - val_loss: 0.8336 - val_accuracy: 0.6765\n","Epoch 30/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6895 - accuracy: 0.7886 - val_loss: 0.8306 - val_accuracy: 0.6776\n","Epoch 31/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6950 - accuracy: 0.7765 - val_loss: 0.8339 - val_accuracy: 0.6753\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6905 - accuracy: 0.7796 - val_loss: 0.8376 - val_accuracy: 0.6686\n","Epoch 33/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6915 - accuracy: 0.7813 - val_loss: 0.8327 - val_accuracy: 0.6855\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7006 - accuracy: 0.7750 - val_loss: 0.8339 - val_accuracy: 0.6719\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6768 - accuracy: 0.7960 - val_loss: 0.8348 - val_accuracy: 0.6742\n","Epoch 36/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6808 - accuracy: 0.7881 - val_loss: 0.8415 - val_accuracy: 0.6652\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6805 - accuracy: 0.7830 - val_loss: 0.8955 - val_accuracy: 0.6561\n","Epoch 38/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6882 - accuracy: 0.7736 - val_loss: 0.8391 - val_accuracy: 0.6708\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6788 - accuracy: 0.7889 - val_loss: 0.8398 - val_accuracy: 0.6776\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6657 - accuracy: 0.7971 - val_loss: 0.8423 - val_accuracy: 0.6663\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6676 - accuracy: 0.7951 - val_loss: 0.8387 - val_accuracy: 0.6765\n","Epoch 42/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6641 - accuracy: 0.7900 - val_loss: 0.8425 - val_accuracy: 0.6719\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6601 - accuracy: 0.7940 - val_loss: 0.8582 - val_accuracy: 0.6618\n","Epoch 44/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6668 - accuracy: 0.7920 - val_loss: 0.8825 - val_accuracy: 0.6448\n","Epoch 45/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6713 - accuracy: 0.7804 - val_loss: 0.8459 - val_accuracy: 0.6674\n","Epoch 46/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6464 - accuracy: 0.8036 - val_loss: 0.8359 - val_accuracy: 0.6765\n","Epoch 47/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6460 - accuracy: 0.8104 - val_loss: 0.8420 - val_accuracy: 0.6731\n","Epoch 48/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6498 - accuracy: 0.7997 - val_loss: 0.8438 - val_accuracy: 0.6719\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6451 - accuracy: 0.8014 - val_loss: 0.8395 - val_accuracy: 0.6776\n","Epoch 50/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6372 - accuracy: 0.8115 - val_loss: 0.8963 - val_accuracy: 0.6471\n","Epoch 51/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6396 - accuracy: 0.8124 - val_loss: 0.8492 - val_accuracy: 0.6652\n","Epoch 52/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6327 - accuracy: 0.8164 - val_loss: 0.8536 - val_accuracy: 0.6686\n","Epoch 53/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6294 - accuracy: 0.8079 - val_loss: 0.8653 - val_accuracy: 0.6640\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6356 - accuracy: 0.8141 - val_loss: 0.8448 - val_accuracy: 0.6742\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6431 - accuracy: 0.8022 - val_loss: 0.8536 - val_accuracy: 0.6629\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6258 - accuracy: 0.8147 - val_loss: 0.8851 - val_accuracy: 0.6550\n","Epoch 57/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6202 - accuracy: 0.8127 - val_loss: 0.8517 - val_accuracy: 0.6652\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6249 - accuracy: 0.8132 - val_loss: 0.8554 - val_accuracy: 0.6561\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6249 - accuracy: 0.8169 - val_loss: 0.8884 - val_accuracy: 0.6618\n","Epoch 60/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6267 - accuracy: 0.8164 - val_loss: 0.8811 - val_accuracy: 0.6550\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6200 - accuracy: 0.8149 - val_loss: 0.8565 - val_accuracy: 0.6663\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6101 - accuracy: 0.8274 - val_loss: 0.8631 - val_accuracy: 0.6652\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6139 - accuracy: 0.8149 - val_loss: 0.9020 - val_accuracy: 0.6538\n","Epoch 64/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6048 - accuracy: 0.8254 - val_loss: 0.8625 - val_accuracy: 0.6674\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6007 - accuracy: 0.8220 - val_loss: 0.8648 - val_accuracy: 0.6674\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5956 - accuracy: 0.8263 - val_loss: 0.8618 - val_accuracy: 0.6742\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5905 - accuracy: 0.8342 - val_loss: 0.8596 - val_accuracy: 0.6674\n","Epoch 68/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5904 - accuracy: 0.8294 - val_loss: 0.8604 - val_accuracy: 0.6708\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5890 - accuracy: 0.8257 - val_loss: 0.8780 - val_accuracy: 0.6629\n","Epoch 70/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5956 - accuracy: 0.8237 - val_loss: 0.8889 - val_accuracy: 0.6527\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5861 - accuracy: 0.8336 - val_loss: 0.8634 - val_accuracy: 0.6686\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5852 - accuracy: 0.8376 - val_loss: 0.8672 - val_accuracy: 0.6629\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6015 - accuracy: 0.8166 - val_loss: 0.8713 - val_accuracy: 0.6550\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5876 - accuracy: 0.8294 - val_loss: 0.8766 - val_accuracy: 0.6640\n","Epoch 75/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5733 - accuracy: 0.8427 - val_loss: 0.8665 - val_accuracy: 0.6606\n","Epoch 76/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5692 - accuracy: 0.8435 - val_loss: 0.8826 - val_accuracy: 0.6674\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5755 - accuracy: 0.8393 - val_loss: 0.8735 - val_accuracy: 0.6663\n","Epoch 78/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5707 - accuracy: 0.8362 - val_loss: 0.8772 - val_accuracy: 0.6640\n","Epoch 79/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5688 - accuracy: 0.8401 - val_loss: 0.8725 - val_accuracy: 0.6674\n","Epoch 80/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5615 - accuracy: 0.8421 - val_loss: 0.8630 - val_accuracy: 0.6753\n","Epoch 81/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5647 - accuracy: 0.8356 - val_loss: 0.9001 - val_accuracy: 0.6584\n","Epoch 82/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5567 - accuracy: 0.8472 - val_loss: 0.8761 - val_accuracy: 0.6572\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5575 - accuracy: 0.8458 - val_loss: 0.9087 - val_accuracy: 0.6652\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5717 - accuracy: 0.8316 - val_loss: 0.8955 - val_accuracy: 0.6686\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5705 - accuracy: 0.8331 - val_loss: 0.8861 - val_accuracy: 0.6697\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5630 - accuracy: 0.8393 - val_loss: 0.8779 - val_accuracy: 0.6606\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5331 - accuracy: 0.8633 - val_loss: 0.8783 - val_accuracy: 0.6595\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5316 - accuracy: 0.8563 - val_loss: 0.8912 - val_accuracy: 0.6618\n","Epoch 89/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5431 - accuracy: 0.8537 - val_loss: 0.9221 - val_accuracy: 0.6697\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5378 - accuracy: 0.8509 - val_loss: 0.8917 - val_accuracy: 0.6640\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5347 - accuracy: 0.8633 - val_loss: 0.8982 - val_accuracy: 0.6595\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5755 - accuracy: 0.8331 - val_loss: 0.9138 - val_accuracy: 0.6482\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5267 - accuracy: 0.8659 - val_loss: 0.8847 - val_accuracy: 0.6640\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5224 - accuracy: 0.8667 - val_loss: 0.8893 - val_accuracy: 0.6663\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5118 - accuracy: 0.8707 - val_loss: 0.9138 - val_accuracy: 0.6663\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5341 - accuracy: 0.8514 - val_loss: 0.9030 - val_accuracy: 0.6572\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5285 - accuracy: 0.8554 - val_loss: 0.8910 - val_accuracy: 0.6550\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5192 - accuracy: 0.8647 - val_loss: 0.9298 - val_accuracy: 0.6561\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5070 - accuracy: 0.8778 - val_loss: 0.9070 - val_accuracy: 0.6686\n","Epoch 100/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5149 - accuracy: 0.8630 - val_loss: 0.9206 - val_accuracy: 0.6618\n","{'loss': [0.7913211584091187, 0.7772465944290161, 0.7800997495651245, 0.7759356498718262, 0.7667660713195801, 0.7623282670974731, 0.759270429611206, 0.7456538081169128, 0.7506897449493408, 0.7478251457214355, 0.7470996975898743, 0.7514684200286865, 0.7394412755966187, 0.7413970232009888, 0.7370003461837769, 0.732110857963562, 0.7287372350692749, 0.730330228805542, 0.7244528532028198, 0.7275400757789612, 0.7241706848144531, 0.7216189503669739, 0.7148760557174683, 0.7126848697662354, 0.7082583904266357, 0.700791597366333, 0.706054151058197, 0.699612021446228, 0.7027201652526855, 0.6895189881324768, 0.6950328350067139, 0.690477192401886, 0.69145268201828, 0.7006166577339172, 0.676776111125946, 0.6807722449302673, 0.6804713010787964, 0.6881711483001709, 0.6788263916969299, 0.6656506061553955, 0.6676039695739746, 0.664107620716095, 0.6601160168647766, 0.6668044924736023, 0.6712611317634583, 0.6464495658874512, 0.6460334062576294, 0.6497571468353271, 0.6450802087783813, 0.6372064352035522, 0.639564573764801, 0.632726788520813, 0.6294376850128174, 0.6356480121612549, 0.6430590748786926, 0.6257697939872742, 0.6201896667480469, 0.624857485294342, 0.6249444484710693, 0.6267462968826294, 0.6200353503227234, 0.6100696325302124, 0.613917350769043, 0.6047646999359131, 0.6006909012794495, 0.5956170558929443, 0.5905318260192871, 0.5904174447059631, 0.5889863967895508, 0.5956122279167175, 0.5861045718193054, 0.585178554058075, 0.6015133261680603, 0.5875958204269409, 0.5733314156532288, 0.5691558718681335, 0.5754590630531311, 0.5707051157951355, 0.5687602758407593, 0.561542809009552, 0.5647209882736206, 0.5567302107810974, 0.557537317276001, 0.5716975331306458, 0.5704783201217651, 0.562981903553009, 0.533058762550354, 0.5315589904785156, 0.5431094169616699, 0.537833034992218, 0.5346561074256897, 0.5754784345626831, 0.5266866683959961, 0.5223695039749146, 0.5118491053581238, 0.5340619087219238, 0.5285422801971436, 0.519165575504303, 0.5069804191589355, 0.514914333820343], 'accuracy': [0.7190153002738953, 0.7297679781913757, 0.7354272603988647, 0.7331635355949402, 0.7405206561088562, 0.7365591526031494, 0.7541030049324036, 0.7614601254463196, 0.755517840385437, 0.7458969950675964, 0.7464629411697388, 0.7470288872718811, 0.7586304545402527, 0.7529711127281189, 0.7541030049324036, 0.7589133977890015, 0.7637238502502441, 0.7586304545402527, 0.7671194076538086, 0.7674023509025574, 0.7628749012947083, 0.7603282332420349, 0.7651386260986328, 0.7691001892089844, 0.7801358103752136, 0.7818335890769958, 0.7764572501182556, 0.7792869210243225, 0.7707979679107666, 0.7886247634887695, 0.7764572501182556, 0.7795698642730713, 0.7812677025794983, 0.7750424742698669, 0.7959818840026855, 0.788058876991272, 0.7829654812812805, 0.7736276388168335, 0.7889077663421631, 0.7971137762069702, 0.7951329946517944, 0.790039598941803, 0.7940011024475098, 0.7920203804969788, 0.7804188132286072, 0.8036219477653503, 0.810413122177124, 0.7996604442596436, 0.8013582229614258, 0.8115450143814087, 0.8123939037322998, 0.8163554072380066, 0.8078664541244507, 0.814091682434082, 0.8022071123123169, 0.8146576285362244, 0.8126768469810486, 0.8132427930831909, 0.8169213533401489, 0.8163554072380066, 0.8149405717849731, 0.8273910880088806, 0.8149405717849731, 0.8254103064537048, 0.8220146894454956, 0.826259195804596, 0.8341822028160095, 0.8293718099594116, 0.8256932497024536, 0.8237125277519226, 0.833616316318512, 0.8375778198242188, 0.8166383504867554, 0.8293718099594116, 0.8426712155342102, 0.8435201048851013, 0.839275598526001, 0.8361629843711853, 0.8401244878768921, 0.8421052694320679, 0.835597038269043, 0.8471986651420593, 0.8457838296890259, 0.8316355347633362, 0.8330503702163696, 0.839275598526001, 0.86332768201828, 0.8562535643577576, 0.8537068367004395, 0.8508771657943726, 0.86332768201828, 0.8330503702163696, 0.8658743500709534, 0.8667232394218445, 0.870684802532196, 0.8514431118965149, 0.8554046154022217, 0.8647425174713135, 0.8777589201927185, 0.8630446791648865], 'val_loss': [0.9370850920677185, 0.9335311055183411, 0.92859947681427, 0.9254891276359558, 0.9222543239593506, 0.9195137619972229, 0.9164571762084961, 0.9140085577964783, 0.9102508425712585, 0.9080182313919067, 0.9178729057312012, 0.9016546010971069, 0.9035295248031616, 0.9006506204605103, 0.9237968921661377, 0.9105972647666931, 0.958191454410553, 0.9168599843978882, 0.9316409826278687, 0.9830153584480286, 0.9266021847724915, 0.8865346312522888, 0.8912405967712402, 0.8879190683364868, 0.8628377914428711, 0.8410453200340271, 0.8383310437202454, 0.8540072441101074, 0.8335597515106201, 0.8305662870407104, 0.8339168429374695, 0.8376473784446716, 0.8327383995056152, 0.8339308500289917, 0.8347556591033936, 0.8414850234985352, 0.8954795002937317, 0.8391398191452026, 0.839840829372406, 0.8423392176628113, 0.8386992812156677, 0.8424770832061768, 0.8582150340080261, 0.8824836611747742, 0.8459107279777527, 0.8358973860740662, 0.841953456401825, 0.8438326716423035, 0.8395320177078247, 0.8962835073471069, 0.8491517901420593, 0.853561282157898, 0.8653350472450256, 0.8448456525802612, 0.8536292314529419, 0.8851311206817627, 0.8517487645149231, 0.855431854724884, 0.8884300589561462, 0.8811428546905518, 0.856542706489563, 0.86313796043396, 0.9019510746002197, 0.8625388145446777, 0.8648209571838379, 0.8617771863937378, 0.8596358299255371, 0.8604401350021362, 0.8780063390731812, 0.8889304995536804, 0.8633920550346375, 0.8672225475311279, 0.8713172674179077, 0.8766291737556458, 0.8665046691894531, 0.8825626969337463, 0.8735195398330688, 0.8772483468055725, 0.8724693655967712, 0.8629812002182007, 0.9000867009162903, 0.8761438131332397, 0.9086512923240662, 0.8954850435256958, 0.8860790729522705, 0.87788987159729, 0.8782661557197571, 0.8911526799201965, 0.9221193194389343, 0.8917430639266968, 0.8982133269309998, 0.9138200283050537, 0.8847460150718689, 0.8893105387687683, 0.9137912392616272, 0.9029951095581055, 0.8910160064697266, 0.9298317432403564, 0.9070246815681458, 0.9205594062805176], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.5373303294181824, 0.5791855454444885, 0.6142534017562866, 0.6006787419319153, 0.6018099784851074, 0.5893664956092834, 0.5916289687156677, 0.5995475053787231, 0.5554298758506775, 0.5961538553237915, 0.598416268825531, 0.5961538553237915, 0.5610859990119934, 0.5882353186607361, 0.5554298758506775, 0.5904977321624756, 0.5882353186607361, 0.5757918357849121, 0.5961538553237915, 0.6097285151481628, 0.6199095249176025, 0.6187782883644104, 0.6425339579582214, 0.6527149081230164, 0.6606335043907166, 0.6549773812294006, 0.6764705777168274, 0.6776018142700195, 0.6753393411636353, 0.668552041053772, 0.685520350933075, 0.6719456911087036, 0.6742081642150879, 0.6651583909988403, 0.6561086177825928, 0.6708144545555115, 0.6776018142700195, 0.6662895679473877, 0.6764705777168274, 0.6719456911087036, 0.6617646813392639, 0.6447963714599609, 0.6674208045005798, 0.6764705777168274, 0.6730769276618958, 0.6719456911087036, 0.6776018142700195, 0.6470588445663452, 0.6651583909988403, 0.668552041053772, 0.6640271544456482, 0.6742081642150879, 0.662895917892456, 0.6549773812294006, 0.6651583909988403, 0.6561086177825928, 0.6617646813392639, 0.6549773812294006, 0.6662895679473877, 0.6651583909988403, 0.6538461446762085, 0.6674208045005798, 0.6674208045005798, 0.6742081642150879, 0.6674208045005798, 0.6708144545555115, 0.662895917892456, 0.6527149081230164, 0.668552041053772, 0.662895917892456, 0.6549773812294006, 0.6640271544456482, 0.6606335043907166, 0.6674208045005798, 0.6662895679473877, 0.6640271544456482, 0.6674208045005798, 0.6753393411636353, 0.6583710312843323, 0.6572397947311401, 0.6651583909988403, 0.668552041053772, 0.6696832776069641, 0.6606335043907166, 0.6595022678375244, 0.6617646813392639, 0.6696832776069641, 0.6640271544456482, 0.6595022678375244, 0.6481900215148926, 0.6640271544456482, 0.6662895679473877, 0.6662895679473877, 0.6572397947311401, 0.6549773812294006, 0.6561086177825928, 0.668552041053772, 0.6617646813392639]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.8108 - accuracy: 0.7034"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 50ms/step - loss: 0.8108 - accuracy: 0.7034 - val_loss: 0.9440 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7927 - accuracy: 0.7173 - val_loss: 0.9372 - val_accuracy: 0.4886\n","Epoch 3/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7864 - accuracy: 0.7212 - val_loss: 0.9323 - val_accuracy: 0.5145\n","Epoch 4/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7842 - accuracy: 0.7289 - val_loss: 0.9278 - val_accuracy: 0.5610\n","Epoch 5/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7802 - accuracy: 0.7287 - val_loss: 0.9246 - val_accuracy: 0.5744\n","Epoch 6/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7815 - accuracy: 0.7199 - val_loss: 0.9212 - val_accuracy: 0.5806\n","Epoch 7/100\n","31/31 [==============================] - 2s 56ms/step - loss: 0.7745 - accuracy: 0.7256 - val_loss: 0.9177 - val_accuracy: 0.5878\n","Epoch 8/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7728 - accuracy: 0.7307 - val_loss: 0.9144 - val_accuracy: 0.5878\n","Epoch 9/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7668 - accuracy: 0.7408 - val_loss: 0.9135 - val_accuracy: 0.5682\n","Epoch 10/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7680 - accuracy: 0.7313 - val_loss: 0.9098 - val_accuracy: 0.5754\n","Epoch 11/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7623 - accuracy: 0.7385 - val_loss: 0.9078 - val_accuracy: 0.5764\n","Epoch 12/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7595 - accuracy: 0.7351 - val_loss: 0.9058 - val_accuracy: 0.5795\n","Epoch 13/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7613 - accuracy: 0.7411 - val_loss: 0.9128 - val_accuracy: 0.5682\n","Epoch 14/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7623 - accuracy: 0.7328 - val_loss: 0.9101 - val_accuracy: 0.5754\n","Epoch 15/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7602 - accuracy: 0.7307 - val_loss: 0.9227 - val_accuracy: 0.5671\n","Epoch 16/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7506 - accuracy: 0.7401 - val_loss: 0.9593 - val_accuracy: 0.5589\n","Epoch 17/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7594 - accuracy: 0.7326 - val_loss: 0.9006 - val_accuracy: 0.5961\n","Epoch 18/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7439 - accuracy: 0.7496 - val_loss: 0.9185 - val_accuracy: 0.5909\n","Epoch 19/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7437 - accuracy: 0.7473 - val_loss: 0.9464 - val_accuracy: 0.5744\n","Epoch 20/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7375 - accuracy: 0.7561 - val_loss: 0.9162 - val_accuracy: 0.6002\n","Epoch 21/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7304 - accuracy: 0.7535 - val_loss: 0.9176 - val_accuracy: 0.6054\n","Epoch 22/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7291 - accuracy: 0.7512 - val_loss: 0.8934 - val_accuracy: 0.6219\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7358 - accuracy: 0.7501 - val_loss: 0.9149 - val_accuracy: 0.6219\n","Epoch 24/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7318 - accuracy: 0.7468 - val_loss: 0.8450 - val_accuracy: 0.6570\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7248 - accuracy: 0.7553 - val_loss: 0.8523 - val_accuracy: 0.6436\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7211 - accuracy: 0.7574 - val_loss: 0.8739 - val_accuracy: 0.6353\n","Epoch 27/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7213 - accuracy: 0.7605 - val_loss: 0.8439 - val_accuracy: 0.6674\n","Epoch 28/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7215 - accuracy: 0.7563 - val_loss: 0.8483 - val_accuracy: 0.6622\n","Epoch 29/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7207 - accuracy: 0.7563 - val_loss: 0.8461 - val_accuracy: 0.6612\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7175 - accuracy: 0.7594 - val_loss: 0.8852 - val_accuracy: 0.6312\n","Epoch 31/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7205 - accuracy: 0.7556 - val_loss: 0.8556 - val_accuracy: 0.6581\n","Epoch 32/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7280 - accuracy: 0.7488 - val_loss: 0.8469 - val_accuracy: 0.6632\n","Epoch 33/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7136 - accuracy: 0.7620 - val_loss: 0.8659 - val_accuracy: 0.6457\n","Epoch 34/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7078 - accuracy: 0.7607 - val_loss: 0.8646 - val_accuracy: 0.6488\n","Epoch 35/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7070 - accuracy: 0.7690 - val_loss: 0.8637 - val_accuracy: 0.6488\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7038 - accuracy: 0.7636 - val_loss: 0.8472 - val_accuracy: 0.6643\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6987 - accuracy: 0.7690 - val_loss: 0.8606 - val_accuracy: 0.6653\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7162 - accuracy: 0.7548 - val_loss: 0.8564 - val_accuracy: 0.6560\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7004 - accuracy: 0.7649 - val_loss: 0.8499 - val_accuracy: 0.6674\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6991 - accuracy: 0.7674 - val_loss: 0.8471 - val_accuracy: 0.6663\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6856 - accuracy: 0.7742 - val_loss: 0.9077 - val_accuracy: 0.6312\n","Epoch 42/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6854 - accuracy: 0.7752 - val_loss: 0.8634 - val_accuracy: 0.6519\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6792 - accuracy: 0.7876 - val_loss: 0.8552 - val_accuracy: 0.6653\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6801 - accuracy: 0.7819 - val_loss: 0.8565 - val_accuracy: 0.6601\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6751 - accuracy: 0.7897 - val_loss: 0.8602 - val_accuracy: 0.6560\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6953 - accuracy: 0.7680 - val_loss: 0.8886 - val_accuracy: 0.6312\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6732 - accuracy: 0.7780 - val_loss: 0.8893 - val_accuracy: 0.6508\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6804 - accuracy: 0.7778 - val_loss: 0.8608 - val_accuracy: 0.6539\n","Epoch 49/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6739 - accuracy: 0.7788 - val_loss: 0.8573 - val_accuracy: 0.6467\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6621 - accuracy: 0.7925 - val_loss: 0.8776 - val_accuracy: 0.6457\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6616 - accuracy: 0.7873 - val_loss: 0.8579 - val_accuracy: 0.6632\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6742 - accuracy: 0.7705 - val_loss: 0.8527 - val_accuracy: 0.6643\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6703 - accuracy: 0.7731 - val_loss: 0.8591 - val_accuracy: 0.6591\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6538 - accuracy: 0.7974 - val_loss: 0.8556 - val_accuracy: 0.6539\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6469 - accuracy: 0.7956 - val_loss: 0.8762 - val_accuracy: 0.6467\n","Epoch 56/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6614 - accuracy: 0.7814 - val_loss: 0.8615 - val_accuracy: 0.6570\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6594 - accuracy: 0.7829 - val_loss: 0.8580 - val_accuracy: 0.6550\n","Epoch 58/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6462 - accuracy: 0.7969 - val_loss: 0.8610 - val_accuracy: 0.6560\n","Epoch 59/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6515 - accuracy: 0.7899 - val_loss: 0.8550 - val_accuracy: 0.6519\n","Epoch 60/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6445 - accuracy: 0.7920 - val_loss: 0.8856 - val_accuracy: 0.6426\n","Epoch 61/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6474 - accuracy: 0.7935 - val_loss: 0.8875 - val_accuracy: 0.6529\n","Epoch 62/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6370 - accuracy: 0.8018 - val_loss: 0.8696 - val_accuracy: 0.6550\n","Epoch 63/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6315 - accuracy: 0.8016 - val_loss: 0.8918 - val_accuracy: 0.6539\n","Epoch 64/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6487 - accuracy: 0.7902 - val_loss: 0.8805 - val_accuracy: 0.6560\n","Epoch 65/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6313 - accuracy: 0.8036 - val_loss: 0.8828 - val_accuracy: 0.6488\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6326 - accuracy: 0.8000 - val_loss: 0.8719 - val_accuracy: 0.6508\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6234 - accuracy: 0.8072 - val_loss: 0.8703 - val_accuracy: 0.6539\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6128 - accuracy: 0.8176 - val_loss: 0.8725 - val_accuracy: 0.6519\n","Epoch 69/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6163 - accuracy: 0.8096 - val_loss: 0.8932 - val_accuracy: 0.6560\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6191 - accuracy: 0.8072 - val_loss: 0.8732 - val_accuracy: 0.6467\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6106 - accuracy: 0.8142 - val_loss: 0.8740 - val_accuracy: 0.6570\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6054 - accuracy: 0.8171 - val_loss: 0.8802 - val_accuracy: 0.6539\n","Epoch 73/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6242 - accuracy: 0.8023 - val_loss: 0.8805 - val_accuracy: 0.6467\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6015 - accuracy: 0.8251 - val_loss: 0.8778 - val_accuracy: 0.6467\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6077 - accuracy: 0.8142 - val_loss: 0.8737 - val_accuracy: 0.6415\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5929 - accuracy: 0.8225 - val_loss: 0.8863 - val_accuracy: 0.6539\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5981 - accuracy: 0.8189 - val_loss: 0.8958 - val_accuracy: 0.6498\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6037 - accuracy: 0.8214 - val_loss: 0.8799 - val_accuracy: 0.6488\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5908 - accuracy: 0.8212 - val_loss: 0.8843 - val_accuracy: 0.6436\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5844 - accuracy: 0.8274 - val_loss: 0.8887 - val_accuracy: 0.6488\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5855 - accuracy: 0.8240 - val_loss: 0.8860 - val_accuracy: 0.6457\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5788 - accuracy: 0.8274 - val_loss: 0.8966 - val_accuracy: 0.6529\n","Epoch 83/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5785 - accuracy: 0.8326 - val_loss: 0.9003 - val_accuracy: 0.6519\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5963 - accuracy: 0.8171 - val_loss: 0.9247 - val_accuracy: 0.6415\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5911 - accuracy: 0.8155 - val_loss: 0.9311 - val_accuracy: 0.6550\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6073 - accuracy: 0.8039 - val_loss: 0.9892 - val_accuracy: 0.6229\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5868 - accuracy: 0.8178 - val_loss: 0.9019 - val_accuracy: 0.6457\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5710 - accuracy: 0.8287 - val_loss: 0.8973 - val_accuracy: 0.6477\n","Epoch 89/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5691 - accuracy: 0.8318 - val_loss: 0.9206 - val_accuracy: 0.6560\n","Epoch 90/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5760 - accuracy: 0.8269 - val_loss: 0.8954 - val_accuracy: 0.6436\n","Epoch 91/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5611 - accuracy: 0.8413 - val_loss: 0.9021 - val_accuracy: 0.6415\n","Epoch 92/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5555 - accuracy: 0.8437 - val_loss: 0.9081 - val_accuracy: 0.6457\n","Epoch 93/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5499 - accuracy: 0.8419 - val_loss: 0.9125 - val_accuracy: 0.6405\n","Epoch 94/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5598 - accuracy: 0.8333 - val_loss: 0.9130 - val_accuracy: 0.6539\n","Epoch 95/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5489 - accuracy: 0.8442 - val_loss: 0.8968 - val_accuracy: 0.6415\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5533 - accuracy: 0.8372 - val_loss: 0.9080 - val_accuracy: 0.6477\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5598 - accuracy: 0.8318 - val_loss: 0.9093 - val_accuracy: 0.6519\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5416 - accuracy: 0.8465 - val_loss: 0.9256 - val_accuracy: 0.6529\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5537 - accuracy: 0.8346 - val_loss: 0.9159 - val_accuracy: 0.6457\n","Epoch 100/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5614 - accuracy: 0.8295 - val_loss: 0.9045 - val_accuracy: 0.6498\n","{'loss': [0.8107893466949463, 0.7926806807518005, 0.7864457368850708, 0.7842121720314026, 0.7801719307899475, 0.7815499305725098, 0.7744699120521545, 0.7727645039558411, 0.7667677998542786, 0.7679887413978577, 0.7622681260108948, 0.7594664096832275, 0.7612636685371399, 0.7622536420822144, 0.7601672410964966, 0.7505548000335693, 0.7594221830368042, 0.7439454197883606, 0.7437038421630859, 0.7374836802482605, 0.7303529381752014, 0.7290928363800049, 0.7358041405677795, 0.7318112850189209, 0.7247632145881653, 0.7211248278617859, 0.7212632894515991, 0.7215040922164917, 0.7207097411155701, 0.7174856662750244, 0.720527708530426, 0.728035032749176, 0.7136083245277405, 0.707758903503418, 0.706975519657135, 0.7038220763206482, 0.6986556053161621, 0.7162345051765442, 0.7003844380378723, 0.6990839242935181, 0.6856420040130615, 0.6854455471038818, 0.6792398691177368, 0.6801356077194214, 0.6750673651695251, 0.6953459978103638, 0.6731948852539062, 0.6803744435310364, 0.673856258392334, 0.6621055603027344, 0.6616449952125549, 0.6742103695869446, 0.6703252792358398, 0.6538093686103821, 0.6468976140022278, 0.6614269018173218, 0.6594167351722717, 0.6461628675460815, 0.6514603495597839, 0.6444926857948303, 0.64742112159729, 0.6370439529418945, 0.6314666271209717, 0.6486934423446655, 0.6313453912734985, 0.6326087117195129, 0.6234223246574402, 0.6127973198890686, 0.6163188815116882, 0.6191250681877136, 0.6105663776397705, 0.605417788028717, 0.6242356300354004, 0.60151207447052, 0.6076778173446655, 0.592948317527771, 0.5980980396270752, 0.6036707162857056, 0.5907835364341736, 0.5844343900680542, 0.5855331420898438, 0.5787708163261414, 0.5785178542137146, 0.5963054895401001, 0.591101348400116, 0.6073266863822937, 0.5867639780044556, 0.5709688067436218, 0.5690993666648865, 0.5759981274604797, 0.5610527992248535, 0.5555115342140198, 0.5498738288879395, 0.5598328113555908, 0.5488558411598206, 0.5533384680747986, 0.559807300567627, 0.5415633916854858, 0.5536521673202515, 0.5613767504692078], 'accuracy': [0.7033591866493225, 0.7173126339912415, 0.7211886048316956, 0.7289405465126038, 0.7286821603775024, 0.7198966145515442, 0.7255814075469971, 0.7307493686676025, 0.7408268451690674, 0.7312661409378052, 0.7385013103485107, 0.7351421117782593, 0.7410852909088135, 0.7328165173530579, 0.7307493686676025, 0.7400516867637634, 0.7325581312179565, 0.7496123909950256, 0.7472867965698242, 0.7560723423957825, 0.7534883618354797, 0.7511627674102783, 0.750129222869873, 0.7467700242996216, 0.7552971839904785, 0.7573643326759338, 0.760465145111084, 0.7563307285308838, 0.7563307285308838, 0.7594315409660339, 0.7555555701255798, 0.7488372325897217, 0.7620155215263367, 0.7607235312461853, 0.7689922451972961, 0.7635658979415894, 0.7689922451972961, 0.7547803521156311, 0.7648578882217407, 0.7674418687820435, 0.7741602063179016, 0.7751938104629517, 0.7875968813896179, 0.7819121479988098, 0.789664089679718, 0.7679586410522461, 0.7780361771583557, 0.7777777910232544, 0.7788113951683044, 0.7925064563751221, 0.7873384952545166, 0.7705426216125488, 0.7731266021728516, 0.7974160313606262, 0.7956072092056274, 0.7813953757286072, 0.7829457521438599, 0.7968991994857788, 0.7899224758148193, 0.7919896841049194, 0.7935400605201721, 0.801808774471283, 0.8015503883361816, 0.7901808619499207, 0.8036175966262817, 0.800000011920929, 0.8072351217269897, 0.8175710439682007, 0.8095607161521912, 0.8072351217269897, 0.814211905002594, 0.817054271697998, 0.8023256063461304, 0.8250645995140076, 0.814211905002594, 0.8224806189537048, 0.818863034248352, 0.8214470148086548, 0.8211886286735535, 0.827390193939209, 0.8240309953689575, 0.827390193939209, 0.8325581550598145, 0.817054271697998, 0.8155038952827454, 0.8038759827613831, 0.817829430103302, 0.8286821842193604, 0.8317829370498657, 0.8268733620643616, 0.8413436412811279, 0.8436692357063293, 0.8418604731559753, 0.8333333134651184, 0.8441860675811768, 0.8372092843055725, 0.8317829370498657, 0.8465116024017334, 0.8346253037452698, 0.8294573426246643], 'val_loss': [0.9439708590507507, 0.9371764063835144, 0.9323405027389526, 0.9277552962303162, 0.9245736598968506, 0.9211695790290833, 0.9176557660102844, 0.9143951535224915, 0.9135299324989319, 0.9097710847854614, 0.9077968001365662, 0.9058226943016052, 0.9128100872039795, 0.910059928894043, 0.9226679801940918, 0.9593237042427063, 0.9006483554840088, 0.9184961318969727, 0.9464482069015503, 0.9162043929100037, 0.9176493883132935, 0.8933846354484558, 0.9149100184440613, 0.8450480699539185, 0.8523359894752502, 0.8738957643508911, 0.8439289927482605, 0.8482570052146912, 0.846141517162323, 0.8852158784866333, 0.8555902242660522, 0.8468728065490723, 0.8658630847930908, 0.8646383881568909, 0.8637278079986572, 0.8471567630767822, 0.8606258630752563, 0.8564274311065674, 0.8498687744140625, 0.8470762372016907, 0.9076701998710632, 0.8634434342384338, 0.8551850318908691, 0.8565065860748291, 0.8602424263954163, 0.8886075019836426, 0.8892802596092224, 0.8608214259147644, 0.8573445677757263, 0.8775710463523865, 0.857939600944519, 0.8526732921600342, 0.8590878844261169, 0.8556498885154724, 0.8762167096138, 0.8615456223487854, 0.8580136299133301, 0.8610075116157532, 0.8550312519073486, 0.8855612874031067, 0.8875005841255188, 0.869557797908783, 0.891837477684021, 0.8804954290390015, 0.8827616572380066, 0.8718584179878235, 0.8702884316444397, 0.8724594116210938, 0.8932496309280396, 0.8732361793518066, 0.8740231394767761, 0.8801735639572144, 0.880470871925354, 0.877774715423584, 0.8737413883209229, 0.8862626552581787, 0.8957616090774536, 0.879888653755188, 0.8842836022377014, 0.8886700868606567, 0.8859723210334778, 0.896638810634613, 0.9002699255943298, 0.9246590733528137, 0.9310945868492126, 0.9891524910926819, 0.9019384384155273, 0.897270917892456, 0.9205867052078247, 0.8953559398651123, 0.9020764231681824, 0.9081225395202637, 0.9125141501426697, 0.913019597530365, 0.8968012928962708, 0.9080135822296143, 0.9093438982963562, 0.9256337881088257, 0.9158796072006226, 0.9045332074165344], 'val_accuracy': [0.48553720116615295, 0.4886363744735718, 0.5144628286361694, 0.5609503984451294, 0.5743801593780518, 0.5805785059928894, 0.5878099203109741, 0.5878099203109741, 0.5681818127632141, 0.5754132270812988, 0.5764462947845459, 0.5795454382896423, 0.5681818127632141, 0.5754132270812988, 0.567148745059967, 0.55888432264328, 0.5960744023323059, 0.5909090638160706, 0.5743801593780518, 0.6002066135406494, 0.60537189245224, 0.6219007968902588, 0.6219007968902588, 0.6570248007774353, 0.6435950398445129, 0.6353305578231812, 0.6673553586006165, 0.6621900796890259, 0.6611570119857788, 0.6311983466148376, 0.6580578684806824, 0.663223147392273, 0.6456611752510071, 0.6487603187561035, 0.6487603187561035, 0.66425621509552, 0.6652892827987671, 0.6559917330741882, 0.6673553586006165, 0.6663222908973694, 0.6311983466148376, 0.6518595218658447, 0.6652892827987671, 0.6601239442825317, 0.6559917330741882, 0.6311983466148376, 0.6508264541625977, 0.6539255976676941, 0.6466942429542542, 0.6456611752510071, 0.663223147392273, 0.66425621509552, 0.6590909361839294, 0.6539255976676941, 0.6466942429542542, 0.6570248007774353, 0.6549586653709412, 0.6559917330741882, 0.6518595218658447, 0.6425619721412659, 0.6528925895690918, 0.6549586653709412, 0.6539255976676941, 0.6559917330741882, 0.6487603187561035, 0.6508264541625977, 0.6539255976676941, 0.6518595218658447, 0.6559917330741882, 0.6466942429542542, 0.6570248007774353, 0.6539255976676941, 0.6466942429542542, 0.6466942429542542, 0.6415289044380188, 0.6539255976676941, 0.6497933864593506, 0.6487603187561035, 0.6435950398445129, 0.6487603187561035, 0.6456611752510071, 0.6528925895690918, 0.6518595218658447, 0.6415289044380188, 0.6549586653709412, 0.6229338645935059, 0.6456611752510071, 0.6477272510528564, 0.6559917330741882, 0.6435950398445129, 0.6415289044380188, 0.6456611752510071, 0.6404958963394165, 0.6539255976676941, 0.6415289044380188, 0.6477272510528564, 0.6518595218658447, 0.6528925895690918, 0.6456611752510071, 0.6497933864593506]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.6278 - accuracy: 0.7972"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 51ms/step - loss: 0.6285 - accuracy: 0.7958 - val_loss: 0.8943 - val_accuracy: 0.4903\n","Epoch 2/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6074 - accuracy: 0.8031 - val_loss: 0.8895 - val_accuracy: 0.4957\n","Epoch 3/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5831 - accuracy: 0.8192 - val_loss: 0.8808 - val_accuracy: 0.5129\n","Epoch 4/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5844 - accuracy: 0.8233 - val_loss: 0.8759 - val_accuracy: 0.5366\n","Epoch 5/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5785 - accuracy: 0.8209 - val_loss: 0.8731 - val_accuracy: 0.5485\n","Epoch 6/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5764 - accuracy: 0.8314 - val_loss: 0.8694 - val_accuracy: 0.5593\n","Epoch 7/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5677 - accuracy: 0.8244 - val_loss: 0.8681 - val_accuracy: 0.5722\n","Epoch 8/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5655 - accuracy: 0.8322 - val_loss: 0.8679 - val_accuracy: 0.5733\n","Epoch 9/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5608 - accuracy: 0.8303 - val_loss: 0.8673 - val_accuracy: 0.5560\n","Epoch 10/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5585 - accuracy: 0.8338 - val_loss: 0.8662 - val_accuracy: 0.5808\n","Epoch 11/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5667 - accuracy: 0.8227 - val_loss: 0.8756 - val_accuracy: 0.5754\n","Epoch 12/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5708 - accuracy: 0.8211 - val_loss: 0.8745 - val_accuracy: 0.5819\n","Epoch 13/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.5523 - accuracy: 0.8400 - val_loss: 0.8918 - val_accuracy: 0.5830\n","Epoch 14/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5590 - accuracy: 0.8343 - val_loss: 0.9155 - val_accuracy: 0.5722\n","Epoch 15/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5485 - accuracy: 0.8341 - val_loss: 0.9557 - val_accuracy: 0.5754\n","Epoch 16/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5367 - accuracy: 0.8475 - val_loss: 0.9766 - val_accuracy: 0.5797\n","Epoch 17/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5418 - accuracy: 0.8402 - val_loss: 1.0106 - val_accuracy: 0.5894\n","Epoch 18/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5364 - accuracy: 0.8475 - val_loss: 0.9927 - val_accuracy: 0.5884\n","Epoch 19/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.5324 - accuracy: 0.8451 - val_loss: 1.0076 - val_accuracy: 0.5927\n","Epoch 20/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5300 - accuracy: 0.8489 - val_loss: 1.0826 - val_accuracy: 0.5884\n","Epoch 21/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5356 - accuracy: 0.8446 - val_loss: 0.8934 - val_accuracy: 0.6379\n","Epoch 22/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5253 - accuracy: 0.8505 - val_loss: 0.9563 - val_accuracy: 0.6379\n","Epoch 23/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5279 - accuracy: 0.8451 - val_loss: 0.8192 - val_accuracy: 0.6595\n","Epoch 24/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5256 - accuracy: 0.8494 - val_loss: 0.9471 - val_accuracy: 0.6444\n","Epoch 25/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5403 - accuracy: 0.8432 - val_loss: 0.7966 - val_accuracy: 0.6897\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5272 - accuracy: 0.8529 - val_loss: 0.8786 - val_accuracy: 0.6778\n","Epoch 27/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5296 - accuracy: 0.8408 - val_loss: 0.8016 - val_accuracy: 0.7112\n","Epoch 28/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5141 - accuracy: 0.8570 - val_loss: 0.7949 - val_accuracy: 0.7123\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5288 - accuracy: 0.8419 - val_loss: 0.8280 - val_accuracy: 0.7026\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5107 - accuracy: 0.8575 - val_loss: 0.8321 - val_accuracy: 0.7004\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5026 - accuracy: 0.8615 - val_loss: 0.8140 - val_accuracy: 0.7004\n","Epoch 32/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4893 - accuracy: 0.8702 - val_loss: 0.8171 - val_accuracy: 0.6950\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5043 - accuracy: 0.8607 - val_loss: 0.8375 - val_accuracy: 0.7037\n","Epoch 34/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5202 - accuracy: 0.8556 - val_loss: 0.8600 - val_accuracy: 0.6983\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4903 - accuracy: 0.8723 - val_loss: 0.8109 - val_accuracy: 0.7123\n","Epoch 36/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4872 - accuracy: 0.8677 - val_loss: 0.8055 - val_accuracy: 0.7144\n","Epoch 37/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4918 - accuracy: 0.8702 - val_loss: 0.8543 - val_accuracy: 0.6735\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5011 - accuracy: 0.8545 - val_loss: 0.8491 - val_accuracy: 0.7026\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4834 - accuracy: 0.8758 - val_loss: 0.8194 - val_accuracy: 0.7134\n","Epoch 40/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4760 - accuracy: 0.8785 - val_loss: 0.8249 - val_accuracy: 0.7177\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4696 - accuracy: 0.8788 - val_loss: 0.8386 - val_accuracy: 0.7080\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4773 - accuracy: 0.8782 - val_loss: 0.8473 - val_accuracy: 0.7112\n","Epoch 43/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4955 - accuracy: 0.8618 - val_loss: 0.8327 - val_accuracy: 0.7198\n","Epoch 44/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4663 - accuracy: 0.8774 - val_loss: 0.8873 - val_accuracy: 0.6994\n","Epoch 45/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5025 - accuracy: 0.8572 - val_loss: 0.8800 - val_accuracy: 0.6789\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4681 - accuracy: 0.8774 - val_loss: 0.8301 - val_accuracy: 0.7112\n","Epoch 47/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4805 - accuracy: 0.8720 - val_loss: 0.9232 - val_accuracy: 0.6940\n","Epoch 48/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4741 - accuracy: 0.8715 - val_loss: 0.8467 - val_accuracy: 0.7188\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4612 - accuracy: 0.8869 - val_loss: 0.8394 - val_accuracy: 0.7101\n","Epoch 50/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4604 - accuracy: 0.8850 - val_loss: 0.8532 - val_accuracy: 0.7101\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4700 - accuracy: 0.8745 - val_loss: 0.8395 - val_accuracy: 0.7144\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4573 - accuracy: 0.8863 - val_loss: 0.8559 - val_accuracy: 0.6994\n","Epoch 53/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4430 - accuracy: 0.8909 - val_loss: 0.8522 - val_accuracy: 0.7220\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4476 - accuracy: 0.8879 - val_loss: 0.8489 - val_accuracy: 0.7177\n","Epoch 55/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4467 - accuracy: 0.8879 - val_loss: 0.8534 - val_accuracy: 0.7166\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4493 - accuracy: 0.8871 - val_loss: 0.8513 - val_accuracy: 0.7198\n","Epoch 57/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4398 - accuracy: 0.8976 - val_loss: 0.8696 - val_accuracy: 0.7123\n","Epoch 58/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4322 - accuracy: 0.8939 - val_loss: 0.9011 - val_accuracy: 0.6886\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4595 - accuracy: 0.8831 - val_loss: 0.9491 - val_accuracy: 0.6918\n","Epoch 60/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4516 - accuracy: 0.8831 - val_loss: 0.9517 - val_accuracy: 0.6692\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4497 - accuracy: 0.8890 - val_loss: 0.8796 - val_accuracy: 0.7188\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4487 - accuracy: 0.8807 - val_loss: 0.8645 - val_accuracy: 0.7188\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4425 - accuracy: 0.8912 - val_loss: 0.8766 - val_accuracy: 0.7123\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4592 - accuracy: 0.8825 - val_loss: 0.8860 - val_accuracy: 0.7047\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4422 - accuracy: 0.8852 - val_loss: 0.8689 - val_accuracy: 0.7026\n","Epoch 66/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4313 - accuracy: 0.8936 - val_loss: 0.8683 - val_accuracy: 0.7231\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4312 - accuracy: 0.8939 - val_loss: 0.8678 - val_accuracy: 0.7037\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4111 - accuracy: 0.9079 - val_loss: 0.8693 - val_accuracy: 0.7155\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4196 - accuracy: 0.8976 - val_loss: 0.8952 - val_accuracy: 0.7231\n","Epoch 70/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4164 - accuracy: 0.8982 - val_loss: 0.9138 - val_accuracy: 0.6907\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4383 - accuracy: 0.8904 - val_loss: 0.8908 - val_accuracy: 0.7037\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4248 - accuracy: 0.8976 - val_loss: 0.8798 - val_accuracy: 0.7177\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4032 - accuracy: 0.9092 - val_loss: 0.8941 - val_accuracy: 0.7123\n","Epoch 74/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4039 - accuracy: 0.9170 - val_loss: 0.8915 - val_accuracy: 0.7134\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4057 - accuracy: 0.9089 - val_loss: 0.9041 - val_accuracy: 0.6918\n","Epoch 76/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4115 - accuracy: 0.9052 - val_loss: 0.8947 - val_accuracy: 0.7123\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4082 - accuracy: 0.9071 - val_loss: 0.9076 - val_accuracy: 0.7155\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3939 - accuracy: 0.9168 - val_loss: 0.9421 - val_accuracy: 0.7188\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4238 - accuracy: 0.8995 - val_loss: 0.9487 - val_accuracy: 0.6821\n","Epoch 80/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4063 - accuracy: 0.9081 - val_loss: 0.9335 - val_accuracy: 0.6897\n","Epoch 81/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3912 - accuracy: 0.9149 - val_loss: 0.9110 - val_accuracy: 0.7155\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3832 - accuracy: 0.9205 - val_loss: 0.9435 - val_accuracy: 0.6810\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3897 - accuracy: 0.9108 - val_loss: 0.9134 - val_accuracy: 0.7188\n","Epoch 84/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3894 - accuracy: 0.9168 - val_loss: 0.9229 - val_accuracy: 0.7112\n","Epoch 85/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3826 - accuracy: 0.9165 - val_loss: 0.9278 - val_accuracy: 0.6972\n","Epoch 86/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3865 - accuracy: 0.9143 - val_loss: 0.9521 - val_accuracy: 0.6886\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3816 - accuracy: 0.9176 - val_loss: 0.9478 - val_accuracy: 0.7112\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3842 - accuracy: 0.9130 - val_loss: 0.9574 - val_accuracy: 0.6864\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3835 - accuracy: 0.9181 - val_loss: 0.9411 - val_accuracy: 0.7188\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3839 - accuracy: 0.9124 - val_loss: 0.9358 - val_accuracy: 0.7101\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3754 - accuracy: 0.9221 - val_loss: 0.9366 - val_accuracy: 0.7166\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3661 - accuracy: 0.9278 - val_loss: 0.9811 - val_accuracy: 0.6961\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3746 - accuracy: 0.9195 - val_loss: 0.9980 - val_accuracy: 0.7004\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3785 - accuracy: 0.9162 - val_loss: 0.9563 - val_accuracy: 0.7026\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3870 - accuracy: 0.9111 - val_loss: 0.9569 - val_accuracy: 0.7123\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3725 - accuracy: 0.9230 - val_loss: 0.9669 - val_accuracy: 0.7004\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3631 - accuracy: 0.9300 - val_loss: 0.9785 - val_accuracy: 0.7134\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3685 - accuracy: 0.9240 - val_loss: 0.9787 - val_accuracy: 0.6843\n","Epoch 99/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3691 - accuracy: 0.9259 - val_loss: 0.9727 - val_accuracy: 0.6994\n","Epoch 100/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3570 - accuracy: 0.9278 - val_loss: 0.9719 - val_accuracy: 0.7091\n","{'loss': [0.6285479068756104, 0.6074321866035461, 0.5830646753311157, 0.5844085216522217, 0.5785197019577026, 0.576361894607544, 0.5677281618118286, 0.5655148029327393, 0.5608153939247131, 0.5585008859634399, 0.5667386651039124, 0.570763349533081, 0.5522969961166382, 0.5589840412139893, 0.5485244393348694, 0.5367494821548462, 0.5418155193328857, 0.5363649725914001, 0.5324202179908752, 0.5299974083900452, 0.5356122851371765, 0.525259792804718, 0.5278680324554443, 0.5255682468414307, 0.5403190851211548, 0.5271944403648376, 0.5295939445495605, 0.5140501260757446, 0.528768002986908, 0.5107141137123108, 0.5025741457939148, 0.489251971244812, 0.5042675733566284, 0.520162045955658, 0.4902632236480713, 0.48716479539871216, 0.4917899966239929, 0.5011142492294312, 0.4833780825138092, 0.47599005699157715, 0.46962878108024597, 0.4772864580154419, 0.49554193019866943, 0.4663114547729492, 0.5025339722633362, 0.4680664539337158, 0.480493426322937, 0.47414112091064453, 0.4611859917640686, 0.46035048365592957, 0.4699578583240509, 0.4573216736316681, 0.44304731488227844, 0.4475743770599365, 0.44673341512680054, 0.4493197500705719, 0.43979981541633606, 0.4322095811367035, 0.4594605267047882, 0.45157572627067566, 0.44968941807746887, 0.44868749380111694, 0.4425029456615448, 0.4592301547527313, 0.4422121047973633, 0.4312986731529236, 0.4311501979827881, 0.41113823652267456, 0.4195680618286133, 0.41639479994773865, 0.4383385479450226, 0.4248082637786865, 0.4031624495983124, 0.40391504764556885, 0.40565669536590576, 0.41154980659484863, 0.40823113918304443, 0.39393699169158936, 0.4238143563270569, 0.4062892198562622, 0.3911922574043274, 0.3832382559776306, 0.3896508812904358, 0.38941505551338196, 0.38260048627853394, 0.386485755443573, 0.38157591223716736, 0.3841722309589386, 0.38348016142845154, 0.3838815987110138, 0.37535643577575684, 0.3660658895969391, 0.3745808005332947, 0.37853094935417175, 0.38701117038726807, 0.3724859356880188, 0.36314061284065247, 0.3684588074684143, 0.36907145380973816, 0.3570425510406494], 'accuracy': [0.7957974076271057, 0.803071141242981, 0.8192349076271057, 0.8232758641242981, 0.8208512663841248, 0.8313577771186829, 0.8243534564971924, 0.8321659564971924, 0.8302801847457886, 0.8337823152542114, 0.8227370977401733, 0.8211206793785095, 0.8399784564971924, 0.834321141242981, 0.8340517282485962, 0.8475215435028076, 0.8402478694915771, 0.8475215435028076, 0.845097005367279, 0.8488685488700867, 0.8445581793785095, 0.8504849076271057, 0.845097005367279, 0.8494073152542114, 0.8432112336158752, 0.852909505367279, 0.8407866358757019, 0.8569504022598267, 0.8418642282485962, 0.8574892282485962, 0.8615301847457886, 0.8701508641242981, 0.860722005367279, 0.8556034564971924, 0.8723060488700867, 0.8677262663841248, 0.8701508641242981, 0.8545258641242981, 0.8758081793785095, 0.8785021305084229, 0.8787715435028076, 0.8782327771186829, 0.8617995977401733, 0.8774245977401733, 0.8572198152542114, 0.8774245977401733, 0.8720366358757019, 0.8714978694915771, 0.8868534564971924, 0.8849676847457886, 0.8744612336158752, 0.8863146305084229, 0.8908944129943848, 0.8879310488700867, 0.8879310488700867, 0.8871228694915771, 0.8976293206214905, 0.8938577771186829, 0.8830819129943848, 0.8830819129943848, 0.889008641242981, 0.8806573152542114, 0.8911637663841248, 0.8825430870056152, 0.8852370977401733, 0.8935883641242981, 0.8938577771186829, 0.907866358757019, 0.8976293206214905, 0.8981680870056152, 0.8903555870056152, 0.8976293206214905, 0.9092133641242981, 0.9170258641242981, 0.9089439511299133, 0.9051724076271057, 0.9070581793785095, 0.9167564511299133, 0.8995150923728943, 0.9081357717514038, 0.9148706793785095, 0.920527994632721, 0.9108297228813171, 0.9167564511299133, 0.9164870977401733, 0.9143319129943848, 0.9175646305084229, 0.9129849076271057, 0.9181034564971924, 0.912446141242981, 0.9221444129943848, 0.9278017282485962, 0.9194504022598267, 0.9162176847457886, 0.9110991358757019, 0.9229525923728943, 0.9299569129943848, 0.9240301847457886, 0.9259159564971924, 0.9278017282485962], 'val_loss': [0.8943328857421875, 0.8894506692886353, 0.8807740211486816, 0.8759002685546875, 0.8731380105018616, 0.869446337223053, 0.8681445717811584, 0.8679299354553223, 0.8672972917556763, 0.8662413358688354, 0.8756324648857117, 0.8744798898696899, 0.891756534576416, 0.9155433177947998, 0.9556860327720642, 0.9765967130661011, 1.010586142539978, 0.992706298828125, 1.007561206817627, 1.0826029777526855, 0.8934487104415894, 0.9563114643096924, 0.8191643357276917, 0.947051465511322, 0.7966171503067017, 0.8785680532455444, 0.8016304969787598, 0.7948785424232483, 0.8280169367790222, 0.8321351408958435, 0.8139984011650085, 0.8170939087867737, 0.8374606966972351, 0.8599730134010315, 0.8109133243560791, 0.8054880499839783, 0.8543398380279541, 0.8490505814552307, 0.819375216960907, 0.8248865604400635, 0.8385686278343201, 0.8473058938980103, 0.8327323794364929, 0.8872613310813904, 0.8800296783447266, 0.8300873041152954, 0.923169732093811, 0.8466538190841675, 0.8393517732620239, 0.8532236218452454, 0.8395174145698547, 0.8558692336082458, 0.8522470593452454, 0.8488947749137878, 0.8534254431724548, 0.8513275384902954, 0.8695722818374634, 0.9011183977127075, 0.949096143245697, 0.9517252445220947, 0.8795833587646484, 0.8645275235176086, 0.8765610456466675, 0.8859550356864929, 0.8688685297966003, 0.8683450222015381, 0.8678184151649475, 0.8693135976791382, 0.8952381610870361, 0.9137982726097107, 0.8907586336135864, 0.8797745704650879, 0.8941482305526733, 0.8914901614189148, 0.9041076898574829, 0.8946524262428284, 0.9076108336448669, 0.9420947432518005, 0.9486585855484009, 0.933546245098114, 0.9109794497489929, 0.9435350894927979, 0.9134182333946228, 0.9228897094726562, 0.9278397560119629, 0.9521015286445618, 0.947830080986023, 0.9574443697929382, 0.9411416053771973, 0.9357664585113525, 0.9366454482078552, 0.9811200499534607, 0.9980391263961792, 0.9563066959381104, 0.9569301009178162, 0.9668523073196411, 0.9784685969352722, 0.9787417054176331, 0.9726936221122742, 0.9719226360321045], 'val_accuracy': [0.4903017282485962, 0.49568966031074524, 0.5129310488700867, 0.5366379022598267, 0.548491358757019, 0.5592672228813171, 0.5721982717514038, 0.5732758641242981, 0.556034505367279, 0.5808189511299133, 0.5754310488700867, 0.5818965435028076, 0.5829741358757019, 0.5721982717514038, 0.5754310488700867, 0.579741358757019, 0.5894396305084229, 0.5883620977401733, 0.5926724076271057, 0.5883620977401733, 0.6379310488700867, 0.6379310488700867, 0.6594827771186829, 0.6443965435028076, 0.6896551847457886, 0.6778017282485962, 0.7112069129943848, 0.712284505367279, 0.7025862336158752, 0.7004310488700867, 0.7004310488700867, 0.6950430870056152, 0.7036637663841248, 0.6982758641242981, 0.712284505367279, 0.7144396305084229, 0.673491358757019, 0.7025862336158752, 0.7133620977401733, 0.7176724076271057, 0.7079741358757019, 0.7112069129943848, 0.7198275923728943, 0.6993534564971924, 0.6788793206214905, 0.7112069129943848, 0.693965494632721, 0.71875, 0.7101293206214905, 0.7101293206214905, 0.7144396305084229, 0.6993534564971924, 0.7219827771186829, 0.7176724076271057, 0.7165948152542114, 0.7198275923728943, 0.712284505367279, 0.6885775923728943, 0.6918103694915771, 0.6691810488700867, 0.71875, 0.71875, 0.712284505367279, 0.704741358757019, 0.7025862336158752, 0.7230603694915771, 0.7036637663841248, 0.7155172228813171, 0.7230603694915771, 0.6907327771186829, 0.7036637663841248, 0.7176724076271057, 0.712284505367279, 0.7133620977401733, 0.6918103694915771, 0.712284505367279, 0.7155172228813171, 0.71875, 0.6821120977401733, 0.6896551847457886, 0.7155172228813171, 0.681034505367279, 0.71875, 0.7112069129943848, 0.6971982717514038, 0.6885775923728943, 0.7112069129943848, 0.6864224076271057, 0.71875, 0.7101293206214905, 0.7165948152542114, 0.6961206793785095, 0.7004310488700867, 0.7025862336158752, 0.712284505367279, 0.7004310488700867, 0.7133620977401733, 0.6842672228813171, 0.6993534564971924, 0.7090517282485962]}\n","38/38 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.6304 - accuracy: 0.7957"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 9s 57ms/step - loss: 0.6261 - accuracy: 0.7974 - val_loss: 0.8905 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5944 - accuracy: 0.8251 - val_loss: 0.8830 - val_accuracy: 0.5023\n","Epoch 3/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5926 - accuracy: 0.8195 - val_loss: 0.8739 - val_accuracy: 0.5339\n","Epoch 4/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5809 - accuracy: 0.8288 - val_loss: 0.8696 - val_accuracy: 0.5577\n","Epoch 5/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5710 - accuracy: 0.8390 - val_loss: 0.8638 - val_accuracy: 0.5928\n","Epoch 6/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5820 - accuracy: 0.8291 - val_loss: 0.8610 - val_accuracy: 0.5848\n","Epoch 7/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5870 - accuracy: 0.8257 - val_loss: 0.8585 - val_accuracy: 0.5803\n","Epoch 8/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5651 - accuracy: 0.8325 - val_loss: 0.8561 - val_accuracy: 0.5882\n","Epoch 9/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5632 - accuracy: 0.8364 - val_loss: 0.8541 - val_accuracy: 0.5871\n","Epoch 10/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5595 - accuracy: 0.8415 - val_loss: 0.8539 - val_accuracy: 0.5882\n","Epoch 11/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5591 - accuracy: 0.8447 - val_loss: 0.8708 - val_accuracy: 0.5735\n","Epoch 12/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5615 - accuracy: 0.8297 - val_loss: 0.8754 - val_accuracy: 0.5803\n","Epoch 13/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5588 - accuracy: 0.8390 - val_loss: 0.9042 - val_accuracy: 0.5769\n","Epoch 14/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5480 - accuracy: 0.8475 - val_loss: 0.8831 - val_accuracy: 0.6007\n","Epoch 15/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5499 - accuracy: 0.8373 - val_loss: 0.9033 - val_accuracy: 0.5950\n","Epoch 16/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5458 - accuracy: 0.8463 - val_loss: 0.9962 - val_accuracy: 0.5690\n","Epoch 17/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5364 - accuracy: 0.8540 - val_loss: 1.0207 - val_accuracy: 0.5758\n","Epoch 18/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5457 - accuracy: 0.8455 - val_loss: 1.0807 - val_accuracy: 0.5679\n","Epoch 19/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.5522 - accuracy: 0.8381 - val_loss: 0.9250 - val_accuracy: 0.6063\n","Epoch 20/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.5352 - accuracy: 0.8478 - val_loss: 0.9636 - val_accuracy: 0.6097\n","Epoch 21/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.5268 - accuracy: 0.8565 - val_loss: 0.8628 - val_accuracy: 0.6437\n","Epoch 22/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5400 - accuracy: 0.8461 - val_loss: 0.9548 - val_accuracy: 0.6256\n","Epoch 23/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5239 - accuracy: 0.8563 - val_loss: 0.8958 - val_accuracy: 0.6391\n","Epoch 24/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5207 - accuracy: 0.8591 - val_loss: 0.8510 - val_accuracy: 0.6674\n","Epoch 25/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5249 - accuracy: 0.8577 - val_loss: 0.8671 - val_accuracy: 0.6686\n","Epoch 26/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5155 - accuracy: 0.8605 - val_loss: 0.8569 - val_accuracy: 0.6787\n","Epoch 27/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5053 - accuracy: 0.8704 - val_loss: 0.7890 - val_accuracy: 0.7048\n","Epoch 28/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5063 - accuracy: 0.8613 - val_loss: 0.7812 - val_accuracy: 0.7104\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5028 - accuracy: 0.8645 - val_loss: 0.7770 - val_accuracy: 0.6991\n","Epoch 30/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5003 - accuracy: 0.8729 - val_loss: 0.7834 - val_accuracy: 0.7138\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5040 - accuracy: 0.8681 - val_loss: 0.7585 - val_accuracy: 0.7093\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5020 - accuracy: 0.8630 - val_loss: 0.7809 - val_accuracy: 0.7025\n","Epoch 33/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5043 - accuracy: 0.8630 - val_loss: 0.7862 - val_accuracy: 0.7195\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5168 - accuracy: 0.8594 - val_loss: 0.7875 - val_accuracy: 0.6991\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5036 - accuracy: 0.8690 - val_loss: 0.7751 - val_accuracy: 0.7070\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4873 - accuracy: 0.8744 - val_loss: 0.7755 - val_accuracy: 0.7195\n","Epoch 37/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4842 - accuracy: 0.8800 - val_loss: 0.7782 - val_accuracy: 0.7217\n","Epoch 38/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4835 - accuracy: 0.8778 - val_loss: 0.8036 - val_accuracy: 0.7115\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4898 - accuracy: 0.8735 - val_loss: 0.7895 - val_accuracy: 0.7172\n","Epoch 40/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4912 - accuracy: 0.8752 - val_loss: 0.7905 - val_accuracy: 0.7059\n","Epoch 41/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5039 - accuracy: 0.8613 - val_loss: 0.8066 - val_accuracy: 0.7149\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4807 - accuracy: 0.8752 - val_loss: 0.7980 - val_accuracy: 0.7070\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4780 - accuracy: 0.8831 - val_loss: 0.7836 - val_accuracy: 0.7093\n","Epoch 44/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4886 - accuracy: 0.8679 - val_loss: 0.8273 - val_accuracy: 0.6946\n","Epoch 45/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4744 - accuracy: 0.8758 - val_loss: 0.8082 - val_accuracy: 0.7048\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4632 - accuracy: 0.8896 - val_loss: 0.8038 - val_accuracy: 0.7093\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4679 - accuracy: 0.8891 - val_loss: 0.7947 - val_accuracy: 0.7104\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4545 - accuracy: 0.8942 - val_loss: 0.8087 - val_accuracy: 0.7115\n","Epoch 49/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4845 - accuracy: 0.8698 - val_loss: 0.8123 - val_accuracy: 0.7014\n","Epoch 50/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4611 - accuracy: 0.8865 - val_loss: 0.8023 - val_accuracy: 0.7115\n","Epoch 51/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4455 - accuracy: 0.8978 - val_loss: 0.8150 - val_accuracy: 0.7127\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4455 - accuracy: 0.8967 - val_loss: 0.8125 - val_accuracy: 0.7104\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4481 - accuracy: 0.8939 - val_loss: 0.8172 - val_accuracy: 0.6991\n","Epoch 54/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4457 - accuracy: 0.8908 - val_loss: 0.8415 - val_accuracy: 0.7025\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4809 - accuracy: 0.8727 - val_loss: 0.8998 - val_accuracy: 0.6923\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4599 - accuracy: 0.8786 - val_loss: 0.8066 - val_accuracy: 0.7070\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4476 - accuracy: 0.8882 - val_loss: 0.8253 - val_accuracy: 0.7059\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4433 - accuracy: 0.8964 - val_loss: 0.8733 - val_accuracy: 0.7059\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4441 - accuracy: 0.8933 - val_loss: 0.8184 - val_accuracy: 0.7002\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4436 - accuracy: 0.8885 - val_loss: 1.0063 - val_accuracy: 0.6584\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4529 - accuracy: 0.8820 - val_loss: 0.8389 - val_accuracy: 0.7093\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4238 - accuracy: 0.9058 - val_loss: 0.8399 - val_accuracy: 0.7059\n","Epoch 63/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4219 - accuracy: 0.9086 - val_loss: 0.8285 - val_accuracy: 0.7070\n","Epoch 64/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4435 - accuracy: 0.8922 - val_loss: 0.8935 - val_accuracy: 0.7081\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4548 - accuracy: 0.8877 - val_loss: 0.8406 - val_accuracy: 0.7115\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4250 - accuracy: 0.9052 - val_loss: 0.8481 - val_accuracy: 0.7115\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4326 - accuracy: 0.8998 - val_loss: 0.8494 - val_accuracy: 0.7127\n","Epoch 68/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4210 - accuracy: 0.9055 - val_loss: 0.8514 - val_accuracy: 0.7183\n","Epoch 69/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4184 - accuracy: 0.9018 - val_loss: 0.8708 - val_accuracy: 0.6968\n","Epoch 70/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4071 - accuracy: 0.9162 - val_loss: 0.8470 - val_accuracy: 0.7048\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4127 - accuracy: 0.9117 - val_loss: 0.8366 - val_accuracy: 0.7093\n","Epoch 72/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4017 - accuracy: 0.9157 - val_loss: 0.8542 - val_accuracy: 0.7048\n","Epoch 73/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4036 - accuracy: 0.9128 - val_loss: 0.8684 - val_accuracy: 0.6991\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4012 - accuracy: 0.9177 - val_loss: 0.9048 - val_accuracy: 0.7138\n","Epoch 75/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4092 - accuracy: 0.9086 - val_loss: 0.8834 - val_accuracy: 0.6980\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4005 - accuracy: 0.9162 - val_loss: 0.8895 - val_accuracy: 0.7115\n","Epoch 77/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3931 - accuracy: 0.9191 - val_loss: 0.8744 - val_accuracy: 0.7104\n","Epoch 78/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3933 - accuracy: 0.9202 - val_loss: 0.8701 - val_accuracy: 0.7070\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3937 - accuracy: 0.9182 - val_loss: 0.8813 - val_accuracy: 0.6957\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3966 - accuracy: 0.9137 - val_loss: 0.8827 - val_accuracy: 0.7093\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3875 - accuracy: 0.9196 - val_loss: 0.8774 - val_accuracy: 0.7048\n","Epoch 82/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3872 - accuracy: 0.9177 - val_loss: 0.8983 - val_accuracy: 0.7093\n","Epoch 83/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3892 - accuracy: 0.9168 - val_loss: 0.8773 - val_accuracy: 0.7093\n","Epoch 84/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4028 - accuracy: 0.9117 - val_loss: 0.9152 - val_accuracy: 0.7048\n","Epoch 85/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3802 - accuracy: 0.9242 - val_loss: 0.8844 - val_accuracy: 0.7025\n","Epoch 86/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3851 - accuracy: 0.9225 - val_loss: 0.9004 - val_accuracy: 0.7048\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3693 - accuracy: 0.9327 - val_loss: 0.8791 - val_accuracy: 0.7161\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3708 - accuracy: 0.9284 - val_loss: 0.9395 - val_accuracy: 0.6867\n","Epoch 89/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3787 - accuracy: 0.9174 - val_loss: 0.9503 - val_accuracy: 0.6844\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3832 - accuracy: 0.9211 - val_loss: 0.9336 - val_accuracy: 0.7014\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3864 - accuracy: 0.9157 - val_loss: 0.9366 - val_accuracy: 0.6957\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3822 - accuracy: 0.9185 - val_loss: 0.8901 - val_accuracy: 0.7059\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3816 - accuracy: 0.9208 - val_loss: 0.8996 - val_accuracy: 0.7002\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3728 - accuracy: 0.9278 - val_loss: 0.9297 - val_accuracy: 0.7014\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3753 - accuracy: 0.9250 - val_loss: 0.9236 - val_accuracy: 0.7070\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3725 - accuracy: 0.9250 - val_loss: 0.9076 - val_accuracy: 0.7048\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3750 - accuracy: 0.9253 - val_loss: 0.9283 - val_accuracy: 0.6968\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3680 - accuracy: 0.9264 - val_loss: 0.9163 - val_accuracy: 0.7093\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3501 - accuracy: 0.9375 - val_loss: 0.9380 - val_accuracy: 0.6968\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3575 - accuracy: 0.9315 - val_loss: 1.0118 - val_accuracy: 0.7014\n","{'loss': [0.6261124610900879, 0.5944123268127441, 0.5925709009170532, 0.5808842182159424, 0.5710293054580688, 0.5820025205612183, 0.5869675874710083, 0.5651123523712158, 0.5632265210151672, 0.5595111846923828, 0.5590763092041016, 0.5614956021308899, 0.5587978363037109, 0.548003077507019, 0.5499337315559387, 0.5458273887634277, 0.5363775491714478, 0.5456981658935547, 0.5522047877311707, 0.5351542830467224, 0.5268396735191345, 0.5400070548057556, 0.5239330530166626, 0.5206859707832336, 0.5249040126800537, 0.5155328512191772, 0.5053360462188721, 0.5062942504882812, 0.5027832984924316, 0.5002948641777039, 0.5039684176445007, 0.5020080208778381, 0.5042890310287476, 0.5168104767799377, 0.5036299824714661, 0.48732829093933105, 0.484225332736969, 0.48351743817329407, 0.48976173996925354, 0.4911941587924957, 0.5039389133453369, 0.48072677850723267, 0.4779801368713379, 0.4886227548122406, 0.47441554069519043, 0.46322932839393616, 0.46794191002845764, 0.4545119106769562, 0.4844726622104645, 0.46105796098709106, 0.445499449968338, 0.44545963406562805, 0.44809022545814514, 0.44572994112968445, 0.4809326231479645, 0.45993757247924805, 0.4476361870765686, 0.44325020909309387, 0.4441017508506775, 0.4435977339744568, 0.45290055871009827, 0.4238417446613312, 0.42191281914711, 0.44353851675987244, 0.45475223660469055, 0.42498916387557983, 0.4326128363609314, 0.4210115373134613, 0.41839390993118286, 0.40713009238243103, 0.41270530223846436, 0.40170910954475403, 0.4036310613155365, 0.40117618441581726, 0.4091634750366211, 0.400452584028244, 0.3930644690990448, 0.39333394169807434, 0.39367711544036865, 0.3966001272201538, 0.3875400125980377, 0.387214332818985, 0.389212429523468, 0.4027557671070099, 0.38020190596580505, 0.38509753346443176, 0.369274765253067, 0.3707866370677948, 0.3786602318286896, 0.3831722140312195, 0.38638368248939514, 0.3821575343608856, 0.38163939118385315, 0.3728024959564209, 0.37532514333724976, 0.37254834175109863, 0.37495094537734985, 0.3680448830127716, 0.35006216168403625, 0.35753026604652405], 'accuracy': [0.797396719455719, 0.825127363204956, 0.8194680213928223, 0.8288058638572693, 0.8389926552772522, 0.8290888667106628, 0.8256932497024536, 0.8324844241142273, 0.8364459276199341, 0.8415393233299255, 0.8446519374847412, 0.8296547532081604, 0.8389926552772522, 0.8474816083908081, 0.83729487657547, 0.8463497161865234, 0.853989839553833, 0.8455008268356323, 0.8381437659263611, 0.8477645516395569, 0.8565365076065063, 0.8460667729377747, 0.8562535643577576, 0.8590831756591797, 0.8576683402061462, 0.8604980111122131, 0.8704017996788025, 0.8613469004631042, 0.8644595146179199, 0.8729485273361206, 0.8681380748748779, 0.8630446791648865, 0.8630446791648865, 0.8593661785125732, 0.868986964225769, 0.8743633031845093, 0.8800226449966431, 0.8777589201927185, 0.8735144138336182, 0.8752122521400452, 0.8613469004631042, 0.8752122521400452, 0.8831352591514587, 0.8678551316261292, 0.8757781386375427, 0.8896434903144836, 0.8890775442123413, 0.8941709399223328, 0.8698358535766602, 0.8865308165550232, 0.897849440574646, 0.8967176079750061, 0.8938879370689392, 0.8907753229141235, 0.872665524482727, 0.8786078095436096, 0.8882286548614502, 0.8964346647262573, 0.8933219909667969, 0.888511598110199, 0.8820033669471741, 0.9057725071907043, 0.9086021780967712, 0.892190158367157, 0.8876627087593079, 0.905206561088562, 0.8998302221298218, 0.9054895043373108, 0.9018110036849976, 0.916242241859436, 0.9117147922515869, 0.9156762957572937, 0.9128466248512268, 0.9176570177078247, 0.9086021780967712, 0.916242241859436, 0.9190718531608582, 0.9202037453651428, 0.918222963809967, 0.9136955142021179, 0.9196377992630005, 0.9176570177078247, 0.9168081283569336, 0.9117147922515869, 0.9241652488708496, 0.9224674701690674, 0.9326542019844055, 0.92840975522995, 0.9173740744590759, 0.9210526347160339, 0.9156762957572937, 0.9185059666633606, 0.9207696914672852, 0.9278438091278076, 0.9250141382217407, 0.9250141382217407, 0.9252971410751343, 0.9264289736747742, 0.9374646544456482, 0.9315223693847656], 'val_loss': [0.8905478119850159, 0.8829911947250366, 0.8738908767700195, 0.8695887327194214, 0.8638392686843872, 0.8610180616378784, 0.8584604263305664, 0.856133222579956, 0.8540536761283875, 0.8539074659347534, 0.8707612156867981, 0.8753540515899658, 0.9042002558708191, 0.8830664157867432, 0.9032756686210632, 0.9962479472160339, 1.0206955671310425, 1.0807074308395386, 0.9250155687332153, 0.9636195302009583, 0.8628331422805786, 0.9548107981681824, 0.8958356976509094, 0.851036012172699, 0.8670893907546997, 0.8568972945213318, 0.7889835834503174, 0.7811657786369324, 0.7770272493362427, 0.7833544611930847, 0.7585492134094238, 0.7809089422225952, 0.7861629724502563, 0.7875194549560547, 0.7750943303108215, 0.775468111038208, 0.778164267539978, 0.8036113977432251, 0.789476752281189, 0.7905063629150391, 0.8066151738166809, 0.7980205416679382, 0.7836390137672424, 0.8273292183876038, 0.8081753849983215, 0.8038474917411804, 0.7947112917900085, 0.8086703419685364, 0.8122718334197998, 0.8022955060005188, 0.8149685263633728, 0.8124949336051941, 0.8172396421432495, 0.8414739966392517, 0.899776041507721, 0.8065624237060547, 0.8253320455551147, 0.8732609152793884, 0.8183821439743042, 1.006255865097046, 0.838923990726471, 0.8398868441581726, 0.8285164833068848, 0.8934504389762878, 0.8405636548995972, 0.8481172323226929, 0.8493582010269165, 0.8513824939727783, 0.870772123336792, 0.8470050692558289, 0.836632251739502, 0.8541655540466309, 0.8684117794036865, 0.9048331379890442, 0.8833621740341187, 0.8894572257995605, 0.8743783831596375, 0.8701205849647522, 0.8813283443450928, 0.8826984167098999, 0.8773964047431946, 0.8983133435249329, 0.8772952556610107, 0.9151528477668762, 0.8844242691993713, 0.9004150032997131, 0.8791379332542419, 0.9395264387130737, 0.9502835273742676, 0.9335716962814331, 0.9366019368171692, 0.8901404738426208, 0.8996071815490723, 0.929650604724884, 0.9236243963241577, 0.9075978398323059, 0.9282864928245544, 0.9163391590118408, 0.9380148649215698, 1.0118192434310913], 'val_accuracy': [0.4954751133918762, 0.5022624731063843, 0.5339366793632507, 0.557692289352417, 0.5927602052688599, 0.5848416090011597, 0.5803167223930359, 0.5882353186607361, 0.587104082107544, 0.5882353186607361, 0.5735294222831726, 0.5803167223930359, 0.5769230723381042, 0.6006787419319153, 0.5950226187705994, 0.5690045356750488, 0.5757918357849121, 0.5678732991218567, 0.6063348650932312, 0.6097285151481628, 0.6436651349067688, 0.6255655884742737, 0.639140248298645, 0.6674208045005798, 0.668552041053772, 0.6787330508232117, 0.7047511339187622, 0.7104072570800781, 0.6990950107574463, 0.7138009071350098, 0.709276020526886, 0.7024886608123779, 0.7194570302963257, 0.6990950107574463, 0.7070135474205017, 0.7194570302963257, 0.7217194437980652, 0.7115384340286255, 0.7171945571899414, 0.7058823704719543, 0.7149321436882019, 0.7070135474205017, 0.709276020526886, 0.6945701241493225, 0.7047511339187622, 0.709276020526886, 0.7104072570800781, 0.7115384340286255, 0.7013574838638306, 0.7115384340286255, 0.7126696705818176, 0.7104072570800781, 0.6990950107574463, 0.7024886608123779, 0.692307710647583, 0.7070135474205017, 0.7058823704719543, 0.7058823704719543, 0.7002262473106384, 0.6583710312843323, 0.709276020526886, 0.7058823704719543, 0.7070135474205017, 0.7081447839736938, 0.7115384340286255, 0.7115384340286255, 0.7126696705818176, 0.7183257937431335, 0.6968325972557068, 0.7047511339187622, 0.709276020526886, 0.7047511339187622, 0.6990950107574463, 0.7138009071350098, 0.6979637742042542, 0.7115384340286255, 0.7104072570800781, 0.7070135474205017, 0.6957013607025146, 0.709276020526886, 0.7047511339187622, 0.709276020526886, 0.709276020526886, 0.7047511339187622, 0.7024886608123779, 0.7047511339187622, 0.7160633206367493, 0.6866515874862671, 0.6843891143798828, 0.7013574838638306, 0.6957013607025146, 0.7058823704719543, 0.7002262473106384, 0.7013574838638306, 0.7070135474205017, 0.7047511339187622, 0.6968325972557068, 0.709276020526886, 0.6968325972557068, 0.7013574838638306]}\n","45/45 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.6351 - accuracy: 0.7869"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 9s 59ms/step - loss: 0.6382 - accuracy: 0.7845 - val_loss: 0.9043 - val_accuracy: 0.4866\n","Epoch 2/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6200 - accuracy: 0.7987 - val_loss: 0.8895 - val_accuracy: 0.4928\n","Epoch 3/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6121 - accuracy: 0.8023 - val_loss: 0.8824 - val_accuracy: 0.5269\n","Epoch 4/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6024 - accuracy: 0.8070 - val_loss: 0.8738 - val_accuracy: 0.5620\n","Epoch 5/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6017 - accuracy: 0.8098 - val_loss: 0.8719 - val_accuracy: 0.5620\n","Epoch 6/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5967 - accuracy: 0.8178 - val_loss: 0.8666 - val_accuracy: 0.5754\n","Epoch 7/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5841 - accuracy: 0.8168 - val_loss: 0.8653 - val_accuracy: 0.5733\n","Epoch 8/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5916 - accuracy: 0.8165 - val_loss: 0.8677 - val_accuracy: 0.5692\n","Epoch 9/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5859 - accuracy: 0.8194 - val_loss: 0.8651 - val_accuracy: 0.5785\n","Epoch 10/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5854 - accuracy: 0.8191 - val_loss: 0.8732 - val_accuracy: 0.5682\n","Epoch 11/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5830 - accuracy: 0.8238 - val_loss: 0.8845 - val_accuracy: 0.5702\n","Epoch 12/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5852 - accuracy: 0.8158 - val_loss: 0.8946 - val_accuracy: 0.5671\n","Epoch 13/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5755 - accuracy: 0.8269 - val_loss: 0.9419 - val_accuracy: 0.5620\n","Epoch 14/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5742 - accuracy: 0.8287 - val_loss: 0.9685 - val_accuracy: 0.5671\n","Epoch 15/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5649 - accuracy: 0.8346 - val_loss: 0.9523 - val_accuracy: 0.5723\n","Epoch 16/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5655 - accuracy: 0.8258 - val_loss: 1.0734 - val_accuracy: 0.5610\n","Epoch 17/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5905 - accuracy: 0.8147 - val_loss: 0.9510 - val_accuracy: 0.5950\n","Epoch 18/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5632 - accuracy: 0.8385 - val_loss: 0.9965 - val_accuracy: 0.5909\n","Epoch 19/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5535 - accuracy: 0.8398 - val_loss: 0.9415 - val_accuracy: 0.6198\n","Epoch 20/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5604 - accuracy: 0.8256 - val_loss: 0.9209 - val_accuracy: 0.6312\n","Epoch 21/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5683 - accuracy: 0.8287 - val_loss: 0.8468 - val_accuracy: 0.6550\n","Epoch 22/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.5434 - accuracy: 0.8486 - val_loss: 0.8544 - val_accuracy: 0.6591\n","Epoch 23/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5448 - accuracy: 0.8382 - val_loss: 0.8407 - val_accuracy: 0.6622\n","Epoch 24/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5630 - accuracy: 0.8287 - val_loss: 0.8292 - val_accuracy: 0.6787\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5456 - accuracy: 0.8465 - val_loss: 0.7966 - val_accuracy: 0.6787\n","Epoch 26/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5527 - accuracy: 0.8333 - val_loss: 0.8235 - val_accuracy: 0.6839\n","Epoch 27/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5389 - accuracy: 0.8455 - val_loss: 0.8165 - val_accuracy: 0.6911\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5286 - accuracy: 0.8475 - val_loss: 0.8448 - val_accuracy: 0.6890\n","Epoch 29/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5290 - accuracy: 0.8499 - val_loss: 0.8064 - val_accuracy: 0.6932\n","Epoch 30/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5216 - accuracy: 0.8514 - val_loss: 0.8386 - val_accuracy: 0.6963\n","Epoch 31/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5437 - accuracy: 0.8380 - val_loss: 0.8224 - val_accuracy: 0.7014\n","Epoch 32/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5254 - accuracy: 0.8499 - val_loss: 0.8115 - val_accuracy: 0.7035\n","Epoch 33/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5231 - accuracy: 0.8512 - val_loss: 0.8240 - val_accuracy: 0.6973\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5115 - accuracy: 0.8566 - val_loss: 0.8181 - val_accuracy: 0.6983\n","Epoch 35/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5232 - accuracy: 0.8519 - val_loss: 0.8293 - val_accuracy: 0.6942\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5172 - accuracy: 0.8571 - val_loss: 0.8382 - val_accuracy: 0.6901\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5202 - accuracy: 0.8545 - val_loss: 0.8266 - val_accuracy: 0.6983\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5095 - accuracy: 0.8618 - val_loss: 0.8642 - val_accuracy: 0.6973\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5070 - accuracy: 0.8633 - val_loss: 0.8385 - val_accuracy: 0.6890\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5062 - accuracy: 0.8589 - val_loss: 0.8352 - val_accuracy: 0.6994\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5095 - accuracy: 0.8612 - val_loss: 0.8897 - val_accuracy: 0.6829\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4949 - accuracy: 0.8623 - val_loss: 0.8444 - val_accuracy: 0.7014\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5087 - accuracy: 0.8530 - val_loss: 0.8499 - val_accuracy: 0.6994\n","Epoch 44/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4930 - accuracy: 0.8612 - val_loss: 0.8358 - val_accuracy: 0.7045\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4864 - accuracy: 0.8726 - val_loss: 0.8337 - val_accuracy: 0.7004\n","Epoch 46/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4885 - accuracy: 0.8674 - val_loss: 0.8719 - val_accuracy: 0.6952\n","Epoch 47/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4868 - accuracy: 0.8687 - val_loss: 0.8437 - val_accuracy: 0.7004\n","Epoch 48/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4828 - accuracy: 0.8703 - val_loss: 0.8524 - val_accuracy: 0.6952\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4867 - accuracy: 0.8664 - val_loss: 0.8677 - val_accuracy: 0.6973\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4835 - accuracy: 0.8674 - val_loss: 0.8491 - val_accuracy: 0.6942\n","Epoch 51/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4714 - accuracy: 0.8752 - val_loss: 0.8648 - val_accuracy: 0.6942\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4647 - accuracy: 0.8752 - val_loss: 0.8600 - val_accuracy: 0.6921\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4769 - accuracy: 0.8739 - val_loss: 0.8581 - val_accuracy: 0.7004\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4640 - accuracy: 0.8829 - val_loss: 0.8629 - val_accuracy: 0.7004\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4723 - accuracy: 0.8736 - val_loss: 0.8788 - val_accuracy: 0.6942\n","Epoch 56/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4685 - accuracy: 0.8822 - val_loss: 0.9234 - val_accuracy: 0.6839\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5081 - accuracy: 0.8558 - val_loss: 1.0649 - val_accuracy: 0.6395\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5144 - accuracy: 0.8517 - val_loss: 0.8415 - val_accuracy: 0.6921\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4570 - accuracy: 0.8845 - val_loss: 0.8588 - val_accuracy: 0.6921\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4528 - accuracy: 0.8853 - val_loss: 0.8734 - val_accuracy: 0.6921\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4725 - accuracy: 0.8726 - val_loss: 0.9035 - val_accuracy: 0.6798\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4466 - accuracy: 0.8886 - val_loss: 0.8759 - val_accuracy: 0.6890\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4484 - accuracy: 0.8897 - val_loss: 0.8824 - val_accuracy: 0.6870\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4510 - accuracy: 0.8837 - val_loss: 0.9456 - val_accuracy: 0.6870\n","Epoch 65/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4455 - accuracy: 0.8889 - val_loss: 0.8982 - val_accuracy: 0.6818\n","Epoch 66/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4551 - accuracy: 0.8811 - val_loss: 0.9530 - val_accuracy: 0.6798\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4618 - accuracy: 0.8765 - val_loss: 0.8790 - val_accuracy: 0.6942\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4523 - accuracy: 0.8829 - val_loss: 0.9297 - val_accuracy: 0.6829\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4441 - accuracy: 0.8902 - val_loss: 0.8942 - val_accuracy: 0.6921\n","Epoch 70/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4394 - accuracy: 0.8933 - val_loss: 0.8731 - val_accuracy: 0.7056\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4275 - accuracy: 0.8995 - val_loss: 0.9074 - val_accuracy: 0.6994\n","Epoch 72/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4337 - accuracy: 0.8966 - val_loss: 0.9037 - val_accuracy: 0.6849\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4354 - accuracy: 0.8951 - val_loss: 0.9378 - val_accuracy: 0.6818\n","Epoch 74/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4217 - accuracy: 0.8969 - val_loss: 0.8872 - val_accuracy: 0.6994\n","Epoch 75/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4193 - accuracy: 0.8987 - val_loss: 0.8968 - val_accuracy: 0.6901\n","Epoch 76/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4240 - accuracy: 0.8992 - val_loss: 0.9288 - val_accuracy: 0.6798\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4139 - accuracy: 0.9023 - val_loss: 0.9114 - val_accuracy: 0.6932\n","Epoch 78/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4095 - accuracy: 0.9119 - val_loss: 0.9118 - val_accuracy: 0.6952\n","Epoch 79/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4130 - accuracy: 0.9005 - val_loss: 0.9286 - val_accuracy: 0.6983\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4082 - accuracy: 0.9088 - val_loss: 0.9679 - val_accuracy: 0.6798\n","Epoch 81/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4155 - accuracy: 0.9008 - val_loss: 0.9166 - val_accuracy: 0.7045\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3994 - accuracy: 0.9075 - val_loss: 1.0198 - val_accuracy: 0.6746\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4163 - accuracy: 0.9016 - val_loss: 0.9244 - val_accuracy: 0.6963\n","Epoch 84/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4671 - accuracy: 0.8724 - val_loss: 1.0478 - val_accuracy: 0.6725\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4445 - accuracy: 0.8848 - val_loss: 0.9198 - val_accuracy: 0.6932\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4091 - accuracy: 0.9039 - val_loss: 0.9335 - val_accuracy: 0.6963\n","Epoch 87/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3946 - accuracy: 0.9173 - val_loss: 0.9499 - val_accuracy: 0.6973\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3939 - accuracy: 0.9127 - val_loss: 0.9494 - val_accuracy: 0.6839\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4053 - accuracy: 0.9080 - val_loss: 0.9321 - val_accuracy: 0.7025\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3952 - accuracy: 0.9103 - val_loss: 0.9349 - val_accuracy: 0.6921\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4036 - accuracy: 0.9003 - val_loss: 1.0669 - val_accuracy: 0.6736\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4250 - accuracy: 0.8915 - val_loss: 0.9854 - val_accuracy: 0.6860\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3918 - accuracy: 0.9137 - val_loss: 1.0248 - val_accuracy: 0.6736\n","Epoch 94/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3944 - accuracy: 0.9142 - val_loss: 0.9722 - val_accuracy: 0.6849\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3940 - accuracy: 0.9080 - val_loss: 0.9529 - val_accuracy: 0.6911\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3879 - accuracy: 0.9152 - val_loss: 0.9676 - val_accuracy: 0.6983\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3907 - accuracy: 0.9101 - val_loss: 0.9482 - val_accuracy: 0.6880\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3772 - accuracy: 0.9186 - val_loss: 0.9592 - val_accuracy: 0.6963\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3817 - accuracy: 0.9171 - val_loss: 0.9719 - val_accuracy: 0.6952\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3843 - accuracy: 0.9124 - val_loss: 0.9907 - val_accuracy: 0.6808\n","{'loss': [0.638215184211731, 0.6200047135353088, 0.6121214032173157, 0.6023924350738525, 0.6016843318939209, 0.5966654419898987, 0.5841205716133118, 0.5916139483451843, 0.5859262943267822, 0.5853821039199829, 0.5830102562904358, 0.5851552486419678, 0.5755036473274231, 0.5742147564888, 0.5649257898330688, 0.56551194190979, 0.5905241966247559, 0.5631762742996216, 0.5535167455673218, 0.56038498878479, 0.5683138370513916, 0.543446958065033, 0.5447755455970764, 0.5629873871803284, 0.5456272959709167, 0.5527186393737793, 0.5389083623886108, 0.5286455154418945, 0.5289573073387146, 0.5216355323791504, 0.5436933636665344, 0.5254329442977905, 0.5231179594993591, 0.5115005373954773, 0.5232256054878235, 0.5172390937805176, 0.5202347040176392, 0.5094721913337708, 0.506979763507843, 0.5062260031700134, 0.5095391869544983, 0.4949491024017334, 0.5086886882781982, 0.4930248260498047, 0.48640403151512146, 0.4884696900844574, 0.4868033230304718, 0.4827753007411957, 0.48673751950263977, 0.4835182726383209, 0.47139281034469604, 0.4646505117416382, 0.47686055302619934, 0.4639818072319031, 0.47230643033981323, 0.4684818685054779, 0.5081425905227661, 0.5144246816635132, 0.45702165365219116, 0.45282211899757385, 0.472542941570282, 0.4465550184249878, 0.4483615756034851, 0.45095494389533997, 0.4454554617404938, 0.455094575881958, 0.46176400780677795, 0.4523126482963562, 0.4441494941711426, 0.4394036829471588, 0.4274902045726776, 0.4337332844734192, 0.4353533983230591, 0.4217180013656616, 0.4193097651004791, 0.42399924993515015, 0.4139476418495178, 0.40948203206062317, 0.4130220413208008, 0.408217191696167, 0.41550731658935547, 0.39937520027160645, 0.41630473732948303, 0.4671444296836853, 0.44452300667762756, 0.4091285467147827, 0.39457035064697266, 0.39386096596717834, 0.4053443372249603, 0.39523351192474365, 0.4035762846469879, 0.4249557554721832, 0.3917577266693115, 0.3944380283355713, 0.393997460603714, 0.3878827393054962, 0.3907003700733185, 0.37715384364128113, 0.38174620270729065, 0.3842562139034271], 'accuracy': [0.7844961285591125, 0.7987080216407776, 0.8023256063461304, 0.8069767355918884, 0.8098191022872925, 0.817829430103302, 0.8167958855628967, 0.8165374398231506, 0.8193798661231995, 0.8191214203834534, 0.8237726092338562, 0.8157622814178467, 0.8268733620643616, 0.8286821842193604, 0.8346253037452698, 0.8258398175239563, 0.8147286772727966, 0.8385012745857239, 0.8397932648658752, 0.8255813717842102, 0.8286821842193604, 0.8485788106918335, 0.8382428884506226, 0.8286821842193604, 0.8465116024017334, 0.8333333134651184, 0.8454780578613281, 0.8475452065467834, 0.8498708009719849, 0.8514211773872375, 0.8379845023155212, 0.8498708009719849, 0.8511627912521362, 0.856589138507843, 0.851938009262085, 0.8571059703826904, 0.8545219898223877, 0.8617570996284485, 0.8633074760437012, 0.8589147329330444, 0.8612403273582458, 0.8622739315032959, 0.8529715538024902, 0.8612403273582458, 0.8726097941398621, 0.8674418330192566, 0.868733823299408, 0.8702842593193054, 0.8664082884788513, 0.8674418330192566, 0.8751937747001648, 0.8751937747001648, 0.8739017844200134, 0.882945716381073, 0.8736433982849121, 0.882170557975769, 0.8558139801025391, 0.8516795635223389, 0.8844961524009705, 0.8852713108062744, 0.8726097941398621, 0.8886305093765259, 0.8896640539169312, 0.8837209343910217, 0.8888888955116272, 0.881136953830719, 0.8764857649803162, 0.882945716381073, 0.8901808857917786, 0.8932816386222839, 0.8994832038879395, 0.8966408371925354, 0.8950904607772827, 0.8968992233276367, 0.8987079858779907, 0.8992248177528381, 0.9023255705833435, 0.9118863344192505, 0.9005168080329895, 0.9087855219841003, 0.9007751941680908, 0.907493531703949, 0.9015504121780396, 0.8723514080047607, 0.8847545385360718, 0.9038759469985962, 0.9173126816749573, 0.9126614928245544, 0.9080103635787964, 0.910335898399353, 0.9002584218978882, 0.8914728760719299, 0.9136950969696045, 0.9142118692398071, 0.9080103635787964, 0.9152454733848572, 0.9100775122642517, 0.9186046719551086, 0.9170542359352112, 0.9124031066894531], 'val_loss': [0.9042662978172302, 0.8895220756530762, 0.8824480175971985, 0.8737954497337341, 0.871886134147644, 0.8666218519210815, 0.8653203248977661, 0.867664635181427, 0.8650591969490051, 0.8731516003608704, 0.884476363658905, 0.894578218460083, 0.9419357180595398, 0.9684830904006958, 0.9523301720619202, 1.0733637809753418, 0.9510411024093628, 0.9964948296546936, 0.9414663314819336, 0.9208691716194153, 0.8467709422111511, 0.8544387817382812, 0.8406789302825928, 0.8292422890663147, 0.7965988516807556, 0.823512077331543, 0.8164945840835571, 0.8448347449302673, 0.8064391016960144, 0.8386433124542236, 0.8224435448646545, 0.8114606738090515, 0.8239822387695312, 0.8181438446044922, 0.8292759656906128, 0.8382047414779663, 0.8266264796257019, 0.8641512393951416, 0.838483452796936, 0.8351679444313049, 0.889702558517456, 0.8444042205810547, 0.8499400615692139, 0.8357707858085632, 0.8336566090583801, 0.8719485402107239, 0.8436803221702576, 0.8524212837219238, 0.8677061200141907, 0.8490782380104065, 0.8647605776786804, 0.859970211982727, 0.858053982257843, 0.862930417060852, 0.8787949085235596, 0.923423707485199, 1.0649136304855347, 0.8414812684059143, 0.8587546944618225, 0.8734068274497986, 0.9035269618034363, 0.8758852481842041, 0.8823508620262146, 0.9455950856208801, 0.8982372283935547, 0.9529709815979004, 0.8790326714515686, 0.9296945333480835, 0.8942143321037292, 0.8731327056884766, 0.9074316620826721, 0.9037089347839355, 0.9377875924110413, 0.8871838450431824, 0.8967651128768921, 0.9287596940994263, 0.9114173650741577, 0.9118437767028809, 0.9285557270050049, 0.9678676128387451, 0.916569173336029, 1.0197925567626953, 0.924369752407074, 1.0477783679962158, 0.9198364615440369, 0.9334716200828552, 0.949884295463562, 0.949353039264679, 0.9321417212486267, 0.9349201917648315, 1.0669207572937012, 0.9853573441505432, 1.0248332023620605, 0.972227931022644, 0.9529090523719788, 0.967591404914856, 0.9481996893882751, 0.959162175655365, 0.9718546867370605, 0.9906908869743347], 'val_accuracy': [0.48657023906707764, 0.4927685856819153, 0.5268595218658447, 0.5619834661483765, 0.5619834661483765, 0.5754132270812988, 0.5733470916748047, 0.5692148804664612, 0.5785123705863953, 0.5681818127632141, 0.5702479481697083, 0.567148745059967, 0.5619834661483765, 0.567148745059967, 0.5723140239715576, 0.5609503984451294, 0.5950413346290588, 0.5909090638160706, 0.6198347210884094, 0.6311983466148376, 0.6549586653709412, 0.6590909361839294, 0.6621900796890259, 0.6787189841270447, 0.6787189841270447, 0.68388432264328, 0.69111567735672, 0.6890496015548706, 0.6931818127632141, 0.6962810158729553, 0.7014462947845459, 0.7035123705863953, 0.6973140239715576, 0.6983470916748047, 0.6942148804664612, 0.6900826692581177, 0.6983470916748047, 0.6973140239715576, 0.6890496015548706, 0.6993801593780518, 0.682851254940033, 0.7014462947845459, 0.6993801593780518, 0.7045454382896423, 0.7004132270812988, 0.6952479481697083, 0.7004132270812988, 0.6952479481697083, 0.6973140239715576, 0.6942148804664612, 0.6942148804664612, 0.692148745059967, 0.7004132270812988, 0.7004132270812988, 0.6942148804664612, 0.68388432264328, 0.6394628286361694, 0.692148745059967, 0.692148745059967, 0.692148745059967, 0.6797520518302917, 0.6890496015548706, 0.6869834661483765, 0.6869834661483765, 0.6818181872367859, 0.6797520518302917, 0.6942148804664612, 0.682851254940033, 0.692148745059967, 0.7055785059928894, 0.6993801593780518, 0.6849173307418823, 0.6818181872367859, 0.6993801593780518, 0.6900826692581177, 0.6797520518302917, 0.6931818127632141, 0.6952479481697083, 0.6983470916748047, 0.6797520518302917, 0.7045454382896423, 0.6745867729187012, 0.6962810158729553, 0.672520637512207, 0.6931818127632141, 0.6962810158729553, 0.6973140239715576, 0.68388432264328, 0.702479362487793, 0.692148745059967, 0.6735537052154541, 0.6859503984451294, 0.6735537052154541, 0.6849173307418823, 0.69111567735672, 0.6983470916748047, 0.6880165338516235, 0.6962810158729553, 0.6952479481697083, 0.6807851195335388]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.5286 - accuracy: 0.8502"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 75ms/step - loss: 0.5261 - accuracy: 0.8518 - val_loss: 0.9188 - val_accuracy: 0.4860\n","Epoch 2/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.4507 - accuracy: 0.8812 - val_loss: 0.9133 - val_accuracy: 0.4892\n","Epoch 3/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4347 - accuracy: 0.8909 - val_loss: 0.9071 - val_accuracy: 0.4968\n","Epoch 4/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4526 - accuracy: 0.8793 - val_loss: 0.8885 - val_accuracy: 0.5075\n","Epoch 5/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4236 - accuracy: 0.8920 - val_loss: 0.8838 - val_accuracy: 0.5162\n","Epoch 6/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4432 - accuracy: 0.8922 - val_loss: 0.8846 - val_accuracy: 0.5205\n","Epoch 7/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.4256 - accuracy: 0.8939 - val_loss: 0.8772 - val_accuracy: 0.5377\n","Epoch 8/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4318 - accuracy: 0.8904 - val_loss: 0.8745 - val_accuracy: 0.5474\n","Epoch 9/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4159 - accuracy: 0.8987 - val_loss: 0.8812 - val_accuracy: 0.5539\n","Epoch 10/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4204 - accuracy: 0.8966 - val_loss: 0.8967 - val_accuracy: 0.5528\n","Epoch 11/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4224 - accuracy: 0.8963 - val_loss: 0.9030 - val_accuracy: 0.5550\n","Epoch 12/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4113 - accuracy: 0.9052 - val_loss: 0.9246 - val_accuracy: 0.5614\n","Epoch 13/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4150 - accuracy: 0.8974 - val_loss: 0.9425 - val_accuracy: 0.5700\n","Epoch 14/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4215 - accuracy: 0.8947 - val_loss: 0.9981 - val_accuracy: 0.5679\n","Epoch 15/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4140 - accuracy: 0.9038 - val_loss: 1.0369 - val_accuracy: 0.5700\n","Epoch 16/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4026 - accuracy: 0.9076 - val_loss: 1.0551 - val_accuracy: 0.5733\n","Epoch 17/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3944 - accuracy: 0.9111 - val_loss: 1.1968 - val_accuracy: 0.5841\n","Epoch 18/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4029 - accuracy: 0.9033 - val_loss: 1.2322 - val_accuracy: 0.5808\n","Epoch 19/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3987 - accuracy: 0.9092 - val_loss: 1.1284 - val_accuracy: 0.5991\n","Epoch 20/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3890 - accuracy: 0.9149 - val_loss: 1.1278 - val_accuracy: 0.6142\n","Epoch 21/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4096 - accuracy: 0.8971 - val_loss: 1.1255 - val_accuracy: 0.6250\n","Epoch 22/100\n","29/29 [==============================] - 1s 36ms/step - loss: 0.3835 - accuracy: 0.9151 - val_loss: 1.0328 - val_accuracy: 0.6509\n","Epoch 23/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3899 - accuracy: 0.9165 - val_loss: 0.9280 - val_accuracy: 0.6886\n","Epoch 24/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.3854 - accuracy: 0.9143 - val_loss: 0.9096 - val_accuracy: 0.6940\n","Epoch 25/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3918 - accuracy: 0.9062 - val_loss: 0.8378 - val_accuracy: 0.7252\n","Epoch 26/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3745 - accuracy: 0.9165 - val_loss: 0.8268 - val_accuracy: 0.7371\n","Epoch 27/100\n","29/29 [==============================] - 4s 136ms/step - loss: 0.3761 - accuracy: 0.9154 - val_loss: 0.7856 - val_accuracy: 0.7414\n","Epoch 28/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3719 - accuracy: 0.9221 - val_loss: 0.7752 - val_accuracy: 0.7640\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3708 - accuracy: 0.9186 - val_loss: 0.7922 - val_accuracy: 0.7446\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3772 - accuracy: 0.9195 - val_loss: 0.8964 - val_accuracy: 0.7144\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3786 - accuracy: 0.9159 - val_loss: 0.7656 - val_accuracy: 0.7629\n","Epoch 32/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3730 - accuracy: 0.9184 - val_loss: 0.7890 - val_accuracy: 0.7565\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3663 - accuracy: 0.9208 - val_loss: 0.7820 - val_accuracy: 0.7532\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3634 - accuracy: 0.9265 - val_loss: 0.8905 - val_accuracy: 0.7284\n","Epoch 35/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3728 - accuracy: 0.9230 - val_loss: 0.7693 - val_accuracy: 0.7716\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3539 - accuracy: 0.9265 - val_loss: 0.7972 - val_accuracy: 0.7629\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3528 - accuracy: 0.9327 - val_loss: 0.7707 - val_accuracy: 0.7554\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3595 - accuracy: 0.9291 - val_loss: 0.7877 - val_accuracy: 0.7586\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3824 - accuracy: 0.9119 - val_loss: 0.8108 - val_accuracy: 0.7381\n","Epoch 40/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3677 - accuracy: 0.9176 - val_loss: 0.8242 - val_accuracy: 0.7403\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3517 - accuracy: 0.9275 - val_loss: 0.7986 - val_accuracy: 0.7608\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3509 - accuracy: 0.9300 - val_loss: 0.8219 - val_accuracy: 0.7575\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3546 - accuracy: 0.9283 - val_loss: 0.8171 - val_accuracy: 0.7575\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3440 - accuracy: 0.9378 - val_loss: 0.8169 - val_accuracy: 0.7586\n","Epoch 45/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3579 - accuracy: 0.9251 - val_loss: 0.8027 - val_accuracy: 0.7500\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3477 - accuracy: 0.9265 - val_loss: 0.8101 - val_accuracy: 0.7522\n","Epoch 47/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3359 - accuracy: 0.9391 - val_loss: 0.8181 - val_accuracy: 0.7586\n","Epoch 48/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3363 - accuracy: 0.9348 - val_loss: 0.8048 - val_accuracy: 0.7586\n","Epoch 49/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3336 - accuracy: 0.9351 - val_loss: 0.8505 - val_accuracy: 0.7489\n","Epoch 50/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3318 - accuracy: 0.9415 - val_loss: 0.8113 - val_accuracy: 0.7543\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3344 - accuracy: 0.9370 - val_loss: 0.8507 - val_accuracy: 0.7554\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3355 - accuracy: 0.9348 - val_loss: 0.8298 - val_accuracy: 0.7565\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3247 - accuracy: 0.9423 - val_loss: 0.8863 - val_accuracy: 0.7392\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3262 - accuracy: 0.9432 - val_loss: 0.8385 - val_accuracy: 0.7522\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3254 - accuracy: 0.9421 - val_loss: 0.8478 - val_accuracy: 0.7468\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3220 - accuracy: 0.9399 - val_loss: 0.8519 - val_accuracy: 0.7435\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3334 - accuracy: 0.9332 - val_loss: 0.9110 - val_accuracy: 0.7295\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3325 - accuracy: 0.9407 - val_loss: 0.8552 - val_accuracy: 0.7522\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3294 - accuracy: 0.9362 - val_loss: 0.8398 - val_accuracy: 0.7489\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3275 - accuracy: 0.9418 - val_loss: 0.8615 - val_accuracy: 0.7468\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3221 - accuracy: 0.9391 - val_loss: 0.8393 - val_accuracy: 0.7565\n","Epoch 62/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3129 - accuracy: 0.9491 - val_loss: 0.9195 - val_accuracy: 0.7274\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3167 - accuracy: 0.9432 - val_loss: 0.8667 - val_accuracy: 0.7532\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3167 - accuracy: 0.9445 - val_loss: 0.8721 - val_accuracy: 0.7543\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3021 - accuracy: 0.9512 - val_loss: 0.8834 - val_accuracy: 0.7522\n","Epoch 66/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3237 - accuracy: 0.9383 - val_loss: 0.8751 - val_accuracy: 0.7489\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3288 - accuracy: 0.9383 - val_loss: 0.9162 - val_accuracy: 0.7446\n","Epoch 68/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3258 - accuracy: 0.9335 - val_loss: 0.8963 - val_accuracy: 0.7457\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3401 - accuracy: 0.9278 - val_loss: 0.9618 - val_accuracy: 0.7188\n","Epoch 70/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3665 - accuracy: 0.9146 - val_loss: 0.8423 - val_accuracy: 0.7619\n","Epoch 71/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3203 - accuracy: 0.9391 - val_loss: 0.9181 - val_accuracy: 0.7446\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3174 - accuracy: 0.9418 - val_loss: 0.8537 - val_accuracy: 0.7522\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2962 - accuracy: 0.9547 - val_loss: 0.8696 - val_accuracy: 0.7662\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3102 - accuracy: 0.9464 - val_loss: 0.9129 - val_accuracy: 0.7403\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2976 - accuracy: 0.9550 - val_loss: 0.8961 - val_accuracy: 0.7532\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3125 - accuracy: 0.9421 - val_loss: 0.9239 - val_accuracy: 0.7446\n","Epoch 77/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3054 - accuracy: 0.9461 - val_loss: 0.8882 - val_accuracy: 0.7414\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2956 - accuracy: 0.9555 - val_loss: 0.8795 - val_accuracy: 0.7522\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2904 - accuracy: 0.9529 - val_loss: 0.9077 - val_accuracy: 0.7468\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2898 - accuracy: 0.9555 - val_loss: 0.9305 - val_accuracy: 0.7392\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2992 - accuracy: 0.9488 - val_loss: 0.9159 - val_accuracy: 0.7489\n","Epoch 82/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3092 - accuracy: 0.9429 - val_loss: 0.8992 - val_accuracy: 0.7478\n","Epoch 83/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2970 - accuracy: 0.9491 - val_loss: 0.9067 - val_accuracy: 0.7532\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2828 - accuracy: 0.9626 - val_loss: 0.9232 - val_accuracy: 0.7349\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2851 - accuracy: 0.9574 - val_loss: 0.9072 - val_accuracy: 0.7425\n","Epoch 86/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2912 - accuracy: 0.9558 - val_loss: 0.9072 - val_accuracy: 0.7446\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2965 - accuracy: 0.9502 - val_loss: 1.0651 - val_accuracy: 0.7112\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3430 - accuracy: 0.9221 - val_loss: 0.8884 - val_accuracy: 0.7522\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2970 - accuracy: 0.9504 - val_loss: 0.8935 - val_accuracy: 0.7522\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2805 - accuracy: 0.9591 - val_loss: 0.9034 - val_accuracy: 0.7500\n","Epoch 91/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2941 - accuracy: 0.9504 - val_loss: 0.9130 - val_accuracy: 0.7575\n","Epoch 92/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2756 - accuracy: 0.9620 - val_loss: 0.9156 - val_accuracy: 0.7446\n","Epoch 93/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2750 - accuracy: 0.9588 - val_loss: 0.9516 - val_accuracy: 0.7403\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2822 - accuracy: 0.9555 - val_loss: 0.9647 - val_accuracy: 0.7457\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2700 - accuracy: 0.9609 - val_loss: 0.9409 - val_accuracy: 0.7489\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2796 - accuracy: 0.9577 - val_loss: 1.0084 - val_accuracy: 0.7328\n","Epoch 97/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2792 - accuracy: 0.9566 - val_loss: 0.9316 - val_accuracy: 0.7478\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2703 - accuracy: 0.9623 - val_loss: 0.9451 - val_accuracy: 0.7457\n","Epoch 99/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2746 - accuracy: 0.9564 - val_loss: 0.9502 - val_accuracy: 0.7468\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3222 - accuracy: 0.9308 - val_loss: 1.0491 - val_accuracy: 0.7241\n","{'loss': [0.526093602180481, 0.450705885887146, 0.4347479045391083, 0.4526446759700775, 0.4236185550689697, 0.4432096779346466, 0.4256439208984375, 0.43179696798324585, 0.415885865688324, 0.4203553795814514, 0.4224340319633484, 0.41126856207847595, 0.4149509370326996, 0.42147836089134216, 0.41397932171821594, 0.4025782644748688, 0.39439237117767334, 0.4028964936733246, 0.3986847996711731, 0.38899868726730347, 0.4095778167247772, 0.38354426622390747, 0.38986754417419434, 0.3854186236858368, 0.39181169867515564, 0.3744591772556305, 0.37612542510032654, 0.37187665700912476, 0.37083131074905396, 0.3772395849227905, 0.3786443769931793, 0.3729540705680847, 0.36628079414367676, 0.3634074032306671, 0.37279683351516724, 0.35391944646835327, 0.3527539074420929, 0.3595101535320282, 0.382393479347229, 0.3676915764808655, 0.3516656756401062, 0.35089272260665894, 0.354551762342453, 0.3440404236316681, 0.35792797803878784, 0.34766334295272827, 0.33588770031929016, 0.3362693190574646, 0.33360108733177185, 0.3317912518978119, 0.33437269926071167, 0.33548277616500854, 0.3247109055519104, 0.32623159885406494, 0.32541120052337646, 0.32202908396720886, 0.33339521288871765, 0.33247604966163635, 0.32939350605010986, 0.32751110196113586, 0.3220897912979126, 0.31293773651123047, 0.31666895747184753, 0.3166673481464386, 0.30212467908859253, 0.32365626096725464, 0.3287612199783325, 0.3257550597190857, 0.34011346101760864, 0.36648836731910706, 0.3202778100967407, 0.31737932562828064, 0.2962138056755066, 0.31015291810035706, 0.29758334159851074, 0.3124847412109375, 0.30542638897895813, 0.29556509852409363, 0.2903986871242523, 0.28978365659713745, 0.29918891191482544, 0.30924278497695923, 0.29696160554885864, 0.2827830910682678, 0.28510743379592896, 0.2911868691444397, 0.29648810625076294, 0.3429688811302185, 0.296998530626297, 0.2804524600505829, 0.2941334545612335, 0.27562108635902405, 0.2749808728694916, 0.2821972668170929, 0.27001243829727173, 0.2796131670475006, 0.2792160212993622, 0.2702864408493042, 0.2746482193470001, 0.32216504216194153], 'accuracy': [0.8518319129943848, 0.881196141242981, 0.8908944129943848, 0.8793103694915771, 0.891972005367279, 0.892241358757019, 0.8938577771186829, 0.8903555870056152, 0.8987069129943848, 0.8965517282485962, 0.8962823152542114, 0.9051724076271057, 0.8973599076271057, 0.8946659564971924, 0.9038254022598267, 0.907597005367279, 0.9110991358757019, 0.9032866358757019, 0.9092133641242981, 0.9148706793785095, 0.897090494632721, 0.9151400923728943, 0.9164870977401733, 0.9143319129943848, 0.90625, 0.9164870977401733, 0.915409505367279, 0.9221444129943848, 0.9186422228813171, 0.9194504022598267, 0.9159482717514038, 0.9183728694915771, 0.9207974076271057, 0.9264547228813171, 0.9229525923728943, 0.9264547228813171, 0.9326508641242981, 0.9291487336158752, 0.9119073152542114, 0.9175646305084229, 0.9275323152542114, 0.9299569129943848, 0.928340494632721, 0.9377694129943848, 0.9251077771186829, 0.9264547228813171, 0.939116358757019, 0.9348060488700867, 0.9350754022598267, 0.9415409564971924, 0.9369612336158752, 0.9348060488700867, 0.9423491358757019, 0.9431573152542114, 0.9420797228813171, 0.9399245977401733, 0.9331896305084229, 0.9407327771186829, 0.936152994632721, 0.9418103694915771, 0.939116358757019, 0.9490840435028076, 0.9431573152542114, 0.9445043206214905, 0.9512392282485962, 0.9383081793785095, 0.9383081793785095, 0.9334590435028076, 0.9278017282485962, 0.9146012663841248, 0.939116358757019, 0.9418103694915771, 0.954741358757019, 0.9463900923728943, 0.9550107717514038, 0.9420797228813171, 0.9461206793785095, 0.9555495977401733, 0.9528555870056152, 0.9555495977401733, 0.9488146305084229, 0.9428879022598267, 0.9490840435028076, 0.962553858757019, 0.9574353694915771, 0.9558189511299133, 0.9501616358757019, 0.9221444129943848, 0.9504310488700867, 0.9590517282485962, 0.9504310488700867, 0.9620150923728943, 0.9587823152542114, 0.9555495977401733, 0.9609375, 0.9577047228813171, 0.9566271305084229, 0.962284505367279, 0.9563577771186829, 0.9307650923728943], 'val_loss': [0.9187644720077515, 0.9133499264717102, 0.9071216583251953, 0.8885065317153931, 0.8837789297103882, 0.8846195340156555, 0.8771848082542419, 0.8744820952415466, 0.8811973333358765, 0.8967117071151733, 0.9030426144599915, 0.9245694875717163, 0.9424620270729065, 0.9981015920639038, 1.0368598699569702, 1.0550634860992432, 1.1967785358428955, 1.2322258949279785, 1.1283665895462036, 1.1277673244476318, 1.125488042831421, 1.0327528715133667, 0.9279727339744568, 0.9096068143844604, 0.8377531170845032, 0.8267962336540222, 0.7855963110923767, 0.7751663327217102, 0.7921997308731079, 0.8963934779167175, 0.765612006187439, 0.7890214323997498, 0.7820473313331604, 0.8904915452003479, 0.7692862749099731, 0.7971672415733337, 0.7706881761550903, 0.7877286672592163, 0.8107971549034119, 0.8242378234863281, 0.7986245155334473, 0.8219239711761475, 0.8170775771141052, 0.816852331161499, 0.8027359247207642, 0.8101347088813782, 0.8181331157684326, 0.8047811985015869, 0.8504873514175415, 0.8112896680831909, 0.850658655166626, 0.8297762274742126, 0.8862714171409607, 0.8384560346603394, 0.8477847576141357, 0.8518640995025635, 0.9109860062599182, 0.8551777005195618, 0.8398091793060303, 0.8615226745605469, 0.8393377065658569, 0.9195257425308228, 0.8667026162147522, 0.8720950484275818, 0.8833852410316467, 0.8750895261764526, 0.9162437915802002, 0.8962653875350952, 0.9618231654167175, 0.8423233032226562, 0.91805499792099, 0.8536535501480103, 0.8695700168609619, 0.9128689169883728, 0.8961490988731384, 0.9239122867584229, 0.8882290124893188, 0.879543125629425, 0.9076710343360901, 0.930507242679596, 0.9158602952957153, 0.8992390632629395, 0.9066559076309204, 0.9231760501861572, 0.907232403755188, 0.9071602821350098, 1.0651413202285767, 0.888434648513794, 0.8935127258300781, 0.9033575654029846, 0.9129625558853149, 0.9156095385551453, 0.9515840411186218, 0.9646766781806946, 0.9409432411193848, 1.0084415674209595, 0.9316064715385437, 0.9451033473014832, 0.9502332210540771, 1.0491013526916504], 'val_accuracy': [0.48599138855934143, 0.4892241358757019, 0.4967672526836395, 0.5075430870056152, 0.5161637663841248, 0.5204741358757019, 0.537715494632721, 0.5474137663841248, 0.5538793206214905, 0.5528017282485962, 0.5549569129943848, 0.5614224076271057, 0.5700430870056152, 0.5678879022598267, 0.5700430870056152, 0.5732758641242981, 0.5840517282485962, 0.5808189511299133, 0.5991379022598267, 0.6142241358757019, 0.625, 0.6508620977401733, 0.6885775923728943, 0.693965494632721, 0.725215494632721, 0.7370689511299133, 0.7413793206214905, 0.764008641242981, 0.7446120977401733, 0.7144396305084229, 0.7629310488700867, 0.756465494632721, 0.7532327771186829, 0.7284482717514038, 0.7715517282485962, 0.7629310488700867, 0.7553879022598267, 0.7586206793785095, 0.7381465435028076, 0.7403017282485962, 0.7607758641242981, 0.7575430870056152, 0.7575430870056152, 0.7586206793785095, 0.75, 0.7521551847457886, 0.7586206793785095, 0.7586206793785095, 0.7489224076271057, 0.7543103694915771, 0.7553879022598267, 0.756465494632721, 0.7392241358757019, 0.7521551847457886, 0.7467672228813171, 0.743534505367279, 0.7295258641242981, 0.7521551847457886, 0.7489224076271057, 0.7467672228813171, 0.756465494632721, 0.7273706793785095, 0.7532327771186829, 0.7543103694915771, 0.7521551847457886, 0.7489224076271057, 0.7446120977401733, 0.7456896305084229, 0.71875, 0.7618534564971924, 0.7446120977401733, 0.7521551847457886, 0.7661637663841248, 0.7403017282485962, 0.7532327771186829, 0.7446120977401733, 0.7413793206214905, 0.7521551847457886, 0.7467672228813171, 0.7392241358757019, 0.7489224076271057, 0.7478448152542114, 0.7532327771186829, 0.7349137663841248, 0.7424569129943848, 0.7446120977401733, 0.7112069129943848, 0.7521551847457886, 0.7521551847457886, 0.75, 0.7575430870056152, 0.7446120977401733, 0.7403017282485962, 0.7456896305084229, 0.7489224076271057, 0.732758641242981, 0.7478448152542114, 0.7456896305084229, 0.7467672228813171, 0.7241379022598267]}\n","38/38 [==============================] - 2s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.5366 - accuracy: 0.8459"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 7s 71ms/step - loss: 0.5308 - accuracy: 0.8483 - val_loss: 0.9151 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4428 - accuracy: 0.8953 - val_loss: 0.9058 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.4341 - accuracy: 0.8899 - val_loss: 0.8862 - val_accuracy: 0.5000\n","Epoch 4/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.4331 - accuracy: 0.8919 - val_loss: 0.8594 - val_accuracy: 0.5498\n","Epoch 5/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4490 - accuracy: 0.8854 - val_loss: 0.8561 - val_accuracy: 0.5554\n","Epoch 6/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4421 - accuracy: 0.8902 - val_loss: 0.8588 - val_accuracy: 0.5588\n","Epoch 7/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4239 - accuracy: 0.8962 - val_loss: 0.8652 - val_accuracy: 0.5588\n","Epoch 8/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4255 - accuracy: 0.8993 - val_loss: 0.8591 - val_accuracy: 0.5792\n","Epoch 9/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4177 - accuracy: 0.9018 - val_loss: 0.8628 - val_accuracy: 0.5905\n","Epoch 10/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4198 - accuracy: 0.9015 - val_loss: 0.8630 - val_accuracy: 0.5871\n","Epoch 11/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4098 - accuracy: 0.9063 - val_loss: 0.8660 - val_accuracy: 0.5848\n","Epoch 12/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4048 - accuracy: 0.9083 - val_loss: 0.8801 - val_accuracy: 0.5781\n","Epoch 13/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4054 - accuracy: 0.9117 - val_loss: 0.9011 - val_accuracy: 0.5871\n","Epoch 14/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4087 - accuracy: 0.9044 - val_loss: 0.9179 - val_accuracy: 0.5894\n","Epoch 15/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3989 - accuracy: 0.9162 - val_loss: 0.9307 - val_accuracy: 0.5950\n","Epoch 16/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4048 - accuracy: 0.9080 - val_loss: 0.9752 - val_accuracy: 0.5973\n","Epoch 17/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3957 - accuracy: 0.9171 - val_loss: 0.9980 - val_accuracy: 0.6131\n","Epoch 18/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3967 - accuracy: 0.9120 - val_loss: 1.0171 - val_accuracy: 0.6120\n","Epoch 19/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3942 - accuracy: 0.9162 - val_loss: 1.0412 - val_accuracy: 0.6324\n","Epoch 20/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4023 - accuracy: 0.9072 - val_loss: 0.9068 - val_accuracy: 0.6459\n","Epoch 21/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4289 - accuracy: 0.8911 - val_loss: 0.9210 - val_accuracy: 0.6674\n","Epoch 22/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3911 - accuracy: 0.9106 - val_loss: 0.8402 - val_accuracy: 0.6900\n","Epoch 23/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3890 - accuracy: 0.9109 - val_loss: 0.9147 - val_accuracy: 0.6810\n","Epoch 24/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3988 - accuracy: 0.9078 - val_loss: 0.7825 - val_accuracy: 0.7285\n","Epoch 25/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.3896 - accuracy: 0.9140 - val_loss: 0.7848 - val_accuracy: 0.7296\n","Epoch 26/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3778 - accuracy: 0.9185 - val_loss: 0.7849 - val_accuracy: 0.7432\n","Epoch 27/100\n","28/28 [==============================] - 2s 60ms/step - loss: 0.3901 - accuracy: 0.9126 - val_loss: 0.7245 - val_accuracy: 0.7511\n","Epoch 28/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3828 - accuracy: 0.9143 - val_loss: 0.7083 - val_accuracy: 0.7534\n","Epoch 29/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3896 - accuracy: 0.9080 - val_loss: 0.7037 - val_accuracy: 0.7726\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3581 - accuracy: 0.9312 - val_loss: 0.7189 - val_accuracy: 0.7692\n","Epoch 31/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3695 - accuracy: 0.9253 - val_loss: 0.7142 - val_accuracy: 0.7557\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3667 - accuracy: 0.9242 - val_loss: 0.7490 - val_accuracy: 0.7500\n","Epoch 33/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3641 - accuracy: 0.9267 - val_loss: 0.7147 - val_accuracy: 0.7726\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3584 - accuracy: 0.9318 - val_loss: 0.7382 - val_accuracy: 0.7670\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3657 - accuracy: 0.9276 - val_loss: 0.7285 - val_accuracy: 0.7602\n","Epoch 36/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3551 - accuracy: 0.9321 - val_loss: 0.7297 - val_accuracy: 0.7602\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3475 - accuracy: 0.9380 - val_loss: 0.7530 - val_accuracy: 0.7715\n","Epoch 38/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3556 - accuracy: 0.9321 - val_loss: 0.7944 - val_accuracy: 0.7376\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3749 - accuracy: 0.9157 - val_loss: 0.7497 - val_accuracy: 0.7443\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3458 - accuracy: 0.9324 - val_loss: 0.7588 - val_accuracy: 0.7477\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3388 - accuracy: 0.9383 - val_loss: 0.7471 - val_accuracy: 0.7602\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3666 - accuracy: 0.9177 - val_loss: 0.7270 - val_accuracy: 0.7557\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3464 - accuracy: 0.9293 - val_loss: 0.7412 - val_accuracy: 0.7602\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3377 - accuracy: 0.9386 - val_loss: 0.8101 - val_accuracy: 0.7330\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3468 - accuracy: 0.9329 - val_loss: 0.7712 - val_accuracy: 0.7557\n","Epoch 46/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3404 - accuracy: 0.9344 - val_loss: 0.7826 - val_accuracy: 0.7455\n","Epoch 47/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3484 - accuracy: 0.9327 - val_loss: 0.7540 - val_accuracy: 0.7647\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3236 - accuracy: 0.9434 - val_loss: 0.7551 - val_accuracy: 0.7613\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3435 - accuracy: 0.9315 - val_loss: 0.8076 - val_accuracy: 0.7376\n","Epoch 50/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3666 - accuracy: 0.9196 - val_loss: 0.7491 - val_accuracy: 0.7624\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3331 - accuracy: 0.9420 - val_loss: 0.7710 - val_accuracy: 0.7579\n","Epoch 52/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3573 - accuracy: 0.9287 - val_loss: 0.9067 - val_accuracy: 0.7127\n","Epoch 53/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3494 - accuracy: 0.9270 - val_loss: 0.7906 - val_accuracy: 0.7568\n","Epoch 54/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3357 - accuracy: 0.9363 - val_loss: 0.8030 - val_accuracy: 0.7376\n","Epoch 55/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3290 - accuracy: 0.9403 - val_loss: 0.7795 - val_accuracy: 0.7658\n","Epoch 56/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3169 - accuracy: 0.9471 - val_loss: 0.7826 - val_accuracy: 0.7477\n","Epoch 57/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3204 - accuracy: 0.9462 - val_loss: 0.7971 - val_accuracy: 0.7466\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3467 - accuracy: 0.9307 - val_loss: 0.7949 - val_accuracy: 0.7704\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3242 - accuracy: 0.9426 - val_loss: 0.8160 - val_accuracy: 0.7330\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3218 - accuracy: 0.9428 - val_loss: 0.7939 - val_accuracy: 0.7511\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3184 - accuracy: 0.9474 - val_loss: 0.8547 - val_accuracy: 0.7466\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3355 - accuracy: 0.9352 - val_loss: 0.8118 - val_accuracy: 0.7455\n","Epoch 63/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3091 - accuracy: 0.9479 - val_loss: 0.7949 - val_accuracy: 0.7523\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3109 - accuracy: 0.9468 - val_loss: 0.8105 - val_accuracy: 0.7545\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3075 - accuracy: 0.9510 - val_loss: 0.8133 - val_accuracy: 0.7557\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3119 - accuracy: 0.9468 - val_loss: 0.8272 - val_accuracy: 0.7353\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3118 - accuracy: 0.9477 - val_loss: 0.9797 - val_accuracy: 0.7172\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3083 - accuracy: 0.9448 - val_loss: 0.8041 - val_accuracy: 0.7636\n","Epoch 69/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3057 - accuracy: 0.9508 - val_loss: 0.8442 - val_accuracy: 0.7410\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3076 - accuracy: 0.9420 - val_loss: 0.8374 - val_accuracy: 0.7443\n","Epoch 71/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3052 - accuracy: 0.9505 - val_loss: 0.8118 - val_accuracy: 0.7568\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3042 - accuracy: 0.9493 - val_loss: 0.8133 - val_accuracy: 0.7613\n","Epoch 73/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3028 - accuracy: 0.9502 - val_loss: 0.8107 - val_accuracy: 0.7500\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2974 - accuracy: 0.9530 - val_loss: 0.8415 - val_accuracy: 0.7443\n","Epoch 75/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2973 - accuracy: 0.9544 - val_loss: 0.8416 - val_accuracy: 0.7557\n","Epoch 76/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3040 - accuracy: 0.9485 - val_loss: 1.0540 - val_accuracy: 0.7036\n","Epoch 77/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3325 - accuracy: 0.9352 - val_loss: 0.8828 - val_accuracy: 0.7432\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3231 - accuracy: 0.9406 - val_loss: 1.0008 - val_accuracy: 0.7093\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3484 - accuracy: 0.9284 - val_loss: 0.8535 - val_accuracy: 0.7523\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3012 - accuracy: 0.9505 - val_loss: 0.8589 - val_accuracy: 0.7262\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2899 - accuracy: 0.9573 - val_loss: 0.8418 - val_accuracy: 0.7410\n","Epoch 82/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2940 - accuracy: 0.9539 - val_loss: 0.8869 - val_accuracy: 0.7364\n","Epoch 83/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3002 - accuracy: 0.9496 - val_loss: 0.8251 - val_accuracy: 0.7466\n","Epoch 84/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2995 - accuracy: 0.9519 - val_loss: 0.8235 - val_accuracy: 0.7466\n","Epoch 85/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2950 - accuracy: 0.9525 - val_loss: 0.8783 - val_accuracy: 0.7443\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3038 - accuracy: 0.9468 - val_loss: 0.8773 - val_accuracy: 0.7398\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2941 - accuracy: 0.9542 - val_loss: 0.8232 - val_accuracy: 0.7489\n","Epoch 88/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2863 - accuracy: 0.9615 - val_loss: 0.9919 - val_accuracy: 0.7115\n","Epoch 89/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2922 - accuracy: 0.9516 - val_loss: 0.8474 - val_accuracy: 0.7511\n","Epoch 90/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2821 - accuracy: 0.9626 - val_loss: 0.8512 - val_accuracy: 0.7489\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2711 - accuracy: 0.9666 - val_loss: 0.8721 - val_accuracy: 0.7624\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2824 - accuracy: 0.9593 - val_loss: 0.8747 - val_accuracy: 0.7364\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2701 - accuracy: 0.9686 - val_loss: 0.8429 - val_accuracy: 0.7455\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2817 - accuracy: 0.9559 - val_loss: 0.8882 - val_accuracy: 0.7511\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2830 - accuracy: 0.9559 - val_loss: 0.8821 - val_accuracy: 0.7443\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2660 - accuracy: 0.9672 - val_loss: 0.8856 - val_accuracy: 0.7421\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2725 - accuracy: 0.9638 - val_loss: 0.8738 - val_accuracy: 0.7624\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2683 - accuracy: 0.9643 - val_loss: 0.9028 - val_accuracy: 0.7410\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2789 - accuracy: 0.9581 - val_loss: 0.8786 - val_accuracy: 0.7342\n","Epoch 100/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2786 - accuracy: 0.9584 - val_loss: 0.8889 - val_accuracy: 0.7387\n","{'loss': [0.5307941436767578, 0.44281792640686035, 0.43405234813690186, 0.43305066227912903, 0.44900694489479065, 0.4421422779560089, 0.423895001411438, 0.42553284764289856, 0.41768503189086914, 0.41979798674583435, 0.4098067283630371, 0.404802531003952, 0.4054121971130371, 0.4087061882019043, 0.3988617956638336, 0.4048444628715515, 0.3956877887248993, 0.39672228693962097, 0.39416390657424927, 0.40234026312828064, 0.4289042055606842, 0.39107176661491394, 0.389016717672348, 0.39875492453575134, 0.3896067440509796, 0.3777928650379181, 0.3900699019432068, 0.38283732533454895, 0.38961806893348694, 0.3581065535545349, 0.369497150182724, 0.366682767868042, 0.36407145857810974, 0.35835057497024536, 0.3656713366508484, 0.3550693690776825, 0.34748539328575134, 0.3556120991706848, 0.3748749792575836, 0.3457992970943451, 0.33880066871643066, 0.3665767014026642, 0.3463634252548218, 0.3376631736755371, 0.34684109687805176, 0.34038540720939636, 0.34844523668289185, 0.32363763451576233, 0.34354960918426514, 0.36655890941619873, 0.33311450481414795, 0.35728421807289124, 0.34937331080436707, 0.3357056677341461, 0.3289545774459839, 0.31693097949028015, 0.32035472989082336, 0.34666669368743896, 0.3241669833660126, 0.32181358337402344, 0.3183710277080536, 0.3355271816253662, 0.3091418445110321, 0.3108859658241272, 0.3074774444103241, 0.311862051486969, 0.31177863478660583, 0.30827203392982483, 0.3056710660457611, 0.3075547218322754, 0.305189847946167, 0.304185152053833, 0.3028252422809601, 0.2974001467227936, 0.297305703163147, 0.30398669838905334, 0.33250322937965393, 0.3230929970741272, 0.34838175773620605, 0.3012382984161377, 0.28985559940338135, 0.29400330781936646, 0.3001840114593506, 0.29947394132614136, 0.29496854543685913, 0.30383118987083435, 0.29408779740333557, 0.28632181882858276, 0.29218143224716187, 0.28205928206443787, 0.27111759781837463, 0.2823750078678131, 0.27005812525749207, 0.28171178698539734, 0.28297168016433716, 0.26603010296821594, 0.27251535654067993, 0.2682980000972748, 0.2788585126399994, 0.27860772609710693], 'accuracy': [0.8483304977416992, 0.8953027725219727, 0.8899264335632324, 0.8919072151184082, 0.8853989839553833, 0.8902093768119812, 0.8961516618728638, 0.8992642760276794, 0.9018110036849976, 0.901528000831604, 0.9063384532928467, 0.9083191752433777, 0.9117147922515869, 0.9043576717376709, 0.916242241859436, 0.9080362319946289, 0.9170911312103271, 0.9119977355003357, 0.916242241859436, 0.9071873426437378, 0.8910582661628723, 0.9105829000473022, 0.9108659029006958, 0.9077532291412354, 0.9139785170555115, 0.9185059666633606, 0.912563681602478, 0.9142614603042603, 0.9080362319946289, 0.9312393665313721, 0.9252971410751343, 0.9241652488708496, 0.926711916923523, 0.9318053126335144, 0.9275608658790588, 0.9320882558822632, 0.9380305409431458, 0.9320882558822632, 0.9156762957572937, 0.9323712587356567, 0.9383135437965393, 0.9176570177078247, 0.9292586445808411, 0.9385964870452881, 0.9329372048377991, 0.9343519806861877, 0.9326542019844055, 0.943406879901886, 0.9315223693847656, 0.9196377992630005, 0.9419921040534973, 0.9286926984786987, 0.9269949197769165, 0.9363327622413635, 0.9402942657470703, 0.947085440158844, 0.9462365508079529, 0.9306734800338745, 0.9425579905509949, 0.9428409934043884, 0.9473684430122375, 0.9352009296417236, 0.9479343295097351, 0.9468024969100952, 0.9510469436645508, 0.9468024969100952, 0.9476513862609863, 0.9448217153549194, 0.950764000415802, 0.9419921040534973, 0.9504810571670532, 0.9493491649627686, 0.9501980543136597, 0.9530277252197266, 0.95444256067276, 0.9485002756118774, 0.9352009296417236, 0.9405772686004639, 0.92840975522995, 0.9504810571670532, 0.9572722315788269, 0.9538766145706177, 0.9496321678161621, 0.9518958926200867, 0.9524617791175842, 0.9468024969100952, 0.9541596174240112, 0.9615166783332825, 0.9516128897666931, 0.9626485705375671, 0.9666100740432739, 0.9592529535293579, 0.9685908555984497, 0.9558573961257935, 0.9558573961257935, 0.9671760201454163, 0.963780403137207, 0.9643463492393494, 0.958121120929718, 0.9584040641784668], 'val_loss': [0.9151477217674255, 0.9057589173316956, 0.8861865401268005, 0.8593588471412659, 0.8560537099838257, 0.8587893843650818, 0.8652422428131104, 0.8590519428253174, 0.8627974987030029, 0.8629978895187378, 0.8660417199134827, 0.8800803422927856, 0.9010714292526245, 0.9179226160049438, 0.9307334423065186, 0.975241482257843, 0.9980456233024597, 1.0170966386795044, 1.0412096977233887, 0.9067819118499756, 0.9210165143013, 0.8402354121208191, 0.9146739840507507, 0.7825443148612976, 0.7848175168037415, 0.7849054336547852, 0.7244556546211243, 0.7082670331001282, 0.703650951385498, 0.7189427018165588, 0.7141676545143127, 0.7490046620368958, 0.7146985530853271, 0.7381937503814697, 0.7285089492797852, 0.7296791076660156, 0.7529702186584473, 0.7944270968437195, 0.7497423887252808, 0.7588188052177429, 0.7471374273300171, 0.7270077466964722, 0.7411996126174927, 0.8101454377174377, 0.7711751461029053, 0.7825648784637451, 0.7539576888084412, 0.7550767660140991, 0.8075540065765381, 0.7491281628608704, 0.7709964513778687, 0.9067480564117432, 0.7906123399734497, 0.8029768466949463, 0.7794988751411438, 0.7825939059257507, 0.7971373200416565, 0.7949066758155823, 0.8160277009010315, 0.793857991695404, 0.8546949028968811, 0.8118108510971069, 0.7948794960975647, 0.8104598522186279, 0.8132579922676086, 0.8272284865379333, 0.9797179698944092, 0.8041146993637085, 0.8442400097846985, 0.8373593688011169, 0.8117920160293579, 0.8132549524307251, 0.8106814026832581, 0.8414871692657471, 0.841605007648468, 1.0540046691894531, 0.8827552199363708, 1.00081205368042, 0.8534888625144958, 0.8588841557502747, 0.8418471217155457, 0.88692307472229, 0.8250879049301147, 0.8234708905220032, 0.8782796263694763, 0.8772796988487244, 0.823184072971344, 0.9918954372406006, 0.8474050164222717, 0.8511727452278137, 0.8720679879188538, 0.8746999502182007, 0.8428910970687866, 0.8882130980491638, 0.8820631504058838, 0.8856118321418762, 0.8738338947296143, 0.9028298258781433, 0.8786467909812927, 0.888930082321167], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.5, 0.5497737526893616, 0.5554298758506775, 0.5588235259056091, 0.5588235259056091, 0.5791855454444885, 0.5904977321624756, 0.587104082107544, 0.5848416090011597, 0.5780543088912964, 0.587104082107544, 0.5893664956092834, 0.5950226187705994, 0.5972850918769836, 0.6131221652030945, 0.6119909286499023, 0.6323529481887817, 0.6459276080131531, 0.6674208045005798, 0.6900452375411987, 0.6809954643249512, 0.7285068035125732, 0.7296379804611206, 0.7432126402854919, 0.7511312365531921, 0.7533936500549316, 0.7726244330406189, 0.7692307829856873, 0.7556561231613159, 0.75, 0.7726244330406189, 0.766968309879303, 0.7601810097694397, 0.7601810097694397, 0.7714931964874268, 0.7375565767288208, 0.7443438768386841, 0.7477375268936157, 0.7601810097694397, 0.7556561231613159, 0.7601810097694397, 0.733031690120697, 0.7556561231613159, 0.7454751133918762, 0.7647058963775635, 0.7613122463226318, 0.7375565767288208, 0.7624434232711792, 0.7579185366630554, 0.7126696705818176, 0.7567873597145081, 0.7375565767288208, 0.7658371329307556, 0.7477375268936157, 0.7466063499450684, 0.7703620195388794, 0.733031690120697, 0.7511312365531921, 0.7466063499450684, 0.7454751133918762, 0.7522624731063843, 0.7545248866081238, 0.7556561231613159, 0.7352941036224365, 0.7171945571899414, 0.7635746598243713, 0.7409502267837524, 0.7443438768386841, 0.7567873597145081, 0.7613122463226318, 0.75, 0.7443438768386841, 0.7556561231613159, 0.7036198973655701, 0.7432126402854919, 0.709276020526886, 0.7522624731063843, 0.726244330406189, 0.7409502267837524, 0.7364253401756287, 0.7466063499450684, 0.7466063499450684, 0.7443438768386841, 0.7398189902305603, 0.7488687634468079, 0.7115384340286255, 0.7511312365531921, 0.7488687634468079, 0.7624434232711792, 0.7364253401756287, 0.7454751133918762, 0.7511312365531921, 0.7443438768386841, 0.7420814633369446, 0.7624434232711792, 0.7409502267837524, 0.7341628670692444, 0.7386877536773682]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 18, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 18, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 9, 256)            0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 9, 256)            196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 5, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 5, 512)            393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 3, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 1, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 1, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               131584    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3838529 (14.64 MB)\n","Trainable params: 3838017 (14.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.4985 - accuracy: 0.8641"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 50ms/step - loss: 0.4949 - accuracy: 0.8659 - val_loss: 0.9216 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4869 - accuracy: 0.8690 - val_loss: 0.9102 - val_accuracy: 0.4897\n","Epoch 3/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4618 - accuracy: 0.8765 - val_loss: 0.8829 - val_accuracy: 0.5248\n","Epoch 4/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4877 - accuracy: 0.8594 - val_loss: 0.8869 - val_accuracy: 0.5258\n","Epoch 5/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4622 - accuracy: 0.8775 - val_loss: 0.8819 - val_accuracy: 0.5455\n","Epoch 6/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4629 - accuracy: 0.8698 - val_loss: 0.8666 - val_accuracy: 0.5496\n","Epoch 7/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4524 - accuracy: 0.8868 - val_loss: 0.8630 - val_accuracy: 0.5496\n","Epoch 8/100\n","31/31 [==============================] - 2s 59ms/step - loss: 0.4455 - accuracy: 0.8811 - val_loss: 0.8762 - val_accuracy: 0.5517\n","Epoch 9/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4444 - accuracy: 0.8871 - val_loss: 0.8829 - val_accuracy: 0.5568\n","Epoch 10/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4432 - accuracy: 0.8873 - val_loss: 0.8902 - val_accuracy: 0.5630\n","Epoch 11/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4439 - accuracy: 0.8819 - val_loss: 0.9044 - val_accuracy: 0.5568\n","Epoch 12/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4285 - accuracy: 0.8956 - val_loss: 0.9363 - val_accuracy: 0.5775\n","Epoch 13/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4272 - accuracy: 0.8959 - val_loss: 0.9675 - val_accuracy: 0.5837\n","Epoch 14/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4167 - accuracy: 0.8966 - val_loss: 1.0247 - val_accuracy: 0.5878\n","Epoch 15/100\n","31/31 [==============================] - 2s 53ms/step - loss: 0.4222 - accuracy: 0.8961 - val_loss: 1.0474 - val_accuracy: 0.5919\n","Epoch 16/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4506 - accuracy: 0.8796 - val_loss: 1.0944 - val_accuracy: 0.5930\n","Epoch 17/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4488 - accuracy: 0.8755 - val_loss: 1.1441 - val_accuracy: 0.5950\n","Epoch 18/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4312 - accuracy: 0.8899 - val_loss: 1.1747 - val_accuracy: 0.5992\n","Epoch 19/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4248 - accuracy: 0.8941 - val_loss: 0.9718 - val_accuracy: 0.6343\n","Epoch 20/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4233 - accuracy: 0.8938 - val_loss: 1.1970 - val_accuracy: 0.6116\n","Epoch 21/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4049 - accuracy: 0.9016 - val_loss: 0.9400 - val_accuracy: 0.6570\n","Epoch 22/100\n","31/31 [==============================] - 3s 110ms/step - loss: 0.4063 - accuracy: 0.8987 - val_loss: 0.9226 - val_accuracy: 0.6798\n","Epoch 23/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.3983 - accuracy: 0.9096 - val_loss: 0.8627 - val_accuracy: 0.7097\n","Epoch 24/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4146 - accuracy: 0.8972 - val_loss: 0.7848 - val_accuracy: 0.7252\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4067 - accuracy: 0.9021 - val_loss: 0.8433 - val_accuracy: 0.7149\n","Epoch 26/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3952 - accuracy: 0.9085 - val_loss: 0.7880 - val_accuracy: 0.7428\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4120 - accuracy: 0.8995 - val_loss: 0.7762 - val_accuracy: 0.7417\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3882 - accuracy: 0.9103 - val_loss: 0.7859 - val_accuracy: 0.7366\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4039 - accuracy: 0.8997 - val_loss: 0.7993 - val_accuracy: 0.7355\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3872 - accuracy: 0.9109 - val_loss: 0.7835 - val_accuracy: 0.7376\n","Epoch 31/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3929 - accuracy: 0.9101 - val_loss: 0.7825 - val_accuracy: 0.7500\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3786 - accuracy: 0.9155 - val_loss: 0.7814 - val_accuracy: 0.7386\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4180 - accuracy: 0.8894 - val_loss: 0.8557 - val_accuracy: 0.7335\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4059 - accuracy: 0.8961 - val_loss: 0.8538 - val_accuracy: 0.7211\n","Epoch 35/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3929 - accuracy: 0.9103 - val_loss: 0.8118 - val_accuracy: 0.7428\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3826 - accuracy: 0.9124 - val_loss: 0.7905 - val_accuracy: 0.7376\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3726 - accuracy: 0.9276 - val_loss: 0.8228 - val_accuracy: 0.7345\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3727 - accuracy: 0.9199 - val_loss: 0.8136 - val_accuracy: 0.7386\n","Epoch 39/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3818 - accuracy: 0.9150 - val_loss: 0.8324 - val_accuracy: 0.7345\n","Epoch 40/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3758 - accuracy: 0.9109 - val_loss: 0.8181 - val_accuracy: 0.7448\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3769 - accuracy: 0.9160 - val_loss: 0.8371 - val_accuracy: 0.7428\n","Epoch 42/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3679 - accuracy: 0.9178 - val_loss: 0.8377 - val_accuracy: 0.7459\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3722 - accuracy: 0.9163 - val_loss: 0.8220 - val_accuracy: 0.7386\n","Epoch 44/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3784 - accuracy: 0.9132 - val_loss: 0.9544 - val_accuracy: 0.7107\n","Epoch 45/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3971 - accuracy: 0.9021 - val_loss: 0.8558 - val_accuracy: 0.7314\n","Epoch 46/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3617 - accuracy: 0.9202 - val_loss: 0.8457 - val_accuracy: 0.7283\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3704 - accuracy: 0.9199 - val_loss: 0.8879 - val_accuracy: 0.7262\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3760 - accuracy: 0.9173 - val_loss: 0.8114 - val_accuracy: 0.7407\n","Epoch 49/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3612 - accuracy: 0.9214 - val_loss: 0.8210 - val_accuracy: 0.7469\n","Epoch 50/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3569 - accuracy: 0.9264 - val_loss: 0.8703 - val_accuracy: 0.7345\n","Epoch 51/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3517 - accuracy: 0.9256 - val_loss: 0.8378 - val_accuracy: 0.7366\n","Epoch 52/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3681 - accuracy: 0.9163 - val_loss: 0.8687 - val_accuracy: 0.7293\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3703 - accuracy: 0.9191 - val_loss: 1.0696 - val_accuracy: 0.6798\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3971 - accuracy: 0.9062 - val_loss: 0.9094 - val_accuracy: 0.7159\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3515 - accuracy: 0.9276 - val_loss: 0.8477 - val_accuracy: 0.7304\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3404 - accuracy: 0.9349 - val_loss: 0.8424 - val_accuracy: 0.7376\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3393 - accuracy: 0.9354 - val_loss: 0.8590 - val_accuracy: 0.7335\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3365 - accuracy: 0.9367 - val_loss: 0.8653 - val_accuracy: 0.7345\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3554 - accuracy: 0.9209 - val_loss: 0.8908 - val_accuracy: 0.7273\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3376 - accuracy: 0.9295 - val_loss: 0.8517 - val_accuracy: 0.7324\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3531 - accuracy: 0.9253 - val_loss: 0.8698 - val_accuracy: 0.7314\n","Epoch 62/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3493 - accuracy: 0.9289 - val_loss: 0.8499 - val_accuracy: 0.7366\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3382 - accuracy: 0.9380 - val_loss: 0.8695 - val_accuracy: 0.7397\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3329 - accuracy: 0.9323 - val_loss: 0.9307 - val_accuracy: 0.7211\n","Epoch 65/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3390 - accuracy: 0.9318 - val_loss: 0.8724 - val_accuracy: 0.7252\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3349 - accuracy: 0.9364 - val_loss: 0.8926 - val_accuracy: 0.7252\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3316 - accuracy: 0.9364 - val_loss: 0.8870 - val_accuracy: 0.7304\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3338 - accuracy: 0.9320 - val_loss: 0.8781 - val_accuracy: 0.7366\n","Epoch 69/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3277 - accuracy: 0.9393 - val_loss: 0.9090 - val_accuracy: 0.7335\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3312 - accuracy: 0.9336 - val_loss: 0.9101 - val_accuracy: 0.7314\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3345 - accuracy: 0.9336 - val_loss: 0.9024 - val_accuracy: 0.7304\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3237 - accuracy: 0.9390 - val_loss: 0.9132 - val_accuracy: 0.7293\n","Epoch 73/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3134 - accuracy: 0.9429 - val_loss: 0.9021 - val_accuracy: 0.7273\n","Epoch 74/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3263 - accuracy: 0.9382 - val_loss: 0.8832 - val_accuracy: 0.7314\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3158 - accuracy: 0.9463 - val_loss: 0.9345 - val_accuracy: 0.7293\n","Epoch 76/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3169 - accuracy: 0.9421 - val_loss: 0.8951 - val_accuracy: 0.7293\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3168 - accuracy: 0.9385 - val_loss: 0.8929 - val_accuracy: 0.7345\n","Epoch 78/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3067 - accuracy: 0.9499 - val_loss: 1.0040 - val_accuracy: 0.7128\n","Epoch 79/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3194 - accuracy: 0.9413 - val_loss: 0.9293 - val_accuracy: 0.7231\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3174 - accuracy: 0.9432 - val_loss: 0.9052 - val_accuracy: 0.7335\n","Epoch 81/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3118 - accuracy: 0.9429 - val_loss: 0.9226 - val_accuracy: 0.7355\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3065 - accuracy: 0.9506 - val_loss: 0.9090 - val_accuracy: 0.7324\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3127 - accuracy: 0.9411 - val_loss: 0.9173 - val_accuracy: 0.7273\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3115 - accuracy: 0.9416 - val_loss: 0.9175 - val_accuracy: 0.7293\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2934 - accuracy: 0.9512 - val_loss: 0.9508 - val_accuracy: 0.7273\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3166 - accuracy: 0.9429 - val_loss: 0.9402 - val_accuracy: 0.7304\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2983 - accuracy: 0.9509 - val_loss: 0.9397 - val_accuracy: 0.7283\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2996 - accuracy: 0.9522 - val_loss: 0.9299 - val_accuracy: 0.7459\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3198 - accuracy: 0.9388 - val_loss: 0.9373 - val_accuracy: 0.7283\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3228 - accuracy: 0.9370 - val_loss: 1.0287 - val_accuracy: 0.7107\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3204 - accuracy: 0.9419 - val_loss: 1.0192 - val_accuracy: 0.7118\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3405 - accuracy: 0.9274 - val_loss: 0.9260 - val_accuracy: 0.7211\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3018 - accuracy: 0.9481 - val_loss: 0.9783 - val_accuracy: 0.7159\n","Epoch 94/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2936 - accuracy: 0.9496 - val_loss: 0.9189 - val_accuracy: 0.7366\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2839 - accuracy: 0.9553 - val_loss: 0.9497 - val_accuracy: 0.7180\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2829 - accuracy: 0.9566 - val_loss: 0.9693 - val_accuracy: 0.7293\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2915 - accuracy: 0.9506 - val_loss: 1.0507 - val_accuracy: 0.7211\n","Epoch 98/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3011 - accuracy: 0.9465 - val_loss: 0.9480 - val_accuracy: 0.7231\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2815 - accuracy: 0.9543 - val_loss: 0.9577 - val_accuracy: 0.7335\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2853 - accuracy: 0.9561 - val_loss: 1.0216 - val_accuracy: 0.7242\n","{'loss': [0.49489733576774597, 0.4869160056114197, 0.46178513765335083, 0.48771750926971436, 0.4622430205345154, 0.4628952741622925, 0.45238178968429565, 0.44550570845603943, 0.44438642263412476, 0.4431600868701935, 0.443885862827301, 0.42847520112991333, 0.42721793055534363, 0.4167313575744629, 0.4222363829612732, 0.45063871145248413, 0.4487552344799042, 0.4312207102775574, 0.4247797727584839, 0.42329856753349304, 0.40492966771125793, 0.4063378572463989, 0.3983428180217743, 0.4146448075771332, 0.40671834349632263, 0.39521560072898865, 0.41199633479118347, 0.38815972208976746, 0.4038577675819397, 0.3871995806694031, 0.39293575286865234, 0.3786308169364929, 0.4180089235305786, 0.40592649579048157, 0.3928891718387604, 0.382638156414032, 0.37257644534111023, 0.37274494767189026, 0.3817811608314514, 0.3758208751678467, 0.376905620098114, 0.36790037155151367, 0.37217971682548523, 0.37844809889793396, 0.39706963300704956, 0.3617251515388489, 0.3704140782356262, 0.37603211402893066, 0.36116573214530945, 0.35688573122024536, 0.35168731212615967, 0.36811012029647827, 0.3703058063983917, 0.3970792293548584, 0.3515080511569977, 0.3404429852962494, 0.3393489122390747, 0.3365420997142792, 0.35535311698913574, 0.3375721275806427, 0.3530937731266022, 0.34933462738990784, 0.3381526470184326, 0.3329329788684845, 0.3389878571033478, 0.3349320590496063, 0.3316044211387634, 0.333768755197525, 0.32772403955459595, 0.3311649560928345, 0.3345482051372528, 0.3236802816390991, 0.31339454650878906, 0.3263014853000641, 0.31575843691825867, 0.31692013144493103, 0.31682950258255005, 0.30673307180404663, 0.3193540573120117, 0.31735217571258545, 0.31175267696380615, 0.30653640627861023, 0.31265202164649963, 0.31147482991218567, 0.2933853268623352, 0.3165513873100281, 0.298340380191803, 0.29956790804862976, 0.3198010325431824, 0.32283031940460205, 0.3204059600830078, 0.3404718339443207, 0.3018127381801605, 0.2935798168182373, 0.2839072644710541, 0.2829085886478424, 0.29153570532798767, 0.30114948749542236, 0.2814672887325287, 0.28528934717178345], 'accuracy': [0.8658914566040039, 0.868992269039154, 0.8764857649803162, 0.8594315052032471, 0.8775193691253662, 0.869767427444458, 0.8868216872215271, 0.881136953830719, 0.8870801329612732, 0.8873385190963745, 0.8819121718406677, 0.8956072330474854, 0.8958656191825867, 0.8966408371925354, 0.896124005317688, 0.8795865774154663, 0.8754522204399109, 0.8899224996566772, 0.8940568566322327, 0.8937984704971313, 0.9015504121780396, 0.8987079858779907, 0.9095607399940491, 0.897157609462738, 0.9020671844482422, 0.908527135848999, 0.8994832038879395, 0.910335898399353, 0.8997415900230408, 0.9108527302742004, 0.9100775122642517, 0.9155038595199585, 0.8894056677818298, 0.896124005317688, 0.910335898399353, 0.9124031066894531, 0.9276486039161682, 0.91989666223526, 0.9149870872497559, 0.9108527302742004, 0.9160206913948059, 0.9178294539451599, 0.9162790775299072, 0.9131782650947571, 0.9020671844482422, 0.9201550483703613, 0.91989666223526, 0.9173126816749573, 0.9214470386505127, 0.9263566136360168, 0.9255813956260681, 0.9162790775299072, 0.9191214442253113, 0.9062015414237976, 0.9276486039161682, 0.934883713722229, 0.9354005455970764, 0.9366925358772278, 0.9209302067756653, 0.9294573664665222, 0.9253230094909668, 0.9289405941963196, 0.9379844665527344, 0.9322997331619263, 0.9317829608917236, 0.9364340901374817, 0.9364340901374817, 0.932041347026825, 0.9392764568328857, 0.9335917234420776, 0.9335917234420776, 0.9390180706977844, 0.9428940415382385, 0.9382429122924805, 0.94625324010849, 0.9421188831329346, 0.9385012984275818, 0.9498708248138428, 0.9413436651229858, 0.9431524276733398, 0.9428940415382385, 0.9506459832191467, 0.9410852789878845, 0.9416020512580872, 0.9511628150939941, 0.9428940415382385, 0.950904369354248, 0.9521963596343994, 0.9387596845626831, 0.9369509220123291, 0.9418604373931885, 0.9273901581764221, 0.948062002658844, 0.9496123790740967, 0.9552971720695496, 0.9565891623497009, 0.9506459832191467, 0.9465116262435913, 0.9542635679244995, 0.9560723304748535], 'val_loss': [0.921623170375824, 0.9101792573928833, 0.8829195499420166, 0.8869460821151733, 0.8819007277488708, 0.8665502667427063, 0.8629950881004333, 0.876190185546875, 0.882880449295044, 0.8901915550231934, 0.9043751358985901, 0.9362764954566956, 0.9674800634384155, 1.0247260332107544, 1.04738187789917, 1.0944139957427979, 1.1441107988357544, 1.1747472286224365, 0.9717608094215393, 1.1970411539077759, 0.9399661421775818, 0.9226184487342834, 0.862710177898407, 0.7847882509231567, 0.843271017074585, 0.7879794239997864, 0.7762246131896973, 0.785905122756958, 0.7992963790893555, 0.78354412317276, 0.7825331687927246, 0.781446099281311, 0.8556684851646423, 0.8538461327552795, 0.8117619156837463, 0.7905446290969849, 0.8228161931037903, 0.8135883808135986, 0.8323798179626465, 0.8181334137916565, 0.8370851874351501, 0.8377058506011963, 0.8219817876815796, 0.954373300075531, 0.8557759523391724, 0.8456814885139465, 0.8879384398460388, 0.8114330172538757, 0.8210254907608032, 0.8702700138092041, 0.8378074169158936, 0.8686607480049133, 1.0696473121643066, 0.9094187021255493, 0.847699761390686, 0.8423832058906555, 0.8589726686477661, 0.8653334975242615, 0.8907507061958313, 0.8516790866851807, 0.8697852492332458, 0.84991455078125, 0.8695277571678162, 0.9306527972221375, 0.872409462928772, 0.8925747275352478, 0.8869622349739075, 0.8781192898750305, 0.9090457558631897, 0.9101307392120361, 0.9023597240447998, 0.9131970405578613, 0.9020895957946777, 0.8832284212112427, 0.9344989657402039, 0.8950555324554443, 0.8929029703140259, 1.003989577293396, 0.9293410778045654, 0.9051641225814819, 0.9226178526878357, 0.9090096950531006, 0.9172827005386353, 0.9175142645835876, 0.9507853388786316, 0.9402168393135071, 0.939695417881012, 0.9299047589302063, 0.9373023509979248, 1.0286980867385864, 1.019209384918213, 0.9260386228561401, 0.9782808423042297, 0.9188547730445862, 0.9497460126876831, 0.9692884683609009, 1.0506865978240967, 0.9479838609695435, 0.9576845765113831, 1.0215916633605957], 'val_accuracy': [0.48553720116615295, 0.48966941237449646, 0.5247933864593506, 0.5258264541625977, 0.5454545617103577, 0.5495867729187012, 0.5495867729187012, 0.5516529083251953, 0.5568181872367859, 0.5630165338516235, 0.5568181872367859, 0.577479362487793, 0.5836777091026306, 0.5878099203109741, 0.5919421315193176, 0.5929751992225647, 0.5950413346290588, 0.5991735458374023, 0.6342975497245789, 0.6115702390670776, 0.6570248007774353, 0.6797520518302917, 0.7097107172012329, 0.7252066135406494, 0.7148760557174683, 0.7427685856819153, 0.7417355179786682, 0.7365702390670776, 0.7355371713638306, 0.7376033067703247, 0.75, 0.7386363744735718, 0.7334710955619812, 0.7210744023323059, 0.7427685856819153, 0.7376033067703247, 0.7345041036605835, 0.7386363744735718, 0.7345041036605835, 0.7448347210884094, 0.7427685856819153, 0.7458677887916565, 0.7386363744735718, 0.71074378490448, 0.7314049601554871, 0.7283057570457458, 0.7262396812438965, 0.7407024502754211, 0.7469007968902588, 0.7345041036605835, 0.7365702390670776, 0.7293388247489929, 0.6797520518302917, 0.7159090638160706, 0.73037189245224, 0.7376033067703247, 0.7334710955619812, 0.7345041036605835, 0.7272727489471436, 0.7324380278587341, 0.7314049601554871, 0.7365702390670776, 0.7396694421768188, 0.7210744023323059, 0.7252066135406494, 0.7252066135406494, 0.73037189245224, 0.7365702390670776, 0.7334710955619812, 0.7314049601554871, 0.73037189245224, 0.7293388247489929, 0.7272727489471436, 0.7314049601554871, 0.7293388247489929, 0.7293388247489929, 0.7345041036605835, 0.7128099203109741, 0.7231404781341553, 0.7334710955619812, 0.7355371713638306, 0.7324380278587341, 0.7272727489471436, 0.7293388247489929, 0.7272727489471436, 0.73037189245224, 0.7283057570457458, 0.7458677887916565, 0.7283057570457458, 0.71074378490448, 0.711776852607727, 0.7210744023323059, 0.7159090638160706, 0.7365702390670776, 0.7179751992225647, 0.7293388247489929, 0.7210744023323059, 0.7231404781341553, 0.7334710955619812, 0.7241735458374023]}\n","32/32 [==============================] - 1s 3ms/step\n"]}]},{"cell_type":"code","source":["metrics_df_gru"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":519},"id":"01_-d_1wzf7I","executionInfo":{"status":"ok","timestamp":1717500387322,"user_tz":-360,"elapsed":42,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"accc06e5-1d89-450d-f298-6f137da087ef"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision    Recall        F1  Sensitivity  Specificity  \\\n","0        0  0.539363   0.542342  0.504188  0.522569     0.504188     0.574539   \n","1        1  0.560028   0.560801  0.553672  0.557214     0.553672     0.566384   \n","2        2  0.559237   0.555347  0.594378  0.574200     0.594378     0.524096   \n","3        0  0.578727   0.604444  0.455611  0.519580     0.455611     0.701843   \n","4        1  0.572740   0.568942  0.600282  0.584192     0.600282     0.545198   \n","5        2  0.594378   0.587361  0.634538  0.610039     0.634538     0.554217   \n","6        0  0.613903   0.619718  0.589615  0.604292     0.589615     0.638191   \n","7        1  0.615819   0.614525  0.621469  0.617978     0.621469     0.610169   \n","8        2  0.641566   0.643585  0.634538  0.639029     0.634538     0.648594   \n","9        0  0.677554   0.692029  0.639866  0.664926     0.639866     0.715243   \n","10       1  0.661017   0.658774  0.668079  0.663394     0.668079     0.653955   \n","11       2  0.703815   0.683544  0.759036  0.719315     0.759036     0.648594   \n","12       0  0.719430   0.724315  0.708543  0.716342     0.708543     0.730318   \n","13       1  0.718220   0.753695  0.648305  0.697039     0.648305     0.788136   \n","14       2  0.753012   0.729927  0.803213  0.764818     0.803213     0.702811   \n","\n","       Kappa  \n","0   0.078727  \n","1   0.120056  \n","2   0.118474  \n","3   0.157454  \n","4   0.145480  \n","5   0.188755  \n","6   0.227806  \n","7   0.231638  \n","8   0.283133  \n","9   0.355109  \n","10  0.322034  \n","11  0.407631  \n","12  0.438861  \n","13  0.436441  \n","14  0.506024  "],"text/html":["\n","  <div id=\"df-52efd296-11ce-42be-8b1b-01a166ae9434\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.539363</td>\n","      <td>0.542342</td>\n","      <td>0.504188</td>\n","      <td>0.522569</td>\n","      <td>0.504188</td>\n","      <td>0.574539</td>\n","      <td>0.078727</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.560028</td>\n","      <td>0.560801</td>\n","      <td>0.553672</td>\n","      <td>0.557214</td>\n","      <td>0.553672</td>\n","      <td>0.566384</td>\n","      <td>0.120056</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.559237</td>\n","      <td>0.555347</td>\n","      <td>0.594378</td>\n","      <td>0.574200</td>\n","      <td>0.594378</td>\n","      <td>0.524096</td>\n","      <td>0.118474</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.578727</td>\n","      <td>0.604444</td>\n","      <td>0.455611</td>\n","      <td>0.519580</td>\n","      <td>0.455611</td>\n","      <td>0.701843</td>\n","      <td>0.157454</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.572740</td>\n","      <td>0.568942</td>\n","      <td>0.600282</td>\n","      <td>0.584192</td>\n","      <td>0.600282</td>\n","      <td>0.545198</td>\n","      <td>0.145480</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.594378</td>\n","      <td>0.587361</td>\n","      <td>0.634538</td>\n","      <td>0.610039</td>\n","      <td>0.634538</td>\n","      <td>0.554217</td>\n","      <td>0.188755</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.613903</td>\n","      <td>0.619718</td>\n","      <td>0.589615</td>\n","      <td>0.604292</td>\n","      <td>0.589615</td>\n","      <td>0.638191</td>\n","      <td>0.227806</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.615819</td>\n","      <td>0.614525</td>\n","      <td>0.621469</td>\n","      <td>0.617978</td>\n","      <td>0.621469</td>\n","      <td>0.610169</td>\n","      <td>0.231638</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.641566</td>\n","      <td>0.643585</td>\n","      <td>0.634538</td>\n","      <td>0.639029</td>\n","      <td>0.634538</td>\n","      <td>0.648594</td>\n","      <td>0.283133</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.677554</td>\n","      <td>0.692029</td>\n","      <td>0.639866</td>\n","      <td>0.664926</td>\n","      <td>0.639866</td>\n","      <td>0.715243</td>\n","      <td>0.355109</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.661017</td>\n","      <td>0.658774</td>\n","      <td>0.668079</td>\n","      <td>0.663394</td>\n","      <td>0.668079</td>\n","      <td>0.653955</td>\n","      <td>0.322034</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.703815</td>\n","      <td>0.683544</td>\n","      <td>0.759036</td>\n","      <td>0.719315</td>\n","      <td>0.759036</td>\n","      <td>0.648594</td>\n","      <td>0.407631</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.719430</td>\n","      <td>0.724315</td>\n","      <td>0.708543</td>\n","      <td>0.716342</td>\n","      <td>0.708543</td>\n","      <td>0.730318</td>\n","      <td>0.438861</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.718220</td>\n","      <td>0.753695</td>\n","      <td>0.648305</td>\n","      <td>0.697039</td>\n","      <td>0.648305</td>\n","      <td>0.788136</td>\n","      <td>0.436441</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.753012</td>\n","      <td>0.729927</td>\n","      <td>0.803213</td>\n","      <td>0.764818</td>\n","      <td>0.803213</td>\n","      <td>0.702811</td>\n","      <td>0.506024</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52efd296-11ce-42be-8b1b-01a166ae9434')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-52efd296-11ce-42be-8b1b-01a166ae9434 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-52efd296-11ce-42be-8b1b-01a166ae9434');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-23aba87c-4c1a-4613-8e6d-20a62a892dc8\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-23aba87c-4c1a-4613-8e6d-20a62a892dc8')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-23aba87c-4c1a-4613-8e6d-20a62a892dc8 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_5b58480a-6db7-4b94-b932-16d6b6948849\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('metrics_df_gru')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_5b58480a-6db7-4b94-b932-16d6b6948849 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('metrics_df_gru');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"metrics_df_gru","summary":"{\n  \"name\": \"metrics_df_gru\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0682658641139153,\n        \"min\": 0.5393634840871022,\n        \"max\": 0.7530120481927711,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.6775544388609716,\n          0.7038152610441767,\n          0.5393634840871022\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06864284711397199,\n        \"min\": 0.5423423423423424,\n        \"max\": 0.7536945812807881,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.6920289855072463,\n          0.6835443037974683,\n          0.5423423423423424\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0888768732734151,\n        \"min\": 0.4556113902847571,\n        \"max\": 0.8032128514056225,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.6680790960451978,\n          0.7085427135678392,\n          0.5041876046901173\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07366180673849179,\n        \"min\": 0.5195797516714422,\n        \"max\": 0.7648183556405354,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.6649260226283725,\n          0.7193149381541389,\n          0.5225694444444444\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0888768732734151,\n        \"min\": 0.4556113902847571,\n        \"max\": 0.8032128514056225,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.6680790960451978,\n          0.7085427135678392,\n          0.5041876046901173\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0775758971622534,\n        \"min\": 0.5240963855421686,\n        \"max\": 0.788135593220339,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.7152428810720268,\n          0.7303182579564489,\n          0.5745393634840871\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1365317282278306,\n        \"min\": 0.07872696817420433,\n        \"max\": 0.5060240963855422,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.355108877721943,\n          0.4076305220883534,\n          0.07872696817420433\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["metrics_df_gru.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/Time Domain/CNN_GRU/Alpha_time_GRU.csv', index = False)"],"metadata":{"id":"Dew-b3DezjAQ","executionInfo":{"status":"ok","timestamp":1717500387323,"user_tz":-360,"elapsed":36,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1l_Td-l70e4U"},"execution_count":null,"outputs":[]}]}